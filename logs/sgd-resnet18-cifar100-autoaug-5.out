The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1038
Batch 20, Loss: 4.1917
Batch 30, Loss: 3.9810
Batch 40, Loss: 3.8262
Batch 50, Loss: 3.7643
Batch 60, Loss: 3.7508
Batch 70, Loss: 3.6929
Batch 80, Loss: 3.6278
Batch 90, Loss: 3.6539
Batch 100, Loss: 3.6462
Batch 110, Loss: 3.6116
Batch 120, Loss: 3.5917
Batch 130, Loss: 3.6013
Batch 140, Loss: 3.5823
Batch 150, Loss: 3.5775
Batch 160, Loss: 3.5827
Batch 170, Loss: 3.5443
Batch 180, Loss: 3.5606
Batch 190, Loss: 3.5329
Batch 200, Loss: 3.5457
Batch 210, Loss: 3.5166
Batch 220, Loss: 3.5421
Batch 230, Loss: 3.5007
Batch 240, Loss: 3.4971
Batch 250, Loss: 3.4624
Batch 260, Loss: 3.4616
Batch 270, Loss: 3.4859
Batch 280, Loss: 3.5189
Batch 290, Loss: 3.4880
Batch 300, Loss: 3.4554
Batch 310, Loss: 3.4821
Batch 320, Loss: 3.4450
Batch 330, Loss: 3.4102
Batch 340, Loss: 3.4609
Batch 350, Loss: 3.4373
Batch 360, Loss: 3.4195
Batch 370, Loss: 3.4136
Batch 380, Loss: 3.3895
Batch 390, Loss: 3.4156
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.300874948501587 seconds
Epoch 1 accuracy: 8.27%
Batch 10, Loss: 3.4225
Batch 20, Loss: 3.3827
Batch 30, Loss: 3.4167
Batch 40, Loss: 3.3999
Batch 50, Loss: 3.3929
Batch 60, Loss: 3.3930
Batch 70, Loss: 3.3907
Batch 80, Loss: 3.3410
Batch 90, Loss: 3.3644
Batch 100, Loss: 3.3217
Batch 110, Loss: 3.3430
Batch 120, Loss: 3.3771
Batch 130, Loss: 3.4078
Batch 140, Loss: 3.3078
Batch 150, Loss: 3.3206
Batch 160, Loss: 3.3595
Batch 170, Loss: 3.2995
Batch 180, Loss: 3.2830
Batch 190, Loss: 3.2916
Batch 200, Loss: 3.2920
Batch 210, Loss: 3.3267
Batch 220, Loss: 3.3420
Batch 230, Loss: 3.2229
Batch 240, Loss: 3.2895
Batch 250, Loss: 3.2716
Batch 260, Loss: 3.2263
Batch 270, Loss: 3.2032
Batch 280, Loss: 3.1726
Batch 290, Loss: 3.2341
Batch 300, Loss: 3.1741
Batch 310, Loss: 3.2094
Batch 320, Loss: 3.1896
Batch 330, Loss: 3.1826
Batch 340, Loss: 3.1858
Batch 350, Loss: 3.2013
Batch 360, Loss: 3.2122
Batch 370, Loss: 3.2107
Batch 380, Loss: 3.1955
Batch 390, Loss: 3.1713
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.245173454284668 seconds
Epoch 2 accuracy: 15.8%
Batch 10, Loss: 3.1331
Batch 20, Loss: 3.1207
Batch 30, Loss: 3.1388
Batch 40, Loss: 3.1427
Batch 50, Loss: 3.1609
Batch 60, Loss: 3.1630
Batch 70, Loss: 3.0780
Batch 80, Loss: 3.1322
Batch 90, Loss: 3.0814
Batch 100, Loss: 3.1095
Batch 110, Loss: 3.0604
Batch 120, Loss: 3.0248
Batch 130, Loss: 3.0733
Batch 140, Loss: 3.0423
Batch 150, Loss: 3.0523
Batch 160, Loss: 2.9574
Batch 170, Loss: 2.9755
Batch 180, Loss: 3.0317
Batch 190, Loss: 2.9785
Batch 200, Loss: 2.9977
Batch 210, Loss: 3.0056
Batch 220, Loss: 3.0253
Batch 230, Loss: 3.0362
Batch 240, Loss: 2.9509
Batch 250, Loss: 3.0015
Batch 260, Loss: 2.9736
Batch 270, Loss: 3.0107
Batch 280, Loss: 2.9975
Batch 290, Loss: 2.9067
Batch 300, Loss: 2.8890
Batch 310, Loss: 2.9206
Batch 320, Loss: 2.9576
Batch 330, Loss: 2.9637
Batch 340, Loss: 2.9391
Batch 350, Loss: 2.9527
Batch 360, Loss: 2.9412
Batch 370, Loss: 2.8727
Batch 380, Loss: 2.9035
Batch 390, Loss: 2.7502
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.24854850769043 seconds
Epoch 3 accuracy: 21.18%
Batch 10, Loss: 2.8190
Batch 20, Loss: 2.8089
Batch 30, Loss: 2.8562
Batch 40, Loss: 2.8506
Batch 50, Loss: 2.8285
Batch 60, Loss: 2.8212
Batch 70, Loss: 2.8453
Batch 80, Loss: 2.7870
Batch 90, Loss: 2.8189
Batch 100, Loss: 2.7778
Batch 110, Loss: 2.7956
Batch 120, Loss: 2.7145
Batch 130, Loss: 2.7706
Batch 140, Loss: 2.7319
Batch 150, Loss: 2.6981
Batch 160, Loss: 2.7865
Batch 170, Loss: 2.7108
Batch 180, Loss: 2.6779
Batch 190, Loss: 2.6681
Batch 200, Loss: 2.7250
Batch 210, Loss: 2.6820
Batch 220, Loss: 2.7449
Batch 230, Loss: 2.6688
Batch 240, Loss: 2.6958
Batch 250, Loss: 2.7102
Batch 260, Loss: 2.7224
Batch 270, Loss: 2.6541
Batch 280, Loss: 2.6732
Batch 290, Loss: 2.6732
Batch 300, Loss: 2.5983
Batch 310, Loss: 2.5948
Batch 320, Loss: 2.5819
Batch 330, Loss: 2.6290
Batch 340, Loss: 2.6348
Batch 350, Loss: 2.6177
Batch 360, Loss: 2.5997
Batch 370, Loss: 2.6333
Batch 380, Loss: 2.6350
Batch 390, Loss: 2.6379
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.304313898086548 seconds
Epoch 4 accuracy: 27.44%
Batch 10, Loss: 2.5977
Batch 20, Loss: 2.5235
Batch 30, Loss: 2.5152
Batch 40, Loss: 2.5315
Batch 50, Loss: 2.5444
Batch 60, Loss: 2.6166
Batch 70, Loss: 2.5470
Batch 80, Loss: 2.5204
Batch 90, Loss: 2.5016
Batch 100, Loss: 2.4794
Batch 110, Loss: 2.5577
Batch 120, Loss: 2.5431
Batch 130, Loss: 2.5371
Batch 140, Loss: 2.5569
Batch 150, Loss: 2.5007
Batch 160, Loss: 2.4591
Batch 170, Loss: 2.4557
Batch 180, Loss: 2.4296
Batch 190, Loss: 2.3909
Batch 200, Loss: 2.5126
Batch 210, Loss: 2.4976
Batch 220, Loss: 2.4568
Batch 230, Loss: 2.4628
Batch 240, Loss: 2.5124
Batch 250, Loss: 2.4520
Batch 260, Loss: 2.3896
Batch 270, Loss: 2.4154
Batch 280, Loss: 2.4205
Batch 290, Loss: 2.4293
Batch 300, Loss: 2.3508
Batch 310, Loss: 2.4138
Batch 320, Loss: 2.4046
Batch 330, Loss: 2.4190
Batch 340, Loss: 2.4468
Batch 350, Loss: 2.4443
Batch 360, Loss: 2.3215
Batch 370, Loss: 2.4188
Batch 380, Loss: 2.3206
Batch 390, Loss: 2.3820
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.126811504364014 seconds
Epoch 5 accuracy: 35.58%
Batch 10, Loss: 2.3209
Batch 20, Loss: 2.3980
Batch 30, Loss: 2.3491
Batch 40, Loss: 2.3508
Batch 50, Loss: 2.4081
Batch 60, Loss: 2.3674
Batch 70, Loss: 2.3230
Batch 80, Loss: 2.3007
Batch 90, Loss: 2.3326
Batch 100, Loss: 2.3273
Batch 110, Loss: 2.2831
Batch 120, Loss: 2.2589
Batch 130, Loss: 2.2655
Batch 140, Loss: 2.2985
Batch 150, Loss: 2.2685
Batch 160, Loss: 2.2890
Batch 170, Loss: 2.2904
Batch 180, Loss: 2.3271
Batch 190, Loss: 2.2868
Batch 200, Loss: 2.2786
Batch 210, Loss: 2.3305
Batch 220, Loss: 2.2985
Batch 230, Loss: 2.2829
Batch 240, Loss: 2.3247
Batch 250, Loss: 2.2521
Batch 260, Loss: 2.2426
Batch 270, Loss: 2.2664
Batch 280, Loss: 2.1797
Batch 290, Loss: 2.2583
Batch 300, Loss: 2.3173
Batch 310, Loss: 2.2494
Batch 320, Loss: 2.2989
Batch 330, Loss: 2.1734
Batch 340, Loss: 2.1755
Batch 350, Loss: 2.2638
Batch 360, Loss: 2.1899
Batch 370, Loss: 2.2313
Batch 380, Loss: 2.1863
Batch 390, Loss: 2.2064
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.134536743164062 seconds
Epoch 6 accuracy: 39.79%
Batch 10, Loss: 2.1518
Batch 20, Loss: 2.2106
Batch 30, Loss: 2.2111
Batch 40, Loss: 2.2206
Batch 50, Loss: 2.1941
Batch 60, Loss: 2.1022
Batch 70, Loss: 2.1472
Batch 80, Loss: 2.1750
Batch 90, Loss: 2.2190
Batch 100, Loss: 2.1017
Batch 110, Loss: 2.1452
Batch 120, Loss: 2.2025
Batch 130, Loss: 2.1688
Batch 140, Loss: 2.1418
Batch 150, Loss: 2.1171
Batch 160, Loss: 2.1551
Batch 170, Loss: 2.1292
Batch 180, Loss: 2.1314
Batch 190, Loss: 2.1850
Batch 200, Loss: 2.1625
Batch 210, Loss: 2.0885
Batch 220, Loss: 2.1160
Batch 230, Loss: 2.1435
Batch 240, Loss: 2.1350
Batch 250, Loss: 2.1428
Batch 260, Loss: 2.0528
Batch 270, Loss: 2.0892
Batch 280, Loss: 2.1136
Batch 290, Loss: 2.1287
Batch 300, Loss: 2.1680
Batch 310, Loss: 2.1272
Batch 320, Loss: 2.2174
Batch 330, Loss: 2.1155
Batch 340, Loss: 2.1652
Batch 350, Loss: 2.1272
Batch 360, Loss: 2.1198
Batch 370, Loss: 2.0763
Batch 380, Loss: 2.1028
Batch 390, Loss: 2.0781
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.254597902297974 seconds
Epoch 7 accuracy: 40.3%
Batch 10, Loss: 2.0179
Batch 20, Loss: 2.0317
Batch 30, Loss: 2.0436
Batch 40, Loss: 2.0256
Batch 50, Loss: 2.0348
Batch 60, Loss: 2.0603
Batch 70, Loss: 2.0929
Batch 80, Loss: 2.1848
Batch 90, Loss: 2.0681
Batch 100, Loss: 2.0233
Batch 110, Loss: 1.9597
Batch 120, Loss: 2.0540
Batch 130, Loss: 2.0709
Batch 140, Loss: 2.0440
Batch 150, Loss: 2.0147
Batch 160, Loss: 2.1065
Batch 170, Loss: 2.0729
Batch 180, Loss: 2.0307
Batch 190, Loss: 2.0653
Batch 200, Loss: 1.9541
Batch 210, Loss: 2.0210
Batch 220, Loss: 1.9880
Batch 230, Loss: 1.9810
Batch 240, Loss: 2.0331
Batch 250, Loss: 2.0523
Batch 260, Loss: 2.0136
Batch 270, Loss: 1.9721
Batch 280, Loss: 2.0659
Batch 290, Loss: 2.0664
Batch 300, Loss: 2.0279
Batch 310, Loss: 1.9956
Batch 320, Loss: 1.9690
Batch 330, Loss: 2.0585
Batch 340, Loss: 1.9948
Batch 350, Loss: 1.9916
Batch 360, Loss: 2.0019
Batch 370, Loss: 2.1096
Batch 380, Loss: 1.9754
Batch 390, Loss: 1.9679
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.220283269882202 seconds
Epoch 8 accuracy: 44.42%
Batch 10, Loss: 1.8927
Batch 20, Loss: 1.9520
Batch 30, Loss: 1.9031
Batch 40, Loss: 1.9774
Batch 50, Loss: 1.8963
Batch 60, Loss: 1.9434
Batch 70, Loss: 1.9096
Batch 80, Loss: 1.9676
Batch 90, Loss: 1.8921
Batch 100, Loss: 1.9604
Batch 110, Loss: 1.9983
Batch 120, Loss: 1.9777
Batch 130, Loss: 2.0737
Batch 140, Loss: 1.9435
Batch 150, Loss: 1.9995
Batch 160, Loss: 1.8925
Batch 170, Loss: 1.9505
Batch 180, Loss: 1.9693
Batch 190, Loss: 2.0114
Batch 200, Loss: 1.9197
Batch 210, Loss: 1.9555
Batch 220, Loss: 1.9619
Batch 230, Loss: 2.0048
Batch 240, Loss: 2.0088
Batch 250, Loss: 2.0058
Batch 260, Loss: 2.0071
Batch 270, Loss: 1.9704
Batch 280, Loss: 2.0258
Batch 290, Loss: 1.9843
Batch 300, Loss: 1.9164
Batch 310, Loss: 1.9647
Batch 320, Loss: 1.9546
Batch 330, Loss: 1.9292
Batch 340, Loss: 1.9589
Batch 350, Loss: 1.8818
Batch 360, Loss: 1.9462
Batch 370, Loss: 1.9622
Batch 380, Loss: 1.9881
Batch 390, Loss: 1.8541
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.154475688934326 seconds
Epoch 9 accuracy: 43.71%
Batch 10, Loss: 1.8704
Batch 20, Loss: 1.8936
Batch 30, Loss: 1.8716
Batch 40, Loss: 1.8384
Batch 50, Loss: 1.9125
Batch 60, Loss: 1.9542
Batch 70, Loss: 1.9246
Batch 80, Loss: 1.9076
Batch 90, Loss: 1.8721
Batch 100, Loss: 1.9318
Batch 110, Loss: 1.8827
Batch 120, Loss: 1.8553
Batch 130, Loss: 1.9204
Batch 140, Loss: 1.8695
Batch 150, Loss: 1.8952
Batch 160, Loss: 1.9450
Batch 170, Loss: 1.9332
Batch 180, Loss: 1.8374
Batch 190, Loss: 1.9123
Batch 200, Loss: 1.8142
Batch 210, Loss: 1.8286
Batch 220, Loss: 1.8899
Batch 230, Loss: 1.8162
Batch 240, Loss: 1.9440
Batch 250, Loss: 1.9373
Batch 260, Loss: 1.9101
Batch 270, Loss: 1.8926
Batch 280, Loss: 1.8657
Batch 290, Loss: 1.8491
Batch 300, Loss: 1.8819
Batch 310, Loss: 1.9726
Batch 320, Loss: 1.8617
Batch 330, Loss: 1.9179
Batch 340, Loss: 1.8727
Batch 350, Loss: 1.9065
Batch 360, Loss: 1.8619
Batch 370, Loss: 1.8342
Batch 380, Loss: 1.8596
Batch 390, Loss: 1.9429
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.198198795318604 seconds
Epoch 10 accuracy: 44.44%
Batch 10, Loss: 1.8882
Batch 20, Loss: 1.8469
Batch 30, Loss: 1.8145
Batch 40, Loss: 1.7325
Batch 50, Loss: 1.8145
Batch 60, Loss: 1.7930
Batch 70, Loss: 1.8356
Batch 80, Loss: 1.8331
Batch 90, Loss: 1.8179
Batch 100, Loss: 1.8368
Batch 110, Loss: 1.8298
Batch 120, Loss: 1.8393
Batch 130, Loss: 1.8028
Batch 140, Loss: 1.7981
Batch 150, Loss: 1.9307
Batch 160, Loss: 1.8278
Batch 170, Loss: 1.7899
Batch 180, Loss: 1.8090
Batch 190, Loss: 1.8512
Batch 200, Loss: 1.8653
Batch 210, Loss: 1.7960
Batch 220, Loss: 1.8227
Batch 230, Loss: 1.8250
Batch 240, Loss: 1.8832
Batch 250, Loss: 1.8816
Batch 260, Loss: 1.8251
Batch 270, Loss: 1.8710
Batch 280, Loss: 1.9055
Batch 290, Loss: 1.8299
Batch 300, Loss: 1.8286
Batch 310, Loss: 1.8664
Batch 320, Loss: 1.8179
Batch 330, Loss: 1.7652
Batch 340, Loss: 1.7894
Batch 350, Loss: 1.8374
Batch 360, Loss: 1.7995
Batch 370, Loss: 1.8610
Batch 380, Loss: 1.7496
Batch 390, Loss: 1.8526
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.198565006256104 seconds
Epoch 11 accuracy: 45.7%
Batch 10, Loss: 1.7812
Batch 20, Loss: 1.7800
Batch 30, Loss: 1.8651
Batch 40, Loss: 1.8145
Batch 50, Loss: 1.7722
Batch 60, Loss: 1.7489
Batch 70, Loss: 1.7529
Batch 80, Loss: 1.7132
Batch 90, Loss: 1.7950
Batch 100, Loss: 1.7375
Batch 110, Loss: 1.7903
Batch 120, Loss: 1.7093
Batch 130, Loss: 1.8535
Batch 140, Loss: 1.8397
Batch 150, Loss: 1.8477
Batch 160, Loss: 1.7817
Batch 170, Loss: 1.8306
Batch 180, Loss: 1.7742
Batch 190, Loss: 1.8466
Batch 200, Loss: 1.7739
Batch 210, Loss: 1.7654
Batch 220, Loss: 1.8463
Batch 230, Loss: 1.7625
Batch 240, Loss: 1.7669
Batch 250, Loss: 1.7956
Batch 260, Loss: 1.7206
Batch 270, Loss: 1.7605
Batch 280, Loss: 1.8666
Batch 290, Loss: 1.7956
Batch 300, Loss: 1.8176
Batch 310, Loss: 1.7192
Batch 320, Loss: 1.7923
Batch 330, Loss: 1.8014
Batch 340, Loss: 1.8223
Batch 350, Loss: 1.7132
Batch 360, Loss: 1.8316
Batch 370, Loss: 1.8193
Batch 380, Loss: 1.8287
Batch 390, Loss: 1.8181
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.090967416763306 seconds
Epoch 12 accuracy: 47.56%
Batch 10, Loss: 1.7353
Batch 20, Loss: 1.6781
Batch 30, Loss: 1.7349
Batch 40, Loss: 1.7403
Batch 50, Loss: 1.8176
Batch 60, Loss: 1.7634
Batch 70, Loss: 1.7570
Batch 80, Loss: 1.7332
Batch 90, Loss: 1.7995
Batch 100, Loss: 1.7514
Batch 110, Loss: 1.7446
Batch 120, Loss: 1.7533
Batch 130, Loss: 1.7339
Batch 140, Loss: 1.7403
Batch 150, Loss: 1.7432
Batch 160, Loss: 1.8008
Batch 170, Loss: 1.7391
Batch 180, Loss: 1.7380
Batch 190, Loss: 1.7273
Batch 200, Loss: 1.7686
Batch 210, Loss: 1.7840
Batch 220, Loss: 1.7432
Batch 230, Loss: 1.7558
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7641
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7843
Batch 280, Loss: 1.7779
Batch 290, Loss: 1.8461
Batch 300, Loss: 1.7811
Batch 310, Loss: 1.7834
Batch 320, Loss: 1.7690
Batch 330, Loss: 1.7817
Batch 340, Loss: 1.6984
Batch 350, Loss: 1.7814
Batch 360, Loss: 1.7263
Batch 370, Loss: 1.7646
Batch 380, Loss: 1.7506
Batch 390, Loss: 1.7504
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.11466383934021 seconds
Epoch 13 accuracy: 48.7%
Batch 10, Loss: 1.7621
Batch 20, Loss: 1.7267
Batch 30, Loss: 1.6868
Batch 40, Loss: 1.6540
Batch 50, Loss: 1.7004
Batch 60, Loss: 1.6560
Batch 70, Loss: 1.6846
Batch 80, Loss: 1.7464
Batch 90, Loss: 1.6694
Batch 100, Loss: 1.7473
Batch 110, Loss: 1.7533
Batch 120, Loss: 1.7380
Batch 130, Loss: 1.7080
Batch 140, Loss: 1.6505
Batch 150, Loss: 1.7816
Batch 160, Loss: 1.7695
Batch 170, Loss: 1.7116
Batch 180, Loss: 1.6595
Batch 190, Loss: 1.7468
Batch 200, Loss: 1.7356
Batch 210, Loss: 1.7786
Batch 220, Loss: 1.7720
Batch 230, Loss: 1.7561
Batch 240, Loss: 1.7691
Batch 250, Loss: 1.7813
Batch 260, Loss: 1.7019
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7219
Batch 290, Loss: 1.6713
Batch 300, Loss: 1.6858
Batch 310, Loss: 1.7187
Batch 320, Loss: 1.8005
Batch 330, Loss: 1.7594
Batch 340, Loss: 1.7026
Batch 350, Loss: 1.6739
Batch 360, Loss: 1.7320
Batch 370, Loss: 1.7039
Batch 380, Loss: 1.7910
Batch 390, Loss: 1.7279
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.237462520599365 seconds
Epoch 14 accuracy: 49.78%
Batch 10, Loss: 1.7162
Batch 20, Loss: 1.6955
Batch 30, Loss: 1.6527
Batch 40, Loss: 1.7162
Batch 50, Loss: 1.6846
Batch 60, Loss: 1.7082
Batch 70, Loss: 1.6814
Batch 80, Loss: 1.6712
Batch 90, Loss: 1.7561
Batch 100, Loss: 1.6665
Batch 110, Loss: 1.6790
Batch 120, Loss: 1.7070
Batch 130, Loss: 1.6759
Batch 140, Loss: 1.6427
Batch 150, Loss: 1.6820
Batch 160, Loss: 1.7032
Batch 170, Loss: 1.6628
Batch 180, Loss: 1.6778
Batch 190, Loss: 1.6473
Batch 200, Loss: 1.7272
Batch 210, Loss: 1.7347
Batch 220, Loss: 1.7461
Batch 230, Loss: 1.7072
Batch 240, Loss: 1.7002
Batch 250, Loss: 1.6621
Batch 260, Loss: 1.8097
Batch 270, Loss: 1.6895
Batch 280, Loss: 1.6687
Batch 290, Loss: 1.6646
Batch 300, Loss: 1.7653
Batch 310, Loss: 1.6792
Batch 320, Loss: 1.7313
Batch 330, Loss: 1.7000
Batch 340, Loss: 1.6634
Batch 350, Loss: 1.7704
Batch 360, Loss: 1.6788
Batch 370, Loss: 1.7008
Batch 380, Loss: 1.7471
Batch 390, Loss: 1.7834
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.20536518096924 seconds
Epoch 15 accuracy: 51.03%
Batch 10, Loss: 1.6921
Batch 20, Loss: 1.6990
Batch 30, Loss: 1.6059
Batch 40, Loss: 1.6066
Batch 50, Loss: 1.6584
Batch 60, Loss: 1.6278
Batch 70, Loss: 1.6732
Batch 80, Loss: 1.6521
Batch 90, Loss: 1.6199
Batch 100, Loss: 1.6357
Batch 110, Loss: 1.6491
Batch 120, Loss: 1.7226
Batch 130, Loss: 1.7010
Batch 140, Loss: 1.6835
Batch 150, Loss: 1.7613
Batch 160, Loss: 1.7330
Batch 170, Loss: 1.6719
Batch 180, Loss: 1.6468
Batch 190, Loss: 1.6489
Batch 200, Loss: 1.6580
Batch 210, Loss: 1.6894
Batch 220, Loss: 1.7297
Batch 230, Loss: 1.6933
Batch 240, Loss: 1.7369
Batch 250, Loss: 1.7357
Batch 260, Loss: 1.7534
Batch 270, Loss: 1.6571
Batch 280, Loss: 1.6519
Batch 290, Loss: 1.7259
Batch 300, Loss: 1.7090
Batch 310, Loss: 1.6819
Batch 320, Loss: 1.6287
Batch 330, Loss: 1.7034
Batch 340, Loss: 1.6698
Batch 350, Loss: 1.7302
Batch 360, Loss: 1.6537
Batch 370, Loss: 1.6726
Batch 380, Loss: 1.7749
Batch 390, Loss: 1.7272
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.09868550300598 seconds
Epoch 16 accuracy: 53.0%
Batch 10, Loss: 1.6060
Batch 20, Loss: 1.6183
Batch 30, Loss: 1.6027
Batch 40, Loss: 1.6993
Batch 50, Loss: 1.6528
Batch 60, Loss: 1.6071
Batch 70, Loss: 1.7314
Batch 80, Loss: 1.6552
Batch 90, Loss: 1.7058
Batch 100, Loss: 1.6595
Batch 110, Loss: 1.6217
Batch 120, Loss: 1.6046
Batch 130, Loss: 1.6780
Batch 140, Loss: 1.6539
Batch 150, Loss: 1.6353
Batch 160, Loss: 1.6705
Batch 170, Loss: 1.7411
Batch 180, Loss: 1.7044
Batch 190, Loss: 1.6672
Batch 200, Loss: 1.6522
Batch 210, Loss: 1.6165
Batch 220, Loss: 1.7213
Batch 230, Loss: 1.6889
Batch 240, Loss: 1.6940
Batch 250, Loss: 1.6512
Batch 260, Loss: 1.6197
Batch 270, Loss: 1.6919
Batch 280, Loss: 1.6928
Batch 290, Loss: 1.6756
Batch 300, Loss: 1.6727
Batch 310, Loss: 1.6427
Batch 320, Loss: 1.6953
Batch 330, Loss: 1.6797
Batch 340, Loss: 1.7332
Batch 350, Loss: 1.7003
Batch 360, Loss: 1.5807
Batch 370, Loss: 1.6816
Batch 380, Loss: 1.7368
Batch 390, Loss: 1.6386
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.07147765159607 seconds
Epoch 17 accuracy: 43.92%
Batch 10, Loss: 1.6643
Batch 20, Loss: 1.6748
Batch 30, Loss: 1.6244
Batch 40, Loss: 1.5837
Batch 50, Loss: 1.6134
Batch 60, Loss: 1.5169
Batch 70, Loss: 1.6105
Batch 80, Loss: 1.5677
Batch 90, Loss: 1.5887
Batch 100, Loss: 1.6447
Batch 110, Loss: 1.6868
Batch 120, Loss: 1.5958
Batch 130, Loss: 1.6891
Batch 140, Loss: 1.6505
Batch 150, Loss: 1.7232
Batch 160, Loss: 1.6456
Batch 170, Loss: 1.7015
Batch 180, Loss: 1.5295
Batch 190, Loss: 1.6878
Batch 200, Loss: 1.6651
Batch 210, Loss: 1.6120
Batch 220, Loss: 1.5906
Batch 230, Loss: 1.6497
Batch 240, Loss: 1.5832
Batch 250, Loss: 1.6323
Batch 260, Loss: 1.5379
Batch 270, Loss: 1.6636
Batch 280, Loss: 1.6134
Batch 290, Loss: 1.6769
Batch 300, Loss: 1.7401
Batch 310, Loss: 1.6191
Batch 320, Loss: 1.6585
Batch 330, Loss: 1.6852
Batch 340, Loss: 1.6951
Batch 350, Loss: 1.6441
Batch 360, Loss: 1.6600
Batch 370, Loss: 1.6893
Batch 380, Loss: 1.6275
Batch 390, Loss: 1.6193
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.098954677581787 seconds
Epoch 18 accuracy: 52.59%
Batch 10, Loss: 1.5172
Batch 20, Loss: 1.5704
Batch 30, Loss: 1.5764
Batch 40, Loss: 1.6099
Batch 50, Loss: 1.5994
Batch 60, Loss: 1.5596
Batch 70, Loss: 1.6011
Batch 80, Loss: 1.5788
Batch 90, Loss: 1.5484
Batch 100, Loss: 1.5843
Batch 110, Loss: 1.6148
Batch 120, Loss: 1.7161
Batch 130, Loss: 1.6378
Batch 140, Loss: 1.5466
Batch 150, Loss: 1.6422
Batch 160, Loss: 1.5499
Batch 170, Loss: 1.5742
Batch 180, Loss: 1.6844
Batch 190, Loss: 1.6542
Batch 200, Loss: 1.6250
Batch 210, Loss: 1.6523
Batch 220, Loss: 1.6296
Batch 230, Loss: 1.6462
Batch 240, Loss: 1.6605
Batch 250, Loss: 1.6561
Batch 260, Loss: 1.6905
Batch 270, Loss: 1.6040
Batch 280, Loss: 1.6522
Batch 290, Loss: 1.6672
Batch 300, Loss: 1.6674
Batch 310, Loss: 1.6599
Batch 320, Loss: 1.5672
Batch 330, Loss: 1.6166
Batch 340, Loss: 1.6073
Batch 350, Loss: 1.5961
Batch 360, Loss: 1.6079
Batch 370, Loss: 1.6218
Batch 380, Loss: 1.6250
Batch 390, Loss: 1.6312
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.077281951904297 seconds
Epoch 19 accuracy: 56.4%
Batch 10, Loss: 1.6011
Batch 20, Loss: 1.6279
Batch 30, Loss: 1.5295
Batch 40, Loss: 1.6352
Batch 50, Loss: 1.5892
Batch 60, Loss: 1.5765
Batch 70, Loss: 1.5660
Batch 80, Loss: 1.6301
Batch 90, Loss: 1.5964
Batch 100, Loss: 1.5382
Batch 110, Loss: 1.6365
Batch 120, Loss: 1.5771
Batch 130, Loss: 1.6100
Batch 140, Loss: 1.5910
Batch 150, Loss: 1.6560
Batch 160, Loss: 1.6163
Batch 170, Loss: 1.5622
Batch 180, Loss: 1.6203
Batch 190, Loss: 1.6757
Batch 200, Loss: 1.6185
Batch 210, Loss: 1.6201
Batch 220, Loss: 1.6381
Batch 230, Loss: 1.5806
Batch 240, Loss: 1.5695
Batch 250, Loss: 1.5708
Batch 260, Loss: 1.6740
Batch 270, Loss: 1.6335
Batch 280, Loss: 1.6040
Batch 290, Loss: 1.6083
Batch 300, Loss: 1.5852
Batch 310, Loss: 1.6930
Batch 320, Loss: 1.5679
Batch 330, Loss: 1.6026
Batch 340, Loss: 1.6250
Batch 350, Loss: 1.5568
Batch 360, Loss: 1.6412
Batch 370, Loss: 1.6810
Batch 380, Loss: 1.6135
Batch 390, Loss: 1.5788
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.162240743637085 seconds
Epoch 20 accuracy: 50.83%
Batch 10, Loss: 1.5517
Batch 20, Loss: 1.5486
Batch 30, Loss: 1.5946
Batch 40, Loss: 1.5211
Batch 50, Loss: 1.5440
Batch 60, Loss: 1.5947
Batch 70, Loss: 1.5643
Batch 80, Loss: 1.6084
Batch 90, Loss: 1.5639
Batch 100, Loss: 1.5756
Batch 110, Loss: 1.6147
Batch 120, Loss: 1.6319
Batch 130, Loss: 1.5806
Batch 140, Loss: 1.5813
Batch 150, Loss: 1.5372
Batch 160, Loss: 1.6346
Batch 170, Loss: 1.6118
Batch 180, Loss: 1.5849
Batch 190, Loss: 1.5484
Batch 200, Loss: 1.5456
Batch 210, Loss: 1.6205
Batch 220, Loss: 1.5967
Batch 230, Loss: 1.6445
Batch 240, Loss: 1.6253
Batch 250, Loss: 1.5990
Batch 260, Loss: 1.6393
Batch 270, Loss: 1.6514
Batch 280, Loss: 1.6382
Batch 290, Loss: 1.7000
Batch 300, Loss: 1.6419
Batch 310, Loss: 1.6461
Batch 320, Loss: 1.6006
Batch 330, Loss: 1.5791
Batch 340, Loss: 1.6298
Batch 350, Loss: 1.6408
Batch 360, Loss: 1.6113
Batch 370, Loss: 1.6172
Batch 380, Loss: 1.6930
Batch 390, Loss: 1.6189
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.1617214679718 seconds
Epoch 21 accuracy: 53.13%
Batch 10, Loss: 1.5287
Batch 20, Loss: 1.6281
Batch 30, Loss: 1.5426
Batch 40, Loss: 1.5822
Batch 50, Loss: 1.5792
Batch 60, Loss: 1.6220
Batch 70, Loss: 1.5773
Batch 80, Loss: 1.5318
Batch 90, Loss: 1.6288
Batch 100, Loss: 1.5573
Batch 110, Loss: 1.4957
Batch 120, Loss: 1.5521
Batch 130, Loss: 1.5660
Batch 140, Loss: 1.5364
Batch 150, Loss: 1.5607
Batch 160, Loss: 1.5691
Batch 170, Loss: 1.5386
Batch 180, Loss: 1.5914
Batch 190, Loss: 1.5801
Batch 200, Loss: 1.5935
Batch 210, Loss: 1.5160
Batch 220, Loss: 1.5700
Batch 230, Loss: 1.6106
Batch 240, Loss: 1.5903
Batch 250, Loss: 1.6839
Batch 260, Loss: 1.5845
Batch 270, Loss: 1.5891
Batch 280, Loss: 1.5638
Batch 290, Loss: 1.6409
Batch 300, Loss: 1.5308
Batch 310, Loss: 1.6031
Batch 320, Loss: 1.5620
Batch 330, Loss: 1.5760
Batch 340, Loss: 1.5879
Batch 350, Loss: 1.5816
Batch 360, Loss: 1.6453
Batch 370, Loss: 1.6226
Batch 380, Loss: 1.5593
Batch 390, Loss: 1.5239
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.107828378677368 seconds
Epoch 22 accuracy: 53.13%
Batch 10, Loss: 1.5449
Batch 20, Loss: 1.5046
Batch 30, Loss: 1.4449
Batch 40, Loss: 1.5902
Batch 50, Loss: 1.4952
Batch 60, Loss: 1.5513
Batch 70, Loss: 1.6074
Batch 80, Loss: 1.5888
Batch 90, Loss: 1.5726
Batch 100, Loss: 1.5602
Batch 110, Loss: 1.5188
Batch 120, Loss: 1.6163
Batch 130, Loss: 1.5349
Batch 140, Loss: 1.6048
Batch 150, Loss: 1.5463
Batch 160, Loss: 1.5943
Batch 170, Loss: 1.6306
Batch 180, Loss: 1.5195
Batch 190, Loss: 1.6077
Batch 200, Loss: 1.6185
Batch 210, Loss: 1.6057
Batch 220, Loss: 1.5776
Batch 230, Loss: 1.5868
Batch 240, Loss: 1.6147
Batch 250, Loss: 1.5591
Batch 260, Loss: 1.6773
Batch 270, Loss: 1.5673
Batch 280, Loss: 1.4937
Batch 290, Loss: 1.5368
Batch 300, Loss: 1.5634
Batch 310, Loss: 1.5666
Batch 320, Loss: 1.5592
Batch 330, Loss: 1.5857
Batch 340, Loss: 1.6268
Batch 350, Loss: 1.6169
Batch 360, Loss: 1.5776
Batch 370, Loss: 1.6444
Batch 380, Loss: 1.6115
Batch 390, Loss: 1.6439
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.11859965324402 seconds
Epoch 23 accuracy: 52.47%
Batch 10, Loss: 1.5500
Batch 20, Loss: 1.5717
Batch 30, Loss: 1.4865
Batch 40, Loss: 1.5220
Batch 50, Loss: 1.5757
Batch 60, Loss: 1.5811
Batch 70, Loss: 1.5575
Batch 80, Loss: 1.5361
Batch 90, Loss: 1.5975
Batch 100, Loss: 1.5544
Batch 110, Loss: 1.5776
Batch 120, Loss: 1.4745
Batch 130, Loss: 1.5976
Batch 140, Loss: 1.5712
Batch 150, Loss: 1.6145
Batch 160, Loss: 1.5252
Batch 170, Loss: 1.5775
Batch 180, Loss: 1.5926
Batch 190, Loss: 1.5928
Batch 200, Loss: 1.5598
Batch 210, Loss: 1.4363
Batch 220, Loss: 1.5038
Batch 230, Loss: 1.5733
Batch 240, Loss: 1.5850
Batch 250, Loss: 1.5248
Batch 260, Loss: 1.5318
Batch 270, Loss: 1.5636
Batch 280, Loss: 1.6079
Batch 290, Loss: 1.6070
Batch 300, Loss: 1.5803
Batch 310, Loss: 1.5714
Batch 320, Loss: 1.5531
Batch 330, Loss: 1.6475
Batch 340, Loss: 1.5813
Batch 350, Loss: 1.5652
Batch 360, Loss: 1.5792
Batch 370, Loss: 1.6332
Batch 380, Loss: 1.5797
Batch 390, Loss: 1.5657
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.091166496276855 seconds
Epoch 24 accuracy: 55.09%
Batch 10, Loss: 1.5397
Batch 20, Loss: 1.5208
Batch 30, Loss: 1.4550
Batch 40, Loss: 1.5293
Batch 50, Loss: 1.4546
Batch 60, Loss: 1.4186
Batch 70, Loss: 1.4888
Batch 80, Loss: 1.5529
Batch 90, Loss: 1.5110
Batch 100, Loss: 1.5908
Batch 110, Loss: 1.5976
Batch 120, Loss: 1.6047
Batch 130, Loss: 1.5797
Batch 140, Loss: 1.5465
Batch 150, Loss: 1.5001
Batch 160, Loss: 1.5181
Batch 170, Loss: 1.5639
Batch 180, Loss: 1.5902
Batch 190, Loss: 1.5785
Batch 200, Loss: 1.5503
Batch 210, Loss: 1.5357
Batch 220, Loss: 1.5500
Batch 230, Loss: 1.5633
Batch 240, Loss: 1.4940
Batch 250, Loss: 1.5062
Batch 260, Loss: 1.5363
Batch 270, Loss: 1.5261
Batch 280, Loss: 1.5241
Batch 290, Loss: 1.5950
Batch 300, Loss: 1.5851
Batch 310, Loss: 1.5699
Batch 320, Loss: 1.5786
Batch 330, Loss: 1.5333
Batch 340, Loss: 1.5821
Batch 350, Loss: 1.5746
Batch 360, Loss: 1.5682
Batch 370, Loss: 1.5355
Batch 380, Loss: 1.6295
Batch 390, Loss: 1.5983
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.180017709732056 seconds
Epoch 25 accuracy: 55.16%
Batch 10, Loss: 1.4663
Batch 20, Loss: 1.4455
Batch 30, Loss: 1.5542
Batch 40, Loss: 1.5417
Batch 50, Loss: 1.4910
Batch 60, Loss: 1.5090
Batch 70, Loss: 1.5063
Batch 80, Loss: 1.5569
Batch 90, Loss: 1.5927
Batch 100, Loss: 1.5794
Batch 110, Loss: 1.5272
Batch 120, Loss: 1.5658
Batch 130, Loss: 1.4770
Batch 140, Loss: 1.5440
Batch 150, Loss: 1.5601
Batch 160, Loss: 1.6165
Batch 170, Loss: 1.5621
Batch 180, Loss: 1.4752
Batch 190, Loss: 1.4705
Batch 200, Loss: 1.4532
Batch 210, Loss: 1.5235
Batch 220, Loss: 1.4834
Batch 230, Loss: 1.5908
Batch 240, Loss: 1.5448
Batch 250, Loss: 1.5573
Batch 260, Loss: 1.5152
Batch 270, Loss: 1.5397
Batch 280, Loss: 1.5347
Batch 290, Loss: 1.4933
Batch 300, Loss: 1.5782
Batch 310, Loss: 1.5429
Batch 320, Loss: 1.5348
Batch 330, Loss: 1.5099
Batch 340, Loss: 1.5243
Batch 350, Loss: 1.5657
Batch 360, Loss: 1.5826
Batch 370, Loss: 1.5964
Batch 380, Loss: 1.5222
Batch 390, Loss: 1.5249
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.09378671646118 seconds
Epoch 26 accuracy: 53.93%
Batch 10, Loss: 1.5349
Batch 20, Loss: 1.5164
Batch 30, Loss: 1.4763
Batch 40, Loss: 1.5187
Batch 50, Loss: 1.5355
Batch 60, Loss: 1.4425
Batch 70, Loss: 1.5014
Batch 80, Loss: 1.4886
Batch 90, Loss: 1.5225
Batch 100, Loss: 1.5506
Batch 110, Loss: 1.5606
Batch 120, Loss: 1.5794
Batch 130, Loss: 1.5052
Batch 140, Loss: 1.5494
Batch 150, Loss: 1.5243
Batch 160, Loss: 1.5149
Batch 170, Loss: 1.5476
Batch 180, Loss: 1.5351
Batch 190, Loss: 1.5705
Batch 200, Loss: 1.5221
Batch 210, Loss: 1.4964
Batch 220, Loss: 1.4979
Batch 230, Loss: 1.5143
Batch 240, Loss: 1.5073
Batch 250, Loss: 1.5284
Batch 260, Loss: 1.5485
Batch 270, Loss: 1.5345
Batch 280, Loss: 1.5539
Batch 290, Loss: 1.6387
Batch 300, Loss: 1.4987
Batch 310, Loss: 1.5144
Batch 320, Loss: 1.5809
Batch 330, Loss: 1.5508
Batch 340, Loss: 1.6091
Batch 350, Loss: 1.4958
Batch 360, Loss: 1.5876
Batch 370, Loss: 1.5298
Batch 380, Loss: 1.5606
Batch 390, Loss: 1.5422
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.146958589553833 seconds
Epoch 27 accuracy: 55.09%
Batch 10, Loss: 1.4816
Batch 20, Loss: 1.4856
Batch 30, Loss: 1.4337
Batch 40, Loss: 1.5025
Batch 50, Loss: 1.4690
Batch 60, Loss: 1.5797
Batch 70, Loss: 1.4561
Batch 80, Loss: 1.4482
Batch 90, Loss: 1.5375
Batch 100, Loss: 1.5215
Batch 110, Loss: 1.4754
Batch 120, Loss: 1.5958
Batch 130, Loss: 1.5157
Batch 140, Loss: 1.5369
Batch 150, Loss: 1.4583
Batch 160, Loss: 1.5458
Batch 170, Loss: 1.5715
Batch 180, Loss: 1.5426
Batch 190, Loss: 1.5465
Batch 200, Loss: 1.4608
Batch 210, Loss: 1.5271
Batch 220, Loss: 1.5425
Batch 230, Loss: 1.5604
Batch 240, Loss: 1.5272
Batch 250, Loss: 1.5566
Batch 260, Loss: 1.4995
Batch 270, Loss: 1.5580
Batch 280, Loss: 1.5538
Batch 290, Loss: 1.5034
Batch 300, Loss: 1.5277
Batch 310, Loss: 1.5860
Batch 320, Loss: 1.5205
Batch 330, Loss: 1.5575
Batch 340, Loss: 1.5819
Batch 350, Loss: 1.6180
Batch 360, Loss: 1.5027
Batch 370, Loss: 1.5718
Batch 380, Loss: 1.5067
Batch 390, Loss: 1.5847
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.146258115768433 seconds
Epoch 28 accuracy: 55.75%
Batch 10, Loss: 1.4566
Batch 20, Loss: 1.4999
Batch 30, Loss: 1.4424
Batch 40, Loss: 1.5062
Batch 50, Loss: 1.4894
Batch 60, Loss: 1.5046
Batch 70, Loss: 1.4883
Batch 80, Loss: 1.4512
Batch 90, Loss: 1.5620
Batch 100, Loss: 1.4670
Batch 110, Loss: 1.5190
Batch 120, Loss: 1.5155
Batch 130, Loss: 1.4655
Batch 140, Loss: 1.5243
Batch 150, Loss: 1.4960
Batch 160, Loss: 1.5446
Batch 170, Loss: 1.5110
Batch 180, Loss: 1.5335
Batch 190, Loss: 1.4652
Batch 200, Loss: 1.5299
Batch 210, Loss: 1.5344
Batch 220, Loss: 1.5482
Batch 230, Loss: 1.5129
Batch 240, Loss: 1.5553
Batch 250, Loss: 1.5402
Batch 260, Loss: 1.4962
Batch 270, Loss: 1.5626
Batch 280, Loss: 1.4608
Batch 290, Loss: 1.6063
Batch 300, Loss: 1.5275
Batch 310, Loss: 1.5664
Batch 320, Loss: 1.5672
Batch 330, Loss: 1.4921
Batch 340, Loss: 1.5582
Batch 350, Loss: 1.4970
Batch 360, Loss: 1.5443
Batch 370, Loss: 1.5171
Batch 380, Loss: 1.5067
Batch 390, Loss: 1.5076
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.196903705596924 seconds
Epoch 29 accuracy: 54.74%
Batch 10, Loss: 1.4782
Batch 20, Loss: 1.5305
Batch 30, Loss: 1.4711
Batch 40, Loss: 1.4877
Batch 50, Loss: 1.4819
Batch 60, Loss: 1.4843
Batch 70, Loss: 1.4625
Batch 80, Loss: 1.3970
Batch 90, Loss: 1.4657
Batch 100, Loss: 1.4809
Batch 110, Loss: 1.4572
Batch 120, Loss: 1.5304
Batch 130, Loss: 1.5408
Batch 140, Loss: 1.5388
Batch 150, Loss: 1.4789
Batch 160, Loss: 1.4982
Batch 170, Loss: 1.4941
Batch 180, Loss: 1.5062
Batch 190, Loss: 1.5578
Batch 200, Loss: 1.4861
Batch 210, Loss: 1.4514
Batch 220, Loss: 1.4776
Batch 230, Loss: 1.4918
Batch 240, Loss: 1.4581
Batch 250, Loss: 1.5865
Batch 260, Loss: 1.5671
Batch 270, Loss: 1.5505
Batch 280, Loss: 1.5286
Batch 290, Loss: 1.5315
Batch 300, Loss: 1.5320
Batch 310, Loss: 1.5408
Batch 320, Loss: 1.5250
Batch 330, Loss: 1.5437
Batch 340, Loss: 1.4503
Batch 350, Loss: 1.5339
Batch 360, Loss: 1.5383
Batch 370, Loss: 1.5676
Batch 380, Loss: 1.4643
Batch 390, Loss: 1.5120
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.012216567993164 seconds
Epoch 30 accuracy: 56.81%
Batch 10, Loss: 1.4682
Batch 20, Loss: 1.4364
Batch 30, Loss: 1.4731
Batch 40, Loss: 1.3993
Batch 50, Loss: 1.4313
Batch 60, Loss: 1.4186
Batch 70, Loss: 1.4244
Batch 80, Loss: 1.5033
Batch 90, Loss: 1.5178
Batch 100, Loss: 1.5382
Batch 110, Loss: 1.4932
Batch 120, Loss: 1.4410
Batch 130, Loss: 1.4286
Batch 140, Loss: 1.5185
Batch 150, Loss: 1.4995
Batch 160, Loss: 1.5023
Batch 170, Loss: 1.4642
Batch 180, Loss: 1.5122
Batch 190, Loss: 1.5491
Batch 200, Loss: 1.5642
Batch 210, Loss: 1.5342
Batch 220, Loss: 1.5606
Batch 230, Loss: 1.5263
Batch 240, Loss: 1.5395
Batch 250, Loss: 1.5021
Batch 260, Loss: 1.4633
Batch 270, Loss: 1.5101
Batch 280, Loss: 1.5503
Batch 290, Loss: 1.4718
Batch 300, Loss: 1.5399
Batch 310, Loss: 1.5585
Batch 320, Loss: 1.5205
Batch 330, Loss: 1.5202
Batch 340, Loss: 1.5094
Batch 350, Loss: 1.5232
Batch 360, Loss: 1.5100
Batch 370, Loss: 1.5389
Batch 380, Loss: 1.5013
Batch 390, Loss: 1.4899
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.244226694107056 seconds
Epoch 31 accuracy: 56.68%
Batch 10, Loss: 1.4736
Batch 20, Loss: 1.3804
Batch 30, Loss: 1.4819
Batch 40, Loss: 1.4490
Batch 50, Loss: 1.4784
Batch 60, Loss: 1.5320
Batch 70, Loss: 1.5041
Batch 80, Loss: 1.4957
Batch 90, Loss: 1.4852
Batch 100, Loss: 1.4835
Batch 110, Loss: 1.4322
Batch 120, Loss: 1.4105
Batch 130, Loss: 1.4499
Batch 140, Loss: 1.5000
Batch 150, Loss: 1.5283
Batch 160, Loss: 1.5613
Batch 170, Loss: 1.5171
Batch 180, Loss: 1.5162
Batch 190, Loss: 1.5227
Batch 200, Loss: 1.5135
Batch 210, Loss: 1.5372
Batch 220, Loss: 1.5346
Batch 230, Loss: 1.4992
Batch 240, Loss: 1.5404
Batch 250, Loss: 1.5577
Batch 260, Loss: 1.4735
Batch 270, Loss: 1.4339
Batch 280, Loss: 1.4800
Batch 290, Loss: 1.5369
Batch 300, Loss: 1.4716
Batch 310, Loss: 1.5119
Batch 320, Loss: 1.5295
Batch 330, Loss: 1.4932
Batch 340, Loss: 1.5145
Batch 350, Loss: 1.4954
Batch 360, Loss: 1.5530
Batch 370, Loss: 1.4798
Batch 380, Loss: 1.5244
Batch 390, Loss: 1.5199
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.272799015045166 seconds
Epoch 32 accuracy: 57.99%
Batch 10, Loss: 1.4391
Batch 20, Loss: 1.5201
Batch 30, Loss: 1.4892
Batch 40, Loss: 1.4144
Batch 50, Loss: 1.4513
Batch 60, Loss: 1.4986
Batch 70, Loss: 1.5419
Batch 80, Loss: 1.4900
Batch 90, Loss: 1.5084
Batch 100, Loss: 1.5164
Batch 110, Loss: 1.5183
Batch 120, Loss: 1.5110
Batch 130, Loss: 1.4637
Batch 140, Loss: 1.4169
Batch 150, Loss: 1.5223
Batch 160, Loss: 1.4794
Batch 170, Loss: 1.5173
Batch 180, Loss: 1.5139
Batch 190, Loss: 1.4513
Batch 200, Loss: 1.4929
Batch 210, Loss: 1.5481
Batch 220, Loss: 1.5267
Batch 230, Loss: 1.5578
Batch 240, Loss: 1.4656
Batch 250, Loss: 1.4709
Batch 260, Loss: 1.4801
Batch 270, Loss: 1.5001
Batch 280, Loss: 1.5334
Batch 290, Loss: 1.5246
Batch 300, Loss: 1.4802
Batch 310, Loss: 1.5168
Batch 320, Loss: 1.5190
Batch 330, Loss: 1.5147
Batch 340, Loss: 1.5295
Batch 350, Loss: 1.4393
Batch 360, Loss: 1.4801
Batch 370, Loss: 1.5616
Batch 380, Loss: 1.6116
Batch 390, Loss: 1.4791
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.07167673110962 seconds
Epoch 33 accuracy: 54.2%
Batch 10, Loss: 1.5136
Batch 20, Loss: 1.4184
Batch 30, Loss: 1.4792
Batch 40, Loss: 1.4419
Batch 50, Loss: 1.4650
Batch 60, Loss: 1.3836
Batch 70, Loss: 1.5340
Batch 80, Loss: 1.4779
Batch 90, Loss: 1.4666
Batch 100, Loss: 1.4244
Batch 110, Loss: 1.3988
Batch 120, Loss: 1.4299
Batch 130, Loss: 1.4692
Batch 140, Loss: 1.4857
Batch 150, Loss: 1.4488
Batch 160, Loss: 1.4787
Batch 170, Loss: 1.4749
Batch 180, Loss: 1.5210
Batch 190, Loss: 1.4880
Batch 200, Loss: 1.4745
Batch 210, Loss: 1.4863
Batch 220, Loss: 1.5643
Batch 230, Loss: 1.4660
Batch 240, Loss: 1.5766
Batch 250, Loss: 1.5450
Batch 260, Loss: 1.4518
Batch 270, Loss: 1.5563
Batch 280, Loss: 1.5242
Batch 290, Loss: 1.5003
Batch 300, Loss: 1.5293
Batch 310, Loss: 1.5469
Batch 320, Loss: 1.4901
Batch 330, Loss: 1.4838
Batch 340, Loss: 1.5665
Batch 350, Loss: 1.5554
Batch 360, Loss: 1.4721
Batch 370, Loss: 1.4593
Batch 380, Loss: 1.4800
Batch 390, Loss: 1.4825
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.144243001937866 seconds
Epoch 34 accuracy: 54.64%
Batch 10, Loss: 1.4305
Batch 20, Loss: 1.4473
Batch 30, Loss: 1.3648
Batch 40, Loss: 1.4427
Batch 50, Loss: 1.5012
Batch 60, Loss: 1.4289
Batch 70, Loss: 1.4970
Batch 80, Loss: 1.4286
Batch 90, Loss: 1.4892
Batch 100, Loss: 1.4841
Batch 110, Loss: 1.4916
Batch 120, Loss: 1.4551
Batch 130, Loss: 1.4500
Batch 140, Loss: 1.4886
Batch 150, Loss: 1.5256
Batch 160, Loss: 1.4402
Batch 170, Loss: 1.4223
Batch 180, Loss: 1.4652
Batch 190, Loss: 1.4842
Batch 200, Loss: 1.4614
Batch 210, Loss: 1.5271
Batch 220, Loss: 1.4701
Batch 230, Loss: 1.4453
Batch 240, Loss: 1.4797
Batch 250, Loss: 1.4434
Batch 260, Loss: 1.5252
Batch 270, Loss: 1.5040
Batch 280, Loss: 1.4753
Batch 290, Loss: 1.5463
Batch 300, Loss: 1.4906
Batch 310, Loss: 1.4850
Batch 320, Loss: 1.4252
Batch 330, Loss: 1.4854
Batch 340, Loss: 1.4780
Batch 350, Loss: 1.4942
Batch 360, Loss: 1.5368
Batch 370, Loss: 1.5331
Batch 380, Loss: 1.5063
Batch 390, Loss: 1.4125
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.125948190689087 seconds
Epoch 35 accuracy: 54.21%
Batch 10, Loss: 1.3614
Batch 20, Loss: 1.4787
Batch 30, Loss: 1.4662
Batch 40, Loss: 1.3980
Batch 50, Loss: 1.3784
Batch 60, Loss: 1.3892
Batch 70, Loss: 1.3721
Batch 80, Loss: 1.4949
Batch 90, Loss: 1.4390
Batch 100, Loss: 1.4746
Batch 110, Loss: 1.4043
Batch 120, Loss: 1.4253
Batch 130, Loss: 1.4786
Batch 140, Loss: 1.4027
Batch 150, Loss: 1.4459
Batch 160, Loss: 1.4265
Batch 170, Loss: 1.4416
Batch 180, Loss: 1.5163
Batch 190, Loss: 1.4119
Batch 200, Loss: 1.4933
Batch 210, Loss: 1.5160
Batch 220, Loss: 1.4870
Batch 230, Loss: 1.4858
Batch 240, Loss: 1.5466
Batch 250, Loss: 1.5323
Batch 260, Loss: 1.5218
Batch 270, Loss: 1.5063
Batch 280, Loss: 1.3960
Batch 290, Loss: 1.5113
Batch 300, Loss: 1.4077
Batch 310, Loss: 1.4707
Batch 320, Loss: 1.5536
Batch 330, Loss: 1.5255
Batch 340, Loss: 1.5146
Batch 350, Loss: 1.4721
Batch 360, Loss: 1.5030
Batch 370, Loss: 1.4941
Batch 380, Loss: 1.4676
Batch 390, Loss: 1.5131
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.100438117980957 seconds
Epoch 36 accuracy: 55.82%
Batch 10, Loss: 1.4814
Batch 20, Loss: 1.4194
Batch 30, Loss: 1.4276
Batch 40, Loss: 1.4218
Batch 50, Loss: 1.5003
Batch 60, Loss: 1.4103
Batch 70, Loss: 1.4200
Batch 80, Loss: 1.4251
Batch 90, Loss: 1.4608
Batch 100, Loss: 1.4618
Batch 110, Loss: 1.4777
Batch 120, Loss: 1.4301
Batch 130, Loss: 1.4489
Batch 140, Loss: 1.4162
Batch 150, Loss: 1.4123
Batch 160, Loss: 1.4304
Batch 170, Loss: 1.3958
Batch 180, Loss: 1.4763
Batch 190, Loss: 1.4488
Batch 200, Loss: 1.4773
Batch 210, Loss: 1.4895
Batch 220, Loss: 1.5081
Batch 230, Loss: 1.4620
Batch 240, Loss: 1.5566
Batch 250, Loss: 1.4204
Batch 260, Loss: 1.4362
Batch 270, Loss: 1.5089
Batch 280, Loss: 1.5068
Batch 290, Loss: 1.4637
Batch 300, Loss: 1.4798
Batch 310, Loss: 1.4530
Batch 320, Loss: 1.5384
Batch 330, Loss: 1.5196
Batch 340, Loss: 1.4641
Batch 350, Loss: 1.4658
Batch 360, Loss: 1.5120
Batch 370, Loss: 1.4601
Batch 380, Loss: 1.4910
Batch 390, Loss: 1.4319
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.122342586517334 seconds
Epoch 37 accuracy: 57.25%
Batch 10, Loss: 1.4650
Batch 20, Loss: 1.4011
Batch 30, Loss: 1.4501
Batch 40, Loss: 1.3822
Batch 50, Loss: 1.5031
Batch 60, Loss: 1.4706
Batch 70, Loss: 1.3695
Batch 80, Loss: 1.4923
Batch 90, Loss: 1.4318
Batch 100, Loss: 1.4556
Batch 110, Loss: 1.4497
Batch 120, Loss: 1.4451
Batch 130, Loss: 1.3910
Batch 140, Loss: 1.4176
Batch 150, Loss: 1.4670
Batch 160, Loss: 1.4841
Batch 170, Loss: 1.4569
Batch 180, Loss: 1.4883
Batch 190, Loss: 1.4262
Batch 200, Loss: 1.4615
Batch 210, Loss: 1.4851
Batch 220, Loss: 1.5555
Batch 230, Loss: 1.4228
Batch 240, Loss: 1.4371
Batch 250, Loss: 1.4587
Batch 260, Loss: 1.4968
Batch 270, Loss: 1.4384
Batch 280, Loss: 1.5221
Batch 290, Loss: 1.4238
Batch 300, Loss: 1.4639
Batch 310, Loss: 1.4481
Batch 320, Loss: 1.4558
Batch 330, Loss: 1.4992
Batch 340, Loss: 1.4243
Batch 350, Loss: 1.5234
Batch 360, Loss: 1.4874
Batch 370, Loss: 1.5408
Batch 380, Loss: 1.5211
Batch 390, Loss: 1.4550
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.005223989486694 seconds
Epoch 38 accuracy: 55.92%
Batch 10, Loss: 1.4470
Batch 20, Loss: 1.4270
Batch 30, Loss: 1.4564
Batch 40, Loss: 1.4415
Batch 50, Loss: 1.4890
Batch 60, Loss: 1.4385
Batch 70, Loss: 1.4105
Batch 80, Loss: 1.4098
Batch 90, Loss: 1.4341
Batch 100, Loss: 1.4557
Batch 110, Loss: 1.5223
Batch 120, Loss: 1.4798
Batch 130, Loss: 1.4454
Batch 140, Loss: 1.3983
Batch 150, Loss: 1.4780
Batch 160, Loss: 1.4017
Batch 170, Loss: 1.4866
Batch 180, Loss: 1.4884
Batch 190, Loss: 1.4675
Batch 200, Loss: 1.4263
Batch 210, Loss: 1.4548
Batch 220, Loss: 1.4773
Batch 230, Loss: 1.4667
Batch 240, Loss: 1.4256
Batch 250, Loss: 1.4652
Batch 260, Loss: 1.3884
Batch 270, Loss: 1.5269
Batch 280, Loss: 1.4731
Batch 290, Loss: 1.4724
Batch 300, Loss: 1.3947
Batch 310, Loss: 1.4651
Batch 320, Loss: 1.4214
Batch 330, Loss: 1.4840
Batch 340, Loss: 1.5058
Batch 350, Loss: 1.4201
Batch 360, Loss: 1.5068
Batch 370, Loss: 1.5079
Batch 380, Loss: 1.4639
Batch 390, Loss: 1.5030
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.15649127960205 seconds
Epoch 39 accuracy: 55.33%
Batch 10, Loss: 1.3579
Batch 20, Loss: 1.4184
Batch 30, Loss: 1.3811
Batch 40, Loss: 1.5282
Batch 50, Loss: 1.4127
Batch 60, Loss: 1.4495
Batch 70, Loss: 1.4493
Batch 80, Loss: 1.4383
Batch 90, Loss: 1.4502
Batch 100, Loss: 1.4514
Batch 110, Loss: 1.5584
Batch 120, Loss: 1.4090
Batch 130, Loss: 1.3923
Batch 140, Loss: 1.3816
Batch 150, Loss: 1.3672
Batch 160, Loss: 1.4163
Batch 170, Loss: 1.3855
Batch 180, Loss: 1.4247
Batch 190, Loss: 1.5279
Batch 200, Loss: 1.4772
Batch 210, Loss: 1.4913
Batch 220, Loss: 1.4192
Batch 230, Loss: 1.5214
Batch 240, Loss: 1.4595
Batch 250, Loss: 1.5148
Batch 260, Loss: 1.4512
Batch 270, Loss: 1.4456
Batch 280, Loss: 1.4809
Batch 290, Loss: 1.4929
Batch 300, Loss: 1.5252
Batch 310, Loss: 1.4029
Batch 320, Loss: 1.4439
Batch 330, Loss: 1.4468
Batch 340, Loss: 1.4864
Batch 350, Loss: 1.4042
Batch 360, Loss: 1.4430
Batch 370, Loss: 1.4870
Batch 380, Loss: 1.5215
Batch 390, Loss: 1.4549
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.073742866516113 seconds
Epoch 40 accuracy: 57.92%
Batch 10, Loss: 1.4331
Batch 20, Loss: 1.4214
Batch 30, Loss: 1.3703
Batch 40, Loss: 1.4121
Batch 50, Loss: 1.3935
Batch 60, Loss: 1.3669
Batch 70, Loss: 1.4461
Batch 80, Loss: 1.4604
Batch 90, Loss: 1.4059
Batch 100, Loss: 1.4328
Batch 110, Loss: 1.4876
Batch 120, Loss: 1.4241
Batch 130, Loss: 1.4345
Batch 140, Loss: 1.4692
Batch 150, Loss: 1.4630
Batch 160, Loss: 1.4199
Batch 170, Loss: 1.5074
Batch 180, Loss: 1.4792
Batch 190, Loss: 1.3876
Batch 200, Loss: 1.4027
Batch 210, Loss: 1.4560
Batch 220, Loss: 1.4890
Batch 230, Loss: 1.3566
Batch 240, Loss: 1.4190
Batch 250, Loss: 1.4035
Batch 260, Loss: 1.4543
Batch 270, Loss: 1.4207
Batch 280, Loss: 1.4844
Batch 290, Loss: 1.4456
Batch 300, Loss: 1.4991
Batch 310, Loss: 1.4124
Batch 320, Loss: 1.5115
Batch 330, Loss: 1.4365
Batch 340, Loss: 1.4521
Batch 350, Loss: 1.4944
Batch 360, Loss: 1.4791
Batch 370, Loss: 1.4497
Batch 380, Loss: 1.4751
Batch 390, Loss: 1.4596
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.19103169441223 seconds
Epoch 41 accuracy: 58.45%
Batch 10, Loss: 1.4587
Batch 20, Loss: 1.3830
Batch 30, Loss: 1.3395
Batch 40, Loss: 1.3675
Batch 50, Loss: 1.4231
Batch 60, Loss: 1.4090
Batch 70, Loss: 1.4648
Batch 80, Loss: 1.3404
Batch 90, Loss: 1.3939
Batch 100, Loss: 1.4396
Batch 110, Loss: 1.4090
Batch 120, Loss: 1.4682
Batch 130, Loss: 1.4827
Batch 140, Loss: 1.5033
Batch 150, Loss: 1.3972
Batch 160, Loss: 1.4736
Batch 170, Loss: 1.4359
Batch 180, Loss: 1.4248
Batch 190, Loss: 1.4273
Batch 200, Loss: 1.4411
Batch 210, Loss: 1.4567
Batch 220, Loss: 1.4405
Batch 230, Loss: 1.4921
Batch 240, Loss: 1.4719
Batch 250, Loss: 1.5307
Batch 260, Loss: 1.4820
Batch 270, Loss: 1.4425
Batch 280, Loss: 1.4080
Batch 290, Loss: 1.4766
Batch 300, Loss: 1.4492
Batch 310, Loss: 1.4633
Batch 320, Loss: 1.4508
Batch 330, Loss: 1.4724
Batch 340, Loss: 1.4915
Batch 350, Loss: 1.5151
Batch 360, Loss: 1.4908
Batch 370, Loss: 1.4880
Batch 380, Loss: 1.4742
Batch 390, Loss: 1.4759
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.13118815422058 seconds
Epoch 42 accuracy: 55.48%
Batch 10, Loss: 1.4599
Batch 20, Loss: 1.4192
Batch 30, Loss: 1.4151
Batch 40, Loss: 1.4490
Batch 50, Loss: 1.3870
Batch 60, Loss: 1.3201
Batch 70, Loss: 1.3505
Batch 80, Loss: 1.4076
Batch 90, Loss: 1.3643
Batch 100, Loss: 1.4104
Batch 110, Loss: 1.4125
Batch 120, Loss: 1.4433
Batch 130, Loss: 1.4258
Batch 140, Loss: 1.4431
Batch 150, Loss: 1.4502
Batch 160, Loss: 1.4261
Batch 170, Loss: 1.4024
Batch 180, Loss: 1.4478
Batch 190, Loss: 1.4303
Batch 200, Loss: 1.4106
Batch 210, Loss: 1.4279
Batch 220, Loss: 1.4085
Batch 230, Loss: 1.4162
Batch 240, Loss: 1.4616
Batch 250, Loss: 1.4560
Batch 260, Loss: 1.4477
Batch 270, Loss: 1.4899
Batch 280, Loss: 1.4123
Batch 290, Loss: 1.4105
Batch 300, Loss: 1.4494
Batch 310, Loss: 1.4417
Batch 320, Loss: 1.4471
Batch 330, Loss: 1.5208
Batch 340, Loss: 1.4601
Batch 350, Loss: 1.4021
Batch 360, Loss: 1.4742
Batch 370, Loss: 1.4373
Batch 380, Loss: 1.4849
Batch 390, Loss: 1.4725
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.076960802078247 seconds
Epoch 43 accuracy: 53.47%
Batch 10, Loss: 1.4358
Batch 20, Loss: 1.4185
Batch 30, Loss: 1.4936
Batch 40, Loss: 1.3867
Batch 50, Loss: 1.4857
Batch 60, Loss: 1.3864
Batch 70, Loss: 1.4337
Batch 80, Loss: 1.4083
Batch 90, Loss: 1.4131
Batch 100, Loss: 1.4360
Batch 110, Loss: 1.4172
Batch 120, Loss: 1.4397
Batch 130, Loss: 1.4876
Batch 140, Loss: 1.4225
Batch 150, Loss: 1.4417
Batch 160, Loss: 1.4541
Batch 170, Loss: 1.4528
Batch 180, Loss: 1.3457
Batch 190, Loss: 1.4231
Batch 200, Loss: 1.4599
Batch 210, Loss: 1.4745
Batch 220, Loss: 1.4707
Batch 230, Loss: 1.4982
Batch 240, Loss: 1.4390
Batch 250, Loss: 1.3522
Batch 260, Loss: 1.4491
Batch 270, Loss: 1.3884
Batch 280, Loss: 1.4366
Batch 290, Loss: 1.4702
Batch 300, Loss: 1.4694
Batch 310, Loss: 1.4178
Batch 320, Loss: 1.4234
Batch 330, Loss: 1.4162
Batch 340, Loss: 1.3890
Batch 350, Loss: 1.4560
Batch 360, Loss: 1.4354
Batch 370, Loss: 1.4317
Batch 380, Loss: 1.3758
Batch 390, Loss: 1.4626
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.0746111869812 seconds
Epoch 44 accuracy: 55.88%
Batch 10, Loss: 1.3753
Batch 20, Loss: 1.3635
Batch 30, Loss: 1.3603
Batch 40, Loss: 1.4244
Batch 50, Loss: 1.3335
Batch 60, Loss: 1.4280
Batch 70, Loss: 1.3695
Batch 80, Loss: 1.4452
Batch 90, Loss: 1.3829
Batch 100, Loss: 1.3753
Batch 110, Loss: 1.4078
Batch 120, Loss: 1.4290
Batch 130, Loss: 1.3952
Batch 140, Loss: 1.4590
Batch 150, Loss: 1.4471
Batch 160, Loss: 1.4370
Batch 170, Loss: 1.3730
Batch 180, Loss: 1.4616
Batch 190, Loss: 1.3770
Batch 200, Loss: 1.4560
Batch 210, Loss: 1.4618
Batch 220, Loss: 1.4388
Batch 230, Loss: 1.4183
Batch 240, Loss: 1.3547
Batch 250, Loss: 1.3816
Batch 260, Loss: 1.4156
Batch 270, Loss: 1.4635
Batch 280, Loss: 1.4974
Batch 290, Loss: 1.4078
Batch 300, Loss: 1.4205
Batch 310, Loss: 1.4709
Batch 320, Loss: 1.5022
Batch 330, Loss: 1.4256
Batch 340, Loss: 1.4469
Batch 350, Loss: 1.4682
Batch 360, Loss: 1.4509
Batch 370, Loss: 1.4730
Batch 380, Loss: 1.4282
Batch 390, Loss: 1.4421
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.11154341697693 seconds
Epoch 45 accuracy: 60.26%
Batch 10, Loss: 1.4409
Batch 20, Loss: 1.3911
Batch 30, Loss: 1.3357
Batch 40, Loss: 1.2960
Batch 50, Loss: 1.4197
Batch 60, Loss: 1.3854
Batch 70, Loss: 1.4086
Batch 80, Loss: 1.4046
Batch 90, Loss: 1.3750
Batch 100, Loss: 1.4087
Batch 110, Loss: 1.4765
Batch 120, Loss: 1.4632
Batch 130, Loss: 1.3724
Batch 140, Loss: 1.4006
Batch 150, Loss: 1.3701
Batch 160, Loss: 1.4224
Batch 170, Loss: 1.4271
Batch 180, Loss: 1.3873
Batch 190, Loss: 1.4328
Batch 200, Loss: 1.4265
Batch 210, Loss: 1.4634
Batch 220, Loss: 1.4251
Batch 230, Loss: 1.3754
Batch 240, Loss: 1.4615
Batch 250, Loss: 1.4845
Batch 260, Loss: 1.4146
Batch 270, Loss: 1.3578
Batch 280, Loss: 1.4928
Batch 290, Loss: 1.4391
Batch 300, Loss: 1.4366
Batch 310, Loss: 1.4535
Batch 320, Loss: 1.4387
Batch 330, Loss: 1.4671
Batch 340, Loss: 1.4368
Batch 350, Loss: 1.4473
Batch 360, Loss: 1.3968
Batch 370, Loss: 1.4498
Batch 380, Loss: 1.4170
Batch 390, Loss: 1.4355
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.05638861656189 seconds
Epoch 46 accuracy: 57.83%
Batch 10, Loss: 1.3476
Batch 20, Loss: 1.3762
Batch 30, Loss: 1.3281
Batch 40, Loss: 1.3621
Batch 50, Loss: 1.4313
Batch 60, Loss: 1.3460
Batch 70, Loss: 1.4195
Batch 80, Loss: 1.4322
Batch 90, Loss: 1.3407
Batch 100, Loss: 1.4177
Batch 110, Loss: 1.3750
Batch 120, Loss: 1.4403
Batch 130, Loss: 1.4098
Batch 140, Loss: 1.3372
Batch 150, Loss: 1.4325
Batch 160, Loss: 1.4137
Batch 170, Loss: 1.5283
Batch 180, Loss: 1.3904
Batch 190, Loss: 1.4384
Batch 200, Loss: 1.4120
Batch 210, Loss: 1.4544
Batch 220, Loss: 1.3744
Batch 230, Loss: 1.3714
Batch 240, Loss: 1.4402
Batch 250, Loss: 1.4004
Batch 260, Loss: 1.4825
Batch 270, Loss: 1.3838
Batch 280, Loss: 1.4614
Batch 290, Loss: 1.4661
Batch 300, Loss: 1.3565
Batch 310, Loss: 1.4303
Batch 320, Loss: 1.3892
Batch 330, Loss: 1.4648
Batch 340, Loss: 1.4125
Batch 350, Loss: 1.4618
Batch 360, Loss: 1.4335
Batch 370, Loss: 1.4621
Batch 380, Loss: 1.3947
Batch 390, Loss: 1.4935
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.06832194328308 seconds
Epoch 47 accuracy: 59.09%
Batch 10, Loss: 1.3404
Batch 20, Loss: 1.3895
Batch 30, Loss: 1.3816
Batch 40, Loss: 1.4255
Batch 50, Loss: 1.3923
Batch 60, Loss: 1.3245
Batch 70, Loss: 1.4243
Batch 80, Loss: 1.4447
Batch 90, Loss: 1.3514
Batch 100, Loss: 1.4157
Batch 110, Loss: 1.3675
Batch 120, Loss: 1.3698
Batch 130, Loss: 1.4153
Batch 140, Loss: 1.4580
Batch 150, Loss: 1.4103
Batch 160, Loss: 1.3598
Batch 170, Loss: 1.3710
Batch 180, Loss: 1.4010
Batch 190, Loss: 1.4068
Batch 200, Loss: 1.3433
Batch 210, Loss: 1.4705
Batch 220, Loss: 1.4146
Batch 230, Loss: 1.5027
Batch 240, Loss: 1.3993
Batch 250, Loss: 1.4732
Batch 260, Loss: 1.3660
Batch 270, Loss: 1.4662
Batch 280, Loss: 1.4256
Batch 290, Loss: 1.4050
Batch 300, Loss: 1.3780
Batch 310, Loss: 1.4324
Batch 320, Loss: 1.4544
Batch 330, Loss: 1.4619
Batch 340, Loss: 1.3812
Batch 350, Loss: 1.3965
Batch 360, Loss: 1.4756
Batch 370, Loss: 1.4659
Batch 380, Loss: 1.4680
Batch 390, Loss: 1.4725
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.253886938095093 seconds
Epoch 48 accuracy: 57.32%
Batch 10, Loss: 1.3291
Batch 20, Loss: 1.3536
Batch 30, Loss: 1.3648
Batch 40, Loss: 1.3105
Batch 50, Loss: 1.2743
Batch 60, Loss: 1.3726
Batch 70, Loss: 1.3933
Batch 80, Loss: 1.4015
Batch 90, Loss: 1.4102
Batch 100, Loss: 1.3885
Batch 110, Loss: 1.3281
Batch 120, Loss: 1.3550
Batch 130, Loss: 1.4030
Batch 140, Loss: 1.4756
Batch 150, Loss: 1.4181
Batch 160, Loss: 1.4975
Batch 170, Loss: 1.4128
Batch 180, Loss: 1.4528
Batch 190, Loss: 1.4046
Batch 200, Loss: 1.3819
Batch 210, Loss: 1.4051
Batch 220, Loss: 1.3395
Batch 230, Loss: 1.3998
Batch 240, Loss: 1.4065
Batch 250, Loss: 1.3640
Batch 260, Loss: 1.4281
Batch 270, Loss: 1.4674
Batch 280, Loss: 1.4824
Batch 290, Loss: 1.4489
Batch 300, Loss: 1.4705
Batch 310, Loss: 1.4635
Batch 320, Loss: 1.4487
Batch 330, Loss: 1.4174
Batch 340, Loss: 1.4469
Batch 350, Loss: 1.3924
Batch 360, Loss: 1.4580
Batch 370, Loss: 1.4192
Batch 380, Loss: 1.4309
Batch 390, Loss: 1.4230
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.1732280254364 seconds
Epoch 49 accuracy: 56.52%
Batch 10, Loss: 1.3535
Batch 20, Loss: 1.4320
Batch 30, Loss: 1.3644
Batch 40, Loss: 1.3235
Batch 50, Loss: 1.3549
Batch 60, Loss: 1.3625
Batch 70, Loss: 1.3840
Batch 80, Loss: 1.3774
Batch 90, Loss: 1.4144
Batch 100, Loss: 1.3614
Batch 110, Loss: 1.3563
Batch 120, Loss: 1.3515
Batch 130, Loss: 1.3783
Batch 140, Loss: 1.4054
Batch 150, Loss: 1.3532
Batch 160, Loss: 1.3948
Batch 170, Loss: 1.3865
Batch 180, Loss: 1.4172
Batch 190, Loss: 1.3763
Batch 200, Loss: 1.4008
Batch 210, Loss: 1.3682
Batch 220, Loss: 1.4150
Batch 230, Loss: 1.4571
Batch 240, Loss: 1.4245
Batch 250, Loss: 1.4088
Batch 260, Loss: 1.3322
Batch 270, Loss: 1.4289
Batch 280, Loss: 1.4296
Batch 290, Loss: 1.4163
Batch 300, Loss: 1.4324
Batch 310, Loss: 1.4361
Batch 320, Loss: 1.4335
Batch 330, Loss: 1.4645
Batch 340, Loss: 1.3917
Batch 350, Loss: 1.3762
Batch 360, Loss: 1.3600
Batch 370, Loss: 1.4082
Batch 380, Loss: 1.4210
Batch 390, Loss: 1.4498
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.145474672317505 seconds
Epoch 50 accuracy: 58.43%
Batch 10, Loss: 1.3184
Batch 20, Loss: 1.3820
Batch 30, Loss: 1.3814
Batch 40, Loss: 1.2952
Batch 50, Loss: 1.3811
Batch 60, Loss: 1.3659
Batch 70, Loss: 1.3648
Batch 80, Loss: 1.3859
Batch 90, Loss: 1.4189
Batch 100, Loss: 1.3707
Batch 110, Loss: 1.4213
Batch 120, Loss: 1.3944
Batch 130, Loss: 1.3831
Batch 140, Loss: 1.3947
Batch 150, Loss: 1.5039
Batch 160, Loss: 1.3487
Batch 170, Loss: 1.3563
Batch 180, Loss: 1.3400
Batch 190, Loss: 1.4398
Batch 200, Loss: 1.3646
Batch 210, Loss: 1.3686
Batch 220, Loss: 1.4075
Batch 230, Loss: 1.3353
Batch 240, Loss: 1.3491
Batch 250, Loss: 1.4207
Batch 260, Loss: 1.3957
Batch 270, Loss: 1.4098
Batch 280, Loss: 1.3569
Batch 290, Loss: 1.4539
Batch 300, Loss: 1.4358
Batch 310, Loss: 1.4190
Batch 320, Loss: 1.4276
Batch 330, Loss: 1.4107
Batch 340, Loss: 1.4231
Batch 350, Loss: 1.4640
Batch 360, Loss: 1.4760
Batch 370, Loss: 1.4357
Batch 380, Loss: 1.3935
Batch 390, Loss: 1.4652
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.097861528396606 seconds
Epoch 51 accuracy: 59.54%
Batch 10, Loss: 1.3880
Batch 20, Loss: 1.3892
Batch 30, Loss: 1.3677
Batch 40, Loss: 1.3765
Batch 50, Loss: 1.3157
Batch 60, Loss: 1.3287
Batch 70, Loss: 1.3784
Batch 80, Loss: 1.2657
Batch 90, Loss: 1.3652
Batch 100, Loss: 1.3255
Batch 110, Loss: 1.4549
Batch 120, Loss: 1.3691
Batch 130, Loss: 1.4133
Batch 140, Loss: 1.3461
Batch 150, Loss: 1.4286
Batch 160, Loss: 1.3760
Batch 170, Loss: 1.3489
Batch 180, Loss: 1.3740
Batch 190, Loss: 1.4167
Batch 200, Loss: 1.4678
Batch 210, Loss: 1.3827
Batch 220, Loss: 1.3577
Batch 230, Loss: 1.3733
Batch 240, Loss: 1.3920
Batch 250, Loss: 1.3565
Batch 260, Loss: 1.4401
Batch 270, Loss: 1.3267
Batch 280, Loss: 1.3486
Batch 290, Loss: 1.4015
Batch 300, Loss: 1.4012
Batch 310, Loss: 1.4725
Batch 320, Loss: 1.4125
Batch 330, Loss: 1.4121
Batch 340, Loss: 1.3944
Batch 350, Loss: 1.4763
Batch 360, Loss: 1.4286
Batch 370, Loss: 1.4202
Batch 380, Loss: 1.3046
Batch 390, Loss: 1.3213
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.078922986984253 seconds
Epoch 52 accuracy: 60.2%
Batch 10, Loss: 1.3937
Batch 20, Loss: 1.3331
Batch 30, Loss: 1.2974
Batch 40, Loss: 1.3884
Batch 50, Loss: 1.3247
Batch 60, Loss: 1.3987
Batch 70, Loss: 1.3326
Batch 80, Loss: 1.3366
Batch 90, Loss: 1.4007
Batch 100, Loss: 1.3218
Batch 110, Loss: 1.4074
Batch 120, Loss: 1.3936
Batch 130, Loss: 1.3748
Batch 140, Loss: 1.3463
Batch 150, Loss: 1.4071
Batch 160, Loss: 1.3717
Batch 170, Loss: 1.3670
Batch 180, Loss: 1.3765
Batch 190, Loss: 1.4389
Batch 200, Loss: 1.3785
Batch 210, Loss: 1.3648
Batch 220, Loss: 1.3627
Batch 230, Loss: 1.3410
Batch 240, Loss: 1.3879
Batch 250, Loss: 1.3777
Batch 260, Loss: 1.3631
Batch 270, Loss: 1.3750
Batch 280, Loss: 1.3732
Batch 290, Loss: 1.3922
Batch 300, Loss: 1.4148
Batch 310, Loss: 1.4332
Batch 320, Loss: 1.4477
Batch 330, Loss: 1.3975
Batch 340, Loss: 1.4558
Batch 350, Loss: 1.3566
Batch 360, Loss: 1.3832
Batch 370, Loss: 1.3227
Batch 380, Loss: 1.4030
Batch 390, Loss: 1.3997
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.15508723258972 seconds
Epoch 53 accuracy: 60.54%
Batch 10, Loss: 1.3440
Batch 20, Loss: 1.3738
Batch 30, Loss: 1.3409
Batch 40, Loss: 1.3353
Batch 50, Loss: 1.3195
Batch 60, Loss: 1.4142
Batch 70, Loss: 1.3368
Batch 80, Loss: 1.3734
Batch 90, Loss: 1.3401
Batch 100, Loss: 1.3426
Batch 110, Loss: 1.3704
Batch 120, Loss: 1.3254
Batch 130, Loss: 1.3598
Batch 140, Loss: 1.3242
Batch 150, Loss: 1.3706
Batch 160, Loss: 1.3184
Batch 170, Loss: 1.3791
Batch 180, Loss: 1.3011
Batch 190, Loss: 1.4079
Batch 200, Loss: 1.3493
Batch 210, Loss: 1.3304
Batch 220, Loss: 1.3589
Batch 230, Loss: 1.3869
Batch 240, Loss: 1.4046
Batch 250, Loss: 1.3713
Batch 260, Loss: 1.4339
Batch 270, Loss: 1.3790
Batch 280, Loss: 1.3908
Batch 290, Loss: 1.3972
Batch 300, Loss: 1.3765
Batch 310, Loss: 1.4011
Batch 320, Loss: 1.4431
Batch 330, Loss: 1.3725
Batch 340, Loss: 1.4191
Batch 350, Loss: 1.4330
Batch 360, Loss: 1.3938
Batch 370, Loss: 1.3668
Batch 380, Loss: 1.3874
Batch 390, Loss: 1.4159
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.07878041267395 seconds
Epoch 54 accuracy: 58.12%
Batch 10, Loss: 1.3613
Batch 20, Loss: 1.3644
Batch 30, Loss: 1.3267
Batch 40, Loss: 1.3473
Batch 50, Loss: 1.3156
Batch 60, Loss: 1.3051
Batch 70, Loss: 1.3402
Batch 80, Loss: 1.2873
Batch 90, Loss: 1.3960
Batch 100, Loss: 1.3921
Batch 110, Loss: 1.3875
Batch 120, Loss: 1.4353
Batch 130, Loss: 1.4158
Batch 140, Loss: 1.3657
Batch 150, Loss: 1.3903
Batch 160, Loss: 1.3853
Batch 170, Loss: 1.4216
Batch 180, Loss: 1.4306
Batch 190, Loss: 1.4096
Batch 200, Loss: 1.3471
Batch 210, Loss: 1.4228
Batch 220, Loss: 1.3187
Batch 230, Loss: 1.3870
Batch 240, Loss: 1.3570
Batch 250, Loss: 1.3699
Batch 260, Loss: 1.3691
Batch 270, Loss: 1.4214
Batch 280, Loss: 1.3717
Batch 290, Loss: 1.4334
Batch 300, Loss: 1.4146
Batch 310, Loss: 1.4270
Batch 320, Loss: 1.3801
Batch 330, Loss: 1.4249
Batch 340, Loss: 1.4324
Batch 350, Loss: 1.4060
Batch 360, Loss: 1.4230
Batch 370, Loss: 1.3801
Batch 380, Loss: 1.3429
Batch 390, Loss: 1.4075
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.00260090827942 seconds
Epoch 55 accuracy: 60.54%
Batch 10, Loss: 1.3296
Batch 20, Loss: 1.2363
Batch 30, Loss: 1.2618
Batch 40, Loss: 1.2508
Batch 50, Loss: 1.3190
Batch 60, Loss: 1.3944
Batch 70, Loss: 1.3431
Batch 80, Loss: 1.3489
Batch 90, Loss: 1.3601
Batch 100, Loss: 1.3110
Batch 110, Loss: 1.3138
Batch 120, Loss: 1.2519
Batch 130, Loss: 1.3829
Batch 140, Loss: 1.3381
Batch 150, Loss: 1.3604
Batch 160, Loss: 1.4475
Batch 170, Loss: 1.3814
Batch 180, Loss: 1.3574
Batch 190, Loss: 1.3409
Batch 200, Loss: 1.2988
Batch 210, Loss: 1.3492
Batch 220, Loss: 1.3097
Batch 230, Loss: 1.3420
Batch 240, Loss: 1.4102
Batch 250, Loss: 1.4054
Batch 260, Loss: 1.3959
Batch 270, Loss: 1.3698
Batch 280, Loss: 1.3508
Batch 290, Loss: 1.3343
Batch 300, Loss: 1.4155
Batch 310, Loss: 1.4421
Batch 320, Loss: 1.4014
Batch 330, Loss: 1.4251
Batch 340, Loss: 1.4101
Batch 350, Loss: 1.3784
Batch 360, Loss: 1.3566
Batch 370, Loss: 1.4080
Batch 380, Loss: 1.4271
Batch 390, Loss: 1.4302
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.08971929550171 seconds
Epoch 56 accuracy: 59.88%
Batch 10, Loss: 1.3465
Batch 20, Loss: 1.3368
Batch 30, Loss: 1.3192
Batch 40, Loss: 1.3417
Batch 50, Loss: 1.3558
Batch 60, Loss: 1.3395
Batch 70, Loss: 1.3418
Batch 80, Loss: 1.3612
Batch 90, Loss: 1.3504
Batch 100, Loss: 1.3632
Batch 110, Loss: 1.3147
Batch 120, Loss: 1.2616
Batch 130, Loss: 1.3839
Batch 140, Loss: 1.2802
Batch 150, Loss: 1.3749
Batch 160, Loss: 1.3612
Batch 170, Loss: 1.4253
Batch 180, Loss: 1.4030
Batch 190, Loss: 1.4590
Batch 200, Loss: 1.2825
Batch 210, Loss: 1.2911
Batch 220, Loss: 1.3272
Batch 230, Loss: 1.4060
Batch 240, Loss: 1.4208
Batch 250, Loss: 1.3539
Batch 260, Loss: 1.3207
Batch 270, Loss: 1.3406
Batch 280, Loss: 1.3403
Batch 290, Loss: 1.4258
Batch 300, Loss: 1.3952
Batch 310, Loss: 1.2763
Batch 320, Loss: 1.3592
Batch 330, Loss: 1.3201
Batch 340, Loss: 1.3900
Batch 350, Loss: 1.3601
Batch 360, Loss: 1.4182
Batch 370, Loss: 1.4324
Batch 380, Loss: 1.3265
Batch 390, Loss: 1.4062
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.03405737876892 seconds
Epoch 57 accuracy: 58.54%
Batch 10, Loss: 1.3672
Batch 20, Loss: 1.3367
Batch 30, Loss: 1.2908
Batch 40, Loss: 1.3709
Batch 50, Loss: 1.3317
Batch 60, Loss: 1.3557
Batch 70, Loss: 1.2828
Batch 80, Loss: 1.3934
Batch 90, Loss: 1.3422
Batch 100, Loss: 1.3598
Batch 110, Loss: 1.3838
Batch 120, Loss: 1.3301
Batch 130, Loss: 1.2939
Batch 140, Loss: 1.2528
Batch 150, Loss: 1.3826
Batch 160, Loss: 1.3308
Batch 170, Loss: 1.3784
Batch 180, Loss: 1.3916
Batch 190, Loss: 1.3984
Batch 200, Loss: 1.4279
Batch 210, Loss: 1.4056
Batch 220, Loss: 1.2889
Batch 230, Loss: 1.3868
Batch 240, Loss: 1.3478
Batch 250, Loss: 1.3617
Batch 260, Loss: 1.3127
Batch 270, Loss: 1.3526
Batch 280, Loss: 1.3616
Batch 290, Loss: 1.4138
Batch 300, Loss: 1.3951
Batch 310, Loss: 1.3614
Batch 320, Loss: 1.3626
Batch 330, Loss: 1.3343
Batch 340, Loss: 1.3708
Batch 350, Loss: 1.3057
Batch 360, Loss: 1.3463
Batch 370, Loss: 1.3981
Batch 380, Loss: 1.3599
Batch 390, Loss: 1.3195
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.07529330253601 seconds
Epoch 58 accuracy: 60.67%
Batch 10, Loss: 1.3450
Batch 20, Loss: 1.3096
Batch 30, Loss: 1.2737
Batch 40, Loss: 1.3282
Batch 50, Loss: 1.3175
Batch 60, Loss: 1.3100
Batch 70, Loss: 1.3387
Batch 80, Loss: 1.3588
Batch 90, Loss: 1.3721
Batch 100, Loss: 1.3142
Batch 110, Loss: 1.3037
Batch 120, Loss: 1.2818
Batch 130, Loss: 1.3167
Batch 140, Loss: 1.2929
Batch 150, Loss: 1.3679
Batch 160, Loss: 1.3490
Batch 170, Loss: 1.3529
Batch 180, Loss: 1.4002
Batch 190, Loss: 1.3503
Batch 200, Loss: 1.4335
Batch 210, Loss: 1.2916
Batch 220, Loss: 1.3612
Batch 230, Loss: 1.3780
Batch 240, Loss: 1.3198
Batch 250, Loss: 1.3056
Batch 260, Loss: 1.3506
Batch 270, Loss: 1.3931
Batch 280, Loss: 1.3471
Batch 290, Loss: 1.3280
Batch 300, Loss: 1.3639
Batch 310, Loss: 1.4009
Batch 320, Loss: 1.4348
Batch 330, Loss: 1.4687
Batch 340, Loss: 1.4259
Batch 350, Loss: 1.3194
Batch 360, Loss: 1.3815
Batch 370, Loss: 1.4414
Batch 380, Loss: 1.3840
Batch 390, Loss: 1.4406
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.085879802703857 seconds
Epoch 59 accuracy: 59.42%
Batch 10, Loss: 1.2764
Batch 20, Loss: 1.3418
Batch 30, Loss: 1.2456
Batch 40, Loss: 1.2394
Batch 50, Loss: 1.3430
Batch 60, Loss: 1.3227
Batch 70, Loss: 1.3742
Batch 80, Loss: 1.3396
Batch 90, Loss: 1.3485
Batch 100, Loss: 1.2737
Batch 110, Loss: 1.3244
Batch 120, Loss: 1.4246
Batch 130, Loss: 1.3058
Batch 140, Loss: 1.3302
Batch 150, Loss: 1.3524
Batch 160, Loss: 1.3270
Batch 170, Loss: 1.2436
Batch 180, Loss: 1.3747
Batch 190, Loss: 1.3268
Batch 200, Loss: 1.4345
Batch 210, Loss: 1.3591
Batch 220, Loss: 1.2996
Batch 230, Loss: 1.3722
Batch 240, Loss: 1.3001
Batch 250, Loss: 1.3519
Batch 260, Loss: 1.3833
Batch 270, Loss: 1.3903
Batch 280, Loss: 1.3987
Batch 290, Loss: 1.3753
Batch 300, Loss: 1.3501
Batch 310, Loss: 1.3244
Batch 320, Loss: 1.4045
Batch 330, Loss: 1.3459
Batch 340, Loss: 1.4073
Batch 350, Loss: 1.3801
Batch 360, Loss: 1.4081
Batch 370, Loss: 1.3151
Batch 380, Loss: 1.3011
Batch 390, Loss: 1.3603
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 24.983896255493164 seconds
Epoch 60 accuracy: 55.68%
Batch 10, Loss: 1.2497
Batch 20, Loss: 1.2582
Batch 30, Loss: 1.2176
Batch 40, Loss: 1.2613
Batch 50, Loss: 1.2687
Batch 60, Loss: 1.3205
Batch 70, Loss: 1.2807
Batch 80, Loss: 1.3280
Batch 90, Loss: 1.3389
Batch 100, Loss: 1.3892
Batch 110, Loss: 1.2910
Batch 120, Loss: 1.3439
Batch 130, Loss: 1.3386
Batch 140, Loss: 1.3427
Batch 150, Loss: 1.3262
Batch 160, Loss: 1.3303
Batch 170, Loss: 1.3000
Batch 180, Loss: 1.3680
Batch 190, Loss: 1.3493
Batch 200, Loss: 1.3640
Batch 210, Loss: 1.3908
Batch 220, Loss: 1.3847
Batch 230, Loss: 1.4066
Batch 240, Loss: 1.3399
Batch 250, Loss: 1.3304
Batch 260, Loss: 1.3727
Batch 270, Loss: 1.3431
Batch 280, Loss: 1.3134
Batch 290, Loss: 1.3375
Batch 300, Loss: 1.3742
Batch 310, Loss: 1.3260
Batch 320, Loss: 1.3485
Batch 330, Loss: 1.3822
Batch 340, Loss: 1.3800
Batch 350, Loss: 1.3316
Batch 360, Loss: 1.3237
Batch 370, Loss: 1.3307
Batch 380, Loss: 1.3620
Batch 390, Loss: 1.4180
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.150641918182373 seconds
Epoch 61 accuracy: 55.4%
Batch 10, Loss: 1.3086
Batch 20, Loss: 1.2937
Batch 30, Loss: 1.2604
Batch 40, Loss: 1.3340
Batch 50, Loss: 1.2870
Batch 60, Loss: 1.3571
Batch 70, Loss: 1.2953
Batch 80, Loss: 1.3395
Batch 90, Loss: 1.3746
Batch 100, Loss: 1.2970
Batch 110, Loss: 1.3607
Batch 120, Loss: 1.3111
Batch 130, Loss: 1.3611
Batch 140, Loss: 1.3087
Batch 150, Loss: 1.3551
Batch 160, Loss: 1.3378
Batch 170, Loss: 1.3733
Batch 180, Loss: 1.3280
Batch 190, Loss: 1.4335
Batch 200, Loss: 1.3468
Batch 210, Loss: 1.3798
Batch 220, Loss: 1.3371
Batch 230, Loss: 1.3621
Batch 240, Loss: 1.3132
Batch 250, Loss: 1.3859
Batch 260, Loss: 1.3624
Batch 270, Loss: 1.3752
Batch 280, Loss: 1.3676
Batch 290, Loss: 1.3437
Batch 300, Loss: 1.3737
Batch 310, Loss: 1.3832
Batch 320, Loss: 1.2829
Batch 330, Loss: 1.3055
Batch 340, Loss: 1.2882
Batch 350, Loss: 1.3663
Batch 360, Loss: 1.3350
Batch 370, Loss: 1.3257
Batch 380, Loss: 1.3233
Batch 390, Loss: 1.3387
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.199576377868652 seconds
Epoch 62 accuracy: 60.22%
Batch 10, Loss: 1.3738
Batch 20, Loss: 1.2833
Batch 30, Loss: 1.3074
Batch 40, Loss: 1.2489
Batch 50, Loss: 1.2367
Batch 60, Loss: 1.3680
Batch 70, Loss: 1.3127
Batch 80, Loss: 1.3078
Batch 90, Loss: 1.2988
Batch 100, Loss: 1.3008
Batch 110, Loss: 1.2770
Batch 120, Loss: 1.3205
Batch 130, Loss: 1.4182
Batch 140, Loss: 1.3295
Batch 150, Loss: 1.3544
Batch 160, Loss: 1.3431
Batch 170, Loss: 1.3428
Batch 180, Loss: 1.3054
Batch 190, Loss: 1.3342
Batch 200, Loss: 1.3103
Batch 210, Loss: 1.3155
Batch 220, Loss: 1.3388
Batch 230, Loss: 1.3205
Batch 240, Loss: 1.4076
Batch 250, Loss: 1.2976
Batch 260, Loss: 1.3331
Batch 270, Loss: 1.3731
Batch 280, Loss: 1.3282
Batch 290, Loss: 1.3051
Batch 300, Loss: 1.3245
Batch 310, Loss: 1.3714
Batch 320, Loss: 1.3412
Batch 330, Loss: 1.3655
Batch 340, Loss: 1.3543
Batch 350, Loss: 1.3754
Batch 360, Loss: 1.3591
Batch 370, Loss: 1.3435
Batch 380, Loss: 1.3336
Batch 390, Loss: 1.3801
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.076408624649048 seconds
Epoch 63 accuracy: 59.61%
Batch 10, Loss: 1.2844
Batch 20, Loss: 1.2916
Batch 30, Loss: 1.3057
Batch 40, Loss: 1.2689
Batch 50, Loss: 1.2933
Batch 60, Loss: 1.3283
Batch 70, Loss: 1.3065
Batch 80, Loss: 1.3253
Batch 90, Loss: 1.2467
Batch 100, Loss: 1.2654
Batch 110, Loss: 1.2795
Batch 120, Loss: 1.2783
Batch 130, Loss: 1.2944
Batch 140, Loss: 1.3183
Batch 150, Loss: 1.3099
Batch 160, Loss: 1.3067
Batch 170, Loss: 1.2988
Batch 180, Loss: 1.2675
Batch 190, Loss: 1.2766
Batch 200, Loss: 1.3142
Batch 210, Loss: 1.2878
Batch 220, Loss: 1.3682
Batch 230, Loss: 1.3592
Batch 240, Loss: 1.3126
Batch 250, Loss: 1.3196
Batch 260, Loss: 1.2523
Batch 270, Loss: 1.3885
Batch 280, Loss: 1.3324
Batch 290, Loss: 1.3275
Batch 300, Loss: 1.3568
Batch 310, Loss: 1.3030
Batch 320, Loss: 1.3794
Batch 330, Loss: 1.2648
Batch 340, Loss: 1.3733
Batch 350, Loss: 1.3375
Batch 360, Loss: 1.4073
Batch 370, Loss: 1.3861
Batch 380, Loss: 1.3481
Batch 390, Loss: 1.3116
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.010801792144775 seconds
Epoch 64 accuracy: 62.71%
Batch 10, Loss: 1.2931
Batch 20, Loss: 1.2622
Batch 30, Loss: 1.3273
Batch 40, Loss: 1.2724
Batch 50, Loss: 1.2650
Batch 60, Loss: 1.3128
Batch 70, Loss: 1.3063
Batch 80, Loss: 1.2150
Batch 90, Loss: 1.3543
Batch 100, Loss: 1.2897
Batch 110, Loss: 1.2737
Batch 120, Loss: 1.2696
Batch 130, Loss: 1.2903
Batch 140, Loss: 1.3458
Batch 150, Loss: 1.2842
Batch 160, Loss: 1.3241
Batch 170, Loss: 1.3270
Batch 180, Loss: 1.3266
Batch 190, Loss: 1.3760
Batch 200, Loss: 1.4014
Batch 210, Loss: 1.3111
Batch 220, Loss: 1.2969
Batch 230, Loss: 1.3685
Batch 240, Loss: 1.3219
Batch 250, Loss: 1.3602
Batch 260, Loss: 1.3428
Batch 270, Loss: 1.2966
Batch 280, Loss: 1.3639
Batch 290, Loss: 1.2695
Batch 300, Loss: 1.2911
Batch 310, Loss: 1.3843
Batch 320, Loss: 1.3849
Batch 330, Loss: 1.3545
Batch 340, Loss: 1.3607
Batch 350, Loss: 1.3652
Batch 360, Loss: 1.3356
Batch 370, Loss: 1.2993
Batch 380, Loss: 1.3756
Batch 390, Loss: 1.3126
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.016735553741455 seconds
Epoch 65 accuracy: 60.8%
Batch 10, Loss: 1.2406
Batch 20, Loss: 1.2601
Batch 30, Loss: 1.2330
Batch 40, Loss: 1.3223
Batch 50, Loss: 1.2858
Batch 60, Loss: 1.2738
Batch 70, Loss: 1.3096
Batch 80, Loss: 1.2638
Batch 90, Loss: 1.2907
Batch 100, Loss: 1.2919
Batch 110, Loss: 1.2934
Batch 120, Loss: 1.3308
Batch 130, Loss: 1.3276
Batch 140, Loss: 1.3271
Batch 150, Loss: 1.3376
Batch 160, Loss: 1.2984
Batch 170, Loss: 1.3411
Batch 180, Loss: 1.3265
Batch 190, Loss: 1.2401
Batch 200, Loss: 1.3565
Batch 210, Loss: 1.2844
Batch 220, Loss: 1.2993
Batch 230, Loss: 1.3595
Batch 240, Loss: 1.3697
Batch 250, Loss: 1.2461
Batch 260, Loss: 1.3685
Batch 270, Loss: 1.3403
Batch 280, Loss: 1.3305
Batch 290, Loss: 1.3375
Batch 300, Loss: 1.3104
Batch 310, Loss: 1.3375
Batch 320, Loss: 1.3312
Batch 330, Loss: 1.3648
Batch 340, Loss: 1.3236
Batch 350, Loss: 1.3758
Batch 360, Loss: 1.3594
Batch 370, Loss: 1.3811
Batch 380, Loss: 1.3403
Batch 390, Loss: 1.3885
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.072914838790894 seconds
Epoch 66 accuracy: 55.15%
Batch 10, Loss: 1.3199
Batch 20, Loss: 1.2956
Batch 30, Loss: 1.2286
Batch 40, Loss: 1.2635
Batch 50, Loss: 1.3111
Batch 60, Loss: 1.2485
Batch 70, Loss: 1.2821
Batch 80, Loss: 1.3465
Batch 90, Loss: 1.3134
Batch 100, Loss: 1.2990
Batch 110, Loss: 1.2897
Batch 120, Loss: 1.3111
Batch 130, Loss: 1.2726
Batch 140, Loss: 1.3344
Batch 150, Loss: 1.2823
Batch 160, Loss: 1.3101
Batch 170, Loss: 1.2957
Batch 180, Loss: 1.3337
Batch 190, Loss: 1.3650
Batch 200, Loss: 1.3158
Batch 210, Loss: 1.2727
Batch 220, Loss: 1.3048
Batch 230, Loss: 1.2866
Batch 240, Loss: 1.2743
Batch 250, Loss: 1.3476
Batch 260, Loss: 1.3632
Batch 270, Loss: 1.3603
Batch 280, Loss: 1.3027
Batch 290, Loss: 1.3236
Batch 300, Loss: 1.3212
Batch 310, Loss: 1.2955
Batch 320, Loss: 1.3659
Batch 330, Loss: 1.3169
Batch 340, Loss: 1.3162
Batch 350, Loss: 1.3308
Batch 360, Loss: 1.3484
Batch 370, Loss: 1.2798
Batch 380, Loss: 1.3841
Batch 390, Loss: 1.3326
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.11961340904236 seconds
Epoch 67 accuracy: 60.99%
Batch 10, Loss: 1.2969
Batch 20, Loss: 1.2231
Batch 30, Loss: 1.2587
Batch 40, Loss: 1.2802
Batch 50, Loss: 1.2815
Batch 60, Loss: 1.3068
Batch 70, Loss: 1.2151
Batch 80, Loss: 1.2677
Batch 90, Loss: 1.2715
Batch 100, Loss: 1.2272
Batch 110, Loss: 1.3270
Batch 120, Loss: 1.2470
Batch 130, Loss: 1.2946
Batch 140, Loss: 1.3037
Batch 150, Loss: 1.3085
Batch 160, Loss: 1.2489
Batch 170, Loss: 1.2591
Batch 180, Loss: 1.2796
Batch 190, Loss: 1.3537
Batch 200, Loss: 1.3558
Batch 210, Loss: 1.3315
Batch 220, Loss: 1.3660
Batch 230, Loss: 1.3757
Batch 240, Loss: 1.3236
Batch 250, Loss: 1.3260
Batch 260, Loss: 1.2627
Batch 270, Loss: 1.2736
Batch 280, Loss: 1.3306
Batch 290, Loss: 1.3667
Batch 300, Loss: 1.3186
Batch 310, Loss: 1.3466
Batch 320, Loss: 1.2937
Batch 330, Loss: 1.3560
Batch 340, Loss: 1.3302
Batch 350, Loss: 1.3204
Batch 360, Loss: 1.3564
Batch 370, Loss: 1.3332
Batch 380, Loss: 1.3647
Batch 390, Loss: 1.3830
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.1484534740448 seconds
Epoch 68 accuracy: 61.45%
Batch 10, Loss: 1.3065
Batch 20, Loss: 1.2586
Batch 30, Loss: 1.1700
Batch 40, Loss: 1.1916
Batch 50, Loss: 1.2926
Batch 60, Loss: 1.2334
Batch 70, Loss: 1.2983
Batch 80, Loss: 1.2536
Batch 90, Loss: 1.3112
Batch 100, Loss: 1.3155
Batch 110, Loss: 1.2810
Batch 120, Loss: 1.1914
Batch 130, Loss: 1.2703
Batch 140, Loss: 1.2564
Batch 150, Loss: 1.2539
Batch 160, Loss: 1.2877
Batch 170, Loss: 1.3154
Batch 180, Loss: 1.2764
Batch 190, Loss: 1.3056
Batch 200, Loss: 1.2817
Batch 210, Loss: 1.2795
Batch 220, Loss: 1.3260
Batch 230, Loss: 1.3261
Batch 240, Loss: 1.3391
Batch 250, Loss: 1.3028
Batch 260, Loss: 1.2709
Batch 270, Loss: 1.2960
Batch 280, Loss: 1.3562
Batch 290, Loss: 1.3533
Batch 300, Loss: 1.3432
Batch 310, Loss: 1.3656
Batch 320, Loss: 1.3494
Batch 330, Loss: 1.2554
Batch 340, Loss: 1.3145
Batch 350, Loss: 1.2896
Batch 360, Loss: 1.2864
Batch 370, Loss: 1.2745
Batch 380, Loss: 1.3645
Batch 390, Loss: 1.3682
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.18439507484436 seconds
Epoch 69 accuracy: 61.65%
Batch 10, Loss: 1.2373
Batch 20, Loss: 1.2794
Batch 30, Loss: 1.1913
Batch 40, Loss: 1.2052
Batch 50, Loss: 1.2455
Batch 60, Loss: 1.2121
Batch 70, Loss: 1.2374
Batch 80, Loss: 1.2858
Batch 90, Loss: 1.2062
Batch 100, Loss: 1.2490
Batch 110, Loss: 1.3209
Batch 120, Loss: 1.2775
Batch 130, Loss: 1.3469
Batch 140, Loss: 1.3113
Batch 150, Loss: 1.3163
Batch 160, Loss: 1.3003
Batch 170, Loss: 1.2832
Batch 180, Loss: 1.2102
Batch 190, Loss: 1.3346
Batch 200, Loss: 1.3702
Batch 210, Loss: 1.2921
Batch 220, Loss: 1.2697
Batch 230, Loss: 1.3077
Batch 240, Loss: 1.3083
Batch 250, Loss: 1.2877
Batch 260, Loss: 1.2477
Batch 270, Loss: 1.3157
Batch 280, Loss: 1.3228
Batch 290, Loss: 1.3669
Batch 300, Loss: 1.3175
Batch 310, Loss: 1.3347
Batch 320, Loss: 1.3196
Batch 330, Loss: 1.2853
Batch 340, Loss: 1.2778
Batch 350, Loss: 1.3175
Batch 360, Loss: 1.3760
Batch 370, Loss: 1.3194
Batch 380, Loss: 1.3194
Batch 390, Loss: 1.3036
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.166213750839233 seconds
Epoch 70 accuracy: 61.75%
Batch 10, Loss: 1.3199
Batch 20, Loss: 1.3388
Batch 30, Loss: 1.2786
Batch 40, Loss: 1.2248
Batch 50, Loss: 1.3048
Batch 60, Loss: 1.2431
Batch 70, Loss: 1.2838
Batch 80, Loss: 1.1968
Batch 90, Loss: 1.2561
Batch 100, Loss: 1.2316
Batch 110, Loss: 1.2297
Batch 120, Loss: 1.2796
Batch 130, Loss: 1.2131
Batch 140, Loss: 1.2955
Batch 150, Loss: 1.2627
Batch 160, Loss: 1.3013
Batch 170, Loss: 1.3513
Batch 180, Loss: 1.3108
Batch 190, Loss: 1.2734
Batch 200, Loss: 1.3489
Batch 210, Loss: 1.2195
Batch 220, Loss: 1.3361
Batch 230, Loss: 1.2956
Batch 240, Loss: 1.3500
Batch 250, Loss: 1.3441
Batch 260, Loss: 1.3628
Batch 270, Loss: 1.3128
Batch 280, Loss: 1.2857
Batch 290, Loss: 1.3457
Batch 300, Loss: 1.2278
Batch 310, Loss: 1.2727
Batch 320, Loss: 1.2801
Batch 330, Loss: 1.3046
Batch 340, Loss: 1.2741
Batch 350, Loss: 1.3248
Batch 360, Loss: 1.2035
Batch 370, Loss: 1.2720
Batch 380, Loss: 1.3182
Batch 390, Loss: 1.3358
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.40908122062683 seconds
Epoch 71 accuracy: 59.21%
Batch 10, Loss: 1.2656
Batch 20, Loss: 1.2486
Batch 30, Loss: 1.2566
Batch 40, Loss: 1.2501
Batch 50, Loss: 1.2191
Batch 60, Loss: 1.2901
Batch 70, Loss: 1.2656
Batch 80, Loss: 1.2899
Batch 90, Loss: 1.2305
Batch 100, Loss: 1.2468
Batch 110, Loss: 1.3739
Batch 120, Loss: 1.2212
Batch 130, Loss: 1.2469
Batch 140, Loss: 1.2609
Batch 150, Loss: 1.2457
Batch 160, Loss: 1.2427
Batch 170, Loss: 1.2817
Batch 180, Loss: 1.2928
Batch 190, Loss: 1.2440
Batch 200, Loss: 1.3164
Batch 210, Loss: 1.3290
Batch 220, Loss: 1.2539
Batch 230, Loss: 1.2704
Batch 240, Loss: 1.2973
Batch 250, Loss: 1.3163
Batch 260, Loss: 1.3778
Batch 270, Loss: 1.2557
Batch 280, Loss: 1.3337
Batch 290, Loss: 1.2906
Batch 300, Loss: 1.2576
Batch 310, Loss: 1.3156
Batch 320, Loss: 1.3427
Batch 330, Loss: 1.2956
Batch 340, Loss: 1.3324
Batch 350, Loss: 1.3451
Batch 360, Loss: 1.2677
Batch 370, Loss: 1.3414
Batch 380, Loss: 1.2902
Batch 390, Loss: 1.3824
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.07680082321167 seconds
Epoch 72 accuracy: 57.28%
Batch 10, Loss: 1.2580
Batch 20, Loss: 1.2813
Batch 30, Loss: 1.2307
Batch 40, Loss: 1.2164
Batch 50, Loss: 1.3536
Batch 60, Loss: 1.2560
Batch 70, Loss: 1.2366
Batch 80, Loss: 1.2686
Batch 90, Loss: 1.2544
Batch 100, Loss: 1.3228
Batch 110, Loss: 1.3198
Batch 120, Loss: 1.2311
Batch 130, Loss: 1.2843
Batch 140, Loss: 1.2740
Batch 150, Loss: 1.2624
Batch 160, Loss: 1.3280
Batch 170, Loss: 1.2133
Batch 180, Loss: 1.2906
Batch 190, Loss: 1.2651
Batch 200, Loss: 1.2581
Batch 210, Loss: 1.3002
Batch 220, Loss: 1.2393
Batch 230, Loss: 1.2326
Batch 240, Loss: 1.2767
Batch 250, Loss: 1.3262
Batch 260, Loss: 1.4216
Batch 270, Loss: 1.3473
Batch 280, Loss: 1.3325
Batch 290, Loss: 1.3687
Batch 300, Loss: 1.2778
Batch 310, Loss: 1.3490
Batch 320, Loss: 1.2585
Batch 330, Loss: 1.2655
Batch 340, Loss: 1.3043
Batch 350, Loss: 1.2740
Batch 360, Loss: 1.3069
Batch 370, Loss: 1.2285
Batch 380, Loss: 1.3379
Batch 390, Loss: 1.3090
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.15604567527771 seconds
Epoch 73 accuracy: 63.69%
Batch 10, Loss: 1.1563
Batch 20, Loss: 1.2564
Batch 30, Loss: 1.2080
Batch 40, Loss: 1.2814
Batch 50, Loss: 1.2626
Batch 60, Loss: 1.1933
Batch 70, Loss: 1.1991
Batch 80, Loss: 1.2451
Batch 90, Loss: 1.2371
Batch 100, Loss: 1.2513
Batch 110, Loss: 1.2759
Batch 120, Loss: 1.2694
Batch 130, Loss: 1.2765
Batch 140, Loss: 1.2368
Batch 150, Loss: 1.2700
Batch 160, Loss: 1.1864
Batch 170, Loss: 1.2845
Batch 180, Loss: 1.2983
Batch 190, Loss: 1.2265
Batch 200, Loss: 1.2610
Batch 210, Loss: 1.3724
Batch 220, Loss: 1.3486
Batch 230, Loss: 1.2808
Batch 240, Loss: 1.3013
Batch 250, Loss: 1.3126
Batch 260, Loss: 1.2604
Batch 270, Loss: 1.2684
Batch 280, Loss: 1.3096
Batch 290, Loss: 1.2842
Batch 300, Loss: 1.2575
Batch 310, Loss: 1.2291
Batch 320, Loss: 1.2869
Batch 330, Loss: 1.2963
Batch 340, Loss: 1.3170
Batch 350, Loss: 1.3533
Batch 360, Loss: 1.2982
Batch 370, Loss: 1.2984
Batch 380, Loss: 1.3008
Batch 390, Loss: 1.2991
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.19468379020691 seconds
Epoch 74 accuracy: 62.26%
Batch 10, Loss: 1.2186
Batch 20, Loss: 1.2048
Batch 30, Loss: 1.2293
Batch 40, Loss: 1.2981
Batch 50, Loss: 1.2370
Batch 60, Loss: 1.2518
Batch 70, Loss: 1.2590
Batch 80, Loss: 1.2636
Batch 90, Loss: 1.1720
Batch 100, Loss: 1.2622
Batch 110, Loss: 1.2080
Batch 120, Loss: 1.2096
Batch 130, Loss: 1.2717
Batch 140, Loss: 1.3046
Batch 150, Loss: 1.2379
Batch 160, Loss: 1.2502
Batch 170, Loss: 1.2835
Batch 180, Loss: 1.2418
Batch 190, Loss: 1.2652
Batch 200, Loss: 1.2387
Batch 210, Loss: 1.2984
Batch 220, Loss: 1.2517
Batch 230, Loss: 1.2994
Batch 240, Loss: 1.3436
Batch 250, Loss: 1.2779
Batch 260, Loss: 1.2749
Batch 270, Loss: 1.3790
Batch 280, Loss: 1.2633
Batch 290, Loss: 1.3181
Batch 300, Loss: 1.2812
Batch 310, Loss: 1.2800
Batch 320, Loss: 1.3021
Batch 330, Loss: 1.3395
Batch 340, Loss: 1.2746
Batch 350, Loss: 1.3264
Batch 360, Loss: 1.3260
Batch 370, Loss: 1.2950
Batch 380, Loss: 1.2786
Batch 390, Loss: 1.2812
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.08723020553589 seconds
Epoch 75 accuracy: 62.03%
Batch 10, Loss: 1.1949
Batch 20, Loss: 1.2246
Batch 30, Loss: 1.2236
Batch 40, Loss: 1.2508
Batch 50, Loss: 1.2437
Batch 60, Loss: 1.1844
Batch 70, Loss: 1.1917
Batch 80, Loss: 1.2120
Batch 90, Loss: 1.2486
Batch 100, Loss: 1.2041
Batch 110, Loss: 1.1763
Batch 120, Loss: 1.2386
Batch 130, Loss: 1.2352
Batch 140, Loss: 1.2791
Batch 150, Loss: 1.2684
Batch 160, Loss: 1.2525
Batch 170, Loss: 1.2987
Batch 180, Loss: 1.2081
Batch 190, Loss: 1.2376
Batch 200, Loss: 1.2118
Batch 210, Loss: 1.3073
Batch 220, Loss: 1.2077
Batch 230, Loss: 1.3200
Batch 240, Loss: 1.2778
Batch 250, Loss: 1.2607
Batch 260, Loss: 1.2644
Batch 270, Loss: 1.3155
Batch 280, Loss: 1.3244
Batch 290, Loss: 1.3026
Batch 300, Loss: 1.2986
Batch 310, Loss: 1.2859
Batch 320, Loss: 1.2212
Batch 330, Loss: 1.1928
Batch 340, Loss: 1.3271
Batch 350, Loss: 1.2825
Batch 360, Loss: 1.2784
Batch 370, Loss: 1.3283
Batch 380, Loss: 1.2773
Batch 390, Loss: 1.2963
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.22428822517395 seconds
Epoch 76 accuracy: 62.64%
Batch 10, Loss: 1.1950
Batch 20, Loss: 1.2296
Batch 30, Loss: 1.1903
Batch 40, Loss: 1.2618
Batch 50, Loss: 1.2010
Batch 60, Loss: 1.2751
Batch 70, Loss: 1.2659
Batch 80, Loss: 1.2855
Batch 90, Loss: 1.1977
Batch 100, Loss: 1.2166
Batch 110, Loss: 1.2134
Batch 120, Loss: 1.2552
Batch 130, Loss: 1.2825
Batch 140, Loss: 1.2749
Batch 150, Loss: 1.2969
Batch 160, Loss: 1.2123
Batch 170, Loss: 1.3086
Batch 180, Loss: 1.2717
Batch 190, Loss: 1.2844
Batch 200, Loss: 1.2266
Batch 210, Loss: 1.2436
Batch 220, Loss: 1.2820
Batch 230, Loss: 1.2117
Batch 240, Loss: 1.2390
Batch 250, Loss: 1.2682
Batch 260, Loss: 1.2621
Batch 270, Loss: 1.2702
Batch 280, Loss: 1.2954
Batch 290, Loss: 1.2330
Batch 300, Loss: 1.2331
Batch 310, Loss: 1.2681
Batch 320, Loss: 1.2676
Batch 330, Loss: 1.3208
Batch 340, Loss: 1.2756
Batch 350, Loss: 1.2467
Batch 360, Loss: 1.2374
Batch 370, Loss: 1.2161
Batch 380, Loss: 1.3019
Batch 390, Loss: 1.2782
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.077784299850464 seconds
Epoch 77 accuracy: 60.3%
Batch 10, Loss: 1.2709
Batch 20, Loss: 1.1556
Batch 30, Loss: 1.1499
Batch 40, Loss: 1.1630
Batch 50, Loss: 1.2049
Batch 60, Loss: 1.2056
Batch 70, Loss: 1.1642
Batch 80, Loss: 1.1993
Batch 90, Loss: 1.1563
Batch 100, Loss: 1.2826
Batch 110, Loss: 1.2407
Batch 120, Loss: 1.2720
Batch 130, Loss: 1.3002
Batch 140, Loss: 1.2469
Batch 150, Loss: 1.2734
Batch 160, Loss: 1.2719
Batch 170, Loss: 1.2533
Batch 180, Loss: 1.2350
Batch 190, Loss: 1.1439
Batch 200, Loss: 1.2075
Batch 210, Loss: 1.2548
Batch 220, Loss: 1.2096
Batch 230, Loss: 1.1348
Batch 240, Loss: 1.2536
Batch 250, Loss: 1.2276
Batch 260, Loss: 1.2248
Batch 270, Loss: 1.2985
Batch 280, Loss: 1.2567
Batch 290, Loss: 1.2936
Batch 300, Loss: 1.2234
Batch 310, Loss: 1.2697
Batch 320, Loss: 1.2502
Batch 330, Loss: 1.3322
Batch 340, Loss: 1.2834
Batch 350, Loss: 1.2813
Batch 360, Loss: 1.2562
Batch 370, Loss: 1.2764
Batch 380, Loss: 1.2464
Batch 390, Loss: 1.2210
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.100844621658325 seconds
Epoch 78 accuracy: 62.48%
Batch 10, Loss: 1.1575
Batch 20, Loss: 1.1902
Batch 30, Loss: 1.2170
Batch 40, Loss: 1.1351
Batch 50, Loss: 1.1649
Batch 60, Loss: 1.2362
Batch 70, Loss: 1.2265
Batch 80, Loss: 1.2647
Batch 90, Loss: 1.1992
Batch 100, Loss: 1.1835
Batch 110, Loss: 1.2077
Batch 120, Loss: 1.2163
Batch 130, Loss: 1.2019
Batch 140, Loss: 1.2619
Batch 150, Loss: 1.2038
Batch 160, Loss: 1.3021
Batch 170, Loss: 1.2751
Batch 180, Loss: 1.2692
Batch 190, Loss: 1.2711
Batch 200, Loss: 1.2893
Batch 210, Loss: 1.2107
Batch 220, Loss: 1.2156
Batch 230, Loss: 1.1793
Batch 240, Loss: 1.2378
Batch 250, Loss: 1.3127
Batch 260, Loss: 1.3266
Batch 270, Loss: 1.2538
Batch 280, Loss: 1.2311
Batch 290, Loss: 1.2796
Batch 300, Loss: 1.2506
Batch 310, Loss: 1.2853
Batch 320, Loss: 1.1982
Batch 330, Loss: 1.1753
Batch 340, Loss: 1.2699
Batch 350, Loss: 1.3181
Batch 360, Loss: 1.2661
Batch 370, Loss: 1.2978
Batch 380, Loss: 1.2639
Batch 390, Loss: 1.2870
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.066036701202393 seconds
Epoch 79 accuracy: 63.02%
Batch 10, Loss: 1.1465
Batch 20, Loss: 1.1857
Batch 30, Loss: 1.1496
Batch 40, Loss: 1.1490
Batch 50, Loss: 1.2276
Batch 60, Loss: 1.2248
Batch 70, Loss: 1.2019
Batch 80, Loss: 1.2015
Batch 90, Loss: 1.2582
Batch 100, Loss: 1.1897
Batch 110, Loss: 1.2386
Batch 120, Loss: 1.2371
Batch 130, Loss: 1.2408
Batch 140, Loss: 1.2072
Batch 150, Loss: 1.1846
Batch 160, Loss: 1.1842
Batch 170, Loss: 1.1882
Batch 180, Loss: 1.2351
Batch 190, Loss: 1.2240
Batch 200, Loss: 1.2333
Batch 210, Loss: 1.2022
Batch 220, Loss: 1.2406
Batch 230, Loss: 1.2244
Batch 240, Loss: 1.2955
Batch 250, Loss: 1.2179
Batch 260, Loss: 1.2137
Batch 270, Loss: 1.2229
Batch 280, Loss: 1.2431
Batch 290, Loss: 1.2514
Batch 300, Loss: 1.3010
Batch 310, Loss: 1.2691
Batch 320, Loss: 1.3103
Batch 330, Loss: 1.2478
Batch 340, Loss: 1.2459
Batch 350, Loss: 1.2549
Batch 360, Loss: 1.2728
Batch 370, Loss: 1.2317
Batch 380, Loss: 1.3009
Batch 390, Loss: 1.3010
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.046240091323853 seconds
Epoch 80 accuracy: 63.13%
Batch 10, Loss: 1.1260
Batch 20, Loss: 1.1574
Batch 30, Loss: 1.1552
Batch 40, Loss: 1.1706
Batch 50, Loss: 1.2006
Batch 60, Loss: 1.2561
Batch 70, Loss: 1.2197
Batch 80, Loss: 1.2091
Batch 90, Loss: 1.2652
Batch 100, Loss: 1.2397
Batch 110, Loss: 1.2385
Batch 120, Loss: 1.1764
Batch 130, Loss: 1.2544
Batch 140, Loss: 1.2602
Batch 150, Loss: 1.1803
Batch 160, Loss: 1.2401
Batch 170, Loss: 1.1902
Batch 180, Loss: 1.2657
Batch 190, Loss: 1.2342
Batch 200, Loss: 1.2451
Batch 210, Loss: 1.2296
Batch 220, Loss: 1.2349
Batch 230, Loss: 1.2112
Batch 240, Loss: 1.3111
Batch 250, Loss: 1.2528
Batch 260, Loss: 1.2211
Batch 270, Loss: 1.2734
Batch 280, Loss: 1.2483
Batch 290, Loss: 1.2600
Batch 300, Loss: 1.2678
Batch 310, Loss: 1.2148
Batch 320, Loss: 1.2526
Batch 330, Loss: 1.2851
Batch 340, Loss: 1.2822
Batch 350, Loss: 1.2359
Batch 360, Loss: 1.1870
Batch 370, Loss: 1.2339
Batch 380, Loss: 1.2500
Batch 390, Loss: 1.2979
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.013521432876587 seconds
Epoch 81 accuracy: 62.0%
Batch 10, Loss: 1.1812
Batch 20, Loss: 1.1319
Batch 30, Loss: 1.2033
Batch 40, Loss: 1.2200
Batch 50, Loss: 1.1868
Batch 60, Loss: 1.2124
Batch 70, Loss: 1.1694
Batch 80, Loss: 1.1837
Batch 90, Loss: 1.1786
Batch 100, Loss: 1.1497
Batch 110, Loss: 1.1965
Batch 120, Loss: 1.1993
Batch 130, Loss: 1.2051
Batch 140, Loss: 1.2386
Batch 150, Loss: 1.2670
Batch 160, Loss: 1.2516
Batch 170, Loss: 1.2596
Batch 180, Loss: 1.2293
Batch 190, Loss: 1.2371
Batch 200, Loss: 1.2490
Batch 210, Loss: 1.2285
Batch 220, Loss: 1.2422
Batch 230, Loss: 1.1623
Batch 240, Loss: 1.2277
Batch 250, Loss: 1.2208
Batch 260, Loss: 1.2137
Batch 270, Loss: 1.2071
Batch 280, Loss: 1.2592
Batch 290, Loss: 1.2665
Batch 300, Loss: 1.2461
Batch 310, Loss: 1.2407
Batch 320, Loss: 1.2822
Batch 330, Loss: 1.2032
Batch 340, Loss: 1.2225
Batch 350, Loss: 1.1795
Batch 360, Loss: 1.1863
Batch 370, Loss: 1.2349
Batch 380, Loss: 1.2285
Batch 390, Loss: 1.2769
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.09618067741394 seconds
Epoch 82 accuracy: 61.41%
Batch 10, Loss: 1.2129
Batch 20, Loss: 1.1485
Batch 30, Loss: 1.1921
Batch 40, Loss: 1.1768
Batch 50, Loss: 1.1659
Batch 60, Loss: 1.1694
Batch 70, Loss: 1.1161
Batch 80, Loss: 1.1701
Batch 90, Loss: 1.1701
Batch 100, Loss: 1.2004
Batch 110, Loss: 1.1742
Batch 120, Loss: 1.2328
Batch 130, Loss: 1.2162
Batch 140, Loss: 1.2346
Batch 150, Loss: 1.1334
Batch 160, Loss: 1.1996
Batch 170, Loss: 1.2122
Batch 180, Loss: 1.1656
Batch 190, Loss: 1.2897
Batch 200, Loss: 1.1937
Batch 210, Loss: 1.2457
Batch 220, Loss: 1.2772
Batch 230, Loss: 1.2132
Batch 240, Loss: 1.3017
Batch 250, Loss: 1.2606
Batch 260, Loss: 1.2530
Batch 270, Loss: 1.2388
Batch 280, Loss: 1.2467
Batch 290, Loss: 1.2240
Batch 300, Loss: 1.2780
Batch 310, Loss: 1.2152
Batch 320, Loss: 1.2781
Batch 330, Loss: 1.1826
Batch 340, Loss: 1.2268
Batch 350, Loss: 1.2028
Batch 360, Loss: 1.1901
Batch 370, Loss: 1.2612
Batch 380, Loss: 1.3403
Batch 390, Loss: 1.2999
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.13028573989868 seconds
Epoch 83 accuracy: 63.15%
Batch 10, Loss: 1.1081
Batch 20, Loss: 1.1214
Batch 30, Loss: 1.1569
Batch 40, Loss: 1.1771
Batch 50, Loss: 1.1723
Batch 60, Loss: 1.1400
Batch 70, Loss: 1.1588
Batch 80, Loss: 1.1731
Batch 90, Loss: 1.1195
Batch 100, Loss: 1.2130
Batch 110, Loss: 1.2145
Batch 120, Loss: 1.2231
Batch 130, Loss: 1.1871
Batch 140, Loss: 1.2104
Batch 150, Loss: 1.2164
Batch 160, Loss: 1.1662
Batch 170, Loss: 1.1041
Batch 180, Loss: 1.1970
Batch 190, Loss: 1.2483
Batch 200, Loss: 1.2023
Batch 210, Loss: 1.2237
Batch 220, Loss: 1.1683
Batch 230, Loss: 1.1846
Batch 240, Loss: 1.1911
Batch 250, Loss: 1.1659
Batch 260, Loss: 1.1909
Batch 270, Loss: 1.3132
Batch 280, Loss: 1.2799
Batch 290, Loss: 1.2539
Batch 300, Loss: 1.3144
Batch 310, Loss: 1.2833
Batch 320, Loss: 1.2013
Batch 330, Loss: 1.2161
Batch 340, Loss: 1.2434
Batch 350, Loss: 1.2471
Batch 360, Loss: 1.2379
Batch 370, Loss: 1.2101
Batch 380, Loss: 1.2364
Batch 390, Loss: 1.2402
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.06749153137207 seconds
Epoch 84 accuracy: 62.95%
Batch 10, Loss: 1.2223
Batch 20, Loss: 1.1562
Batch 30, Loss: 1.0819
Batch 40, Loss: 1.1887
Batch 50, Loss: 1.1478
Batch 60, Loss: 1.1744
Batch 70, Loss: 1.1489
Batch 80, Loss: 1.1438
Batch 90, Loss: 1.2218
Batch 100, Loss: 1.2190
Batch 110, Loss: 1.2034
Batch 120, Loss: 1.1495
Batch 130, Loss: 1.2042
Batch 140, Loss: 1.3016
Batch 150, Loss: 1.1804
Batch 160, Loss: 1.2052
Batch 170, Loss: 1.1799
Batch 180, Loss: 1.1364
Batch 190, Loss: 1.1688
Batch 200, Loss: 1.1828
Batch 210, Loss: 1.2363
Batch 220, Loss: 1.2260
Batch 230, Loss: 1.2577
Batch 240, Loss: 1.2333
Batch 250, Loss: 1.1718
Batch 260, Loss: 1.2314
Batch 270, Loss: 1.2298
Batch 280, Loss: 1.1986
Batch 290, Loss: 1.1774
Batch 300, Loss: 1.2496
Batch 310, Loss: 1.1680
Batch 320, Loss: 1.2607
Batch 330, Loss: 1.1593
Batch 340, Loss: 1.1879
Batch 350, Loss: 1.3210
Batch 360, Loss: 1.2246
Batch 370, Loss: 1.2373
Batch 380, Loss: 1.2980
Batch 390, Loss: 1.2652
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.090197801589966 seconds
Epoch 85 accuracy: 59.9%
Batch 10, Loss: 1.1738
Batch 20, Loss: 1.0755
Batch 30, Loss: 1.1789
Batch 40, Loss: 1.1073
Batch 50, Loss: 1.2110
Batch 60, Loss: 1.0786
Batch 70, Loss: 1.1401
Batch 80, Loss: 1.1787
Batch 90, Loss: 1.1964
Batch 100, Loss: 1.1838
Batch 110, Loss: 1.2055
Batch 120, Loss: 1.2129
Batch 130, Loss: 1.1685
Batch 140, Loss: 1.1456
Batch 150, Loss: 1.1665
Batch 160, Loss: 1.1564
Batch 170, Loss: 1.0672
Batch 180, Loss: 1.2238
Batch 190, Loss: 1.1670
Batch 200, Loss: 1.2175
Batch 210, Loss: 1.3160
Batch 220, Loss: 1.2086
Batch 230, Loss: 1.2738
Batch 240, Loss: 1.2002
Batch 250, Loss: 1.2302
Batch 260, Loss: 1.3085
Batch 270, Loss: 1.2691
Batch 280, Loss: 1.1711
Batch 290, Loss: 1.2250
Batch 300, Loss: 1.2052
Batch 310, Loss: 1.2220
Batch 320, Loss: 1.2734
Batch 330, Loss: 1.1450
Batch 340, Loss: 1.2177
Batch 350, Loss: 1.2432
Batch 360, Loss: 1.2819
Batch 370, Loss: 1.2671
Batch 380, Loss: 1.1937
Batch 390, Loss: 1.1992
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.095500230789185 seconds
Epoch 86 accuracy: 61.93%
Batch 10, Loss: 1.0982
Batch 20, Loss: 1.1192
Batch 30, Loss: 1.1334
Batch 40, Loss: 1.1203
Batch 50, Loss: 1.1708
Batch 60, Loss: 1.2191
Batch 70, Loss: 1.1685
Batch 80, Loss: 1.2459
Batch 90, Loss: 1.1666
Batch 100, Loss: 1.2070
Batch 110, Loss: 1.2159
Batch 120, Loss: 1.2228
Batch 130, Loss: 1.1863
Batch 140, Loss: 1.1712
Batch 150, Loss: 1.1600
Batch 160, Loss: 1.1930
Batch 170, Loss: 1.1626
Batch 180, Loss: 1.2264
Batch 190, Loss: 1.1255
Batch 200, Loss: 1.1827
Batch 210, Loss: 1.2594
Batch 220, Loss: 1.1930
Batch 230, Loss: 1.2291
Batch 240, Loss: 1.1773
Batch 250, Loss: 1.2433
Batch 260, Loss: 1.2807
Batch 270, Loss: 1.1971
Batch 280, Loss: 1.2827
Batch 290, Loss: 1.2554
Batch 300, Loss: 1.1933
Batch 310, Loss: 1.1475
Batch 320, Loss: 1.1933
Batch 330, Loss: 1.1518
Batch 340, Loss: 1.1438
Batch 350, Loss: 1.1956
Batch 360, Loss: 1.1824
Batch 370, Loss: 1.1645
Batch 380, Loss: 1.2185
Batch 390, Loss: 1.2075
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 24.946303367614746 seconds
Epoch 87 accuracy: 63.4%
Batch 10, Loss: 1.2180
Batch 20, Loss: 1.0938
Batch 30, Loss: 1.1434
Batch 40, Loss: 1.1394
Batch 50, Loss: 1.1207
Batch 60, Loss: 1.1661
Batch 70, Loss: 1.1500
Batch 80, Loss: 1.1368
Batch 90, Loss: 1.1511
Batch 100, Loss: 1.1884
Batch 110, Loss: 1.1314
Batch 120, Loss: 1.1485
Batch 130, Loss: 1.1259
Batch 140, Loss: 1.1675
Batch 150, Loss: 1.1255
Batch 160, Loss: 1.1840
Batch 170, Loss: 1.2138
Batch 180, Loss: 1.1785
Batch 190, Loss: 1.1954
Batch 200, Loss: 1.2033
Batch 210, Loss: 1.1526
Batch 220, Loss: 1.1668
Batch 230, Loss: 1.1626
Batch 240, Loss: 1.2082
Batch 250, Loss: 1.1875
Batch 260, Loss: 1.0972
Batch 270, Loss: 1.1734
Batch 280, Loss: 1.2110
Batch 290, Loss: 1.2597
Batch 300, Loss: 1.2099
Batch 310, Loss: 1.1711
Batch 320, Loss: 1.1910
Batch 330, Loss: 1.1901
Batch 340, Loss: 1.2040
Batch 350, Loss: 1.2122
Batch 360, Loss: 1.2735
Batch 370, Loss: 1.2202
Batch 380, Loss: 1.1924
Batch 390, Loss: 1.2462
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.045389413833618 seconds
Epoch 88 accuracy: 64.5%
Batch 10, Loss: 1.0831
Batch 20, Loss: 1.0598
Batch 30, Loss: 1.1334
Batch 40, Loss: 1.2040
Batch 50, Loss: 1.0903
Batch 60, Loss: 1.1042
Batch 70, Loss: 1.1005
Batch 80, Loss: 1.1509
Batch 90, Loss: 1.2012
Batch 100, Loss: 1.1622
Batch 110, Loss: 1.1737
Batch 120, Loss: 1.1348
Batch 130, Loss: 1.2084
Batch 140, Loss: 1.1943
Batch 150, Loss: 1.1685
Batch 160, Loss: 1.2038
Batch 170, Loss: 1.2011
Batch 180, Loss: 1.2070
Batch 190, Loss: 1.1829
Batch 200, Loss: 1.2508
Batch 210, Loss: 1.1750
Batch 220, Loss: 1.2460
Batch 230, Loss: 1.2039
Batch 240, Loss: 1.2124
Batch 250, Loss: 1.1711
Batch 260, Loss: 1.2324
Batch 270, Loss: 1.2024
Batch 280, Loss: 1.1446
Batch 290, Loss: 1.2495
Batch 300, Loss: 1.1779
Batch 310, Loss: 1.1741
Batch 320, Loss: 1.2303
Batch 330, Loss: 1.2168
Batch 340, Loss: 1.1401
Batch 350, Loss: 1.2172
Batch 360, Loss: 1.2413
Batch 370, Loss: 1.1385
Batch 380, Loss: 1.2564
Batch 390, Loss: 1.2427
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.080404043197632 seconds
Epoch 89 accuracy: 66.84%
Batch 10, Loss: 1.0817
Batch 20, Loss: 1.1167
Batch 30, Loss: 1.1262
Batch 40, Loss: 1.1315
Batch 50, Loss: 1.1434
Batch 60, Loss: 1.1844
Batch 70, Loss: 1.1361
Batch 80, Loss: 1.1962
Batch 90, Loss: 1.1543
Batch 100, Loss: 1.1506
Batch 110, Loss: 1.2257
Batch 120, Loss: 1.0929
Batch 130, Loss: 1.1900
Batch 140, Loss: 1.1207
Batch 150, Loss: 1.1685
Batch 160, Loss: 1.1910
Batch 170, Loss: 1.2168
Batch 180, Loss: 1.1596
Batch 190, Loss: 1.1897
Batch 200, Loss: 1.1453
Batch 210, Loss: 1.1270
Batch 220, Loss: 1.1664
Batch 230, Loss: 1.1565
Batch 240, Loss: 1.1352
Batch 250, Loss: 1.1573
Batch 260, Loss: 1.2092
Batch 270, Loss: 1.2362
Batch 280, Loss: 1.1052
Batch 290, Loss: 1.1581
Batch 300, Loss: 1.1478
Batch 310, Loss: 1.1939
Batch 320, Loss: 1.2084
Batch 330, Loss: 1.1725
Batch 340, Loss: 1.2818
Batch 350, Loss: 1.2323
Batch 360, Loss: 1.1638
Batch 370, Loss: 1.2568
Batch 380, Loss: 1.1694
Batch 390, Loss: 1.1730
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.09298539161682 seconds
Epoch 90 accuracy: 59.91%
Batch 10, Loss: 1.1707
Batch 20, Loss: 1.1525
Batch 30, Loss: 1.1897
Batch 40, Loss: 1.0775
Batch 50, Loss: 1.1395
Batch 60, Loss: 1.1264
Batch 70, Loss: 1.1211
Batch 80, Loss: 1.1131
Batch 90, Loss: 1.1029
Batch 100, Loss: 1.1079
Batch 110, Loss: 1.1568
Batch 120, Loss: 1.1608
Batch 130, Loss: 1.1015
Batch 140, Loss: 1.1154
Batch 150, Loss: 1.1761
Batch 160, Loss: 1.1592
Batch 170, Loss: 1.1512
Batch 180, Loss: 1.1515
Batch 190, Loss: 1.1714
Batch 200, Loss: 1.1103
Batch 210, Loss: 1.2478
Batch 220, Loss: 1.1708
Batch 230, Loss: 1.2202
Batch 240, Loss: 1.1645
Batch 250, Loss: 1.1956
Batch 260, Loss: 1.1470
Batch 270, Loss: 1.1559
Batch 280, Loss: 1.1976
Batch 290, Loss: 1.1593
Batch 300, Loss: 1.2001
Batch 310, Loss: 1.2399
Batch 320, Loss: 1.2535
Batch 330, Loss: 1.2118
Batch 340, Loss: 1.1834
Batch 350, Loss: 1.2183
Batch 360, Loss: 1.2121
Batch 370, Loss: 1.1667
Batch 380, Loss: 1.2349
Batch 390, Loss: 1.2117
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.064476251602173 seconds
Epoch 91 accuracy: 62.16%
Batch 10, Loss: 1.1021
Batch 20, Loss: 1.1494
Batch 30, Loss: 1.0694
Batch 40, Loss: 1.1286
Batch 50, Loss: 1.0946
Batch 60, Loss: 1.1610
Batch 70, Loss: 1.1145
Batch 80, Loss: 1.1576
Batch 90, Loss: 1.1574
Batch 100, Loss: 1.1908
Batch 110, Loss: 1.1143
Batch 120, Loss: 1.1579
Batch 130, Loss: 1.1064
Batch 140, Loss: 1.1716
Batch 150, Loss: 1.0700
Batch 160, Loss: 1.1801
Batch 170, Loss: 1.1426
Batch 180, Loss: 1.2242
Batch 190, Loss: 1.1709
Batch 200, Loss: 1.2322
Batch 210, Loss: 1.0973
Batch 220, Loss: 1.1033
Batch 230, Loss: 1.1195
Batch 240, Loss: 1.2024
Batch 250, Loss: 1.1728
Batch 260, Loss: 1.2455
Batch 270, Loss: 1.2093
Batch 280, Loss: 1.2290
Batch 290, Loss: 1.1643
Batch 300, Loss: 1.1376
Batch 310, Loss: 1.1152
Batch 320, Loss: 1.0535
Batch 330, Loss: 1.1511
Batch 340, Loss: 1.1304
Batch 350, Loss: 1.1692
Batch 360, Loss: 1.1255
Batch 370, Loss: 1.1779
Batch 380, Loss: 1.1572
Batch 390, Loss: 1.1909
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.114337682724 seconds
Epoch 92 accuracy: 62.63%
Batch 10, Loss: 1.0966
Batch 20, Loss: 1.1036
Batch 30, Loss: 1.1041
Batch 40, Loss: 1.0965
Batch 50, Loss: 1.0685
Batch 60, Loss: 1.0738
Batch 70, Loss: 1.1313
Batch 80, Loss: 1.1797
Batch 90, Loss: 1.0744
Batch 100, Loss: 1.1256
Batch 110, Loss: 1.2099
Batch 120, Loss: 1.1315
Batch 130, Loss: 1.0926
Batch 140, Loss: 1.1006
Batch 150, Loss: 1.1934
Batch 160, Loss: 1.1023
Batch 170, Loss: 1.1305
Batch 180, Loss: 1.1909
Batch 190, Loss: 1.1534
Batch 200, Loss: 1.1275
Batch 210, Loss: 1.1514
Batch 220, Loss: 1.1147
Batch 230, Loss: 1.2155
Batch 240, Loss: 1.1635
Batch 250, Loss: 1.1892
Batch 260, Loss: 1.1686
Batch 270, Loss: 1.2329
Batch 280, Loss: 1.2070
Batch 290, Loss: 1.2428
Batch 300, Loss: 1.1711
Batch 310, Loss: 1.1603
Batch 320, Loss: 1.1538
Batch 330, Loss: 1.1940
Batch 340, Loss: 1.1737
Batch 350, Loss: 1.1622
Batch 360, Loss: 1.1387
Batch 370, Loss: 1.1596
Batch 380, Loss: 1.2218
Batch 390, Loss: 1.1721
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.020162105560303 seconds
Epoch 93 accuracy: 65.56%
Batch 10, Loss: 1.1048
Batch 20, Loss: 1.1245
Batch 30, Loss: 1.1303
Batch 40, Loss: 1.0992
Batch 50, Loss: 1.1798
Batch 60, Loss: 1.1751
Batch 70, Loss: 1.1656
Batch 80, Loss: 1.0836
Batch 90, Loss: 1.0832
Batch 100, Loss: 1.1124
Batch 110, Loss: 1.1420
Batch 120, Loss: 1.1464
Batch 130, Loss: 1.0696
Batch 140, Loss: 1.0780
Batch 150, Loss: 1.1329
Batch 160, Loss: 1.1416
Batch 170, Loss: 1.1121
Batch 180, Loss: 1.1229
Batch 190, Loss: 1.1384
Batch 200, Loss: 1.1348
Batch 210, Loss: 1.1635
Batch 220, Loss: 1.2006
Batch 230, Loss: 1.0985
Batch 240, Loss: 1.1798
Batch 250, Loss: 1.2352
Batch 260, Loss: 1.2126
Batch 270, Loss: 1.2036
Batch 280, Loss: 1.1407
Batch 290, Loss: 1.1870
Batch 300, Loss: 1.1723
Batch 310, Loss: 1.1550
Batch 320, Loss: 1.1857
Batch 330, Loss: 1.2127
Batch 340, Loss: 1.2442
Batch 350, Loss: 1.1872
Batch 360, Loss: 1.1669
Batch 370, Loss: 1.1177
Batch 380, Loss: 1.1495
Batch 390, Loss: 1.2133
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.01102375984192 seconds
Epoch 94 accuracy: 63.86%
Batch 10, Loss: 1.0895
Batch 20, Loss: 1.1049
Batch 30, Loss: 1.1357
Batch 40, Loss: 1.0567
Batch 50, Loss: 1.1037
Batch 60, Loss: 1.0975
Batch 70, Loss: 1.1108
Batch 80, Loss: 1.0858
Batch 90, Loss: 1.1368
Batch 100, Loss: 1.1229
Batch 110, Loss: 1.1257
Batch 120, Loss: 1.0910
Batch 130, Loss: 1.1297
Batch 140, Loss: 1.1541
Batch 150, Loss: 1.1213
Batch 160, Loss: 1.0640
Batch 170, Loss: 1.1034
Batch 180, Loss: 1.1437
Batch 190, Loss: 1.1289
Batch 200, Loss: 1.1786
Batch 210, Loss: 1.1002
Batch 220, Loss: 1.0663
Batch 230, Loss: 1.1085
Batch 240, Loss: 1.0542
Batch 250, Loss: 1.1352
Batch 260, Loss: 1.1699
Batch 270, Loss: 1.1824
Batch 280, Loss: 1.1299
Batch 290, Loss: 1.1214
Batch 300, Loss: 1.1021
Batch 310, Loss: 1.1218
Batch 320, Loss: 1.1356
Batch 330, Loss: 1.1246
Batch 340, Loss: 1.1811
Batch 350, Loss: 1.1956
Batch 360, Loss: 1.2011
Batch 370, Loss: 1.1604
Batch 380, Loss: 1.1543
Batch 390, Loss: 1.1495
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.062456846237183 seconds
Epoch 95 accuracy: 64.11%
Batch 10, Loss: 1.1603
Batch 20, Loss: 1.0515
Batch 30, Loss: 1.0802
Batch 40, Loss: 1.0524
Batch 50, Loss: 1.0654
Batch 60, Loss: 1.0283
Batch 70, Loss: 1.1013
Batch 80, Loss: 1.0635
Batch 90, Loss: 1.1120
Batch 100, Loss: 1.0869
Batch 110, Loss: 1.0258
Batch 120, Loss: 1.1097
Batch 130, Loss: 1.1072
Batch 140, Loss: 1.0217
Batch 150, Loss: 1.1322
Batch 160, Loss: 1.0764
Batch 170, Loss: 1.1329
Batch 180, Loss: 1.1028
Batch 190, Loss: 1.1858
Batch 200, Loss: 1.1478
Batch 210, Loss: 1.1293
Batch 220, Loss: 1.1401
Batch 230, Loss: 1.1955
Batch 240, Loss: 1.2342
Batch 250, Loss: 1.1454
Batch 260, Loss: 1.1660
Batch 270, Loss: 1.1065
Batch 280, Loss: 1.2106
Batch 290, Loss: 1.1644
Batch 300, Loss: 1.1991
Batch 310, Loss: 1.1080
Batch 320, Loss: 1.1607
Batch 330, Loss: 1.1352
Batch 340, Loss: 1.1818
Batch 350, Loss: 1.1208
Batch 360, Loss: 1.1373
Batch 370, Loss: 1.1625
Batch 380, Loss: 1.1510
Batch 390, Loss: 1.1011
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.128912448883057 seconds
Epoch 96 accuracy: 64.86%
Batch 10, Loss: 1.0422
Batch 20, Loss: 1.1069
Batch 30, Loss: 1.0379
Batch 40, Loss: 1.0536
Batch 50, Loss: 1.0710
Batch 60, Loss: 1.0755
Batch 70, Loss: 1.1061
Batch 80, Loss: 1.0883
Batch 90, Loss: 1.1559
Batch 100, Loss: 1.0957
Batch 110, Loss: 1.0883
Batch 120, Loss: 1.0518
Batch 130, Loss: 1.0669
Batch 140, Loss: 1.0978
Batch 150, Loss: 1.1502
Batch 160, Loss: 1.1596
Batch 170, Loss: 1.0675
Batch 180, Loss: 1.1164
Batch 190, Loss: 1.0933
Batch 200, Loss: 1.1181
Batch 210, Loss: 1.1966
Batch 220, Loss: 1.1593
Batch 230, Loss: 1.1423
Batch 240, Loss: 1.1225
Batch 250, Loss: 1.1282
Batch 260, Loss: 1.1320
Batch 270, Loss: 1.1147
Batch 280, Loss: 1.0855
Batch 290, Loss: 1.1678
Batch 300, Loss: 1.1263
Batch 310, Loss: 1.1117
Batch 320, Loss: 1.1198
Batch 330, Loss: 1.1913
Batch 340, Loss: 1.0868
Batch 350, Loss: 1.1034
Batch 360, Loss: 1.1063
Batch 370, Loss: 1.1987
Batch 380, Loss: 1.1583
Batch 390, Loss: 1.1603
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.039886951446533 seconds
Epoch 97 accuracy: 65.09%
Batch 10, Loss: 1.0875
Batch 20, Loss: 1.1189
Batch 30, Loss: 1.0354
Batch 40, Loss: 1.1194
Batch 50, Loss: 1.0674
Batch 60, Loss: 1.0540
Batch 70, Loss: 1.0748
Batch 80, Loss: 1.0651
Batch 90, Loss: 1.0558
Batch 100, Loss: 1.0098
Batch 110, Loss: 1.0603
Batch 120, Loss: 1.1002
Batch 130, Loss: 1.0413
Batch 140, Loss: 1.1160
Batch 150, Loss: 1.1040
Batch 160, Loss: 1.1464
Batch 170, Loss: 1.1487
Batch 180, Loss: 1.1175
Batch 190, Loss: 1.0962
Batch 200, Loss: 1.1475
Batch 210, Loss: 1.1534
Batch 220, Loss: 1.1129
Batch 230, Loss: 1.0937
Batch 240, Loss: 1.1674
Batch 250, Loss: 1.1315
Batch 260, Loss: 1.1948
Batch 270, Loss: 1.0950
Batch 280, Loss: 1.0967
Batch 290, Loss: 1.1587
Batch 300, Loss: 1.1095
Batch 310, Loss: 1.0658
Batch 320, Loss: 1.0766
Batch 330, Loss: 1.1694
Batch 340, Loss: 1.1533
Batch 350, Loss: 1.1061
Batch 360, Loss: 1.1102
Batch 370, Loss: 1.1343
Batch 380, Loss: 1.1405
Batch 390, Loss: 1.2252
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.09423828125 seconds
Epoch 98 accuracy: 64.95%
Batch 10, Loss: 1.1084
Batch 20, Loss: 1.0893
Batch 30, Loss: 1.0529
Batch 40, Loss: 1.0875
Batch 50, Loss: 1.0253
Batch 60, Loss: 1.1090
Batch 70, Loss: 1.1336
Batch 80, Loss: 1.0354
Batch 90, Loss: 1.0724
Batch 100, Loss: 1.0950
Batch 110, Loss: 1.0958
Batch 120, Loss: 1.0535
Batch 130, Loss: 1.1096
Batch 140, Loss: 1.0310
Batch 150, Loss: 1.0903
Batch 160, Loss: 1.1340
Batch 170, Loss: 1.1094
Batch 180, Loss: 1.1130
Batch 190, Loss: 1.0883
Batch 200, Loss: 1.0895
Batch 210, Loss: 1.1390
Batch 220, Loss: 1.0816
Batch 230, Loss: 1.1446
Batch 240, Loss: 1.1199
Batch 250, Loss: 1.1256
Batch 260, Loss: 1.0875
Batch 270, Loss: 1.1212
Batch 280, Loss: 1.1195
Batch 290, Loss: 1.1583
Batch 300, Loss: 1.1496
Batch 310, Loss: 1.0971
Batch 320, Loss: 1.1290
Batch 330, Loss: 1.1394
Batch 340, Loss: 1.1449
Batch 350, Loss: 1.1533
Batch 360, Loss: 1.1389
Batch 370, Loss: 1.1432
Batch 380, Loss: 1.0679
Batch 390, Loss: 1.0974
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.099584102630615 seconds
Epoch 99 accuracy: 64.92%
Batch 10, Loss: 1.1017
Batch 20, Loss: 1.0432
Batch 30, Loss: 1.0736
Batch 40, Loss: 1.0551
Batch 50, Loss: 1.0643
Batch 60, Loss: 1.0040
Batch 70, Loss: 1.0916
Batch 80, Loss: 1.0604
Batch 90, Loss: 1.0591
Batch 100, Loss: 1.1007
Batch 110, Loss: 1.0024
Batch 120, Loss: 1.0706
Batch 130, Loss: 1.0225
Batch 140, Loss: 1.0839
Batch 150, Loss: 1.0913
Batch 160, Loss: 1.0914
Batch 170, Loss: 1.1335
Batch 180, Loss: 1.0844
Batch 190, Loss: 1.1319
Batch 200, Loss: 1.1020
Batch 210, Loss: 1.0775
Batch 220, Loss: 1.0787
Batch 230, Loss: 1.0881
Batch 240, Loss: 1.1166
Batch 250, Loss: 1.1109
Batch 260, Loss: 1.0375
Batch 270, Loss: 1.0873
Batch 280, Loss: 1.0977
Batch 290, Loss: 1.1668
Batch 300, Loss: 1.1006
Batch 310, Loss: 1.2084
Batch 320, Loss: 1.1886
Batch 330, Loss: 1.1177
Batch 340, Loss: 1.0742
Batch 350, Loss: 1.1356
Batch 360, Loss: 1.2017
Batch 370, Loss: 1.1027
Batch 380, Loss: 1.1637
Batch 390, Loss: 1.1265
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 24.978619813919067 seconds
Epoch 100 accuracy: 64.61%
Batch 10, Loss: 1.0549
Batch 20, Loss: 1.0759
Batch 30, Loss: 1.1319
Batch 40, Loss: 1.0844
Batch 50, Loss: 1.0816
Batch 60, Loss: 0.9951
Batch 70, Loss: 0.9953
Batch 80, Loss: 1.1100
Batch 90, Loss: 1.0401
Batch 100, Loss: 1.1214
Batch 110, Loss: 1.0636
Batch 120, Loss: 1.0649
Batch 130, Loss: 1.0633
Batch 140, Loss: 1.0909
Batch 150, Loss: 1.0980
Batch 160, Loss: 1.0776
Batch 170, Loss: 1.0504
Batch 180, Loss: 1.0523
Batch 190, Loss: 1.1051
Batch 200, Loss: 1.1296
Batch 210, Loss: 1.0835
Batch 220, Loss: 1.0954
Batch 230, Loss: 1.0563
Batch 240, Loss: 1.0667
Batch 250, Loss: 1.1086
Batch 260, Loss: 1.1564
Batch 270, Loss: 1.1379
Batch 280, Loss: 1.1024
Batch 290, Loss: 1.0885
Batch 300, Loss: 1.1239
Batch 310, Loss: 1.1464
Batch 320, Loss: 1.1154
Batch 330, Loss: 1.1162
Batch 340, Loss: 1.1350
Batch 350, Loss: 1.0690
Batch 360, Loss: 1.0938
Batch 370, Loss: 1.1629
Batch 380, Loss: 1.1052
Batch 390, Loss: 1.0841
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.149133443832397 seconds
Epoch 101 accuracy: 63.38%
Batch 10, Loss: 1.0427
Batch 20, Loss: 1.0481
Batch 30, Loss: 1.0117
Batch 40, Loss: 1.0215
Batch 50, Loss: 1.0553
Batch 60, Loss: 1.0307
Batch 70, Loss: 1.0940
Batch 80, Loss: 1.0438
Batch 90, Loss: 1.0391
Batch 100, Loss: 1.1066
Batch 110, Loss: 1.1183
Batch 120, Loss: 1.0917
Batch 130, Loss: 1.0076
Batch 140, Loss: 1.0546
Batch 150, Loss: 1.1023
Batch 160, Loss: 1.0612
Batch 170, Loss: 1.0499
Batch 180, Loss: 1.1054
Batch 190, Loss: 1.0382
Batch 200, Loss: 1.0716
Batch 210, Loss: 1.0648
Batch 220, Loss: 1.1328
Batch 230, Loss: 1.0906
Batch 240, Loss: 1.0920
Batch 250, Loss: 1.0561
Batch 260, Loss: 1.1615
Batch 270, Loss: 1.1412
Batch 280, Loss: 1.1184
Batch 290, Loss: 1.1006
Batch 300, Loss: 1.0848
Batch 310, Loss: 1.0635
Batch 320, Loss: 1.1409
Batch 330, Loss: 1.1188
Batch 340, Loss: 1.1464
Batch 350, Loss: 1.0510
Batch 360, Loss: 1.1088
Batch 370, Loss: 1.1280
Batch 380, Loss: 1.1236
Batch 390, Loss: 1.1225
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.08589005470276 seconds
Epoch 102 accuracy: 64.27%
Batch 10, Loss: 1.0634
Batch 20, Loss: 1.0505
Batch 30, Loss: 0.9636
Batch 40, Loss: 1.0146
Batch 50, Loss: 0.9993
Batch 60, Loss: 1.0361
Batch 70, Loss: 1.0954
Batch 80, Loss: 1.0287
Batch 90, Loss: 1.0507
Batch 100, Loss: 1.0234
Batch 110, Loss: 1.0241
Batch 120, Loss: 1.0665
Batch 130, Loss: 1.0569
Batch 140, Loss: 1.0692
Batch 150, Loss: 0.9891
Batch 160, Loss: 1.0806
Batch 170, Loss: 1.0602
Batch 180, Loss: 1.0802
Batch 190, Loss: 1.1538
Batch 200, Loss: 1.0452
Batch 210, Loss: 1.1300
Batch 220, Loss: 1.0786
Batch 230, Loss: 1.0888
Batch 240, Loss: 1.0920
Batch 250, Loss: 1.0607
Batch 260, Loss: 1.0983
Batch 270, Loss: 1.0701
Batch 280, Loss: 1.1154
Batch 290, Loss: 1.0179
Batch 300, Loss: 1.0915
Batch 310, Loss: 1.1127
Batch 320, Loss: 1.1287
Batch 330, Loss: 1.0643
Batch 340, Loss: 1.0872
Batch 350, Loss: 1.0936
Batch 360, Loss: 1.1339
Batch 370, Loss: 1.0996
Batch 380, Loss: 1.0845
Batch 390, Loss: 1.1186
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.03024673461914 seconds
Epoch 103 accuracy: 65.06%
Batch 10, Loss: 0.9905
Batch 20, Loss: 0.9919
Batch 30, Loss: 1.0332
Batch 40, Loss: 1.0027
Batch 50, Loss: 1.0114
Batch 60, Loss: 1.0490
Batch 70, Loss: 0.9697
Batch 80, Loss: 1.0604
Batch 90, Loss: 1.0441
Batch 100, Loss: 1.0403
Batch 110, Loss: 1.0965
Batch 120, Loss: 1.0689
Batch 130, Loss: 1.1133
Batch 140, Loss: 1.0933
Batch 150, Loss: 1.0532
Batch 160, Loss: 1.0234
Batch 170, Loss: 1.0940
Batch 180, Loss: 1.0851
Batch 190, Loss: 1.1213
Batch 200, Loss: 1.0616
Batch 210, Loss: 1.1089
Batch 220, Loss: 1.0491
Batch 230, Loss: 1.0339
Batch 240, Loss: 1.0987
Batch 250, Loss: 1.1553
Batch 260, Loss: 1.0173
Batch 270, Loss: 1.1090
Batch 280, Loss: 1.1101
Batch 290, Loss: 1.0425
Batch 300, Loss: 1.1051
Batch 310, Loss: 1.0357
Batch 320, Loss: 1.0901
Batch 330, Loss: 1.0831
Batch 340, Loss: 1.0894
Batch 350, Loss: 1.0574
Batch 360, Loss: 1.0781
Batch 370, Loss: 1.0790
Batch 380, Loss: 1.0606
Batch 390, Loss: 1.0970
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.090930461883545 seconds
Epoch 104 accuracy: 66.72%
Batch 10, Loss: 0.9978
Batch 20, Loss: 0.9622
Batch 30, Loss: 0.9162
Batch 40, Loss: 1.0192
Batch 50, Loss: 1.0430
Batch 60, Loss: 0.9915
Batch 70, Loss: 1.0106
Batch 80, Loss: 1.0768
Batch 90, Loss: 1.0299
Batch 100, Loss: 1.0023
Batch 110, Loss: 1.0311
Batch 120, Loss: 1.0390
Batch 130, Loss: 1.0806
Batch 140, Loss: 1.0281
Batch 150, Loss: 1.0069
Batch 160, Loss: 1.0361
Batch 170, Loss: 1.1198
Batch 180, Loss: 1.0642
Batch 190, Loss: 1.0601
Batch 200, Loss: 1.0440
Batch 210, Loss: 1.0193
Batch 220, Loss: 1.1076
Batch 230, Loss: 1.0474
Batch 240, Loss: 1.0486
Batch 250, Loss: 1.0736
Batch 260, Loss: 1.0498
Batch 270, Loss: 1.0949
Batch 280, Loss: 1.0891
Batch 290, Loss: 1.0476
Batch 300, Loss: 1.0917
Batch 310, Loss: 1.0914
Batch 320, Loss: 1.0335
Batch 330, Loss: 1.0833
Batch 340, Loss: 1.0426
Batch 350, Loss: 1.0611
Batch 360, Loss: 1.0869
Batch 370, Loss: 1.1008
Batch 380, Loss: 1.0647
Batch 390, Loss: 1.0644
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.085934162139893 seconds
Epoch 105 accuracy: 66.06%
Batch 10, Loss: 1.0304
Batch 20, Loss: 0.9910
Batch 30, Loss: 0.9781
Batch 40, Loss: 0.9901
Batch 50, Loss: 1.0146
Batch 60, Loss: 1.0190
Batch 70, Loss: 1.0527
Batch 80, Loss: 1.0504
Batch 90, Loss: 1.0512
Batch 100, Loss: 1.0689
Batch 110, Loss: 1.0614
Batch 120, Loss: 1.0782
Batch 130, Loss: 1.0290
Batch 140, Loss: 1.0468
Batch 150, Loss: 1.0189
Batch 160, Loss: 1.0338
Batch 170, Loss: 1.0595
Batch 180, Loss: 1.0414
Batch 190, Loss: 1.0451
Batch 200, Loss: 1.0609
Batch 210, Loss: 1.0632
Batch 220, Loss: 1.0396
Batch 230, Loss: 1.0765
Batch 240, Loss: 1.1178
Batch 250, Loss: 1.1195
Batch 260, Loss: 1.0419
Batch 270, Loss: 1.0572
Batch 280, Loss: 1.0507
Batch 290, Loss: 1.0880
Batch 300, Loss: 1.0484
Batch 310, Loss: 1.0407
Batch 320, Loss: 1.0329
Batch 330, Loss: 1.0891
Batch 340, Loss: 1.0866
Batch 350, Loss: 1.1329
Batch 360, Loss: 1.0650
Batch 370, Loss: 1.1338
Batch 380, Loss: 1.0802
Batch 390, Loss: 1.0509
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.061708450317383 seconds
Epoch 106 accuracy: 68.37%
Batch 10, Loss: 0.9960
Batch 20, Loss: 0.9948
Batch 30, Loss: 0.9828
Batch 40, Loss: 1.0294
Batch 50, Loss: 1.0637
Batch 60, Loss: 1.0018
Batch 70, Loss: 0.9635
Batch 80, Loss: 0.9892
Batch 90, Loss: 0.9809
Batch 100, Loss: 0.9958
Batch 110, Loss: 1.0102
Batch 120, Loss: 1.0060
Batch 130, Loss: 1.0755
Batch 140, Loss: 1.0781
Batch 150, Loss: 1.0332
Batch 160, Loss: 1.0138
Batch 170, Loss: 0.9757
Batch 180, Loss: 1.0220
Batch 190, Loss: 1.0043
Batch 200, Loss: 1.0237
Batch 210, Loss: 0.9994
Batch 220, Loss: 1.0310
Batch 230, Loss: 1.0309
Batch 240, Loss: 1.0103
Batch 250, Loss: 1.0157
Batch 260, Loss: 1.1082
Batch 270, Loss: 1.0791
Batch 280, Loss: 1.1119
Batch 290, Loss: 0.9970
Batch 300, Loss: 1.0582
Batch 310, Loss: 1.0277
Batch 320, Loss: 0.9852
Batch 330, Loss: 1.0543
Batch 340, Loss: 1.1257
Batch 350, Loss: 1.0473
Batch 360, Loss: 1.1432
Batch 370, Loss: 1.0881
Batch 380, Loss: 1.0628
Batch 390, Loss: 1.0588
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.236498594284058 seconds
Epoch 107 accuracy: 66.11%
Batch 10, Loss: 1.0421
Batch 20, Loss: 1.0181
Batch 30, Loss: 0.9464
Batch 40, Loss: 0.9856
Batch 50, Loss: 1.0251
Batch 60, Loss: 1.0442
Batch 70, Loss: 1.0577
Batch 80, Loss: 1.0333
Batch 90, Loss: 1.0347
Batch 100, Loss: 1.0642
Batch 110, Loss: 0.9852
Batch 120, Loss: 1.0522
Batch 130, Loss: 0.9951
Batch 140, Loss: 0.9934
Batch 150, Loss: 1.0494
Batch 160, Loss: 0.9936
Batch 170, Loss: 1.0423
Batch 180, Loss: 1.0434
Batch 190, Loss: 1.0095
Batch 200, Loss: 1.0409
Batch 210, Loss: 1.0035
Batch 220, Loss: 1.0383
Batch 230, Loss: 1.0763
Batch 240, Loss: 1.0351
Batch 250, Loss: 1.0369
Batch 260, Loss: 1.0179
Batch 270, Loss: 1.0413
Batch 280, Loss: 1.0068
Batch 290, Loss: 1.0256
Batch 300, Loss: 1.0391
Batch 310, Loss: 1.1168
Batch 320, Loss: 0.9966
Batch 330, Loss: 1.0808
Batch 340, Loss: 1.0357
Batch 350, Loss: 0.9916
Batch 360, Loss: 1.0820
Batch 370, Loss: 1.0190
Batch 380, Loss: 1.0282
Batch 390, Loss: 1.0292
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.16895031929016 seconds
Epoch 108 accuracy: 66.59%
Batch 10, Loss: 0.9742
Batch 20, Loss: 0.9978
Batch 30, Loss: 1.0487
Batch 40, Loss: 0.9774
Batch 50, Loss: 1.0001
Batch 60, Loss: 1.0119
Batch 70, Loss: 1.0096
Batch 80, Loss: 0.9957
Batch 90, Loss: 1.0003
Batch 100, Loss: 1.0443
Batch 110, Loss: 1.0269
Batch 120, Loss: 0.9909
Batch 130, Loss: 0.9575
Batch 140, Loss: 0.9857
Batch 150, Loss: 0.9904
Batch 160, Loss: 0.9945
Batch 170, Loss: 1.0345
Batch 180, Loss: 0.9931
Batch 190, Loss: 1.0140
Batch 200, Loss: 1.0535
Batch 210, Loss: 1.0528
Batch 220, Loss: 0.9927
Batch 230, Loss: 1.0641
Batch 240, Loss: 0.9415
Batch 250, Loss: 1.0395
Batch 260, Loss: 1.0066
Batch 270, Loss: 1.0273
Batch 280, Loss: 1.0166
Batch 290, Loss: 1.0885
Batch 300, Loss: 1.0608
Batch 310, Loss: 1.0349
Batch 320, Loss: 1.0241
Batch 330, Loss: 1.0147
Batch 340, Loss: 1.0157
Batch 350, Loss: 1.0689
Batch 360, Loss: 1.0388
Batch 370, Loss: 1.0849
Batch 380, Loss: 1.0549
Batch 390, Loss: 1.0754
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.060662269592285 seconds
Epoch 109 accuracy: 66.8%
Batch 10, Loss: 0.9534
Batch 20, Loss: 0.8870
Batch 30, Loss: 0.9359
Batch 40, Loss: 0.8748
Batch 50, Loss: 0.9787
Batch 60, Loss: 0.9638
Batch 70, Loss: 1.0007
Batch 80, Loss: 1.0127
Batch 90, Loss: 1.0150
Batch 100, Loss: 1.0032
Batch 110, Loss: 0.9964
Batch 120, Loss: 1.0351
Batch 130, Loss: 1.0417
Batch 140, Loss: 1.0183
Batch 150, Loss: 1.0216
Batch 160, Loss: 0.9603
Batch 170, Loss: 1.0150
Batch 180, Loss: 1.0240
Batch 190, Loss: 1.0200
Batch 200, Loss: 1.0400
Batch 210, Loss: 1.0165
Batch 220, Loss: 0.9668
Batch 230, Loss: 0.9824
Batch 240, Loss: 1.0468
Batch 250, Loss: 1.0055
Batch 260, Loss: 1.0222
Batch 270, Loss: 1.0110
Batch 280, Loss: 1.0943
Batch 290, Loss: 1.0898
Batch 300, Loss: 1.0731
Batch 310, Loss: 1.0582
Batch 320, Loss: 1.0758
Batch 330, Loss: 1.0464
Batch 340, Loss: 1.0473
Batch 350, Loss: 1.0580
Batch 360, Loss: 1.0733
Batch 370, Loss: 1.0953
Batch 380, Loss: 1.0324
Batch 390, Loss: 1.0457
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.047850370407104 seconds
Epoch 110 accuracy: 66.01%
Batch 10, Loss: 0.9619
Batch 20, Loss: 0.9737
Batch 30, Loss: 0.9869
Batch 40, Loss: 0.9015
Batch 50, Loss: 1.0079
Batch 60, Loss: 0.9885
Batch 70, Loss: 0.9240
Batch 80, Loss: 1.0243
Batch 90, Loss: 0.9940
Batch 100, Loss: 0.9827
Batch 110, Loss: 0.9894
Batch 120, Loss: 1.0052
Batch 130, Loss: 0.9884
Batch 140, Loss: 1.0321
Batch 150, Loss: 1.0724
Batch 160, Loss: 1.0266
Batch 170, Loss: 1.0126
Batch 180, Loss: 1.0326
Batch 190, Loss: 1.0008
Batch 200, Loss: 1.0241
Batch 210, Loss: 0.9854
Batch 220, Loss: 0.9906
Batch 230, Loss: 1.0513
Batch 240, Loss: 1.0295
Batch 250, Loss: 1.0091
Batch 260, Loss: 0.9572
Batch 270, Loss: 1.0234
Batch 280, Loss: 1.0322
Batch 290, Loss: 1.0082
Batch 300, Loss: 0.9885
Batch 310, Loss: 1.0459
Batch 320, Loss: 1.0513
Batch 330, Loss: 1.0094
Batch 340, Loss: 0.9813
Batch 350, Loss: 1.0684
Batch 360, Loss: 1.0584
Batch 370, Loss: 1.0538
Batch 380, Loss: 1.0545
Batch 390, Loss: 1.0530
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.079407691955566 seconds
Epoch 111 accuracy: 67.72%
Batch 10, Loss: 1.0068
Batch 20, Loss: 0.9635
Batch 30, Loss: 0.9501
Batch 40, Loss: 0.9928
Batch 50, Loss: 0.9244
Batch 60, Loss: 0.9971
Batch 70, Loss: 0.9795
Batch 80, Loss: 0.9662
Batch 90, Loss: 0.9111
Batch 100, Loss: 0.9719
Batch 110, Loss: 0.9358
Batch 120, Loss: 0.9814
Batch 130, Loss: 0.9933
Batch 140, Loss: 0.9479
Batch 150, Loss: 1.0038
Batch 160, Loss: 0.9603
Batch 170, Loss: 1.0266
Batch 180, Loss: 1.0604
Batch 190, Loss: 1.0428
Batch 200, Loss: 1.0174
Batch 210, Loss: 1.0339
Batch 220, Loss: 0.9995
Batch 230, Loss: 0.9954
Batch 240, Loss: 0.9861
Batch 250, Loss: 1.0466
Batch 260, Loss: 1.0371
Batch 270, Loss: 1.0310
Batch 280, Loss: 1.0023
Batch 290, Loss: 0.9484
Batch 300, Loss: 1.0374
Batch 310, Loss: 1.0130
Batch 320, Loss: 1.0787
Batch 330, Loss: 1.0703
Batch 340, Loss: 1.0797
Batch 350, Loss: 0.9647
Batch 360, Loss: 1.1078
Batch 370, Loss: 1.0585
Batch 380, Loss: 1.0517
Batch 390, Loss: 1.0583
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.09206223487854 seconds
Epoch 112 accuracy: 68.51%
Batch 10, Loss: 0.9499
Batch 20, Loss: 0.9990
Batch 30, Loss: 0.9281
Batch 40, Loss: 0.9748
Batch 50, Loss: 0.9171
Batch 60, Loss: 0.9432
Batch 70, Loss: 0.9298
Batch 80, Loss: 0.9410
Batch 90, Loss: 0.9346
Batch 100, Loss: 0.9598
Batch 110, Loss: 0.9690
Batch 120, Loss: 0.9650
Batch 130, Loss: 0.9781
Batch 140, Loss: 0.9708
Batch 150, Loss: 0.9833
Batch 160, Loss: 0.9782
Batch 170, Loss: 0.9635
Batch 180, Loss: 0.9748
Batch 190, Loss: 0.9943
Batch 200, Loss: 0.9755
Batch 210, Loss: 0.9550
Batch 220, Loss: 0.9497
Batch 230, Loss: 1.0088
Batch 240, Loss: 1.0629
Batch 250, Loss: 0.9515
Batch 260, Loss: 0.9431
Batch 270, Loss: 1.0453
Batch 280, Loss: 1.0018
Batch 290, Loss: 1.0627
Batch 300, Loss: 0.9877
Batch 310, Loss: 1.0240
Batch 320, Loss: 1.0695
Batch 330, Loss: 0.9675
Batch 340, Loss: 0.9566
Batch 350, Loss: 1.0189
Batch 360, Loss: 1.0160
Batch 370, Loss: 1.0170
Batch 380, Loss: 0.9444
Batch 390, Loss: 1.0610
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.13447141647339 seconds
Epoch 113 accuracy: 67.8%
Batch 10, Loss: 0.9399
Batch 20, Loss: 0.9626
Batch 30, Loss: 0.9436
Batch 40, Loss: 0.9387
Batch 50, Loss: 0.8809
Batch 60, Loss: 0.9048
Batch 70, Loss: 0.9754
Batch 80, Loss: 0.9722
Batch 90, Loss: 0.9208
Batch 100, Loss: 0.9240
Batch 110, Loss: 1.0031
Batch 120, Loss: 0.9585
Batch 130, Loss: 0.9392
Batch 140, Loss: 1.0151
Batch 150, Loss: 0.9933
Batch 160, Loss: 1.0177
Batch 170, Loss: 0.9866
Batch 180, Loss: 0.9718
Batch 190, Loss: 0.9441
Batch 200, Loss: 1.0394
Batch 210, Loss: 0.9633
Batch 220, Loss: 0.9972
Batch 230, Loss: 0.9971
Batch 240, Loss: 1.0056
Batch 250, Loss: 1.0361
Batch 260, Loss: 0.9536
Batch 270, Loss: 0.9840
Batch 280, Loss: 1.0108
Batch 290, Loss: 1.0008
Batch 300, Loss: 1.0273
Batch 310, Loss: 0.9758
Batch 320, Loss: 1.0181
Batch 330, Loss: 1.0399
Batch 340, Loss: 1.0173
Batch 350, Loss: 1.0143
Batch 360, Loss: 0.9982
Batch 370, Loss: 0.9729
Batch 380, Loss: 1.0651
Batch 390, Loss: 1.0270
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.011706829071045 seconds
Epoch 114 accuracy: 67.49%
Batch 10, Loss: 0.9432
Batch 20, Loss: 0.9495
Batch 30, Loss: 0.8836
Batch 40, Loss: 0.9314
Batch 50, Loss: 0.9051
Batch 60, Loss: 0.9375
Batch 70, Loss: 0.9442
Batch 80, Loss: 0.9216
Batch 90, Loss: 1.0120
Batch 100, Loss: 0.9951
Batch 110, Loss: 0.9730
Batch 120, Loss: 0.9589
Batch 130, Loss: 0.9657
Batch 140, Loss: 1.0106
Batch 150, Loss: 1.0140
Batch 160, Loss: 0.9735
Batch 170, Loss: 0.9400
Batch 180, Loss: 0.9284
Batch 190, Loss: 0.9613
Batch 200, Loss: 0.9214
Batch 210, Loss: 1.0130
Batch 220, Loss: 0.9565
Batch 230, Loss: 0.9523
Batch 240, Loss: 1.0321
Batch 250, Loss: 1.0312
Batch 260, Loss: 1.0206
Batch 270, Loss: 0.9440
Batch 280, Loss: 0.9940
Batch 290, Loss: 0.9932
Batch 300, Loss: 0.9693
Batch 310, Loss: 0.9653
Batch 320, Loss: 1.0021
Batch 330, Loss: 0.9737
Batch 340, Loss: 1.0383
Batch 350, Loss: 1.0283
Batch 360, Loss: 1.0210
Batch 370, Loss: 0.9681
Batch 380, Loss: 1.0095
Batch 390, Loss: 0.9944
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.020378828048706 seconds
Epoch 115 accuracy: 66.98%
Batch 10, Loss: 0.8946
Batch 20, Loss: 0.9226
Batch 30, Loss: 0.9070
Batch 40, Loss: 0.9352
Batch 50, Loss: 0.9390
Batch 60, Loss: 0.9003
Batch 70, Loss: 0.9203
Batch 80, Loss: 0.9214
Batch 90, Loss: 0.8759
Batch 100, Loss: 0.9287
Batch 110, Loss: 0.9476
Batch 120, Loss: 0.9472
Batch 130, Loss: 0.9056
Batch 140, Loss: 0.9490
Batch 150, Loss: 0.9367
Batch 160, Loss: 0.9410
Batch 170, Loss: 0.9081
Batch 180, Loss: 0.9405
Batch 190, Loss: 0.9767
Batch 200, Loss: 0.9789
Batch 210, Loss: 0.9632
Batch 220, Loss: 0.9284
Batch 230, Loss: 0.9937
Batch 240, Loss: 0.9810
Batch 250, Loss: 0.9792
Batch 260, Loss: 1.0105
Batch 270, Loss: 1.0013
Batch 280, Loss: 0.9602
Batch 290, Loss: 0.9787
Batch 300, Loss: 0.9529
Batch 310, Loss: 0.9645
Batch 320, Loss: 0.9357
Batch 330, Loss: 0.9353
Batch 340, Loss: 1.0123
Batch 350, Loss: 0.9754
Batch 360, Loss: 0.9945
Batch 370, Loss: 0.9823
Batch 380, Loss: 1.0107
Batch 390, Loss: 0.9519
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.088388919830322 seconds
Epoch 116 accuracy: 64.46%
Batch 10, Loss: 0.8692
Batch 20, Loss: 0.9394
Batch 30, Loss: 0.9124
Batch 40, Loss: 0.9184
Batch 50, Loss: 0.9471
Batch 60, Loss: 0.9103
Batch 70, Loss: 0.8960
Batch 80, Loss: 0.8973
Batch 90, Loss: 0.9360
Batch 100, Loss: 0.9060
Batch 110, Loss: 0.9159
Batch 120, Loss: 0.9331
Batch 130, Loss: 0.9519
Batch 140, Loss: 0.9999
Batch 150, Loss: 0.9576
Batch 160, Loss: 0.9554
Batch 170, Loss: 0.9603
Batch 180, Loss: 0.9441
Batch 190, Loss: 0.9551
Batch 200, Loss: 0.9661
Batch 210, Loss: 0.9310
Batch 220, Loss: 0.9940
Batch 230, Loss: 0.8336
Batch 240, Loss: 0.9313
Batch 250, Loss: 0.9290
Batch 260, Loss: 0.9733
Batch 270, Loss: 0.9696
Batch 280, Loss: 1.0110
Batch 290, Loss: 0.9739
Batch 300, Loss: 1.0096
Batch 310, Loss: 0.9833
Batch 320, Loss: 0.9511
Batch 330, Loss: 0.9677
Batch 340, Loss: 0.9574
Batch 350, Loss: 0.9977
Batch 360, Loss: 0.9660
Batch 370, Loss: 0.9709
Batch 380, Loss: 1.0517
Batch 390, Loss: 1.0090
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.20742440223694 seconds
Epoch 117 accuracy: 68.97%
Batch 10, Loss: 0.9523
Batch 20, Loss: 0.9220
Batch 30, Loss: 0.9035
Batch 40, Loss: 0.8703
Batch 50, Loss: 0.9311
Batch 60, Loss: 0.9087
Batch 70, Loss: 0.9506
Batch 80, Loss: 0.9070
Batch 90, Loss: 0.8983
Batch 100, Loss: 0.9483
Batch 110, Loss: 0.8968
Batch 120, Loss: 0.9650
Batch 130, Loss: 0.9476
Batch 140, Loss: 0.9229
Batch 150, Loss: 0.9176
Batch 160, Loss: 0.9698
Batch 170, Loss: 0.9373
Batch 180, Loss: 0.9671
Batch 190, Loss: 0.9792
Batch 200, Loss: 0.9702
Batch 210, Loss: 0.9700
Batch 220, Loss: 0.9409
Batch 230, Loss: 0.9798
Batch 240, Loss: 0.9090
Batch 250, Loss: 0.9676
Batch 260, Loss: 0.9572
Batch 270, Loss: 0.9268
Batch 280, Loss: 0.9899
Batch 290, Loss: 1.0225
Batch 300, Loss: 0.9401
Batch 310, Loss: 0.9592
Batch 320, Loss: 0.9647
Batch 330, Loss: 0.9814
Batch 340, Loss: 0.9854
Batch 350, Loss: 0.9815
Batch 360, Loss: 0.9617
Batch 370, Loss: 0.9413
Batch 380, Loss: 0.9547
Batch 390, Loss: 1.0253
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.06523060798645 seconds
Epoch 118 accuracy: 68.27%
Batch 10, Loss: 0.9176
Batch 20, Loss: 0.9371
Batch 30, Loss: 0.8987
Batch 40, Loss: 0.9088
Batch 50, Loss: 0.9209
Batch 60, Loss: 0.8337
Batch 70, Loss: 0.9006
Batch 80, Loss: 0.9286
Batch 90, Loss: 0.8807
Batch 100, Loss: 0.9156
Batch 110, Loss: 0.9319
Batch 120, Loss: 0.9145
Batch 130, Loss: 0.9631
Batch 140, Loss: 0.8750
Batch 150, Loss: 0.9224
Batch 160, Loss: 0.9043
Batch 170, Loss: 0.9183
Batch 180, Loss: 0.8419
Batch 190, Loss: 0.9074
Batch 200, Loss: 0.9066
Batch 210, Loss: 0.9602
Batch 220, Loss: 0.9244
Batch 230, Loss: 0.9506
Batch 240, Loss: 0.9601
Batch 250, Loss: 0.9491
Batch 260, Loss: 0.8780
Batch 270, Loss: 0.9689
Batch 280, Loss: 0.9012
Batch 290, Loss: 0.9756
Batch 300, Loss: 0.9561
Batch 310, Loss: 0.9090
Batch 320, Loss: 0.9570
Batch 330, Loss: 0.9663
Batch 340, Loss: 0.8943
Batch 350, Loss: 0.9173
Batch 360, Loss: 0.9699
Batch 370, Loss: 1.0252
Batch 380, Loss: 0.9752
Batch 390, Loss: 0.9900
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.162474393844604 seconds
Epoch 119 accuracy: 67.8%
Batch 10, Loss: 0.8366
Batch 20, Loss: 0.8927
Batch 30, Loss: 0.8672
Batch 40, Loss: 0.8780
Batch 50, Loss: 0.9024
Batch 60, Loss: 0.8783
Batch 70, Loss: 0.8859
Batch 80, Loss: 0.9290
Batch 90, Loss: 0.8419
Batch 100, Loss: 0.9360
Batch 110, Loss: 0.9280
Batch 120, Loss: 0.8820
Batch 130, Loss: 0.9508
Batch 140, Loss: 0.9083
Batch 150, Loss: 0.9215
Batch 160, Loss: 0.9321
Batch 170, Loss: 0.9101
Batch 180, Loss: 0.9948
Batch 190, Loss: 0.9587
Batch 200, Loss: 0.9514
Batch 210, Loss: 0.9668
Batch 220, Loss: 0.9315
Batch 230, Loss: 0.8895
Batch 240, Loss: 0.9259
Batch 250, Loss: 0.9580
Batch 260, Loss: 0.8672
Batch 270, Loss: 0.9684
Batch 280, Loss: 1.0202
Batch 290, Loss: 0.9469
Batch 300, Loss: 0.9576
Batch 310, Loss: 0.9726
Batch 320, Loss: 0.9547
Batch 330, Loss: 0.9385
Batch 340, Loss: 0.9538
Batch 350, Loss: 0.9170
Batch 360, Loss: 0.9208
Batch 370, Loss: 1.0034
Batch 380, Loss: 0.9439
Batch 390, Loss: 0.8481
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.00938081741333 seconds
Epoch 120 accuracy: 69.56%
Batch 10, Loss: 0.8724
Batch 20, Loss: 0.9339
Batch 30, Loss: 0.8485
Batch 40, Loss: 0.8871
Batch 50, Loss: 0.8754
Batch 60, Loss: 0.8806
Batch 70, Loss: 0.8986
Batch 80, Loss: 0.8608
Batch 90, Loss: 0.8831
Batch 100, Loss: 0.9473
Batch 110, Loss: 0.9058
Batch 120, Loss: 0.8974
Batch 130, Loss: 0.8921
Batch 140, Loss: 0.9153
Batch 150, Loss: 0.9567
Batch 160, Loss: 0.9136
Batch 170, Loss: 0.8762
Batch 180, Loss: 0.8764
Batch 190, Loss: 0.8579
Batch 200, Loss: 0.8492
Batch 210, Loss: 0.8951
Batch 220, Loss: 0.8896
Batch 230, Loss: 0.8662
Batch 240, Loss: 0.9110
Batch 250, Loss: 0.9188
Batch 260, Loss: 0.9399
Batch 270, Loss: 0.8926
Batch 280, Loss: 0.9736
Batch 290, Loss: 0.9725
Batch 300, Loss: 0.9348
Batch 310, Loss: 0.9071
Batch 320, Loss: 0.9198
Batch 330, Loss: 0.9228
Batch 340, Loss: 0.9469
Batch 350, Loss: 0.9669
Batch 360, Loss: 0.9969
Batch 370, Loss: 0.9460
Batch 380, Loss: 0.9510
Batch 390, Loss: 0.9957
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.109020709991455 seconds
Epoch 121 accuracy: 69.27%
Batch 10, Loss: 0.8994
Batch 20, Loss: 0.8562
Batch 30, Loss: 0.8893
Batch 40, Loss: 0.8252
Batch 50, Loss: 0.8863
Batch 60, Loss: 0.9085
Batch 70, Loss: 0.8645
Batch 80, Loss: 0.9393
Batch 90, Loss: 0.8407
Batch 100, Loss: 0.8700
Batch 110, Loss: 0.9063
Batch 120, Loss: 0.8852
Batch 130, Loss: 0.8419
Batch 140, Loss: 0.8816
Batch 150, Loss: 0.8984
Batch 160, Loss: 0.8994
Batch 170, Loss: 0.8591
Batch 180, Loss: 0.8862
Batch 190, Loss: 0.8490
Batch 200, Loss: 0.8750
Batch 210, Loss: 0.8904
Batch 220, Loss: 0.8789
Batch 230, Loss: 0.9823
Batch 240, Loss: 0.9048
Batch 250, Loss: 1.0230
Batch 260, Loss: 0.9672
Batch 270, Loss: 0.9036
Batch 280, Loss: 0.8933
Batch 290, Loss: 0.9336
Batch 300, Loss: 0.8812
Batch 310, Loss: 0.8909
Batch 320, Loss: 0.9061
Batch 330, Loss: 0.8896
Batch 340, Loss: 0.9554
Batch 350, Loss: 0.9133
Batch 360, Loss: 0.9508
Batch 370, Loss: 0.9747
Batch 380, Loss: 0.9551
Batch 390, Loss: 0.9649
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 24.992934226989746 seconds
Epoch 122 accuracy: 68.8%
Batch 10, Loss: 0.9046
Batch 20, Loss: 0.8825
Batch 30, Loss: 0.8549
Batch 40, Loss: 0.8150
Batch 50, Loss: 0.8650
Batch 60, Loss: 0.8787
Batch 70, Loss: 0.9095
Batch 80, Loss: 0.8966
Batch 90, Loss: 0.9137
Batch 100, Loss: 0.9479
Batch 110, Loss: 0.9270
Batch 120, Loss: 0.8883
Batch 130, Loss: 0.8860
Batch 140, Loss: 0.8334
Batch 150, Loss: 0.8553
Batch 160, Loss: 0.8601
Batch 170, Loss: 0.9245
Batch 180, Loss: 0.8587
Batch 190, Loss: 0.9413
Batch 200, Loss: 0.8948
Batch 210, Loss: 0.8681
Batch 220, Loss: 0.9255
Batch 230, Loss: 0.9574
Batch 240, Loss: 0.8176
Batch 250, Loss: 0.8430
Batch 260, Loss: 0.8684
Batch 270, Loss: 0.8621
Batch 280, Loss: 0.8661
Batch 290, Loss: 0.9208
Batch 300, Loss: 0.8948
Batch 310, Loss: 0.9409
Batch 320, Loss: 0.8836
Batch 330, Loss: 0.9119
Batch 340, Loss: 0.9185
Batch 350, Loss: 0.9259
Batch 360, Loss: 0.9201
Batch 370, Loss: 0.8930
Batch 380, Loss: 0.9069
Batch 390, Loss: 0.8970
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.0600163936615 seconds
Epoch 123 accuracy: 69.23%
Batch 10, Loss: 0.9150
Batch 20, Loss: 0.8131
Batch 30, Loss: 0.8394
Batch 40, Loss: 0.8487
Batch 50, Loss: 0.8361
Batch 60, Loss: 0.8664
Batch 70, Loss: 0.8443
Batch 80, Loss: 0.8710
Batch 90, Loss: 0.8863
Batch 100, Loss: 0.8688
Batch 110, Loss: 0.8744
Batch 120, Loss: 0.8656
Batch 130, Loss: 0.8843
Batch 140, Loss: 0.9083
Batch 150, Loss: 0.8877
Batch 160, Loss: 0.8335
Batch 170, Loss: 0.8708
Batch 180, Loss: 0.9008
Batch 190, Loss: 0.8527
Batch 200, Loss: 0.8928
Batch 210, Loss: 0.8866
Batch 220, Loss: 0.9028
Batch 230, Loss: 0.9148
Batch 240, Loss: 0.9026
Batch 250, Loss: 0.8969
Batch 260, Loss: 0.9227
Batch 270, Loss: 0.9274
Batch 280, Loss: 0.9274
Batch 290, Loss: 0.8808
Batch 300, Loss: 0.8824
Batch 310, Loss: 0.8890
Batch 320, Loss: 0.8864
Batch 330, Loss: 0.8902
Batch 340, Loss: 0.8953
Batch 350, Loss: 0.8861
Batch 360, Loss: 0.8904
Batch 370, Loss: 0.9059
Batch 380, Loss: 0.8850
Batch 390, Loss: 0.8769
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.045166730880737 seconds
Epoch 124 accuracy: 68.68%
Batch 10, Loss: 0.8081
Batch 20, Loss: 0.8774
Batch 30, Loss: 0.8316
Batch 40, Loss: 0.8394
Batch 50, Loss: 0.8202
Batch 60, Loss: 0.8347
Batch 70, Loss: 0.8095
Batch 80, Loss: 0.8415
Batch 90, Loss: 0.8656
Batch 100, Loss: 0.8854
Batch 110, Loss: 0.9280
Batch 120, Loss: 0.8209
Batch 130, Loss: 0.8553
Batch 140, Loss: 0.9335
Batch 150, Loss: 0.8653
Batch 160, Loss: 0.8585
Batch 170, Loss: 0.8310
Batch 180, Loss: 0.8357
Batch 190, Loss: 0.8084
Batch 200, Loss: 0.8910
Batch 210, Loss: 0.8582
Batch 220, Loss: 0.8285
Batch 230, Loss: 0.8916
Batch 240, Loss: 0.9247
Batch 250, Loss: 0.9405
Batch 260, Loss: 0.8901
Batch 270, Loss: 0.9250
Batch 280, Loss: 0.8653
Batch 290, Loss: 0.8986
Batch 300, Loss: 0.8899
Batch 310, Loss: 0.9006
Batch 320, Loss: 0.9128
Batch 330, Loss: 0.9043
Batch 340, Loss: 0.9345
Batch 350, Loss: 0.8876
Batch 360, Loss: 0.8901
Batch 370, Loss: 0.9495
Batch 380, Loss: 0.9123
Batch 390, Loss: 0.9236
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.05671763420105 seconds
Epoch 125 accuracy: 70.29%
Batch 10, Loss: 0.8010
Batch 20, Loss: 0.8600
Batch 30, Loss: 0.8055
Batch 40, Loss: 0.8625
Batch 50, Loss: 0.8325
Batch 60, Loss: 0.7796
Batch 70, Loss: 0.7820
Batch 80, Loss: 0.8284
Batch 90, Loss: 0.8674
Batch 100, Loss: 0.8361
Batch 110, Loss: 0.8677
Batch 120, Loss: 0.8867
Batch 130, Loss: 0.8068
Batch 140, Loss: 0.8169
Batch 150, Loss: 0.8615
Batch 160, Loss: 0.8561
Batch 170, Loss: 0.8969
Batch 180, Loss: 0.8333
Batch 190, Loss: 0.8243
Batch 200, Loss: 0.9090
Batch 210, Loss: 0.8650
Batch 220, Loss: 0.8618
Batch 230, Loss: 0.9019
Batch 240, Loss: 0.8247
Batch 250, Loss: 0.8838
Batch 260, Loss: 0.9151
Batch 270, Loss: 0.9075
Batch 280, Loss: 0.9756
Batch 290, Loss: 0.9122
Batch 300, Loss: 0.9033
Batch 310, Loss: 0.8953
Batch 320, Loss: 0.9181
Batch 330, Loss: 0.8733
Batch 340, Loss: 0.8564
Batch 350, Loss: 0.8381
Batch 360, Loss: 0.9470
Batch 370, Loss: 0.8662
Batch 380, Loss: 0.8804
Batch 390, Loss: 0.9140
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.129918336868286 seconds
Epoch 126 accuracy: 71.13%
Batch 10, Loss: 0.8494
Batch 20, Loss: 0.7798
Batch 30, Loss: 0.8800
Batch 40, Loss: 0.8591
Batch 50, Loss: 0.8708
Batch 60, Loss: 0.8672
Batch 70, Loss: 0.8417
Batch 80, Loss: 0.8670
Batch 90, Loss: 0.8185
Batch 100, Loss: 0.8129
Batch 110, Loss: 0.7915
Batch 120, Loss: 0.8268
Batch 130, Loss: 0.8574
Batch 140, Loss: 0.8158
Batch 150, Loss: 0.8763
Batch 160, Loss: 0.8087
Batch 170, Loss: 0.8503
Batch 180, Loss: 0.8418
Batch 190, Loss: 0.8562
Batch 200, Loss: 0.8434
Batch 210, Loss: 0.8510
Batch 220, Loss: 0.8870
Batch 230, Loss: 0.8208
Batch 240, Loss: 0.8541
Batch 250, Loss: 0.8958
Batch 260, Loss: 0.8286
Batch 270, Loss: 0.8646
Batch 280, Loss: 0.8918
Batch 290, Loss: 0.9055
Batch 300, Loss: 0.8185
Batch 310, Loss: 0.8817
Batch 320, Loss: 0.8880
Batch 330, Loss: 0.8789
Batch 340, Loss: 0.8410
Batch 350, Loss: 0.8841
Batch 360, Loss: 0.8824
Batch 370, Loss: 0.8243
Batch 380, Loss: 0.8845
Batch 390, Loss: 0.8990
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.108893632888794 seconds
Epoch 127 accuracy: 70.59%
Batch 10, Loss: 0.8097
Batch 20, Loss: 0.8211
Batch 30, Loss: 0.7734
Batch 40, Loss: 0.7804
Batch 50, Loss: 0.7865
Batch 60, Loss: 0.8422
Batch 70, Loss: 0.8303
Batch 80, Loss: 0.7829
Batch 90, Loss: 0.8519
Batch 100, Loss: 0.8162
Batch 110, Loss: 0.8339
Batch 120, Loss: 0.8576
Batch 130, Loss: 0.7994
Batch 140, Loss: 0.8227
Batch 150, Loss: 0.8662
Batch 160, Loss: 0.8283
Batch 170, Loss: 0.8195
Batch 180, Loss: 0.8622
Batch 190, Loss: 0.8732
Batch 200, Loss: 0.8079
Batch 210, Loss: 0.8065
Batch 220, Loss: 0.8624
Batch 230, Loss: 0.8733
Batch 240, Loss: 0.8515
Batch 250, Loss: 0.8383
Batch 260, Loss: 0.8364
Batch 270, Loss: 0.8471
Batch 280, Loss: 0.8298
Batch 290, Loss: 0.8771
Batch 300, Loss: 0.8796
Batch 310, Loss: 0.8765
Batch 320, Loss: 0.8598
Batch 330, Loss: 0.8058
Batch 340, Loss: 0.8210
Batch 350, Loss: 0.8376
Batch 360, Loss: 0.8776
Batch 370, Loss: 0.8949
Batch 380, Loss: 0.8628
Batch 390, Loss: 0.9179
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.041417121887207 seconds
Epoch 128 accuracy: 69.72%
Batch 10, Loss: 0.7782
Batch 20, Loss: 0.8616
Batch 30, Loss: 0.8310
Batch 40, Loss: 0.8182
Batch 50, Loss: 0.7510
Batch 60, Loss: 0.7802
Batch 70, Loss: 0.7799
Batch 80, Loss: 0.7767
Batch 90, Loss: 0.8135
Batch 100, Loss: 0.7735
Batch 110, Loss: 0.7755
Batch 120, Loss: 0.8788
Batch 130, Loss: 0.8728
Batch 140, Loss: 0.8245
Batch 150, Loss: 0.7895
Batch 160, Loss: 0.8387
Batch 170, Loss: 0.8467
Batch 180, Loss: 0.7811
Batch 190, Loss: 0.8490
Batch 200, Loss: 0.8958
Batch 210, Loss: 0.8370
Batch 220, Loss: 0.8262
Batch 230, Loss: 0.8438
Batch 240, Loss: 0.8137
Batch 250, Loss: 0.8025
Batch 260, Loss: 0.8567
Batch 270, Loss: 0.7999
Batch 280, Loss: 0.8774
Batch 290, Loss: 0.8373
Batch 300, Loss: 0.8625
Batch 310, Loss: 0.8442
Batch 320, Loss: 0.8686
Batch 330, Loss: 0.8787
Batch 340, Loss: 0.8649
Batch 350, Loss: 0.8685
Batch 360, Loss: 0.8258
Batch 370, Loss: 0.8679
Batch 380, Loss: 0.8443
Batch 390, Loss: 0.8748
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.066895008087158 seconds
Epoch 129 accuracy: 70.98%
Batch 10, Loss: 0.7523
Batch 20, Loss: 0.7778
Batch 30, Loss: 0.7909
Batch 40, Loss: 0.8120
Batch 50, Loss: 0.8150
Batch 60, Loss: 0.7778
Batch 70, Loss: 0.7683
Batch 80, Loss: 0.7877
Batch 90, Loss: 0.8035
Batch 100, Loss: 0.7828
Batch 110, Loss: 0.8412
Batch 120, Loss: 0.8664
Batch 130, Loss: 0.8350
Batch 140, Loss: 0.7886
Batch 150, Loss: 0.8596
Batch 160, Loss: 0.8411
Batch 170, Loss: 0.8217
Batch 180, Loss: 0.8485
Batch 190, Loss: 0.8002
Batch 200, Loss: 0.8271
Batch 210, Loss: 0.7854
Batch 220, Loss: 0.8370
Batch 230, Loss: 0.8350
Batch 240, Loss: 0.8317
Batch 250, Loss: 0.7852
Batch 260, Loss: 0.7896
Batch 270, Loss: 0.8401
Batch 280, Loss: 0.8226
Batch 290, Loss: 0.7854
Batch 300, Loss: 0.8158
Batch 310, Loss: 0.7981
Batch 320, Loss: 0.7996
Batch 330, Loss: 0.8516
Batch 340, Loss: 0.8617
Batch 350, Loss: 0.8660
Batch 360, Loss: 0.8427
Batch 370, Loss: 0.8345
Batch 380, Loss: 0.8639
Batch 390, Loss: 0.8366
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.063204288482666 seconds
Epoch 130 accuracy: 70.74%
Batch 10, Loss: 0.7770
Batch 20, Loss: 0.7745
Batch 30, Loss: 0.8198
Batch 40, Loss: 0.7405
Batch 50, Loss: 0.8229
Batch 60, Loss: 0.7964
Batch 70, Loss: 0.7701
Batch 80, Loss: 0.7563
Batch 90, Loss: 0.7269
Batch 100, Loss: 0.8078
Batch 110, Loss: 0.7797
Batch 120, Loss: 0.8125
Batch 130, Loss: 0.7547
Batch 140, Loss: 0.7537
Batch 150, Loss: 0.7635
Batch 160, Loss: 0.8342
Batch 170, Loss: 0.8575
Batch 180, Loss: 0.8218
Batch 190, Loss: 0.8085
Batch 200, Loss: 0.8107
Batch 210, Loss: 0.8045
Batch 220, Loss: 0.8303
Batch 230, Loss: 0.8487
Batch 240, Loss: 0.7930
Batch 250, Loss: 0.8527
Batch 260, Loss: 0.8407
Batch 270, Loss: 0.8179
Batch 280, Loss: 0.7907
Batch 290, Loss: 0.7976
Batch 300, Loss: 0.8326
Batch 310, Loss: 0.8384
Batch 320, Loss: 0.8245
Batch 330, Loss: 0.8074
Batch 340, Loss: 0.8133
Batch 350, Loss: 0.8060
Batch 360, Loss: 0.8322
Batch 370, Loss: 0.8192
Batch 380, Loss: 0.8455
Batch 390, Loss: 0.8224
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.092055320739746 seconds
Epoch 131 accuracy: 71.63%
Batch 10, Loss: 0.7426
Batch 20, Loss: 0.7909
Batch 30, Loss: 0.7710
Batch 40, Loss: 0.8373
Batch 50, Loss: 0.7806
Batch 60, Loss: 0.7867
Batch 70, Loss: 0.7704
Batch 80, Loss: 0.7543
Batch 90, Loss: 0.7522
Batch 100, Loss: 0.8183
Batch 110, Loss: 0.8003
Batch 120, Loss: 0.7844
Batch 130, Loss: 0.8031
Batch 140, Loss: 0.7805
Batch 150, Loss: 0.7299
Batch 160, Loss: 0.8326
Batch 170, Loss: 0.7688
Batch 180, Loss: 0.8357
Batch 190, Loss: 0.7878
Batch 200, Loss: 0.7910
Batch 210, Loss: 0.8020
Batch 220, Loss: 0.7961
Batch 230, Loss: 0.8247
Batch 240, Loss: 0.8160
Batch 250, Loss: 0.8333
Batch 260, Loss: 0.8194
Batch 270, Loss: 0.8239
Batch 280, Loss: 0.8156
Batch 290, Loss: 0.8100
Batch 300, Loss: 0.7733
Batch 310, Loss: 0.8480
Batch 320, Loss: 0.7903
Batch 330, Loss: 0.7619
Batch 340, Loss: 0.8133
Batch 350, Loss: 0.8354
Batch 360, Loss: 0.7859
Batch 370, Loss: 0.8197
Batch 380, Loss: 0.8179
Batch 390, Loss: 0.8169
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.16955304145813 seconds
Epoch 132 accuracy: 70.9%
Batch 10, Loss: 0.7545
Batch 20, Loss: 0.7192
Batch 30, Loss: 0.7372
Batch 40, Loss: 0.7528
Batch 50, Loss: 0.7694
Batch 60, Loss: 0.7495
Batch 70, Loss: 0.7480
Batch 80, Loss: 0.8018
Batch 90, Loss: 0.7673
Batch 100, Loss: 0.7511
Batch 110, Loss: 0.8159
Batch 120, Loss: 0.7681
Batch 130, Loss: 0.7694
Batch 140, Loss: 0.8394
Batch 150, Loss: 0.7618
Batch 160, Loss: 0.8290
Batch 170, Loss: 0.7683
Batch 180, Loss: 0.7720
Batch 190, Loss: 0.8514
Batch 200, Loss: 0.7885
Batch 210, Loss: 0.7903
Batch 220, Loss: 0.7670
Batch 230, Loss: 0.7661
Batch 240, Loss: 0.8006
Batch 250, Loss: 0.8083
Batch 260, Loss: 0.7565
Batch 270, Loss: 0.7959
Batch 280, Loss: 0.8257
Batch 290, Loss: 0.8359
Batch 300, Loss: 0.8175
Batch 310, Loss: 0.8211
Batch 320, Loss: 0.8305
Batch 330, Loss: 0.7809
Batch 340, Loss: 0.8416
Batch 350, Loss: 0.7759
Batch 360, Loss: 0.8270
Batch 370, Loss: 0.8233
Batch 380, Loss: 0.8494
Batch 390, Loss: 0.8512
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.07810878753662 seconds
Epoch 133 accuracy: 71.77%
Batch 10, Loss: 0.8057
Batch 20, Loss: 0.7860
Batch 30, Loss: 0.7821
Batch 40, Loss: 0.7493
Batch 50, Loss: 0.7199
Batch 60, Loss: 0.7623
Batch 70, Loss: 0.7474
Batch 80, Loss: 0.7752
Batch 90, Loss: 0.7570
Batch 100, Loss: 0.7710
Batch 110, Loss: 0.7732
Batch 120, Loss: 0.8007
Batch 130, Loss: 0.8104
Batch 140, Loss: 0.7459
Batch 150, Loss: 0.8107
Batch 160, Loss: 0.7730
Batch 170, Loss: 0.7709
Batch 180, Loss: 0.7873
Batch 190, Loss: 0.7273
Batch 200, Loss: 0.7572
Batch 210, Loss: 0.8380
Batch 220, Loss: 0.7669
Batch 230, Loss: 0.7695
Batch 240, Loss: 0.7576
Batch 250, Loss: 0.7585
Batch 260, Loss: 0.8468
Batch 270, Loss: 0.7556
Batch 280, Loss: 0.8484
Batch 290, Loss: 0.7830
Batch 300, Loss: 0.8589
Batch 310, Loss: 0.7987
Batch 320, Loss: 0.7875
Batch 330, Loss: 0.8002
Batch 340, Loss: 0.8238
Batch 350, Loss: 0.8594
Batch 360, Loss: 0.8307
Batch 370, Loss: 0.8225
Batch 380, Loss: 0.8025
Batch 390, Loss: 0.8743
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.00019669532776 seconds
Epoch 134 accuracy: 71.72%
Batch 10, Loss: 0.7510
Batch 20, Loss: 0.7563
Batch 30, Loss: 0.7074
Batch 40, Loss: 0.7436
Batch 50, Loss: 0.8168
Batch 60, Loss: 0.7410
Batch 70, Loss: 0.7686
Batch 80, Loss: 0.7406
Batch 90, Loss: 0.7376
Batch 100, Loss: 0.6978
Batch 110, Loss: 0.7197
Batch 120, Loss: 0.7347
Batch 130, Loss: 0.7389
Batch 140, Loss: 0.7578
Batch 150, Loss: 0.7554
Batch 160, Loss: 0.8125
Batch 170, Loss: 0.7815
Batch 180, Loss: 0.7749
Batch 190, Loss: 0.7891
Batch 200, Loss: 0.7600
Batch 210, Loss: 0.7966
Batch 220, Loss: 0.8100
Batch 230, Loss: 0.7956
Batch 240, Loss: 0.7941
Batch 250, Loss: 0.7679
Batch 260, Loss: 0.7656
Batch 270, Loss: 0.7656
Batch 280, Loss: 0.7420
Batch 290, Loss: 0.7444
Batch 300, Loss: 0.7788
Batch 310, Loss: 0.8151
Batch 320, Loss: 0.7773
Batch 330, Loss: 0.7696
Batch 340, Loss: 0.7976
Batch 350, Loss: 0.7801
Batch 360, Loss: 0.7879
Batch 370, Loss: 0.8292
Batch 380, Loss: 0.8099
Batch 390, Loss: 0.7935
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.078582048416138 seconds
Epoch 135 accuracy: 71.15%
Batch 10, Loss: 0.7558
Batch 20, Loss: 0.7241
Batch 30, Loss: 0.7311
Batch 40, Loss: 0.7567
Batch 50, Loss: 0.7007
Batch 60, Loss: 0.7187
Batch 70, Loss: 0.7523
Batch 80, Loss: 0.7400
Batch 90, Loss: 0.7632
Batch 100, Loss: 0.7031
Batch 110, Loss: 0.7231
Batch 120, Loss: 0.7657
Batch 130, Loss: 0.7369
Batch 140, Loss: 0.7373
Batch 150, Loss: 0.7572
Batch 160, Loss: 0.7590
Batch 170, Loss: 0.7507
Batch 180, Loss: 0.7597
Batch 190, Loss: 0.7521
Batch 200, Loss: 0.7828
Batch 210, Loss: 0.7500
Batch 220, Loss: 0.7815
Batch 230, Loss: 0.7626
Batch 240, Loss: 0.7676
Batch 250, Loss: 0.7620
Batch 260, Loss: 0.8315
Batch 270, Loss: 0.7573
Batch 280, Loss: 0.8012
Batch 290, Loss: 0.7529
Batch 300, Loss: 0.7728
Batch 310, Loss: 0.7565
Batch 320, Loss: 0.7763
Batch 330, Loss: 0.7776
Batch 340, Loss: 0.7889
Batch 350, Loss: 0.7925
Batch 360, Loss: 0.7727
Batch 370, Loss: 0.7848
Batch 380, Loss: 0.7958
Batch 390, Loss: 0.7838
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.020674228668213 seconds
Epoch 136 accuracy: 71.95%
Batch 10, Loss: 0.6989
Batch 20, Loss: 0.7151
Batch 30, Loss: 0.7101
Batch 40, Loss: 0.7044
Batch 50, Loss: 0.6728
Batch 60, Loss: 0.7262
Batch 70, Loss: 0.7009
Batch 80, Loss: 0.7236
Batch 90, Loss: 0.7494
Batch 100, Loss: 0.7788
Batch 110, Loss: 0.7182
Batch 120, Loss: 0.7222
Batch 130, Loss: 0.7416
Batch 140, Loss: 0.6990
Batch 150, Loss: 0.7089
Batch 160, Loss: 0.7704
Batch 170, Loss: 0.7695
Batch 180, Loss: 0.7688
Batch 190, Loss: 0.8045
Batch 200, Loss: 0.7370
Batch 210, Loss: 0.7167
Batch 220, Loss: 0.7834
Batch 230, Loss: 0.7350
Batch 240, Loss: 0.7274
Batch 250, Loss: 0.7378
Batch 260, Loss: 0.7975
Batch 270, Loss: 0.7589
Batch 280, Loss: 0.7098
Batch 290, Loss: 0.8203
Batch 300, Loss: 0.7688
Batch 310, Loss: 0.8048
Batch 320, Loss: 0.7764
Batch 330, Loss: 0.7444
Batch 340, Loss: 0.7331
Batch 350, Loss: 0.7604
Batch 360, Loss: 0.7725
Batch 370, Loss: 0.7835
Batch 380, Loss: 0.7640
Batch 390, Loss: 0.7439
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.09588360786438 seconds
Epoch 137 accuracy: 72.11%
Batch 10, Loss: 0.7100
Batch 20, Loss: 0.7424
Batch 30, Loss: 0.6978
Batch 40, Loss: 0.6784
Batch 50, Loss: 0.7118
Batch 60, Loss: 0.7042
Batch 70, Loss: 0.6558
Batch 80, Loss: 0.7485
Batch 90, Loss: 0.7835
Batch 100, Loss: 0.6854
Batch 110, Loss: 0.6799
Batch 120, Loss: 0.7622
Batch 130, Loss: 0.7230
Batch 140, Loss: 0.7042
Batch 150, Loss: 0.7335
Batch 160, Loss: 0.7186
Batch 170, Loss: 0.7273
Batch 180, Loss: 0.7568
Batch 190, Loss: 0.7609
Batch 200, Loss: 0.7540
Batch 210, Loss: 0.7121
Batch 220, Loss: 0.7252
Batch 230, Loss: 0.7201
Batch 240, Loss: 0.6977
Batch 250, Loss: 0.7555
Batch 260, Loss: 0.7465
Batch 270, Loss: 0.7200
Batch 280, Loss: 0.8084
Batch 290, Loss: 0.7096
Batch 300, Loss: 0.7197
Batch 310, Loss: 0.7367
Batch 320, Loss: 0.7339
Batch 330, Loss: 0.7204
Batch 340, Loss: 0.7277
Batch 350, Loss: 0.7389
Batch 360, Loss: 0.7609
Batch 370, Loss: 0.7504
Batch 380, Loss: 0.7791
Batch 390, Loss: 0.8231
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.060153245925903 seconds
Epoch 138 accuracy: 71.44%
Batch 10, Loss: 0.6640
Batch 20, Loss: 0.6784
Batch 30, Loss: 0.7288
Batch 40, Loss: 0.6867
Batch 50, Loss: 0.7316
Batch 60, Loss: 0.7232
Batch 70, Loss: 0.7101
Batch 80, Loss: 0.6762
Batch 90, Loss: 0.7222
Batch 100, Loss: 0.6835
Batch 110, Loss: 0.7681
Batch 120, Loss: 0.7326
Batch 130, Loss: 0.6762
Batch 140, Loss: 0.7064
Batch 150, Loss: 0.7558
Batch 160, Loss: 0.6866
Batch 170, Loss: 0.6798
Batch 180, Loss: 0.7131
Batch 190, Loss: 0.7390
Batch 200, Loss: 0.6950
Batch 210, Loss: 0.7447
Batch 220, Loss: 0.7524
Batch 230, Loss: 0.6799
Batch 240, Loss: 0.7681
Batch 250, Loss: 0.7235
Batch 260, Loss: 0.6946
Batch 270, Loss: 0.7904
Batch 280, Loss: 0.7417
Batch 290, Loss: 0.7444
Batch 300, Loss: 0.7546
Batch 310, Loss: 0.8242
Batch 320, Loss: 0.7613
Batch 330, Loss: 0.8211
Batch 340, Loss: 0.7216
Batch 350, Loss: 0.7623
Batch 360, Loss: 0.7506
Batch 370, Loss: 0.7372
Batch 380, Loss: 0.7054
Batch 390, Loss: 0.7719
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.159470796585083 seconds
Epoch 139 accuracy: 72.54%
Batch 10, Loss: 0.7313
Batch 20, Loss: 0.6767
Batch 30, Loss: 0.6878
Batch 40, Loss: 0.7118
Batch 50, Loss: 0.6711
Batch 60, Loss: 0.6985
Batch 70, Loss: 0.7010
Batch 80, Loss: 0.6549
Batch 90, Loss: 0.7149
Batch 100, Loss: 0.7229
Batch 110, Loss: 0.6957
Batch 120, Loss: 0.6869
Batch 130, Loss: 0.7038
Batch 140, Loss: 0.7053
Batch 150, Loss: 0.7196
Batch 160, Loss: 0.6493
Batch 170, Loss: 0.6738
Batch 180, Loss: 0.7422
Batch 190, Loss: 0.7545
Batch 200, Loss: 0.6833
Batch 210, Loss: 0.7022
Batch 220, Loss: 0.7297
Batch 230, Loss: 0.7058
Batch 240, Loss: 0.7300
Batch 250, Loss: 0.7113
Batch 260, Loss: 0.7127
Batch 270, Loss: 0.6921
Batch 280, Loss: 0.7293
Batch 290, Loss: 0.7116
Batch 300, Loss: 0.7695
Batch 310, Loss: 0.6828
Batch 320, Loss: 0.7349
Batch 330, Loss: 0.7745
Batch 340, Loss: 0.7505
Batch 350, Loss: 0.7240
Batch 360, Loss: 0.7473
Batch 370, Loss: 0.7110
Batch 380, Loss: 0.7214
Batch 390, Loss: 0.7551
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.096486568450928 seconds
Epoch 140 accuracy: 72.72%
Batch 10, Loss: 0.6790
Batch 20, Loss: 0.7069
Batch 30, Loss: 0.6583
Batch 40, Loss: 0.7217
Batch 50, Loss: 0.7359
Batch 60, Loss: 0.6540
Batch 70, Loss: 0.6426
Batch 80, Loss: 0.6715
Batch 90, Loss: 0.6484
Batch 100, Loss: 0.6835
Batch 110, Loss: 0.7012
Batch 120, Loss: 0.7257
Batch 130, Loss: 0.6756
Batch 140, Loss: 0.6564
Batch 150, Loss: 0.7349
Batch 160, Loss: 0.7383
Batch 170, Loss: 0.6814
Batch 180, Loss: 0.7068
Batch 190, Loss: 0.6419
Batch 200, Loss: 0.6985
Batch 210, Loss: 0.7077
Batch 220, Loss: 0.7177
Batch 230, Loss: 0.7149
Batch 240, Loss: 0.7072
Batch 250, Loss: 0.7306
Batch 260, Loss: 0.6939
Batch 270, Loss: 0.7140
Batch 280, Loss: 0.7190
Batch 290, Loss: 0.6960
Batch 300, Loss: 0.6758
Batch 310, Loss: 0.7492
Batch 320, Loss: 0.6754
Batch 330, Loss: 0.6684
Batch 340, Loss: 0.7129
Batch 350, Loss: 0.7895
Batch 360, Loss: 0.7393
Batch 370, Loss: 0.7126
Batch 380, Loss: 0.7147
Batch 390, Loss: 0.7128
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.06045389175415 seconds
Epoch 141 accuracy: 72.4%
Batch 10, Loss: 0.6271
Batch 20, Loss: 0.6421
Batch 30, Loss: 0.6421
Batch 40, Loss: 0.5980
Batch 50, Loss: 0.6250
Batch 60, Loss: 0.7057
Batch 70, Loss: 0.6219
Batch 80, Loss: 0.7299
Batch 90, Loss: 0.6695
Batch 100, Loss: 0.6706
Batch 110, Loss: 0.7277
Batch 120, Loss: 0.6795
Batch 130, Loss: 0.6817
Batch 140, Loss: 0.6705
Batch 150, Loss: 0.6723
Batch 160, Loss: 0.6647
Batch 170, Loss: 0.7070
Batch 180, Loss: 0.6539
Batch 190, Loss: 0.7254
Batch 200, Loss: 0.6775
Batch 210, Loss: 0.5969
Batch 220, Loss: 0.6554
Batch 230, Loss: 0.7120
Batch 240, Loss: 0.6778
Batch 250, Loss: 0.6783
Batch 260, Loss: 0.7130
Batch 270, Loss: 0.7793
Batch 280, Loss: 0.6881
Batch 290, Loss: 0.7152
Batch 300, Loss: 0.7005
Batch 310, Loss: 0.6917
Batch 320, Loss: 0.6850
Batch 330, Loss: 0.6900
Batch 340, Loss: 0.7194
Batch 350, Loss: 0.7094
Batch 360, Loss: 0.7144
Batch 370, Loss: 0.7391
Batch 380, Loss: 0.7092
Batch 390, Loss: 0.7195
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.054521083831787 seconds
Epoch 142 accuracy: 72.9%
Batch 10, Loss: 0.6498
Batch 20, Loss: 0.6514
Batch 30, Loss: 0.6995
Batch 40, Loss: 0.6726
Batch 50, Loss: 0.6919
Batch 60, Loss: 0.6735
Batch 70, Loss: 0.6876
Batch 80, Loss: 0.6531
Batch 90, Loss: 0.6466
Batch 100, Loss: 0.6576
Batch 110, Loss: 0.6416
Batch 120, Loss: 0.6388
Batch 130, Loss: 0.6344
Batch 140, Loss: 0.6439
Batch 150, Loss: 0.6892
Batch 160, Loss: 0.5932
Batch 170, Loss: 0.6580
Batch 180, Loss: 0.6633
Batch 190, Loss: 0.6701
Batch 200, Loss: 0.7075
Batch 210, Loss: 0.6392
Batch 220, Loss: 0.6837
Batch 230, Loss: 0.7150
Batch 240, Loss: 0.6564
Batch 250, Loss: 0.7135
Batch 260, Loss: 0.6484
Batch 270, Loss: 0.7475
Batch 280, Loss: 0.7073
Batch 290, Loss: 0.7213
Batch 300, Loss: 0.7088
Batch 310, Loss: 0.6915
Batch 320, Loss: 0.6613
Batch 330, Loss: 0.6856
Batch 340, Loss: 0.6722
Batch 350, Loss: 0.7157
Batch 360, Loss: 0.6942
Batch 370, Loss: 0.7072
Batch 380, Loss: 0.7063
Batch 390, Loss: 0.7263
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.10581612586975 seconds
Epoch 143 accuracy: 72.62%
Batch 10, Loss: 0.6633
Batch 20, Loss: 0.6952
Batch 30, Loss: 0.6235
Batch 40, Loss: 0.5770
Batch 50, Loss: 0.6045
Batch 60, Loss: 0.6232
Batch 70, Loss: 0.6548
Batch 80, Loss: 0.7071
Batch 90, Loss: 0.6844
Batch 100, Loss: 0.7053
Batch 110, Loss: 0.6539
Batch 120, Loss: 0.6867
Batch 130, Loss: 0.6269
Batch 140, Loss: 0.6833
Batch 150, Loss: 0.6080
Batch 160, Loss: 0.6980
Batch 170, Loss: 0.6393
Batch 180, Loss: 0.6653
Batch 190, Loss: 0.6387
Batch 200, Loss: 0.6900
Batch 210, Loss: 0.6593
Batch 220, Loss: 0.6821
Batch 230, Loss: 0.6667
Batch 240, Loss: 0.6658
Batch 250, Loss: 0.6765
Batch 260, Loss: 0.6943
Batch 270, Loss: 0.6869
Batch 280, Loss: 0.6814
Batch 290, Loss: 0.6644
Batch 300, Loss: 0.6833
Batch 310, Loss: 0.6539
Batch 320, Loss: 0.6708
Batch 330, Loss: 0.7006
Batch 340, Loss: 0.7256
Batch 350, Loss: 0.7014
Batch 360, Loss: 0.6410
Batch 370, Loss: 0.6845
Batch 380, Loss: 0.6762
Batch 390, Loss: 0.7093
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.110795259475708 seconds
Epoch 144 accuracy: 74.01%
Batch 10, Loss: 0.6667
Batch 20, Loss: 0.6640
Batch 30, Loss: 0.6388
Batch 40, Loss: 0.6646
Batch 50, Loss: 0.6364
Batch 60, Loss: 0.6330
Batch 70, Loss: 0.6200
Batch 80, Loss: 0.6730
Batch 90, Loss: 0.6491
Batch 100, Loss: 0.6568
Batch 110, Loss: 0.6530
Batch 120, Loss: 0.6404
Batch 130, Loss: 0.5869
Batch 140, Loss: 0.6575
Batch 150, Loss: 0.6556
Batch 160, Loss: 0.6364
Batch 170, Loss: 0.6891
Batch 180, Loss: 0.6982
Batch 190, Loss: 0.6408
Batch 200, Loss: 0.6862
Batch 210, Loss: 0.6855
Batch 220, Loss: 0.6714
Batch 230, Loss: 0.6762
Batch 240, Loss: 0.6403
Batch 250, Loss: 0.6781
Batch 260, Loss: 0.6382
Batch 270, Loss: 0.6494
Batch 280, Loss: 0.6589
Batch 290, Loss: 0.6283
Batch 300, Loss: 0.6427
Batch 310, Loss: 0.6980
Batch 320, Loss: 0.7276
Batch 330, Loss: 0.6880
Batch 340, Loss: 0.7022
Batch 350, Loss: 0.7081
Batch 360, Loss: 0.6470
Batch 370, Loss: 0.6944
Batch 380, Loss: 0.6922
Batch 390, Loss: 0.7323
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.068930864334106 seconds
Epoch 145 accuracy: 73.25%
Batch 10, Loss: 0.6582
Batch 20, Loss: 0.6030
Batch 30, Loss: 0.6448
Batch 40, Loss: 0.6174
Batch 50, Loss: 0.6277
Batch 60, Loss: 0.5821
Batch 70, Loss: 0.5915
Batch 80, Loss: 0.6209
Batch 90, Loss: 0.6254
Batch 100, Loss: 0.6541
Batch 110, Loss: 0.6262
Batch 120, Loss: 0.6180
Batch 130, Loss: 0.7162
Batch 140, Loss: 0.6292
Batch 150, Loss: 0.6148
Batch 160, Loss: 0.6062
Batch 170, Loss: 0.6187
Batch 180, Loss: 0.6442
Batch 190, Loss: 0.6265
Batch 200, Loss: 0.6608
Batch 210, Loss: 0.6114
Batch 220, Loss: 0.6513
Batch 230, Loss: 0.7015
Batch 240, Loss: 0.6485
Batch 250, Loss: 0.6114
Batch 260, Loss: 0.6688
Batch 270, Loss: 0.6911
Batch 280, Loss: 0.6508
Batch 290, Loss: 0.6675
Batch 300, Loss: 0.6539
Batch 310, Loss: 0.6944
Batch 320, Loss: 0.6421
Batch 330, Loss: 0.6014
Batch 340, Loss: 0.6453
Batch 350, Loss: 0.6588
Batch 360, Loss: 0.6408
Batch 370, Loss: 0.6292
Batch 380, Loss: 0.5880
Batch 390, Loss: 0.6855
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.117104291915894 seconds
Epoch 146 accuracy: 73.12%
Batch 10, Loss: 0.6136
Batch 20, Loss: 0.6225
Batch 30, Loss: 0.5750
Batch 40, Loss: 0.5994
Batch 50, Loss: 0.6155
Batch 60, Loss: 0.6672
Batch 70, Loss: 0.6259
Batch 80, Loss: 0.5900
Batch 90, Loss: 0.6173
Batch 100, Loss: 0.5900
Batch 110, Loss: 0.6152
Batch 120, Loss: 0.6247
Batch 130, Loss: 0.5919
Batch 140, Loss: 0.6636
Batch 150, Loss: 0.6363
Batch 160, Loss: 0.6573
Batch 170, Loss: 0.6210
Batch 180, Loss: 0.6430
Batch 190, Loss: 0.6364
Batch 200, Loss: 0.6516
Batch 210, Loss: 0.6418
Batch 220, Loss: 0.6290
Batch 230, Loss: 0.6434
Batch 240, Loss: 0.6756
Batch 250, Loss: 0.6862
Batch 260, Loss: 0.6721
Batch 270, Loss: 0.6471
Batch 280, Loss: 0.6332
Batch 290, Loss: 0.6635
Batch 300, Loss: 0.6455
Batch 310, Loss: 0.6684
Batch 320, Loss: 0.6541
Batch 330, Loss: 0.6049
Batch 340, Loss: 0.6818
Batch 350, Loss: 0.6470
Batch 360, Loss: 0.6360
Batch 370, Loss: 0.6911
Batch 380, Loss: 0.6632
Batch 390, Loss: 0.6582
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.03084683418274 seconds
Epoch 147 accuracy: 74.12%
Batch 10, Loss: 0.6222
Batch 20, Loss: 0.6438
Batch 30, Loss: 0.5568
Batch 40, Loss: 0.5597
Batch 50, Loss: 0.5431
Batch 60, Loss: 0.5857
Batch 70, Loss: 0.5671
Batch 80, Loss: 0.5900
Batch 90, Loss: 0.6187
Batch 100, Loss: 0.5733
Batch 110, Loss: 0.6597
Batch 120, Loss: 0.6171
Batch 130, Loss: 0.6258
Batch 140, Loss: 0.6643
Batch 150, Loss: 0.5979
Batch 160, Loss: 0.6008
Batch 170, Loss: 0.5881
Batch 180, Loss: 0.6202
Batch 190, Loss: 0.6581
Batch 200, Loss: 0.6270
Batch 210, Loss: 0.6376
Batch 220, Loss: 0.6668
Batch 230, Loss: 0.6207
Batch 240, Loss: 0.6496
Batch 250, Loss: 0.6203
Batch 260, Loss: 0.6859
Batch 270, Loss: 0.5737
Batch 280, Loss: 0.6397
Batch 290, Loss: 0.6130
Batch 300, Loss: 0.6271
Batch 310, Loss: 0.6408
Batch 320, Loss: 0.5952
Batch 330, Loss: 0.6136
Batch 340, Loss: 0.6402
Batch 350, Loss: 0.6135
Batch 360, Loss: 0.6125
Batch 370, Loss: 0.6704
Batch 380, Loss: 0.6261
Batch 390, Loss: 0.6561
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.174410581588745 seconds
Epoch 148 accuracy: 73.44%
Batch 10, Loss: 0.6027
Batch 20, Loss: 0.6150
Batch 30, Loss: 0.5500
Batch 40, Loss: 0.5450
Batch 50, Loss: 0.5915
Batch 60, Loss: 0.5871
Batch 70, Loss: 0.5689
Batch 80, Loss: 0.5936
Batch 90, Loss: 0.5799
Batch 100, Loss: 0.5712
Batch 110, Loss: 0.5998
Batch 120, Loss: 0.6191
Batch 130, Loss: 0.6315
Batch 140, Loss: 0.5718
Batch 150, Loss: 0.5752
Batch 160, Loss: 0.5936
Batch 170, Loss: 0.6018
Batch 180, Loss: 0.6106
Batch 190, Loss: 0.5694
Batch 200, Loss: 0.6131
Batch 210, Loss: 0.5834
Batch 220, Loss: 0.5789
Batch 230, Loss: 0.6226
Batch 240, Loss: 0.6609
Batch 250, Loss: 0.5774
Batch 260, Loss: 0.6436
Batch 270, Loss: 0.6313
Batch 280, Loss: 0.5850
Batch 290, Loss: 0.6287
Batch 300, Loss: 0.6373
Batch 310, Loss: 0.6052
Batch 320, Loss: 0.6781
Batch 330, Loss: 0.6394
Batch 340, Loss: 0.6433
Batch 350, Loss: 0.6111
Batch 360, Loss: 0.6093
Batch 370, Loss: 0.6215
Batch 380, Loss: 0.5888
Batch 390, Loss: 0.6243
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.071651220321655 seconds
Epoch 149 accuracy: 74.57%
Batch 10, Loss: 0.5650
Batch 20, Loss: 0.5684
Batch 30, Loss: 0.6221
Batch 40, Loss: 0.6141
Batch 50, Loss: 0.5837
Batch 60, Loss: 0.5899
Batch 70, Loss: 0.5451
Batch 80, Loss: 0.5720
Batch 90, Loss: 0.5770
Batch 100, Loss: 0.5684
Batch 110, Loss: 0.5963
Batch 120, Loss: 0.5861
Batch 130, Loss: 0.5437
Batch 140, Loss: 0.5520
Batch 150, Loss: 0.5613
Batch 160, Loss: 0.5942
Batch 170, Loss: 0.5551
Batch 180, Loss: 0.5739
Batch 190, Loss: 0.5904
Batch 200, Loss: 0.5888
Batch 210, Loss: 0.6108
Batch 220, Loss: 0.5792
Batch 230, Loss: 0.6117
Batch 240, Loss: 0.5960
Batch 250, Loss: 0.6007
Batch 260, Loss: 0.5726
Batch 270, Loss: 0.5884
Batch 280, Loss: 0.5927
Batch 290, Loss: 0.5860
Batch 300, Loss: 0.5969
Batch 310, Loss: 0.5930
Batch 320, Loss: 0.5989
Batch 330, Loss: 0.6275
Batch 340, Loss: 0.5817
Batch 350, Loss: 0.6239
Batch 360, Loss: 0.6085
Batch 370, Loss: 0.5961
Batch 380, Loss: 0.5921
Batch 390, Loss: 0.6190
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.05805230140686 seconds
Epoch 150 accuracy: 74.98%
Batch 10, Loss: 0.5815
Batch 20, Loss: 0.5646
Batch 30, Loss: 0.5559
Batch 40, Loss: 0.5805
Batch 50, Loss: 0.5774
Batch 60, Loss: 0.5851
Batch 70, Loss: 0.5469
Batch 80, Loss: 0.5435
Batch 90, Loss: 0.5842
Batch 100, Loss: 0.5832
Batch 110, Loss: 0.5294
Batch 120, Loss: 0.6097
Batch 130, Loss: 0.5746
Batch 140, Loss: 0.5698
Batch 150, Loss: 0.6192
Batch 160, Loss: 0.6064
Batch 170, Loss: 0.5611
Batch 180, Loss: 0.6442
Batch 190, Loss: 0.5997
Batch 200, Loss: 0.5774
Batch 210, Loss: 0.6130
Batch 220, Loss: 0.6050
Batch 230, Loss: 0.6072
Batch 240, Loss: 0.6210
Batch 250, Loss: 0.5722
Batch 260, Loss: 0.5582
Batch 270, Loss: 0.6094
Batch 280, Loss: 0.5961
Batch 290, Loss: 0.5771
Batch 300, Loss: 0.6326
Batch 310, Loss: 0.5936
Batch 320, Loss: 0.6018
Batch 330, Loss: 0.5877
Batch 340, Loss: 0.5806
Batch 350, Loss: 0.6319
Batch 360, Loss: 0.5848
Batch 370, Loss: 0.6280
Batch 380, Loss: 0.6373
Batch 390, Loss: 0.6019
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.24989938735962 seconds
Epoch 151 accuracy: 74.65%
Batch 10, Loss: 0.6314
Batch 20, Loss: 0.5405
Batch 30, Loss: 0.5284
Batch 40, Loss: 0.5757
Batch 50, Loss: 0.5176
Batch 60, Loss: 0.5482
Batch 70, Loss: 0.5770
Batch 80, Loss: 0.5528
Batch 90, Loss: 0.6250
Batch 100, Loss: 0.5569
Batch 110, Loss: 0.6248
Batch 120, Loss: 0.5829
Batch 130, Loss: 0.5682
Batch 140, Loss: 0.5881
Batch 150, Loss: 0.5985
Batch 160, Loss: 0.5316
Batch 170, Loss: 0.5892
Batch 180, Loss: 0.5938
Batch 190, Loss: 0.6249
Batch 200, Loss: 0.5934
Batch 210, Loss: 0.5778
Batch 220, Loss: 0.5797
Batch 230, Loss: 0.5850
Batch 240, Loss: 0.5419
Batch 250, Loss: 0.5773
Batch 260, Loss: 0.5965
Batch 270, Loss: 0.5976
Batch 280, Loss: 0.5504
Batch 290, Loss: 0.5816
Batch 300, Loss: 0.6023
Batch 310, Loss: 0.6015
Batch 320, Loss: 0.6268
Batch 330, Loss: 0.5750
Batch 340, Loss: 0.6006
Batch 350, Loss: 0.6417
Batch 360, Loss: 0.5827
Batch 370, Loss: 0.5708
Batch 380, Loss: 0.5761
Batch 390, Loss: 0.5911
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.134135723114014 seconds
Epoch 152 accuracy: 75.64%
Batch 10, Loss: 0.5179
Batch 20, Loss: 0.5591
Batch 30, Loss: 0.5455
Batch 40, Loss: 0.5502
Batch 50, Loss: 0.5178
Batch 60, Loss: 0.5534
Batch 70, Loss: 0.5145
Batch 80, Loss: 0.5381
Batch 90, Loss: 0.5265
Batch 100, Loss: 0.5888
Batch 110, Loss: 0.5696
Batch 120, Loss: 0.5108
Batch 130, Loss: 0.6093
Batch 140, Loss: 0.6162
Batch 150, Loss: 0.5574
Batch 160, Loss: 0.5719
Batch 170, Loss: 0.5470
Batch 180, Loss: 0.5856
Batch 190, Loss: 0.5403
Batch 200, Loss: 0.5622
Batch 210, Loss: 0.5395
Batch 220, Loss: 0.5998
Batch 230, Loss: 0.6021
Batch 240, Loss: 0.5274
Batch 250, Loss: 0.5908
Batch 260, Loss: 0.5688
Batch 270, Loss: 0.5665
Batch 280, Loss: 0.5631
Batch 290, Loss: 0.5413
Batch 300, Loss: 0.5571
Batch 310, Loss: 0.5552
Batch 320, Loss: 0.5666
Batch 330, Loss: 0.5701
Batch 340, Loss: 0.5904
Batch 350, Loss: 0.6222
Batch 360, Loss: 0.5852
Batch 370, Loss: 0.6226
Batch 380, Loss: 0.5754
Batch 390, Loss: 0.6127
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.086389303207397 seconds
Epoch 153 accuracy: 74.49%
Batch 10, Loss: 0.5625
Batch 20, Loss: 0.5547
Batch 30, Loss: 0.5364
Batch 40, Loss: 0.5195
Batch 50, Loss: 0.5193
Batch 60, Loss: 0.5500
Batch 70, Loss: 0.5228
Batch 80, Loss: 0.5383
Batch 90, Loss: 0.4975
Batch 100, Loss: 0.5324
Batch 110, Loss: 0.5627
Batch 120, Loss: 0.5399
Batch 130, Loss: 0.5533
Batch 140, Loss: 0.5754
Batch 150, Loss: 0.5644
Batch 160, Loss: 0.5519
Batch 170, Loss: 0.5535
Batch 180, Loss: 0.4979
Batch 190, Loss: 0.5768
Batch 200, Loss: 0.5771
Batch 210, Loss: 0.5826
Batch 220, Loss: 0.5966
Batch 230, Loss: 0.5339
Batch 240, Loss: 0.5396
Batch 250, Loss: 0.5196
Batch 260, Loss: 0.5035
Batch 270, Loss: 0.5285
Batch 280, Loss: 0.5272
Batch 290, Loss: 0.5269
Batch 300, Loss: 0.5832
Batch 310, Loss: 0.5724
Batch 320, Loss: 0.5484
Batch 330, Loss: 0.5476
Batch 340, Loss: 0.5633
Batch 350, Loss: 0.5708
Batch 360, Loss: 0.5904
Batch 370, Loss: 0.5786
Batch 380, Loss: 0.5549
Batch 390, Loss: 0.5951
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.15240979194641 seconds
Epoch 154 accuracy: 74.77%
Batch 10, Loss: 0.4856
Batch 20, Loss: 0.5306
Batch 30, Loss: 0.5356
Batch 40, Loss: 0.5377
Batch 50, Loss: 0.5324
Batch 60, Loss: 0.4946
Batch 70, Loss: 0.5324
Batch 80, Loss: 0.5321
Batch 90, Loss: 0.4825
Batch 100, Loss: 0.5745
Batch 110, Loss: 0.4916
Batch 120, Loss: 0.5347
Batch 130, Loss: 0.5599
Batch 140, Loss: 0.5494
Batch 150, Loss: 0.4794
Batch 160, Loss: 0.5525
Batch 170, Loss: 0.5086
Batch 180, Loss: 0.5498
Batch 190, Loss: 0.5660
Batch 200, Loss: 0.5652
Batch 210, Loss: 0.5305
Batch 220, Loss: 0.5508
Batch 230, Loss: 0.5628
Batch 240, Loss: 0.4889
Batch 250, Loss: 0.5590
Batch 260, Loss: 0.5527
Batch 270, Loss: 0.5878
Batch 280, Loss: 0.5101
Batch 290, Loss: 0.5486
Batch 300, Loss: 0.5466
Batch 310, Loss: 0.5742
Batch 320, Loss: 0.5179
Batch 330, Loss: 0.5408
Batch 340, Loss: 0.5491
Batch 350, Loss: 0.5595
Batch 360, Loss: 0.5278
Batch 370, Loss: 0.5199
Batch 380, Loss: 0.5116
Batch 390, Loss: 0.5361
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 24.998262643814087 seconds
Epoch 155 accuracy: 75.22%
Batch 10, Loss: 0.4800
Batch 20, Loss: 0.5074
Batch 30, Loss: 0.5303
Batch 40, Loss: 0.5216
Batch 50, Loss: 0.5515
Batch 60, Loss: 0.5140
Batch 70, Loss: 0.4867
Batch 80, Loss: 0.4984
Batch 90, Loss: 0.5131
Batch 100, Loss: 0.5102
Batch 110, Loss: 0.5496
Batch 120, Loss: 0.5716
Batch 130, Loss: 0.4727
Batch 140, Loss: 0.5314
Batch 150, Loss: 0.5236
Batch 160, Loss: 0.5258
Batch 170, Loss: 0.5496
Batch 180, Loss: 0.5017
Batch 190, Loss: 0.5169
Batch 200, Loss: 0.5280
Batch 210, Loss: 0.5088
Batch 220, Loss: 0.5252
Batch 230, Loss: 0.5052
Batch 240, Loss: 0.4909
Batch 250, Loss: 0.5332
Batch 260, Loss: 0.4965
Batch 270, Loss: 0.5542
Batch 280, Loss: 0.5443
Batch 290, Loss: 0.5393
Batch 300, Loss: 0.5743
Batch 310, Loss: 0.5516
Batch 320, Loss: 0.4902
Batch 330, Loss: 0.5561
Batch 340, Loss: 0.5656
Batch 350, Loss: 0.5698
Batch 360, Loss: 0.5378
Batch 370, Loss: 0.5270
Batch 380, Loss: 0.5861
Batch 390, Loss: 0.5622
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.047727346420288 seconds
Epoch 156 accuracy: 75.53%
Batch 10, Loss: 0.4866
Batch 20, Loss: 0.4791
Batch 30, Loss: 0.5033
Batch 40, Loss: 0.4958
Batch 50, Loss: 0.5035
Batch 60, Loss: 0.4335
Batch 70, Loss: 0.5010
Batch 80, Loss: 0.4791
Batch 90, Loss: 0.4984
Batch 100, Loss: 0.4837
Batch 110, Loss: 0.4790
Batch 120, Loss: 0.5193
Batch 130, Loss: 0.5322
Batch 140, Loss: 0.4554
Batch 150, Loss: 0.5087
Batch 160, Loss: 0.4880
Batch 170, Loss: 0.5174
Batch 180, Loss: 0.5115
Batch 190, Loss: 0.5448
Batch 200, Loss: 0.4736
Batch 210, Loss: 0.5675
Batch 220, Loss: 0.5037
Batch 230, Loss: 0.5123
Batch 240, Loss: 0.5500
Batch 250, Loss: 0.5379
Batch 260, Loss: 0.5308
Batch 270, Loss: 0.5445
Batch 280, Loss: 0.5118
Batch 290, Loss: 0.5090
Batch 300, Loss: 0.5101
Batch 310, Loss: 0.5545
Batch 320, Loss: 0.5367
Batch 330, Loss: 0.5148
Batch 340, Loss: 0.5122
Batch 350, Loss: 0.5020
Batch 360, Loss: 0.5057
Batch 370, Loss: 0.5206
Batch 380, Loss: 0.4906
Batch 390, Loss: 0.5037
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.12206530570984 seconds
Epoch 157 accuracy: 76.17%
Batch 10, Loss: 0.4966
Batch 20, Loss: 0.4476
Batch 30, Loss: 0.4737
Batch 40, Loss: 0.4838
Batch 50, Loss: 0.4652
Batch 60, Loss: 0.5128
Batch 70, Loss: 0.5094
Batch 80, Loss: 0.5259
Batch 90, Loss: 0.4829
Batch 100, Loss: 0.4941
Batch 110, Loss: 0.4705
Batch 120, Loss: 0.4710
Batch 130, Loss: 0.5120
Batch 140, Loss: 0.4680
Batch 150, Loss: 0.4662
Batch 160, Loss: 0.4886
Batch 170, Loss: 0.4869
Batch 180, Loss: 0.5343
Batch 190, Loss: 0.4845
Batch 200, Loss: 0.4587
Batch 210, Loss: 0.4983
Batch 220, Loss: 0.5036
Batch 230, Loss: 0.5043
Batch 240, Loss: 0.5002
Batch 250, Loss: 0.5649
Batch 260, Loss: 0.4656
Batch 270, Loss: 0.4872
Batch 280, Loss: 0.5236
Batch 290, Loss: 0.4913
Batch 300, Loss: 0.5587
Batch 310, Loss: 0.5262
Batch 320, Loss: 0.5322
Batch 330, Loss: 0.5074
Batch 340, Loss: 0.5080
Batch 350, Loss: 0.5106
Batch 360, Loss: 0.5437
Batch 370, Loss: 0.5220
Batch 380, Loss: 0.5108
Batch 390, Loss: 0.5357
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.061768054962158 seconds
Epoch 158 accuracy: 75.18%
Batch 10, Loss: 0.4463
Batch 20, Loss: 0.4542
Batch 30, Loss: 0.4911
Batch 40, Loss: 0.5304
Batch 50, Loss: 0.4780
Batch 60, Loss: 0.4349
Batch 70, Loss: 0.4812
Batch 80, Loss: 0.5134
Batch 90, Loss: 0.4412
Batch 100, Loss: 0.5039
Batch 110, Loss: 0.5031
Batch 120, Loss: 0.4504
Batch 130, Loss: 0.5231
Batch 140, Loss: 0.4811
Batch 150, Loss: 0.5152
Batch 160, Loss: 0.4394
Batch 170, Loss: 0.4679
Batch 180, Loss: 0.4807
Batch 190, Loss: 0.4581
Batch 200, Loss: 0.5147
Batch 210, Loss: 0.5093
Batch 220, Loss: 0.5142
Batch 230, Loss: 0.5332
Batch 240, Loss: 0.4653
Batch 250, Loss: 0.4903
Batch 260, Loss: 0.4741
Batch 270, Loss: 0.4992
Batch 280, Loss: 0.4902
Batch 290, Loss: 0.4679
Batch 300, Loss: 0.4790
Batch 310, Loss: 0.5078
Batch 320, Loss: 0.4918
Batch 330, Loss: 0.4814
Batch 340, Loss: 0.4702
Batch 350, Loss: 0.4416
Batch 360, Loss: 0.5043
Batch 370, Loss: 0.4537
Batch 380, Loss: 0.4940
Batch 390, Loss: 0.5203
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.121888637542725 seconds
Epoch 159 accuracy: 76.49%
Batch 10, Loss: 0.4863
Batch 20, Loss: 0.4906
Batch 30, Loss: 0.4871
Batch 40, Loss: 0.4971
Batch 50, Loss: 0.4706
Batch 60, Loss: 0.4984
Batch 70, Loss: 0.4534
Batch 80, Loss: 0.4717
Batch 90, Loss: 0.4622
Batch 100, Loss: 0.4498
Batch 110, Loss: 0.4752
Batch 120, Loss: 0.4949
Batch 130, Loss: 0.5025
Batch 140, Loss: 0.5118
Batch 150, Loss: 0.4592
Batch 160, Loss: 0.4960
Batch 170, Loss: 0.4735
Batch 180, Loss: 0.4506
Batch 190, Loss: 0.4737
Batch 200, Loss: 0.4728
Batch 210, Loss: 0.4484
Batch 220, Loss: 0.4869
Batch 230, Loss: 0.4583
Batch 240, Loss: 0.4817
Batch 250, Loss: 0.4727
Batch 260, Loss: 0.4783
Batch 270, Loss: 0.4739
Batch 280, Loss: 0.4550
Batch 290, Loss: 0.4683
Batch 300, Loss: 0.4740
Batch 310, Loss: 0.4396
Batch 320, Loss: 0.4654
Batch 330, Loss: 0.4774
Batch 340, Loss: 0.4886
Batch 350, Loss: 0.4826
Batch 360, Loss: 0.4667
Batch 370, Loss: 0.4764
Batch 380, Loss: 0.4576
Batch 390, Loss: 0.4274
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.101737022399902 seconds
Epoch 160 accuracy: 76.49%
Batch 10, Loss: 0.4631
Batch 20, Loss: 0.4257
Batch 30, Loss: 0.4658
Batch 40, Loss: 0.4646
Batch 50, Loss: 0.4470
Batch 60, Loss: 0.4483
Batch 70, Loss: 0.4437
Batch 80, Loss: 0.4429
Batch 90, Loss: 0.4698
Batch 100, Loss: 0.4460
Batch 110, Loss: 0.4204
Batch 120, Loss: 0.4577
Batch 130, Loss: 0.4337
Batch 140, Loss: 0.4552
Batch 150, Loss: 0.4519
Batch 160, Loss: 0.4501
Batch 170, Loss: 0.4415
Batch 180, Loss: 0.5238
Batch 190, Loss: 0.4213
Batch 200, Loss: 0.4703
Batch 210, Loss: 0.4428
Batch 220, Loss: 0.4676
Batch 230, Loss: 0.4452
Batch 240, Loss: 0.4598
Batch 250, Loss: 0.4824
Batch 260, Loss: 0.4604
Batch 270, Loss: 0.4972
Batch 280, Loss: 0.4589
Batch 290, Loss: 0.4294
Batch 300, Loss: 0.4900
Batch 310, Loss: 0.4672
Batch 320, Loss: 0.4388
Batch 330, Loss: 0.4782
Batch 340, Loss: 0.4929
Batch 350, Loss: 0.4869
Batch 360, Loss: 0.4450
Batch 370, Loss: 0.4511
Batch 380, Loss: 0.4446
Batch 390, Loss: 0.5224
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.073785305023193 seconds
Epoch 161 accuracy: 76.34%
Batch 10, Loss: 0.4633
Batch 20, Loss: 0.4493
Batch 30, Loss: 0.4402
Batch 40, Loss: 0.4174
Batch 50, Loss: 0.4810
Batch 60, Loss: 0.3996
Batch 70, Loss: 0.4541
Batch 80, Loss: 0.4278
Batch 90, Loss: 0.4810
Batch 100, Loss: 0.4427
Batch 110, Loss: 0.4893
Batch 120, Loss: 0.4478
Batch 130, Loss: 0.4665
Batch 140, Loss: 0.4705
Batch 150, Loss: 0.4428
Batch 160, Loss: 0.4603
Batch 170, Loss: 0.4601
Batch 180, Loss: 0.4777
Batch 190, Loss: 0.4551
Batch 200, Loss: 0.4828
Batch 210, Loss: 0.4324
Batch 220, Loss: 0.4601
Batch 230, Loss: 0.4626
Batch 240, Loss: 0.4573
Batch 250, Loss: 0.4270
Batch 260, Loss: 0.4228
Batch 270, Loss: 0.4289
Batch 280, Loss: 0.4303
Batch 290, Loss: 0.4768
Batch 300, Loss: 0.4580
Batch 310, Loss: 0.5185
Batch 320, Loss: 0.4716
Batch 330, Loss: 0.4996
Batch 340, Loss: 0.4641
Batch 350, Loss: 0.4745
Batch 360, Loss: 0.4408
Batch 370, Loss: 0.4438
Batch 380, Loss: 0.4794
Batch 390, Loss: 0.4539
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.00333023071289 seconds
Epoch 162 accuracy: 76.68%
Batch 10, Loss: 0.3983
Batch 20, Loss: 0.4146
Batch 30, Loss: 0.4072
Batch 40, Loss: 0.4440
Batch 50, Loss: 0.4003
Batch 60, Loss: 0.4226
Batch 70, Loss: 0.4166
Batch 80, Loss: 0.3878
Batch 90, Loss: 0.4390
Batch 100, Loss: 0.4343
Batch 110, Loss: 0.4509
Batch 120, Loss: 0.4644
Batch 130, Loss: 0.4466
Batch 140, Loss: 0.4468
Batch 150, Loss: 0.4615
Batch 160, Loss: 0.4199
Batch 170, Loss: 0.4370
Batch 180, Loss: 0.4403
Batch 190, Loss: 0.4552
Batch 200, Loss: 0.4474
Batch 210, Loss: 0.4325
Batch 220, Loss: 0.4353
Batch 230, Loss: 0.4326
Batch 240, Loss: 0.4271
Batch 250, Loss: 0.4969
Batch 260, Loss: 0.4649
Batch 270, Loss: 0.4217
Batch 280, Loss: 0.4569
Batch 290, Loss: 0.4339
Batch 300, Loss: 0.4473
Batch 310, Loss: 0.4724
Batch 320, Loss: 0.4330
Batch 330, Loss: 0.4463
Batch 340, Loss: 0.4489
Batch 350, Loss: 0.4218
Batch 360, Loss: 0.4909
Batch 370, Loss: 0.4275
Batch 380, Loss: 0.4757
Batch 390, Loss: 0.4276
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.046611309051514 seconds
Epoch 163 accuracy: 76.87%
Batch 10, Loss: 0.4238
Batch 20, Loss: 0.3977
Batch 30, Loss: 0.4077
Batch 40, Loss: 0.4374
Batch 50, Loss: 0.3916
Batch 60, Loss: 0.3883
Batch 70, Loss: 0.3970
Batch 80, Loss: 0.4305
Batch 90, Loss: 0.4273
Batch 100, Loss: 0.3981
Batch 110, Loss: 0.4322
Batch 120, Loss: 0.4607
Batch 130, Loss: 0.4092
Batch 140, Loss: 0.4392
Batch 150, Loss: 0.4268
Batch 160, Loss: 0.4057
Batch 170, Loss: 0.4127
Batch 180, Loss: 0.4402
Batch 190, Loss: 0.4421
Batch 200, Loss: 0.4313
Batch 210, Loss: 0.4197
Batch 220, Loss: 0.4531
Batch 230, Loss: 0.3983
Batch 240, Loss: 0.4351
Batch 250, Loss: 0.4171
Batch 260, Loss: 0.4381
Batch 270, Loss: 0.4189
Batch 280, Loss: 0.4642
Batch 290, Loss: 0.4304
Batch 300, Loss: 0.4645
Batch 310, Loss: 0.4491
Batch 320, Loss: 0.4174
Batch 330, Loss: 0.4702
Batch 340, Loss: 0.4516
Batch 350, Loss: 0.4431
Batch 360, Loss: 0.4268
Batch 370, Loss: 0.4249
Batch 380, Loss: 0.4441
Batch 390, Loss: 0.4686
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.150310516357422 seconds
Epoch 164 accuracy: 77.23%
Batch 10, Loss: 0.4205
Batch 20, Loss: 0.4328
Batch 30, Loss: 0.4308
Batch 40, Loss: 0.3785
Batch 50, Loss: 0.3840
Batch 60, Loss: 0.4183
Batch 70, Loss: 0.4196
Batch 80, Loss: 0.4291
Batch 90, Loss: 0.4394
Batch 100, Loss: 0.4294
Batch 110, Loss: 0.4050
Batch 120, Loss: 0.4107
Batch 130, Loss: 0.4112
Batch 140, Loss: 0.3704
Batch 150, Loss: 0.4331
Batch 160, Loss: 0.4323
Batch 170, Loss: 0.3964
Batch 180, Loss: 0.4198
Batch 190, Loss: 0.3868
Batch 200, Loss: 0.4223
Batch 210, Loss: 0.4073
Batch 220, Loss: 0.4509
Batch 230, Loss: 0.4021
Batch 240, Loss: 0.4234
Batch 250, Loss: 0.4187
Batch 260, Loss: 0.4134
Batch 270, Loss: 0.4303
Batch 280, Loss: 0.4114
Batch 290, Loss: 0.4086
Batch 300, Loss: 0.3943
Batch 310, Loss: 0.4384
Batch 320, Loss: 0.4474
Batch 330, Loss: 0.3798
Batch 340, Loss: 0.3987
Batch 350, Loss: 0.4118
Batch 360, Loss: 0.4028
Batch 370, Loss: 0.4089
Batch 380, Loss: 0.4369
Batch 390, Loss: 0.4397
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.197317123413086 seconds
Epoch 165 accuracy: 77.14%
Batch 10, Loss: 0.4051
Batch 20, Loss: 0.4509
Batch 30, Loss: 0.4268
Batch 40, Loss: 0.3970
Batch 50, Loss: 0.3965
Batch 60, Loss: 0.4045
Batch 70, Loss: 0.3862
Batch 80, Loss: 0.4274
Batch 90, Loss: 0.3955
Batch 100, Loss: 0.3944
Batch 110, Loss: 0.4159
Batch 120, Loss: 0.4122
Batch 130, Loss: 0.4119
Batch 140, Loss: 0.3897
Batch 150, Loss: 0.4261
Batch 160, Loss: 0.3951
Batch 170, Loss: 0.4286
Batch 180, Loss: 0.3666
Batch 190, Loss: 0.4177
Batch 200, Loss: 0.3937
Batch 210, Loss: 0.4043
Batch 220, Loss: 0.4139
Batch 230, Loss: 0.4262
Batch 240, Loss: 0.3729
Batch 250, Loss: 0.3848
Batch 260, Loss: 0.4181
Batch 270, Loss: 0.4146
Batch 280, Loss: 0.4303
Batch 290, Loss: 0.4490
Batch 300, Loss: 0.4435
Batch 310, Loss: 0.4341
Batch 320, Loss: 0.4694
Batch 330, Loss: 0.4639
Batch 340, Loss: 0.4262
Batch 350, Loss: 0.3634
Batch 360, Loss: 0.4435
Batch 370, Loss: 0.4366
Batch 380, Loss: 0.4268
Batch 390, Loss: 0.4318
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.044109582901 seconds
Epoch 166 accuracy: 76.59%
Batch 10, Loss: 0.4117
Batch 20, Loss: 0.3924
Batch 30, Loss: 0.3965
Batch 40, Loss: 0.3755
Batch 50, Loss: 0.3983
Batch 60, Loss: 0.3901
Batch 70, Loss: 0.3850
Batch 80, Loss: 0.3616
Batch 90, Loss: 0.3674
Batch 100, Loss: 0.4073
Batch 110, Loss: 0.3864
Batch 120, Loss: 0.3949
Batch 130, Loss: 0.3705
Batch 140, Loss: 0.4085
Batch 150, Loss: 0.3500
Batch 160, Loss: 0.4108
Batch 170, Loss: 0.4167
Batch 180, Loss: 0.3810
Batch 190, Loss: 0.3870
Batch 200, Loss: 0.3523
Batch 210, Loss: 0.3969
Batch 220, Loss: 0.4431
Batch 230, Loss: 0.4082
Batch 240, Loss: 0.3927
Batch 250, Loss: 0.4166
Batch 260, Loss: 0.4228
Batch 270, Loss: 0.4086
Batch 280, Loss: 0.3880
Batch 290, Loss: 0.3888
Batch 300, Loss: 0.4042
Batch 310, Loss: 0.3938
Batch 320, Loss: 0.3744
Batch 330, Loss: 0.4439
Batch 340, Loss: 0.4067
Batch 350, Loss: 0.3714
Batch 360, Loss: 0.4124
Batch 370, Loss: 0.4062
Batch 380, Loss: 0.4085
Batch 390, Loss: 0.4391
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.03104543685913 seconds
Epoch 167 accuracy: 77.7%
Batch 10, Loss: 0.3651
Batch 20, Loss: 0.4240
Batch 30, Loss: 0.3981
Batch 40, Loss: 0.3975
Batch 50, Loss: 0.4000
Batch 60, Loss: 0.4247
Batch 70, Loss: 0.4099
Batch 80, Loss: 0.3495
Batch 90, Loss: 0.3988
Batch 100, Loss: 0.3746
Batch 110, Loss: 0.3626
Batch 120, Loss: 0.3979
Batch 130, Loss: 0.3712
Batch 140, Loss: 0.3699
Batch 150, Loss: 0.3941
Batch 160, Loss: 0.4009
Batch 170, Loss: 0.3719
Batch 180, Loss: 0.3864
Batch 190, Loss: 0.4064
Batch 200, Loss: 0.3607
Batch 210, Loss: 0.4126
Batch 220, Loss: 0.3649
Batch 230, Loss: 0.3984
Batch 240, Loss: 0.3586
Batch 250, Loss: 0.4001
Batch 260, Loss: 0.3803
Batch 270, Loss: 0.3871
Batch 280, Loss: 0.3863
Batch 290, Loss: 0.3860
Batch 300, Loss: 0.3701
Batch 310, Loss: 0.4030
Batch 320, Loss: 0.4317
Batch 330, Loss: 0.4062
Batch 340, Loss: 0.3872
Batch 350, Loss: 0.4202
Batch 360, Loss: 0.4014
Batch 370, Loss: 0.4160
Batch 380, Loss: 0.4007
Batch 390, Loss: 0.3862
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.06394672393799 seconds
Epoch 168 accuracy: 77.39%
Batch 10, Loss: 0.3962
Batch 20, Loss: 0.4347
Batch 30, Loss: 0.3815
Batch 40, Loss: 0.3996
Batch 50, Loss: 0.3599
Batch 60, Loss: 0.3773
Batch 70, Loss: 0.3610
Batch 80, Loss: 0.4134
Batch 90, Loss: 0.3532
Batch 100, Loss: 0.3792
Batch 110, Loss: 0.3966
Batch 120, Loss: 0.3924
Batch 130, Loss: 0.3377
Batch 140, Loss: 0.3629
Batch 150, Loss: 0.3455
Batch 160, Loss: 0.3960
Batch 170, Loss: 0.3680
Batch 180, Loss: 0.3521
Batch 190, Loss: 0.3812
Batch 200, Loss: 0.3906
Batch 210, Loss: 0.3983
Batch 220, Loss: 0.3743
Batch 230, Loss: 0.3932
Batch 240, Loss: 0.3642
Batch 250, Loss: 0.3527
Batch 260, Loss: 0.3714
Batch 270, Loss: 0.3817
Batch 280, Loss: 0.3678
Batch 290, Loss: 0.3604
Batch 300, Loss: 0.4147
Batch 310, Loss: 0.3784
Batch 320, Loss: 0.3539
Batch 330, Loss: 0.3431
Batch 340, Loss: 0.3987
Batch 350, Loss: 0.3952
Batch 360, Loss: 0.4022
Batch 370, Loss: 0.3853
Batch 380, Loss: 0.3930
Batch 390, Loss: 0.3842
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.09292483329773 seconds
Epoch 169 accuracy: 77.87%
Batch 10, Loss: 0.3753
Batch 20, Loss: 0.3665
Batch 30, Loss: 0.3494
Batch 40, Loss: 0.3407
Batch 50, Loss: 0.3364
Batch 60, Loss: 0.3389
Batch 70, Loss: 0.3550
Batch 80, Loss: 0.3619
Batch 90, Loss: 0.3523
Batch 100, Loss: 0.3734
Batch 110, Loss: 0.3781
Batch 120, Loss: 0.3458
Batch 130, Loss: 0.3411
Batch 140, Loss: 0.3561
Batch 150, Loss: 0.3549
Batch 160, Loss: 0.3789
Batch 170, Loss: 0.3418
Batch 180, Loss: 0.3632
Batch 190, Loss: 0.4139
Batch 200, Loss: 0.3533
Batch 210, Loss: 0.3883
Batch 220, Loss: 0.3734
Batch 230, Loss: 0.3693
Batch 240, Loss: 0.3499
Batch 250, Loss: 0.3640
Batch 260, Loss: 0.3813
Batch 270, Loss: 0.3863
Batch 280, Loss: 0.3565
Batch 290, Loss: 0.3391
Batch 300, Loss: 0.3894
Batch 310, Loss: 0.3519
Batch 320, Loss: 0.3623
Batch 330, Loss: 0.3593
Batch 340, Loss: 0.3677
Batch 350, Loss: 0.4054
Batch 360, Loss: 0.3537
Batch 370, Loss: 0.4056
Batch 380, Loss: 0.3803
Batch 390, Loss: 0.3650
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.04534673690796 seconds
Epoch 170 accuracy: 78.33%
Batch 10, Loss: 0.3484
Batch 20, Loss: 0.3643
Batch 30, Loss: 0.3369
Batch 40, Loss: 0.3458
Batch 50, Loss: 0.3590
Batch 60, Loss: 0.3206
Batch 70, Loss: 0.3769
Batch 80, Loss: 0.3392
Batch 90, Loss: 0.3942
Batch 100, Loss: 0.3828
Batch 110, Loss: 0.3509
Batch 120, Loss: 0.3576
Batch 130, Loss: 0.3529
Batch 140, Loss: 0.3575
Batch 150, Loss: 0.3388
Batch 160, Loss: 0.3496
Batch 170, Loss: 0.3831
Batch 180, Loss: 0.3820
Batch 190, Loss: 0.3836
Batch 200, Loss: 0.3793
Batch 210, Loss: 0.3479
Batch 220, Loss: 0.3834
Batch 230, Loss: 0.3606
Batch 240, Loss: 0.3739
Batch 250, Loss: 0.3457
Batch 260, Loss: 0.3619
Batch 270, Loss: 0.3974
Batch 280, Loss: 0.3985
Batch 290, Loss: 0.3637
Batch 300, Loss: 0.3837
Batch 310, Loss: 0.3761
Batch 320, Loss: 0.3809
Batch 330, Loss: 0.3837
Batch 340, Loss: 0.3338
Batch 350, Loss: 0.3555
Batch 360, Loss: 0.4236
Batch 370, Loss: 0.3931
Batch 380, Loss: 0.3612
Batch 390, Loss: 0.3558
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 24.990963220596313 seconds
Epoch 171 accuracy: 78.08%
Batch 10, Loss: 0.3467
Batch 20, Loss: 0.3602
Batch 30, Loss: 0.3377
Batch 40, Loss: 0.3483
Batch 50, Loss: 0.3230
Batch 60, Loss: 0.3628
Batch 70, Loss: 0.3098
Batch 80, Loss: 0.3404
Batch 90, Loss: 0.3593
Batch 100, Loss: 0.3618
Batch 110, Loss: 0.3465
Batch 120, Loss: 0.3469
Batch 130, Loss: 0.3514
Batch 140, Loss: 0.3553
Batch 150, Loss: 0.3532
Batch 160, Loss: 0.3343
Batch 170, Loss: 0.3645
Batch 180, Loss: 0.3680
Batch 190, Loss: 0.3652
Batch 200, Loss: 0.3597
Batch 210, Loss: 0.3434
Batch 220, Loss: 0.3529
Batch 230, Loss: 0.3760
Batch 240, Loss: 0.3470
Batch 250, Loss: 0.3702
Batch 260, Loss: 0.3323
Batch 270, Loss: 0.3667
Batch 280, Loss: 0.3393
Batch 290, Loss: 0.3497
Batch 300, Loss: 0.3561
Batch 310, Loss: 0.3361
Batch 320, Loss: 0.3213
Batch 330, Loss: 0.3358
Batch 340, Loss: 0.3534
Batch 350, Loss: 0.3642
Batch 360, Loss: 0.3497
Batch 370, Loss: 0.3667
Batch 380, Loss: 0.4012
Batch 390, Loss: 0.3411
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.11002278327942 seconds
Epoch 172 accuracy: 78.19%
Batch 10, Loss: 0.3363
Batch 20, Loss: 0.3275
Batch 30, Loss: 0.3002
Batch 40, Loss: 0.3566
Batch 50, Loss: 0.3341
Batch 60, Loss: 0.3673
Batch 70, Loss: 0.3061
Batch 80, Loss: 0.3647
Batch 90, Loss: 0.3525
Batch 100, Loss: 0.3817
Batch 110, Loss: 0.3390
Batch 120, Loss: 0.3217
Batch 130, Loss: 0.3826
Batch 140, Loss: 0.3170
Batch 150, Loss: 0.3658
Batch 160, Loss: 0.3313
Batch 170, Loss: 0.3222
Batch 180, Loss: 0.3183
Batch 190, Loss: 0.3917
Batch 200, Loss: 0.3186
Batch 210, Loss: 0.3268
Batch 220, Loss: 0.3630
Batch 230, Loss: 0.3495
Batch 240, Loss: 0.3204
Batch 250, Loss: 0.3890
Batch 260, Loss: 0.3404
Batch 270, Loss: 0.3620
Batch 280, Loss: 0.3544
Batch 290, Loss: 0.3475
Batch 300, Loss: 0.3408
Batch 310, Loss: 0.3219
Batch 320, Loss: 0.3812
Batch 330, Loss: 0.3290
Batch 340, Loss: 0.3828
Batch 350, Loss: 0.3471
Batch 360, Loss: 0.3876
Batch 370, Loss: 0.3827
Batch 380, Loss: 0.3323
Batch 390, Loss: 0.3611
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.117295265197754 seconds
Epoch 173 accuracy: 78.61%
Batch 10, Loss: 0.3395
Batch 20, Loss: 0.3242
Batch 30, Loss: 0.3465
Batch 40, Loss: 0.3161
Batch 50, Loss: 0.3365
Batch 60, Loss: 0.3006
Batch 70, Loss: 0.3760
Batch 80, Loss: 0.3533
Batch 90, Loss: 0.3375
Batch 100, Loss: 0.3460
Batch 110, Loss: 0.3245
Batch 120, Loss: 0.3487
Batch 130, Loss: 0.3579
Batch 140, Loss: 0.3562
Batch 150, Loss: 0.3294
Batch 160, Loss: 0.3155
Batch 170, Loss: 0.3356
Batch 180, Loss: 0.3203
Batch 190, Loss: 0.3466
Batch 200, Loss: 0.3280
Batch 210, Loss: 0.2946
Batch 220, Loss: 0.3454
Batch 230, Loss: 0.3423
Batch 240, Loss: 0.3618
Batch 250, Loss: 0.3151
Batch 260, Loss: 0.2988
Batch 270, Loss: 0.3596
Batch 280, Loss: 0.3295
Batch 290, Loss: 0.3197
Batch 300, Loss: 0.3212
Batch 310, Loss: 0.3626
Batch 320, Loss: 0.3467
Batch 330, Loss: 0.3181
Batch 340, Loss: 0.3371
Batch 350, Loss: 0.3497
Batch 360, Loss: 0.3256
Batch 370, Loss: 0.3413
Batch 380, Loss: 0.3143
Batch 390, Loss: 0.3372
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.050429821014404 seconds
Epoch 174 accuracy: 78.79%
Batch 10, Loss: 0.3130
Batch 20, Loss: 0.3292
Batch 30, Loss: 0.3308
Batch 40, Loss: 0.2950
Batch 50, Loss: 0.3605
Batch 60, Loss: 0.3272
Batch 70, Loss: 0.2909
Batch 80, Loss: 0.3190
Batch 90, Loss: 0.3355
Batch 100, Loss: 0.3202
Batch 110, Loss: 0.3722
Batch 120, Loss: 0.3264
Batch 130, Loss: 0.3490
Batch 140, Loss: 0.3244
Batch 150, Loss: 0.3696
Batch 160, Loss: 0.3053
Batch 170, Loss: 0.3176
Batch 180, Loss: 0.3316
Batch 190, Loss: 0.3286
Batch 200, Loss: 0.3244
Batch 210, Loss: 0.3199
Batch 220, Loss: 0.3215
Batch 230, Loss: 0.3342
Batch 240, Loss: 0.3342
Batch 250, Loss: 0.3446
Batch 260, Loss: 0.2917
Batch 270, Loss: 0.3358
Batch 280, Loss: 0.3269
Batch 290, Loss: 0.3477
Batch 300, Loss: 0.3384
Batch 310, Loss: 0.3073
Batch 320, Loss: 0.3343
Batch 330, Loss: 0.3759
Batch 340, Loss: 0.3118
Batch 350, Loss: 0.3436
Batch 360, Loss: 0.3268
Batch 370, Loss: 0.3429
Batch 380, Loss: 0.3128
Batch 390, Loss: 0.3109
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.072932243347168 seconds
Epoch 175 accuracy: 78.81%
Batch 10, Loss: 0.3140
Batch 20, Loss: 0.3292
Batch 30, Loss: 0.3354
Batch 40, Loss: 0.2948
Batch 50, Loss: 0.3514
Batch 60, Loss: 0.3120
Batch 70, Loss: 0.2972
Batch 80, Loss: 0.2999
Batch 90, Loss: 0.3429
Batch 100, Loss: 0.3247
Batch 110, Loss: 0.2860
Batch 120, Loss: 0.3225
Batch 130, Loss: 0.3294
Batch 140, Loss: 0.2962
Batch 150, Loss: 0.3321
Batch 160, Loss: 0.3310
Batch 170, Loss: 0.3164
Batch 180, Loss: 0.3392
Batch 190, Loss: 0.3498
Batch 200, Loss: 0.2830
Batch 210, Loss: 0.3409
Batch 220, Loss: 0.3147
Batch 230, Loss: 0.3365
Batch 240, Loss: 0.3048
Batch 250, Loss: 0.2920
Batch 260, Loss: 0.3076
Batch 270, Loss: 0.2783
Batch 280, Loss: 0.3294
Batch 290, Loss: 0.3249
Batch 300, Loss: 0.3172
Batch 310, Loss: 0.3377
Batch 320, Loss: 0.3074
Batch 330, Loss: 0.3406
Batch 340, Loss: 0.2971
Batch 350, Loss: 0.3092
Batch 360, Loss: 0.3099
Batch 370, Loss: 0.3198
Batch 380, Loss: 0.3249
Batch 390, Loss: 0.3273
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.110945463180542 seconds
Epoch 176 accuracy: 79.05%
Batch 10, Loss: 0.2942
Batch 20, Loss: 0.3117
Batch 30, Loss: 0.3388
Batch 40, Loss: 0.3091
Batch 50, Loss: 0.2800
Batch 60, Loss: 0.3155
Batch 70, Loss: 0.2888
Batch 80, Loss: 0.3007
Batch 90, Loss: 0.3152
Batch 100, Loss: 0.2999
Batch 110, Loss: 0.3421
Batch 120, Loss: 0.3061
Batch 130, Loss: 0.2986
Batch 140, Loss: 0.3150
Batch 150, Loss: 0.3173
Batch 160, Loss: 0.3183
Batch 170, Loss: 0.3198
Batch 180, Loss: 0.2969
Batch 190, Loss: 0.3161
Batch 200, Loss: 0.3369
Batch 210, Loss: 0.2952
Batch 220, Loss: 0.3281
Batch 230, Loss: 0.2974
Batch 240, Loss: 0.3317
Batch 250, Loss: 0.2847
Batch 260, Loss: 0.3242
Batch 270, Loss: 0.3056
Batch 280, Loss: 0.3468
Batch 290, Loss: 0.3312
Batch 300, Loss: 0.3047
Batch 310, Loss: 0.3173
Batch 320, Loss: 0.3273
Batch 330, Loss: 0.3007
Batch 340, Loss: 0.3323
Batch 350, Loss: 0.3073
Batch 360, Loss: 0.3153
Batch 370, Loss: 0.3489
Batch 380, Loss: 0.3084
Batch 390, Loss: 0.3522
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.143194913864136 seconds
Epoch 177 accuracy: 79.11%
Batch 10, Loss: 0.3020
Batch 20, Loss: 0.2733
Batch 30, Loss: 0.3409
Batch 40, Loss: 0.3009
Batch 50, Loss: 0.3048
Batch 60, Loss: 0.2577
Batch 70, Loss: 0.3026
Batch 80, Loss: 0.2911
Batch 90, Loss: 0.3227
Batch 100, Loss: 0.2943
Batch 110, Loss: 0.2800
Batch 120, Loss: 0.2897
Batch 130, Loss: 0.2981
Batch 140, Loss: 0.3072
Batch 150, Loss: 0.3035
Batch 160, Loss: 0.2837
Batch 170, Loss: 0.3069
Batch 180, Loss: 0.2920
Batch 190, Loss: 0.2818
Batch 200, Loss: 0.3511
Batch 210, Loss: 0.3095
Batch 220, Loss: 0.2734
Batch 230, Loss: 0.3241
Batch 240, Loss: 0.3201
Batch 250, Loss: 0.3234
Batch 260, Loss: 0.2982
Batch 270, Loss: 0.3139
Batch 280, Loss: 0.2797
Batch 290, Loss: 0.3261
Batch 300, Loss: 0.3135
Batch 310, Loss: 0.2973
Batch 320, Loss: 0.3051
Batch 330, Loss: 0.2846
Batch 340, Loss: 0.2932
Batch 350, Loss: 0.3118
Batch 360, Loss: 0.2708
Batch 370, Loss: 0.3185
Batch 380, Loss: 0.2994
Batch 390, Loss: 0.3252
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 24.997855186462402 seconds
Epoch 178 accuracy: 79.42%
Batch 10, Loss: 0.2952
Batch 20, Loss: 0.3268
Batch 30, Loss: 0.2792
Batch 40, Loss: 0.2824
Batch 50, Loss: 0.2937
Batch 60, Loss: 0.2886
Batch 70, Loss: 0.3120
Batch 80, Loss: 0.3009
Batch 90, Loss: 0.2722
Batch 100, Loss: 0.3058
Batch 110, Loss: 0.3246
Batch 120, Loss: 0.2965
Batch 130, Loss: 0.3031
Batch 140, Loss: 0.3084
Batch 150, Loss: 0.2536
Batch 160, Loss: 0.2686
Batch 170, Loss: 0.3108
Batch 180, Loss: 0.3203
Batch 190, Loss: 0.2967
Batch 200, Loss: 0.2828
Batch 210, Loss: 0.2724
Batch 220, Loss: 0.2839
Batch 230, Loss: 0.3044
Batch 240, Loss: 0.2959
Batch 250, Loss: 0.3121
Batch 260, Loss: 0.3002
Batch 270, Loss: 0.2771
Batch 280, Loss: 0.3324
Batch 290, Loss: 0.3105
Batch 300, Loss: 0.2954
Batch 310, Loss: 0.3213
Batch 320, Loss: 0.3047
Batch 330, Loss: 0.3175
Batch 340, Loss: 0.2873
Batch 350, Loss: 0.2904
Batch 360, Loss: 0.2824
Batch 370, Loss: 0.3012
Batch 380, Loss: 0.3138
Batch 390, Loss: 0.2896
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.03450322151184 seconds
Epoch 179 accuracy: 79.57%
Batch 10, Loss: 0.3018
Batch 20, Loss: 0.2975
Batch 30, Loss: 0.2775
Batch 40, Loss: 0.2994
Batch 50, Loss: 0.3377
Batch 60, Loss: 0.3057
Batch 70, Loss: 0.2946
Batch 80, Loss: 0.2868
Batch 90, Loss: 0.3097
Batch 100, Loss: 0.2898
Batch 110, Loss: 0.2602
Batch 120, Loss: 0.2705
Batch 130, Loss: 0.2840
Batch 140, Loss: 0.2720
Batch 150, Loss: 0.2822
Batch 160, Loss: 0.2747
Batch 170, Loss: 0.2860
Batch 180, Loss: 0.2665
Batch 190, Loss: 0.2740
Batch 200, Loss: 0.2928
Batch 210, Loss: 0.2881
Batch 220, Loss: 0.2743
Batch 230, Loss: 0.2831
Batch 240, Loss: 0.2836
Batch 250, Loss: 0.2881
Batch 260, Loss: 0.2909
Batch 270, Loss: 0.3135
Batch 280, Loss: 0.2827
Batch 290, Loss: 0.3019
Batch 300, Loss: 0.2917
Batch 310, Loss: 0.3181
Batch 320, Loss: 0.2844
Batch 330, Loss: 0.3120
Batch 340, Loss: 0.2756
Batch 350, Loss: 0.2707
Batch 360, Loss: 0.2996
Batch 370, Loss: 0.3109
Batch 380, Loss: 0.3051
Batch 390, Loss: 0.3126
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 24.956082105636597 seconds
Epoch 180 accuracy: 79.55%
Batch 10, Loss: 0.3082
Batch 20, Loss: 0.3125
Batch 30, Loss: 0.2969
Batch 40, Loss: 0.2730
Batch 50, Loss: 0.3040
Batch 60, Loss: 0.2367
Batch 70, Loss: 0.2871
Batch 80, Loss: 0.2884
Batch 90, Loss: 0.2534
Batch 100, Loss: 0.2931
Batch 110, Loss: 0.2681
Batch 120, Loss: 0.2753
Batch 130, Loss: 0.2744
Batch 140, Loss: 0.3029
Batch 150, Loss: 0.2633
Batch 160, Loss: 0.2923
Batch 170, Loss: 0.2992
Batch 180, Loss: 0.2785
Batch 190, Loss: 0.2751
Batch 200, Loss: 0.3008
Batch 210, Loss: 0.2949
Batch 220, Loss: 0.2814
Batch 230, Loss: 0.2599
Batch 240, Loss: 0.2983
Batch 250, Loss: 0.2881
Batch 260, Loss: 0.2670
Batch 270, Loss: 0.3002
Batch 280, Loss: 0.2379
Batch 290, Loss: 0.2856
Batch 300, Loss: 0.2860
Batch 310, Loss: 0.2661
Batch 320, Loss: 0.2732
Batch 330, Loss: 0.2950
Batch 340, Loss: 0.2948
Batch 350, Loss: 0.2682
Batch 360, Loss: 0.2972
Batch 370, Loss: 0.2861
Batch 380, Loss: 0.3191
Batch 390, Loss: 0.2833
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.066943168640137 seconds
Epoch 181 accuracy: 79.52%
Batch 10, Loss: 0.2834
Batch 20, Loss: 0.2705
Batch 30, Loss: 0.2835
Batch 40, Loss: 0.2707
Batch 50, Loss: 0.2659
Batch 60, Loss: 0.2568
Batch 70, Loss: 0.2673
Batch 80, Loss: 0.2538
Batch 90, Loss: 0.2546
Batch 100, Loss: 0.2923
Batch 110, Loss: 0.2792
Batch 120, Loss: 0.2803
Batch 130, Loss: 0.2906
Batch 140, Loss: 0.2903
Batch 150, Loss: 0.3042
Batch 160, Loss: 0.2726
Batch 170, Loss: 0.2993
Batch 180, Loss: 0.2721
Batch 190, Loss: 0.2865
Batch 200, Loss: 0.3027
Batch 210, Loss: 0.2719
Batch 220, Loss: 0.2568
Batch 230, Loss: 0.3057
Batch 240, Loss: 0.2602
Batch 250, Loss: 0.2775
Batch 260, Loss: 0.2764
Batch 270, Loss: 0.2671
Batch 280, Loss: 0.2661
Batch 290, Loss: 0.2548
Batch 300, Loss: 0.2877
Batch 310, Loss: 0.3018
Batch 320, Loss: 0.3025
Batch 330, Loss: 0.2943
Batch 340, Loss: 0.2999
Batch 350, Loss: 0.2437
Batch 360, Loss: 0.2862
Batch 370, Loss: 0.3008
Batch 380, Loss: 0.2707
Batch 390, Loss: 0.2975
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.11283016204834 seconds
Epoch 182 accuracy: 79.58%
Batch 10, Loss: 0.2639
Batch 20, Loss: 0.3028
Batch 30, Loss: 0.2601
Batch 40, Loss: 0.2512
Batch 50, Loss: 0.2648
Batch 60, Loss: 0.3025
Batch 70, Loss: 0.2670
Batch 80, Loss: 0.2472
Batch 90, Loss: 0.2795
Batch 100, Loss: 0.2924
Batch 110, Loss: 0.2562
Batch 120, Loss: 0.2552
Batch 130, Loss: 0.2664
Batch 140, Loss: 0.2654
Batch 150, Loss: 0.2858
Batch 160, Loss: 0.2773
Batch 170, Loss: 0.2558
Batch 180, Loss: 0.2571
Batch 190, Loss: 0.2730
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2769
Batch 220, Loss: 0.2698
Batch 230, Loss: 0.2779
Batch 240, Loss: 0.2584
Batch 250, Loss: 0.2964
Batch 260, Loss: 0.2863
Batch 270, Loss: 0.2561
Batch 280, Loss: 0.2800
Batch 290, Loss: 0.2527
Batch 300, Loss: 0.2693
Batch 310, Loss: 0.3110
Batch 320, Loss: 0.2661
Batch 330, Loss: 0.2895
Batch 340, Loss: 0.2753
Batch 350, Loss: 0.2724
Batch 360, Loss: 0.2781
Batch 370, Loss: 0.2820
Batch 380, Loss: 0.2490
Batch 390, Loss: 0.2463
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.087613344192505 seconds
Epoch 183 accuracy: 79.76%
Batch 10, Loss: 0.2777
Batch 20, Loss: 0.3035
Batch 30, Loss: 0.2592
Batch 40, Loss: 0.2874
Batch 50, Loss: 0.3059
Batch 60, Loss: 0.2969
Batch 70, Loss: 0.3120
Batch 80, Loss: 0.2885
Batch 90, Loss: 0.2696
Batch 100, Loss: 0.2682
Batch 110, Loss: 0.2716
Batch 120, Loss: 0.2859
Batch 130, Loss: 0.2630
Batch 140, Loss: 0.2699
Batch 150, Loss: 0.2554
Batch 160, Loss: 0.2808
Batch 170, Loss: 0.2917
Batch 180, Loss: 0.2964
Batch 190, Loss: 0.2540
Batch 200, Loss: 0.2447
Batch 210, Loss: 0.2581
Batch 220, Loss: 0.2909
Batch 230, Loss: 0.2616
Batch 240, Loss: 0.2575
Batch 250, Loss: 0.2852
Batch 260, Loss: 0.2863
Batch 270, Loss: 0.2692
Batch 280, Loss: 0.2522
Batch 290, Loss: 0.2433
Batch 300, Loss: 0.2926
Batch 310, Loss: 0.2838
Batch 320, Loss: 0.3053
Batch 330, Loss: 0.2879
Batch 340, Loss: 0.2861
Batch 350, Loss: 0.2626
Batch 360, Loss: 0.2799
Batch 370, Loss: 0.2762
Batch 380, Loss: 0.2718
Batch 390, Loss: 0.2850
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.014020681381226 seconds
Epoch 184 accuracy: 79.79%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2445
Batch 30, Loss: 0.2493
Batch 40, Loss: 0.2462
Batch 50, Loss: 0.2717
Batch 60, Loss: 0.3106
Batch 70, Loss: 0.2777
Batch 80, Loss: 0.2530
Batch 90, Loss: 0.2462
Batch 100, Loss: 0.2601
Batch 110, Loss: 0.2640
Batch 120, Loss: 0.2741
Batch 130, Loss: 0.2559
Batch 140, Loss: 0.2639
Batch 150, Loss: 0.2852
Batch 160, Loss: 0.2470
Batch 170, Loss: 0.2527
Batch 180, Loss: 0.2694
Batch 190, Loss: 0.2544
Batch 200, Loss: 0.2352
Batch 210, Loss: 0.2544
Batch 220, Loss: 0.2774
Batch 230, Loss: 0.2547
Batch 240, Loss: 0.2570
Batch 250, Loss: 0.2877
Batch 260, Loss: 0.2711
Batch 270, Loss: 0.2451
Batch 280, Loss: 0.2822
Batch 290, Loss: 0.2742
Batch 300, Loss: 0.2642
Batch 310, Loss: 0.2920
Batch 320, Loss: 0.2878
Batch 330, Loss: 0.2836
Batch 340, Loss: 0.2830
Batch 350, Loss: 0.2869
Batch 360, Loss: 0.2784
Batch 370, Loss: 0.2583
Batch 380, Loss: 0.2754
Batch 390, Loss: 0.2238
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.097311973571777 seconds
Epoch 185 accuracy: 79.98%
Batch 10, Loss: 0.2752
Batch 20, Loss: 0.2395
Batch 30, Loss: 0.2691
Batch 40, Loss: 0.2551
Batch 50, Loss: 0.2773
Batch 60, Loss: 0.2413
Batch 70, Loss: 0.2771
Batch 80, Loss: 0.2621
Batch 90, Loss: 0.2615
Batch 100, Loss: 0.2697
Batch 110, Loss: 0.2415
Batch 120, Loss: 0.2909
Batch 130, Loss: 0.2521
Batch 140, Loss: 0.2620
Batch 150, Loss: 0.2536
Batch 160, Loss: 0.2617
Batch 170, Loss: 0.2615
Batch 180, Loss: 0.2647
Batch 190, Loss: 0.2513
Batch 200, Loss: 0.2725
Batch 210, Loss: 0.2519
Batch 220, Loss: 0.2315
Batch 230, Loss: 0.2495
Batch 240, Loss: 0.2605
Batch 250, Loss: 0.2633
Batch 260, Loss: 0.2433
Batch 270, Loss: 0.2502
Batch 280, Loss: 0.2595
Batch 290, Loss: 0.2469
Batch 300, Loss: 0.2443
Batch 310, Loss: 0.2780
Batch 320, Loss: 0.2764
Batch 330, Loss: 0.2589
Batch 340, Loss: 0.2511
Batch 350, Loss: 0.2294
Batch 360, Loss: 0.2720
Batch 370, Loss: 0.2605
Batch 380, Loss: 0.2459
Batch 390, Loss: 0.2505
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.086438417434692 seconds
Epoch 186 accuracy: 79.76%
Batch 10, Loss: 0.2465
Batch 20, Loss: 0.2482
Batch 30, Loss: 0.2640
Batch 40, Loss: 0.2767
Batch 50, Loss: 0.2709
Batch 60, Loss: 0.2477
Batch 70, Loss: 0.2316
Batch 80, Loss: 0.2594
Batch 90, Loss: 0.2454
Batch 100, Loss: 0.2863
Batch 110, Loss: 0.2627
Batch 120, Loss: 0.2755
Batch 130, Loss: 0.2425
Batch 140, Loss: 0.2578
Batch 150, Loss: 0.2805
Batch 160, Loss: 0.2550
Batch 170, Loss: 0.2680
Batch 180, Loss: 0.2410
Batch 190, Loss: 0.2750
Batch 200, Loss: 0.2631
Batch 210, Loss: 0.2575
Batch 220, Loss: 0.2427
Batch 230, Loss: 0.2749
Batch 240, Loss: 0.2419
Batch 250, Loss: 0.2593
Batch 260, Loss: 0.2481
Batch 270, Loss: 0.2532
Batch 280, Loss: 0.2576
Batch 290, Loss: 0.2610
Batch 300, Loss: 0.2714
Batch 310, Loss: 0.2396
Batch 320, Loss: 0.2533
Batch 330, Loss: 0.2484
Batch 340, Loss: 0.2363
Batch 350, Loss: 0.2449
Batch 360, Loss: 0.2635
Batch 370, Loss: 0.2713
Batch 380, Loss: 0.2586
Batch 390, Loss: 0.2580
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 24.921918392181396 seconds
Epoch 187 accuracy: 79.82%
Batch 10, Loss: 0.2418
Batch 20, Loss: 0.2626
Batch 30, Loss: 0.2274
Batch 40, Loss: 0.2640
Batch 50, Loss: 0.2558
Batch 60, Loss: 0.2520
Batch 70, Loss: 0.2622
Batch 80, Loss: 0.2512
Batch 90, Loss: 0.2336
Batch 100, Loss: 0.2797
Batch 110, Loss: 0.2593
Batch 120, Loss: 0.2603
Batch 130, Loss: 0.2256
Batch 140, Loss: 0.2810
Batch 150, Loss: 0.2506
Batch 160, Loss: 0.2194
Batch 170, Loss: 0.2860
Batch 180, Loss: 0.2659
Batch 190, Loss: 0.2569
Batch 200, Loss: 0.2612
Batch 210, Loss: 0.2330
Batch 220, Loss: 0.2548
Batch 230, Loss: 0.2610
Batch 240, Loss: 0.2418
Batch 250, Loss: 0.2592
Batch 260, Loss: 0.2652
Batch 270, Loss: 0.2516
Batch 280, Loss: 0.2569
Batch 290, Loss: 0.2582
Batch 300, Loss: 0.2447
Batch 310, Loss: 0.2641
Batch 320, Loss: 0.2510
Batch 330, Loss: 0.2564
Batch 340, Loss: 0.2469
Batch 350, Loss: 0.2371
Batch 360, Loss: 0.2300
Batch 370, Loss: 0.2593
Batch 380, Loss: 0.2829
Batch 390, Loss: 0.2695
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.021573543548584 seconds
Epoch 188 accuracy: 79.83%
Batch 10, Loss: 0.2468
Batch 20, Loss: 0.2203
Batch 30, Loss: 0.2397
Batch 40, Loss: 0.2429
Batch 50, Loss: 0.2574
Batch 60, Loss: 0.2787
Batch 70, Loss: 0.2374
Batch 80, Loss: 0.2312
Batch 90, Loss: 0.3136
Batch 100, Loss: 0.2628
Batch 110, Loss: 0.2384
Batch 120, Loss: 0.2331
Batch 130, Loss: 0.2669
Batch 140, Loss: 0.2470
Batch 150, Loss: 0.2822
Batch 160, Loss: 0.2470
Batch 170, Loss: 0.2566
Batch 180, Loss: 0.2186
Batch 190, Loss: 0.2642
Batch 200, Loss: 0.2357
Batch 210, Loss: 0.2623
Batch 220, Loss: 0.2613
Batch 230, Loss: 0.2456
Batch 240, Loss: 0.2575
Batch 250, Loss: 0.2634
Batch 260, Loss: 0.2510
Batch 270, Loss: 0.2706
Batch 280, Loss: 0.2171
Batch 290, Loss: 0.2474
Batch 300, Loss: 0.2627
Batch 310, Loss: 0.2685
Batch 320, Loss: 0.2523
Batch 330, Loss: 0.2443
Batch 340, Loss: 0.2771
Batch 350, Loss: 0.2431
Batch 360, Loss: 0.2512
Batch 370, Loss: 0.2353
Batch 380, Loss: 0.2171
Batch 390, Loss: 0.2390
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.0474796295166 seconds
Epoch 189 accuracy: 80.13%
Batch 10, Loss: 0.2345
Batch 20, Loss: 0.2180
Batch 30, Loss: 0.2537
Batch 40, Loss: 0.2448
Batch 50, Loss: 0.2399
Batch 60, Loss: 0.2333
Batch 70, Loss: 0.2229
Batch 80, Loss: 0.2582
Batch 90, Loss: 0.2583
Batch 100, Loss: 0.2189
Batch 110, Loss: 0.2492
Batch 120, Loss: 0.2611
Batch 130, Loss: 0.2589
Batch 140, Loss: 0.2617
Batch 150, Loss: 0.2319
Batch 160, Loss: 0.2695
Batch 170, Loss: 0.2282
Batch 180, Loss: 0.2394
Batch 190, Loss: 0.2458
Batch 200, Loss: 0.2388
Batch 210, Loss: 0.2300
Batch 220, Loss: 0.2535
Batch 230, Loss: 0.2328
Batch 240, Loss: 0.2429
Batch 250, Loss: 0.2447
Batch 260, Loss: 0.2553
Batch 270, Loss: 0.2347
Batch 280, Loss: 0.2365
Batch 290, Loss: 0.2354
Batch 300, Loss: 0.2477
Batch 310, Loss: 0.2389
Batch 320, Loss: 0.2600
Batch 330, Loss: 0.2441
Batch 340, Loss: 0.2475
Batch 350, Loss: 0.2073
Batch 360, Loss: 0.2280
Batch 370, Loss: 0.2385
Batch 380, Loss: 0.2373
Batch 390, Loss: 0.2293
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.089062213897705 seconds
Epoch 190 accuracy: 80.21%
Batch 10, Loss: 0.2231
Batch 20, Loss: 0.2422
Batch 30, Loss: 0.2479
Batch 40, Loss: 0.2573
Batch 50, Loss: 0.2410
Batch 60, Loss: 0.2444
Batch 70, Loss: 0.2313
Batch 80, Loss: 0.2291
Batch 90, Loss: 0.2740
Batch 100, Loss: 0.2349
Batch 110, Loss: 0.2371
Batch 120, Loss: 0.2305
Batch 130, Loss: 0.2403
Batch 140, Loss: 0.2333
Batch 150, Loss: 0.2473
Batch 160, Loss: 0.2552
Batch 170, Loss: 0.2329
Batch 180, Loss: 0.2873
Batch 190, Loss: 0.2270
Batch 200, Loss: 0.2409
Batch 210, Loss: 0.2442
Batch 220, Loss: 0.2243
Batch 230, Loss: 0.2421
Batch 240, Loss: 0.2444
Batch 250, Loss: 0.2200
Batch 260, Loss: 0.2202
Batch 270, Loss: 0.2458
Batch 280, Loss: 0.2567
Batch 290, Loss: 0.2469
Batch 300, Loss: 0.2367
Batch 310, Loss: 0.2544
Batch 320, Loss: 0.2645
Batch 330, Loss: 0.2759
Batch 340, Loss: 0.2585
Batch 350, Loss: 0.2168
Batch 360, Loss: 0.2168
Batch 370, Loss: 0.2370
Batch 380, Loss: 0.2410
Batch 390, Loss: 0.2457
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.086400032043457 seconds
Epoch 191 accuracy: 80.34%
Batch 10, Loss: 0.2111
Batch 20, Loss: 0.2395
Batch 30, Loss: 0.2262
Batch 40, Loss: 0.2820
Batch 50, Loss: 0.2239
Batch 60, Loss: 0.2138
Batch 70, Loss: 0.2404
Batch 80, Loss: 0.2442
Batch 90, Loss: 0.2965
Batch 100, Loss: 0.2280
Batch 110, Loss: 0.2359
Batch 120, Loss: 0.2078
Batch 130, Loss: 0.2368
Batch 140, Loss: 0.2409
Batch 150, Loss: 0.2550
Batch 160, Loss: 0.2280
Batch 170, Loss: 0.2212
Batch 180, Loss: 0.2330
Batch 190, Loss: 0.2299
Batch 200, Loss: 0.2496
Batch 210, Loss: 0.2320
Batch 220, Loss: 0.2342
Batch 230, Loss: 0.2272
Batch 240, Loss: 0.2278
Batch 250, Loss: 0.2230
Batch 260, Loss: 0.2510
Batch 270, Loss: 0.2544
Batch 280, Loss: 0.2382
Batch 290, Loss: 0.2299
Batch 300, Loss: 0.2508
Batch 310, Loss: 0.2299
Batch 320, Loss: 0.2509
Batch 330, Loss: 0.2215
Batch 340, Loss: 0.2351
Batch 350, Loss: 0.2456
Batch 360, Loss: 0.2212
Batch 370, Loss: 0.2292
Batch 380, Loss: 0.2451
Batch 390, Loss: 0.2423
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.175158262252808 seconds
Epoch 192 accuracy: 80.01%
Batch 10, Loss: 0.2145
Batch 20, Loss: 0.2549
Batch 30, Loss: 0.2085
Batch 40, Loss: 0.2484
Batch 50, Loss: 0.2219
Batch 60, Loss: 0.2223
Batch 70, Loss: 0.2282
Batch 80, Loss: 0.2358
Batch 90, Loss: 0.2265
Batch 100, Loss: 0.2352
Batch 110, Loss: 0.2282
Batch 120, Loss: 0.2252
Batch 130, Loss: 0.2674
Batch 140, Loss: 0.2406
Batch 150, Loss: 0.2440
Batch 160, Loss: 0.2506
Batch 170, Loss: 0.2252
Batch 180, Loss: 0.2530
Batch 190, Loss: 0.2430
Batch 200, Loss: 0.2675
Batch 210, Loss: 0.2512
Batch 220, Loss: 0.2516
Batch 230, Loss: 0.2593
Batch 240, Loss: 0.2376
Batch 250, Loss: 0.2601
Batch 260, Loss: 0.2171
Batch 270, Loss: 0.2403
Batch 280, Loss: 0.2359
Batch 290, Loss: 0.2315
Batch 300, Loss: 0.2151
Batch 310, Loss: 0.2379
Batch 320, Loss: 0.2491
Batch 330, Loss: 0.2225
Batch 340, Loss: 0.2666
Batch 350, Loss: 0.2279
Batch 360, Loss: 0.2424
Batch 370, Loss: 0.2482
Batch 380, Loss: 0.2471
Batch 390, Loss: 0.2164
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.1308913230896 seconds
Epoch 193 accuracy: 80.19%
Batch 10, Loss: 0.2361
Batch 20, Loss: 0.2440
Batch 30, Loss: 0.2826
Batch 40, Loss: 0.2444
Batch 50, Loss: 0.2500
Batch 60, Loss: 0.2288
Batch 70, Loss: 0.2392
Batch 80, Loss: 0.2272
Batch 90, Loss: 0.2325
Batch 100, Loss: 0.2510
Batch 110, Loss: 0.2511
Batch 120, Loss: 0.2858
Batch 130, Loss: 0.2478
Batch 140, Loss: 0.2241
Batch 150, Loss: 0.2255
Batch 160, Loss: 0.2662
Batch 170, Loss: 0.2327
Batch 180, Loss: 0.2223
Batch 190, Loss: 0.2775
Batch 200, Loss: 0.2171
Batch 210, Loss: 0.2294
Batch 220, Loss: 0.2477
Batch 230, Loss: 0.2249
Batch 240, Loss: 0.2393
Batch 250, Loss: 0.2392
Batch 260, Loss: 0.2320
Batch 270, Loss: 0.2022
Batch 280, Loss: 0.2284
Batch 290, Loss: 0.2465
Batch 300, Loss: 0.2305
Batch 310, Loss: 0.2227
Batch 320, Loss: 0.2697
Batch 330, Loss: 0.2686
Batch 340, Loss: 0.2301
Batch 350, Loss: 0.2531
Batch 360, Loss: 0.2409
Batch 370, Loss: 0.2094
Batch 380, Loss: 0.2269
Batch 390, Loss: 0.2433
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.103079795837402 seconds
Epoch 194 accuracy: 80.15%
Batch 10, Loss: 0.2213
Batch 20, Loss: 0.2448
Batch 30, Loss: 0.2351
Batch 40, Loss: 0.2405
Batch 50, Loss: 0.2615
Batch 60, Loss: 0.2332
Batch 70, Loss: 0.2232
Batch 80, Loss: 0.2313
Batch 90, Loss: 0.2412
Batch 100, Loss: 0.2341
Batch 110, Loss: 0.2824
Batch 120, Loss: 0.2284
Batch 130, Loss: 0.2375
Batch 140, Loss: 0.2587
Batch 150, Loss: 0.2594
Batch 160, Loss: 0.2204
Batch 170, Loss: 0.2287
Batch 180, Loss: 0.2367
Batch 190, Loss: 0.2376
Batch 200, Loss: 0.2442
Batch 210, Loss: 0.2230
Batch 220, Loss: 0.2722
Batch 230, Loss: 0.2275
Batch 240, Loss: 0.2707
Batch 250, Loss: 0.2253
Batch 260, Loss: 0.2434
Batch 270, Loss: 0.2096
Batch 280, Loss: 0.2253
Batch 290, Loss: 0.2324
Batch 300, Loss: 0.2434
Batch 310, Loss: 0.2423
Batch 320, Loss: 0.2441
Batch 330, Loss: 0.2461
Batch 340, Loss: 0.2073
Batch 350, Loss: 0.2351
Batch 360, Loss: 0.2686
Batch 370, Loss: 0.2269
Batch 380, Loss: 0.2302
Batch 390, Loss: 0.2496
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 24.982335805892944 seconds
Epoch 195 accuracy: 80.25%
Batch 10, Loss: 0.2215
Batch 20, Loss: 0.2495
Batch 30, Loss: 0.2501
Batch 40, Loss: 0.2388
Batch 50, Loss: 0.2494
Batch 60, Loss: 0.2013
Batch 70, Loss: 0.2266
Batch 80, Loss: 0.2296
Batch 90, Loss: 0.2183
Batch 100, Loss: 0.2284
Batch 110, Loss: 0.2270
Batch 120, Loss: 0.2347
Batch 130, Loss: 0.2006
Batch 140, Loss: 0.2403
Batch 150, Loss: 0.2405
Batch 160, Loss: 0.2122
Batch 170, Loss: 0.2173
Batch 180, Loss: 0.2341
Batch 190, Loss: 0.2392
Batch 200, Loss: 0.2746
Batch 210, Loss: 0.2196
Batch 220, Loss: 0.2789
Batch 230, Loss: 0.2577
Batch 240, Loss: 0.2353
Batch 250, Loss: 0.2348
Batch 260, Loss: 0.2266
Batch 270, Loss: 0.2190
Batch 280, Loss: 0.2401
Batch 290, Loss: 0.2338
Batch 300, Loss: 0.2208
Batch 310, Loss: 0.2442
Batch 320, Loss: 0.1958
Batch 330, Loss: 0.2293
Batch 340, Loss: 0.2480
Batch 350, Loss: 0.2348
Batch 360, Loss: 0.2340
Batch 370, Loss: 0.2197
Batch 380, Loss: 0.2268
Batch 390, Loss: 0.2103
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.0775728225708 seconds
Epoch 196 accuracy: 80.4%
Batch 10, Loss: 0.2133
Batch 20, Loss: 0.2322
Batch 30, Loss: 0.2351
Batch 40, Loss: 0.2171
Batch 50, Loss: 0.2294
Batch 60, Loss: 0.2194
Batch 70, Loss: 0.2294
Batch 80, Loss: 0.2145
Batch 90, Loss: 0.2741
Batch 100, Loss: 0.2135
Batch 110, Loss: 0.2578
Batch 120, Loss: 0.2350
Batch 130, Loss: 0.2238
Batch 140, Loss: 0.2415
Batch 150, Loss: 0.2284
Batch 160, Loss: 0.2379
Batch 170, Loss: 0.2199
Batch 180, Loss: 0.2263
Batch 190, Loss: 0.2235
Batch 200, Loss: 0.2794
Batch 210, Loss: 0.2063
Batch 220, Loss: 0.2516
Batch 230, Loss: 0.2668
Batch 240, Loss: 0.2384
Batch 250, Loss: 0.2293
Batch 260, Loss: 0.2328
Batch 270, Loss: 0.2159
Batch 280, Loss: 0.2422
Batch 290, Loss: 0.2419
Batch 300, Loss: 0.2613
Batch 310, Loss: 0.2331
Batch 320, Loss: 0.2306
Batch 330, Loss: 0.2316
Batch 340, Loss: 0.2523
Batch 350, Loss: 0.2289
Batch 360, Loss: 0.2417
Batch 370, Loss: 0.2182
Batch 380, Loss: 0.2234
Batch 390, Loss: 0.2236
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.03830051422119 seconds
Epoch 197 accuracy: 80.24%
Batch 10, Loss: 0.2574
Batch 20, Loss: 0.2158
Batch 30, Loss: 0.2415
Batch 40, Loss: 0.2434
Batch 50, Loss: 0.2302
Batch 60, Loss: 0.2413
Batch 70, Loss: 0.1773
Batch 80, Loss: 0.2223
Batch 90, Loss: 0.2466
Batch 100, Loss: 0.2235
Batch 110, Loss: 0.2674
Batch 120, Loss: 0.2112
Batch 130, Loss: 0.2251
Batch 140, Loss: 0.2563
Batch 150, Loss: 0.2202
Batch 160, Loss: 0.2393
Batch 170, Loss: 0.2357
Batch 180, Loss: 0.2288
Batch 190, Loss: 0.2338
Batch 200, Loss: 0.2689
Batch 210, Loss: 0.2561
Batch 220, Loss: 0.2811
Batch 230, Loss: 0.2248
Batch 240, Loss: 0.2168
Batch 250, Loss: 0.2164
Batch 260, Loss: 0.2552
Batch 270, Loss: 0.2438
Batch 280, Loss: 0.2221
Batch 290, Loss: 0.2455
Batch 300, Loss: 0.2213
Batch 310, Loss: 0.2513
Batch 320, Loss: 0.2357
Batch 330, Loss: 0.2347
Batch 340, Loss: 0.2273
Batch 350, Loss: 0.2535
Batch 360, Loss: 0.2563
Batch 370, Loss: 0.2250
Batch 380, Loss: 0.2499
Batch 390, Loss: 0.2554
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.081005096435547 seconds
Epoch 198 accuracy: 80.33%
Batch 10, Loss: 0.2684
Batch 20, Loss: 0.2513
Batch 30, Loss: 0.2217
Batch 40, Loss: 0.2261
Batch 50, Loss: 0.2590
Batch 60, Loss: 0.2352
Batch 70, Loss: 0.2328
Batch 80, Loss: 0.2342
Batch 90, Loss: 0.2373
Batch 100, Loss: 0.2332
Batch 110, Loss: 0.2385
Batch 120, Loss: 0.2178
Batch 130, Loss: 0.2422
Batch 140, Loss: 0.2267
Batch 150, Loss: 0.2171
Batch 160, Loss: 0.2381
Batch 170, Loss: 0.2088
Batch 180, Loss: 0.2507
Batch 190, Loss: 0.2233
Batch 200, Loss: 0.2493
Batch 210, Loss: 0.2138
Batch 220, Loss: 0.2479
Batch 230, Loss: 0.2450
Batch 240, Loss: 0.2120
Batch 250, Loss: 0.2472
Batch 260, Loss: 0.2260
Batch 270, Loss: 0.2279
Batch 280, Loss: 0.2491
Batch 290, Loss: 0.2407
Batch 300, Loss: 0.2253
Batch 310, Loss: 0.2483
Batch 320, Loss: 0.2455
Batch 330, Loss: 0.2239
Batch 340, Loss: 0.2200
Batch 350, Loss: 0.2274
Batch 360, Loss: 0.2108
Batch 370, Loss: 0.2481
Batch 380, Loss: 0.2333
Batch 390, Loss: 0.2385
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.105082511901855 seconds
Epoch 199 accuracy: 80.24%
Batch 10, Loss: 0.2254
Batch 20, Loss: 0.2685
Batch 30, Loss: 0.2401
Batch 40, Loss: 0.1956
Batch 50, Loss: 0.2382
Batch 60, Loss: 0.2105
Batch 70, Loss: 0.2558
Batch 80, Loss: 0.2191
Batch 90, Loss: 0.2326
Batch 100, Loss: 0.2626
Batch 110, Loss: 0.2123
Batch 120, Loss: 0.2417
Batch 130, Loss: 0.2075
Batch 140, Loss: 0.2183
Batch 150, Loss: 0.2471
Batch 160, Loss: 0.2352
Batch 170, Loss: 0.2643
Batch 180, Loss: 0.2296
Batch 190, Loss: 0.2109
Batch 200, Loss: 0.2691
Batch 210, Loss: 0.2484
Batch 220, Loss: 0.2409
Batch 230, Loss: 0.1992
Batch 240, Loss: 0.2386
Batch 250, Loss: 0.2345
Batch 260, Loss: 0.2169
Batch 270, Loss: 0.2356
Batch 280, Loss: 0.2189
Batch 290, Loss: 0.2137
Batch 300, Loss: 0.2144
Batch 310, Loss: 0.2303
Batch 320, Loss: 0.2361
Batch 330, Loss: 0.2243
Batch 340, Loss: 0.2717
Batch 350, Loss: 0.2392
Batch 360, Loss: 0.2636
Batch 370, Loss: 0.2430
Batch 380, Loss: 0.2310
Batch 390, Loss: 0.2687
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.13519048690796 seconds
Epoch 200 accuracy: 80.36%
Total training time: 5026.227640867233 seconds
