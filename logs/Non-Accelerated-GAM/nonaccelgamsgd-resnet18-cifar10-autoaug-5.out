The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAMNonAccelerated
Using non-accelerated GAM
/home/tkleinkn/GAMtest/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /home/coulombc/wheels_builder/tmp.2617/python-3.11/torch/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Batch 100, Loss: 2.0609
Batch 200, Loss: 1.6548
Batch 300, Loss: 1.5932
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 246.0407898426056 seconds
Epoch 1 accuracy: 31.84%
Batch 100, Loss: 1.5044
Batch 200, Loss: 1.4610
Batch 300, Loss: 1.4248
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 237.0904426574707 seconds
Epoch 2 accuracy: 42.97%
Batch 100, Loss: 1.3607
Batch 200, Loss: 1.3264
Batch 300, Loss: 1.2873
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 236.97878909111023 seconds
Epoch 3 accuracy: 49.81%
Batch 100, Loss: 1.2277
Batch 200, Loss: 1.2052
Batch 300, Loss: 1.1592
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 236.86274647712708 seconds
Epoch 4 accuracy: 49.52%
Batch 100, Loss: 1.1129
Batch 200, Loss: 1.0757
Batch 300, Loss: 1.0720
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 243.19817996025085 seconds
Epoch 5 accuracy: 59.46%
Batch 100, Loss: 1.0120
Batch 200, Loss: 0.9778
Batch 300, Loss: 0.9641
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 236.79494428634644 seconds
Epoch 6 accuracy: 67.61%
Batch 100, Loss: 0.9077
Batch 200, Loss: 0.8866
Batch 300, Loss: 0.8717
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 236.73751068115234 seconds
Epoch 7 accuracy: 71.04%
Batch 100, Loss: 0.8388
Batch 200, Loss: 0.8391
Batch 300, Loss: 0.8100
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 236.73097968101501 seconds
Epoch 8 accuracy: 73.41%
Batch 100, Loss: 0.7935
Batch 200, Loss: 0.7978
Batch 300, Loss: 0.7874
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 236.7137269973755 seconds
Epoch 9 accuracy: 75.9%
Batch 100, Loss: 0.7723
Batch 200, Loss: 0.7566
Batch 300, Loss: 0.7706
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 238.1831624507904 seconds
Epoch 10 accuracy: 75.84%
Batch 100, Loss: 0.7449
Batch 200, Loss: 0.7385
Batch 300, Loss: 0.7416
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 236.47184538841248 seconds
Epoch 11 accuracy: 78.33%
Batch 100, Loss: 0.7222
Batch 200, Loss: 0.7140
Batch 300, Loss: 0.7097
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 236.77396297454834 seconds
Epoch 12 accuracy: 78.57%
Batch 100, Loss: 0.7004
Batch 200, Loss: 0.6990
Batch 300, Loss: 0.6993
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 236.59653091430664 seconds
Epoch 13 accuracy: 75.43%
Batch 100, Loss: 0.6941
Batch 200, Loss: 0.6775
Batch 300, Loss: 0.6791
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 236.86434864997864 seconds
Epoch 14 accuracy: 79.2%
Batch 100, Loss: 0.6805
Batch 200, Loss: 0.6791
Batch 300, Loss: 0.6726
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 236.7822561264038 seconds
Epoch 15 accuracy: 80.82%
Batch 100, Loss: 0.6697
Batch 200, Loss: 0.6613
Batch 300, Loss: 0.6672
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 236.63988995552063 seconds
Epoch 16 accuracy: 74.68%
Batch 100, Loss: 0.6613
Batch 200, Loss: 0.6608
Batch 300, Loss: 0.6532
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 236.77752661705017 seconds
Epoch 17 accuracy: 78.58%
Batch 100, Loss: 0.6410
Batch 200, Loss: 0.6436
Batch 300, Loss: 0.6460
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 236.77930092811584 seconds
Epoch 18 accuracy: 79.23%
Batch 100, Loss: 0.6271
Batch 200, Loss: 0.6226
Batch 300, Loss: 0.6309
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 236.80578327178955 seconds
Epoch 19 accuracy: 77.9%
Batch 100, Loss: 0.6276
Batch 200, Loss: 0.6209
Batch 300, Loss: 0.6329
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 236.70194244384766 seconds
Epoch 20 accuracy: 81.39%
Batch 100, Loss: 0.6367
Batch 200, Loss: 0.6151
Batch 300, Loss: 0.6187
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 236.61758971214294 seconds
Epoch 21 accuracy: 81.26%
Batch 100, Loss: 0.6176
Batch 200, Loss: 0.6033
Batch 300, Loss: 0.6120
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 236.68801474571228 seconds
Epoch 22 accuracy: 82.32%
Batch 100, Loss: 0.6203
Batch 200, Loss: 0.6009
Batch 300, Loss: 0.6103
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 236.60956478118896 seconds
Epoch 23 accuracy: 81.49%
Batch 100, Loss: 0.5932
Batch 200, Loss: 0.5926
Batch 300, Loss: 0.6018
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 236.59254908561707 seconds
Epoch 24 accuracy: 83.9%
Batch 100, Loss: 0.5989
Batch 200, Loss: 0.5971
Batch 300, Loss: 0.6078
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 236.5146586894989 seconds
Epoch 25 accuracy: 81.71%
Batch 100, Loss: 0.6029
Batch 200, Loss: 0.6068
Batch 300, Loss: 0.5907
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 236.56764245033264 seconds
Epoch 26 accuracy: 83.42%
Batch 100, Loss: 0.5829
Batch 200, Loss: 0.5813
Batch 300, Loss: 0.5985
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 236.89388155937195 seconds
Epoch 27 accuracy: 83.34%
Batch 100, Loss: 0.5939
Batch 200, Loss: 0.5894
Batch 300, Loss: 0.5949
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 236.76086378097534 seconds
Epoch 28 accuracy: 81.71%
Batch 100, Loss: 0.5795
Batch 200, Loss: 0.5877
Batch 300, Loss: 0.5772
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 236.5991654396057 seconds
Epoch 29 accuracy: 83.23%
Batch 100, Loss: 0.5702
Batch 200, Loss: 0.5790
Batch 300, Loss: 0.5848
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 240.30683851242065 seconds
Epoch 30 accuracy: 81.86%
Batch 100, Loss: 0.5711
Batch 200, Loss: 0.5841
Batch 300, Loss: 0.5739
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 236.6281123161316 seconds
Epoch 31 accuracy: 80.24%
Batch 100, Loss: 0.5768
Batch 200, Loss: 0.5681
Batch 300, Loss: 0.5656
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 236.48509454727173 seconds
Epoch 32 accuracy: 82.0%
Batch 100, Loss: 0.5737
Batch 200, Loss: 0.5660
Batch 300, Loss: 0.5726
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 236.45817351341248 seconds
Epoch 33 accuracy: 82.53%
Batch 100, Loss: 0.5572
Batch 200, Loss: 0.5649
Batch 300, Loss: 0.5758
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 236.67178797721863 seconds
Epoch 34 accuracy: 81.45%
Batch 100, Loss: 0.5610
Batch 200, Loss: 0.5719
Batch 300, Loss: 0.5704
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 236.65099382400513 seconds
Epoch 35 accuracy: 84.07%
Batch 100, Loss: 0.5551
Batch 200, Loss: 0.5667
Batch 300, Loss: 0.5532
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 236.58248281478882 seconds
Epoch 36 accuracy: 83.33%
Batch 100, Loss: 0.5470
Batch 200, Loss: 0.5683
Batch 300, Loss: 0.5569
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 236.569748878479 seconds
Epoch 37 accuracy: 84.02%
Batch 100, Loss: 0.5450
Batch 200, Loss: 0.5720
Batch 300, Loss: 0.5501
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 236.69012689590454 seconds
Epoch 38 accuracy: 85.08%
Batch 100, Loss: 0.5503
Batch 200, Loss: 0.5563
Batch 300, Loss: 0.5604
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 236.69096302986145 seconds
Epoch 39 accuracy: 83.97%
Batch 100, Loss: 0.5562
Batch 200, Loss: 0.5522
Batch 300, Loss: 0.5536
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 236.74400877952576 seconds
Epoch 40 accuracy: 85.31%
Batch 100, Loss: 0.5578
Batch 200, Loss: 0.5501
Batch 300, Loss: 0.5534
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 236.54920172691345 seconds
Epoch 41 accuracy: 83.75%
Batch 100, Loss: 0.5488
Batch 200, Loss: 0.5456
Batch 300, Loss: 0.5550
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 236.75236105918884 seconds
Epoch 42 accuracy: 86.26%
Batch 100, Loss: 0.5456
Batch 200, Loss: 0.5356
Batch 300, Loss: 0.5430
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 236.91393518447876 seconds
Epoch 43 accuracy: 85.29%
Batch 100, Loss: 0.5433
Batch 200, Loss: 0.5317
Batch 300, Loss: 0.5459
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 236.78536915779114 seconds
Epoch 44 accuracy: 85.55%
Batch 100, Loss: 0.5381
Batch 200, Loss: 0.5522
Batch 300, Loss: 0.5320
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 236.90524888038635 seconds
Epoch 45 accuracy: 85.83%
Batch 100, Loss: 0.5297
Batch 200, Loss: 0.5460
Batch 300, Loss: 0.5419
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 236.40487122535706 seconds
Epoch 46 accuracy: 84.89%
Batch 100, Loss: 0.5193
Batch 200, Loss: 0.5395
Batch 300, Loss: 0.5327
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 236.56087565422058 seconds
Epoch 47 accuracy: 86.16%
Batch 100, Loss: 0.5332
Batch 200, Loss: 0.5254
Batch 300, Loss: 0.5428
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 236.6277837753296 seconds
Epoch 48 accuracy: 83.61%
Batch 100, Loss: 0.5276
Batch 200, Loss: 0.5312
Batch 300, Loss: 0.5307
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 236.75117778778076 seconds
Epoch 49 accuracy: 83.89%
Batch 100, Loss: 0.5324
Batch 200, Loss: 0.5331
Batch 300, Loss: 0.5287
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 236.54004383087158 seconds
Epoch 50 accuracy: 83.11%
Batch 100, Loss: 0.5113
Batch 200, Loss: 0.5143
Batch 300, Loss: 0.5475
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 236.72627019882202 seconds
Epoch 51 accuracy: 84.84%
Batch 100, Loss: 0.5199
Batch 200, Loss: 0.5333
Batch 300, Loss: 0.5156
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 236.4636037349701 seconds
Epoch 52 accuracy: 86.16%
Batch 100, Loss: 0.5313
Batch 200, Loss: 0.5280
Batch 300, Loss: 0.5312
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 236.81185173988342 seconds
Epoch 53 accuracy: 80.33%
Batch 100, Loss: 0.5100
Batch 200, Loss: 0.5298
Batch 300, Loss: 0.5236
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 236.82183599472046 seconds
Epoch 54 accuracy: 80.13%
Batch 100, Loss: 0.5159
Batch 200, Loss: 0.5138
Batch 300, Loss: 0.5317
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 236.55506563186646 seconds
Epoch 55 accuracy: 84.72%
Batch 100, Loss: 0.5227
Batch 200, Loss: 0.5064
Batch 300, Loss: 0.5166
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 236.54333639144897 seconds
Epoch 56 accuracy: 85.23%
Batch 100, Loss: 0.5061
Batch 200, Loss: 0.5045
Batch 300, Loss: 0.5180
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 236.8501214981079 seconds
Epoch 57 accuracy: 85.45%
Batch 100, Loss: 0.5094
Batch 200, Loss: 0.5048
Batch 300, Loss: 0.5190
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 236.61760783195496 seconds
Epoch 58 accuracy: 81.39%
Batch 100, Loss: 0.5061
Batch 200, Loss: 0.5044
Batch 300, Loss: 0.5321
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 236.64265894889832 seconds
Epoch 59 accuracy: 86.5%
Batch 100, Loss: 0.5141
Batch 200, Loss: 0.5197
Batch 300, Loss: 0.5116
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 236.3476116657257 seconds
Epoch 60 accuracy: 86.56%
Batch 100, Loss: 0.5000
Batch 200, Loss: 0.5029
Batch 300, Loss: 0.5198
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 236.56921982765198 seconds
Epoch 61 accuracy: 84.64%
Batch 100, Loss: 0.5014
Batch 200, Loss: 0.5090
Batch 300, Loss: 0.5069
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 236.59916925430298 seconds
Epoch 62 accuracy: 85.53%
Batch 100, Loss: 0.5128
Batch 200, Loss: 0.4986
Batch 300, Loss: 0.5112
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 236.5310344696045 seconds
Epoch 63 accuracy: 85.86%
Batch 100, Loss: 0.5061
Batch 200, Loss: 0.5081
Batch 300, Loss: 0.5023
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 236.51324725151062 seconds
Epoch 64 accuracy: 87.03%
Batch 100, Loss: 0.4942
Batch 200, Loss: 0.5035
Batch 300, Loss: 0.5112
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 236.7297191619873 seconds
Epoch 65 accuracy: 87.25%
Batch 100, Loss: 0.4977
Batch 200, Loss: 0.5040
Batch 300, Loss: 0.4985
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 236.74041390419006 seconds
Epoch 66 accuracy: 83.49%
Batch 100, Loss: 0.4962
Batch 200, Loss: 0.4878
Batch 300, Loss: 0.5044
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 236.58393144607544 seconds
Epoch 67 accuracy: 85.23%
Batch 100, Loss: 0.5024
Batch 200, Loss: 0.4945
Batch 300, Loss: 0.4881
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 236.38922715187073 seconds
Epoch 68 accuracy: 88.74%
Batch 100, Loss: 0.4870
Batch 200, Loss: 0.4918
Batch 300, Loss: 0.4964
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 236.40275955200195 seconds
Epoch 69 accuracy: 86.29%
Batch 100, Loss: 0.4938
Batch 200, Loss: 0.5043
Batch 300, Loss: 0.4878
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 236.51133465766907 seconds
Epoch 70 accuracy: 84.6%
Batch 100, Loss: 0.4861
Batch 200, Loss: 0.4740
Batch 300, Loss: 0.5060
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 236.57209372520447 seconds
Epoch 71 accuracy: 86.01%
Batch 100, Loss: 0.4918
Batch 200, Loss: 0.4833
Batch 300, Loss: 0.4972
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 236.81763458251953 seconds
Epoch 72 accuracy: 86.53%
Batch 100, Loss: 0.4848
Batch 200, Loss: 0.4728
Batch 300, Loss: 0.4881
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 236.58067774772644 seconds
Epoch 73 accuracy: 88.39%
Batch 100, Loss: 0.4873
Batch 200, Loss: 0.4825
Batch 300, Loss: 0.4899
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 236.36505222320557 seconds
Epoch 74 accuracy: 85.35%
Batch 100, Loss: 0.4780
Batch 200, Loss: 0.4845
Batch 300, Loss: 0.4801
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 236.52085995674133 seconds
Epoch 75 accuracy: 84.48%
Batch 100, Loss: 0.4798
Batch 200, Loss: 0.4857
Batch 300, Loss: 0.4842
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 236.5351345539093 seconds
Epoch 76 accuracy: 85.39%
Batch 100, Loss: 0.4728
Batch 200, Loss: 0.4778
Batch 300, Loss: 0.4827
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 236.88073921203613 seconds
Epoch 77 accuracy: 85.68%
Batch 100, Loss: 0.4752
Batch 200, Loss: 0.4893
Batch 300, Loss: 0.4791
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 236.74768352508545 seconds
Epoch 78 accuracy: 88.79%
Batch 100, Loss: 0.4655
Batch 200, Loss: 0.4720
Batch 300, Loss: 0.4813
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 236.72548031806946 seconds
Epoch 79 accuracy: 87.68%
Batch 100, Loss: 0.4789
Batch 200, Loss: 0.4799
Batch 300, Loss: 0.4855
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 236.65452551841736 seconds
Epoch 80 accuracy: 88.62%
Batch 100, Loss: 0.4723
Batch 200, Loss: 0.4629
Batch 300, Loss: 0.4692
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 236.83745431900024 seconds
Epoch 81 accuracy: 88.89%
Batch 100, Loss: 0.4750
Batch 200, Loss: 0.4648
Batch 300, Loss: 0.4612
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 236.51214981079102 seconds
Epoch 82 accuracy: 87.57%
Batch 100, Loss: 0.4637
Batch 200, Loss: 0.4584
Batch 300, Loss: 0.4651
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 236.77757620811462 seconds
Epoch 83 accuracy: 87.66%
Batch 100, Loss: 0.4668
Batch 200, Loss: 0.4617
Batch 300, Loss: 0.4757
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 236.79711651802063 seconds
Epoch 84 accuracy: 89.52%
Batch 100, Loss: 0.4634
Batch 200, Loss: 0.4610
Batch 300, Loss: 0.4696
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 236.6924831867218 seconds
Epoch 85 accuracy: 88.4%
Batch 100, Loss: 0.4563
Batch 200, Loss: 0.4462
Batch 300, Loss: 0.4668
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 236.5111961364746 seconds
Epoch 86 accuracy: 87.22%
Batch 100, Loss: 0.4488
Batch 200, Loss: 0.4655
Batch 300, Loss: 0.4691
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 236.57212448120117 seconds
Epoch 87 accuracy: 87.86%
Batch 100, Loss: 0.4473
Batch 200, Loss: 0.4563
Batch 300, Loss: 0.4696
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 236.65662050247192 seconds
Epoch 88 accuracy: 88.4%
Batch 100, Loss: 0.4515
Batch 200, Loss: 0.4556
Batch 300, Loss: 0.4535
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 236.6413083076477 seconds
Epoch 89 accuracy: 88.03%
Batch 100, Loss: 0.4498
Batch 200, Loss: 0.4365
Batch 300, Loss: 0.4537
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 236.63146686553955 seconds
Epoch 90 accuracy: 88.01%
Batch 100, Loss: 0.4371
Batch 200, Loss: 0.4601
Batch 300, Loss: 0.4434
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 236.6231279373169 seconds
Epoch 91 accuracy: 89.29%
Batch 100, Loss: 0.4408
Batch 200, Loss: 0.4379
Batch 300, Loss: 0.4586
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 236.6966495513916 seconds
Epoch 92 accuracy: 87.53%
Batch 100, Loss: 0.4370
Batch 200, Loss: 0.4426
Batch 300, Loss: 0.4377
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 236.75857639312744 seconds
Epoch 93 accuracy: 88.86%
Batch 100, Loss: 0.4522
Batch 200, Loss: 0.4306
Batch 300, Loss: 0.4354
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 236.78900527954102 seconds
Epoch 94 accuracy: 87.61%
Batch 100, Loss: 0.4399
Batch 200, Loss: 0.4407
Batch 300, Loss: 0.4343
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 236.6434555053711 seconds
Epoch 95 accuracy: 88.49%
Batch 100, Loss: 0.4300
Batch 200, Loss: 0.4331
Batch 300, Loss: 0.4378
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 236.59443545341492 seconds
Epoch 96 accuracy: 88.74%
Batch 100, Loss: 0.4250
Batch 200, Loss: 0.4384
Batch 300, Loss: 0.4401
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 236.58951377868652 seconds
Epoch 97 accuracy: 88.41%
Batch 100, Loss: 0.4372
Batch 200, Loss: 0.4346
Batch 300, Loss: 0.4335
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 236.70055389404297 seconds
Epoch 98 accuracy: 87.59%
Batch 100, Loss: 0.4296
Batch 200, Loss: 0.4315
Batch 300, Loss: 0.4189
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 236.7833709716797 seconds
Epoch 99 accuracy: 87.79%
Batch 100, Loss: 0.4277
Batch 200, Loss: 0.4293
Batch 300, Loss: 0.4211
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 236.70565223693848 seconds
Epoch 100 accuracy: 90.01%
Batch 100, Loss: 0.4119
Batch 200, Loss: 0.4158
Batch 300, Loss: 0.4313
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 236.65515160560608 seconds
Epoch 101 accuracy: 90.53%
Batch 100, Loss: 0.4243
Batch 200, Loss: 0.4154
Batch 300, Loss: 0.4252
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 236.61334228515625 seconds
Epoch 102 accuracy: 90.05%
Batch 100, Loss: 0.4169
Batch 200, Loss: 0.4237
Batch 300, Loss: 0.4234
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 236.5979025363922 seconds
Epoch 103 accuracy: 88.72%
Batch 100, Loss: 0.4138
Batch 200, Loss: 0.4129
Batch 300, Loss: 0.4158
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 236.77245450019836 seconds
Epoch 104 accuracy: 88.9%
Batch 100, Loss: 0.4136
Batch 200, Loss: 0.4162
Batch 300, Loss: 0.4096
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 236.40689301490784 seconds
Epoch 105 accuracy: 90.23%
Batch 100, Loss: 0.4052
Batch 200, Loss: 0.4094
Batch 300, Loss: 0.4111
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 236.41939234733582 seconds
Epoch 106 accuracy: 89.94%
Batch 100, Loss: 0.3998
Batch 200, Loss: 0.4033
Batch 300, Loss: 0.4145
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 236.26677823066711 seconds
Epoch 107 accuracy: 88.74%
Batch 100, Loss: 0.4062
Batch 200, Loss: 0.4092
Batch 300, Loss: 0.4032
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 236.3248815536499 seconds
Epoch 108 accuracy: 90.54%
Batch 100, Loss: 0.3922
Batch 200, Loss: 0.4006
Batch 300, Loss: 0.4117
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 236.34693026542664 seconds
Epoch 109 accuracy: 90.79%
Batch 100, Loss: 0.3991
Batch 200, Loss: 0.3977
Batch 300, Loss: 0.3899
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 236.40040183067322 seconds
Epoch 110 accuracy: 89.83%
Batch 100, Loss: 0.3976
Batch 200, Loss: 0.3881
Batch 300, Loss: 0.3912
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 236.52227187156677 seconds
Epoch 111 accuracy: 89.59%
Batch 100, Loss: 0.4086
Batch 200, Loss: 0.3989
Batch 300, Loss: 0.3901
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 236.7161045074463 seconds
Epoch 112 accuracy: 91.08%
Batch 100, Loss: 0.3881
Batch 200, Loss: 0.3863
Batch 300, Loss: 0.3960
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 236.10120344161987 seconds
Epoch 113 accuracy: 90.89%
Batch 100, Loss: 0.3966
Batch 200, Loss: 0.3891
Batch 300, Loss: 0.3917
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 236.3422393798828 seconds
Epoch 114 accuracy: 90.85%
Batch 100, Loss: 0.3757
Batch 200, Loss: 0.3922
Batch 300, Loss: 0.3822
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 236.29965949058533 seconds
Epoch 115 accuracy: 90.75%
Batch 100, Loss: 0.3778
Batch 200, Loss: 0.3838
Batch 300, Loss: 0.3874
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 236.28057265281677 seconds
Epoch 116 accuracy: 90.88%
Batch 100, Loss: 0.3767
Batch 200, Loss: 0.3819
Batch 300, Loss: 0.3832
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 236.25159525871277 seconds
Epoch 117 accuracy: 91.94%
Batch 100, Loss: 0.3655
Batch 200, Loss: 0.3876
Batch 300, Loss: 0.3765
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 236.58889961242676 seconds
Epoch 118 accuracy: 88.0%
Batch 100, Loss: 0.3868
Batch 200, Loss: 0.3709
Batch 300, Loss: 0.3766
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 236.61225986480713 seconds
Epoch 119 accuracy: 90.65%
Batch 100, Loss: 0.3830
Batch 200, Loss: 0.3707
Batch 300, Loss: 0.3728
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 236.67238998413086 seconds
Epoch 120 accuracy: 92.31%
Batch 100, Loss: 0.3651
Batch 200, Loss: 0.3691
Batch 300, Loss: 0.3696
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 236.4696180820465 seconds
Epoch 121 accuracy: 91.55%
Batch 100, Loss: 0.3624
Batch 200, Loss: 0.3646
Batch 300, Loss: 0.3715
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 236.59545421600342 seconds
Epoch 122 accuracy: 91.03%
Batch 100, Loss: 0.3634
Batch 200, Loss: 0.3585
Batch 300, Loss: 0.3675
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 236.6029188632965 seconds
Epoch 123 accuracy: 91.9%
Batch 100, Loss: 0.3528
Batch 200, Loss: 0.3736
Batch 300, Loss: 0.3502
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 236.42755961418152 seconds
Epoch 124 accuracy: 90.99%
Batch 100, Loss: 0.3556
Batch 200, Loss: 0.3616
Batch 300, Loss: 0.3649
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 236.49389576911926 seconds
Epoch 125 accuracy: 91.79%
Batch 100, Loss: 0.3561
Batch 200, Loss: 0.3556
Batch 300, Loss: 0.3559
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 236.5930426120758 seconds
Epoch 126 accuracy: 92.08%
Batch 100, Loss: 0.3441
Batch 200, Loss: 0.3431
Batch 300, Loss: 0.3540
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 236.63040947914124 seconds
Epoch 127 accuracy: 91.48%
Batch 100, Loss: 0.3489
Batch 200, Loss: 0.3506
Batch 300, Loss: 0.3473
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 236.41395330429077 seconds
Epoch 128 accuracy: 90.66%
Batch 100, Loss: 0.3421
Batch 200, Loss: 0.3474
Batch 300, Loss: 0.3503
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 236.71793174743652 seconds
Epoch 129 accuracy: 92.53%
Batch 100, Loss: 0.3479
Batch 200, Loss: 0.3298
Batch 300, Loss: 0.3394
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 236.8811628818512 seconds
Epoch 130 accuracy: 91.88%
Batch 100, Loss: 0.3299
Batch 200, Loss: 0.3388
Batch 300, Loss: 0.3446
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 236.7644543647766 seconds
Epoch 131 accuracy: 91.93%
Batch 100, Loss: 0.3344
Batch 200, Loss: 0.3371
Batch 300, Loss: 0.3427
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 236.71368551254272 seconds
Epoch 132 accuracy: 92.54%
Batch 100, Loss: 0.3313
Batch 200, Loss: 0.3270
Batch 300, Loss: 0.3412
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 236.47335386276245 seconds
Epoch 133 accuracy: 92.23%
Batch 100, Loss: 0.3265
Batch 200, Loss: 0.3227
Batch 300, Loss: 0.3366
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 236.83370852470398 seconds
Epoch 134 accuracy: 91.0%
Batch 100, Loss: 0.3254
Batch 200, Loss: 0.3258
Batch 300, Loss: 0.3187
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 236.7401728630066 seconds
Epoch 135 accuracy: 92.7%
Batch 100, Loss: 0.3231
Batch 200, Loss: 0.3263
Batch 300, Loss: 0.3232
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 236.58734393119812 seconds
Epoch 136 accuracy: 91.8%
Batch 100, Loss: 0.3186
Batch 200, Loss: 0.3188
Batch 300, Loss: 0.3216
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 236.7233431339264 seconds
Epoch 137 accuracy: 92.42%
Batch 100, Loss: 0.3139
Batch 200, Loss: 0.3095
Batch 300, Loss: 0.3220
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 236.64503955841064 seconds
Epoch 138 accuracy: 93.06%
Batch 100, Loss: 0.3218
Batch 200, Loss: 0.3131
Batch 300, Loss: 0.3143
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 236.8799169063568 seconds
Epoch 139 accuracy: 92.04%
Batch 100, Loss: 0.3095
Batch 200, Loss: 0.3130
Batch 300, Loss: 0.3159
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 236.86872839927673 seconds
Epoch 140 accuracy: 93.32%
Batch 100, Loss: 0.3067
Batch 200, Loss: 0.3018
Batch 300, Loss: 0.3012
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 236.66586828231812 seconds
Epoch 141 accuracy: 92.67%
Batch 100, Loss: 0.2973
Batch 200, Loss: 0.3042
Batch 300, Loss: 0.2984
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 236.84292435646057 seconds
Epoch 142 accuracy: 92.71%
Batch 100, Loss: 0.2936
Batch 200, Loss: 0.3017
Batch 300, Loss: 0.2989
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 236.70918226242065 seconds
Epoch 143 accuracy: 93.61%
Batch 100, Loss: 0.2973
Batch 200, Loss: 0.2940
Batch 300, Loss: 0.3010
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 236.65423893928528 seconds
Epoch 144 accuracy: 93.4%
Batch 100, Loss: 0.2870
Batch 200, Loss: 0.2996
Batch 300, Loss: 0.2941
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 236.59054613113403 seconds
Epoch 145 accuracy: 93.67%
Batch 100, Loss: 0.2888
Batch 200, Loss: 0.2865
Batch 300, Loss: 0.2907
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 236.66235971450806 seconds
Epoch 146 accuracy: 93.5%
Batch 100, Loss: 0.2833
Batch 200, Loss: 0.2845
Batch 300, Loss: 0.2843
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 236.63051748275757 seconds
Epoch 147 accuracy: 93.77%
Batch 100, Loss: 0.2709
Batch 200, Loss: 0.2746
Batch 300, Loss: 0.2888
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 236.5265748500824 seconds
Epoch 148 accuracy: 93.26%
Batch 100, Loss: 0.2770
Batch 200, Loss: 0.2809
Batch 300, Loss: 0.2819
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 236.86716294288635 seconds
Epoch 149 accuracy: 93.54%
Batch 100, Loss: 0.2675
Batch 200, Loss: 0.2873
Batch 300, Loss: 0.2787
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 236.50486207008362 seconds
Epoch 150 accuracy: 93.57%
Batch 100, Loss: 0.2598
Batch 200, Loss: 0.2766
Batch 300, Loss: 0.2735
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 236.77730107307434 seconds
Epoch 151 accuracy: 93.18%
Batch 100, Loss: 0.2651
Batch 200, Loss: 0.2632
Batch 300, Loss: 0.2839
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 236.77053880691528 seconds
Epoch 152 accuracy: 94.34%
Batch 100, Loss: 0.2760
Batch 200, Loss: 0.2665
Batch 300, Loss: 0.2707
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 236.50038242340088 seconds
Epoch 153 accuracy: 94.51%
Batch 100, Loss: 0.2591
Batch 200, Loss: 0.2677
Batch 300, Loss: 0.2682
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 236.70113277435303 seconds
Epoch 154 accuracy: 93.97%
Batch 100, Loss: 0.2515
Batch 200, Loss: 0.2598
Batch 300, Loss: 0.2518
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 236.48973894119263 seconds
Epoch 155 accuracy: 94.42%
Batch 100, Loss: 0.2521
Batch 200, Loss: 0.2574
Batch 300, Loss: 0.2642
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 236.89753079414368 seconds
Epoch 156 accuracy: 94.32%
Batch 100, Loss: 0.2498
Batch 200, Loss: 0.2533
Batch 300, Loss: 0.2505
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 236.7520899772644 seconds
Epoch 157 accuracy: 94.33%
Batch 100, Loss: 0.2461
Batch 200, Loss: 0.2414
Batch 300, Loss: 0.2504
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 236.60238337516785 seconds
Epoch 158 accuracy: 94.35%
Batch 100, Loss: 0.2408
Batch 200, Loss: 0.2418
Batch 300, Loss: 0.2441
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 236.54110026359558 seconds
Epoch 159 accuracy: 94.36%
Batch 100, Loss: 0.2310
Batch 200, Loss: 0.2480
Batch 300, Loss: 0.2341
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 236.75146007537842 seconds
Epoch 160 accuracy: 94.41%
Batch 100, Loss: 0.2432
Batch 200, Loss: 0.2424
Batch 300, Loss: 0.2383
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 236.75201535224915 seconds
Epoch 161 accuracy: 94.85%
Batch 100, Loss: 0.2326
Batch 200, Loss: 0.2263
Batch 300, Loss: 0.2296
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 236.61228466033936 seconds
Epoch 162 accuracy: 94.72%
Batch 100, Loss: 0.2287
Batch 200, Loss: 0.2225
Batch 300, Loss: 0.2235
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 236.7292034626007 seconds
Epoch 163 accuracy: 94.37%
Batch 100, Loss: 0.2270
Batch 200, Loss: 0.2272
Batch 300, Loss: 0.2263
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 236.88725399971008 seconds
Epoch 164 accuracy: 94.89%
Batch 100, Loss: 0.2218
Batch 200, Loss: 0.2180
Batch 300, Loss: 0.2169
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 236.5548026561737 seconds
Epoch 165 accuracy: 95.02%
Batch 100, Loss: 0.2114
Batch 200, Loss: 0.2123
Batch 300, Loss: 0.2214
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 236.3927972316742 seconds
Epoch 166 accuracy: 95.13%
Batch 100, Loss: 0.2151
Batch 200, Loss: 0.2115
Batch 300, Loss: 0.2166
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 236.4666712284088 seconds
Epoch 167 accuracy: 95.58%
Batch 100, Loss: 0.1993
Batch 200, Loss: 0.2131
Batch 300, Loss: 0.2145
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 236.61725902557373 seconds
Epoch 168 accuracy: 95.6%
Batch 100, Loss: 0.2062
Batch 200, Loss: 0.2037
Batch 300, Loss: 0.2128
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 236.7622561454773 seconds
Epoch 169 accuracy: 95.55%
Batch 100, Loss: 0.2043
Batch 200, Loss: 0.2042
Batch 300, Loss: 0.2036
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 236.64341473579407 seconds
Epoch 170 accuracy: 95.43%
Batch 100, Loss: 0.2001
Batch 200, Loss: 0.2081
Batch 300, Loss: 0.1960
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 236.7870557308197 seconds
Epoch 171 accuracy: 95.53%
Batch 100, Loss: 0.1940
Batch 200, Loss: 0.1946
Batch 300, Loss: 0.1904
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 236.80572509765625 seconds
Epoch 172 accuracy: 95.34%
Batch 100, Loss: 0.1929
Batch 200, Loss: 0.1982
Batch 300, Loss: 0.1937
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 236.63161420822144 seconds
Epoch 173 accuracy: 95.51%
Batch 100, Loss: 0.1902
Batch 200, Loss: 0.1946
Batch 300, Loss: 0.1863
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 236.64550852775574 seconds
Epoch 174 accuracy: 95.43%
Batch 100, Loss: 0.1803
Batch 200, Loss: 0.1917
Batch 300, Loss: 0.1893
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 236.57990837097168 seconds
Epoch 175 accuracy: 95.73%
Batch 100, Loss: 0.1861
Batch 200, Loss: 0.1808
Batch 300, Loss: 0.1763
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 236.62839126586914 seconds
Epoch 176 accuracy: 95.61%
Batch 100, Loss: 0.1861
Batch 200, Loss: 0.1779
Batch 300, Loss: 0.1769
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 236.51624870300293 seconds
Epoch 177 accuracy: 95.7%
Batch 100, Loss: 0.1758
Batch 200, Loss: 0.1812
Batch 300, Loss: 0.1770
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 236.66126155853271 seconds
Epoch 178 accuracy: 96.02%
Batch 100, Loss: 0.1743
Batch 200, Loss: 0.1726
Batch 300, Loss: 0.1715
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 236.7117416858673 seconds
Epoch 179 accuracy: 95.87%
Batch 100, Loss: 0.1756
Batch 200, Loss: 0.1670
Batch 300, Loss: 0.1678
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 236.81766366958618 seconds
Epoch 180 accuracy: 96.11%
Batch 100, Loss: 0.1632
Batch 200, Loss: 0.1726
Batch 300, Loss: 0.1728
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 236.74551725387573 seconds
Epoch 181 accuracy: 95.92%
Batch 100, Loss: 0.1616
Batch 200, Loss: 0.1726
Batch 300, Loss: 0.1632
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 236.7842526435852 seconds
Epoch 182 accuracy: 96.02%
Batch 100, Loss: 0.1706
Batch 200, Loss: 0.1637
Batch 300, Loss: 0.1684
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 236.65201020240784 seconds
Epoch 183 accuracy: 96.18%
Batch 100, Loss: 0.1576
Batch 200, Loss: 0.1679
Batch 300, Loss: 0.1629
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 236.86630058288574 seconds
Epoch 184 accuracy: 96.13%
Batch 100, Loss: 0.1570
Batch 200, Loss: 0.1588
Batch 300, Loss: 0.1630
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 236.66195797920227 seconds
Epoch 185 accuracy: 96.28%
Batch 100, Loss: 0.1536
Batch 200, Loss: 0.1601
Batch 300, Loss: 0.1540
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 236.73779368400574 seconds
Epoch 186 accuracy: 96.32%
Batch 100, Loss: 0.1584
Batch 200, Loss: 0.1590
Batch 300, Loss: 0.1548
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 236.62329173088074 seconds
Epoch 187 accuracy: 96.24%
Batch 100, Loss: 0.1571
Batch 200, Loss: 0.1602
Batch 300, Loss: 0.1505
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 236.81533694267273 seconds
Epoch 188 accuracy: 96.11%
Batch 100, Loss: 0.1510
Batch 200, Loss: 0.1566
Batch 300, Loss: 0.1530
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 236.71792221069336 seconds
Epoch 189 accuracy: 96.34%
Batch 100, Loss: 0.1484
Batch 200, Loss: 0.1531
Batch 300, Loss: 0.1516
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 236.75038599967957 seconds
Epoch 190 accuracy: 96.24%
Batch 100, Loss: 0.1419
Batch 200, Loss: 0.1488
Batch 300, Loss: 0.1465
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 236.64680552482605 seconds
Epoch 191 accuracy: 96.33%
Batch 100, Loss: 0.1449
Batch 200, Loss: 0.1457
Batch 300, Loss: 0.1467
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 236.6336486339569 seconds
Epoch 192 accuracy: 96.46%
Batch 100, Loss: 0.1526
Batch 200, Loss: 0.1525
Batch 300, Loss: 0.1463
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 236.74448490142822 seconds
Epoch 193 accuracy: 96.45%
Batch 100, Loss: 0.1493
Batch 200, Loss: 0.1485
Batch 300, Loss: 0.1437
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 236.70313954353333 seconds
Epoch 194 accuracy: 96.34%
Batch 100, Loss: 0.1446
Batch 200, Loss: 0.1464
Batch 300, Loss: 0.1398
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 236.7564504146576 seconds
Epoch 195 accuracy: 96.28%
Batch 100, Loss: 0.1440
Batch 200, Loss: 0.1510
Batch 300, Loss: 0.1420
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 236.7770767211914 seconds
Epoch 196 accuracy: 96.39%
Batch 100, Loss: 0.1443
Batch 200, Loss: 0.1411
Batch 300, Loss: 0.1489
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 236.81095695495605 seconds
Epoch 197 accuracy: 96.54%
Batch 100, Loss: 0.1428
Batch 200, Loss: 0.1443
Batch 300, Loss: 0.1475
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 236.90938591957092 seconds
Epoch 198 accuracy: 96.35%
Batch 100, Loss: 0.1408
Batch 200, Loss: 0.1406
Batch 300, Loss: 0.1468
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 236.58287453651428 seconds
Epoch 199 accuracy: 96.46%
Batch 100, Loss: 0.1443
Batch 200, Loss: 0.1445
Batch 300, Loss: 0.1488
Epoch 200 learning rate: 0.0
Epoch 200 time: 236.70726656913757 seconds
Epoch 200 accuracy: 96.31%
rho:  0.04 , alpha:  0.3
Total training time: 47351.15995025635 seconds
