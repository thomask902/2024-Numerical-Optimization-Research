The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1083
Batch 20, Loss: 4.1285
Batch 30, Loss: 3.9358
Batch 40, Loss: 3.7580
Batch 50, Loss: 3.6865
Batch 60, Loss: 3.6833
Batch 70, Loss: 3.6561
Batch 80, Loss: 3.6540
Batch 90, Loss: 3.5810
Batch 100, Loss: 3.5987
Batch 110, Loss: 3.5915
Batch 120, Loss: 3.5898
Batch 130, Loss: 3.5948
Batch 140, Loss: 3.5473
Batch 150, Loss: 3.5682
Batch 160, Loss: 3.5398
Batch 170, Loss: 3.5368
Batch 180, Loss: 3.5321
Batch 190, Loss: 3.5414
Batch 200, Loss: 3.5512
Batch 210, Loss: 3.5455
Batch 220, Loss: 3.5303
Batch 230, Loss: 3.5214
Batch 240, Loss: 3.4896
Batch 250, Loss: 3.5180
Batch 260, Loss: 3.4993
Batch 270, Loss: 3.4718
Batch 280, Loss: 3.5340
Batch 290, Loss: 3.4930
Batch 300, Loss: 3.4432
Batch 310, Loss: 3.4812
Batch 320, Loss: 3.4428
Batch 330, Loss: 3.4872
Batch 340, Loss: 3.4406
Batch 350, Loss: 3.4473
Batch 360, Loss: 3.4867
Batch 370, Loss: 3.4028
Batch 380, Loss: 3.4891
Batch 390, Loss: 3.4327
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.490817308425903 seconds
Epoch 1 accuracy: 8.44%
Batch 10, Loss: 3.3795
Batch 20, Loss: 3.3791
Batch 30, Loss: 3.4349
Batch 40, Loss: 3.4206
Batch 50, Loss: 3.4326
Batch 60, Loss: 3.4218
Batch 70, Loss: 3.3690
Batch 80, Loss: 3.3929
Batch 90, Loss: 3.3716
Batch 100, Loss: 3.3703
Batch 110, Loss: 3.3681
Batch 120, Loss: 3.3521
Batch 130, Loss: 3.3736
Batch 140, Loss: 3.4158
Batch 150, Loss: 3.4000
Batch 160, Loss: 3.3676
Batch 170, Loss: 3.3241
Batch 180, Loss: 3.3028
Batch 190, Loss: 3.3482
Batch 200, Loss: 3.3501
Batch 210, Loss: 3.2718
Batch 220, Loss: 3.3100
Batch 230, Loss: 3.3104
Batch 240, Loss: 3.2691
Batch 250, Loss: 3.2990
Batch 260, Loss: 3.2614
Batch 270, Loss: 3.3175
Batch 280, Loss: 3.2703
Batch 290, Loss: 3.2583
Batch 300, Loss: 3.2572
Batch 310, Loss: 3.2584
Batch 320, Loss: 3.2688
Batch 330, Loss: 3.2649
Batch 340, Loss: 3.2357
Batch 350, Loss: 3.2592
Batch 360, Loss: 3.2276
Batch 370, Loss: 3.2007
Batch 380, Loss: 3.2074
Batch 390, Loss: 3.1890
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.41389226913452 seconds
Epoch 2 accuracy: 13.92%
Batch 10, Loss: 3.1929
Batch 20, Loss: 3.1944
Batch 30, Loss: 3.2116
Batch 40, Loss: 3.2313
Batch 50, Loss: 3.1625
Batch 60, Loss: 3.1964
Batch 70, Loss: 3.1791
Batch 80, Loss: 3.1561
Batch 90, Loss: 3.1413
Batch 100, Loss: 3.1374
Batch 110, Loss: 3.1169
Batch 120, Loss: 3.1017
Batch 130, Loss: 3.1496
Batch 140, Loss: 3.0774
Batch 150, Loss: 3.1047
Batch 160, Loss: 3.1103
Batch 170, Loss: 3.1185
Batch 180, Loss: 3.1019
Batch 190, Loss: 3.1264
Batch 200, Loss: 3.0700
Batch 210, Loss: 3.0923
Batch 220, Loss: 3.0437
Batch 230, Loss: 3.0535
Batch 240, Loss: 3.0421
Batch 250, Loss: 3.0806
Batch 260, Loss: 2.9979
Batch 270, Loss: 2.9694
Batch 280, Loss: 3.0299
Batch 290, Loss: 3.0126
Batch 300, Loss: 2.9895
Batch 310, Loss: 3.0202
Batch 320, Loss: 3.0039
Batch 330, Loss: 3.0260
Batch 340, Loss: 3.0125
Batch 350, Loss: 2.9519
Batch 360, Loss: 2.9870
Batch 370, Loss: 3.0328
Batch 380, Loss: 2.9317
Batch 390, Loss: 2.9547
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.369351387023926 seconds
Epoch 3 accuracy: 17.75%
Batch 10, Loss: 2.9669
Batch 20, Loss: 2.9566
Batch 30, Loss: 2.8965
Batch 40, Loss: 2.8855
Batch 50, Loss: 2.9002
Batch 60, Loss: 2.8281
Batch 70, Loss: 2.9509
Batch 80, Loss: 2.8527
Batch 90, Loss: 2.8549
Batch 100, Loss: 2.8579
Batch 110, Loss: 2.8517
Batch 120, Loss: 2.8639
Batch 130, Loss: 2.8031
Batch 140, Loss: 2.7831
Batch 150, Loss: 2.8406
Batch 160, Loss: 2.7539
Batch 170, Loss: 2.8059
Batch 180, Loss: 2.7409
Batch 190, Loss: 2.8585
Batch 200, Loss: 2.8105
Batch 210, Loss: 2.8293
Batch 220, Loss: 2.8075
Batch 230, Loss: 2.7939
Batch 240, Loss: 2.8046
Batch 250, Loss: 2.7225
Batch 260, Loss: 2.7447
Batch 270, Loss: 2.7207
Batch 280, Loss: 2.7315
Batch 290, Loss: 2.7129
Batch 300, Loss: 2.7377
Batch 310, Loss: 2.7165
Batch 320, Loss: 2.7112
Batch 330, Loss: 2.6618
Batch 340, Loss: 2.7342
Batch 350, Loss: 2.7080
Batch 360, Loss: 2.6523
Batch 370, Loss: 2.7154
Batch 380, Loss: 2.7014
Batch 390, Loss: 2.6953
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.362541675567627 seconds
Epoch 4 accuracy: 27.68%
Batch 10, Loss: 2.6243
Batch 20, Loss: 2.6431
Batch 30, Loss: 2.6561
Batch 40, Loss: 2.5759
Batch 50, Loss: 2.6064
Batch 60, Loss: 2.5246
Batch 70, Loss: 2.5445
Batch 80, Loss: 2.6614
Batch 90, Loss: 2.5952
Batch 100, Loss: 2.6273
Batch 110, Loss: 2.6189
Batch 120, Loss: 2.5771
Batch 130, Loss: 2.5484
Batch 140, Loss: 2.5418
Batch 150, Loss: 2.6417
Batch 160, Loss: 2.6538
Batch 170, Loss: 2.5567
Batch 180, Loss: 2.6224
Batch 190, Loss: 2.6158
Batch 200, Loss: 2.6350
Batch 210, Loss: 2.4996
Batch 220, Loss: 2.5424
Batch 230, Loss: 2.4578
Batch 240, Loss: 2.4665
Batch 250, Loss: 2.4623
Batch 260, Loss: 2.4635
Batch 270, Loss: 2.5339
Batch 280, Loss: 2.4887
Batch 290, Loss: 2.5003
Batch 300, Loss: 2.5158
Batch 310, Loss: 2.5031
Batch 320, Loss: 2.4692
Batch 330, Loss: 2.4658
Batch 340, Loss: 2.4552
Batch 350, Loss: 2.4152
Batch 360, Loss: 2.4627
Batch 370, Loss: 2.5339
Batch 380, Loss: 2.4535
Batch 390, Loss: 2.4741
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.274819374084473 seconds
Epoch 5 accuracy: 32.6%
Batch 10, Loss: 2.4739
Batch 20, Loss: 2.3085
Batch 30, Loss: 2.3442
Batch 40, Loss: 2.3767
Batch 50, Loss: 2.4494
Batch 60, Loss: 2.3835
Batch 70, Loss: 2.4634
Batch 80, Loss: 2.4215
Batch 90, Loss: 2.4333
Batch 100, Loss: 2.4142
Batch 110, Loss: 2.3169
Batch 120, Loss: 2.4205
Batch 130, Loss: 2.3557
Batch 140, Loss: 2.3477
Batch 150, Loss: 2.3427
Batch 160, Loss: 2.4488
Batch 170, Loss: 2.3677
Batch 180, Loss: 2.3722
Batch 190, Loss: 2.3943
Batch 200, Loss: 2.3389
Batch 210, Loss: 2.3129
Batch 220, Loss: 2.3336
Batch 230, Loss: 2.2790
Batch 240, Loss: 2.3222
Batch 250, Loss: 2.3792
Batch 260, Loss: 2.3453
Batch 270, Loss: 2.3703
Batch 280, Loss: 2.3333
Batch 290, Loss: 2.2631
Batch 300, Loss: 2.3267
Batch 310, Loss: 2.2716
Batch 320, Loss: 2.2982
Batch 330, Loss: 2.2224
Batch 340, Loss: 2.2295
Batch 350, Loss: 2.2734
Batch 360, Loss: 2.3386
Batch 370, Loss: 2.3040
Batch 380, Loss: 2.1738
Batch 390, Loss: 2.2609
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.39283847808838 seconds
Epoch 6 accuracy: 36.72%
Batch 10, Loss: 2.2419
Batch 20, Loss: 2.1921
Batch 30, Loss: 2.1422
Batch 40, Loss: 2.2313
Batch 50, Loss: 2.2169
Batch 60, Loss: 2.2580
Batch 70, Loss: 2.1790
Batch 80, Loss: 2.2422
Batch 90, Loss: 2.1203
Batch 100, Loss: 2.2106
Batch 110, Loss: 2.2157
Batch 120, Loss: 2.1658
Batch 130, Loss: 2.1538
Batch 140, Loss: 2.1365
Batch 150, Loss: 2.2000
Batch 160, Loss: 2.1886
Batch 170, Loss: 2.1335
Batch 180, Loss: 2.2131
Batch 190, Loss: 2.2317
Batch 200, Loss: 2.2351
Batch 210, Loss: 2.1826
Batch 220, Loss: 2.2175
Batch 230, Loss: 2.1484
Batch 240, Loss: 2.1342
Batch 250, Loss: 2.1622
Batch 260, Loss: 2.1436
Batch 270, Loss: 2.1604
Batch 280, Loss: 2.1966
Batch 290, Loss: 2.1412
Batch 300, Loss: 2.1313
Batch 310, Loss: 2.1404
Batch 320, Loss: 2.1928
Batch 330, Loss: 2.1667
Batch 340, Loss: 2.0812
Batch 350, Loss: 2.1747
Batch 360, Loss: 2.1101
Batch 370, Loss: 2.1839
Batch 380, Loss: 2.1369
Batch 390, Loss: 2.1719
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.351105213165283 seconds
Epoch 7 accuracy: 40.65%
Batch 10, Loss: 2.1517
Batch 20, Loss: 2.1307
Batch 30, Loss: 2.0839
Batch 40, Loss: 2.1391
Batch 50, Loss: 2.0170
Batch 60, Loss: 2.0446
Batch 70, Loss: 2.0632
Batch 80, Loss: 2.1497
Batch 90, Loss: 2.1023
Batch 100, Loss: 2.1047
Batch 110, Loss: 2.0294
Batch 120, Loss: 2.0534
Batch 130, Loss: 2.1391
Batch 140, Loss: 2.1157
Batch 150, Loss: 2.0674
Batch 160, Loss: 2.0771
Batch 170, Loss: 2.1323
Batch 180, Loss: 2.1203
Batch 190, Loss: 2.0901
Batch 200, Loss: 2.1428
Batch 210, Loss: 2.0742
Batch 220, Loss: 2.0558
Batch 230, Loss: 2.0781
Batch 240, Loss: 2.1081
Batch 250, Loss: 2.0384
Batch 260, Loss: 2.0701
Batch 270, Loss: 2.0718
Batch 280, Loss: 2.0308
Batch 290, Loss: 1.9558
Batch 300, Loss: 2.0331
Batch 310, Loss: 2.1203
Batch 320, Loss: 2.0393
Batch 330, Loss: 2.0128
Batch 340, Loss: 2.0442
Batch 350, Loss: 2.0329
Batch 360, Loss: 2.0196
Batch 370, Loss: 2.0695
Batch 380, Loss: 2.0567
Batch 390, Loss: 2.0724
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.41634440422058 seconds
Epoch 8 accuracy: 45.79%
Batch 10, Loss: 1.9544
Batch 20, Loss: 1.9989
Batch 30, Loss: 1.9666
Batch 40, Loss: 1.9777
Batch 50, Loss: 2.0350
Batch 60, Loss: 1.9881
Batch 70, Loss: 1.9786
Batch 80, Loss: 2.0255
Batch 90, Loss: 2.0245
Batch 100, Loss: 2.0179
Batch 110, Loss: 1.8767
Batch 120, Loss: 1.9116
Batch 130, Loss: 1.9465
Batch 140, Loss: 1.9792
Batch 150, Loss: 2.0100
Batch 160, Loss: 2.0014
Batch 170, Loss: 2.0119
Batch 180, Loss: 2.0182
Batch 190, Loss: 1.9979
Batch 200, Loss: 1.9496
Batch 210, Loss: 1.9553
Batch 220, Loss: 2.0159
Batch 230, Loss: 1.9868
Batch 240, Loss: 1.9810
Batch 250, Loss: 1.9758
Batch 260, Loss: 2.0218
Batch 270, Loss: 1.9663
Batch 280, Loss: 1.9702
Batch 290, Loss: 1.9496
Batch 300, Loss: 1.9680
Batch 310, Loss: 1.9524
Batch 320, Loss: 1.9653
Batch 330, Loss: 1.9452
Batch 340, Loss: 1.9923
Batch 350, Loss: 2.0211
Batch 360, Loss: 1.9558
Batch 370, Loss: 1.9853
Batch 380, Loss: 1.9162
Batch 390, Loss: 1.9312
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.38851022720337 seconds
Epoch 9 accuracy: 45.25%
Batch 10, Loss: 1.9554
Batch 20, Loss: 1.8929
Batch 30, Loss: 2.0225
Batch 40, Loss: 1.8800
Batch 50, Loss: 1.8254
Batch 60, Loss: 1.8784
Batch 70, Loss: 2.0108
Batch 80, Loss: 1.9130
Batch 90, Loss: 1.8931
Batch 100, Loss: 1.9220
Batch 110, Loss: 1.9075
Batch 120, Loss: 1.8677
Batch 130, Loss: 1.9396
Batch 140, Loss: 1.9012
Batch 150, Loss: 1.9164
Batch 160, Loss: 1.8912
Batch 170, Loss: 1.9005
Batch 180, Loss: 1.9703
Batch 190, Loss: 1.9516
Batch 200, Loss: 1.8564
Batch 210, Loss: 1.8954
Batch 220, Loss: 1.9384
Batch 230, Loss: 1.9490
Batch 240, Loss: 1.8800
Batch 250, Loss: 1.9096
Batch 260, Loss: 1.8744
Batch 270, Loss: 1.8789
Batch 280, Loss: 1.9006
Batch 290, Loss: 1.8561
Batch 300, Loss: 1.8214
Batch 310, Loss: 1.9283
Batch 320, Loss: 1.8665
Batch 330, Loss: 1.8972
Batch 340, Loss: 1.9033
Batch 350, Loss: 1.9216
Batch 360, Loss: 1.8497
Batch 370, Loss: 1.9264
Batch 380, Loss: 1.9128
Batch 390, Loss: 1.8479
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.42523217201233 seconds
Epoch 10 accuracy: 40.78%
Batch 10, Loss: 1.8053
Batch 20, Loss: 1.8538
Batch 30, Loss: 1.8236
Batch 40, Loss: 1.8241
Batch 50, Loss: 1.8478
Batch 60, Loss: 1.8080
Batch 70, Loss: 1.8550
Batch 80, Loss: 1.8946
Batch 90, Loss: 1.8601
Batch 100, Loss: 1.9014
Batch 110, Loss: 1.8592
Batch 120, Loss: 1.8723
Batch 130, Loss: 1.8897
Batch 140, Loss: 1.8498
Batch 150, Loss: 1.8820
Batch 160, Loss: 1.9368
Batch 170, Loss: 1.8934
Batch 180, Loss: 1.8960
Batch 190, Loss: 1.8776
Batch 200, Loss: 1.8705
Batch 210, Loss: 1.8276
Batch 220, Loss: 1.8513
Batch 230, Loss: 1.8388
Batch 240, Loss: 1.9004
Batch 250, Loss: 1.9321
Batch 260, Loss: 1.7869
Batch 270, Loss: 1.8921
Batch 280, Loss: 1.8712
Batch 290, Loss: 1.8274
Batch 300, Loss: 1.8518
Batch 310, Loss: 1.8379
Batch 320, Loss: 1.7758
Batch 330, Loss: 1.8542
Batch 340, Loss: 1.8487
Batch 350, Loss: 1.7542
Batch 360, Loss: 1.8365
Batch 370, Loss: 1.8121
Batch 380, Loss: 1.8824
Batch 390, Loss: 1.8527
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.384170055389404 seconds
Epoch 11 accuracy: 44.49%
Batch 10, Loss: 1.7707
Batch 20, Loss: 1.7897
Batch 30, Loss: 1.8525
Batch 40, Loss: 1.7634
Batch 50, Loss: 1.7938
Batch 60, Loss: 1.8069
Batch 70, Loss: 1.8084
Batch 80, Loss: 1.7836
Batch 90, Loss: 1.8096
Batch 100, Loss: 1.7587
Batch 110, Loss: 1.7889
Batch 120, Loss: 1.7599
Batch 130, Loss: 1.7641
Batch 140, Loss: 1.8172
Batch 150, Loss: 1.8837
Batch 160, Loss: 1.8220
Batch 170, Loss: 1.8165
Batch 180, Loss: 1.8012
Batch 190, Loss: 1.7952
Batch 200, Loss: 1.8452
Batch 210, Loss: 1.8034
Batch 220, Loss: 1.7965
Batch 230, Loss: 1.7932
Batch 240, Loss: 1.8659
Batch 250, Loss: 1.8575
Batch 260, Loss: 1.8805
Batch 270, Loss: 1.7800
Batch 280, Loss: 1.7804
Batch 290, Loss: 1.7955
Batch 300, Loss: 1.8136
Batch 310, Loss: 1.8512
Batch 320, Loss: 1.7875
Batch 330, Loss: 1.8710
Batch 340, Loss: 1.7817
Batch 350, Loss: 1.8389
Batch 360, Loss: 1.8124
Batch 370, Loss: 1.7803
Batch 380, Loss: 1.8043
Batch 390, Loss: 1.8468
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.367382764816284 seconds
Epoch 12 accuracy: 51.21%
Batch 10, Loss: 1.8516
Batch 20, Loss: 1.7907
Batch 30, Loss: 1.7285
Batch 40, Loss: 1.7878
Batch 50, Loss: 1.7757
Batch 60, Loss: 1.7476
Batch 70, Loss: 1.8134
Batch 80, Loss: 1.8038
Batch 90, Loss: 1.7366
Batch 100, Loss: 1.7988
Batch 110, Loss: 1.7618
Batch 120, Loss: 1.7804
Batch 130, Loss: 1.7903
Batch 140, Loss: 1.7754
Batch 150, Loss: 1.7754
Batch 160, Loss: 1.7539
Batch 170, Loss: 1.7527
Batch 180, Loss: 1.7853
Batch 190, Loss: 1.7873
Batch 200, Loss: 1.7229
Batch 210, Loss: 1.7097
Batch 220, Loss: 1.8688
Batch 230, Loss: 1.7698
Batch 240, Loss: 1.7900
Batch 250, Loss: 1.7743
Batch 260, Loss: 1.7768
Batch 270, Loss: 1.7272
Batch 280, Loss: 1.8023
Batch 290, Loss: 1.7845
Batch 300, Loss: 1.7439
Batch 310, Loss: 1.8085
Batch 320, Loss: 1.7838
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.8117
Batch 350, Loss: 1.7115
Batch 360, Loss: 1.7463
Batch 370, Loss: 1.8180
Batch 380, Loss: 1.8087
Batch 390, Loss: 1.8011
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.290245294570923 seconds
Epoch 13 accuracy: 51.0%
Batch 10, Loss: 1.7435
Batch 20, Loss: 1.7720
Batch 30, Loss: 1.7158
Batch 40, Loss: 1.7259
Batch 50, Loss: 1.7326
Batch 60, Loss: 1.7553
Batch 70, Loss: 1.7694
Batch 80, Loss: 1.7646
Batch 90, Loss: 1.7223
Batch 100, Loss: 1.7226
Batch 110, Loss: 1.7423
Batch 120, Loss: 1.8037
Batch 130, Loss: 1.7626
Batch 140, Loss: 1.7346
Batch 150, Loss: 1.7446
Batch 160, Loss: 1.7734
Batch 170, Loss: 1.7200
Batch 180, Loss: 1.7343
Batch 190, Loss: 1.7649
Batch 200, Loss: 1.8289
Batch 210, Loss: 1.7331
Batch 220, Loss: 1.7508
Batch 230, Loss: 1.6921
Batch 240, Loss: 1.6771
Batch 250, Loss: 1.7750
Batch 260, Loss: 1.7779
Batch 270, Loss: 1.7386
Batch 280, Loss: 1.7516
Batch 290, Loss: 1.7691
Batch 300, Loss: 1.8030
Batch 310, Loss: 1.7584
Batch 320, Loss: 1.7610
Batch 330, Loss: 1.7360
Batch 340, Loss: 1.7521
Batch 350, Loss: 1.6743
Batch 360, Loss: 1.8182
Batch 370, Loss: 1.7426
Batch 380, Loss: 1.7083
Batch 390, Loss: 1.8136
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.393946170806885 seconds
Epoch 14 accuracy: 50.08%
Batch 10, Loss: 1.6813
Batch 20, Loss: 1.7171
Batch 30, Loss: 1.6913
Batch 40, Loss: 1.6609
Batch 50, Loss: 1.7701
Batch 60, Loss: 1.7371
Batch 70, Loss: 1.7131
Batch 80, Loss: 1.7781
Batch 90, Loss: 1.7335
Batch 100, Loss: 1.7066
Batch 110, Loss: 1.6389
Batch 120, Loss: 1.6449
Batch 130, Loss: 1.6923
Batch 140, Loss: 1.6591
Batch 150, Loss: 1.6927
Batch 160, Loss: 1.7248
Batch 170, Loss: 1.7198
Batch 180, Loss: 1.7683
Batch 190, Loss: 1.7517
Batch 200, Loss: 1.7388
Batch 210, Loss: 1.6693
Batch 220, Loss: 1.6898
Batch 230, Loss: 1.6781
Batch 240, Loss: 1.7405
Batch 250, Loss: 1.7594
Batch 260, Loss: 1.7323
Batch 270, Loss: 1.7733
Batch 280, Loss: 1.7360
Batch 290, Loss: 1.7425
Batch 300, Loss: 1.7025
Batch 310, Loss: 1.7268
Batch 320, Loss: 1.7743
Batch 330, Loss: 1.7596
Batch 340, Loss: 1.6985
Batch 350, Loss: 1.7366
Batch 360, Loss: 1.7632
Batch 370, Loss: 1.6769
Batch 380, Loss: 1.6917
Batch 390, Loss: 1.6982
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.3232364654541 seconds
Epoch 15 accuracy: 48.74%
Batch 10, Loss: 1.6434
Batch 20, Loss: 1.6880
Batch 30, Loss: 1.6799
Batch 40, Loss: 1.6629
Batch 50, Loss: 1.6397
Batch 60, Loss: 1.6842
Batch 70, Loss: 1.6915
Batch 80, Loss: 1.7191
Batch 90, Loss: 1.7518
Batch 100, Loss: 1.6759
Batch 110, Loss: 1.6563
Batch 120, Loss: 1.7032
Batch 130, Loss: 1.6646
Batch 140, Loss: 1.7154
Batch 150, Loss: 1.7797
Batch 160, Loss: 1.6831
Batch 170, Loss: 1.7593
Batch 180, Loss: 1.6591
Batch 190, Loss: 1.6811
Batch 200, Loss: 1.6360
Batch 210, Loss: 1.6899
Batch 220, Loss: 1.7203
Batch 230, Loss: 1.6391
Batch 240, Loss: 1.6597
Batch 250, Loss: 1.6603
Batch 260, Loss: 1.6734
Batch 270, Loss: 1.6439
Batch 280, Loss: 1.6995
Batch 290, Loss: 1.7220
Batch 300, Loss: 1.7100
Batch 310, Loss: 1.7457
Batch 320, Loss: 1.7368
Batch 330, Loss: 1.6561
Batch 340, Loss: 1.7049
Batch 350, Loss: 1.6673
Batch 360, Loss: 1.6730
Batch 370, Loss: 1.6782
Batch 380, Loss: 1.7547
Batch 390, Loss: 1.7846
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.333626985549927 seconds
Epoch 16 accuracy: 46.78%
Batch 10, Loss: 1.7197
Batch 20, Loss: 1.5770
Batch 30, Loss: 1.6980
Batch 40, Loss: 1.6436
Batch 50, Loss: 1.6358
Batch 60, Loss: 1.6310
Batch 70, Loss: 1.6704
Batch 80, Loss: 1.6537
Batch 90, Loss: 1.7101
Batch 100, Loss: 1.6903
Batch 110, Loss: 1.6451
Batch 120, Loss: 1.6893
Batch 130, Loss: 1.7151
Batch 140, Loss: 1.6026
Batch 150, Loss: 1.6745
Batch 160, Loss: 1.7289
Batch 170, Loss: 1.6816
Batch 180, Loss: 1.5931
Batch 190, Loss: 1.6666
Batch 200, Loss: 1.7641
Batch 210, Loss: 1.7037
Batch 220, Loss: 1.7228
Batch 230, Loss: 1.6191
Batch 240, Loss: 1.7186
Batch 250, Loss: 1.6327
Batch 260, Loss: 1.6879
Batch 270, Loss: 1.6707
Batch 280, Loss: 1.6737
Batch 290, Loss: 1.7088
Batch 300, Loss: 1.6844
Batch 310, Loss: 1.7042
Batch 320, Loss: 1.6929
Batch 330, Loss: 1.6447
Batch 340, Loss: 1.6302
Batch 350, Loss: 1.6967
Batch 360, Loss: 1.6635
Batch 370, Loss: 1.6963
Batch 380, Loss: 1.6962
Batch 390, Loss: 1.7380
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.37643814086914 seconds
Epoch 17 accuracy: 51.99%
Batch 10, Loss: 1.6075
Batch 20, Loss: 1.6647
Batch 30, Loss: 1.5883
Batch 40, Loss: 1.6716
Batch 50, Loss: 1.6541
Batch 60, Loss: 1.6872
Batch 70, Loss: 1.6016
Batch 80, Loss: 1.6943
Batch 90, Loss: 1.5922
Batch 100, Loss: 1.5955
Batch 110, Loss: 1.6473
Batch 120, Loss: 1.6659
Batch 130, Loss: 1.6247
Batch 140, Loss: 1.6753
Batch 150, Loss: 1.6538
Batch 160, Loss: 1.7111
Batch 170, Loss: 1.5894
Batch 180, Loss: 1.6906
Batch 190, Loss: 1.6569
Batch 200, Loss: 1.6068
Batch 210, Loss: 1.6206
Batch 220, Loss: 1.6509
Batch 230, Loss: 1.6463
Batch 240, Loss: 1.6578
Batch 250, Loss: 1.6459
Batch 260, Loss: 1.6180
Batch 270, Loss: 1.6102
Batch 280, Loss: 1.6917
Batch 290, Loss: 1.6103
Batch 300, Loss: 1.6349
Batch 310, Loss: 1.6260
Batch 320, Loss: 1.6750
Batch 330, Loss: 1.6117
Batch 340, Loss: 1.6950
Batch 350, Loss: 1.6798
Batch 360, Loss: 1.6978
Batch 370, Loss: 1.6391
Batch 380, Loss: 1.6577
Batch 390, Loss: 1.6321
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.40744948387146 seconds
Epoch 18 accuracy: 50.76%
Batch 10, Loss: 1.6445
Batch 20, Loss: 1.6340
Batch 30, Loss: 1.6367
Batch 40, Loss: 1.6212
Batch 50, Loss: 1.6315
Batch 60, Loss: 1.6007
Batch 70, Loss: 1.6885
Batch 80, Loss: 1.6297
Batch 90, Loss: 1.6312
Batch 100, Loss: 1.6829
Batch 110, Loss: 1.6414
Batch 120, Loss: 1.6708
Batch 130, Loss: 1.5812
Batch 140, Loss: 1.7009
Batch 150, Loss: 1.6437
Batch 160, Loss: 1.6870
Batch 170, Loss: 1.6177
Batch 180, Loss: 1.6685
Batch 190, Loss: 1.7000
Batch 200, Loss: 1.5730
Batch 210, Loss: 1.6255
Batch 220, Loss: 1.6030
Batch 230, Loss: 1.6370
Batch 240, Loss: 1.6826
Batch 250, Loss: 1.6697
Batch 260, Loss: 1.6529
Batch 270, Loss: 1.5796
Batch 280, Loss: 1.6111
Batch 290, Loss: 1.6329
Batch 300, Loss: 1.6288
Batch 310, Loss: 1.6438
Batch 320, Loss: 1.6638
Batch 330, Loss: 1.6832
Batch 340, Loss: 1.6239
Batch 350, Loss: 1.6261
Batch 360, Loss: 1.5788
Batch 370, Loss: 1.6764
Batch 380, Loss: 1.6611
Batch 390, Loss: 1.6703
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.35383415222168 seconds
Epoch 19 accuracy: 52.79%
Batch 10, Loss: 1.6452
Batch 20, Loss: 1.5457
Batch 30, Loss: 1.5530
Batch 40, Loss: 1.5799
Batch 50, Loss: 1.6114
Batch 60, Loss: 1.5055
Batch 70, Loss: 1.5900
Batch 80, Loss: 1.6699
Batch 90, Loss: 1.6238
Batch 100, Loss: 1.5531
Batch 110, Loss: 1.6214
Batch 120, Loss: 1.6217
Batch 130, Loss: 1.5554
Batch 140, Loss: 1.6449
Batch 150, Loss: 1.6161
Batch 160, Loss: 1.6676
Batch 170, Loss: 1.6645
Batch 180, Loss: 1.6364
Batch 190, Loss: 1.5819
Batch 200, Loss: 1.7353
Batch 210, Loss: 1.6627
Batch 220, Loss: 1.6350
Batch 230, Loss: 1.6308
Batch 240, Loss: 1.6844
Batch 250, Loss: 1.5671
Batch 260, Loss: 1.5995
Batch 270, Loss: 1.6855
Batch 280, Loss: 1.6825
Batch 290, Loss: 1.6465
Batch 300, Loss: 1.6337
Batch 310, Loss: 1.6395
Batch 320, Loss: 1.5796
Batch 330, Loss: 1.5854
Batch 340, Loss: 1.5844
Batch 350, Loss: 1.6546
Batch 360, Loss: 1.6307
Batch 370, Loss: 1.6348
Batch 380, Loss: 1.5896
Batch 390, Loss: 1.6369
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.298980712890625 seconds
Epoch 20 accuracy: 54.34%
Batch 10, Loss: 1.5328
Batch 20, Loss: 1.5699
Batch 30, Loss: 1.5500
Batch 40, Loss: 1.5655
Batch 50, Loss: 1.6248
Batch 60, Loss: 1.6059
Batch 70, Loss: 1.6391
Batch 80, Loss: 1.6541
Batch 90, Loss: 1.5824
Batch 100, Loss: 1.6168
Batch 110, Loss: 1.6155
Batch 120, Loss: 1.6233
Batch 130, Loss: 1.6586
Batch 140, Loss: 1.5148
Batch 150, Loss: 1.6749
Batch 160, Loss: 1.5875
Batch 170, Loss: 1.5859
Batch 180, Loss: 1.6120
Batch 190, Loss: 1.6454
Batch 200, Loss: 1.6526
Batch 210, Loss: 1.6184
Batch 220, Loss: 1.6359
Batch 230, Loss: 1.6612
Batch 240, Loss: 1.6001
Batch 250, Loss: 1.6290
Batch 260, Loss: 1.6172
Batch 270, Loss: 1.6255
Batch 280, Loss: 1.6071
Batch 290, Loss: 1.6190
Batch 300, Loss: 1.6154
Batch 310, Loss: 1.6428
Batch 320, Loss: 1.6146
Batch 330, Loss: 1.5898
Batch 340, Loss: 1.5266
Batch 350, Loss: 1.6634
Batch 360, Loss: 1.5848
Batch 370, Loss: 1.5980
Batch 380, Loss: 1.6088
Batch 390, Loss: 1.6297
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.299004316329956 seconds
Epoch 21 accuracy: 54.86%
Batch 10, Loss: 1.5136
Batch 20, Loss: 1.5414
Batch 30, Loss: 1.5913
Batch 40, Loss: 1.5365
Batch 50, Loss: 1.5989
Batch 60, Loss: 1.5793
Batch 70, Loss: 1.5746
Batch 80, Loss: 1.5582
Batch 90, Loss: 1.5810
Batch 100, Loss: 1.6419
Batch 110, Loss: 1.5654
Batch 120, Loss: 1.5941
Batch 130, Loss: 1.5915
Batch 140, Loss: 1.6096
Batch 150, Loss: 1.6693
Batch 160, Loss: 1.5758
Batch 170, Loss: 1.6141
Batch 180, Loss: 1.6055
Batch 190, Loss: 1.5896
Batch 200, Loss: 1.6575
Batch 210, Loss: 1.6512
Batch 220, Loss: 1.6233
Batch 230, Loss: 1.6105
Batch 240, Loss: 1.6268
Batch 250, Loss: 1.6194
Batch 260, Loss: 1.5394
Batch 270, Loss: 1.5560
Batch 280, Loss: 1.6131
Batch 290, Loss: 1.6346
Batch 300, Loss: 1.5965
Batch 310, Loss: 1.6610
Batch 320, Loss: 1.5488
Batch 330, Loss: 1.5922
Batch 340, Loss: 1.6121
Batch 350, Loss: 1.5185
Batch 360, Loss: 1.6018
Batch 370, Loss: 1.6039
Batch 380, Loss: 1.5769
Batch 390, Loss: 1.6176
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.26854157447815 seconds
Epoch 22 accuracy: 53.53%
Batch 10, Loss: 1.5199
Batch 20, Loss: 1.5670
Batch 30, Loss: 1.5039
Batch 40, Loss: 1.5680
Batch 50, Loss: 1.6083
Batch 60, Loss: 1.5579
Batch 70, Loss: 1.5379
Batch 80, Loss: 1.5968
Batch 90, Loss: 1.5900
Batch 100, Loss: 1.5606
Batch 110, Loss: 1.5852
Batch 120, Loss: 1.5965
Batch 130, Loss: 1.6331
Batch 140, Loss: 1.6274
Batch 150, Loss: 1.6095
Batch 160, Loss: 1.5099
Batch 170, Loss: 1.5902
Batch 180, Loss: 1.5906
Batch 190, Loss: 1.6267
Batch 200, Loss: 1.6387
Batch 210, Loss: 1.5186
Batch 220, Loss: 1.5946
Batch 230, Loss: 1.6424
Batch 240, Loss: 1.5696
Batch 250, Loss: 1.6055
Batch 260, Loss: 1.6891
Batch 270, Loss: 1.6651
Batch 280, Loss: 1.7229
Batch 290, Loss: 1.6380
Batch 300, Loss: 1.5988
Batch 310, Loss: 1.5775
Batch 320, Loss: 1.6348
Batch 330, Loss: 1.5454
Batch 340, Loss: 1.5686
Batch 350, Loss: 1.5921
Batch 360, Loss: 1.5845
Batch 370, Loss: 1.6011
Batch 380, Loss: 1.6029
Batch 390, Loss: 1.5769
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.2838773727417 seconds
Epoch 23 accuracy: 53.46%
Batch 10, Loss: 1.5522
Batch 20, Loss: 1.5445
Batch 30, Loss: 1.4623
Batch 40, Loss: 1.6007
Batch 50, Loss: 1.5180
Batch 60, Loss: 1.5586
Batch 70, Loss: 1.5714
Batch 80, Loss: 1.6420
Batch 90, Loss: 1.5667
Batch 100, Loss: 1.4946
Batch 110, Loss: 1.5430
Batch 120, Loss: 1.5634
Batch 130, Loss: 1.5248
Batch 140, Loss: 1.5405
Batch 150, Loss: 1.6338
Batch 160, Loss: 1.5502
Batch 170, Loss: 1.6031
Batch 180, Loss: 1.6339
Batch 190, Loss: 1.6091
Batch 200, Loss: 1.5541
Batch 210, Loss: 1.5960
Batch 220, Loss: 1.5303
Batch 230, Loss: 1.5437
Batch 240, Loss: 1.5959
Batch 250, Loss: 1.5874
Batch 260, Loss: 1.6255
Batch 270, Loss: 1.6296
Batch 280, Loss: 1.5253
Batch 290, Loss: 1.4935
Batch 300, Loss: 1.5181
Batch 310, Loss: 1.6090
Batch 320, Loss: 1.5412
Batch 330, Loss: 1.6395
Batch 340, Loss: 1.5803
Batch 350, Loss: 1.6228
Batch 360, Loss: 1.6113
Batch 370, Loss: 1.5469
Batch 380, Loss: 1.5865
Batch 390, Loss: 1.6644
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.326537132263184 seconds
Epoch 24 accuracy: 53.06%
Batch 10, Loss: 1.5624
Batch 20, Loss: 1.5645
Batch 30, Loss: 1.5646
Batch 40, Loss: 1.5410
Batch 50, Loss: 1.4355
Batch 60, Loss: 1.4480
Batch 70, Loss: 1.5891
Batch 80, Loss: 1.5773
Batch 90, Loss: 1.5364
Batch 100, Loss: 1.5287
Batch 110, Loss: 1.5438
Batch 120, Loss: 1.6219
Batch 130, Loss: 1.5466
Batch 140, Loss: 1.6480
Batch 150, Loss: 1.5992
Batch 160, Loss: 1.5526
Batch 170, Loss: 1.5814
Batch 180, Loss: 1.5953
Batch 190, Loss: 1.5431
Batch 200, Loss: 1.5677
Batch 210, Loss: 1.6243
Batch 220, Loss: 1.5568
Batch 230, Loss: 1.5574
Batch 240, Loss: 1.5648
Batch 250, Loss: 1.5245
Batch 260, Loss: 1.5672
Batch 270, Loss: 1.5799
Batch 280, Loss: 1.5844
Batch 290, Loss: 1.6029
Batch 300, Loss: 1.4968
Batch 310, Loss: 1.5745
Batch 320, Loss: 1.4998
Batch 330, Loss: 1.5368
Batch 340, Loss: 1.5979
Batch 350, Loss: 1.5981
Batch 360, Loss: 1.5630
Batch 370, Loss: 1.6473
Batch 380, Loss: 1.5243
Batch 390, Loss: 1.5489
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.258588790893555 seconds
Epoch 25 accuracy: 53.68%
Batch 10, Loss: 1.4607
Batch 20, Loss: 1.5544
Batch 30, Loss: 1.5060
Batch 40, Loss: 1.4898
Batch 50, Loss: 1.5574
Batch 60, Loss: 1.4673
Batch 70, Loss: 1.5175
Batch 80, Loss: 1.5395
Batch 90, Loss: 1.5521
Batch 100, Loss: 1.5028
Batch 110, Loss: 1.5432
Batch 120, Loss: 1.5348
Batch 130, Loss: 1.5412
Batch 140, Loss: 1.5910
Batch 150, Loss: 1.6039
Batch 160, Loss: 1.5797
Batch 170, Loss: 1.5595
Batch 180, Loss: 1.5208
Batch 190, Loss: 1.5270
Batch 200, Loss: 1.5937
Batch 210, Loss: 1.5589
Batch 220, Loss: 1.5760
Batch 230, Loss: 1.4825
Batch 240, Loss: 1.5900
Batch 250, Loss: 1.5693
Batch 260, Loss: 1.5555
Batch 270, Loss: 1.5205
Batch 280, Loss: 1.5163
Batch 290, Loss: 1.5965
Batch 300, Loss: 1.5814
Batch 310, Loss: 1.5254
Batch 320, Loss: 1.5065
Batch 330, Loss: 1.5087
Batch 340, Loss: 1.5557
Batch 350, Loss: 1.5767
Batch 360, Loss: 1.6244
Batch 370, Loss: 1.5460
Batch 380, Loss: 1.5987
Batch 390, Loss: 1.5879
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.3123517036438 seconds
Epoch 26 accuracy: 55.39%
Batch 10, Loss: 1.4595
Batch 20, Loss: 1.4210
Batch 30, Loss: 1.4812
Batch 40, Loss: 1.5027
Batch 50, Loss: 1.4834
Batch 60, Loss: 1.5447
Batch 70, Loss: 1.5191
Batch 80, Loss: 1.5011
Batch 90, Loss: 1.5209
Batch 100, Loss: 1.5172
Batch 110, Loss: 1.5798
Batch 120, Loss: 1.5705
Batch 130, Loss: 1.5196
Batch 140, Loss: 1.5398
Batch 150, Loss: 1.5375
Batch 160, Loss: 1.5424
Batch 170, Loss: 1.4952
Batch 180, Loss: 1.6365
Batch 190, Loss: 1.4964
Batch 200, Loss: 1.6244
Batch 210, Loss: 1.5661
Batch 220, Loss: 1.5167
Batch 230, Loss: 1.5802
Batch 240, Loss: 1.5371
Batch 250, Loss: 1.5083
Batch 260, Loss: 1.5061
Batch 270, Loss: 1.5777
Batch 280, Loss: 1.5873
Batch 290, Loss: 1.5763
Batch 300, Loss: 1.5512
Batch 310, Loss: 1.5728
Batch 320, Loss: 1.5834
Batch 330, Loss: 1.6296
Batch 340, Loss: 1.5486
Batch 350, Loss: 1.5164
Batch 360, Loss: 1.5815
Batch 370, Loss: 1.5240
Batch 380, Loss: 1.5278
Batch 390, Loss: 1.6416
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.327322483062744 seconds
Epoch 27 accuracy: 52.67%
Batch 10, Loss: 1.5869
Batch 20, Loss: 1.5160
Batch 30, Loss: 1.4999
Batch 40, Loss: 1.4882
Batch 50, Loss: 1.5144
Batch 60, Loss: 1.4895
Batch 70, Loss: 1.5136
Batch 80, Loss: 1.4538
Batch 90, Loss: 1.5798
Batch 100, Loss: 1.5854
Batch 110, Loss: 1.5618
Batch 120, Loss: 1.5373
Batch 130, Loss: 1.5544
Batch 140, Loss: 1.4686
Batch 150, Loss: 1.5924
Batch 160, Loss: 1.5960
Batch 170, Loss: 1.5417
Batch 180, Loss: 1.5321
Batch 190, Loss: 1.5122
Batch 200, Loss: 1.5446
Batch 210, Loss: 1.5339
Batch 220, Loss: 1.5465
Batch 230, Loss: 1.5157
Batch 240, Loss: 1.5267
Batch 250, Loss: 1.5073
Batch 260, Loss: 1.5503
Batch 270, Loss: 1.5503
Batch 280, Loss: 1.4622
Batch 290, Loss: 1.5118
Batch 300, Loss: 1.6066
Batch 310, Loss: 1.5472
Batch 320, Loss: 1.5403
Batch 330, Loss: 1.5694
Batch 340, Loss: 1.5604
Batch 350, Loss: 1.5780
Batch 360, Loss: 1.5271
Batch 370, Loss: 1.6249
Batch 380, Loss: 1.6119
Batch 390, Loss: 1.6345
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.375808477401733 seconds
Epoch 28 accuracy: 53.2%
Batch 10, Loss: 1.4375
Batch 20, Loss: 1.4681
Batch 30, Loss: 1.5376
Batch 40, Loss: 1.4763
Batch 50, Loss: 1.4534
Batch 60, Loss: 1.5116
Batch 70, Loss: 1.4943
Batch 80, Loss: 1.4747
Batch 90, Loss: 1.5728
Batch 100, Loss: 1.5578
Batch 110, Loss: 1.4556
Batch 120, Loss: 1.4635
Batch 130, Loss: 1.5252
Batch 140, Loss: 1.5847
Batch 150, Loss: 1.5226
Batch 160, Loss: 1.5321
Batch 170, Loss: 1.5116
Batch 180, Loss: 1.5019
Batch 190, Loss: 1.5301
Batch 200, Loss: 1.5622
Batch 210, Loss: 1.4645
Batch 220, Loss: 1.4822
Batch 230, Loss: 1.5103
Batch 240, Loss: 1.6288
Batch 250, Loss: 1.5691
Batch 260, Loss: 1.5011
Batch 270, Loss: 1.4750
Batch 280, Loss: 1.5668
Batch 290, Loss: 1.5210
Batch 300, Loss: 1.5226
Batch 310, Loss: 1.5478
Batch 320, Loss: 1.6307
Batch 330, Loss: 1.5807
Batch 340, Loss: 1.6338
Batch 350, Loss: 1.5386
Batch 360, Loss: 1.6287
Batch 370, Loss: 1.5716
Batch 380, Loss: 1.4742
Batch 390, Loss: 1.5442
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.303836584091187 seconds
Epoch 29 accuracy: 51.83%
Batch 10, Loss: 1.4936
Batch 20, Loss: 1.5071
Batch 30, Loss: 1.4576
Batch 40, Loss: 1.4241
Batch 50, Loss: 1.5211
Batch 60, Loss: 1.5413
Batch 70, Loss: 1.4638
Batch 80, Loss: 1.5062
Batch 90, Loss: 1.5479
Batch 100, Loss: 1.4478
Batch 110, Loss: 1.4566
Batch 120, Loss: 1.5028
Batch 130, Loss: 1.5139
Batch 140, Loss: 1.4917
Batch 150, Loss: 1.5129
Batch 160, Loss: 1.5584
Batch 170, Loss: 1.4842
Batch 180, Loss: 1.4798
Batch 190, Loss: 1.4577
Batch 200, Loss: 1.5601
Batch 210, Loss: 1.5826
Batch 220, Loss: 1.5019
Batch 230, Loss: 1.5388
Batch 240, Loss: 1.5129
Batch 250, Loss: 1.4926
Batch 260, Loss: 1.6101
Batch 270, Loss: 1.4816
Batch 280, Loss: 1.5025
Batch 290, Loss: 1.4998
Batch 300, Loss: 1.4747
Batch 310, Loss: 1.5566
Batch 320, Loss: 1.5205
Batch 330, Loss: 1.5440
Batch 340, Loss: 1.5430
Batch 350, Loss: 1.5390
Batch 360, Loss: 1.5506
Batch 370, Loss: 1.4864
Batch 380, Loss: 1.5463
Batch 390, Loss: 1.6275
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.274396657943726 seconds
Epoch 30 accuracy: 56.97%
Batch 10, Loss: 1.5000
Batch 20, Loss: 1.5042
Batch 30, Loss: 1.4518
Batch 40, Loss: 1.5179
Batch 50, Loss: 1.4786
Batch 60, Loss: 1.4932
Batch 70, Loss: 1.5197
Batch 80, Loss: 1.5510
Batch 90, Loss: 1.4966
Batch 100, Loss: 1.4910
Batch 110, Loss: 1.4884
Batch 120, Loss: 1.4130
Batch 130, Loss: 1.4635
Batch 140, Loss: 1.4753
Batch 150, Loss: 1.5301
Batch 160, Loss: 1.4919
Batch 170, Loss: 1.5766
Batch 180, Loss: 1.5187
Batch 190, Loss: 1.5656
Batch 200, Loss: 1.5322
Batch 210, Loss: 1.4846
Batch 220, Loss: 1.5121
Batch 230, Loss: 1.4552
Batch 240, Loss: 1.5607
Batch 250, Loss: 1.5298
Batch 260, Loss: 1.5432
Batch 270, Loss: 1.5843
Batch 280, Loss: 1.5473
Batch 290, Loss: 1.4881
Batch 300, Loss: 1.5395
Batch 310, Loss: 1.5431
Batch 320, Loss: 1.4380
Batch 330, Loss: 1.4944
Batch 340, Loss: 1.5045
Batch 350, Loss: 1.5744
Batch 360, Loss: 1.4812
Batch 370, Loss: 1.4990
Batch 380, Loss: 1.5210
Batch 390, Loss: 1.5197
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.3938467502594 seconds
Epoch 31 accuracy: 58.7%
Batch 10, Loss: 1.4642
Batch 20, Loss: 1.5101
Batch 30, Loss: 1.5066
Batch 40, Loss: 1.5092
Batch 50, Loss: 1.4495
Batch 60, Loss: 1.4537
Batch 70, Loss: 1.4215
Batch 80, Loss: 1.4108
Batch 90, Loss: 1.4747
Batch 100, Loss: 1.4817
Batch 110, Loss: 1.4762
Batch 120, Loss: 1.5669
Batch 130, Loss: 1.5253
Batch 140, Loss: 1.5052
Batch 150, Loss: 1.5109
Batch 160, Loss: 1.5339
Batch 170, Loss: 1.5058
Batch 180, Loss: 1.4652
Batch 190, Loss: 1.5356
Batch 200, Loss: 1.5039
Batch 210, Loss: 1.4538
Batch 220, Loss: 1.5024
Batch 230, Loss: 1.4825
Batch 240, Loss: 1.5036
Batch 250, Loss: 1.4768
Batch 260, Loss: 1.5949
Batch 270, Loss: 1.5650
Batch 280, Loss: 1.4532
Batch 290, Loss: 1.5332
Batch 300, Loss: 1.5204
Batch 310, Loss: 1.5371
Batch 320, Loss: 1.5608
Batch 330, Loss: 1.5322
Batch 340, Loss: 1.4807
Batch 350, Loss: 1.5062
Batch 360, Loss: 1.5063
Batch 370, Loss: 1.4982
Batch 380, Loss: 1.5104
Batch 390, Loss: 1.4868
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.374691009521484 seconds
Epoch 32 accuracy: 53.73%
Batch 10, Loss: 1.4520
Batch 20, Loss: 1.4941
Batch 30, Loss: 1.4445
Batch 40, Loss: 1.3756
Batch 50, Loss: 1.4961
Batch 60, Loss: 1.4827
Batch 70, Loss: 1.4812
Batch 80, Loss: 1.4896
Batch 90, Loss: 1.5209
Batch 100, Loss: 1.5146
Batch 110, Loss: 1.5094
Batch 120, Loss: 1.5108
Batch 130, Loss: 1.4642
Batch 140, Loss: 1.5135
Batch 150, Loss: 1.3900
Batch 160, Loss: 1.4292
Batch 170, Loss: 1.5227
Batch 180, Loss: 1.4880
Batch 190, Loss: 1.4983
Batch 200, Loss: 1.4676
Batch 210, Loss: 1.5467
Batch 220, Loss: 1.4973
Batch 230, Loss: 1.4760
Batch 240, Loss: 1.5351
Batch 250, Loss: 1.5105
Batch 260, Loss: 1.5074
Batch 270, Loss: 1.5929
Batch 280, Loss: 1.5353
Batch 290, Loss: 1.4594
Batch 300, Loss: 1.5917
Batch 310, Loss: 1.4981
Batch 320, Loss: 1.4633
Batch 330, Loss: 1.5890
Batch 340, Loss: 1.4925
Batch 350, Loss: 1.5003
Batch 360, Loss: 1.5302
Batch 370, Loss: 1.5701
Batch 380, Loss: 1.5343
Batch 390, Loss: 1.4955
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.331998348236084 seconds
Epoch 33 accuracy: 52.46%
Batch 10, Loss: 1.4071
Batch 20, Loss: 1.4050
Batch 30, Loss: 1.4232
Batch 40, Loss: 1.4084
Batch 50, Loss: 1.5030
Batch 60, Loss: 1.4554
Batch 70, Loss: 1.4034
Batch 80, Loss: 1.4897
Batch 90, Loss: 1.5014
Batch 100, Loss: 1.4894
Batch 110, Loss: 1.5240
Batch 120, Loss: 1.4758
Batch 130, Loss: 1.4831
Batch 140, Loss: 1.4967
Batch 150, Loss: 1.5315
Batch 160, Loss: 1.5446
Batch 170, Loss: 1.4692
Batch 180, Loss: 1.4652
Batch 190, Loss: 1.5735
Batch 200, Loss: 1.5509
Batch 210, Loss: 1.5038
Batch 220, Loss: 1.4947
Batch 230, Loss: 1.4902
Batch 240, Loss: 1.5341
Batch 250, Loss: 1.5380
Batch 260, Loss: 1.5405
Batch 270, Loss: 1.4773
Batch 280, Loss: 1.5109
Batch 290, Loss: 1.5029
Batch 300, Loss: 1.5234
Batch 310, Loss: 1.5091
Batch 320, Loss: 1.4587
Batch 330, Loss: 1.4200
Batch 340, Loss: 1.4838
Batch 350, Loss: 1.5224
Batch 360, Loss: 1.4794
Batch 370, Loss: 1.5768
Batch 380, Loss: 1.4855
Batch 390, Loss: 1.5949
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.277843713760376 seconds
Epoch 34 accuracy: 55.61%
Batch 10, Loss: 1.4185
Batch 20, Loss: 1.4135
Batch 30, Loss: 1.5443
Batch 40, Loss: 1.5081
Batch 50, Loss: 1.4915
Batch 60, Loss: 1.4710
Batch 70, Loss: 1.5321
Batch 80, Loss: 1.4980
Batch 90, Loss: 1.5140
Batch 100, Loss: 1.4891
Batch 110, Loss: 1.4372
Batch 120, Loss: 1.4703
Batch 130, Loss: 1.4920
Batch 140, Loss: 1.4207
Batch 150, Loss: 1.4772
Batch 160, Loss: 1.5125
Batch 170, Loss: 1.4838
Batch 180, Loss: 1.4700
Batch 190, Loss: 1.4757
Batch 200, Loss: 1.5228
Batch 210, Loss: 1.4388
Batch 220, Loss: 1.5645
Batch 230, Loss: 1.4547
Batch 240, Loss: 1.4173
Batch 250, Loss: 1.5312
Batch 260, Loss: 1.5100
Batch 270, Loss: 1.4576
Batch 280, Loss: 1.5180
Batch 290, Loss: 1.4739
Batch 300, Loss: 1.4573
Batch 310, Loss: 1.4468
Batch 320, Loss: 1.4433
Batch 330, Loss: 1.4518
Batch 340, Loss: 1.5243
Batch 350, Loss: 1.4257
Batch 360, Loss: 1.5296
Batch 370, Loss: 1.5368
Batch 380, Loss: 1.5007
Batch 390, Loss: 1.5061
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.361568689346313 seconds
Epoch 35 accuracy: 55.12%
Batch 10, Loss: 1.5262
Batch 20, Loss: 1.4653
Batch 30, Loss: 1.4547
Batch 40, Loss: 1.4033
Batch 50, Loss: 1.4181
Batch 60, Loss: 1.4216
Batch 70, Loss: 1.4411
Batch 80, Loss: 1.4682
Batch 90, Loss: 1.5644
Batch 100, Loss: 1.4937
Batch 110, Loss: 1.5554
Batch 120, Loss: 1.5311
Batch 130, Loss: 1.4789
Batch 140, Loss: 1.4683
Batch 150, Loss: 1.4610
Batch 160, Loss: 1.5019
Batch 170, Loss: 1.4935
Batch 180, Loss: 1.5246
Batch 190, Loss: 1.4692
Batch 200, Loss: 1.5131
Batch 210, Loss: 1.5116
Batch 220, Loss: 1.5025
Batch 230, Loss: 1.4121
Batch 240, Loss: 1.4968
Batch 250, Loss: 1.5241
Batch 260, Loss: 1.4821
Batch 270, Loss: 1.4658
Batch 280, Loss: 1.5458
Batch 290, Loss: 1.5227
Batch 300, Loss: 1.4926
Batch 310, Loss: 1.5061
Batch 320, Loss: 1.4790
Batch 330, Loss: 1.4442
Batch 340, Loss: 1.4632
Batch 350, Loss: 1.5194
Batch 360, Loss: 1.4631
Batch 370, Loss: 1.5381
Batch 380, Loss: 1.4572
Batch 390, Loss: 1.4949
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.326401948928833 seconds
Epoch 36 accuracy: 56.58%
Batch 10, Loss: 1.4516
Batch 20, Loss: 1.5271
Batch 30, Loss: 1.4440
Batch 40, Loss: 1.4543
Batch 50, Loss: 1.4048
Batch 60, Loss: 1.4364
Batch 70, Loss: 1.4164
Batch 80, Loss: 1.4946
Batch 90, Loss: 1.5108
Batch 100, Loss: 1.4580
Batch 110, Loss: 1.4445
Batch 120, Loss: 1.4858
Batch 130, Loss: 1.5201
Batch 140, Loss: 1.4992
Batch 150, Loss: 1.4573
Batch 160, Loss: 1.5078
Batch 170, Loss: 1.4493
Batch 180, Loss: 1.4442
Batch 190, Loss: 1.4668
Batch 200, Loss: 1.5091
Batch 210, Loss: 1.4550
Batch 220, Loss: 1.5050
Batch 230, Loss: 1.4210
Batch 240, Loss: 1.5119
Batch 250, Loss: 1.5207
Batch 260, Loss: 1.4341
Batch 270, Loss: 1.4586
Batch 280, Loss: 1.4652
Batch 290, Loss: 1.5060
Batch 300, Loss: 1.4832
Batch 310, Loss: 1.5130
Batch 320, Loss: 1.4239
Batch 330, Loss: 1.5057
Batch 340, Loss: 1.3951
Batch 350, Loss: 1.4599
Batch 360, Loss: 1.4992
Batch 370, Loss: 1.4561
Batch 380, Loss: 1.5640
Batch 390, Loss: 1.5219
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.310569286346436 seconds
Epoch 37 accuracy: 52.73%
Batch 10, Loss: 1.4204
Batch 20, Loss: 1.4449
Batch 30, Loss: 1.4811
Batch 40, Loss: 1.3950
Batch 50, Loss: 1.4536
Batch 60, Loss: 1.4552
Batch 70, Loss: 1.4740
Batch 80, Loss: 1.3688
Batch 90, Loss: 1.5012
Batch 100, Loss: 1.4666
Batch 110, Loss: 1.4715
Batch 120, Loss: 1.4731
Batch 130, Loss: 1.4398
Batch 140, Loss: 1.4907
Batch 150, Loss: 1.4218
Batch 160, Loss: 1.4818
Batch 170, Loss: 1.4817
Batch 180, Loss: 1.4592
Batch 190, Loss: 1.4302
Batch 200, Loss: 1.4576
Batch 210, Loss: 1.4897
Batch 220, Loss: 1.4855
Batch 230, Loss: 1.4555
Batch 240, Loss: 1.4623
Batch 250, Loss: 1.4698
Batch 260, Loss: 1.4919
Batch 270, Loss: 1.4554
Batch 280, Loss: 1.4764
Batch 290, Loss: 1.4947
Batch 300, Loss: 1.5235
Batch 310, Loss: 1.5269
Batch 320, Loss: 1.4713
Batch 330, Loss: 1.5027
Batch 340, Loss: 1.4502
Batch 350, Loss: 1.4680
Batch 360, Loss: 1.4749
Batch 370, Loss: 1.6002
Batch 380, Loss: 1.4807
Batch 390, Loss: 1.5037
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.260120391845703 seconds
Epoch 38 accuracy: 54.85%
Batch 10, Loss: 1.3955
Batch 20, Loss: 1.4153
Batch 30, Loss: 1.4187
Batch 40, Loss: 1.4851
Batch 50, Loss: 1.4815
Batch 60, Loss: 1.4274
Batch 70, Loss: 1.4219
Batch 80, Loss: 1.4462
Batch 90, Loss: 1.4960
Batch 100, Loss: 1.5145
Batch 110, Loss: 1.5084
Batch 120, Loss: 1.4856
Batch 130, Loss: 1.4795
Batch 140, Loss: 1.4878
Batch 150, Loss: 1.4331
Batch 160, Loss: 1.3941
Batch 170, Loss: 1.4635
Batch 180, Loss: 1.5040
Batch 190, Loss: 1.4650
Batch 200, Loss: 1.4380
Batch 210, Loss: 1.5012
Batch 220, Loss: 1.4177
Batch 230, Loss: 1.4528
Batch 240, Loss: 1.5028
Batch 250, Loss: 1.4415
Batch 260, Loss: 1.4757
Batch 270, Loss: 1.4525
Batch 280, Loss: 1.4674
Batch 290, Loss: 1.5077
Batch 300, Loss: 1.4762
Batch 310, Loss: 1.4502
Batch 320, Loss: 1.4664
Batch 330, Loss: 1.5040
Batch 340, Loss: 1.4750
Batch 350, Loss: 1.4745
Batch 360, Loss: 1.4802
Batch 370, Loss: 1.4952
Batch 380, Loss: 1.4553
Batch 390, Loss: 1.4243
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.24682927131653 seconds
Epoch 39 accuracy: 57.88%
Batch 10, Loss: 1.3857
Batch 20, Loss: 1.4330
Batch 30, Loss: 1.4300
Batch 40, Loss: 1.4098
Batch 50, Loss: 1.3716
Batch 60, Loss: 1.4784
Batch 70, Loss: 1.4100
Batch 80, Loss: 1.5083
Batch 90, Loss: 1.4119
Batch 100, Loss: 1.4682
Batch 110, Loss: 1.4965
Batch 120, Loss: 1.4725
Batch 130, Loss: 1.4448
Batch 140, Loss: 1.4898
Batch 150, Loss: 1.4456
Batch 160, Loss: 1.3949
Batch 170, Loss: 1.4503
Batch 180, Loss: 1.5114
Batch 190, Loss: 1.3906
Batch 200, Loss: 1.4625
Batch 210, Loss: 1.4258
Batch 220, Loss: 1.4410
Batch 230, Loss: 1.5282
Batch 240, Loss: 1.5491
Batch 250, Loss: 1.5029
Batch 260, Loss: 1.5205
Batch 270, Loss: 1.4309
Batch 280, Loss: 1.4784
Batch 290, Loss: 1.4960
Batch 300, Loss: 1.5223
Batch 310, Loss: 1.4604
Batch 320, Loss: 1.4270
Batch 330, Loss: 1.4712
Batch 340, Loss: 1.4423
Batch 350, Loss: 1.4196
Batch 360, Loss: 1.4745
Batch 370, Loss: 1.4301
Batch 380, Loss: 1.5527
Batch 390, Loss: 1.4667
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.313518047332764 seconds
Epoch 40 accuracy: 57.82%
Batch 10, Loss: 1.4135
Batch 20, Loss: 1.3987
Batch 30, Loss: 1.3918
Batch 40, Loss: 1.3756
Batch 50, Loss: 1.4855
Batch 60, Loss: 1.4359
Batch 70, Loss: 1.4613
Batch 80, Loss: 1.4336
Batch 90, Loss: 1.4495
Batch 100, Loss: 1.4794
Batch 110, Loss: 1.4508
Batch 120, Loss: 1.4334
Batch 130, Loss: 1.4525
Batch 140, Loss: 1.5456
Batch 150, Loss: 1.4253
Batch 160, Loss: 1.4824
Batch 170, Loss: 1.4609
Batch 180, Loss: 1.4320
Batch 190, Loss: 1.4673
Batch 200, Loss: 1.4225
Batch 210, Loss: 1.4911
Batch 220, Loss: 1.3942
Batch 230, Loss: 1.4354
Batch 240, Loss: 1.3994
Batch 250, Loss: 1.4884
Batch 260, Loss: 1.5109
Batch 270, Loss: 1.4196
Batch 280, Loss: 1.4074
Batch 290, Loss: 1.4851
Batch 300, Loss: 1.4998
Batch 310, Loss: 1.4317
Batch 320, Loss: 1.4634
Batch 330, Loss: 1.4178
Batch 340, Loss: 1.4679
Batch 350, Loss: 1.5062
Batch 360, Loss: 1.4437
Batch 370, Loss: 1.4438
Batch 380, Loss: 1.4546
Batch 390, Loss: 1.4259
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.311275482177734 seconds
Epoch 41 accuracy: 54.95%
Batch 10, Loss: 1.3443
Batch 20, Loss: 1.3378
Batch 30, Loss: 1.4148
Batch 40, Loss: 1.4337
Batch 50, Loss: 1.4363
Batch 60, Loss: 1.4281
Batch 70, Loss: 1.4280
Batch 80, Loss: 1.4119
Batch 90, Loss: 1.5413
Batch 100, Loss: 1.4533
Batch 110, Loss: 1.3982
Batch 120, Loss: 1.4361
Batch 130, Loss: 1.4360
Batch 140, Loss: 1.4420
Batch 150, Loss: 1.3759
Batch 160, Loss: 1.4012
Batch 170, Loss: 1.4585
Batch 180, Loss: 1.4241
Batch 190, Loss: 1.4063
Batch 200, Loss: 1.4994
Batch 210, Loss: 1.4524
Batch 220, Loss: 1.4794
Batch 230, Loss: 1.4331
Batch 240, Loss: 1.4059
Batch 250, Loss: 1.4420
Batch 260, Loss: 1.3882
Batch 270, Loss: 1.4252
Batch 280, Loss: 1.4400
Batch 290, Loss: 1.5334
Batch 300, Loss: 1.4501
Batch 310, Loss: 1.5301
Batch 320, Loss: 1.4060
Batch 330, Loss: 1.4771
Batch 340, Loss: 1.5001
Batch 350, Loss: 1.4761
Batch 360, Loss: 1.5151
Batch 370, Loss: 1.5152
Batch 380, Loss: 1.4414
Batch 390, Loss: 1.5398
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.330307960510254 seconds
Epoch 42 accuracy: 55.66%
Batch 10, Loss: 1.3931
Batch 20, Loss: 1.4106
Batch 30, Loss: 1.3908
Batch 40, Loss: 1.3975
Batch 50, Loss: 1.3799
Batch 60, Loss: 1.3145
Batch 70, Loss: 1.4105
Batch 80, Loss: 1.4010
Batch 90, Loss: 1.4367
Batch 100, Loss: 1.4109
Batch 110, Loss: 1.4378
Batch 120, Loss: 1.4258
Batch 130, Loss: 1.4634
Batch 140, Loss: 1.4638
Batch 150, Loss: 1.4067
Batch 160, Loss: 1.4237
Batch 170, Loss: 1.3906
Batch 180, Loss: 1.4074
Batch 190, Loss: 1.4921
Batch 200, Loss: 1.4591
Batch 210, Loss: 1.4374
Batch 220, Loss: 1.4381
Batch 230, Loss: 1.4698
Batch 240, Loss: 1.4733
Batch 250, Loss: 1.5043
Batch 260, Loss: 1.4925
Batch 270, Loss: 1.4380
Batch 280, Loss: 1.4654
Batch 290, Loss: 1.5266
Batch 300, Loss: 1.4130
Batch 310, Loss: 1.5127
Batch 320, Loss: 1.4487
Batch 330, Loss: 1.4090
Batch 340, Loss: 1.4096
Batch 350, Loss: 1.4136
Batch 360, Loss: 1.4097
Batch 370, Loss: 1.3887
Batch 380, Loss: 1.4702
Batch 390, Loss: 1.5348
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.292600870132446 seconds
Epoch 43 accuracy: 54.71%
Batch 10, Loss: 1.4402
Batch 20, Loss: 1.4339
Batch 30, Loss: 1.4270
Batch 40, Loss: 1.3900
Batch 50, Loss: 1.3851
Batch 60, Loss: 1.4289
Batch 70, Loss: 1.3811
Batch 80, Loss: 1.3746
Batch 90, Loss: 1.4602
Batch 100, Loss: 1.4132
Batch 110, Loss: 1.3429
Batch 120, Loss: 1.4552
Batch 130, Loss: 1.4203
Batch 140, Loss: 1.3985
Batch 150, Loss: 1.3978
Batch 160, Loss: 1.4160
Batch 170, Loss: 1.4030
Batch 180, Loss: 1.4597
Batch 190, Loss: 1.5139
Batch 200, Loss: 1.4458
Batch 210, Loss: 1.4194
Batch 220, Loss: 1.4124
Batch 230, Loss: 1.4179
Batch 240, Loss: 1.5308
Batch 250, Loss: 1.4043
Batch 260, Loss: 1.4064
Batch 270, Loss: 1.5069
Batch 280, Loss: 1.4741
Batch 290, Loss: 1.4630
Batch 300, Loss: 1.3948
Batch 310, Loss: 1.4574
Batch 320, Loss: 1.4621
Batch 330, Loss: 1.4432
Batch 340, Loss: 1.5143
Batch 350, Loss: 1.5187
Batch 360, Loss: 1.4220
Batch 370, Loss: 1.3600
Batch 380, Loss: 1.4283
Batch 390, Loss: 1.4769
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.278064966201782 seconds
Epoch 44 accuracy: 59.28%
Batch 10, Loss: 1.4237
Batch 20, Loss: 1.4356
Batch 30, Loss: 1.3738
Batch 40, Loss: 1.3890
Batch 50, Loss: 1.4288
Batch 60, Loss: 1.3571
Batch 70, Loss: 1.4290
Batch 80, Loss: 1.4126
Batch 90, Loss: 1.3872
Batch 100, Loss: 1.3942
Batch 110, Loss: 1.3873
Batch 120, Loss: 1.4339
Batch 130, Loss: 1.4608
Batch 140, Loss: 1.5124
Batch 150, Loss: 1.4644
Batch 160, Loss: 1.4407
Batch 170, Loss: 1.3469
Batch 180, Loss: 1.4308
Batch 190, Loss: 1.4752
Batch 200, Loss: 1.4628
Batch 210, Loss: 1.4011
Batch 220, Loss: 1.3557
Batch 230, Loss: 1.4174
Batch 240, Loss: 1.3967
Batch 250, Loss: 1.4063
Batch 260, Loss: 1.4257
Batch 270, Loss: 1.4738
Batch 280, Loss: 1.4393
Batch 290, Loss: 1.4637
Batch 300, Loss: 1.4380
Batch 310, Loss: 1.4323
Batch 320, Loss: 1.4514
Batch 330, Loss: 1.3822
Batch 340, Loss: 1.4175
Batch 350, Loss: 1.4331
Batch 360, Loss: 1.4855
Batch 370, Loss: 1.4125
Batch 380, Loss: 1.4308
Batch 390, Loss: 1.4401
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.332108736038208 seconds
Epoch 45 accuracy: 58.35%
Batch 10, Loss: 1.4160
Batch 20, Loss: 1.3729
Batch 30, Loss: 1.3771
Batch 40, Loss: 1.2975
Batch 50, Loss: 1.3324
Batch 60, Loss: 1.3589
Batch 70, Loss: 1.4027
Batch 80, Loss: 1.4494
Batch 90, Loss: 1.3415
Batch 100, Loss: 1.3803
Batch 110, Loss: 1.3703
Batch 120, Loss: 1.4192
Batch 130, Loss: 1.3548
Batch 140, Loss: 1.4290
Batch 150, Loss: 1.4020
Batch 160, Loss: 1.4561
Batch 170, Loss: 1.4264
Batch 180, Loss: 1.4757
Batch 190, Loss: 1.4210
Batch 200, Loss: 1.3986
Batch 210, Loss: 1.4246
Batch 220, Loss: 1.4597
Batch 230, Loss: 1.4732
Batch 240, Loss: 1.3684
Batch 250, Loss: 1.4835
Batch 260, Loss: 1.4446
Batch 270, Loss: 1.4483
Batch 280, Loss: 1.4277
Batch 290, Loss: 1.4302
Batch 300, Loss: 1.3708
Batch 310, Loss: 1.4823
Batch 320, Loss: 1.4308
Batch 330, Loss: 1.4598
Batch 340, Loss: 1.4122
Batch 350, Loss: 1.4496
Batch 360, Loss: 1.4301
Batch 370, Loss: 1.4228
Batch 380, Loss: 1.3383
Batch 390, Loss: 1.4235
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.32149076461792 seconds
Epoch 46 accuracy: 56.32%
Batch 10, Loss: 1.4004
Batch 20, Loss: 1.4406
Batch 30, Loss: 1.4132
Batch 40, Loss: 1.3717
Batch 50, Loss: 1.3768
Batch 60, Loss: 1.3104
Batch 70, Loss: 1.3681
Batch 80, Loss: 1.4697
Batch 90, Loss: 1.3289
Batch 100, Loss: 1.4673
Batch 110, Loss: 1.3936
Batch 120, Loss: 1.4054
Batch 130, Loss: 1.3951
Batch 140, Loss: 1.4266
Batch 150, Loss: 1.2940
Batch 160, Loss: 1.3915
Batch 170, Loss: 1.3611
Batch 180, Loss: 1.4235
Batch 190, Loss: 1.4147
Batch 200, Loss: 1.3581
Batch 210, Loss: 1.3336
Batch 220, Loss: 1.3527
Batch 230, Loss: 1.4089
Batch 240, Loss: 1.4432
Batch 250, Loss: 1.4067
Batch 260, Loss: 1.4242
Batch 270, Loss: 1.4342
Batch 280, Loss: 1.3595
Batch 290, Loss: 1.4364
Batch 300, Loss: 1.4714
Batch 310, Loss: 1.3960
Batch 320, Loss: 1.4512
Batch 330, Loss: 1.4098
Batch 340, Loss: 1.4971
Batch 350, Loss: 1.4788
Batch 360, Loss: 1.3853
Batch 370, Loss: 1.4794
Batch 380, Loss: 1.4595
Batch 390, Loss: 1.4162
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.308701992034912 seconds
Epoch 47 accuracy: 56.34%
Batch 10, Loss: 1.3962
Batch 20, Loss: 1.4107
Batch 30, Loss: 1.3479
Batch 40, Loss: 1.3424
Batch 50, Loss: 1.3492
Batch 60, Loss: 1.3670
Batch 70, Loss: 1.3880
Batch 80, Loss: 1.3628
Batch 90, Loss: 1.5213
Batch 100, Loss: 1.4162
Batch 110, Loss: 1.3760
Batch 120, Loss: 1.3461
Batch 130, Loss: 1.4388
Batch 140, Loss: 1.4151
Batch 150, Loss: 1.4519
Batch 160, Loss: 1.4512
Batch 170, Loss: 1.4051
Batch 180, Loss: 1.3843
Batch 190, Loss: 1.3792
Batch 200, Loss: 1.3214
Batch 210, Loss: 1.4288
Batch 220, Loss: 1.3787
Batch 230, Loss: 1.4499
Batch 240, Loss: 1.3657
Batch 250, Loss: 1.4764
Batch 260, Loss: 1.4023
Batch 270, Loss: 1.3811
Batch 280, Loss: 1.3163
Batch 290, Loss: 1.3887
Batch 300, Loss: 1.4545
Batch 310, Loss: 1.3971
Batch 320, Loss: 1.5009
Batch 330, Loss: 1.4831
Batch 340, Loss: 1.4280
Batch 350, Loss: 1.4800
Batch 360, Loss: 1.4109
Batch 370, Loss: 1.4592
Batch 380, Loss: 1.4204
Batch 390, Loss: 1.4747
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.238943099975586 seconds
Epoch 48 accuracy: 53.87%
Batch 10, Loss: 1.3690
Batch 20, Loss: 1.3767
Batch 30, Loss: 1.3939
Batch 40, Loss: 1.3707
Batch 50, Loss: 1.3832
Batch 60, Loss: 1.3432
Batch 70, Loss: 1.3747
Batch 80, Loss: 1.3318
Batch 90, Loss: 1.3795
Batch 100, Loss: 1.3622
Batch 110, Loss: 1.3813
Batch 120, Loss: 1.3730
Batch 130, Loss: 1.4081
Batch 140, Loss: 1.4476
Batch 150, Loss: 1.4822
Batch 160, Loss: 1.4190
Batch 170, Loss: 1.4071
Batch 180, Loss: 1.3597
Batch 190, Loss: 1.4324
Batch 200, Loss: 1.4052
Batch 210, Loss: 1.3703
Batch 220, Loss: 1.4195
Batch 230, Loss: 1.4387
Batch 240, Loss: 1.4514
Batch 250, Loss: 1.4387
Batch 260, Loss: 1.3788
Batch 270, Loss: 1.3696
Batch 280, Loss: 1.3661
Batch 290, Loss: 1.4216
Batch 300, Loss: 1.4201
Batch 310, Loss: 1.4763
Batch 320, Loss: 1.4437
Batch 330, Loss: 1.4676
Batch 340, Loss: 1.4000
Batch 350, Loss: 1.4195
Batch 360, Loss: 1.4449
Batch 370, Loss: 1.4183
Batch 380, Loss: 1.4345
Batch 390, Loss: 1.4561
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.296481132507324 seconds
Epoch 49 accuracy: 56.07%
Batch 10, Loss: 1.3501
Batch 20, Loss: 1.3681
Batch 30, Loss: 1.4074
Batch 40, Loss: 1.3116
Batch 50, Loss: 1.4096
Batch 60, Loss: 1.3651
Batch 70, Loss: 1.4134
Batch 80, Loss: 1.3948
Batch 90, Loss: 1.3959
Batch 100, Loss: 1.4278
Batch 110, Loss: 1.4282
Batch 120, Loss: 1.3895
Batch 130, Loss: 1.4574
Batch 140, Loss: 1.3427
Batch 150, Loss: 1.4188
Batch 160, Loss: 1.3525
Batch 170, Loss: 1.4750
Batch 180, Loss: 1.4387
Batch 190, Loss: 1.4425
Batch 200, Loss: 1.4427
Batch 210, Loss: 1.4883
Batch 220, Loss: 1.3887
Batch 230, Loss: 1.4462
Batch 240, Loss: 1.4155
Batch 250, Loss: 1.4002
Batch 260, Loss: 1.3730
Batch 270, Loss: 1.3595
Batch 280, Loss: 1.4146
Batch 290, Loss: 1.4379
Batch 300, Loss: 1.4025
Batch 310, Loss: 1.3817
Batch 320, Loss: 1.4094
Batch 330, Loss: 1.4337
Batch 340, Loss: 1.4244
Batch 350, Loss: 1.3710
Batch 360, Loss: 1.3772
Batch 370, Loss: 1.4006
Batch 380, Loss: 1.4395
Batch 390, Loss: 1.4211
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.340230226516724 seconds
Epoch 50 accuracy: 59.66%
Batch 10, Loss: 1.3628
Batch 20, Loss: 1.3804
Batch 30, Loss: 1.3849
Batch 40, Loss: 1.3880
Batch 50, Loss: 1.3157
Batch 60, Loss: 1.3725
Batch 70, Loss: 1.3447
Batch 80, Loss: 1.3429
Batch 90, Loss: 1.3669
Batch 100, Loss: 1.3974
Batch 110, Loss: 1.3887
Batch 120, Loss: 1.4308
Batch 130, Loss: 1.4666
Batch 140, Loss: 1.3159
Batch 150, Loss: 1.4094
Batch 160, Loss: 1.3484
Batch 170, Loss: 1.3841
Batch 180, Loss: 1.3454
Batch 190, Loss: 1.3898
Batch 200, Loss: 1.3868
Batch 210, Loss: 1.3874
Batch 220, Loss: 1.3839
Batch 230, Loss: 1.3930
Batch 240, Loss: 1.4345
Batch 250, Loss: 1.3909
Batch 260, Loss: 1.3942
Batch 270, Loss: 1.4153
Batch 280, Loss: 1.4389
Batch 290, Loss: 1.4250
Batch 300, Loss: 1.3999
Batch 310, Loss: 1.3976
Batch 320, Loss: 1.4660
Batch 330, Loss: 1.4304
Batch 340, Loss: 1.4150
Batch 350, Loss: 1.4382
Batch 360, Loss: 1.4313
Batch 370, Loss: 1.4085
Batch 380, Loss: 1.4257
Batch 390, Loss: 1.4132
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.245882272720337 seconds
Epoch 51 accuracy: 58.21%
Batch 10, Loss: 1.4054
Batch 20, Loss: 1.3516
Batch 30, Loss: 1.3378
Batch 40, Loss: 1.3357
Batch 50, Loss: 1.3715
Batch 60, Loss: 1.3564
Batch 70, Loss: 1.4197
Batch 80, Loss: 1.3283
Batch 90, Loss: 1.3823
Batch 100, Loss: 1.3407
Batch 110, Loss: 1.3880
Batch 120, Loss: 1.4422
Batch 130, Loss: 1.3798
Batch 140, Loss: 1.4340
Batch 150, Loss: 1.4366
Batch 160, Loss: 1.4329
Batch 170, Loss: 1.4173
Batch 180, Loss: 1.4326
Batch 190, Loss: 1.4057
Batch 200, Loss: 1.3406
Batch 210, Loss: 1.4309
Batch 220, Loss: 1.3577
Batch 230, Loss: 1.3886
Batch 240, Loss: 1.3844
Batch 250, Loss: 1.3735
Batch 260, Loss: 1.3500
Batch 270, Loss: 1.3781
Batch 280, Loss: 1.3800
Batch 290, Loss: 1.3518
Batch 300, Loss: 1.4375
Batch 310, Loss: 1.4046
Batch 320, Loss: 1.3431
Batch 330, Loss: 1.4353
Batch 340, Loss: 1.3614
Batch 350, Loss: 1.4019
Batch 360, Loss: 1.5150
Batch 370, Loss: 1.3609
Batch 380, Loss: 1.3950
Batch 390, Loss: 1.4311
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.30794620513916 seconds
Epoch 52 accuracy: 58.57%
Batch 10, Loss: 1.3427
Batch 20, Loss: 1.3294
Batch 30, Loss: 1.3498
Batch 40, Loss: 1.3918
Batch 50, Loss: 1.3437
Batch 60, Loss: 1.3699
Batch 70, Loss: 1.3125
Batch 80, Loss: 1.3400
Batch 90, Loss: 1.3551
Batch 100, Loss: 1.4104
Batch 110, Loss: 1.4247
Batch 120, Loss: 1.3887
Batch 130, Loss: 1.3761
Batch 140, Loss: 1.3973
Batch 150, Loss: 1.3366
Batch 160, Loss: 1.3773
Batch 170, Loss: 1.3824
Batch 180, Loss: 1.4702
Batch 190, Loss: 1.4113
Batch 200, Loss: 1.4246
Batch 210, Loss: 1.3356
Batch 220, Loss: 1.3926
Batch 230, Loss: 1.3528
Batch 240, Loss: 1.3706
Batch 250, Loss: 1.3887
Batch 260, Loss: 1.4649
Batch 270, Loss: 1.4252
Batch 280, Loss: 1.4380
Batch 290, Loss: 1.3625
Batch 300, Loss: 1.3859
Batch 310, Loss: 1.4810
Batch 320, Loss: 1.4035
Batch 330, Loss: 1.4309
Batch 340, Loss: 1.3308
Batch 350, Loss: 1.4713
Batch 360, Loss: 1.4135
Batch 370, Loss: 1.4755
Batch 380, Loss: 1.3787
Batch 390, Loss: 1.4244
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.307887077331543 seconds
Epoch 53 accuracy: 58.63%
Batch 10, Loss: 1.3171
Batch 20, Loss: 1.3403
Batch 30, Loss: 1.3376
Batch 40, Loss: 1.2812
Batch 50, Loss: 1.3181
Batch 60, Loss: 1.3142
Batch 70, Loss: 1.3486
Batch 80, Loss: 1.3429
Batch 90, Loss: 1.3265
Batch 100, Loss: 1.4090
Batch 110, Loss: 1.3284
Batch 120, Loss: 1.3699
Batch 130, Loss: 1.3720
Batch 140, Loss: 1.3527
Batch 150, Loss: 1.3790
Batch 160, Loss: 1.3887
Batch 170, Loss: 1.3368
Batch 180, Loss: 1.3551
Batch 190, Loss: 1.3885
Batch 200, Loss: 1.3418
Batch 210, Loss: 1.4301
Batch 220, Loss: 1.4420
Batch 230, Loss: 1.4425
Batch 240, Loss: 1.4256
Batch 250, Loss: 1.4205
Batch 260, Loss: 1.3951
Batch 270, Loss: 1.4056
Batch 280, Loss: 1.4260
Batch 290, Loss: 1.3484
Batch 300, Loss: 1.4037
Batch 310, Loss: 1.4176
Batch 320, Loss: 1.4562
Batch 330, Loss: 1.3715
Batch 340, Loss: 1.3152
Batch 350, Loss: 1.4303
Batch 360, Loss: 1.3892
Batch 370, Loss: 1.3834
Batch 380, Loss: 1.4526
Batch 390, Loss: 1.4129
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.295674085617065 seconds
Epoch 54 accuracy: 60.54%
Batch 10, Loss: 1.2828
Batch 20, Loss: 1.3677
Batch 30, Loss: 1.3229
Batch 40, Loss: 1.2997
Batch 50, Loss: 1.2888
Batch 60, Loss: 1.3195
Batch 70, Loss: 1.3394
Batch 80, Loss: 1.3196
Batch 90, Loss: 1.3568
Batch 100, Loss: 1.3725
Batch 110, Loss: 1.4147
Batch 120, Loss: 1.3562
Batch 130, Loss: 1.3131
Batch 140, Loss: 1.4465
Batch 150, Loss: 1.3963
Batch 160, Loss: 1.3990
Batch 170, Loss: 1.3878
Batch 180, Loss: 1.3623
Batch 190, Loss: 1.3641
Batch 200, Loss: 1.3438
Batch 210, Loss: 1.3173
Batch 220, Loss: 1.3363
Batch 230, Loss: 1.3882
Batch 240, Loss: 1.4124
Batch 250, Loss: 1.4170
Batch 260, Loss: 1.4257
Batch 270, Loss: 1.4139
Batch 280, Loss: 1.4601
Batch 290, Loss: 1.4565
Batch 300, Loss: 1.4068
Batch 310, Loss: 1.3674
Batch 320, Loss: 1.3811
Batch 330, Loss: 1.4762
Batch 340, Loss: 1.4673
Batch 350, Loss: 1.4246
Batch 360, Loss: 1.3482
Batch 370, Loss: 1.3766
Batch 380, Loss: 1.4152
Batch 390, Loss: 1.3813
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.271405458450317 seconds
Epoch 55 accuracy: 59.77%
Batch 10, Loss: 1.3729
Batch 20, Loss: 1.3639
Batch 30, Loss: 1.3024
Batch 40, Loss: 1.3477
Batch 50, Loss: 1.3430
Batch 60, Loss: 1.3669
Batch 70, Loss: 1.3925
Batch 80, Loss: 1.3422
Batch 90, Loss: 1.3836
Batch 100, Loss: 1.3006
Batch 110, Loss: 1.3224
Batch 120, Loss: 1.3575
Batch 130, Loss: 1.3012
Batch 140, Loss: 1.3005
Batch 150, Loss: 1.3207
Batch 160, Loss: 1.3479
Batch 170, Loss: 1.2982
Batch 180, Loss: 1.3860
Batch 190, Loss: 1.4179
Batch 200, Loss: 1.3878
Batch 210, Loss: 1.3955
Batch 220, Loss: 1.4594
Batch 230, Loss: 1.3643
Batch 240, Loss: 1.4206
Batch 250, Loss: 1.3788
Batch 260, Loss: 1.3307
Batch 270, Loss: 1.3306
Batch 280, Loss: 1.3766
Batch 290, Loss: 1.3714
Batch 300, Loss: 1.4448
Batch 310, Loss: 1.3727
Batch 320, Loss: 1.3321
Batch 330, Loss: 1.4051
Batch 340, Loss: 1.4430
Batch 350, Loss: 1.4172
Batch 360, Loss: 1.4229
Batch 370, Loss: 1.3694
Batch 380, Loss: 1.4247
Batch 390, Loss: 1.3956
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.337400913238525 seconds
Epoch 56 accuracy: 56.78%
Batch 10, Loss: 1.3856
Batch 20, Loss: 1.3274
Batch 30, Loss: 1.3713
Batch 40, Loss: 1.3175
Batch 50, Loss: 1.3469
Batch 60, Loss: 1.2881
Batch 70, Loss: 1.3147
Batch 80, Loss: 1.3254
Batch 90, Loss: 1.3209
Batch 100, Loss: 1.3890
Batch 110, Loss: 1.3738
Batch 120, Loss: 1.3416
Batch 130, Loss: 1.3286
Batch 140, Loss: 1.3238
Batch 150, Loss: 1.3709
Batch 160, Loss: 1.3391
Batch 170, Loss: 1.3484
Batch 180, Loss: 1.3468
Batch 190, Loss: 1.4336
Batch 200, Loss: 1.3736
Batch 210, Loss: 1.3998
Batch 220, Loss: 1.3826
Batch 230, Loss: 1.4168
Batch 240, Loss: 1.3917
Batch 250, Loss: 1.3553
Batch 260, Loss: 1.4476
Batch 270, Loss: 1.3652
Batch 280, Loss: 1.3779
Batch 290, Loss: 1.3735
Batch 300, Loss: 1.3447
Batch 310, Loss: 1.4105
Batch 320, Loss: 1.4032
Batch 330, Loss: 1.4255
Batch 340, Loss: 1.4341
Batch 350, Loss: 1.3531
Batch 360, Loss: 1.4380
Batch 370, Loss: 1.3996
Batch 380, Loss: 1.4237
Batch 390, Loss: 1.3493
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.222174644470215 seconds
Epoch 57 accuracy: 60.16%
Batch 10, Loss: 1.3315
Batch 20, Loss: 1.3298
Batch 30, Loss: 1.3742
Batch 40, Loss: 1.2636
Batch 50, Loss: 1.3260
Batch 60, Loss: 1.3149
Batch 70, Loss: 1.3290
Batch 80, Loss: 1.3082
Batch 90, Loss: 1.3749
Batch 100, Loss: 1.2919
Batch 110, Loss: 1.3653
Batch 120, Loss: 1.3043
Batch 130, Loss: 1.4122
Batch 140, Loss: 1.3177
Batch 150, Loss: 1.3293
Batch 160, Loss: 1.3776
Batch 170, Loss: 1.3162
Batch 180, Loss: 1.4109
Batch 190, Loss: 1.3689
Batch 200, Loss: 1.3880
Batch 210, Loss: 1.3743
Batch 220, Loss: 1.3264
Batch 230, Loss: 1.4126
Batch 240, Loss: 1.3218
Batch 250, Loss: 1.4710
Batch 260, Loss: 1.3584
Batch 270, Loss: 1.3656
Batch 280, Loss: 1.3751
Batch 290, Loss: 1.3643
Batch 300, Loss: 1.3563
Batch 310, Loss: 1.3618
Batch 320, Loss: 1.3548
Batch 330, Loss: 1.3780
Batch 340, Loss: 1.4568
Batch 350, Loss: 1.3858
Batch 360, Loss: 1.4332
Batch 370, Loss: 1.4591
Batch 380, Loss: 1.4167
Batch 390, Loss: 1.3914
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.234727144241333 seconds
Epoch 58 accuracy: 57.38%
Batch 10, Loss: 1.3008
Batch 20, Loss: 1.3582
Batch 30, Loss: 1.3093
Batch 40, Loss: 1.3470
Batch 50, Loss: 1.3740
Batch 60, Loss: 1.3567
Batch 70, Loss: 1.3868
Batch 80, Loss: 1.3436
Batch 90, Loss: 1.2966
Batch 100, Loss: 1.3013
Batch 110, Loss: 1.3283
Batch 120, Loss: 1.2726
Batch 130, Loss: 1.3758
Batch 140, Loss: 1.3360
Batch 150, Loss: 1.3885
Batch 160, Loss: 1.3030
Batch 170, Loss: 1.3650
Batch 180, Loss: 1.3764
Batch 190, Loss: 1.3143
Batch 200, Loss: 1.3412
Batch 210, Loss: 1.3490
Batch 220, Loss: 1.3369
Batch 230, Loss: 1.3989
Batch 240, Loss: 1.3693
Batch 250, Loss: 1.3646
Batch 260, Loss: 1.4220
Batch 270, Loss: 1.3422
Batch 280, Loss: 1.4099
Batch 290, Loss: 1.4347
Batch 300, Loss: 1.4067
Batch 310, Loss: 1.3882
Batch 320, Loss: 1.3686
Batch 330, Loss: 1.3759
Batch 340, Loss: 1.3460
Batch 350, Loss: 1.3445
Batch 360, Loss: 1.3210
Batch 370, Loss: 1.3894
Batch 380, Loss: 1.3720
Batch 390, Loss: 1.3463
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.32838773727417 seconds
Epoch 59 accuracy: 54.89%
Batch 10, Loss: 1.3307
Batch 20, Loss: 1.2895
Batch 30, Loss: 1.2747
Batch 40, Loss: 1.2969
Batch 50, Loss: 1.2710
Batch 60, Loss: 1.3133
Batch 70, Loss: 1.3479
Batch 80, Loss: 1.2424
Batch 90, Loss: 1.3684
Batch 100, Loss: 1.3376
Batch 110, Loss: 1.3688
Batch 120, Loss: 1.3547
Batch 130, Loss: 1.3575
Batch 140, Loss: 1.2925
Batch 150, Loss: 1.2788
Batch 160, Loss: 1.3210
Batch 170, Loss: 1.3484
Batch 180, Loss: 1.3148
Batch 190, Loss: 1.3414
Batch 200, Loss: 1.3432
Batch 210, Loss: 1.3536
Batch 220, Loss: 1.2902
Batch 230, Loss: 1.4050
Batch 240, Loss: 1.4499
Batch 250, Loss: 1.3433
Batch 260, Loss: 1.4157
Batch 270, Loss: 1.3626
Batch 280, Loss: 1.3308
Batch 290, Loss: 1.3033
Batch 300, Loss: 1.3150
Batch 310, Loss: 1.3864
Batch 320, Loss: 1.3792
Batch 330, Loss: 1.3615
Batch 340, Loss: 1.3529
Batch 350, Loss: 1.4331
Batch 360, Loss: 1.2912
Batch 370, Loss: 1.4044
Batch 380, Loss: 1.4066
Batch 390, Loss: 1.4070
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.327896118164062 seconds
Epoch 60 accuracy: 57.81%
Batch 10, Loss: 1.3696
Batch 20, Loss: 1.3210
Batch 30, Loss: 1.2647
Batch 40, Loss: 1.3475
Batch 50, Loss: 1.2932
Batch 60, Loss: 1.3325
Batch 70, Loss: 1.3335
Batch 80, Loss: 1.3522
Batch 90, Loss: 1.3500
Batch 100, Loss: 1.2840
Batch 110, Loss: 1.3579
Batch 120, Loss: 1.2998
Batch 130, Loss: 1.4057
Batch 140, Loss: 1.3001
Batch 150, Loss: 1.3330
Batch 160, Loss: 1.3405
Batch 170, Loss: 1.3736
Batch 180, Loss: 1.2599
Batch 190, Loss: 1.2997
Batch 200, Loss: 1.2788
Batch 210, Loss: 1.3966
Batch 220, Loss: 1.3632
Batch 230, Loss: 1.3168
Batch 240, Loss: 1.3229
Batch 250, Loss: 1.3305
Batch 260, Loss: 1.3546
Batch 270, Loss: 1.3303
Batch 280, Loss: 1.3558
Batch 290, Loss: 1.4396
Batch 300, Loss: 1.3391
Batch 310, Loss: 1.3481
Batch 320, Loss: 1.3297
Batch 330, Loss: 1.4217
Batch 340, Loss: 1.3976
Batch 350, Loss: 1.3917
Batch 360, Loss: 1.4176
Batch 370, Loss: 1.4117
Batch 380, Loss: 1.3286
Batch 390, Loss: 1.3792
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.331058979034424 seconds
Epoch 61 accuracy: 59.04%
Batch 10, Loss: 1.2937
Batch 20, Loss: 1.3124
Batch 30, Loss: 1.2675
Batch 40, Loss: 1.3376
Batch 50, Loss: 1.2875
Batch 60, Loss: 1.2780
Batch 70, Loss: 1.2508
Batch 80, Loss: 1.3424
Batch 90, Loss: 1.3364
Batch 100, Loss: 1.2811
Batch 110, Loss: 1.3362
Batch 120, Loss: 1.3843
Batch 130, Loss: 1.3322
Batch 140, Loss: 1.3739
Batch 150, Loss: 1.3101
Batch 160, Loss: 1.3571
Batch 170, Loss: 1.4056
Batch 180, Loss: 1.3846
Batch 190, Loss: 1.3275
Batch 200, Loss: 1.2950
Batch 210, Loss: 1.3882
Batch 220, Loss: 1.3242
Batch 230, Loss: 1.3875
Batch 240, Loss: 1.3356
Batch 250, Loss: 1.3150
Batch 260, Loss: 1.3470
Batch 270, Loss: 1.4170
Batch 280, Loss: 1.3429
Batch 290, Loss: 1.4188
Batch 300, Loss: 1.3496
Batch 310, Loss: 1.4007
Batch 320, Loss: 1.2997
Batch 330, Loss: 1.3415
Batch 340, Loss: 1.3488
Batch 350, Loss: 1.3296
Batch 360, Loss: 1.3463
Batch 370, Loss: 1.4284
Batch 380, Loss: 1.3571
Batch 390, Loss: 1.3516
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.298555374145508 seconds
Epoch 62 accuracy: 59.18%
Batch 10, Loss: 1.2923
Batch 20, Loss: 1.2421
Batch 30, Loss: 1.2902
Batch 40, Loss: 1.3085
Batch 50, Loss: 1.3737
Batch 60, Loss: 1.2545
Batch 70, Loss: 1.3136
Batch 80, Loss: 1.3358
Batch 90, Loss: 1.3505
Batch 100, Loss: 1.3219
Batch 110, Loss: 1.4230
Batch 120, Loss: 1.2972
Batch 130, Loss: 1.3500
Batch 140, Loss: 1.3527
Batch 150, Loss: 1.3380
Batch 160, Loss: 1.4083
Batch 170, Loss: 1.3174
Batch 180, Loss: 1.3219
Batch 190, Loss: 1.3624
Batch 200, Loss: 1.3365
Batch 210, Loss: 1.3095
Batch 220, Loss: 1.3354
Batch 230, Loss: 1.3369
Batch 240, Loss: 1.3340
Batch 250, Loss: 1.3308
Batch 260, Loss: 1.3270
Batch 270, Loss: 1.3916
Batch 280, Loss: 1.3818
Batch 290, Loss: 1.3396
Batch 300, Loss: 1.2766
Batch 310, Loss: 1.3228
Batch 320, Loss: 1.3145
Batch 330, Loss: 1.3564
Batch 340, Loss: 1.3906
Batch 350, Loss: 1.3904
Batch 360, Loss: 1.3852
Batch 370, Loss: 1.3353
Batch 380, Loss: 1.3589
Batch 390, Loss: 1.3932
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.253677368164062 seconds
Epoch 63 accuracy: 59.79%
Batch 10, Loss: 1.2274
Batch 20, Loss: 1.2632
Batch 30, Loss: 1.3334
Batch 40, Loss: 1.2678
Batch 50, Loss: 1.3946
Batch 60, Loss: 1.3237
Batch 70, Loss: 1.2970
Batch 80, Loss: 1.3753
Batch 90, Loss: 1.2959
Batch 100, Loss: 1.4011
Batch 110, Loss: 1.3844
Batch 120, Loss: 1.3172
Batch 130, Loss: 1.3498
Batch 140, Loss: 1.2486
Batch 150, Loss: 1.3903
Batch 160, Loss: 1.3601
Batch 170, Loss: 1.3775
Batch 180, Loss: 1.3580
Batch 190, Loss: 1.3458
Batch 200, Loss: 1.3341
Batch 210, Loss: 1.3603
Batch 220, Loss: 1.3817
Batch 230, Loss: 1.3224
Batch 240, Loss: 1.3280
Batch 250, Loss: 1.2598
Batch 260, Loss: 1.3938
Batch 270, Loss: 1.3353
Batch 280, Loss: 1.3796
Batch 290, Loss: 1.3220
Batch 300, Loss: 1.3380
Batch 310, Loss: 1.2436
Batch 320, Loss: 1.4272
Batch 330, Loss: 1.3123
Batch 340, Loss: 1.3736
Batch 350, Loss: 1.4131
Batch 360, Loss: 1.3203
Batch 370, Loss: 1.3824
Batch 380, Loss: 1.2972
Batch 390, Loss: 1.3336
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.309305906295776 seconds
Epoch 64 accuracy: 59.76%
Batch 10, Loss: 1.3103
Batch 20, Loss: 1.2183
Batch 30, Loss: 1.3172
Batch 40, Loss: 1.2640
Batch 50, Loss: 1.3331
Batch 60, Loss: 1.3198
Batch 70, Loss: 1.2967
Batch 80, Loss: 1.3071
Batch 90, Loss: 1.3100
Batch 100, Loss: 1.2791
Batch 110, Loss: 1.3174
Batch 120, Loss: 1.2948
Batch 130, Loss: 1.3168
Batch 140, Loss: 1.3107
Batch 150, Loss: 1.3375
Batch 160, Loss: 1.3802
Batch 170, Loss: 1.3359
Batch 180, Loss: 1.3571
Batch 190, Loss: 1.3863
Batch 200, Loss: 1.3860
Batch 210, Loss: 1.3276
Batch 220, Loss: 1.3441
Batch 230, Loss: 1.3142
Batch 240, Loss: 1.2328
Batch 250, Loss: 1.2713
Batch 260, Loss: 1.3107
Batch 270, Loss: 1.3896
Batch 280, Loss: 1.3373
Batch 290, Loss: 1.3890
Batch 300, Loss: 1.2710
Batch 310, Loss: 1.4314
Batch 320, Loss: 1.3302
Batch 330, Loss: 1.3665
Batch 340, Loss: 1.3533
Batch 350, Loss: 1.3662
Batch 360, Loss: 1.3465
Batch 370, Loss: 1.3715
Batch 380, Loss: 1.3018
Batch 390, Loss: 1.3829
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.263900995254517 seconds
Epoch 65 accuracy: 60.18%
Batch 10, Loss: 1.3213
Batch 20, Loss: 1.2803
Batch 30, Loss: 1.3382
Batch 40, Loss: 1.3238
Batch 50, Loss: 1.3219
Batch 60, Loss: 1.2781
Batch 70, Loss: 1.1939
Batch 80, Loss: 1.2538
Batch 90, Loss: 1.2924
Batch 100, Loss: 1.3587
Batch 110, Loss: 1.3699
Batch 120, Loss: 1.3422
Batch 130, Loss: 1.2809
Batch 140, Loss: 1.3200
Batch 150, Loss: 1.3014
Batch 160, Loss: 1.2915
Batch 170, Loss: 1.3552
Batch 180, Loss: 1.2911
Batch 190, Loss: 1.3173
Batch 200, Loss: 1.2828
Batch 210, Loss: 1.4051
Batch 220, Loss: 1.3286
Batch 230, Loss: 1.2809
Batch 240, Loss: 1.3163
Batch 250, Loss: 1.2703
Batch 260, Loss: 1.2993
Batch 270, Loss: 1.3314
Batch 280, Loss: 1.3483
Batch 290, Loss: 1.3257
Batch 300, Loss: 1.3998
Batch 310, Loss: 1.3556
Batch 320, Loss: 1.3654
Batch 330, Loss: 1.3821
Batch 340, Loss: 1.3355
Batch 350, Loss: 1.2829
Batch 360, Loss: 1.2990
Batch 370, Loss: 1.3361
Batch 380, Loss: 1.3369
Batch 390, Loss: 1.3646
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.313220262527466 seconds
Epoch 66 accuracy: 59.53%
Batch 10, Loss: 1.2666
Batch 20, Loss: 1.2729
Batch 30, Loss: 1.2463
Batch 40, Loss: 1.3706
Batch 50, Loss: 1.2550
Batch 60, Loss: 1.2842
Batch 70, Loss: 1.3370
Batch 80, Loss: 1.3316
Batch 90, Loss: 1.2684
Batch 100, Loss: 1.3389
Batch 110, Loss: 1.2941
Batch 120, Loss: 1.2290
Batch 130, Loss: 1.2649
Batch 140, Loss: 1.3510
Batch 150, Loss: 1.3344
Batch 160, Loss: 1.2645
Batch 170, Loss: 1.3163
Batch 180, Loss: 1.3201
Batch 190, Loss: 1.3612
Batch 200, Loss: 1.3144
Batch 210, Loss: 1.2833
Batch 220, Loss: 1.3654
Batch 230, Loss: 1.3973
Batch 240, Loss: 1.4402
Batch 250, Loss: 1.3287
Batch 260, Loss: 1.3547
Batch 270, Loss: 1.3069
Batch 280, Loss: 1.4015
Batch 290, Loss: 1.3120
Batch 300, Loss: 1.3200
Batch 310, Loss: 1.2823
Batch 320, Loss: 1.2821
Batch 330, Loss: 1.2812
Batch 340, Loss: 1.3044
Batch 350, Loss: 1.3272
Batch 360, Loss: 1.3772
Batch 370, Loss: 1.3705
Batch 380, Loss: 1.3952
Batch 390, Loss: 1.3449
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.204586029052734 seconds
Epoch 67 accuracy: 59.81%
Batch 10, Loss: 1.3391
Batch 20, Loss: 1.2894
Batch 30, Loss: 1.2920
Batch 40, Loss: 1.1665
Batch 50, Loss: 1.2770
Batch 60, Loss: 1.3221
Batch 70, Loss: 1.2523
Batch 80, Loss: 1.3081
Batch 90, Loss: 1.2635
Batch 100, Loss: 1.3231
Batch 110, Loss: 1.2745
Batch 120, Loss: 1.3315
Batch 130, Loss: 1.3702
Batch 140, Loss: 1.2735
Batch 150, Loss: 1.3372
Batch 160, Loss: 1.3163
Batch 170, Loss: 1.2973
Batch 180, Loss: 1.4046
Batch 190, Loss: 1.4072
Batch 200, Loss: 1.3614
Batch 210, Loss: 1.2997
Batch 220, Loss: 1.3079
Batch 230, Loss: 1.2985
Batch 240, Loss: 1.3165
Batch 250, Loss: 1.3352
Batch 260, Loss: 1.2224
Batch 270, Loss: 1.2637
Batch 280, Loss: 1.3231
Batch 290, Loss: 1.3242
Batch 300, Loss: 1.3163
Batch 310, Loss: 1.2830
Batch 320, Loss: 1.2864
Batch 330, Loss: 1.3632
Batch 340, Loss: 1.2817
Batch 350, Loss: 1.3425
Batch 360, Loss: 1.3048
Batch 370, Loss: 1.3622
Batch 380, Loss: 1.3234
Batch 390, Loss: 1.2737
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.35767436027527 seconds
Epoch 68 accuracy: 62.51%
Batch 10, Loss: 1.2389
Batch 20, Loss: 1.2453
Batch 30, Loss: 1.2620
Batch 40, Loss: 1.2985
Batch 50, Loss: 1.2029
Batch 60, Loss: 1.2366
Batch 70, Loss: 1.3010
Batch 80, Loss: 1.3192
Batch 90, Loss: 1.2402
Batch 100, Loss: 1.3145
Batch 110, Loss: 1.2990
Batch 120, Loss: 1.2851
Batch 130, Loss: 1.3199
Batch 140, Loss: 1.3131
Batch 150, Loss: 1.2985
Batch 160, Loss: 1.3107
Batch 170, Loss: 1.3558
Batch 180, Loss: 1.2789
Batch 190, Loss: 1.3625
Batch 200, Loss: 1.3266
Batch 210, Loss: 1.2528
Batch 220, Loss: 1.2592
Batch 230, Loss: 1.3659
Batch 240, Loss: 1.3358
Batch 250, Loss: 1.2838
Batch 260, Loss: 1.3282
Batch 270, Loss: 1.3081
Batch 280, Loss: 1.3840
Batch 290, Loss: 1.2883
Batch 300, Loss: 1.3542
Batch 310, Loss: 1.3183
Batch 320, Loss: 1.2538
Batch 330, Loss: 1.2609
Batch 340, Loss: 1.2706
Batch 350, Loss: 1.3828
Batch 360, Loss: 1.3557
Batch 370, Loss: 1.3513
Batch 380, Loss: 1.3569
Batch 390, Loss: 1.2930
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.275017023086548 seconds
Epoch 69 accuracy: 58.65%
Batch 10, Loss: 1.3526
Batch 20, Loss: 1.3305
Batch 30, Loss: 1.2606
Batch 40, Loss: 1.2591
Batch 50, Loss: 1.2998
Batch 60, Loss: 1.3118
Batch 70, Loss: 1.2581
Batch 80, Loss: 1.3183
Batch 90, Loss: 1.2607
Batch 100, Loss: 1.2906
Batch 110, Loss: 1.2688
Batch 120, Loss: 1.3419
Batch 130, Loss: 1.2845
Batch 140, Loss: 1.2867
Batch 150, Loss: 1.3208
Batch 160, Loss: 1.2945
Batch 170, Loss: 1.3551
Batch 180, Loss: 1.2708
Batch 190, Loss: 1.3375
Batch 200, Loss: 1.3274
Batch 210, Loss: 1.2882
Batch 220, Loss: 1.3074
Batch 230, Loss: 1.2396
Batch 240, Loss: 1.2615
Batch 250, Loss: 1.2800
Batch 260, Loss: 1.3015
Batch 270, Loss: 1.2930
Batch 280, Loss: 1.4041
Batch 290, Loss: 1.2963
Batch 300, Loss: 1.3351
Batch 310, Loss: 1.3378
Batch 320, Loss: 1.4004
Batch 330, Loss: 1.3210
Batch 340, Loss: 1.3101
Batch 350, Loss: 1.3476
Batch 360, Loss: 1.3570
Batch 370, Loss: 1.3382
Batch 380, Loss: 1.2919
Batch 390, Loss: 1.3000
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.32484745979309 seconds
Epoch 70 accuracy: 59.58%
Batch 10, Loss: 1.3051
Batch 20, Loss: 1.2285
Batch 30, Loss: 1.2317
Batch 40, Loss: 1.3106
Batch 50, Loss: 1.2364
Batch 60, Loss: 1.2336
Batch 70, Loss: 1.3008
Batch 80, Loss: 1.3047
Batch 90, Loss: 1.2519
Batch 100, Loss: 1.2775
Batch 110, Loss: 1.2767
Batch 120, Loss: 1.3143
Batch 130, Loss: 1.3053
Batch 140, Loss: 1.2966
Batch 150, Loss: 1.3239
Batch 160, Loss: 1.2875
Batch 170, Loss: 1.2460
Batch 180, Loss: 1.3363
Batch 190, Loss: 1.3158
Batch 200, Loss: 1.2867
Batch 210, Loss: 1.2937
Batch 220, Loss: 1.2593
Batch 230, Loss: 1.3282
Batch 240, Loss: 1.2917
Batch 250, Loss: 1.3117
Batch 260, Loss: 1.2599
Batch 270, Loss: 1.2613
Batch 280, Loss: 1.2727
Batch 290, Loss: 1.2859
Batch 300, Loss: 1.2869
Batch 310, Loss: 1.2331
Batch 320, Loss: 1.2797
Batch 330, Loss: 1.3386
Batch 340, Loss: 1.3427
Batch 350, Loss: 1.3446
Batch 360, Loss: 1.2833
Batch 370, Loss: 1.2705
Batch 380, Loss: 1.2888
Batch 390, Loss: 1.3424
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.33977460861206 seconds
Epoch 71 accuracy: 60.91%
Batch 10, Loss: 1.2615
Batch 20, Loss: 1.2285
Batch 30, Loss: 1.2210
Batch 40, Loss: 1.2507
Batch 50, Loss: 1.2653
Batch 60, Loss: 1.3193
Batch 70, Loss: 1.2417
Batch 80, Loss: 1.2622
Batch 90, Loss: 1.3036
Batch 100, Loss: 1.2727
Batch 110, Loss: 1.2936
Batch 120, Loss: 1.2511
Batch 130, Loss: 1.2883
Batch 140, Loss: 1.3278
Batch 150, Loss: 1.2833
Batch 160, Loss: 1.2541
Batch 170, Loss: 1.2802
Batch 180, Loss: 1.3092
Batch 190, Loss: 1.2919
Batch 200, Loss: 1.3484
Batch 210, Loss: 1.2692
Batch 220, Loss: 1.2833
Batch 230, Loss: 1.3051
Batch 240, Loss: 1.2983
Batch 250, Loss: 1.2951
Batch 260, Loss: 1.3381
Batch 270, Loss: 1.2574
Batch 280, Loss: 1.2900
Batch 290, Loss: 1.2631
Batch 300, Loss: 1.2983
Batch 310, Loss: 1.2486
Batch 320, Loss: 1.2802
Batch 330, Loss: 1.3198
Batch 340, Loss: 1.3187
Batch 350, Loss: 1.2258
Batch 360, Loss: 1.3536
Batch 370, Loss: 1.2723
Batch 380, Loss: 1.2852
Batch 390, Loss: 1.3460
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.31969690322876 seconds
Epoch 72 accuracy: 62.18%
Batch 10, Loss: 1.1624
Batch 20, Loss: 1.2480
Batch 30, Loss: 1.1932
Batch 40, Loss: 1.2646
Batch 50, Loss: 1.2573
Batch 60, Loss: 1.2340
Batch 70, Loss: 1.2114
Batch 80, Loss: 1.1917
Batch 90, Loss: 1.2573
Batch 100, Loss: 1.2269
Batch 110, Loss: 1.2879
Batch 120, Loss: 1.2656
Batch 130, Loss: 1.3118
Batch 140, Loss: 1.2810
Batch 150, Loss: 1.3272
Batch 160, Loss: 1.2967
Batch 170, Loss: 1.2996
Batch 180, Loss: 1.2414
Batch 190, Loss: 1.2807
Batch 200, Loss: 1.2720
Batch 210, Loss: 1.3017
Batch 220, Loss: 1.3381
Batch 230, Loss: 1.2675
Batch 240, Loss: 1.3792
Batch 250, Loss: 1.2793
Batch 260, Loss: 1.2902
Batch 270, Loss: 1.3109
Batch 280, Loss: 1.2300
Batch 290, Loss: 1.3695
Batch 300, Loss: 1.2324
Batch 310, Loss: 1.3239
Batch 320, Loss: 1.2753
Batch 330, Loss: 1.2918
Batch 340, Loss: 1.3603
Batch 350, Loss: 1.3054
Batch 360, Loss: 1.3048
Batch 370, Loss: 1.3401
Batch 380, Loss: 1.3467
Batch 390, Loss: 1.3632
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.286812782287598 seconds
Epoch 73 accuracy: 63.5%
Batch 10, Loss: 1.2607
Batch 20, Loss: 1.2352
Batch 30, Loss: 1.1636
Batch 40, Loss: 1.2138
Batch 50, Loss: 1.2799
Batch 60, Loss: 1.2367
Batch 70, Loss: 1.2172
Batch 80, Loss: 1.2535
Batch 90, Loss: 1.2780
Batch 100, Loss: 1.2165
Batch 110, Loss: 1.2895
Batch 120, Loss: 1.2766
Batch 130, Loss: 1.2277
Batch 140, Loss: 1.2849
Batch 150, Loss: 1.2534
Batch 160, Loss: 1.2947
Batch 170, Loss: 1.2063
Batch 180, Loss: 1.2367
Batch 190, Loss: 1.2683
Batch 200, Loss: 1.3089
Batch 210, Loss: 1.2264
Batch 220, Loss: 1.2683
Batch 230, Loss: 1.2779
Batch 240, Loss: 1.2326
Batch 250, Loss: 1.2834
Batch 260, Loss: 1.3439
Batch 270, Loss: 1.3017
Batch 280, Loss: 1.3316
Batch 290, Loss: 1.2533
Batch 300, Loss: 1.2873
Batch 310, Loss: 1.2755
Batch 320, Loss: 1.2894
Batch 330, Loss: 1.3071
Batch 340, Loss: 1.2773
Batch 350, Loss: 1.2887
Batch 360, Loss: 1.2866
Batch 370, Loss: 1.3176
Batch 380, Loss: 1.2936
Batch 390, Loss: 1.3515
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.274168968200684 seconds
Epoch 74 accuracy: 60.98%
Batch 10, Loss: 1.2327
Batch 20, Loss: 1.2538
Batch 30, Loss: 1.2197
Batch 40, Loss: 1.1948
Batch 50, Loss: 1.1961
Batch 60, Loss: 1.2627
Batch 70, Loss: 1.2224
Batch 80, Loss: 1.3047
Batch 90, Loss: 1.2690
Batch 100, Loss: 1.2917
Batch 110, Loss: 1.2471
Batch 120, Loss: 1.2247
Batch 130, Loss: 1.2610
Batch 140, Loss: 1.2728
Batch 150, Loss: 1.2735
Batch 160, Loss: 1.2408
Batch 170, Loss: 1.2675
Batch 180, Loss: 1.2768
Batch 190, Loss: 1.3644
Batch 200, Loss: 1.2885
Batch 210, Loss: 1.2674
Batch 220, Loss: 1.2949
Batch 230, Loss: 1.2715
Batch 240, Loss: 1.2496
Batch 250, Loss: 1.2843
Batch 260, Loss: 1.3060
Batch 270, Loss: 1.2382
Batch 280, Loss: 1.3268
Batch 290, Loss: 1.3043
Batch 300, Loss: 1.1986
Batch 310, Loss: 1.3324
Batch 320, Loss: 1.2068
Batch 330, Loss: 1.3140
Batch 340, Loss: 1.3103
Batch 350, Loss: 1.3057
Batch 360, Loss: 1.3502
Batch 370, Loss: 1.3093
Batch 380, Loss: 1.2829
Batch 390, Loss: 1.3116
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 26.05567502975464 seconds
Epoch 75 accuracy: 62.74%
Batch 10, Loss: 1.2913
Batch 20, Loss: 1.2186
Batch 30, Loss: 1.2985
Batch 40, Loss: 1.1857
Batch 50, Loss: 1.1827
Batch 60, Loss: 1.2301
Batch 70, Loss: 1.2740
Batch 80, Loss: 1.1737
Batch 90, Loss: 1.2464
Batch 100, Loss: 1.2413
Batch 110, Loss: 1.2993
Batch 120, Loss: 1.3383
Batch 130, Loss: 1.2598
Batch 140, Loss: 1.2281
Batch 150, Loss: 1.2913
Batch 160, Loss: 1.2152
Batch 170, Loss: 1.2799
Batch 180, Loss: 1.2973
Batch 190, Loss: 1.2392
Batch 200, Loss: 1.2771
Batch 210, Loss: 1.2515
Batch 220, Loss: 1.2687
Batch 230, Loss: 1.3395
Batch 240, Loss: 1.2736
Batch 250, Loss: 1.3340
Batch 260, Loss: 1.3804
Batch 270, Loss: 1.3171
Batch 280, Loss: 1.3035
Batch 290, Loss: 1.3002
Batch 300, Loss: 1.2720
Batch 310, Loss: 1.2882
Batch 320, Loss: 1.2757
Batch 330, Loss: 1.3005
Batch 340, Loss: 1.2206
Batch 350, Loss: 1.2650
Batch 360, Loss: 1.2507
Batch 370, Loss: 1.2497
Batch 380, Loss: 1.2797
Batch 390, Loss: 1.3342
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.316749572753906 seconds
Epoch 76 accuracy: 62.17%
Batch 10, Loss: 1.2184
Batch 20, Loss: 1.2457
Batch 30, Loss: 1.1805
Batch 40, Loss: 1.2424
Batch 50, Loss: 1.2095
Batch 60, Loss: 1.2787
Batch 70, Loss: 1.1915
Batch 80, Loss: 1.2615
Batch 90, Loss: 1.3524
Batch 100, Loss: 1.1818
Batch 110, Loss: 1.2888
Batch 120, Loss: 1.3460
Batch 130, Loss: 1.2703
Batch 140, Loss: 1.2345
Batch 150, Loss: 1.2438
Batch 160, Loss: 1.2234
Batch 170, Loss: 1.2580
Batch 180, Loss: 1.2805
Batch 190, Loss: 1.3144
Batch 200, Loss: 1.3079
Batch 210, Loss: 1.2469
Batch 220, Loss: 1.2587
Batch 230, Loss: 1.2793
Batch 240, Loss: 1.2815
Batch 250, Loss: 1.3149
Batch 260, Loss: 1.2801
Batch 270, Loss: 1.2852
Batch 280, Loss: 1.2947
Batch 290, Loss: 1.2237
Batch 300, Loss: 1.3287
Batch 310, Loss: 1.2877
Batch 320, Loss: 1.2099
Batch 330, Loss: 1.2105
Batch 340, Loss: 1.2228
Batch 350, Loss: 1.3175
Batch 360, Loss: 1.2826
Batch 370, Loss: 1.2522
Batch 380, Loss: 1.2676
Batch 390, Loss: 1.3011
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.330265760421753 seconds
Epoch 77 accuracy: 62.21%
Batch 10, Loss: 1.2493
Batch 20, Loss: 1.2663
Batch 30, Loss: 1.2466
Batch 40, Loss: 1.2267
Batch 50, Loss: 1.2538
Batch 60, Loss: 1.1674
Batch 70, Loss: 1.2010
Batch 80, Loss: 1.2353
Batch 90, Loss: 1.1789
Batch 100, Loss: 1.2024
Batch 110, Loss: 1.2779
Batch 120, Loss: 1.2465
Batch 130, Loss: 1.2030
Batch 140, Loss: 1.1991
Batch 150, Loss: 1.2280
Batch 160, Loss: 1.2460
Batch 170, Loss: 1.3054
Batch 180, Loss: 1.2450
Batch 190, Loss: 1.2642
Batch 200, Loss: 1.2493
Batch 210, Loss: 1.1823
Batch 220, Loss: 1.2303
Batch 230, Loss: 1.2393
Batch 240, Loss: 1.3081
Batch 250, Loss: 1.3329
Batch 260, Loss: 1.3131
Batch 270, Loss: 1.2245
Batch 280, Loss: 1.2740
Batch 290, Loss: 1.2483
Batch 300, Loss: 1.2301
Batch 310, Loss: 1.2116
Batch 320, Loss: 1.2679
Batch 330, Loss: 1.2690
Batch 340, Loss: 1.2564
Batch 350, Loss: 1.2229
Batch 360, Loss: 1.2867
Batch 370, Loss: 1.2610
Batch 380, Loss: 1.2450
Batch 390, Loss: 1.2598
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.328365802764893 seconds
Epoch 78 accuracy: 60.11%
Batch 10, Loss: 1.1969
Batch 20, Loss: 1.2501
Batch 30, Loss: 1.1976
Batch 40, Loss: 1.1851
Batch 50, Loss: 1.1543
Batch 60, Loss: 1.2266
Batch 70, Loss: 1.3205
Batch 80, Loss: 1.2380
Batch 90, Loss: 1.1896
Batch 100, Loss: 1.1648
Batch 110, Loss: 1.1916
Batch 120, Loss: 1.2413
Batch 130, Loss: 1.2051
Batch 140, Loss: 1.2621
Batch 150, Loss: 1.2581
Batch 160, Loss: 1.2434
Batch 170, Loss: 1.2893
Batch 180, Loss: 1.2881
Batch 190, Loss: 1.2570
Batch 200, Loss: 1.2100
Batch 210, Loss: 1.2415
Batch 220, Loss: 1.2629
Batch 230, Loss: 1.2747
Batch 240, Loss: 1.2523
Batch 250, Loss: 1.2238
Batch 260, Loss: 1.2674
Batch 270, Loss: 1.1366
Batch 280, Loss: 1.1960
Batch 290, Loss: 1.2720
Batch 300, Loss: 1.2802
Batch 310, Loss: 1.3447
Batch 320, Loss: 1.2588
Batch 330, Loss: 1.3442
Batch 340, Loss: 1.2300
Batch 350, Loss: 1.2886
Batch 360, Loss: 1.2894
Batch 370, Loss: 1.2360
Batch 380, Loss: 1.3118
Batch 390, Loss: 1.3255
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.297173500061035 seconds
Epoch 79 accuracy: 61.43%
Batch 10, Loss: 1.2713
Batch 20, Loss: 1.1989
Batch 30, Loss: 1.2525
Batch 40, Loss: 1.1601
Batch 50, Loss: 1.1747
Batch 60, Loss: 1.2100
Batch 70, Loss: 1.2069
Batch 80, Loss: 1.2626
Batch 90, Loss: 1.2073
Batch 100, Loss: 1.2296
Batch 110, Loss: 1.1688
Batch 120, Loss: 1.2153
Batch 130, Loss: 1.1814
Batch 140, Loss: 1.1740
Batch 150, Loss: 1.2755
Batch 160, Loss: 1.2474
Batch 170, Loss: 1.2127
Batch 180, Loss: 1.2155
Batch 190, Loss: 1.1897
Batch 200, Loss: 1.1449
Batch 210, Loss: 1.2072
Batch 220, Loss: 1.2504
Batch 230, Loss: 1.2405
Batch 240, Loss: 1.1947
Batch 250, Loss: 1.2374
Batch 260, Loss: 1.2952
Batch 270, Loss: 1.3092
Batch 280, Loss: 1.2023
Batch 290, Loss: 1.2883
Batch 300, Loss: 1.3227
Batch 310, Loss: 1.3295
Batch 320, Loss: 1.3041
Batch 330, Loss: 1.2524
Batch 340, Loss: 1.3457
Batch 350, Loss: 1.2182
Batch 360, Loss: 1.2120
Batch 370, Loss: 1.2979
Batch 380, Loss: 1.2949
Batch 390, Loss: 1.2864
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.220048666000366 seconds
Epoch 80 accuracy: 61.9%
Batch 10, Loss: 1.1695
Batch 20, Loss: 1.1669
Batch 30, Loss: 1.1734
Batch 40, Loss: 1.2297
Batch 50, Loss: 1.2238
Batch 60, Loss: 1.2457
Batch 70, Loss: 1.2530
Batch 80, Loss: 1.2657
Batch 90, Loss: 1.2355
Batch 100, Loss: 1.1846
Batch 110, Loss: 1.2331
Batch 120, Loss: 1.2033
Batch 130, Loss: 1.1663
Batch 140, Loss: 1.1854
Batch 150, Loss: 1.2432
Batch 160, Loss: 1.1843
Batch 170, Loss: 1.2639
Batch 180, Loss: 1.2358
Batch 190, Loss: 1.2380
Batch 200, Loss: 1.2328
Batch 210, Loss: 1.2441
Batch 220, Loss: 1.2793
Batch 230, Loss: 1.2642
Batch 240, Loss: 1.2558
Batch 250, Loss: 1.3037
Batch 260, Loss: 1.1587
Batch 270, Loss: 1.2290
Batch 280, Loss: 1.2474
Batch 290, Loss: 1.2417
Batch 300, Loss: 1.2258
Batch 310, Loss: 1.2787
Batch 320, Loss: 1.2603
Batch 330, Loss: 1.2181
Batch 340, Loss: 1.2479
Batch 350, Loss: 1.2131
Batch 360, Loss: 1.2554
Batch 370, Loss: 1.3304
Batch 380, Loss: 1.3098
Batch 390, Loss: 1.2861
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.324021577835083 seconds
Epoch 81 accuracy: 64.19%
Batch 10, Loss: 1.1117
Batch 20, Loss: 1.1643
Batch 30, Loss: 1.1594
Batch 40, Loss: 1.1938
Batch 50, Loss: 1.1684
Batch 60, Loss: 1.2466
Batch 70, Loss: 1.2092
Batch 80, Loss: 1.1893
Batch 90, Loss: 1.2269
Batch 100, Loss: 1.1909
Batch 110, Loss: 1.2202
Batch 120, Loss: 1.1646
Batch 130, Loss: 1.2793
Batch 140, Loss: 1.2250
Batch 150, Loss: 1.2094
Batch 160, Loss: 1.3332
Batch 170, Loss: 1.1336
Batch 180, Loss: 1.2562
Batch 190, Loss: 1.2351
Batch 200, Loss: 1.1974
Batch 210, Loss: 1.2773
Batch 220, Loss: 1.1940
Batch 230, Loss: 1.2231
Batch 240, Loss: 1.2369
Batch 250, Loss: 1.2786
Batch 260, Loss: 1.2450
Batch 270, Loss: 1.2095
Batch 280, Loss: 1.2878
Batch 290, Loss: 1.2121
Batch 300, Loss: 1.2289
Batch 310, Loss: 1.2384
Batch 320, Loss: 1.2619
Batch 330, Loss: 1.3750
Batch 340, Loss: 1.2127
Batch 350, Loss: 1.2481
Batch 360, Loss: 1.2881
Batch 370, Loss: 1.2284
Batch 380, Loss: 1.2392
Batch 390, Loss: 1.2458
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.254488229751587 seconds
Epoch 82 accuracy: 63.05%
Batch 10, Loss: 1.1668
Batch 20, Loss: 1.1773
Batch 30, Loss: 1.1737
Batch 40, Loss: 1.1973
Batch 50, Loss: 1.1581
Batch 60, Loss: 1.1990
Batch 70, Loss: 1.2231
Batch 80, Loss: 1.1412
Batch 90, Loss: 1.2296
Batch 100, Loss: 1.1785
Batch 110, Loss: 1.1942
Batch 120, Loss: 1.2043
Batch 130, Loss: 1.2757
Batch 140, Loss: 1.2336
Batch 150, Loss: 1.1715
Batch 160, Loss: 1.1625
Batch 170, Loss: 1.2688
Batch 180, Loss: 1.2460
Batch 190, Loss: 1.1987
Batch 200, Loss: 1.2222
Batch 210, Loss: 1.2254
Batch 220, Loss: 1.2381
Batch 230, Loss: 1.1957
Batch 240, Loss: 1.2770
Batch 250, Loss: 1.2219
Batch 260, Loss: 1.3075
Batch 270, Loss: 1.2271
Batch 280, Loss: 1.1232
Batch 290, Loss: 1.2344
Batch 300, Loss: 1.1577
Batch 310, Loss: 1.2264
Batch 320, Loss: 1.2641
Batch 330, Loss: 1.1560
Batch 340, Loss: 1.2440
Batch 350, Loss: 1.2346
Batch 360, Loss: 1.2106
Batch 370, Loss: 1.2170
Batch 380, Loss: 1.2711
Batch 390, Loss: 1.2762
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.242688179016113 seconds
Epoch 83 accuracy: 59.75%
Batch 10, Loss: 1.2540
Batch 20, Loss: 1.1192
Batch 30, Loss: 1.1849
Batch 40, Loss: 1.1855
Batch 50, Loss: 1.2034
Batch 60, Loss: 1.2485
Batch 70, Loss: 1.1980
Batch 80, Loss: 1.2024
Batch 90, Loss: 1.1606
Batch 100, Loss: 1.2361
Batch 110, Loss: 1.1924
Batch 120, Loss: 1.1379
Batch 130, Loss: 1.2070
Batch 140, Loss: 1.2433
Batch 150, Loss: 1.1954
Batch 160, Loss: 1.1911
Batch 170, Loss: 1.1417
Batch 180, Loss: 1.2089
Batch 190, Loss: 1.2152
Batch 200, Loss: 1.2740
Batch 210, Loss: 1.2014
Batch 220, Loss: 1.1527
Batch 230, Loss: 1.2005
Batch 240, Loss: 1.2250
Batch 250, Loss: 1.2832
Batch 260, Loss: 1.1892
Batch 270, Loss: 1.1209
Batch 280, Loss: 1.1979
Batch 290, Loss: 1.2516
Batch 300, Loss: 1.2580
Batch 310, Loss: 1.2368
Batch 320, Loss: 1.2186
Batch 330, Loss: 1.2402
Batch 340, Loss: 1.2346
Batch 350, Loss: 1.2890
Batch 360, Loss: 1.2859
Batch 370, Loss: 1.2583
Batch 380, Loss: 1.2106
Batch 390, Loss: 1.2669
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.26961636543274 seconds
Epoch 84 accuracy: 61.08%
Batch 10, Loss: 1.2224
Batch 20, Loss: 1.1513
Batch 30, Loss: 1.1841
Batch 40, Loss: 1.1378
Batch 50, Loss: 1.1738
Batch 60, Loss: 1.2232
Batch 70, Loss: 1.1072
Batch 80, Loss: 1.1857
Batch 90, Loss: 1.1785
Batch 100, Loss: 1.1907
Batch 110, Loss: 1.2354
Batch 120, Loss: 1.1795
Batch 130, Loss: 1.2126
Batch 140, Loss: 1.2425
Batch 150, Loss: 1.1559
Batch 160, Loss: 1.2113
Batch 170, Loss: 1.1493
Batch 180, Loss: 1.2106
Batch 190, Loss: 1.1951
Batch 200, Loss: 1.2181
Batch 210, Loss: 1.2153
Batch 220, Loss: 1.2073
Batch 230, Loss: 1.1766
Batch 240, Loss: 1.2380
Batch 250, Loss: 1.2356
Batch 260, Loss: 1.1585
Batch 270, Loss: 1.2155
Batch 280, Loss: 1.1870
Batch 290, Loss: 1.2054
Batch 300, Loss: 1.1786
Batch 310, Loss: 1.1845
Batch 320, Loss: 1.2308
Batch 330, Loss: 1.2072
Batch 340, Loss: 1.2865
Batch 350, Loss: 1.2519
Batch 360, Loss: 1.2958
Batch 370, Loss: 1.2297
Batch 380, Loss: 1.3317
Batch 390, Loss: 1.2329
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.37198257446289 seconds
Epoch 85 accuracy: 62.79%
Batch 10, Loss: 1.1920
Batch 20, Loss: 1.1598
Batch 30, Loss: 1.1526
Batch 40, Loss: 1.1671
Batch 50, Loss: 1.2048
Batch 60, Loss: 1.1730
Batch 70, Loss: 1.2124
Batch 80, Loss: 1.2060
Batch 90, Loss: 1.1542
Batch 100, Loss: 1.1360
Batch 110, Loss: 1.1865
Batch 120, Loss: 1.2117
Batch 130, Loss: 1.2173
Batch 140, Loss: 1.1659
Batch 150, Loss: 1.2216
Batch 160, Loss: 1.1857
Batch 170, Loss: 1.1660
Batch 180, Loss: 1.2436
Batch 190, Loss: 1.1675
Batch 200, Loss: 1.2991
Batch 210, Loss: 1.2592
Batch 220, Loss: 1.2190
Batch 230, Loss: 1.2138
Batch 240, Loss: 1.1944
Batch 250, Loss: 1.1621
Batch 260, Loss: 1.1846
Batch 270, Loss: 1.2353
Batch 280, Loss: 1.2177
Batch 290, Loss: 1.2277
Batch 300, Loss: 1.1977
Batch 310, Loss: 1.2405
Batch 320, Loss: 1.2423
Batch 330, Loss: 1.1994
Batch 340, Loss: 1.2903
Batch 350, Loss: 1.2171
Batch 360, Loss: 1.1604
Batch 370, Loss: 1.2007
Batch 380, Loss: 1.2186
Batch 390, Loss: 1.2251
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.298085689544678 seconds
Epoch 86 accuracy: 64.82%
Batch 10, Loss: 1.1423
Batch 20, Loss: 1.1365
Batch 30, Loss: 1.1782
Batch 40, Loss: 1.1910
Batch 50, Loss: 1.1317
Batch 60, Loss: 1.1701
Batch 70, Loss: 1.1565
Batch 80, Loss: 1.1775
Batch 90, Loss: 1.1876
Batch 100, Loss: 1.1787
Batch 110, Loss: 1.2029
Batch 120, Loss: 1.1804
Batch 130, Loss: 1.2044
Batch 140, Loss: 1.1427
Batch 150, Loss: 1.1644
Batch 160, Loss: 1.1380
Batch 170, Loss: 1.1995
Batch 180, Loss: 1.2252
Batch 190, Loss: 1.2055
Batch 200, Loss: 1.1799
Batch 210, Loss: 1.2052
Batch 220, Loss: 1.2311
Batch 230, Loss: 1.2069
Batch 240, Loss: 1.2641
Batch 250, Loss: 1.2245
Batch 260, Loss: 1.2013
Batch 270, Loss: 1.2282
Batch 280, Loss: 1.2516
Batch 290, Loss: 1.1976
Batch 300, Loss: 1.1741
Batch 310, Loss: 1.1710
Batch 320, Loss: 1.2381
Batch 330, Loss: 1.1379
Batch 340, Loss: 1.1515
Batch 350, Loss: 1.2408
Batch 360, Loss: 1.1915
Batch 370, Loss: 1.1917
Batch 380, Loss: 1.2358
Batch 390, Loss: 1.1651
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.25174069404602 seconds
Epoch 87 accuracy: 63.7%
Batch 10, Loss: 1.0905
Batch 20, Loss: 1.1178
Batch 30, Loss: 1.1964
Batch 40, Loss: 1.1081
Batch 50, Loss: 1.1492
Batch 60, Loss: 1.1846
Batch 70, Loss: 1.2121
Batch 80, Loss: 1.1702
Batch 90, Loss: 1.1977
Batch 100, Loss: 1.1811
Batch 110, Loss: 1.1908
Batch 120, Loss: 1.1450
Batch 130, Loss: 1.1559
Batch 140, Loss: 1.1735
Batch 150, Loss: 1.2169
Batch 160, Loss: 1.1554
Batch 170, Loss: 1.1853
Batch 180, Loss: 1.1975
Batch 190, Loss: 1.1534
Batch 200, Loss: 1.1970
Batch 210, Loss: 1.1960
Batch 220, Loss: 1.1753
Batch 230, Loss: 1.1307
Batch 240, Loss: 1.1587
Batch 250, Loss: 1.1397
Batch 260, Loss: 1.1580
Batch 270, Loss: 1.1925
Batch 280, Loss: 1.1938
Batch 290, Loss: 1.2230
Batch 300, Loss: 1.2066
Batch 310, Loss: 1.2143
Batch 320, Loss: 1.2375
Batch 330, Loss: 1.1967
Batch 340, Loss: 1.1202
Batch 350, Loss: 1.2376
Batch 360, Loss: 1.2356
Batch 370, Loss: 1.1909
Batch 380, Loss: 1.1851
Batch 390, Loss: 1.1895
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.2651207447052 seconds
Epoch 88 accuracy: 62.42%
Batch 10, Loss: 1.1256
Batch 20, Loss: 1.1309
Batch 30, Loss: 1.1539
Batch 40, Loss: 1.1379
Batch 50, Loss: 1.1236
Batch 60, Loss: 1.1344
Batch 70, Loss: 1.1474
Batch 80, Loss: 1.0986
Batch 90, Loss: 1.1695
Batch 100, Loss: 1.1751
Batch 110, Loss: 1.0969
Batch 120, Loss: 1.1572
Batch 130, Loss: 1.2065
Batch 140, Loss: 1.1999
Batch 150, Loss: 1.1591
Batch 160, Loss: 1.1675
Batch 170, Loss: 1.1751
Batch 180, Loss: 1.1842
Batch 190, Loss: 1.1682
Batch 200, Loss: 1.1773
Batch 210, Loss: 1.2109
Batch 220, Loss: 1.2167
Batch 230, Loss: 1.1671
Batch 240, Loss: 1.1815
Batch 250, Loss: 1.1516
Batch 260, Loss: 1.1945
Batch 270, Loss: 1.1334
Batch 280, Loss: 1.1910
Batch 290, Loss: 1.1660
Batch 300, Loss: 1.2552
Batch 310, Loss: 1.2301
Batch 320, Loss: 1.2338
Batch 330, Loss: 1.1817
Batch 340, Loss: 1.1738
Batch 350, Loss: 1.1667
Batch 360, Loss: 1.1462
Batch 370, Loss: 1.2325
Batch 380, Loss: 1.2702
Batch 390, Loss: 1.2186
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.311256885528564 seconds
Epoch 89 accuracy: 63.21%
Batch 10, Loss: 1.1355
Batch 20, Loss: 1.1260
Batch 30, Loss: 1.1334
Batch 40, Loss: 1.1401
Batch 50, Loss: 1.1060
Batch 60, Loss: 1.1737
Batch 70, Loss: 1.1580
Batch 80, Loss: 1.2189
Batch 90, Loss: 1.1539
Batch 100, Loss: 1.1658
Batch 110, Loss: 1.1320
Batch 120, Loss: 1.1639
Batch 130, Loss: 1.1398
Batch 140, Loss: 1.1145
Batch 150, Loss: 1.1961
Batch 160, Loss: 1.1585
Batch 170, Loss: 1.1082
Batch 180, Loss: 1.1298
Batch 190, Loss: 1.1441
Batch 200, Loss: 1.2047
Batch 210, Loss: 1.2672
Batch 220, Loss: 1.2267
Batch 230, Loss: 1.1758
Batch 240, Loss: 1.2248
Batch 250, Loss: 1.2422
Batch 260, Loss: 1.2355
Batch 270, Loss: 1.1392
Batch 280, Loss: 1.2394
Batch 290, Loss: 1.1742
Batch 300, Loss: 1.2573
Batch 310, Loss: 1.1892
Batch 320, Loss: 1.2452
Batch 330, Loss: 1.2397
Batch 340, Loss: 1.2261
Batch 350, Loss: 1.2269
Batch 360, Loss: 1.2108
Batch 370, Loss: 1.2108
Batch 380, Loss: 1.2124
Batch 390, Loss: 1.1779
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.289156675338745 seconds
Epoch 90 accuracy: 63.85%
Batch 10, Loss: 1.0931
Batch 20, Loss: 1.0843
Batch 30, Loss: 1.0895
Batch 40, Loss: 1.1136
Batch 50, Loss: 1.1290
Batch 60, Loss: 1.1732
Batch 70, Loss: 1.1519
Batch 80, Loss: 1.0925
Batch 90, Loss: 1.1476
Batch 100, Loss: 1.1720
Batch 110, Loss: 1.1736
Batch 120, Loss: 1.1735
Batch 130, Loss: 1.2055
Batch 140, Loss: 1.1751
Batch 150, Loss: 1.1596
Batch 160, Loss: 1.1403
Batch 170, Loss: 1.1293
Batch 180, Loss: 1.0915
Batch 190, Loss: 1.2109
Batch 200, Loss: 1.2305
Batch 210, Loss: 1.1904
Batch 220, Loss: 1.1468
Batch 230, Loss: 1.1480
Batch 240, Loss: 1.1487
Batch 250, Loss: 1.1456
Batch 260, Loss: 1.2372
Batch 270, Loss: 1.1900
Batch 280, Loss: 1.2111
Batch 290, Loss: 1.1667
Batch 300, Loss: 1.2070
Batch 310, Loss: 1.1510
Batch 320, Loss: 1.1491
Batch 330, Loss: 1.1991
Batch 340, Loss: 1.1190
Batch 350, Loss: 1.1891
Batch 360, Loss: 1.2148
Batch 370, Loss: 1.2302
Batch 380, Loss: 1.1983
Batch 390, Loss: 1.2067
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.276854038238525 seconds
Epoch 91 accuracy: 61.49%
Batch 10, Loss: 1.1858
Batch 20, Loss: 1.1597
Batch 30, Loss: 1.0807
Batch 40, Loss: 1.0956
Batch 50, Loss: 1.1268
Batch 60, Loss: 1.0678
Batch 70, Loss: 1.1368
Batch 80, Loss: 1.0986
Batch 90, Loss: 1.1743
Batch 100, Loss: 1.1122
Batch 110, Loss: 1.1277
Batch 120, Loss: 1.0629
Batch 130, Loss: 1.1782
Batch 140, Loss: 1.1762
Batch 150, Loss: 1.1996
Batch 160, Loss: 1.2051
Batch 170, Loss: 1.1653
Batch 180, Loss: 1.1447
Batch 190, Loss: 1.1725
Batch 200, Loss: 1.1531
Batch 210, Loss: 1.1890
Batch 220, Loss: 1.2193
Batch 230, Loss: 1.2176
Batch 240, Loss: 1.1907
Batch 250, Loss: 1.1906
Batch 260, Loss: 1.1548
Batch 270, Loss: 1.1832
Batch 280, Loss: 1.1760
Batch 290, Loss: 1.1787
Batch 300, Loss: 1.1540
Batch 310, Loss: 1.1593
Batch 320, Loss: 1.1909
Batch 330, Loss: 1.1512
Batch 340, Loss: 1.2004
Batch 350, Loss: 1.1863
Batch 360, Loss: 1.1704
Batch 370, Loss: 1.2314
Batch 380, Loss: 1.1835
Batch 390, Loss: 1.1895
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.279217958450317 seconds
Epoch 92 accuracy: 63.67%
Batch 10, Loss: 1.0984
Batch 20, Loss: 1.0946
Batch 30, Loss: 1.0999
Batch 40, Loss: 1.1697
Batch 50, Loss: 1.1316
Batch 60, Loss: 1.1602
Batch 70, Loss: 1.1089
Batch 80, Loss: 1.1225
Batch 90, Loss: 1.1331
Batch 100, Loss: 1.1719
Batch 110, Loss: 1.1547
Batch 120, Loss: 1.1382
Batch 130, Loss: 1.1038
Batch 140, Loss: 1.1572
Batch 150, Loss: 1.2057
Batch 160, Loss: 1.1486
Batch 170, Loss: 1.1600
Batch 180, Loss: 1.1103
Batch 190, Loss: 1.2002
Batch 200, Loss: 1.0684
Batch 210, Loss: 1.1892
Batch 220, Loss: 1.1611
Batch 230, Loss: 1.1409
Batch 240, Loss: 1.1734
Batch 250, Loss: 1.2804
Batch 260, Loss: 1.2087
Batch 270, Loss: 1.2161
Batch 280, Loss: 1.2026
Batch 290, Loss: 1.1129
Batch 300, Loss: 1.1954
Batch 310, Loss: 1.1824
Batch 320, Loss: 1.1356
Batch 330, Loss: 1.2403
Batch 340, Loss: 1.2019
Batch 350, Loss: 1.1642
Batch 360, Loss: 1.1855
Batch 370, Loss: 1.2187
Batch 380, Loss: 1.1603
Batch 390, Loss: 1.1513
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.279746055603027 seconds
Epoch 93 accuracy: 66.42%
Batch 10, Loss: 1.1346
Batch 20, Loss: 1.0798
Batch 30, Loss: 1.1064
Batch 40, Loss: 1.0907
Batch 50, Loss: 1.0574
Batch 60, Loss: 1.1088
Batch 70, Loss: 1.0655
Batch 80, Loss: 1.1328
Batch 90, Loss: 1.1032
Batch 100, Loss: 1.1121
Batch 110, Loss: 1.1568
Batch 120, Loss: 1.0856
Batch 130, Loss: 1.1655
Batch 140, Loss: 1.1519
Batch 150, Loss: 1.1526
Batch 160, Loss: 1.1623
Batch 170, Loss: 1.1439
Batch 180, Loss: 1.1612
Batch 190, Loss: 1.0838
Batch 200, Loss: 1.1653
Batch 210, Loss: 1.1477
Batch 220, Loss: 1.1858
Batch 230, Loss: 1.1362
Batch 240, Loss: 1.1475
Batch 250, Loss: 1.1205
Batch 260, Loss: 1.0962
Batch 270, Loss: 1.1838
Batch 280, Loss: 1.1280
Batch 290, Loss: 1.1285
Batch 300, Loss: 1.1437
Batch 310, Loss: 1.1553
Batch 320, Loss: 1.1214
Batch 330, Loss: 1.1762
Batch 340, Loss: 1.1728
Batch 350, Loss: 1.1850
Batch 360, Loss: 1.1302
Batch 370, Loss: 1.1800
Batch 380, Loss: 1.1094
Batch 390, Loss: 1.1061
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.350369691848755 seconds
Epoch 94 accuracy: 65.67%
Batch 10, Loss: 1.1113
Batch 20, Loss: 1.1071
Batch 30, Loss: 1.1326
Batch 40, Loss: 1.0526
Batch 50, Loss: 1.2027
Batch 60, Loss: 1.0556
Batch 70, Loss: 1.1007
Batch 80, Loss: 1.0834
Batch 90, Loss: 1.1623
Batch 100, Loss: 1.1327
Batch 110, Loss: 1.1331
Batch 120, Loss: 1.1724
Batch 130, Loss: 1.1526
Batch 140, Loss: 1.0871
Batch 150, Loss: 1.0970
Batch 160, Loss: 1.1476
Batch 170, Loss: 1.0923
Batch 180, Loss: 1.1782
Batch 190, Loss: 1.1279
Batch 200, Loss: 1.1070
Batch 210, Loss: 1.1430
Batch 220, Loss: 1.1623
Batch 230, Loss: 1.1825
Batch 240, Loss: 1.1271
Batch 250, Loss: 1.1666
Batch 260, Loss: 1.1722
Batch 270, Loss: 1.1270
Batch 280, Loss: 1.1506
Batch 290, Loss: 1.1039
Batch 300, Loss: 1.1754
Batch 310, Loss: 1.1834
Batch 320, Loss: 1.1680
Batch 330, Loss: 1.1299
Batch 340, Loss: 1.2467
Batch 350, Loss: 1.1694
Batch 360, Loss: 1.1565
Batch 370, Loss: 1.1561
Batch 380, Loss: 1.1489
Batch 390, Loss: 1.1208
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.22852611541748 seconds
Epoch 95 accuracy: 64.6%
Batch 10, Loss: 1.1017
Batch 20, Loss: 1.1142
Batch 30, Loss: 1.0713
Batch 40, Loss: 1.0820
Batch 50, Loss: 1.0734
Batch 60, Loss: 1.1570
Batch 70, Loss: 1.0520
Batch 80, Loss: 1.1086
Batch 90, Loss: 1.0923
Batch 100, Loss: 1.0719
Batch 110, Loss: 1.1013
Batch 120, Loss: 1.0843
Batch 130, Loss: 1.0961
Batch 140, Loss: 1.1605
Batch 150, Loss: 1.1691
Batch 160, Loss: 1.1697
Batch 170, Loss: 1.1051
Batch 180, Loss: 1.1938
Batch 190, Loss: 1.1284
Batch 200, Loss: 1.0958
Batch 210, Loss: 1.1252
Batch 220, Loss: 1.1722
Batch 230, Loss: 1.1585
Batch 240, Loss: 1.1515
Batch 250, Loss: 1.0865
Batch 260, Loss: 1.1306
Batch 270, Loss: 1.1294
Batch 280, Loss: 1.1652
Batch 290, Loss: 1.1374
Batch 300, Loss: 1.2186
Batch 310, Loss: 1.1464
Batch 320, Loss: 1.1764
Batch 330, Loss: 1.1980
Batch 340, Loss: 1.1900
Batch 350, Loss: 1.1519
Batch 360, Loss: 1.1453
Batch 370, Loss: 1.1642
Batch 380, Loss: 1.1531
Batch 390, Loss: 1.1537
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.19941544532776 seconds
Epoch 96 accuracy: 65.64%
Batch 10, Loss: 1.0591
Batch 20, Loss: 1.0415
Batch 30, Loss: 1.0511
Batch 40, Loss: 1.1193
Batch 50, Loss: 1.1230
Batch 60, Loss: 1.1339
Batch 70, Loss: 1.1447
Batch 80, Loss: 1.1080
Batch 90, Loss: 1.0534
Batch 100, Loss: 1.1079
Batch 110, Loss: 1.0010
Batch 120, Loss: 1.0787
Batch 130, Loss: 1.0710
Batch 140, Loss: 1.1561
Batch 150, Loss: 1.0976
Batch 160, Loss: 1.0994
Batch 170, Loss: 1.1010
Batch 180, Loss: 1.0460
Batch 190, Loss: 1.1082
Batch 200, Loss: 1.0836
Batch 210, Loss: 1.1296
Batch 220, Loss: 1.1638
Batch 230, Loss: 1.1490
Batch 240, Loss: 1.1528
Batch 250, Loss: 1.1104
Batch 260, Loss: 1.1864
Batch 270, Loss: 1.1241
Batch 280, Loss: 1.1567
Batch 290, Loss: 1.1365
Batch 300, Loss: 1.1587
Batch 310, Loss: 1.1336
Batch 320, Loss: 1.1290
Batch 330, Loss: 1.1854
Batch 340, Loss: 1.1010
Batch 350, Loss: 1.1194
Batch 360, Loss: 1.1134
Batch 370, Loss: 1.2011
Batch 380, Loss: 1.2022
Batch 390, Loss: 1.1302
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.308614015579224 seconds
Epoch 97 accuracy: 66.31%
Batch 10, Loss: 1.0744
Batch 20, Loss: 1.0942
Batch 30, Loss: 1.0487
Batch 40, Loss: 1.0712
Batch 50, Loss: 1.0309
Batch 60, Loss: 1.0488
Batch 70, Loss: 1.0802
Batch 80, Loss: 1.0794
Batch 90, Loss: 1.0486
Batch 100, Loss: 1.1455
Batch 110, Loss: 1.0770
Batch 120, Loss: 1.1051
Batch 130, Loss: 1.1374
Batch 140, Loss: 1.0757
Batch 150, Loss: 1.0920
Batch 160, Loss: 1.0412
Batch 170, Loss: 1.1182
Batch 180, Loss: 1.0647
Batch 190, Loss: 1.1659
Batch 200, Loss: 1.0980
Batch 210, Loss: 1.1581
Batch 220, Loss: 1.1143
Batch 230, Loss: 1.1789
Batch 240, Loss: 1.1415
Batch 250, Loss: 1.1337
Batch 260, Loss: 1.1157
Batch 270, Loss: 1.1752
Batch 280, Loss: 1.0930
Batch 290, Loss: 1.1740
Batch 300, Loss: 1.0822
Batch 310, Loss: 1.1852
Batch 320, Loss: 1.1222
Batch 330, Loss: 1.1418
Batch 340, Loss: 1.1703
Batch 350, Loss: 1.1056
Batch 360, Loss: 1.1170
Batch 370, Loss: 1.1897
Batch 380, Loss: 1.1380
Batch 390, Loss: 1.1816
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.192519426345825 seconds
Epoch 98 accuracy: 66.99%
Batch 10, Loss: 1.0354
Batch 20, Loss: 1.0041
Batch 30, Loss: 1.0903
Batch 40, Loss: 1.0693
Batch 50, Loss: 1.1133
Batch 60, Loss: 1.0720
Batch 70, Loss: 1.0727
Batch 80, Loss: 1.0689
Batch 90, Loss: 1.0314
Batch 100, Loss: 1.0911
Batch 110, Loss: 1.1481
Batch 120, Loss: 1.1240
Batch 130, Loss: 1.1494
Batch 140, Loss: 1.0998
Batch 150, Loss: 1.0738
Batch 160, Loss: 1.0768
Batch 170, Loss: 1.0770
Batch 180, Loss: 1.0742
Batch 190, Loss: 1.1551
Batch 200, Loss: 1.1047
Batch 210, Loss: 1.1382
Batch 220, Loss: 1.1367
Batch 230, Loss: 1.1415
Batch 240, Loss: 1.0810
Batch 250, Loss: 1.1147
Batch 260, Loss: 1.0712
Batch 270, Loss: 1.0983
Batch 280, Loss: 1.1457
Batch 290, Loss: 1.1495
Batch 300, Loss: 1.1211
Batch 310, Loss: 1.0690
Batch 320, Loss: 1.0272
Batch 330, Loss: 1.1154
Batch 340, Loss: 1.1093
Batch 350, Loss: 1.1421
Batch 360, Loss: 1.1283
Batch 370, Loss: 1.1646
Batch 380, Loss: 1.1447
Batch 390, Loss: 1.1658
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.271251678466797 seconds
Epoch 99 accuracy: 63.68%
Batch 10, Loss: 1.0621
Batch 20, Loss: 1.1136
Batch 30, Loss: 1.0444
Batch 40, Loss: 1.0758
Batch 50, Loss: 1.0568
Batch 60, Loss: 1.1429
Batch 70, Loss: 1.0986
Batch 80, Loss: 1.0395
Batch 90, Loss: 1.1185
Batch 100, Loss: 1.0918
Batch 110, Loss: 1.0875
Batch 120, Loss: 1.0690
Batch 130, Loss: 1.1561
Batch 140, Loss: 1.0787
Batch 150, Loss: 1.0808
Batch 160, Loss: 1.1475
Batch 170, Loss: 1.0899
Batch 180, Loss: 1.1468
Batch 190, Loss: 1.0929
Batch 200, Loss: 1.1378
Batch 210, Loss: 1.0552
Batch 220, Loss: 1.1474
Batch 230, Loss: 1.0698
Batch 240, Loss: 1.0987
Batch 250, Loss: 1.0751
Batch 260, Loss: 1.1797
Batch 270, Loss: 1.1081
Batch 280, Loss: 1.1391
Batch 290, Loss: 1.1127
Batch 300, Loss: 1.1129
Batch 310, Loss: 1.1430
Batch 320, Loss: 1.0914
Batch 330, Loss: 1.0486
Batch 340, Loss: 1.1206
Batch 350, Loss: 1.1574
Batch 360, Loss: 1.1446
Batch 370, Loss: 1.1270
Batch 380, Loss: 1.1129
Batch 390, Loss: 1.1547
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.254940032958984 seconds
Epoch 100 accuracy: 65.05%
Batch 10, Loss: 1.0435
Batch 20, Loss: 0.9887
Batch 30, Loss: 0.9951
Batch 40, Loss: 1.0909
Batch 50, Loss: 1.1234
Batch 60, Loss: 1.0505
Batch 70, Loss: 1.0974
Batch 80, Loss: 1.1010
Batch 90, Loss: 1.0342
Batch 100, Loss: 1.0499
Batch 110, Loss: 1.0832
Batch 120, Loss: 1.0780
Batch 130, Loss: 1.0437
Batch 140, Loss: 1.0603
Batch 150, Loss: 1.1136
Batch 160, Loss: 1.0930
Batch 170, Loss: 1.0842
Batch 180, Loss: 1.1165
Batch 190, Loss: 1.1140
Batch 200, Loss: 1.1315
Batch 210, Loss: 1.1056
Batch 220, Loss: 1.0655
Batch 230, Loss: 1.0493
Batch 240, Loss: 1.1343
Batch 250, Loss: 1.1813
Batch 260, Loss: 1.1138
Batch 270, Loss: 1.1243
Batch 280, Loss: 1.1182
Batch 290, Loss: 1.0357
Batch 300, Loss: 1.1607
Batch 310, Loss: 1.1005
Batch 320, Loss: 1.0787
Batch 330, Loss: 1.1469
Batch 340, Loss: 1.1511
Batch 350, Loss: 1.0983
Batch 360, Loss: 1.1197
Batch 370, Loss: 1.1015
Batch 380, Loss: 1.1782
Batch 390, Loss: 1.1318
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.289676427841187 seconds
Epoch 101 accuracy: 66.76%
Batch 10, Loss: 1.0476
Batch 20, Loss: 0.9886
Batch 30, Loss: 0.9738
Batch 40, Loss: 1.0386
Batch 50, Loss: 1.0182
Batch 60, Loss: 1.0645
Batch 70, Loss: 1.0386
Batch 80, Loss: 1.0367
Batch 90, Loss: 1.0666
Batch 100, Loss: 1.0760
Batch 110, Loss: 1.0358
Batch 120, Loss: 1.0497
Batch 130, Loss: 1.0195
Batch 140, Loss: 1.0270
Batch 150, Loss: 1.0885
Batch 160, Loss: 1.0942
Batch 170, Loss: 1.1359
Batch 180, Loss: 1.1320
Batch 190, Loss: 1.1183
Batch 200, Loss: 1.0668
Batch 210, Loss: 1.1061
Batch 220, Loss: 1.0689
Batch 230, Loss: 1.0665
Batch 240, Loss: 1.0070
Batch 250, Loss: 1.0748
Batch 260, Loss: 1.0737
Batch 270, Loss: 1.1246
Batch 280, Loss: 1.0697
Batch 290, Loss: 1.1433
Batch 300, Loss: 1.1325
Batch 310, Loss: 1.1558
Batch 320, Loss: 1.1381
Batch 330, Loss: 1.0943
Batch 340, Loss: 1.1156
Batch 350, Loss: 1.1399
Batch 360, Loss: 1.1053
Batch 370, Loss: 1.0818
Batch 380, Loss: 1.0794
Batch 390, Loss: 1.1809
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.356536865234375 seconds
Epoch 102 accuracy: 64.94%
Batch 10, Loss: 1.0577
Batch 20, Loss: 1.0201
Batch 30, Loss: 1.0269
Batch 40, Loss: 1.0239
Batch 50, Loss: 1.0542
Batch 60, Loss: 1.0095
Batch 70, Loss: 1.0639
Batch 80, Loss: 1.0496
Batch 90, Loss: 1.0289
Batch 100, Loss: 1.0608
Batch 110, Loss: 1.0968
Batch 120, Loss: 1.0435
Batch 130, Loss: 1.0785
Batch 140, Loss: 1.0543
Batch 150, Loss: 1.0751
Batch 160, Loss: 1.0948
Batch 170, Loss: 1.0985
Batch 180, Loss: 1.1431
Batch 190, Loss: 1.0491
Batch 200, Loss: 1.0873
Batch 210, Loss: 1.1093
Batch 220, Loss: 1.1167
Batch 230, Loss: 1.0838
Batch 240, Loss: 1.0755
Batch 250, Loss: 1.1143
Batch 260, Loss: 1.1031
Batch 270, Loss: 1.0472
Batch 280, Loss: 1.0751
Batch 290, Loss: 1.0496
Batch 300, Loss: 1.1365
Batch 310, Loss: 1.0998
Batch 320, Loss: 1.0537
Batch 330, Loss: 1.0851
Batch 340, Loss: 1.0995
Batch 350, Loss: 1.0748
Batch 360, Loss: 1.0571
Batch 370, Loss: 1.1168
Batch 380, Loss: 1.1186
Batch 390, Loss: 1.1517
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.295878171920776 seconds
Epoch 103 accuracy: 64.3%
Batch 10, Loss: 1.0320
Batch 20, Loss: 1.0158
Batch 30, Loss: 0.9962
Batch 40, Loss: 1.0607
Batch 50, Loss: 0.9761
Batch 60, Loss: 1.0686
Batch 70, Loss: 1.0385
Batch 80, Loss: 1.0608
Batch 90, Loss: 1.0121
Batch 100, Loss: 1.0601
Batch 110, Loss: 0.9891
Batch 120, Loss: 1.0572
Batch 130, Loss: 1.0517
Batch 140, Loss: 1.0250
Batch 150, Loss: 1.0907
Batch 160, Loss: 1.0025
Batch 170, Loss: 1.0511
Batch 180, Loss: 1.0549
Batch 190, Loss: 1.0332
Batch 200, Loss: 1.0906
Batch 210, Loss: 1.0596
Batch 220, Loss: 1.0249
Batch 230, Loss: 1.0570
Batch 240, Loss: 1.1397
Batch 250, Loss: 1.0620
Batch 260, Loss: 1.0972
Batch 270, Loss: 1.1270
Batch 280, Loss: 1.1041
Batch 290, Loss: 1.1152
Batch 300, Loss: 1.0624
Batch 310, Loss: 1.1140
Batch 320, Loss: 1.1384
Batch 330, Loss: 1.0695
Batch 340, Loss: 1.0937
Batch 350, Loss: 1.1051
Batch 360, Loss: 1.1745
Batch 370, Loss: 1.0974
Batch 380, Loss: 1.1126
Batch 390, Loss: 1.1211
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.202847480773926 seconds
Epoch 104 accuracy: 64.27%
Batch 10, Loss: 1.0406
Batch 20, Loss: 1.0080
Batch 30, Loss: 0.9977
Batch 40, Loss: 1.0646
Batch 50, Loss: 1.0015
Batch 60, Loss: 0.9855
Batch 70, Loss: 1.0081
Batch 80, Loss: 0.9942
Batch 90, Loss: 0.9875
Batch 100, Loss: 1.0517
Batch 110, Loss: 1.0377
Batch 120, Loss: 1.0259
Batch 130, Loss: 1.0610
Batch 140, Loss: 1.1037
Batch 150, Loss: 1.0279
Batch 160, Loss: 1.0619
Batch 170, Loss: 1.0187
Batch 180, Loss: 1.1017
Batch 190, Loss: 1.0685
Batch 200, Loss: 1.0168
Batch 210, Loss: 1.0956
Batch 220, Loss: 1.0461
Batch 230, Loss: 1.1012
Batch 240, Loss: 1.1115
Batch 250, Loss: 1.0825
Batch 260, Loss: 1.1506
Batch 270, Loss: 1.0688
Batch 280, Loss: 1.0879
Batch 290, Loss: 1.0991
Batch 300, Loss: 1.0657
Batch 310, Loss: 1.0691
Batch 320, Loss: 1.0939
Batch 330, Loss: 1.1069
Batch 340, Loss: 1.0908
Batch 350, Loss: 1.0849
Batch 360, Loss: 1.1053
Batch 370, Loss: 1.0943
Batch 380, Loss: 1.0899
Batch 390, Loss: 1.0301
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.260956287384033 seconds
Epoch 105 accuracy: 65.3%
Batch 10, Loss: 1.1056
Batch 20, Loss: 0.9951
Batch 30, Loss: 1.0003
Batch 40, Loss: 1.0025
Batch 50, Loss: 1.0221
Batch 60, Loss: 1.1021
Batch 70, Loss: 0.9884
Batch 80, Loss: 0.9721
Batch 90, Loss: 1.0237
Batch 100, Loss: 1.0589
Batch 110, Loss: 1.0484
Batch 120, Loss: 0.9949
Batch 130, Loss: 1.1199
Batch 140, Loss: 1.0287
Batch 150, Loss: 1.0207
Batch 160, Loss: 1.0469
Batch 170, Loss: 1.0924
Batch 180, Loss: 1.0341
Batch 190, Loss: 1.0272
Batch 200, Loss: 1.0282
Batch 210, Loss: 0.9894
Batch 220, Loss: 1.0686
Batch 230, Loss: 1.0681
Batch 240, Loss: 1.1104
Batch 250, Loss: 1.0627
Batch 260, Loss: 1.1452
Batch 270, Loss: 1.0532
Batch 280, Loss: 1.0565
Batch 290, Loss: 1.1314
Batch 300, Loss: 1.0969
Batch 310, Loss: 0.9935
Batch 320, Loss: 1.1153
Batch 330, Loss: 1.0522
Batch 340, Loss: 1.0339
Batch 350, Loss: 1.0106
Batch 360, Loss: 1.0948
Batch 370, Loss: 1.1095
Batch 380, Loss: 1.0681
Batch 390, Loss: 1.0754
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.338805437088013 seconds
Epoch 106 accuracy: 68.2%
Batch 10, Loss: 1.0126
Batch 20, Loss: 1.0012
Batch 30, Loss: 0.9544
Batch 40, Loss: 0.9964
Batch 50, Loss: 1.0271
Batch 60, Loss: 1.0023
Batch 70, Loss: 1.0393
Batch 80, Loss: 0.9896
Batch 90, Loss: 1.0003
Batch 100, Loss: 0.9995
Batch 110, Loss: 0.9937
Batch 120, Loss: 0.9828
Batch 130, Loss: 1.0078
Batch 140, Loss: 1.0182
Batch 150, Loss: 1.1017
Batch 160, Loss: 0.9736
Batch 170, Loss: 1.1062
Batch 180, Loss: 1.0413
Batch 190, Loss: 1.0612
Batch 200, Loss: 1.0855
Batch 210, Loss: 1.0294
Batch 220, Loss: 1.0641
Batch 230, Loss: 1.0776
Batch 240, Loss: 1.0665
Batch 250, Loss: 1.0368
Batch 260, Loss: 1.0637
Batch 270, Loss: 1.0489
Batch 280, Loss: 1.0165
Batch 290, Loss: 1.0969
Batch 300, Loss: 1.0237
Batch 310, Loss: 1.0438
Batch 320, Loss: 1.0729
Batch 330, Loss: 1.0301
Batch 340, Loss: 1.0695
Batch 350, Loss: 1.0458
Batch 360, Loss: 1.0725
Batch 370, Loss: 1.0719
Batch 380, Loss: 1.0828
Batch 390, Loss: 1.0873
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.275975704193115 seconds
Epoch 107 accuracy: 67.39%
Batch 10, Loss: 1.0028
Batch 20, Loss: 1.0104
Batch 30, Loss: 0.9524
Batch 40, Loss: 1.0393
Batch 50, Loss: 1.0215
Batch 60, Loss: 1.0196
Batch 70, Loss: 1.0070
Batch 80, Loss: 1.0312
Batch 90, Loss: 0.9599
Batch 100, Loss: 1.0001
Batch 110, Loss: 1.0849
Batch 120, Loss: 1.0494
Batch 130, Loss: 1.0253
Batch 140, Loss: 1.0554
Batch 150, Loss: 1.0905
Batch 160, Loss: 1.0595
Batch 170, Loss: 0.9898
Batch 180, Loss: 1.0399
Batch 190, Loss: 0.9584
Batch 200, Loss: 1.0835
Batch 210, Loss: 1.0074
Batch 220, Loss: 1.0234
Batch 230, Loss: 1.0693
Batch 240, Loss: 1.0321
Batch 250, Loss: 1.0462
Batch 260, Loss: 1.0598
Batch 270, Loss: 1.0562
Batch 280, Loss: 1.0076
Batch 290, Loss: 1.0503
Batch 300, Loss: 1.0788
Batch 310, Loss: 1.0271
Batch 320, Loss: 1.0288
Batch 330, Loss: 1.1209
Batch 340, Loss: 1.0317
Batch 350, Loss: 1.0228
Batch 360, Loss: 1.0841
Batch 370, Loss: 1.0335
Batch 380, Loss: 1.0287
Batch 390, Loss: 1.0683
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.27366042137146 seconds
Epoch 108 accuracy: 67.84%
Batch 10, Loss: 1.0191
Batch 20, Loss: 0.9490
Batch 30, Loss: 1.0094
Batch 40, Loss: 0.9966
Batch 50, Loss: 1.0304
Batch 60, Loss: 0.9807
Batch 70, Loss: 0.9624
Batch 80, Loss: 1.0155
Batch 90, Loss: 0.9325
Batch 100, Loss: 0.9825
Batch 110, Loss: 0.9669
Batch 120, Loss: 0.9482
Batch 130, Loss: 1.0391
Batch 140, Loss: 0.9843
Batch 150, Loss: 0.9855
Batch 160, Loss: 0.9968
Batch 170, Loss: 1.1251
Batch 180, Loss: 1.0113
Batch 190, Loss: 1.0493
Batch 200, Loss: 1.0253
Batch 210, Loss: 1.0097
Batch 220, Loss: 1.0430
Batch 230, Loss: 1.0264
Batch 240, Loss: 1.0246
Batch 250, Loss: 1.0331
Batch 260, Loss: 1.0528
Batch 270, Loss: 1.0946
Batch 280, Loss: 1.0547
Batch 290, Loss: 1.0542
Batch 300, Loss: 1.0560
Batch 310, Loss: 1.0437
Batch 320, Loss: 1.0881
Batch 330, Loss: 1.0325
Batch 340, Loss: 1.0364
Batch 350, Loss: 1.0839
Batch 360, Loss: 1.1295
Batch 370, Loss: 1.0554
Batch 380, Loss: 0.9811
Batch 390, Loss: 1.0538
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.24828267097473 seconds
Epoch 109 accuracy: 66.58%
Batch 10, Loss: 0.9768
Batch 20, Loss: 1.0298
Batch 30, Loss: 0.9436
Batch 40, Loss: 1.0311
Batch 50, Loss: 0.9350
Batch 60, Loss: 1.0045
Batch 70, Loss: 1.0081
Batch 80, Loss: 1.0034
Batch 90, Loss: 0.9899
Batch 100, Loss: 0.9668
Batch 110, Loss: 1.0560
Batch 120, Loss: 1.0381
Batch 130, Loss: 0.9902
Batch 140, Loss: 0.9874
Batch 150, Loss: 0.9705
Batch 160, Loss: 0.9723
Batch 170, Loss: 1.0171
Batch 180, Loss: 1.0695
Batch 190, Loss: 1.0414
Batch 200, Loss: 1.0213
Batch 210, Loss: 0.9923
Batch 220, Loss: 1.0236
Batch 230, Loss: 1.0419
Batch 240, Loss: 1.0132
Batch 250, Loss: 1.0067
Batch 260, Loss: 0.9352
Batch 270, Loss: 1.0187
Batch 280, Loss: 1.0476
Batch 290, Loss: 1.1231
Batch 300, Loss: 1.0394
Batch 310, Loss: 1.0767
Batch 320, Loss: 1.0472
Batch 330, Loss: 1.1099
Batch 340, Loss: 1.0746
Batch 350, Loss: 1.1119
Batch 360, Loss: 1.0701
Batch 370, Loss: 1.0399
Batch 380, Loss: 1.0569
Batch 390, Loss: 1.0613
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.188333749771118 seconds
Epoch 110 accuracy: 66.28%
Batch 10, Loss: 0.9723
Batch 20, Loss: 0.9597
Batch 30, Loss: 0.9763
Batch 40, Loss: 0.9942
Batch 50, Loss: 0.9922
Batch 60, Loss: 0.9527
Batch 70, Loss: 0.9434
Batch 80, Loss: 0.9763
Batch 90, Loss: 0.9387
Batch 100, Loss: 0.9390
Batch 110, Loss: 1.0009
Batch 120, Loss: 1.0116
Batch 130, Loss: 0.9922
Batch 140, Loss: 1.0156
Batch 150, Loss: 0.9818
Batch 160, Loss: 0.9822
Batch 170, Loss: 1.0314
Batch 180, Loss: 0.9762
Batch 190, Loss: 1.0619
Batch 200, Loss: 1.0903
Batch 210, Loss: 1.0815
Batch 220, Loss: 1.0290
Batch 230, Loss: 0.9831
Batch 240, Loss: 1.0839
Batch 250, Loss: 0.9963
Batch 260, Loss: 1.0351
Batch 270, Loss: 1.0039
Batch 280, Loss: 1.0904
Batch 290, Loss: 1.0367
Batch 300, Loss: 1.1034
Batch 310, Loss: 1.0051
Batch 320, Loss: 1.0079
Batch 330, Loss: 1.0667
Batch 340, Loss: 1.0253
Batch 350, Loss: 1.0318
Batch 360, Loss: 1.0390
Batch 370, Loss: 0.9740
Batch 380, Loss: 1.0196
Batch 390, Loss: 1.0136
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.26886248588562 seconds
Epoch 111 accuracy: 67.05%
Batch 10, Loss: 0.9479
Batch 20, Loss: 0.9761
Batch 30, Loss: 0.9566
Batch 40, Loss: 0.9752
Batch 50, Loss: 0.9870
Batch 60, Loss: 0.9493
Batch 70, Loss: 0.9184
Batch 80, Loss: 0.9603
Batch 90, Loss: 1.0036
Batch 100, Loss: 0.9589
Batch 110, Loss: 0.9741
Batch 120, Loss: 1.0165
Batch 130, Loss: 1.0009
Batch 140, Loss: 0.9875
Batch 150, Loss: 0.9650
Batch 160, Loss: 1.0008
Batch 170, Loss: 0.9519
Batch 180, Loss: 1.0108
Batch 190, Loss: 1.0289
Batch 200, Loss: 0.9910
Batch 210, Loss: 1.0375
Batch 220, Loss: 1.0390
Batch 230, Loss: 1.0472
Batch 240, Loss: 1.0105
Batch 250, Loss: 1.0047
Batch 260, Loss: 1.0288
Batch 270, Loss: 1.0203
Batch 280, Loss: 1.0329
Batch 290, Loss: 0.9956
Batch 300, Loss: 1.0123
Batch 310, Loss: 1.0085
Batch 320, Loss: 1.0709
Batch 330, Loss: 0.9949
Batch 340, Loss: 1.0522
Batch 350, Loss: 1.0346
Batch 360, Loss: 0.9626
Batch 370, Loss: 1.1069
Batch 380, Loss: 1.0113
Batch 390, Loss: 1.0630
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.306708335876465 seconds
Epoch 112 accuracy: 66.55%
Batch 10, Loss: 0.9650
Batch 20, Loss: 0.9058
Batch 30, Loss: 0.9424
Batch 40, Loss: 0.9013
Batch 50, Loss: 0.9250
Batch 60, Loss: 0.9409
Batch 70, Loss: 0.9914
Batch 80, Loss: 0.9907
Batch 90, Loss: 0.9774
Batch 100, Loss: 1.0006
Batch 110, Loss: 0.9765
Batch 120, Loss: 0.9855
Batch 130, Loss: 0.9938
Batch 140, Loss: 1.0245
Batch 150, Loss: 0.9903
Batch 160, Loss: 0.9883
Batch 170, Loss: 0.9387
Batch 180, Loss: 0.9403
Batch 190, Loss: 1.0185
Batch 200, Loss: 1.0926
Batch 210, Loss: 0.9831
Batch 220, Loss: 1.0017
Batch 230, Loss: 0.9915
Batch 240, Loss: 0.9920
Batch 250, Loss: 0.9976
Batch 260, Loss: 1.0720
Batch 270, Loss: 1.0138
Batch 280, Loss: 0.9894
Batch 290, Loss: 1.0621
Batch 300, Loss: 0.9728
Batch 310, Loss: 0.9784
Batch 320, Loss: 1.0288
Batch 330, Loss: 1.0053
Batch 340, Loss: 1.0420
Batch 350, Loss: 1.0183
Batch 360, Loss: 1.0015
Batch 370, Loss: 0.9287
Batch 380, Loss: 1.0150
Batch 390, Loss: 1.0649
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.189581155776978 seconds
Epoch 113 accuracy: 67.36%
Batch 10, Loss: 0.9387
Batch 20, Loss: 0.9810
Batch 30, Loss: 0.9764
Batch 40, Loss: 0.9443
Batch 50, Loss: 0.8993
Batch 60, Loss: 0.9920
Batch 70, Loss: 0.9430
Batch 80, Loss: 0.9429
Batch 90, Loss: 0.9630
Batch 100, Loss: 0.9474
Batch 110, Loss: 0.9846
Batch 120, Loss: 0.9726
Batch 130, Loss: 0.9428
Batch 140, Loss: 0.9265
Batch 150, Loss: 1.0219
Batch 160, Loss: 0.9945
Batch 170, Loss: 1.0083
Batch 180, Loss: 0.9807
Batch 190, Loss: 0.9333
Batch 200, Loss: 0.9886
Batch 210, Loss: 0.9673
Batch 220, Loss: 0.9765
Batch 230, Loss: 0.9481
Batch 240, Loss: 1.0130
Batch 250, Loss: 1.0515
Batch 260, Loss: 0.9874
Batch 270, Loss: 0.9799
Batch 280, Loss: 0.9871
Batch 290, Loss: 0.9942
Batch 300, Loss: 0.9572
Batch 310, Loss: 1.0324
Batch 320, Loss: 0.9696
Batch 330, Loss: 1.0516
Batch 340, Loss: 0.9717
Batch 350, Loss: 0.9974
Batch 360, Loss: 1.0042
Batch 370, Loss: 0.9582
Batch 380, Loss: 1.0381
Batch 390, Loss: 0.9913
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.259891271591187 seconds
Epoch 114 accuracy: 67.37%
Batch 10, Loss: 0.9683
Batch 20, Loss: 0.8811
Batch 30, Loss: 0.9320
Batch 40, Loss: 0.9868
Batch 50, Loss: 0.9218
Batch 60, Loss: 0.9566
Batch 70, Loss: 0.9573
Batch 80, Loss: 0.9508
Batch 90, Loss: 0.8730
Batch 100, Loss: 0.8995
Batch 110, Loss: 0.9026
Batch 120, Loss: 0.9328
Batch 130, Loss: 1.0282
Batch 140, Loss: 1.0155
Batch 150, Loss: 0.9774
Batch 160, Loss: 1.0096
Batch 170, Loss: 0.9589
Batch 180, Loss: 0.9266
Batch 190, Loss: 0.9472
Batch 200, Loss: 0.9522
Batch 210, Loss: 1.0466
Batch 220, Loss: 0.9908
Batch 230, Loss: 0.9693
Batch 240, Loss: 0.9999
Batch 250, Loss: 0.9544
Batch 260, Loss: 1.0355
Batch 270, Loss: 1.0029
Batch 280, Loss: 1.0042
Batch 290, Loss: 0.9539
Batch 300, Loss: 1.0331
Batch 310, Loss: 0.9840
Batch 320, Loss: 0.9784
Batch 330, Loss: 0.9868
Batch 340, Loss: 0.9865
Batch 350, Loss: 1.0176
Batch 360, Loss: 1.0008
Batch 370, Loss: 0.9938
Batch 380, Loss: 0.9902
Batch 390, Loss: 1.0483
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.2335844039917 seconds
Epoch 115 accuracy: 67.88%
Batch 10, Loss: 0.9120
Batch 20, Loss: 0.8893
Batch 30, Loss: 0.9572
Batch 40, Loss: 0.9478
Batch 50, Loss: 0.9434
Batch 60, Loss: 0.9772
Batch 70, Loss: 0.9195
Batch 80, Loss: 0.9762
Batch 90, Loss: 0.8819
Batch 100, Loss: 0.8978
Batch 110, Loss: 0.9869
Batch 120, Loss: 0.9557
Batch 130, Loss: 0.9226
Batch 140, Loss: 0.9581
Batch 150, Loss: 0.9129
Batch 160, Loss: 1.0045
Batch 170, Loss: 0.9747
Batch 180, Loss: 0.9933
Batch 190, Loss: 1.0320
Batch 200, Loss: 0.9939
Batch 210, Loss: 0.9820
Batch 220, Loss: 0.9334
Batch 230, Loss: 1.0098
Batch 240, Loss: 1.0246
Batch 250, Loss: 0.9406
Batch 260, Loss: 1.0278
Batch 270, Loss: 0.9844
Batch 280, Loss: 1.0005
Batch 290, Loss: 1.0318
Batch 300, Loss: 0.9970
Batch 310, Loss: 0.9176
Batch 320, Loss: 1.0282
Batch 330, Loss: 0.9307
Batch 340, Loss: 1.0409
Batch 350, Loss: 0.9793
Batch 360, Loss: 1.0318
Batch 370, Loss: 1.0258
Batch 380, Loss: 0.9994
Batch 390, Loss: 0.9806
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.246015787124634 seconds
Epoch 116 accuracy: 68.48%
Batch 10, Loss: 0.9048
Batch 20, Loss: 0.9138
Batch 30, Loss: 0.9469
Batch 40, Loss: 0.8707
Batch 50, Loss: 0.9465
Batch 60, Loss: 0.9159
Batch 70, Loss: 0.8872
Batch 80, Loss: 0.9699
Batch 90, Loss: 0.9554
Batch 100, Loss: 0.9182
Batch 110, Loss: 0.9662
Batch 120, Loss: 0.9101
Batch 130, Loss: 0.9500
Batch 140, Loss: 0.9563
Batch 150, Loss: 0.9677
Batch 160, Loss: 1.0242
Batch 170, Loss: 0.9974
Batch 180, Loss: 1.0410
Batch 190, Loss: 0.9445
Batch 200, Loss: 0.9823
Batch 210, Loss: 1.0035
Batch 220, Loss: 1.0738
Batch 230, Loss: 0.9860
Batch 240, Loss: 0.9633
Batch 250, Loss: 0.9131
Batch 260, Loss: 0.9703
Batch 270, Loss: 0.9106
Batch 280, Loss: 0.9442
Batch 290, Loss: 0.9183
Batch 300, Loss: 0.9238
Batch 310, Loss: 0.9665
Batch 320, Loss: 1.0273
Batch 330, Loss: 0.9536
Batch 340, Loss: 1.0034
Batch 350, Loss: 1.0459
Batch 360, Loss: 0.9906
Batch 370, Loss: 0.9925
Batch 380, Loss: 0.9768
Batch 390, Loss: 0.9205
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.333497524261475 seconds
Epoch 117 accuracy: 68.41%
Batch 10, Loss: 0.8996
Batch 20, Loss: 0.8973
Batch 30, Loss: 0.8787
Batch 40, Loss: 0.8978
Batch 50, Loss: 0.9902
Batch 60, Loss: 0.8574
Batch 70, Loss: 0.8949
Batch 80, Loss: 0.9222
Batch 90, Loss: 0.8653
Batch 100, Loss: 0.9353
Batch 110, Loss: 0.8729
Batch 120, Loss: 0.9641
Batch 130, Loss: 0.9217
Batch 140, Loss: 0.9423
Batch 150, Loss: 0.9274
Batch 160, Loss: 0.9402
Batch 170, Loss: 0.9125
Batch 180, Loss: 0.9438
Batch 190, Loss: 0.9432
Batch 200, Loss: 0.9151
Batch 210, Loss: 0.9823
Batch 220, Loss: 0.9119
Batch 230, Loss: 0.9455
Batch 240, Loss: 0.9472
Batch 250, Loss: 0.9657
Batch 260, Loss: 0.9528
Batch 270, Loss: 0.9515
Batch 280, Loss: 0.9779
Batch 290, Loss: 0.9740
Batch 300, Loss: 1.0001
Batch 310, Loss: 0.9198
Batch 320, Loss: 0.9630
Batch 330, Loss: 0.9978
Batch 340, Loss: 0.9654
Batch 350, Loss: 1.0045
Batch 360, Loss: 0.9188
Batch 370, Loss: 0.9710
Batch 380, Loss: 0.9553
Batch 390, Loss: 0.9163
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.27311372756958 seconds
Epoch 118 accuracy: 69.23%
Batch 10, Loss: 0.8838
Batch 20, Loss: 0.8951
Batch 30, Loss: 0.8685
Batch 40, Loss: 0.9323
Batch 50, Loss: 0.9498
Batch 60, Loss: 0.9186
Batch 70, Loss: 0.8706
Batch 80, Loss: 0.9145
Batch 90, Loss: 0.9053
Batch 100, Loss: 0.8293
Batch 110, Loss: 0.8899
Batch 120, Loss: 0.9148
Batch 130, Loss: 0.8954
Batch 140, Loss: 0.8838
Batch 150, Loss: 0.9251
Batch 160, Loss: 0.9184
Batch 170, Loss: 0.8902
Batch 180, Loss: 0.9047
Batch 190, Loss: 0.8729
Batch 200, Loss: 0.8864
Batch 210, Loss: 0.9258
Batch 220, Loss: 0.9545
Batch 230, Loss: 0.9163
Batch 240, Loss: 0.9621
Batch 250, Loss: 0.9574
Batch 260, Loss: 0.9123
Batch 270, Loss: 0.9734
Batch 280, Loss: 0.9393
Batch 290, Loss: 0.9482
Batch 300, Loss: 0.9209
Batch 310, Loss: 0.9457
Batch 320, Loss: 0.9925
Batch 330, Loss: 0.9282
Batch 340, Loss: 0.9938
Batch 350, Loss: 0.9878
Batch 360, Loss: 0.9524
Batch 370, Loss: 0.9846
Batch 380, Loss: 0.9787
Batch 390, Loss: 1.0161
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.26397156715393 seconds
Epoch 119 accuracy: 67.72%
Batch 10, Loss: 0.9474
Batch 20, Loss: 0.9172
Batch 30, Loss: 0.8575
Batch 40, Loss: 0.9037
Batch 50, Loss: 0.8966
Batch 60, Loss: 0.8957
Batch 70, Loss: 0.9071
Batch 80, Loss: 0.9342
Batch 90, Loss: 0.9091
Batch 100, Loss: 0.9045
Batch 110, Loss: 0.9061
Batch 120, Loss: 0.9033
Batch 130, Loss: 0.8773
Batch 140, Loss: 0.9201
Batch 150, Loss: 0.9239
Batch 160, Loss: 0.9007
Batch 170, Loss: 0.9531
Batch 180, Loss: 0.9087
Batch 190, Loss: 0.9910
Batch 200, Loss: 0.9614
Batch 210, Loss: 0.9024
Batch 220, Loss: 0.9667
Batch 230, Loss: 0.9249
Batch 240, Loss: 0.9610
Batch 250, Loss: 0.9012
Batch 260, Loss: 0.9519
Batch 270, Loss: 0.8986
Batch 280, Loss: 0.9566
Batch 290, Loss: 0.9142
Batch 300, Loss: 0.9718
Batch 310, Loss: 0.9653
Batch 320, Loss: 0.9605
Batch 330, Loss: 0.9661
Batch 340, Loss: 0.9444
Batch 350, Loss: 0.9419
Batch 360, Loss: 0.9870
Batch 370, Loss: 0.9328
Batch 380, Loss: 0.9626
Batch 390, Loss: 0.9243
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.305983066558838 seconds
Epoch 120 accuracy: 69.13%
Batch 10, Loss: 0.9043
Batch 20, Loss: 0.8985
Batch 30, Loss: 0.9244
Batch 40, Loss: 0.8963
Batch 50, Loss: 0.8971
Batch 60, Loss: 0.8318
Batch 70, Loss: 0.8544
Batch 80, Loss: 0.8636
Batch 90, Loss: 0.9209
Batch 100, Loss: 0.9154
Batch 110, Loss: 0.9487
Batch 120, Loss: 0.9107
Batch 130, Loss: 0.9636
Batch 140, Loss: 0.9132
Batch 150, Loss: 0.9133
Batch 160, Loss: 0.8990
Batch 170, Loss: 0.9427
Batch 180, Loss: 0.9161
Batch 190, Loss: 0.8835
Batch 200, Loss: 0.9360
Batch 210, Loss: 0.8913
Batch 220, Loss: 0.9189
Batch 230, Loss: 0.9218
Batch 240, Loss: 0.9411
Batch 250, Loss: 0.8938
Batch 260, Loss: 0.9475
Batch 270, Loss: 0.8814
Batch 280, Loss: 0.9176
Batch 290, Loss: 0.8835
Batch 300, Loss: 0.9490
Batch 310, Loss: 0.9761
Batch 320, Loss: 0.9372
Batch 330, Loss: 0.9344
Batch 340, Loss: 0.9298
Batch 350, Loss: 0.9464
Batch 360, Loss: 0.9180
Batch 370, Loss: 0.9598
Batch 380, Loss: 0.9570
Batch 390, Loss: 0.9640
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.223441123962402 seconds
Epoch 121 accuracy: 68.21%
Batch 10, Loss: 0.9309
Batch 20, Loss: 0.8591
Batch 30, Loss: 0.8615
Batch 40, Loss: 0.8337
Batch 50, Loss: 0.8548
Batch 60, Loss: 0.8420
Batch 70, Loss: 0.8314
Batch 80, Loss: 0.9392
Batch 90, Loss: 0.8875
Batch 100, Loss: 0.9476
Batch 110, Loss: 0.8880
Batch 120, Loss: 0.8662
Batch 130, Loss: 0.8761
Batch 140, Loss: 0.9062
Batch 150, Loss: 0.9169
Batch 160, Loss: 0.8932
Batch 170, Loss: 0.8852
Batch 180, Loss: 0.8306
Batch 190, Loss: 0.9227
Batch 200, Loss: 0.8963
Batch 210, Loss: 0.9630
Batch 220, Loss: 0.8585
Batch 230, Loss: 0.9245
Batch 240, Loss: 0.9296
Batch 250, Loss: 0.8481
Batch 260, Loss: 0.9046
Batch 270, Loss: 0.9509
Batch 280, Loss: 0.9038
Batch 290, Loss: 0.9189
Batch 300, Loss: 0.9063
Batch 310, Loss: 0.8969
Batch 320, Loss: 0.9532
Batch 330, Loss: 0.9704
Batch 340, Loss: 0.9443
Batch 350, Loss: 0.9989
Batch 360, Loss: 0.9654
Batch 370, Loss: 0.8949
Batch 380, Loss: 0.9291
Batch 390, Loss: 0.9305
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.237727880477905 seconds
Epoch 122 accuracy: 69.58%
Batch 10, Loss: 0.8614
Batch 20, Loss: 0.8922
Batch 30, Loss: 0.8762
Batch 40, Loss: 0.8785
Batch 50, Loss: 0.8647
Batch 60, Loss: 0.8887
Batch 70, Loss: 0.8784
Batch 80, Loss: 0.8462
Batch 90, Loss: 0.8648
Batch 100, Loss: 0.9279
Batch 110, Loss: 0.8591
Batch 120, Loss: 0.8615
Batch 130, Loss: 0.8651
Batch 140, Loss: 0.8677
Batch 150, Loss: 0.8627
Batch 160, Loss: 0.9653
Batch 170, Loss: 0.9094
Batch 180, Loss: 0.9319
Batch 190, Loss: 0.8787
Batch 200, Loss: 0.9138
Batch 210, Loss: 0.8887
Batch 220, Loss: 0.9324
Batch 230, Loss: 0.8874
Batch 240, Loss: 0.9461
Batch 250, Loss: 0.9163
Batch 260, Loss: 0.9086
Batch 270, Loss: 0.8905
Batch 280, Loss: 0.9192
Batch 290, Loss: 0.8818
Batch 300, Loss: 0.9730
Batch 310, Loss: 0.8939
Batch 320, Loss: 0.9316
Batch 330, Loss: 0.8902
Batch 340, Loss: 0.8906
Batch 350, Loss: 0.9189
Batch 360, Loss: 0.9301
Batch 370, Loss: 0.9534
Batch 380, Loss: 0.9199
Batch 390, Loss: 0.9300
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.241766691207886 seconds
Epoch 123 accuracy: 69.2%
Batch 10, Loss: 0.8851
Batch 20, Loss: 0.8938
Batch 30, Loss: 0.8677
Batch 40, Loss: 0.9474
Batch 50, Loss: 0.8354
Batch 60, Loss: 0.8766
Batch 70, Loss: 0.8451
Batch 80, Loss: 0.8799
Batch 90, Loss: 0.8424
Batch 100, Loss: 0.8354
Batch 110, Loss: 0.8407
Batch 120, Loss: 0.8369
Batch 130, Loss: 0.8880
Batch 140, Loss: 0.9631
Batch 150, Loss: 0.9040
Batch 160, Loss: 0.8661
Batch 170, Loss: 0.8969
Batch 180, Loss: 0.8502
Batch 190, Loss: 0.9262
Batch 200, Loss: 0.8645
Batch 210, Loss: 0.8320
Batch 220, Loss: 0.9138
Batch 230, Loss: 0.8784
Batch 240, Loss: 0.9020
Batch 250, Loss: 0.9467
Batch 260, Loss: 0.9381
Batch 270, Loss: 0.8785
Batch 280, Loss: 0.9243
Batch 290, Loss: 0.8663
Batch 300, Loss: 0.8843
Batch 310, Loss: 0.9058
Batch 320, Loss: 0.9443
Batch 330, Loss: 0.9084
Batch 340, Loss: 0.9024
Batch 350, Loss: 0.9040
Batch 360, Loss: 0.9766
Batch 370, Loss: 0.8989
Batch 380, Loss: 0.8714
Batch 390, Loss: 0.9831
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.2819344997406 seconds
Epoch 124 accuracy: 70.46%
Batch 10, Loss: 0.8407
Batch 20, Loss: 0.8088
Batch 30, Loss: 0.8250
Batch 40, Loss: 0.8212
Batch 50, Loss: 0.8299
Batch 60, Loss: 0.8872
Batch 70, Loss: 0.8432
Batch 80, Loss: 0.8232
Batch 90, Loss: 0.8541
Batch 100, Loss: 0.8321
Batch 110, Loss: 0.8416
Batch 120, Loss: 0.8285
Batch 130, Loss: 0.8584
Batch 140, Loss: 0.8516
Batch 150, Loss: 0.8403
Batch 160, Loss: 0.8689
Batch 170, Loss: 0.8607
Batch 180, Loss: 0.8452
Batch 190, Loss: 0.8590
Batch 200, Loss: 0.8746
Batch 210, Loss: 0.8523
Batch 220, Loss: 0.8877
Batch 230, Loss: 0.9078
Batch 240, Loss: 0.8540
Batch 250, Loss: 0.8113
Batch 260, Loss: 0.9122
Batch 270, Loss: 0.8881
Batch 280, Loss: 0.8829
Batch 290, Loss: 0.8514
Batch 300, Loss: 0.9367
Batch 310, Loss: 0.8656
Batch 320, Loss: 0.8958
Batch 330, Loss: 0.8653
Batch 340, Loss: 0.8957
Batch 350, Loss: 0.8874
Batch 360, Loss: 0.8497
Batch 370, Loss: 0.9560
Batch 380, Loss: 0.8624
Batch 390, Loss: 0.9174
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.254387855529785 seconds
Epoch 125 accuracy: 70.4%
Batch 10, Loss: 0.8292
Batch 20, Loss: 0.8722
Batch 30, Loss: 0.8067
Batch 40, Loss: 0.8752
Batch 50, Loss: 0.8026
Batch 60, Loss: 0.8481
Batch 70, Loss: 0.8159
Batch 80, Loss: 0.8242
Batch 90, Loss: 0.8706
Batch 100, Loss: 0.8205
Batch 110, Loss: 0.8501
Batch 120, Loss: 0.8554
Batch 130, Loss: 0.8737
Batch 140, Loss: 0.8981
Batch 150, Loss: 0.8548
Batch 160, Loss: 0.8404
Batch 170, Loss: 0.8835
Batch 180, Loss: 0.8986
Batch 190, Loss: 0.8460
Batch 200, Loss: 0.9098
Batch 210, Loss: 0.8895
Batch 220, Loss: 0.9242
Batch 230, Loss: 0.8722
Batch 240, Loss: 0.8431
Batch 250, Loss: 0.9190
Batch 260, Loss: 0.9369
Batch 270, Loss: 0.9568
Batch 280, Loss: 0.8675
Batch 290, Loss: 0.8435
Batch 300, Loss: 0.8947
Batch 310, Loss: 0.8904
Batch 320, Loss: 0.9142
Batch 330, Loss: 0.8947
Batch 340, Loss: 0.8915
Batch 350, Loss: 0.8815
Batch 360, Loss: 0.8911
Batch 370, Loss: 0.8848
Batch 380, Loss: 0.9415
Batch 390, Loss: 0.9234
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.2636559009552 seconds
Epoch 126 accuracy: 71.92%
Batch 10, Loss: 0.7996
Batch 20, Loss: 0.8106
Batch 30, Loss: 0.8329
Batch 40, Loss: 0.7754
Batch 50, Loss: 0.7967
Batch 60, Loss: 0.8248
Batch 70, Loss: 0.8082
Batch 80, Loss: 0.8581
Batch 90, Loss: 0.8299
Batch 100, Loss: 0.9222
Batch 110, Loss: 0.7887
Batch 120, Loss: 0.8372
Batch 130, Loss: 0.8253
Batch 140, Loss: 0.8418
Batch 150, Loss: 0.8825
Batch 160, Loss: 0.8254
Batch 170, Loss: 0.8567
Batch 180, Loss: 0.8288
Batch 190, Loss: 0.8694
Batch 200, Loss: 0.8803
Batch 210, Loss: 0.8512
Batch 220, Loss: 0.8612
Batch 230, Loss: 0.8556
Batch 240, Loss: 0.8723
Batch 250, Loss: 0.8025
Batch 260, Loss: 0.9401
Batch 270, Loss: 0.8473
Batch 280, Loss: 0.9274
Batch 290, Loss: 0.8925
Batch 300, Loss: 0.9113
Batch 310, Loss: 0.8532
Batch 320, Loss: 0.8980
Batch 330, Loss: 0.8971
Batch 340, Loss: 0.8643
Batch 350, Loss: 0.8575
Batch 360, Loss: 0.9282
Batch 370, Loss: 0.8418
Batch 380, Loss: 0.8854
Batch 390, Loss: 0.8560
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.268540143966675 seconds
Epoch 127 accuracy: 70.69%
Batch 10, Loss: 0.7902
Batch 20, Loss: 0.8439
Batch 30, Loss: 0.8425
Batch 40, Loss: 0.8159
Batch 50, Loss: 0.7826
Batch 60, Loss: 0.8313
Batch 70, Loss: 0.8126
Batch 80, Loss: 0.8553
Batch 90, Loss: 0.8213
Batch 100, Loss: 0.8304
Batch 110, Loss: 0.8421
Batch 120, Loss: 0.7908
Batch 130, Loss: 0.8105
Batch 140, Loss: 0.8574
Batch 150, Loss: 0.8762
Batch 160, Loss: 0.8162
Batch 170, Loss: 0.8191
Batch 180, Loss: 0.8212
Batch 190, Loss: 0.8314
Batch 200, Loss: 0.8517
Batch 210, Loss: 0.8147
Batch 220, Loss: 0.8724
Batch 230, Loss: 0.8493
Batch 240, Loss: 0.8772
Batch 250, Loss: 0.8664
Batch 260, Loss: 0.8954
Batch 270, Loss: 0.8644
Batch 280, Loss: 0.8591
Batch 290, Loss: 0.8892
Batch 300, Loss: 0.9219
Batch 310, Loss: 0.8840
Batch 320, Loss: 0.9010
Batch 330, Loss: 0.8896
Batch 340, Loss: 0.8922
Batch 350, Loss: 0.8618
Batch 360, Loss: 0.9437
Batch 370, Loss: 0.8804
Batch 380, Loss: 0.8535
Batch 390, Loss: 0.8761
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.385207653045654 seconds
Epoch 128 accuracy: 70.62%
Batch 10, Loss: 0.7977
Batch 20, Loss: 0.7937
Batch 30, Loss: 0.8508
Batch 40, Loss: 0.8131
Batch 50, Loss: 0.7977
Batch 60, Loss: 0.7927
Batch 70, Loss: 0.7749
Batch 80, Loss: 0.8148
Batch 90, Loss: 0.8614
Batch 100, Loss: 0.7821
Batch 110, Loss: 0.8352
Batch 120, Loss: 0.8134
Batch 130, Loss: 0.8330
Batch 140, Loss: 0.8040
Batch 150, Loss: 0.8100
Batch 160, Loss: 0.8524
Batch 170, Loss: 0.8486
Batch 180, Loss: 0.8736
Batch 190, Loss: 0.8174
Batch 200, Loss: 0.8612
Batch 210, Loss: 0.8670
Batch 220, Loss: 0.8529
Batch 230, Loss: 0.8409
Batch 240, Loss: 0.8752
Batch 250, Loss: 0.8238
Batch 260, Loss: 0.8579
Batch 270, Loss: 0.8677
Batch 280, Loss: 0.8689
Batch 290, Loss: 0.8966
Batch 300, Loss: 0.9043
Batch 310, Loss: 0.8440
Batch 320, Loss: 0.8171
Batch 330, Loss: 0.8431
Batch 340, Loss: 0.8715
Batch 350, Loss: 0.8400
Batch 360, Loss: 0.8397
Batch 370, Loss: 0.8831
Batch 380, Loss: 0.8699
Batch 390, Loss: 0.8797
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.230727910995483 seconds
Epoch 129 accuracy: 70.37%
Batch 10, Loss: 0.8203
Batch 20, Loss: 0.7663
Batch 30, Loss: 0.8570
Batch 40, Loss: 0.7928
Batch 50, Loss: 0.7249
Batch 60, Loss: 0.8338
Batch 70, Loss: 0.7676
Batch 80, Loss: 0.7666
Batch 90, Loss: 0.8300
Batch 100, Loss: 0.7707
Batch 110, Loss: 0.7312
Batch 120, Loss: 0.8093
Batch 130, Loss: 0.8423
Batch 140, Loss: 0.8155
Batch 150, Loss: 0.8207
Batch 160, Loss: 0.7929
Batch 170, Loss: 0.8407
Batch 180, Loss: 0.8202
Batch 190, Loss: 0.8240
Batch 200, Loss: 0.8133
Batch 210, Loss: 0.8595
Batch 220, Loss: 0.8051
Batch 230, Loss: 0.7976
Batch 240, Loss: 0.7891
Batch 250, Loss: 0.7983
Batch 260, Loss: 0.8114
Batch 270, Loss: 0.8173
Batch 280, Loss: 0.8585
Batch 290, Loss: 0.8785
Batch 300, Loss: 0.8354
Batch 310, Loss: 0.9082
Batch 320, Loss: 0.8573
Batch 330, Loss: 0.8303
Batch 340, Loss: 0.8661
Batch 350, Loss: 0.8557
Batch 360, Loss: 0.8939
Batch 370, Loss: 0.8752
Batch 380, Loss: 0.8474
Batch 390, Loss: 0.8828
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.298259258270264 seconds
Epoch 130 accuracy: 70.76%
Batch 10, Loss: 0.8174
Batch 20, Loss: 0.8093
Batch 30, Loss: 0.8077
Batch 40, Loss: 0.7669
Batch 50, Loss: 0.7509
Batch 60, Loss: 0.7941
Batch 70, Loss: 0.8168
Batch 80, Loss: 0.7477
Batch 90, Loss: 0.7918
Batch 100, Loss: 0.7904
Batch 110, Loss: 0.7862
Batch 120, Loss: 0.7770
Batch 130, Loss: 0.8049
Batch 140, Loss: 0.7853
Batch 150, Loss: 0.7729
Batch 160, Loss: 0.7895
Batch 170, Loss: 0.7792
Batch 180, Loss: 0.8294
Batch 190, Loss: 0.8051
Batch 200, Loss: 0.7877
Batch 210, Loss: 0.7637
Batch 220, Loss: 0.7919
Batch 230, Loss: 0.8085
Batch 240, Loss: 0.8227
Batch 250, Loss: 0.8093
Batch 260, Loss: 0.8028
Batch 270, Loss: 0.8024
Batch 280, Loss: 0.8072
Batch 290, Loss: 0.8548
Batch 300, Loss: 0.8611
Batch 310, Loss: 0.7784
Batch 320, Loss: 0.8650
Batch 330, Loss: 0.8561
Batch 340, Loss: 0.8622
Batch 350, Loss: 0.8699
Batch 360, Loss: 0.8704
Batch 370, Loss: 0.8383
Batch 380, Loss: 0.8671
Batch 390, Loss: 0.8634
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.24463200569153 seconds
Epoch 131 accuracy: 71.62%
Batch 10, Loss: 0.7699
Batch 20, Loss: 0.7581
Batch 30, Loss: 0.7976
Batch 40, Loss: 0.8337
Batch 50, Loss: 0.7989
Batch 60, Loss: 0.7824
Batch 70, Loss: 0.8232
Batch 80, Loss: 0.7852
Batch 90, Loss: 0.7891
Batch 100, Loss: 0.7470
Batch 110, Loss: 0.7867
Batch 120, Loss: 0.7790
Batch 130, Loss: 0.7968
Batch 140, Loss: 0.7592
Batch 150, Loss: 0.8007
Batch 160, Loss: 0.7661
Batch 170, Loss: 0.8344
Batch 180, Loss: 0.8013
Batch 190, Loss: 0.7526
Batch 200, Loss: 0.8230
Batch 210, Loss: 0.7729
Batch 220, Loss: 0.8067
Batch 230, Loss: 0.7973
Batch 240, Loss: 0.8005
Batch 250, Loss: 0.8350
Batch 260, Loss: 0.8272
Batch 270, Loss: 0.7732
Batch 280, Loss: 0.8445
Batch 290, Loss: 0.8300
Batch 300, Loss: 0.8329
Batch 310, Loss: 0.8307
Batch 320, Loss: 0.8826
Batch 330, Loss: 0.8195
Batch 340, Loss: 0.8221
Batch 350, Loss: 0.7979
Batch 360, Loss: 0.7911
Batch 370, Loss: 0.7922
Batch 380, Loss: 0.8000
Batch 390, Loss: 0.8083
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.297133445739746 seconds
Epoch 132 accuracy: 70.71%
Batch 10, Loss: 0.7360
Batch 20, Loss: 0.7525
Batch 30, Loss: 0.7518
Batch 40, Loss: 0.7345
Batch 50, Loss: 0.7448
Batch 60, Loss: 0.7739
Batch 70, Loss: 0.8106
Batch 80, Loss: 0.7525
Batch 90, Loss: 0.7296
Batch 100, Loss: 0.8108
Batch 110, Loss: 0.7209
Batch 120, Loss: 0.7626
Batch 130, Loss: 0.7852
Batch 140, Loss: 0.7916
Batch 150, Loss: 0.8185
Batch 160, Loss: 0.7318
Batch 170, Loss: 0.8342
Batch 180, Loss: 0.7343
Batch 190, Loss: 0.8464
Batch 200, Loss: 0.7785
Batch 210, Loss: 0.7612
Batch 220, Loss: 0.7960
Batch 230, Loss: 0.8345
Batch 240, Loss: 0.7411
Batch 250, Loss: 0.8557
Batch 260, Loss: 0.7999
Batch 270, Loss: 0.7816
Batch 280, Loss: 0.8040
Batch 290, Loss: 0.7676
Batch 300, Loss: 0.7688
Batch 310, Loss: 0.7814
Batch 320, Loss: 0.8641
Batch 330, Loss: 0.8254
Batch 340, Loss: 0.7537
Batch 350, Loss: 0.8208
Batch 360, Loss: 0.8492
Batch 370, Loss: 0.8117
Batch 380, Loss: 0.8080
Batch 390, Loss: 0.7674
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.341975927352905 seconds
Epoch 133 accuracy: 71.37%
Batch 10, Loss: 0.7484
Batch 20, Loss: 0.7446
Batch 30, Loss: 0.7749
Batch 40, Loss: 0.7277
Batch 50, Loss: 0.7726
Batch 60, Loss: 0.7373
Batch 70, Loss: 0.7323
Batch 80, Loss: 0.7804
Batch 90, Loss: 0.7404
Batch 100, Loss: 0.7936
Batch 110, Loss: 0.7865
Batch 120, Loss: 0.7750
Batch 130, Loss: 0.7768
Batch 140, Loss: 0.7704
Batch 150, Loss: 0.7858
Batch 160, Loss: 0.7405
Batch 170, Loss: 0.8044
Batch 180, Loss: 0.7448
Batch 190, Loss: 0.7408
Batch 200, Loss: 0.7434
Batch 210, Loss: 0.7517
Batch 220, Loss: 0.8127
Batch 230, Loss: 0.7668
Batch 240, Loss: 0.8116
Batch 250, Loss: 0.7462
Batch 260, Loss: 0.7915
Batch 270, Loss: 0.8136
Batch 280, Loss: 0.8162
Batch 290, Loss: 0.8118
Batch 300, Loss: 0.7708
Batch 310, Loss: 0.8193
Batch 320, Loss: 0.8151
Batch 330, Loss: 0.8120
Batch 340, Loss: 0.7701
Batch 350, Loss: 0.8433
Batch 360, Loss: 0.7948
Batch 370, Loss: 0.7798
Batch 380, Loss: 0.8059
Batch 390, Loss: 0.8264
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.322774171829224 seconds
Epoch 134 accuracy: 71.19%
Batch 10, Loss: 0.7661
Batch 20, Loss: 0.7399
Batch 30, Loss: 0.7489
Batch 40, Loss: 0.7999
Batch 50, Loss: 0.7483
Batch 60, Loss: 0.7765
Batch 70, Loss: 0.7944
Batch 80, Loss: 0.7638
Batch 90, Loss: 0.6515
Batch 100, Loss: 0.7700
Batch 110, Loss: 0.7479
Batch 120, Loss: 0.7223
Batch 130, Loss: 0.7563
Batch 140, Loss: 0.7802
Batch 150, Loss: 0.8539
Batch 160, Loss: 0.7700
Batch 170, Loss: 0.7776
Batch 180, Loss: 0.7371
Batch 190, Loss: 0.7753
Batch 200, Loss: 0.7441
Batch 210, Loss: 0.8006
Batch 220, Loss: 0.7404
Batch 230, Loss: 0.7968
Batch 240, Loss: 0.7907
Batch 250, Loss: 0.7684
Batch 260, Loss: 0.7642
Batch 270, Loss: 0.7507
Batch 280, Loss: 0.7812
Batch 290, Loss: 0.7895
Batch 300, Loss: 0.7576
Batch 310, Loss: 0.8147
Batch 320, Loss: 0.7884
Batch 330, Loss: 0.8541
Batch 340, Loss: 0.8488
Batch 350, Loss: 0.8375
Batch 360, Loss: 0.7602
Batch 370, Loss: 0.7978
Batch 380, Loss: 0.8134
Batch 390, Loss: 0.7723
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.271108150482178 seconds
Epoch 135 accuracy: 71.57%
Batch 10, Loss: 0.6780
Batch 20, Loss: 0.7116
Batch 30, Loss: 0.7074
Batch 40, Loss: 0.7238
Batch 50, Loss: 0.7558
Batch 60, Loss: 0.7171
Batch 70, Loss: 0.7609
Batch 80, Loss: 0.7662
Batch 90, Loss: 0.7672
Batch 100, Loss: 0.7054
Batch 110, Loss: 0.7545
Batch 120, Loss: 0.7580
Batch 130, Loss: 0.7770
Batch 140, Loss: 0.6881
Batch 150, Loss: 0.7473
Batch 160, Loss: 0.7207
Batch 170, Loss: 0.7409
Batch 180, Loss: 0.7648
Batch 190, Loss: 0.7838
Batch 200, Loss: 0.7669
Batch 210, Loss: 0.7765
Batch 220, Loss: 0.7531
Batch 230, Loss: 0.7510
Batch 240, Loss: 0.7416
Batch 250, Loss: 0.7368
Batch 260, Loss: 0.7767
Batch 270, Loss: 0.7895
Batch 280, Loss: 0.7920
Batch 290, Loss: 0.8208
Batch 300, Loss: 0.7881
Batch 310, Loss: 0.7934
Batch 320, Loss: 0.7680
Batch 330, Loss: 0.7892
Batch 340, Loss: 0.7912
Batch 350, Loss: 0.7743
Batch 360, Loss: 0.8028
Batch 370, Loss: 0.7953
Batch 380, Loss: 0.7896
Batch 390, Loss: 0.7694
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.250237941741943 seconds
Epoch 136 accuracy: 72.48%
Batch 10, Loss: 0.7107
Batch 20, Loss: 0.7243
Batch 30, Loss: 0.7223
Batch 40, Loss: 0.6896
Batch 50, Loss: 0.7151
Batch 60, Loss: 0.7027
Batch 70, Loss: 0.7208
Batch 80, Loss: 0.6984
Batch 90, Loss: 0.7455
Batch 100, Loss: 0.7777
Batch 110, Loss: 0.7611
Batch 120, Loss: 0.7317
Batch 130, Loss: 0.7747
Batch 140, Loss: 0.7526
Batch 150, Loss: 0.7565
Batch 160, Loss: 0.7558
Batch 170, Loss: 0.7344
Batch 180, Loss: 0.7897
Batch 190, Loss: 0.7431
Batch 200, Loss: 0.7414
Batch 210, Loss: 0.7303
Batch 220, Loss: 0.7817
Batch 230, Loss: 0.7034
Batch 240, Loss: 0.7263
Batch 250, Loss: 0.7442
Batch 260, Loss: 0.7088
Batch 270, Loss: 0.7705
Batch 280, Loss: 0.8000
Batch 290, Loss: 0.7886
Batch 300, Loss: 0.7638
Batch 310, Loss: 0.7483
Batch 320, Loss: 0.7395
Batch 330, Loss: 0.7522
Batch 340, Loss: 0.7333
Batch 350, Loss: 0.7641
Batch 360, Loss: 0.8317
Batch 370, Loss: 0.7450
Batch 380, Loss: 0.7386
Batch 390, Loss: 0.7613
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.26297616958618 seconds
Epoch 137 accuracy: 71.98%
Batch 10, Loss: 0.6744
Batch 20, Loss: 0.7666
Batch 30, Loss: 0.7163
Batch 40, Loss: 0.6657
Batch 50, Loss: 0.7253
Batch 60, Loss: 0.7117
Batch 70, Loss: 0.6831
Batch 80, Loss: 0.7355
Batch 90, Loss: 0.7228
Batch 100, Loss: 0.7359
Batch 110, Loss: 0.7460
Batch 120, Loss: 0.6925
Batch 130, Loss: 0.6672
Batch 140, Loss: 0.7446
Batch 150, Loss: 0.7434
Batch 160, Loss: 0.6494
Batch 170, Loss: 0.7627
Batch 180, Loss: 0.7194
Batch 190, Loss: 0.7265
Batch 200, Loss: 0.7531
Batch 210, Loss: 0.7258
Batch 220, Loss: 0.7333
Batch 230, Loss: 0.6966
Batch 240, Loss: 0.7605
Batch 250, Loss: 0.7630
Batch 260, Loss: 0.8105
Batch 270, Loss: 0.7932
Batch 280, Loss: 0.7842
Batch 290, Loss: 0.8259
Batch 300, Loss: 0.7571
Batch 310, Loss: 0.7016
Batch 320, Loss: 0.7346
Batch 330, Loss: 0.7227
Batch 340, Loss: 0.7492
Batch 350, Loss: 0.8329
Batch 360, Loss: 0.7296
Batch 370, Loss: 0.7464
Batch 380, Loss: 0.7547
Batch 390, Loss: 0.7947
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.25376033782959 seconds
Epoch 138 accuracy: 71.13%
Batch 10, Loss: 0.6994
Batch 20, Loss: 0.6403
Batch 30, Loss: 0.6422
Batch 40, Loss: 0.7515
Batch 50, Loss: 0.6798
Batch 60, Loss: 0.7102
Batch 70, Loss: 0.7404
Batch 80, Loss: 0.6763
Batch 90, Loss: 0.7198
Batch 100, Loss: 0.7110
Batch 110, Loss: 0.7126
Batch 120, Loss: 0.7078
Batch 130, Loss: 0.7276
Batch 140, Loss: 0.7209
Batch 150, Loss: 0.7268
Batch 160, Loss: 0.6963
Batch 170, Loss: 0.7354
Batch 180, Loss: 0.6916
Batch 190, Loss: 0.7391
Batch 200, Loss: 0.7552
Batch 210, Loss: 0.7355
Batch 220, Loss: 0.6950
Batch 230, Loss: 0.7538
Batch 240, Loss: 0.7298
Batch 250, Loss: 0.7348
Batch 260, Loss: 0.7510
Batch 270, Loss: 0.7244
Batch 280, Loss: 0.7960
Batch 290, Loss: 0.7889
Batch 300, Loss: 0.7454
Batch 310, Loss: 0.7729
Batch 320, Loss: 0.7265
Batch 330, Loss: 0.6651
Batch 340, Loss: 0.7536
Batch 350, Loss: 0.7302
Batch 360, Loss: 0.7771
Batch 370, Loss: 0.7494
Batch 380, Loss: 0.7609
Batch 390, Loss: 0.7575
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.29302215576172 seconds
Epoch 139 accuracy: 71.98%
Batch 10, Loss: 0.7352
Batch 20, Loss: 0.7273
Batch 30, Loss: 0.6770
Batch 40, Loss: 0.6642
Batch 50, Loss: 0.7022
Batch 60, Loss: 0.6987
Batch 70, Loss: 0.7037
Batch 80, Loss: 0.6715
Batch 90, Loss: 0.6786
Batch 100, Loss: 0.6939
Batch 110, Loss: 0.7452
Batch 120, Loss: 0.6981
Batch 130, Loss: 0.7015
Batch 140, Loss: 0.7217
Batch 150, Loss: 0.6881
Batch 160, Loss: 0.7257
Batch 170, Loss: 0.7016
Batch 180, Loss: 0.7193
Batch 190, Loss: 0.6562
Batch 200, Loss: 0.6810
Batch 210, Loss: 0.7086
Batch 220, Loss: 0.7218
Batch 230, Loss: 0.7403
Batch 240, Loss: 0.6893
Batch 250, Loss: 0.7069
Batch 260, Loss: 0.6988
Batch 270, Loss: 0.7351
Batch 280, Loss: 0.7341
Batch 290, Loss: 0.6829
Batch 300, Loss: 0.6692
Batch 310, Loss: 0.7118
Batch 320, Loss: 0.7368
Batch 330, Loss: 0.7463
Batch 340, Loss: 0.7459
Batch 350, Loss: 0.7373
Batch 360, Loss: 0.7183
Batch 370, Loss: 0.7068
Batch 380, Loss: 0.7457
Batch 390, Loss: 0.7088
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.261313438415527 seconds
Epoch 140 accuracy: 73.0%
Batch 10, Loss: 0.6965
Batch 20, Loss: 0.6643
Batch 30, Loss: 0.6431
Batch 40, Loss: 0.6659
Batch 50, Loss: 0.7213
Batch 60, Loss: 0.6372
Batch 70, Loss: 0.7030
Batch 80, Loss: 0.6852
Batch 90, Loss: 0.6881
Batch 100, Loss: 0.6465
Batch 110, Loss: 0.7093
Batch 120, Loss: 0.6956
Batch 130, Loss: 0.6939
Batch 140, Loss: 0.6757
Batch 150, Loss: 0.7214
Batch 160, Loss: 0.6687
Batch 170, Loss: 0.6974
Batch 180, Loss: 0.6897
Batch 190, Loss: 0.7146
Batch 200, Loss: 0.7281
Batch 210, Loss: 0.6766
Batch 220, Loss: 0.6799
Batch 230, Loss: 0.7182
Batch 240, Loss: 0.6868
Batch 250, Loss: 0.7506
Batch 260, Loss: 0.7320
Batch 270, Loss: 0.7577
Batch 280, Loss: 0.7014
Batch 290, Loss: 0.7301
Batch 300, Loss: 0.7213
Batch 310, Loss: 0.7409
Batch 320, Loss: 0.6979
Batch 330, Loss: 0.7920
Batch 340, Loss: 0.6847
Batch 350, Loss: 0.7496
Batch 360, Loss: 0.7360
Batch 370, Loss: 0.7571
Batch 380, Loss: 0.6996
Batch 390, Loss: 0.7678
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.23709273338318 seconds
Epoch 141 accuracy: 73.21%
Batch 10, Loss: 0.6462
Batch 20, Loss: 0.6746
Batch 30, Loss: 0.6832
Batch 40, Loss: 0.6304
Batch 50, Loss: 0.6691
Batch 60, Loss: 0.6718
Batch 70, Loss: 0.6757
Batch 80, Loss: 0.6668
Batch 90, Loss: 0.6264
Batch 100, Loss: 0.6594
Batch 110, Loss: 0.6955
Batch 120, Loss: 0.6872
Batch 130, Loss: 0.7257
Batch 140, Loss: 0.7139
Batch 150, Loss: 0.7486
Batch 160, Loss: 0.6438
Batch 170, Loss: 0.6829
Batch 180, Loss: 0.6520
Batch 190, Loss: 0.7224
Batch 200, Loss: 0.6501
Batch 210, Loss: 0.6646
Batch 220, Loss: 0.7232
Batch 230, Loss: 0.6572
Batch 240, Loss: 0.7196
Batch 250, Loss: 0.6781
Batch 260, Loss: 0.7440
Batch 270, Loss: 0.7023
Batch 280, Loss: 0.7154
Batch 290, Loss: 0.6729
Batch 300, Loss: 0.7812
Batch 310, Loss: 0.7094
Batch 320, Loss: 0.7246
Batch 330, Loss: 0.6547
Batch 340, Loss: 0.6504
Batch 350, Loss: 0.7165
Batch 360, Loss: 0.7416
Batch 370, Loss: 0.6818
Batch 380, Loss: 0.6813
Batch 390, Loss: 0.7197
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.24174165725708 seconds
Epoch 142 accuracy: 71.99%
Batch 10, Loss: 0.6709
Batch 20, Loss: 0.6240
Batch 30, Loss: 0.6413
Batch 40, Loss: 0.6474
Batch 50, Loss: 0.6800
Batch 60, Loss: 0.6296
Batch 70, Loss: 0.6611
Batch 80, Loss: 0.6198
Batch 90, Loss: 0.6902
Batch 100, Loss: 0.6739
Batch 110, Loss: 0.7172
Batch 120, Loss: 0.6741
Batch 130, Loss: 0.6723
Batch 140, Loss: 0.7348
Batch 150, Loss: 0.6781
Batch 160, Loss: 0.6681
Batch 170, Loss: 0.6678
Batch 180, Loss: 0.7206
Batch 190, Loss: 0.6634
Batch 200, Loss: 0.7157
Batch 210, Loss: 0.7163
Batch 220, Loss: 0.6692
Batch 230, Loss: 0.6808
Batch 240, Loss: 0.6613
Batch 250, Loss: 0.7024
Batch 260, Loss: 0.7131
Batch 270, Loss: 0.7160
Batch 280, Loss: 0.6969
Batch 290, Loss: 0.7229
Batch 300, Loss: 0.6903
Batch 310, Loss: 0.6837
Batch 320, Loss: 0.6928
Batch 330, Loss: 0.6843
Batch 340, Loss: 0.7389
Batch 350, Loss: 0.7258
Batch 360, Loss: 0.6701
Batch 370, Loss: 0.7083
Batch 380, Loss: 0.7496
Batch 390, Loss: 0.7114
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.32875394821167 seconds
Epoch 143 accuracy: 73.64%
Batch 10, Loss: 0.6558
Batch 20, Loss: 0.6618
Batch 30, Loss: 0.6323
Batch 40, Loss: 0.6356
Batch 50, Loss: 0.6405
Batch 60, Loss: 0.6685
Batch 70, Loss: 0.6343
Batch 80, Loss: 0.6327
Batch 90, Loss: 0.6813
Batch 100, Loss: 0.6375
Batch 110, Loss: 0.6261
Batch 120, Loss: 0.6542
Batch 130, Loss: 0.6408
Batch 140, Loss: 0.6249
Batch 150, Loss: 0.6275
Batch 160, Loss: 0.6430
Batch 170, Loss: 0.6388
Batch 180, Loss: 0.7020
Batch 190, Loss: 0.6297
Batch 200, Loss: 0.6804
Batch 210, Loss: 0.6865
Batch 220, Loss: 0.6954
Batch 230, Loss: 0.6802
Batch 240, Loss: 0.6963
Batch 250, Loss: 0.7143
Batch 260, Loss: 0.6832
Batch 270, Loss: 0.6851
Batch 280, Loss: 0.6607
Batch 290, Loss: 0.6460
Batch 300, Loss: 0.6896
Batch 310, Loss: 0.7092
Batch 320, Loss: 0.7251
Batch 330, Loss: 0.7330
Batch 340, Loss: 0.6945
Batch 350, Loss: 0.7067
Batch 360, Loss: 0.6253
Batch 370, Loss: 0.7349
Batch 380, Loss: 0.6707
Batch 390, Loss: 0.6956
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.32988953590393 seconds
Epoch 144 accuracy: 73.4%
Batch 10, Loss: 0.6239
Batch 20, Loss: 0.6514
Batch 30, Loss: 0.6744
Batch 40, Loss: 0.6569
Batch 50, Loss: 0.6541
Batch 60, Loss: 0.6532
Batch 70, Loss: 0.6458
Batch 80, Loss: 0.6215
Batch 90, Loss: 0.6100
Batch 100, Loss: 0.6577
Batch 110, Loss: 0.6584
Batch 120, Loss: 0.6365
Batch 130, Loss: 0.6680
Batch 140, Loss: 0.6786
Batch 150, Loss: 0.6427
Batch 160, Loss: 0.6426
Batch 170, Loss: 0.6418
Batch 180, Loss: 0.6416
Batch 190, Loss: 0.6052
Batch 200, Loss: 0.6819
Batch 210, Loss: 0.6388
Batch 220, Loss: 0.6441
Batch 230, Loss: 0.7065
Batch 240, Loss: 0.6458
Batch 250, Loss: 0.6566
Batch 260, Loss: 0.6873
Batch 270, Loss: 0.6971
Batch 280, Loss: 0.6910
Batch 290, Loss: 0.6516
Batch 300, Loss: 0.6574
Batch 310, Loss: 0.6139
Batch 320, Loss: 0.6389
Batch 330, Loss: 0.6836
Batch 340, Loss: 0.6865
Batch 350, Loss: 0.6463
Batch 360, Loss: 0.6680
Batch 370, Loss: 0.7201
Batch 380, Loss: 0.6351
Batch 390, Loss: 0.6699
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.312190532684326 seconds
Epoch 145 accuracy: 73.87%
Batch 10, Loss: 0.6002
Batch 20, Loss: 0.6046
Batch 30, Loss: 0.6073
Batch 40, Loss: 0.6512
Batch 50, Loss: 0.5940
Batch 60, Loss: 0.6400
Batch 70, Loss: 0.6697
Batch 80, Loss: 0.6463
Batch 90, Loss: 0.6493
Batch 100, Loss: 0.6529
Batch 110, Loss: 0.6339
Batch 120, Loss: 0.6580
Batch 130, Loss: 0.6279
Batch 140, Loss: 0.6473
Batch 150, Loss: 0.6157
Batch 160, Loss: 0.6273
Batch 170, Loss: 0.6291
Batch 180, Loss: 0.6344
Batch 190, Loss: 0.5951
Batch 200, Loss: 0.6472
Batch 210, Loss: 0.6226
Batch 220, Loss: 0.6351
Batch 230, Loss: 0.6492
Batch 240, Loss: 0.6496
Batch 250, Loss: 0.6084
Batch 260, Loss: 0.6337
Batch 270, Loss: 0.6497
Batch 280, Loss: 0.6906
Batch 290, Loss: 0.6625
Batch 300, Loss: 0.6296
Batch 310, Loss: 0.6620
Batch 320, Loss: 0.6277
Batch 330, Loss: 0.6095
Batch 340, Loss: 0.6477
Batch 350, Loss: 0.6517
Batch 360, Loss: 0.7140
Batch 370, Loss: 0.6925
Batch 380, Loss: 0.7015
Batch 390, Loss: 0.7164
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.326822519302368 seconds
Epoch 146 accuracy: 72.97%
Batch 10, Loss: 0.6025
Batch 20, Loss: 0.6663
Batch 30, Loss: 0.5707
Batch 40, Loss: 0.6003
Batch 50, Loss: 0.6648
Batch 60, Loss: 0.6100
Batch 70, Loss: 0.6244
Batch 80, Loss: 0.5905
Batch 90, Loss: 0.6379
Batch 100, Loss: 0.6208
Batch 110, Loss: 0.6644
Batch 120, Loss: 0.6304
Batch 130, Loss: 0.5844
Batch 140, Loss: 0.6288
Batch 150, Loss: 0.5778
Batch 160, Loss: 0.6334
Batch 170, Loss: 0.6207
Batch 180, Loss: 0.6488
Batch 190, Loss: 0.6114
Batch 200, Loss: 0.6144
Batch 210, Loss: 0.6397
Batch 220, Loss: 0.6289
Batch 230, Loss: 0.6562
Batch 240, Loss: 0.6219
Batch 250, Loss: 0.6154
Batch 260, Loss: 0.6513
Batch 270, Loss: 0.6330
Batch 280, Loss: 0.6055
Batch 290, Loss: 0.6576
Batch 300, Loss: 0.6508
Batch 310, Loss: 0.6689
Batch 320, Loss: 0.6772
Batch 330, Loss: 0.6482
Batch 340, Loss: 0.6178
Batch 350, Loss: 0.6448
Batch 360, Loss: 0.6944
Batch 370, Loss: 0.6304
Batch 380, Loss: 0.6003
Batch 390, Loss: 0.6665
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.305388927459717 seconds
Epoch 147 accuracy: 74.43%
Batch 10, Loss: 0.6246
Batch 20, Loss: 0.6315
Batch 30, Loss: 0.6136
Batch 40, Loss: 0.6141
Batch 50, Loss: 0.6207
Batch 60, Loss: 0.6123
Batch 70, Loss: 0.5914
Batch 80, Loss: 0.6045
Batch 90, Loss: 0.5385
Batch 100, Loss: 0.6233
Batch 110, Loss: 0.6181
Batch 120, Loss: 0.6313
Batch 130, Loss: 0.6261
Batch 140, Loss: 0.5957
Batch 150, Loss: 0.6079
Batch 160, Loss: 0.6180
Batch 170, Loss: 0.6394
Batch 180, Loss: 0.6359
Batch 190, Loss: 0.6389
Batch 200, Loss: 0.6079
Batch 210, Loss: 0.6211
Batch 220, Loss: 0.6090
Batch 230, Loss: 0.6103
Batch 240, Loss: 0.5693
Batch 250, Loss: 0.5883
Batch 260, Loss: 0.6025
Batch 270, Loss: 0.6469
Batch 280, Loss: 0.5935
Batch 290, Loss: 0.6412
Batch 300, Loss: 0.6379
Batch 310, Loss: 0.6279
Batch 320, Loss: 0.6412
Batch 330, Loss: 0.6275
Batch 340, Loss: 0.6541
Batch 350, Loss: 0.6371
Batch 360, Loss: 0.6945
Batch 370, Loss: 0.6307
Batch 380, Loss: 0.6788
Batch 390, Loss: 0.6888
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.301204919815063 seconds
Epoch 148 accuracy: 73.91%
Batch 10, Loss: 0.5962
Batch 20, Loss: 0.6080
Batch 30, Loss: 0.5637
Batch 40, Loss: 0.5801
Batch 50, Loss: 0.5838
Batch 60, Loss: 0.5667
Batch 70, Loss: 0.6430
Batch 80, Loss: 0.5838
Batch 90, Loss: 0.5931
Batch 100, Loss: 0.5632
Batch 110, Loss: 0.5945
Batch 120, Loss: 0.6285
Batch 130, Loss: 0.6512
Batch 140, Loss: 0.5599
Batch 150, Loss: 0.5680
Batch 160, Loss: 0.5915
Batch 170, Loss: 0.6347
Batch 180, Loss: 0.6324
Batch 190, Loss: 0.6102
Batch 200, Loss: 0.6323
Batch 210, Loss: 0.5908
Batch 220, Loss: 0.6014
Batch 230, Loss: 0.6267
Batch 240, Loss: 0.5855
Batch 250, Loss: 0.6285
Batch 260, Loss: 0.6060
Batch 270, Loss: 0.6442
Batch 280, Loss: 0.5972
Batch 290, Loss: 0.6110
Batch 300, Loss: 0.6190
Batch 310, Loss: 0.6373
Batch 320, Loss: 0.6690
Batch 330, Loss: 0.6223
Batch 340, Loss: 0.5487
Batch 350, Loss: 0.5971
Batch 360, Loss: 0.6152
Batch 370, Loss: 0.6108
Batch 380, Loss: 0.6228
Batch 390, Loss: 0.6112
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.2685387134552 seconds
Epoch 149 accuracy: 74.2%
Batch 10, Loss: 0.6134
Batch 20, Loss: 0.5799
Batch 30, Loss: 0.5662
Batch 40, Loss: 0.5610
Batch 50, Loss: 0.6188
Batch 60, Loss: 0.5591
Batch 70, Loss: 0.5680
Batch 80, Loss: 0.5111
Batch 90, Loss: 0.5723
Batch 100, Loss: 0.5536
Batch 110, Loss: 0.5743
Batch 120, Loss: 0.5826
Batch 130, Loss: 0.5777
Batch 140, Loss: 0.5854
Batch 150, Loss: 0.5438
Batch 160, Loss: 0.6106
Batch 170, Loss: 0.6000
Batch 180, Loss: 0.5951
Batch 190, Loss: 0.5838
Batch 200, Loss: 0.6209
Batch 210, Loss: 0.6323
Batch 220, Loss: 0.5791
Batch 230, Loss: 0.6074
Batch 240, Loss: 0.6242
Batch 250, Loss: 0.5803
Batch 260, Loss: 0.5888
Batch 270, Loss: 0.6226
Batch 280, Loss: 0.5615
Batch 290, Loss: 0.5723
Batch 300, Loss: 0.6104
Batch 310, Loss: 0.6137
Batch 320, Loss: 0.5842
Batch 330, Loss: 0.6053
Batch 340, Loss: 0.6295
Batch 350, Loss: 0.5872
Batch 360, Loss: 0.6085
Batch 370, Loss: 0.5834
Batch 380, Loss: 0.6269
Batch 390, Loss: 0.6171
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.194350242614746 seconds
Epoch 150 accuracy: 74.33%
Batch 10, Loss: 0.5516
Batch 20, Loss: 0.5578
Batch 30, Loss: 0.5863
Batch 40, Loss: 0.6073
Batch 50, Loss: 0.5803
Batch 60, Loss: 0.5950
Batch 70, Loss: 0.6035
Batch 80, Loss: 0.5857
Batch 90, Loss: 0.6279
Batch 100, Loss: 0.5699
Batch 110, Loss: 0.5638
Batch 120, Loss: 0.5809
Batch 130, Loss: 0.5629
Batch 140, Loss: 0.5462
Batch 150, Loss: 0.6078
Batch 160, Loss: 0.5813
Batch 170, Loss: 0.5928
Batch 180, Loss: 0.5902
Batch 190, Loss: 0.6019
Batch 200, Loss: 0.5598
Batch 210, Loss: 0.5473
Batch 220, Loss: 0.5789
Batch 230, Loss: 0.5568
Batch 240, Loss: 0.5810
Batch 250, Loss: 0.5811
Batch 260, Loss: 0.5818
Batch 270, Loss: 0.5735
Batch 280, Loss: 0.6121
Batch 290, Loss: 0.6385
Batch 300, Loss: 0.5759
Batch 310, Loss: 0.6171
Batch 320, Loss: 0.5784
Batch 330, Loss: 0.6125
Batch 340, Loss: 0.5961
Batch 350, Loss: 0.5868
Batch 360, Loss: 0.6487
Batch 370, Loss: 0.5882
Batch 380, Loss: 0.5511
Batch 390, Loss: 0.5673
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.32597064971924 seconds
Epoch 151 accuracy: 75.34%
Batch 10, Loss: 0.5964
Batch 20, Loss: 0.5476
Batch 30, Loss: 0.5663
Batch 40, Loss: 0.5319
Batch 50, Loss: 0.5573
Batch 60, Loss: 0.5877
Batch 70, Loss: 0.5532
Batch 80, Loss: 0.4874
Batch 90, Loss: 0.5926
Batch 100, Loss: 0.6205
Batch 110, Loss: 0.5519
Batch 120, Loss: 0.5797
Batch 130, Loss: 0.5675
Batch 140, Loss: 0.5621
Batch 150, Loss: 0.5624
Batch 160, Loss: 0.5337
Batch 170, Loss: 0.5817
Batch 180, Loss: 0.5371
Batch 190, Loss: 0.5673
Batch 200, Loss: 0.6190
Batch 210, Loss: 0.5982
Batch 220, Loss: 0.5671
Batch 230, Loss: 0.5832
Batch 240, Loss: 0.5971
Batch 250, Loss: 0.5814
Batch 260, Loss: 0.6133
Batch 270, Loss: 0.5858
Batch 280, Loss: 0.5333
Batch 290, Loss: 0.5931
Batch 300, Loss: 0.6128
Batch 310, Loss: 0.5541
Batch 320, Loss: 0.6170
Batch 330, Loss: 0.5429
Batch 340, Loss: 0.6223
Batch 350, Loss: 0.6001
Batch 360, Loss: 0.5611
Batch 370, Loss: 0.5978
Batch 380, Loss: 0.6303
Batch 390, Loss: 0.6030
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.280252695083618 seconds
Epoch 152 accuracy: 74.3%
Batch 10, Loss: 0.5449
Batch 20, Loss: 0.5246
Batch 30, Loss: 0.5212
Batch 40, Loss: 0.5214
Batch 50, Loss: 0.5124
Batch 60, Loss: 0.5322
Batch 70, Loss: 0.5728
Batch 80, Loss: 0.5242
Batch 90, Loss: 0.5727
Batch 100, Loss: 0.5235
Batch 110, Loss: 0.5294
Batch 120, Loss: 0.5574
Batch 130, Loss: 0.5859
Batch 140, Loss: 0.5573
Batch 150, Loss: 0.5843
Batch 160, Loss: 0.5443
Batch 170, Loss: 0.5412
Batch 180, Loss: 0.5618
Batch 190, Loss: 0.5765
Batch 200, Loss: 0.5459
Batch 210, Loss: 0.5455
Batch 220, Loss: 0.5565
Batch 230, Loss: 0.5279
Batch 240, Loss: 0.5640
Batch 250, Loss: 0.5600
Batch 260, Loss: 0.5307
Batch 270, Loss: 0.5357
Batch 280, Loss: 0.6076
Batch 290, Loss: 0.5986
Batch 300, Loss: 0.5782
Batch 310, Loss: 0.6075
Batch 320, Loss: 0.5267
Batch 330, Loss: 0.6131
Batch 340, Loss: 0.5436
Batch 350, Loss: 0.5266
Batch 360, Loss: 0.5656
Batch 370, Loss: 0.6323
Batch 380, Loss: 0.5941
Batch 390, Loss: 0.6072
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.252655267715454 seconds
Epoch 153 accuracy: 73.56%
Batch 10, Loss: 0.5724
Batch 20, Loss: 0.5606
Batch 30, Loss: 0.5287
Batch 40, Loss: 0.5384
Batch 50, Loss: 0.5599
Batch 60, Loss: 0.5440
Batch 70, Loss: 0.5115
Batch 80, Loss: 0.5284
Batch 90, Loss: 0.5224
Batch 100, Loss: 0.5041
Batch 110, Loss: 0.5220
Batch 120, Loss: 0.5330
Batch 130, Loss: 0.5518
Batch 140, Loss: 0.5247
Batch 150, Loss: 0.5279
Batch 160, Loss: 0.5589
Batch 170, Loss: 0.5991
Batch 180, Loss: 0.5346
Batch 190, Loss: 0.5348
Batch 200, Loss: 0.5309
Batch 210, Loss: 0.5693
Batch 220, Loss: 0.5434
Batch 230, Loss: 0.5382
Batch 240, Loss: 0.5448
Batch 250, Loss: 0.5871
Batch 260, Loss: 0.5456
Batch 270, Loss: 0.5716
Batch 280, Loss: 0.5574
Batch 290, Loss: 0.5735
Batch 300, Loss: 0.5534
Batch 310, Loss: 0.5848
Batch 320, Loss: 0.5587
Batch 330, Loss: 0.5343
Batch 340, Loss: 0.5469
Batch 350, Loss: 0.5986
Batch 360, Loss: 0.5331
Batch 370, Loss: 0.6079
Batch 380, Loss: 0.5693
Batch 390, Loss: 0.5927
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.324233531951904 seconds
Epoch 154 accuracy: 74.8%
Batch 10, Loss: 0.4876
Batch 20, Loss: 0.5202
Batch 30, Loss: 0.5399
Batch 40, Loss: 0.5136
Batch 50, Loss: 0.5207
Batch 60, Loss: 0.5132
Batch 70, Loss: 0.5339
Batch 80, Loss: 0.5140
Batch 90, Loss: 0.5469
Batch 100, Loss: 0.5063
Batch 110, Loss: 0.4891
Batch 120, Loss: 0.5363
Batch 130, Loss: 0.5547
Batch 140, Loss: 0.5363
Batch 150, Loss: 0.5339
Batch 160, Loss: 0.5211
Batch 170, Loss: 0.5302
Batch 180, Loss: 0.5317
Batch 190, Loss: 0.5464
Batch 200, Loss: 0.5046
Batch 210, Loss: 0.5527
Batch 220, Loss: 0.5657
Batch 230, Loss: 0.5287
Batch 240, Loss: 0.5294
Batch 250, Loss: 0.5459
Batch 260, Loss: 0.5510
Batch 270, Loss: 0.5457
Batch 280, Loss: 0.5605
Batch 290, Loss: 0.5389
Batch 300, Loss: 0.5739
Batch 310, Loss: 0.5599
Batch 320, Loss: 0.5490
Batch 330, Loss: 0.5496
Batch 340, Loss: 0.5611
Batch 350, Loss: 0.5914
Batch 360, Loss: 0.5453
Batch 370, Loss: 0.5063
Batch 380, Loss: 0.5239
Batch 390, Loss: 0.5369
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.3327054977417 seconds
Epoch 155 accuracy: 74.47%
Batch 10, Loss: 0.4764
Batch 20, Loss: 0.4920
Batch 30, Loss: 0.5068
Batch 40, Loss: 0.4745
Batch 50, Loss: 0.5440
Batch 60, Loss: 0.5093
Batch 70, Loss: 0.5034
Batch 80, Loss: 0.4891
Batch 90, Loss: 0.5201
Batch 100, Loss: 0.5266
Batch 110, Loss: 0.5191
Batch 120, Loss: 0.5343
Batch 130, Loss: 0.5334
Batch 140, Loss: 0.4851
Batch 150, Loss: 0.4970
Batch 160, Loss: 0.5146
Batch 170, Loss: 0.5003
Batch 180, Loss: 0.5518
Batch 190, Loss: 0.5177
Batch 200, Loss: 0.5148
Batch 210, Loss: 0.5001
Batch 220, Loss: 0.5407
Batch 230, Loss: 0.5415
Batch 240, Loss: 0.5121
Batch 250, Loss: 0.5520
Batch 260, Loss: 0.6216
Batch 270, Loss: 0.5116
Batch 280, Loss: 0.5148
Batch 290, Loss: 0.5197
Batch 300, Loss: 0.4955
Batch 310, Loss: 0.5736
Batch 320, Loss: 0.4956
Batch 330, Loss: 0.5419
Batch 340, Loss: 0.5300
Batch 350, Loss: 0.5220
Batch 360, Loss: 0.5404
Batch 370, Loss: 0.4876
Batch 380, Loss: 0.5278
Batch 390, Loss: 0.5606
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.30513572692871 seconds
Epoch 156 accuracy: 75.3%
Batch 10, Loss: 0.4834
Batch 20, Loss: 0.5083
Batch 30, Loss: 0.4677
Batch 40, Loss: 0.4847
Batch 50, Loss: 0.4416
Batch 60, Loss: 0.4853
Batch 70, Loss: 0.5247
Batch 80, Loss: 0.5253
Batch 90, Loss: 0.5101
Batch 100, Loss: 0.5356
Batch 110, Loss: 0.5165
Batch 120, Loss: 0.4808
Batch 130, Loss: 0.4875
Batch 140, Loss: 0.5113
Batch 150, Loss: 0.4908
Batch 160, Loss: 0.4893
Batch 170, Loss: 0.5621
Batch 180, Loss: 0.4763
Batch 190, Loss: 0.5036
Batch 200, Loss: 0.5447
Batch 210, Loss: 0.5089
Batch 220, Loss: 0.4911
Batch 230, Loss: 0.5454
Batch 240, Loss: 0.4914
Batch 250, Loss: 0.4962
Batch 260, Loss: 0.5003
Batch 270, Loss: 0.5562
Batch 280, Loss: 0.5467
Batch 290, Loss: 0.4788
Batch 300, Loss: 0.5521
Batch 310, Loss: 0.5167
Batch 320, Loss: 0.5017
Batch 330, Loss: 0.5174
Batch 340, Loss: 0.5418
Batch 350, Loss: 0.5260
Batch 360, Loss: 0.5129
Batch 370, Loss: 0.5220
Batch 380, Loss: 0.5389
Batch 390, Loss: 0.5149
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.28343939781189 seconds
Epoch 157 accuracy: 75.01%
Batch 10, Loss: 0.4480
Batch 20, Loss: 0.4948
Batch 30, Loss: 0.5185
Batch 40, Loss: 0.5010
Batch 50, Loss: 0.4506
Batch 60, Loss: 0.5442
Batch 70, Loss: 0.5060
Batch 80, Loss: 0.4949
Batch 90, Loss: 0.4732
Batch 100, Loss: 0.5230
Batch 110, Loss: 0.4991
Batch 120, Loss: 0.5136
Batch 130, Loss: 0.5148
Batch 140, Loss: 0.4583
Batch 150, Loss: 0.4792
Batch 160, Loss: 0.4753
Batch 170, Loss: 0.5387
Batch 180, Loss: 0.4972
Batch 190, Loss: 0.5012
Batch 200, Loss: 0.4923
Batch 210, Loss: 0.5040
Batch 220, Loss: 0.5183
Batch 230, Loss: 0.5151
Batch 240, Loss: 0.5053
Batch 250, Loss: 0.4786
Batch 260, Loss: 0.5299
Batch 270, Loss: 0.4857
Batch 280, Loss: 0.5254
Batch 290, Loss: 0.4425
Batch 300, Loss: 0.5108
Batch 310, Loss: 0.4918
Batch 320, Loss: 0.5210
Batch 330, Loss: 0.4761
Batch 340, Loss: 0.5074
Batch 350, Loss: 0.5034
Batch 360, Loss: 0.5109
Batch 370, Loss: 0.5189
Batch 380, Loss: 0.5828
Batch 390, Loss: 0.5307
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.34026551246643 seconds
Epoch 158 accuracy: 75.81%
Batch 10, Loss: 0.4886
Batch 20, Loss: 0.5168
Batch 30, Loss: 0.4355
Batch 40, Loss: 0.4768
Batch 50, Loss: 0.4800
Batch 60, Loss: 0.4898
Batch 70, Loss: 0.4537
Batch 80, Loss: 0.4429
Batch 90, Loss: 0.4505
Batch 100, Loss: 0.4673
Batch 110, Loss: 0.4777
Batch 120, Loss: 0.4726
Batch 130, Loss: 0.4688
Batch 140, Loss: 0.5065
Batch 150, Loss: 0.4812
Batch 160, Loss: 0.5000
Batch 170, Loss: 0.4673
Batch 180, Loss: 0.4691
Batch 190, Loss: 0.4764
Batch 200, Loss: 0.4786
Batch 210, Loss: 0.4591
Batch 220, Loss: 0.4823
Batch 230, Loss: 0.4689
Batch 240, Loss: 0.4781
Batch 250, Loss: 0.4746
Batch 260, Loss: 0.5005
Batch 270, Loss: 0.4731
Batch 280, Loss: 0.5141
Batch 290, Loss: 0.4850
Batch 300, Loss: 0.4946
Batch 310, Loss: 0.4576
Batch 320, Loss: 0.4559
Batch 330, Loss: 0.5132
Batch 340, Loss: 0.5351
Batch 350, Loss: 0.4894
Batch 360, Loss: 0.5198
Batch 370, Loss: 0.5067
Batch 380, Loss: 0.5132
Batch 390, Loss: 0.5108
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.30509042739868 seconds
Epoch 159 accuracy: 75.23%
Batch 10, Loss: 0.4257
Batch 20, Loss: 0.4695
Batch 30, Loss: 0.4942
Batch 40, Loss: 0.4665
Batch 50, Loss: 0.4788
Batch 60, Loss: 0.4983
Batch 70, Loss: 0.4587
Batch 80, Loss: 0.4636
Batch 90, Loss: 0.4580
Batch 100, Loss: 0.4761
Batch 110, Loss: 0.4720
Batch 120, Loss: 0.4801
Batch 130, Loss: 0.4873
Batch 140, Loss: 0.4423
Batch 150, Loss: 0.4664
Batch 160, Loss: 0.4951
Batch 170, Loss: 0.4940
Batch 180, Loss: 0.5169
Batch 190, Loss: 0.5089
Batch 200, Loss: 0.4538
Batch 210, Loss: 0.4959
Batch 220, Loss: 0.4819
Batch 230, Loss: 0.4761
Batch 240, Loss: 0.4675
Batch 250, Loss: 0.4794
Batch 260, Loss: 0.4689
Batch 270, Loss: 0.4418
Batch 280, Loss: 0.4561
Batch 290, Loss: 0.5022
Batch 300, Loss: 0.5000
Batch 310, Loss: 0.4546
Batch 320, Loss: 0.4718
Batch 330, Loss: 0.4897
Batch 340, Loss: 0.5461
Batch 350, Loss: 0.4561
Batch 360, Loss: 0.5159
Batch 370, Loss: 0.4650
Batch 380, Loss: 0.4888
Batch 390, Loss: 0.4899
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.329601526260376 seconds
Epoch 160 accuracy: 75.69%
Batch 10, Loss: 0.4704
Batch 20, Loss: 0.4573
Batch 30, Loss: 0.4935
Batch 40, Loss: 0.4673
Batch 50, Loss: 0.4758
Batch 60, Loss: 0.4630
Batch 70, Loss: 0.4517
Batch 80, Loss: 0.4217
Batch 90, Loss: 0.4986
Batch 100, Loss: 0.4562
Batch 110, Loss: 0.4494
Batch 120, Loss: 0.4912
Batch 130, Loss: 0.4584
Batch 140, Loss: 0.4661
Batch 150, Loss: 0.4684
Batch 160, Loss: 0.4201
Batch 170, Loss: 0.4630
Batch 180, Loss: 0.4898
Batch 190, Loss: 0.4651
Batch 200, Loss: 0.4936
Batch 210, Loss: 0.4358
Batch 220, Loss: 0.4642
Batch 230, Loss: 0.4229
Batch 240, Loss: 0.4353
Batch 250, Loss: 0.5018
Batch 260, Loss: 0.5086
Batch 270, Loss: 0.4541
Batch 280, Loss: 0.5248
Batch 290, Loss: 0.4625
Batch 300, Loss: 0.4842
Batch 310, Loss: 0.4708
Batch 320, Loss: 0.4919
Batch 330, Loss: 0.4990
Batch 340, Loss: 0.4925
Batch 350, Loss: 0.4760
Batch 360, Loss: 0.4574
Batch 370, Loss: 0.4905
Batch 380, Loss: 0.4551
Batch 390, Loss: 0.4413
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.27334189414978 seconds
Epoch 161 accuracy: 76.76%
Batch 10, Loss: 0.4404
Batch 20, Loss: 0.4057
Batch 30, Loss: 0.4452
Batch 40, Loss: 0.3878
Batch 50, Loss: 0.4533
Batch 60, Loss: 0.4909
Batch 70, Loss: 0.4390
Batch 80, Loss: 0.4598
Batch 90, Loss: 0.4484
Batch 100, Loss: 0.4396
Batch 110, Loss: 0.4658
Batch 120, Loss: 0.4487
Batch 130, Loss: 0.4242
Batch 140, Loss: 0.4306
Batch 150, Loss: 0.4381
Batch 160, Loss: 0.4278
Batch 170, Loss: 0.4497
Batch 180, Loss: 0.4254
Batch 190, Loss: 0.4518
Batch 200, Loss: 0.4337
Batch 210, Loss: 0.4653
Batch 220, Loss: 0.4883
Batch 230, Loss: 0.4714
Batch 240, Loss: 0.4414
Batch 250, Loss: 0.4459
Batch 260, Loss: 0.4491
Batch 270, Loss: 0.4429
Batch 280, Loss: 0.4774
Batch 290, Loss: 0.4848
Batch 300, Loss: 0.4336
Batch 310, Loss: 0.4333
Batch 320, Loss: 0.4807
Batch 330, Loss: 0.4646
Batch 340, Loss: 0.4636
Batch 350, Loss: 0.4342
Batch 360, Loss: 0.4926
Batch 370, Loss: 0.4220
Batch 380, Loss: 0.4786
Batch 390, Loss: 0.4666
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.32504630088806 seconds
Epoch 162 accuracy: 75.76%
Batch 10, Loss: 0.4861
Batch 20, Loss: 0.4561
Batch 30, Loss: 0.4538
Batch 40, Loss: 0.4512
Batch 50, Loss: 0.3997
Batch 60, Loss: 0.4603
Batch 70, Loss: 0.4633
Batch 80, Loss: 0.4255
Batch 90, Loss: 0.4386
Batch 100, Loss: 0.4400
Batch 110, Loss: 0.4497
Batch 120, Loss: 0.3908
Batch 130, Loss: 0.4380
Batch 140, Loss: 0.4429
Batch 150, Loss: 0.4444
Batch 160, Loss: 0.4339
Batch 170, Loss: 0.4029
Batch 180, Loss: 0.3728
Batch 190, Loss: 0.4734
Batch 200, Loss: 0.4551
Batch 210, Loss: 0.4669
Batch 220, Loss: 0.4165
Batch 230, Loss: 0.4481
Batch 240, Loss: 0.4586
Batch 250, Loss: 0.4324
Batch 260, Loss: 0.4573
Batch 270, Loss: 0.4608
Batch 280, Loss: 0.4302
Batch 290, Loss: 0.4405
Batch 300, Loss: 0.4671
Batch 310, Loss: 0.4739
Batch 320, Loss: 0.4501
Batch 330, Loss: 0.4515
Batch 340, Loss: 0.4295
Batch 350, Loss: 0.5056
Batch 360, Loss: 0.4907
Batch 370, Loss: 0.4694
Batch 380, Loss: 0.4540
Batch 390, Loss: 0.4591
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.260728120803833 seconds
Epoch 163 accuracy: 76.71%
Batch 10, Loss: 0.4180
Batch 20, Loss: 0.4621
Batch 30, Loss: 0.4256
Batch 40, Loss: 0.4202
Batch 50, Loss: 0.4171
Batch 60, Loss: 0.4103
Batch 70, Loss: 0.4127
Batch 80, Loss: 0.4324
Batch 90, Loss: 0.3810
Batch 100, Loss: 0.4249
Batch 110, Loss: 0.4329
Batch 120, Loss: 0.4520
Batch 130, Loss: 0.4600
Batch 140, Loss: 0.4459
Batch 150, Loss: 0.4632
Batch 160, Loss: 0.4625
Batch 170, Loss: 0.4453
Batch 180, Loss: 0.4256
Batch 190, Loss: 0.4191
Batch 200, Loss: 0.4686
Batch 210, Loss: 0.3964
Batch 220, Loss: 0.4371
Batch 230, Loss: 0.4260
Batch 240, Loss: 0.4506
Batch 250, Loss: 0.4112
Batch 260, Loss: 0.4321
Batch 270, Loss: 0.4571
Batch 280, Loss: 0.4765
Batch 290, Loss: 0.4215
Batch 300, Loss: 0.4279
Batch 310, Loss: 0.4466
Batch 320, Loss: 0.4400
Batch 330, Loss: 0.4909
Batch 340, Loss: 0.3992
Batch 350, Loss: 0.4225
Batch 360, Loss: 0.4744
Batch 370, Loss: 0.4534
Batch 380, Loss: 0.4401
Batch 390, Loss: 0.4553
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.295042037963867 seconds
Epoch 164 accuracy: 76.96%
Batch 10, Loss: 0.4102
Batch 20, Loss: 0.4094
Batch 30, Loss: 0.3952
Batch 40, Loss: 0.4067
Batch 50, Loss: 0.3892
Batch 60, Loss: 0.4211
Batch 70, Loss: 0.4053
Batch 80, Loss: 0.4448
Batch 90, Loss: 0.3953
Batch 100, Loss: 0.4343
Batch 110, Loss: 0.4381
Batch 120, Loss: 0.3683
Batch 130, Loss: 0.4350
Batch 140, Loss: 0.4174
Batch 150, Loss: 0.4232
Batch 160, Loss: 0.4346
Batch 170, Loss: 0.4240
Batch 180, Loss: 0.4393
Batch 190, Loss: 0.4150
Batch 200, Loss: 0.4184
Batch 210, Loss: 0.4337
Batch 220, Loss: 0.3714
Batch 230, Loss: 0.4194
Batch 240, Loss: 0.4483
Batch 250, Loss: 0.4318
Batch 260, Loss: 0.4527
Batch 270, Loss: 0.4298
Batch 280, Loss: 0.4126
Batch 290, Loss: 0.4489
Batch 300, Loss: 0.4329
Batch 310, Loss: 0.4185
Batch 320, Loss: 0.4150
Batch 330, Loss: 0.4217
Batch 340, Loss: 0.4168
Batch 350, Loss: 0.4296
Batch 360, Loss: 0.4195
Batch 370, Loss: 0.4638
Batch 380, Loss: 0.4190
Batch 390, Loss: 0.4195
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.290250778198242 seconds
Epoch 165 accuracy: 76.7%
Batch 10, Loss: 0.4315
Batch 20, Loss: 0.4174
Batch 30, Loss: 0.4326
Batch 40, Loss: 0.4103
Batch 50, Loss: 0.4117
Batch 60, Loss: 0.4574
Batch 70, Loss: 0.4013
Batch 80, Loss: 0.4029
Batch 90, Loss: 0.3857
Batch 100, Loss: 0.4439
Batch 110, Loss: 0.3782
Batch 120, Loss: 0.3870
Batch 130, Loss: 0.4100
Batch 140, Loss: 0.3907
Batch 150, Loss: 0.3744
Batch 160, Loss: 0.4060
Batch 170, Loss: 0.3703
Batch 180, Loss: 0.4363
Batch 190, Loss: 0.4138
Batch 200, Loss: 0.4206
Batch 210, Loss: 0.4218
Batch 220, Loss: 0.4076
Batch 230, Loss: 0.3982
Batch 240, Loss: 0.3870
Batch 250, Loss: 0.3872
Batch 260, Loss: 0.4647
Batch 270, Loss: 0.4210
Batch 280, Loss: 0.3982
Batch 290, Loss: 0.4301
Batch 300, Loss: 0.3938
Batch 310, Loss: 0.4168
Batch 320, Loss: 0.4082
Batch 330, Loss: 0.3886
Batch 340, Loss: 0.4137
Batch 350, Loss: 0.4092
Batch 360, Loss: 0.4226
Batch 370, Loss: 0.4397
Batch 380, Loss: 0.4015
Batch 390, Loss: 0.4483
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.363784790039062 seconds
Epoch 166 accuracy: 77.01%
Batch 10, Loss: 0.3994
Batch 20, Loss: 0.3434
Batch 30, Loss: 0.3831
Batch 40, Loss: 0.4019
Batch 50, Loss: 0.4117
Batch 60, Loss: 0.3916
Batch 70, Loss: 0.3854
Batch 80, Loss: 0.3521
Batch 90, Loss: 0.3883
Batch 100, Loss: 0.3936
Batch 110, Loss: 0.3823
Batch 120, Loss: 0.4098
Batch 130, Loss: 0.4046
Batch 140, Loss: 0.4001
Batch 150, Loss: 0.4226
Batch 160, Loss: 0.4310
Batch 170, Loss: 0.3907
Batch 180, Loss: 0.4402
Batch 190, Loss: 0.3731
Batch 200, Loss: 0.4052
Batch 210, Loss: 0.4093
Batch 220, Loss: 0.3854
Batch 230, Loss: 0.4190
Batch 240, Loss: 0.4183
Batch 250, Loss: 0.3972
Batch 260, Loss: 0.3816
Batch 270, Loss: 0.3635
Batch 280, Loss: 0.3792
Batch 290, Loss: 0.4469
Batch 300, Loss: 0.3601
Batch 310, Loss: 0.3630
Batch 320, Loss: 0.4138
Batch 330, Loss: 0.4134
Batch 340, Loss: 0.3745
Batch 350, Loss: 0.3868
Batch 360, Loss: 0.4371
Batch 370, Loss: 0.4012
Batch 380, Loss: 0.3736
Batch 390, Loss: 0.3910
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.312378883361816 seconds
Epoch 167 accuracy: 77.73%
Batch 10, Loss: 0.3646
Batch 20, Loss: 0.3530
Batch 30, Loss: 0.3658
Batch 40, Loss: 0.3955
Batch 50, Loss: 0.3399
Batch 60, Loss: 0.4005
Batch 70, Loss: 0.3725
Batch 80, Loss: 0.3824
Batch 90, Loss: 0.3644
Batch 100, Loss: 0.4166
Batch 110, Loss: 0.3781
Batch 120, Loss: 0.4120
Batch 130, Loss: 0.3802
Batch 140, Loss: 0.3706
Batch 150, Loss: 0.3615
Batch 160, Loss: 0.3711
Batch 170, Loss: 0.4172
Batch 180, Loss: 0.3397
Batch 190, Loss: 0.3677
Batch 200, Loss: 0.4035
Batch 210, Loss: 0.4011
Batch 220, Loss: 0.3932
Batch 230, Loss: 0.3810
Batch 240, Loss: 0.3816
Batch 250, Loss: 0.3825
Batch 260, Loss: 0.3498
Batch 270, Loss: 0.3994
Batch 280, Loss: 0.3839
Batch 290, Loss: 0.3881
Batch 300, Loss: 0.4079
Batch 310, Loss: 0.3993
Batch 320, Loss: 0.3855
Batch 330, Loss: 0.3909
Batch 340, Loss: 0.3662
Batch 350, Loss: 0.4117
Batch 360, Loss: 0.4374
Batch 370, Loss: 0.4132
Batch 380, Loss: 0.3823
Batch 390, Loss: 0.4011
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.307170152664185 seconds
Epoch 168 accuracy: 77.25%
Batch 10, Loss: 0.3753
Batch 20, Loss: 0.3913
Batch 30, Loss: 0.3901
Batch 40, Loss: 0.3707
Batch 50, Loss: 0.3696
Batch 60, Loss: 0.3891
Batch 70, Loss: 0.3818
Batch 80, Loss: 0.3947
Batch 90, Loss: 0.3934
Batch 100, Loss: 0.3775
Batch 110, Loss: 0.3969
Batch 120, Loss: 0.3614
Batch 130, Loss: 0.3670
Batch 140, Loss: 0.3986
Batch 150, Loss: 0.3862
Batch 160, Loss: 0.4093
Batch 170, Loss: 0.3835
Batch 180, Loss: 0.3752
Batch 190, Loss: 0.3703
Batch 200, Loss: 0.3748
Batch 210, Loss: 0.3891
Batch 220, Loss: 0.3845
Batch 230, Loss: 0.3515
Batch 240, Loss: 0.3495
Batch 250, Loss: 0.3709
Batch 260, Loss: 0.3944
Batch 270, Loss: 0.4048
Batch 280, Loss: 0.3909
Batch 290, Loss: 0.3808
Batch 300, Loss: 0.3808
Batch 310, Loss: 0.4226
Batch 320, Loss: 0.4065
Batch 330, Loss: 0.3885
Batch 340, Loss: 0.4263
Batch 350, Loss: 0.3800
Batch 360, Loss: 0.4021
Batch 370, Loss: 0.3702
Batch 380, Loss: 0.3551
Batch 390, Loss: 0.3805
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.252893686294556 seconds
Epoch 169 accuracy: 77.61%
Batch 10, Loss: 0.3413
Batch 20, Loss: 0.3453
Batch 30, Loss: 0.3767
Batch 40, Loss: 0.3485
Batch 50, Loss: 0.3873
Batch 60, Loss: 0.3567
Batch 70, Loss: 0.3446
Batch 80, Loss: 0.3320
Batch 90, Loss: 0.3592
Batch 100, Loss: 0.3660
Batch 110, Loss: 0.3829
Batch 120, Loss: 0.4122
Batch 130, Loss: 0.3512
Batch 140, Loss: 0.3568
Batch 150, Loss: 0.3710
Batch 160, Loss: 0.3627
Batch 170, Loss: 0.3676
Batch 180, Loss: 0.3316
Batch 190, Loss: 0.4124
Batch 200, Loss: 0.3681
Batch 210, Loss: 0.3978
Batch 220, Loss: 0.3894
Batch 230, Loss: 0.4278
Batch 240, Loss: 0.3661
Batch 250, Loss: 0.3515
Batch 260, Loss: 0.3732
Batch 270, Loss: 0.3524
Batch 280, Loss: 0.3648
Batch 290, Loss: 0.3731
Batch 300, Loss: 0.3916
Batch 310, Loss: 0.3657
Batch 320, Loss: 0.3776
Batch 330, Loss: 0.3565
Batch 340, Loss: 0.3916
Batch 350, Loss: 0.3591
Batch 360, Loss: 0.3744
Batch 370, Loss: 0.3389
Batch 380, Loss: 0.3761
Batch 390, Loss: 0.4006
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.27872085571289 seconds
Epoch 170 accuracy: 77.99%
Batch 10, Loss: 0.3522
Batch 20, Loss: 0.3833
Batch 30, Loss: 0.3487
Batch 40, Loss: 0.3301
Batch 50, Loss: 0.3541
Batch 60, Loss: 0.3362
Batch 70, Loss: 0.3265
Batch 80, Loss: 0.3414
Batch 90, Loss: 0.3646
Batch 100, Loss: 0.3753
Batch 110, Loss: 0.3242
Batch 120, Loss: 0.3342
Batch 130, Loss: 0.3425
Batch 140, Loss: 0.3747
Batch 150, Loss: 0.3355
Batch 160, Loss: 0.3555
Batch 170, Loss: 0.3321
Batch 180, Loss: 0.4226
Batch 190, Loss: 0.3906
Batch 200, Loss: 0.3386
Batch 210, Loss: 0.3711
Batch 220, Loss: 0.3903
Batch 230, Loss: 0.3878
Batch 240, Loss: 0.3853
Batch 250, Loss: 0.3494
Batch 260, Loss: 0.3631
Batch 270, Loss: 0.4129
Batch 280, Loss: 0.3495
Batch 290, Loss: 0.3581
Batch 300, Loss: 0.3327
Batch 310, Loss: 0.3606
Batch 320, Loss: 0.3751
Batch 330, Loss: 0.3920
Batch 340, Loss: 0.3357
Batch 350, Loss: 0.3899
Batch 360, Loss: 0.3577
Batch 370, Loss: 0.3448
Batch 380, Loss: 0.3614
Batch 390, Loss: 0.3996
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.305735111236572 seconds
Epoch 171 accuracy: 77.78%
Batch 10, Loss: 0.3571
Batch 20, Loss: 0.3233
Batch 30, Loss: 0.3515
Batch 40, Loss: 0.3292
Batch 50, Loss: 0.3487
Batch 60, Loss: 0.3641
Batch 70, Loss: 0.3501
Batch 80, Loss: 0.3535
Batch 90, Loss: 0.3150
Batch 100, Loss: 0.3251
Batch 110, Loss: 0.3654
Batch 120, Loss: 0.3707
Batch 130, Loss: 0.3461
Batch 140, Loss: 0.3329
Batch 150, Loss: 0.3562
Batch 160, Loss: 0.3361
Batch 170, Loss: 0.3739
Batch 180, Loss: 0.3760
Batch 190, Loss: 0.3276
Batch 200, Loss: 0.3396
Batch 210, Loss: 0.3481
Batch 220, Loss: 0.3461
Batch 230, Loss: 0.3551
Batch 240, Loss: 0.3657
Batch 250, Loss: 0.3636
Batch 260, Loss: 0.3903
Batch 270, Loss: 0.3591
Batch 280, Loss: 0.3615
Batch 290, Loss: 0.3571
Batch 300, Loss: 0.3890
Batch 310, Loss: 0.3418
Batch 320, Loss: 0.3528
Batch 330, Loss: 0.3483
Batch 340, Loss: 0.3592
Batch 350, Loss: 0.3746
Batch 360, Loss: 0.3818
Batch 370, Loss: 0.3777
Batch 380, Loss: 0.3543
Batch 390, Loss: 0.3522
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.31100583076477 seconds
Epoch 172 accuracy: 78.06%
Batch 10, Loss: 0.3315
Batch 20, Loss: 0.3330
Batch 30, Loss: 0.3175
Batch 40, Loss: 0.3229
Batch 50, Loss: 0.3264
Batch 60, Loss: 0.3682
Batch 70, Loss: 0.3283
Batch 80, Loss: 0.3329
Batch 90, Loss: 0.3328
Batch 100, Loss: 0.3465
Batch 110, Loss: 0.3747
Batch 120, Loss: 0.3309
Batch 130, Loss: 0.3791
Batch 140, Loss: 0.3366
Batch 150, Loss: 0.3217
Batch 160, Loss: 0.3365
Batch 170, Loss: 0.3554
Batch 180, Loss: 0.3345
Batch 190, Loss: 0.3630
Batch 200, Loss: 0.3430
Batch 210, Loss: 0.3227
Batch 220, Loss: 0.3639
Batch 230, Loss: 0.3180
Batch 240, Loss: 0.3790
Batch 250, Loss: 0.3350
Batch 260, Loss: 0.3414
Batch 270, Loss: 0.3326
Batch 280, Loss: 0.3318
Batch 290, Loss: 0.3740
Batch 300, Loss: 0.3579
Batch 310, Loss: 0.3745
Batch 320, Loss: 0.3694
Batch 330, Loss: 0.3591
Batch 340, Loss: 0.3395
Batch 350, Loss: 0.3246
Batch 360, Loss: 0.3450
Batch 370, Loss: 0.3295
Batch 380, Loss: 0.3213
Batch 390, Loss: 0.3622
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.226539611816406 seconds
Epoch 173 accuracy: 78.24%
Batch 10, Loss: 0.3404
Batch 20, Loss: 0.3441
Batch 30, Loss: 0.3307
Batch 40, Loss: 0.3342
Batch 50, Loss: 0.3046
Batch 60, Loss: 0.3273
Batch 70, Loss: 0.3183
Batch 80, Loss: 0.3525
Batch 90, Loss: 0.3287
Batch 100, Loss: 0.3160
Batch 110, Loss: 0.3675
Batch 120, Loss: 0.3440
Batch 130, Loss: 0.3964
Batch 140, Loss: 0.3286
Batch 150, Loss: 0.3826
Batch 160, Loss: 0.3395
Batch 170, Loss: 0.3579
Batch 180, Loss: 0.3447
Batch 190, Loss: 0.3458
Batch 200, Loss: 0.3082
Batch 210, Loss: 0.3277
Batch 220, Loss: 0.3674
Batch 230, Loss: 0.3198
Batch 240, Loss: 0.3151
Batch 250, Loss: 0.3398
Batch 260, Loss: 0.3342
Batch 270, Loss: 0.3449
Batch 280, Loss: 0.3113
Batch 290, Loss: 0.3260
Batch 300, Loss: 0.3266
Batch 310, Loss: 0.3443
Batch 320, Loss: 0.3331
Batch 330, Loss: 0.3332
Batch 340, Loss: 0.3518
Batch 350, Loss: 0.3464
Batch 360, Loss: 0.3660
Batch 370, Loss: 0.3477
Batch 380, Loss: 0.3498
Batch 390, Loss: 0.3242
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.286057233810425 seconds
Epoch 174 accuracy: 78.48%
Batch 10, Loss: 0.3048
Batch 20, Loss: 0.2995
Batch 30, Loss: 0.3314
Batch 40, Loss: 0.3110
Batch 50, Loss: 0.3178
Batch 60, Loss: 0.3076
Batch 70, Loss: 0.3421
Batch 80, Loss: 0.3280
Batch 90, Loss: 0.3008
Batch 100, Loss: 0.2941
Batch 110, Loss: 0.3095
Batch 120, Loss: 0.3145
Batch 130, Loss: 0.3315
Batch 140, Loss: 0.3223
Batch 150, Loss: 0.3153
Batch 160, Loss: 0.3404
Batch 170, Loss: 0.3350
Batch 180, Loss: 0.3470
Batch 190, Loss: 0.2933
Batch 200, Loss: 0.3091
Batch 210, Loss: 0.3409
Batch 220, Loss: 0.3290
Batch 230, Loss: 0.3430
Batch 240, Loss: 0.3227
Batch 250, Loss: 0.3332
Batch 260, Loss: 0.3169
Batch 270, Loss: 0.3125
Batch 280, Loss: 0.3373
Batch 290, Loss: 0.3277
Batch 300, Loss: 0.3240
Batch 310, Loss: 0.3776
Batch 320, Loss: 0.3108
Batch 330, Loss: 0.3308
Batch 340, Loss: 0.3524
Batch 350, Loss: 0.3346
Batch 360, Loss: 0.3492
Batch 370, Loss: 0.3281
Batch 380, Loss: 0.3414
Batch 390, Loss: 0.3231
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.312950134277344 seconds
Epoch 175 accuracy: 78.52%
Batch 10, Loss: 0.3392
Batch 20, Loss: 0.2818
Batch 30, Loss: 0.3245
Batch 40, Loss: 0.3175
Batch 50, Loss: 0.3532
Batch 60, Loss: 0.2870
Batch 70, Loss: 0.2948
Batch 80, Loss: 0.3341
Batch 90, Loss: 0.3020
Batch 100, Loss: 0.3096
Batch 110, Loss: 0.3129
Batch 120, Loss: 0.3387
Batch 130, Loss: 0.3362
Batch 140, Loss: 0.3016
Batch 150, Loss: 0.3072
Batch 160, Loss: 0.3102
Batch 170, Loss: 0.2907
Batch 180, Loss: 0.2969
Batch 190, Loss: 0.3310
Batch 200, Loss: 0.3259
Batch 210, Loss: 0.3081
Batch 220, Loss: 0.3074
Batch 230, Loss: 0.3251
Batch 240, Loss: 0.2908
Batch 250, Loss: 0.3258
Batch 260, Loss: 0.3216
Batch 270, Loss: 0.3478
Batch 280, Loss: 0.3217
Batch 290, Loss: 0.3016
Batch 300, Loss: 0.3014
Batch 310, Loss: 0.3090
Batch 320, Loss: 0.3435
Batch 330, Loss: 0.2949
Batch 340, Loss: 0.3223
Batch 350, Loss: 0.3116
Batch 360, Loss: 0.3226
Batch 370, Loss: 0.3049
Batch 380, Loss: 0.3255
Batch 390, Loss: 0.3162
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.28007674217224 seconds
Epoch 176 accuracy: 78.22%
Batch 10, Loss: 0.3018
Batch 20, Loss: 0.3088
Batch 30, Loss: 0.2977
Batch 40, Loss: 0.2831
Batch 50, Loss: 0.2827
Batch 60, Loss: 0.3269
Batch 70, Loss: 0.3151
Batch 80, Loss: 0.2976
Batch 90, Loss: 0.2954
Batch 100, Loss: 0.3050
Batch 110, Loss: 0.3213
Batch 120, Loss: 0.3295
Batch 130, Loss: 0.3255
Batch 140, Loss: 0.3024
Batch 150, Loss: 0.3164
Batch 160, Loss: 0.3298
Batch 170, Loss: 0.3155
Batch 180, Loss: 0.3101
Batch 190, Loss: 0.3166
Batch 200, Loss: 0.3087
Batch 210, Loss: 0.2855
Batch 220, Loss: 0.2911
Batch 230, Loss: 0.3305
Batch 240, Loss: 0.2809
Batch 250, Loss: 0.2888
Batch 260, Loss: 0.2970
Batch 270, Loss: 0.3123
Batch 280, Loss: 0.2952
Batch 290, Loss: 0.3018
Batch 300, Loss: 0.3084
Batch 310, Loss: 0.3252
Batch 320, Loss: 0.3360
Batch 330, Loss: 0.3279
Batch 340, Loss: 0.3500
Batch 350, Loss: 0.3027
Batch 360, Loss: 0.3253
Batch 370, Loss: 0.2943
Batch 380, Loss: 0.3348
Batch 390, Loss: 0.3031
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.251521348953247 seconds
Epoch 177 accuracy: 78.71%
Batch 10, Loss: 0.3022
Batch 20, Loss: 0.3135
Batch 30, Loss: 0.3065
Batch 40, Loss: 0.3180
Batch 50, Loss: 0.2873
Batch 60, Loss: 0.3249
Batch 70, Loss: 0.2865
Batch 80, Loss: 0.2750
Batch 90, Loss: 0.2929
Batch 100, Loss: 0.2734
Batch 110, Loss: 0.3078
Batch 120, Loss: 0.3133
Batch 130, Loss: 0.3006
Batch 140, Loss: 0.3092
Batch 150, Loss: 0.2828
Batch 160, Loss: 0.3165
Batch 170, Loss: 0.3015
Batch 180, Loss: 0.2870
Batch 190, Loss: 0.3120
Batch 200, Loss: 0.3062
Batch 210, Loss: 0.2969
Batch 220, Loss: 0.3111
Batch 230, Loss: 0.2875
Batch 240, Loss: 0.2760
Batch 250, Loss: 0.3027
Batch 260, Loss: 0.3272
Batch 270, Loss: 0.3086
Batch 280, Loss: 0.3378
Batch 290, Loss: 0.3369
Batch 300, Loss: 0.2788
Batch 310, Loss: 0.3302
Batch 320, Loss: 0.3121
Batch 330, Loss: 0.3123
Batch 340, Loss: 0.3177
Batch 350, Loss: 0.3133
Batch 360, Loss: 0.3037
Batch 370, Loss: 0.2858
Batch 380, Loss: 0.2763
Batch 390, Loss: 0.2922
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.26798677444458 seconds
Epoch 178 accuracy: 78.69%
Batch 10, Loss: 0.3017
Batch 20, Loss: 0.3265
Batch 30, Loss: 0.3188
Batch 40, Loss: 0.2710
Batch 50, Loss: 0.3054
Batch 60, Loss: 0.3061
Batch 70, Loss: 0.2675
Batch 80, Loss: 0.3279
Batch 90, Loss: 0.3022
Batch 100, Loss: 0.2867
Batch 110, Loss: 0.3320
Batch 120, Loss: 0.2652
Batch 130, Loss: 0.2640
Batch 140, Loss: 0.2790
Batch 150, Loss: 0.2842
Batch 160, Loss: 0.2432
Batch 170, Loss: 0.3302
Batch 180, Loss: 0.2911
Batch 190, Loss: 0.3155
Batch 200, Loss: 0.2945
Batch 210, Loss: 0.2928
Batch 220, Loss: 0.2898
Batch 230, Loss: 0.3116
Batch 240, Loss: 0.3145
Batch 250, Loss: 0.2996
Batch 260, Loss: 0.2749
Batch 270, Loss: 0.3305
Batch 280, Loss: 0.2812
Batch 290, Loss: 0.2905
Batch 300, Loss: 0.2642
Batch 310, Loss: 0.2801
Batch 320, Loss: 0.3217
Batch 330, Loss: 0.2596
Batch 340, Loss: 0.2654
Batch 350, Loss: 0.2880
Batch 360, Loss: 0.2902
Batch 370, Loss: 0.3055
Batch 380, Loss: 0.3018
Batch 390, Loss: 0.2957
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.32984733581543 seconds
Epoch 179 accuracy: 78.94%
Batch 10, Loss: 0.2901
Batch 20, Loss: 0.2943
Batch 30, Loss: 0.2848
Batch 40, Loss: 0.2980
Batch 50, Loss: 0.2777
Batch 60, Loss: 0.3246
Batch 70, Loss: 0.2881
Batch 80, Loss: 0.2890
Batch 90, Loss: 0.3298
Batch 100, Loss: 0.2730
Batch 110, Loss: 0.2744
Batch 120, Loss: 0.2653
Batch 130, Loss: 0.3015
Batch 140, Loss: 0.3212
Batch 150, Loss: 0.2843
Batch 160, Loss: 0.2767
Batch 170, Loss: 0.2594
Batch 180, Loss: 0.2868
Batch 190, Loss: 0.2868
Batch 200, Loss: 0.2858
Batch 210, Loss: 0.2700
Batch 220, Loss: 0.2865
Batch 230, Loss: 0.2910
Batch 240, Loss: 0.2764
Batch 250, Loss: 0.2783
Batch 260, Loss: 0.3074
Batch 270, Loss: 0.2776
Batch 280, Loss: 0.2752
Batch 290, Loss: 0.3119
Batch 300, Loss: 0.3206
Batch 310, Loss: 0.2717
Batch 320, Loss: 0.2985
Batch 330, Loss: 0.2996
Batch 340, Loss: 0.3223
Batch 350, Loss: 0.3198
Batch 360, Loss: 0.2867
Batch 370, Loss: 0.3376
Batch 380, Loss: 0.2769
Batch 390, Loss: 0.2688
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.28543710708618 seconds
Epoch 180 accuracy: 79.08%
Batch 10, Loss: 0.3022
Batch 20, Loss: 0.2640
Batch 30, Loss: 0.2842
Batch 40, Loss: 0.3012
Batch 50, Loss: 0.2875
Batch 60, Loss: 0.2845
Batch 70, Loss: 0.2713
Batch 80, Loss: 0.3009
Batch 90, Loss: 0.2742
Batch 100, Loss: 0.2781
Batch 110, Loss: 0.2737
Batch 120, Loss: 0.2850
Batch 130, Loss: 0.2837
Batch 140, Loss: 0.2742
Batch 150, Loss: 0.3018
Batch 160, Loss: 0.3022
Batch 170, Loss: 0.2900
Batch 180, Loss: 0.2628
Batch 190, Loss: 0.3141
Batch 200, Loss: 0.3006
Batch 210, Loss: 0.2813
Batch 220, Loss: 0.2993
Batch 230, Loss: 0.3209
Batch 240, Loss: 0.2735
Batch 250, Loss: 0.2824
Batch 260, Loss: 0.2670
Batch 270, Loss: 0.2769
Batch 280, Loss: 0.2848
Batch 290, Loss: 0.3099
Batch 300, Loss: 0.2638
Batch 310, Loss: 0.3256
Batch 320, Loss: 0.2879
Batch 330, Loss: 0.2893
Batch 340, Loss: 0.3188
Batch 350, Loss: 0.2736
Batch 360, Loss: 0.2953
Batch 370, Loss: 0.2992
Batch 380, Loss: 0.2978
Batch 390, Loss: 0.2721
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.147035837173462 seconds
Epoch 181 accuracy: 79.02%
Batch 10, Loss: 0.2621
Batch 20, Loss: 0.2789
Batch 30, Loss: 0.2683
Batch 40, Loss: 0.2501
Batch 50, Loss: 0.2912
Batch 60, Loss: 0.2566
Batch 70, Loss: 0.2769
Batch 80, Loss: 0.2654
Batch 90, Loss: 0.3175
Batch 100, Loss: 0.2531
Batch 110, Loss: 0.2764
Batch 120, Loss: 0.3121
Batch 130, Loss: 0.2850
Batch 140, Loss: 0.2728
Batch 150, Loss: 0.2838
Batch 160, Loss: 0.2422
Batch 170, Loss: 0.2827
Batch 180, Loss: 0.2496
Batch 190, Loss: 0.3092
Batch 200, Loss: 0.2533
Batch 210, Loss: 0.3069
Batch 220, Loss: 0.2812
Batch 230, Loss: 0.2999
Batch 240, Loss: 0.2684
Batch 250, Loss: 0.2644
Batch 260, Loss: 0.2668
Batch 270, Loss: 0.2696
Batch 280, Loss: 0.2676
Batch 290, Loss: 0.2911
Batch 300, Loss: 0.3106
Batch 310, Loss: 0.2866
Batch 320, Loss: 0.2679
Batch 330, Loss: 0.2461
Batch 340, Loss: 0.2925
Batch 350, Loss: 0.2957
Batch 360, Loss: 0.2555
Batch 370, Loss: 0.2839
Batch 380, Loss: 0.2646
Batch 390, Loss: 0.3453
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.23338770866394 seconds
Epoch 182 accuracy: 79.34%
Batch 10, Loss: 0.2421
Batch 20, Loss: 0.2651
Batch 30, Loss: 0.2452
Batch 40, Loss: 0.2992
Batch 50, Loss: 0.2661
Batch 60, Loss: 0.2936
Batch 70, Loss: 0.2808
Batch 80, Loss: 0.2694
Batch 90, Loss: 0.2610
Batch 100, Loss: 0.2832
Batch 110, Loss: 0.2892
Batch 120, Loss: 0.2885
Batch 130, Loss: 0.3037
Batch 140, Loss: 0.2983
Batch 150, Loss: 0.2911
Batch 160, Loss: 0.2870
Batch 170, Loss: 0.2542
Batch 180, Loss: 0.2761
Batch 190, Loss: 0.2678
Batch 200, Loss: 0.2873
Batch 210, Loss: 0.2700
Batch 220, Loss: 0.2468
Batch 230, Loss: 0.2733
Batch 240, Loss: 0.2649
Batch 250, Loss: 0.2981
Batch 260, Loss: 0.2881
Batch 270, Loss: 0.2840
Batch 280, Loss: 0.2565
Batch 290, Loss: 0.2886
Batch 300, Loss: 0.2622
Batch 310, Loss: 0.2693
Batch 320, Loss: 0.2293
Batch 330, Loss: 0.2739
Batch 340, Loss: 0.2800
Batch 350, Loss: 0.2257
Batch 360, Loss: 0.2480
Batch 370, Loss: 0.2693
Batch 380, Loss: 0.2755
Batch 390, Loss: 0.2753
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.27276873588562 seconds
Epoch 183 accuracy: 79.48%
Batch 10, Loss: 0.2887
Batch 20, Loss: 0.2612
Batch 30, Loss: 0.2862
Batch 40, Loss: 0.2676
Batch 50, Loss: 0.2450
Batch 60, Loss: 0.2680
Batch 70, Loss: 0.2727
Batch 80, Loss: 0.2723
Batch 90, Loss: 0.2342
Batch 100, Loss: 0.2746
Batch 110, Loss: 0.2608
Batch 120, Loss: 0.2450
Batch 130, Loss: 0.2451
Batch 140, Loss: 0.2756
Batch 150, Loss: 0.2791
Batch 160, Loss: 0.2672
Batch 170, Loss: 0.2870
Batch 180, Loss: 0.2734
Batch 190, Loss: 0.2632
Batch 200, Loss: 0.2936
Batch 210, Loss: 0.2593
Batch 220, Loss: 0.2523
Batch 230, Loss: 0.2750
Batch 240, Loss: 0.2713
Batch 250, Loss: 0.2556
Batch 260, Loss: 0.2969
Batch 270, Loss: 0.2970
Batch 280, Loss: 0.2682
Batch 290, Loss: 0.2423
Batch 300, Loss: 0.2825
Batch 310, Loss: 0.2865
Batch 320, Loss: 0.2612
Batch 330, Loss: 0.2674
Batch 340, Loss: 0.2764
Batch 350, Loss: 0.2576
Batch 360, Loss: 0.2922
Batch 370, Loss: 0.2601
Batch 380, Loss: 0.2927
Batch 390, Loss: 0.2803
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.285977125167847 seconds
Epoch 184 accuracy: 79.19%
Batch 10, Loss: 0.2656
Batch 20, Loss: 0.2420
Batch 30, Loss: 0.2724
Batch 40, Loss: 0.2844
Batch 50, Loss: 0.2924
Batch 60, Loss: 0.2601
Batch 70, Loss: 0.2818
Batch 80, Loss: 0.2441
Batch 90, Loss: 0.2975
Batch 100, Loss: 0.2628
Batch 110, Loss: 0.2496
Batch 120, Loss: 0.2320
Batch 130, Loss: 0.2691
Batch 140, Loss: 0.2787
Batch 150, Loss: 0.2499
Batch 160, Loss: 0.2504
Batch 170, Loss: 0.2898
Batch 180, Loss: 0.2423
Batch 190, Loss: 0.2543
Batch 200, Loss: 0.2591
Batch 210, Loss: 0.2477
Batch 220, Loss: 0.2783
Batch 230, Loss: 0.2694
Batch 240, Loss: 0.2385
Batch 250, Loss: 0.2810
Batch 260, Loss: 0.2709
Batch 270, Loss: 0.2536
Batch 280, Loss: 0.2617
Batch 290, Loss: 0.2710
Batch 300, Loss: 0.2551
Batch 310, Loss: 0.3077
Batch 320, Loss: 0.2456
Batch 330, Loss: 0.2766
Batch 340, Loss: 0.2827
Batch 350, Loss: 0.2638
Batch 360, Loss: 0.2284
Batch 370, Loss: 0.2766
Batch 380, Loss: 0.2701
Batch 390, Loss: 0.2686
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.1982638835907 seconds
Epoch 185 accuracy: 79.73%
Batch 10, Loss: 0.2655
Batch 20, Loss: 0.2463
Batch 30, Loss: 0.2713
Batch 40, Loss: 0.2460
Batch 50, Loss: 0.2701
Batch 60, Loss: 0.2673
Batch 70, Loss: 0.2672
Batch 80, Loss: 0.2699
Batch 90, Loss: 0.2529
Batch 100, Loss: 0.2732
Batch 110, Loss: 0.2734
Batch 120, Loss: 0.2788
Batch 130, Loss: 0.2818
Batch 140, Loss: 0.2513
Batch 150, Loss: 0.2329
Batch 160, Loss: 0.2687
Batch 170, Loss: 0.2599
Batch 180, Loss: 0.2563
Batch 190, Loss: 0.2613
Batch 200, Loss: 0.2690
Batch 210, Loss: 0.2537
Batch 220, Loss: 0.2541
Batch 230, Loss: 0.2420
Batch 240, Loss: 0.2765
Batch 250, Loss: 0.2796
Batch 260, Loss: 0.2613
Batch 270, Loss: 0.2598
Batch 280, Loss: 0.2678
Batch 290, Loss: 0.2431
Batch 300, Loss: 0.2642
Batch 310, Loss: 0.2648
Batch 320, Loss: 0.2598
Batch 330, Loss: 0.2561
Batch 340, Loss: 0.2702
Batch 350, Loss: 0.2538
Batch 360, Loss: 0.2357
Batch 370, Loss: 0.2977
Batch 380, Loss: 0.2626
Batch 390, Loss: 0.2717
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.230144739151 seconds
Epoch 186 accuracy: 79.89%
Batch 10, Loss: 0.2321
Batch 20, Loss: 0.2517
Batch 30, Loss: 0.2685
Batch 40, Loss: 0.2679
Batch 50, Loss: 0.2261
Batch 60, Loss: 0.2609
Batch 70, Loss: 0.2521
Batch 80, Loss: 0.2575
Batch 90, Loss: 0.2411
Batch 100, Loss: 0.2732
Batch 110, Loss: 0.2486
Batch 120, Loss: 0.2561
Batch 130, Loss: 0.2677
Batch 140, Loss: 0.2428
Batch 150, Loss: 0.2799
Batch 160, Loss: 0.2308
Batch 170, Loss: 0.2676
Batch 180, Loss: 0.2491
Batch 190, Loss: 0.2707
Batch 200, Loss: 0.2860
Batch 210, Loss: 0.2636
Batch 220, Loss: 0.2570
Batch 230, Loss: 0.2397
Batch 240, Loss: 0.2329
Batch 250, Loss: 0.2614
Batch 260, Loss: 0.2478
Batch 270, Loss: 0.2592
Batch 280, Loss: 0.2960
Batch 290, Loss: 0.2188
Batch 300, Loss: 0.2443
Batch 310, Loss: 0.3065
Batch 320, Loss: 0.2566
Batch 330, Loss: 0.2483
Batch 340, Loss: 0.2411
Batch 350, Loss: 0.2609
Batch 360, Loss: 0.2618
Batch 370, Loss: 0.2506
Batch 380, Loss: 0.2317
Batch 390, Loss: 0.2579
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.28244638442993 seconds
Epoch 187 accuracy: 79.67%
Batch 10, Loss: 0.2766
Batch 20, Loss: 0.2466
Batch 30, Loss: 0.2456
Batch 40, Loss: 0.2709
Batch 50, Loss: 0.2391
Batch 60, Loss: 0.2493
Batch 70, Loss: 0.2351
Batch 80, Loss: 0.2655
Batch 90, Loss: 0.2878
Batch 100, Loss: 0.2717
Batch 110, Loss: 0.2619
Batch 120, Loss: 0.2491
Batch 130, Loss: 0.2639
Batch 140, Loss: 0.2570
Batch 150, Loss: 0.2445
Batch 160, Loss: 0.2370
Batch 170, Loss: 0.2361
Batch 180, Loss: 0.2628
Batch 190, Loss: 0.2566
Batch 200, Loss: 0.2645
Batch 210, Loss: 0.2369
Batch 220, Loss: 0.2558
Batch 230, Loss: 0.2418
Batch 240, Loss: 0.2605
Batch 250, Loss: 0.2504
Batch 260, Loss: 0.2632
Batch 270, Loss: 0.2637
Batch 280, Loss: 0.2701
Batch 290, Loss: 0.2602
Batch 300, Loss: 0.2398
Batch 310, Loss: 0.2604
Batch 320, Loss: 0.2370
Batch 330, Loss: 0.2519
Batch 340, Loss: 0.2266
Batch 350, Loss: 0.2572
Batch 360, Loss: 0.2613
Batch 370, Loss: 0.2505
Batch 380, Loss: 0.2501
Batch 390, Loss: 0.2413
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.175055503845215 seconds
Epoch 188 accuracy: 79.94%
Batch 10, Loss: 0.2433
Batch 20, Loss: 0.2862
Batch 30, Loss: 0.2765
Batch 40, Loss: 0.2657
Batch 50, Loss: 0.2753
Batch 60, Loss: 0.2178
Batch 70, Loss: 0.2197
Batch 80, Loss: 0.2386
Batch 90, Loss: 0.2418
Batch 100, Loss: 0.2471
Batch 110, Loss: 0.2427
Batch 120, Loss: 0.2342
Batch 130, Loss: 0.2443
Batch 140, Loss: 0.2344
Batch 150, Loss: 0.2791
Batch 160, Loss: 0.2676
Batch 170, Loss: 0.2344
Batch 180, Loss: 0.2592
Batch 190, Loss: 0.2690
Batch 200, Loss: 0.2390
Batch 210, Loss: 0.2515
Batch 220, Loss: 0.2542
Batch 230, Loss: 0.2453
Batch 240, Loss: 0.2300
Batch 250, Loss: 0.2266
Batch 260, Loss: 0.2391
Batch 270, Loss: 0.2541
Batch 280, Loss: 0.2605
Batch 290, Loss: 0.2331
Batch 300, Loss: 0.2544
Batch 310, Loss: 0.2391
Batch 320, Loss: 0.2596
Batch 330, Loss: 0.2841
Batch 340, Loss: 0.2818
Batch 350, Loss: 0.2778
Batch 360, Loss: 0.2468
Batch 370, Loss: 0.2746
Batch 380, Loss: 0.2639
Batch 390, Loss: 0.2070
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.25695514678955 seconds
Epoch 189 accuracy: 79.7%
Batch 10, Loss: 0.2580
Batch 20, Loss: 0.2151
Batch 30, Loss: 0.2502
Batch 40, Loss: 0.1955
Batch 50, Loss: 0.2606
Batch 60, Loss: 0.2361
Batch 70, Loss: 0.2188
Batch 80, Loss: 0.2992
Batch 90, Loss: 0.2580
Batch 100, Loss: 0.2553
Batch 110, Loss: 0.2397
Batch 120, Loss: 0.2423
Batch 130, Loss: 0.2191
Batch 140, Loss: 0.2547
Batch 150, Loss: 0.2700
Batch 160, Loss: 0.2769
Batch 170, Loss: 0.2777
Batch 180, Loss: 0.2482
Batch 190, Loss: 0.2508
Batch 200, Loss: 0.2483
Batch 210, Loss: 0.2466
Batch 220, Loss: 0.2380
Batch 230, Loss: 0.2421
Batch 240, Loss: 0.2348
Batch 250, Loss: 0.2266
Batch 260, Loss: 0.2914
Batch 270, Loss: 0.2595
Batch 280, Loss: 0.2553
Batch 290, Loss: 0.2426
Batch 300, Loss: 0.2520
Batch 310, Loss: 0.2422
Batch 320, Loss: 0.2541
Batch 330, Loss: 0.2422
Batch 340, Loss: 0.2597
Batch 350, Loss: 0.2647
Batch 360, Loss: 0.2434
Batch 370, Loss: 0.2475
Batch 380, Loss: 0.2564
Batch 390, Loss: 0.2457
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.330952405929565 seconds
Epoch 190 accuracy: 79.95%
Batch 10, Loss: 0.2340
Batch 20, Loss: 0.2328
Batch 30, Loss: 0.2099
Batch 40, Loss: 0.2237
Batch 50, Loss: 0.2350
Batch 60, Loss: 0.2800
Batch 70, Loss: 0.2291
Batch 80, Loss: 0.2395
Batch 90, Loss: 0.2330
Batch 100, Loss: 0.2572
Batch 110, Loss: 0.2260
Batch 120, Loss: 0.2379
Batch 130, Loss: 0.2650
Batch 140, Loss: 0.2584
Batch 150, Loss: 0.2018
Batch 160, Loss: 0.2479
Batch 170, Loss: 0.2635
Batch 180, Loss: 0.2151
Batch 190, Loss: 0.2538
Batch 200, Loss: 0.2427
Batch 210, Loss: 0.2709
Batch 220, Loss: 0.2087
Batch 230, Loss: 0.2475
Batch 240, Loss: 0.2593
Batch 250, Loss: 0.2262
Batch 260, Loss: 0.2448
Batch 270, Loss: 0.2427
Batch 280, Loss: 0.2113
Batch 290, Loss: 0.2412
Batch 300, Loss: 0.2598
Batch 310, Loss: 0.2677
Batch 320, Loss: 0.2508
Batch 330, Loss: 0.2492
Batch 340, Loss: 0.2151
Batch 350, Loss: 0.2380
Batch 360, Loss: 0.2550
Batch 370, Loss: 0.2792
Batch 380, Loss: 0.2504
Batch 390, Loss: 0.2316
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.269246339797974 seconds
Epoch 191 accuracy: 79.97%
Batch 10, Loss: 0.2344
Batch 20, Loss: 0.2346
Batch 30, Loss: 0.2495
Batch 40, Loss: 0.2323
Batch 50, Loss: 0.2326
Batch 60, Loss: 0.2405
Batch 70, Loss: 0.2301
Batch 80, Loss: 0.2540
Batch 90, Loss: 0.2525
Batch 100, Loss: 0.2482
Batch 110, Loss: 0.2408
Batch 120, Loss: 0.2266
Batch 130, Loss: 0.2483
Batch 140, Loss: 0.2032
Batch 150, Loss: 0.2354
Batch 160, Loss: 0.2293
Batch 170, Loss: 0.2558
Batch 180, Loss: 0.2584
Batch 190, Loss: 0.2656
Batch 200, Loss: 0.2371
Batch 210, Loss: 0.2506
Batch 220, Loss: 0.2261
Batch 230, Loss: 0.2589
Batch 240, Loss: 0.2587
Batch 250, Loss: 0.2704
Batch 260, Loss: 0.2762
Batch 270, Loss: 0.2480
Batch 280, Loss: 0.2276
Batch 290, Loss: 0.2213
Batch 300, Loss: 0.2287
Batch 310, Loss: 0.2316
Batch 320, Loss: 0.2428
Batch 330, Loss: 0.2476
Batch 340, Loss: 0.2415
Batch 350, Loss: 0.2304
Batch 360, Loss: 0.2222
Batch 370, Loss: 0.2732
Batch 380, Loss: 0.2842
Batch 390, Loss: 0.2564
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.201396942138672 seconds
Epoch 192 accuracy: 79.89%
Batch 10, Loss: 0.2354
Batch 20, Loss: 0.2321
Batch 30, Loss: 0.2492
Batch 40, Loss: 0.2302
Batch 50, Loss: 0.2419
Batch 60, Loss: 0.2179
Batch 70, Loss: 0.2479
Batch 80, Loss: 0.2516
Batch 90, Loss: 0.2481
Batch 100, Loss: 0.2596
Batch 110, Loss: 0.2453
Batch 120, Loss: 0.2877
Batch 130, Loss: 0.2275
Batch 140, Loss: 0.2550
Batch 150, Loss: 0.2683
Batch 160, Loss: 0.2216
Batch 170, Loss: 0.2444
Batch 180, Loss: 0.2533
Batch 190, Loss: 0.2245
Batch 200, Loss: 0.2592
Batch 210, Loss: 0.2527
Batch 220, Loss: 0.2519
Batch 230, Loss: 0.2534
Batch 240, Loss: 0.2466
Batch 250, Loss: 0.2384
Batch 260, Loss: 0.2307
Batch 270, Loss: 0.2773
Batch 280, Loss: 0.2353
Batch 290, Loss: 0.2527
Batch 300, Loss: 0.2532
Batch 310, Loss: 0.2176
Batch 320, Loss: 0.2330
Batch 330, Loss: 0.2374
Batch 340, Loss: 0.2339
Batch 350, Loss: 0.2589
Batch 360, Loss: 0.2495
Batch 370, Loss: 0.2188
Batch 380, Loss: 0.2197
Batch 390, Loss: 0.2555
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.284996271133423 seconds
Epoch 193 accuracy: 80.11%
Batch 10, Loss: 0.2255
Batch 20, Loss: 0.2350
Batch 30, Loss: 0.2616
Batch 40, Loss: 0.2333
Batch 50, Loss: 0.2575
Batch 60, Loss: 0.2740
Batch 70, Loss: 0.2233
Batch 80, Loss: 0.2397
Batch 90, Loss: 0.2401
Batch 100, Loss: 0.2057
Batch 110, Loss: 0.2253
Batch 120, Loss: 0.2268
Batch 130, Loss: 0.2247
Batch 140, Loss: 0.2580
Batch 150, Loss: 0.2460
Batch 160, Loss: 0.2572
Batch 170, Loss: 0.2573
Batch 180, Loss: 0.2339
Batch 190, Loss: 0.2222
Batch 200, Loss: 0.2180
Batch 210, Loss: 0.2423
Batch 220, Loss: 0.1909
Batch 230, Loss: 0.2223
Batch 240, Loss: 0.2682
Batch 250, Loss: 0.2262
Batch 260, Loss: 0.2394
Batch 270, Loss: 0.2366
Batch 280, Loss: 0.2512
Batch 290, Loss: 0.2180
Batch 300, Loss: 0.2591
Batch 310, Loss: 0.2427
Batch 320, Loss: 0.2650
Batch 330, Loss: 0.2330
Batch 340, Loss: 0.2153
Batch 350, Loss: 0.2428
Batch 360, Loss: 0.2759
Batch 370, Loss: 0.2297
Batch 380, Loss: 0.2193
Batch 390, Loss: 0.2558
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.372833728790283 seconds
Epoch 194 accuracy: 79.94%
Batch 10, Loss: 0.2518
Batch 20, Loss: 0.2173
Batch 30, Loss: 0.2279
Batch 40, Loss: 0.2520
Batch 50, Loss: 0.2388
Batch 60, Loss: 0.2193
Batch 70, Loss: 0.2318
Batch 80, Loss: 0.2147
Batch 90, Loss: 0.2394
Batch 100, Loss: 0.2400
Batch 110, Loss: 0.2542
Batch 120, Loss: 0.2507
Batch 130, Loss: 0.2300
Batch 140, Loss: 0.2032
Batch 150, Loss: 0.2305
Batch 160, Loss: 0.2483
Batch 170, Loss: 0.2603
Batch 180, Loss: 0.2070
Batch 190, Loss: 0.2289
Batch 200, Loss: 0.2235
Batch 210, Loss: 0.2354
Batch 220, Loss: 0.2533
Batch 230, Loss: 0.2411
Batch 240, Loss: 0.2746
Batch 250, Loss: 0.2203
Batch 260, Loss: 0.2345
Batch 270, Loss: 0.2603
Batch 280, Loss: 0.2526
Batch 290, Loss: 0.2310
Batch 300, Loss: 0.2396
Batch 310, Loss: 0.2147
Batch 320, Loss: 0.2395
Batch 330, Loss: 0.2212
Batch 340, Loss: 0.2157
Batch 350, Loss: 0.2145
Batch 360, Loss: 0.2401
Batch 370, Loss: 0.2284
Batch 380, Loss: 0.2186
Batch 390, Loss: 0.2114
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.355865955352783 seconds
Epoch 195 accuracy: 79.99%
Batch 10, Loss: 0.2384
Batch 20, Loss: 0.2252
Batch 30, Loss: 0.2280
Batch 40, Loss: 0.2505
Batch 50, Loss: 0.2322
Batch 60, Loss: 0.2347
Batch 70, Loss: 0.2205
Batch 80, Loss: 0.2680
Batch 90, Loss: 0.2475
Batch 100, Loss: 0.2166
Batch 110, Loss: 0.2635
Batch 120, Loss: 0.2533
Batch 130, Loss: 0.2243
Batch 140, Loss: 0.2522
Batch 150, Loss: 0.2353
Batch 160, Loss: 0.2150
Batch 170, Loss: 0.2722
Batch 180, Loss: 0.2501
Batch 190, Loss: 0.2377
Batch 200, Loss: 0.2387
Batch 210, Loss: 0.2556
Batch 220, Loss: 0.2327
Batch 230, Loss: 0.2430
Batch 240, Loss: 0.2197
Batch 250, Loss: 0.2299
Batch 260, Loss: 0.2425
Batch 270, Loss: 0.2323
Batch 280, Loss: 0.2104
Batch 290, Loss: 0.2308
Batch 300, Loss: 0.2323
Batch 310, Loss: 0.2263
Batch 320, Loss: 0.2639
Batch 330, Loss: 0.2455
Batch 340, Loss: 0.2344
Batch 350, Loss: 0.2096
Batch 360, Loss: 0.2369
Batch 370, Loss: 0.2484
Batch 380, Loss: 0.2315
Batch 390, Loss: 0.2117
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.262341499328613 seconds
Epoch 196 accuracy: 80.04%
Batch 10, Loss: 0.2342
Batch 20, Loss: 0.2462
Batch 30, Loss: 0.2316
Batch 40, Loss: 0.2609
Batch 50, Loss: 0.2341
Batch 60, Loss: 0.2223
Batch 70, Loss: 0.2302
Batch 80, Loss: 0.2224
Batch 90, Loss: 0.2185
Batch 100, Loss: 0.2491
Batch 110, Loss: 0.2433
Batch 120, Loss: 0.2276
Batch 130, Loss: 0.2329
Batch 140, Loss: 0.2567
Batch 150, Loss: 0.2128
Batch 160, Loss: 0.2158
Batch 170, Loss: 0.2404
Batch 180, Loss: 0.2506
Batch 190, Loss: 0.2450
Batch 200, Loss: 0.2262
Batch 210, Loss: 0.2393
Batch 220, Loss: 0.2212
Batch 230, Loss: 0.2207
Batch 240, Loss: 0.2094
Batch 250, Loss: 0.2590
Batch 260, Loss: 0.2456
Batch 270, Loss: 0.2502
Batch 280, Loss: 0.2129
Batch 290, Loss: 0.2324
Batch 300, Loss: 0.2403
Batch 310, Loss: 0.2655
Batch 320, Loss: 0.2262
Batch 330, Loss: 0.2378
Batch 340, Loss: 0.2380
Batch 350, Loss: 0.2265
Batch 360, Loss: 0.2070
Batch 370, Loss: 0.2484
Batch 380, Loss: 0.2344
Batch 390, Loss: 0.2393
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.3544340133667 seconds
Epoch 197 accuracy: 79.93%
Batch 10, Loss: 0.2287
Batch 20, Loss: 0.2446
Batch 30, Loss: 0.2752
Batch 40, Loss: 0.2103
Batch 50, Loss: 0.2188
Batch 60, Loss: 0.2077
Batch 70, Loss: 0.2549
Batch 80, Loss: 0.2136
Batch 90, Loss: 0.2405
Batch 100, Loss: 0.2246
Batch 110, Loss: 0.2492
Batch 120, Loss: 0.2170
Batch 130, Loss: 0.2369
Batch 140, Loss: 0.2224
Batch 150, Loss: 0.2335
Batch 160, Loss: 0.2143
Batch 170, Loss: 0.2487
Batch 180, Loss: 0.2474
Batch 190, Loss: 0.2371
Batch 200, Loss: 0.2238
Batch 210, Loss: 0.2389
Batch 220, Loss: 0.2300
Batch 230, Loss: 0.2396
Batch 240, Loss: 0.2203
Batch 250, Loss: 0.2579
Batch 260, Loss: 0.2383
Batch 270, Loss: 0.2943
Batch 280, Loss: 0.2367
Batch 290, Loss: 0.2439
Batch 300, Loss: 0.2696
Batch 310, Loss: 0.2420
Batch 320, Loss: 0.2437
Batch 330, Loss: 0.2238
Batch 340, Loss: 0.2194
Batch 350, Loss: 0.2248
Batch 360, Loss: 0.2807
Batch 370, Loss: 0.2071
Batch 380, Loss: 0.2330
Batch 390, Loss: 0.2312
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.293129205703735 seconds
Epoch 198 accuracy: 80.02%
Batch 10, Loss: 0.2854
Batch 20, Loss: 0.2587
Batch 30, Loss: 0.2500
Batch 40, Loss: 0.2183
Batch 50, Loss: 0.2472
Batch 60, Loss: 0.2232
Batch 70, Loss: 0.2291
Batch 80, Loss: 0.2281
Batch 90, Loss: 0.2283
Batch 100, Loss: 0.2319
Batch 110, Loss: 0.2338
Batch 120, Loss: 0.2285
Batch 130, Loss: 0.2201
Batch 140, Loss: 0.2627
Batch 150, Loss: 0.2218
Batch 160, Loss: 0.2183
Batch 170, Loss: 0.2325
Batch 180, Loss: 0.2458
Batch 190, Loss: 0.2397
Batch 200, Loss: 0.2268
Batch 210, Loss: 0.2768
Batch 220, Loss: 0.2602
Batch 230, Loss: 0.2242
Batch 240, Loss: 0.2415
Batch 250, Loss: 0.2516
Batch 260, Loss: 0.2088
Batch 270, Loss: 0.2506
Batch 280, Loss: 0.2380
Batch 290, Loss: 0.2457
Batch 300, Loss: 0.2066
Batch 310, Loss: 0.2654
Batch 320, Loss: 0.2319
Batch 330, Loss: 0.2460
Batch 340, Loss: 0.2156
Batch 350, Loss: 0.2648
Batch 360, Loss: 0.2174
Batch 370, Loss: 0.2200
Batch 380, Loss: 0.2241
Batch 390, Loss: 0.2196
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.25696587562561 seconds
Epoch 199 accuracy: 79.97%
Batch 10, Loss: 0.2446
Batch 20, Loss: 0.2320
Batch 30, Loss: 0.2213
Batch 40, Loss: 0.2550
Batch 50, Loss: 0.2355
Batch 60, Loss: 0.2129
Batch 70, Loss: 0.2350
Batch 80, Loss: 0.2383
Batch 90, Loss: 0.2440
Batch 100, Loss: 0.2384
Batch 110, Loss: 0.2368
Batch 120, Loss: 0.2395
Batch 130, Loss: 0.2289
Batch 140, Loss: 0.2513
Batch 150, Loss: 0.2391
Batch 160, Loss: 0.2643
Batch 170, Loss: 0.2297
Batch 180, Loss: 0.2528
Batch 190, Loss: 0.2214
Batch 200, Loss: 0.2463
Batch 210, Loss: 0.2477
Batch 220, Loss: 0.2057
Batch 230, Loss: 0.2298
Batch 240, Loss: 0.2136
Batch 250, Loss: 0.2546
Batch 260, Loss: 0.2393
Batch 270, Loss: 0.2377
Batch 280, Loss: 0.2383
Batch 290, Loss: 0.2411
Batch 300, Loss: 0.2344
Batch 310, Loss: 0.2242
Batch 320, Loss: 0.2418
Batch 330, Loss: 0.2285
Batch 340, Loss: 0.2375
Batch 350, Loss: 0.2301
Batch 360, Loss: 0.2566
Batch 370, Loss: 0.2411
Batch 380, Loss: 0.2183
Batch 390, Loss: 0.2202
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.223783254623413 seconds
Epoch 200 accuracy: 80.05%
Total training time: 5065.876859664917 seconds
