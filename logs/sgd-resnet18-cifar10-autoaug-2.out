The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 4.6629
Batch 20, Loss: 2.4741
Batch 30, Loss: 1.9404
Batch 40, Loss: 1.9155
Batch 50, Loss: 1.8262
Batch 60, Loss: 1.7889
Batch 70, Loss: 1.7672
Batch 80, Loss: 1.7716
Batch 90, Loss: 1.7740
Batch 100, Loss: 1.7159
Batch 110, Loss: 1.7030
Batch 120, Loss: 1.6810
Batch 130, Loss: 1.6829
Batch 140, Loss: 1.6850
Batch 150, Loss: 1.6653
Batch 160, Loss: 1.6741
Batch 170, Loss: 1.6600
Batch 180, Loss: 1.6320
Batch 190, Loss: 1.6511
Batch 200, Loss: 1.6169
Batch 210, Loss: 1.6216
Batch 220, Loss: 1.6192
Batch 230, Loss: 1.6103
Batch 240, Loss: 1.5932
Batch 250, Loss: 1.6096
Batch 260, Loss: 1.5900
Batch 270, Loss: 1.5658
Batch 280, Loss: 1.5794
Batch 290, Loss: 1.5593
Batch 300, Loss: 1.5271
Batch 310, Loss: 1.5732
Batch 320, Loss: 1.5485
Batch 330, Loss: 1.5487
Batch 340, Loss: 1.5580
Batch 350, Loss: 1.5337
Batch 360, Loss: 1.5452
Batch 370, Loss: 1.4916
Batch 380, Loss: 1.5456
Batch 390, Loss: 1.5092
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.152842044830322 seconds
Epoch 1 accuracy: 31.18%
Batch 10, Loss: 1.5143
Batch 20, Loss: 1.5121
Batch 30, Loss: 1.5046
Batch 40, Loss: 1.5131
Batch 50, Loss: 1.4995
Batch 60, Loss: 1.5251
Batch 70, Loss: 1.4730
Batch 80, Loss: 1.4835
Batch 90, Loss: 1.4485
Batch 100, Loss: 1.4892
Batch 110, Loss: 1.4417
Batch 120, Loss: 1.4573
Batch 130, Loss: 1.4733
Batch 140, Loss: 1.4841
Batch 150, Loss: 1.4111
Batch 160, Loss: 1.4651
Batch 170, Loss: 1.4339
Batch 180, Loss: 1.4253
Batch 190, Loss: 1.4191
Batch 200, Loss: 1.4269
Batch 210, Loss: 1.3839
Batch 220, Loss: 1.4175
Batch 230, Loss: 1.4022
Batch 240, Loss: 1.4253
Batch 250, Loss: 1.3944
Batch 260, Loss: 1.3995
Batch 270, Loss: 1.4385
Batch 280, Loss: 1.4156
Batch 290, Loss: 1.4417
Batch 300, Loss: 1.4044
Batch 310, Loss: 1.4189
Batch 320, Loss: 1.4324
Batch 330, Loss: 1.3995
Batch 340, Loss: 1.3970
Batch 350, Loss: 1.3798
Batch 360, Loss: 1.3947
Batch 370, Loss: 1.3697
Batch 380, Loss: 1.3778
Batch 390, Loss: 1.3851
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.093522787094116 seconds
Epoch 2 accuracy: 41.67%
Batch 10, Loss: 1.3362
Batch 20, Loss: 1.3496
Batch 30, Loss: 1.3766
Batch 40, Loss: 1.3652
Batch 50, Loss: 1.3932
Batch 60, Loss: 1.3382
Batch 70, Loss: 1.3610
Batch 80, Loss: 1.3525
Batch 90, Loss: 1.3825
Batch 100, Loss: 1.3112
Batch 110, Loss: 1.3322
Batch 120, Loss: 1.3169
Batch 130, Loss: 1.3549
Batch 140, Loss: 1.3429
Batch 150, Loss: 1.2780
Batch 160, Loss: 1.3232
Batch 170, Loss: 1.3144
Batch 180, Loss: 1.3031
Batch 190, Loss: 1.2878
Batch 200, Loss: 1.2552
Batch 210, Loss: 1.2671
Batch 220, Loss: 1.3108
Batch 230, Loss: 1.3265
Batch 240, Loss: 1.2701
Batch 250, Loss: 1.2777
Batch 260, Loss: 1.2904
Batch 270, Loss: 1.3066
Batch 280, Loss: 1.2856
Batch 290, Loss: 1.2822
Batch 300, Loss: 1.2764
Batch 310, Loss: 1.2818
Batch 320, Loss: 1.2326
Batch 330, Loss: 1.2230
Batch 340, Loss: 1.2927
Batch 350, Loss: 1.2606
Batch 360, Loss: 1.2315
Batch 370, Loss: 1.2994
Batch 380, Loss: 1.2603
Batch 390, Loss: 1.2782
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.071399927139282 seconds
Epoch 3 accuracy: 48.77%
Batch 10, Loss: 1.2267
Batch 20, Loss: 1.2387
Batch 30, Loss: 1.2226
Batch 40, Loss: 1.2094
Batch 50, Loss: 1.2162
Batch 60, Loss: 1.2526
Batch 70, Loss: 1.1994
Batch 80, Loss: 1.1980
Batch 90, Loss: 1.2591
Batch 100, Loss: 1.2313
Batch 110, Loss: 1.1744
Batch 120, Loss: 1.2091
Batch 130, Loss: 1.1408
Batch 140, Loss: 1.1626
Batch 150, Loss: 1.1643
Batch 160, Loss: 1.1619
Batch 170, Loss: 1.1441
Batch 180, Loss: 1.2439
Batch 190, Loss: 1.2525
Batch 200, Loss: 1.1555
Batch 210, Loss: 1.1660
Batch 220, Loss: 1.1543
Batch 230, Loss: 1.1407
Batch 240, Loss: 1.0840
Batch 250, Loss: 1.1960
Batch 260, Loss: 1.1642
Batch 270, Loss: 1.0953
Batch 280, Loss: 1.1072
Batch 290, Loss: 1.1343
Batch 300, Loss: 1.1652
Batch 310, Loss: 1.1935
Batch 320, Loss: 1.1768
Batch 330, Loss: 1.1418
Batch 340, Loss: 1.1642
Batch 350, Loss: 1.1395
Batch 360, Loss: 1.1434
Batch 370, Loss: 1.1222
Batch 380, Loss: 1.1003
Batch 390, Loss: 1.1331
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.13288903236389 seconds
Epoch 4 accuracy: 58.47%
Batch 10, Loss: 1.0707
Batch 20, Loss: 1.0944
Batch 30, Loss: 1.1691
Batch 40, Loss: 1.1233
Batch 50, Loss: 1.1265
Batch 60, Loss: 1.1573
Batch 70, Loss: 1.1092
Batch 80, Loss: 1.1266
Batch 90, Loss: 1.0900
Batch 100, Loss: 1.0992
Batch 110, Loss: 1.0767
Batch 120, Loss: 1.0922
Batch 130, Loss: 1.1234
Batch 140, Loss: 1.0835
Batch 150, Loss: 1.0987
Batch 160, Loss: 1.0984
Batch 170, Loss: 1.0693
Batch 180, Loss: 1.0918
Batch 190, Loss: 1.0247
Batch 200, Loss: 1.0509
Batch 210, Loss: 1.0973
Batch 220, Loss: 1.0774
Batch 230, Loss: 1.0569
Batch 240, Loss: 1.1023
Batch 250, Loss: 1.0638
Batch 260, Loss: 1.0809
Batch 270, Loss: 1.0497
Batch 280, Loss: 1.0008
Batch 290, Loss: 1.0683
Batch 300, Loss: 1.0977
Batch 310, Loss: 1.0613
Batch 320, Loss: 1.0272
Batch 330, Loss: 1.0437
Batch 340, Loss: 1.0929
Batch 350, Loss: 1.0662
Batch 360, Loss: 1.0370
Batch 370, Loss: 1.0426
Batch 380, Loss: 1.0217
Batch 390, Loss: 1.0427
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.055957794189453 seconds
Epoch 5 accuracy: 59.23%
Batch 10, Loss: 1.0599
Batch 20, Loss: 0.9901
Batch 30, Loss: 1.0236
Batch 40, Loss: 0.9978
Batch 50, Loss: 1.0261
Batch 60, Loss: 1.0010
Batch 70, Loss: 0.9842
Batch 80, Loss: 0.9831
Batch 90, Loss: 0.9995
Batch 100, Loss: 1.0273
Batch 110, Loss: 0.9807
Batch 120, Loss: 1.0313
Batch 130, Loss: 0.9819
Batch 140, Loss: 1.0110
Batch 150, Loss: 1.0377
Batch 160, Loss: 1.0314
Batch 170, Loss: 0.9729
Batch 180, Loss: 1.0068
Batch 190, Loss: 1.0097
Batch 200, Loss: 1.0153
Batch 210, Loss: 1.0316
Batch 220, Loss: 0.9811
Batch 230, Loss: 0.9610
Batch 240, Loss: 0.9946
Batch 250, Loss: 0.9864
Batch 260, Loss: 0.9523
Batch 270, Loss: 0.9973
Batch 280, Loss: 1.0151
Batch 290, Loss: 0.9652
Batch 300, Loss: 0.9932
Batch 310, Loss: 1.0033
Batch 320, Loss: 0.9575
Batch 330, Loss: 0.9950
Batch 340, Loss: 0.9867
Batch 350, Loss: 0.9902
Batch 360, Loss: 0.9949
Batch 370, Loss: 0.9827
Batch 380, Loss: 0.9401
Batch 390, Loss: 0.9886
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.10004162788391 seconds
Epoch 6 accuracy: 60.93%
Batch 10, Loss: 0.9720
Batch 20, Loss: 0.9313
Batch 30, Loss: 0.9283
Batch 40, Loss: 0.9690
Batch 50, Loss: 0.9972
Batch 60, Loss: 0.9656
Batch 70, Loss: 0.9322
Batch 80, Loss: 0.9659
Batch 90, Loss: 0.9048
Batch 100, Loss: 0.9669
Batch 110, Loss: 0.9944
Batch 120, Loss: 0.9015
Batch 130, Loss: 0.9395
Batch 140, Loss: 0.9365
Batch 150, Loss: 0.9695
Batch 160, Loss: 0.9595
Batch 170, Loss: 0.9752
Batch 180, Loss: 0.9481
Batch 190, Loss: 0.9438
Batch 200, Loss: 0.9266
Batch 210, Loss: 0.9359
Batch 220, Loss: 0.9129
Batch 230, Loss: 0.8894
Batch 240, Loss: 0.9306
Batch 250, Loss: 0.9552
Batch 260, Loss: 0.9763
Batch 270, Loss: 0.9866
Batch 280, Loss: 0.9079
Batch 290, Loss: 0.9158
Batch 300, Loss: 0.8919
Batch 310, Loss: 0.8629
Batch 320, Loss: 0.8680
Batch 330, Loss: 0.9124
Batch 340, Loss: 0.9471
Batch 350, Loss: 0.8944
Batch 360, Loss: 0.8787
Batch 370, Loss: 0.9027
Batch 380, Loss: 0.9077
Batch 390, Loss: 0.8666
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.096192359924316 seconds
Epoch 7 accuracy: 63.6%
Batch 10, Loss: 0.9128
Batch 20, Loss: 0.9154
Batch 30, Loss: 0.9477
Batch 40, Loss: 0.8789
Batch 50, Loss: 0.9346
Batch 60, Loss: 0.9181
Batch 70, Loss: 0.9071
Batch 80, Loss: 0.9194
Batch 90, Loss: 0.8399
Batch 100, Loss: 0.8851
Batch 110, Loss: 0.8523
Batch 120, Loss: 0.8867
Batch 130, Loss: 0.8677
Batch 140, Loss: 0.8830
Batch 150, Loss: 0.8963
Batch 160, Loss: 0.9118
Batch 170, Loss: 0.9335
Batch 180, Loss: 0.8537
Batch 190, Loss: 0.8968
Batch 200, Loss: 0.8718
Batch 210, Loss: 0.8501
Batch 220, Loss: 0.8858
Batch 230, Loss: 0.9016
Batch 240, Loss: 0.8706
Batch 250, Loss: 0.8868
Batch 260, Loss: 0.9010
Batch 270, Loss: 0.8532
Batch 280, Loss: 0.8956
Batch 290, Loss: 0.8549
Batch 300, Loss: 0.8145
Batch 310, Loss: 0.8410
Batch 320, Loss: 0.8740
Batch 330, Loss: 0.8991
Batch 340, Loss: 0.8746
Batch 350, Loss: 0.8680
Batch 360, Loss: 0.8524
Batch 370, Loss: 0.8611
Batch 380, Loss: 0.8653
Batch 390, Loss: 0.8439
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.081581354141235 seconds
Epoch 8 accuracy: 71.01%
Batch 10, Loss: 0.8591
Batch 20, Loss: 0.8692
Batch 30, Loss: 0.8292
Batch 40, Loss: 0.8442
Batch 50, Loss: 0.8387
Batch 60, Loss: 0.9056
Batch 70, Loss: 0.8084
Batch 80, Loss: 0.8424
Batch 90, Loss: 0.8330
Batch 100, Loss: 0.8388
Batch 110, Loss: 0.8366
Batch 120, Loss: 0.8455
Batch 130, Loss: 0.7877
Batch 140, Loss: 0.8553
Batch 150, Loss: 0.8165
Batch 160, Loss: 0.8548
Batch 170, Loss: 0.8448
Batch 180, Loss: 0.7811
Batch 190, Loss: 0.8082
Batch 200, Loss: 0.8500
Batch 210, Loss: 0.8247
Batch 220, Loss: 0.8329
Batch 230, Loss: 0.8836
Batch 240, Loss: 0.8185
Batch 250, Loss: 0.7805
Batch 260, Loss: 0.7882
Batch 270, Loss: 0.8248
Batch 280, Loss: 0.8412
Batch 290, Loss: 0.8174
Batch 300, Loss: 0.8332
Batch 310, Loss: 0.7778
Batch 320, Loss: 0.8116
Batch 330, Loss: 0.8315
Batch 340, Loss: 0.7997
Batch 350, Loss: 0.7966
Batch 360, Loss: 0.8069
Batch 370, Loss: 0.8079
Batch 380, Loss: 0.7806
Batch 390, Loss: 0.7896
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.045230388641357 seconds
Epoch 9 accuracy: 66.56%
Batch 10, Loss: 0.8151
Batch 20, Loss: 0.7813
Batch 30, Loss: 0.7652
Batch 40, Loss: 0.8342
Batch 50, Loss: 0.7555
Batch 60, Loss: 0.8351
Batch 70, Loss: 0.7955
Batch 80, Loss: 0.8098
Batch 90, Loss: 0.7895
Batch 100, Loss: 0.8128
Batch 110, Loss: 0.7817
Batch 120, Loss: 0.7999
Batch 130, Loss: 0.7975
Batch 140, Loss: 0.8475
Batch 150, Loss: 0.7789
Batch 160, Loss: 0.8017
Batch 170, Loss: 0.8031
Batch 180, Loss: 0.8359
Batch 190, Loss: 0.7970
Batch 200, Loss: 0.7717
Batch 210, Loss: 0.7656
Batch 220, Loss: 0.7863
Batch 230, Loss: 0.7961
Batch 240, Loss: 0.7507
Batch 250, Loss: 0.8468
Batch 260, Loss: 0.8148
Batch 270, Loss: 0.7866
Batch 280, Loss: 0.8039
Batch 290, Loss: 0.7987
Batch 300, Loss: 0.8194
Batch 310, Loss: 0.7623
Batch 320, Loss: 0.7559
Batch 330, Loss: 0.7935
Batch 340, Loss: 0.7794
Batch 350, Loss: 0.7590
Batch 360, Loss: 0.7357
Batch 370, Loss: 0.7708
Batch 380, Loss: 0.7971
Batch 390, Loss: 0.7569
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.030874490737915 seconds
Epoch 10 accuracy: 70.34%
Batch 10, Loss: 0.7851
Batch 20, Loss: 0.8329
Batch 30, Loss: 0.8179
Batch 40, Loss: 0.8003
Batch 50, Loss: 0.7545
Batch 60, Loss: 0.7634
Batch 70, Loss: 0.7511
Batch 80, Loss: 0.7404
Batch 90, Loss: 0.7793
Batch 100, Loss: 0.7699
Batch 110, Loss: 0.8368
Batch 120, Loss: 0.7710
Batch 130, Loss: 0.7920
Batch 140, Loss: 0.7371
Batch 150, Loss: 0.7262
Batch 160, Loss: 0.7658
Batch 170, Loss: 0.7532
Batch 180, Loss: 0.8008
Batch 190, Loss: 0.7580
Batch 200, Loss: 0.7320
Batch 210, Loss: 0.7759
Batch 220, Loss: 0.7619
Batch 230, Loss: 0.7640
Batch 240, Loss: 0.7236
Batch 250, Loss: 0.7819
Batch 260, Loss: 0.7323
Batch 270, Loss: 0.8061
Batch 280, Loss: 0.7603
Batch 290, Loss: 0.7315
Batch 300, Loss: 0.7248
Batch 310, Loss: 0.7856
Batch 320, Loss: 0.7733
Batch 330, Loss: 0.7698
Batch 340, Loss: 0.7280
Batch 350, Loss: 0.7669
Batch 360, Loss: 0.7435
Batch 370, Loss: 0.7152
Batch 380, Loss: 0.7459
Batch 390, Loss: 0.7431
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.08807635307312 seconds
Epoch 11 accuracy: 65.03%
Batch 10, Loss: 0.7510
Batch 20, Loss: 0.7998
Batch 30, Loss: 0.7511
Batch 40, Loss: 0.7585
Batch 50, Loss: 0.7822
Batch 60, Loss: 0.7478
Batch 70, Loss: 0.7172
Batch 80, Loss: 0.7101
Batch 90, Loss: 0.7011
Batch 100, Loss: 0.7101
Batch 110, Loss: 0.7295
Batch 120, Loss: 0.7800
Batch 130, Loss: 0.7733
Batch 140, Loss: 0.7426
Batch 150, Loss: 0.7487
Batch 160, Loss: 0.7174
Batch 170, Loss: 0.7527
Batch 180, Loss: 0.7073
Batch 190, Loss: 0.7437
Batch 200, Loss: 0.7677
Batch 210, Loss: 0.7465
Batch 220, Loss: 0.7398
Batch 230, Loss: 0.7354
Batch 240, Loss: 0.7598
Batch 250, Loss: 0.7512
Batch 260, Loss: 0.7527
Batch 270, Loss: 0.7013
Batch 280, Loss: 0.7236
Batch 290, Loss: 0.7728
Batch 300, Loss: 0.7626
Batch 310, Loss: 0.7130
Batch 320, Loss: 0.7068
Batch 330, Loss: 0.7447
Batch 340, Loss: 0.7738
Batch 350, Loss: 0.7207
Batch 360, Loss: 0.7303
Batch 370, Loss: 0.7235
Batch 380, Loss: 0.7341
Batch 390, Loss: 0.7265
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.05887746810913 seconds
Epoch 12 accuracy: 76.17%
Batch 10, Loss: 0.7075
Batch 20, Loss: 0.7036
Batch 30, Loss: 0.7534
Batch 40, Loss: 0.7058
Batch 50, Loss: 0.7034
Batch 60, Loss: 0.7070
Batch 70, Loss: 0.7040
Batch 80, Loss: 0.7267
Batch 90, Loss: 0.7197
Batch 100, Loss: 0.6928
Batch 110, Loss: 0.7430
Batch 120, Loss: 0.7223
Batch 130, Loss: 0.7589
Batch 140, Loss: 0.7224
Batch 150, Loss: 0.7114
Batch 160, Loss: 0.7467
Batch 170, Loss: 0.7240
Batch 180, Loss: 0.6924
Batch 190, Loss: 0.7195
Batch 200, Loss: 0.7348
Batch 210, Loss: 0.6693
Batch 220, Loss: 0.7344
Batch 230, Loss: 0.6929
Batch 240, Loss: 0.7082
Batch 250, Loss: 0.7353
Batch 260, Loss: 0.7601
Batch 270, Loss: 0.7092
Batch 280, Loss: 0.7183
Batch 290, Loss: 0.6895
Batch 300, Loss: 0.7181
Batch 310, Loss: 0.7381
Batch 320, Loss: 0.7122
Batch 330, Loss: 0.7394
Batch 340, Loss: 0.7064
Batch 350, Loss: 0.7408
Batch 360, Loss: 0.7145
Batch 370, Loss: 0.7141
Batch 380, Loss: 0.6866
Batch 390, Loss: 0.6698
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.02413773536682 seconds
Epoch 13 accuracy: 79.2%
Batch 10, Loss: 0.7099
Batch 20, Loss: 0.7500
Batch 30, Loss: 0.7188
Batch 40, Loss: 0.7040
Batch 50, Loss: 0.6723
Batch 60, Loss: 0.7358
Batch 70, Loss: 0.7392
Batch 80, Loss: 0.6856
Batch 90, Loss: 0.7087
Batch 100, Loss: 0.7300
Batch 110, Loss: 0.7315
Batch 120, Loss: 0.6687
Batch 130, Loss: 0.7414
Batch 140, Loss: 0.6671
Batch 150, Loss: 0.7355
Batch 160, Loss: 0.7180
Batch 170, Loss: 0.7167
Batch 180, Loss: 0.7169
Batch 190, Loss: 0.7302
Batch 200, Loss: 0.7238
Batch 210, Loss: 0.6829
Batch 220, Loss: 0.6902
Batch 230, Loss: 0.7396
Batch 240, Loss: 0.7201
Batch 250, Loss: 0.6700
Batch 260, Loss: 0.7020
Batch 270, Loss: 0.6962
Batch 280, Loss: 0.6933
Batch 290, Loss: 0.6936
Batch 300, Loss: 0.6862
Batch 310, Loss: 0.7295
Batch 320, Loss: 0.7188
Batch 330, Loss: 0.6949
Batch 340, Loss: 0.6805
Batch 350, Loss: 0.7423
Batch 360, Loss: 0.7260
Batch 370, Loss: 0.7344
Batch 380, Loss: 0.7298
Batch 390, Loss: 0.6744
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.027623176574707 seconds
Epoch 14 accuracy: 74.7%
Batch 10, Loss: 0.7046
Batch 20, Loss: 0.7152
Batch 30, Loss: 0.7018
Batch 40, Loss: 0.6882
Batch 50, Loss: 0.6593
Batch 60, Loss: 0.6812
Batch 70, Loss: 0.7001
Batch 80, Loss: 0.7428
Batch 90, Loss: 0.6892
Batch 100, Loss: 0.6979
Batch 110, Loss: 0.7204
Batch 120, Loss: 0.6929
Batch 130, Loss: 0.6799
Batch 140, Loss: 0.6800
Batch 150, Loss: 0.6817
Batch 160, Loss: 0.6760
Batch 170, Loss: 0.6694
Batch 180, Loss: 0.7011
Batch 190, Loss: 0.7108
Batch 200, Loss: 0.7322
Batch 210, Loss: 0.6964
Batch 220, Loss: 0.6804
Batch 230, Loss: 0.6726
Batch 240, Loss: 0.6577
Batch 250, Loss: 0.6284
Batch 260, Loss: 0.6758
Batch 270, Loss: 0.7173
Batch 280, Loss: 0.6909
Batch 290, Loss: 0.7052
Batch 300, Loss: 0.6677
Batch 310, Loss: 0.6713
Batch 320, Loss: 0.6571
Batch 330, Loss: 0.7064
Batch 340, Loss: 0.6591
Batch 350, Loss: 0.6715
Batch 360, Loss: 0.7173
Batch 370, Loss: 0.7025
Batch 380, Loss: 0.6937
Batch 390, Loss: 0.6841
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.07099986076355 seconds
Epoch 15 accuracy: 76.17%
Batch 10, Loss: 0.6343
Batch 20, Loss: 0.7163
Batch 30, Loss: 0.6350
Batch 40, Loss: 0.6462
Batch 50, Loss: 0.6655
Batch 60, Loss: 0.6836
Batch 70, Loss: 0.6804
Batch 80, Loss: 0.6808
Batch 90, Loss: 0.6675
Batch 100, Loss: 0.6548
Batch 110, Loss: 0.6957
Batch 120, Loss: 0.7113
Batch 130, Loss: 0.7147
Batch 140, Loss: 0.6509
Batch 150, Loss: 0.7007
Batch 160, Loss: 0.6621
Batch 170, Loss: 0.6958
Batch 180, Loss: 0.6862
Batch 190, Loss: 0.6924
Batch 200, Loss: 0.6875
Batch 210, Loss: 0.6918
Batch 220, Loss: 0.6654
Batch 230, Loss: 0.6609
Batch 240, Loss: 0.6604
Batch 250, Loss: 0.6799
Batch 260, Loss: 0.6436
Batch 270, Loss: 0.6676
Batch 280, Loss: 0.7166
Batch 290, Loss: 0.6398
Batch 300, Loss: 0.6561
Batch 310, Loss: 0.6425
Batch 320, Loss: 0.6789
Batch 330, Loss: 0.6862
Batch 340, Loss: 0.6988
Batch 350, Loss: 0.7173
Batch 360, Loss: 0.7077
Batch 370, Loss: 0.6691
Batch 380, Loss: 0.6608
Batch 390, Loss: 0.6865
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.03818964958191 seconds
Epoch 16 accuracy: 76.33%
Batch 10, Loss: 0.6737
Batch 20, Loss: 0.6774
Batch 30, Loss: 0.6944
Batch 40, Loss: 0.6481
Batch 50, Loss: 0.6732
Batch 60, Loss: 0.6810
Batch 70, Loss: 0.7039
Batch 80, Loss: 0.6376
Batch 90, Loss: 0.6264
Batch 100, Loss: 0.6364
Batch 110, Loss: 0.6798
Batch 120, Loss: 0.7165
Batch 130, Loss: 0.6977
Batch 140, Loss: 0.6521
Batch 150, Loss: 0.6246
Batch 160, Loss: 0.7235
Batch 170, Loss: 0.6964
Batch 180, Loss: 0.6512
Batch 190, Loss: 0.6359
Batch 200, Loss: 0.6316
Batch 210, Loss: 0.6789
Batch 220, Loss: 0.6646
Batch 230, Loss: 0.6890
Batch 240, Loss: 0.6403
Batch 250, Loss: 0.6168
Batch 260, Loss: 0.7172
Batch 270, Loss: 0.6466
Batch 280, Loss: 0.6514
Batch 290, Loss: 0.6288
Batch 300, Loss: 0.6967
Batch 310, Loss: 0.6687
Batch 320, Loss: 0.6601
Batch 330, Loss: 0.6982
Batch 340, Loss: 0.6417
Batch 350, Loss: 0.6388
Batch 360, Loss: 0.6611
Batch 370, Loss: 0.6688
Batch 380, Loss: 0.6484
Batch 390, Loss: 0.6449
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.049478769302368 seconds
Epoch 17 accuracy: 78.06%
Batch 10, Loss: 0.6763
Batch 20, Loss: 0.6674
Batch 30, Loss: 0.6853
Batch 40, Loss: 0.6869
Batch 50, Loss: 0.6763
Batch 60, Loss: 0.6813
Batch 70, Loss: 0.6566
Batch 80, Loss: 0.6217
Batch 90, Loss: 0.6325
Batch 100, Loss: 0.6186
Batch 110, Loss: 0.6870
Batch 120, Loss: 0.6370
Batch 130, Loss: 0.6785
Batch 140, Loss: 0.6500
Batch 150, Loss: 0.6683
Batch 160, Loss: 0.6729
Batch 170, Loss: 0.6513
Batch 180, Loss: 0.6441
Batch 190, Loss: 0.6536
Batch 200, Loss: 0.6509
Batch 210, Loss: 0.6701
Batch 220, Loss: 0.6231
Batch 230, Loss: 0.6211
Batch 240, Loss: 0.6699
Batch 250, Loss: 0.6555
Batch 260, Loss: 0.6285
Batch 270, Loss: 0.6971
Batch 280, Loss: 0.6635
Batch 290, Loss: 0.6554
Batch 300, Loss: 0.6550
Batch 310, Loss: 0.6605
Batch 320, Loss: 0.6628
Batch 330, Loss: 0.6764
Batch 340, Loss: 0.6469
Batch 350, Loss: 0.6292
Batch 360, Loss: 0.6224
Batch 370, Loss: 0.6504
Batch 380, Loss: 0.6564
Batch 390, Loss: 0.6345
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.03797197341919 seconds
Epoch 18 accuracy: 80.81%
Batch 10, Loss: 0.6253
Batch 20, Loss: 0.6403
Batch 30, Loss: 0.6187
Batch 40, Loss: 0.6415
Batch 50, Loss: 0.6654
Batch 60, Loss: 0.6270
Batch 70, Loss: 0.5831
Batch 80, Loss: 0.6772
Batch 90, Loss: 0.6414
Batch 100, Loss: 0.6218
Batch 110, Loss: 0.5772
Batch 120, Loss: 0.6243
Batch 130, Loss: 0.6609
Batch 140, Loss: 0.5947
Batch 150, Loss: 0.6299
Batch 160, Loss: 0.6303
Batch 170, Loss: 0.6594
Batch 180, Loss: 0.6722
Batch 190, Loss: 0.6733
Batch 200, Loss: 0.6227
Batch 210, Loss: 0.6249
Batch 220, Loss: 0.6459
Batch 230, Loss: 0.6669
Batch 240, Loss: 0.6524
Batch 250, Loss: 0.6025
Batch 260, Loss: 0.6569
Batch 270, Loss: 0.5996
Batch 280, Loss: 0.6386
Batch 290, Loss: 0.6253
Batch 300, Loss: 0.6278
Batch 310, Loss: 0.6500
Batch 320, Loss: 0.6252
Batch 330, Loss: 0.6224
Batch 340, Loss: 0.6638
Batch 350, Loss: 0.6733
Batch 360, Loss: 0.7080
Batch 370, Loss: 0.6436
Batch 380, Loss: 0.6356
Batch 390, Loss: 0.6704
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.000182628631592 seconds
Epoch 19 accuracy: 81.74%
Batch 10, Loss: 0.6219
Batch 20, Loss: 0.6195
Batch 30, Loss: 0.6556
Batch 40, Loss: 0.6198
Batch 50, Loss: 0.6279
Batch 60, Loss: 0.6529
Batch 70, Loss: 0.6411
Batch 80, Loss: 0.6486
Batch 90, Loss: 0.6636
Batch 100, Loss: 0.6355
Batch 110, Loss: 0.6361
Batch 120, Loss: 0.6702
Batch 130, Loss: 0.6296
Batch 140, Loss: 0.6406
Batch 150, Loss: 0.6184
Batch 160, Loss: 0.6602
Batch 170, Loss: 0.6326
Batch 180, Loss: 0.6575
Batch 190, Loss: 0.6498
Batch 200, Loss: 0.6736
Batch 210, Loss: 0.6652
Batch 220, Loss: 0.6357
Batch 230, Loss: 0.6621
Batch 240, Loss: 0.6959
Batch 250, Loss: 0.6450
Batch 260, Loss: 0.6197
Batch 270, Loss: 0.6196
Batch 280, Loss: 0.6277
Batch 290, Loss: 0.6249
Batch 300, Loss: 0.6680
Batch 310, Loss: 0.6519
Batch 320, Loss: 0.6446
Batch 330, Loss: 0.6335
Batch 340, Loss: 0.6281
Batch 350, Loss: 0.6319
Batch 360, Loss: 0.6567
Batch 370, Loss: 0.6426
Batch 380, Loss: 0.7174
Batch 390, Loss: 0.6206
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.03847622871399 seconds
Epoch 20 accuracy: 78.4%
Batch 10, Loss: 0.6293
Batch 20, Loss: 0.6495
Batch 30, Loss: 0.5893
Batch 40, Loss: 0.6135
Batch 50, Loss: 0.6069
Batch 60, Loss: 0.6070
Batch 70, Loss: 0.5949
Batch 80, Loss: 0.5914
Batch 90, Loss: 0.6568
Batch 100, Loss: 0.6240
Batch 110, Loss: 0.6281
Batch 120, Loss: 0.6256
Batch 130, Loss: 0.6056
Batch 140, Loss: 0.6532
Batch 150, Loss: 0.6687
Batch 160, Loss: 0.6483
Batch 170, Loss: 0.6536
Batch 180, Loss: 0.6040
Batch 190, Loss: 0.6156
Batch 200, Loss: 0.6859
Batch 210, Loss: 0.6512
Batch 220, Loss: 0.6222
Batch 230, Loss: 0.6179
Batch 240, Loss: 0.6268
Batch 250, Loss: 0.6201
Batch 260, Loss: 0.6484
Batch 270, Loss: 0.6338
Batch 280, Loss: 0.6159
Batch 290, Loss: 0.6074
Batch 300, Loss: 0.6274
Batch 310, Loss: 0.6181
Batch 320, Loss: 0.5933
Batch 330, Loss: 0.6385
Batch 340, Loss: 0.6523
Batch 350, Loss: 0.6604
Batch 360, Loss: 0.6645
Batch 370, Loss: 0.6502
Batch 380, Loss: 0.6267
Batch 390, Loss: 0.6208
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.076186418533325 seconds
Epoch 21 accuracy: 75.24%
Batch 10, Loss: 0.5813
Batch 20, Loss: 0.6477
Batch 30, Loss: 0.6149
Batch 40, Loss: 0.6262
Batch 50, Loss: 0.6420
Batch 60, Loss: 0.6240
Batch 70, Loss: 0.5876
Batch 80, Loss: 0.6480
Batch 90, Loss: 0.6079
Batch 100, Loss: 0.5853
Batch 110, Loss: 0.5762
Batch 120, Loss: 0.5842
Batch 130, Loss: 0.6394
Batch 140, Loss: 0.6662
Batch 150, Loss: 0.6074
Batch 160, Loss: 0.6216
Batch 170, Loss: 0.6119
Batch 180, Loss: 0.6477
Batch 190, Loss: 0.6114
Batch 200, Loss: 0.6134
Batch 210, Loss: 0.6419
Batch 220, Loss: 0.6042
Batch 230, Loss: 0.6079
Batch 240, Loss: 0.6162
Batch 250, Loss: 0.5925
Batch 260, Loss: 0.6204
Batch 270, Loss: 0.6516
Batch 280, Loss: 0.6679
Batch 290, Loss: 0.6179
Batch 300, Loss: 0.5921
Batch 310, Loss: 0.5724
Batch 320, Loss: 0.6022
Batch 330, Loss: 0.6448
Batch 340, Loss: 0.5943
Batch 350, Loss: 0.6544
Batch 360, Loss: 0.6426
Batch 370, Loss: 0.5602
Batch 380, Loss: 0.6261
Batch 390, Loss: 0.6097
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.07351589202881 seconds
Epoch 22 accuracy: 81.11%
Batch 10, Loss: 0.6190
Batch 20, Loss: 0.5955
Batch 30, Loss: 0.6815
Batch 40, Loss: 0.6275
Batch 50, Loss: 0.6031
Batch 60, Loss: 0.6197
Batch 70, Loss: 0.6064
Batch 80, Loss: 0.6267
Batch 90, Loss: 0.6469
Batch 100, Loss: 0.6085
Batch 110, Loss: 0.5986
Batch 120, Loss: 0.5837
Batch 130, Loss: 0.5696
Batch 140, Loss: 0.5981
Batch 150, Loss: 0.6097
Batch 160, Loss: 0.6698
Batch 170, Loss: 0.6073
Batch 180, Loss: 0.6131
Batch 190, Loss: 0.6002
Batch 200, Loss: 0.5974
Batch 210, Loss: 0.6771
Batch 220, Loss: 0.6388
Batch 230, Loss: 0.5739
Batch 240, Loss: 0.6123
Batch 250, Loss: 0.5738
Batch 260, Loss: 0.5953
Batch 270, Loss: 0.6070
Batch 280, Loss: 0.5954
Batch 290, Loss: 0.6110
Batch 300, Loss: 0.6652
Batch 310, Loss: 0.6270
Batch 320, Loss: 0.6050
Batch 330, Loss: 0.5894
Batch 340, Loss: 0.6526
Batch 350, Loss: 0.6013
Batch 360, Loss: 0.5947
Batch 370, Loss: 0.6016
Batch 380, Loss: 0.6111
Batch 390, Loss: 0.6330
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.08914351463318 seconds
Epoch 23 accuracy: 79.6%
Batch 10, Loss: 0.6490
Batch 20, Loss: 0.6218
Batch 30, Loss: 0.5905
Batch 40, Loss: 0.6187
Batch 50, Loss: 0.6255
Batch 60, Loss: 0.5981
Batch 70, Loss: 0.6081
Batch 80, Loss: 0.5974
Batch 90, Loss: 0.6102
Batch 100, Loss: 0.6205
Batch 110, Loss: 0.6277
Batch 120, Loss: 0.6222
Batch 130, Loss: 0.6356
Batch 140, Loss: 0.5982
Batch 150, Loss: 0.6082
Batch 160, Loss: 0.5962
Batch 170, Loss: 0.6209
Batch 180, Loss: 0.5852
Batch 190, Loss: 0.6313
Batch 200, Loss: 0.5987
Batch 210, Loss: 0.6467
Batch 220, Loss: 0.6131
Batch 230, Loss: 0.5699
Batch 240, Loss: 0.6367
Batch 250, Loss: 0.5888
Batch 260, Loss: 0.6036
Batch 270, Loss: 0.5954
Batch 280, Loss: 0.6519
Batch 290, Loss: 0.6205
Batch 300, Loss: 0.6687
Batch 310, Loss: 0.5588
Batch 320, Loss: 0.6052
Batch 330, Loss: 0.5990
Batch 340, Loss: 0.6168
Batch 350, Loss: 0.6010
Batch 360, Loss: 0.6248
Batch 370, Loss: 0.5769
Batch 380, Loss: 0.6225
Batch 390, Loss: 0.5882
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.10399317741394 seconds
Epoch 24 accuracy: 81.6%
Batch 10, Loss: 0.5842
Batch 20, Loss: 0.6047
Batch 30, Loss: 0.5992
Batch 40, Loss: 0.6002
Batch 50, Loss: 0.6248
Batch 60, Loss: 0.6321
Batch 70, Loss: 0.5821
Batch 80, Loss: 0.6034
Batch 90, Loss: 0.5671
Batch 100, Loss: 0.6094
Batch 110, Loss: 0.6024
Batch 120, Loss: 0.5742
Batch 130, Loss: 0.6083
Batch 140, Loss: 0.5810
Batch 150, Loss: 0.6142
Batch 160, Loss: 0.6040
Batch 170, Loss: 0.6086
Batch 180, Loss: 0.6163
Batch 190, Loss: 0.6015
Batch 200, Loss: 0.6343
Batch 210, Loss: 0.5967
Batch 220, Loss: 0.5690
Batch 230, Loss: 0.5824
Batch 240, Loss: 0.5865
Batch 250, Loss: 0.6174
Batch 260, Loss: 0.6335
Batch 270, Loss: 0.6196
Batch 280, Loss: 0.6243
Batch 290, Loss: 0.6366
Batch 300, Loss: 0.5736
Batch 310, Loss: 0.6263
Batch 320, Loss: 0.6122
Batch 330, Loss: 0.6050
Batch 340, Loss: 0.5749
Batch 350, Loss: 0.6026
Batch 360, Loss: 0.5825
Batch 370, Loss: 0.6103
Batch 380, Loss: 0.6085
Batch 390, Loss: 0.6106
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.081306219100952 seconds
Epoch 25 accuracy: 80.92%
Batch 10, Loss: 0.5961
Batch 20, Loss: 0.5948
Batch 30, Loss: 0.5948
Batch 40, Loss: 0.5844
Batch 50, Loss: 0.5866
Batch 60, Loss: 0.6313
Batch 70, Loss: 0.6192
Batch 80, Loss: 0.5912
Batch 90, Loss: 0.5645
Batch 100, Loss: 0.5842
Batch 110, Loss: 0.6354
Batch 120, Loss: 0.6441
Batch 130, Loss: 0.6178
Batch 140, Loss: 0.6456
Batch 150, Loss: 0.6414
Batch 160, Loss: 0.6108
Batch 170, Loss: 0.5673
Batch 180, Loss: 0.6687
Batch 190, Loss: 0.6010
Batch 200, Loss: 0.5715
Batch 210, Loss: 0.6130
Batch 220, Loss: 0.5901
Batch 230, Loss: 0.5877
Batch 240, Loss: 0.5726
Batch 250, Loss: 0.6121
Batch 260, Loss: 0.5773
Batch 270, Loss: 0.5700
Batch 280, Loss: 0.5680
Batch 290, Loss: 0.5699
Batch 300, Loss: 0.5961
Batch 310, Loss: 0.6081
Batch 320, Loss: 0.5746
Batch 330, Loss: 0.6153
Batch 340, Loss: 0.6031
Batch 350, Loss: 0.5614
Batch 360, Loss: 0.5867
Batch 370, Loss: 0.6128
Batch 380, Loss: 0.6031
Batch 390, Loss: 0.5886
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.015334606170654 seconds
Epoch 26 accuracy: 77.65%
Batch 10, Loss: 0.5751
Batch 20, Loss: 0.5536
Batch 30, Loss: 0.5897
Batch 40, Loss: 0.6038
Batch 50, Loss: 0.6257
Batch 60, Loss: 0.6030
Batch 70, Loss: 0.6059
Batch 80, Loss: 0.6292
Batch 90, Loss: 0.6107
Batch 100, Loss: 0.5981
Batch 110, Loss: 0.5751
Batch 120, Loss: 0.5977
Batch 130, Loss: 0.6011
Batch 140, Loss: 0.5818
Batch 150, Loss: 0.5837
Batch 160, Loss: 0.5818
Batch 170, Loss: 0.5956
Batch 180, Loss: 0.6145
Batch 190, Loss: 0.6164
Batch 200, Loss: 0.6127
Batch 210, Loss: 0.5795
Batch 220, Loss: 0.6295
Batch 230, Loss: 0.5669
Batch 240, Loss: 0.6347
Batch 250, Loss: 0.6191
Batch 260, Loss: 0.6232
Batch 270, Loss: 0.6228
Batch 280, Loss: 0.6052
Batch 290, Loss: 0.5992
Batch 300, Loss: 0.5956
Batch 310, Loss: 0.5789
Batch 320, Loss: 0.6288
Batch 330, Loss: 0.5809
Batch 340, Loss: 0.6206
Batch 350, Loss: 0.5968
Batch 360, Loss: 0.6231
Batch 370, Loss: 0.5683
Batch 380, Loss: 0.6005
Batch 390, Loss: 0.6060
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.01736044883728 seconds
Epoch 27 accuracy: 84.68%
Batch 10, Loss: 0.5887
Batch 20, Loss: 0.5715
Batch 30, Loss: 0.5692
Batch 40, Loss: 0.5877
Batch 50, Loss: 0.5986
Batch 60, Loss: 0.5889
Batch 70, Loss: 0.5799
Batch 80, Loss: 0.6064
Batch 90, Loss: 0.5508
Batch 100, Loss: 0.6234
Batch 110, Loss: 0.6241
Batch 120, Loss: 0.6122
Batch 130, Loss: 0.5826
Batch 140, Loss: 0.5983
Batch 150, Loss: 0.5789
Batch 160, Loss: 0.5920
Batch 170, Loss: 0.5992
Batch 180, Loss: 0.5722
Batch 190, Loss: 0.6357
Batch 200, Loss: 0.6111
Batch 210, Loss: 0.5903
Batch 220, Loss: 0.5852
Batch 230, Loss: 0.5488
Batch 240, Loss: 0.5738
Batch 250, Loss: 0.6072
Batch 260, Loss: 0.6208
Batch 270, Loss: 0.5886
Batch 280, Loss: 0.6169
Batch 290, Loss: 0.5740
Batch 300, Loss: 0.5354
Batch 310, Loss: 0.6302
Batch 320, Loss: 0.5969
Batch 330, Loss: 0.5869
Batch 340, Loss: 0.6279
Batch 350, Loss: 0.5944
Batch 360, Loss: 0.5643
Batch 370, Loss: 0.5856
Batch 380, Loss: 0.6109
Batch 390, Loss: 0.6032
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.12061858177185 seconds
Epoch 28 accuracy: 78.52%
Batch 10, Loss: 0.6262
Batch 20, Loss: 0.6182
Batch 30, Loss: 0.5872
Batch 40, Loss: 0.5542
Batch 50, Loss: 0.6204
Batch 60, Loss: 0.6015
Batch 70, Loss: 0.6017
Batch 80, Loss: 0.5717
Batch 90, Loss: 0.5511
Batch 100, Loss: 0.6333
Batch 110, Loss: 0.6041
Batch 120, Loss: 0.5820
Batch 130, Loss: 0.5611
Batch 140, Loss: 0.5983
Batch 150, Loss: 0.5785
Batch 160, Loss: 0.6190
Batch 170, Loss: 0.6201
Batch 180, Loss: 0.6049
Batch 190, Loss: 0.5721
Batch 200, Loss: 0.5919
Batch 210, Loss: 0.5688
Batch 220, Loss: 0.6030
Batch 230, Loss: 0.5880
Batch 240, Loss: 0.5732
Batch 250, Loss: 0.5622
Batch 260, Loss: 0.5576
Batch 270, Loss: 0.5741
Batch 280, Loss: 0.5876
Batch 290, Loss: 0.6313
Batch 300, Loss: 0.5649
Batch 310, Loss: 0.5904
Batch 320, Loss: 0.5921
Batch 330, Loss: 0.5929
Batch 340, Loss: 0.5918
Batch 350, Loss: 0.5718
Batch 360, Loss: 0.5975
Batch 370, Loss: 0.5710
Batch 380, Loss: 0.6138
Batch 390, Loss: 0.6283
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 24.982724905014038 seconds
Epoch 29 accuracy: 79.8%
Batch 10, Loss: 0.6106
Batch 20, Loss: 0.5590
Batch 30, Loss: 0.5911
Batch 40, Loss: 0.5810
Batch 50, Loss: 0.5718
Batch 60, Loss: 0.6153
Batch 70, Loss: 0.5606
Batch 80, Loss: 0.5674
Batch 90, Loss: 0.5302
Batch 100, Loss: 0.5943
Batch 110, Loss: 0.6077
Batch 120, Loss: 0.6220
Batch 130, Loss: 0.6002
Batch 140, Loss: 0.5746
Batch 150, Loss: 0.5870
Batch 160, Loss: 0.5575
Batch 170, Loss: 0.6079
Batch 180, Loss: 0.6131
Batch 190, Loss: 0.5905
Batch 200, Loss: 0.6050
Batch 210, Loss: 0.5658
Batch 220, Loss: 0.6116
Batch 230, Loss: 0.5830
Batch 240, Loss: 0.6425
Batch 250, Loss: 0.6050
Batch 260, Loss: 0.5971
Batch 270, Loss: 0.5824
Batch 280, Loss: 0.5747
Batch 290, Loss: 0.6255
Batch 300, Loss: 0.5805
Batch 310, Loss: 0.5645
Batch 320, Loss: 0.6330
Batch 330, Loss: 0.6199
Batch 340, Loss: 0.5956
Batch 350, Loss: 0.5709
Batch 360, Loss: 0.5712
Batch 370, Loss: 0.5681
Batch 380, Loss: 0.5965
Batch 390, Loss: 0.6226
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.120696783065796 seconds
Epoch 30 accuracy: 82.59%
Batch 10, Loss: 0.5550
Batch 20, Loss: 0.6016
Batch 30, Loss: 0.6133
Batch 40, Loss: 0.5789
Batch 50, Loss: 0.6166
Batch 60, Loss: 0.6144
Batch 70, Loss: 0.5430
Batch 80, Loss: 0.5773
Batch 90, Loss: 0.5935
Batch 100, Loss: 0.5623
Batch 110, Loss: 0.6213
Batch 120, Loss: 0.5717
Batch 130, Loss: 0.5813
Batch 140, Loss: 0.5811
Batch 150, Loss: 0.5758
Batch 160, Loss: 0.5686
Batch 170, Loss: 0.5997
Batch 180, Loss: 0.5909
Batch 190, Loss: 0.5498
Batch 200, Loss: 0.5869
Batch 210, Loss: 0.6392
Batch 220, Loss: 0.5509
Batch 230, Loss: 0.6118
Batch 240, Loss: 0.5841
Batch 250, Loss: 0.6174
Batch 260, Loss: 0.5777
Batch 270, Loss: 0.6120
Batch 280, Loss: 0.5771
Batch 290, Loss: 0.5723
Batch 300, Loss: 0.6040
Batch 310, Loss: 0.5986
Batch 320, Loss: 0.5783
Batch 330, Loss: 0.5989
Batch 340, Loss: 0.5531
Batch 350, Loss: 0.5287
Batch 360, Loss: 0.5698
Batch 370, Loss: 0.5512
Batch 380, Loss: 0.5536
Batch 390, Loss: 0.5769
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.036877870559692 seconds
Epoch 31 accuracy: 83.64%
Batch 10, Loss: 0.5938
Batch 20, Loss: 0.5974
Batch 30, Loss: 0.5956
Batch 40, Loss: 0.5690
Batch 50, Loss: 0.5936
Batch 60, Loss: 0.5665
Batch 70, Loss: 0.5365
Batch 80, Loss: 0.5651
Batch 90, Loss: 0.5468
Batch 100, Loss: 0.5921
Batch 110, Loss: 0.5851
Batch 120, Loss: 0.5761
Batch 130, Loss: 0.5523
Batch 140, Loss: 0.5832
Batch 150, Loss: 0.5904
Batch 160, Loss: 0.5993
Batch 170, Loss: 0.6071
Batch 180, Loss: 0.5654
Batch 190, Loss: 0.6084
Batch 200, Loss: 0.5982
Batch 210, Loss: 0.5827
Batch 220, Loss: 0.5636
Batch 230, Loss: 0.5796
Batch 240, Loss: 0.5786
Batch 250, Loss: 0.5973
Batch 260, Loss: 0.5541
Batch 270, Loss: 0.5795
Batch 280, Loss: 0.5683
Batch 290, Loss: 0.6401
Batch 300, Loss: 0.5695
Batch 310, Loss: 0.5536
Batch 320, Loss: 0.5665
Batch 330, Loss: 0.6105
Batch 340, Loss: 0.5511
Batch 350, Loss: 0.5767
Batch 360, Loss: 0.5954
Batch 370, Loss: 0.6357
Batch 380, Loss: 0.5840
Batch 390, Loss: 0.5667
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.0085346698761 seconds
Epoch 32 accuracy: 83.0%
Batch 10, Loss: 0.5548
Batch 20, Loss: 0.5627
Batch 30, Loss: 0.5792
Batch 40, Loss: 0.6280
Batch 50, Loss: 0.6116
Batch 60, Loss: 0.5832
Batch 70, Loss: 0.6412
Batch 80, Loss: 0.5858
Batch 90, Loss: 0.5789
Batch 100, Loss: 0.6208
Batch 110, Loss: 0.5621
Batch 120, Loss: 0.5751
Batch 130, Loss: 0.5586
Batch 140, Loss: 0.5993
Batch 150, Loss: 0.5424
Batch 160, Loss: 0.5403
Batch 170, Loss: 0.5642
Batch 180, Loss: 0.5830
Batch 190, Loss: 0.5467
Batch 200, Loss: 0.5643
Batch 210, Loss: 0.5843
Batch 220, Loss: 0.5638
Batch 230, Loss: 0.5533
Batch 240, Loss: 0.5607
Batch 250, Loss: 0.5573
Batch 260, Loss: 0.5870
Batch 270, Loss: 0.5649
Batch 280, Loss: 0.5778
Batch 290, Loss: 0.5676
Batch 300, Loss: 0.5621
Batch 310, Loss: 0.5571
Batch 320, Loss: 0.5985
Batch 330, Loss: 0.5490
Batch 340, Loss: 0.6048
Batch 350, Loss: 0.5902
Batch 360, Loss: 0.5862
Batch 370, Loss: 0.5492
Batch 380, Loss: 0.5881
Batch 390, Loss: 0.5787
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.10413384437561 seconds
Epoch 33 accuracy: 79.09%
Batch 10, Loss: 0.5810
Batch 20, Loss: 0.5320
Batch 30, Loss: 0.5987
Batch 40, Loss: 0.5841
Batch 50, Loss: 0.5796
Batch 60, Loss: 0.5168
Batch 70, Loss: 0.5598
Batch 80, Loss: 0.6005
Batch 90, Loss: 0.5902
Batch 100, Loss: 0.5607
Batch 110, Loss: 0.5821
Batch 120, Loss: 0.5768
Batch 130, Loss: 0.5643
Batch 140, Loss: 0.5946
Batch 150, Loss: 0.5821
Batch 160, Loss: 0.5921
Batch 170, Loss: 0.5971
Batch 180, Loss: 0.6281
Batch 190, Loss: 0.5765
Batch 200, Loss: 0.5831
Batch 210, Loss: 0.5828
Batch 220, Loss: 0.5584
Batch 230, Loss: 0.5994
Batch 240, Loss: 0.5578
Batch 250, Loss: 0.5865
Batch 260, Loss: 0.6011
Batch 270, Loss: 0.5568
Batch 280, Loss: 0.5694
Batch 290, Loss: 0.5761
Batch 300, Loss: 0.5847
Batch 310, Loss: 0.6006
Batch 320, Loss: 0.5665
Batch 330, Loss: 0.5437
Batch 340, Loss: 0.6003
Batch 350, Loss: 0.5342
Batch 360, Loss: 0.5583
Batch 370, Loss: 0.5319
Batch 380, Loss: 0.6093
Batch 390, Loss: 0.5913
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.07311177253723 seconds
Epoch 34 accuracy: 79.61%
Batch 10, Loss: 0.5798
Batch 20, Loss: 0.5671
Batch 30, Loss: 0.5722
Batch 40, Loss: 0.5624
Batch 50, Loss: 0.6093
Batch 60, Loss: 0.5911
Batch 70, Loss: 0.5714
Batch 80, Loss: 0.5875
Batch 90, Loss: 0.5667
Batch 100, Loss: 0.5729
Batch 110, Loss: 0.5864
Batch 120, Loss: 0.5584
Batch 130, Loss: 0.5493
Batch 140, Loss: 0.5256
Batch 150, Loss: 0.6010
Batch 160, Loss: 0.5610
Batch 170, Loss: 0.6077
Batch 180, Loss: 0.5847
Batch 190, Loss: 0.5758
Batch 200, Loss: 0.5400
Batch 210, Loss: 0.6168
Batch 220, Loss: 0.5622
Batch 230, Loss: 0.5510
Batch 240, Loss: 0.5498
Batch 250, Loss: 0.6085
Batch 260, Loss: 0.6316
Batch 270, Loss: 0.5301
Batch 280, Loss: 0.5491
Batch 290, Loss: 0.5747
Batch 300, Loss: 0.5866
Batch 310, Loss: 0.5744
Batch 320, Loss: 0.5931
Batch 330, Loss: 0.6074
Batch 340, Loss: 0.5986
Batch 350, Loss: 0.5905
Batch 360, Loss: 0.5831
Batch 370, Loss: 0.5980
Batch 380, Loss: 0.5540
Batch 390, Loss: 0.5616
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.004392862319946 seconds
Epoch 35 accuracy: 83.89%
Batch 10, Loss: 0.5473
Batch 20, Loss: 0.5877
Batch 30, Loss: 0.5877
Batch 40, Loss: 0.5795
Batch 50, Loss: 0.5851
Batch 60, Loss: 0.5801
Batch 70, Loss: 0.5590
Batch 80, Loss: 0.5733
Batch 90, Loss: 0.5546
Batch 100, Loss: 0.5444
Batch 110, Loss: 0.5581
Batch 120, Loss: 0.6097
Batch 130, Loss: 0.5499
Batch 140, Loss: 0.5939
Batch 150, Loss: 0.5732
Batch 160, Loss: 0.5638
Batch 170, Loss: 0.5711
Batch 180, Loss: 0.5759
Batch 190, Loss: 0.5873
Batch 200, Loss: 0.5364
Batch 210, Loss: 0.5402
Batch 220, Loss: 0.5730
Batch 230, Loss: 0.5639
Batch 240, Loss: 0.5685
Batch 250, Loss: 0.5962
Batch 260, Loss: 0.5379
Batch 270, Loss: 0.5768
Batch 280, Loss: 0.5431
Batch 290, Loss: 0.5797
Batch 300, Loss: 0.5933
Batch 310, Loss: 0.5966
Batch 320, Loss: 0.5765
Batch 330, Loss: 0.5697
Batch 340, Loss: 0.5947
Batch 350, Loss: 0.5503
Batch 360, Loss: 0.5889
Batch 370, Loss: 0.5793
Batch 380, Loss: 0.5772
Batch 390, Loss: 0.5780
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.127070426940918 seconds
Epoch 36 accuracy: 83.76%
Batch 10, Loss: 0.5474
Batch 20, Loss: 0.5898
Batch 30, Loss: 0.5467
Batch 40, Loss: 0.5595
Batch 50, Loss: 0.5435
Batch 60, Loss: 0.5739
Batch 70, Loss: 0.5810
Batch 80, Loss: 0.5353
Batch 90, Loss: 0.5267
Batch 100, Loss: 0.5764
Batch 110, Loss: 0.5784
Batch 120, Loss: 0.5652
Batch 130, Loss: 0.5763
Batch 140, Loss: 0.5076
Batch 150, Loss: 0.5500
Batch 160, Loss: 0.5392
Batch 170, Loss: 0.5785
Batch 180, Loss: 0.5938
Batch 190, Loss: 0.5769
Batch 200, Loss: 0.5259
Batch 210, Loss: 0.5490
Batch 220, Loss: 0.5111
Batch 230, Loss: 0.5866
Batch 240, Loss: 0.5749
Batch 250, Loss: 0.5683
Batch 260, Loss: 0.5254
Batch 270, Loss: 0.5909
Batch 280, Loss: 0.5779
Batch 290, Loss: 0.5482
Batch 300, Loss: 0.5979
Batch 310, Loss: 0.5601
Batch 320, Loss: 0.5823
Batch 330, Loss: 0.5609
Batch 340, Loss: 0.5419
Batch 350, Loss: 0.6068
Batch 360, Loss: 0.5785
Batch 370, Loss: 0.5816
Batch 380, Loss: 0.5849
Batch 390, Loss: 0.5647
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.057384967803955 seconds
Epoch 37 accuracy: 81.44%
Batch 10, Loss: 0.5094
Batch 20, Loss: 0.5562
Batch 30, Loss: 0.5445
Batch 40, Loss: 0.5162
Batch 50, Loss: 0.5346
Batch 60, Loss: 0.5583
Batch 70, Loss: 0.6040
Batch 80, Loss: 0.5739
Batch 90, Loss: 0.5648
Batch 100, Loss: 0.5311
Batch 110, Loss: 0.5819
Batch 120, Loss: 0.5717
Batch 130, Loss: 0.5772
Batch 140, Loss: 0.5851
Batch 150, Loss: 0.5335
Batch 160, Loss: 0.5544
Batch 170, Loss: 0.5385
Batch 180, Loss: 0.5853
Batch 190, Loss: 0.5202
Batch 200, Loss: 0.5635
Batch 210, Loss: 0.5449
Batch 220, Loss: 0.5906
Batch 230, Loss: 0.5851
Batch 240, Loss: 0.5715
Batch 250, Loss: 0.5494
Batch 260, Loss: 0.5966
Batch 270, Loss: 0.6155
Batch 280, Loss: 0.5637
Batch 290, Loss: 0.6180
Batch 300, Loss: 0.5534
Batch 310, Loss: 0.5816
Batch 320, Loss: 0.5867
Batch 330, Loss: 0.5459
Batch 340, Loss: 0.5499
Batch 350, Loss: 0.5169
Batch 360, Loss: 0.6026
Batch 370, Loss: 0.5080
Batch 380, Loss: 0.5955
Batch 390, Loss: 0.5616
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.041276693344116 seconds
Epoch 38 accuracy: 82.85%
Batch 10, Loss: 0.5286
Batch 20, Loss: 0.5219
Batch 30, Loss: 0.5722
Batch 40, Loss: 0.5344
Batch 50, Loss: 0.5131
Batch 60, Loss: 0.5408
Batch 70, Loss: 0.5633
Batch 80, Loss: 0.6013
Batch 90, Loss: 0.5628
Batch 100, Loss: 0.5630
Batch 110, Loss: 0.5386
Batch 120, Loss: 0.5523
Batch 130, Loss: 0.5230
Batch 140, Loss: 0.5237
Batch 150, Loss: 0.5473
Batch 160, Loss: 0.5773
Batch 170, Loss: 0.5976
Batch 180, Loss: 0.5420
Batch 190, Loss: 0.5362
Batch 200, Loss: 0.6010
Batch 210, Loss: 0.6104
Batch 220, Loss: 0.5633
Batch 230, Loss: 0.5557
Batch 240, Loss: 0.5603
Batch 250, Loss: 0.5596
Batch 260, Loss: 0.5652
Batch 270, Loss: 0.5465
Batch 280, Loss: 0.6053
Batch 290, Loss: 0.5720
Batch 300, Loss: 0.5370
Batch 310, Loss: 0.5336
Batch 320, Loss: 0.6016
Batch 330, Loss: 0.6036
Batch 340, Loss: 0.5710
Batch 350, Loss: 0.5188
Batch 360, Loss: 0.5530
Batch 370, Loss: 0.5733
Batch 380, Loss: 0.5314
Batch 390, Loss: 0.5431
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.0420343875885 seconds
Epoch 39 accuracy: 82.74%
Batch 10, Loss: 0.5706
Batch 20, Loss: 0.5666
Batch 30, Loss: 0.5844
Batch 40, Loss: 0.5533
Batch 50, Loss: 0.5945
Batch 60, Loss: 0.5420
Batch 70, Loss: 0.5558
Batch 80, Loss: 0.5762
Batch 90, Loss: 0.5508
Batch 100, Loss: 0.5770
Batch 110, Loss: 0.5760
Batch 120, Loss: 0.5811
Batch 130, Loss: 0.5422
Batch 140, Loss: 0.5337
Batch 150, Loss: 0.5430
Batch 160, Loss: 0.5762
Batch 170, Loss: 0.5324
Batch 180, Loss: 0.5705
Batch 190, Loss: 0.5183
Batch 200, Loss: 0.6012
Batch 210, Loss: 0.5169
Batch 220, Loss: 0.5703
Batch 230, Loss: 0.6020
Batch 240, Loss: 0.5420
Batch 250, Loss: 0.5315
Batch 260, Loss: 0.5470
Batch 270, Loss: 0.6052
Batch 280, Loss: 0.5603
Batch 290, Loss: 0.5507
Batch 300, Loss: 0.5480
Batch 310, Loss: 0.5415
Batch 320, Loss: 0.5478
Batch 330, Loss: 0.5379
Batch 340, Loss: 0.5676
Batch 350, Loss: 0.5758
Batch 360, Loss: 0.5826
Batch 370, Loss: 0.5689
Batch 380, Loss: 0.5890
Batch 390, Loss: 0.5762
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.075536012649536 seconds
Epoch 40 accuracy: 82.12%
Batch 10, Loss: 0.6037
Batch 20, Loss: 0.5425
Batch 30, Loss: 0.5549
Batch 40, Loss: 0.5420
Batch 50, Loss: 0.5486
Batch 60, Loss: 0.5692
Batch 70, Loss: 0.5235
Batch 80, Loss: 0.5198
Batch 90, Loss: 0.5367
Batch 100, Loss: 0.5520
Batch 110, Loss: 0.5664
Batch 120, Loss: 0.6006
Batch 130, Loss: 0.5786
Batch 140, Loss: 0.5682
Batch 150, Loss: 0.5751
Batch 160, Loss: 0.5740
Batch 170, Loss: 0.5271
Batch 180, Loss: 0.5255
Batch 190, Loss: 0.5791
Batch 200, Loss: 0.5248
Batch 210, Loss: 0.5866
Batch 220, Loss: 0.5344
Batch 230, Loss: 0.5579
Batch 240, Loss: 0.5564
Batch 250, Loss: 0.5529
Batch 260, Loss: 0.5602
Batch 270, Loss: 0.5521
Batch 280, Loss: 0.5674
Batch 290, Loss: 0.5687
Batch 300, Loss: 0.5756
Batch 310, Loss: 0.5723
Batch 320, Loss: 0.5686
Batch 330, Loss: 0.5886
Batch 340, Loss: 0.5135
Batch 350, Loss: 0.5264
Batch 360, Loss: 0.5451
Batch 370, Loss: 0.5592
Batch 380, Loss: 0.6181
Batch 390, Loss: 0.5528
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.094833374023438 seconds
Epoch 41 accuracy: 78.63%
Batch 10, Loss: 0.5864
Batch 20, Loss: 0.5406
Batch 30, Loss: 0.5477
Batch 40, Loss: 0.5868
Batch 50, Loss: 0.5595
Batch 60, Loss: 0.5960
Batch 70, Loss: 0.5385
Batch 80, Loss: 0.5871
Batch 90, Loss: 0.5702
Batch 100, Loss: 0.5305
Batch 110, Loss: 0.5566
Batch 120, Loss: 0.5382
Batch 130, Loss: 0.5230
Batch 140, Loss: 0.5723
Batch 150, Loss: 0.5861
Batch 160, Loss: 0.5664
Batch 170, Loss: 0.5448
Batch 180, Loss: 0.5623
Batch 190, Loss: 0.5808
Batch 200, Loss: 0.5446
Batch 210, Loss: 0.5605
Batch 220, Loss: 0.5261
Batch 230, Loss: 0.5626
Batch 240, Loss: 0.5622
Batch 250, Loss: 0.5475
Batch 260, Loss: 0.5670
Batch 270, Loss: 0.5439
Batch 280, Loss: 0.5524
Batch 290, Loss: 0.5583
Batch 300, Loss: 0.5201
Batch 310, Loss: 0.5401
Batch 320, Loss: 0.5568
Batch 330, Loss: 0.5876
Batch 340, Loss: 0.5229
Batch 350, Loss: 0.5531
Batch 360, Loss: 0.5580
Batch 370, Loss: 0.5620
Batch 380, Loss: 0.5367
Batch 390, Loss: 0.5583
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.002676486968994 seconds
Epoch 42 accuracy: 83.61%
Batch 10, Loss: 0.5618
Batch 20, Loss: 0.5471
Batch 30, Loss: 0.5074
Batch 40, Loss: 0.5536
Batch 50, Loss: 0.5887
Batch 60, Loss: 0.5798
Batch 70, Loss: 0.5359
Batch 80, Loss: 0.5344
Batch 90, Loss: 0.5409
Batch 100, Loss: 0.5486
Batch 110, Loss: 0.5433
Batch 120, Loss: 0.5586
Batch 130, Loss: 0.5510
Batch 140, Loss: 0.5566
Batch 150, Loss: 0.5569
Batch 160, Loss: 0.5436
Batch 170, Loss: 0.5918
Batch 180, Loss: 0.5546
Batch 190, Loss: 0.5529
Batch 200, Loss: 0.5252
Batch 210, Loss: 0.5517
Batch 220, Loss: 0.5553
Batch 230, Loss: 0.5551
Batch 240, Loss: 0.5789
Batch 250, Loss: 0.5658
Batch 260, Loss: 0.5451
Batch 270, Loss: 0.5813
Batch 280, Loss: 0.5459
Batch 290, Loss: 0.5411
Batch 300, Loss: 0.5584
Batch 310, Loss: 0.5432
Batch 320, Loss: 0.5523
Batch 330, Loss: 0.5655
Batch 340, Loss: 0.5756
Batch 350, Loss: 0.5841
Batch 360, Loss: 0.5552
Batch 370, Loss: 0.5521
Batch 380, Loss: 0.5743
Batch 390, Loss: 0.5800
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.044472217559814 seconds
Epoch 43 accuracy: 81.9%
Batch 10, Loss: 0.5139
Batch 20, Loss: 0.5611
Batch 30, Loss: 0.5326
Batch 40, Loss: 0.5374
Batch 50, Loss: 0.5839
Batch 60, Loss: 0.5545
Batch 70, Loss: 0.5637
Batch 80, Loss: 0.5875
Batch 90, Loss: 0.5662
Batch 100, Loss: 0.5384
Batch 110, Loss: 0.5521
Batch 120, Loss: 0.5441
Batch 130, Loss: 0.5557
Batch 140, Loss: 0.5613
Batch 150, Loss: 0.5294
Batch 160, Loss: 0.5495
Batch 170, Loss: 0.5709
Batch 180, Loss: 0.5490
Batch 190, Loss: 0.5047
Batch 200, Loss: 0.5516
Batch 210, Loss: 0.5690
Batch 220, Loss: 0.5728
Batch 230, Loss: 0.5592
Batch 240, Loss: 0.5436
Batch 250, Loss: 0.5494
Batch 260, Loss: 0.5471
Batch 270, Loss: 0.5419
Batch 280, Loss: 0.5462
Batch 290, Loss: 0.5151
Batch 300, Loss: 0.5455
Batch 310, Loss: 0.5397
Batch 320, Loss: 0.5307
Batch 330, Loss: 0.5596
Batch 340, Loss: 0.5248
Batch 350, Loss: 0.5744
Batch 360, Loss: 0.5228
Batch 370, Loss: 0.5436
Batch 380, Loss: 0.5373
Batch 390, Loss: 0.5466
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.019386291503906 seconds
Epoch 44 accuracy: 84.46%
Batch 10, Loss: 0.5437
Batch 20, Loss: 0.5242
Batch 30, Loss: 0.5342
Batch 40, Loss: 0.5831
Batch 50, Loss: 0.5052
Batch 60, Loss: 0.5497
Batch 70, Loss: 0.5119
Batch 80, Loss: 0.5387
Batch 90, Loss: 0.6038
Batch 100, Loss: 0.5591
Batch 110, Loss: 0.5302
Batch 120, Loss: 0.5415
Batch 130, Loss: 0.5777
Batch 140, Loss: 0.5252
Batch 150, Loss: 0.5133
Batch 160, Loss: 0.5239
Batch 170, Loss: 0.5671
Batch 180, Loss: 0.5316
Batch 190, Loss: 0.5651
Batch 200, Loss: 0.5393
Batch 210, Loss: 0.5421
Batch 220, Loss: 0.5590
Batch 230, Loss: 0.5545
Batch 240, Loss: 0.5512
Batch 250, Loss: 0.5535
Batch 260, Loss: 0.5455
Batch 270, Loss: 0.5752
Batch 280, Loss: 0.5460
Batch 290, Loss: 0.5752
Batch 300, Loss: 0.5489
Batch 310, Loss: 0.5902
Batch 320, Loss: 0.5665
Batch 330, Loss: 0.5303
Batch 340, Loss: 0.5279
Batch 350, Loss: 0.5245
Batch 360, Loss: 0.5090
Batch 370, Loss: 0.5792
Batch 380, Loss: 0.5395
Batch 390, Loss: 0.5252
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.024892568588257 seconds
Epoch 45 accuracy: 80.92%
Batch 10, Loss: 0.5388
Batch 20, Loss: 0.5539
Batch 30, Loss: 0.5457
Batch 40, Loss: 0.5289
Batch 50, Loss: 0.5392
Batch 60, Loss: 0.5556
Batch 70, Loss: 0.5097
Batch 80, Loss: 0.5162
Batch 90, Loss: 0.5117
Batch 100, Loss: 0.5142
Batch 110, Loss: 0.5170
Batch 120, Loss: 0.5709
Batch 130, Loss: 0.5476
Batch 140, Loss: 0.5173
Batch 150, Loss: 0.5777
Batch 160, Loss: 0.5462
Batch 170, Loss: 0.5957
Batch 180, Loss: 0.5492
Batch 190, Loss: 0.5128
Batch 200, Loss: 0.5469
Batch 210, Loss: 0.5451
Batch 220, Loss: 0.5232
Batch 230, Loss: 0.5927
Batch 240, Loss: 0.5901
Batch 250, Loss: 0.5765
Batch 260, Loss: 0.5471
Batch 270, Loss: 0.5637
Batch 280, Loss: 0.5278
Batch 290, Loss: 0.5314
Batch 300, Loss: 0.5646
Batch 310, Loss: 0.5845
Batch 320, Loss: 0.5197
Batch 330, Loss: 0.5153
Batch 340, Loss: 0.5644
Batch 350, Loss: 0.5171
Batch 360, Loss: 0.5627
Batch 370, Loss: 0.5908
Batch 380, Loss: 0.5308
Batch 390, Loss: 0.4857
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 24.972190618515015 seconds
Epoch 46 accuracy: 81.66%
Batch 10, Loss: 0.5449
Batch 20, Loss: 0.5442
Batch 30, Loss: 0.5568
Batch 40, Loss: 0.5400
Batch 50, Loss: 0.5417
Batch 60, Loss: 0.5482
Batch 70, Loss: 0.5274
Batch 80, Loss: 0.5446
Batch 90, Loss: 0.4948
Batch 100, Loss: 0.5432
Batch 110, Loss: 0.5518
Batch 120, Loss: 0.5391
Batch 130, Loss: 0.5413
Batch 140, Loss: 0.5485
Batch 150, Loss: 0.5576
Batch 160, Loss: 0.5478
Batch 170, Loss: 0.5474
Batch 180, Loss: 0.5577
Batch 190, Loss: 0.5542
Batch 200, Loss: 0.5589
Batch 210, Loss: 0.5274
Batch 220, Loss: 0.5314
Batch 230, Loss: 0.5432
Batch 240, Loss: 0.5532
Batch 250, Loss: 0.5569
Batch 260, Loss: 0.5168
Batch 270, Loss: 0.5270
Batch 280, Loss: 0.5829
Batch 290, Loss: 0.5598
Batch 300, Loss: 0.5245
Batch 310, Loss: 0.5272
Batch 320, Loss: 0.5352
Batch 330, Loss: 0.5728
Batch 340, Loss: 0.5548
Batch 350, Loss: 0.5600
Batch 360, Loss: 0.5675
Batch 370, Loss: 0.5364
Batch 380, Loss: 0.5609
Batch 390, Loss: 0.5777
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.02177095413208 seconds
Epoch 47 accuracy: 82.61%
Batch 10, Loss: 0.5492
Batch 20, Loss: 0.5067
Batch 30, Loss: 0.5308
Batch 40, Loss: 0.5656
Batch 50, Loss: 0.5411
Batch 60, Loss: 0.5607
Batch 70, Loss: 0.5056
Batch 80, Loss: 0.5441
Batch 90, Loss: 0.5692
Batch 100, Loss: 0.4845
Batch 110, Loss: 0.5396
Batch 120, Loss: 0.5323
Batch 130, Loss: 0.5611
Batch 140, Loss: 0.5817
Batch 150, Loss: 0.5401
Batch 160, Loss: 0.5710
Batch 170, Loss: 0.5333
Batch 180, Loss: 0.5928
Batch 190, Loss: 0.5617
Batch 200, Loss: 0.5384
Batch 210, Loss: 0.5146
Batch 220, Loss: 0.5007
Batch 230, Loss: 0.5719
Batch 240, Loss: 0.5612
Batch 250, Loss: 0.5258
Batch 260, Loss: 0.5687
Batch 270, Loss: 0.5355
Batch 280, Loss: 0.5309
Batch 290, Loss: 0.5361
Batch 300, Loss: 0.5242
Batch 310, Loss: 0.5888
Batch 320, Loss: 0.5691
Batch 330, Loss: 0.5795
Batch 340, Loss: 0.5033
Batch 350, Loss: 0.5397
Batch 360, Loss: 0.5423
Batch 370, Loss: 0.5371
Batch 380, Loss: 0.5345
Batch 390, Loss: 0.5844
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.068387269973755 seconds
Epoch 48 accuracy: 82.37%
Batch 10, Loss: 0.5964
Batch 20, Loss: 0.5625
Batch 30, Loss: 0.5427
Batch 40, Loss: 0.5303
Batch 50, Loss: 0.5122
Batch 60, Loss: 0.5479
Batch 70, Loss: 0.5553
Batch 80, Loss: 0.5658
Batch 90, Loss: 0.5636
Batch 100, Loss: 0.5347
Batch 110, Loss: 0.5548
Batch 120, Loss: 0.5780
Batch 130, Loss: 0.5606
Batch 140, Loss: 0.5364
Batch 150, Loss: 0.5291
Batch 160, Loss: 0.5451
Batch 170, Loss: 0.5255
Batch 180, Loss: 0.5564
Batch 190, Loss: 0.5045
Batch 200, Loss: 0.5418
Batch 210, Loss: 0.5456
Batch 220, Loss: 0.5145
Batch 230, Loss: 0.5117
Batch 240, Loss: 0.5593
Batch 250, Loss: 0.5198
Batch 260, Loss: 0.5305
Batch 270, Loss: 0.5350
Batch 280, Loss: 0.5210
Batch 290, Loss: 0.4965
Batch 300, Loss: 0.5658
Batch 310, Loss: 0.5307
Batch 320, Loss: 0.5543
Batch 330, Loss: 0.5722
Batch 340, Loss: 0.5512
Batch 350, Loss: 0.5834
Batch 360, Loss: 0.5392
Batch 370, Loss: 0.5538
Batch 380, Loss: 0.5408
Batch 390, Loss: 0.5107
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.02543354034424 seconds
Epoch 49 accuracy: 83.04%
Batch 10, Loss: 0.5763
Batch 20, Loss: 0.5550
Batch 30, Loss: 0.5152
Batch 40, Loss: 0.5100
Batch 50, Loss: 0.5474
Batch 60, Loss: 0.5201
Batch 70, Loss: 0.5363
Batch 80, Loss: 0.5390
Batch 90, Loss: 0.5112
Batch 100, Loss: 0.5298
Batch 110, Loss: 0.5499
Batch 120, Loss: 0.5479
Batch 130, Loss: 0.5348
Batch 140, Loss: 0.5601
Batch 150, Loss: 0.4973
Batch 160, Loss: 0.5152
Batch 170, Loss: 0.5115
Batch 180, Loss: 0.5444
Batch 190, Loss: 0.5557
Batch 200, Loss: 0.5442
Batch 210, Loss: 0.5241
Batch 220, Loss: 0.5600
Batch 230, Loss: 0.5296
Batch 240, Loss: 0.5506
Batch 250, Loss: 0.5454
Batch 260, Loss: 0.5063
Batch 270, Loss: 0.5302
Batch 280, Loss: 0.5106
Batch 290, Loss: 0.5147
Batch 300, Loss: 0.5415
Batch 310, Loss: 0.5468
Batch 320, Loss: 0.5052
Batch 330, Loss: 0.5365
Batch 340, Loss: 0.5339
Batch 350, Loss: 0.5322
Batch 360, Loss: 0.5200
Batch 370, Loss: 0.5186
Batch 380, Loss: 0.5569
Batch 390, Loss: 0.5301
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 24.982785940170288 seconds
Epoch 50 accuracy: 83.2%
Batch 10, Loss: 0.5351
Batch 20, Loss: 0.5527
Batch 30, Loss: 0.4957
Batch 40, Loss: 0.5494
Batch 50, Loss: 0.5131
Batch 60, Loss: 0.5424
Batch 70, Loss: 0.5412
Batch 80, Loss: 0.5722
Batch 90, Loss: 0.5499
Batch 100, Loss: 0.5202
Batch 110, Loss: 0.5455
Batch 120, Loss: 0.5654
Batch 130, Loss: 0.5181
Batch 140, Loss: 0.5298
Batch 150, Loss: 0.5455
Batch 160, Loss: 0.5623
Batch 170, Loss: 0.5168
Batch 180, Loss: 0.5017
Batch 190, Loss: 0.5605
Batch 200, Loss: 0.5491
Batch 210, Loss: 0.5582
Batch 220, Loss: 0.5509
Batch 230, Loss: 0.4892
Batch 240, Loss: 0.5076
Batch 250, Loss: 0.5077
Batch 260, Loss: 0.5344
Batch 270, Loss: 0.5202
Batch 280, Loss: 0.5414
Batch 290, Loss: 0.5895
Batch 300, Loss: 0.5152
Batch 310, Loss: 0.5243
Batch 320, Loss: 0.5537
Batch 330, Loss: 0.4916
Batch 340, Loss: 0.5221
Batch 350, Loss: 0.5162
Batch 360, Loss: 0.5025
Batch 370, Loss: 0.5765
Batch 380, Loss: 0.5460
Batch 390, Loss: 0.5406
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 24.99811363220215 seconds
Epoch 51 accuracy: 82.3%
Batch 10, Loss: 0.5646
Batch 20, Loss: 0.5455
Batch 30, Loss: 0.5267
Batch 40, Loss: 0.5302
Batch 50, Loss: 0.5402
Batch 60, Loss: 0.5445
Batch 70, Loss: 0.5480
Batch 80, Loss: 0.5656
Batch 90, Loss: 0.5359
Batch 100, Loss: 0.5424
Batch 110, Loss: 0.5360
Batch 120, Loss: 0.5171
Batch 130, Loss: 0.5104
Batch 140, Loss: 0.5110
Batch 150, Loss: 0.5271
Batch 160, Loss: 0.5121
Batch 170, Loss: 0.5373
Batch 180, Loss: 0.5227
Batch 190, Loss: 0.5029
Batch 200, Loss: 0.5416
Batch 210, Loss: 0.5651
Batch 220, Loss: 0.5375
Batch 230, Loss: 0.5557
Batch 240, Loss: 0.5232
Batch 250, Loss: 0.5800
Batch 260, Loss: 0.5615
Batch 270, Loss: 0.5317
Batch 280, Loss: 0.5238
Batch 290, Loss: 0.5211
Batch 300, Loss: 0.4947
Batch 310, Loss: 0.5400
Batch 320, Loss: 0.5582
Batch 330, Loss: 0.4834
Batch 340, Loss: 0.5201
Batch 350, Loss: 0.5496
Batch 360, Loss: 0.5492
Batch 370, Loss: 0.5454
Batch 380, Loss: 0.5391
Batch 390, Loss: 0.5401
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.054654121398926 seconds
Epoch 52 accuracy: 86.26%
Batch 10, Loss: 0.5498
Batch 20, Loss: 0.5430
Batch 30, Loss: 0.5367
Batch 40, Loss: 0.5462
Batch 50, Loss: 0.5104
Batch 60, Loss: 0.5074
Batch 70, Loss: 0.5431
Batch 80, Loss: 0.5174
Batch 90, Loss: 0.4939
Batch 100, Loss: 0.5816
Batch 110, Loss: 0.5217
Batch 120, Loss: 0.4959
Batch 130, Loss: 0.5489
Batch 140, Loss: 0.5412
Batch 150, Loss: 0.5278
Batch 160, Loss: 0.5152
Batch 170, Loss: 0.5442
Batch 180, Loss: 0.4985
Batch 190, Loss: 0.5223
Batch 200, Loss: 0.5218
Batch 210, Loss: 0.5141
Batch 220, Loss: 0.4940
Batch 230, Loss: 0.5017
Batch 240, Loss: 0.5292
Batch 250, Loss: 0.5307
Batch 260, Loss: 0.5331
Batch 270, Loss: 0.5307
Batch 280, Loss: 0.5666
Batch 290, Loss: 0.5258
Batch 300, Loss: 0.5655
Batch 310, Loss: 0.5389
Batch 320, Loss: 0.4982
Batch 330, Loss: 0.4960
Batch 340, Loss: 0.4960
Batch 350, Loss: 0.5357
Batch 360, Loss: 0.5056
Batch 370, Loss: 0.5549
Batch 380, Loss: 0.5514
Batch 390, Loss: 0.5164
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 24.969390869140625 seconds
Epoch 53 accuracy: 85.56%
Batch 10, Loss: 0.5371
Batch 20, Loss: 0.5579
Batch 30, Loss: 0.5175
Batch 40, Loss: 0.5288
Batch 50, Loss: 0.5049
Batch 60, Loss: 0.5193
Batch 70, Loss: 0.5094
Batch 80, Loss: 0.5521
Batch 90, Loss: 0.5501
Batch 100, Loss: 0.5504
Batch 110, Loss: 0.5114
Batch 120, Loss: 0.5350
Batch 130, Loss: 0.5371
Batch 140, Loss: 0.5088
Batch 150, Loss: 0.5283
Batch 160, Loss: 0.5263
Batch 170, Loss: 0.5618
Batch 180, Loss: 0.5507
Batch 190, Loss: 0.5559
Batch 200, Loss: 0.5279
Batch 210, Loss: 0.5755
Batch 220, Loss: 0.5577
Batch 230, Loss: 0.5033
Batch 240, Loss: 0.5535
Batch 250, Loss: 0.5276
Batch 260, Loss: 0.5273
Batch 270, Loss: 0.5398
Batch 280, Loss: 0.5394
Batch 290, Loss: 0.5197
Batch 300, Loss: 0.5141
Batch 310, Loss: 0.5259
Batch 320, Loss: 0.5123
Batch 330, Loss: 0.5526
Batch 340, Loss: 0.5486
Batch 350, Loss: 0.5449
Batch 360, Loss: 0.5245
Batch 370, Loss: 0.5092
Batch 380, Loss: 0.5049
Batch 390, Loss: 0.5379
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.02904987335205 seconds
Epoch 54 accuracy: 82.02%
Batch 10, Loss: 0.5223
Batch 20, Loss: 0.4909
Batch 30, Loss: 0.5223
Batch 40, Loss: 0.5090
Batch 50, Loss: 0.5049
Batch 60, Loss: 0.5636
Batch 70, Loss: 0.5326
Batch 80, Loss: 0.5272
Batch 90, Loss: 0.5445
Batch 100, Loss: 0.5430
Batch 110, Loss: 0.5239
Batch 120, Loss: 0.5433
Batch 130, Loss: 0.5427
Batch 140, Loss: 0.5257
Batch 150, Loss: 0.5533
Batch 160, Loss: 0.5585
Batch 170, Loss: 0.4756
Batch 180, Loss: 0.4872
Batch 190, Loss: 0.5433
Batch 200, Loss: 0.5359
Batch 210, Loss: 0.5168
Batch 220, Loss: 0.5227
Batch 230, Loss: 0.5445
Batch 240, Loss: 0.5102
Batch 250, Loss: 0.5235
Batch 260, Loss: 0.5232
Batch 270, Loss: 0.5369
Batch 280, Loss: 0.4857
Batch 290, Loss: 0.4777
Batch 300, Loss: 0.5449
Batch 310, Loss: 0.4900
Batch 320, Loss: 0.5787
Batch 330, Loss: 0.5499
Batch 340, Loss: 0.4797
Batch 350, Loss: 0.4914
Batch 360, Loss: 0.5497
Batch 370, Loss: 0.5450
Batch 380, Loss: 0.5481
Batch 390, Loss: 0.5327
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.015196800231934 seconds
Epoch 55 accuracy: 83.35%
Batch 10, Loss: 0.5178
Batch 20, Loss: 0.5546
Batch 30, Loss: 0.5089
Batch 40, Loss: 0.5527
Batch 50, Loss: 0.5159
Batch 60, Loss: 0.5618
Batch 70, Loss: 0.5561
Batch 80, Loss: 0.5247
Batch 90, Loss: 0.5133
Batch 100, Loss: 0.4845
Batch 110, Loss: 0.5202
Batch 120, Loss: 0.5194
Batch 130, Loss: 0.5232
Batch 140, Loss: 0.5589
Batch 150, Loss: 0.5138
Batch 160, Loss: 0.5299
Batch 170, Loss: 0.5325
Batch 180, Loss: 0.5394
Batch 190, Loss: 0.5002
Batch 200, Loss: 0.5404
Batch 210, Loss: 0.5094
Batch 220, Loss: 0.5112
Batch 230, Loss: 0.5371
Batch 240, Loss: 0.5462
Batch 250, Loss: 0.5491
Batch 260, Loss: 0.5347
Batch 270, Loss: 0.5526
Batch 280, Loss: 0.5313
Batch 290, Loss: 0.4671
Batch 300, Loss: 0.5535
Batch 310, Loss: 0.5421
Batch 320, Loss: 0.5259
Batch 330, Loss: 0.5634
Batch 340, Loss: 0.5390
Batch 350, Loss: 0.5062
Batch 360, Loss: 0.5265
Batch 370, Loss: 0.5392
Batch 380, Loss: 0.5338
Batch 390, Loss: 0.5269
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.0348858833313 seconds
Epoch 56 accuracy: 82.27%
Batch 10, Loss: 0.5331
Batch 20, Loss: 0.5599
Batch 30, Loss: 0.5129
Batch 40, Loss: 0.5113
Batch 50, Loss: 0.5047
Batch 60, Loss: 0.5032
Batch 70, Loss: 0.4791
Batch 80, Loss: 0.5063
Batch 90, Loss: 0.5618
Batch 100, Loss: 0.5096
Batch 110, Loss: 0.5474
Batch 120, Loss: 0.5021
Batch 130, Loss: 0.5412
Batch 140, Loss: 0.4836
Batch 150, Loss: 0.5639
Batch 160, Loss: 0.5240
Batch 170, Loss: 0.5225
Batch 180, Loss: 0.5680
Batch 190, Loss: 0.5155
Batch 200, Loss: 0.5161
Batch 210, Loss: 0.5485
Batch 220, Loss: 0.5707
Batch 230, Loss: 0.5006
Batch 240, Loss: 0.4918
Batch 250, Loss: 0.5295
Batch 260, Loss: 0.5498
Batch 270, Loss: 0.5006
Batch 280, Loss: 0.4938
Batch 290, Loss: 0.4996
Batch 300, Loss: 0.5142
Batch 310, Loss: 0.5685
Batch 320, Loss: 0.5411
Batch 330, Loss: 0.5104
Batch 340, Loss: 0.5262
Batch 350, Loss: 0.5184
Batch 360, Loss: 0.5432
Batch 370, Loss: 0.5189
Batch 380, Loss: 0.5258
Batch 390, Loss: 0.5550
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.026784420013428 seconds
Epoch 57 accuracy: 82.95%
Batch 10, Loss: 0.5371
Batch 20, Loss: 0.5564
Batch 30, Loss: 0.5050
Batch 40, Loss: 0.5178
Batch 50, Loss: 0.4711
Batch 60, Loss: 0.5024
Batch 70, Loss: 0.5411
Batch 80, Loss: 0.6013
Batch 90, Loss: 0.5549
Batch 100, Loss: 0.5002
Batch 110, Loss: 0.5126
Batch 120, Loss: 0.5132
Batch 130, Loss: 0.5268
Batch 140, Loss: 0.5036
Batch 150, Loss: 0.5112
Batch 160, Loss: 0.5437
Batch 170, Loss: 0.4897
Batch 180, Loss: 0.5294
Batch 190, Loss: 0.5177
Batch 200, Loss: 0.5112
Batch 210, Loss: 0.5160
Batch 220, Loss: 0.5016
Batch 230, Loss: 0.4742
Batch 240, Loss: 0.5404
Batch 250, Loss: 0.4948
Batch 260, Loss: 0.5133
Batch 270, Loss: 0.5134
Batch 280, Loss: 0.5162
Batch 290, Loss: 0.5278
Batch 300, Loss: 0.5385
Batch 310, Loss: 0.4960
Batch 320, Loss: 0.5248
Batch 330, Loss: 0.5081
Batch 340, Loss: 0.4997
Batch 350, Loss: 0.5029
Batch 360, Loss: 0.5281
Batch 370, Loss: 0.5260
Batch 380, Loss: 0.5194
Batch 390, Loss: 0.4981
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.08440375328064 seconds
Epoch 58 accuracy: 82.75%
Batch 10, Loss: 0.5631
Batch 20, Loss: 0.5479
Batch 30, Loss: 0.4966
Batch 40, Loss: 0.4773
Batch 50, Loss: 0.4910
Batch 60, Loss: 0.4748
Batch 70, Loss: 0.5298
Batch 80, Loss: 0.5170
Batch 90, Loss: 0.4833
Batch 100, Loss: 0.5033
Batch 110, Loss: 0.5120
Batch 120, Loss: 0.5280
Batch 130, Loss: 0.5669
Batch 140, Loss: 0.5270
Batch 150, Loss: 0.4774
Batch 160, Loss: 0.5156
Batch 170, Loss: 0.5133
Batch 180, Loss: 0.4927
Batch 190, Loss: 0.5073
Batch 200, Loss: 0.5322
Batch 210, Loss: 0.5402
Batch 220, Loss: 0.5127
Batch 230, Loss: 0.5265
Batch 240, Loss: 0.4957
Batch 250, Loss: 0.4703
Batch 260, Loss: 0.4960
Batch 270, Loss: 0.5153
Batch 280, Loss: 0.5405
Batch 290, Loss: 0.5215
Batch 300, Loss: 0.5234
Batch 310, Loss: 0.5121
Batch 320, Loss: 0.5340
Batch 330, Loss: 0.4999
Batch 340, Loss: 0.5354
Batch 350, Loss: 0.5278
Batch 360, Loss: 0.4942
Batch 370, Loss: 0.5851
Batch 380, Loss: 0.5143
Batch 390, Loss: 0.5087
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.058274269104004 seconds
Epoch 59 accuracy: 83.79%
Batch 10, Loss: 0.5181
Batch 20, Loss: 0.4772
Batch 30, Loss: 0.5082
Batch 40, Loss: 0.5525
Batch 50, Loss: 0.5104
Batch 60, Loss: 0.5192
Batch 70, Loss: 0.5129
Batch 80, Loss: 0.5108
Batch 90, Loss: 0.5345
Batch 100, Loss: 0.4979
Batch 110, Loss: 0.5141
Batch 120, Loss: 0.5095
Batch 130, Loss: 0.5387
Batch 140, Loss: 0.5156
Batch 150, Loss: 0.5284
Batch 160, Loss: 0.5533
Batch 170, Loss: 0.5268
Batch 180, Loss: 0.5178
Batch 190, Loss: 0.5005
Batch 200, Loss: 0.5213
Batch 210, Loss: 0.5235
Batch 220, Loss: 0.5360
Batch 230, Loss: 0.5254
Batch 240, Loss: 0.5563
Batch 250, Loss: 0.5409
Batch 260, Loss: 0.5192
Batch 270, Loss: 0.4801
Batch 280, Loss: 0.4987
Batch 290, Loss: 0.5340
Batch 300, Loss: 0.5556
Batch 310, Loss: 0.5055
Batch 320, Loss: 0.4976
Batch 330, Loss: 0.4749
Batch 340, Loss: 0.5229
Batch 350, Loss: 0.5141
Batch 360, Loss: 0.5125
Batch 370, Loss: 0.5181
Batch 380, Loss: 0.4847
Batch 390, Loss: 0.4987
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.054811000823975 seconds
Epoch 60 accuracy: 86.45%
Batch 10, Loss: 0.4954
Batch 20, Loss: 0.5003
Batch 30, Loss: 0.5053
Batch 40, Loss: 0.5289
Batch 50, Loss: 0.5071
Batch 60, Loss: 0.4693
Batch 70, Loss: 0.5024
Batch 80, Loss: 0.5457
Batch 90, Loss: 0.5223
Batch 100, Loss: 0.5201
Batch 110, Loss: 0.5169
Batch 120, Loss: 0.5503
Batch 130, Loss: 0.4928
Batch 140, Loss: 0.5183
Batch 150, Loss: 0.5107
Batch 160, Loss: 0.5002
Batch 170, Loss: 0.5088
Batch 180, Loss: 0.5112
Batch 190, Loss: 0.5135
Batch 200, Loss: 0.4973
Batch 210, Loss: 0.5108
Batch 220, Loss: 0.4947
Batch 230, Loss: 0.5530
Batch 240, Loss: 0.5652
Batch 250, Loss: 0.4979
Batch 260, Loss: 0.5051
Batch 270, Loss: 0.4816
Batch 280, Loss: 0.5119
Batch 290, Loss: 0.5227
Batch 300, Loss: 0.5140
Batch 310, Loss: 0.5573
Batch 320, Loss: 0.5089
Batch 330, Loss: 0.5386
Batch 340, Loss: 0.5321
Batch 350, Loss: 0.5176
Batch 360, Loss: 0.4780
Batch 370, Loss: 0.5215
Batch 380, Loss: 0.5857
Batch 390, Loss: 0.5565
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.046117067337036 seconds
Epoch 61 accuracy: 82.6%
Batch 10, Loss: 0.5315
Batch 20, Loss: 0.5101
Batch 30, Loss: 0.5217
Batch 40, Loss: 0.4871
Batch 50, Loss: 0.5073
Batch 60, Loss: 0.5046
Batch 70, Loss: 0.4887
Batch 80, Loss: 0.5163
Batch 90, Loss: 0.5225
Batch 100, Loss: 0.5434
Batch 110, Loss: 0.5124
Batch 120, Loss: 0.5007
Batch 130, Loss: 0.4696
Batch 140, Loss: 0.5731
Batch 150, Loss: 0.5050
Batch 160, Loss: 0.4909
Batch 170, Loss: 0.5211
Batch 180, Loss: 0.5073
Batch 190, Loss: 0.4989
Batch 200, Loss: 0.5339
Batch 210, Loss: 0.5082
Batch 220, Loss: 0.5182
Batch 230, Loss: 0.5126
Batch 240, Loss: 0.5282
Batch 250, Loss: 0.4499
Batch 260, Loss: 0.5186
Batch 270, Loss: 0.5563
Batch 280, Loss: 0.5091
Batch 290, Loss: 0.5262
Batch 300, Loss: 0.4852
Batch 310, Loss: 0.4945
Batch 320, Loss: 0.4847
Batch 330, Loss: 0.5303
Batch 340, Loss: 0.5156
Batch 350, Loss: 0.5282
Batch 360, Loss: 0.5398
Batch 370, Loss: 0.5298
Batch 380, Loss: 0.5095
Batch 390, Loss: 0.4954
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 24.99544596672058 seconds
Epoch 62 accuracy: 85.84%
Batch 10, Loss: 0.5093
Batch 20, Loss: 0.4908
Batch 30, Loss: 0.5259
Batch 40, Loss: 0.5497
Batch 50, Loss: 0.5197
Batch 60, Loss: 0.5317
Batch 70, Loss: 0.5495
Batch 80, Loss: 0.5011
Batch 90, Loss: 0.4859
Batch 100, Loss: 0.4829
Batch 110, Loss: 0.5122
Batch 120, Loss: 0.5256
Batch 130, Loss: 0.5020
Batch 140, Loss: 0.4660
Batch 150, Loss: 0.5154
Batch 160, Loss: 0.5244
Batch 170, Loss: 0.5080
Batch 180, Loss: 0.5185
Batch 190, Loss: 0.4901
Batch 200, Loss: 0.5267
Batch 210, Loss: 0.5369
Batch 220, Loss: 0.5102
Batch 230, Loss: 0.5605
Batch 240, Loss: 0.5204
Batch 250, Loss: 0.5120
Batch 260, Loss: 0.5435
Batch 270, Loss: 0.5076
Batch 280, Loss: 0.5252
Batch 290, Loss: 0.5324
Batch 300, Loss: 0.5238
Batch 310, Loss: 0.5388
Batch 320, Loss: 0.5190
Batch 330, Loss: 0.5032
Batch 340, Loss: 0.4627
Batch 350, Loss: 0.5023
Batch 360, Loss: 0.5055
Batch 370, Loss: 0.4997
Batch 380, Loss: 0.5235
Batch 390, Loss: 0.5298
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 24.998271703720093 seconds
Epoch 63 accuracy: 84.44%
Batch 10, Loss: 0.5091
Batch 20, Loss: 0.5019
Batch 30, Loss: 0.4871
Batch 40, Loss: 0.4724
Batch 50, Loss: 0.5090
Batch 60, Loss: 0.5274
Batch 70, Loss: 0.4784
Batch 80, Loss: 0.4657
Batch 90, Loss: 0.5265
Batch 100, Loss: 0.5155
Batch 110, Loss: 0.4887
Batch 120, Loss: 0.5123
Batch 130, Loss: 0.5105
Batch 140, Loss: 0.4684
Batch 150, Loss: 0.4991
Batch 160, Loss: 0.5060
Batch 170, Loss: 0.4879
Batch 180, Loss: 0.5310
Batch 190, Loss: 0.5056
Batch 200, Loss: 0.5090
Batch 210, Loss: 0.4972
Batch 220, Loss: 0.5164
Batch 230, Loss: 0.5282
Batch 240, Loss: 0.5066
Batch 250, Loss: 0.5204
Batch 260, Loss: 0.5350
Batch 270, Loss: 0.5309
Batch 280, Loss: 0.5420
Batch 290, Loss: 0.5711
Batch 300, Loss: 0.5213
Batch 310, Loss: 0.4932
Batch 320, Loss: 0.5226
Batch 330, Loss: 0.5163
Batch 340, Loss: 0.4824
Batch 350, Loss: 0.5312
Batch 360, Loss: 0.5321
Batch 370, Loss: 0.4970
Batch 380, Loss: 0.5040
Batch 390, Loss: 0.5311
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.011067152023315 seconds
Epoch 64 accuracy: 85.5%
Batch 10, Loss: 0.5148
Batch 20, Loss: 0.5231
Batch 30, Loss: 0.4557
Batch 40, Loss: 0.4878
Batch 50, Loss: 0.5193
Batch 60, Loss: 0.4681
Batch 70, Loss: 0.5237
Batch 80, Loss: 0.5519
Batch 90, Loss: 0.5087
Batch 100, Loss: 0.4741
Batch 110, Loss: 0.4772
Batch 120, Loss: 0.4951
Batch 130, Loss: 0.5106
Batch 140, Loss: 0.5383
Batch 150, Loss: 0.5246
Batch 160, Loss: 0.5239
Batch 170, Loss: 0.5226
Batch 180, Loss: 0.5076
Batch 190, Loss: 0.5088
Batch 200, Loss: 0.5156
Batch 210, Loss: 0.5019
Batch 220, Loss: 0.4959
Batch 230, Loss: 0.5196
Batch 240, Loss: 0.4948
Batch 250, Loss: 0.4922
Batch 260, Loss: 0.5362
Batch 270, Loss: 0.4921
Batch 280, Loss: 0.4697
Batch 290, Loss: 0.5420
Batch 300, Loss: 0.4871
Batch 310, Loss: 0.5057
Batch 320, Loss: 0.5059
Batch 330, Loss: 0.5548
Batch 340, Loss: 0.5508
Batch 350, Loss: 0.5221
Batch 360, Loss: 0.4617
Batch 370, Loss: 0.5243
Batch 380, Loss: 0.4789
Batch 390, Loss: 0.5005
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.03602385520935 seconds
Epoch 65 accuracy: 87.02%
Batch 10, Loss: 0.4667
Batch 20, Loss: 0.5015
Batch 30, Loss: 0.4769
Batch 40, Loss: 0.4730
Batch 50, Loss: 0.5008
Batch 60, Loss: 0.5189
Batch 70, Loss: 0.5034
Batch 80, Loss: 0.5349
Batch 90, Loss: 0.5401
Batch 100, Loss: 0.5085
Batch 110, Loss: 0.5476
Batch 120, Loss: 0.5177
Batch 130, Loss: 0.4857
Batch 140, Loss: 0.5045
Batch 150, Loss: 0.4909
Batch 160, Loss: 0.4759
Batch 170, Loss: 0.4850
Batch 180, Loss: 0.5086
Batch 190, Loss: 0.5215
Batch 200, Loss: 0.5451
Batch 210, Loss: 0.5136
Batch 220, Loss: 0.5182
Batch 230, Loss: 0.4893
Batch 240, Loss: 0.5387
Batch 250, Loss: 0.4650
Batch 260, Loss: 0.4713
Batch 270, Loss: 0.5127
Batch 280, Loss: 0.4967
Batch 290, Loss: 0.4732
Batch 300, Loss: 0.4966
Batch 310, Loss: 0.4929
Batch 320, Loss: 0.5229
Batch 330, Loss: 0.5377
Batch 340, Loss: 0.5054
Batch 350, Loss: 0.4757
Batch 360, Loss: 0.4960
Batch 370, Loss: 0.5446
Batch 380, Loss: 0.5293
Batch 390, Loss: 0.5172
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.021406650543213 seconds
Epoch 66 accuracy: 84.32%
Batch 10, Loss: 0.5075
Batch 20, Loss: 0.5035
Batch 30, Loss: 0.5135
Batch 40, Loss: 0.5059
Batch 50, Loss: 0.4835
Batch 60, Loss: 0.4867
Batch 70, Loss: 0.5170
Batch 80, Loss: 0.5172
Batch 90, Loss: 0.5176
Batch 100, Loss: 0.5117
Batch 110, Loss: 0.4590
Batch 120, Loss: 0.4839
Batch 130, Loss: 0.5021
Batch 140, Loss: 0.5001
Batch 150, Loss: 0.5130
Batch 160, Loss: 0.5275
Batch 170, Loss: 0.5386
Batch 180, Loss: 0.5073
Batch 190, Loss: 0.5082
Batch 200, Loss: 0.5137
Batch 210, Loss: 0.5098
Batch 220, Loss: 0.5240
Batch 230, Loss: 0.5105
Batch 240, Loss: 0.5272
Batch 250, Loss: 0.5248
Batch 260, Loss: 0.5182
Batch 270, Loss: 0.5210
Batch 280, Loss: 0.5019
Batch 290, Loss: 0.5244
Batch 300, Loss: 0.5354
Batch 310, Loss: 0.5121
Batch 320, Loss: 0.4915
Batch 330, Loss: 0.5081
Batch 340, Loss: 0.4955
Batch 350, Loss: 0.5380
Batch 360, Loss: 0.5196
Batch 370, Loss: 0.5205
Batch 380, Loss: 0.4995
Batch 390, Loss: 0.5001
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 24.993629693984985 seconds
Epoch 67 accuracy: 83.22%
Batch 10, Loss: 0.5015
Batch 20, Loss: 0.5201
Batch 30, Loss: 0.5353
Batch 40, Loss: 0.5130
Batch 50, Loss: 0.4920
Batch 60, Loss: 0.4858
Batch 70, Loss: 0.4608
Batch 80, Loss: 0.4996
Batch 90, Loss: 0.5192
Batch 100, Loss: 0.5409
Batch 110, Loss: 0.5400
Batch 120, Loss: 0.4932
Batch 130, Loss: 0.5025
Batch 140, Loss: 0.4803
Batch 150, Loss: 0.5124
Batch 160, Loss: 0.4977
Batch 170, Loss: 0.4974
Batch 180, Loss: 0.4851
Batch 190, Loss: 0.5285
Batch 200, Loss: 0.4885
Batch 210, Loss: 0.5407
Batch 220, Loss: 0.4938
Batch 230, Loss: 0.4763
Batch 240, Loss: 0.5181
Batch 250, Loss: 0.4972
Batch 260, Loss: 0.5147
Batch 270, Loss: 0.4978
Batch 280, Loss: 0.4873
Batch 290, Loss: 0.5119
Batch 300, Loss: 0.4918
Batch 310, Loss: 0.5226
Batch 320, Loss: 0.4786
Batch 330, Loss: 0.4997
Batch 340, Loss: 0.4929
Batch 350, Loss: 0.4801
Batch 360, Loss: 0.5275
Batch 370, Loss: 0.4908
Batch 380, Loss: 0.5237
Batch 390, Loss: 0.5020
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.04023027420044 seconds
Epoch 68 accuracy: 86.53%
Batch 10, Loss: 0.4626
Batch 20, Loss: 0.4651
Batch 30, Loss: 0.4797
Batch 40, Loss: 0.5275
Batch 50, Loss: 0.4959
Batch 60, Loss: 0.4685
Batch 70, Loss: 0.5132
Batch 80, Loss: 0.5238
Batch 90, Loss: 0.5168
Batch 100, Loss: 0.4615
Batch 110, Loss: 0.4855
Batch 120, Loss: 0.5008
Batch 130, Loss: 0.4557
Batch 140, Loss: 0.5056
Batch 150, Loss: 0.4997
Batch 160, Loss: 0.5268
Batch 170, Loss: 0.4683
Batch 180, Loss: 0.4944
Batch 190, Loss: 0.4979
Batch 200, Loss: 0.5052
Batch 210, Loss: 0.5311
Batch 220, Loss: 0.4595
Batch 230, Loss: 0.5196
Batch 240, Loss: 0.4640
Batch 250, Loss: 0.5038
Batch 260, Loss: 0.4984
Batch 270, Loss: 0.4840
Batch 280, Loss: 0.5436
Batch 290, Loss: 0.4791
Batch 300, Loss: 0.4639
Batch 310, Loss: 0.5225
Batch 320, Loss: 0.5446
Batch 330, Loss: 0.4918
Batch 340, Loss: 0.4679
Batch 350, Loss: 0.5353
Batch 360, Loss: 0.5360
Batch 370, Loss: 0.5130
Batch 380, Loss: 0.4940
Batch 390, Loss: 0.4972
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.01362943649292 seconds
Epoch 69 accuracy: 83.95%
Batch 10, Loss: 0.5152
Batch 20, Loss: 0.4863
Batch 30, Loss: 0.5087
Batch 40, Loss: 0.5288
Batch 50, Loss: 0.4485
Batch 60, Loss: 0.5248
Batch 70, Loss: 0.4780
Batch 80, Loss: 0.4985
Batch 90, Loss: 0.4794
Batch 100, Loss: 0.4756
Batch 110, Loss: 0.4780
Batch 120, Loss: 0.4791
Batch 130, Loss: 0.5106
Batch 140, Loss: 0.4849
Batch 150, Loss: 0.5137
Batch 160, Loss: 0.5228
Batch 170, Loss: 0.5253
Batch 180, Loss: 0.4893
Batch 190, Loss: 0.4938
Batch 200, Loss: 0.4669
Batch 210, Loss: 0.5009
Batch 220, Loss: 0.4853
Batch 230, Loss: 0.4873
Batch 240, Loss: 0.4895
Batch 250, Loss: 0.5062
Batch 260, Loss: 0.4659
Batch 270, Loss: 0.5140
Batch 280, Loss: 0.5244
Batch 290, Loss: 0.5369
Batch 300, Loss: 0.4959
Batch 310, Loss: 0.5216
Batch 320, Loss: 0.4676
Batch 330, Loss: 0.5261
Batch 340, Loss: 0.5305
Batch 350, Loss: 0.5122
Batch 360, Loss: 0.4936
Batch 370, Loss: 0.5335
Batch 380, Loss: 0.5305
Batch 390, Loss: 0.4937
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.07406187057495 seconds
Epoch 70 accuracy: 85.17%
Batch 10, Loss: 0.5213
Batch 20, Loss: 0.4546
Batch 30, Loss: 0.4916
Batch 40, Loss: 0.4740
Batch 50, Loss: 0.4747
Batch 60, Loss: 0.5246
Batch 70, Loss: 0.5144
Batch 80, Loss: 0.4874
Batch 90, Loss: 0.5209
Batch 100, Loss: 0.4494
Batch 110, Loss: 0.5280
Batch 120, Loss: 0.4703
Batch 130, Loss: 0.5138
Batch 140, Loss: 0.5274
Batch 150, Loss: 0.5115
Batch 160, Loss: 0.5061
Batch 170, Loss: 0.5446
Batch 180, Loss: 0.4832
Batch 190, Loss: 0.5106
Batch 200, Loss: 0.4744
Batch 210, Loss: 0.4680
Batch 220, Loss: 0.4910
Batch 230, Loss: 0.4863
Batch 240, Loss: 0.5319
Batch 250, Loss: 0.5387
Batch 260, Loss: 0.5494
Batch 270, Loss: 0.5418
Batch 280, Loss: 0.5035
Batch 290, Loss: 0.5015
Batch 300, Loss: 0.5244
Batch 310, Loss: 0.5316
Batch 320, Loss: 0.4532
Batch 330, Loss: 0.4772
Batch 340, Loss: 0.5092
Batch 350, Loss: 0.4763
Batch 360, Loss: 0.5308
Batch 370, Loss: 0.5373
Batch 380, Loss: 0.5071
Batch 390, Loss: 0.4675
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.019119262695312 seconds
Epoch 71 accuracy: 86.41%
Batch 10, Loss: 0.4926
Batch 20, Loss: 0.5076
Batch 30, Loss: 0.4743
Batch 40, Loss: 0.5164
Batch 50, Loss: 0.5324
Batch 60, Loss: 0.4936
Batch 70, Loss: 0.4850
Batch 80, Loss: 0.4891
Batch 90, Loss: 0.4973
Batch 100, Loss: 0.4916
Batch 110, Loss: 0.5331
Batch 120, Loss: 0.5029
Batch 130, Loss: 0.5262
Batch 140, Loss: 0.4868
Batch 150, Loss: 0.4546
Batch 160, Loss: 0.4807
Batch 170, Loss: 0.4704
Batch 180, Loss: 0.4917
Batch 190, Loss: 0.4503
Batch 200, Loss: 0.4927
Batch 210, Loss: 0.5002
Batch 220, Loss: 0.4651
Batch 230, Loss: 0.5236
Batch 240, Loss: 0.4974
Batch 250, Loss: 0.5172
Batch 260, Loss: 0.5346
Batch 270, Loss: 0.5469
Batch 280, Loss: 0.5239
Batch 290, Loss: 0.4690
Batch 300, Loss: 0.5193
Batch 310, Loss: 0.4912
Batch 320, Loss: 0.5624
Batch 330, Loss: 0.5112
Batch 340, Loss: 0.4811
Batch 350, Loss: 0.5093
Batch 360, Loss: 0.4706
Batch 370, Loss: 0.5056
Batch 380, Loss: 0.5038
Batch 390, Loss: 0.4739
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.023150205612183 seconds
Epoch 72 accuracy: 84.83%
Batch 10, Loss: 0.4597
Batch 20, Loss: 0.5218
Batch 30, Loss: 0.5096
Batch 40, Loss: 0.4651
Batch 50, Loss: 0.5244
Batch 60, Loss: 0.4907
Batch 70, Loss: 0.4756
Batch 80, Loss: 0.5096
Batch 90, Loss: 0.4773
Batch 100, Loss: 0.4573
Batch 110, Loss: 0.4937
Batch 120, Loss: 0.5022
Batch 130, Loss: 0.5008
Batch 140, Loss: 0.4965
Batch 150, Loss: 0.4812
Batch 160, Loss: 0.4573
Batch 170, Loss: 0.5251
Batch 180, Loss: 0.4746
Batch 190, Loss: 0.4823
Batch 200, Loss: 0.5003
Batch 210, Loss: 0.5380
Batch 220, Loss: 0.4834
Batch 230, Loss: 0.4912
Batch 240, Loss: 0.5151
Batch 250, Loss: 0.5094
Batch 260, Loss: 0.4937
Batch 270, Loss: 0.4843
Batch 280, Loss: 0.4815
Batch 290, Loss: 0.5018
Batch 300, Loss: 0.4918
Batch 310, Loss: 0.5154
Batch 320, Loss: 0.5025
Batch 330, Loss: 0.4907
Batch 340, Loss: 0.5193
Batch 350, Loss: 0.5083
Batch 360, Loss: 0.5100
Batch 370, Loss: 0.5050
Batch 380, Loss: 0.4849
Batch 390, Loss: 0.5069
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 24.974174976348877 seconds
Epoch 73 accuracy: 80.65%
Batch 10, Loss: 0.4747
Batch 20, Loss: 0.5080
Batch 30, Loss: 0.5064
Batch 40, Loss: 0.4534
Batch 50, Loss: 0.5102
Batch 60, Loss: 0.5052
Batch 70, Loss: 0.5006
Batch 80, Loss: 0.5125
Batch 90, Loss: 0.4959
Batch 100, Loss: 0.4654
Batch 110, Loss: 0.4968
Batch 120, Loss: 0.4852
Batch 130, Loss: 0.5212
Batch 140, Loss: 0.5281
Batch 150, Loss: 0.5372
Batch 160, Loss: 0.5104
Batch 170, Loss: 0.5087
Batch 180, Loss: 0.4852
Batch 190, Loss: 0.4884
Batch 200, Loss: 0.4923
Batch 210, Loss: 0.5348
Batch 220, Loss: 0.4783
Batch 230, Loss: 0.4604
Batch 240, Loss: 0.4879
Batch 250, Loss: 0.5276
Batch 260, Loss: 0.4894
Batch 270, Loss: 0.4978
Batch 280, Loss: 0.5135
Batch 290, Loss: 0.5099
Batch 300, Loss: 0.4695
Batch 310, Loss: 0.4709
Batch 320, Loss: 0.4869
Batch 330, Loss: 0.4614
Batch 340, Loss: 0.4949
Batch 350, Loss: 0.5160
Batch 360, Loss: 0.5456
Batch 370, Loss: 0.5040
Batch 380, Loss: 0.4930
Batch 390, Loss: 0.4853
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.12843894958496 seconds
Epoch 74 accuracy: 86.85%
Batch 10, Loss: 0.4894
Batch 20, Loss: 0.4870
Batch 30, Loss: 0.4554
Batch 40, Loss: 0.4638
Batch 50, Loss: 0.4738
Batch 60, Loss: 0.4942
Batch 70, Loss: 0.4774
Batch 80, Loss: 0.4686
Batch 90, Loss: 0.4918
Batch 100, Loss: 0.5044
Batch 110, Loss: 0.5175
Batch 120, Loss: 0.5139
Batch 130, Loss: 0.4801
Batch 140, Loss: 0.4732
Batch 150, Loss: 0.5053
Batch 160, Loss: 0.4776
Batch 170, Loss: 0.5326
Batch 180, Loss: 0.5027
Batch 190, Loss: 0.5070
Batch 200, Loss: 0.4803
Batch 210, Loss: 0.4903
Batch 220, Loss: 0.5220
Batch 230, Loss: 0.5038
Batch 240, Loss: 0.4811
Batch 250, Loss: 0.5044
Batch 260, Loss: 0.5136
Batch 270, Loss: 0.4588
Batch 280, Loss: 0.5091
Batch 290, Loss: 0.4278
Batch 300, Loss: 0.4815
Batch 310, Loss: 0.4827
Batch 320, Loss: 0.5223
Batch 330, Loss: 0.4991
Batch 340, Loss: 0.4880
Batch 350, Loss: 0.4806
Batch 360, Loss: 0.5182
Batch 370, Loss: 0.5215
Batch 380, Loss: 0.4833
Batch 390, Loss: 0.4716
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.154723405838013 seconds
Epoch 75 accuracy: 86.4%
Batch 10, Loss: 0.4803
Batch 20, Loss: 0.4835
Batch 30, Loss: 0.4766
Batch 40, Loss: 0.4749
Batch 50, Loss: 0.4974
Batch 60, Loss: 0.4911
Batch 70, Loss: 0.4861
Batch 80, Loss: 0.4756
Batch 90, Loss: 0.4763
Batch 100, Loss: 0.4546
Batch 110, Loss: 0.4478
Batch 120, Loss: 0.4420
Batch 130, Loss: 0.5062
Batch 140, Loss: 0.4957
Batch 150, Loss: 0.5155
Batch 160, Loss: 0.4840
Batch 170, Loss: 0.5045
Batch 180, Loss: 0.4784
Batch 190, Loss: 0.5294
Batch 200, Loss: 0.4750
Batch 210, Loss: 0.4817
Batch 220, Loss: 0.5044
Batch 230, Loss: 0.4666
Batch 240, Loss: 0.4945
Batch 250, Loss: 0.5081
Batch 260, Loss: 0.4741
Batch 270, Loss: 0.4758
Batch 280, Loss: 0.4920
Batch 290, Loss: 0.4873
Batch 300, Loss: 0.4794
Batch 310, Loss: 0.4858
Batch 320, Loss: 0.5068
Batch 330, Loss: 0.5175
Batch 340, Loss: 0.4672
Batch 350, Loss: 0.4769
Batch 360, Loss: 0.4812
Batch 370, Loss: 0.5246
Batch 380, Loss: 0.4863
Batch 390, Loss: 0.5028
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 24.966089487075806 seconds
Epoch 76 accuracy: 86.35%
Batch 10, Loss: 0.4716
Batch 20, Loss: 0.4613
Batch 30, Loss: 0.4674
Batch 40, Loss: 0.5017
Batch 50, Loss: 0.4983
Batch 60, Loss: 0.4891
Batch 70, Loss: 0.5026
Batch 80, Loss: 0.4445
Batch 90, Loss: 0.4712
Batch 100, Loss: 0.4925
Batch 110, Loss: 0.4844
Batch 120, Loss: 0.4741
Batch 130, Loss: 0.4530
Batch 140, Loss: 0.4720
Batch 150, Loss: 0.4727
Batch 160, Loss: 0.4816
Batch 170, Loss: 0.4981
Batch 180, Loss: 0.5002
Batch 190, Loss: 0.4884
Batch 200, Loss: 0.4896
Batch 210, Loss: 0.4585
Batch 220, Loss: 0.4851
Batch 230, Loss: 0.4789
Batch 240, Loss: 0.5210
Batch 250, Loss: 0.5174
Batch 260, Loss: 0.5181
Batch 270, Loss: 0.5155
Batch 280, Loss: 0.4960
Batch 290, Loss: 0.5256
Batch 300, Loss: 0.4875
Batch 310, Loss: 0.4759
Batch 320, Loss: 0.4437
Batch 330, Loss: 0.5120
Batch 340, Loss: 0.4960
Batch 350, Loss: 0.4796
Batch 360, Loss: 0.4881
Batch 370, Loss: 0.4829
Batch 380, Loss: 0.4622
Batch 390, Loss: 0.4851
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.025695323944092 seconds
Epoch 77 accuracy: 84.06%
Batch 10, Loss: 0.4825
Batch 20, Loss: 0.4621
Batch 30, Loss: 0.4919
Batch 40, Loss: 0.4548
Batch 50, Loss: 0.4640
Batch 60, Loss: 0.4988
Batch 70, Loss: 0.4945
Batch 80, Loss: 0.4797
Batch 90, Loss: 0.5049
Batch 100, Loss: 0.4506
Batch 110, Loss: 0.4672
Batch 120, Loss: 0.4505
Batch 130, Loss: 0.5371
Batch 140, Loss: 0.4885
Batch 150, Loss: 0.4514
Batch 160, Loss: 0.4660
Batch 170, Loss: 0.4370
Batch 180, Loss: 0.4695
Batch 190, Loss: 0.5037
Batch 200, Loss: 0.4806
Batch 210, Loss: 0.4500
Batch 220, Loss: 0.5121
Batch 230, Loss: 0.4546
Batch 240, Loss: 0.4880
Batch 250, Loss: 0.5236
Batch 260, Loss: 0.5189
Batch 270, Loss: 0.4818
Batch 280, Loss: 0.5113
Batch 290, Loss: 0.4749
Batch 300, Loss: 0.5088
Batch 310, Loss: 0.5079
Batch 320, Loss: 0.5037
Batch 330, Loss: 0.4907
Batch 340, Loss: 0.4769
Batch 350, Loss: 0.5026
Batch 360, Loss: 0.5062
Batch 370, Loss: 0.5142
Batch 380, Loss: 0.5327
Batch 390, Loss: 0.4605
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.02685809135437 seconds
Epoch 78 accuracy: 86.4%
Batch 10, Loss: 0.4956
Batch 20, Loss: 0.4591
Batch 30, Loss: 0.4981
Batch 40, Loss: 0.4855
Batch 50, Loss: 0.4671
Batch 60, Loss: 0.4297
Batch 70, Loss: 0.4464
Batch 80, Loss: 0.4481
Batch 90, Loss: 0.4948
Batch 100, Loss: 0.4656
Batch 110, Loss: 0.4413
Batch 120, Loss: 0.4956
Batch 130, Loss: 0.4479
Batch 140, Loss: 0.4796
Batch 150, Loss: 0.5487
Batch 160, Loss: 0.5087
Batch 170, Loss: 0.4381
Batch 180, Loss: 0.4957
Batch 190, Loss: 0.4575
Batch 200, Loss: 0.4667
Batch 210, Loss: 0.4985
Batch 220, Loss: 0.4650
Batch 230, Loss: 0.4796
Batch 240, Loss: 0.4897
Batch 250, Loss: 0.5028
Batch 260, Loss: 0.4865
Batch 270, Loss: 0.4768
Batch 280, Loss: 0.5060
Batch 290, Loss: 0.4653
Batch 300, Loss: 0.4325
Batch 310, Loss: 0.5291
Batch 320, Loss: 0.4954
Batch 330, Loss: 0.4884
Batch 340, Loss: 0.4720
Batch 350, Loss: 0.4969
Batch 360, Loss: 0.5049
Batch 370, Loss: 0.4642
Batch 380, Loss: 0.4996
Batch 390, Loss: 0.5129
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.081100463867188 seconds
Epoch 79 accuracy: 85.18%
Batch 10, Loss: 0.4928
Batch 20, Loss: 0.4674
Batch 30, Loss: 0.4919
Batch 40, Loss: 0.4946
Batch 50, Loss: 0.4629
Batch 60, Loss: 0.5136
Batch 70, Loss: 0.4999
Batch 80, Loss: 0.4952
Batch 90, Loss: 0.4419
Batch 100, Loss: 0.4823
Batch 110, Loss: 0.4636
Batch 120, Loss: 0.4950
Batch 130, Loss: 0.4865
Batch 140, Loss: 0.4723
Batch 150, Loss: 0.5105
Batch 160, Loss: 0.4728
Batch 170, Loss: 0.4978
Batch 180, Loss: 0.4822
Batch 190, Loss: 0.4869
Batch 200, Loss: 0.4592
Batch 210, Loss: 0.4890
Batch 220, Loss: 0.4799
Batch 230, Loss: 0.4652
Batch 240, Loss: 0.4624
Batch 250, Loss: 0.5030
Batch 260, Loss: 0.4669
Batch 270, Loss: 0.4463
Batch 280, Loss: 0.4798
Batch 290, Loss: 0.4878
Batch 300, Loss: 0.4974
Batch 310, Loss: 0.4715
Batch 320, Loss: 0.4981
Batch 330, Loss: 0.5035
Batch 340, Loss: 0.4762
Batch 350, Loss: 0.4571
Batch 360, Loss: 0.4810
Batch 370, Loss: 0.4533
Batch 380, Loss: 0.5198
Batch 390, Loss: 0.4812
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 24.98677349090576 seconds
Epoch 80 accuracy: 85.08%
Batch 10, Loss: 0.4953
Batch 20, Loss: 0.5158
Batch 30, Loss: 0.4494
Batch 40, Loss: 0.4909
Batch 50, Loss: 0.5191
Batch 60, Loss: 0.4541
Batch 70, Loss: 0.4668
Batch 80, Loss: 0.4827
Batch 90, Loss: 0.4574
Batch 100, Loss: 0.4777
Batch 110, Loss: 0.4826
Batch 120, Loss: 0.4716
Batch 130, Loss: 0.4786
Batch 140, Loss: 0.4880
Batch 150, Loss: 0.5065
Batch 160, Loss: 0.4704
Batch 170, Loss: 0.4506
Batch 180, Loss: 0.4979
Batch 190, Loss: 0.4702
Batch 200, Loss: 0.4737
Batch 210, Loss: 0.4260
Batch 220, Loss: 0.4941
Batch 230, Loss: 0.4857
Batch 240, Loss: 0.5099
Batch 250, Loss: 0.4711
Batch 260, Loss: 0.4659
Batch 270, Loss: 0.5093
Batch 280, Loss: 0.4903
Batch 290, Loss: 0.4962
Batch 300, Loss: 0.5090
Batch 310, Loss: 0.4898
Batch 320, Loss: 0.4680
Batch 330, Loss: 0.4848
Batch 340, Loss: 0.4427
Batch 350, Loss: 0.4841
Batch 360, Loss: 0.4780
Batch 370, Loss: 0.4568
Batch 380, Loss: 0.5031
Batch 390, Loss: 0.4509
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.02736783027649 seconds
Epoch 81 accuracy: 85.86%
Batch 10, Loss: 0.4768
Batch 20, Loss: 0.4932
Batch 30, Loss: 0.4473
Batch 40, Loss: 0.4919
Batch 50, Loss: 0.4452
Batch 60, Loss: 0.4827
Batch 70, Loss: 0.4663
Batch 80, Loss: 0.5040
Batch 90, Loss: 0.4493
Batch 100, Loss: 0.4509
Batch 110, Loss: 0.4742
Batch 120, Loss: 0.4810
Batch 130, Loss: 0.4586
Batch 140, Loss: 0.4982
Batch 150, Loss: 0.4933
Batch 160, Loss: 0.4492
Batch 170, Loss: 0.4876
Batch 180, Loss: 0.4548
Batch 190, Loss: 0.4934
Batch 200, Loss: 0.4603
Batch 210, Loss: 0.4723
Batch 220, Loss: 0.4647
Batch 230, Loss: 0.4623
Batch 240, Loss: 0.4777
Batch 250, Loss: 0.4695
Batch 260, Loss: 0.4727
Batch 270, Loss: 0.4556
Batch 280, Loss: 0.5242
Batch 290, Loss: 0.5030
Batch 300, Loss: 0.4542
Batch 310, Loss: 0.4625
Batch 320, Loss: 0.4865
Batch 330, Loss: 0.5093
Batch 340, Loss: 0.4825
Batch 350, Loss: 0.4585
Batch 360, Loss: 0.4791
Batch 370, Loss: 0.4423
Batch 380, Loss: 0.4796
Batch 390, Loss: 0.4741
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 24.98091173171997 seconds
Epoch 82 accuracy: 87.14%
Batch 10, Loss: 0.4635
Batch 20, Loss: 0.5250
Batch 30, Loss: 0.5017
Batch 40, Loss: 0.4770
Batch 50, Loss: 0.4501
Batch 60, Loss: 0.4604
Batch 70, Loss: 0.4523
Batch 80, Loss: 0.4585
Batch 90, Loss: 0.4660
Batch 100, Loss: 0.4627
Batch 110, Loss: 0.4783
Batch 120, Loss: 0.4363
Batch 130, Loss: 0.5090
Batch 140, Loss: 0.4719
Batch 150, Loss: 0.4782
Batch 160, Loss: 0.4896
Batch 170, Loss: 0.4704
Batch 180, Loss: 0.4705
Batch 190, Loss: 0.4687
Batch 200, Loss: 0.4781
Batch 210, Loss: 0.4841
Batch 220, Loss: 0.5082
Batch 230, Loss: 0.4652
Batch 240, Loss: 0.4803
Batch 250, Loss: 0.4648
Batch 260, Loss: 0.4521
Batch 270, Loss: 0.4906
Batch 280, Loss: 0.4793
Batch 290, Loss: 0.4482
Batch 300, Loss: 0.4822
Batch 310, Loss: 0.4831
Batch 320, Loss: 0.4748
Batch 330, Loss: 0.4961
Batch 340, Loss: 0.4679
Batch 350, Loss: 0.4490
Batch 360, Loss: 0.4476
Batch 370, Loss: 0.4878
Batch 380, Loss: 0.5128
Batch 390, Loss: 0.4527
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.04527974128723 seconds
Epoch 83 accuracy: 88.08%
Batch 10, Loss: 0.4999
Batch 20, Loss: 0.4611
Batch 30, Loss: 0.4562
Batch 40, Loss: 0.4618
Batch 50, Loss: 0.4942
Batch 60, Loss: 0.4649
Batch 70, Loss: 0.4612
Batch 80, Loss: 0.4603
Batch 90, Loss: 0.4748
Batch 100, Loss: 0.4766
Batch 110, Loss: 0.4653
Batch 120, Loss: 0.4427
Batch 130, Loss: 0.4590
Batch 140, Loss: 0.4575
Batch 150, Loss: 0.4667
Batch 160, Loss: 0.4773
Batch 170, Loss: 0.4552
Batch 180, Loss: 0.4684
Batch 190, Loss: 0.4608
Batch 200, Loss: 0.4528
Batch 210, Loss: 0.4449
Batch 220, Loss: 0.4437
Batch 230, Loss: 0.4817
Batch 240, Loss: 0.4878
Batch 250, Loss: 0.4776
Batch 260, Loss: 0.4822
Batch 270, Loss: 0.5146
Batch 280, Loss: 0.5259
Batch 290, Loss: 0.4752
Batch 300, Loss: 0.4830
Batch 310, Loss: 0.4544
Batch 320, Loss: 0.4638
Batch 330, Loss: 0.4788
Batch 340, Loss: 0.4542
Batch 350, Loss: 0.4458
Batch 360, Loss: 0.4675
Batch 370, Loss: 0.4213
Batch 380, Loss: 0.4774
Batch 390, Loss: 0.4758
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.016089916229248 seconds
Epoch 84 accuracy: 84.94%
Batch 10, Loss: 0.4572
Batch 20, Loss: 0.4569
Batch 30, Loss: 0.4477
Batch 40, Loss: 0.4718
Batch 50, Loss: 0.4707
Batch 60, Loss: 0.4448
Batch 70, Loss: 0.4301
Batch 80, Loss: 0.4498
Batch 90, Loss: 0.4852
Batch 100, Loss: 0.4761
Batch 110, Loss: 0.4985
Batch 120, Loss: 0.4801
Batch 130, Loss: 0.4556
Batch 140, Loss: 0.4449
Batch 150, Loss: 0.4817
Batch 160, Loss: 0.4976
Batch 170, Loss: 0.4783
Batch 180, Loss: 0.4539
Batch 190, Loss: 0.4631
Batch 200, Loss: 0.4518
Batch 210, Loss: 0.4434
Batch 220, Loss: 0.4788
Batch 230, Loss: 0.4641
Batch 240, Loss: 0.4682
Batch 250, Loss: 0.4696
Batch 260, Loss: 0.4784
Batch 270, Loss: 0.4658
Batch 280, Loss: 0.4693
Batch 290, Loss: 0.4461
Batch 300, Loss: 0.5003
Batch 310, Loss: 0.5071
Batch 320, Loss: 0.4841
Batch 330, Loss: 0.4232
Batch 340, Loss: 0.4637
Batch 350, Loss: 0.4714
Batch 360, Loss: 0.4353
Batch 370, Loss: 0.4727
Batch 380, Loss: 0.4500
Batch 390, Loss: 0.4751
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 24.998430967330933 seconds
Epoch 85 accuracy: 86.74%
Batch 10, Loss: 0.5076
Batch 20, Loss: 0.4589
Batch 30, Loss: 0.4577
Batch 40, Loss: 0.4323
Batch 50, Loss: 0.4683
Batch 60, Loss: 0.4511
Batch 70, Loss: 0.4434
Batch 80, Loss: 0.4644
Batch 90, Loss: 0.4717
Batch 100, Loss: 0.4849
Batch 110, Loss: 0.5027
Batch 120, Loss: 0.4767
Batch 130, Loss: 0.4434
Batch 140, Loss: 0.4536
Batch 150, Loss: 0.4727
Batch 160, Loss: 0.4595
Batch 170, Loss: 0.4198
Batch 180, Loss: 0.4702
Batch 190, Loss: 0.4668
Batch 200, Loss: 0.4635
Batch 210, Loss: 0.4696
Batch 220, Loss: 0.4648
Batch 230, Loss: 0.4556
Batch 240, Loss: 0.4633
Batch 250, Loss: 0.4556
Batch 260, Loss: 0.4833
Batch 270, Loss: 0.4663
Batch 280, Loss: 0.4760
Batch 290, Loss: 0.4743
Batch 300, Loss: 0.4860
Batch 310, Loss: 0.4501
Batch 320, Loss: 0.4529
Batch 330, Loss: 0.4662
Batch 340, Loss: 0.4601
Batch 350, Loss: 0.4551
Batch 360, Loss: 0.4733
Batch 370, Loss: 0.5045
Batch 380, Loss: 0.4566
Batch 390, Loss: 0.4583
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.0546977519989 seconds
Epoch 86 accuracy: 87.12%
Batch 10, Loss: 0.4805
Batch 20, Loss: 0.4463
Batch 30, Loss: 0.5186
Batch 40, Loss: 0.4252
Batch 50, Loss: 0.4392
Batch 60, Loss: 0.4481
Batch 70, Loss: 0.4682
Batch 80, Loss: 0.4375
Batch 90, Loss: 0.4678
Batch 100, Loss: 0.4725
Batch 110, Loss: 0.4876
Batch 120, Loss: 0.4690
Batch 130, Loss: 0.4812
Batch 140, Loss: 0.4883
Batch 150, Loss: 0.4714
Batch 160, Loss: 0.4556
Batch 170, Loss: 0.4602
Batch 180, Loss: 0.4749
Batch 190, Loss: 0.4738
Batch 200, Loss: 0.4371
Batch 210, Loss: 0.4606
Batch 220, Loss: 0.4363
Batch 230, Loss: 0.4557
Batch 240, Loss: 0.5140
Batch 250, Loss: 0.4788
Batch 260, Loss: 0.4719
Batch 270, Loss: 0.5038
Batch 280, Loss: 0.4611
Batch 290, Loss: 0.4587
Batch 300, Loss: 0.4868
Batch 310, Loss: 0.5213
Batch 320, Loss: 0.5115
Batch 330, Loss: 0.4590
Batch 340, Loss: 0.4664
Batch 350, Loss: 0.4610
Batch 360, Loss: 0.4861
Batch 370, Loss: 0.4617
Batch 380, Loss: 0.4905
Batch 390, Loss: 0.4642
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 24.99550461769104 seconds
Epoch 87 accuracy: 88.02%
Batch 10, Loss: 0.4449
Batch 20, Loss: 0.4329
Batch 30, Loss: 0.4457
Batch 40, Loss: 0.4257
Batch 50, Loss: 0.4441
Batch 60, Loss: 0.4317
Batch 70, Loss: 0.4529
Batch 80, Loss: 0.4712
Batch 90, Loss: 0.4473
Batch 100, Loss: 0.4233
Batch 110, Loss: 0.4725
Batch 120, Loss: 0.4681
Batch 130, Loss: 0.4811
Batch 140, Loss: 0.4731
Batch 150, Loss: 0.4690
Batch 160, Loss: 0.4882
Batch 170, Loss: 0.4394
Batch 180, Loss: 0.4141
Batch 190, Loss: 0.4534
Batch 200, Loss: 0.4796
Batch 210, Loss: 0.4589
Batch 220, Loss: 0.4516
Batch 230, Loss: 0.4628
Batch 240, Loss: 0.4723
Batch 250, Loss: 0.4668
Batch 260, Loss: 0.4587
Batch 270, Loss: 0.4461
Batch 280, Loss: 0.4653
Batch 290, Loss: 0.4484
Batch 300, Loss: 0.4586
Batch 310, Loss: 0.4899
Batch 320, Loss: 0.4675
Batch 330, Loss: 0.4485
Batch 340, Loss: 0.4762
Batch 350, Loss: 0.4759
Batch 360, Loss: 0.4546
Batch 370, Loss: 0.5008
Batch 380, Loss: 0.4779
Batch 390, Loss: 0.4517
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.00084090232849 seconds
Epoch 88 accuracy: 85.94%
Batch 10, Loss: 0.4480
Batch 20, Loss: 0.4763
Batch 30, Loss: 0.4606
Batch 40, Loss: 0.4733
Batch 50, Loss: 0.4714
Batch 60, Loss: 0.4362
Batch 70, Loss: 0.4682
Batch 80, Loss: 0.4542
Batch 90, Loss: 0.4672
Batch 100, Loss: 0.4551
Batch 110, Loss: 0.4765
Batch 120, Loss: 0.4572
Batch 130, Loss: 0.4633
Batch 140, Loss: 0.4815
Batch 150, Loss: 0.4201
Batch 160, Loss: 0.4174
Batch 170, Loss: 0.4804
Batch 180, Loss: 0.4449
Batch 190, Loss: 0.4480
Batch 200, Loss: 0.4639
Batch 210, Loss: 0.5086
Batch 220, Loss: 0.4883
Batch 230, Loss: 0.4740
Batch 240, Loss: 0.4655
Batch 250, Loss: 0.4496
Batch 260, Loss: 0.4528
Batch 270, Loss: 0.4617
Batch 280, Loss: 0.4663
Batch 290, Loss: 0.4589
Batch 300, Loss: 0.4350
Batch 310, Loss: 0.4580
Batch 320, Loss: 0.4536
Batch 330, Loss: 0.4769
Batch 340, Loss: 0.4487
Batch 350, Loss: 0.4623
Batch 360, Loss: 0.4753
Batch 370, Loss: 0.4780
Batch 380, Loss: 0.4875
Batch 390, Loss: 0.4501
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 24.99462628364563 seconds
Epoch 89 accuracy: 85.65%
Batch 10, Loss: 0.4361
Batch 20, Loss: 0.4710
Batch 30, Loss: 0.4631
Batch 40, Loss: 0.4648
Batch 50, Loss: 0.4792
Batch 60, Loss: 0.4705
Batch 70, Loss: 0.4525
Batch 80, Loss: 0.4167
Batch 90, Loss: 0.4327
Batch 100, Loss: 0.4607
Batch 110, Loss: 0.3985
Batch 120, Loss: 0.4375
Batch 130, Loss: 0.4219
Batch 140, Loss: 0.4367
Batch 150, Loss: 0.4561
Batch 160, Loss: 0.5305
Batch 170, Loss: 0.4668
Batch 180, Loss: 0.4418
Batch 190, Loss: 0.4343
Batch 200, Loss: 0.4386
Batch 210, Loss: 0.4604
Batch 220, Loss: 0.4529
Batch 230, Loss: 0.4419
Batch 240, Loss: 0.4488
Batch 250, Loss: 0.4918
Batch 260, Loss: 0.4527
Batch 270, Loss: 0.4659
Batch 280, Loss: 0.4442
Batch 290, Loss: 0.4643
Batch 300, Loss: 0.5013
Batch 310, Loss: 0.4998
Batch 320, Loss: 0.4727
Batch 330, Loss: 0.4465
Batch 340, Loss: 0.4634
Batch 350, Loss: 0.4646
Batch 360, Loss: 0.4813
Batch 370, Loss: 0.4343
Batch 380, Loss: 0.4534
Batch 390, Loss: 0.4763
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.041622638702393 seconds
Epoch 90 accuracy: 88.63%
Batch 10, Loss: 0.4651
Batch 20, Loss: 0.4940
Batch 30, Loss: 0.4655
Batch 40, Loss: 0.4627
Batch 50, Loss: 0.4939
Batch 60, Loss: 0.4645
Batch 70, Loss: 0.4338
Batch 80, Loss: 0.4438
Batch 90, Loss: 0.4536
Batch 100, Loss: 0.4672
Batch 110, Loss: 0.4698
Batch 120, Loss: 0.4468
Batch 130, Loss: 0.4884
Batch 140, Loss: 0.4294
Batch 150, Loss: 0.4576
Batch 160, Loss: 0.4821
Batch 170, Loss: 0.4223
Batch 180, Loss: 0.4432
Batch 190, Loss: 0.4417
Batch 200, Loss: 0.4702
Batch 210, Loss: 0.4443
Batch 220, Loss: 0.4610
Batch 230, Loss: 0.4865
Batch 240, Loss: 0.4519
Batch 250, Loss: 0.4963
Batch 260, Loss: 0.4741
Batch 270, Loss: 0.4486
Batch 280, Loss: 0.4421
Batch 290, Loss: 0.4730
Batch 300, Loss: 0.4481
Batch 310, Loss: 0.4572
Batch 320, Loss: 0.4892
Batch 330, Loss: 0.4549
Batch 340, Loss: 0.4569
Batch 350, Loss: 0.4413
Batch 360, Loss: 0.4527
Batch 370, Loss: 0.4409
Batch 380, Loss: 0.4570
Batch 390, Loss: 0.4560
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 24.996504068374634 seconds
Epoch 91 accuracy: 84.75%
Batch 10, Loss: 0.4763
Batch 20, Loss: 0.4637
Batch 30, Loss: 0.4452
Batch 40, Loss: 0.4517
Batch 50, Loss: 0.4393
Batch 60, Loss: 0.4634
Batch 70, Loss: 0.4414
Batch 80, Loss: 0.4583
Batch 90, Loss: 0.4468
Batch 100, Loss: 0.4598
Batch 110, Loss: 0.4235
Batch 120, Loss: 0.4568
Batch 130, Loss: 0.4673
Batch 140, Loss: 0.4517
Batch 150, Loss: 0.5021
Batch 160, Loss: 0.4561
Batch 170, Loss: 0.4650
Batch 180, Loss: 0.4468
Batch 190, Loss: 0.4272
Batch 200, Loss: 0.4456
Batch 210, Loss: 0.4773
Batch 220, Loss: 0.4503
Batch 230, Loss: 0.4198
Batch 240, Loss: 0.4301
Batch 250, Loss: 0.4799
Batch 260, Loss: 0.4709
Batch 270, Loss: 0.4551
Batch 280, Loss: 0.4765
Batch 290, Loss: 0.4475
Batch 300, Loss: 0.4502
Batch 310, Loss: 0.4743
Batch 320, Loss: 0.4424
Batch 330, Loss: 0.4799
Batch 340, Loss: 0.4418
Batch 350, Loss: 0.4414
Batch 360, Loss: 0.4331
Batch 370, Loss: 0.4606
Batch 380, Loss: 0.4630
Batch 390, Loss: 0.4636
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.092205286026 seconds
Epoch 92 accuracy: 88.19%
Batch 10, Loss: 0.4326
Batch 20, Loss: 0.4422
Batch 30, Loss: 0.4704
Batch 40, Loss: 0.4402
Batch 50, Loss: 0.4395
Batch 60, Loss: 0.4049
Batch 70, Loss: 0.4682
Batch 80, Loss: 0.4076
Batch 90, Loss: 0.4273
Batch 100, Loss: 0.4250
Batch 110, Loss: 0.4310
Batch 120, Loss: 0.4579
Batch 130, Loss: 0.4239
Batch 140, Loss: 0.4804
Batch 150, Loss: 0.4477
Batch 160, Loss: 0.4780
Batch 170, Loss: 0.4286
Batch 180, Loss: 0.4809
Batch 190, Loss: 0.4509
Batch 200, Loss: 0.4519
Batch 210, Loss: 0.4622
Batch 220, Loss: 0.4593
Batch 230, Loss: 0.4407
Batch 240, Loss: 0.4239
Batch 250, Loss: 0.4247
Batch 260, Loss: 0.4420
Batch 270, Loss: 0.4208
Batch 280, Loss: 0.4835
Batch 290, Loss: 0.4675
Batch 300, Loss: 0.4277
Batch 310, Loss: 0.4704
Batch 320, Loss: 0.4618
Batch 330, Loss: 0.4768
Batch 340, Loss: 0.4681
Batch 350, Loss: 0.4431
Batch 360, Loss: 0.4802
Batch 370, Loss: 0.4694
Batch 380, Loss: 0.4339
Batch 390, Loss: 0.4481
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 24.984079837799072 seconds
Epoch 93 accuracy: 87.24%
Batch 10, Loss: 0.4030
Batch 20, Loss: 0.4068
Batch 30, Loss: 0.4341
Batch 40, Loss: 0.4129
Batch 50, Loss: 0.4406
Batch 60, Loss: 0.4658
Batch 70, Loss: 0.4474
Batch 80, Loss: 0.4596
Batch 90, Loss: 0.4326
Batch 100, Loss: 0.4545
Batch 110, Loss: 0.4554
Batch 120, Loss: 0.4697
Batch 130, Loss: 0.4728
Batch 140, Loss: 0.4479
Batch 150, Loss: 0.4442
Batch 160, Loss: 0.4669
Batch 170, Loss: 0.4391
Batch 180, Loss: 0.4695
Batch 190, Loss: 0.4501
Batch 200, Loss: 0.4387
Batch 210, Loss: 0.4520
Batch 220, Loss: 0.4391
Batch 230, Loss: 0.4645
Batch 240, Loss: 0.4503
Batch 250, Loss: 0.4801
Batch 260, Loss: 0.4295
Batch 270, Loss: 0.4161
Batch 280, Loss: 0.4884
Batch 290, Loss: 0.4320
Batch 300, Loss: 0.4694
Batch 310, Loss: 0.4809
Batch 320, Loss: 0.4846
Batch 330, Loss: 0.5199
Batch 340, Loss: 0.4527
Batch 350, Loss: 0.4720
Batch 360, Loss: 0.4359
Batch 370, Loss: 0.4760
Batch 380, Loss: 0.4680
Batch 390, Loss: 0.4503
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 24.975470304489136 seconds
Epoch 94 accuracy: 88.38%
Batch 10, Loss: 0.4433
Batch 20, Loss: 0.4262
Batch 30, Loss: 0.4127
Batch 40, Loss: 0.4236
Batch 50, Loss: 0.4592
Batch 60, Loss: 0.4445
Batch 70, Loss: 0.4432
Batch 80, Loss: 0.4706
Batch 90, Loss: 0.4403
Batch 100, Loss: 0.4540
Batch 110, Loss: 0.4844
Batch 120, Loss: 0.4431
Batch 130, Loss: 0.4206
Batch 140, Loss: 0.4292
Batch 150, Loss: 0.4562
Batch 160, Loss: 0.4436
Batch 170, Loss: 0.4629
Batch 180, Loss: 0.4696
Batch 190, Loss: 0.4525
Batch 200, Loss: 0.4054
Batch 210, Loss: 0.4112
Batch 220, Loss: 0.4276
Batch 230, Loss: 0.4255
Batch 240, Loss: 0.4422
Batch 250, Loss: 0.4520
Batch 260, Loss: 0.5198
Batch 270, Loss: 0.4821
Batch 280, Loss: 0.4377
Batch 290, Loss: 0.4682
Batch 300, Loss: 0.4721
Batch 310, Loss: 0.4511
Batch 320, Loss: 0.4545
Batch 330, Loss: 0.4643
Batch 340, Loss: 0.4440
Batch 350, Loss: 0.4618
Batch 360, Loss: 0.4519
Batch 370, Loss: 0.4478
Batch 380, Loss: 0.4252
Batch 390, Loss: 0.4555
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 24.984806537628174 seconds
Epoch 95 accuracy: 89.8%
Batch 10, Loss: 0.4518
Batch 20, Loss: 0.4508
Batch 30, Loss: 0.4318
Batch 40, Loss: 0.4277
Batch 50, Loss: 0.4668
Batch 60, Loss: 0.4635
Batch 70, Loss: 0.4228
Batch 80, Loss: 0.4419
Batch 90, Loss: 0.4670
Batch 100, Loss: 0.4446
Batch 110, Loss: 0.4440
Batch 120, Loss: 0.4333
Batch 130, Loss: 0.4349
Batch 140, Loss: 0.4337
Batch 150, Loss: 0.4079
Batch 160, Loss: 0.4101
Batch 170, Loss: 0.4520
Batch 180, Loss: 0.4063
Batch 190, Loss: 0.4400
Batch 200, Loss: 0.4468
Batch 210, Loss: 0.4226
Batch 220, Loss: 0.4487
Batch 230, Loss: 0.4416
Batch 240, Loss: 0.4385
Batch 250, Loss: 0.4670
Batch 260, Loss: 0.4451
Batch 270, Loss: 0.4522
Batch 280, Loss: 0.4273
Batch 290, Loss: 0.4420
Batch 300, Loss: 0.4412
Batch 310, Loss: 0.4339
Batch 320, Loss: 0.3989
Batch 330, Loss: 0.4786
Batch 340, Loss: 0.4785
Batch 350, Loss: 0.4669
Batch 360, Loss: 0.4907
Batch 370, Loss: 0.4714
Batch 380, Loss: 0.4899
Batch 390, Loss: 0.4966
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.12023091316223 seconds
Epoch 96 accuracy: 87.05%
Batch 10, Loss: 0.4348
Batch 20, Loss: 0.4277
Batch 30, Loss: 0.4220
Batch 40, Loss: 0.4414
Batch 50, Loss: 0.4519
Batch 60, Loss: 0.4539
Batch 70, Loss: 0.4431
Batch 80, Loss: 0.3875
Batch 90, Loss: 0.4352
Batch 100, Loss: 0.4539
Batch 110, Loss: 0.4567
Batch 120, Loss: 0.4178
Batch 130, Loss: 0.4725
Batch 140, Loss: 0.4190
Batch 150, Loss: 0.4371
Batch 160, Loss: 0.4173
Batch 170, Loss: 0.4800
Batch 180, Loss: 0.4203
Batch 190, Loss: 0.4016
Batch 200, Loss: 0.4223
Batch 210, Loss: 0.4659
Batch 220, Loss: 0.4734
Batch 230, Loss: 0.4773
Batch 240, Loss: 0.4377
Batch 250, Loss: 0.4838
Batch 260, Loss: 0.4617
Batch 270, Loss: 0.5005
Batch 280, Loss: 0.4285
Batch 290, Loss: 0.4745
Batch 300, Loss: 0.4769
Batch 310, Loss: 0.4333
Batch 320, Loss: 0.4413
Batch 330, Loss: 0.4187
Batch 340, Loss: 0.4252
Batch 350, Loss: 0.4385
Batch 360, Loss: 0.4296
Batch 370, Loss: 0.4246
Batch 380, Loss: 0.4429
Batch 390, Loss: 0.4478
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.071733474731445 seconds
Epoch 97 accuracy: 88.54%
Batch 10, Loss: 0.4149
Batch 20, Loss: 0.4272
Batch 30, Loss: 0.4387
Batch 40, Loss: 0.4449
Batch 50, Loss: 0.3960
Batch 60, Loss: 0.4531
Batch 70, Loss: 0.4123
Batch 80, Loss: 0.4568
Batch 90, Loss: 0.4720
Batch 100, Loss: 0.4479
Batch 110, Loss: 0.3873
Batch 120, Loss: 0.4302
Batch 130, Loss: 0.4403
Batch 140, Loss: 0.4446
Batch 150, Loss: 0.4242
Batch 160, Loss: 0.4380
Batch 170, Loss: 0.4404
Batch 180, Loss: 0.4325
Batch 190, Loss: 0.4689
Batch 200, Loss: 0.4648
Batch 210, Loss: 0.4465
Batch 220, Loss: 0.3824
Batch 230, Loss: 0.4531
Batch 240, Loss: 0.4091
Batch 250, Loss: 0.4291
Batch 260, Loss: 0.4099
Batch 270, Loss: 0.3962
Batch 280, Loss: 0.4757
Batch 290, Loss: 0.4349
Batch 300, Loss: 0.4391
Batch 310, Loss: 0.4318
Batch 320, Loss: 0.4671
Batch 330, Loss: 0.4367
Batch 340, Loss: 0.4201
Batch 350, Loss: 0.4102
Batch 360, Loss: 0.4173
Batch 370, Loss: 0.4479
Batch 380, Loss: 0.4722
Batch 390, Loss: 0.4418
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 24.971129417419434 seconds
Epoch 98 accuracy: 88.26%
Batch 10, Loss: 0.4350
Batch 20, Loss: 0.4144
Batch 30, Loss: 0.4168
Batch 40, Loss: 0.4215
Batch 50, Loss: 0.3878
Batch 60, Loss: 0.4401
Batch 70, Loss: 0.4290
Batch 80, Loss: 0.4372
Batch 90, Loss: 0.4230
Batch 100, Loss: 0.4480
Batch 110, Loss: 0.4924
Batch 120, Loss: 0.4167
Batch 130, Loss: 0.4225
Batch 140, Loss: 0.4593
Batch 150, Loss: 0.4555
Batch 160, Loss: 0.4218
Batch 170, Loss: 0.4537
Batch 180, Loss: 0.4296
Batch 190, Loss: 0.4138
Batch 200, Loss: 0.4030
Batch 210, Loss: 0.4442
Batch 220, Loss: 0.4917
Batch 230, Loss: 0.4282
Batch 240, Loss: 0.4458
Batch 250, Loss: 0.4323
Batch 260, Loss: 0.4304
Batch 270, Loss: 0.4560
Batch 280, Loss: 0.4325
Batch 290, Loss: 0.4005
Batch 300, Loss: 0.4212
Batch 310, Loss: 0.4076
Batch 320, Loss: 0.4289
Batch 330, Loss: 0.4481
Batch 340, Loss: 0.4486
Batch 350, Loss: 0.4456
Batch 360, Loss: 0.4204
Batch 370, Loss: 0.4324
Batch 380, Loss: 0.4540
Batch 390, Loss: 0.4441
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.021759271621704 seconds
Epoch 99 accuracy: 88.49%
Batch 10, Loss: 0.4565
Batch 20, Loss: 0.3864
Batch 30, Loss: 0.4394
Batch 40, Loss: 0.4338
Batch 50, Loss: 0.4004
Batch 60, Loss: 0.4783
Batch 70, Loss: 0.4018
Batch 80, Loss: 0.4007
Batch 90, Loss: 0.4326
Batch 100, Loss: 0.4420
Batch 110, Loss: 0.4073
Batch 120, Loss: 0.4673
Batch 130, Loss: 0.4711
Batch 140, Loss: 0.4584
Batch 150, Loss: 0.4475
Batch 160, Loss: 0.4690
Batch 170, Loss: 0.4372
Batch 180, Loss: 0.4603
Batch 190, Loss: 0.4258
Batch 200, Loss: 0.4379
Batch 210, Loss: 0.4217
Batch 220, Loss: 0.4333
Batch 230, Loss: 0.4127
Batch 240, Loss: 0.4329
Batch 250, Loss: 0.4356
Batch 260, Loss: 0.4466
Batch 270, Loss: 0.4704
Batch 280, Loss: 0.4065
Batch 290, Loss: 0.4294
Batch 300, Loss: 0.4503
Batch 310, Loss: 0.4442
Batch 320, Loss: 0.4264
Batch 330, Loss: 0.3976
Batch 340, Loss: 0.4530
Batch 350, Loss: 0.4293
Batch 360, Loss: 0.4652
Batch 370, Loss: 0.3752
Batch 380, Loss: 0.4326
Batch 390, Loss: 0.4335
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 24.986908197402954 seconds
Epoch 100 accuracy: 89.08%
Batch 10, Loss: 0.4430
Batch 20, Loss: 0.4316
Batch 30, Loss: 0.4178
Batch 40, Loss: 0.4297
Batch 50, Loss: 0.4411
Batch 60, Loss: 0.4235
Batch 70, Loss: 0.4273
Batch 80, Loss: 0.4030
Batch 90, Loss: 0.3967
Batch 100, Loss: 0.4349
Batch 110, Loss: 0.4764
Batch 120, Loss: 0.4028
Batch 130, Loss: 0.4353
Batch 140, Loss: 0.4160
Batch 150, Loss: 0.4481
Batch 160, Loss: 0.4421
Batch 170, Loss: 0.4576
Batch 180, Loss: 0.4521
Batch 190, Loss: 0.4405
Batch 200, Loss: 0.4412
Batch 210, Loss: 0.4509
Batch 220, Loss: 0.3997
Batch 230, Loss: 0.4066
Batch 240, Loss: 0.3984
Batch 250, Loss: 0.4426
Batch 260, Loss: 0.4814
Batch 270, Loss: 0.4107
Batch 280, Loss: 0.4163
Batch 290, Loss: 0.4522
Batch 300, Loss: 0.3978
Batch 310, Loss: 0.4398
Batch 320, Loss: 0.4559
Batch 330, Loss: 0.4420
Batch 340, Loss: 0.4455
Batch 350, Loss: 0.4076
Batch 360, Loss: 0.4315
Batch 370, Loss: 0.4503
Batch 380, Loss: 0.4216
Batch 390, Loss: 0.4379
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.001081228256226 seconds
Epoch 101 accuracy: 87.5%
Batch 10, Loss: 0.4398
Batch 20, Loss: 0.4080
Batch 30, Loss: 0.4416
Batch 40, Loss: 0.4158
Batch 50, Loss: 0.4235
Batch 60, Loss: 0.4086
Batch 70, Loss: 0.4010
Batch 80, Loss: 0.4279
Batch 90, Loss: 0.4287
Batch 100, Loss: 0.3894
Batch 110, Loss: 0.4223
Batch 120, Loss: 0.4353
Batch 130, Loss: 0.4420
Batch 140, Loss: 0.4379
Batch 150, Loss: 0.4191
Batch 160, Loss: 0.4373
Batch 170, Loss: 0.4134
Batch 180, Loss: 0.4485
Batch 190, Loss: 0.4366
Batch 200, Loss: 0.4394
Batch 210, Loss: 0.4499
Batch 220, Loss: 0.4265
Batch 230, Loss: 0.4272
Batch 240, Loss: 0.4678
Batch 250, Loss: 0.4201
Batch 260, Loss: 0.4276
Batch 270, Loss: 0.4297
Batch 280, Loss: 0.4089
Batch 290, Loss: 0.4356
Batch 300, Loss: 0.4049
Batch 310, Loss: 0.3956
Batch 320, Loss: 0.4239
Batch 330, Loss: 0.4055
Batch 340, Loss: 0.4103
Batch 350, Loss: 0.4490
Batch 360, Loss: 0.4587
Batch 370, Loss: 0.4245
Batch 380, Loss: 0.4390
Batch 390, Loss: 0.4151
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 24.981346130371094 seconds
Epoch 102 accuracy: 88.45%
Batch 10, Loss: 0.4033
Batch 20, Loss: 0.4160
Batch 30, Loss: 0.4230
Batch 40, Loss: 0.4221
Batch 50, Loss: 0.4391
Batch 60, Loss: 0.4197
Batch 70, Loss: 0.3887
Batch 80, Loss: 0.4129
Batch 90, Loss: 0.4022
Batch 100, Loss: 0.4486
Batch 110, Loss: 0.4319
Batch 120, Loss: 0.3792
Batch 130, Loss: 0.4033
Batch 140, Loss: 0.4535
Batch 150, Loss: 0.4633
Batch 160, Loss: 0.4411
Batch 170, Loss: 0.4097
Batch 180, Loss: 0.4028
Batch 190, Loss: 0.4050
Batch 200, Loss: 0.4428
Batch 210, Loss: 0.4640
Batch 220, Loss: 0.4164
Batch 230, Loss: 0.4136
Batch 240, Loss: 0.4543
Batch 250, Loss: 0.3870
Batch 260, Loss: 0.4262
Batch 270, Loss: 0.4449
Batch 280, Loss: 0.4099
Batch 290, Loss: 0.3823
Batch 300, Loss: 0.4469
Batch 310, Loss: 0.4520
Batch 320, Loss: 0.4040
Batch 330, Loss: 0.4015
Batch 340, Loss: 0.4381
Batch 350, Loss: 0.4513
Batch 360, Loss: 0.4023
Batch 370, Loss: 0.4203
Batch 380, Loss: 0.4193
Batch 390, Loss: 0.4421
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.062168836593628 seconds
Epoch 103 accuracy: 89.6%
Batch 10, Loss: 0.3868
Batch 20, Loss: 0.4419
Batch 30, Loss: 0.4409
Batch 40, Loss: 0.4361
Batch 50, Loss: 0.4363
Batch 60, Loss: 0.4093
Batch 70, Loss: 0.4025
Batch 80, Loss: 0.4181
Batch 90, Loss: 0.4832
Batch 100, Loss: 0.4395
Batch 110, Loss: 0.3983
Batch 120, Loss: 0.4184
Batch 130, Loss: 0.4402
Batch 140, Loss: 0.3886
Batch 150, Loss: 0.4184
Batch 160, Loss: 0.4034
Batch 170, Loss: 0.3974
Batch 180, Loss: 0.4762
Batch 190, Loss: 0.4292
Batch 200, Loss: 0.4000
Batch 210, Loss: 0.4120
Batch 220, Loss: 0.4093
Batch 230, Loss: 0.4484
Batch 240, Loss: 0.4403
Batch 250, Loss: 0.4081
Batch 260, Loss: 0.4186
Batch 270, Loss: 0.4479
Batch 280, Loss: 0.4470
Batch 290, Loss: 0.4024
Batch 300, Loss: 0.4323
Batch 310, Loss: 0.4217
Batch 320, Loss: 0.4519
Batch 330, Loss: 0.4356
Batch 340, Loss: 0.4408
Batch 350, Loss: 0.4539
Batch 360, Loss: 0.4392
Batch 370, Loss: 0.4626
Batch 380, Loss: 0.4308
Batch 390, Loss: 0.4398
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.01182532310486 seconds
Epoch 104 accuracy: 88.12%
Batch 10, Loss: 0.4300
Batch 20, Loss: 0.3954
Batch 30, Loss: 0.4025
Batch 40, Loss: 0.4342
Batch 50, Loss: 0.4532
Batch 60, Loss: 0.4310
Batch 70, Loss: 0.4180
Batch 80, Loss: 0.4047
Batch 90, Loss: 0.4179
Batch 100, Loss: 0.4070
Batch 110, Loss: 0.3960
Batch 120, Loss: 0.4422
Batch 130, Loss: 0.4466
Batch 140, Loss: 0.4309
Batch 150, Loss: 0.4546
Batch 160, Loss: 0.4329
Batch 170, Loss: 0.4135
Batch 180, Loss: 0.4650
Batch 190, Loss: 0.4236
Batch 200, Loss: 0.4377
Batch 210, Loss: 0.4245
Batch 220, Loss: 0.4106
Batch 230, Loss: 0.4202
Batch 240, Loss: 0.4044
Batch 250, Loss: 0.4492
Batch 260, Loss: 0.4216
Batch 270, Loss: 0.4480
Batch 280, Loss: 0.4420
Batch 290, Loss: 0.4108
Batch 300, Loss: 0.4521
Batch 310, Loss: 0.4286
Batch 320, Loss: 0.3935
Batch 330, Loss: 0.4148
Batch 340, Loss: 0.4265
Batch 350, Loss: 0.4402
Batch 360, Loss: 0.4208
Batch 370, Loss: 0.3972
Batch 380, Loss: 0.4533
Batch 390, Loss: 0.3991
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.020766258239746 seconds
Epoch 105 accuracy: 88.07%
Batch 10, Loss: 0.4218
Batch 20, Loss: 0.4230
Batch 30, Loss: 0.4105
Batch 40, Loss: 0.3975
Batch 50, Loss: 0.3734
Batch 60, Loss: 0.3769
Batch 70, Loss: 0.4181
Batch 80, Loss: 0.4184
Batch 90, Loss: 0.4574
Batch 100, Loss: 0.4015
Batch 110, Loss: 0.4121
Batch 120, Loss: 0.4133
Batch 130, Loss: 0.4265
Batch 140, Loss: 0.4446
Batch 150, Loss: 0.4508
Batch 160, Loss: 0.4118
Batch 170, Loss: 0.4251
Batch 180, Loss: 0.4327
Batch 190, Loss: 0.4254
Batch 200, Loss: 0.4017
Batch 210, Loss: 0.4349
Batch 220, Loss: 0.4578
Batch 230, Loss: 0.4298
Batch 240, Loss: 0.4363
Batch 250, Loss: 0.4193
Batch 260, Loss: 0.4446
Batch 270, Loss: 0.3908
Batch 280, Loss: 0.4002
Batch 290, Loss: 0.4193
Batch 300, Loss: 0.4296
Batch 310, Loss: 0.4039
Batch 320, Loss: 0.4048
Batch 330, Loss: 0.3828
Batch 340, Loss: 0.4070
Batch 350, Loss: 0.4424
Batch 360, Loss: 0.4035
Batch 370, Loss: 0.3685
Batch 380, Loss: 0.4042
Batch 390, Loss: 0.4494
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.03694176673889 seconds
Epoch 106 accuracy: 88.4%
Batch 10, Loss: 0.4880
Batch 20, Loss: 0.4236
Batch 30, Loss: 0.3847
Batch 40, Loss: 0.4038
Batch 50, Loss: 0.4355
Batch 60, Loss: 0.4436
Batch 70, Loss: 0.4424
Batch 80, Loss: 0.4231
Batch 90, Loss: 0.3971
Batch 100, Loss: 0.4101
Batch 110, Loss: 0.4229
Batch 120, Loss: 0.4305
Batch 130, Loss: 0.4095
Batch 140, Loss: 0.4055
Batch 150, Loss: 0.4363
Batch 160, Loss: 0.4019
Batch 170, Loss: 0.4109
Batch 180, Loss: 0.4083
Batch 190, Loss: 0.3973
Batch 200, Loss: 0.4172
Batch 210, Loss: 0.4319
Batch 220, Loss: 0.4678
Batch 230, Loss: 0.4198
Batch 240, Loss: 0.4447
Batch 250, Loss: 0.4184
Batch 260, Loss: 0.4472
Batch 270, Loss: 0.3932
Batch 280, Loss: 0.3814
Batch 290, Loss: 0.4136
Batch 300, Loss: 0.3769
Batch 310, Loss: 0.4187
Batch 320, Loss: 0.4361
Batch 330, Loss: 0.4252
Batch 340, Loss: 0.3899
Batch 350, Loss: 0.3949
Batch 360, Loss: 0.4334
Batch 370, Loss: 0.4316
Batch 380, Loss: 0.4411
Batch 390, Loss: 0.4460
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.059699535369873 seconds
Epoch 107 accuracy: 86.17%
Batch 10, Loss: 0.4625
Batch 20, Loss: 0.4222
Batch 30, Loss: 0.4075
Batch 40, Loss: 0.4092
Batch 50, Loss: 0.4150
Batch 60, Loss: 0.4415
Batch 70, Loss: 0.4220
Batch 80, Loss: 0.4129
Batch 90, Loss: 0.4295
Batch 100, Loss: 0.4175
Batch 110, Loss: 0.4001
Batch 120, Loss: 0.3971
Batch 130, Loss: 0.4102
Batch 140, Loss: 0.4205
Batch 150, Loss: 0.4222
Batch 160, Loss: 0.3668
Batch 170, Loss: 0.4032
Batch 180, Loss: 0.3994
Batch 190, Loss: 0.4212
Batch 200, Loss: 0.4244
Batch 210, Loss: 0.4397
Batch 220, Loss: 0.3822
Batch 230, Loss: 0.4209
Batch 240, Loss: 0.3954
Batch 250, Loss: 0.4554
Batch 260, Loss: 0.4211
Batch 270, Loss: 0.4108
Batch 280, Loss: 0.4154
Batch 290, Loss: 0.3962
Batch 300, Loss: 0.4364
Batch 310, Loss: 0.3807
Batch 320, Loss: 0.4066
Batch 330, Loss: 0.4495
Batch 340, Loss: 0.4287
Batch 350, Loss: 0.4392
Batch 360, Loss: 0.4443
Batch 370, Loss: 0.4526
Batch 380, Loss: 0.4171
Batch 390, Loss: 0.4262
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.027798414230347 seconds
Epoch 108 accuracy: 89.23%
Batch 10, Loss: 0.4029
Batch 20, Loss: 0.3884
Batch 30, Loss: 0.4020
Batch 40, Loss: 0.4178
Batch 50, Loss: 0.4200
Batch 60, Loss: 0.3977
Batch 70, Loss: 0.3618
Batch 80, Loss: 0.3842
Batch 90, Loss: 0.4135
Batch 100, Loss: 0.3989
Batch 110, Loss: 0.3958
Batch 120, Loss: 0.4053
Batch 130, Loss: 0.4003
Batch 140, Loss: 0.3925
Batch 150, Loss: 0.4148
Batch 160, Loss: 0.4158
Batch 170, Loss: 0.3852
Batch 180, Loss: 0.4035
Batch 190, Loss: 0.4147
Batch 200, Loss: 0.4113
Batch 210, Loss: 0.4519
Batch 220, Loss: 0.4100
Batch 230, Loss: 0.4426
Batch 240, Loss: 0.4183
Batch 250, Loss: 0.4471
Batch 260, Loss: 0.4142
Batch 270, Loss: 0.4229
Batch 280, Loss: 0.3750
Batch 290, Loss: 0.4008
Batch 300, Loss: 0.4101
Batch 310, Loss: 0.3801
Batch 320, Loss: 0.4138
Batch 330, Loss: 0.4149
Batch 340, Loss: 0.4408
Batch 350, Loss: 0.4284
Batch 360, Loss: 0.4218
Batch 370, Loss: 0.4405
Batch 380, Loss: 0.4296
Batch 390, Loss: 0.4373
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 24.96912717819214 seconds
Epoch 109 accuracy: 90.16%
Batch 10, Loss: 0.3804
Batch 20, Loss: 0.4043
Batch 30, Loss: 0.4040
Batch 40, Loss: 0.4129
Batch 50, Loss: 0.3873
Batch 60, Loss: 0.3987
Batch 70, Loss: 0.4155
Batch 80, Loss: 0.4030
Batch 90, Loss: 0.4053
Batch 100, Loss: 0.3768
Batch 110, Loss: 0.3651
Batch 120, Loss: 0.4022
Batch 130, Loss: 0.3589
Batch 140, Loss: 0.3988
Batch 150, Loss: 0.3845
Batch 160, Loss: 0.3669
Batch 170, Loss: 0.4227
Batch 180, Loss: 0.4529
Batch 190, Loss: 0.4690
Batch 200, Loss: 0.3737
Batch 210, Loss: 0.3973
Batch 220, Loss: 0.3885
Batch 230, Loss: 0.3957
Batch 240, Loss: 0.4225
Batch 250, Loss: 0.3633
Batch 260, Loss: 0.4121
Batch 270, Loss: 0.4097
Batch 280, Loss: 0.3769
Batch 290, Loss: 0.4426
Batch 300, Loss: 0.3914
Batch 310, Loss: 0.4046
Batch 320, Loss: 0.4141
Batch 330, Loss: 0.3980
Batch 340, Loss: 0.4240
Batch 350, Loss: 0.4441
Batch 360, Loss: 0.4163
Batch 370, Loss: 0.4433
Batch 380, Loss: 0.4059
Batch 390, Loss: 0.4381
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.00130581855774 seconds
Epoch 110 accuracy: 89.44%
Batch 10, Loss: 0.3751
Batch 20, Loss: 0.3996
Batch 30, Loss: 0.3811
Batch 40, Loss: 0.3933
Batch 50, Loss: 0.4038
Batch 60, Loss: 0.4193
Batch 70, Loss: 0.3776
Batch 80, Loss: 0.3871
Batch 90, Loss: 0.4108
Batch 100, Loss: 0.3993
Batch 110, Loss: 0.4093
Batch 120, Loss: 0.4115
Batch 130, Loss: 0.4127
Batch 140, Loss: 0.4108
Batch 150, Loss: 0.3854
Batch 160, Loss: 0.4477
Batch 170, Loss: 0.4142
Batch 180, Loss: 0.4238
Batch 190, Loss: 0.4434
Batch 200, Loss: 0.4264
Batch 210, Loss: 0.4141
Batch 220, Loss: 0.4098
Batch 230, Loss: 0.4240
Batch 240, Loss: 0.4400
Batch 250, Loss: 0.3926
Batch 260, Loss: 0.3936
Batch 270, Loss: 0.3875
Batch 280, Loss: 0.3755
Batch 290, Loss: 0.4001
Batch 300, Loss: 0.4138
Batch 310, Loss: 0.3931
Batch 320, Loss: 0.4244
Batch 330, Loss: 0.4151
Batch 340, Loss: 0.4012
Batch 350, Loss: 0.3957
Batch 360, Loss: 0.4120
Batch 370, Loss: 0.4035
Batch 380, Loss: 0.3903
Batch 390, Loss: 0.4096
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.98953127861023 seconds
Epoch 111 accuracy: 88.84%
Batch 10, Loss: 0.3728
Batch 20, Loss: 0.4026
Batch 30, Loss: 0.4120
Batch 40, Loss: 0.4035
Batch 50, Loss: 0.3875
Batch 60, Loss: 0.3829
Batch 70, Loss: 0.3649
Batch 80, Loss: 0.4090
Batch 90, Loss: 0.4002
Batch 100, Loss: 0.3524
Batch 110, Loss: 0.4045
Batch 120, Loss: 0.4171
Batch 130, Loss: 0.3692
Batch 140, Loss: 0.3595
Batch 150, Loss: 0.4053
Batch 160, Loss: 0.3986
Batch 170, Loss: 0.3956
Batch 180, Loss: 0.3808
Batch 190, Loss: 0.4026
Batch 200, Loss: 0.3891
Batch 210, Loss: 0.4001
Batch 220, Loss: 0.4103
Batch 230, Loss: 0.4153
Batch 240, Loss: 0.4263
Batch 250, Loss: 0.4190
Batch 260, Loss: 0.3904
Batch 270, Loss: 0.3858
Batch 280, Loss: 0.4279
Batch 290, Loss: 0.4342
Batch 300, Loss: 0.4066
Batch 310, Loss: 0.4233
Batch 320, Loss: 0.3904
Batch 330, Loss: 0.4032
Batch 340, Loss: 0.4206
Batch 350, Loss: 0.4143
Batch 360, Loss: 0.4347
Batch 370, Loss: 0.4235
Batch 380, Loss: 0.4295
Batch 390, Loss: 0.3660
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.040364503860474 seconds
Epoch 112 accuracy: 88.54%
Batch 10, Loss: 0.3982
Batch 20, Loss: 0.4000
Batch 30, Loss: 0.3863
Batch 40, Loss: 0.3876
Batch 50, Loss: 0.3986
Batch 60, Loss: 0.4154
Batch 70, Loss: 0.4110
Batch 80, Loss: 0.3956
Batch 90, Loss: 0.4074
Batch 100, Loss: 0.4150
Batch 110, Loss: 0.4465
Batch 120, Loss: 0.3992
Batch 130, Loss: 0.4023
Batch 140, Loss: 0.3565
Batch 150, Loss: 0.3970
Batch 160, Loss: 0.4157
Batch 170, Loss: 0.4251
Batch 180, Loss: 0.3891
Batch 190, Loss: 0.4122
Batch 200, Loss: 0.4034
Batch 210, Loss: 0.4116
Batch 220, Loss: 0.4032
Batch 230, Loss: 0.4165
Batch 240, Loss: 0.3988
Batch 250, Loss: 0.3598
Batch 260, Loss: 0.3845
Batch 270, Loss: 0.3857
Batch 280, Loss: 0.4378
Batch 290, Loss: 0.4079
Batch 300, Loss: 0.3941
Batch 310, Loss: 0.4343
Batch 320, Loss: 0.4159
Batch 330, Loss: 0.4333
Batch 340, Loss: 0.3971
Batch 350, Loss: 0.4106
Batch 360, Loss: 0.3809
Batch 370, Loss: 0.3969
Batch 380, Loss: 0.3832
Batch 390, Loss: 0.4280
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.03540587425232 seconds
Epoch 113 accuracy: 90.21%
Batch 10, Loss: 0.3869
Batch 20, Loss: 0.3946
Batch 30, Loss: 0.4044
Batch 40, Loss: 0.4068
Batch 50, Loss: 0.4070
Batch 60, Loss: 0.4115
Batch 70, Loss: 0.3866
Batch 80, Loss: 0.3947
Batch 90, Loss: 0.3860
Batch 100, Loss: 0.4159
Batch 110, Loss: 0.3773
Batch 120, Loss: 0.3895
Batch 130, Loss: 0.4118
Batch 140, Loss: 0.4024
Batch 150, Loss: 0.3941
Batch 160, Loss: 0.4150
Batch 170, Loss: 0.4089
Batch 180, Loss: 0.4013
Batch 190, Loss: 0.4001
Batch 200, Loss: 0.3736
Batch 210, Loss: 0.3799
Batch 220, Loss: 0.3674
Batch 230, Loss: 0.3917
Batch 240, Loss: 0.4058
Batch 250, Loss: 0.4056
Batch 260, Loss: 0.4111
Batch 270, Loss: 0.3935
Batch 280, Loss: 0.3743
Batch 290, Loss: 0.3738
Batch 300, Loss: 0.4376
Batch 310, Loss: 0.3764
Batch 320, Loss: 0.4212
Batch 330, Loss: 0.3750
Batch 340, Loss: 0.3920
Batch 350, Loss: 0.3800
Batch 360, Loss: 0.3984
Batch 370, Loss: 0.3993
Batch 380, Loss: 0.4188
Batch 390, Loss: 0.3972
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 24.960724592208862 seconds
Epoch 114 accuracy: 87.71%
Batch 10, Loss: 0.4112
Batch 20, Loss: 0.3926
Batch 30, Loss: 0.3853
Batch 40, Loss: 0.3836
Batch 50, Loss: 0.4157
Batch 60, Loss: 0.4203
Batch 70, Loss: 0.3887
Batch 80, Loss: 0.4088
Batch 90, Loss: 0.3894
Batch 100, Loss: 0.3609
Batch 110, Loss: 0.4077
Batch 120, Loss: 0.3944
Batch 130, Loss: 0.4033
Batch 140, Loss: 0.4208
Batch 150, Loss: 0.4062
Batch 160, Loss: 0.4116
Batch 170, Loss: 0.3734
Batch 180, Loss: 0.3964
Batch 190, Loss: 0.3783
Batch 200, Loss: 0.3871
Batch 210, Loss: 0.3867
Batch 220, Loss: 0.3685
Batch 230, Loss: 0.3825
Batch 240, Loss: 0.4067
Batch 250, Loss: 0.3966
Batch 260, Loss: 0.3933
Batch 270, Loss: 0.3948
Batch 280, Loss: 0.4206
Batch 290, Loss: 0.4120
Batch 300, Loss: 0.3672
Batch 310, Loss: 0.4044
Batch 320, Loss: 0.4106
Batch 330, Loss: 0.4114
Batch 340, Loss: 0.3850
Batch 350, Loss: 0.4072
Batch 360, Loss: 0.4041
Batch 370, Loss: 0.3931
Batch 380, Loss: 0.3906
Batch 390, Loss: 0.4229
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.031768321990967 seconds
Epoch 115 accuracy: 89.51%
Batch 10, Loss: 0.3851
Batch 20, Loss: 0.3752
Batch 30, Loss: 0.4187
Batch 40, Loss: 0.3560
Batch 50, Loss: 0.3785
Batch 60, Loss: 0.4112
Batch 70, Loss: 0.3949
Batch 80, Loss: 0.4001
Batch 90, Loss: 0.3510
Batch 100, Loss: 0.4097
Batch 110, Loss: 0.4031
Batch 120, Loss: 0.3629
Batch 130, Loss: 0.3733
Batch 140, Loss: 0.3836
Batch 150, Loss: 0.4013
Batch 160, Loss: 0.3560
Batch 170, Loss: 0.3896
Batch 180, Loss: 0.4113
Batch 190, Loss: 0.3953
Batch 200, Loss: 0.4038
Batch 210, Loss: 0.4007
Batch 220, Loss: 0.3828
Batch 230, Loss: 0.4238
Batch 240, Loss: 0.3990
Batch 250, Loss: 0.4006
Batch 260, Loss: 0.4337
Batch 270, Loss: 0.3820
Batch 280, Loss: 0.4111
Batch 290, Loss: 0.3819
Batch 300, Loss: 0.4122
Batch 310, Loss: 0.3901
Batch 320, Loss: 0.3800
Batch 330, Loss: 0.3626
Batch 340, Loss: 0.4030
Batch 350, Loss: 0.3827
Batch 360, Loss: 0.4073
Batch 370, Loss: 0.3829
Batch 380, Loss: 0.3769
Batch 390, Loss: 0.3658
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.0203115940094 seconds
Epoch 116 accuracy: 90.26%
Batch 10, Loss: 0.3974
Batch 20, Loss: 0.3814
Batch 30, Loss: 0.3857
Batch 40, Loss: 0.4347
Batch 50, Loss: 0.3531
Batch 60, Loss: 0.3892
Batch 70, Loss: 0.3758
Batch 80, Loss: 0.3253
Batch 90, Loss: 0.3533
Batch 100, Loss: 0.3490
Batch 110, Loss: 0.3924
Batch 120, Loss: 0.4151
Batch 130, Loss: 0.3776
Batch 140, Loss: 0.3711
Batch 150, Loss: 0.3832
Batch 160, Loss: 0.3679
Batch 170, Loss: 0.3859
Batch 180, Loss: 0.4001
Batch 190, Loss: 0.3704
Batch 200, Loss: 0.3707
Batch 210, Loss: 0.3884
Batch 220, Loss: 0.4162
Batch 230, Loss: 0.4097
Batch 240, Loss: 0.4306
Batch 250, Loss: 0.4219
Batch 260, Loss: 0.4019
Batch 270, Loss: 0.4099
Batch 280, Loss: 0.4028
Batch 290, Loss: 0.3840
Batch 300, Loss: 0.3762
Batch 310, Loss: 0.3641
Batch 320, Loss: 0.4087
Batch 330, Loss: 0.3922
Batch 340, Loss: 0.4309
Batch 350, Loss: 0.4076
Batch 360, Loss: 0.4160
Batch 370, Loss: 0.3917
Batch 380, Loss: 0.3492
Batch 390, Loss: 0.3778
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 24.955658197402954 seconds
Epoch 117 accuracy: 90.33%
Batch 10, Loss: 0.3643
Batch 20, Loss: 0.3998
Batch 30, Loss: 0.3702
Batch 40, Loss: 0.3864
Batch 50, Loss: 0.3480
Batch 60, Loss: 0.3785
Batch 70, Loss: 0.3916
Batch 80, Loss: 0.3930
Batch 90, Loss: 0.3543
Batch 100, Loss: 0.3763
Batch 110, Loss: 0.3916
Batch 120, Loss: 0.3769
Batch 130, Loss: 0.4152
Batch 140, Loss: 0.4204
Batch 150, Loss: 0.3802
Batch 160, Loss: 0.3844
Batch 170, Loss: 0.3952
Batch 180, Loss: 0.3538
Batch 190, Loss: 0.3603
Batch 200, Loss: 0.3765
Batch 210, Loss: 0.3991
Batch 220, Loss: 0.3736
Batch 230, Loss: 0.3772
Batch 240, Loss: 0.3596
Batch 250, Loss: 0.3852
Batch 260, Loss: 0.3860
Batch 270, Loss: 0.3680
Batch 280, Loss: 0.4155
Batch 290, Loss: 0.4262
Batch 300, Loss: 0.3846
Batch 310, Loss: 0.3749
Batch 320, Loss: 0.4004
Batch 330, Loss: 0.4015
Batch 340, Loss: 0.3707
Batch 350, Loss: 0.3792
Batch 360, Loss: 0.4064
Batch 370, Loss: 0.3771
Batch 380, Loss: 0.3875
Batch 390, Loss: 0.3979
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 24.969441175460815 seconds
Epoch 118 accuracy: 91.12%
Batch 10, Loss: 0.3490
Batch 20, Loss: 0.3825
Batch 30, Loss: 0.3365
Batch 40, Loss: 0.3675
Batch 50, Loss: 0.3789
Batch 60, Loss: 0.3928
Batch 70, Loss: 0.3957
Batch 80, Loss: 0.4096
Batch 90, Loss: 0.4098
Batch 100, Loss: 0.3760
Batch 110, Loss: 0.3806
Batch 120, Loss: 0.3749
Batch 130, Loss: 0.3964
Batch 140, Loss: 0.3778
Batch 150, Loss: 0.4129
Batch 160, Loss: 0.3875
Batch 170, Loss: 0.3758
Batch 180, Loss: 0.3508
Batch 190, Loss: 0.3828
Batch 200, Loss: 0.3963
Batch 210, Loss: 0.3705
Batch 220, Loss: 0.3706
Batch 230, Loss: 0.3461
Batch 240, Loss: 0.3960
Batch 250, Loss: 0.3921
Batch 260, Loss: 0.4179
Batch 270, Loss: 0.3872
Batch 280, Loss: 0.3980
Batch 290, Loss: 0.4015
Batch 300, Loss: 0.3606
Batch 310, Loss: 0.3851
Batch 320, Loss: 0.3817
Batch 330, Loss: 0.4052
Batch 340, Loss: 0.4224
Batch 350, Loss: 0.3717
Batch 360, Loss: 0.4330
Batch 370, Loss: 0.3744
Batch 380, Loss: 0.3917
Batch 390, Loss: 0.3946
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.03829264640808 seconds
Epoch 119 accuracy: 90.48%
Batch 10, Loss: 0.4069
Batch 20, Loss: 0.3922
Batch 30, Loss: 0.3640
Batch 40, Loss: 0.3756
Batch 50, Loss: 0.3682
Batch 60, Loss: 0.3601
Batch 70, Loss: 0.3827
Batch 80, Loss: 0.3350
Batch 90, Loss: 0.3553
Batch 100, Loss: 0.3435
Batch 110, Loss: 0.3652
Batch 120, Loss: 0.3607
Batch 130, Loss: 0.3675
Batch 140, Loss: 0.3835
Batch 150, Loss: 0.3806
Batch 160, Loss: 0.3778
Batch 170, Loss: 0.3652
Batch 180, Loss: 0.3577
Batch 190, Loss: 0.3656
Batch 200, Loss: 0.4155
Batch 210, Loss: 0.3884
Batch 220, Loss: 0.3530
Batch 230, Loss: 0.4020
Batch 240, Loss: 0.3633
Batch 250, Loss: 0.3755
Batch 260, Loss: 0.3700
Batch 270, Loss: 0.3698
Batch 280, Loss: 0.3936
Batch 290, Loss: 0.4011
Batch 300, Loss: 0.3794
Batch 310, Loss: 0.3937
Batch 320, Loss: 0.4119
Batch 330, Loss: 0.3816
Batch 340, Loss: 0.3895
Batch 350, Loss: 0.4084
Batch 360, Loss: 0.3539
Batch 370, Loss: 0.4047
Batch 380, Loss: 0.3878
Batch 390, Loss: 0.3733
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 24.988325119018555 seconds
Epoch 120 accuracy: 91.06%
Batch 10, Loss: 0.3691
Batch 20, Loss: 0.3754
Batch 30, Loss: 0.3729
Batch 40, Loss: 0.3778
Batch 50, Loss: 0.3754
Batch 60, Loss: 0.3686
Batch 70, Loss: 0.3484
Batch 80, Loss: 0.3502
Batch 90, Loss: 0.3958
Batch 100, Loss: 0.3971
Batch 110, Loss: 0.3551
Batch 120, Loss: 0.3488
Batch 130, Loss: 0.3270
Batch 140, Loss: 0.3661
Batch 150, Loss: 0.3597
Batch 160, Loss: 0.3791
Batch 170, Loss: 0.3799
Batch 180, Loss: 0.3978
Batch 190, Loss: 0.4026
Batch 200, Loss: 0.3355
Batch 210, Loss: 0.3737
Batch 220, Loss: 0.3615
Batch 230, Loss: 0.4059
Batch 240, Loss: 0.3799
Batch 250, Loss: 0.4007
Batch 260, Loss: 0.3819
Batch 270, Loss: 0.3553
Batch 280, Loss: 0.3660
Batch 290, Loss: 0.4027
Batch 300, Loss: 0.3788
Batch 310, Loss: 0.3511
Batch 320, Loss: 0.3332
Batch 330, Loss: 0.4149
Batch 340, Loss: 0.3616
Batch 350, Loss: 0.3777
Batch 360, Loss: 0.4091
Batch 370, Loss: 0.3789
Batch 380, Loss: 0.3630
Batch 390, Loss: 0.4036
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.02068829536438 seconds
Epoch 121 accuracy: 90.75%
Batch 10, Loss: 0.3599
Batch 20, Loss: 0.3675
Batch 30, Loss: 0.3628
Batch 40, Loss: 0.3777
Batch 50, Loss: 0.3870
Batch 60, Loss: 0.4009
Batch 70, Loss: 0.3728
Batch 80, Loss: 0.3930
Batch 90, Loss: 0.3452
Batch 100, Loss: 0.3282
Batch 110, Loss: 0.3931
Batch 120, Loss: 0.3780
Batch 130, Loss: 0.3687
Batch 140, Loss: 0.3651
Batch 150, Loss: 0.3646
Batch 160, Loss: 0.3941
Batch 170, Loss: 0.3875
Batch 180, Loss: 0.3769
Batch 190, Loss: 0.3723
Batch 200, Loss: 0.3553
Batch 210, Loss: 0.3839
Batch 220, Loss: 0.3957
Batch 230, Loss: 0.3723
Batch 240, Loss: 0.3932
Batch 250, Loss: 0.3644
Batch 260, Loss: 0.3798
Batch 270, Loss: 0.3831
Batch 280, Loss: 0.3676
Batch 290, Loss: 0.3958
Batch 300, Loss: 0.3916
Batch 310, Loss: 0.3620
Batch 320, Loss: 0.3659
Batch 330, Loss: 0.4001
Batch 340, Loss: 0.3604
Batch 350, Loss: 0.3854
Batch 360, Loss: 0.3936
Batch 370, Loss: 0.3507
Batch 380, Loss: 0.3582
Batch 390, Loss: 0.3979
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 24.94980788230896 seconds
Epoch 122 accuracy: 90.32%
Batch 10, Loss: 0.3870
Batch 20, Loss: 0.3539
Batch 30, Loss: 0.3482
Batch 40, Loss: 0.3416
Batch 50, Loss: 0.3538
Batch 60, Loss: 0.3947
Batch 70, Loss: 0.3453
Batch 80, Loss: 0.3804
Batch 90, Loss: 0.3742
Batch 100, Loss: 0.3556
Batch 110, Loss: 0.3420
Batch 120, Loss: 0.3640
Batch 130, Loss: 0.3722
Batch 140, Loss: 0.3669
Batch 150, Loss: 0.3523
Batch 160, Loss: 0.3344
Batch 170, Loss: 0.3716
Batch 180, Loss: 0.3830
Batch 190, Loss: 0.4093
Batch 200, Loss: 0.3898
Batch 210, Loss: 0.3755
Batch 220, Loss: 0.3720
Batch 230, Loss: 0.4072
Batch 240, Loss: 0.3646
Batch 250, Loss: 0.3520
Batch 260, Loss: 0.3704
Batch 270, Loss: 0.3896
Batch 280, Loss: 0.3664
Batch 290, Loss: 0.3964
Batch 300, Loss: 0.3658
Batch 310, Loss: 0.3709
Batch 320, Loss: 0.3764
Batch 330, Loss: 0.3862
Batch 340, Loss: 0.3751
Batch 350, Loss: 0.3813
Batch 360, Loss: 0.3937
Batch 370, Loss: 0.3447
Batch 380, Loss: 0.3782
Batch 390, Loss: 0.3660
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 24.980740785598755 seconds
Epoch 123 accuracy: 90.01%
Batch 10, Loss: 0.3539
Batch 20, Loss: 0.3554
Batch 30, Loss: 0.3369
Batch 40, Loss: 0.3691
Batch 50, Loss: 0.3507
Batch 60, Loss: 0.3367
Batch 70, Loss: 0.3367
Batch 80, Loss: 0.3715
Batch 90, Loss: 0.3383
Batch 100, Loss: 0.3497
Batch 110, Loss: 0.3651
Batch 120, Loss: 0.3489
Batch 130, Loss: 0.3767
Batch 140, Loss: 0.4074
Batch 150, Loss: 0.3776
Batch 160, Loss: 0.3882
Batch 170, Loss: 0.3549
Batch 180, Loss: 0.3653
Batch 190, Loss: 0.3443
Batch 200, Loss: 0.3599
Batch 210, Loss: 0.3969
Batch 220, Loss: 0.3618
Batch 230, Loss: 0.3770
Batch 240, Loss: 0.3904
Batch 250, Loss: 0.3447
Batch 260, Loss: 0.3777
Batch 270, Loss: 0.3809
Batch 280, Loss: 0.3311
Batch 290, Loss: 0.3433
Batch 300, Loss: 0.4020
Batch 310, Loss: 0.3767
Batch 320, Loss: 0.4113
Batch 330, Loss: 0.3622
Batch 340, Loss: 0.3532
Batch 350, Loss: 0.3793
Batch 360, Loss: 0.3966
Batch 370, Loss: 0.3459
Batch 380, Loss: 0.3958
Batch 390, Loss: 0.3834
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 24.94357180595398 seconds
Epoch 124 accuracy: 88.69%
Batch 10, Loss: 0.3650
Batch 20, Loss: 0.3965
Batch 30, Loss: 0.3422
Batch 40, Loss: 0.3654
Batch 50, Loss: 0.3909
Batch 60, Loss: 0.3567
Batch 70, Loss: 0.3436
Batch 80, Loss: 0.3610
Batch 90, Loss: 0.3867
Batch 100, Loss: 0.3618
Batch 110, Loss: 0.3629
Batch 120, Loss: 0.3701
Batch 130, Loss: 0.3327
Batch 140, Loss: 0.3778
Batch 150, Loss: 0.3757
Batch 160, Loss: 0.3800
Batch 170, Loss: 0.3511
Batch 180, Loss: 0.3699
Batch 190, Loss: 0.3485
Batch 200, Loss: 0.3823
Batch 210, Loss: 0.3820
Batch 220, Loss: 0.3727
Batch 230, Loss: 0.3224
Batch 240, Loss: 0.3666
Batch 250, Loss: 0.3733
Batch 260, Loss: 0.3812
Batch 270, Loss: 0.3686
Batch 280, Loss: 0.3952
Batch 290, Loss: 0.3546
Batch 300, Loss: 0.3772
Batch 310, Loss: 0.3578
Batch 320, Loss: 0.3463
Batch 330, Loss: 0.3646
Batch 340, Loss: 0.3822
Batch 350, Loss: 0.3565
Batch 360, Loss: 0.3684
Batch 370, Loss: 0.3387
Batch 380, Loss: 0.4187
Batch 390, Loss: 0.3852
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.02051043510437 seconds
Epoch 125 accuracy: 89.58%
Batch 10, Loss: 0.3740
Batch 20, Loss: 0.4082
Batch 30, Loss: 0.3463
Batch 40, Loss: 0.3385
Batch 50, Loss: 0.3729
Batch 60, Loss: 0.3822
Batch 70, Loss: 0.3507
Batch 80, Loss: 0.3811
Batch 90, Loss: 0.3728
Batch 100, Loss: 0.3626
Batch 110, Loss: 0.3553
Batch 120, Loss: 0.3459
Batch 130, Loss: 0.3697
Batch 140, Loss: 0.4146
Batch 150, Loss: 0.3442
Batch 160, Loss: 0.3913
Batch 170, Loss: 0.3483
Batch 180, Loss: 0.3187
Batch 190, Loss: 0.3760
Batch 200, Loss: 0.3512
Batch 210, Loss: 0.3677
Batch 220, Loss: 0.3316
Batch 230, Loss: 0.3611
Batch 240, Loss: 0.3656
Batch 250, Loss: 0.3821
Batch 260, Loss: 0.4053
Batch 270, Loss: 0.3734
Batch 280, Loss: 0.3536
Batch 290, Loss: 0.3522
Batch 300, Loss: 0.3691
Batch 310, Loss: 0.3647
Batch 320, Loss: 0.4201
Batch 330, Loss: 0.3953
Batch 340, Loss: 0.3764
Batch 350, Loss: 0.3464
Batch 360, Loss: 0.3606
Batch 370, Loss: 0.3619
Batch 380, Loss: 0.4076
Batch 390, Loss: 0.3625
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.05326747894287 seconds
Epoch 126 accuracy: 90.31%
Batch 10, Loss: 0.3853
Batch 20, Loss: 0.3361
Batch 30, Loss: 0.3496
Batch 40, Loss: 0.3590
Batch 50, Loss: 0.3606
Batch 60, Loss: 0.3388
Batch 70, Loss: 0.3781
Batch 80, Loss: 0.3708
Batch 90, Loss: 0.3455
Batch 100, Loss: 0.3102
Batch 110, Loss: 0.3795
Batch 120, Loss: 0.3627
Batch 130, Loss: 0.3574
Batch 140, Loss: 0.3388
Batch 150, Loss: 0.4002
Batch 160, Loss: 0.3324
Batch 170, Loss: 0.3610
Batch 180, Loss: 0.3414
Batch 190, Loss: 0.2957
Batch 200, Loss: 0.3706
Batch 210, Loss: 0.3348
Batch 220, Loss: 0.3979
Batch 230, Loss: 0.3829
Batch 240, Loss: 0.3529
Batch 250, Loss: 0.3631
Batch 260, Loss: 0.3493
Batch 270, Loss: 0.3925
Batch 280, Loss: 0.3914
Batch 290, Loss: 0.3636
Batch 300, Loss: 0.3709
Batch 310, Loss: 0.3532
Batch 320, Loss: 0.3643
Batch 330, Loss: 0.3554
Batch 340, Loss: 0.3702
Batch 350, Loss: 0.3699
Batch 360, Loss: 0.3995
Batch 370, Loss: 0.3784
Batch 380, Loss: 0.3273
Batch 390, Loss: 0.3678
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.018744945526123 seconds
Epoch 127 accuracy: 90.35%
Batch 10, Loss: 0.3696
Batch 20, Loss: 0.3165
Batch 30, Loss: 0.3352
Batch 40, Loss: 0.3414
Batch 50, Loss: 0.3314
Batch 60, Loss: 0.2972
Batch 70, Loss: 0.3547
Batch 80, Loss: 0.3563
Batch 90, Loss: 0.3271
Batch 100, Loss: 0.3570
Batch 110, Loss: 0.3460
Batch 120, Loss: 0.3221
Batch 130, Loss: 0.3847
Batch 140, Loss: 0.3570
Batch 150, Loss: 0.3667
Batch 160, Loss: 0.3609
Batch 170, Loss: 0.3650
Batch 180, Loss: 0.3262
Batch 190, Loss: 0.3830
Batch 200, Loss: 0.3475
Batch 210, Loss: 0.3467
Batch 220, Loss: 0.3682
Batch 230, Loss: 0.3713
Batch 240, Loss: 0.3727
Batch 250, Loss: 0.3927
Batch 260, Loss: 0.3384
Batch 270, Loss: 0.3758
Batch 280, Loss: 0.3480
Batch 290, Loss: 0.3501
Batch 300, Loss: 0.3568
Batch 310, Loss: 0.3424
Batch 320, Loss: 0.3660
Batch 330, Loss: 0.3457
Batch 340, Loss: 0.3804
Batch 350, Loss: 0.3769
Batch 360, Loss: 0.3600
Batch 370, Loss: 0.3676
Batch 380, Loss: 0.3989
Batch 390, Loss: 0.3477
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.001251220703125 seconds
Epoch 128 accuracy: 91.85%
Batch 10, Loss: 0.3296
Batch 20, Loss: 0.3330
Batch 30, Loss: 0.3393
Batch 40, Loss: 0.3382
Batch 50, Loss: 0.3631
Batch 60, Loss: 0.3255
Batch 70, Loss: 0.3499
Batch 80, Loss: 0.3486
Batch 90, Loss: 0.3144
Batch 100, Loss: 0.3592
Batch 110, Loss: 0.3561
Batch 120, Loss: 0.3697
Batch 130, Loss: 0.3433
Batch 140, Loss: 0.3198
Batch 150, Loss: 0.3698
Batch 160, Loss: 0.4129
Batch 170, Loss: 0.3926
Batch 180, Loss: 0.3295
Batch 190, Loss: 0.3573
Batch 200, Loss: 0.3587
Batch 210, Loss: 0.3244
Batch 220, Loss: 0.3661
Batch 230, Loss: 0.3494
Batch 240, Loss: 0.3909
Batch 250, Loss: 0.3666
Batch 260, Loss: 0.3656
Batch 270, Loss: 0.3486
Batch 280, Loss: 0.3310
Batch 290, Loss: 0.3810
Batch 300, Loss: 0.3591
Batch 310, Loss: 0.3806
Batch 320, Loss: 0.3215
Batch 330, Loss: 0.3254
Batch 340, Loss: 0.3447
Batch 350, Loss: 0.3651
Batch 360, Loss: 0.3485
Batch 370, Loss: 0.4105
Batch 380, Loss: 0.3418
Batch 390, Loss: 0.3572
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.02008867263794 seconds
Epoch 129 accuracy: 91.49%
Batch 10, Loss: 0.3622
Batch 20, Loss: 0.3364
Batch 30, Loss: 0.3579
Batch 40, Loss: 0.3346
Batch 50, Loss: 0.3706
Batch 60, Loss: 0.3302
Batch 70, Loss: 0.4002
Batch 80, Loss: 0.3807
Batch 90, Loss: 0.3461
Batch 100, Loss: 0.3536
Batch 110, Loss: 0.3333
Batch 120, Loss: 0.3663
Batch 130, Loss: 0.3720
Batch 140, Loss: 0.3633
Batch 150, Loss: 0.3280
Batch 160, Loss: 0.3514
Batch 170, Loss: 0.3519
Batch 180, Loss: 0.3614
Batch 190, Loss: 0.3308
Batch 200, Loss: 0.3468
Batch 210, Loss: 0.3729
Batch 220, Loss: 0.3425
Batch 230, Loss: 0.3576
Batch 240, Loss: 0.3575
Batch 250, Loss: 0.3653
Batch 260, Loss: 0.3246
Batch 270, Loss: 0.3487
Batch 280, Loss: 0.3159
Batch 290, Loss: 0.3393
Batch 300, Loss: 0.3557
Batch 310, Loss: 0.3324
Batch 320, Loss: 0.3570
Batch 330, Loss: 0.3384
Batch 340, Loss: 0.3496
Batch 350, Loss: 0.3974
Batch 360, Loss: 0.3416
Batch 370, Loss: 0.3407
Batch 380, Loss: 0.3418
Batch 390, Loss: 0.3371
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.009791374206543 seconds
Epoch 130 accuracy: 91.5%
Batch 10, Loss: 0.3217
Batch 20, Loss: 0.3130
Batch 30, Loss: 0.3647
Batch 40, Loss: 0.3162
Batch 50, Loss: 0.3420
Batch 60, Loss: 0.3879
Batch 70, Loss: 0.3237
Batch 80, Loss: 0.3733
Batch 90, Loss: 0.2913
Batch 100, Loss: 0.3238
Batch 110, Loss: 0.3372
Batch 120, Loss: 0.3713
Batch 130, Loss: 0.3495
Batch 140, Loss: 0.3412
Batch 150, Loss: 0.3277
Batch 160, Loss: 0.3507
Batch 170, Loss: 0.3449
Batch 180, Loss: 0.3314
Batch 190, Loss: 0.3427
Batch 200, Loss: 0.3264
Batch 210, Loss: 0.3132
Batch 220, Loss: 0.3375
Batch 230, Loss: 0.3460
Batch 240, Loss: 0.3250
Batch 250, Loss: 0.3348
Batch 260, Loss: 0.3112
Batch 270, Loss: 0.3391
Batch 280, Loss: 0.3491
Batch 290, Loss: 0.3607
Batch 300, Loss: 0.3524
Batch 310, Loss: 0.3474
Batch 320, Loss: 0.3704
Batch 330, Loss: 0.3307
Batch 340, Loss: 0.3556
Batch 350, Loss: 0.3444
Batch 360, Loss: 0.3351
Batch 370, Loss: 0.3508
Batch 380, Loss: 0.3449
Batch 390, Loss: 0.3535
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 24.948674201965332 seconds
Epoch 131 accuracy: 90.92%
Batch 10, Loss: 0.3135
Batch 20, Loss: 0.3643
Batch 30, Loss: 0.3274
Batch 40, Loss: 0.3478
Batch 50, Loss: 0.3506
Batch 60, Loss: 0.3528
Batch 70, Loss: 0.3529
Batch 80, Loss: 0.3396
Batch 90, Loss: 0.3541
Batch 100, Loss: 0.3515
Batch 110, Loss: 0.3135
Batch 120, Loss: 0.3777
Batch 130, Loss: 0.3519
Batch 140, Loss: 0.3765
Batch 150, Loss: 0.3443
Batch 160, Loss: 0.3570
Batch 170, Loss: 0.3634
Batch 180, Loss: 0.3014
Batch 190, Loss: 0.3295
Batch 200, Loss: 0.3484
Batch 210, Loss: 0.3288
Batch 220, Loss: 0.3262
Batch 230, Loss: 0.3554
Batch 240, Loss: 0.3136
Batch 250, Loss: 0.3379
Batch 260, Loss: 0.3886
Batch 270, Loss: 0.3507
Batch 280, Loss: 0.3550
Batch 290, Loss: 0.3671
Batch 300, Loss: 0.3545
Batch 310, Loss: 0.3349
Batch 320, Loss: 0.3378
Batch 330, Loss: 0.3507
Batch 340, Loss: 0.3480
Batch 350, Loss: 0.3149
Batch 360, Loss: 0.3368
Batch 370, Loss: 0.3444
Batch 380, Loss: 0.3492
Batch 390, Loss: 0.3356
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.00557017326355 seconds
Epoch 132 accuracy: 91.61%
Batch 10, Loss: 0.3347
Batch 20, Loss: 0.3196
Batch 30, Loss: 0.3670
Batch 40, Loss: 0.3786
Batch 50, Loss: 0.3487
Batch 60, Loss: 0.3332
Batch 70, Loss: 0.3303
Batch 80, Loss: 0.3276
Batch 90, Loss: 0.3438
Batch 100, Loss: 0.3196
Batch 110, Loss: 0.3651
Batch 120, Loss: 0.3181
Batch 130, Loss: 0.3228
Batch 140, Loss: 0.3422
Batch 150, Loss: 0.3351
Batch 160, Loss: 0.3316
Batch 170, Loss: 0.3543
Batch 180, Loss: 0.3040
Batch 190, Loss: 0.3491
Batch 200, Loss: 0.3387
Batch 210, Loss: 0.3555
Batch 220, Loss: 0.3748
Batch 230, Loss: 0.3469
Batch 240, Loss: 0.3382
Batch 250, Loss: 0.3532
Batch 260, Loss: 0.3470
Batch 270, Loss: 0.3734
Batch 280, Loss: 0.3452
Batch 290, Loss: 0.3265
Batch 300, Loss: 0.3032
Batch 310, Loss: 0.3379
Batch 320, Loss: 0.3393
Batch 330, Loss: 0.3422
Batch 340, Loss: 0.3363
Batch 350, Loss: 0.3810
Batch 360, Loss: 0.3426
Batch 370, Loss: 0.3428
Batch 380, Loss: 0.3425
Batch 390, Loss: 0.3763
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.030052185058594 seconds
Epoch 133 accuracy: 92.39%
Batch 10, Loss: 0.3467
Batch 20, Loss: 0.3391
Batch 30, Loss: 0.3194
Batch 40, Loss: 0.3635
Batch 50, Loss: 0.3166
Batch 60, Loss: 0.3350
Batch 70, Loss: 0.3062
Batch 80, Loss: 0.2991
Batch 90, Loss: 0.3236
Batch 100, Loss: 0.3346
Batch 110, Loss: 0.3386
Batch 120, Loss: 0.3463
Batch 130, Loss: 0.3371
Batch 140, Loss: 0.2967
Batch 150, Loss: 0.3252
Batch 160, Loss: 0.3542
Batch 170, Loss: 0.3149
Batch 180, Loss: 0.3463
Batch 190, Loss: 0.3596
Batch 200, Loss: 0.3184
Batch 210, Loss: 0.3127
Batch 220, Loss: 0.3310
Batch 230, Loss: 0.3681
Batch 240, Loss: 0.3309
Batch 250, Loss: 0.3486
Batch 260, Loss: 0.3319
Batch 270, Loss: 0.3602
Batch 280, Loss: 0.3170
Batch 290, Loss: 0.3508
Batch 300, Loss: 0.3457
Batch 310, Loss: 0.3510
Batch 320, Loss: 0.2930
Batch 330, Loss: 0.3408
Batch 340, Loss: 0.3512
Batch 350, Loss: 0.4117
Batch 360, Loss: 0.3500
Batch 370, Loss: 0.3269
Batch 380, Loss: 0.3328
Batch 390, Loss: 0.3370
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.011574029922485 seconds
Epoch 134 accuracy: 91.5%
Batch 10, Loss: 0.3525
Batch 20, Loss: 0.3270
Batch 30, Loss: 0.3479
Batch 40, Loss: 0.3213
Batch 50, Loss: 0.3219
Batch 60, Loss: 0.3486
Batch 70, Loss: 0.3101
Batch 80, Loss: 0.3239
Batch 90, Loss: 0.3513
Batch 100, Loss: 0.3193
Batch 110, Loss: 0.3279
Batch 120, Loss: 0.2956
Batch 130, Loss: 0.3549
Batch 140, Loss: 0.3627
Batch 150, Loss: 0.3236
Batch 160, Loss: 0.3643
Batch 170, Loss: 0.3386
Batch 180, Loss: 0.3319
Batch 190, Loss: 0.3522
Batch 200, Loss: 0.3534
Batch 210, Loss: 0.3478
Batch 220, Loss: 0.3343
Batch 230, Loss: 0.3347
Batch 240, Loss: 0.2967
Batch 250, Loss: 0.3285
Batch 260, Loss: 0.3412
Batch 270, Loss: 0.3281
Batch 280, Loss: 0.3347
Batch 290, Loss: 0.3627
Batch 300, Loss: 0.3155
Batch 310, Loss: 0.3416
Batch 320, Loss: 0.3217
Batch 330, Loss: 0.3202
Batch 340, Loss: 0.3364
Batch 350, Loss: 0.3321
Batch 360, Loss: 0.2966
Batch 370, Loss: 0.3354
Batch 380, Loss: 0.3582
Batch 390, Loss: 0.3033
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 24.98368191719055 seconds
Epoch 135 accuracy: 91.38%
Batch 10, Loss: 0.3489
Batch 20, Loss: 0.2937
Batch 30, Loss: 0.3085
Batch 40, Loss: 0.2942
Batch 50, Loss: 0.2968
Batch 60, Loss: 0.3156
Batch 70, Loss: 0.3352
Batch 80, Loss: 0.3083
Batch 90, Loss: 0.3343
Batch 100, Loss: 0.3148
Batch 110, Loss: 0.2954
Batch 120, Loss: 0.3183
Batch 130, Loss: 0.3011
Batch 140, Loss: 0.3497
Batch 150, Loss: 0.3074
Batch 160, Loss: 0.3044
Batch 170, Loss: 0.3389
Batch 180, Loss: 0.3477
Batch 190, Loss: 0.3408
Batch 200, Loss: 0.3205
Batch 210, Loss: 0.3261
Batch 220, Loss: 0.3271
Batch 230, Loss: 0.3388
Batch 240, Loss: 0.3233
Batch 250, Loss: 0.3176
Batch 260, Loss: 0.3530
Batch 270, Loss: 0.3249
Batch 280, Loss: 0.3440
Batch 290, Loss: 0.3510
Batch 300, Loss: 0.3005
Batch 310, Loss: 0.3271
Batch 320, Loss: 0.3577
Batch 330, Loss: 0.3311
Batch 340, Loss: 0.3038
Batch 350, Loss: 0.3332
Batch 360, Loss: 0.3376
Batch 370, Loss: 0.3314
Batch 380, Loss: 0.3172
Batch 390, Loss: 0.3654
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 24.990286350250244 seconds
Epoch 136 accuracy: 91.25%
Batch 10, Loss: 0.3094
Batch 20, Loss: 0.3099
Batch 30, Loss: 0.3280
Batch 40, Loss: 0.3373
Batch 50, Loss: 0.3174
Batch 60, Loss: 0.3011
Batch 70, Loss: 0.3343
Batch 80, Loss: 0.3156
Batch 90, Loss: 0.3358
Batch 100, Loss: 0.3674
Batch 110, Loss: 0.3153
Batch 120, Loss: 0.3279
Batch 130, Loss: 0.3416
Batch 140, Loss: 0.3484
Batch 150, Loss: 0.3394
Batch 160, Loss: 0.3637
Batch 170, Loss: 0.3115
Batch 180, Loss: 0.3101
Batch 190, Loss: 0.3216
Batch 200, Loss: 0.3379
Batch 210, Loss: 0.3408
Batch 220, Loss: 0.3281
Batch 230, Loss: 0.3348
Batch 240, Loss: 0.3087
Batch 250, Loss: 0.3636
Batch 260, Loss: 0.3849
Batch 270, Loss: 0.3185
Batch 280, Loss: 0.3186
Batch 290, Loss: 0.3328
Batch 300, Loss: 0.3362
Batch 310, Loss: 0.2951
Batch 320, Loss: 0.3281
Batch 330, Loss: 0.3457
Batch 340, Loss: 0.3307
Batch 350, Loss: 0.3534
Batch 360, Loss: 0.3363
Batch 370, Loss: 0.3659
Batch 380, Loss: 0.3119
Batch 390, Loss: 0.3460
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 24.972630977630615 seconds
Epoch 137 accuracy: 91.25%
Batch 10, Loss: 0.3082
Batch 20, Loss: 0.3240
Batch 30, Loss: 0.3391
Batch 40, Loss: 0.3042
Batch 50, Loss: 0.3087
Batch 60, Loss: 0.3061
Batch 70, Loss: 0.3352
Batch 80, Loss: 0.3034
Batch 90, Loss: 0.3510
Batch 100, Loss: 0.3232
Batch 110, Loss: 0.3203
Batch 120, Loss: 0.3361
Batch 130, Loss: 0.3201
Batch 140, Loss: 0.3190
Batch 150, Loss: 0.3286
Batch 160, Loss: 0.3368
Batch 170, Loss: 0.3070
Batch 180, Loss: 0.3351
Batch 190, Loss: 0.2918
Batch 200, Loss: 0.3220
Batch 210, Loss: 0.3304
Batch 220, Loss: 0.3146
Batch 230, Loss: 0.3090
Batch 240, Loss: 0.2914
Batch 250, Loss: 0.2992
Batch 260, Loss: 0.3356
Batch 270, Loss: 0.3090
Batch 280, Loss: 0.3442
Batch 290, Loss: 0.3372
Batch 300, Loss: 0.3011
Batch 310, Loss: 0.3210
Batch 320, Loss: 0.3168
Batch 330, Loss: 0.3511
Batch 340, Loss: 0.2895
Batch 350, Loss: 0.3214
Batch 360, Loss: 0.2934
Batch 370, Loss: 0.3504
Batch 380, Loss: 0.3651
Batch 390, Loss: 0.3447
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 24.953848838806152 seconds
Epoch 138 accuracy: 91.92%
Batch 10, Loss: 0.2897
Batch 20, Loss: 0.2999
Batch 30, Loss: 0.3171
Batch 40, Loss: 0.3118
Batch 50, Loss: 0.3115
Batch 60, Loss: 0.3357
Batch 70, Loss: 0.3076
Batch 80, Loss: 0.2806
Batch 90, Loss: 0.3092
Batch 100, Loss: 0.3469
Batch 110, Loss: 0.3187
Batch 120, Loss: 0.3271
Batch 130, Loss: 0.3052
Batch 140, Loss: 0.3200
Batch 150, Loss: 0.3227
Batch 160, Loss: 0.3232
Batch 170, Loss: 0.3030
Batch 180, Loss: 0.3153
Batch 190, Loss: 0.3402
Batch 200, Loss: 0.3472
Batch 210, Loss: 0.3319
Batch 220, Loss: 0.3649
Batch 230, Loss: 0.3194
Batch 240, Loss: 0.3113
Batch 250, Loss: 0.3366
Batch 260, Loss: 0.3270
Batch 270, Loss: 0.3172
Batch 280, Loss: 0.3360
Batch 290, Loss: 0.3268
Batch 300, Loss: 0.3089
Batch 310, Loss: 0.2960
Batch 320, Loss: 0.3496
Batch 330, Loss: 0.3154
Batch 340, Loss: 0.3030
Batch 350, Loss: 0.2926
Batch 360, Loss: 0.2956
Batch 370, Loss: 0.3236
Batch 380, Loss: 0.2975
Batch 390, Loss: 0.3113
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.008585214614868 seconds
Epoch 139 accuracy: 91.12%
Batch 10, Loss: 0.3202
Batch 20, Loss: 0.3333
Batch 30, Loss: 0.3247
Batch 40, Loss: 0.3266
Batch 50, Loss: 0.3084
Batch 60, Loss: 0.3471
Batch 70, Loss: 0.3172
Batch 80, Loss: 0.2731
Batch 90, Loss: 0.2959
Batch 100, Loss: 0.3170
Batch 110, Loss: 0.3308
Batch 120, Loss: 0.3075
Batch 130, Loss: 0.3023
Batch 140, Loss: 0.3068
Batch 150, Loss: 0.3258
Batch 160, Loss: 0.3263
Batch 170, Loss: 0.3241
Batch 180, Loss: 0.3251
Batch 190, Loss: 0.3194
Batch 200, Loss: 0.3079
Batch 210, Loss: 0.3314
Batch 220, Loss: 0.3147
Batch 230, Loss: 0.2984
Batch 240, Loss: 0.3040
Batch 250, Loss: 0.2992
Batch 260, Loss: 0.3488
Batch 270, Loss: 0.3128
Batch 280, Loss: 0.3154
Batch 290, Loss: 0.3149
Batch 300, Loss: 0.3132
Batch 310, Loss: 0.3155
Batch 320, Loss: 0.3304
Batch 330, Loss: 0.3041
Batch 340, Loss: 0.3132
Batch 350, Loss: 0.3442
Batch 360, Loss: 0.3217
Batch 370, Loss: 0.3423
Batch 380, Loss: 0.2975
Batch 390, Loss: 0.3260
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.026792526245117 seconds
Epoch 140 accuracy: 91.64%
Batch 10, Loss: 0.2888
Batch 20, Loss: 0.3424
Batch 30, Loss: 0.2765
Batch 40, Loss: 0.3068
Batch 50, Loss: 0.2790
Batch 60, Loss: 0.3353
Batch 70, Loss: 0.3484
Batch 80, Loss: 0.3378
Batch 90, Loss: 0.2992
Batch 100, Loss: 0.3454
Batch 110, Loss: 0.3207
Batch 120, Loss: 0.2938
Batch 130, Loss: 0.3025
Batch 140, Loss: 0.3049
Batch 150, Loss: 0.2814
Batch 160, Loss: 0.3149
Batch 170, Loss: 0.3005
Batch 180, Loss: 0.3079
Batch 190, Loss: 0.3156
Batch 200, Loss: 0.3195
Batch 210, Loss: 0.3311
Batch 220, Loss: 0.2917
Batch 230, Loss: 0.3283
Batch 240, Loss: 0.3036
Batch 250, Loss: 0.2891
Batch 260, Loss: 0.2979
Batch 270, Loss: 0.3121
Batch 280, Loss: 0.3412
Batch 290, Loss: 0.3244
Batch 300, Loss: 0.2990
Batch 310, Loss: 0.3070
Batch 320, Loss: 0.3053
Batch 330, Loss: 0.3276
Batch 340, Loss: 0.3088
Batch 350, Loss: 0.3281
Batch 360, Loss: 0.3347
Batch 370, Loss: 0.2980
Batch 380, Loss: 0.3503
Batch 390, Loss: 0.3122
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.0413920879364 seconds
Epoch 141 accuracy: 92.58%
Batch 10, Loss: 0.3216
Batch 20, Loss: 0.2828
Batch 30, Loss: 0.3061
Batch 40, Loss: 0.3055
Batch 50, Loss: 0.2914
Batch 60, Loss: 0.3079
Batch 70, Loss: 0.3019
Batch 80, Loss: 0.3255
Batch 90, Loss: 0.3093
Batch 100, Loss: 0.3008
Batch 110, Loss: 0.3190
Batch 120, Loss: 0.2973
Batch 130, Loss: 0.3471
Batch 140, Loss: 0.2976
Batch 150, Loss: 0.2778
Batch 160, Loss: 0.3206
Batch 170, Loss: 0.3176
Batch 180, Loss: 0.3316
Batch 190, Loss: 0.3199
Batch 200, Loss: 0.3090
Batch 210, Loss: 0.2764
Batch 220, Loss: 0.2919
Batch 230, Loss: 0.3265
Batch 240, Loss: 0.3230
Batch 250, Loss: 0.3124
Batch 260, Loss: 0.3066
Batch 270, Loss: 0.3094
Batch 280, Loss: 0.2967
Batch 290, Loss: 0.3118
Batch 300, Loss: 0.3339
Batch 310, Loss: 0.3517
Batch 320, Loss: 0.3140
Batch 330, Loss: 0.3445
Batch 340, Loss: 0.3503
Batch 350, Loss: 0.2921
Batch 360, Loss: 0.2925
Batch 370, Loss: 0.2887
Batch 380, Loss: 0.3084
Batch 390, Loss: 0.2940
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.059791088104248 seconds
Epoch 142 accuracy: 92.9%
Batch 10, Loss: 0.2991
Batch 20, Loss: 0.2964
Batch 30, Loss: 0.3020
Batch 40, Loss: 0.2931
Batch 50, Loss: 0.3078
Batch 60, Loss: 0.3097
Batch 70, Loss: 0.3105
Batch 80, Loss: 0.3293
Batch 90, Loss: 0.2984
Batch 100, Loss: 0.2869
Batch 110, Loss: 0.2822
Batch 120, Loss: 0.2765
Batch 130, Loss: 0.2845
Batch 140, Loss: 0.3347
Batch 150, Loss: 0.2974
Batch 160, Loss: 0.3076
Batch 170, Loss: 0.2691
Batch 180, Loss: 0.3103
Batch 190, Loss: 0.2817
Batch 200, Loss: 0.3254
Batch 210, Loss: 0.2956
Batch 220, Loss: 0.3375
Batch 230, Loss: 0.3311
Batch 240, Loss: 0.3142
Batch 250, Loss: 0.2963
Batch 260, Loss: 0.2982
Batch 270, Loss: 0.3190
Batch 280, Loss: 0.3469
Batch 290, Loss: 0.3288
Batch 300, Loss: 0.3666
Batch 310, Loss: 0.3101
Batch 320, Loss: 0.2739
Batch 330, Loss: 0.3126
Batch 340, Loss: 0.2823
Batch 350, Loss: 0.3097
Batch 360, Loss: 0.2540
Batch 370, Loss: 0.3108
Batch 380, Loss: 0.3139
Batch 390, Loss: 0.3011
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.001876831054688 seconds
Epoch 143 accuracy: 91.75%
Batch 10, Loss: 0.2809
Batch 20, Loss: 0.2840
Batch 30, Loss: 0.2991
Batch 40, Loss: 0.2743
Batch 50, Loss: 0.3047
Batch 60, Loss: 0.2751
Batch 70, Loss: 0.3057
Batch 80, Loss: 0.3039
Batch 90, Loss: 0.3077
Batch 100, Loss: 0.3019
Batch 110, Loss: 0.2912
Batch 120, Loss: 0.2995
Batch 130, Loss: 0.2971
Batch 140, Loss: 0.3237
Batch 150, Loss: 0.3362
Batch 160, Loss: 0.2807
Batch 170, Loss: 0.2892
Batch 180, Loss: 0.2855
Batch 190, Loss: 0.2907
Batch 200, Loss: 0.2757
Batch 210, Loss: 0.2706
Batch 220, Loss: 0.3221
Batch 230, Loss: 0.2611
Batch 240, Loss: 0.3171
Batch 250, Loss: 0.3138
Batch 260, Loss: 0.3215
Batch 270, Loss: 0.3265
Batch 280, Loss: 0.2747
Batch 290, Loss: 0.2945
Batch 300, Loss: 0.2850
Batch 310, Loss: 0.2881
Batch 320, Loss: 0.2949
Batch 330, Loss: 0.3082
Batch 340, Loss: 0.3152
Batch 350, Loss: 0.2992
Batch 360, Loss: 0.3311
Batch 370, Loss: 0.3028
Batch 380, Loss: 0.2967
Batch 390, Loss: 0.3071
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 24.98573064804077 seconds
Epoch 144 accuracy: 93.11%
Batch 10, Loss: 0.2745
Batch 20, Loss: 0.2999
Batch 30, Loss: 0.2878
Batch 40, Loss: 0.3081
Batch 50, Loss: 0.2813
Batch 60, Loss: 0.2731
Batch 70, Loss: 0.2885
Batch 80, Loss: 0.2819
Batch 90, Loss: 0.3036
Batch 100, Loss: 0.3000
Batch 110, Loss: 0.2987
Batch 120, Loss: 0.3022
Batch 130, Loss: 0.2918
Batch 140, Loss: 0.3149
Batch 150, Loss: 0.2882
Batch 160, Loss: 0.2878
Batch 170, Loss: 0.2959
Batch 180, Loss: 0.3080
Batch 190, Loss: 0.2753
Batch 200, Loss: 0.3008
Batch 210, Loss: 0.3085
Batch 220, Loss: 0.2701
Batch 230, Loss: 0.2905
Batch 240, Loss: 0.3015
Batch 250, Loss: 0.3272
Batch 260, Loss: 0.2773
Batch 270, Loss: 0.2728
Batch 280, Loss: 0.2827
Batch 290, Loss: 0.3333
Batch 300, Loss: 0.3039
Batch 310, Loss: 0.3139
Batch 320, Loss: 0.3402
Batch 330, Loss: 0.2757
Batch 340, Loss: 0.3053
Batch 350, Loss: 0.3144
Batch 360, Loss: 0.3122
Batch 370, Loss: 0.3091
Batch 380, Loss: 0.2724
Batch 390, Loss: 0.3034
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.024197816848755 seconds
Epoch 145 accuracy: 92.96%
Batch 10, Loss: 0.3076
Batch 20, Loss: 0.2672
Batch 30, Loss: 0.2948
Batch 40, Loss: 0.2948
Batch 50, Loss: 0.3028
Batch 60, Loss: 0.2860
Batch 70, Loss: 0.3031
Batch 80, Loss: 0.2780
Batch 90, Loss: 0.2906
Batch 100, Loss: 0.2669
Batch 110, Loss: 0.3066
Batch 120, Loss: 0.2974
Batch 130, Loss: 0.3026
Batch 140, Loss: 0.3221
Batch 150, Loss: 0.2914
Batch 160, Loss: 0.2942
Batch 170, Loss: 0.2964
Batch 180, Loss: 0.3246
Batch 190, Loss: 0.2640
Batch 200, Loss: 0.2922
Batch 210, Loss: 0.2871
Batch 220, Loss: 0.3164
Batch 230, Loss: 0.3003
Batch 240, Loss: 0.2915
Batch 250, Loss: 0.3271
Batch 260, Loss: 0.2942
Batch 270, Loss: 0.2892
Batch 280, Loss: 0.2753
Batch 290, Loss: 0.2836
Batch 300, Loss: 0.2889
Batch 310, Loss: 0.2873
Batch 320, Loss: 0.2762
Batch 330, Loss: 0.2737
Batch 340, Loss: 0.2866
Batch 350, Loss: 0.3108
Batch 360, Loss: 0.3080
Batch 370, Loss: 0.2943
Batch 380, Loss: 0.3083
Batch 390, Loss: 0.2893
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.08568811416626 seconds
Epoch 146 accuracy: 92.78%
Batch 10, Loss: 0.2774
Batch 20, Loss: 0.2905
Batch 30, Loss: 0.2806
Batch 40, Loss: 0.2739
Batch 50, Loss: 0.2992
Batch 60, Loss: 0.2725
Batch 70, Loss: 0.2722
Batch 80, Loss: 0.2887
Batch 90, Loss: 0.2705
Batch 100, Loss: 0.2878
Batch 110, Loss: 0.2595
Batch 120, Loss: 0.2577
Batch 130, Loss: 0.3007
Batch 140, Loss: 0.3066
Batch 150, Loss: 0.2781
Batch 160, Loss: 0.2974
Batch 170, Loss: 0.3001
Batch 180, Loss: 0.2869
Batch 190, Loss: 0.2769
Batch 200, Loss: 0.2972
Batch 210, Loss: 0.3068
Batch 220, Loss: 0.2824
Batch 230, Loss: 0.2642
Batch 240, Loss: 0.2827
Batch 250, Loss: 0.2749
Batch 260, Loss: 0.2912
Batch 270, Loss: 0.3128
Batch 280, Loss: 0.2847
Batch 290, Loss: 0.3149
Batch 300, Loss: 0.3082
Batch 310, Loss: 0.2784
Batch 320, Loss: 0.2821
Batch 330, Loss: 0.2954
Batch 340, Loss: 0.3118
Batch 350, Loss: 0.2910
Batch 360, Loss: 0.2882
Batch 370, Loss: 0.3030
Batch 380, Loss: 0.2993
Batch 390, Loss: 0.3182
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.051616430282593 seconds
Epoch 147 accuracy: 93.11%
Batch 10, Loss: 0.2786
Batch 20, Loss: 0.2956
Batch 30, Loss: 0.2743
Batch 40, Loss: 0.2948
Batch 50, Loss: 0.3160
Batch 60, Loss: 0.2806
Batch 70, Loss: 0.3056
Batch 80, Loss: 0.2905
Batch 90, Loss: 0.2569
Batch 100, Loss: 0.2874
Batch 110, Loss: 0.2940
Batch 120, Loss: 0.2848
Batch 130, Loss: 0.3011
Batch 140, Loss: 0.2852
Batch 150, Loss: 0.2697
Batch 160, Loss: 0.3004
Batch 170, Loss: 0.2571
Batch 180, Loss: 0.2595
Batch 190, Loss: 0.2842
Batch 200, Loss: 0.2905
Batch 210, Loss: 0.2998
Batch 220, Loss: 0.2867
Batch 230, Loss: 0.3063
Batch 240, Loss: 0.2911
Batch 250, Loss: 0.2938
Batch 260, Loss: 0.2891
Batch 270, Loss: 0.3135
Batch 280, Loss: 0.2554
Batch 290, Loss: 0.2896
Batch 300, Loss: 0.2736
Batch 310, Loss: 0.2636
Batch 320, Loss: 0.2722
Batch 330, Loss: 0.2691
Batch 340, Loss: 0.2814
Batch 350, Loss: 0.2938
Batch 360, Loss: 0.3132
Batch 370, Loss: 0.2786
Batch 380, Loss: 0.3046
Batch 390, Loss: 0.3320
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 24.990505695343018 seconds
Epoch 148 accuracy: 93.55%
Batch 10, Loss: 0.2949
Batch 20, Loss: 0.2938
Batch 30, Loss: 0.2590
Batch 40, Loss: 0.2966
Batch 50, Loss: 0.2673
Batch 60, Loss: 0.2661
Batch 70, Loss: 0.2909
Batch 80, Loss: 0.2975
Batch 90, Loss: 0.2570
Batch 100, Loss: 0.2856
Batch 110, Loss: 0.2953
Batch 120, Loss: 0.2578
Batch 130, Loss: 0.2780
Batch 140, Loss: 0.2900
Batch 150, Loss: 0.2463
Batch 160, Loss: 0.2581
Batch 170, Loss: 0.2801
Batch 180, Loss: 0.3212
Batch 190, Loss: 0.2759
Batch 200, Loss: 0.2902
Batch 210, Loss: 0.2818
Batch 220, Loss: 0.2797
Batch 230, Loss: 0.3216
Batch 240, Loss: 0.2624
Batch 250, Loss: 0.2793
Batch 260, Loss: 0.2802
Batch 270, Loss: 0.2977
Batch 280, Loss: 0.2854
Batch 290, Loss: 0.2896
Batch 300, Loss: 0.2928
Batch 310, Loss: 0.3029
Batch 320, Loss: 0.3007
Batch 330, Loss: 0.2939
Batch 340, Loss: 0.3060
Batch 350, Loss: 0.2925
Batch 360, Loss: 0.3098
Batch 370, Loss: 0.2507
Batch 380, Loss: 0.2875
Batch 390, Loss: 0.2813
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.00203514099121 seconds
Epoch 149 accuracy: 92.99%
Batch 10, Loss: 0.2710
Batch 20, Loss: 0.2885
Batch 30, Loss: 0.2776
Batch 40, Loss: 0.2503
Batch 50, Loss: 0.2733
Batch 60, Loss: 0.2967
Batch 70, Loss: 0.2764
Batch 80, Loss: 0.2586
Batch 90, Loss: 0.2843
Batch 100, Loss: 0.2873
Batch 110, Loss: 0.2561
Batch 120, Loss: 0.2744
Batch 130, Loss: 0.3139
Batch 140, Loss: 0.3049
Batch 150, Loss: 0.2472
Batch 160, Loss: 0.2654
Batch 170, Loss: 0.2965
Batch 180, Loss: 0.3000
Batch 190, Loss: 0.2662
Batch 200, Loss: 0.2779
Batch 210, Loss: 0.2808
Batch 220, Loss: 0.3169
Batch 230, Loss: 0.2726
Batch 240, Loss: 0.2890
Batch 250, Loss: 0.2775
Batch 260, Loss: 0.3024
Batch 270, Loss: 0.3057
Batch 280, Loss: 0.2938
Batch 290, Loss: 0.2817
Batch 300, Loss: 0.2872
Batch 310, Loss: 0.2771
Batch 320, Loss: 0.2617
Batch 330, Loss: 0.2639
Batch 340, Loss: 0.2955
Batch 350, Loss: 0.3036
Batch 360, Loss: 0.2946
Batch 370, Loss: 0.3051
Batch 380, Loss: 0.2906
Batch 390, Loss: 0.2837
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.09459900856018 seconds
Epoch 150 accuracy: 93.51%
Batch 10, Loss: 0.2554
Batch 20, Loss: 0.2309
Batch 30, Loss: 0.2643
Batch 40, Loss: 0.2897
Batch 50, Loss: 0.3104
Batch 60, Loss: 0.2542
Batch 70, Loss: 0.2752
Batch 80, Loss: 0.2745
Batch 90, Loss: 0.2715
Batch 100, Loss: 0.2656
Batch 110, Loss: 0.2816
Batch 120, Loss: 0.2714
Batch 130, Loss: 0.2823
Batch 140, Loss: 0.2631
Batch 150, Loss: 0.2903
Batch 160, Loss: 0.2823
Batch 170, Loss: 0.2751
Batch 180, Loss: 0.2537
Batch 190, Loss: 0.2903
Batch 200, Loss: 0.2927
Batch 210, Loss: 0.2909
Batch 220, Loss: 0.2646
Batch 230, Loss: 0.2934
Batch 240, Loss: 0.2750
Batch 250, Loss: 0.2840
Batch 260, Loss: 0.2580
Batch 270, Loss: 0.2369
Batch 280, Loss: 0.2874
Batch 290, Loss: 0.2552
Batch 300, Loss: 0.2829
Batch 310, Loss: 0.2963
Batch 320, Loss: 0.2706
Batch 330, Loss: 0.2995
Batch 340, Loss: 0.2656
Batch 350, Loss: 0.3046
Batch 360, Loss: 0.2502
Batch 370, Loss: 0.2699
Batch 380, Loss: 0.2685
Batch 390, Loss: 0.2730
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.084996938705444 seconds
Epoch 151 accuracy: 93.33%
Batch 10, Loss: 0.2528
Batch 20, Loss: 0.2512
Batch 30, Loss: 0.2896
Batch 40, Loss: 0.2634
Batch 50, Loss: 0.2832
Batch 60, Loss: 0.3093
Batch 70, Loss: 0.2745
Batch 80, Loss: 0.2507
Batch 90, Loss: 0.2900
Batch 100, Loss: 0.2567
Batch 110, Loss: 0.2667
Batch 120, Loss: 0.2433
Batch 130, Loss: 0.2857
Batch 140, Loss: 0.2641
Batch 150, Loss: 0.2538
Batch 160, Loss: 0.2804
Batch 170, Loss: 0.2745
Batch 180, Loss: 0.2686
Batch 190, Loss: 0.2884
Batch 200, Loss: 0.2373
Batch 210, Loss: 0.2874
Batch 220, Loss: 0.2891
Batch 230, Loss: 0.2768
Batch 240, Loss: 0.2603
Batch 250, Loss: 0.2742
Batch 260, Loss: 0.2574
Batch 270, Loss: 0.2603
Batch 280, Loss: 0.2705
Batch 290, Loss: 0.2928
Batch 300, Loss: 0.2690
Batch 310, Loss: 0.2856
Batch 320, Loss: 0.2504
Batch 330, Loss: 0.2822
Batch 340, Loss: 0.2686
Batch 350, Loss: 0.2573
Batch 360, Loss: 0.2884
Batch 370, Loss: 0.2699
Batch 380, Loss: 0.2857
Batch 390, Loss: 0.2854
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.045170783996582 seconds
Epoch 152 accuracy: 94.15%
Batch 10, Loss: 0.2657
Batch 20, Loss: 0.2257
Batch 30, Loss: 0.2589
Batch 40, Loss: 0.2537
Batch 50, Loss: 0.2627
Batch 60, Loss: 0.2439
Batch 70, Loss: 0.2748
Batch 80, Loss: 0.2856
Batch 90, Loss: 0.2658
Batch 100, Loss: 0.2620
Batch 110, Loss: 0.2568
Batch 120, Loss: 0.2619
Batch 130, Loss: 0.2489
Batch 140, Loss: 0.2664
Batch 150, Loss: 0.2730
Batch 160, Loss: 0.2762
Batch 170, Loss: 0.2905
Batch 180, Loss: 0.2603
Batch 190, Loss: 0.2560
Batch 200, Loss: 0.2708
Batch 210, Loss: 0.2502
Batch 220, Loss: 0.2671
Batch 230, Loss: 0.2574
Batch 240, Loss: 0.2896
Batch 250, Loss: 0.2587
Batch 260, Loss: 0.2445
Batch 270, Loss: 0.2711
Batch 280, Loss: 0.3131
Batch 290, Loss: 0.2853
Batch 300, Loss: 0.2961
Batch 310, Loss: 0.2461
Batch 320, Loss: 0.2866
Batch 330, Loss: 0.2905
Batch 340, Loss: 0.2650
Batch 350, Loss: 0.2969
Batch 360, Loss: 0.2514
Batch 370, Loss: 0.3002
Batch 380, Loss: 0.2599
Batch 390, Loss: 0.2896
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.136208534240723 seconds
Epoch 153 accuracy: 93.98%
Batch 10, Loss: 0.2618
Batch 20, Loss: 0.2761
Batch 30, Loss: 0.2605
Batch 40, Loss: 0.2662
Batch 50, Loss: 0.2555
Batch 60, Loss: 0.2812
Batch 70, Loss: 0.2564
Batch 80, Loss: 0.2672
Batch 90, Loss: 0.2496
Batch 100, Loss: 0.2496
Batch 110, Loss: 0.2575
Batch 120, Loss: 0.2561
Batch 130, Loss: 0.2531
Batch 140, Loss: 0.2422
Batch 150, Loss: 0.2548
Batch 160, Loss: 0.2812
Batch 170, Loss: 0.2707
Batch 180, Loss: 0.2540
Batch 190, Loss: 0.2336
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2553
Batch 220, Loss: 0.2533
Batch 230, Loss: 0.2595
Batch 240, Loss: 0.2567
Batch 250, Loss: 0.2655
Batch 260, Loss: 0.3113
Batch 270, Loss: 0.2640
Batch 280, Loss: 0.2732
Batch 290, Loss: 0.2739
Batch 300, Loss: 0.2410
Batch 310, Loss: 0.2754
Batch 320, Loss: 0.2575
Batch 330, Loss: 0.2521
Batch 340, Loss: 0.2431
Batch 350, Loss: 0.2697
Batch 360, Loss: 0.2466
Batch 370, Loss: 0.2927
Batch 380, Loss: 0.2689
Batch 390, Loss: 0.2596
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.04676055908203 seconds
Epoch 154 accuracy: 93.95%
Batch 10, Loss: 0.2524
Batch 20, Loss: 0.2526
Batch 30, Loss: 0.2787
Batch 40, Loss: 0.2323
Batch 50, Loss: 0.2554
Batch 60, Loss: 0.2614
Batch 70, Loss: 0.2575
Batch 80, Loss: 0.2533
Batch 90, Loss: 0.2420
Batch 100, Loss: 0.2553
Batch 110, Loss: 0.2342
Batch 120, Loss: 0.2372
Batch 130, Loss: 0.2463
Batch 140, Loss: 0.2522
Batch 150, Loss: 0.2810
Batch 160, Loss: 0.2416
Batch 170, Loss: 0.2532
Batch 180, Loss: 0.2556
Batch 190, Loss: 0.2981
Batch 200, Loss: 0.2569
Batch 210, Loss: 0.2367
Batch 220, Loss: 0.2293
Batch 230, Loss: 0.2340
Batch 240, Loss: 0.2659
Batch 250, Loss: 0.2569
Batch 260, Loss: 0.2508
Batch 270, Loss: 0.2394
Batch 280, Loss: 0.2458
Batch 290, Loss: 0.2676
Batch 300, Loss: 0.3024
Batch 310, Loss: 0.2554
Batch 320, Loss: 0.2750
Batch 330, Loss: 0.2420
Batch 340, Loss: 0.2502
Batch 350, Loss: 0.2520
Batch 360, Loss: 0.2633
Batch 370, Loss: 0.2780
Batch 380, Loss: 0.2708
Batch 390, Loss: 0.2772
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.06282353401184 seconds
Epoch 155 accuracy: 93.75%
Batch 10, Loss: 0.2566
Batch 20, Loss: 0.2798
Batch 30, Loss: 0.2659
Batch 40, Loss: 0.2776
Batch 50, Loss: 0.2386
Batch 60, Loss: 0.2428
Batch 70, Loss: 0.2874
Batch 80, Loss: 0.2669
Batch 90, Loss: 0.2626
Batch 100, Loss: 0.2444
Batch 110, Loss: 0.2416
Batch 120, Loss: 0.2346
Batch 130, Loss: 0.2236
Batch 140, Loss: 0.2396
Batch 150, Loss: 0.2493
Batch 160, Loss: 0.2419
Batch 170, Loss: 0.2524
Batch 180, Loss: 0.2408
Batch 190, Loss: 0.2579
Batch 200, Loss: 0.2394
Batch 210, Loss: 0.2512
Batch 220, Loss: 0.2516
Batch 230, Loss: 0.2651
Batch 240, Loss: 0.2668
Batch 250, Loss: 0.2607
Batch 260, Loss: 0.2432
Batch 270, Loss: 0.2556
Batch 280, Loss: 0.2823
Batch 290, Loss: 0.2606
Batch 300, Loss: 0.2583
Batch 310, Loss: 0.2421
Batch 320, Loss: 0.2591
Batch 330, Loss: 0.2486
Batch 340, Loss: 0.2345
Batch 350, Loss: 0.2583
Batch 360, Loss: 0.2685
Batch 370, Loss: 0.2445
Batch 380, Loss: 0.2255
Batch 390, Loss: 0.2554
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.023643493652344 seconds
Epoch 156 accuracy: 94.11%
Batch 10, Loss: 0.2561
Batch 20, Loss: 0.2396
Batch 30, Loss: 0.2617
Batch 40, Loss: 0.2621
Batch 50, Loss: 0.2405
Batch 60, Loss: 0.2431
Batch 70, Loss: 0.2395
Batch 80, Loss: 0.2765
Batch 90, Loss: 0.2388
Batch 100, Loss: 0.2428
Batch 110, Loss: 0.2583
Batch 120, Loss: 0.2450
Batch 130, Loss: 0.2101
Batch 140, Loss: 0.2634
Batch 150, Loss: 0.2452
Batch 160, Loss: 0.2394
Batch 170, Loss: 0.2330
Batch 180, Loss: 0.2362
Batch 190, Loss: 0.2419
Batch 200, Loss: 0.2604
Batch 210, Loss: 0.2839
Batch 220, Loss: 0.2499
Batch 230, Loss: 0.2368
Batch 240, Loss: 0.2325
Batch 250, Loss: 0.2517
Batch 260, Loss: 0.2546
Batch 270, Loss: 0.2731
Batch 280, Loss: 0.2721
Batch 290, Loss: 0.2287
Batch 300, Loss: 0.2591
Batch 310, Loss: 0.2452
Batch 320, Loss: 0.2480
Batch 330, Loss: 0.2446
Batch 340, Loss: 0.2611
Batch 350, Loss: 0.2535
Batch 360, Loss: 0.2469
Batch 370, Loss: 0.2295
Batch 380, Loss: 0.2360
Batch 390, Loss: 0.2679
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.038060903549194 seconds
Epoch 157 accuracy: 94.1%
Batch 10, Loss: 0.2544
Batch 20, Loss: 0.2537
Batch 30, Loss: 0.2418
Batch 40, Loss: 0.2133
Batch 50, Loss: 0.2447
Batch 60, Loss: 0.2415
Batch 70, Loss: 0.2537
Batch 80, Loss: 0.2361
Batch 90, Loss: 0.2531
Batch 100, Loss: 0.2155
Batch 110, Loss: 0.2383
Batch 120, Loss: 0.2272
Batch 130, Loss: 0.2368
Batch 140, Loss: 0.2219
Batch 150, Loss: 0.2304
Batch 160, Loss: 0.2772
Batch 170, Loss: 0.2506
Batch 180, Loss: 0.2473
Batch 190, Loss: 0.2355
Batch 200, Loss: 0.2322
Batch 210, Loss: 0.2167
Batch 220, Loss: 0.2644
Batch 230, Loss: 0.2535
Batch 240, Loss: 0.2676
Batch 250, Loss: 0.2520
Batch 260, Loss: 0.2546
Batch 270, Loss: 0.2317
Batch 280, Loss: 0.2529
Batch 290, Loss: 0.2693
Batch 300, Loss: 0.2572
Batch 310, Loss: 0.2385
Batch 320, Loss: 0.2378
Batch 330, Loss: 0.2843
Batch 340, Loss: 0.2537
Batch 350, Loss: 0.2145
Batch 360, Loss: 0.2666
Batch 370, Loss: 0.2357
Batch 380, Loss: 0.2227
Batch 390, Loss: 0.2608
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.0540554523468 seconds
Epoch 158 accuracy: 94.59%
Batch 10, Loss: 0.2540
Batch 20, Loss: 0.2387
Batch 30, Loss: 0.2780
Batch 40, Loss: 0.2703
Batch 50, Loss: 0.2201
Batch 60, Loss: 0.2205
Batch 70, Loss: 0.2507
Batch 80, Loss: 0.2238
Batch 90, Loss: 0.2510
Batch 100, Loss: 0.2818
Batch 110, Loss: 0.2093
Batch 120, Loss: 0.2379
Batch 130, Loss: 0.2331
Batch 140, Loss: 0.2578
Batch 150, Loss: 0.2258
Batch 160, Loss: 0.2407
Batch 170, Loss: 0.2292
Batch 180, Loss: 0.2467
Batch 190, Loss: 0.2596
Batch 200, Loss: 0.2515
Batch 210, Loss: 0.2303
Batch 220, Loss: 0.2705
Batch 230, Loss: 0.2275
Batch 240, Loss: 0.2535
Batch 250, Loss: 0.2478
Batch 260, Loss: 0.2530
Batch 270, Loss: 0.2730
Batch 280, Loss: 0.2396
Batch 290, Loss: 0.2081
Batch 300, Loss: 0.2179
Batch 310, Loss: 0.2218
Batch 320, Loss: 0.2376
Batch 330, Loss: 0.2298
Batch 340, Loss: 0.2510
Batch 350, Loss: 0.2734
Batch 360, Loss: 0.2592
Batch 370, Loss: 0.2528
Batch 380, Loss: 0.2495
Batch 390, Loss: 0.2532
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.0568630695343 seconds
Epoch 159 accuracy: 94.47%
Batch 10, Loss: 0.2395
Batch 20, Loss: 0.2406
Batch 30, Loss: 0.2525
Batch 40, Loss: 0.2446
Batch 50, Loss: 0.2166
Batch 60, Loss: 0.2582
Batch 70, Loss: 0.2296
Batch 80, Loss: 0.2210
Batch 90, Loss: 0.2322
Batch 100, Loss: 0.2306
Batch 110, Loss: 0.2557
Batch 120, Loss: 0.2408
Batch 130, Loss: 0.2229
Batch 140, Loss: 0.2223
Batch 150, Loss: 0.2590
Batch 160, Loss: 0.2389
Batch 170, Loss: 0.2356
Batch 180, Loss: 0.2410
Batch 190, Loss: 0.2216
Batch 200, Loss: 0.2424
Batch 210, Loss: 0.2426
Batch 220, Loss: 0.2387
Batch 230, Loss: 0.2752
Batch 240, Loss: 0.2351
Batch 250, Loss: 0.2597
Batch 260, Loss: 0.2587
Batch 270, Loss: 0.2323
Batch 280, Loss: 0.2093
Batch 290, Loss: 0.2387
Batch 300, Loss: 0.2597
Batch 310, Loss: 0.2455
Batch 320, Loss: 0.2458
Batch 330, Loss: 0.2409
Batch 340, Loss: 0.2287
Batch 350, Loss: 0.2314
Batch 360, Loss: 0.2260
Batch 370, Loss: 0.2598
Batch 380, Loss: 0.2416
Batch 390, Loss: 0.2861
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.063382148742676 seconds
Epoch 160 accuracy: 94.47%
Batch 10, Loss: 0.2554
Batch 20, Loss: 0.2530
Batch 30, Loss: 0.2464
Batch 40, Loss: 0.2329
Batch 50, Loss: 0.2261
Batch 60, Loss: 0.2412
Batch 70, Loss: 0.2084
Batch 80, Loss: 0.2274
Batch 90, Loss: 0.2227
Batch 100, Loss: 0.2350
Batch 110, Loss: 0.2217
Batch 120, Loss: 0.2164
Batch 130, Loss: 0.2447
Batch 140, Loss: 0.2580
Batch 150, Loss: 0.2385
Batch 160, Loss: 0.2311
Batch 170, Loss: 0.2541
Batch 180, Loss: 0.2198
Batch 190, Loss: 0.2348
Batch 200, Loss: 0.2308
Batch 210, Loss: 0.2509
Batch 220, Loss: 0.2342
Batch 230, Loss: 0.2638
Batch 240, Loss: 0.2397
Batch 250, Loss: 0.2367
Batch 260, Loss: 0.2383
Batch 270, Loss: 0.2424
Batch 280, Loss: 0.2216
Batch 290, Loss: 0.2576
Batch 300, Loss: 0.2351
Batch 310, Loss: 0.2379
Batch 320, Loss: 0.2373
Batch 330, Loss: 0.2415
Batch 340, Loss: 0.2215
Batch 350, Loss: 0.2479
Batch 360, Loss: 0.2501
Batch 370, Loss: 0.2439
Batch 380, Loss: 0.2328
Batch 390, Loss: 0.2485
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.078193187713623 seconds
Epoch 161 accuracy: 94.02%
Batch 10, Loss: 0.2351
Batch 20, Loss: 0.2306
Batch 30, Loss: 0.2347
Batch 40, Loss: 0.2283
Batch 50, Loss: 0.1966
Batch 60, Loss: 0.2302
Batch 70, Loss: 0.2114
Batch 80, Loss: 0.2212
Batch 90, Loss: 0.2645
Batch 100, Loss: 0.2280
Batch 110, Loss: 0.2453
Batch 120, Loss: 0.2217
Batch 130, Loss: 0.2346
Batch 140, Loss: 0.2255
Batch 150, Loss: 0.2459
Batch 160, Loss: 0.2173
Batch 170, Loss: 0.2346
Batch 180, Loss: 0.2072
Batch 190, Loss: 0.2330
Batch 200, Loss: 0.2317
Batch 210, Loss: 0.2166
Batch 220, Loss: 0.2449
Batch 230, Loss: 0.2194
Batch 240, Loss: 0.2108
Batch 250, Loss: 0.2312
Batch 260, Loss: 0.2437
Batch 270, Loss: 0.2268
Batch 280, Loss: 0.2368
Batch 290, Loss: 0.2308
Batch 300, Loss: 0.2127
Batch 310, Loss: 0.2681
Batch 320, Loss: 0.2459
Batch 330, Loss: 0.2452
Batch 340, Loss: 0.2367
Batch 350, Loss: 0.2060
Batch 360, Loss: 0.2480
Batch 370, Loss: 0.2362
Batch 380, Loss: 0.2609
Batch 390, Loss: 0.2270
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.044105291366577 seconds
Epoch 162 accuracy: 94.62%
Batch 10, Loss: 0.2538
Batch 20, Loss: 0.2179
Batch 30, Loss: 0.2559
Batch 40, Loss: 0.2163
Batch 50, Loss: 0.2216
Batch 60, Loss: 0.2175
Batch 70, Loss: 0.2080
Batch 80, Loss: 0.2087
Batch 90, Loss: 0.2023
Batch 100, Loss: 0.2255
Batch 110, Loss: 0.2326
Batch 120, Loss: 0.2504
Batch 130, Loss: 0.2231
Batch 140, Loss: 0.2180
Batch 150, Loss: 0.2248
Batch 160, Loss: 0.2234
Batch 170, Loss: 0.2460
Batch 180, Loss: 0.2280
Batch 190, Loss: 0.2127
Batch 200, Loss: 0.2247
Batch 210, Loss: 0.2142
Batch 220, Loss: 0.2104
Batch 230, Loss: 0.1945
Batch 240, Loss: 0.2246
Batch 250, Loss: 0.2226
Batch 260, Loss: 0.2254
Batch 270, Loss: 0.2565
Batch 280, Loss: 0.2419
Batch 290, Loss: 0.2294
Batch 300, Loss: 0.2114
Batch 310, Loss: 0.2389
Batch 320, Loss: 0.2252
Batch 330, Loss: 0.2588
Batch 340, Loss: 0.2539
Batch 350, Loss: 0.2264
Batch 360, Loss: 0.2184
Batch 370, Loss: 0.2124
Batch 380, Loss: 0.2335
Batch 390, Loss: 0.2284
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.052159786224365 seconds
Epoch 163 accuracy: 94.41%
Batch 10, Loss: 0.2329
Batch 20, Loss: 0.2506
Batch 30, Loss: 0.2116
Batch 40, Loss: 0.2083
Batch 50, Loss: 0.2402
Batch 60, Loss: 0.2257
Batch 70, Loss: 0.2177
Batch 80, Loss: 0.2119
Batch 90, Loss: 0.2149
Batch 100, Loss: 0.1920
Batch 110, Loss: 0.2270
Batch 120, Loss: 0.2338
Batch 130, Loss: 0.2152
Batch 140, Loss: 0.2080
Batch 150, Loss: 0.2239
Batch 160, Loss: 0.2230
Batch 170, Loss: 0.1932
Batch 180, Loss: 0.2321
Batch 190, Loss: 0.2169
Batch 200, Loss: 0.2048
Batch 210, Loss: 0.2156
Batch 220, Loss: 0.1984
Batch 230, Loss: 0.2095
Batch 240, Loss: 0.2422
Batch 250, Loss: 0.2280
Batch 260, Loss: 0.2163
Batch 270, Loss: 0.2335
Batch 280, Loss: 0.2270
Batch 290, Loss: 0.2145
Batch 300, Loss: 0.2134
Batch 310, Loss: 0.2216
Batch 320, Loss: 0.2303
Batch 330, Loss: 0.2229
Batch 340, Loss: 0.1965
Batch 350, Loss: 0.2174
Batch 360, Loss: 0.2518
Batch 370, Loss: 0.2548
Batch 380, Loss: 0.2162
Batch 390, Loss: 0.2611
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.030328512191772 seconds
Epoch 164 accuracy: 94.47%
Batch 10, Loss: 0.2312
Batch 20, Loss: 0.2011
Batch 30, Loss: 0.1968
Batch 40, Loss: 0.2273
Batch 50, Loss: 0.2341
Batch 60, Loss: 0.2301
Batch 70, Loss: 0.2567
Batch 80, Loss: 0.2088
Batch 90, Loss: 0.1912
Batch 100, Loss: 0.2155
Batch 110, Loss: 0.2123
Batch 120, Loss: 0.2231
Batch 130, Loss: 0.2259
Batch 140, Loss: 0.1954
Batch 150, Loss: 0.1925
Batch 160, Loss: 0.2088
Batch 170, Loss: 0.2102
Batch 180, Loss: 0.1875
Batch 190, Loss: 0.2168
Batch 200, Loss: 0.2246
Batch 210, Loss: 0.2135
Batch 220, Loss: 0.2005
Batch 230, Loss: 0.2089
Batch 240, Loss: 0.2120
Batch 250, Loss: 0.2153
Batch 260, Loss: 0.2524
Batch 270, Loss: 0.2029
Batch 280, Loss: 0.2027
Batch 290, Loss: 0.2321
Batch 300, Loss: 0.2160
Batch 310, Loss: 0.2110
Batch 320, Loss: 0.2068
Batch 330, Loss: 0.2158
Batch 340, Loss: 0.1943
Batch 350, Loss: 0.1888
Batch 360, Loss: 0.2066
Batch 370, Loss: 0.2310
Batch 380, Loss: 0.2341
Batch 390, Loss: 0.2103
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.090992212295532 seconds
Epoch 165 accuracy: 94.34%
Batch 10, Loss: 0.2027
Batch 20, Loss: 0.1932
Batch 30, Loss: 0.2193
Batch 40, Loss: 0.2129
Batch 50, Loss: 0.2097
Batch 60, Loss: 0.2255
Batch 70, Loss: 0.2116
Batch 80, Loss: 0.1992
Batch 90, Loss: 0.2234
Batch 100, Loss: 0.2115
Batch 110, Loss: 0.2166
Batch 120, Loss: 0.2048
Batch 130, Loss: 0.2157
Batch 140, Loss: 0.2255
Batch 150, Loss: 0.2393
Batch 160, Loss: 0.2129
Batch 170, Loss: 0.2244
Batch 180, Loss: 0.1874
Batch 190, Loss: 0.2424
Batch 200, Loss: 0.2084
Batch 210, Loss: 0.2254
Batch 220, Loss: 0.2103
Batch 230, Loss: 0.2338
Batch 240, Loss: 0.2138
Batch 250, Loss: 0.2109
Batch 260, Loss: 0.2156
Batch 270, Loss: 0.1912
Batch 280, Loss: 0.2259
Batch 290, Loss: 0.2308
Batch 300, Loss: 0.2085
Batch 310, Loss: 0.2349
Batch 320, Loss: 0.2141
Batch 330, Loss: 0.2101
Batch 340, Loss: 0.2377
Batch 350, Loss: 0.2118
Batch 360, Loss: 0.1954
Batch 370, Loss: 0.2285
Batch 380, Loss: 0.2143
Batch 390, Loss: 0.1930
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.091145038604736 seconds
Epoch 166 accuracy: 95.2%
Batch 10, Loss: 0.2295
Batch 20, Loss: 0.2243
Batch 30, Loss: 0.1963
Batch 40, Loss: 0.2229
Batch 50, Loss: 0.2330
Batch 60, Loss: 0.2018
Batch 70, Loss: 0.2022
Batch 80, Loss: 0.2069
Batch 90, Loss: 0.2025
Batch 100, Loss: 0.2101
Batch 110, Loss: 0.2029
Batch 120, Loss: 0.1808
Batch 130, Loss: 0.2091
Batch 140, Loss: 0.1912
Batch 150, Loss: 0.2370
Batch 160, Loss: 0.1877
Batch 170, Loss: 0.2068
Batch 180, Loss: 0.2076
Batch 190, Loss: 0.2328
Batch 200, Loss: 0.2066
Batch 210, Loss: 0.1948
Batch 220, Loss: 0.2223
Batch 230, Loss: 0.2107
Batch 240, Loss: 0.2083
Batch 250, Loss: 0.2072
Batch 260, Loss: 0.2127
Batch 270, Loss: 0.1848
Batch 280, Loss: 0.2039
Batch 290, Loss: 0.2355
Batch 300, Loss: 0.2317
Batch 310, Loss: 0.2094
Batch 320, Loss: 0.2230
Batch 330, Loss: 0.2314
Batch 340, Loss: 0.2213
Batch 350, Loss: 0.1900
Batch 360, Loss: 0.2403
Batch 370, Loss: 0.2027
Batch 380, Loss: 0.2535
Batch 390, Loss: 0.2072
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.118462800979614 seconds
Epoch 167 accuracy: 94.93%
Batch 10, Loss: 0.1736
Batch 20, Loss: 0.2105
Batch 30, Loss: 0.2087
Batch 40, Loss: 0.1952
Batch 50, Loss: 0.1905
Batch 60, Loss: 0.2079
Batch 70, Loss: 0.1996
Batch 80, Loss: 0.2043
Batch 90, Loss: 0.2294
Batch 100, Loss: 0.2111
Batch 110, Loss: 0.2360
Batch 120, Loss: 0.2010
Batch 130, Loss: 0.2104
Batch 140, Loss: 0.2124
Batch 150, Loss: 0.1936
Batch 160, Loss: 0.2104
Batch 170, Loss: 0.2035
Batch 180, Loss: 0.1851
Batch 190, Loss: 0.2029
Batch 200, Loss: 0.1791
Batch 210, Loss: 0.1942
Batch 220, Loss: 0.2059
Batch 230, Loss: 0.1988
Batch 240, Loss: 0.2107
Batch 250, Loss: 0.1874
Batch 260, Loss: 0.1818
Batch 270, Loss: 0.2058
Batch 280, Loss: 0.1983
Batch 290, Loss: 0.2184
Batch 300, Loss: 0.2112
Batch 310, Loss: 0.2022
Batch 320, Loss: 0.1917
Batch 330, Loss: 0.2298
Batch 340, Loss: 0.2014
Batch 350, Loss: 0.2050
Batch 360, Loss: 0.1961
Batch 370, Loss: 0.2307
Batch 380, Loss: 0.2398
Batch 390, Loss: 0.2078
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.100909948349 seconds
Epoch 168 accuracy: 95.07%
Batch 10, Loss: 0.1928
Batch 20, Loss: 0.2358
Batch 30, Loss: 0.2018
Batch 40, Loss: 0.1859
Batch 50, Loss: 0.1771
Batch 60, Loss: 0.2089
Batch 70, Loss: 0.1866
Batch 80, Loss: 0.1649
Batch 90, Loss: 0.2314
Batch 100, Loss: 0.1937
Batch 110, Loss: 0.1862
Batch 120, Loss: 0.2199
Batch 130, Loss: 0.1977
Batch 140, Loss: 0.1969
Batch 150, Loss: 0.2140
Batch 160, Loss: 0.1631
Batch 170, Loss: 0.2151
Batch 180, Loss: 0.1931
Batch 190, Loss: 0.2094
Batch 200, Loss: 0.1794
Batch 210, Loss: 0.1999
Batch 220, Loss: 0.2226
Batch 230, Loss: 0.2044
Batch 240, Loss: 0.2188
Batch 250, Loss: 0.2146
Batch 260, Loss: 0.2199
Batch 270, Loss: 0.2020
Batch 280, Loss: 0.1801
Batch 290, Loss: 0.1922
Batch 300, Loss: 0.2028
Batch 310, Loss: 0.1908
Batch 320, Loss: 0.1773
Batch 330, Loss: 0.1960
Batch 340, Loss: 0.1928
Batch 350, Loss: 0.2047
Batch 360, Loss: 0.1794
Batch 370, Loss: 0.1684
Batch 380, Loss: 0.2237
Batch 390, Loss: 0.1704
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.09955596923828 seconds
Epoch 169 accuracy: 95.07%
Batch 10, Loss: 0.1902
Batch 20, Loss: 0.1769
Batch 30, Loss: 0.1713
Batch 40, Loss: 0.1812
Batch 50, Loss: 0.1869
Batch 60, Loss: 0.1953
Batch 70, Loss: 0.1908
Batch 80, Loss: 0.2379
Batch 90, Loss: 0.2049
Batch 100, Loss: 0.1726
Batch 110, Loss: 0.1985
Batch 120, Loss: 0.2044
Batch 130, Loss: 0.2119
Batch 140, Loss: 0.2116
Batch 150, Loss: 0.1909
Batch 160, Loss: 0.2003
Batch 170, Loss: 0.1780
Batch 180, Loss: 0.1889
Batch 190, Loss: 0.2011
Batch 200, Loss: 0.2047
Batch 210, Loss: 0.1823
Batch 220, Loss: 0.1896
Batch 230, Loss: 0.1867
Batch 240, Loss: 0.1937
Batch 250, Loss: 0.1867
Batch 260, Loss: 0.1917
Batch 270, Loss: 0.2259
Batch 280, Loss: 0.2090
Batch 290, Loss: 0.2230
Batch 300, Loss: 0.2103
Batch 310, Loss: 0.1949
Batch 320, Loss: 0.2096
Batch 330, Loss: 0.1998
Batch 340, Loss: 0.2024
Batch 350, Loss: 0.2194
Batch 360, Loss: 0.1917
Batch 370, Loss: 0.2003
Batch 380, Loss: 0.1941
Batch 390, Loss: 0.1921
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.078248262405396 seconds
Epoch 170 accuracy: 95.29%
Batch 10, Loss: 0.1963
Batch 20, Loss: 0.1791
Batch 30, Loss: 0.1886
Batch 40, Loss: 0.1693
Batch 50, Loss: 0.1889
Batch 60, Loss: 0.1789
Batch 70, Loss: 0.2091
Batch 80, Loss: 0.1984
Batch 90, Loss: 0.1830
Batch 100, Loss: 0.2077
Batch 110, Loss: 0.2023
Batch 120, Loss: 0.2201
Batch 130, Loss: 0.1898
Batch 140, Loss: 0.1984
Batch 150, Loss: 0.1758
Batch 160, Loss: 0.1996
Batch 170, Loss: 0.2263
Batch 180, Loss: 0.1701
Batch 190, Loss: 0.1718
Batch 200, Loss: 0.1715
Batch 210, Loss: 0.1592
Batch 220, Loss: 0.1719
Batch 230, Loss: 0.2144
Batch 240, Loss: 0.2016
Batch 250, Loss: 0.1847
Batch 260, Loss: 0.1932
Batch 270, Loss: 0.1851
Batch 280, Loss: 0.1963
Batch 290, Loss: 0.1856
Batch 300, Loss: 0.1895
Batch 310, Loss: 0.1836
Batch 320, Loss: 0.2012
Batch 330, Loss: 0.1902
Batch 340, Loss: 0.2133
Batch 350, Loss: 0.1848
Batch 360, Loss: 0.2052
Batch 370, Loss: 0.1684
Batch 380, Loss: 0.2078
Batch 390, Loss: 0.1920
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.03340435028076 seconds
Epoch 171 accuracy: 95.25%
Batch 10, Loss: 0.2007
Batch 20, Loss: 0.1907
Batch 30, Loss: 0.1804
Batch 40, Loss: 0.1765
Batch 50, Loss: 0.1954
Batch 60, Loss: 0.1769
Batch 70, Loss: 0.1904
Batch 80, Loss: 0.1777
Batch 90, Loss: 0.2072
Batch 100, Loss: 0.2068
Batch 110, Loss: 0.1918
Batch 120, Loss: 0.1985
Batch 130, Loss: 0.2055
Batch 140, Loss: 0.2024
Batch 150, Loss: 0.1716
Batch 160, Loss: 0.2159
Batch 170, Loss: 0.1986
Batch 180, Loss: 0.2247
Batch 190, Loss: 0.2024
Batch 200, Loss: 0.1858
Batch 210, Loss: 0.2005
Batch 220, Loss: 0.1852
Batch 230, Loss: 0.1892
Batch 240, Loss: 0.1727
Batch 250, Loss: 0.1862
Batch 260, Loss: 0.1904
Batch 270, Loss: 0.1992
Batch 280, Loss: 0.1972
Batch 290, Loss: 0.1796
Batch 300, Loss: 0.1916
Batch 310, Loss: 0.1756
Batch 320, Loss: 0.1731
Batch 330, Loss: 0.1799
Batch 340, Loss: 0.1812
Batch 350, Loss: 0.1669
Batch 360, Loss: 0.2106
Batch 370, Loss: 0.1884
Batch 380, Loss: 0.1722
Batch 390, Loss: 0.1931
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.057371854782104 seconds
Epoch 172 accuracy: 95.4%
Batch 10, Loss: 0.1855
Batch 20, Loss: 0.1750
Batch 30, Loss: 0.1860
Batch 40, Loss: 0.1967
Batch 50, Loss: 0.1919
Batch 60, Loss: 0.2063
Batch 70, Loss: 0.1800
Batch 80, Loss: 0.1991
Batch 90, Loss: 0.1836
Batch 100, Loss: 0.1813
Batch 110, Loss: 0.1791
Batch 120, Loss: 0.1815
Batch 130, Loss: 0.1790
Batch 140, Loss: 0.1838
Batch 150, Loss: 0.2125
Batch 160, Loss: 0.1698
Batch 170, Loss: 0.1933
Batch 180, Loss: 0.1816
Batch 190, Loss: 0.1561
Batch 200, Loss: 0.1844
Batch 210, Loss: 0.2004
Batch 220, Loss: 0.1876
Batch 230, Loss: 0.1635
Batch 240, Loss: 0.2106
Batch 250, Loss: 0.1599
Batch 260, Loss: 0.1628
Batch 270, Loss: 0.1742
Batch 280, Loss: 0.2078
Batch 290, Loss: 0.2146
Batch 300, Loss: 0.1856
Batch 310, Loss: 0.1804
Batch 320, Loss: 0.1869
Batch 330, Loss: 0.1735
Batch 340, Loss: 0.1828
Batch 350, Loss: 0.1744
Batch 360, Loss: 0.1911
Batch 370, Loss: 0.1733
Batch 380, Loss: 0.1826
Batch 390, Loss: 0.1825
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 24.987375736236572 seconds
Epoch 173 accuracy: 95.52%
Batch 10, Loss: 0.1956
Batch 20, Loss: 0.1861
Batch 30, Loss: 0.1866
Batch 40, Loss: 0.1750
Batch 50, Loss: 0.1897
Batch 60, Loss: 0.1755
Batch 70, Loss: 0.1768
Batch 80, Loss: 0.1708
Batch 90, Loss: 0.1797
Batch 100, Loss: 0.1896
Batch 110, Loss: 0.1622
Batch 120, Loss: 0.1907
Batch 130, Loss: 0.1817
Batch 140, Loss: 0.1570
Batch 150, Loss: 0.1867
Batch 160, Loss: 0.1743
Batch 170, Loss: 0.1806
Batch 180, Loss: 0.1804
Batch 190, Loss: 0.1906
Batch 200, Loss: 0.1982
Batch 210, Loss: 0.1771
Batch 220, Loss: 0.1636
Batch 230, Loss: 0.1725
Batch 240, Loss: 0.1804
Batch 250, Loss: 0.1769
Batch 260, Loss: 0.1747
Batch 270, Loss: 0.1748
Batch 280, Loss: 0.1754
Batch 290, Loss: 0.1737
Batch 300, Loss: 0.2050
Batch 310, Loss: 0.1824
Batch 320, Loss: 0.1914
Batch 330, Loss: 0.1967
Batch 340, Loss: 0.1898
Batch 350, Loss: 0.1771
Batch 360, Loss: 0.1815
Batch 370, Loss: 0.1607
Batch 380, Loss: 0.2015
Batch 390, Loss: 0.2016
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.063605070114136 seconds
Epoch 174 accuracy: 95.46%
Batch 10, Loss: 0.1760
Batch 20, Loss: 0.1778
Batch 30, Loss: 0.1711
Batch 40, Loss: 0.1486
Batch 50, Loss: 0.1860
Batch 60, Loss: 0.1993
Batch 70, Loss: 0.1564
Batch 80, Loss: 0.1493
Batch 90, Loss: 0.1701
Batch 100, Loss: 0.1835
Batch 110, Loss: 0.1520
Batch 120, Loss: 0.1798
Batch 130, Loss: 0.1619
Batch 140, Loss: 0.1750
Batch 150, Loss: 0.1753
Batch 160, Loss: 0.1690
Batch 170, Loss: 0.1992
Batch 180, Loss: 0.1837
Batch 190, Loss: 0.1908
Batch 200, Loss: 0.1486
Batch 210, Loss: 0.1569
Batch 220, Loss: 0.1705
Batch 230, Loss: 0.1717
Batch 240, Loss: 0.1865
Batch 250, Loss: 0.1873
Batch 260, Loss: 0.1635
Batch 270, Loss: 0.1740
Batch 280, Loss: 0.2076
Batch 290, Loss: 0.1954
Batch 300, Loss: 0.1652
Batch 310, Loss: 0.1874
Batch 320, Loss: 0.1750
Batch 330, Loss: 0.1906
Batch 340, Loss: 0.2048
Batch 350, Loss: 0.1603
Batch 360, Loss: 0.1639
Batch 370, Loss: 0.1720
Batch 380, Loss: 0.1992
Batch 390, Loss: 0.1708
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.03239870071411 seconds
Epoch 175 accuracy: 95.77%
Batch 10, Loss: 0.1801
Batch 20, Loss: 0.1751
Batch 30, Loss: 0.1630
Batch 40, Loss: 0.1986
Batch 50, Loss: 0.1726
Batch 60, Loss: 0.1656
Batch 70, Loss: 0.1565
Batch 80, Loss: 0.1881
Batch 90, Loss: 0.1701
Batch 100, Loss: 0.1589
Batch 110, Loss: 0.2019
Batch 120, Loss: 0.1613
Batch 130, Loss: 0.1761
Batch 140, Loss: 0.1571
Batch 150, Loss: 0.1795
Batch 160, Loss: 0.1719
Batch 170, Loss: 0.1538
Batch 180, Loss: 0.1701
Batch 190, Loss: 0.1765
Batch 200, Loss: 0.1663
Batch 210, Loss: 0.1804
Batch 220, Loss: 0.1690
Batch 230, Loss: 0.1824
Batch 240, Loss: 0.1979
Batch 250, Loss: 0.1705
Batch 260, Loss: 0.1570
Batch 270, Loss: 0.1714
Batch 280, Loss: 0.1750
Batch 290, Loss: 0.1683
Batch 300, Loss: 0.1418
Batch 310, Loss: 0.1499
Batch 320, Loss: 0.1948
Batch 330, Loss: 0.1818
Batch 340, Loss: 0.1600
Batch 350, Loss: 0.1822
Batch 360, Loss: 0.1664
Batch 370, Loss: 0.1665
Batch 380, Loss: 0.1940
Batch 390, Loss: 0.1820
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.01826286315918 seconds
Epoch 176 accuracy: 95.74%
Batch 10, Loss: 0.1671
Batch 20, Loss: 0.1946
Batch 30, Loss: 0.1593
Batch 40, Loss: 0.1828
Batch 50, Loss: 0.1481
Batch 60, Loss: 0.1692
Batch 70, Loss: 0.1622
Batch 80, Loss: 0.1739
Batch 90, Loss: 0.1678
Batch 100, Loss: 0.1581
Batch 110, Loss: 0.1503
Batch 120, Loss: 0.1542
Batch 130, Loss: 0.1906
Batch 140, Loss: 0.1817
Batch 150, Loss: 0.1824
Batch 160, Loss: 0.1672
Batch 170, Loss: 0.1685
Batch 180, Loss: 0.1593
Batch 190, Loss: 0.1821
Batch 200, Loss: 0.1702
Batch 210, Loss: 0.1859
Batch 220, Loss: 0.1563
Batch 230, Loss: 0.1793
Batch 240, Loss: 0.1739
Batch 250, Loss: 0.1722
Batch 260, Loss: 0.1727
Batch 270, Loss: 0.1777
Batch 280, Loss: 0.1524
Batch 290, Loss: 0.1692
Batch 300, Loss: 0.1730
Batch 310, Loss: 0.1683
Batch 320, Loss: 0.1667
Batch 330, Loss: 0.1894
Batch 340, Loss: 0.1659
Batch 350, Loss: 0.1814
Batch 360, Loss: 0.1444
Batch 370, Loss: 0.1291
Batch 380, Loss: 0.1834
Batch 390, Loss: 0.1803
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.040874004364014 seconds
Epoch 177 accuracy: 95.98%
Batch 10, Loss: 0.1604
Batch 20, Loss: 0.1545
Batch 30, Loss: 0.1829
Batch 40, Loss: 0.1536
Batch 50, Loss: 0.1506
Batch 60, Loss: 0.1717
Batch 70, Loss: 0.1921
Batch 80, Loss: 0.1551
Batch 90, Loss: 0.1731
Batch 100, Loss: 0.1676
Batch 110, Loss: 0.1672
Batch 120, Loss: 0.1544
Batch 130, Loss: 0.1423
Batch 140, Loss: 0.1669
Batch 150, Loss: 0.1788
Batch 160, Loss: 0.1895
Batch 170, Loss: 0.1432
Batch 180, Loss: 0.1875
Batch 190, Loss: 0.1948
Batch 200, Loss: 0.1923
Batch 210, Loss: 0.1656
Batch 220, Loss: 0.1950
Batch 230, Loss: 0.1693
Batch 240, Loss: 0.1655
Batch 250, Loss: 0.1824
Batch 260, Loss: 0.1519
Batch 270, Loss: 0.1665
Batch 280, Loss: 0.1636
Batch 290, Loss: 0.1750
Batch 300, Loss: 0.1645
Batch 310, Loss: 0.1460
Batch 320, Loss: 0.1620
Batch 330, Loss: 0.1497
Batch 340, Loss: 0.1712
Batch 350, Loss: 0.1514
Batch 360, Loss: 0.1353
Batch 370, Loss: 0.1554
Batch 380, Loss: 0.1470
Batch 390, Loss: 0.1886
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.036566495895386 seconds
Epoch 178 accuracy: 95.88%
Batch 10, Loss: 0.1557
Batch 20, Loss: 0.1743
Batch 30, Loss: 0.1546
Batch 40, Loss: 0.1605
Batch 50, Loss: 0.1449
Batch 60, Loss: 0.1629
Batch 70, Loss: 0.1777
Batch 80, Loss: 0.1617
Batch 90, Loss: 0.1601
Batch 100, Loss: 0.1914
Batch 110, Loss: 0.1585
Batch 120, Loss: 0.1709
Batch 130, Loss: 0.1741
Batch 140, Loss: 0.1603
Batch 150, Loss: 0.1554
Batch 160, Loss: 0.1594
Batch 170, Loss: 0.1533
Batch 180, Loss: 0.1554
Batch 190, Loss: 0.1593
Batch 200, Loss: 0.1501
Batch 210, Loss: 0.1755
Batch 220, Loss: 0.1616
Batch 230, Loss: 0.1631
Batch 240, Loss: 0.1584
Batch 250, Loss: 0.1493
Batch 260, Loss: 0.1509
Batch 270, Loss: 0.1972
Batch 280, Loss: 0.1715
Batch 290, Loss: 0.1473
Batch 300, Loss: 0.1568
Batch 310, Loss: 0.1829
Batch 320, Loss: 0.1751
Batch 330, Loss: 0.1359
Batch 340, Loss: 0.1603
Batch 350, Loss: 0.1630
Batch 360, Loss: 0.1499
Batch 370, Loss: 0.1695
Batch 380, Loss: 0.1465
Batch 390, Loss: 0.1664
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.012457847595215 seconds
Epoch 179 accuracy: 95.75%
Batch 10, Loss: 0.1526
Batch 20, Loss: 0.1659
Batch 30, Loss: 0.1305
Batch 40, Loss: 0.1401
Batch 50, Loss: 0.1577
Batch 60, Loss: 0.1552
Batch 70, Loss: 0.1462
Batch 80, Loss: 0.1723
Batch 90, Loss: 0.1473
Batch 100, Loss: 0.1366
Batch 110, Loss: 0.1482
Batch 120, Loss: 0.1280
Batch 130, Loss: 0.1696
Batch 140, Loss: 0.1740
Batch 150, Loss: 0.1747
Batch 160, Loss: 0.1754
Batch 170, Loss: 0.1593
Batch 180, Loss: 0.1755
Batch 190, Loss: 0.1338
Batch 200, Loss: 0.1477
Batch 210, Loss: 0.1477
Batch 220, Loss: 0.1614
Batch 230, Loss: 0.1575
Batch 240, Loss: 0.1833
Batch 250, Loss: 0.1511
Batch 260, Loss: 0.1578
Batch 270, Loss: 0.1698
Batch 280, Loss: 0.1588
Batch 290, Loss: 0.1448
Batch 300, Loss: 0.1713
Batch 310, Loss: 0.1696
Batch 320, Loss: 0.1642
Batch 330, Loss: 0.1705
Batch 340, Loss: 0.1620
Batch 350, Loss: 0.1517
Batch 360, Loss: 0.1566
Batch 370, Loss: 0.1776
Batch 380, Loss: 0.1482
Batch 390, Loss: 0.1605
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.047234773635864 seconds
Epoch 180 accuracy: 95.89%
Batch 10, Loss: 0.1477
Batch 20, Loss: 0.1514
Batch 30, Loss: 0.1573
Batch 40, Loss: 0.1693
Batch 50, Loss: 0.1463
Batch 60, Loss: 0.1672
Batch 70, Loss: 0.1402
Batch 80, Loss: 0.1713
Batch 90, Loss: 0.1546
Batch 100, Loss: 0.1701
Batch 110, Loss: 0.1560
Batch 120, Loss: 0.1612
Batch 130, Loss: 0.1441
Batch 140, Loss: 0.1737
Batch 150, Loss: 0.1722
Batch 160, Loss: 0.1655
Batch 170, Loss: 0.1372
Batch 180, Loss: 0.1449
Batch 190, Loss: 0.1479
Batch 200, Loss: 0.1552
Batch 210, Loss: 0.1524
Batch 220, Loss: 0.1610
Batch 230, Loss: 0.1492
Batch 240, Loss: 0.1592
Batch 250, Loss: 0.1425
Batch 260, Loss: 0.1586
Batch 270, Loss: 0.1640
Batch 280, Loss: 0.1628
Batch 290, Loss: 0.1457
Batch 300, Loss: 0.1495
Batch 310, Loss: 0.1687
Batch 320, Loss: 0.1917
Batch 330, Loss: 0.1375
Batch 340, Loss: 0.1627
Batch 350, Loss: 0.1285
Batch 360, Loss: 0.1483
Batch 370, Loss: 0.1498
Batch 380, Loss: 0.1623
Batch 390, Loss: 0.1487
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.03168511390686 seconds
Epoch 181 accuracy: 95.99%
Batch 10, Loss: 0.1487
Batch 20, Loss: 0.1513
Batch 30, Loss: 0.1702
Batch 40, Loss: 0.1658
Batch 50, Loss: 0.1413
Batch 60, Loss: 0.1631
Batch 70, Loss: 0.1699
Batch 80, Loss: 0.1398
Batch 90, Loss: 0.1730
Batch 100, Loss: 0.1448
Batch 110, Loss: 0.1715
Batch 120, Loss: 0.1420
Batch 130, Loss: 0.1577
Batch 140, Loss: 0.1555
Batch 150, Loss: 0.1502
Batch 160, Loss: 0.1732
Batch 170, Loss: 0.1778
Batch 180, Loss: 0.1434
Batch 190, Loss: 0.1427
Batch 200, Loss: 0.1546
Batch 210, Loss: 0.1354
Batch 220, Loss: 0.1299
Batch 230, Loss: 0.1502
Batch 240, Loss: 0.1367
Batch 250, Loss: 0.1470
Batch 260, Loss: 0.1431
Batch 270, Loss: 0.1519
Batch 280, Loss: 0.1285
Batch 290, Loss: 0.1475
Batch 300, Loss: 0.1619
Batch 310, Loss: 0.1582
Batch 320, Loss: 0.1529
Batch 330, Loss: 0.1677
Batch 340, Loss: 0.1712
Batch 350, Loss: 0.1565
Batch 360, Loss: 0.1582
Batch 370, Loss: 0.1610
Batch 380, Loss: 0.1605
Batch 390, Loss: 0.1637
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.025733709335327 seconds
Epoch 182 accuracy: 96.21%
Batch 10, Loss: 0.1456
Batch 20, Loss: 0.1599
Batch 30, Loss: 0.1444
Batch 40, Loss: 0.1459
Batch 50, Loss: 0.1515
Batch 60, Loss: 0.1414
Batch 70, Loss: 0.1487
Batch 80, Loss: 0.1480
Batch 90, Loss: 0.1239
Batch 100, Loss: 0.1538
Batch 110, Loss: 0.1325
Batch 120, Loss: 0.1623
Batch 130, Loss: 0.1595
Batch 140, Loss: 0.1556
Batch 150, Loss: 0.1407
Batch 160, Loss: 0.1361
Batch 170, Loss: 0.1575
Batch 180, Loss: 0.1494
Batch 190, Loss: 0.1581
Batch 200, Loss: 0.1803
Batch 210, Loss: 0.1450
Batch 220, Loss: 0.1357
Batch 230, Loss: 0.1387
Batch 240, Loss: 0.1451
Batch 250, Loss: 0.1389
Batch 260, Loss: 0.1506
Batch 270, Loss: 0.1530
Batch 280, Loss: 0.1712
Batch 290, Loss: 0.1491
Batch 300, Loss: 0.1440
Batch 310, Loss: 0.1499
Batch 320, Loss: 0.1618
Batch 330, Loss: 0.1369
Batch 340, Loss: 0.1391
Batch 350, Loss: 0.1543
Batch 360, Loss: 0.1352
Batch 370, Loss: 0.1363
Batch 380, Loss: 0.1499
Batch 390, Loss: 0.1433
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.037193775177002 seconds
Epoch 183 accuracy: 96.23%
Batch 10, Loss: 0.1672
Batch 20, Loss: 0.1446
Batch 30, Loss: 0.1353
Batch 40, Loss: 0.1487
Batch 50, Loss: 0.1360
Batch 60, Loss: 0.1480
Batch 70, Loss: 0.1342
Batch 80, Loss: 0.1412
Batch 90, Loss: 0.1654
Batch 100, Loss: 0.1466
Batch 110, Loss: 0.1562
Batch 120, Loss: 0.1506
Batch 130, Loss: 0.1427
Batch 140, Loss: 0.1670
Batch 150, Loss: 0.1129
Batch 160, Loss: 0.1601
Batch 170, Loss: 0.1452
Batch 180, Loss: 0.1407
Batch 190, Loss: 0.1437
Batch 200, Loss: 0.1475
Batch 210, Loss: 0.1376
Batch 220, Loss: 0.1595
Batch 230, Loss: 0.1469
Batch 240, Loss: 0.1470
Batch 250, Loss: 0.1343
Batch 260, Loss: 0.1571
Batch 270, Loss: 0.1406
Batch 280, Loss: 0.1377
Batch 290, Loss: 0.1579
Batch 300, Loss: 0.1267
Batch 310, Loss: 0.1540
Batch 320, Loss: 0.1294
Batch 330, Loss: 0.1454
Batch 340, Loss: 0.1380
Batch 350, Loss: 0.1485
Batch 360, Loss: 0.1700
Batch 370, Loss: 0.1372
Batch 380, Loss: 0.1384
Batch 390, Loss: 0.1580
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.017763137817383 seconds
Epoch 184 accuracy: 96.16%
Batch 10, Loss: 0.1411
Batch 20, Loss: 0.1613
Batch 30, Loss: 0.1213
Batch 40, Loss: 0.1354
Batch 50, Loss: 0.1284
Batch 60, Loss: 0.1617
Batch 70, Loss: 0.1384
Batch 80, Loss: 0.1367
Batch 90, Loss: 0.1474
Batch 100, Loss: 0.1438
Batch 110, Loss: 0.1414
Batch 120, Loss: 0.1357
Batch 130, Loss: 0.1513
Batch 140, Loss: 0.1412
Batch 150, Loss: 0.1444
Batch 160, Loss: 0.1308
Batch 170, Loss: 0.1435
Batch 180, Loss: 0.1241
Batch 190, Loss: 0.1027
Batch 200, Loss: 0.1408
Batch 210, Loss: 0.1438
Batch 220, Loss: 0.1361
Batch 230, Loss: 0.1622
Batch 240, Loss: 0.1632
Batch 250, Loss: 0.1336
Batch 260, Loss: 0.1502
Batch 270, Loss: 0.1351
Batch 280, Loss: 0.1598
Batch 290, Loss: 0.1618
Batch 300, Loss: 0.1405
Batch 310, Loss: 0.1555
Batch 320, Loss: 0.1306
Batch 330, Loss: 0.1369
Batch 340, Loss: 0.1329
Batch 350, Loss: 0.1137
Batch 360, Loss: 0.1481
Batch 370, Loss: 0.1582
Batch 380, Loss: 0.1507
Batch 390, Loss: 0.1396
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.060983657836914 seconds
Epoch 185 accuracy: 96.03%
Batch 10, Loss: 0.1297
Batch 20, Loss: 0.1605
Batch 30, Loss: 0.1503
Batch 40, Loss: 0.1565
Batch 50, Loss: 0.1451
Batch 60, Loss: 0.1492
Batch 70, Loss: 0.1516
Batch 80, Loss: 0.1362
Batch 90, Loss: 0.1295
Batch 100, Loss: 0.1405
Batch 110, Loss: 0.1605
Batch 120, Loss: 0.1479
Batch 130, Loss: 0.1615
Batch 140, Loss: 0.1506
Batch 150, Loss: 0.1404
Batch 160, Loss: 0.1319
Batch 170, Loss: 0.1412
Batch 180, Loss: 0.1529
Batch 190, Loss: 0.1279
Batch 200, Loss: 0.1191
Batch 210, Loss: 0.1432
Batch 220, Loss: 0.1469
Batch 230, Loss: 0.1346
Batch 240, Loss: 0.1503
Batch 250, Loss: 0.1365
Batch 260, Loss: 0.1333
Batch 270, Loss: 0.1503
Batch 280, Loss: 0.1501
Batch 290, Loss: 0.1264
Batch 300, Loss: 0.1384
Batch 310, Loss: 0.1502
Batch 320, Loss: 0.1380
Batch 330, Loss: 0.1491
Batch 340, Loss: 0.1317
Batch 350, Loss: 0.1319
Batch 360, Loss: 0.1569
Batch 370, Loss: 0.1537
Batch 380, Loss: 0.1578
Batch 390, Loss: 0.1512
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.071325540542603 seconds
Epoch 186 accuracy: 96.15%
Batch 10, Loss: 0.1504
Batch 20, Loss: 0.1307
Batch 30, Loss: 0.1291
Batch 40, Loss: 0.1327
Batch 50, Loss: 0.1482
Batch 60, Loss: 0.1248
Batch 70, Loss: 0.1310
Batch 80, Loss: 0.1449
Batch 90, Loss: 0.1455
Batch 100, Loss: 0.1523
Batch 110, Loss: 0.1274
Batch 120, Loss: 0.1428
Batch 130, Loss: 0.1544
Batch 140, Loss: 0.1363
Batch 150, Loss: 0.1358
Batch 160, Loss: 0.1261
Batch 170, Loss: 0.1463
Batch 180, Loss: 0.1489
Batch 190, Loss: 0.1413
Batch 200, Loss: 0.1290
Batch 210, Loss: 0.1523
Batch 220, Loss: 0.1374
Batch 230, Loss: 0.1402
Batch 240, Loss: 0.1240
Batch 250, Loss: 0.1406
Batch 260, Loss: 0.1535
Batch 270, Loss: 0.1258
Batch 280, Loss: 0.1402
Batch 290, Loss: 0.1445
Batch 300, Loss: 0.1499
Batch 310, Loss: 0.1616
Batch 320, Loss: 0.1414
Batch 330, Loss: 0.1300
Batch 340, Loss: 0.1452
Batch 350, Loss: 0.1312
Batch 360, Loss: 0.1243
Batch 370, Loss: 0.1585
Batch 380, Loss: 0.1542
Batch 390, Loss: 0.1204
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.044901609420776 seconds
Epoch 187 accuracy: 96.25%
Batch 10, Loss: 0.1218
Batch 20, Loss: 0.1431
Batch 30, Loss: 0.1427
Batch 40, Loss: 0.1291
Batch 50, Loss: 0.1268
Batch 60, Loss: 0.1529
Batch 70, Loss: 0.1177
Batch 80, Loss: 0.1371
Batch 90, Loss: 0.1332
Batch 100, Loss: 0.1475
Batch 110, Loss: 0.1113
Batch 120, Loss: 0.1371
Batch 130, Loss: 0.1244
Batch 140, Loss: 0.1251
Batch 150, Loss: 0.1131
Batch 160, Loss: 0.1216
Batch 170, Loss: 0.1400
Batch 180, Loss: 0.1548
Batch 190, Loss: 0.1362
Batch 200, Loss: 0.1273
Batch 210, Loss: 0.1277
Batch 220, Loss: 0.1242
Batch 230, Loss: 0.1291
Batch 240, Loss: 0.1489
Batch 250, Loss: 0.1665
Batch 260, Loss: 0.1373
Batch 270, Loss: 0.1168
Batch 280, Loss: 0.1317
Batch 290, Loss: 0.1431
Batch 300, Loss: 0.1433
Batch 310, Loss: 0.1458
Batch 320, Loss: 0.1226
Batch 330, Loss: 0.1420
Batch 340, Loss: 0.1480
Batch 350, Loss: 0.1221
Batch 360, Loss: 0.1461
Batch 370, Loss: 0.1319
Batch 380, Loss: 0.1322
Batch 390, Loss: 0.1296
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.071834325790405 seconds
Epoch 188 accuracy: 96.2%
Batch 10, Loss: 0.1550
Batch 20, Loss: 0.1379
Batch 30, Loss: 0.1242
Batch 40, Loss: 0.1385
Batch 50, Loss: 0.1278
Batch 60, Loss: 0.1201
Batch 70, Loss: 0.1239
Batch 80, Loss: 0.1395
Batch 90, Loss: 0.1212
Batch 100, Loss: 0.1365
Batch 110, Loss: 0.1256
Batch 120, Loss: 0.1398
Batch 130, Loss: 0.1327
Batch 140, Loss: 0.1449
Batch 150, Loss: 0.1372
Batch 160, Loss: 0.1518
Batch 170, Loss: 0.1172
Batch 180, Loss: 0.1468
Batch 190, Loss: 0.1219
Batch 200, Loss: 0.1515
Batch 210, Loss: 0.1475
Batch 220, Loss: 0.1369
Batch 230, Loss: 0.1489
Batch 240, Loss: 0.1393
Batch 250, Loss: 0.1263
Batch 260, Loss: 0.1365
Batch 270, Loss: 0.1483
Batch 280, Loss: 0.1473
Batch 290, Loss: 0.1184
Batch 300, Loss: 0.1259
Batch 310, Loss: 0.1176
Batch 320, Loss: 0.1412
Batch 330, Loss: 0.1332
Batch 340, Loss: 0.1208
Batch 350, Loss: 0.1615
Batch 360, Loss: 0.1358
Batch 370, Loss: 0.1687
Batch 380, Loss: 0.1476
Batch 390, Loss: 0.1409
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.10735034942627 seconds
Epoch 189 accuracy: 96.16%
Batch 10, Loss: 0.1617
Batch 20, Loss: 0.1207
Batch 30, Loss: 0.1275
Batch 40, Loss: 0.1256
Batch 50, Loss: 0.1396
Batch 60, Loss: 0.1200
Batch 70, Loss: 0.1143
Batch 80, Loss: 0.1214
Batch 90, Loss: 0.1252
Batch 100, Loss: 0.1375
Batch 110, Loss: 0.1355
Batch 120, Loss: 0.1328
Batch 130, Loss: 0.1669
Batch 140, Loss: 0.1390
Batch 150, Loss: 0.1556
Batch 160, Loss: 0.1432
Batch 170, Loss: 0.1329
Batch 180, Loss: 0.1403
Batch 190, Loss: 0.1290
Batch 200, Loss: 0.1639
Batch 210, Loss: 0.1278
Batch 220, Loss: 0.1327
Batch 230, Loss: 0.1563
Batch 240, Loss: 0.1168
Batch 250, Loss: 0.1253
Batch 260, Loss: 0.1447
Batch 270, Loss: 0.1208
Batch 280, Loss: 0.1489
Batch 290, Loss: 0.1160
Batch 300, Loss: 0.1569
Batch 310, Loss: 0.1202
Batch 320, Loss: 0.1335
Batch 330, Loss: 0.1263
Batch 340, Loss: 0.1381
Batch 350, Loss: 0.1293
Batch 360, Loss: 0.1498
Batch 370, Loss: 0.1125
Batch 380, Loss: 0.1264
Batch 390, Loss: 0.1217
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.08696436882019 seconds
Epoch 190 accuracy: 96.4%
Batch 10, Loss: 0.1127
Batch 20, Loss: 0.1454
Batch 30, Loss: 0.1278
Batch 40, Loss: 0.1314
Batch 50, Loss: 0.1621
Batch 60, Loss: 0.1264
Batch 70, Loss: 0.1420
Batch 80, Loss: 0.1311
Batch 90, Loss: 0.1240
Batch 100, Loss: 0.1393
Batch 110, Loss: 0.1329
Batch 120, Loss: 0.1419
Batch 130, Loss: 0.1318
Batch 140, Loss: 0.1548
Batch 150, Loss: 0.1113
Batch 160, Loss: 0.1391
Batch 170, Loss: 0.1354
Batch 180, Loss: 0.1192
Batch 190, Loss: 0.1320
Batch 200, Loss: 0.1474
Batch 210, Loss: 0.1306
Batch 220, Loss: 0.1532
Batch 230, Loss: 0.1342
Batch 240, Loss: 0.1431
Batch 250, Loss: 0.1283
Batch 260, Loss: 0.1332
Batch 270, Loss: 0.1352
Batch 280, Loss: 0.1245
Batch 290, Loss: 0.1311
Batch 300, Loss: 0.1170
Batch 310, Loss: 0.1352
Batch 320, Loss: 0.1075
Batch 330, Loss: 0.1250
Batch 340, Loss: 0.1394
Batch 350, Loss: 0.1198
Batch 360, Loss: 0.1296
Batch 370, Loss: 0.1044
Batch 380, Loss: 0.1180
Batch 390, Loss: 0.1290
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.075507164001465 seconds
Epoch 191 accuracy: 96.29%
Batch 10, Loss: 0.1339
Batch 20, Loss: 0.1430
Batch 30, Loss: 0.1471
Batch 40, Loss: 0.1203
Batch 50, Loss: 0.1356
Batch 60, Loss: 0.1232
Batch 70, Loss: 0.1282
Batch 80, Loss: 0.1481
Batch 90, Loss: 0.1143
Batch 100, Loss: 0.1433
Batch 110, Loss: 0.1423
Batch 120, Loss: 0.1274
Batch 130, Loss: 0.1477
Batch 140, Loss: 0.1241
Batch 150, Loss: 0.1293
Batch 160, Loss: 0.1330
Batch 170, Loss: 0.1281
Batch 180, Loss: 0.1283
Batch 190, Loss: 0.1348
Batch 200, Loss: 0.1279
Batch 210, Loss: 0.1310
Batch 220, Loss: 0.1230
Batch 230, Loss: 0.1240
Batch 240, Loss: 0.1282
Batch 250, Loss: 0.1398
Batch 260, Loss: 0.1455
Batch 270, Loss: 0.1458
Batch 280, Loss: 0.1128
Batch 290, Loss: 0.1291
Batch 300, Loss: 0.1384
Batch 310, Loss: 0.1117
Batch 320, Loss: 0.1474
Batch 330, Loss: 0.1334
Batch 340, Loss: 0.1178
Batch 350, Loss: 0.1089
Batch 360, Loss: 0.1260
Batch 370, Loss: 0.1226
Batch 380, Loss: 0.1353
Batch 390, Loss: 0.1387
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.033804893493652 seconds
Epoch 192 accuracy: 96.28%
Batch 10, Loss: 0.1593
Batch 20, Loss: 0.1359
Batch 30, Loss: 0.1116
Batch 40, Loss: 0.1014
Batch 50, Loss: 0.1484
Batch 60, Loss: 0.1121
Batch 70, Loss: 0.1235
Batch 80, Loss: 0.1016
Batch 90, Loss: 0.1386
Batch 100, Loss: 0.1297
Batch 110, Loss: 0.1257
Batch 120, Loss: 0.1066
Batch 130, Loss: 0.1360
Batch 140, Loss: 0.1242
Batch 150, Loss: 0.1386
Batch 160, Loss: 0.1043
Batch 170, Loss: 0.1316
Batch 180, Loss: 0.1267
Batch 190, Loss: 0.1406
Batch 200, Loss: 0.1113
Batch 210, Loss: 0.1121
Batch 220, Loss: 0.1229
Batch 230, Loss: 0.1355
Batch 240, Loss: 0.1523
Batch 250, Loss: 0.1397
Batch 260, Loss: 0.1221
Batch 270, Loss: 0.1222
Batch 280, Loss: 0.1104
Batch 290, Loss: 0.1229
Batch 300, Loss: 0.1326
Batch 310, Loss: 0.1376
Batch 320, Loss: 0.1345
Batch 330, Loss: 0.1247
Batch 340, Loss: 0.1178
Batch 350, Loss: 0.1340
Batch 360, Loss: 0.1058
Batch 370, Loss: 0.1165
Batch 380, Loss: 0.1234
Batch 390, Loss: 0.1358
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.065240383148193 seconds
Epoch 193 accuracy: 96.35%
Batch 10, Loss: 0.1329
Batch 20, Loss: 0.1196
Batch 30, Loss: 0.1340
Batch 40, Loss: 0.1327
Batch 50, Loss: 0.1259
Batch 60, Loss: 0.1536
Batch 70, Loss: 0.1189
Batch 80, Loss: 0.1288
Batch 90, Loss: 0.1082
Batch 100, Loss: 0.1486
Batch 110, Loss: 0.1316
Batch 120, Loss: 0.1226
Batch 130, Loss: 0.1348
Batch 140, Loss: 0.1155
Batch 150, Loss: 0.1315
Batch 160, Loss: 0.1208
Batch 170, Loss: 0.1316
Batch 180, Loss: 0.1187
Batch 190, Loss: 0.1059
Batch 200, Loss: 0.1099
Batch 210, Loss: 0.1180
Batch 220, Loss: 0.1410
Batch 230, Loss: 0.1244
Batch 240, Loss: 0.1178
Batch 250, Loss: 0.1369
Batch 260, Loss: 0.1320
Batch 270, Loss: 0.1242
Batch 280, Loss: 0.1462
Batch 290, Loss: 0.1258
Batch 300, Loss: 0.1178
Batch 310, Loss: 0.1415
Batch 320, Loss: 0.1161
Batch 330, Loss: 0.1424
Batch 340, Loss: 0.1401
Batch 350, Loss: 0.1242
Batch 360, Loss: 0.1228
Batch 370, Loss: 0.1347
Batch 380, Loss: 0.1492
Batch 390, Loss: 0.1316
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.002973079681396 seconds
Epoch 194 accuracy: 96.43%
Batch 10, Loss: 0.1204
Batch 20, Loss: 0.1556
Batch 30, Loss: 0.1312
Batch 40, Loss: 0.1226
Batch 50, Loss: 0.1516
Batch 60, Loss: 0.1264
Batch 70, Loss: 0.1235
Batch 80, Loss: 0.1239
Batch 90, Loss: 0.1299
Batch 100, Loss: 0.1418
Batch 110, Loss: 0.1229
Batch 120, Loss: 0.1245
Batch 130, Loss: 0.1163
Batch 140, Loss: 0.1196
Batch 150, Loss: 0.1127
Batch 160, Loss: 0.1163
Batch 170, Loss: 0.1148
Batch 180, Loss: 0.1147
Batch 190, Loss: 0.1273
Batch 200, Loss: 0.1450
Batch 210, Loss: 0.1389
Batch 220, Loss: 0.1194
Batch 230, Loss: 0.1295
Batch 240, Loss: 0.1178
Batch 250, Loss: 0.1166
Batch 260, Loss: 0.1201
Batch 270, Loss: 0.1286
Batch 280, Loss: 0.1277
Batch 290, Loss: 0.1138
Batch 300, Loss: 0.1221
Batch 310, Loss: 0.1289
Batch 320, Loss: 0.1388
Batch 330, Loss: 0.1381
Batch 340, Loss: 0.1265
Batch 350, Loss: 0.1269
Batch 360, Loss: 0.1296
Batch 370, Loss: 0.1215
Batch 380, Loss: 0.1526
Batch 390, Loss: 0.1309
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.035741090774536 seconds
Epoch 195 accuracy: 96.37%
Batch 10, Loss: 0.1230
Batch 20, Loss: 0.1260
Batch 30, Loss: 0.1382
Batch 40, Loss: 0.1318
Batch 50, Loss: 0.1204
Batch 60, Loss: 0.1232
Batch 70, Loss: 0.1498
Batch 80, Loss: 0.1180
Batch 90, Loss: 0.1290
Batch 100, Loss: 0.1422
Batch 110, Loss: 0.1175
Batch 120, Loss: 0.1204
Batch 130, Loss: 0.1131
Batch 140, Loss: 0.1167
Batch 150, Loss: 0.1122
Batch 160, Loss: 0.1249
Batch 170, Loss: 0.1098
Batch 180, Loss: 0.1262
Batch 190, Loss: 0.1122
Batch 200, Loss: 0.1213
Batch 210, Loss: 0.1281
Batch 220, Loss: 0.1151
Batch 230, Loss: 0.1197
Batch 240, Loss: 0.1143
Batch 250, Loss: 0.1199
Batch 260, Loss: 0.1190
Batch 270, Loss: 0.1353
Batch 280, Loss: 0.1345
Batch 290, Loss: 0.1209
Batch 300, Loss: 0.1097
Batch 310, Loss: 0.1166
Batch 320, Loss: 0.1292
Batch 330, Loss: 0.1383
Batch 340, Loss: 0.1455
Batch 350, Loss: 0.1244
Batch 360, Loss: 0.1248
Batch 370, Loss: 0.1129
Batch 380, Loss: 0.1264
Batch 390, Loss: 0.1347
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.042601346969604 seconds
Epoch 196 accuracy: 96.38%
Batch 10, Loss: 0.1234
Batch 20, Loss: 0.1240
Batch 30, Loss: 0.1225
Batch 40, Loss: 0.1123
Batch 50, Loss: 0.1402
Batch 60, Loss: 0.1401
Batch 70, Loss: 0.1177
Batch 80, Loss: 0.1363
Batch 90, Loss: 0.1163
Batch 100, Loss: 0.1103
Batch 110, Loss: 0.1376
Batch 120, Loss: 0.1181
Batch 130, Loss: 0.1195
Batch 140, Loss: 0.1320
Batch 150, Loss: 0.1275
Batch 160, Loss: 0.1455
Batch 170, Loss: 0.1339
Batch 180, Loss: 0.1251
Batch 190, Loss: 0.1185
Batch 200, Loss: 0.1403
Batch 210, Loss: 0.1067
Batch 220, Loss: 0.1259
Batch 230, Loss: 0.1404
Batch 240, Loss: 0.1154
Batch 250, Loss: 0.1326
Batch 260, Loss: 0.1164
Batch 270, Loss: 0.1138
Batch 280, Loss: 0.1296
Batch 290, Loss: 0.1194
Batch 300, Loss: 0.1623
Batch 310, Loss: 0.1294
Batch 320, Loss: 0.1252
Batch 330, Loss: 0.1210
Batch 340, Loss: 0.1081
Batch 350, Loss: 0.1109
Batch 360, Loss: 0.1415
Batch 370, Loss: 0.1070
Batch 380, Loss: 0.1038
Batch 390, Loss: 0.1324
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.084160327911377 seconds
Epoch 197 accuracy: 96.43%
Batch 10, Loss: 0.1405
Batch 20, Loss: 0.1226
Batch 30, Loss: 0.1315
Batch 40, Loss: 0.1224
Batch 50, Loss: 0.1233
Batch 60, Loss: 0.1390
Batch 70, Loss: 0.1245
Batch 80, Loss: 0.1486
Batch 90, Loss: 0.1217
Batch 100, Loss: 0.1213
Batch 110, Loss: 0.1106
Batch 120, Loss: 0.1253
Batch 130, Loss: 0.1302
Batch 140, Loss: 0.1259
Batch 150, Loss: 0.1128
Batch 160, Loss: 0.1156
Batch 170, Loss: 0.1179
Batch 180, Loss: 0.1290
Batch 190, Loss: 0.1335
Batch 200, Loss: 0.1411
Batch 210, Loss: 0.1255
Batch 220, Loss: 0.1247
Batch 230, Loss: 0.1314
Batch 240, Loss: 0.1336
Batch 250, Loss: 0.1229
Batch 260, Loss: 0.1274
Batch 270, Loss: 0.1101
Batch 280, Loss: 0.1282
Batch 290, Loss: 0.1232
Batch 300, Loss: 0.1476
Batch 310, Loss: 0.1082
Batch 320, Loss: 0.1241
Batch 330, Loss: 0.1232
Batch 340, Loss: 0.1309
Batch 350, Loss: 0.1102
Batch 360, Loss: 0.1257
Batch 370, Loss: 0.1329
Batch 380, Loss: 0.1029
Batch 390, Loss: 0.1387
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.025072813034058 seconds
Epoch 198 accuracy: 96.39%
Batch 10, Loss: 0.1211
Batch 20, Loss: 0.1350
Batch 30, Loss: 0.1333
Batch 40, Loss: 0.1438
Batch 50, Loss: 0.1028
Batch 60, Loss: 0.1096
Batch 70, Loss: 0.1339
Batch 80, Loss: 0.1154
Batch 90, Loss: 0.1263
Batch 100, Loss: 0.1239
Batch 110, Loss: 0.1107
Batch 120, Loss: 0.1212
Batch 130, Loss: 0.1046
Batch 140, Loss: 0.1259
Batch 150, Loss: 0.1102
Batch 160, Loss: 0.1245
Batch 170, Loss: 0.1324
Batch 180, Loss: 0.1378
Batch 190, Loss: 0.1162
Batch 200, Loss: 0.1081
Batch 210, Loss: 0.1308
Batch 220, Loss: 0.1265
Batch 230, Loss: 0.1272
Batch 240, Loss: 0.1342
Batch 250, Loss: 0.1114
Batch 260, Loss: 0.1111
Batch 270, Loss: 0.1328
Batch 280, Loss: 0.1174
Batch 290, Loss: 0.1212
Batch 300, Loss: 0.1238
Batch 310, Loss: 0.1275
Batch 320, Loss: 0.1104
Batch 330, Loss: 0.1174
Batch 340, Loss: 0.1199
Batch 350, Loss: 0.1431
Batch 360, Loss: 0.1213
Batch 370, Loss: 0.1310
Batch 380, Loss: 0.1127
Batch 390, Loss: 0.1294
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.07116937637329 seconds
Epoch 199 accuracy: 96.4%
Batch 10, Loss: 0.1167
Batch 20, Loss: 0.1264
Batch 30, Loss: 0.1127
Batch 40, Loss: 0.1398
Batch 50, Loss: 0.1601
Batch 60, Loss: 0.1102
Batch 70, Loss: 0.1303
Batch 80, Loss: 0.1243
Batch 90, Loss: 0.1161
Batch 100, Loss: 0.1247
Batch 110, Loss: 0.1111
Batch 120, Loss: 0.1338
Batch 130, Loss: 0.1350
Batch 140, Loss: 0.1228
Batch 150, Loss: 0.1084
Batch 160, Loss: 0.1284
Batch 170, Loss: 0.1238
Batch 180, Loss: 0.1188
Batch 190, Loss: 0.1255
Batch 200, Loss: 0.1214
Batch 210, Loss: 0.1160
Batch 220, Loss: 0.1328
Batch 230, Loss: 0.1286
Batch 240, Loss: 0.1316
Batch 250, Loss: 0.1481
Batch 260, Loss: 0.1254
Batch 270, Loss: 0.1243
Batch 280, Loss: 0.1245
Batch 290, Loss: 0.1436
Batch 300, Loss: 0.1304
Batch 310, Loss: 0.1278
Batch 320, Loss: 0.1026
Batch 330, Loss: 0.1226
Batch 340, Loss: 0.1269
Batch 350, Loss: 0.1283
Batch 360, Loss: 0.1338
Batch 370, Loss: 0.1174
Batch 380, Loss: 0.1173
Batch 390, Loss: 0.1221
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.016421794891357 seconds
Epoch 200 accuracy: 96.43%
Total training time: 5013.427646636963 seconds
