The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:183: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GNOM
Using Gradient-Norm Only Minimization (GNOM)
/home/tkleinkn/GAMtest/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /home/coulombc/wheels_builder/tmp.2617/python-3.11/torch/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Batch 10, Loss: 346.9545
Batch 20, Loss: 798.3057
Batch 30, Loss: 505.7288
Batch 40, Loss: 240.2302
Batch 50, Loss: 98.6124
Batch 60, Loss: 74.5737
Batch 70, Loss: 46.1256
Batch 80, Loss: 31.4234
Batch 90, Loss: 25.2386
Batch 100, Loss: 23.4491
Batch 110, Loss: 22.7211
Batch 120, Loss: 20.6661
Batch 130, Loss: 18.5016
Batch 140, Loss: 20.2707
Batch 150, Loss: 18.5558
Batch 160, Loss: 16.8646
Batch 170, Loss: 17.4422
Batch 180, Loss: 17.2285
Batch 190, Loss: 17.5418
Batch 200, Loss: 16.6026
Batch 210, Loss: 15.8221
Batch 220, Loss: 15.0880
Batch 230, Loss: 15.4170
Batch 240, Loss: 15.5868
Batch 250, Loss: 15.7306
Batch 260, Loss: 15.3255
Batch 270, Loss: 15.1648
Batch 280, Loss: 15.0322
Batch 290, Loss: 14.4224
Batch 300, Loss: 14.8624
Batch 310, Loss: 14.7255
Batch 320, Loss: 14.7477
Batch 330, Loss: 13.9430
Batch 340, Loss: 13.6056
Batch 350, Loss: 13.9375
Batch 360, Loss: 13.8985
Batch 370, Loss: 14.0590
Batch 380, Loss: 13.9801
Batch 390, Loss: 13.8177
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 127.93786144256592 seconds
Epoch 1 accuracy: 10.07%
Batch 10, Loss: 13.5544
Batch 20, Loss: 13.0737
Batch 30, Loss: 13.0267
Batch 40, Loss: 13.1805
Batch 50, Loss: 13.3247
Batch 60, Loss: 13.1977
Batch 70, Loss: 13.1704
Batch 80, Loss: 12.9432
Batch 90, Loss: 12.6526
Batch 100, Loss: 12.5527
Batch 110, Loss: 12.8245
Batch 120, Loss: 12.4709
Batch 130, Loss: 12.4990
Batch 140, Loss: 12.2053
Batch 150, Loss: 12.0555
Batch 160, Loss: 12.2324
Batch 170, Loss: 12.2496
Batch 180, Loss: 12.0566
Batch 190, Loss: 11.8147
Batch 200, Loss: 11.4609
Batch 210, Loss: 11.7617
Batch 220, Loss: 11.5169
Batch 230, Loss: 11.4781
Batch 240, Loss: 11.1469
Batch 250, Loss: 11.2345
Batch 260, Loss: 11.1291
Batch 270, Loss: 10.8901
Batch 280, Loss: 10.8345
Batch 290, Loss: 10.7878
Batch 300, Loss: 10.7028
Batch 310, Loss: 10.2771
Batch 320, Loss: 10.4989
Batch 330, Loss: 10.5846
Batch 340, Loss: 10.4071
Batch 350, Loss: 9.9324
Batch 360, Loss: 10.0970
Batch 370, Loss: 9.9161
Batch 380, Loss: 9.4931
Batch 390, Loss: 9.5924
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 118.93744015693665 seconds
Epoch 2 accuracy: 9.94%
Batch 10, Loss: 9.1507
Batch 20, Loss: 9.2606
Batch 30, Loss: 9.0351
Batch 40, Loss: 8.7888
Batch 50, Loss: 8.3871
Batch 60, Loss: 8.2648
Batch 70, Loss: 8.2714
Batch 80, Loss: 8.1680
Batch 90, Loss: 8.1487
Batch 100, Loss: 7.6965
Batch 110, Loss: 7.6460
Batch 120, Loss: 7.9944
Batch 130, Loss: 7.5788
Batch 140, Loss: 7.6643
Batch 150, Loss: 7.6555
Batch 160, Loss: 7.4105
Batch 170, Loss: 7.5864
Batch 180, Loss: 7.3713
Batch 190, Loss: 7.4671
Batch 200, Loss: 7.2076
Batch 210, Loss: 7.0692
Batch 220, Loss: 7.0132
Batch 230, Loss: 7.1064
Batch 240, Loss: 7.2055
Batch 250, Loss: 6.8685
Batch 260, Loss: 6.9132
Batch 270, Loss: 6.9841
Batch 280, Loss: 6.8841
Batch 290, Loss: 6.6843
Batch 300, Loss: 6.5765
Batch 310, Loss: 6.7475
Batch 320, Loss: 6.7241
Batch 330, Loss: 6.4901
Batch 340, Loss: 6.4094
Batch 350, Loss: 6.3269
Batch 360, Loss: 5.9905
Batch 370, Loss: 6.1187
Batch 380, Loss: 6.1725
Batch 390, Loss: 5.9079
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 118.92050623893738 seconds
Epoch 3 accuracy: 9.2%
Batch 10, Loss: 5.8653
Batch 20, Loss: 5.5617
Batch 30, Loss: 5.5402
Batch 40, Loss: 5.4015
Batch 50, Loss: 5.3024
Batch 60, Loss: 5.3322
Batch 70, Loss: 4.9457
Batch 80, Loss: 4.9702
Batch 90, Loss: 4.6266
Batch 100, Loss: 4.6350
Batch 110, Loss: 4.5491
Batch 120, Loss: 4.5470
Batch 130, Loss: 4.5714
Batch 140, Loss: 4.2868
Batch 150, Loss: 4.2356
Batch 160, Loss: 4.1016
Batch 170, Loss: 4.3302
Batch 180, Loss: 4.1146
Batch 190, Loss: 4.2159
Batch 200, Loss: 3.9906
Batch 210, Loss: 3.8391
Batch 220, Loss: 3.9356
Batch 230, Loss: 3.8781
Batch 240, Loss: 3.7680
Batch 250, Loss: 3.9784
Batch 260, Loss: 3.8395
Batch 270, Loss: 3.8405
Batch 280, Loss: 3.8216
Batch 290, Loss: 3.8278
Batch 300, Loss: 3.6754
Batch 310, Loss: 3.7765
Batch 320, Loss: 3.8071
Batch 330, Loss: 3.7188
Batch 340, Loss: 3.7124
Batch 350, Loss: 3.5743
Batch 360, Loss: 3.6076
Batch 370, Loss: 3.6446
Batch 380, Loss: 3.6792
Batch 390, Loss: 3.5555
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 118.90625381469727 seconds
Epoch 4 accuracy: 13.43%
Batch 10, Loss: 3.4371
Batch 20, Loss: 3.4650
Batch 30, Loss: 3.4605
Batch 40, Loss: 3.4098
Batch 50, Loss: 3.4532
Batch 60, Loss: 3.3795
Batch 70, Loss: 3.4386
Batch 80, Loss: 3.5037
Batch 90, Loss: 3.3553
Batch 100, Loss: 3.3094
Batch 110, Loss: 3.1665
Batch 120, Loss: 3.2023
Batch 130, Loss: 3.1733
Batch 140, Loss: 3.0949
Batch 150, Loss: 3.1267
Batch 160, Loss: 3.1695
Batch 170, Loss: 3.0729
Batch 180, Loss: 3.0360
Batch 190, Loss: 3.1690
Batch 200, Loss: 3.0914
Batch 210, Loss: 3.0558
Batch 220, Loss: 3.1542
Batch 230, Loss: 3.0900
Batch 240, Loss: 2.9560
Batch 250, Loss: 3.0057
Batch 260, Loss: 3.0403
Batch 270, Loss: 3.0132
Batch 280, Loss: 2.8821
Batch 290, Loss: 3.0066
Batch 300, Loss: 2.9982
Batch 310, Loss: 2.9383
Batch 320, Loss: 3.0623
Batch 330, Loss: 2.7420
Batch 340, Loss: 2.8694
Batch 350, Loss: 2.8740
Batch 360, Loss: 2.8795
Batch 370, Loss: 2.7633
Batch 380, Loss: 2.7989
Batch 390, Loss: 2.7571
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 118.85993695259094 seconds
Epoch 5 accuracy: 13.69%
Batch 10, Loss: 2.7921
Batch 20, Loss: 2.7285
Batch 30, Loss: 2.7965
Batch 40, Loss: 2.7005
Batch 50, Loss: 2.6586
Batch 60, Loss: 2.6578
Batch 70, Loss: 2.6703
Batch 80, Loss: 2.5817
Batch 90, Loss: 2.7325
Batch 100, Loss: 2.6908
Batch 110, Loss: 2.5320
Batch 120, Loss: 2.5127
Batch 130, Loss: 2.5868
Batch 140, Loss: 2.5974
Batch 150, Loss: 2.5522
Batch 160, Loss: 2.5142
Batch 170, Loss: 2.4841
Batch 180, Loss: 2.5033
Batch 190, Loss: 2.4430
Batch 200, Loss: 2.3944
Batch 210, Loss: 2.5149
Batch 220, Loss: 2.3647
Batch 230, Loss: 2.4274
Batch 240, Loss: 2.4240
Batch 250, Loss: 2.4118
Batch 260, Loss: 2.4227
Batch 270, Loss: 2.3945
Batch 280, Loss: 2.4120
Batch 290, Loss: 2.3890
Batch 300, Loss: 2.3716
Batch 310, Loss: 2.4019
Batch 320, Loss: 2.2889
Batch 330, Loss: 2.2678
Batch 340, Loss: 2.2929
Batch 350, Loss: 2.2764
Batch 360, Loss: 2.3777
Batch 370, Loss: 2.3428
Batch 380, Loss: 2.3418
Batch 390, Loss: 2.3137
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 118.87108302116394 seconds
Epoch 6 accuracy: 16.16%
Batch 10, Loss: 2.3007
Batch 20, Loss: 2.3561
Batch 30, Loss: 2.2907
Batch 40, Loss: 2.2898
Batch 50, Loss: 2.2130
Batch 60, Loss: 2.2246
Batch 70, Loss: 2.2189
Batch 80, Loss: 2.2235
Batch 90, Loss: 2.1838
Batch 100, Loss: 2.2763
Batch 110, Loss: 2.2102
Batch 120, Loss: 2.2458
Batch 130, Loss: 2.2608
Batch 140, Loss: 2.2194
Batch 150, Loss: 2.2305
Batch 160, Loss: 2.1749
Batch 170, Loss: 2.2931
Batch 180, Loss: 2.2331
Batch 190, Loss: 2.1743
Batch 200, Loss: 2.2070
Batch 210, Loss: 2.1425
Batch 220, Loss: 2.2041
Batch 230, Loss: 2.0938
Batch 240, Loss: 2.1379
Batch 250, Loss: 2.1914
Batch 260, Loss: 2.1359
Batch 270, Loss: 2.1785
Batch 280, Loss: 2.1519
Batch 290, Loss: 2.1269
Batch 300, Loss: 2.0677
Batch 310, Loss: 2.0840
Batch 320, Loss: 2.1163
Batch 330, Loss: 2.1002
Batch 340, Loss: 2.1148
Batch 350, Loss: 2.0831
Batch 360, Loss: 2.0669
Batch 370, Loss: 2.1059
Batch 380, Loss: 2.0749
Batch 390, Loss: 2.1590
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 118.84047102928162 seconds
Epoch 7 accuracy: 14.24%
Batch 10, Loss: 2.0789
Batch 20, Loss: 2.0271
Batch 30, Loss: 2.0644
Batch 40, Loss: 2.0583
Batch 50, Loss: 2.0643
Batch 60, Loss: 2.0923
Batch 70, Loss: 2.0504
Batch 80, Loss: 2.0523
Batch 90, Loss: 2.0846
Batch 100, Loss: 2.1418
Batch 110, Loss: 2.0742
Batch 120, Loss: 2.0714
Batch 130, Loss: 2.0311
Batch 140, Loss: 2.1247
Batch 150, Loss: 2.1069
Batch 160, Loss: 2.0221
Batch 170, Loss: 2.0188
Batch 180, Loss: 2.0223
Batch 190, Loss: 1.9831
Batch 200, Loss: 2.0468
Batch 210, Loss: 2.0664
Batch 220, Loss: 2.0129
Batch 230, Loss: 2.0424
Batch 240, Loss: 1.9716
Batch 250, Loss: 2.0022
Batch 260, Loss: 2.0671
Batch 270, Loss: 2.0617
Batch 280, Loss: 2.0330
Batch 290, Loss: 2.0174
Batch 300, Loss: 1.9965
Batch 310, Loss: 1.9971
Batch 320, Loss: 2.0026
Batch 330, Loss: 2.0393
Batch 340, Loss: 1.9970
Batch 350, Loss: 2.0169
Batch 360, Loss: 2.0205
Batch 370, Loss: 1.9771
Batch 380, Loss: 2.0389
Batch 390, Loss: 2.0135
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 118.87315654754639 seconds
Epoch 8 accuracy: 12.61%
Batch 10, Loss: 1.9456
Batch 20, Loss: 2.0027
Batch 30, Loss: 2.0112
Batch 40, Loss: 1.9763
Batch 50, Loss: 1.9684
Batch 60, Loss: 1.9694
Batch 70, Loss: 1.9802
Batch 80, Loss: 2.0088
Batch 90, Loss: 1.9471
Batch 100, Loss: 1.9473
Batch 110, Loss: 1.9921
Batch 120, Loss: 2.0082
Batch 130, Loss: 2.0172
Batch 140, Loss: 1.9961
Batch 150, Loss: 1.9575
Batch 160, Loss: 1.9813
Batch 170, Loss: 1.9381
Batch 180, Loss: 1.9689
Batch 190, Loss: 1.9474
Batch 200, Loss: 1.9479
Batch 210, Loss: 1.9536
Batch 220, Loss: 1.9497
Batch 230, Loss: 1.9505
Batch 240, Loss: 1.9261
Batch 250, Loss: 1.9570
Batch 260, Loss: 1.9262
Batch 270, Loss: 1.9372
Batch 280, Loss: 1.9751
Batch 290, Loss: 1.9341
Batch 300, Loss: 1.9411
Batch 310, Loss: 1.9066
Batch 320, Loss: 1.9344
Batch 330, Loss: 1.9568
Batch 340, Loss: 1.9330
Batch 350, Loss: 1.9187
Batch 360, Loss: 1.9253
Batch 370, Loss: 1.8886
Batch 380, Loss: 1.9519
Batch 390, Loss: 1.8804
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 118.84175157546997 seconds
Epoch 9 accuracy: 13.78%
Batch 10, Loss: 1.9213
Batch 20, Loss: 1.9420
Batch 30, Loss: 1.9069
Batch 40, Loss: 1.8973
Batch 50, Loss: 1.9428
Batch 60, Loss: 1.8799
Batch 70, Loss: 1.9233
Batch 80, Loss: 1.9199
Batch 90, Loss: 1.8937
Batch 100, Loss: 1.8901
Batch 110, Loss: 1.8757
Batch 120, Loss: 1.8882
Batch 130, Loss: 1.8988
Batch 140, Loss: 1.8933
Batch 150, Loss: 1.8760
Batch 160, Loss: 1.8847
Batch 170, Loss: 1.8808
Batch 180, Loss: 1.9040
Batch 190, Loss: 1.8951
Batch 200, Loss: 1.8737
Batch 210, Loss: 1.8878
Batch 220, Loss: 1.8613
Batch 230, Loss: 1.8531
Batch 240, Loss: 1.8858
Batch 250, Loss: 1.8493
Batch 260, Loss: 1.8627
Batch 270, Loss: 1.8657
Batch 280, Loss: 1.8581
Batch 290, Loss: 1.8533
Batch 300, Loss: 1.8425
Batch 310, Loss: 1.8663
Batch 320, Loss: 1.8481
Batch 330, Loss: 1.8166
Batch 340, Loss: 1.8452
Batch 350, Loss: 1.8211
Batch 360, Loss: 1.8513
Batch 370, Loss: 1.8341
Batch 380, Loss: 1.8358
Batch 390, Loss: 1.8033
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 118.82690596580505 seconds
Epoch 10 accuracy: 15.98%
Batch 10, Loss: 1.8236
Batch 20, Loss: 1.8198
Batch 30, Loss: 1.8127
Batch 40, Loss: 1.8249
Batch 50, Loss: 1.8104
Batch 60, Loss: 1.8217
Batch 70, Loss: 1.8334
Batch 80, Loss: 1.8079
Batch 90, Loss: 1.8171
Batch 100, Loss: 1.8162
Batch 110, Loss: 1.8102
Batch 120, Loss: 1.8229
Batch 130, Loss: 1.8205
Batch 140, Loss: 1.8027
Batch 150, Loss: 1.7966
Batch 160, Loss: 1.7936
Batch 170, Loss: 1.7923
Batch 180, Loss: 1.7973
Batch 190, Loss: 1.7925
Batch 200, Loss: 1.7979
Batch 210, Loss: 1.7873
Batch 220, Loss: 1.7853
Batch 230, Loss: 1.7804
Batch 240, Loss: 1.7857
Batch 250, Loss: 1.7794
Batch 260, Loss: 1.7745
Batch 270, Loss: 1.7745
Batch 280, Loss: 1.7785
Batch 290, Loss: 1.7777
Batch 300, Loss: 1.7731
Batch 310, Loss: 1.7823
Batch 320, Loss: 1.7738
Batch 330, Loss: 1.7644
Batch 340, Loss: 1.7700
Batch 350, Loss: 1.7687
Batch 360, Loss: 1.7672
Batch 370, Loss: 1.7632
Batch 380, Loss: 1.7710
Batch 390, Loss: 1.7653
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 118.82667350769043 seconds
Epoch 11 accuracy: 9.9%
Batch 10, Loss: 1.7627
Batch 20, Loss: 1.7607
Batch 30, Loss: 1.7644
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7616
Batch 60, Loss: 1.7591
Batch 70, Loss: 1.7600
Batch 80, Loss: 1.7594
Batch 90, Loss: 1.7590
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7591
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7592
Batch 140, Loss: 1.7559
Batch 150, Loss: 1.7593
Batch 160, Loss: 1.7587
Batch 170, Loss: 1.7590
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7587
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7584
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7572
Batch 300, Loss: 1.7572
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7583
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7575
Batch 370, Loss: 1.7574
Batch 380, Loss: 1.7573
Batch 390, Loss: 1.7591
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 118.78364205360413 seconds
Epoch 12 accuracy: 9.92%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7583
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7568
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7573
Batch 130, Loss: 1.7576
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7585
Batch 200, Loss: 1.7585
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7575
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7570
Batch 270, Loss: 1.7590
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7570
Batch 310, Loss: 1.7575
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7571
Batch 340, Loss: 1.7583
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 118.77051210403442 seconds
Epoch 13 accuracy: 9.87%
Batch 10, Loss: 1.7581
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7573
Batch 50, Loss: 1.7573
Batch 60, Loss: 1.7586
Batch 70, Loss: 1.7573
Batch 80, Loss: 1.7585
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7575
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7583
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7573
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7574
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7583
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7574
Batch 370, Loss: 1.7574
Batch 380, Loss: 1.7575
Batch 390, Loss: 1.7577
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 118.79654145240784 seconds
Epoch 14 accuracy: 9.98%
Batch 10, Loss: 1.7582
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7587
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7584
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7585
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7575
Batch 200, Loss: 1.7572
Batch 210, Loss: 1.7574
Batch 220, Loss: 1.7568
Batch 230, Loss: 1.7574
Batch 240, Loss: 1.7568
Batch 250, Loss: 1.7574
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7589
Batch 290, Loss: 1.7585
Batch 300, Loss: 1.7593
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7582
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7585
Batch 390, Loss: 1.7575
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 118.78858685493469 seconds
Epoch 15 accuracy: 10.0%
Batch 10, Loss: 1.7581
Batch 20, Loss: 1.7574
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7575
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7586
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7574
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7577
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 118.76844048500061 seconds
Epoch 16 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7572
Batch 70, Loss: 1.7573
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7585
Batch 110, Loss: 1.7587
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7584
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7575
Batch 210, Loss: 1.7576
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7575
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7576
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7588
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7584
Batch 390, Loss: 1.7580
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 118.78287601470947 seconds
Epoch 17 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7574
Batch 50, Loss: 1.7587
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7573
Batch 80, Loss: 1.7584
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7584
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7576
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7587
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7583
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7584
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7576
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7577
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 118.79565501213074 seconds
Epoch 18 accuracy: 10.01%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7583
Batch 50, Loss: 1.7574
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7572
Batch 80, Loss: 1.7582
Batch 90, Loss: 1.7585
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7574
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7585
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7575
Batch 190, Loss: 1.7573
Batch 200, Loss: 1.7585
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7575
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7583
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7583
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7583
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7573
Batch 390, Loss: 1.7579
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 118.72078156471252 seconds
Epoch 19 accuracy: 10.01%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7573
Batch 30, Loss: 1.7584
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7585
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7584
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7574
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7573
Batch 140, Loss: 1.7585
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7574
Batch 170, Loss: 1.7584
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7582
Batch 220, Loss: 1.7584
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7576
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7576
Batch 370, Loss: 1.7584
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7577
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 118.76868891716003 seconds
Epoch 20 accuracy: 10.0%
Batch 10, Loss: 1.7572
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7573
Batch 50, Loss: 1.7584
Batch 60, Loss: 1.7576
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7582
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7584
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7584
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7586
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7574
Batch 390, Loss: 1.7587
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 118.77298736572266 seconds
Epoch 21 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7583
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7587
Batch 390, Loss: 1.7583
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 118.79316735267639 seconds
Epoch 22 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7584
Batch 60, Loss: 1.7582
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7583
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7582
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7583
Batch 190, Loss: 1.7575
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7583
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7583
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 118.79701685905457 seconds
Epoch 23 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7570
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7583
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7576
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7583
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7570
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7591
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7584
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7571
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7584
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 118.81363916397095 seconds
Epoch 24 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7583
Batch 40, Loss: 1.7574
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7584
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7575
Batch 220, Loss: 1.7584
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7576
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7573
Batch 320, Loss: 1.7583
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7584
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7586
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7579
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 118.78014421463013 seconds
Epoch 25 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7585
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 118.74938201904297 seconds
Epoch 26 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7575
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7583
Batch 70, Loss: 1.7587
Batch 80, Loss: 1.7583
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7583
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7581
Batch 170, Loss: 1.7574
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7573
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7587
Batch 220, Loss: 1.7584
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7583
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7583
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7574
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7579
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 118.76098084449768 seconds
Epoch 27 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7572
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7589
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7591
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7572
Batch 160, Loss: 1.7583
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7576
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7585
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 118.82577967643738 seconds
Epoch 28 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7572
Batch 40, Loss: 1.7584
Batch 50, Loss: 1.7589
Batch 60, Loss: 1.7575
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7573
Batch 130, Loss: 1.7584
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7585
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7583
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7583
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7583
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7583
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7574
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7584
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7581
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 118.82134819030762 seconds
Epoch 29 accuracy: 9.99%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7574
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7586
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7584
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7583
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7576
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7574
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7583
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 118.80794644355774 seconds
Epoch 30 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7573
Batch 60, Loss: 1.7574
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7587
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7574
Batch 130, Loss: 1.7585
Batch 140, Loss: 1.7585
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7575
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7584
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7583
Batch 300, Loss: 1.7582
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7575
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7576
Batch 390, Loss: 1.7586
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 118.83101320266724 seconds
Epoch 31 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7585
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7574
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7585
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7575
Batch 280, Loss: 1.7576
Batch 290, Loss: 1.7585
Batch 300, Loss: 1.7584
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7574
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7584
Batch 390, Loss: 1.7579
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 118.86137747764587 seconds
Epoch 32 accuracy: 10.0%
Batch 10, Loss: 1.7575
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7584
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7574
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7586
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7583
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7573
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7584
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7576
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7582
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 118.77209830284119 seconds
Epoch 33 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7575
Batch 70, Loss: 1.7583
Batch 80, Loss: 1.7586
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7574
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7584
Batch 180, Loss: 1.7583
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7575
Batch 360, Loss: 1.7575
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7583
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 118.88381099700928 seconds
Epoch 34 accuracy: 10.0%
Batch 10, Loss: 1.7586
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7583
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7572
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7587
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7575
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7582
Batch 150, Loss: 1.7586
Batch 160, Loss: 1.7574
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7584
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7585
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7584
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7586
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7578
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 118.75878405570984 seconds
Epoch 35 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7574
Batch 70, Loss: 1.7571
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7587
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7574
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7575
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7576
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7583
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7575
Batch 330, Loss: 1.7583
Batch 340, Loss: 1.7582
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7584
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 118.7972960472107 seconds
Epoch 36 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7572
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7583
Batch 120, Loss: 1.7576
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7583
Batch 160, Loss: 1.7585
Batch 170, Loss: 1.7576
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7573
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7588
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7584
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7575
Batch 350, Loss: 1.7569
Batch 360, Loss: 1.7583
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7585
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 118.7730782032013 seconds
Epoch 37 accuracy: 10.0%
Batch 10, Loss: 1.7575
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7586
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7587
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7575
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7583
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7583
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7586
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7585
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7576
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7581
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 118.73654985427856 seconds
Epoch 38 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7574
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7584
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7587
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7588
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7586
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7584
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7575
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7584
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 118.78883624076843 seconds
Epoch 39 accuracy: 10.0%
Batch 10, Loss: 1.7571
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7583
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7575
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7585
Batch 130, Loss: 1.7583
Batch 140, Loss: 1.7573
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7573
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7583
Batch 310, Loss: 1.7584
Batch 320, Loss: 1.7584
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7584
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7577
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 118.75782203674316 seconds
Epoch 40 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7584
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7584
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7585
Batch 170, Loss: 1.7574
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7584
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7575
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 118.82907199859619 seconds
Epoch 41 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7584
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7584
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7582
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 118.76356315612793 seconds
Epoch 42 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7574
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7583
Batch 190, Loss: 1.7575
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7587
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7583
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 118.75184750556946 seconds
Epoch 43 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7574
Batch 50, Loss: 1.7586
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7583
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7575
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7583
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7575
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7584
Batch 230, Loss: 1.7586
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7576
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7584
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 118.79291605949402 seconds
Epoch 44 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7586
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7584
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7573
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7584
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7584
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7583
Batch 320, Loss: 1.7573
Batch 330, Loss: 1.7584
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7575
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7585
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7576
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 118.78000354766846 seconds
Epoch 45 accuracy: 10.0%
Batch 10, Loss: 1.7581
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7572
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7571
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7574
Batch 130, Loss: 1.7584
Batch 140, Loss: 1.7585
Batch 150, Loss: 1.7583
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7583
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7574
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7586
Batch 310, Loss: 1.7584
Batch 320, Loss: 1.7574
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7575
Batch 350, Loss: 1.7585
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7588
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7579
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 118.79340481758118 seconds
Epoch 46 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7582
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7584
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7584
Batch 210, Loss: 1.7574
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7583
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7572
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7584
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 118.84498262405396 seconds
Epoch 47 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7574
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7583
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7573
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7584
Batch 180, Loss: 1.7575
Batch 190, Loss: 1.7573
Batch 200, Loss: 1.7583
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7583
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7572
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7584
Batch 310, Loss: 1.7586
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7582
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7581
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 118.80697679519653 seconds
Epoch 48 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7575
Batch 80, Loss: 1.7583
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7583
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7574
Batch 200, Loss: 1.7584
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7583
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7581
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 118.74542951583862 seconds
Epoch 49 accuracy: 10.0%
Batch 10, Loss: 1.7584
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7575
Batch 60, Loss: 1.7584
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7584
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7584
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7585
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7575
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7574
Batch 360, Loss: 1.7586
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7584
Batch 390, Loss: 1.7580
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 118.76382446289062 seconds
Epoch 50 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7574
Batch 70, Loss: 1.7586
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7582
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7584
Batch 160, Loss: 1.7584
Batch 170, Loss: 1.7576
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7575
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7583
Batch 350, Loss: 1.7583
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 118.79339933395386 seconds
Epoch 51 accuracy: 10.0%
Batch 10, Loss: 1.7584
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7583
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7574
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7572
Batch 200, Loss: 1.7576
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7587
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7586
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7586
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7583
Batch 360, Loss: 1.7575
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7582
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 118.76769948005676 seconds
Epoch 52 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7587
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7574
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7583
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 118.7573709487915 seconds
Epoch 53 accuracy: 10.0%
Batch 10, Loss: 1.7575
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7581
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7585
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7583
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7575
Batch 140, Loss: 1.7582
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7584
Batch 170, Loss: 1.7575
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7572
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7585
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7583
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7574
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7582
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 118.83578372001648 seconds
Epoch 54 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7573
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7583
Batch 60, Loss: 1.7583
Batch 70, Loss: 1.7584
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7575
Batch 290, Loss: 1.7586
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7574
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7579
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 118.84628772735596 seconds
Epoch 55 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7575
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7584
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7583
Batch 130, Loss: 1.7576
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7583
Batch 210, Loss: 1.7583
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7572
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7576
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 118.77292275428772 seconds
Epoch 56 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7586
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7582
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7583
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7581
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7576
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7585
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7583
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7575
Batch 360, Loss: 1.7583
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7581
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 118.82242250442505 seconds
Epoch 57 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7574
Batch 40, Loss: 1.7584
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7585
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7584
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 118.81267595291138 seconds
Epoch 58 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7575
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7586
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7570
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7585
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7574
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7584
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7580
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 118.9292585849762 seconds
Epoch 59 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7581
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7582
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7581
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7576
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7583
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7585
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7576
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7584
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7580
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 118.80379271507263 seconds
Epoch 60 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7582
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7583
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7585
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7584
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 118.75712704658508 seconds
Epoch 61 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7574
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7584
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7582
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7574
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7581
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 118.78486514091492 seconds
Epoch 62 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7573
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7575
Batch 130, Loss: 1.7575
Batch 140, Loss: 1.7583
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7583
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7582
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 118.80121445655823 seconds
Epoch 63 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7574
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7583
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7579
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 118.81041264533997 seconds
Epoch 64 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7573
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7585
Batch 130, Loss: 1.7583
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7574
Batch 220, Loss: 1.7586
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7575
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7584
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 118.76072311401367 seconds
Epoch 65 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7572
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7583
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7582
Batch 90, Loss: 1.7574
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7576
Batch 230, Loss: 1.7588
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7583
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 118.74430441856384 seconds
Epoch 66 accuracy: 10.0%
Batch 10, Loss: 1.7582
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7583
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7583
Batch 180, Loss: 1.7584
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7583
Batch 210, Loss: 1.7583
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7583
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7585
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7583
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 118.80557203292847 seconds
Epoch 67 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7582
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7583
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7575
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7584
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 118.8160650730133 seconds
Epoch 68 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7576
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7587
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7576
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7583
Batch 360, Loss: 1.7583
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7580
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 118.82640981674194 seconds
Epoch 69 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7583
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7582
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7580
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 118.83969068527222 seconds
Epoch 70 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7581
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7575
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7575
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7575
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7578
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 118.84182953834534 seconds
Epoch 71 accuracy: 10.0%
Batch 10, Loss: 1.7575
Batch 20, Loss: 1.7586
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7582
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 118.7956817150116 seconds
Epoch 72 accuracy: 10.0%
Batch 10, Loss: 1.7574
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7588
Batch 100, Loss: 1.7575
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7574
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7586
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7573
Batch 270, Loss: 1.7583
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7582
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 119.05106568336487 seconds
Epoch 73 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7582
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7576
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7582
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7573
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7576
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7584
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7577
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 118.80209016799927 seconds
Epoch 74 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7572
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7583
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7585
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7576
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.7583
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7584
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7583
Batch 390, Loss: 1.7579
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 118.78458738327026 seconds
Epoch 75 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7583
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7575
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7584
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7587
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7582
Batch 210, Loss: 1.7576
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7576
Batch 280, Loss: 1.7584
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7575
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7586
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 118.84545874595642 seconds
Epoch 76 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7572
Batch 150, Loss: 1.7583
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7588
Batch 180, Loss: 1.7584
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7575
Batch 300, Loss: 1.7575
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7586
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7583
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 118.8430449962616 seconds
Epoch 77 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7586
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7575
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7575
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7584
Batch 330, Loss: 1.7575
Batch 340, Loss: 1.7582
Batch 350, Loss: 1.7584
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7582
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 118.85853719711304 seconds
Epoch 78 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7575
Batch 60, Loss: 1.7583
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7586
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7576
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7573
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7583
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7583
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7579
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 118.7975401878357 seconds
Epoch 79 accuracy: 10.0%
Batch 10, Loss: 1.7582
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7583
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7575
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7583
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7576
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7581
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 118.77447199821472 seconds
Epoch 80 accuracy: 10.0%
Batch 10, Loss: 1.7574
Batch 20, Loss: 1.7573
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7585
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7583
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7575
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7583
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7580
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 118.7727701663971 seconds
Epoch 81 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7575
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7574
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7575
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7585
Batch 130, Loss: 1.7582
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7585
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 118.81723189353943 seconds
Epoch 82 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7583
Batch 270, Loss: 1.7583
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7581
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 118.80905961990356 seconds
Epoch 83 accuracy: 10.0%
Batch 10, Loss: 1.7581
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7574
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7584
Batch 210, Loss: 1.7585
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7576
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 118.8120346069336 seconds
Epoch 84 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7582
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7575
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7582
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7582
Batch 390, Loss: 1.7578
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 118.85747003555298 seconds
Epoch 85 accuracy: 10.0%
Batch 10, Loss: 1.7573
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7587
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7573
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7583
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7583
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7576
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 118.86778211593628 seconds
Epoch 86 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7575
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7575
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 118.79118776321411 seconds
Epoch 87 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7575
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7575
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7584
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7576
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7583
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7575
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7584
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7577
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 118.79601812362671 seconds
Epoch 88 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7576
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7575
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7573
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7585
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7582
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 118.77133870124817 seconds
Epoch 89 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7583
Batch 130, Loss: 1.7574
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7585
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 118.82737445831299 seconds
Epoch 90 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7582
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7582
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 118.88802909851074 seconds
Epoch 91 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7582
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7578
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 118.81463479995728 seconds
Epoch 92 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7576
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7575
Batch 250, Loss: 1.7582
Batch 260, Loss: 1.7589
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7583
Batch 290, Loss: 1.7576
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7581
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 118.79636359214783 seconds
Epoch 93 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7575
Batch 200, Loss: 1.7576
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7583
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7577
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 118.7825186252594 seconds
Epoch 94 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7581
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7583
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7582
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7575
Batch 360, Loss: 1.7584
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7576
Batch 390, Loss: 1.7582
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 118.77157926559448 seconds
Epoch 95 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 118.81430578231812 seconds
Epoch 96 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7576
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7582
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 118.82985520362854 seconds
Epoch 97 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7581
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7582
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7576
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7583
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7577
Batch 390, Loss: 1.7581
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 118.79562520980835 seconds
Epoch 98 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7584
Batch 120, Loss: 1.7576
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 118.7567868232727 seconds
Epoch 99 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7574
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7582
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7584
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 118.8428361415863 seconds
Epoch 100 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7574
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 118.89389610290527 seconds
Epoch 101 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7576
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 118.85236358642578 seconds
Epoch 102 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7584
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7575
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7582
Batch 360, Loss: 1.7583
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7578
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 118.87501668930054 seconds
Epoch 103 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7580
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7576
Batch 90, Loss: 1.7575
Batch 100, Loss: 1.7583
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7575
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7580
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 118.7772626876831 seconds
Epoch 104 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7581
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7575
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7579
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 118.79245352745056 seconds
Epoch 105 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7580
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7582
Batch 110, Loss: 1.7581
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7582
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7582
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 118.78786277770996 seconds
Epoch 106 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7580
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 118.81773543357849 seconds
Epoch 107 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7576
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7576
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7582
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7577
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 118.7876980304718 seconds
Epoch 108 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7582
Batch 50, Loss: 1.7581
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7581
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7577
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 118.83054280281067 seconds
Epoch 109 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7574
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7584
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7575
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7580
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 118.7721745967865 seconds
Epoch 110 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7583
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7573
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7575
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7583
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7583
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7575
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 118.7972526550293 seconds
Epoch 111 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7581
Batch 70, Loss: 1.7582
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7576
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7582
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7582
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 118.79906702041626 seconds
Epoch 112 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7576
Batch 30, Loss: 1.7582
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7576
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7581
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 118.73994588851929 seconds
Epoch 113 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7575
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7575
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7581
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7574
Batch 210, Loss: 1.7583
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 118.79141759872437 seconds
Epoch 114 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7580
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7581
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 118.7714455127716 seconds
Epoch 115 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7580
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7583
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7576
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7581
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 118.88004899024963 seconds
Epoch 116 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7580
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7575
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7575
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7582
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 118.86973309516907 seconds
Epoch 117 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7582
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7581
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 118.8035900592804 seconds
Epoch 118 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7575
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7581
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 118.79879021644592 seconds
Epoch 119 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7576
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7583
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7581
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 118.76653003692627 seconds
Epoch 120 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7576
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7575
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7582
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7576
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7582
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7581
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 118.7652702331543 seconds
Epoch 121 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7575
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7582
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7576
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7576
Batch 380, Loss: 1.7581
Batch 390, Loss: 1.7579
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 118.78211879730225 seconds
Epoch 122 accuracy: 10.0%
Batch 10, Loss: 1.7576
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7582
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7581
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7583
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 118.82007646560669 seconds
Epoch 123 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 118.96555757522583 seconds
Epoch 124 accuracy: 10.0%
Batch 10, Loss: 1.7579
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7581
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7575
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7580
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 118.73944067955017 seconds
Epoch 125 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7576
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7575
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7581
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7581
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7581
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7577
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 118.81335783004761 seconds
Epoch 126 accuracy: 10.0%
Batch 10, Loss: 1.7580
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7576
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7576
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7580
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 118.8154649734497 seconds
Epoch 127 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7576
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 118.76773524284363 seconds
Epoch 128 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7576
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 118.79644560813904 seconds
Epoch 129 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7580
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7576
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 118.7463481426239 seconds
Epoch 130 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7581
Batch 90, Loss: 1.7581
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7581
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7579
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 118.81857085227966 seconds
Epoch 131 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7580
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7581
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7580
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 118.83998894691467 seconds
Epoch 132 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7580
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7576
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7581
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7581
Batch 350, Loss: 1.7580
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 118.81852221488953 seconds
Epoch 133 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7579
Batch 30, Loss: 1.7576
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7581
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7580
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 118.78254055976868 seconds
Epoch 134 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7580
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 118.74697637557983 seconds
Epoch 135 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7580
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7576
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7580
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7576
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7582
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7580
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 118.75658583641052 seconds
Epoch 136 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 118.78175735473633 seconds
Epoch 137 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7576
Batch 140, Loss: 1.7576
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7575
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7583
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7582
Batch 240, Loss: 1.7581
Batch 250, Loss: 1.7581
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7580
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 118.78006339073181 seconds
Epoch 138 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7581
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7580
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7577
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 118.76131200790405 seconds
Epoch 139 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7576
Batch 110, Loss: 1.7575
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7580
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7581
Batch 180, Loss: 1.7581
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7581
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 118.8094379901886 seconds
Epoch 140 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7580
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 118.73534870147705 seconds
Epoch 141 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7579
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7580
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7578
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 118.76431632041931 seconds
Epoch 142 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 118.76707863807678 seconds
Epoch 143 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 118.77968716621399 seconds
Epoch 144 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7580
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7580
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7580
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 118.82049131393433 seconds
Epoch 145 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7577
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7580
Batch 370, Loss: 1.7580
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 118.79657697677612 seconds
Epoch 146 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7579
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7577
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7580
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 118.80984139442444 seconds
Epoch 147 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 118.84356141090393 seconds
Epoch 148 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7580
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7578
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 118.83968734741211 seconds
Epoch 149 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7577
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7580
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7580
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 118.77318263053894 seconds
Epoch 150 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7576
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7579
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7576
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7576
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7580
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7580
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 118.79099798202515 seconds
Epoch 151 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7577
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7579
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7580
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7577
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7580
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 118.76611471176147 seconds
Epoch 152 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7579
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7581
Batch 310, Loss: 1.7580
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7579
Batch 390, Loss: 1.7579
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 118.7985405921936 seconds
Epoch 153 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7577
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7577
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 118.76234030723572 seconds
Epoch 154 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7580
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 118.73253917694092 seconds
Epoch 155 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7577
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 118.7544379234314 seconds
Epoch 156 accuracy: 10.0%
Batch 10, Loss: 1.7577
Batch 20, Loss: 1.7577
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7577
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7577
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7577
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7579
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7579
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 118.75912833213806 seconds
Epoch 157 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7580
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 118.75578331947327 seconds
Epoch 158 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7579
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 118.7537624835968 seconds
Epoch 159 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7579
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7579
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7579
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7577
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 118.79311180114746 seconds
Epoch 160 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7579
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7579
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 118.78201198577881 seconds
Epoch 161 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7577
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7579
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7579
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7579
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 118.7332067489624 seconds
Epoch 162 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7577
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7579
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 118.76226806640625 seconds
Epoch 163 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7577
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7579
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7577
Batch 220, Loss: 1.7577
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7577
Batch 300, Loss: 1.7579
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 118.7544777393341 seconds
Epoch 164 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7579
Batch 150, Loss: 1.7577
Batch 160, Loss: 1.7577
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7577
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7579
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 118.75768780708313 seconds
Epoch 165 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7579
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 118.78342056274414 seconds
Epoch 166 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7579
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7577
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7579
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 118.76163673400879 seconds
Epoch 167 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7577
Batch 210, Loss: 1.7579
Batch 220, Loss: 1.7579
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7579
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7579
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 118.7732880115509 seconds
Epoch 168 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7577
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7579
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7579
Batch 130, Loss: 1.7577
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 118.87522888183594 seconds
Epoch 169 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7577
Batch 90, Loss: 1.7577
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7579
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7577
Batch 270, Loss: 1.7577
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7579
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 118.77206015586853 seconds
Epoch 170 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7577
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7579
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 118.71470475196838 seconds
Epoch 171 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 118.77426481246948 seconds
Epoch 172 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7579
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 118.79854917526245 seconds
Epoch 173 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 118.74915862083435 seconds
Epoch 174 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 118.81000709533691 seconds
Epoch 175 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 118.75069260597229 seconds
Epoch 176 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 118.76159620285034 seconds
Epoch 177 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 118.7715961933136 seconds
Epoch 178 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 118.75920248031616 seconds
Epoch 179 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 118.7418806552887 seconds
Epoch 180 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 118.7746901512146 seconds
Epoch 181 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 118.7654595375061 seconds
Epoch 182 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 118.73207640647888 seconds
Epoch 183 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 118.78510594367981 seconds
Epoch 184 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 118.78610587120056 seconds
Epoch 185 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 118.71225333213806 seconds
Epoch 186 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 118.80791091918945 seconds
Epoch 187 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 118.73607301712036 seconds
Epoch 188 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 118.75312948226929 seconds
Epoch 189 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 118.77380347251892 seconds
Epoch 190 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 118.7582654953003 seconds
Epoch 191 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 118.79473948478699 seconds
Epoch 192 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 118.74021697044373 seconds
Epoch 193 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 118.77107071876526 seconds
Epoch 194 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 118.80720257759094 seconds
Epoch 195 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 118.76191401481628 seconds
Epoch 196 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 118.83170509338379 seconds
Epoch 197 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 118.78503370285034 seconds
Epoch 198 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 118.85013818740845 seconds
Epoch 199 accuracy: 10.0%
Batch 10, Loss: 1.7578
Batch 20, Loss: 1.7578
Batch 30, Loss: 1.7578
Batch 40, Loss: 1.7578
Batch 50, Loss: 1.7578
Batch 60, Loss: 1.7578
Batch 70, Loss: 1.7578
Batch 80, Loss: 1.7578
Batch 90, Loss: 1.7578
Batch 100, Loss: 1.7578
Batch 110, Loss: 1.7578
Batch 120, Loss: 1.7578
Batch 130, Loss: 1.7578
Batch 140, Loss: 1.7578
Batch 150, Loss: 1.7578
Batch 160, Loss: 1.7578
Batch 170, Loss: 1.7578
Batch 180, Loss: 1.7578
Batch 190, Loss: 1.7578
Batch 200, Loss: 1.7578
Batch 210, Loss: 1.7578
Batch 220, Loss: 1.7578
Batch 230, Loss: 1.7578
Batch 240, Loss: 1.7578
Batch 250, Loss: 1.7578
Batch 260, Loss: 1.7578
Batch 270, Loss: 1.7578
Batch 280, Loss: 1.7578
Batch 290, Loss: 1.7578
Batch 300, Loss: 1.7578
Batch 310, Loss: 1.7578
Batch 320, Loss: 1.7578
Batch 330, Loss: 1.7578
Batch 340, Loss: 1.7578
Batch 350, Loss: 1.7578
Batch 360, Loss: 1.7578
Batch 370, Loss: 1.7578
Batch 380, Loss: 1.7578
Batch 390, Loss: 1.7578
Epoch 200 learning rate: 0.0
Epoch 200 time: 118.74018573760986 seconds
Epoch 200 accuracy: 10.0%
Total training time: 23768.73411798477 seconds
