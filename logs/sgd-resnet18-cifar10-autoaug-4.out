The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 5.0708
Batch 20, Loss: 3.0290
Batch 30, Loss: 2.3362
Batch 40, Loss: 1.8821
Batch 50, Loss: 1.8350
Batch 60, Loss: 1.7765
Batch 70, Loss: 1.7731
Batch 80, Loss: 1.7749
Batch 90, Loss: 1.7653
Batch 100, Loss: 1.7605
Batch 110, Loss: 1.7592
Batch 120, Loss: 1.7675
Batch 130, Loss: 1.7595
Batch 140, Loss: 1.7529
Batch 150, Loss: 1.7476
Batch 160, Loss: 1.7350
Batch 170, Loss: 1.7102
Batch 180, Loss: 1.7173
Batch 190, Loss: 1.7090
Batch 200, Loss: 1.6980
Batch 210, Loss: 1.6848
Batch 220, Loss: 1.6708
Batch 230, Loss: 1.6702
Batch 240, Loss: 1.6630
Batch 250, Loss: 1.6443
Batch 260, Loss: 1.6328
Batch 270, Loss: 1.6569
Batch 280, Loss: 1.6379
Batch 290, Loss: 1.6268
Batch 300, Loss: 1.6113
Batch 310, Loss: 1.6000
Batch 320, Loss: 1.6164
Batch 330, Loss: 1.5814
Batch 340, Loss: 1.5987
Batch 350, Loss: 1.6094
Batch 360, Loss: 1.5979
Batch 370, Loss: 1.5908
Batch 380, Loss: 1.5892
Batch 390, Loss: 1.6095
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.828487396240234 seconds
Epoch 1 accuracy: 19.3%
Batch 10, Loss: 1.6006
Batch 20, Loss: 1.5903
Batch 30, Loss: 1.5998
Batch 40, Loss: 1.6156
Batch 50, Loss: 1.5862
Batch 60, Loss: 1.5681
Batch 70, Loss: 1.5612
Batch 80, Loss: 1.5701
Batch 90, Loss: 1.5942
Batch 100, Loss: 1.5744
Batch 110, Loss: 1.5926
Batch 120, Loss: 1.5590
Batch 130, Loss: 1.5751
Batch 140, Loss: 1.5815
Batch 150, Loss: 1.5642
Batch 160, Loss: 1.5488
Batch 170, Loss: 1.5543
Batch 180, Loss: 1.5400
Batch 190, Loss: 1.5416
Batch 200, Loss: 1.5373
Batch 210, Loss: 1.5063
Batch 220, Loss: 1.5266
Batch 230, Loss: 1.5238
Batch 240, Loss: 1.5373
Batch 250, Loss: 1.5302
Batch 260, Loss: 1.5327
Batch 270, Loss: 1.5128
Batch 280, Loss: 1.5130
Batch 290, Loss: 1.5242
Batch 300, Loss: 1.4698
Batch 310, Loss: 1.5129
Batch 320, Loss: 1.5097
Batch 330, Loss: 1.4914
Batch 340, Loss: 1.4909
Batch 350, Loss: 1.5333
Batch 360, Loss: 1.4979
Batch 370, Loss: 1.4832
Batch 380, Loss: 1.5003
Batch 390, Loss: 1.4999
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.159985303878784 seconds
Epoch 2 accuracy: 35.6%
Batch 10, Loss: 1.4735
Batch 20, Loss: 1.4720
Batch 30, Loss: 1.4543
Batch 40, Loss: 1.4452
Batch 50, Loss: 1.4776
Batch 60, Loss: 1.4764
Batch 70, Loss: 1.4645
Batch 80, Loss: 1.4676
Batch 90, Loss: 1.4462
Batch 100, Loss: 1.4477
Batch 110, Loss: 1.4675
Batch 120, Loss: 1.4455
Batch 130, Loss: 1.4349
Batch 140, Loss: 1.4437
Batch 150, Loss: 1.4381
Batch 160, Loss: 1.4248
Batch 170, Loss: 1.4003
Batch 180, Loss: 1.4120
Batch 190, Loss: 1.4585
Batch 200, Loss: 1.4256
Batch 210, Loss: 1.4395
Batch 220, Loss: 1.4344
Batch 230, Loss: 1.4033
Batch 240, Loss: 1.4260
Batch 250, Loss: 1.4118
Batch 260, Loss: 1.4156
Batch 270, Loss: 1.4115
Batch 280, Loss: 1.3869
Batch 290, Loss: 1.3353
Batch 300, Loss: 1.3533
Batch 310, Loss: 1.3588
Batch 320, Loss: 1.3724
Batch 330, Loss: 1.3819
Batch 340, Loss: 1.3750
Batch 350, Loss: 1.3746
Batch 360, Loss: 1.3741
Batch 370, Loss: 1.3384
Batch 380, Loss: 1.3663
Batch 390, Loss: 1.3445
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.25337791442871 seconds
Epoch 3 accuracy: 35.51%
Batch 10, Loss: 1.3686
Batch 20, Loss: 1.3967
Batch 30, Loss: 1.3654
Batch 40, Loss: 1.3440
Batch 50, Loss: 1.3517
Batch 60, Loss: 1.3144
Batch 70, Loss: 1.3235
Batch 80, Loss: 1.3347
Batch 90, Loss: 1.2926
Batch 100, Loss: 1.3650
Batch 110, Loss: 1.2855
Batch 120, Loss: 1.3102
Batch 130, Loss: 1.3640
Batch 140, Loss: 1.3337
Batch 150, Loss: 1.2971
Batch 160, Loss: 1.2828
Batch 170, Loss: 1.2739
Batch 180, Loss: 1.3180
Batch 190, Loss: 1.2792
Batch 200, Loss: 1.2844
Batch 210, Loss: 1.3122
Batch 220, Loss: 1.2695
Batch 230, Loss: 1.2474
Batch 240, Loss: 1.3026
Batch 250, Loss: 1.2869
Batch 260, Loss: 1.2414
Batch 270, Loss: 1.2649
Batch 280, Loss: 1.2938
Batch 290, Loss: 1.2726
Batch 300, Loss: 1.2602
Batch 310, Loss: 1.2034
Batch 320, Loss: 1.2561
Batch 330, Loss: 1.2448
Batch 340, Loss: 1.2355
Batch 350, Loss: 1.2522
Batch 360, Loss: 1.2671
Batch 370, Loss: 1.2527
Batch 380, Loss: 1.2321
Batch 390, Loss: 1.2355
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.15050721168518 seconds
Epoch 4 accuracy: 46.71%
Batch 10, Loss: 1.2201
Batch 20, Loss: 1.2232
Batch 30, Loss: 1.2243
Batch 40, Loss: 1.2276
Batch 50, Loss: 1.2211
Batch 60, Loss: 1.2080
Batch 70, Loss: 1.2147
Batch 80, Loss: 1.2347
Batch 90, Loss: 1.1990
Batch 100, Loss: 1.2048
Batch 110, Loss: 1.1908
Batch 120, Loss: 1.2469
Batch 130, Loss: 1.2052
Batch 140, Loss: 1.2387
Batch 150, Loss: 1.2226
Batch 160, Loss: 1.2044
Batch 170, Loss: 1.1603
Batch 180, Loss: 1.1775
Batch 190, Loss: 1.1302
Batch 200, Loss: 1.1642
Batch 210, Loss: 1.1375
Batch 220, Loss: 1.1213
Batch 230, Loss: 1.1890
Batch 240, Loss: 1.1779
Batch 250, Loss: 1.2139
Batch 260, Loss: 1.1321
Batch 270, Loss: 1.1309
Batch 280, Loss: 1.1999
Batch 290, Loss: 1.1709
Batch 300, Loss: 1.1170
Batch 310, Loss: 1.1361
Batch 320, Loss: 1.2177
Batch 330, Loss: 1.1771
Batch 340, Loss: 1.1606
Batch 350, Loss: 1.1323
Batch 360, Loss: 1.1221
Batch 370, Loss: 1.1979
Batch 380, Loss: 1.1377
Batch 390, Loss: 1.0940
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.23166561126709 seconds
Epoch 5 accuracy: 55.34%
Batch 10, Loss: 1.0938
Batch 20, Loss: 1.1175
Batch 30, Loss: 1.1291
Batch 40, Loss: 1.0943
Batch 50, Loss: 1.1335
Batch 60, Loss: 1.1300
Batch 70, Loss: 1.1272
Batch 80, Loss: 1.1196
Batch 90, Loss: 1.1296
Batch 100, Loss: 1.1232
Batch 110, Loss: 1.1376
Batch 120, Loss: 1.0922
Batch 130, Loss: 1.1243
Batch 140, Loss: 1.1059
Batch 150, Loss: 1.0436
Batch 160, Loss: 1.1329
Batch 170, Loss: 1.1148
Batch 180, Loss: 1.0624
Batch 190, Loss: 1.0723
Batch 200, Loss: 1.0471
Batch 210, Loss: 1.0880
Batch 220, Loss: 1.0596
Batch 230, Loss: 1.0772
Batch 240, Loss: 1.0631
Batch 250, Loss: 1.1090
Batch 260, Loss: 1.0945
Batch 270, Loss: 1.0546
Batch 280, Loss: 1.0431
Batch 290, Loss: 1.0836
Batch 300, Loss: 1.1029
Batch 310, Loss: 1.1050
Batch 320, Loss: 1.0678
Batch 330, Loss: 1.0530
Batch 340, Loss: 1.0338
Batch 350, Loss: 1.0374
Batch 360, Loss: 1.1061
Batch 370, Loss: 1.0899
Batch 380, Loss: 1.0793
Batch 390, Loss: 1.0557
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.208069324493408 seconds
Epoch 6 accuracy: 58.0%
Batch 10, Loss: 1.0592
Batch 20, Loss: 1.0699
Batch 30, Loss: 1.0455
Batch 40, Loss: 1.0645
Batch 50, Loss: 1.0315
Batch 60, Loss: 1.0409
Batch 70, Loss: 1.0399
Batch 80, Loss: 1.0062
Batch 90, Loss: 1.0196
Batch 100, Loss: 1.0278
Batch 110, Loss: 0.9940
Batch 120, Loss: 0.9836
Batch 130, Loss: 1.0284
Batch 140, Loss: 1.0615
Batch 150, Loss: 1.0384
Batch 160, Loss: 1.1024
Batch 170, Loss: 1.0309
Batch 180, Loss: 1.0592
Batch 190, Loss: 1.0199
Batch 200, Loss: 1.0617
Batch 210, Loss: 1.0611
Batch 220, Loss: 1.0019
Batch 230, Loss: 1.0346
Batch 240, Loss: 1.0390
Batch 250, Loss: 1.0466
Batch 260, Loss: 1.0478
Batch 270, Loss: 1.0865
Batch 280, Loss: 0.9920
Batch 290, Loss: 0.9688
Batch 300, Loss: 1.0041
Batch 310, Loss: 0.9855
Batch 320, Loss: 0.9952
Batch 330, Loss: 0.9612
Batch 340, Loss: 1.0411
Batch 350, Loss: 0.9674
Batch 360, Loss: 1.0369
Batch 370, Loss: 1.0432
Batch 380, Loss: 1.0163
Batch 390, Loss: 0.9776
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.150668621063232 seconds
Epoch 7 accuracy: 59.6%
Batch 10, Loss: 0.9974
Batch 20, Loss: 0.9808
Batch 30, Loss: 1.0426
Batch 40, Loss: 0.9810
Batch 50, Loss: 0.9375
Batch 60, Loss: 0.9847
Batch 70, Loss: 0.9964
Batch 80, Loss: 0.9756
Batch 90, Loss: 1.0452
Batch 100, Loss: 1.0125
Batch 110, Loss: 1.0035
Batch 120, Loss: 1.0183
Batch 130, Loss: 0.9785
Batch 140, Loss: 0.9830
Batch 150, Loss: 0.9442
Batch 160, Loss: 0.9527
Batch 170, Loss: 0.9975
Batch 180, Loss: 0.9601
Batch 190, Loss: 0.9927
Batch 200, Loss: 0.9709
Batch 210, Loss: 0.9664
Batch 220, Loss: 0.9590
Batch 230, Loss: 1.0008
Batch 240, Loss: 0.9727
Batch 250, Loss: 0.8876
Batch 260, Loss: 0.9249
Batch 270, Loss: 0.9328
Batch 280, Loss: 0.9896
Batch 290, Loss: 0.9552
Batch 300, Loss: 0.9472
Batch 310, Loss: 0.9391
Batch 320, Loss: 0.9662
Batch 330, Loss: 0.9785
Batch 340, Loss: 0.9596
Batch 350, Loss: 0.9938
Batch 360, Loss: 0.9383
Batch 370, Loss: 0.9241
Batch 380, Loss: 0.9254
Batch 390, Loss: 0.9394
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.176228284835815 seconds
Epoch 8 accuracy: 54.87%
Batch 10, Loss: 0.9136
Batch 20, Loss: 0.9463
Batch 30, Loss: 0.9311
Batch 40, Loss: 0.9131
Batch 50, Loss: 0.9494
Batch 60, Loss: 0.9752
Batch 70, Loss: 0.9560
Batch 80, Loss: 0.9611
Batch 90, Loss: 0.9260
Batch 100, Loss: 0.9569
Batch 110, Loss: 0.9447
Batch 120, Loss: 0.9260
Batch 130, Loss: 0.9259
Batch 140, Loss: 0.9367
Batch 150, Loss: 0.9038
Batch 160, Loss: 0.9340
Batch 170, Loss: 0.9090
Batch 180, Loss: 0.9648
Batch 190, Loss: 0.9003
Batch 200, Loss: 0.9338
Batch 210, Loss: 0.9195
Batch 220, Loss: 0.9119
Batch 230, Loss: 0.9206
Batch 240, Loss: 0.9356
Batch 250, Loss: 0.9409
Batch 260, Loss: 0.9449
Batch 270, Loss: 0.8584
Batch 280, Loss: 0.8907
Batch 290, Loss: 0.9218
Batch 300, Loss: 0.9101
Batch 310, Loss: 0.9020
Batch 320, Loss: 0.8971
Batch 330, Loss: 0.9492
Batch 340, Loss: 0.8885
Batch 350, Loss: 0.9144
Batch 360, Loss: 0.9393
Batch 370, Loss: 0.8704
Batch 380, Loss: 0.9198
Batch 390, Loss: 0.8552
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.267008781433105 seconds
Epoch 9 accuracy: 65.45%
Batch 10, Loss: 0.8831
Batch 20, Loss: 0.8742
Batch 30, Loss: 0.8769
Batch 40, Loss: 0.8699
Batch 50, Loss: 0.8949
Batch 60, Loss: 0.9115
Batch 70, Loss: 0.9529
Batch 80, Loss: 0.8787
Batch 90, Loss: 0.8852
Batch 100, Loss: 0.9369
Batch 110, Loss: 0.9395
Batch 120, Loss: 0.8607
Batch 130, Loss: 0.8721
Batch 140, Loss: 0.9014
Batch 150, Loss: 0.8585
Batch 160, Loss: 0.9092
Batch 170, Loss: 0.8912
Batch 180, Loss: 0.8815
Batch 190, Loss: 0.8713
Batch 200, Loss: 0.8671
Batch 210, Loss: 0.8715
Batch 220, Loss: 0.8528
Batch 230, Loss: 0.8938
Batch 240, Loss: 0.8663
Batch 250, Loss: 0.8412
Batch 260, Loss: 0.8828
Batch 270, Loss: 0.8679
Batch 280, Loss: 0.8697
Batch 290, Loss: 0.8752
Batch 300, Loss: 0.8715
Batch 310, Loss: 0.8524
Batch 320, Loss: 0.8923
Batch 330, Loss: 0.8808
Batch 340, Loss: 0.8612
Batch 350, Loss: 0.8358
Batch 360, Loss: 0.8686
Batch 370, Loss: 0.8724
Batch 380, Loss: 0.8364
Batch 390, Loss: 0.8172
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.251039266586304 seconds
Epoch 10 accuracy: 65.66%
Batch 10, Loss: 0.8542
Batch 20, Loss: 0.8556
Batch 30, Loss: 0.8455
Batch 40, Loss: 0.8341
Batch 50, Loss: 0.8329
Batch 60, Loss: 0.8658
Batch 70, Loss: 0.8457
Batch 80, Loss: 0.8162
Batch 90, Loss: 0.8120
Batch 100, Loss: 0.8596
Batch 110, Loss: 0.8366
Batch 120, Loss: 0.8918
Batch 130, Loss: 0.8793
Batch 140, Loss: 0.9154
Batch 150, Loss: 0.8382
Batch 160, Loss: 0.8405
Batch 170, Loss: 0.8237
Batch 180, Loss: 0.8700
Batch 190, Loss: 0.8387
Batch 200, Loss: 0.8444
Batch 210, Loss: 0.9009
Batch 220, Loss: 0.8066
Batch 230, Loss: 0.8049
Batch 240, Loss: 0.8011
Batch 250, Loss: 0.8094
Batch 260, Loss: 0.8292
Batch 270, Loss: 0.8273
Batch 280, Loss: 0.7988
Batch 290, Loss: 0.7938
Batch 300, Loss: 0.7922
Batch 310, Loss: 0.8016
Batch 320, Loss: 0.8472
Batch 330, Loss: 0.8514
Batch 340, Loss: 0.8340
Batch 350, Loss: 0.8140
Batch 360, Loss: 0.7940
Batch 370, Loss: 0.7842
Batch 380, Loss: 0.7801
Batch 390, Loss: 0.8022
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.117462158203125 seconds
Epoch 11 accuracy: 67.67%
Batch 10, Loss: 0.8004
Batch 20, Loss: 0.8013
Batch 30, Loss: 0.8383
Batch 40, Loss: 0.7912
Batch 50, Loss: 0.8291
Batch 60, Loss: 0.8319
Batch 70, Loss: 0.8222
Batch 80, Loss: 0.8144
Batch 90, Loss: 0.8081
Batch 100, Loss: 0.8005
Batch 110, Loss: 0.7951
Batch 120, Loss: 0.7790
Batch 130, Loss: 0.8301
Batch 140, Loss: 0.8265
Batch 150, Loss: 0.8322
Batch 160, Loss: 0.8291
Batch 170, Loss: 0.7736
Batch 180, Loss: 0.7718
Batch 190, Loss: 0.7488
Batch 200, Loss: 0.7663
Batch 210, Loss: 0.7979
Batch 220, Loss: 0.8134
Batch 230, Loss: 0.7984
Batch 240, Loss: 0.7889
Batch 250, Loss: 0.8007
Batch 260, Loss: 0.8118
Batch 270, Loss: 0.8214
Batch 280, Loss: 0.7800
Batch 290, Loss: 0.7658
Batch 300, Loss: 0.7934
Batch 310, Loss: 0.7920
Batch 320, Loss: 0.8349
Batch 330, Loss: 0.8151
Batch 340, Loss: 0.8043
Batch 350, Loss: 0.7678
Batch 360, Loss: 0.7606
Batch 370, Loss: 0.7893
Batch 380, Loss: 0.7656
Batch 390, Loss: 0.7777
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.207823038101196 seconds
Epoch 12 accuracy: 74.95%
Batch 10, Loss: 0.7931
Batch 20, Loss: 0.8191
Batch 30, Loss: 0.8083
Batch 40, Loss: 0.7710
Batch 50, Loss: 0.7707
Batch 60, Loss: 0.7862
Batch 70, Loss: 0.7974
Batch 80, Loss: 0.8165
Batch 90, Loss: 0.7605
Batch 100, Loss: 0.7969
Batch 110, Loss: 0.8064
Batch 120, Loss: 0.7923
Batch 130, Loss: 0.7877
Batch 140, Loss: 0.7701
Batch 150, Loss: 0.7964
Batch 160, Loss: 0.7848
Batch 170, Loss: 0.8227
Batch 180, Loss: 0.7550
Batch 190, Loss: 0.7458
Batch 200, Loss: 0.7803
Batch 210, Loss: 0.8007
Batch 220, Loss: 0.7767
Batch 230, Loss: 0.7574
Batch 240, Loss: 0.7649
Batch 250, Loss: 0.7676
Batch 260, Loss: 0.7962
Batch 270, Loss: 0.7917
Batch 280, Loss: 0.7502
Batch 290, Loss: 0.7707
Batch 300, Loss: 0.7326
Batch 310, Loss: 0.7687
Batch 320, Loss: 0.7577
Batch 330, Loss: 0.8085
Batch 340, Loss: 0.7835
Batch 350, Loss: 0.7709
Batch 360, Loss: 0.7806
Batch 370, Loss: 0.7677
Batch 380, Loss: 0.7484
Batch 390, Loss: 0.7728
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.24772620201111 seconds
Epoch 13 accuracy: 75.23%
Batch 10, Loss: 0.7707
Batch 20, Loss: 0.7966
Batch 30, Loss: 0.7331
Batch 40, Loss: 0.7742
Batch 50, Loss: 0.7527
Batch 60, Loss: 0.7440
Batch 70, Loss: 0.7437
Batch 80, Loss: 0.7183
Batch 90, Loss: 0.7492
Batch 100, Loss: 0.7617
Batch 110, Loss: 0.7862
Batch 120, Loss: 0.7385
Batch 130, Loss: 0.7766
Batch 140, Loss: 0.7577
Batch 150, Loss: 0.7697
Batch 160, Loss: 0.7423
Batch 170, Loss: 0.7583
Batch 180, Loss: 0.6825
Batch 190, Loss: 0.7853
Batch 200, Loss: 0.7245
Batch 210, Loss: 0.7317
Batch 220, Loss: 0.7911
Batch 230, Loss: 0.8091
Batch 240, Loss: 0.7618
Batch 250, Loss: 0.7303
Batch 260, Loss: 0.7657
Batch 270, Loss: 0.7718
Batch 280, Loss: 0.7419
Batch 290, Loss: 0.7377
Batch 300, Loss: 0.7873
Batch 310, Loss: 0.7867
Batch 320, Loss: 0.7123
Batch 330, Loss: 0.7573
Batch 340, Loss: 0.7837
Batch 350, Loss: 0.7665
Batch 360, Loss: 0.7397
Batch 370, Loss: 0.7013
Batch 380, Loss: 0.7274
Batch 390, Loss: 0.7321
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.262863397598267 seconds
Epoch 14 accuracy: 74.42%
Batch 10, Loss: 0.7008
Batch 20, Loss: 0.7505
Batch 30, Loss: 0.7363
Batch 40, Loss: 0.7438
Batch 50, Loss: 0.7724
Batch 60, Loss: 0.7650
Batch 70, Loss: 0.7323
Batch 80, Loss: 0.7563
Batch 90, Loss: 0.7104
Batch 100, Loss: 0.7557
Batch 110, Loss: 0.7334
Batch 120, Loss: 0.7805
Batch 130, Loss: 0.7172
Batch 140, Loss: 0.7011
Batch 150, Loss: 0.7188
Batch 160, Loss: 0.7159
Batch 170, Loss: 0.7170
Batch 180, Loss: 0.7536
Batch 190, Loss: 0.7146
Batch 200, Loss: 0.7456
Batch 210, Loss: 0.7337
Batch 220, Loss: 0.7687
Batch 230, Loss: 0.7561
Batch 240, Loss: 0.7536
Batch 250, Loss: 0.7087
Batch 260, Loss: 0.7003
Batch 270, Loss: 0.7203
Batch 280, Loss: 0.7604
Batch 290, Loss: 0.7301
Batch 300, Loss: 0.7175
Batch 310, Loss: 0.7729
Batch 320, Loss: 0.6806
Batch 330, Loss: 0.7272
Batch 340, Loss: 0.6964
Batch 350, Loss: 0.6993
Batch 360, Loss: 0.7622
Batch 370, Loss: 0.7315
Batch 380, Loss: 0.7303
Batch 390, Loss: 0.7469
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.233935356140137 seconds
Epoch 15 accuracy: 61.93%
Batch 10, Loss: 0.7818
Batch 20, Loss: 0.7475
Batch 30, Loss: 0.7259
Batch 40, Loss: 0.7471
Batch 50, Loss: 0.7386
Batch 60, Loss: 0.7451
Batch 70, Loss: 0.7299
Batch 80, Loss: 0.6944
Batch 90, Loss: 0.6849
Batch 100, Loss: 0.7525
Batch 110, Loss: 0.7143
Batch 120, Loss: 0.7209
Batch 130, Loss: 0.7481
Batch 140, Loss: 0.7549
Batch 150, Loss: 0.7375
Batch 160, Loss: 0.7268
Batch 170, Loss: 0.6782
Batch 180, Loss: 0.6894
Batch 190, Loss: 0.7406
Batch 200, Loss: 0.7515
Batch 210, Loss: 0.7089
Batch 220, Loss: 0.6991
Batch 230, Loss: 0.6848
Batch 240, Loss: 0.6881
Batch 250, Loss: 0.7348
Batch 260, Loss: 0.7295
Batch 270, Loss: 0.7125
Batch 280, Loss: 0.6811
Batch 290, Loss: 0.7128
Batch 300, Loss: 0.6950
Batch 310, Loss: 0.7066
Batch 320, Loss: 0.7147
Batch 330, Loss: 0.7103
Batch 340, Loss: 0.7060
Batch 350, Loss: 0.7344
Batch 360, Loss: 0.7400
Batch 370, Loss: 0.6925
Batch 380, Loss: 0.6850
Batch 390, Loss: 0.6781
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.116121768951416 seconds
Epoch 16 accuracy: 75.97%
Batch 10, Loss: 0.6771
Batch 20, Loss: 0.7268
Batch 30, Loss: 0.7261
Batch 40, Loss: 0.7038
Batch 50, Loss: 0.7006
Batch 60, Loss: 0.6789
Batch 70, Loss: 0.7114
Batch 80, Loss: 0.6766
Batch 90, Loss: 0.7232
Batch 100, Loss: 0.6968
Batch 110, Loss: 0.6972
Batch 120, Loss: 0.7022
Batch 130, Loss: 0.6880
Batch 140, Loss: 0.7254
Batch 150, Loss: 0.7045
Batch 160, Loss: 0.6584
Batch 170, Loss: 0.7424
Batch 180, Loss: 0.7106
Batch 190, Loss: 0.7106
Batch 200, Loss: 0.7018
Batch 210, Loss: 0.6480
Batch 220, Loss: 0.7040
Batch 230, Loss: 0.7092
Batch 240, Loss: 0.7385
Batch 250, Loss: 0.7274
Batch 260, Loss: 0.7290
Batch 270, Loss: 0.7321
Batch 280, Loss: 0.7359
Batch 290, Loss: 0.6924
Batch 300, Loss: 0.7169
Batch 310, Loss: 0.6975
Batch 320, Loss: 0.6929
Batch 330, Loss: 0.7201
Batch 340, Loss: 0.7008
Batch 350, Loss: 0.7268
Batch 360, Loss: 0.6724
Batch 370, Loss: 0.6718
Batch 380, Loss: 0.7019
Batch 390, Loss: 0.7018
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.163915157318115 seconds
Epoch 17 accuracy: 76.62%
Batch 10, Loss: 0.7067
Batch 20, Loss: 0.7466
Batch 30, Loss: 0.6783
Batch 40, Loss: 0.6729
Batch 50, Loss: 0.6755
Batch 60, Loss: 0.7114
Batch 70, Loss: 0.6758
Batch 80, Loss: 0.7100
Batch 90, Loss: 0.6837
Batch 100, Loss: 0.7137
Batch 110, Loss: 0.6918
Batch 120, Loss: 0.7248
Batch 130, Loss: 0.6908
Batch 140, Loss: 0.6876
Batch 150, Loss: 0.7110
Batch 160, Loss: 0.7070
Batch 170, Loss: 0.7285
Batch 180, Loss: 0.7207
Batch 190, Loss: 0.6660
Batch 200, Loss: 0.7206
Batch 210, Loss: 0.7447
Batch 220, Loss: 0.6803
Batch 230, Loss: 0.7335
Batch 240, Loss: 0.6742
Batch 250, Loss: 0.6837
Batch 260, Loss: 0.7075
Batch 270, Loss: 0.7024
Batch 280, Loss: 0.7154
Batch 290, Loss: 0.6611
Batch 300, Loss: 0.6535
Batch 310, Loss: 0.7008
Batch 320, Loss: 0.6644
Batch 330, Loss: 0.6784
Batch 340, Loss: 0.7039
Batch 350, Loss: 0.6779
Batch 360, Loss: 0.7289
Batch 370, Loss: 0.7032
Batch 380, Loss: 0.6247
Batch 390, Loss: 0.6962
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.248271703720093 seconds
Epoch 18 accuracy: 76.77%
Batch 10, Loss: 0.6513
Batch 20, Loss: 0.7344
Batch 30, Loss: 0.6934
Batch 40, Loss: 0.6826
Batch 50, Loss: 0.6894
Batch 60, Loss: 0.6589
Batch 70, Loss: 0.6613
Batch 80, Loss: 0.6811
Batch 90, Loss: 0.7201
Batch 100, Loss: 0.6718
Batch 110, Loss: 0.6813
Batch 120, Loss: 0.6724
Batch 130, Loss: 0.6690
Batch 140, Loss: 0.7146
Batch 150, Loss: 0.6999
Batch 160, Loss: 0.7051
Batch 170, Loss: 0.6969
Batch 180, Loss: 0.6927
Batch 190, Loss: 0.6837
Batch 200, Loss: 0.6550
Batch 210, Loss: 0.6807
Batch 220, Loss: 0.6546
Batch 230, Loss: 0.6573
Batch 240, Loss: 0.6745
Batch 250, Loss: 0.6344
Batch 260, Loss: 0.6781
Batch 270, Loss: 0.6640
Batch 280, Loss: 0.6606
Batch 290, Loss: 0.6677
Batch 300, Loss: 0.6366
Batch 310, Loss: 0.6583
Batch 320, Loss: 0.6726
Batch 330, Loss: 0.6625
Batch 340, Loss: 0.7009
Batch 350, Loss: 0.6911
Batch 360, Loss: 0.6910
Batch 370, Loss: 0.6669
Batch 380, Loss: 0.7241
Batch 390, Loss: 0.7037
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.225806713104248 seconds
Epoch 19 accuracy: 71.96%
Batch 10, Loss: 0.6556
Batch 20, Loss: 0.6993
Batch 30, Loss: 0.6599
Batch 40, Loss: 0.6209
Batch 50, Loss: 0.6441
Batch 60, Loss: 0.6990
Batch 70, Loss: 0.7145
Batch 80, Loss: 0.6797
Batch 90, Loss: 0.6620
Batch 100, Loss: 0.6939
Batch 110, Loss: 0.6708
Batch 120, Loss: 0.6825
Batch 130, Loss: 0.7082
Batch 140, Loss: 0.6936
Batch 150, Loss: 0.6251
Batch 160, Loss: 0.6614
Batch 170, Loss: 0.6399
Batch 180, Loss: 0.6339
Batch 190, Loss: 0.6829
Batch 200, Loss: 0.6708
Batch 210, Loss: 0.6560
Batch 220, Loss: 0.6641
Batch 230, Loss: 0.6574
Batch 240, Loss: 0.6601
Batch 250, Loss: 0.6713
Batch 260, Loss: 0.6532
Batch 270, Loss: 0.6849
Batch 280, Loss: 0.6774
Batch 290, Loss: 0.6999
Batch 300, Loss: 0.6649
Batch 310, Loss: 0.6295
Batch 320, Loss: 0.6635
Batch 330, Loss: 0.6540
Batch 340, Loss: 0.6822
Batch 350, Loss: 0.6727
Batch 360, Loss: 0.6930
Batch 370, Loss: 0.6130
Batch 380, Loss: 0.6294
Batch 390, Loss: 0.6456
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.05381679534912 seconds
Epoch 20 accuracy: 79.48%
Batch 10, Loss: 0.6298
Batch 20, Loss: 0.6624
Batch 30, Loss: 0.6439
Batch 40, Loss: 0.6387
Batch 50, Loss: 0.6562
Batch 60, Loss: 0.6961
Batch 70, Loss: 0.6997
Batch 80, Loss: 0.6500
Batch 90, Loss: 0.6681
Batch 100, Loss: 0.6041
Batch 110, Loss: 0.6066
Batch 120, Loss: 0.6186
Batch 130, Loss: 0.6461
Batch 140, Loss: 0.6702
Batch 150, Loss: 0.6761
Batch 160, Loss: 0.7277
Batch 170, Loss: 0.6770
Batch 180, Loss: 0.6066
Batch 190, Loss: 0.6344
Batch 200, Loss: 0.6529
Batch 210, Loss: 0.6754
Batch 220, Loss: 0.6185
Batch 230, Loss: 0.6483
Batch 240, Loss: 0.6663
Batch 250, Loss: 0.6599
Batch 260, Loss: 0.6690
Batch 270, Loss: 0.6468
Batch 280, Loss: 0.6801
Batch 290, Loss: 0.6534
Batch 300, Loss: 0.6451
Batch 310, Loss: 0.6443
Batch 320, Loss: 0.6298
Batch 330, Loss: 0.6513
Batch 340, Loss: 0.6463
Batch 350, Loss: 0.6455
Batch 360, Loss: 0.6951
Batch 370, Loss: 0.6922
Batch 380, Loss: 0.6561
Batch 390, Loss: 0.6406
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.297857999801636 seconds
Epoch 21 accuracy: 77.87%
Batch 10, Loss: 0.6430
Batch 20, Loss: 0.6757
Batch 30, Loss: 0.6504
Batch 40, Loss: 0.6445
Batch 50, Loss: 0.6247
Batch 60, Loss: 0.6515
Batch 70, Loss: 0.6313
Batch 80, Loss: 0.6411
Batch 90, Loss: 0.6517
Batch 100, Loss: 0.6493
Batch 110, Loss: 0.6678
Batch 120, Loss: 0.6442
Batch 130, Loss: 0.6615
Batch 140, Loss: 0.6305
Batch 150, Loss: 0.6472
Batch 160, Loss: 0.6800
Batch 170, Loss: 0.6836
Batch 180, Loss: 0.6518
Batch 190, Loss: 0.6717
Batch 200, Loss: 0.6416
Batch 210, Loss: 0.6421
Batch 220, Loss: 0.6870
Batch 230, Loss: 0.6668
Batch 240, Loss: 0.6039
Batch 250, Loss: 0.6576
Batch 260, Loss: 0.6481
Batch 270, Loss: 0.6234
Batch 280, Loss: 0.6216
Batch 290, Loss: 0.6259
Batch 300, Loss: 0.6734
Batch 310, Loss: 0.6544
Batch 320, Loss: 0.6710
Batch 330, Loss: 0.6527
Batch 340, Loss: 0.5816
Batch 350, Loss: 0.6727
Batch 360, Loss: 0.6829
Batch 370, Loss: 0.6780
Batch 380, Loss: 0.6789
Batch 390, Loss: 0.6287
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.128705501556396 seconds
Epoch 22 accuracy: 79.0%
Batch 10, Loss: 0.6247
Batch 20, Loss: 0.6638
Batch 30, Loss: 0.6346
Batch 40, Loss: 0.6580
Batch 50, Loss: 0.6299
Batch 60, Loss: 0.6455
Batch 70, Loss: 0.6443
Batch 80, Loss: 0.6219
Batch 90, Loss: 0.6327
Batch 100, Loss: 0.6322
Batch 110, Loss: 0.6355
Batch 120, Loss: 0.6366
Batch 130, Loss: 0.6641
Batch 140, Loss: 0.6617
Batch 150, Loss: 0.6491
Batch 160, Loss: 0.6700
Batch 170, Loss: 0.6136
Batch 180, Loss: 0.6465
Batch 190, Loss: 0.6448
Batch 200, Loss: 0.5851
Batch 210, Loss: 0.6246
Batch 220, Loss: 0.6014
Batch 230, Loss: 0.6491
Batch 240, Loss: 0.6398
Batch 250, Loss: 0.6111
Batch 260, Loss: 0.6541
Batch 270, Loss: 0.6391
Batch 280, Loss: 0.6801
Batch 290, Loss: 0.6677
Batch 300, Loss: 0.6578
Batch 310, Loss: 0.6539
Batch 320, Loss: 0.6279
Batch 330, Loss: 0.6396
Batch 340, Loss: 0.6052
Batch 350, Loss: 0.6448
Batch 360, Loss: 0.6786
Batch 370, Loss: 0.6635
Batch 380, Loss: 0.6309
Batch 390, Loss: 0.6326
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.1434543132782 seconds
Epoch 23 accuracy: 79.25%
Batch 10, Loss: 0.6341
Batch 20, Loss: 0.6892
Batch 30, Loss: 0.6601
Batch 40, Loss: 0.6333
Batch 50, Loss: 0.6425
Batch 60, Loss: 0.6665
Batch 70, Loss: 0.6224
Batch 80, Loss: 0.6049
Batch 90, Loss: 0.6466
Batch 100, Loss: 0.6111
Batch 110, Loss: 0.6659
Batch 120, Loss: 0.6194
Batch 130, Loss: 0.6420
Batch 140, Loss: 0.6348
Batch 150, Loss: 0.6506
Batch 160, Loss: 0.6018
Batch 170, Loss: 0.5919
Batch 180, Loss: 0.6379
Batch 190, Loss: 0.6695
Batch 200, Loss: 0.6251
Batch 210, Loss: 0.6480
Batch 220, Loss: 0.6639
Batch 230, Loss: 0.6443
Batch 240, Loss: 0.5972
Batch 250, Loss: 0.6283
Batch 260, Loss: 0.5992
Batch 270, Loss: 0.5790
Batch 280, Loss: 0.6326
Batch 290, Loss: 0.6383
Batch 300, Loss: 0.6342
Batch 310, Loss: 0.6626
Batch 320, Loss: 0.6305
Batch 330, Loss: 0.6161
Batch 340, Loss: 0.6631
Batch 350, Loss: 0.6508
Batch 360, Loss: 0.6684
Batch 370, Loss: 0.6190
Batch 380, Loss: 0.6059
Batch 390, Loss: 0.5813
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.155383348464966 seconds
Epoch 24 accuracy: 79.27%
Batch 10, Loss: 0.6348
Batch 20, Loss: 0.6564
Batch 30, Loss: 0.6011
Batch 40, Loss: 0.6176
Batch 50, Loss: 0.6202
Batch 60, Loss: 0.6050
Batch 70, Loss: 0.6242
Batch 80, Loss: 0.6229
Batch 90, Loss: 0.6123
Batch 100, Loss: 0.6749
Batch 110, Loss: 0.6566
Batch 120, Loss: 0.6409
Batch 130, Loss: 0.6772
Batch 140, Loss: 0.6216
Batch 150, Loss: 0.6507
Batch 160, Loss: 0.5924
Batch 170, Loss: 0.5952
Batch 180, Loss: 0.6291
Batch 190, Loss: 0.6259
Batch 200, Loss: 0.6412
Batch 210, Loss: 0.6034
Batch 220, Loss: 0.6439
Batch 230, Loss: 0.6218
Batch 240, Loss: 0.6392
Batch 250, Loss: 0.6014
Batch 260, Loss: 0.6135
Batch 270, Loss: 0.6328
Batch 280, Loss: 0.6170
Batch 290, Loss: 0.5916
Batch 300, Loss: 0.6192
Batch 310, Loss: 0.5695
Batch 320, Loss: 0.5896
Batch 330, Loss: 0.5824
Batch 340, Loss: 0.6154
Batch 350, Loss: 0.6282
Batch 360, Loss: 0.6230
Batch 370, Loss: 0.6037
Batch 380, Loss: 0.6360
Batch 390, Loss: 0.6388
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.15158462524414 seconds
Epoch 25 accuracy: 79.59%
Batch 10, Loss: 0.5907
Batch 20, Loss: 0.5808
Batch 30, Loss: 0.6180
Batch 40, Loss: 0.6104
Batch 50, Loss: 0.5959
Batch 60, Loss: 0.6131
Batch 70, Loss: 0.6548
Batch 80, Loss: 0.6762
Batch 90, Loss: 0.6463
Batch 100, Loss: 0.6310
Batch 110, Loss: 0.5957
Batch 120, Loss: 0.6624
Batch 130, Loss: 0.6455
Batch 140, Loss: 0.5938
Batch 150, Loss: 0.5926
Batch 160, Loss: 0.6116
Batch 170, Loss: 0.6280
Batch 180, Loss: 0.6303
Batch 190, Loss: 0.6360
Batch 200, Loss: 0.6182
Batch 210, Loss: 0.6389
Batch 220, Loss: 0.6067
Batch 230, Loss: 0.6271
Batch 240, Loss: 0.6478
Batch 250, Loss: 0.6150
Batch 260, Loss: 0.6498
Batch 270, Loss: 0.6059
Batch 280, Loss: 0.6014
Batch 290, Loss: 0.6241
Batch 300, Loss: 0.6359
Batch 310, Loss: 0.5886
Batch 320, Loss: 0.6219
Batch 330, Loss: 0.5921
Batch 340, Loss: 0.6183
Batch 350, Loss: 0.6082
Batch 360, Loss: 0.6580
Batch 370, Loss: 0.6505
Batch 380, Loss: 0.6463
Batch 390, Loss: 0.6044
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.09711790084839 seconds
Epoch 26 accuracy: 82.13%
Batch 10, Loss: 0.6073
Batch 20, Loss: 0.6120
Batch 30, Loss: 0.6089
Batch 40, Loss: 0.5696
Batch 50, Loss: 0.5982
Batch 60, Loss: 0.6036
Batch 70, Loss: 0.6267
Batch 80, Loss: 0.5916
Batch 90, Loss: 0.6120
Batch 100, Loss: 0.6304
Batch 110, Loss: 0.5950
Batch 120, Loss: 0.6525
Batch 130, Loss: 0.6232
Batch 140, Loss: 0.6181
Batch 150, Loss: 0.6083
Batch 160, Loss: 0.6273
Batch 170, Loss: 0.6148
Batch 180, Loss: 0.6293
Batch 190, Loss: 0.6417
Batch 200, Loss: 0.5885
Batch 210, Loss: 0.6014
Batch 220, Loss: 0.6300
Batch 230, Loss: 0.6411
Batch 240, Loss: 0.5665
Batch 250, Loss: 0.5983
Batch 260, Loss: 0.6340
Batch 270, Loss: 0.6315
Batch 280, Loss: 0.5748
Batch 290, Loss: 0.5959
Batch 300, Loss: 0.5718
Batch 310, Loss: 0.6083
Batch 320, Loss: 0.6322
Batch 330, Loss: 0.6170
Batch 340, Loss: 0.6250
Batch 350, Loss: 0.6169
Batch 360, Loss: 0.6252
Batch 370, Loss: 0.6422
Batch 380, Loss: 0.6885
Batch 390, Loss: 0.6257
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.1339168548584 seconds
Epoch 27 accuracy: 80.06%
Batch 10, Loss: 0.6427
Batch 20, Loss: 0.6020
Batch 30, Loss: 0.6211
Batch 40, Loss: 0.5807
Batch 50, Loss: 0.5917
Batch 60, Loss: 0.5879
Batch 70, Loss: 0.6324
Batch 80, Loss: 0.6363
Batch 90, Loss: 0.5636
Batch 100, Loss: 0.5906
Batch 110, Loss: 0.6111
Batch 120, Loss: 0.5939
Batch 130, Loss: 0.6201
Batch 140, Loss: 0.5962
Batch 150, Loss: 0.5988
Batch 160, Loss: 0.5753
Batch 170, Loss: 0.6126
Batch 180, Loss: 0.5909
Batch 190, Loss: 0.6344
Batch 200, Loss: 0.6345
Batch 210, Loss: 0.6097
Batch 220, Loss: 0.6348
Batch 230, Loss: 0.6180
Batch 240, Loss: 0.6186
Batch 250, Loss: 0.6697
Batch 260, Loss: 0.5920
Batch 270, Loss: 0.5814
Batch 280, Loss: 0.5937
Batch 290, Loss: 0.6124
Batch 300, Loss: 0.6099
Batch 310, Loss: 0.6158
Batch 320, Loss: 0.6275
Batch 330, Loss: 0.5828
Batch 340, Loss: 0.5676
Batch 350, Loss: 0.5878
Batch 360, Loss: 0.5811
Batch 370, Loss: 0.6421
Batch 380, Loss: 0.5878
Batch 390, Loss: 0.6346
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.134094953536987 seconds
Epoch 28 accuracy: 73.51%
Batch 10, Loss: 0.5760
Batch 20, Loss: 0.6091
Batch 30, Loss: 0.5718
Batch 40, Loss: 0.6195
Batch 50, Loss: 0.6028
Batch 60, Loss: 0.6035
Batch 70, Loss: 0.6032
Batch 80, Loss: 0.5948
Batch 90, Loss: 0.6366
Batch 100, Loss: 0.5849
Batch 110, Loss: 0.6200
Batch 120, Loss: 0.6246
Batch 130, Loss: 0.6193
Batch 140, Loss: 0.5956
Batch 150, Loss: 0.5972
Batch 160, Loss: 0.5863
Batch 170, Loss: 0.5959
Batch 180, Loss: 0.5970
Batch 190, Loss: 0.6016
Batch 200, Loss: 0.6184
Batch 210, Loss: 0.6124
Batch 220, Loss: 0.6033
Batch 230, Loss: 0.6052
Batch 240, Loss: 0.5941
Batch 250, Loss: 0.5803
Batch 260, Loss: 0.6298
Batch 270, Loss: 0.6229
Batch 280, Loss: 0.6362
Batch 290, Loss: 0.6420
Batch 300, Loss: 0.5778
Batch 310, Loss: 0.6146
Batch 320, Loss: 0.6091
Batch 330, Loss: 0.5912
Batch 340, Loss: 0.6078
Batch 350, Loss: 0.5922
Batch 360, Loss: 0.5913
Batch 370, Loss: 0.6106
Batch 380, Loss: 0.5838
Batch 390, Loss: 0.5792
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.157748460769653 seconds
Epoch 29 accuracy: 75.91%
Batch 10, Loss: 0.5903
Batch 20, Loss: 0.5612
Batch 30, Loss: 0.6314
Batch 40, Loss: 0.5988
Batch 50, Loss: 0.6055
Batch 60, Loss: 0.6100
Batch 70, Loss: 0.6360
Batch 80, Loss: 0.6241
Batch 90, Loss: 0.5963
Batch 100, Loss: 0.6109
Batch 110, Loss: 0.6339
Batch 120, Loss: 0.5910
Batch 130, Loss: 0.6237
Batch 140, Loss: 0.5630
Batch 150, Loss: 0.6066
Batch 160, Loss: 0.5770
Batch 170, Loss: 0.6051
Batch 180, Loss: 0.6364
Batch 190, Loss: 0.5761
Batch 200, Loss: 0.5542
Batch 210, Loss: 0.5842
Batch 220, Loss: 0.6158
Batch 230, Loss: 0.6058
Batch 240, Loss: 0.5657
Batch 250, Loss: 0.5912
Batch 260, Loss: 0.6388
Batch 270, Loss: 0.5865
Batch 280, Loss: 0.5899
Batch 290, Loss: 0.5801
Batch 300, Loss: 0.5767
Batch 310, Loss: 0.6067
Batch 320, Loss: 0.5793
Batch 330, Loss: 0.6165
Batch 340, Loss: 0.6131
Batch 350, Loss: 0.6354
Batch 360, Loss: 0.6250
Batch 370, Loss: 0.6282
Batch 380, Loss: 0.5853
Batch 390, Loss: 0.6256
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.198643684387207 seconds
Epoch 30 accuracy: 79.74%
Batch 10, Loss: 0.6238
Batch 20, Loss: 0.5940
Batch 30, Loss: 0.5831
Batch 40, Loss: 0.5981
Batch 50, Loss: 0.5763
Batch 60, Loss: 0.6023
Batch 70, Loss: 0.5519
Batch 80, Loss: 0.5578
Batch 90, Loss: 0.6014
Batch 100, Loss: 0.6083
Batch 110, Loss: 0.5736
Batch 120, Loss: 0.5610
Batch 130, Loss: 0.5993
Batch 140, Loss: 0.6007
Batch 150, Loss: 0.6016
Batch 160, Loss: 0.5596
Batch 170, Loss: 0.5714
Batch 180, Loss: 0.5714
Batch 190, Loss: 0.6118
Batch 200, Loss: 0.6126
Batch 210, Loss: 0.5918
Batch 220, Loss: 0.6557
Batch 230, Loss: 0.5849
Batch 240, Loss: 0.6303
Batch 250, Loss: 0.6071
Batch 260, Loss: 0.5925
Batch 270, Loss: 0.5537
Batch 280, Loss: 0.6097
Batch 290, Loss: 0.5704
Batch 300, Loss: 0.6028
Batch 310, Loss: 0.6379
Batch 320, Loss: 0.6111
Batch 330, Loss: 0.5931
Batch 340, Loss: 0.5879
Batch 350, Loss: 0.5954
Batch 360, Loss: 0.6140
Batch 370, Loss: 0.5779
Batch 380, Loss: 0.5512
Batch 390, Loss: 0.6226
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.1137912273407 seconds
Epoch 31 accuracy: 83.54%
Batch 10, Loss: 0.5558
Batch 20, Loss: 0.5975
Batch 30, Loss: 0.5712
Batch 40, Loss: 0.5648
Batch 50, Loss: 0.5915
Batch 60, Loss: 0.6262
Batch 70, Loss: 0.6111
Batch 80, Loss: 0.5734
Batch 90, Loss: 0.6059
Batch 100, Loss: 0.5712
Batch 110, Loss: 0.5981
Batch 120, Loss: 0.5704
Batch 130, Loss: 0.5691
Batch 140, Loss: 0.5755
Batch 150, Loss: 0.6024
Batch 160, Loss: 0.5794
Batch 170, Loss: 0.6164
Batch 180, Loss: 0.5997
Batch 190, Loss: 0.5888
Batch 200, Loss: 0.6541
Batch 210, Loss: 0.5682
Batch 220, Loss: 0.6296
Batch 230, Loss: 0.5503
Batch 240, Loss: 0.5970
Batch 250, Loss: 0.5648
Batch 260, Loss: 0.5838
Batch 270, Loss: 0.6687
Batch 280, Loss: 0.6113
Batch 290, Loss: 0.6536
Batch 300, Loss: 0.6310
Batch 310, Loss: 0.5934
Batch 320, Loss: 0.5871
Batch 330, Loss: 0.6021
Batch 340, Loss: 0.5948
Batch 350, Loss: 0.5772
Batch 360, Loss: 0.5709
Batch 370, Loss: 0.5938
Batch 380, Loss: 0.5550
Batch 390, Loss: 0.6311
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.240883350372314 seconds
Epoch 32 accuracy: 83.02%
Batch 10, Loss: 0.5803
Batch 20, Loss: 0.5937
Batch 30, Loss: 0.5813
Batch 40, Loss: 0.5765
Batch 50, Loss: 0.5867
Batch 60, Loss: 0.5871
Batch 70, Loss: 0.5610
Batch 80, Loss: 0.5554
Batch 90, Loss: 0.6266
Batch 100, Loss: 0.5829
Batch 110, Loss: 0.5760
Batch 120, Loss: 0.5777
Batch 130, Loss: 0.6041
Batch 140, Loss: 0.5588
Batch 150, Loss: 0.6095
Batch 160, Loss: 0.5931
Batch 170, Loss: 0.5991
Batch 180, Loss: 0.5826
Batch 190, Loss: 0.5566
Batch 200, Loss: 0.6217
Batch 210, Loss: 0.6162
Batch 220, Loss: 0.5970
Batch 230, Loss: 0.6241
Batch 240, Loss: 0.6104
Batch 250, Loss: 0.6008
Batch 260, Loss: 0.6148
Batch 270, Loss: 0.5806
Batch 280, Loss: 0.5835
Batch 290, Loss: 0.5918
Batch 300, Loss: 0.5610
Batch 310, Loss: 0.5775
Batch 320, Loss: 0.6001
Batch 330, Loss: 0.5744
Batch 340, Loss: 0.6131
Batch 350, Loss: 0.5969
Batch 360, Loss: 0.5628
Batch 370, Loss: 0.6250
Batch 380, Loss: 0.5890
Batch 390, Loss: 0.5781
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.25108790397644 seconds
Epoch 33 accuracy: 81.78%
Batch 10, Loss: 0.5671
Batch 20, Loss: 0.5544
Batch 30, Loss: 0.5972
Batch 40, Loss: 0.5860
Batch 50, Loss: 0.5967
Batch 60, Loss: 0.5553
Batch 70, Loss: 0.5206
Batch 80, Loss: 0.5723
Batch 90, Loss: 0.5992
Batch 100, Loss: 0.5734
Batch 110, Loss: 0.5832
Batch 120, Loss: 0.6059
Batch 130, Loss: 0.5968
Batch 140, Loss: 0.5593
Batch 150, Loss: 0.5415
Batch 160, Loss: 0.5554
Batch 170, Loss: 0.5620
Batch 180, Loss: 0.5448
Batch 190, Loss: 0.5768
Batch 200, Loss: 0.6022
Batch 210, Loss: 0.5792
Batch 220, Loss: 0.5456
Batch 230, Loss: 0.5842
Batch 240, Loss: 0.6046
Batch 250, Loss: 0.5364
Batch 260, Loss: 0.6240
Batch 270, Loss: 0.6088
Batch 280, Loss: 0.5974
Batch 290, Loss: 0.6192
Batch 300, Loss: 0.5876
Batch 310, Loss: 0.6073
Batch 320, Loss: 0.6263
Batch 330, Loss: 0.5957
Batch 340, Loss: 0.5920
Batch 350, Loss: 0.5898
Batch 360, Loss: 0.6106
Batch 370, Loss: 0.5946
Batch 380, Loss: 0.5839
Batch 390, Loss: 0.6019
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.09111213684082 seconds
Epoch 34 accuracy: 76.22%
Batch 10, Loss: 0.5524
Batch 20, Loss: 0.5797
Batch 30, Loss: 0.5897
Batch 40, Loss: 0.6076
Batch 50, Loss: 0.5925
Batch 60, Loss: 0.5703
Batch 70, Loss: 0.5440
Batch 80, Loss: 0.6158
Batch 90, Loss: 0.6209
Batch 100, Loss: 0.5810
Batch 110, Loss: 0.5963
Batch 120, Loss: 0.6214
Batch 130, Loss: 0.5892
Batch 140, Loss: 0.5799
Batch 150, Loss: 0.5772
Batch 160, Loss: 0.6058
Batch 170, Loss: 0.6387
Batch 180, Loss: 0.6120
Batch 190, Loss: 0.5781
Batch 200, Loss: 0.5745
Batch 210, Loss: 0.6198
Batch 220, Loss: 0.5883
Batch 230, Loss: 0.5993
Batch 240, Loss: 0.5964
Batch 250, Loss: 0.6108
Batch 260, Loss: 0.5597
Batch 270, Loss: 0.5507
Batch 280, Loss: 0.5601
Batch 290, Loss: 0.5873
Batch 300, Loss: 0.5660
Batch 310, Loss: 0.6475
Batch 320, Loss: 0.5690
Batch 330, Loss: 0.5429
Batch 340, Loss: 0.6192
Batch 350, Loss: 0.5942
Batch 360, Loss: 0.6274
Batch 370, Loss: 0.5566
Batch 380, Loss: 0.6041
Batch 390, Loss: 0.5537
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.17021870613098 seconds
Epoch 35 accuracy: 80.99%
Batch 10, Loss: 0.5779
Batch 20, Loss: 0.5730
Batch 30, Loss: 0.5668
Batch 40, Loss: 0.6277
Batch 50, Loss: 0.5457
Batch 60, Loss: 0.5702
Batch 70, Loss: 0.6058
Batch 80, Loss: 0.5940
Batch 90, Loss: 0.6043
Batch 100, Loss: 0.6366
Batch 110, Loss: 0.5474
Batch 120, Loss: 0.5965
Batch 130, Loss: 0.5914
Batch 140, Loss: 0.5741
Batch 150, Loss: 0.6051
Batch 160, Loss: 0.5988
Batch 170, Loss: 0.5828
Batch 180, Loss: 0.5790
Batch 190, Loss: 0.5508
Batch 200, Loss: 0.5790
Batch 210, Loss: 0.5523
Batch 220, Loss: 0.5574
Batch 230, Loss: 0.5555
Batch 240, Loss: 0.5884
Batch 250, Loss: 0.5598
Batch 260, Loss: 0.5908
Batch 270, Loss: 0.6047
Batch 280, Loss: 0.6219
Batch 290, Loss: 0.6045
Batch 300, Loss: 0.5758
Batch 310, Loss: 0.5611
Batch 320, Loss: 0.5706
Batch 330, Loss: 0.5608
Batch 340, Loss: 0.5825
Batch 350, Loss: 0.5528
Batch 360, Loss: 0.5584
Batch 370, Loss: 0.5947
Batch 380, Loss: 0.5651
Batch 390, Loss: 0.5832
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.102092504501343 seconds
Epoch 36 accuracy: 79.71%
Batch 10, Loss: 0.5554
Batch 20, Loss: 0.6000
Batch 30, Loss: 0.5947
Batch 40, Loss: 0.5652
Batch 50, Loss: 0.5558
Batch 60, Loss: 0.6202
Batch 70, Loss: 0.5524
Batch 80, Loss: 0.5722
Batch 90, Loss: 0.5996
Batch 100, Loss: 0.5846
Batch 110, Loss: 0.5909
Batch 120, Loss: 0.5821
Batch 130, Loss: 0.5419
Batch 140, Loss: 0.5535
Batch 150, Loss: 0.5761
Batch 160, Loss: 0.6227
Batch 170, Loss: 0.5898
Batch 180, Loss: 0.5524
Batch 190, Loss: 0.5583
Batch 200, Loss: 0.5623
Batch 210, Loss: 0.6104
Batch 220, Loss: 0.5475
Batch 230, Loss: 0.6036
Batch 240, Loss: 0.6047
Batch 250, Loss: 0.6024
Batch 260, Loss: 0.5700
Batch 270, Loss: 0.5906
Batch 280, Loss: 0.5808
Batch 290, Loss: 0.5424
Batch 300, Loss: 0.5914
Batch 310, Loss: 0.6168
Batch 320, Loss: 0.5943
Batch 330, Loss: 0.5903
Batch 340, Loss: 0.5359
Batch 350, Loss: 0.5654
Batch 360, Loss: 0.5700
Batch 370, Loss: 0.5461
Batch 380, Loss: 0.5961
Batch 390, Loss: 0.5857
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.094966888427734 seconds
Epoch 37 accuracy: 82.73%
Batch 10, Loss: 0.5799
Batch 20, Loss: 0.5659
Batch 30, Loss: 0.5693
Batch 40, Loss: 0.5456
Batch 50, Loss: 0.5602
Batch 60, Loss: 0.5724
Batch 70, Loss: 0.5629
Batch 80, Loss: 0.5434
Batch 90, Loss: 0.5572
Batch 100, Loss: 0.5621
Batch 110, Loss: 0.5796
Batch 120, Loss: 0.5452
Batch 130, Loss: 0.5195
Batch 140, Loss: 0.6069
Batch 150, Loss: 0.5840
Batch 160, Loss: 0.5755
Batch 170, Loss: 0.5665
Batch 180, Loss: 0.6170
Batch 190, Loss: 0.5571
Batch 200, Loss: 0.5559
Batch 210, Loss: 0.5764
Batch 220, Loss: 0.5477
Batch 230, Loss: 0.5501
Batch 240, Loss: 0.5588
Batch 250, Loss: 0.6052
Batch 260, Loss: 0.6131
Batch 270, Loss: 0.5470
Batch 280, Loss: 0.5983
Batch 290, Loss: 0.5826
Batch 300, Loss: 0.5966
Batch 310, Loss: 0.5604
Batch 320, Loss: 0.6141
Batch 330, Loss: 0.5751
Batch 340, Loss: 0.5941
Batch 350, Loss: 0.5703
Batch 360, Loss: 0.5480
Batch 370, Loss: 0.5640
Batch 380, Loss: 0.5645
Batch 390, Loss: 0.5545
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.12056565284729 seconds
Epoch 38 accuracy: 81.98%
Batch 10, Loss: 0.5826
Batch 20, Loss: 0.6396
Batch 30, Loss: 0.5516
Batch 40, Loss: 0.5734
Batch 50, Loss: 0.5626
Batch 60, Loss: 0.5548
Batch 70, Loss: 0.5482
Batch 80, Loss: 0.5657
Batch 90, Loss: 0.5870
Batch 100, Loss: 0.5778
Batch 110, Loss: 0.5591
Batch 120, Loss: 0.6024
Batch 130, Loss: 0.5700
Batch 140, Loss: 0.5670
Batch 150, Loss: 0.5907
Batch 160, Loss: 0.5509
Batch 170, Loss: 0.5817
Batch 180, Loss: 0.5643
Batch 190, Loss: 0.6028
Batch 200, Loss: 0.6009
Batch 210, Loss: 0.6117
Batch 220, Loss: 0.5808
Batch 230, Loss: 0.5442
Batch 240, Loss: 0.5993
Batch 250, Loss: 0.5985
Batch 260, Loss: 0.5498
Batch 270, Loss: 0.5694
Batch 280, Loss: 0.5434
Batch 290, Loss: 0.5784
Batch 300, Loss: 0.5096
Batch 310, Loss: 0.5435
Batch 320, Loss: 0.5737
Batch 330, Loss: 0.5867
Batch 340, Loss: 0.5836
Batch 350, Loss: 0.5932
Batch 360, Loss: 0.5383
Batch 370, Loss: 0.5815
Batch 380, Loss: 0.5578
Batch 390, Loss: 0.5643
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.180083751678467 seconds
Epoch 39 accuracy: 81.37%
Batch 10, Loss: 0.5610
Batch 20, Loss: 0.5078
Batch 30, Loss: 0.5519
Batch 40, Loss: 0.5821
Batch 50, Loss: 0.5580
Batch 60, Loss: 0.5982
Batch 70, Loss: 0.5806
Batch 80, Loss: 0.5712
Batch 90, Loss: 0.5574
Batch 100, Loss: 0.5276
Batch 110, Loss: 0.5758
Batch 120, Loss: 0.5315
Batch 130, Loss: 0.5310
Batch 140, Loss: 0.5679
Batch 150, Loss: 0.5919
Batch 160, Loss: 0.5507
Batch 170, Loss: 0.5325
Batch 180, Loss: 0.5888
Batch 190, Loss: 0.5855
Batch 200, Loss: 0.5498
Batch 210, Loss: 0.6042
Batch 220, Loss: 0.5852
Batch 230, Loss: 0.5764
Batch 240, Loss: 0.5589
Batch 250, Loss: 0.5896
Batch 260, Loss: 0.6033
Batch 270, Loss: 0.5740
Batch 280, Loss: 0.5703
Batch 290, Loss: 0.5495
Batch 300, Loss: 0.5897
Batch 310, Loss: 0.5745
Batch 320, Loss: 0.5404
Batch 330, Loss: 0.5745
Batch 340, Loss: 0.5565
Batch 350, Loss: 0.5623
Batch 360, Loss: 0.5252
Batch 370, Loss: 0.5179
Batch 380, Loss: 0.6068
Batch 390, Loss: 0.5768
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.203376531600952 seconds
Epoch 40 accuracy: 84.8%
Batch 10, Loss: 0.5323
Batch 20, Loss: 0.5391
Batch 30, Loss: 0.5768
Batch 40, Loss: 0.5687
Batch 50, Loss: 0.5518
Batch 60, Loss: 0.5925
Batch 70, Loss: 0.5462
Batch 80, Loss: 0.5581
Batch 90, Loss: 0.5436
Batch 100, Loss: 0.5376
Batch 110, Loss: 0.5456
Batch 120, Loss: 0.5515
Batch 130, Loss: 0.5734
Batch 140, Loss: 0.6208
Batch 150, Loss: 0.5581
Batch 160, Loss: 0.5639
Batch 170, Loss: 0.5862
Batch 180, Loss: 0.5157
Batch 190, Loss: 0.5458
Batch 200, Loss: 0.5215
Batch 210, Loss: 0.5466
Batch 220, Loss: 0.5899
Batch 230, Loss: 0.5649
Batch 240, Loss: 0.5967
Batch 250, Loss: 0.5897
Batch 260, Loss: 0.5844
Batch 270, Loss: 0.5263
Batch 280, Loss: 0.5840
Batch 290, Loss: 0.5673
Batch 300, Loss: 0.5734
Batch 310, Loss: 0.5911
Batch 320, Loss: 0.5904
Batch 330, Loss: 0.5616
Batch 340, Loss: 0.5391
Batch 350, Loss: 0.5911
Batch 360, Loss: 0.5770
Batch 370, Loss: 0.5541
Batch 380, Loss: 0.5770
Batch 390, Loss: 0.6016
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.168806076049805 seconds
Epoch 41 accuracy: 83.54%
Batch 10, Loss: 0.5601
Batch 20, Loss: 0.5522
Batch 30, Loss: 0.5880
Batch 40, Loss: 0.5571
Batch 50, Loss: 0.5316
Batch 60, Loss: 0.5058
Batch 70, Loss: 0.5385
Batch 80, Loss: 0.5653
Batch 90, Loss: 0.5336
Batch 100, Loss: 0.6399
Batch 110, Loss: 0.5455
Batch 120, Loss: 0.5378
Batch 130, Loss: 0.5494
Batch 140, Loss: 0.5281
Batch 150, Loss: 0.5835
Batch 160, Loss: 0.5490
Batch 170, Loss: 0.5375
Batch 180, Loss: 0.5745
Batch 190, Loss: 0.6175
Batch 200, Loss: 0.5551
Batch 210, Loss: 0.5526
Batch 220, Loss: 0.5178
Batch 230, Loss: 0.5925
Batch 240, Loss: 0.5639
Batch 250, Loss: 0.5916
Batch 260, Loss: 0.5483
Batch 270, Loss: 0.5866
Batch 280, Loss: 0.5714
Batch 290, Loss: 0.5698
Batch 300, Loss: 0.5670
Batch 310, Loss: 0.5452
Batch 320, Loss: 0.6102
Batch 330, Loss: 0.5827
Batch 340, Loss: 0.5864
Batch 350, Loss: 0.5369
Batch 360, Loss: 0.5839
Batch 370, Loss: 0.5786
Batch 380, Loss: 0.5424
Batch 390, Loss: 0.5773
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.237264394760132 seconds
Epoch 42 accuracy: 79.39%
Batch 10, Loss: 0.5939
Batch 20, Loss: 0.5736
Batch 30, Loss: 0.5591
Batch 40, Loss: 0.5571
Batch 50, Loss: 0.5459
Batch 60, Loss: 0.5410
Batch 70, Loss: 0.5831
Batch 80, Loss: 0.5815
Batch 90, Loss: 0.5315
Batch 100, Loss: 0.5492
Batch 110, Loss: 0.5307
Batch 120, Loss: 0.5231
Batch 130, Loss: 0.5637
Batch 140, Loss: 0.5572
Batch 150, Loss: 0.5557
Batch 160, Loss: 0.5874
Batch 170, Loss: 0.5891
Batch 180, Loss: 0.5808
Batch 190, Loss: 0.5475
Batch 200, Loss: 0.5929
Batch 210, Loss: 0.5419
Batch 220, Loss: 0.6031
Batch 230, Loss: 0.5521
Batch 240, Loss: 0.5815
Batch 250, Loss: 0.5783
Batch 260, Loss: 0.5725
Batch 270, Loss: 0.4967
Batch 280, Loss: 0.5243
Batch 290, Loss: 0.5594
Batch 300, Loss: 0.5552
Batch 310, Loss: 0.5900
Batch 320, Loss: 0.5766
Batch 330, Loss: 0.5731
Batch 340, Loss: 0.5641
Batch 350, Loss: 0.5470
Batch 360, Loss: 0.5761
Batch 370, Loss: 0.5987
Batch 380, Loss: 0.6041
Batch 390, Loss: 0.5875
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.223077535629272 seconds
Epoch 43 accuracy: 77.05%
Batch 10, Loss: 0.5187
Batch 20, Loss: 0.5541
Batch 30, Loss: 0.5777
Batch 40, Loss: 0.5640
Batch 50, Loss: 0.5449
Batch 60, Loss: 0.5600
Batch 70, Loss: 0.5709
Batch 80, Loss: 0.4946
Batch 90, Loss: 0.5820
Batch 100, Loss: 0.5442
Batch 110, Loss: 0.5400
Batch 120, Loss: 0.5961
Batch 130, Loss: 0.5334
Batch 140, Loss: 0.5451
Batch 150, Loss: 0.5592
Batch 160, Loss: 0.5477
Batch 170, Loss: 0.6030
Batch 180, Loss: 0.5230
Batch 190, Loss: 0.5487
Batch 200, Loss: 0.5196
Batch 210, Loss: 0.5801
Batch 220, Loss: 0.5798
Batch 230, Loss: 0.5911
Batch 240, Loss: 0.5746
Batch 250, Loss: 0.5679
Batch 260, Loss: 0.5812
Batch 270, Loss: 0.5982
Batch 280, Loss: 0.5896
Batch 290, Loss: 0.5474
Batch 300, Loss: 0.5847
Batch 310, Loss: 0.5929
Batch 320, Loss: 0.5846
Batch 330, Loss: 0.5754
Batch 340, Loss: 0.5204
Batch 350, Loss: 0.5657
Batch 360, Loss: 0.5900
Batch 370, Loss: 0.5845
Batch 380, Loss: 0.5108
Batch 390, Loss: 0.5495
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.117201328277588 seconds
Epoch 44 accuracy: 85.36%
Batch 10, Loss: 0.5524
Batch 20, Loss: 0.5465
Batch 30, Loss: 0.5122
Batch 40, Loss: 0.5134
Batch 50, Loss: 0.5208
Batch 60, Loss: 0.5426
Batch 70, Loss: 0.6295
Batch 80, Loss: 0.5577
Batch 90, Loss: 0.5836
Batch 100, Loss: 0.5754
Batch 110, Loss: 0.5590
Batch 120, Loss: 0.5490
Batch 130, Loss: 0.5050
Batch 140, Loss: 0.5511
Batch 150, Loss: 0.6001
Batch 160, Loss: 0.5498
Batch 170, Loss: 0.5739
Batch 180, Loss: 0.5179
Batch 190, Loss: 0.5148
Batch 200, Loss: 0.5406
Batch 210, Loss: 0.5663
Batch 220, Loss: 0.5803
Batch 230, Loss: 0.5243
Batch 240, Loss: 0.5773
Batch 250, Loss: 0.5464
Batch 260, Loss: 0.5832
Batch 270, Loss: 0.5662
Batch 280, Loss: 0.5380
Batch 290, Loss: 0.5398
Batch 300, Loss: 0.6207
Batch 310, Loss: 0.5513
Batch 320, Loss: 0.5334
Batch 330, Loss: 0.5160
Batch 340, Loss: 0.5386
Batch 350, Loss: 0.5558
Batch 360, Loss: 0.5475
Batch 370, Loss: 0.5696
Batch 380, Loss: 0.5815
Batch 390, Loss: 0.5865
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.109944820404053 seconds
Epoch 45 accuracy: 80.0%
Batch 10, Loss: 0.5857
Batch 20, Loss: 0.5375
Batch 30, Loss: 0.5776
Batch 40, Loss: 0.5647
Batch 50, Loss: 0.5849
Batch 60, Loss: 0.5635
Batch 70, Loss: 0.5773
Batch 80, Loss: 0.5461
Batch 90, Loss: 0.5512
Batch 100, Loss: 0.5624
Batch 110, Loss: 0.5378
Batch 120, Loss: 0.5314
Batch 130, Loss: 0.5726
Batch 140, Loss: 0.5763
Batch 150, Loss: 0.5420
Batch 160, Loss: 0.5233
Batch 170, Loss: 0.5475
Batch 180, Loss: 0.5590
Batch 190, Loss: 0.5044
Batch 200, Loss: 0.5199
Batch 210, Loss: 0.5743
Batch 220, Loss: 0.5491
Batch 230, Loss: 0.5851
Batch 240, Loss: 0.5505
Batch 250, Loss: 0.5687
Batch 260, Loss: 0.5387
Batch 270, Loss: 0.5171
Batch 280, Loss: 0.5349
Batch 290, Loss: 0.5349
Batch 300, Loss: 0.5906
Batch 310, Loss: 0.5292
Batch 320, Loss: 0.5733
Batch 330, Loss: 0.5035
Batch 340, Loss: 0.5410
Batch 350, Loss: 0.5332
Batch 360, Loss: 0.5536
Batch 370, Loss: 0.6077
Batch 380, Loss: 0.6001
Batch 390, Loss: 0.5589
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.274922847747803 seconds
Epoch 46 accuracy: 84.9%
Batch 10, Loss: 0.5521
Batch 20, Loss: 0.5262
Batch 30, Loss: 0.5474
Batch 40, Loss: 0.4770
Batch 50, Loss: 0.5154
Batch 60, Loss: 0.5498
Batch 70, Loss: 0.5552
Batch 80, Loss: 0.5593
Batch 90, Loss: 0.5169
Batch 100, Loss: 0.5326
Batch 110, Loss: 0.5622
Batch 120, Loss: 0.5483
Batch 130, Loss: 0.5244
Batch 140, Loss: 0.5591
Batch 150, Loss: 0.5633
Batch 160, Loss: 0.5443
Batch 170, Loss: 0.5504
Batch 180, Loss: 0.5537
Batch 190, Loss: 0.5686
Batch 200, Loss: 0.5906
Batch 210, Loss: 0.6152
Batch 220, Loss: 0.5594
Batch 230, Loss: 0.5765
Batch 240, Loss: 0.6010
Batch 250, Loss: 0.5417
Batch 260, Loss: 0.5483
Batch 270, Loss: 0.5602
Batch 280, Loss: 0.5546
Batch 290, Loss: 0.5414
Batch 300, Loss: 0.5449
Batch 310, Loss: 0.5484
Batch 320, Loss: 0.5314
Batch 330, Loss: 0.5453
Batch 340, Loss: 0.5385
Batch 350, Loss: 0.5226
Batch 360, Loss: 0.5751
Batch 370, Loss: 0.5424
Batch 380, Loss: 0.5189
Batch 390, Loss: 0.5504
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.133058309555054 seconds
Epoch 47 accuracy: 82.82%
Batch 10, Loss: 0.5358
Batch 20, Loss: 0.5897
Batch 30, Loss: 0.5349
Batch 40, Loss: 0.5586
Batch 50, Loss: 0.5569
Batch 60, Loss: 0.5133
Batch 70, Loss: 0.5045
Batch 80, Loss: 0.5429
Batch 90, Loss: 0.5397
Batch 100, Loss: 0.5545
Batch 110, Loss: 0.5796
Batch 120, Loss: 0.5625
Batch 130, Loss: 0.5735
Batch 140, Loss: 0.5615
Batch 150, Loss: 0.5532
Batch 160, Loss: 0.5569
Batch 170, Loss: 0.5527
Batch 180, Loss: 0.5712
Batch 190, Loss: 0.5625
Batch 200, Loss: 0.5549
Batch 210, Loss: 0.5517
Batch 220, Loss: 0.5282
Batch 230, Loss: 0.5078
Batch 240, Loss: 0.5673
Batch 250, Loss: 0.5567
Batch 260, Loss: 0.5860
Batch 270, Loss: 0.5645
Batch 280, Loss: 0.5497
Batch 290, Loss: 0.5922
Batch 300, Loss: 0.5620
Batch 310, Loss: 0.5542
Batch 320, Loss: 0.5091
Batch 330, Loss: 0.5118
Batch 340, Loss: 0.5900
Batch 350, Loss: 0.5583
Batch 360, Loss: 0.5540
Batch 370, Loss: 0.5483
Batch 380, Loss: 0.5784
Batch 390, Loss: 0.5338
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.17794632911682 seconds
Epoch 48 accuracy: 82.72%
Batch 10, Loss: 0.5245
Batch 20, Loss: 0.5464
Batch 30, Loss: 0.5795
Batch 40, Loss: 0.5448
Batch 50, Loss: 0.5626
Batch 60, Loss: 0.5850
Batch 70, Loss: 0.5440
Batch 80, Loss: 0.5498
Batch 90, Loss: 0.5760
Batch 100, Loss: 0.5155
Batch 110, Loss: 0.5439
Batch 120, Loss: 0.5378
Batch 130, Loss: 0.5464
Batch 140, Loss: 0.5474
Batch 150, Loss: 0.5415
Batch 160, Loss: 0.5295
Batch 170, Loss: 0.5502
Batch 180, Loss: 0.5549
Batch 190, Loss: 0.5166
Batch 200, Loss: 0.5564
Batch 210, Loss: 0.5536
Batch 220, Loss: 0.5234
Batch 230, Loss: 0.5289
Batch 240, Loss: 0.5490
Batch 250, Loss: 0.5914
Batch 260, Loss: 0.5618
Batch 270, Loss: 0.5741
Batch 280, Loss: 0.5109
Batch 290, Loss: 0.5603
Batch 300, Loss: 0.5789
Batch 310, Loss: 0.5589
Batch 320, Loss: 0.5984
Batch 330, Loss: 0.5490
Batch 340, Loss: 0.5337
Batch 350, Loss: 0.5398
Batch 360, Loss: 0.5702
Batch 370, Loss: 0.5595
Batch 380, Loss: 0.5355
Batch 390, Loss: 0.5544
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.171432495117188 seconds
Epoch 49 accuracy: 83.71%
Batch 10, Loss: 0.5217
Batch 20, Loss: 0.5504
Batch 30, Loss: 0.5294
Batch 40, Loss: 0.5174
Batch 50, Loss: 0.5159
Batch 60, Loss: 0.5296
Batch 70, Loss: 0.5352
Batch 80, Loss: 0.5276
Batch 90, Loss: 0.5307
Batch 100, Loss: 0.5528
Batch 110, Loss: 0.5348
Batch 120, Loss: 0.5525
Batch 130, Loss: 0.5624
Batch 140, Loss: 0.5655
Batch 150, Loss: 0.5702
Batch 160, Loss: 0.5617
Batch 170, Loss: 0.5983
Batch 180, Loss: 0.5756
Batch 190, Loss: 0.5285
Batch 200, Loss: 0.5302
Batch 210, Loss: 0.5260
Batch 220, Loss: 0.5585
Batch 230, Loss: 0.5632
Batch 240, Loss: 0.5141
Batch 250, Loss: 0.5368
Batch 260, Loss: 0.5224
Batch 270, Loss: 0.5184
Batch 280, Loss: 0.5515
Batch 290, Loss: 0.5352
Batch 300, Loss: 0.5531
Batch 310, Loss: 0.5450
Batch 320, Loss: 0.5607
Batch 330, Loss: 0.5411
Batch 340, Loss: 0.5208
Batch 350, Loss: 0.5394
Batch 360, Loss: 0.5597
Batch 370, Loss: 0.4974
Batch 380, Loss: 0.5275
Batch 390, Loss: 0.5600
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.186870574951172 seconds
Epoch 50 accuracy: 80.86%
Batch 10, Loss: 0.5207
Batch 20, Loss: 0.5569
Batch 30, Loss: 0.5573
Batch 40, Loss: 0.5182
Batch 50, Loss: 0.5484
Batch 60, Loss: 0.5300
Batch 70, Loss: 0.5556
Batch 80, Loss: 0.5746
Batch 90, Loss: 0.5066
Batch 100, Loss: 0.5151
Batch 110, Loss: 0.5232
Batch 120, Loss: 0.5165
Batch 130, Loss: 0.5591
Batch 140, Loss: 0.5105
Batch 150, Loss: 0.5552
Batch 160, Loss: 0.5258
Batch 170, Loss: 0.5632
Batch 180, Loss: 0.5412
Batch 190, Loss: 0.5233
Batch 200, Loss: 0.5583
Batch 210, Loss: 0.5135
Batch 220, Loss: 0.5315
Batch 230, Loss: 0.5425
Batch 240, Loss: 0.5052
Batch 250, Loss: 0.5429
Batch 260, Loss: 0.5043
Batch 270, Loss: 0.5324
Batch 280, Loss: 0.5454
Batch 290, Loss: 0.5556
Batch 300, Loss: 0.5606
Batch 310, Loss: 0.5290
Batch 320, Loss: 0.5935
Batch 330, Loss: 0.5148
Batch 340, Loss: 0.5802
Batch 350, Loss: 0.5507
Batch 360, Loss: 0.5962
Batch 370, Loss: 0.5566
Batch 380, Loss: 0.5273
Batch 390, Loss: 0.5385
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.098315238952637 seconds
Epoch 51 accuracy: 82.52%
Batch 10, Loss: 0.5929
Batch 20, Loss: 0.5047
Batch 30, Loss: 0.5272
Batch 40, Loss: 0.5372
Batch 50, Loss: 0.5293
Batch 60, Loss: 0.5025
Batch 70, Loss: 0.5171
Batch 80, Loss: 0.4968
Batch 90, Loss: 0.5862
Batch 100, Loss: 0.4779
Batch 110, Loss: 0.5253
Batch 120, Loss: 0.5512
Batch 130, Loss: 0.5288
Batch 140, Loss: 0.5263
Batch 150, Loss: 0.5440
Batch 160, Loss: 0.5432
Batch 170, Loss: 0.5259
Batch 180, Loss: 0.5403
Batch 190, Loss: 0.5344
Batch 200, Loss: 0.5586
Batch 210, Loss: 0.5515
Batch 220, Loss: 0.5640
Batch 230, Loss: 0.5593
Batch 240, Loss: 0.5214
Batch 250, Loss: 0.5375
Batch 260, Loss: 0.5188
Batch 270, Loss: 0.5461
Batch 280, Loss: 0.5388
Batch 290, Loss: 0.5834
Batch 300, Loss: 0.5650
Batch 310, Loss: 0.5230
Batch 320, Loss: 0.5358
Batch 330, Loss: 0.6002
Batch 340, Loss: 0.5492
Batch 350, Loss: 0.5429
Batch 360, Loss: 0.5536
Batch 370, Loss: 0.5477
Batch 380, Loss: 0.5144
Batch 390, Loss: 0.5319
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.240273237228394 seconds
Epoch 52 accuracy: 77.77%
Batch 10, Loss: 0.5320
Batch 20, Loss: 0.4938
Batch 30, Loss: 0.5482
Batch 40, Loss: 0.5744
Batch 50, Loss: 0.5805
Batch 60, Loss: 0.5404
Batch 70, Loss: 0.5216
Batch 80, Loss: 0.5124
Batch 90, Loss: 0.5886
Batch 100, Loss: 0.5711
Batch 110, Loss: 0.5127
Batch 120, Loss: 0.5404
Batch 130, Loss: 0.5050
Batch 140, Loss: 0.5261
Batch 150, Loss: 0.5587
Batch 160, Loss: 0.5636
Batch 170, Loss: 0.5403
Batch 180, Loss: 0.5092
Batch 190, Loss: 0.5769
Batch 200, Loss: 0.5246
Batch 210, Loss: 0.5515
Batch 220, Loss: 0.5375
Batch 230, Loss: 0.5548
Batch 240, Loss: 0.5211
Batch 250, Loss: 0.5340
Batch 260, Loss: 0.5427
Batch 270, Loss: 0.5558
Batch 280, Loss: 0.5655
Batch 290, Loss: 0.5920
Batch 300, Loss: 0.5582
Batch 310, Loss: 0.5342
Batch 320, Loss: 0.5447
Batch 330, Loss: 0.5429
Batch 340, Loss: 0.5188
Batch 350, Loss: 0.5428
Batch 360, Loss: 0.5349
Batch 370, Loss: 0.4919
Batch 380, Loss: 0.5367
Batch 390, Loss: 0.5465
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.21827530860901 seconds
Epoch 53 accuracy: 85.1%
Batch 10, Loss: 0.5213
Batch 20, Loss: 0.4930
Batch 30, Loss: 0.5480
Batch 40, Loss: 0.5191
Batch 50, Loss: 0.5549
Batch 60, Loss: 0.5849
Batch 70, Loss: 0.5270
Batch 80, Loss: 0.5054
Batch 90, Loss: 0.5381
Batch 100, Loss: 0.5184
Batch 110, Loss: 0.5218
Batch 120, Loss: 0.5439
Batch 130, Loss: 0.5537
Batch 140, Loss: 0.5415
Batch 150, Loss: 0.5288
Batch 160, Loss: 0.5295
Batch 170, Loss: 0.5627
Batch 180, Loss: 0.5063
Batch 190, Loss: 0.5655
Batch 200, Loss: 0.5105
Batch 210, Loss: 0.5354
Batch 220, Loss: 0.5589
Batch 230, Loss: 0.5189
Batch 240, Loss: 0.5453
Batch 250, Loss: 0.5083
Batch 260, Loss: 0.5082
Batch 270, Loss: 0.5496
Batch 280, Loss: 0.5284
Batch 290, Loss: 0.5467
Batch 300, Loss: 0.5440
Batch 310, Loss: 0.4721
Batch 320, Loss: 0.5150
Batch 330, Loss: 0.5551
Batch 340, Loss: 0.5631
Batch 350, Loss: 0.5259
Batch 360, Loss: 0.5919
Batch 370, Loss: 0.5302
Batch 380, Loss: 0.5427
Batch 390, Loss: 0.5564
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.10323190689087 seconds
Epoch 54 accuracy: 81.64%
Batch 10, Loss: 0.5363
Batch 20, Loss: 0.5674
Batch 30, Loss: 0.5575
Batch 40, Loss: 0.5309
Batch 50, Loss: 0.4899
Batch 60, Loss: 0.5072
Batch 70, Loss: 0.5420
Batch 80, Loss: 0.5574
Batch 90, Loss: 0.5831
Batch 100, Loss: 0.5581
Batch 110, Loss: 0.5641
Batch 120, Loss: 0.5422
Batch 130, Loss: 0.5508
Batch 140, Loss: 0.5445
Batch 150, Loss: 0.5181
Batch 160, Loss: 0.5001
Batch 170, Loss: 0.5369
Batch 180, Loss: 0.5012
Batch 190, Loss: 0.5348
Batch 200, Loss: 0.5079
Batch 210, Loss: 0.5633
Batch 220, Loss: 0.5499
Batch 230, Loss: 0.5257
Batch 240, Loss: 0.5362
Batch 250, Loss: 0.5347
Batch 260, Loss: 0.5394
Batch 270, Loss: 0.5070
Batch 280, Loss: 0.5224
Batch 290, Loss: 0.5138
Batch 300, Loss: 0.5394
Batch 310, Loss: 0.5609
Batch 320, Loss: 0.5623
Batch 330, Loss: 0.5517
Batch 340, Loss: 0.5321
Batch 350, Loss: 0.5543
Batch 360, Loss: 0.4911
Batch 370, Loss: 0.5480
Batch 380, Loss: 0.5437
Batch 390, Loss: 0.4997
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.182417154312134 seconds
Epoch 55 accuracy: 86.2%
Batch 10, Loss: 0.5331
Batch 20, Loss: 0.5270
Batch 30, Loss: 0.5335
Batch 40, Loss: 0.5291
Batch 50, Loss: 0.5295
Batch 60, Loss: 0.5568
Batch 70, Loss: 0.5380
Batch 80, Loss: 0.5176
Batch 90, Loss: 0.5444
Batch 100, Loss: 0.5368
Batch 110, Loss: 0.5154
Batch 120, Loss: 0.5504
Batch 130, Loss: 0.5297
Batch 140, Loss: 0.5193
Batch 150, Loss: 0.5247
Batch 160, Loss: 0.5515
Batch 170, Loss: 0.5051
Batch 180, Loss: 0.5171
Batch 190, Loss: 0.5266
Batch 200, Loss: 0.5266
Batch 210, Loss: 0.5259
Batch 220, Loss: 0.5492
Batch 230, Loss: 0.5088
Batch 240, Loss: 0.5525
Batch 250, Loss: 0.5413
Batch 260, Loss: 0.5519
Batch 270, Loss: 0.5253
Batch 280, Loss: 0.4951
Batch 290, Loss: 0.5365
Batch 300, Loss: 0.5043
Batch 310, Loss: 0.5562
Batch 320, Loss: 0.5435
Batch 330, Loss: 0.5551
Batch 340, Loss: 0.5378
Batch 350, Loss: 0.5603
Batch 360, Loss: 0.5358
Batch 370, Loss: 0.5309
Batch 380, Loss: 0.5391
Batch 390, Loss: 0.5386
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.139134645462036 seconds
Epoch 56 accuracy: 81.26%
Batch 10, Loss: 0.5361
Batch 20, Loss: 0.5169
Batch 30, Loss: 0.5623
Batch 40, Loss: 0.5579
Batch 50, Loss: 0.5358
Batch 60, Loss: 0.5040
Batch 70, Loss: 0.5195
Batch 80, Loss: 0.5618
Batch 90, Loss: 0.5370
Batch 100, Loss: 0.5413
Batch 110, Loss: 0.5223
Batch 120, Loss: 0.4933
Batch 130, Loss: 0.5445
Batch 140, Loss: 0.5336
Batch 150, Loss: 0.5173
Batch 160, Loss: 0.5599
Batch 170, Loss: 0.5096
Batch 180, Loss: 0.5487
Batch 190, Loss: 0.5262
Batch 200, Loss: 0.4857
Batch 210, Loss: 0.5487
Batch 220, Loss: 0.5486
Batch 230, Loss: 0.5410
Batch 240, Loss: 0.5140
Batch 250, Loss: 0.4778
Batch 260, Loss: 0.5030
Batch 270, Loss: 0.5396
Batch 280, Loss: 0.5013
Batch 290, Loss: 0.5450
Batch 300, Loss: 0.4913
Batch 310, Loss: 0.5410
Batch 320, Loss: 0.5391
Batch 330, Loss: 0.5384
Batch 340, Loss: 0.5348
Batch 350, Loss: 0.5319
Batch 360, Loss: 0.5551
Batch 370, Loss: 0.5493
Batch 380, Loss: 0.5330
Batch 390, Loss: 0.5269
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.10363221168518 seconds
Epoch 57 accuracy: 85.77%
Batch 10, Loss: 0.5231
Batch 20, Loss: 0.5084
Batch 30, Loss: 0.4863
Batch 40, Loss: 0.5726
Batch 50, Loss: 0.5237
Batch 60, Loss: 0.5300
Batch 70, Loss: 0.5274
Batch 80, Loss: 0.5525
Batch 90, Loss: 0.5098
Batch 100, Loss: 0.5627
Batch 110, Loss: 0.5380
Batch 120, Loss: 0.5152
Batch 130, Loss: 0.5104
Batch 140, Loss: 0.5278
Batch 150, Loss: 0.5667
Batch 160, Loss: 0.5547
Batch 170, Loss: 0.5158
Batch 180, Loss: 0.5506
Batch 190, Loss: 0.4759
Batch 200, Loss: 0.5255
Batch 210, Loss: 0.5145
Batch 220, Loss: 0.5285
Batch 230, Loss: 0.5166
Batch 240, Loss: 0.5072
Batch 250, Loss: 0.5392
Batch 260, Loss: 0.5206
Batch 270, Loss: 0.5059
Batch 280, Loss: 0.5362
Batch 290, Loss: 0.5117
Batch 300, Loss: 0.5413
Batch 310, Loss: 0.5405
Batch 320, Loss: 0.5542
Batch 330, Loss: 0.5297
Batch 340, Loss: 0.5080
Batch 350, Loss: 0.5174
Batch 360, Loss: 0.5660
Batch 370, Loss: 0.5363
Batch 380, Loss: 0.5197
Batch 390, Loss: 0.5805
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.18532085418701 seconds
Epoch 58 accuracy: 84.06%
Batch 10, Loss: 0.5126
Batch 20, Loss: 0.5340
Batch 30, Loss: 0.5329
Batch 40, Loss: 0.5029
Batch 50, Loss: 0.5258
Batch 60, Loss: 0.4838
Batch 70, Loss: 0.5006
Batch 80, Loss: 0.5049
Batch 90, Loss: 0.5311
Batch 100, Loss: 0.5139
Batch 110, Loss: 0.5724
Batch 120, Loss: 0.5601
Batch 130, Loss: 0.5107
Batch 140, Loss: 0.5208
Batch 150, Loss: 0.4930
Batch 160, Loss: 0.4755
Batch 170, Loss: 0.5250
Batch 180, Loss: 0.5330
Batch 190, Loss: 0.5551
Batch 200, Loss: 0.5655
Batch 210, Loss: 0.5222
Batch 220, Loss: 0.5276
Batch 230, Loss: 0.4747
Batch 240, Loss: 0.4660
Batch 250, Loss: 0.5224
Batch 260, Loss: 0.5318
Batch 270, Loss: 0.5119
Batch 280, Loss: 0.5232
Batch 290, Loss: 0.4629
Batch 300, Loss: 0.5362
Batch 310, Loss: 0.5714
Batch 320, Loss: 0.5475
Batch 330, Loss: 0.5454
Batch 340, Loss: 0.5131
Batch 350, Loss: 0.5654
Batch 360, Loss: 0.4984
Batch 370, Loss: 0.5334
Batch 380, Loss: 0.5153
Batch 390, Loss: 0.5544
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.145764112472534 seconds
Epoch 59 accuracy: 80.9%
Batch 10, Loss: 0.5130
Batch 20, Loss: 0.5357
Batch 30, Loss: 0.5026
Batch 40, Loss: 0.5442
Batch 50, Loss: 0.5135
Batch 60, Loss: 0.5062
Batch 70, Loss: 0.5015
Batch 80, Loss: 0.5207
Batch 90, Loss: 0.5179
Batch 100, Loss: 0.5110
Batch 110, Loss: 0.5332
Batch 120, Loss: 0.5605
Batch 130, Loss: 0.5394
Batch 140, Loss: 0.5588
Batch 150, Loss: 0.5466
Batch 160, Loss: 0.5276
Batch 170, Loss: 0.5247
Batch 180, Loss: 0.4986
Batch 190, Loss: 0.5251
Batch 200, Loss: 0.4717
Batch 210, Loss: 0.4998
Batch 220, Loss: 0.5240
Batch 230, Loss: 0.5663
Batch 240, Loss: 0.5300
Batch 250, Loss: 0.5462
Batch 260, Loss: 0.5135
Batch 270, Loss: 0.4989
Batch 280, Loss: 0.5562
Batch 290, Loss: 0.5353
Batch 300, Loss: 0.5195
Batch 310, Loss: 0.5186
Batch 320, Loss: 0.5434
Batch 330, Loss: 0.5047
Batch 340, Loss: 0.5214
Batch 350, Loss: 0.5185
Batch 360, Loss: 0.5024
Batch 370, Loss: 0.5188
Batch 380, Loss: 0.5107
Batch 390, Loss: 0.5408
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.121766328811646 seconds
Epoch 60 accuracy: 82.33%
Batch 10, Loss: 0.5287
Batch 20, Loss: 0.5122
Batch 30, Loss: 0.5682
Batch 40, Loss: 0.4703
Batch 50, Loss: 0.5139
Batch 60, Loss: 0.5078
Batch 70, Loss: 0.5484
Batch 80, Loss: 0.5096
Batch 90, Loss: 0.4844
Batch 100, Loss: 0.5032
Batch 110, Loss: 0.4927
Batch 120, Loss: 0.5130
Batch 130, Loss: 0.5441
Batch 140, Loss: 0.4844
Batch 150, Loss: 0.5256
Batch 160, Loss: 0.5534
Batch 170, Loss: 0.5563
Batch 180, Loss: 0.5058
Batch 190, Loss: 0.5209
Batch 200, Loss: 0.5325
Batch 210, Loss: 0.5163
Batch 220, Loss: 0.4826
Batch 230, Loss: 0.5136
Batch 240, Loss: 0.4986
Batch 250, Loss: 0.5312
Batch 260, Loss: 0.5319
Batch 270, Loss: 0.5151
Batch 280, Loss: 0.4950
Batch 290, Loss: 0.5021
Batch 300, Loss: 0.5426
Batch 310, Loss: 0.5140
Batch 320, Loss: 0.5504
Batch 330, Loss: 0.5508
Batch 340, Loss: 0.4996
Batch 350, Loss: 0.5209
Batch 360, Loss: 0.5212
Batch 370, Loss: 0.5312
Batch 380, Loss: 0.5200
Batch 390, Loss: 0.5212
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.11712622642517 seconds
Epoch 61 accuracy: 82.09%
Batch 10, Loss: 0.5345
Batch 20, Loss: 0.5470
Batch 30, Loss: 0.5220
Batch 40, Loss: 0.4734
Batch 50, Loss: 0.5084
Batch 60, Loss: 0.5107
Batch 70, Loss: 0.5156
Batch 80, Loss: 0.5268
Batch 90, Loss: 0.5441
Batch 100, Loss: 0.5084
Batch 110, Loss: 0.4992
Batch 120, Loss: 0.5533
Batch 130, Loss: 0.5091
Batch 140, Loss: 0.5363
Batch 150, Loss: 0.5407
Batch 160, Loss: 0.5228
Batch 170, Loss: 0.4930
Batch 180, Loss: 0.5379
Batch 190, Loss: 0.5289
Batch 200, Loss: 0.5223
Batch 210, Loss: 0.5144
Batch 220, Loss: 0.5513
Batch 230, Loss: 0.5161
Batch 240, Loss: 0.5304
Batch 250, Loss: 0.5218
Batch 260, Loss: 0.4883
Batch 270, Loss: 0.5052
Batch 280, Loss: 0.5712
Batch 290, Loss: 0.5397
Batch 300, Loss: 0.5125
Batch 310, Loss: 0.5047
Batch 320, Loss: 0.4857
Batch 330, Loss: 0.5143
Batch 340, Loss: 0.5331
Batch 350, Loss: 0.4989
Batch 360, Loss: 0.4989
Batch 370, Loss: 0.5503
Batch 380, Loss: 0.5104
Batch 390, Loss: 0.5074
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.171967029571533 seconds
Epoch 62 accuracy: 85.43%
Batch 10, Loss: 0.4606
Batch 20, Loss: 0.4794
Batch 30, Loss: 0.5328
Batch 40, Loss: 0.4996
Batch 50, Loss: 0.4861
Batch 60, Loss: 0.5022
Batch 70, Loss: 0.4982
Batch 80, Loss: 0.5223
Batch 90, Loss: 0.5181
Batch 100, Loss: 0.5203
Batch 110, Loss: 0.5333
Batch 120, Loss: 0.5198
Batch 130, Loss: 0.5418
Batch 140, Loss: 0.5151
Batch 150, Loss: 0.5466
Batch 160, Loss: 0.5499
Batch 170, Loss: 0.5226
Batch 180, Loss: 0.5457
Batch 190, Loss: 0.5347
Batch 200, Loss: 0.5275
Batch 210, Loss: 0.5177
Batch 220, Loss: 0.5218
Batch 230, Loss: 0.5213
Batch 240, Loss: 0.5403
Batch 250, Loss: 0.5089
Batch 260, Loss: 0.5333
Batch 270, Loss: 0.5157
Batch 280, Loss: 0.5210
Batch 290, Loss: 0.5164
Batch 300, Loss: 0.5457
Batch 310, Loss: 0.5444
Batch 320, Loss: 0.5135
Batch 330, Loss: 0.4881
Batch 340, Loss: 0.5178
Batch 350, Loss: 0.5067
Batch 360, Loss: 0.5274
Batch 370, Loss: 0.5390
Batch 380, Loss: 0.5057
Batch 390, Loss: 0.5308
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.171947240829468 seconds
Epoch 63 accuracy: 83.67%
Batch 10, Loss: 0.4909
Batch 20, Loss: 0.4984
Batch 30, Loss: 0.5250
Batch 40, Loss: 0.5112
Batch 50, Loss: 0.5284
Batch 60, Loss: 0.5148
Batch 70, Loss: 0.5142
Batch 80, Loss: 0.5420
Batch 90, Loss: 0.5151
Batch 100, Loss: 0.5241
Batch 110, Loss: 0.5130
Batch 120, Loss: 0.5269
Batch 130, Loss: 0.5222
Batch 140, Loss: 0.5493
Batch 150, Loss: 0.5039
Batch 160, Loss: 0.5252
Batch 170, Loss: 0.5279
Batch 180, Loss: 0.5334
Batch 190, Loss: 0.5400
Batch 200, Loss: 0.4956
Batch 210, Loss: 0.5454
Batch 220, Loss: 0.5080
Batch 230, Loss: 0.5363
Batch 240, Loss: 0.4874
Batch 250, Loss: 0.4887
Batch 260, Loss: 0.4713
Batch 270, Loss: 0.5359
Batch 280, Loss: 0.5355
Batch 290, Loss: 0.4924
Batch 300, Loss: 0.5198
Batch 310, Loss: 0.5530
Batch 320, Loss: 0.4899
Batch 330, Loss: 0.5145
Batch 340, Loss: 0.4688
Batch 350, Loss: 0.4907
Batch 360, Loss: 0.5341
Batch 370, Loss: 0.5140
Batch 380, Loss: 0.5263
Batch 390, Loss: 0.5563
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.177568912506104 seconds
Epoch 64 accuracy: 83.26%
Batch 10, Loss: 0.5288
Batch 20, Loss: 0.4738
Batch 30, Loss: 0.4936
Batch 40, Loss: 0.4968
Batch 50, Loss: 0.5233
Batch 60, Loss: 0.5365
Batch 70, Loss: 0.4744
Batch 80, Loss: 0.4792
Batch 90, Loss: 0.5425
Batch 100, Loss: 0.4840
Batch 110, Loss: 0.5026
Batch 120, Loss: 0.5099
Batch 130, Loss: 0.5188
Batch 140, Loss: 0.5022
Batch 150, Loss: 0.5107
Batch 160, Loss: 0.5558
Batch 170, Loss: 0.5363
Batch 180, Loss: 0.5063
Batch 190, Loss: 0.5081
Batch 200, Loss: 0.5221
Batch 210, Loss: 0.4849
Batch 220, Loss: 0.5278
Batch 230, Loss: 0.5131
Batch 240, Loss: 0.5176
Batch 250, Loss: 0.5396
Batch 260, Loss: 0.4945
Batch 270, Loss: 0.5021
Batch 280, Loss: 0.4959
Batch 290, Loss: 0.5555
Batch 300, Loss: 0.5534
Batch 310, Loss: 0.4925
Batch 320, Loss: 0.5120
Batch 330, Loss: 0.5283
Batch 340, Loss: 0.5200
Batch 350, Loss: 0.5436
Batch 360, Loss: 0.4802
Batch 370, Loss: 0.5127
Batch 380, Loss: 0.5042
Batch 390, Loss: 0.5285
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.15055823326111 seconds
Epoch 65 accuracy: 84.93%
Batch 10, Loss: 0.5122
Batch 20, Loss: 0.5080
Batch 30, Loss: 0.5564
Batch 40, Loss: 0.5307
Batch 50, Loss: 0.5386
Batch 60, Loss: 0.5017
Batch 70, Loss: 0.4670
Batch 80, Loss: 0.5054
Batch 90, Loss: 0.5349
Batch 100, Loss: 0.5590
Batch 110, Loss: 0.5651
Batch 120, Loss: 0.4981
Batch 130, Loss: 0.5024
Batch 140, Loss: 0.4637
Batch 150, Loss: 0.4845
Batch 160, Loss: 0.5118
Batch 170, Loss: 0.4972
Batch 180, Loss: 0.5085
Batch 190, Loss: 0.5025
Batch 200, Loss: 0.5276
Batch 210, Loss: 0.5191
Batch 220, Loss: 0.5109
Batch 230, Loss: 0.5311
Batch 240, Loss: 0.5162
Batch 250, Loss: 0.5160
Batch 260, Loss: 0.4990
Batch 270, Loss: 0.5041
Batch 280, Loss: 0.5002
Batch 290, Loss: 0.5169
Batch 300, Loss: 0.5655
Batch 310, Loss: 0.4956
Batch 320, Loss: 0.5076
Batch 330, Loss: 0.5122
Batch 340, Loss: 0.4928
Batch 350, Loss: 0.5333
Batch 360, Loss: 0.5486
Batch 370, Loss: 0.5080
Batch 380, Loss: 0.5321
Batch 390, Loss: 0.4919
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.195724487304688 seconds
Epoch 66 accuracy: 84.99%
Batch 10, Loss: 0.5036
Batch 20, Loss: 0.5158
Batch 30, Loss: 0.4990
Batch 40, Loss: 0.5065
Batch 50, Loss: 0.4856
Batch 60, Loss: 0.4891
Batch 70, Loss: 0.4828
Batch 80, Loss: 0.5241
Batch 90, Loss: 0.5321
Batch 100, Loss: 0.4904
Batch 110, Loss: 0.5083
Batch 120, Loss: 0.5008
Batch 130, Loss: 0.4756
Batch 140, Loss: 0.4956
Batch 150, Loss: 0.5063
Batch 160, Loss: 0.5074
Batch 170, Loss: 0.5133
Batch 180, Loss: 0.5047
Batch 190, Loss: 0.5210
Batch 200, Loss: 0.4999
Batch 210, Loss: 0.5322
Batch 220, Loss: 0.5566
Batch 230, Loss: 0.5000
Batch 240, Loss: 0.5251
Batch 250, Loss: 0.5292
Batch 260, Loss: 0.5274
Batch 270, Loss: 0.5104
Batch 280, Loss: 0.4952
Batch 290, Loss: 0.4889
Batch 300, Loss: 0.5148
Batch 310, Loss: 0.5239
Batch 320, Loss: 0.4940
Batch 330, Loss: 0.5167
Batch 340, Loss: 0.5112
Batch 350, Loss: 0.5172
Batch 360, Loss: 0.5302
Batch 370, Loss: 0.4720
Batch 380, Loss: 0.5462
Batch 390, Loss: 0.4980
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.215569496154785 seconds
Epoch 67 accuracy: 85.43%
Batch 10, Loss: 0.5366
Batch 20, Loss: 0.5103
Batch 30, Loss: 0.5000
Batch 40, Loss: 0.5056
Batch 50, Loss: 0.4762
Batch 60, Loss: 0.4886
Batch 70, Loss: 0.5264
Batch 80, Loss: 0.4946
Batch 90, Loss: 0.5640
Batch 100, Loss: 0.5390
Batch 110, Loss: 0.5173
Batch 120, Loss: 0.4966
Batch 130, Loss: 0.4928
Batch 140, Loss: 0.5073
Batch 150, Loss: 0.4969
Batch 160, Loss: 0.5074
Batch 170, Loss: 0.5051
Batch 180, Loss: 0.4929
Batch 190, Loss: 0.5338
Batch 200, Loss: 0.5436
Batch 210, Loss: 0.5052
Batch 220, Loss: 0.5643
Batch 230, Loss: 0.4821
Batch 240, Loss: 0.4991
Batch 250, Loss: 0.4867
Batch 260, Loss: 0.5099
Batch 270, Loss: 0.5060
Batch 280, Loss: 0.4800
Batch 290, Loss: 0.4602
Batch 300, Loss: 0.5282
Batch 310, Loss: 0.5228
Batch 320, Loss: 0.5018
Batch 330, Loss: 0.5252
Batch 340, Loss: 0.4688
Batch 350, Loss: 0.5283
Batch 360, Loss: 0.4878
Batch 370, Loss: 0.5552
Batch 380, Loss: 0.5363
Batch 390, Loss: 0.5275
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.408475160598755 seconds
Epoch 68 accuracy: 86.64%
Batch 10, Loss: 0.5089
Batch 20, Loss: 0.5016
Batch 30, Loss: 0.5203
Batch 40, Loss: 0.5096
Batch 50, Loss: 0.4804
Batch 60, Loss: 0.5299
Batch 70, Loss: 0.5227
Batch 80, Loss: 0.5185
Batch 90, Loss: 0.5293
Batch 100, Loss: 0.5133
Batch 110, Loss: 0.5295
Batch 120, Loss: 0.5019
Batch 130, Loss: 0.4959
Batch 140, Loss: 0.5085
Batch 150, Loss: 0.5047
Batch 160, Loss: 0.4893
Batch 170, Loss: 0.5163
Batch 180, Loss: 0.4977
Batch 190, Loss: 0.4989
Batch 200, Loss: 0.5023
Batch 210, Loss: 0.5066
Batch 220, Loss: 0.5334
Batch 230, Loss: 0.4685
Batch 240, Loss: 0.4957
Batch 250, Loss: 0.4698
Batch 260, Loss: 0.5621
Batch 270, Loss: 0.4850
Batch 280, Loss: 0.4643
Batch 290, Loss: 0.5215
Batch 300, Loss: 0.4878
Batch 310, Loss: 0.5170
Batch 320, Loss: 0.5038
Batch 330, Loss: 0.5253
Batch 340, Loss: 0.5286
Batch 350, Loss: 0.4858
Batch 360, Loss: 0.4925
Batch 370, Loss: 0.5051
Batch 380, Loss: 0.5144
Batch 390, Loss: 0.5501
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.162024974822998 seconds
Epoch 69 accuracy: 83.94%
Batch 10, Loss: 0.4995
Batch 20, Loss: 0.4876
Batch 30, Loss: 0.4856
Batch 40, Loss: 0.4820
Batch 50, Loss: 0.5020
Batch 60, Loss: 0.4888
Batch 70, Loss: 0.4824
Batch 80, Loss: 0.5265
Batch 90, Loss: 0.4800
Batch 100, Loss: 0.5165
Batch 110, Loss: 0.5060
Batch 120, Loss: 0.4957
Batch 130, Loss: 0.4946
Batch 140, Loss: 0.5421
Batch 150, Loss: 0.4830
Batch 160, Loss: 0.4726
Batch 170, Loss: 0.4776
Batch 180, Loss: 0.5186
Batch 190, Loss: 0.5045
Batch 200, Loss: 0.5012
Batch 210, Loss: 0.4806
Batch 220, Loss: 0.5039
Batch 230, Loss: 0.5193
Batch 240, Loss: 0.5260
Batch 250, Loss: 0.5098
Batch 260, Loss: 0.5263
Batch 270, Loss: 0.5400
Batch 280, Loss: 0.5198
Batch 290, Loss: 0.5183
Batch 300, Loss: 0.4901
Batch 310, Loss: 0.5228
Batch 320, Loss: 0.4877
Batch 330, Loss: 0.4767
Batch 340, Loss: 0.5377
Batch 350, Loss: 0.4843
Batch 360, Loss: 0.4986
Batch 370, Loss: 0.4770
Batch 380, Loss: 0.5109
Batch 390, Loss: 0.5100
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.14919662475586 seconds
Epoch 70 accuracy: 86.64%
Batch 10, Loss: 0.4903
Batch 20, Loss: 0.5159
Batch 30, Loss: 0.5237
Batch 40, Loss: 0.4886
Batch 50, Loss: 0.4976
Batch 60, Loss: 0.4732
Batch 70, Loss: 0.4750
Batch 80, Loss: 0.5100
Batch 90, Loss: 0.4883
Batch 100, Loss: 0.4600
Batch 110, Loss: 0.5053
Batch 120, Loss: 0.5475
Batch 130, Loss: 0.5279
Batch 140, Loss: 0.4898
Batch 150, Loss: 0.4923
Batch 160, Loss: 0.5310
Batch 170, Loss: 0.4727
Batch 180, Loss: 0.5136
Batch 190, Loss: 0.4829
Batch 200, Loss: 0.5170
Batch 210, Loss: 0.5095
Batch 220, Loss: 0.4730
Batch 230, Loss: 0.5066
Batch 240, Loss: 0.5082
Batch 250, Loss: 0.4979
Batch 260, Loss: 0.5202
Batch 270, Loss: 0.5087
Batch 280, Loss: 0.5286
Batch 290, Loss: 0.4580
Batch 300, Loss: 0.5230
Batch 310, Loss: 0.4988
Batch 320, Loss: 0.4563
Batch 330, Loss: 0.5056
Batch 340, Loss: 0.4866
Batch 350, Loss: 0.4919
Batch 360, Loss: 0.5090
Batch 370, Loss: 0.4988
Batch 380, Loss: 0.5153
Batch 390, Loss: 0.4815
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.15013313293457 seconds
Epoch 71 accuracy: 85.9%
Batch 10, Loss: 0.5092
Batch 20, Loss: 0.4582
Batch 30, Loss: 0.4836
Batch 40, Loss: 0.4906
Batch 50, Loss: 0.4807
Batch 60, Loss: 0.4814
Batch 70, Loss: 0.4655
Batch 80, Loss: 0.4982
Batch 90, Loss: 0.4900
Batch 100, Loss: 0.5440
Batch 110, Loss: 0.5239
Batch 120, Loss: 0.4247
Batch 130, Loss: 0.5062
Batch 140, Loss: 0.4714
Batch 150, Loss: 0.4649
Batch 160, Loss: 0.4940
Batch 170, Loss: 0.5139
Batch 180, Loss: 0.5177
Batch 190, Loss: 0.5003
Batch 200, Loss: 0.5050
Batch 210, Loss: 0.5077
Batch 220, Loss: 0.5426
Batch 230, Loss: 0.4824
Batch 240, Loss: 0.5264
Batch 250, Loss: 0.5417
Batch 260, Loss: 0.5150
Batch 270, Loss: 0.5091
Batch 280, Loss: 0.4920
Batch 290, Loss: 0.4905
Batch 300, Loss: 0.4913
Batch 310, Loss: 0.4895
Batch 320, Loss: 0.5412
Batch 330, Loss: 0.4835
Batch 340, Loss: 0.5176
Batch 350, Loss: 0.5099
Batch 360, Loss: 0.5171
Batch 370, Loss: 0.5070
Batch 380, Loss: 0.5323
Batch 390, Loss: 0.5182
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.18890929222107 seconds
Epoch 72 accuracy: 86.39%
Batch 10, Loss: 0.4524
Batch 20, Loss: 0.4653
Batch 30, Loss: 0.5036
Batch 40, Loss: 0.5178
Batch 50, Loss: 0.5035
Batch 60, Loss: 0.5239
Batch 70, Loss: 0.4915
Batch 80, Loss: 0.5302
Batch 90, Loss: 0.5361
Batch 100, Loss: 0.4968
Batch 110, Loss: 0.4897
Batch 120, Loss: 0.5413
Batch 130, Loss: 0.5059
Batch 140, Loss: 0.4861
Batch 150, Loss: 0.5222
Batch 160, Loss: 0.4544
Batch 170, Loss: 0.4904
Batch 180, Loss: 0.4816
Batch 190, Loss: 0.5065
Batch 200, Loss: 0.5041
Batch 210, Loss: 0.5034
Batch 220, Loss: 0.4971
Batch 230, Loss: 0.5047
Batch 240, Loss: 0.4886
Batch 250, Loss: 0.5028
Batch 260, Loss: 0.5022
Batch 270, Loss: 0.4988
Batch 280, Loss: 0.4870
Batch 290, Loss: 0.5311
Batch 300, Loss: 0.4839
Batch 310, Loss: 0.4872
Batch 320, Loss: 0.5339
Batch 330, Loss: 0.4694
Batch 340, Loss: 0.5069
Batch 350, Loss: 0.5088
Batch 360, Loss: 0.4999
Batch 370, Loss: 0.5504
Batch 380, Loss: 0.4991
Batch 390, Loss: 0.4984
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.161521434783936 seconds
Epoch 73 accuracy: 85.18%
Batch 10, Loss: 0.4783
Batch 20, Loss: 0.4764
Batch 30, Loss: 0.5195
Batch 40, Loss: 0.5338
Batch 50, Loss: 0.4692
Batch 60, Loss: 0.4755
Batch 70, Loss: 0.4975
Batch 80, Loss: 0.4962
Batch 90, Loss: 0.4974
Batch 100, Loss: 0.4895
Batch 110, Loss: 0.5024
Batch 120, Loss: 0.5053
Batch 130, Loss: 0.4952
Batch 140, Loss: 0.5003
Batch 150, Loss: 0.5100
Batch 160, Loss: 0.4857
Batch 170, Loss: 0.4686
Batch 180, Loss: 0.4835
Batch 190, Loss: 0.4657
Batch 200, Loss: 0.4627
Batch 210, Loss: 0.5003
Batch 220, Loss: 0.5237
Batch 230, Loss: 0.5015
Batch 240, Loss: 0.4516
Batch 250, Loss: 0.5000
Batch 260, Loss: 0.4797
Batch 270, Loss: 0.4784
Batch 280, Loss: 0.5090
Batch 290, Loss: 0.4952
Batch 300, Loss: 0.5172
Batch 310, Loss: 0.5174
Batch 320, Loss: 0.5031
Batch 330, Loss: 0.5420
Batch 340, Loss: 0.5481
Batch 350, Loss: 0.4829
Batch 360, Loss: 0.5145
Batch 370, Loss: 0.4896
Batch 380, Loss: 0.5007
Batch 390, Loss: 0.4393
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.194730281829834 seconds
Epoch 74 accuracy: 86.64%
Batch 10, Loss: 0.4991
Batch 20, Loss: 0.5129
Batch 30, Loss: 0.4826
Batch 40, Loss: 0.4636
Batch 50, Loss: 0.4654
Batch 60, Loss: 0.4689
Batch 70, Loss: 0.4968
Batch 80, Loss: 0.4984
Batch 90, Loss: 0.5093
Batch 100, Loss: 0.4984
Batch 110, Loss: 0.5144
Batch 120, Loss: 0.4763
Batch 130, Loss: 0.5126
Batch 140, Loss: 0.5118
Batch 150, Loss: 0.5034
Batch 160, Loss: 0.4859
Batch 170, Loss: 0.5020
Batch 180, Loss: 0.5208
Batch 190, Loss: 0.4986
Batch 200, Loss: 0.4795
Batch 210, Loss: 0.5123
Batch 220, Loss: 0.4894
Batch 230, Loss: 0.5304
Batch 240, Loss: 0.5371
Batch 250, Loss: 0.4886
Batch 260, Loss: 0.4744
Batch 270, Loss: 0.4765
Batch 280, Loss: 0.4569
Batch 290, Loss: 0.5161
Batch 300, Loss: 0.5340
Batch 310, Loss: 0.5048
Batch 320, Loss: 0.4765
Batch 330, Loss: 0.5010
Batch 340, Loss: 0.4773
Batch 350, Loss: 0.4495
Batch 360, Loss: 0.4984
Batch 370, Loss: 0.4831
Batch 380, Loss: 0.5078
Batch 390, Loss: 0.5251
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.176721334457397 seconds
Epoch 75 accuracy: 84.22%
Batch 10, Loss: 0.5116
Batch 20, Loss: 0.5025
Batch 30, Loss: 0.4680
Batch 40, Loss: 0.5005
Batch 50, Loss: 0.4823
Batch 60, Loss: 0.5212
Batch 70, Loss: 0.5063
Batch 80, Loss: 0.4914
Batch 90, Loss: 0.4770
Batch 100, Loss: 0.4569
Batch 110, Loss: 0.4670
Batch 120, Loss: 0.4979
Batch 130, Loss: 0.4858
Batch 140, Loss: 0.4508
Batch 150, Loss: 0.4697
Batch 160, Loss: 0.4614
Batch 170, Loss: 0.4330
Batch 180, Loss: 0.4559
Batch 190, Loss: 0.5207
Batch 200, Loss: 0.4860
Batch 210, Loss: 0.4868
Batch 220, Loss: 0.4885
Batch 230, Loss: 0.4812
Batch 240, Loss: 0.4992
Batch 250, Loss: 0.5296
Batch 260, Loss: 0.4480
Batch 270, Loss: 0.4770
Batch 280, Loss: 0.5122
Batch 290, Loss: 0.5072
Batch 300, Loss: 0.4799
Batch 310, Loss: 0.5168
Batch 320, Loss: 0.5333
Batch 330, Loss: 0.5144
Batch 340, Loss: 0.5036
Batch 350, Loss: 0.4776
Batch 360, Loss: 0.4641
Batch 370, Loss: 0.5194
Batch 380, Loss: 0.5039
Batch 390, Loss: 0.4882
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.12186098098755 seconds
Epoch 76 accuracy: 85.21%
Batch 10, Loss: 0.4701
Batch 20, Loss: 0.4720
Batch 30, Loss: 0.4621
Batch 40, Loss: 0.4621
Batch 50, Loss: 0.5031
Batch 60, Loss: 0.4843
Batch 70, Loss: 0.4422
Batch 80, Loss: 0.4995
Batch 90, Loss: 0.4818
Batch 100, Loss: 0.4426
Batch 110, Loss: 0.4710
Batch 120, Loss: 0.4903
Batch 130, Loss: 0.4786
Batch 140, Loss: 0.4664
Batch 150, Loss: 0.4757
Batch 160, Loss: 0.4941
Batch 170, Loss: 0.4835
Batch 180, Loss: 0.5070
Batch 190, Loss: 0.4793
Batch 200, Loss: 0.4672
Batch 210, Loss: 0.4838
Batch 220, Loss: 0.4775
Batch 230, Loss: 0.4955
Batch 240, Loss: 0.5330
Batch 250, Loss: 0.4491
Batch 260, Loss: 0.4675
Batch 270, Loss: 0.4692
Batch 280, Loss: 0.4669
Batch 290, Loss: 0.5383
Batch 300, Loss: 0.4624
Batch 310, Loss: 0.4852
Batch 320, Loss: 0.5064
Batch 330, Loss: 0.4870
Batch 340, Loss: 0.4739
Batch 350, Loss: 0.4963
Batch 360, Loss: 0.4720
Batch 370, Loss: 0.4787
Batch 380, Loss: 0.4742
Batch 390, Loss: 0.5194
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.153586626052856 seconds
Epoch 77 accuracy: 82.59%
Batch 10, Loss: 0.5208
Batch 20, Loss: 0.5062
Batch 30, Loss: 0.4570
Batch 40, Loss: 0.4849
Batch 50, Loss: 0.4694
Batch 60, Loss: 0.4747
Batch 70, Loss: 0.4804
Batch 80, Loss: 0.5158
Batch 90, Loss: 0.4941
Batch 100, Loss: 0.4771
Batch 110, Loss: 0.4927
Batch 120, Loss: 0.4683
Batch 130, Loss: 0.4793
Batch 140, Loss: 0.4594
Batch 150, Loss: 0.5098
Batch 160, Loss: 0.4548
Batch 170, Loss: 0.4671
Batch 180, Loss: 0.4478
Batch 190, Loss: 0.4983
Batch 200, Loss: 0.5189
Batch 210, Loss: 0.5132
Batch 220, Loss: 0.4636
Batch 230, Loss: 0.4528
Batch 240, Loss: 0.4775
Batch 250, Loss: 0.4747
Batch 260, Loss: 0.5317
Batch 270, Loss: 0.5074
Batch 280, Loss: 0.4914
Batch 290, Loss: 0.5154
Batch 300, Loss: 0.4865
Batch 310, Loss: 0.5111
Batch 320, Loss: 0.5429
Batch 330, Loss: 0.4932
Batch 340, Loss: 0.4712
Batch 350, Loss: 0.4977
Batch 360, Loss: 0.5448
Batch 370, Loss: 0.4625
Batch 380, Loss: 0.4763
Batch 390, Loss: 0.4781
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.115525484085083 seconds
Epoch 78 accuracy: 83.78%
Batch 10, Loss: 0.5054
Batch 20, Loss: 0.5118
Batch 30, Loss: 0.4670
Batch 40, Loss: 0.5004
Batch 50, Loss: 0.4844
Batch 60, Loss: 0.4981
Batch 70, Loss: 0.4489
Batch 80, Loss: 0.5108
Batch 90, Loss: 0.4569
Batch 100, Loss: 0.4891
Batch 110, Loss: 0.4597
Batch 120, Loss: 0.4951
Batch 130, Loss: 0.4827
Batch 140, Loss: 0.4512
Batch 150, Loss: 0.4737
Batch 160, Loss: 0.4618
Batch 170, Loss: 0.4822
Batch 180, Loss: 0.4872
Batch 190, Loss: 0.4788
Batch 200, Loss: 0.4543
Batch 210, Loss: 0.4781
Batch 220, Loss: 0.4700
Batch 230, Loss: 0.5036
Batch 240, Loss: 0.4763
Batch 250, Loss: 0.5415
Batch 260, Loss: 0.4863
Batch 270, Loss: 0.4771
Batch 280, Loss: 0.4966
Batch 290, Loss: 0.5048
Batch 300, Loss: 0.4450
Batch 310, Loss: 0.4635
Batch 320, Loss: 0.5028
Batch 330, Loss: 0.4760
Batch 340, Loss: 0.4752
Batch 350, Loss: 0.4679
Batch 360, Loss: 0.4737
Batch 370, Loss: 0.4837
Batch 380, Loss: 0.4822
Batch 390, Loss: 0.4876
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.131184339523315 seconds
Epoch 79 accuracy: 82.84%
Batch 10, Loss: 0.4659
Batch 20, Loss: 0.4516
Batch 30, Loss: 0.4709
Batch 40, Loss: 0.5041
Batch 50, Loss: 0.4413
Batch 60, Loss: 0.5029
Batch 70, Loss: 0.5336
Batch 80, Loss: 0.4808
Batch 90, Loss: 0.4715
Batch 100, Loss: 0.5108
Batch 110, Loss: 0.5284
Batch 120, Loss: 0.5052
Batch 130, Loss: 0.4838
Batch 140, Loss: 0.4704
Batch 150, Loss: 0.4440
Batch 160, Loss: 0.4611
Batch 170, Loss: 0.4935
Batch 180, Loss: 0.4491
Batch 190, Loss: 0.4666
Batch 200, Loss: 0.4568
Batch 210, Loss: 0.5045
Batch 220, Loss: 0.4822
Batch 230, Loss: 0.4931
Batch 240, Loss: 0.4959
Batch 250, Loss: 0.4808
Batch 260, Loss: 0.4897
Batch 270, Loss: 0.4761
Batch 280, Loss: 0.4453
Batch 290, Loss: 0.4909
Batch 300, Loss: 0.4865
Batch 310, Loss: 0.4919
Batch 320, Loss: 0.5311
Batch 330, Loss: 0.4731
Batch 340, Loss: 0.5115
Batch 350, Loss: 0.5088
Batch 360, Loss: 0.4750
Batch 370, Loss: 0.4789
Batch 380, Loss: 0.4831
Batch 390, Loss: 0.4514
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.23893928527832 seconds
Epoch 80 accuracy: 86.52%
Batch 10, Loss: 0.4281
Batch 20, Loss: 0.4503
Batch 30, Loss: 0.4913
Batch 40, Loss: 0.4529
Batch 50, Loss: 0.4720
Batch 60, Loss: 0.4542
Batch 70, Loss: 0.4539
Batch 80, Loss: 0.5113
Batch 90, Loss: 0.4509
Batch 100, Loss: 0.4952
Batch 110, Loss: 0.5103
Batch 120, Loss: 0.4342
Batch 130, Loss: 0.4597
Batch 140, Loss: 0.4878
Batch 150, Loss: 0.4819
Batch 160, Loss: 0.4765
Batch 170, Loss: 0.4877
Batch 180, Loss: 0.4415
Batch 190, Loss: 0.4769
Batch 200, Loss: 0.4763
Batch 210, Loss: 0.4831
Batch 220, Loss: 0.5076
Batch 230, Loss: 0.4730
Batch 240, Loss: 0.5004
Batch 250, Loss: 0.4389
Batch 260, Loss: 0.4889
Batch 270, Loss: 0.5072
Batch 280, Loss: 0.5101
Batch 290, Loss: 0.5075
Batch 300, Loss: 0.4501
Batch 310, Loss: 0.4719
Batch 320, Loss: 0.4669
Batch 330, Loss: 0.4788
Batch 340, Loss: 0.4949
Batch 350, Loss: 0.4898
Batch 360, Loss: 0.4698
Batch 370, Loss: 0.4862
Batch 380, Loss: 0.5216
Batch 390, Loss: 0.4875
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.110055685043335 seconds
Epoch 81 accuracy: 85.88%
Batch 10, Loss: 0.4486
Batch 20, Loss: 0.4665
Batch 30, Loss: 0.4436
Batch 40, Loss: 0.4683
Batch 50, Loss: 0.4373
Batch 60, Loss: 0.4561
Batch 70, Loss: 0.4619
Batch 80, Loss: 0.4987
Batch 90, Loss: 0.4435
Batch 100, Loss: 0.4468
Batch 110, Loss: 0.4588
Batch 120, Loss: 0.4731
Batch 130, Loss: 0.5296
Batch 140, Loss: 0.4801
Batch 150, Loss: 0.4608
Batch 160, Loss: 0.4443
Batch 170, Loss: 0.4751
Batch 180, Loss: 0.4769
Batch 190, Loss: 0.4830
Batch 200, Loss: 0.5209
Batch 210, Loss: 0.5305
Batch 220, Loss: 0.4556
Batch 230, Loss: 0.4553
Batch 240, Loss: 0.4891
Batch 250, Loss: 0.4847
Batch 260, Loss: 0.4789
Batch 270, Loss: 0.4693
Batch 280, Loss: 0.4676
Batch 290, Loss: 0.4806
Batch 300, Loss: 0.4667
Batch 310, Loss: 0.4893
Batch 320, Loss: 0.4851
Batch 330, Loss: 0.4849
Batch 340, Loss: 0.5011
Batch 350, Loss: 0.4698
Batch 360, Loss: 0.5147
Batch 370, Loss: 0.5028
Batch 380, Loss: 0.4847
Batch 390, Loss: 0.4362
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.23407220840454 seconds
Epoch 82 accuracy: 85.74%
Batch 10, Loss: 0.4723
Batch 20, Loss: 0.4412
Batch 30, Loss: 0.4694
Batch 40, Loss: 0.4699
Batch 50, Loss: 0.4805
Batch 60, Loss: 0.4295
Batch 70, Loss: 0.4419
Batch 80, Loss: 0.4967
Batch 90, Loss: 0.4566
Batch 100, Loss: 0.4606
Batch 110, Loss: 0.4852
Batch 120, Loss: 0.4863
Batch 130, Loss: 0.4627
Batch 140, Loss: 0.4616
Batch 150, Loss: 0.4782
Batch 160, Loss: 0.4739
Batch 170, Loss: 0.4835
Batch 180, Loss: 0.4848
Batch 190, Loss: 0.4982
Batch 200, Loss: 0.4365
Batch 210, Loss: 0.4544
Batch 220, Loss: 0.4479
Batch 230, Loss: 0.4780
Batch 240, Loss: 0.4521
Batch 250, Loss: 0.4864
Batch 260, Loss: 0.5022
Batch 270, Loss: 0.4592
Batch 280, Loss: 0.4863
Batch 290, Loss: 0.5084
Batch 300, Loss: 0.4768
Batch 310, Loss: 0.4916
Batch 320, Loss: 0.4669
Batch 330, Loss: 0.4811
Batch 340, Loss: 0.4986
Batch 350, Loss: 0.4783
Batch 360, Loss: 0.4599
Batch 370, Loss: 0.4701
Batch 380, Loss: 0.4763
Batch 390, Loss: 0.4821
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.113544464111328 seconds
Epoch 83 accuracy: 84.92%
Batch 10, Loss: 0.4147
Batch 20, Loss: 0.4171
Batch 30, Loss: 0.4692
Batch 40, Loss: 0.4457
Batch 50, Loss: 0.4628
Batch 60, Loss: 0.4515
Batch 70, Loss: 0.4816
Batch 80, Loss: 0.4717
Batch 90, Loss: 0.4839
Batch 100, Loss: 0.4759
Batch 110, Loss: 0.4629
Batch 120, Loss: 0.4819
Batch 130, Loss: 0.4516
Batch 140, Loss: 0.4615
Batch 150, Loss: 0.4315
Batch 160, Loss: 0.4554
Batch 170, Loss: 0.4453
Batch 180, Loss: 0.4921
Batch 190, Loss: 0.4788
Batch 200, Loss: 0.5038
Batch 210, Loss: 0.4567
Batch 220, Loss: 0.4825
Batch 230, Loss: 0.4813
Batch 240, Loss: 0.4687
Batch 250, Loss: 0.5033
Batch 260, Loss: 0.4864
Batch 270, Loss: 0.4912
Batch 280, Loss: 0.4970
Batch 290, Loss: 0.4648
Batch 300, Loss: 0.4792
Batch 310, Loss: 0.4745
Batch 320, Loss: 0.4770
Batch 330, Loss: 0.4807
Batch 340, Loss: 0.5098
Batch 350, Loss: 0.4597
Batch 360, Loss: 0.4953
Batch 370, Loss: 0.4635
Batch 380, Loss: 0.4848
Batch 390, Loss: 0.4552
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.217760801315308 seconds
Epoch 84 accuracy: 81.39%
Batch 10, Loss: 0.4571
Batch 20, Loss: 0.4878
Batch 30, Loss: 0.5277
Batch 40, Loss: 0.5079
Batch 50, Loss: 0.4813
Batch 60, Loss: 0.4900
Batch 70, Loss: 0.4607
Batch 80, Loss: 0.4587
Batch 90, Loss: 0.4310
Batch 100, Loss: 0.4555
Batch 110, Loss: 0.4666
Batch 120, Loss: 0.5209
Batch 130, Loss: 0.4580
Batch 140, Loss: 0.4611
Batch 150, Loss: 0.4628
Batch 160, Loss: 0.5084
Batch 170, Loss: 0.4668
Batch 180, Loss: 0.4517
Batch 190, Loss: 0.4569
Batch 200, Loss: 0.4429
Batch 210, Loss: 0.4536
Batch 220, Loss: 0.4886
Batch 230, Loss: 0.4927
Batch 240, Loss: 0.4924
Batch 250, Loss: 0.5138
Batch 260, Loss: 0.4968
Batch 270, Loss: 0.4813
Batch 280, Loss: 0.4255
Batch 290, Loss: 0.4418
Batch 300, Loss: 0.4859
Batch 310, Loss: 0.5060
Batch 320, Loss: 0.4629
Batch 330, Loss: 0.5010
Batch 340, Loss: 0.4972
Batch 350, Loss: 0.4641
Batch 360, Loss: 0.4417
Batch 370, Loss: 0.4486
Batch 380, Loss: 0.4672
Batch 390, Loss: 0.4748
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.09001064300537 seconds
Epoch 85 accuracy: 85.65%
Batch 10, Loss: 0.4794
Batch 20, Loss: 0.4953
Batch 30, Loss: 0.5006
Batch 40, Loss: 0.4660
Batch 50, Loss: 0.4356
Batch 60, Loss: 0.4396
Batch 70, Loss: 0.4927
Batch 80, Loss: 0.4182
Batch 90, Loss: 0.4876
Batch 100, Loss: 0.4713
Batch 110, Loss: 0.4879
Batch 120, Loss: 0.4988
Batch 130, Loss: 0.4723
Batch 140, Loss: 0.4744
Batch 150, Loss: 0.4937
Batch 160, Loss: 0.4915
Batch 170, Loss: 0.4782
Batch 180, Loss: 0.4915
Batch 190, Loss: 0.4069
Batch 200, Loss: 0.5114
Batch 210, Loss: 0.5260
Batch 220, Loss: 0.4880
Batch 230, Loss: 0.4835
Batch 240, Loss: 0.4550
Batch 250, Loss: 0.4998
Batch 260, Loss: 0.4604
Batch 270, Loss: 0.4886
Batch 280, Loss: 0.4717
Batch 290, Loss: 0.4515
Batch 300, Loss: 0.4444
Batch 310, Loss: 0.4430
Batch 320, Loss: 0.5063
Batch 330, Loss: 0.4230
Batch 340, Loss: 0.4492
Batch 350, Loss: 0.4614
Batch 360, Loss: 0.4754
Batch 370, Loss: 0.4778
Batch 380, Loss: 0.5082
Batch 390, Loss: 0.4560
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.172603368759155 seconds
Epoch 86 accuracy: 86.71%
Batch 10, Loss: 0.4679
Batch 20, Loss: 0.4447
Batch 30, Loss: 0.4657
Batch 40, Loss: 0.4817
Batch 50, Loss: 0.4867
Batch 60, Loss: 0.4820
Batch 70, Loss: 0.4374
Batch 80, Loss: 0.4456
Batch 90, Loss: 0.4680
Batch 100, Loss: 0.4844
Batch 110, Loss: 0.4667
Batch 120, Loss: 0.4474
Batch 130, Loss: 0.4972
Batch 140, Loss: 0.4814
Batch 150, Loss: 0.4846
Batch 160, Loss: 0.4666
Batch 170, Loss: 0.5046
Batch 180, Loss: 0.4655
Batch 190, Loss: 0.4697
Batch 200, Loss: 0.4705
Batch 210, Loss: 0.4401
Batch 220, Loss: 0.4516
Batch 230, Loss: 0.4500
Batch 240, Loss: 0.4498
Batch 250, Loss: 0.4675
Batch 260, Loss: 0.4568
Batch 270, Loss: 0.4571
Batch 280, Loss: 0.4721
Batch 290, Loss: 0.4982
Batch 300, Loss: 0.4534
Batch 310, Loss: 0.4802
Batch 320, Loss: 0.4658
Batch 330, Loss: 0.4888
Batch 340, Loss: 0.4930
Batch 350, Loss: 0.5254
Batch 360, Loss: 0.5166
Batch 370, Loss: 0.4499
Batch 380, Loss: 0.4720
Batch 390, Loss: 0.5046
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.196903467178345 seconds
Epoch 87 accuracy: 88.24%
Batch 10, Loss: 0.4533
Batch 20, Loss: 0.4369
Batch 30, Loss: 0.4256
Batch 40, Loss: 0.4360
Batch 50, Loss: 0.4212
Batch 60, Loss: 0.4824
Batch 70, Loss: 0.4744
Batch 80, Loss: 0.4735
Batch 90, Loss: 0.5013
Batch 100, Loss: 0.4704
Batch 110, Loss: 0.5016
Batch 120, Loss: 0.4461
Batch 130, Loss: 0.4684
Batch 140, Loss: 0.4689
Batch 150, Loss: 0.4389
Batch 160, Loss: 0.4780
Batch 170, Loss: 0.4776
Batch 180, Loss: 0.4548
Batch 190, Loss: 0.4847
Batch 200, Loss: 0.4764
Batch 210, Loss: 0.4552
Batch 220, Loss: 0.4601
Batch 230, Loss: 0.4853
Batch 240, Loss: 0.5031
Batch 250, Loss: 0.4459
Batch 260, Loss: 0.4783
Batch 270, Loss: 0.4714
Batch 280, Loss: 0.4711
Batch 290, Loss: 0.4340
Batch 300, Loss: 0.4853
Batch 310, Loss: 0.4779
Batch 320, Loss: 0.4589
Batch 330, Loss: 0.4806
Batch 340, Loss: 0.4604
Batch 350, Loss: 0.4598
Batch 360, Loss: 0.4615
Batch 370, Loss: 0.4659
Batch 380, Loss: 0.4701
Batch 390, Loss: 0.4851
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.068606853485107 seconds
Epoch 88 accuracy: 87.86%
Batch 10, Loss: 0.4718
Batch 20, Loss: 0.4405
Batch 30, Loss: 0.3996
Batch 40, Loss: 0.4442
Batch 50, Loss: 0.4927
Batch 60, Loss: 0.5037
Batch 70, Loss: 0.4495
Batch 80, Loss: 0.4512
Batch 90, Loss: 0.4696
Batch 100, Loss: 0.4141
Batch 110, Loss: 0.4288
Batch 120, Loss: 0.4709
Batch 130, Loss: 0.4230
Batch 140, Loss: 0.4207
Batch 150, Loss: 0.4531
Batch 160, Loss: 0.4747
Batch 170, Loss: 0.4663
Batch 180, Loss: 0.4560
Batch 190, Loss: 0.4499
Batch 200, Loss: 0.4488
Batch 210, Loss: 0.4436
Batch 220, Loss: 0.5207
Batch 230, Loss: 0.4597
Batch 240, Loss: 0.4528
Batch 250, Loss: 0.4887
Batch 260, Loss: 0.4469
Batch 270, Loss: 0.4490
Batch 280, Loss: 0.4761
Batch 290, Loss: 0.4940
Batch 300, Loss: 0.4704
Batch 310, Loss: 0.5061
Batch 320, Loss: 0.4900
Batch 330, Loss: 0.4676
Batch 340, Loss: 0.4682
Batch 350, Loss: 0.4901
Batch 360, Loss: 0.4947
Batch 370, Loss: 0.4716
Batch 380, Loss: 0.4752
Batch 390, Loss: 0.4746
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.11628484725952 seconds
Epoch 89 accuracy: 87.02%
Batch 10, Loss: 0.4907
Batch 20, Loss: 0.4465
Batch 30, Loss: 0.4538
Batch 40, Loss: 0.4594
Batch 50, Loss: 0.4670
Batch 60, Loss: 0.4249
Batch 70, Loss: 0.4444
Batch 80, Loss: 0.4545
Batch 90, Loss: 0.5106
Batch 100, Loss: 0.4611
Batch 110, Loss: 0.4398
Batch 120, Loss: 0.4497
Batch 130, Loss: 0.4623
Batch 140, Loss: 0.4449
Batch 150, Loss: 0.4417
Batch 160, Loss: 0.4409
Batch 170, Loss: 0.4399
Batch 180, Loss: 0.4473
Batch 190, Loss: 0.4623
Batch 200, Loss: 0.4472
Batch 210, Loss: 0.4565
Batch 220, Loss: 0.4248
Batch 230, Loss: 0.4321
Batch 240, Loss: 0.4655
Batch 250, Loss: 0.4979
Batch 260, Loss: 0.4535
Batch 270, Loss: 0.4651
Batch 280, Loss: 0.4721
Batch 290, Loss: 0.4300
Batch 300, Loss: 0.4543
Batch 310, Loss: 0.4259
Batch 320, Loss: 0.4550
Batch 330, Loss: 0.4954
Batch 340, Loss: 0.4296
Batch 350, Loss: 0.4671
Batch 360, Loss: 0.4720
Batch 370, Loss: 0.4468
Batch 380, Loss: 0.4628
Batch 390, Loss: 0.4401
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.159109115600586 seconds
Epoch 90 accuracy: 88.06%
Batch 10, Loss: 0.4349
Batch 20, Loss: 0.4896
Batch 30, Loss: 0.4647
Batch 40, Loss: 0.5013
Batch 50, Loss: 0.4638
Batch 60, Loss: 0.3893
Batch 70, Loss: 0.4390
Batch 80, Loss: 0.4489
Batch 90, Loss: 0.4285
Batch 100, Loss: 0.4477
Batch 110, Loss: 0.4765
Batch 120, Loss: 0.4850
Batch 130, Loss: 0.5053
Batch 140, Loss: 0.4678
Batch 150, Loss: 0.4121
Batch 160, Loss: 0.4483
Batch 170, Loss: 0.4125
Batch 180, Loss: 0.4279
Batch 190, Loss: 0.4558
Batch 200, Loss: 0.4555
Batch 210, Loss: 0.4526
Batch 220, Loss: 0.4562
Batch 230, Loss: 0.4826
Batch 240, Loss: 0.4914
Batch 250, Loss: 0.4756
Batch 260, Loss: 0.4747
Batch 270, Loss: 0.4378
Batch 280, Loss: 0.4736
Batch 290, Loss: 0.4897
Batch 300, Loss: 0.4562
Batch 310, Loss: 0.4820
Batch 320, Loss: 0.4545
Batch 330, Loss: 0.4452
Batch 340, Loss: 0.4983
Batch 350, Loss: 0.4856
Batch 360, Loss: 0.4534
Batch 370, Loss: 0.4486
Batch 380, Loss: 0.4444
Batch 390, Loss: 0.4439
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.207091569900513 seconds
Epoch 91 accuracy: 85.1%
Batch 10, Loss: 0.4539
Batch 20, Loss: 0.4227
Batch 30, Loss: 0.4362
Batch 40, Loss: 0.4597
Batch 50, Loss: 0.4592
Batch 60, Loss: 0.4761
Batch 70, Loss: 0.4405
Batch 80, Loss: 0.4104
Batch 90, Loss: 0.4319
Batch 100, Loss: 0.4633
Batch 110, Loss: 0.4652
Batch 120, Loss: 0.4431
Batch 130, Loss: 0.4853
Batch 140, Loss: 0.4381
Batch 150, Loss: 0.4592
Batch 160, Loss: 0.4467
Batch 170, Loss: 0.4628
Batch 180, Loss: 0.4654
Batch 190, Loss: 0.4589
Batch 200, Loss: 0.4633
Batch 210, Loss: 0.4603
Batch 220, Loss: 0.4957
Batch 230, Loss: 0.4552
Batch 240, Loss: 0.4779
Batch 250, Loss: 0.4521
Batch 260, Loss: 0.4382
Batch 270, Loss: 0.4382
Batch 280, Loss: 0.4395
Batch 290, Loss: 0.4785
Batch 300, Loss: 0.4693
Batch 310, Loss: 0.4710
Batch 320, Loss: 0.4787
Batch 330, Loss: 0.4707
Batch 340, Loss: 0.4560
Batch 350, Loss: 0.4915
Batch 360, Loss: 0.4242
Batch 370, Loss: 0.4590
Batch 380, Loss: 0.4461
Batch 390, Loss: 0.4507
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.06088089942932 seconds
Epoch 92 accuracy: 86.19%
Batch 10, Loss: 0.4418
Batch 20, Loss: 0.4445
Batch 30, Loss: 0.4715
Batch 40, Loss: 0.4495
Batch 50, Loss: 0.4711
Batch 60, Loss: 0.4278
Batch 70, Loss: 0.4202
Batch 80, Loss: 0.4265
Batch 90, Loss: 0.4393
Batch 100, Loss: 0.4914
Batch 110, Loss: 0.4137
Batch 120, Loss: 0.4613
Batch 130, Loss: 0.4321
Batch 140, Loss: 0.4321
Batch 150, Loss: 0.4825
Batch 160, Loss: 0.4826
Batch 170, Loss: 0.4697
Batch 180, Loss: 0.4656
Batch 190, Loss: 0.4570
Batch 200, Loss: 0.4079
Batch 210, Loss: 0.4332
Batch 220, Loss: 0.4066
Batch 230, Loss: 0.4596
Batch 240, Loss: 0.4840
Batch 250, Loss: 0.4639
Batch 260, Loss: 0.4803
Batch 270, Loss: 0.4550
Batch 280, Loss: 0.4534
Batch 290, Loss: 0.4505
Batch 300, Loss: 0.4572
Batch 310, Loss: 0.4631
Batch 320, Loss: 0.4768
Batch 330, Loss: 0.4549
Batch 340, Loss: 0.4237
Batch 350, Loss: 0.4442
Batch 360, Loss: 0.4484
Batch 370, Loss: 0.4355
Batch 380, Loss: 0.4351
Batch 390, Loss: 0.4428
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.134297370910645 seconds
Epoch 93 accuracy: 86.68%
Batch 10, Loss: 0.4438
Batch 20, Loss: 0.4207
Batch 30, Loss: 0.4462
Batch 40, Loss: 0.4553
Batch 50, Loss: 0.4334
Batch 60, Loss: 0.4235
Batch 70, Loss: 0.4795
Batch 80, Loss: 0.4476
Batch 90, Loss: 0.4569
Batch 100, Loss: 0.4634
Batch 110, Loss: 0.4563
Batch 120, Loss: 0.4430
Batch 130, Loss: 0.4410
Batch 140, Loss: 0.4411
Batch 150, Loss: 0.4435
Batch 160, Loss: 0.4473
Batch 170, Loss: 0.4318
Batch 180, Loss: 0.4755
Batch 190, Loss: 0.4682
Batch 200, Loss: 0.4841
Batch 210, Loss: 0.4751
Batch 220, Loss: 0.4693
Batch 230, Loss: 0.4595
Batch 240, Loss: 0.4261
Batch 250, Loss: 0.4096
Batch 260, Loss: 0.4434
Batch 270, Loss: 0.4626
Batch 280, Loss: 0.4507
Batch 290, Loss: 0.4529
Batch 300, Loss: 0.4451
Batch 310, Loss: 0.4670
Batch 320, Loss: 0.4229
Batch 330, Loss: 0.4887
Batch 340, Loss: 0.4609
Batch 350, Loss: 0.4546
Batch 360, Loss: 0.4771
Batch 370, Loss: 0.4325
Batch 380, Loss: 0.4927
Batch 390, Loss: 0.4294
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.230671405792236 seconds
Epoch 94 accuracy: 87.87%
Batch 10, Loss: 0.4602
Batch 20, Loss: 0.4469
Batch 30, Loss: 0.4493
Batch 40, Loss: 0.4244
Batch 50, Loss: 0.4162
Batch 60, Loss: 0.4894
Batch 70, Loss: 0.4409
Batch 80, Loss: 0.4469
Batch 90, Loss: 0.4874
Batch 100, Loss: 0.4373
Batch 110, Loss: 0.4212
Batch 120, Loss: 0.4593
Batch 130, Loss: 0.4243
Batch 140, Loss: 0.4518
Batch 150, Loss: 0.4599
Batch 160, Loss: 0.4692
Batch 170, Loss: 0.4255
Batch 180, Loss: 0.4727
Batch 190, Loss: 0.4270
Batch 200, Loss: 0.4411
Batch 210, Loss: 0.4643
Batch 220, Loss: 0.4577
Batch 230, Loss: 0.4712
Batch 240, Loss: 0.4456
Batch 250, Loss: 0.4421
Batch 260, Loss: 0.4690
Batch 270, Loss: 0.4602
Batch 280, Loss: 0.4303
Batch 290, Loss: 0.4547
Batch 300, Loss: 0.4607
Batch 310, Loss: 0.4696
Batch 320, Loss: 0.4549
Batch 330, Loss: 0.4667
Batch 340, Loss: 0.5033
Batch 350, Loss: 0.4639
Batch 360, Loss: 0.4815
Batch 370, Loss: 0.4360
Batch 380, Loss: 0.4727
Batch 390, Loss: 0.4233
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.055443286895752 seconds
Epoch 95 accuracy: 87.61%
Batch 10, Loss: 0.4166
Batch 20, Loss: 0.4241
Batch 30, Loss: 0.4265
Batch 40, Loss: 0.4635
Batch 50, Loss: 0.4203
Batch 60, Loss: 0.4096
Batch 70, Loss: 0.4899
Batch 80, Loss: 0.4625
Batch 90, Loss: 0.4679
Batch 100, Loss: 0.4280
Batch 110, Loss: 0.4516
Batch 120, Loss: 0.4418
Batch 130, Loss: 0.4275
Batch 140, Loss: 0.4549
Batch 150, Loss: 0.4311
Batch 160, Loss: 0.4511
Batch 170, Loss: 0.4455
Batch 180, Loss: 0.4566
Batch 190, Loss: 0.4190
Batch 200, Loss: 0.4469
Batch 210, Loss: 0.4817
Batch 220, Loss: 0.4380
Batch 230, Loss: 0.4480
Batch 240, Loss: 0.4440
Batch 250, Loss: 0.4523
Batch 260, Loss: 0.4135
Batch 270, Loss: 0.4657
Batch 280, Loss: 0.4593
Batch 290, Loss: 0.4406
Batch 300, Loss: 0.4469
Batch 310, Loss: 0.4165
Batch 320, Loss: 0.4326
Batch 330, Loss: 0.4276
Batch 340, Loss: 0.4517
Batch 350, Loss: 0.4523
Batch 360, Loss: 0.4676
Batch 370, Loss: 0.4664
Batch 380, Loss: 0.4590
Batch 390, Loss: 0.4255
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.18318748474121 seconds
Epoch 96 accuracy: 88.28%
Batch 10, Loss: 0.4260
Batch 20, Loss: 0.4089
Batch 30, Loss: 0.4593
Batch 40, Loss: 0.4292
Batch 50, Loss: 0.4287
Batch 60, Loss: 0.4421
Batch 70, Loss: 0.4649
Batch 80, Loss: 0.4303
Batch 90, Loss: 0.4390
Batch 100, Loss: 0.3992
Batch 110, Loss: 0.4317
Batch 120, Loss: 0.4251
Batch 130, Loss: 0.4905
Batch 140, Loss: 0.4534
Batch 150, Loss: 0.4629
Batch 160, Loss: 0.4819
Batch 170, Loss: 0.3968
Batch 180, Loss: 0.4308
Batch 190, Loss: 0.4016
Batch 200, Loss: 0.4186
Batch 210, Loss: 0.4210
Batch 220, Loss: 0.4508
Batch 230, Loss: 0.4493
Batch 240, Loss: 0.4155
Batch 250, Loss: 0.4274
Batch 260, Loss: 0.4475
Batch 270, Loss: 0.4708
Batch 280, Loss: 0.4673
Batch 290, Loss: 0.5035
Batch 300, Loss: 0.4974
Batch 310, Loss: 0.4203
Batch 320, Loss: 0.4137
Batch 330, Loss: 0.4119
Batch 340, Loss: 0.4402
Batch 350, Loss: 0.4590
Batch 360, Loss: 0.4469
Batch 370, Loss: 0.4365
Batch 380, Loss: 0.4723
Batch 390, Loss: 0.4347
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.19522738456726 seconds
Epoch 97 accuracy: 88.84%
Batch 10, Loss: 0.4561
Batch 20, Loss: 0.4202
Batch 30, Loss: 0.4880
Batch 40, Loss: 0.4553
Batch 50, Loss: 0.4815
Batch 60, Loss: 0.4540
Batch 70, Loss: 0.4345
Batch 80, Loss: 0.4386
Batch 90, Loss: 0.4468
Batch 100, Loss: 0.4353
Batch 110, Loss: 0.3968
Batch 120, Loss: 0.4537
Batch 130, Loss: 0.4243
Batch 140, Loss: 0.4316
Batch 150, Loss: 0.4148
Batch 160, Loss: 0.4359
Batch 170, Loss: 0.4576
Batch 180, Loss: 0.4127
Batch 190, Loss: 0.4476
Batch 200, Loss: 0.4262
Batch 210, Loss: 0.4207
Batch 220, Loss: 0.4448
Batch 230, Loss: 0.4403
Batch 240, Loss: 0.4620
Batch 250, Loss: 0.4435
Batch 260, Loss: 0.4746
Batch 270, Loss: 0.4344
Batch 280, Loss: 0.4251
Batch 290, Loss: 0.4291
Batch 300, Loss: 0.4328
Batch 310, Loss: 0.4642
Batch 320, Loss: 0.4675
Batch 330, Loss: 0.4699
Batch 340, Loss: 0.4449
Batch 350, Loss: 0.4310
Batch 360, Loss: 0.4516
Batch 370, Loss: 0.4498
Batch 380, Loss: 0.4681
Batch 390, Loss: 0.4364
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.17919683456421 seconds
Epoch 98 accuracy: 89.41%
Batch 10, Loss: 0.4047
Batch 20, Loss: 0.4285
Batch 30, Loss: 0.4468
Batch 40, Loss: 0.4640
Batch 50, Loss: 0.4082
Batch 60, Loss: 0.4141
Batch 70, Loss: 0.4712
Batch 80, Loss: 0.4638
Batch 90, Loss: 0.4733
Batch 100, Loss: 0.4426
Batch 110, Loss: 0.4179
Batch 120, Loss: 0.3893
Batch 130, Loss: 0.4205
Batch 140, Loss: 0.4352
Batch 150, Loss: 0.4711
Batch 160, Loss: 0.4509
Batch 170, Loss: 0.4306
Batch 180, Loss: 0.4108
Batch 190, Loss: 0.4156
Batch 200, Loss: 0.4446
Batch 210, Loss: 0.4246
Batch 220, Loss: 0.4346
Batch 230, Loss: 0.4898
Batch 240, Loss: 0.4659
Batch 250, Loss: 0.4413
Batch 260, Loss: 0.4470
Batch 270, Loss: 0.4567
Batch 280, Loss: 0.4205
Batch 290, Loss: 0.3975
Batch 300, Loss: 0.4547
Batch 310, Loss: 0.4593
Batch 320, Loss: 0.4528
Batch 330, Loss: 0.4146
Batch 340, Loss: 0.4568
Batch 350, Loss: 0.4267
Batch 360, Loss: 0.4160
Batch 370, Loss: 0.4333
Batch 380, Loss: 0.4046
Batch 390, Loss: 0.4438
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.131153345108032 seconds
Epoch 99 accuracy: 87.01%
Batch 10, Loss: 0.4006
Batch 20, Loss: 0.4497
Batch 30, Loss: 0.4532
Batch 40, Loss: 0.4274
Batch 50, Loss: 0.4535
Batch 60, Loss: 0.4460
Batch 70, Loss: 0.4019
Batch 80, Loss: 0.4462
Batch 90, Loss: 0.4323
Batch 100, Loss: 0.4326
Batch 110, Loss: 0.4203
Batch 120, Loss: 0.4354
Batch 130, Loss: 0.4649
Batch 140, Loss: 0.4287
Batch 150, Loss: 0.4035
Batch 160, Loss: 0.4397
Batch 170, Loss: 0.4227
Batch 180, Loss: 0.4165
Batch 190, Loss: 0.4499
Batch 200, Loss: 0.4287
Batch 210, Loss: 0.3947
Batch 220, Loss: 0.4024
Batch 230, Loss: 0.4289
Batch 240, Loss: 0.4231
Batch 250, Loss: 0.4217
Batch 260, Loss: 0.4441
Batch 270, Loss: 0.4528
Batch 280, Loss: 0.4343
Batch 290, Loss: 0.4249
Batch 300, Loss: 0.4288
Batch 310, Loss: 0.4195
Batch 320, Loss: 0.4435
Batch 330, Loss: 0.4423
Batch 340, Loss: 0.4484
Batch 350, Loss: 0.4767
Batch 360, Loss: 0.4760
Batch 370, Loss: 0.4259
Batch 380, Loss: 0.3955
Batch 390, Loss: 0.4420
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.11441922187805 seconds
Epoch 100 accuracy: 89.4%
Batch 10, Loss: 0.4175
Batch 20, Loss: 0.4483
Batch 30, Loss: 0.4219
Batch 40, Loss: 0.4429
Batch 50, Loss: 0.3917
Batch 60, Loss: 0.4147
Batch 70, Loss: 0.4369
Batch 80, Loss: 0.3970
Batch 90, Loss: 0.4338
Batch 100, Loss: 0.4665
Batch 110, Loss: 0.4487
Batch 120, Loss: 0.4453
Batch 130, Loss: 0.4484
Batch 140, Loss: 0.4517
Batch 150, Loss: 0.4187
Batch 160, Loss: 0.4238
Batch 170, Loss: 0.4676
Batch 180, Loss: 0.4161
Batch 190, Loss: 0.4276
Batch 200, Loss: 0.4167
Batch 210, Loss: 0.4219
Batch 220, Loss: 0.4580
Batch 230, Loss: 0.3836
Batch 240, Loss: 0.4361
Batch 250, Loss: 0.4437
Batch 260, Loss: 0.4459
Batch 270, Loss: 0.4097
Batch 280, Loss: 0.4351
Batch 290, Loss: 0.4442
Batch 300, Loss: 0.4013
Batch 310, Loss: 0.4245
Batch 320, Loss: 0.4558
Batch 330, Loss: 0.4494
Batch 340, Loss: 0.4314
Batch 350, Loss: 0.4045
Batch 360, Loss: 0.4045
Batch 370, Loss: 0.4409
Batch 380, Loss: 0.4035
Batch 390, Loss: 0.4210
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.181947946548462 seconds
Epoch 101 accuracy: 88.92%
Batch 10, Loss: 0.3927
Batch 20, Loss: 0.4023
Batch 30, Loss: 0.4041
Batch 40, Loss: 0.4462
Batch 50, Loss: 0.4191
Batch 60, Loss: 0.4201
Batch 70, Loss: 0.4281
Batch 80, Loss: 0.4058
Batch 90, Loss: 0.4046
Batch 100, Loss: 0.4170
Batch 110, Loss: 0.4329
Batch 120, Loss: 0.4524
Batch 130, Loss: 0.4864
Batch 140, Loss: 0.4114
Batch 150, Loss: 0.4128
Batch 160, Loss: 0.4078
Batch 170, Loss: 0.3986
Batch 180, Loss: 0.4265
Batch 190, Loss: 0.3878
Batch 200, Loss: 0.4121
Batch 210, Loss: 0.4080
Batch 220, Loss: 0.4464
Batch 230, Loss: 0.4420
Batch 240, Loss: 0.4095
Batch 250, Loss: 0.4097
Batch 260, Loss: 0.4329
Batch 270, Loss: 0.4410
Batch 280, Loss: 0.4379
Batch 290, Loss: 0.4385
Batch 300, Loss: 0.4312
Batch 310, Loss: 0.4828
Batch 320, Loss: 0.4262
Batch 330, Loss: 0.4151
Batch 340, Loss: 0.4619
Batch 350, Loss: 0.4445
Batch 360, Loss: 0.4773
Batch 370, Loss: 0.4620
Batch 380, Loss: 0.4107
Batch 390, Loss: 0.4566
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.154412984848022 seconds
Epoch 102 accuracy: 88.65%
Batch 10, Loss: 0.4560
Batch 20, Loss: 0.4327
Batch 30, Loss: 0.3989
Batch 40, Loss: 0.4154
Batch 50, Loss: 0.3753
Batch 60, Loss: 0.4008
Batch 70, Loss: 0.4424
Batch 80, Loss: 0.4238
Batch 90, Loss: 0.4432
Batch 100, Loss: 0.4045
Batch 110, Loss: 0.4295
Batch 120, Loss: 0.4421
Batch 130, Loss: 0.4229
Batch 140, Loss: 0.4608
Batch 150, Loss: 0.4663
Batch 160, Loss: 0.4253
Batch 170, Loss: 0.4387
Batch 180, Loss: 0.4408
Batch 190, Loss: 0.4287
Batch 200, Loss: 0.4372
Batch 210, Loss: 0.4163
Batch 220, Loss: 0.4517
Batch 230, Loss: 0.4023
Batch 240, Loss: 0.4418
Batch 250, Loss: 0.4041
Batch 260, Loss: 0.4603
Batch 270, Loss: 0.4374
Batch 280, Loss: 0.4511
Batch 290, Loss: 0.3994
Batch 300, Loss: 0.4295
Batch 310, Loss: 0.4472
Batch 320, Loss: 0.4089
Batch 330, Loss: 0.4074
Batch 340, Loss: 0.4304
Batch 350, Loss: 0.4270
Batch 360, Loss: 0.4345
Batch 370, Loss: 0.4352
Batch 380, Loss: 0.4603
Batch 390, Loss: 0.3939
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.1145920753479 seconds
Epoch 103 accuracy: 88.56%
Batch 10, Loss: 0.4065
Batch 20, Loss: 0.3928
Batch 30, Loss: 0.4434
Batch 40, Loss: 0.4368
Batch 50, Loss: 0.4731
Batch 60, Loss: 0.4550
Batch 70, Loss: 0.4478
Batch 80, Loss: 0.3941
Batch 90, Loss: 0.4128
Batch 100, Loss: 0.3740
Batch 110, Loss: 0.4206
Batch 120, Loss: 0.4348
Batch 130, Loss: 0.4025
Batch 140, Loss: 0.4610
Batch 150, Loss: 0.4250
Batch 160, Loss: 0.4422
Batch 170, Loss: 0.4241
Batch 180, Loss: 0.4490
Batch 190, Loss: 0.3815
Batch 200, Loss: 0.4468
Batch 210, Loss: 0.4359
Batch 220, Loss: 0.4578
Batch 230, Loss: 0.4341
Batch 240, Loss: 0.4194
Batch 250, Loss: 0.4131
Batch 260, Loss: 0.4367
Batch 270, Loss: 0.4228
Batch 280, Loss: 0.4459
Batch 290, Loss: 0.3875
Batch 300, Loss: 0.4028
Batch 310, Loss: 0.4531
Batch 320, Loss: 0.4249
Batch 330, Loss: 0.4699
Batch 340, Loss: 0.4331
Batch 350, Loss: 0.4454
Batch 360, Loss: 0.4032
Batch 370, Loss: 0.4507
Batch 380, Loss: 0.4067
Batch 390, Loss: 0.4319
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.08517360687256 seconds
Epoch 104 accuracy: 89.03%
Batch 10, Loss: 0.3986
Batch 20, Loss: 0.4503
Batch 30, Loss: 0.4626
Batch 40, Loss: 0.4133
Batch 50, Loss: 0.4207
Batch 60, Loss: 0.3935
Batch 70, Loss: 0.4130
Batch 80, Loss: 0.4304
Batch 90, Loss: 0.3873
Batch 100, Loss: 0.4206
Batch 110, Loss: 0.4405
Batch 120, Loss: 0.4214
Batch 130, Loss: 0.4386
Batch 140, Loss: 0.4417
Batch 150, Loss: 0.4492
Batch 160, Loss: 0.3985
Batch 170, Loss: 0.4276
Batch 180, Loss: 0.4350
Batch 190, Loss: 0.4181
Batch 200, Loss: 0.4562
Batch 210, Loss: 0.3942
Batch 220, Loss: 0.3737
Batch 230, Loss: 0.4095
Batch 240, Loss: 0.4345
Batch 250, Loss: 0.4311
Batch 260, Loss: 0.4615
Batch 270, Loss: 0.4364
Batch 280, Loss: 0.4583
Batch 290, Loss: 0.4173
Batch 300, Loss: 0.4564
Batch 310, Loss: 0.4343
Batch 320, Loss: 0.4053
Batch 330, Loss: 0.4129
Batch 340, Loss: 0.4375
Batch 350, Loss: 0.4179
Batch 360, Loss: 0.4252
Batch 370, Loss: 0.3992
Batch 380, Loss: 0.3703
Batch 390, Loss: 0.4077
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.114789485931396 seconds
Epoch 105 accuracy: 89.95%
Batch 10, Loss: 0.4250
Batch 20, Loss: 0.4428
Batch 30, Loss: 0.4237
Batch 40, Loss: 0.4047
Batch 50, Loss: 0.4068
Batch 60, Loss: 0.3946
Batch 70, Loss: 0.3782
Batch 80, Loss: 0.4301
Batch 90, Loss: 0.4490
Batch 100, Loss: 0.4328
Batch 110, Loss: 0.3734
Batch 120, Loss: 0.4036
Batch 130, Loss: 0.4295
Batch 140, Loss: 0.4091
Batch 150, Loss: 0.4252
Batch 160, Loss: 0.4125
Batch 170, Loss: 0.4227
Batch 180, Loss: 0.4223
Batch 190, Loss: 0.3972
Batch 200, Loss: 0.3818
Batch 210, Loss: 0.4430
Batch 220, Loss: 0.3959
Batch 230, Loss: 0.3969
Batch 240, Loss: 0.4431
Batch 250, Loss: 0.4391
Batch 260, Loss: 0.4201
Batch 270, Loss: 0.4005
Batch 280, Loss: 0.4101
Batch 290, Loss: 0.4434
Batch 300, Loss: 0.4266
Batch 310, Loss: 0.4041
Batch 320, Loss: 0.4198
Batch 330, Loss: 0.4487
Batch 340, Loss: 0.4326
Batch 350, Loss: 0.4278
Batch 360, Loss: 0.4361
Batch 370, Loss: 0.4131
Batch 380, Loss: 0.4394
Batch 390, Loss: 0.4335
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.204299926757812 seconds
Epoch 106 accuracy: 89.67%
Batch 10, Loss: 0.4084
Batch 20, Loss: 0.4243
Batch 30, Loss: 0.3699
Batch 40, Loss: 0.4092
Batch 50, Loss: 0.4187
Batch 60, Loss: 0.4326
Batch 70, Loss: 0.3953
Batch 80, Loss: 0.4048
Batch 90, Loss: 0.4206
Batch 100, Loss: 0.4365
Batch 110, Loss: 0.4197
Batch 120, Loss: 0.4357
Batch 130, Loss: 0.4055
Batch 140, Loss: 0.4230
Batch 150, Loss: 0.4040
Batch 160, Loss: 0.4678
Batch 170, Loss: 0.4407
Batch 180, Loss: 0.4356
Batch 190, Loss: 0.4118
Batch 200, Loss: 0.3884
Batch 210, Loss: 0.3912
Batch 220, Loss: 0.4151
Batch 230, Loss: 0.4352
Batch 240, Loss: 0.3885
Batch 250, Loss: 0.3962
Batch 260, Loss: 0.3980
Batch 270, Loss: 0.4603
Batch 280, Loss: 0.3993
Batch 290, Loss: 0.4455
Batch 300, Loss: 0.4031
Batch 310, Loss: 0.4368
Batch 320, Loss: 0.4454
Batch 330, Loss: 0.4137
Batch 340, Loss: 0.4200
Batch 350, Loss: 0.4233
Batch 360, Loss: 0.3955
Batch 370, Loss: 0.4122
Batch 380, Loss: 0.4292
Batch 390, Loss: 0.4092
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.079598426818848 seconds
Epoch 107 accuracy: 86.06%
Batch 10, Loss: 0.4245
Batch 20, Loss: 0.3972
Batch 30, Loss: 0.4190
Batch 40, Loss: 0.4276
Batch 50, Loss: 0.4037
Batch 60, Loss: 0.4338
Batch 70, Loss: 0.4135
Batch 80, Loss: 0.4205
Batch 90, Loss: 0.4302
Batch 100, Loss: 0.4144
Batch 110, Loss: 0.3710
Batch 120, Loss: 0.3932
Batch 130, Loss: 0.4022
Batch 140, Loss: 0.4294
Batch 150, Loss: 0.4266
Batch 160, Loss: 0.4483
Batch 170, Loss: 0.3954
Batch 180, Loss: 0.4311
Batch 190, Loss: 0.4318
Batch 200, Loss: 0.4173
Batch 210, Loss: 0.4059
Batch 220, Loss: 0.4164
Batch 230, Loss: 0.3863
Batch 240, Loss: 0.3979
Batch 250, Loss: 0.4518
Batch 260, Loss: 0.4135
Batch 270, Loss: 0.4298
Batch 280, Loss: 0.4107
Batch 290, Loss: 0.4456
Batch 300, Loss: 0.4215
Batch 310, Loss: 0.4140
Batch 320, Loss: 0.4196
Batch 330, Loss: 0.3714
Batch 340, Loss: 0.4154
Batch 350, Loss: 0.4328
Batch 360, Loss: 0.4013
Batch 370, Loss: 0.3914
Batch 380, Loss: 0.4101
Batch 390, Loss: 0.4738
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.118868827819824 seconds
Epoch 108 accuracy: 89.18%
Batch 10, Loss: 0.4096
Batch 20, Loss: 0.4097
Batch 30, Loss: 0.4047
Batch 40, Loss: 0.3961
Batch 50, Loss: 0.4404
Batch 60, Loss: 0.4038
Batch 70, Loss: 0.3985
Batch 80, Loss: 0.4094
Batch 90, Loss: 0.4271
Batch 100, Loss: 0.4135
Batch 110, Loss: 0.3975
Batch 120, Loss: 0.4397
Batch 130, Loss: 0.4037
Batch 140, Loss: 0.4548
Batch 150, Loss: 0.4154
Batch 160, Loss: 0.3935
Batch 170, Loss: 0.3935
Batch 180, Loss: 0.4050
Batch 190, Loss: 0.3791
Batch 200, Loss: 0.3852
Batch 210, Loss: 0.3942
Batch 220, Loss: 0.3981
Batch 230, Loss: 0.3887
Batch 240, Loss: 0.4262
Batch 250, Loss: 0.4304
Batch 260, Loss: 0.4049
Batch 270, Loss: 0.4146
Batch 280, Loss: 0.4161
Batch 290, Loss: 0.4110
Batch 300, Loss: 0.4524
Batch 310, Loss: 0.4001
Batch 320, Loss: 0.3649
Batch 330, Loss: 0.4178
Batch 340, Loss: 0.3987
Batch 350, Loss: 0.3730
Batch 360, Loss: 0.4246
Batch 370, Loss: 0.4362
Batch 380, Loss: 0.4377
Batch 390, Loss: 0.4052
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.135795831680298 seconds
Epoch 109 accuracy: 89.1%
Batch 10, Loss: 0.4111
Batch 20, Loss: 0.3878
Batch 30, Loss: 0.4017
Batch 40, Loss: 0.4120
Batch 50, Loss: 0.4130
Batch 60, Loss: 0.3896
Batch 70, Loss: 0.3655
Batch 80, Loss: 0.4067
Batch 90, Loss: 0.4264
Batch 100, Loss: 0.4557
Batch 110, Loss: 0.4489
Batch 120, Loss: 0.3807
Batch 130, Loss: 0.4560
Batch 140, Loss: 0.4321
Batch 150, Loss: 0.4411
Batch 160, Loss: 0.4474
Batch 170, Loss: 0.4548
Batch 180, Loss: 0.3926
Batch 190, Loss: 0.4125
Batch 200, Loss: 0.4141
Batch 210, Loss: 0.4040
Batch 220, Loss: 0.4159
Batch 230, Loss: 0.4105
Batch 240, Loss: 0.3860
Batch 250, Loss: 0.4029
Batch 260, Loss: 0.3844
Batch 270, Loss: 0.4099
Batch 280, Loss: 0.4070
Batch 290, Loss: 0.4176
Batch 300, Loss: 0.3974
Batch 310, Loss: 0.4014
Batch 320, Loss: 0.3998
Batch 330, Loss: 0.4059
Batch 340, Loss: 0.3765
Batch 350, Loss: 0.4240
Batch 360, Loss: 0.3806
Batch 370, Loss: 0.4195
Batch 380, Loss: 0.4258
Batch 390, Loss: 0.4223
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.120222806930542 seconds
Epoch 110 accuracy: 89.5%
Batch 10, Loss: 0.4432
Batch 20, Loss: 0.4319
Batch 30, Loss: 0.4252
Batch 40, Loss: 0.4305
Batch 50, Loss: 0.3994
Batch 60, Loss: 0.3878
Batch 70, Loss: 0.4220
Batch 80, Loss: 0.3924
Batch 90, Loss: 0.4061
Batch 100, Loss: 0.3911
Batch 110, Loss: 0.4068
Batch 120, Loss: 0.4015
Batch 130, Loss: 0.4172
Batch 140, Loss: 0.3670
Batch 150, Loss: 0.3863
Batch 160, Loss: 0.4104
Batch 170, Loss: 0.3938
Batch 180, Loss: 0.4232
Batch 190, Loss: 0.3911
Batch 200, Loss: 0.3973
Batch 210, Loss: 0.3993
Batch 220, Loss: 0.3915
Batch 230, Loss: 0.4068
Batch 240, Loss: 0.4018
Batch 250, Loss: 0.3796
Batch 260, Loss: 0.4088
Batch 270, Loss: 0.3956
Batch 280, Loss: 0.4335
Batch 290, Loss: 0.4179
Batch 300, Loss: 0.3893
Batch 310, Loss: 0.4276
Batch 320, Loss: 0.3848
Batch 330, Loss: 0.4105
Batch 340, Loss: 0.4276
Batch 350, Loss: 0.3779
Batch 360, Loss: 0.4321
Batch 370, Loss: 0.3892
Batch 380, Loss: 0.4214
Batch 390, Loss: 0.3827
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.1691153049469 seconds
Epoch 111 accuracy: 88.62%
Batch 10, Loss: 0.3973
Batch 20, Loss: 0.3824
Batch 30, Loss: 0.3932
Batch 40, Loss: 0.3749
Batch 50, Loss: 0.3990
Batch 60, Loss: 0.3874
Batch 70, Loss: 0.3826
Batch 80, Loss: 0.3886
Batch 90, Loss: 0.4183
Batch 100, Loss: 0.3819
Batch 110, Loss: 0.4048
Batch 120, Loss: 0.4462
Batch 130, Loss: 0.4066
Batch 140, Loss: 0.4343
Batch 150, Loss: 0.4097
Batch 160, Loss: 0.4062
Batch 170, Loss: 0.4217
Batch 180, Loss: 0.4179
Batch 190, Loss: 0.4051
Batch 200, Loss: 0.4244
Batch 210, Loss: 0.4147
Batch 220, Loss: 0.3775
Batch 230, Loss: 0.3679
Batch 240, Loss: 0.4635
Batch 250, Loss: 0.4592
Batch 260, Loss: 0.3940
Batch 270, Loss: 0.4106
Batch 280, Loss: 0.4287
Batch 290, Loss: 0.4485
Batch 300, Loss: 0.4188
Batch 310, Loss: 0.4044
Batch 320, Loss: 0.3692
Batch 330, Loss: 0.4053
Batch 340, Loss: 0.4174
Batch 350, Loss: 0.4012
Batch 360, Loss: 0.4408
Batch 370, Loss: 0.4003
Batch 380, Loss: 0.4106
Batch 390, Loss: 0.4007
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.09132742881775 seconds
Epoch 112 accuracy: 89.59%
Batch 10, Loss: 0.4086
Batch 20, Loss: 0.3644
Batch 30, Loss: 0.3999
Batch 40, Loss: 0.3931
Batch 50, Loss: 0.3852
Batch 60, Loss: 0.3702
Batch 70, Loss: 0.3976
Batch 80, Loss: 0.4051
Batch 90, Loss: 0.3889
Batch 100, Loss: 0.3988
Batch 110, Loss: 0.4061
Batch 120, Loss: 0.3785
Batch 130, Loss: 0.3854
Batch 140, Loss: 0.3968
Batch 150, Loss: 0.3925
Batch 160, Loss: 0.4041
Batch 170, Loss: 0.4343
Batch 180, Loss: 0.3977
Batch 190, Loss: 0.3993
Batch 200, Loss: 0.3742
Batch 210, Loss: 0.3934
Batch 220, Loss: 0.3637
Batch 230, Loss: 0.4214
Batch 240, Loss: 0.4086
Batch 250, Loss: 0.3868
Batch 260, Loss: 0.3927
Batch 270, Loss: 0.3886
Batch 280, Loss: 0.4123
Batch 290, Loss: 0.3785
Batch 300, Loss: 0.4073
Batch 310, Loss: 0.4063
Batch 320, Loss: 0.4456
Batch 330, Loss: 0.3956
Batch 340, Loss: 0.3959
Batch 350, Loss: 0.3860
Batch 360, Loss: 0.4242
Batch 370, Loss: 0.4265
Batch 380, Loss: 0.3930
Batch 390, Loss: 0.4192
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.16783595085144 seconds
Epoch 113 accuracy: 84.87%
Batch 10, Loss: 0.3972
Batch 20, Loss: 0.4111
Batch 30, Loss: 0.4032
Batch 40, Loss: 0.3795
Batch 50, Loss: 0.4540
Batch 60, Loss: 0.3801
Batch 70, Loss: 0.3936
Batch 80, Loss: 0.3687
Batch 90, Loss: 0.3976
Batch 100, Loss: 0.3873
Batch 110, Loss: 0.4322
Batch 120, Loss: 0.4160
Batch 130, Loss: 0.4067
Batch 140, Loss: 0.4078
Batch 150, Loss: 0.3715
Batch 160, Loss: 0.3771
Batch 170, Loss: 0.3899
Batch 180, Loss: 0.3721
Batch 190, Loss: 0.4255
Batch 200, Loss: 0.3943
Batch 210, Loss: 0.4226
Batch 220, Loss: 0.4188
Batch 230, Loss: 0.4405
Batch 240, Loss: 0.3903
Batch 250, Loss: 0.3749
Batch 260, Loss: 0.4037
Batch 270, Loss: 0.3980
Batch 280, Loss: 0.3893
Batch 290, Loss: 0.4183
Batch 300, Loss: 0.3808
Batch 310, Loss: 0.4336
Batch 320, Loss: 0.4069
Batch 330, Loss: 0.3882
Batch 340, Loss: 0.4209
Batch 350, Loss: 0.3784
Batch 360, Loss: 0.4128
Batch 370, Loss: 0.4065
Batch 380, Loss: 0.3945
Batch 390, Loss: 0.3897
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.20513367652893 seconds
Epoch 114 accuracy: 89.65%
Batch 10, Loss: 0.4228
Batch 20, Loss: 0.3850
Batch 30, Loss: 0.3892
Batch 40, Loss: 0.3944
Batch 50, Loss: 0.3749
Batch 60, Loss: 0.3777
Batch 70, Loss: 0.3803
Batch 80, Loss: 0.3894
Batch 90, Loss: 0.4143
Batch 100, Loss: 0.3980
Batch 110, Loss: 0.3943
Batch 120, Loss: 0.4215
Batch 130, Loss: 0.3733
Batch 140, Loss: 0.4372
Batch 150, Loss: 0.4095
Batch 160, Loss: 0.4087
Batch 170, Loss: 0.4033
Batch 180, Loss: 0.4101
Batch 190, Loss: 0.3768
Batch 200, Loss: 0.4143
Batch 210, Loss: 0.3894
Batch 220, Loss: 0.3699
Batch 230, Loss: 0.4081
Batch 240, Loss: 0.4256
Batch 250, Loss: 0.3748
Batch 260, Loss: 0.3835
Batch 270, Loss: 0.4053
Batch 280, Loss: 0.3923
Batch 290, Loss: 0.3879
Batch 300, Loss: 0.4034
Batch 310, Loss: 0.3902
Batch 320, Loss: 0.3953
Batch 330, Loss: 0.4168
Batch 340, Loss: 0.3753
Batch 350, Loss: 0.3853
Batch 360, Loss: 0.4149
Batch 370, Loss: 0.4210
Batch 380, Loss: 0.3782
Batch 390, Loss: 0.4013
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.06351327896118 seconds
Epoch 115 accuracy: 90.27%
Batch 10, Loss: 0.3785
Batch 20, Loss: 0.3992
Batch 30, Loss: 0.4024
Batch 40, Loss: 0.3897
Batch 50, Loss: 0.3786
Batch 60, Loss: 0.4066
Batch 70, Loss: 0.4122
Batch 80, Loss: 0.4048
Batch 90, Loss: 0.3654
Batch 100, Loss: 0.3839
Batch 110, Loss: 0.3860
Batch 120, Loss: 0.3946
Batch 130, Loss: 0.4028
Batch 140, Loss: 0.3970
Batch 150, Loss: 0.3993
Batch 160, Loss: 0.3877
Batch 170, Loss: 0.4050
Batch 180, Loss: 0.3846
Batch 190, Loss: 0.3665
Batch 200, Loss: 0.4021
Batch 210, Loss: 0.4193
Batch 220, Loss: 0.3929
Batch 230, Loss: 0.3882
Batch 240, Loss: 0.3942
Batch 250, Loss: 0.3932
Batch 260, Loss: 0.3712
Batch 270, Loss: 0.3911
Batch 280, Loss: 0.4078
Batch 290, Loss: 0.3956
Batch 300, Loss: 0.3866
Batch 310, Loss: 0.4067
Batch 320, Loss: 0.3699
Batch 330, Loss: 0.3851
Batch 340, Loss: 0.3931
Batch 350, Loss: 0.3854
Batch 360, Loss: 0.4018
Batch 370, Loss: 0.4103
Batch 380, Loss: 0.3853
Batch 390, Loss: 0.4020
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.091125965118408 seconds
Epoch 116 accuracy: 89.02%
Batch 10, Loss: 0.4089
Batch 20, Loss: 0.3820
Batch 30, Loss: 0.3842
Batch 40, Loss: 0.4006
Batch 50, Loss: 0.3783
Batch 60, Loss: 0.4000
Batch 70, Loss: 0.3644
Batch 80, Loss: 0.3832
Batch 90, Loss: 0.3866
Batch 100, Loss: 0.3427
Batch 110, Loss: 0.3747
Batch 120, Loss: 0.3786
Batch 130, Loss: 0.3975
Batch 140, Loss: 0.3666
Batch 150, Loss: 0.3868
Batch 160, Loss: 0.4236
Batch 170, Loss: 0.3930
Batch 180, Loss: 0.4015
Batch 190, Loss: 0.3734
Batch 200, Loss: 0.3898
Batch 210, Loss: 0.3966
Batch 220, Loss: 0.3530
Batch 230, Loss: 0.3799
Batch 240, Loss: 0.3768
Batch 250, Loss: 0.3840
Batch 260, Loss: 0.4117
Batch 270, Loss: 0.3533
Batch 280, Loss: 0.3948
Batch 290, Loss: 0.3852
Batch 300, Loss: 0.3914
Batch 310, Loss: 0.3701
Batch 320, Loss: 0.3637
Batch 330, Loss: 0.3906
Batch 340, Loss: 0.3769
Batch 350, Loss: 0.4032
Batch 360, Loss: 0.4055
Batch 370, Loss: 0.3787
Batch 380, Loss: 0.4036
Batch 390, Loss: 0.3855
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.08701753616333 seconds
Epoch 117 accuracy: 91.31%
Batch 10, Loss: 0.3794
Batch 20, Loss: 0.3616
Batch 30, Loss: 0.3377
Batch 40, Loss: 0.3879
Batch 50, Loss: 0.3774
Batch 60, Loss: 0.4099
Batch 70, Loss: 0.3859
Batch 80, Loss: 0.3914
Batch 90, Loss: 0.3683
Batch 100, Loss: 0.3851
Batch 110, Loss: 0.3763
Batch 120, Loss: 0.3938
Batch 130, Loss: 0.3692
Batch 140, Loss: 0.3994
Batch 150, Loss: 0.3758
Batch 160, Loss: 0.3744
Batch 170, Loss: 0.3422
Batch 180, Loss: 0.4001
Batch 190, Loss: 0.3584
Batch 200, Loss: 0.3941
Batch 210, Loss: 0.3735
Batch 220, Loss: 0.3826
Batch 230, Loss: 0.3847
Batch 240, Loss: 0.3862
Batch 250, Loss: 0.4105
Batch 260, Loss: 0.3619
Batch 270, Loss: 0.4041
Batch 280, Loss: 0.3834
Batch 290, Loss: 0.3789
Batch 300, Loss: 0.3900
Batch 310, Loss: 0.4022
Batch 320, Loss: 0.4204
Batch 330, Loss: 0.3713
Batch 340, Loss: 0.4033
Batch 350, Loss: 0.3579
Batch 360, Loss: 0.3679
Batch 370, Loss: 0.3636
Batch 380, Loss: 0.3368
Batch 390, Loss: 0.3688
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.22270441055298 seconds
Epoch 118 accuracy: 90.14%
Batch 10, Loss: 0.3798
Batch 20, Loss: 0.3710
Batch 30, Loss: 0.3620
Batch 40, Loss: 0.3422
Batch 50, Loss: 0.4281
Batch 60, Loss: 0.3877
Batch 70, Loss: 0.3798
Batch 80, Loss: 0.4000
Batch 90, Loss: 0.3923
Batch 100, Loss: 0.3622
Batch 110, Loss: 0.3635
Batch 120, Loss: 0.3715
Batch 130, Loss: 0.3974
Batch 140, Loss: 0.3612
Batch 150, Loss: 0.4000
Batch 160, Loss: 0.3842
Batch 170, Loss: 0.3944
Batch 180, Loss: 0.4090
Batch 190, Loss: 0.3686
Batch 200, Loss: 0.3977
Batch 210, Loss: 0.3557
Batch 220, Loss: 0.3727
Batch 230, Loss: 0.3709
Batch 240, Loss: 0.3912
Batch 250, Loss: 0.3751
Batch 260, Loss: 0.3696
Batch 270, Loss: 0.3944
Batch 280, Loss: 0.3661
Batch 290, Loss: 0.3998
Batch 300, Loss: 0.4056
Batch 310, Loss: 0.4011
Batch 320, Loss: 0.3756
Batch 330, Loss: 0.3913
Batch 340, Loss: 0.3647
Batch 350, Loss: 0.3846
Batch 360, Loss: 0.3686
Batch 370, Loss: 0.3605
Batch 380, Loss: 0.3985
Batch 390, Loss: 0.4255
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.141918182373047 seconds
Epoch 119 accuracy: 89.96%
Batch 10, Loss: 0.3962
Batch 20, Loss: 0.4205
Batch 30, Loss: 0.3603
Batch 40, Loss: 0.3395
Batch 50, Loss: 0.3863
Batch 60, Loss: 0.3610
Batch 70, Loss: 0.3832
Batch 80, Loss: 0.3896
Batch 90, Loss: 0.4068
Batch 100, Loss: 0.3686
Batch 110, Loss: 0.3716
Batch 120, Loss: 0.4056
Batch 130, Loss: 0.4146
Batch 140, Loss: 0.4168
Batch 150, Loss: 0.4003
Batch 160, Loss: 0.3718
Batch 170, Loss: 0.3824
Batch 180, Loss: 0.4015
Batch 190, Loss: 0.3441
Batch 200, Loss: 0.3738
Batch 210, Loss: 0.3641
Batch 220, Loss: 0.4060
Batch 230, Loss: 0.3788
Batch 240, Loss: 0.3941
Batch 250, Loss: 0.3894
Batch 260, Loss: 0.4144
Batch 270, Loss: 0.4025
Batch 280, Loss: 0.3567
Batch 290, Loss: 0.3458
Batch 300, Loss: 0.3721
Batch 310, Loss: 0.3690
Batch 320, Loss: 0.3797
Batch 330, Loss: 0.4052
Batch 340, Loss: 0.3835
Batch 350, Loss: 0.3794
Batch 360, Loss: 0.3981
Batch 370, Loss: 0.3618
Batch 380, Loss: 0.4005
Batch 390, Loss: 0.3780
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.050262689590454 seconds
Epoch 120 accuracy: 90.11%
Batch 10, Loss: 0.3642
Batch 20, Loss: 0.3705
Batch 30, Loss: 0.3770
Batch 40, Loss: 0.3934
Batch 50, Loss: 0.3757
Batch 60, Loss: 0.4028
Batch 70, Loss: 0.3619
Batch 80, Loss: 0.3840
Batch 90, Loss: 0.3865
Batch 100, Loss: 0.3678
Batch 110, Loss: 0.3462
Batch 120, Loss: 0.3827
Batch 130, Loss: 0.3779
Batch 140, Loss: 0.3952
Batch 150, Loss: 0.3475
Batch 160, Loss: 0.3707
Batch 170, Loss: 0.3793
Batch 180, Loss: 0.3841
Batch 190, Loss: 0.3808
Batch 200, Loss: 0.3966
Batch 210, Loss: 0.3686
Batch 220, Loss: 0.3576
Batch 230, Loss: 0.3704
Batch 240, Loss: 0.3666
Batch 250, Loss: 0.3500
Batch 260, Loss: 0.3940
Batch 270, Loss: 0.3764
Batch 280, Loss: 0.3713
Batch 290, Loss: 0.3728
Batch 300, Loss: 0.3588
Batch 310, Loss: 0.3862
Batch 320, Loss: 0.3578
Batch 330, Loss: 0.3396
Batch 340, Loss: 0.3932
Batch 350, Loss: 0.3663
Batch 360, Loss: 0.3620
Batch 370, Loss: 0.3957
Batch 380, Loss: 0.3941
Batch 390, Loss: 0.4163
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.1055908203125 seconds
Epoch 121 accuracy: 90.23%
Batch 10, Loss: 0.3784
Batch 20, Loss: 0.3815
Batch 30, Loss: 0.3637
Batch 40, Loss: 0.3514
Batch 50, Loss: 0.3679
Batch 60, Loss: 0.3652
Batch 70, Loss: 0.3858
Batch 80, Loss: 0.3617
Batch 90, Loss: 0.3291
Batch 100, Loss: 0.3518
Batch 110, Loss: 0.3804
Batch 120, Loss: 0.3371
Batch 130, Loss: 0.3807
Batch 140, Loss: 0.3500
Batch 150, Loss: 0.3523
Batch 160, Loss: 0.3750
Batch 170, Loss: 0.3374
Batch 180, Loss: 0.3770
Batch 190, Loss: 0.4006
Batch 200, Loss: 0.3894
Batch 210, Loss: 0.3798
Batch 220, Loss: 0.3791
Batch 230, Loss: 0.3658
Batch 240, Loss: 0.3625
Batch 250, Loss: 0.3679
Batch 260, Loss: 0.3715
Batch 270, Loss: 0.3515
Batch 280, Loss: 0.3679
Batch 290, Loss: 0.3779
Batch 300, Loss: 0.3559
Batch 310, Loss: 0.4051
Batch 320, Loss: 0.3658
Batch 330, Loss: 0.3992
Batch 340, Loss: 0.3792
Batch 350, Loss: 0.3804
Batch 360, Loss: 0.3412
Batch 370, Loss: 0.3771
Batch 380, Loss: 0.3901
Batch 390, Loss: 0.3582
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.20762825012207 seconds
Epoch 122 accuracy: 89.92%
Batch 10, Loss: 0.3421
Batch 20, Loss: 0.3725
Batch 30, Loss: 0.3880
Batch 40, Loss: 0.3947
Batch 50, Loss: 0.3663
Batch 60, Loss: 0.3773
Batch 70, Loss: 0.3569
Batch 80, Loss: 0.4056
Batch 90, Loss: 0.3910
Batch 100, Loss: 0.3729
Batch 110, Loss: 0.3613
Batch 120, Loss: 0.3656
Batch 130, Loss: 0.3875
Batch 140, Loss: 0.3259
Batch 150, Loss: 0.3679
Batch 160, Loss: 0.3740
Batch 170, Loss: 0.4096
Batch 180, Loss: 0.4130
Batch 190, Loss: 0.3508
Batch 200, Loss: 0.3629
Batch 210, Loss: 0.3550
Batch 220, Loss: 0.3750
Batch 230, Loss: 0.3411
Batch 240, Loss: 0.3849
Batch 250, Loss: 0.3589
Batch 260, Loss: 0.3675
Batch 270, Loss: 0.3501
Batch 280, Loss: 0.3508
Batch 290, Loss: 0.3640
Batch 300, Loss: 0.3738
Batch 310, Loss: 0.3472
Batch 320, Loss: 0.3572
Batch 330, Loss: 0.3547
Batch 340, Loss: 0.3844
Batch 350, Loss: 0.3706
Batch 360, Loss: 0.3902
Batch 370, Loss: 0.3566
Batch 380, Loss: 0.3772
Batch 390, Loss: 0.4062
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.1973295211792 seconds
Epoch 123 accuracy: 91.76%
Batch 10, Loss: 0.3826
Batch 20, Loss: 0.3490
Batch 30, Loss: 0.3528
Batch 40, Loss: 0.3704
Batch 50, Loss: 0.3601
Batch 60, Loss: 0.3763
Batch 70, Loss: 0.3516
Batch 80, Loss: 0.3762
Batch 90, Loss: 0.3888
Batch 100, Loss: 0.3521
Batch 110, Loss: 0.3917
Batch 120, Loss: 0.3467
Batch 130, Loss: 0.3953
Batch 140, Loss: 0.3863
Batch 150, Loss: 0.3790
Batch 160, Loss: 0.3480
Batch 170, Loss: 0.3385
Batch 180, Loss: 0.4160
Batch 190, Loss: 0.4014
Batch 200, Loss: 0.3596
Batch 210, Loss: 0.3975
Batch 220, Loss: 0.3639
Batch 230, Loss: 0.3758
Batch 240, Loss: 0.3838
Batch 250, Loss: 0.3704
Batch 260, Loss: 0.3752
Batch 270, Loss: 0.3690
Batch 280, Loss: 0.3576
Batch 290, Loss: 0.3512
Batch 300, Loss: 0.3960
Batch 310, Loss: 0.3743
Batch 320, Loss: 0.3604
Batch 330, Loss: 0.3643
Batch 340, Loss: 0.3936
Batch 350, Loss: 0.3806
Batch 360, Loss: 0.3713
Batch 370, Loss: 0.4286
Batch 380, Loss: 0.3993
Batch 390, Loss: 0.3880
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.15717101097107 seconds
Epoch 124 accuracy: 90.59%
Batch 10, Loss: 0.3435
Batch 20, Loss: 0.3919
Batch 30, Loss: 0.3648
Batch 40, Loss: 0.3547
Batch 50, Loss: 0.3562
Batch 60, Loss: 0.3544
Batch 70, Loss: 0.3550
Batch 80, Loss: 0.3704
Batch 90, Loss: 0.3903
Batch 100, Loss: 0.3635
Batch 110, Loss: 0.3970
Batch 120, Loss: 0.3378
Batch 130, Loss: 0.3556
Batch 140, Loss: 0.3293
Batch 150, Loss: 0.3581
Batch 160, Loss: 0.3387
Batch 170, Loss: 0.3665
Batch 180, Loss: 0.3520
Batch 190, Loss: 0.3824
Batch 200, Loss: 0.3566
Batch 210, Loss: 0.3424
Batch 220, Loss: 0.3314
Batch 230, Loss: 0.3712
Batch 240, Loss: 0.3922
Batch 250, Loss: 0.3380
Batch 260, Loss: 0.3598
Batch 270, Loss: 0.3753
Batch 280, Loss: 0.3569
Batch 290, Loss: 0.3744
Batch 300, Loss: 0.3479
Batch 310, Loss: 0.3704
Batch 320, Loss: 0.3715
Batch 330, Loss: 0.3878
Batch 340, Loss: 0.3491
Batch 350, Loss: 0.3678
Batch 360, Loss: 0.3755
Batch 370, Loss: 0.3345
Batch 380, Loss: 0.3661
Batch 390, Loss: 0.3696
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.16537380218506 seconds
Epoch 125 accuracy: 90.31%
Batch 10, Loss: 0.3532
Batch 20, Loss: 0.3472
Batch 30, Loss: 0.3396
Batch 40, Loss: 0.3474
Batch 50, Loss: 0.3628
Batch 60, Loss: 0.3578
Batch 70, Loss: 0.3596
Batch 80, Loss: 0.3916
Batch 90, Loss: 0.3561
Batch 100, Loss: 0.3594
Batch 110, Loss: 0.3412
Batch 120, Loss: 0.3613
Batch 130, Loss: 0.3792
Batch 140, Loss: 0.3666
Batch 150, Loss: 0.3683
Batch 160, Loss: 0.3484
Batch 170, Loss: 0.3261
Batch 180, Loss: 0.3450
Batch 190, Loss: 0.3264
Batch 200, Loss: 0.3497
Batch 210, Loss: 0.3607
Batch 220, Loss: 0.3546
Batch 230, Loss: 0.3830
Batch 240, Loss: 0.3576
Batch 250, Loss: 0.3382
Batch 260, Loss: 0.3329
Batch 270, Loss: 0.3623
Batch 280, Loss: 0.3478
Batch 290, Loss: 0.3838
Batch 300, Loss: 0.3744
Batch 310, Loss: 0.3619
Batch 320, Loss: 0.3761
Batch 330, Loss: 0.3538
Batch 340, Loss: 0.3717
Batch 350, Loss: 0.3342
Batch 360, Loss: 0.3713
Batch 370, Loss: 0.3827
Batch 380, Loss: 0.3488
Batch 390, Loss: 0.3797
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.15822434425354 seconds
Epoch 126 accuracy: 90.68%
Batch 10, Loss: 0.3808
Batch 20, Loss: 0.3549
Batch 30, Loss: 0.3493
Batch 40, Loss: 0.3513
Batch 50, Loss: 0.3859
Batch 60, Loss: 0.3415
Batch 70, Loss: 0.3820
Batch 80, Loss: 0.3779
Batch 90, Loss: 0.3666
Batch 100, Loss: 0.3733
Batch 110, Loss: 0.3590
Batch 120, Loss: 0.3801
Batch 130, Loss: 0.3607
Batch 140, Loss: 0.3802
Batch 150, Loss: 0.3721
Batch 160, Loss: 0.3536
Batch 170, Loss: 0.3751
Batch 180, Loss: 0.3659
Batch 190, Loss: 0.3690
Batch 200, Loss: 0.3482
Batch 210, Loss: 0.3726
Batch 220, Loss: 0.3607
Batch 230, Loss: 0.3420
Batch 240, Loss: 0.3517
Batch 250, Loss: 0.3169
Batch 260, Loss: 0.3452
Batch 270, Loss: 0.3545
Batch 280, Loss: 0.3457
Batch 290, Loss: 0.3520
Batch 300, Loss: 0.3880
Batch 310, Loss: 0.3830
Batch 320, Loss: 0.3629
Batch 330, Loss: 0.3709
Batch 340, Loss: 0.3561
Batch 350, Loss: 0.3326
Batch 360, Loss: 0.3334
Batch 370, Loss: 0.3502
Batch 380, Loss: 0.3369
Batch 390, Loss: 0.3519
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.229340076446533 seconds
Epoch 127 accuracy: 91.65%
Batch 10, Loss: 0.3333
Batch 20, Loss: 0.3862
Batch 30, Loss: 0.3725
Batch 40, Loss: 0.3970
Batch 50, Loss: 0.3577
Batch 60, Loss: 0.3503
Batch 70, Loss: 0.3468
Batch 80, Loss: 0.3429
Batch 90, Loss: 0.3753
Batch 100, Loss: 0.3562
Batch 110, Loss: 0.3706
Batch 120, Loss: 0.3381
Batch 130, Loss: 0.3298
Batch 140, Loss: 0.3574
Batch 150, Loss: 0.3366
Batch 160, Loss: 0.3337
Batch 170, Loss: 0.3703
Batch 180, Loss: 0.3775
Batch 190, Loss: 0.3679
Batch 200, Loss: 0.3468
Batch 210, Loss: 0.3346
Batch 220, Loss: 0.3379
Batch 230, Loss: 0.3625
Batch 240, Loss: 0.3753
Batch 250, Loss: 0.3350
Batch 260, Loss: 0.3156
Batch 270, Loss: 0.3696
Batch 280, Loss: 0.3378
Batch 290, Loss: 0.3498
Batch 300, Loss: 0.3799
Batch 310, Loss: 0.3672
Batch 320, Loss: 0.3389
Batch 330, Loss: 0.3495
Batch 340, Loss: 0.3553
Batch 350, Loss: 0.3262
Batch 360, Loss: 0.3407
Batch 370, Loss: 0.3376
Batch 380, Loss: 0.3727
Batch 390, Loss: 0.3756
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.127689123153687 seconds
Epoch 128 accuracy: 91.32%
Batch 10, Loss: 0.4016
Batch 20, Loss: 0.3567
Batch 30, Loss: 0.3228
Batch 40, Loss: 0.3387
Batch 50, Loss: 0.3364
Batch 60, Loss: 0.3411
Batch 70, Loss: 0.3518
Batch 80, Loss: 0.3670
Batch 90, Loss: 0.3252
Batch 100, Loss: 0.3509
Batch 110, Loss: 0.3877
Batch 120, Loss: 0.3712
Batch 130, Loss: 0.3372
Batch 140, Loss: 0.3333
Batch 150, Loss: 0.3479
Batch 160, Loss: 0.3650
Batch 170, Loss: 0.3512
Batch 180, Loss: 0.3549
Batch 190, Loss: 0.3392
Batch 200, Loss: 0.3844
Batch 210, Loss: 0.3562
Batch 220, Loss: 0.3015
Batch 230, Loss: 0.3108
Batch 240, Loss: 0.3727
Batch 250, Loss: 0.3646
Batch 260, Loss: 0.3588
Batch 270, Loss: 0.4087
Batch 280, Loss: 0.3499
Batch 290, Loss: 0.3460
Batch 300, Loss: 0.3508
Batch 310, Loss: 0.3549
Batch 320, Loss: 0.3223
Batch 330, Loss: 0.3818
Batch 340, Loss: 0.3516
Batch 350, Loss: 0.3402
Batch 360, Loss: 0.3257
Batch 370, Loss: 0.3645
Batch 380, Loss: 0.3512
Batch 390, Loss: 0.3814
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.173465490341187 seconds
Epoch 129 accuracy: 87.82%
Batch 10, Loss: 0.3516
Batch 20, Loss: 0.3502
Batch 30, Loss: 0.3779
Batch 40, Loss: 0.3677
Batch 50, Loss: 0.3254
Batch 60, Loss: 0.3330
Batch 70, Loss: 0.3470
Batch 80, Loss: 0.3212
Batch 90, Loss: 0.3634
Batch 100, Loss: 0.4082
Batch 110, Loss: 0.3229
Batch 120, Loss: 0.3367
Batch 130, Loss: 0.3354
Batch 140, Loss: 0.3427
Batch 150, Loss: 0.3367
Batch 160, Loss: 0.3532
Batch 170, Loss: 0.3525
Batch 180, Loss: 0.3495
Batch 190, Loss: 0.3508
Batch 200, Loss: 0.3604
Batch 210, Loss: 0.3607
Batch 220, Loss: 0.3690
Batch 230, Loss: 0.3534
Batch 240, Loss: 0.3594
Batch 250, Loss: 0.3472
Batch 260, Loss: 0.3482
Batch 270, Loss: 0.3722
Batch 280, Loss: 0.3852
Batch 290, Loss: 0.3539
Batch 300, Loss: 0.3273
Batch 310, Loss: 0.3575
Batch 320, Loss: 0.3372
Batch 330, Loss: 0.3422
Batch 340, Loss: 0.3562
Batch 350, Loss: 0.3658
Batch 360, Loss: 0.3310
Batch 370, Loss: 0.3578
Batch 380, Loss: 0.3721
Batch 390, Loss: 0.3163
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.181830167770386 seconds
Epoch 130 accuracy: 91.65%
Batch 10, Loss: 0.3384
Batch 20, Loss: 0.3323
Batch 30, Loss: 0.3788
Batch 40, Loss: 0.3666
Batch 50, Loss: 0.3052
Batch 60, Loss: 0.3607
Batch 70, Loss: 0.3518
Batch 80, Loss: 0.3234
Batch 90, Loss: 0.3099
Batch 100, Loss: 0.3248
Batch 110, Loss: 0.3494
Batch 120, Loss: 0.3459
Batch 130, Loss: 0.3661
Batch 140, Loss: 0.3484
Batch 150, Loss: 0.3570
Batch 160, Loss: 0.3301
Batch 170, Loss: 0.3299
Batch 180, Loss: 0.3290
Batch 190, Loss: 0.3351
Batch 200, Loss: 0.3564
Batch 210, Loss: 0.3472
Batch 220, Loss: 0.3557
Batch 230, Loss: 0.3415
Batch 240, Loss: 0.3456
Batch 250, Loss: 0.3527
Batch 260, Loss: 0.3616
Batch 270, Loss: 0.3494
Batch 280, Loss: 0.3320
Batch 290, Loss: 0.3712
Batch 300, Loss: 0.3169
Batch 310, Loss: 0.3272
Batch 320, Loss: 0.3394
Batch 330, Loss: 0.3780
Batch 340, Loss: 0.3701
Batch 350, Loss: 0.3124
Batch 360, Loss: 0.3828
Batch 370, Loss: 0.3252
Batch 380, Loss: 0.3566
Batch 390, Loss: 0.3782
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.18928098678589 seconds
Epoch 131 accuracy: 90.55%
Batch 10, Loss: 0.3390
Batch 20, Loss: 0.3472
Batch 30, Loss: 0.3702
Batch 40, Loss: 0.3392
Batch 50, Loss: 0.3206
Batch 60, Loss: 0.3654
Batch 70, Loss: 0.2917
Batch 80, Loss: 0.3456
Batch 90, Loss: 0.3336
Batch 100, Loss: 0.3180
Batch 110, Loss: 0.3480
Batch 120, Loss: 0.3285
Batch 130, Loss: 0.3555
Batch 140, Loss: 0.3432
Batch 150, Loss: 0.3415
Batch 160, Loss: 0.3548
Batch 170, Loss: 0.3698
Batch 180, Loss: 0.3172
Batch 190, Loss: 0.3469
Batch 200, Loss: 0.3456
Batch 210, Loss: 0.3554
Batch 220, Loss: 0.3664
Batch 230, Loss: 0.3732
Batch 240, Loss: 0.3341
Batch 250, Loss: 0.3720
Batch 260, Loss: 0.3677
Batch 270, Loss: 0.3755
Batch 280, Loss: 0.3313
Batch 290, Loss: 0.3579
Batch 300, Loss: 0.3335
Batch 310, Loss: 0.3296
Batch 320, Loss: 0.3221
Batch 330, Loss: 0.3486
Batch 340, Loss: 0.3950
Batch 350, Loss: 0.3299
Batch 360, Loss: 0.3534
Batch 370, Loss: 0.3510
Batch 380, Loss: 0.3526
Batch 390, Loss: 0.3273
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.171143293380737 seconds
Epoch 132 accuracy: 91.08%
Batch 10, Loss: 0.3431
Batch 20, Loss: 0.3335
Batch 30, Loss: 0.3259
Batch 40, Loss: 0.3723
Batch 50, Loss: 0.3821
Batch 60, Loss: 0.3516
Batch 70, Loss: 0.3309
Batch 80, Loss: 0.3414
Batch 90, Loss: 0.3091
Batch 100, Loss: 0.3429
Batch 110, Loss: 0.3464
Batch 120, Loss: 0.3521
Batch 130, Loss: 0.3527
Batch 140, Loss: 0.3614
Batch 150, Loss: 0.2846
Batch 160, Loss: 0.3149
Batch 170, Loss: 0.3126
Batch 180, Loss: 0.2841
Batch 190, Loss: 0.3405
Batch 200, Loss: 0.3552
Batch 210, Loss: 0.3271
Batch 220, Loss: 0.3723
Batch 230, Loss: 0.3489
Batch 240, Loss: 0.3624
Batch 250, Loss: 0.3243
Batch 260, Loss: 0.3446
Batch 270, Loss: 0.3012
Batch 280, Loss: 0.3381
Batch 290, Loss: 0.3493
Batch 300, Loss: 0.3497
Batch 310, Loss: 0.3521
Batch 320, Loss: 0.3701
Batch 330, Loss: 0.3094
Batch 340, Loss: 0.4000
Batch 350, Loss: 0.3550
Batch 360, Loss: 0.3253
Batch 370, Loss: 0.3369
Batch 380, Loss: 0.3317
Batch 390, Loss: 0.2990
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.140851736068726 seconds
Epoch 133 accuracy: 91.82%
Batch 10, Loss: 0.3374
Batch 20, Loss: 0.3148
Batch 30, Loss: 0.3062
Batch 40, Loss: 0.3366
Batch 50, Loss: 0.3276
Batch 60, Loss: 0.3784
Batch 70, Loss: 0.3193
Batch 80, Loss: 0.3347
Batch 90, Loss: 0.3393
Batch 100, Loss: 0.3135
Batch 110, Loss: 0.3275
Batch 120, Loss: 0.3115
Batch 130, Loss: 0.3295
Batch 140, Loss: 0.3511
Batch 150, Loss: 0.3421
Batch 160, Loss: 0.3342
Batch 170, Loss: 0.3275
Batch 180, Loss: 0.3418
Batch 190, Loss: 0.3332
Batch 200, Loss: 0.3260
Batch 210, Loss: 0.3506
Batch 220, Loss: 0.3249
Batch 230, Loss: 0.3433
Batch 240, Loss: 0.3409
Batch 250, Loss: 0.3372
Batch 260, Loss: 0.3406
Batch 270, Loss: 0.3557
Batch 280, Loss: 0.3392
Batch 290, Loss: 0.3582
Batch 300, Loss: 0.3257
Batch 310, Loss: 0.3076
Batch 320, Loss: 0.3733
Batch 330, Loss: 0.3294
Batch 340, Loss: 0.3527
Batch 350, Loss: 0.3274
Batch 360, Loss: 0.3180
Batch 370, Loss: 0.3470
Batch 380, Loss: 0.3292
Batch 390, Loss: 0.3298
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.085622549057007 seconds
Epoch 134 accuracy: 91.24%
Batch 10, Loss: 0.3191
Batch 20, Loss: 0.3138
Batch 30, Loss: 0.3047
Batch 40, Loss: 0.2997
Batch 50, Loss: 0.3177
Batch 60, Loss: 0.3231
Batch 70, Loss: 0.3090
Batch 80, Loss: 0.3056
Batch 90, Loss: 0.3546
Batch 100, Loss: 0.3283
Batch 110, Loss: 0.3042
Batch 120, Loss: 0.2990
Batch 130, Loss: 0.3565
Batch 140, Loss: 0.3506
Batch 150, Loss: 0.2936
Batch 160, Loss: 0.3541
Batch 170, Loss: 0.3249
Batch 180, Loss: 0.3216
Batch 190, Loss: 0.3510
Batch 200, Loss: 0.3409
Batch 210, Loss: 0.3587
Batch 220, Loss: 0.3152
Batch 230, Loss: 0.3444
Batch 240, Loss: 0.3457
Batch 250, Loss: 0.3200
Batch 260, Loss: 0.3301
Batch 270, Loss: 0.3378
Batch 280, Loss: 0.3253
Batch 290, Loss: 0.3134
Batch 300, Loss: 0.3398
Batch 310, Loss: 0.2968
Batch 320, Loss: 0.3542
Batch 330, Loss: 0.3332
Batch 340, Loss: 0.3633
Batch 350, Loss: 0.3573
Batch 360, Loss: 0.3453
Batch 370, Loss: 0.3502
Batch 380, Loss: 0.3735
Batch 390, Loss: 0.3494
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.16291046142578 seconds
Epoch 135 accuracy: 91.65%
Batch 10, Loss: 0.3290
Batch 20, Loss: 0.3062
Batch 30, Loss: 0.3085
Batch 40, Loss: 0.3044
Batch 50, Loss: 0.3297
Batch 60, Loss: 0.2931
Batch 70, Loss: 0.3309
Batch 80, Loss: 0.3034
Batch 90, Loss: 0.3430
Batch 100, Loss: 0.3234
Batch 110, Loss: 0.3435
Batch 120, Loss: 0.3724
Batch 130, Loss: 0.2896
Batch 140, Loss: 0.3205
Batch 150, Loss: 0.3112
Batch 160, Loss: 0.2895
Batch 170, Loss: 0.3129
Batch 180, Loss: 0.3277
Batch 190, Loss: 0.3228
Batch 200, Loss: 0.3324
Batch 210, Loss: 0.3454
Batch 220, Loss: 0.3227
Batch 230, Loss: 0.3581
Batch 240, Loss: 0.3269
Batch 250, Loss: 0.3191
Batch 260, Loss: 0.3232
Batch 270, Loss: 0.3392
Batch 280, Loss: 0.2998
Batch 290, Loss: 0.3208
Batch 300, Loss: 0.3163
Batch 310, Loss: 0.3304
Batch 320, Loss: 0.3533
Batch 330, Loss: 0.3476
Batch 340, Loss: 0.3081
Batch 350, Loss: 0.3589
Batch 360, Loss: 0.3309
Batch 370, Loss: 0.3701
Batch 380, Loss: 0.3160
Batch 390, Loss: 0.3138
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.12725806236267 seconds
Epoch 136 accuracy: 91.34%
Batch 10, Loss: 0.3287
Batch 20, Loss: 0.3374
Batch 30, Loss: 0.3507
Batch 40, Loss: 0.3102
Batch 50, Loss: 0.3375
Batch 60, Loss: 0.3388
Batch 70, Loss: 0.3135
Batch 80, Loss: 0.3289
Batch 90, Loss: 0.3250
Batch 100, Loss: 0.3150
Batch 110, Loss: 0.3008
Batch 120, Loss: 0.3383
Batch 130, Loss: 0.3393
Batch 140, Loss: 0.3604
Batch 150, Loss: 0.3343
Batch 160, Loss: 0.3128
Batch 170, Loss: 0.3243
Batch 180, Loss: 0.3013
Batch 190, Loss: 0.3288
Batch 200, Loss: 0.3535
Batch 210, Loss: 0.3441
Batch 220, Loss: 0.3081
Batch 230, Loss: 0.3207
Batch 240, Loss: 0.3111
Batch 250, Loss: 0.3145
Batch 260, Loss: 0.3076
Batch 270, Loss: 0.3435
Batch 280, Loss: 0.3371
Batch 290, Loss: 0.3183
Batch 300, Loss: 0.3093
Batch 310, Loss: 0.3464
Batch 320, Loss: 0.3101
Batch 330, Loss: 0.3655
Batch 340, Loss: 0.3178
Batch 350, Loss: 0.3271
Batch 360, Loss: 0.3340
Batch 370, Loss: 0.3585
Batch 380, Loss: 0.3259
Batch 390, Loss: 0.3378
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.072433948516846 seconds
Epoch 137 accuracy: 91.18%
Batch 10, Loss: 0.3121
Batch 20, Loss: 0.3196
Batch 30, Loss: 0.3052
Batch 40, Loss: 0.3080
Batch 50, Loss: 0.3325
Batch 60, Loss: 0.3267
Batch 70, Loss: 0.3363
Batch 80, Loss: 0.3312
Batch 90, Loss: 0.3502
Batch 100, Loss: 0.3597
Batch 110, Loss: 0.3236
Batch 120, Loss: 0.3082
Batch 130, Loss: 0.3026
Batch 140, Loss: 0.2938
Batch 150, Loss: 0.3205
Batch 160, Loss: 0.3085
Batch 170, Loss: 0.3013
Batch 180, Loss: 0.3125
Batch 190, Loss: 0.3425
Batch 200, Loss: 0.3467
Batch 210, Loss: 0.3105
Batch 220, Loss: 0.3059
Batch 230, Loss: 0.3072
Batch 240, Loss: 0.3230
Batch 250, Loss: 0.3088
Batch 260, Loss: 0.3382
Batch 270, Loss: 0.3073
Batch 280, Loss: 0.3265
Batch 290, Loss: 0.3109
Batch 300, Loss: 0.3046
Batch 310, Loss: 0.3612
Batch 320, Loss: 0.3394
Batch 330, Loss: 0.3357
Batch 340, Loss: 0.3459
Batch 350, Loss: 0.3028
Batch 360, Loss: 0.3521
Batch 370, Loss: 0.2978
Batch 380, Loss: 0.3126
Batch 390, Loss: 0.3333
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.087258338928223 seconds
Epoch 138 accuracy: 92.98%
Batch 10, Loss: 0.2955
Batch 20, Loss: 0.3143
Batch 30, Loss: 0.2974
Batch 40, Loss: 0.3046
Batch 50, Loss: 0.3185
Batch 60, Loss: 0.3417
Batch 70, Loss: 0.3152
Batch 80, Loss: 0.2904
Batch 90, Loss: 0.3415
Batch 100, Loss: 0.3457
Batch 110, Loss: 0.3286
Batch 120, Loss: 0.3452
Batch 130, Loss: 0.3386
Batch 140, Loss: 0.3362
Batch 150, Loss: 0.3268
Batch 160, Loss: 0.3046
Batch 170, Loss: 0.3195
Batch 180, Loss: 0.3236
Batch 190, Loss: 0.3152
Batch 200, Loss: 0.2932
Batch 210, Loss: 0.3246
Batch 220, Loss: 0.3125
Batch 230, Loss: 0.3379
Batch 240, Loss: 0.3498
Batch 250, Loss: 0.2912
Batch 260, Loss: 0.3137
Batch 270, Loss: 0.2897
Batch 280, Loss: 0.3130
Batch 290, Loss: 0.3172
Batch 300, Loss: 0.3110
Batch 310, Loss: 0.2995
Batch 320, Loss: 0.3085
Batch 330, Loss: 0.3336
Batch 340, Loss: 0.3275
Batch 350, Loss: 0.3329
Batch 360, Loss: 0.3208
Batch 370, Loss: 0.3021
Batch 380, Loss: 0.3127
Batch 390, Loss: 0.3258
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.124619722366333 seconds
Epoch 139 accuracy: 92.1%
Batch 10, Loss: 0.3739
Batch 20, Loss: 0.2881
Batch 30, Loss: 0.3133
Batch 40, Loss: 0.3241
Batch 50, Loss: 0.3211
Batch 60, Loss: 0.3160
Batch 70, Loss: 0.2935
Batch 80, Loss: 0.3249
Batch 90, Loss: 0.3469
Batch 100, Loss: 0.3060
Batch 110, Loss: 0.3245
Batch 120, Loss: 0.3118
Batch 130, Loss: 0.3111
Batch 140, Loss: 0.2858
Batch 150, Loss: 0.2897
Batch 160, Loss: 0.3122
Batch 170, Loss: 0.2934
Batch 180, Loss: 0.3287
Batch 190, Loss: 0.3237
Batch 200, Loss: 0.3062
Batch 210, Loss: 0.2901
Batch 220, Loss: 0.2906
Batch 230, Loss: 0.3078
Batch 240, Loss: 0.2699
Batch 250, Loss: 0.3184
Batch 260, Loss: 0.3389
Batch 270, Loss: 0.3085
Batch 280, Loss: 0.3387
Batch 290, Loss: 0.3175
Batch 300, Loss: 0.3194
Batch 310, Loss: 0.3271
Batch 320, Loss: 0.3216
Batch 330, Loss: 0.2922
Batch 340, Loss: 0.3012
Batch 350, Loss: 0.3088
Batch 360, Loss: 0.3394
Batch 370, Loss: 0.3324
Batch 380, Loss: 0.3178
Batch 390, Loss: 0.3034
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.175554752349854 seconds
Epoch 140 accuracy: 92.06%
Batch 10, Loss: 0.3171
Batch 20, Loss: 0.2978
Batch 30, Loss: 0.3150
Batch 40, Loss: 0.3142
Batch 50, Loss: 0.3076
Batch 60, Loss: 0.3000
Batch 70, Loss: 0.3204
Batch 80, Loss: 0.3458
Batch 90, Loss: 0.3264
Batch 100, Loss: 0.2843
Batch 110, Loss: 0.3029
Batch 120, Loss: 0.3154
Batch 130, Loss: 0.2629
Batch 140, Loss: 0.3181
Batch 150, Loss: 0.3439
Batch 160, Loss: 0.3212
Batch 170, Loss: 0.2800
Batch 180, Loss: 0.3098
Batch 190, Loss: 0.2994
Batch 200, Loss: 0.2999
Batch 210, Loss: 0.3109
Batch 220, Loss: 0.3031
Batch 230, Loss: 0.3272
Batch 240, Loss: 0.3169
Batch 250, Loss: 0.3103
Batch 260, Loss: 0.3472
Batch 270, Loss: 0.3264
Batch 280, Loss: 0.3028
Batch 290, Loss: 0.2979
Batch 300, Loss: 0.3155
Batch 310, Loss: 0.2978
Batch 320, Loss: 0.2997
Batch 330, Loss: 0.2971
Batch 340, Loss: 0.3122
Batch 350, Loss: 0.3209
Batch 360, Loss: 0.3100
Batch 370, Loss: 0.3444
Batch 380, Loss: 0.3258
Batch 390, Loss: 0.3214
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.095012426376343 seconds
Epoch 141 accuracy: 92.69%
Batch 10, Loss: 0.2889
Batch 20, Loss: 0.3238
Batch 30, Loss: 0.3274
Batch 40, Loss: 0.2916
Batch 50, Loss: 0.3077
Batch 60, Loss: 0.2728
Batch 70, Loss: 0.3349
Batch 80, Loss: 0.2912
Batch 90, Loss: 0.3031
Batch 100, Loss: 0.3167
Batch 110, Loss: 0.3041
Batch 120, Loss: 0.3168
Batch 130, Loss: 0.2983
Batch 140, Loss: 0.2923
Batch 150, Loss: 0.3033
Batch 160, Loss: 0.2891
Batch 170, Loss: 0.3067
Batch 180, Loss: 0.3073
Batch 190, Loss: 0.2962
Batch 200, Loss: 0.3003
Batch 210, Loss: 0.3005
Batch 220, Loss: 0.3417
Batch 230, Loss: 0.2888
Batch 240, Loss: 0.2977
Batch 250, Loss: 0.3265
Batch 260, Loss: 0.2972
Batch 270, Loss: 0.2763
Batch 280, Loss: 0.3383
Batch 290, Loss: 0.3170
Batch 300, Loss: 0.3184
Batch 310, Loss: 0.2770
Batch 320, Loss: 0.3144
Batch 330, Loss: 0.3203
Batch 340, Loss: 0.3160
Batch 350, Loss: 0.3120
Batch 360, Loss: 0.3112
Batch 370, Loss: 0.3137
Batch 380, Loss: 0.3120
Batch 390, Loss: 0.2945
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.084831476211548 seconds
Epoch 142 accuracy: 93.18%
Batch 10, Loss: 0.2789
Batch 20, Loss: 0.3153
Batch 30, Loss: 0.2950
Batch 40, Loss: 0.2970
Batch 50, Loss: 0.3281
Batch 60, Loss: 0.3081
Batch 70, Loss: 0.3241
Batch 80, Loss: 0.3147
Batch 90, Loss: 0.2875
Batch 100, Loss: 0.3045
Batch 110, Loss: 0.3059
Batch 120, Loss: 0.2920
Batch 130, Loss: 0.3207
Batch 140, Loss: 0.2643
Batch 150, Loss: 0.3167
Batch 160, Loss: 0.3255
Batch 170, Loss: 0.3176
Batch 180, Loss: 0.3069
Batch 190, Loss: 0.3057
Batch 200, Loss: 0.3154
Batch 210, Loss: 0.2993
Batch 220, Loss: 0.2998
Batch 230, Loss: 0.2515
Batch 240, Loss: 0.2979
Batch 250, Loss: 0.2895
Batch 260, Loss: 0.2832
Batch 270, Loss: 0.2898
Batch 280, Loss: 0.2911
Batch 290, Loss: 0.2814
Batch 300, Loss: 0.2981
Batch 310, Loss: 0.3326
Batch 320, Loss: 0.2913
Batch 330, Loss: 0.3156
Batch 340, Loss: 0.3047
Batch 350, Loss: 0.2905
Batch 360, Loss: 0.3106
Batch 370, Loss: 0.3055
Batch 380, Loss: 0.3293
Batch 390, Loss: 0.3256
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.10564684867859 seconds
Epoch 143 accuracy: 93.03%
Batch 10, Loss: 0.2958
Batch 20, Loss: 0.2911
Batch 30, Loss: 0.2768
Batch 40, Loss: 0.2762
Batch 50, Loss: 0.3257
Batch 60, Loss: 0.2782
Batch 70, Loss: 0.2953
Batch 80, Loss: 0.2831
Batch 90, Loss: 0.2889
Batch 100, Loss: 0.3221
Batch 110, Loss: 0.2913
Batch 120, Loss: 0.3061
Batch 130, Loss: 0.2823
Batch 140, Loss: 0.3098
Batch 150, Loss: 0.2913
Batch 160, Loss: 0.3206
Batch 170, Loss: 0.2765
Batch 180, Loss: 0.2999
Batch 190, Loss: 0.2710
Batch 200, Loss: 0.3086
Batch 210, Loss: 0.2906
Batch 220, Loss: 0.2850
Batch 230, Loss: 0.3253
Batch 240, Loss: 0.3421
Batch 250, Loss: 0.3058
Batch 260, Loss: 0.2656
Batch 270, Loss: 0.3194
Batch 280, Loss: 0.3227
Batch 290, Loss: 0.3370
Batch 300, Loss: 0.2931
Batch 310, Loss: 0.3130
Batch 320, Loss: 0.3141
Batch 330, Loss: 0.2959
Batch 340, Loss: 0.2842
Batch 350, Loss: 0.2923
Batch 360, Loss: 0.3228
Batch 370, Loss: 0.2986
Batch 380, Loss: 0.3187
Batch 390, Loss: 0.3018
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.192233324050903 seconds
Epoch 144 accuracy: 92.92%
Batch 10, Loss: 0.2993
Batch 20, Loss: 0.3064
Batch 30, Loss: 0.2935
Batch 40, Loss: 0.3057
Batch 50, Loss: 0.3086
Batch 60, Loss: 0.3102
Batch 70, Loss: 0.2785
Batch 80, Loss: 0.2869
Batch 90, Loss: 0.3019
Batch 100, Loss: 0.2671
Batch 110, Loss: 0.3312
Batch 120, Loss: 0.2960
Batch 130, Loss: 0.3225
Batch 140, Loss: 0.3188
Batch 150, Loss: 0.2904
Batch 160, Loss: 0.3013
Batch 170, Loss: 0.3079
Batch 180, Loss: 0.3132
Batch 190, Loss: 0.2927
Batch 200, Loss: 0.3017
Batch 210, Loss: 0.3112
Batch 220, Loss: 0.2848
Batch 230, Loss: 0.3313
Batch 240, Loss: 0.3060
Batch 250, Loss: 0.2745
Batch 260, Loss: 0.2738
Batch 270, Loss: 0.2771
Batch 280, Loss: 0.2894
Batch 290, Loss: 0.3001
Batch 300, Loss: 0.2923
Batch 310, Loss: 0.3123
Batch 320, Loss: 0.3001
Batch 330, Loss: 0.3256
Batch 340, Loss: 0.2872
Batch 350, Loss: 0.2922
Batch 360, Loss: 0.3003
Batch 370, Loss: 0.2985
Batch 380, Loss: 0.3344
Batch 390, Loss: 0.3128
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.1781063079834 seconds
Epoch 145 accuracy: 92.73%
Batch 10, Loss: 0.2827
Batch 20, Loss: 0.2984
Batch 30, Loss: 0.2738
Batch 40, Loss: 0.2821
Batch 50, Loss: 0.2823
Batch 60, Loss: 0.2800
Batch 70, Loss: 0.2862
Batch 80, Loss: 0.2892
Batch 90, Loss: 0.2828
Batch 100, Loss: 0.2889
Batch 110, Loss: 0.3311
Batch 120, Loss: 0.3160
Batch 130, Loss: 0.2954
Batch 140, Loss: 0.2897
Batch 150, Loss: 0.3328
Batch 160, Loss: 0.2905
Batch 170, Loss: 0.2702
Batch 180, Loss: 0.2689
Batch 190, Loss: 0.2909
Batch 200, Loss: 0.3290
Batch 210, Loss: 0.3151
Batch 220, Loss: 0.3141
Batch 230, Loss: 0.3036
Batch 240, Loss: 0.3177
Batch 250, Loss: 0.3073
Batch 260, Loss: 0.3225
Batch 270, Loss: 0.2832
Batch 280, Loss: 0.3530
Batch 290, Loss: 0.2791
Batch 300, Loss: 0.3249
Batch 310, Loss: 0.3253
Batch 320, Loss: 0.2793
Batch 330, Loss: 0.2730
Batch 340, Loss: 0.2979
Batch 350, Loss: 0.3022
Batch 360, Loss: 0.3067
Batch 370, Loss: 0.3082
Batch 380, Loss: 0.2936
Batch 390, Loss: 0.3118
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.1813702583313 seconds
Epoch 146 accuracy: 92.82%
Batch 10, Loss: 0.2808
Batch 20, Loss: 0.3067
Batch 30, Loss: 0.2860
Batch 40, Loss: 0.2683
Batch 50, Loss: 0.2908
Batch 60, Loss: 0.2779
Batch 70, Loss: 0.2871
Batch 80, Loss: 0.3139
Batch 90, Loss: 0.2946
Batch 100, Loss: 0.3085
Batch 110, Loss: 0.3113
Batch 120, Loss: 0.2944
Batch 130, Loss: 0.3085
Batch 140, Loss: 0.3046
Batch 150, Loss: 0.2765
Batch 160, Loss: 0.2730
Batch 170, Loss: 0.3419
Batch 180, Loss: 0.2786
Batch 190, Loss: 0.2745
Batch 200, Loss: 0.2722
Batch 210, Loss: 0.2753
Batch 220, Loss: 0.2795
Batch 230, Loss: 0.2818
Batch 240, Loss: 0.3064
Batch 250, Loss: 0.3152
Batch 260, Loss: 0.2841
Batch 270, Loss: 0.3138
Batch 280, Loss: 0.2397
Batch 290, Loss: 0.2780
Batch 300, Loss: 0.2648
Batch 310, Loss: 0.2868
Batch 320, Loss: 0.3077
Batch 330, Loss: 0.2841
Batch 340, Loss: 0.3154
Batch 350, Loss: 0.3056
Batch 360, Loss: 0.2850
Batch 370, Loss: 0.2829
Batch 380, Loss: 0.2887
Batch 390, Loss: 0.3113
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.103665351867676 seconds
Epoch 147 accuracy: 92.7%
Batch 10, Loss: 0.2975
Batch 20, Loss: 0.2568
Batch 30, Loss: 0.3051
Batch 40, Loss: 0.2943
Batch 50, Loss: 0.2814
Batch 60, Loss: 0.2688
Batch 70, Loss: 0.2750
Batch 80, Loss: 0.2767
Batch 90, Loss: 0.2875
Batch 100, Loss: 0.2827
Batch 110, Loss: 0.2742
Batch 120, Loss: 0.2693
Batch 130, Loss: 0.2803
Batch 140, Loss: 0.2792
Batch 150, Loss: 0.2823
Batch 160, Loss: 0.3066
Batch 170, Loss: 0.3011
Batch 180, Loss: 0.3060
Batch 190, Loss: 0.3087
Batch 200, Loss: 0.2734
Batch 210, Loss: 0.2656
Batch 220, Loss: 0.2891
Batch 230, Loss: 0.2626
Batch 240, Loss: 0.3072
Batch 250, Loss: 0.3224
Batch 260, Loss: 0.2984
Batch 270, Loss: 0.3179
Batch 280, Loss: 0.3247
Batch 290, Loss: 0.3022
Batch 300, Loss: 0.2918
Batch 310, Loss: 0.3062
Batch 320, Loss: 0.2933
Batch 330, Loss: 0.2695
Batch 340, Loss: 0.2826
Batch 350, Loss: 0.3063
Batch 360, Loss: 0.3174
Batch 370, Loss: 0.2857
Batch 380, Loss: 0.2850
Batch 390, Loss: 0.2846
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.147923946380615 seconds
Epoch 148 accuracy: 92.94%
Batch 10, Loss: 0.2798
Batch 20, Loss: 0.2853
Batch 30, Loss: 0.2604
Batch 40, Loss: 0.2710
Batch 50, Loss: 0.2710
Batch 60, Loss: 0.2987
Batch 70, Loss: 0.2858
Batch 80, Loss: 0.3004
Batch 90, Loss: 0.2710
Batch 100, Loss: 0.2892
Batch 110, Loss: 0.2792
Batch 120, Loss: 0.3043
Batch 130, Loss: 0.2878
Batch 140, Loss: 0.2795
Batch 150, Loss: 0.3042
Batch 160, Loss: 0.2902
Batch 170, Loss: 0.2777
Batch 180, Loss: 0.2828
Batch 190, Loss: 0.2822
Batch 200, Loss: 0.3081
Batch 210, Loss: 0.2785
Batch 220, Loss: 0.2912
Batch 230, Loss: 0.2837
Batch 240, Loss: 0.2930
Batch 250, Loss: 0.2922
Batch 260, Loss: 0.2514
Batch 270, Loss: 0.2724
Batch 280, Loss: 0.2955
Batch 290, Loss: 0.2915
Batch 300, Loss: 0.3091
Batch 310, Loss: 0.2870
Batch 320, Loss: 0.2841
Batch 330, Loss: 0.2709
Batch 340, Loss: 0.2929
Batch 350, Loss: 0.2789
Batch 360, Loss: 0.2615
Batch 370, Loss: 0.2679
Batch 380, Loss: 0.2886
Batch 390, Loss: 0.3047
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.126046419143677 seconds
Epoch 149 accuracy: 93.38%
Batch 10, Loss: 0.2759
Batch 20, Loss: 0.2722
Batch 30, Loss: 0.2444
Batch 40, Loss: 0.2596
Batch 50, Loss: 0.2576
Batch 60, Loss: 0.2742
Batch 70, Loss: 0.2830
Batch 80, Loss: 0.2818
Batch 90, Loss: 0.2702
Batch 100, Loss: 0.2852
Batch 110, Loss: 0.2744
Batch 120, Loss: 0.3024
Batch 130, Loss: 0.2776
Batch 140, Loss: 0.3042
Batch 150, Loss: 0.2824
Batch 160, Loss: 0.2666
Batch 170, Loss: 0.2973
Batch 180, Loss: 0.2793
Batch 190, Loss: 0.3030
Batch 200, Loss: 0.2603
Batch 210, Loss: 0.2613
Batch 220, Loss: 0.2532
Batch 230, Loss: 0.2993
Batch 240, Loss: 0.2886
Batch 250, Loss: 0.2988
Batch 260, Loss: 0.2856
Batch 270, Loss: 0.2539
Batch 280, Loss: 0.2697
Batch 290, Loss: 0.2615
Batch 300, Loss: 0.2858
Batch 310, Loss: 0.2686
Batch 320, Loss: 0.3103
Batch 330, Loss: 0.2604
Batch 340, Loss: 0.2865
Batch 350, Loss: 0.2857
Batch 360, Loss: 0.2840
Batch 370, Loss: 0.2695
Batch 380, Loss: 0.2635
Batch 390, Loss: 0.2662
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.150580167770386 seconds
Epoch 150 accuracy: 93.07%
Batch 10, Loss: 0.2886
Batch 20, Loss: 0.2739
Batch 30, Loss: 0.2685
Batch 40, Loss: 0.2895
Batch 50, Loss: 0.2907
Batch 60, Loss: 0.2694
Batch 70, Loss: 0.2731
Batch 80, Loss: 0.2643
Batch 90, Loss: 0.2575
Batch 100, Loss: 0.2476
Batch 110, Loss: 0.2724
Batch 120, Loss: 0.2753
Batch 130, Loss: 0.2512
Batch 140, Loss: 0.2632
Batch 150, Loss: 0.2665
Batch 160, Loss: 0.2734
Batch 170, Loss: 0.2682
Batch 180, Loss: 0.2907
Batch 190, Loss: 0.2490
Batch 200, Loss: 0.2631
Batch 210, Loss: 0.2626
Batch 220, Loss: 0.2718
Batch 230, Loss: 0.2841
Batch 240, Loss: 0.2912
Batch 250, Loss: 0.2797
Batch 260, Loss: 0.2501
Batch 270, Loss: 0.2702
Batch 280, Loss: 0.2931
Batch 290, Loss: 0.2657
Batch 300, Loss: 0.3035
Batch 310, Loss: 0.3024
Batch 320, Loss: 0.2681
Batch 330, Loss: 0.2603
Batch 340, Loss: 0.2798
Batch 350, Loss: 0.3064
Batch 360, Loss: 0.2844
Batch 370, Loss: 0.2697
Batch 380, Loss: 0.2755
Batch 390, Loss: 0.3165
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.249703407287598 seconds
Epoch 151 accuracy: 93.23%
Batch 10, Loss: 0.2977
Batch 20, Loss: 0.2398
Batch 30, Loss: 0.2665
Batch 40, Loss: 0.2519
Batch 50, Loss: 0.2811
Batch 60, Loss: 0.2515
Batch 70, Loss: 0.2566
Batch 80, Loss: 0.2756
Batch 90, Loss: 0.2872
Batch 100, Loss: 0.2525
Batch 110, Loss: 0.2764
Batch 120, Loss: 0.2383
Batch 130, Loss: 0.2801
Batch 140, Loss: 0.2250
Batch 150, Loss: 0.2485
Batch 160, Loss: 0.2816
Batch 170, Loss: 0.2950
Batch 180, Loss: 0.2858
Batch 190, Loss: 0.2726
Batch 200, Loss: 0.3119
Batch 210, Loss: 0.2599
Batch 220, Loss: 0.2829
Batch 230, Loss: 0.2740
Batch 240, Loss: 0.2703
Batch 250, Loss: 0.2708
Batch 260, Loss: 0.2726
Batch 270, Loss: 0.3091
Batch 280, Loss: 0.2858
Batch 290, Loss: 0.2532
Batch 300, Loss: 0.2755
Batch 310, Loss: 0.2713
Batch 320, Loss: 0.2477
Batch 330, Loss: 0.2701
Batch 340, Loss: 0.2533
Batch 350, Loss: 0.2717
Batch 360, Loss: 0.2803
Batch 370, Loss: 0.2769
Batch 380, Loss: 0.2647
Batch 390, Loss: 0.2767
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.206834316253662 seconds
Epoch 152 accuracy: 93.06%
Batch 10, Loss: 0.2778
Batch 20, Loss: 0.2742
Batch 30, Loss: 0.2563
Batch 40, Loss: 0.2617
Batch 50, Loss: 0.2356
Batch 60, Loss: 0.2506
Batch 70, Loss: 0.2550
Batch 80, Loss: 0.2527
Batch 90, Loss: 0.2484
Batch 100, Loss: 0.2662
Batch 110, Loss: 0.2637
Batch 120, Loss: 0.2930
Batch 130, Loss: 0.2389
Batch 140, Loss: 0.2583
Batch 150, Loss: 0.2542
Batch 160, Loss: 0.2538
Batch 170, Loss: 0.2764
Batch 180, Loss: 0.2491
Batch 190, Loss: 0.2368
Batch 200, Loss: 0.2698
Batch 210, Loss: 0.2454
Batch 220, Loss: 0.2622
Batch 230, Loss: 0.2743
Batch 240, Loss: 0.2540
Batch 250, Loss: 0.2738
Batch 260, Loss: 0.2687
Batch 270, Loss: 0.2691
Batch 280, Loss: 0.2542
Batch 290, Loss: 0.2775
Batch 300, Loss: 0.2800
Batch 310, Loss: 0.2780
Batch 320, Loss: 0.2614
Batch 330, Loss: 0.2587
Batch 340, Loss: 0.2515
Batch 350, Loss: 0.2958
Batch 360, Loss: 0.2815
Batch 370, Loss: 0.2812
Batch 380, Loss: 0.3033
Batch 390, Loss: 0.2841
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.227325439453125 seconds
Epoch 153 accuracy: 93.36%
Batch 10, Loss: 0.2413
Batch 20, Loss: 0.2630
Batch 30, Loss: 0.2713
Batch 40, Loss: 0.2576
Batch 50, Loss: 0.2645
Batch 60, Loss: 0.3000
Batch 70, Loss: 0.2491
Batch 80, Loss: 0.2477
Batch 90, Loss: 0.2582
Batch 100, Loss: 0.2421
Batch 110, Loss: 0.2593
Batch 120, Loss: 0.2350
Batch 130, Loss: 0.2554
Batch 140, Loss: 0.2603
Batch 150, Loss: 0.2527
Batch 160, Loss: 0.2705
Batch 170, Loss: 0.2938
Batch 180, Loss: 0.2954
Batch 190, Loss: 0.2920
Batch 200, Loss: 0.2887
Batch 210, Loss: 0.2236
Batch 220, Loss: 0.2827
Batch 230, Loss: 0.2538
Batch 240, Loss: 0.2570
Batch 250, Loss: 0.2700
Batch 260, Loss: 0.2467
Batch 270, Loss: 0.2682
Batch 280, Loss: 0.2706
Batch 290, Loss: 0.2935
Batch 300, Loss: 0.2711
Batch 310, Loss: 0.2796
Batch 320, Loss: 0.2654
Batch 330, Loss: 0.2664
Batch 340, Loss: 0.2674
Batch 350, Loss: 0.2576
Batch 360, Loss: 0.2776
Batch 370, Loss: 0.2579
Batch 380, Loss: 0.2787
Batch 390, Loss: 0.2476
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.18018078804016 seconds
Epoch 154 accuracy: 93.91%
Batch 10, Loss: 0.2661
Batch 20, Loss: 0.2475
Batch 30, Loss: 0.2484
Batch 40, Loss: 0.2558
Batch 50, Loss: 0.2201
Batch 60, Loss: 0.2229
Batch 70, Loss: 0.2271
Batch 80, Loss: 0.2747
Batch 90, Loss: 0.2607
Batch 100, Loss: 0.2482
Batch 110, Loss: 0.2557
Batch 120, Loss: 0.2589
Batch 130, Loss: 0.2308
Batch 140, Loss: 0.2576
Batch 150, Loss: 0.2224
Batch 160, Loss: 0.2766
Batch 170, Loss: 0.2924
Batch 180, Loss: 0.2881
Batch 190, Loss: 0.2916
Batch 200, Loss: 0.2752
Batch 210, Loss: 0.2457
Batch 220, Loss: 0.2677
Batch 230, Loss: 0.2581
Batch 240, Loss: 0.2398
Batch 250, Loss: 0.2451
Batch 260, Loss: 0.2626
Batch 270, Loss: 0.2531
Batch 280, Loss: 0.2633
Batch 290, Loss: 0.2526
Batch 300, Loss: 0.2702
Batch 310, Loss: 0.2844
Batch 320, Loss: 0.2681
Batch 330, Loss: 0.2779
Batch 340, Loss: 0.2620
Batch 350, Loss: 0.2878
Batch 360, Loss: 0.2579
Batch 370, Loss: 0.2661
Batch 380, Loss: 0.2250
Batch 390, Loss: 0.2552
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.236615896224976 seconds
Epoch 155 accuracy: 93.77%
Batch 10, Loss: 0.2259
Batch 20, Loss: 0.2672
Batch 30, Loss: 0.2464
Batch 40, Loss: 0.2425
Batch 50, Loss: 0.2556
Batch 60, Loss: 0.2612
Batch 70, Loss: 0.2784
Batch 80, Loss: 0.2857
Batch 90, Loss: 0.2741
Batch 100, Loss: 0.2662
Batch 110, Loss: 0.2494
Batch 120, Loss: 0.2302
Batch 130, Loss: 0.2568
Batch 140, Loss: 0.2509
Batch 150, Loss: 0.2286
Batch 160, Loss: 0.2376
Batch 170, Loss: 0.2351
Batch 180, Loss: 0.2551
Batch 190, Loss: 0.2077
Batch 200, Loss: 0.2077
Batch 210, Loss: 0.2811
Batch 220, Loss: 0.2867
Batch 230, Loss: 0.2678
Batch 240, Loss: 0.2415
Batch 250, Loss: 0.2371
Batch 260, Loss: 0.2376
Batch 270, Loss: 0.2509
Batch 280, Loss: 0.2482
Batch 290, Loss: 0.2614
Batch 300, Loss: 0.2610
Batch 310, Loss: 0.2488
Batch 320, Loss: 0.2521
Batch 330, Loss: 0.2533
Batch 340, Loss: 0.2874
Batch 350, Loss: 0.2270
Batch 360, Loss: 0.2374
Batch 370, Loss: 0.2645
Batch 380, Loss: 0.2773
Batch 390, Loss: 0.2297
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.0797758102417 seconds
Epoch 156 accuracy: 93.77%
Batch 10, Loss: 0.2541
Batch 20, Loss: 0.2492
Batch 30, Loss: 0.2810
Batch 40, Loss: 0.2644
Batch 50, Loss: 0.2494
Batch 60, Loss: 0.2655
Batch 70, Loss: 0.2197
Batch 80, Loss: 0.2149
Batch 90, Loss: 0.2637
Batch 100, Loss: 0.2493
Batch 110, Loss: 0.2509
Batch 120, Loss: 0.2435
Batch 130, Loss: 0.2166
Batch 140, Loss: 0.2441
Batch 150, Loss: 0.2673
Batch 160, Loss: 0.2692
Batch 170, Loss: 0.2511
Batch 180, Loss: 0.2614
Batch 190, Loss: 0.2239
Batch 200, Loss: 0.2694
Batch 210, Loss: 0.2500
Batch 220, Loss: 0.2465
Batch 230, Loss: 0.2604
Batch 240, Loss: 0.2003
Batch 250, Loss: 0.2561
Batch 260, Loss: 0.2771
Batch 270, Loss: 0.2941
Batch 280, Loss: 0.2465
Batch 290, Loss: 0.2239
Batch 300, Loss: 0.2561
Batch 310, Loss: 0.2427
Batch 320, Loss: 0.2692
Batch 330, Loss: 0.2249
Batch 340, Loss: 0.2536
Batch 350, Loss: 0.2703
Batch 360, Loss: 0.2509
Batch 370, Loss: 0.2197
Batch 380, Loss: 0.2035
Batch 390, Loss: 0.2428
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.098114490509033 seconds
Epoch 157 accuracy: 93.99%
Batch 10, Loss: 0.2540
Batch 20, Loss: 0.2405
Batch 30, Loss: 0.2433
Batch 40, Loss: 0.2249
Batch 50, Loss: 0.2337
Batch 60, Loss: 0.2789
Batch 70, Loss: 0.2499
Batch 80, Loss: 0.2277
Batch 90, Loss: 0.2252
Batch 100, Loss: 0.2619
Batch 110, Loss: 0.2606
Batch 120, Loss: 0.2542
Batch 130, Loss: 0.2555
Batch 140, Loss: 0.2749
Batch 150, Loss: 0.2357
Batch 160, Loss: 0.2483
Batch 170, Loss: 0.2398
Batch 180, Loss: 0.2571
Batch 190, Loss: 0.2159
Batch 200, Loss: 0.2270
Batch 210, Loss: 0.2279
Batch 220, Loss: 0.2416
Batch 230, Loss: 0.2237
Batch 240, Loss: 0.2383
Batch 250, Loss: 0.2552
Batch 260, Loss: 0.2367
Batch 270, Loss: 0.2792
Batch 280, Loss: 0.2543
Batch 290, Loss: 0.2617
Batch 300, Loss: 0.2528
Batch 310, Loss: 0.2380
Batch 320, Loss: 0.2712
Batch 330, Loss: 0.2418
Batch 340, Loss: 0.2604
Batch 350, Loss: 0.2476
Batch 360, Loss: 0.2564
Batch 370, Loss: 0.2591
Batch 380, Loss: 0.2152
Batch 390, Loss: 0.2736
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.164655923843384 seconds
Epoch 158 accuracy: 94.12%
Batch 10, Loss: 0.2179
Batch 20, Loss: 0.2344
Batch 30, Loss: 0.2507
Batch 40, Loss: 0.2338
Batch 50, Loss: 0.2439
Batch 60, Loss: 0.2169
Batch 70, Loss: 0.2562
Batch 80, Loss: 0.2663
Batch 90, Loss: 0.2514
Batch 100, Loss: 0.2548
Batch 110, Loss: 0.2357
Batch 120, Loss: 0.2376
Batch 130, Loss: 0.2387
Batch 140, Loss: 0.2531
Batch 150, Loss: 0.2268
Batch 160, Loss: 0.2098
Batch 170, Loss: 0.2412
Batch 180, Loss: 0.2452
Batch 190, Loss: 0.2384
Batch 200, Loss: 0.2519
Batch 210, Loss: 0.2503
Batch 220, Loss: 0.2296
Batch 230, Loss: 0.2371
Batch 240, Loss: 0.2263
Batch 250, Loss: 0.2483
Batch 260, Loss: 0.2518
Batch 270, Loss: 0.2476
Batch 280, Loss: 0.2348
Batch 290, Loss: 0.2427
Batch 300, Loss: 0.2400
Batch 310, Loss: 0.2411
Batch 320, Loss: 0.2540
Batch 330, Loss: 0.2699
Batch 340, Loss: 0.2242
Batch 350, Loss: 0.2460
Batch 360, Loss: 0.2279
Batch 370, Loss: 0.2489
Batch 380, Loss: 0.2101
Batch 390, Loss: 0.2495
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.108623504638672 seconds
Epoch 159 accuracy: 94.21%
Batch 10, Loss: 0.2340
Batch 20, Loss: 0.2107
Batch 30, Loss: 0.2337
Batch 40, Loss: 0.2586
Batch 50, Loss: 0.2361
Batch 60, Loss: 0.2229
Batch 70, Loss: 0.2473
Batch 80, Loss: 0.2339
Batch 90, Loss: 0.2516
Batch 100, Loss: 0.2156
Batch 110, Loss: 0.2505
Batch 120, Loss: 0.2406
Batch 130, Loss: 0.2604
Batch 140, Loss: 0.2320
Batch 150, Loss: 0.2659
Batch 160, Loss: 0.2126
Batch 170, Loss: 0.2401
Batch 180, Loss: 0.2456
Batch 190, Loss: 0.2472
Batch 200, Loss: 0.2392
Batch 210, Loss: 0.2149
Batch 220, Loss: 0.2260
Batch 230, Loss: 0.2428
Batch 240, Loss: 0.2339
Batch 250, Loss: 0.2508
Batch 260, Loss: 0.2299
Batch 270, Loss: 0.2388
Batch 280, Loss: 0.2329
Batch 290, Loss: 0.2374
Batch 300, Loss: 0.2480
Batch 310, Loss: 0.2266
Batch 320, Loss: 0.2519
Batch 330, Loss: 0.2412
Batch 340, Loss: 0.2537
Batch 350, Loss: 0.2229
Batch 360, Loss: 0.2343
Batch 370, Loss: 0.2615
Batch 380, Loss: 0.2497
Batch 390, Loss: 0.2272
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.122007369995117 seconds
Epoch 160 accuracy: 94.12%
Batch 10, Loss: 0.2126
Batch 20, Loss: 0.2160
Batch 30, Loss: 0.2432
Batch 40, Loss: 0.2285
Batch 50, Loss: 0.2356
Batch 60, Loss: 0.2340
Batch 70, Loss: 0.2467
Batch 80, Loss: 0.2288
Batch 90, Loss: 0.2324
Batch 100, Loss: 0.2065
Batch 110, Loss: 0.2274
Batch 120, Loss: 0.1971
Batch 130, Loss: 0.2364
Batch 140, Loss: 0.2308
Batch 150, Loss: 0.2386
Batch 160, Loss: 0.2552
Batch 170, Loss: 0.2498
Batch 180, Loss: 0.2164
Batch 190, Loss: 0.2488
Batch 200, Loss: 0.2227
Batch 210, Loss: 0.2389
Batch 220, Loss: 0.2424
Batch 230, Loss: 0.2350
Batch 240, Loss: 0.2442
Batch 250, Loss: 0.2194
Batch 260, Loss: 0.2278
Batch 270, Loss: 0.2542
Batch 280, Loss: 0.2391
Batch 290, Loss: 0.2421
Batch 300, Loss: 0.2250
Batch 310, Loss: 0.2384
Batch 320, Loss: 0.2309
Batch 330, Loss: 0.2439
Batch 340, Loss: 0.2448
Batch 350, Loss: 0.2344
Batch 360, Loss: 0.2345
Batch 370, Loss: 0.2254
Batch 380, Loss: 0.2403
Batch 390, Loss: 0.2258
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.166668176651 seconds
Epoch 161 accuracy: 93.79%
Batch 10, Loss: 0.2209
Batch 20, Loss: 0.2123
Batch 30, Loss: 0.2069
Batch 40, Loss: 0.2053
Batch 50, Loss: 0.2479
Batch 60, Loss: 0.2374
Batch 70, Loss: 0.2062
Batch 80, Loss: 0.2059
Batch 90, Loss: 0.2275
Batch 100, Loss: 0.2446
Batch 110, Loss: 0.2408
Batch 120, Loss: 0.2075
Batch 130, Loss: 0.2299
Batch 140, Loss: 0.2107
Batch 150, Loss: 0.2149
Batch 160, Loss: 0.2266
Batch 170, Loss: 0.2313
Batch 180, Loss: 0.2228
Batch 190, Loss: 0.2386
Batch 200, Loss: 0.2610
Batch 210, Loss: 0.2318
Batch 220, Loss: 0.2376
Batch 230, Loss: 0.2289
Batch 240, Loss: 0.2171
Batch 250, Loss: 0.2342
Batch 260, Loss: 0.2275
Batch 270, Loss: 0.2333
Batch 280, Loss: 0.2371
Batch 290, Loss: 0.2147
Batch 300, Loss: 0.2337
Batch 310, Loss: 0.2312
Batch 320, Loss: 0.2344
Batch 330, Loss: 0.2597
Batch 340, Loss: 0.2303
Batch 350, Loss: 0.2493
Batch 360, Loss: 0.2249
Batch 370, Loss: 0.2363
Batch 380, Loss: 0.2202
Batch 390, Loss: 0.2479
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.206697702407837 seconds
Epoch 162 accuracy: 94.53%
Batch 10, Loss: 0.2135
Batch 20, Loss: 0.2265
Batch 30, Loss: 0.1851
Batch 40, Loss: 0.2106
Batch 50, Loss: 0.2297
Batch 60, Loss: 0.2172
Batch 70, Loss: 0.2164
Batch 80, Loss: 0.2376
Batch 90, Loss: 0.2150
Batch 100, Loss: 0.2430
Batch 110, Loss: 0.2107
Batch 120, Loss: 0.2155
Batch 130, Loss: 0.2203
Batch 140, Loss: 0.2164
Batch 150, Loss: 0.2542
Batch 160, Loss: 0.2152
Batch 170, Loss: 0.2184
Batch 180, Loss: 0.2458
Batch 190, Loss: 0.2101
Batch 200, Loss: 0.2405
Batch 210, Loss: 0.2113
Batch 220, Loss: 0.2128
Batch 230, Loss: 0.2114
Batch 240, Loss: 0.2380
Batch 250, Loss: 0.2023
Batch 260, Loss: 0.2085
Batch 270, Loss: 0.2530
Batch 280, Loss: 0.2363
Batch 290, Loss: 0.2097
Batch 300, Loss: 0.2210
Batch 310, Loss: 0.2148
Batch 320, Loss: 0.2416
Batch 330, Loss: 0.2227
Batch 340, Loss: 0.2265
Batch 350, Loss: 0.2290
Batch 360, Loss: 0.2697
Batch 370, Loss: 0.2145
Batch 380, Loss: 0.2144
Batch 390, Loss: 0.2061
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.191903352737427 seconds
Epoch 163 accuracy: 94.37%
Batch 10, Loss: 0.2043
Batch 20, Loss: 0.2018
Batch 30, Loss: 0.2148
Batch 40, Loss: 0.2162
Batch 50, Loss: 0.2210
Batch 60, Loss: 0.2407
Batch 70, Loss: 0.2061
Batch 80, Loss: 0.2376
Batch 90, Loss: 0.2151
Batch 100, Loss: 0.2432
Batch 110, Loss: 0.2135
Batch 120, Loss: 0.2272
Batch 130, Loss: 0.2099
Batch 140, Loss: 0.2094
Batch 150, Loss: 0.2156
Batch 160, Loss: 0.2078
Batch 170, Loss: 0.2046
Batch 180, Loss: 0.2258
Batch 190, Loss: 0.2012
Batch 200, Loss: 0.2253
Batch 210, Loss: 0.2308
Batch 220, Loss: 0.2213
Batch 230, Loss: 0.2249
Batch 240, Loss: 0.2139
Batch 250, Loss: 0.2184
Batch 260, Loss: 0.2032
Batch 270, Loss: 0.2444
Batch 280, Loss: 0.2331
Batch 290, Loss: 0.2000
Batch 300, Loss: 0.2028
Batch 310, Loss: 0.2399
Batch 320, Loss: 0.2115
Batch 330, Loss: 0.1944
Batch 340, Loss: 0.2400
Batch 350, Loss: 0.2196
Batch 360, Loss: 0.2365
Batch 370, Loss: 0.2082
Batch 380, Loss: 0.2151
Batch 390, Loss: 0.2102
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.073525428771973 seconds
Epoch 164 accuracy: 94.67%
Batch 10, Loss: 0.2209
Batch 20, Loss: 0.2206
Batch 30, Loss: 0.2052
Batch 40, Loss: 0.2081
Batch 50, Loss: 0.1958
Batch 60, Loss: 0.2039
Batch 70, Loss: 0.2156
Batch 80, Loss: 0.2436
Batch 90, Loss: 0.2065
Batch 100, Loss: 0.1933
Batch 110, Loss: 0.2278
Batch 120, Loss: 0.2132
Batch 130, Loss: 0.2297
Batch 140, Loss: 0.2290
Batch 150, Loss: 0.2120
Batch 160, Loss: 0.2353
Batch 170, Loss: 0.2306
Batch 180, Loss: 0.2290
Batch 190, Loss: 0.2345
Batch 200, Loss: 0.2050
Batch 210, Loss: 0.2089
Batch 220, Loss: 0.2229
Batch 230, Loss: 0.2084
Batch 240, Loss: 0.2235
Batch 250, Loss: 0.2381
Batch 260, Loss: 0.2495
Batch 270, Loss: 0.1946
Batch 280, Loss: 0.1961
Batch 290, Loss: 0.2140
Batch 300, Loss: 0.2057
Batch 310, Loss: 0.2203
Batch 320, Loss: 0.2207
Batch 330, Loss: 0.1736
Batch 340, Loss: 0.2184
Batch 350, Loss: 0.2023
Batch 360, Loss: 0.2216
Batch 370, Loss: 0.1910
Batch 380, Loss: 0.2104
Batch 390, Loss: 0.2121
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.201582670211792 seconds
Epoch 165 accuracy: 94.87%
Batch 10, Loss: 0.2279
Batch 20, Loss: 0.1856
Batch 30, Loss: 0.2245
Batch 40, Loss: 0.2145
Batch 50, Loss: 0.1988
Batch 60, Loss: 0.2294
Batch 70, Loss: 0.2054
Batch 80, Loss: 0.1937
Batch 90, Loss: 0.2068
Batch 100, Loss: 0.2416
Batch 110, Loss: 0.2175
Batch 120, Loss: 0.2121
Batch 130, Loss: 0.2040
Batch 140, Loss: 0.2140
Batch 150, Loss: 0.2281
Batch 160, Loss: 0.2451
Batch 170, Loss: 0.2088
Batch 180, Loss: 0.2129
Batch 190, Loss: 0.2151
Batch 200, Loss: 0.2209
Batch 210, Loss: 0.2367
Batch 220, Loss: 0.2046
Batch 230, Loss: 0.2103
Batch 240, Loss: 0.1995
Batch 250, Loss: 0.2280
Batch 260, Loss: 0.2341
Batch 270, Loss: 0.2268
Batch 280, Loss: 0.2196
Batch 290, Loss: 0.2016
Batch 300, Loss: 0.2164
Batch 310, Loss: 0.2111
Batch 320, Loss: 0.2324
Batch 330, Loss: 0.2236
Batch 340, Loss: 0.2169
Batch 350, Loss: 0.1978
Batch 360, Loss: 0.2015
Batch 370, Loss: 0.2124
Batch 380, Loss: 0.2144
Batch 390, Loss: 0.1991
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.160491943359375 seconds
Epoch 166 accuracy: 94.68%
Batch 10, Loss: 0.1972
Batch 20, Loss: 0.2224
Batch 30, Loss: 0.2106
Batch 40, Loss: 0.2183
Batch 50, Loss: 0.2102
Batch 60, Loss: 0.1891
Batch 70, Loss: 0.2166
Batch 80, Loss: 0.1836
Batch 90, Loss: 0.2231
Batch 100, Loss: 0.2023
Batch 110, Loss: 0.1807
Batch 120, Loss: 0.2465
Batch 130, Loss: 0.2203
Batch 140, Loss: 0.2054
Batch 150, Loss: 0.2302
Batch 160, Loss: 0.2108
Batch 170, Loss: 0.2033
Batch 180, Loss: 0.2090
Batch 190, Loss: 0.2082
Batch 200, Loss: 0.1870
Batch 210, Loss: 0.2111
Batch 220, Loss: 0.2195
Batch 230, Loss: 0.2181
Batch 240, Loss: 0.1974
Batch 250, Loss: 0.2141
Batch 260, Loss: 0.2349
Batch 270, Loss: 0.2115
Batch 280, Loss: 0.2073
Batch 290, Loss: 0.1893
Batch 300, Loss: 0.2288
Batch 310, Loss: 0.1945
Batch 320, Loss: 0.2069
Batch 330, Loss: 0.1991
Batch 340, Loss: 0.2089
Batch 350, Loss: 0.1713
Batch 360, Loss: 0.2132
Batch 370, Loss: 0.1848
Batch 380, Loss: 0.2274
Batch 390, Loss: 0.2080
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.20861530303955 seconds
Epoch 167 accuracy: 94.91%
Batch 10, Loss: 0.2068
Batch 20, Loss: 0.1918
Batch 30, Loss: 0.2258
Batch 40, Loss: 0.2010
Batch 50, Loss: 0.2098
Batch 60, Loss: 0.2081
Batch 70, Loss: 0.2217
Batch 80, Loss: 0.2108
Batch 90, Loss: 0.1870
Batch 100, Loss: 0.1865
Batch 110, Loss: 0.2167
Batch 120, Loss: 0.1954
Batch 130, Loss: 0.1876
Batch 140, Loss: 0.2131
Batch 150, Loss: 0.2145
Batch 160, Loss: 0.2150
Batch 170, Loss: 0.2115
Batch 180, Loss: 0.2123
Batch 190, Loss: 0.1855
Batch 200, Loss: 0.2123
Batch 210, Loss: 0.2051
Batch 220, Loss: 0.2171
Batch 230, Loss: 0.2159
Batch 240, Loss: 0.1839
Batch 250, Loss: 0.2166
Batch 260, Loss: 0.2219
Batch 270, Loss: 0.1993
Batch 280, Loss: 0.2232
Batch 290, Loss: 0.2217
Batch 300, Loss: 0.2068
Batch 310, Loss: 0.2275
Batch 320, Loss: 0.1969
Batch 330, Loss: 0.2025
Batch 340, Loss: 0.1920
Batch 350, Loss: 0.2282
Batch 360, Loss: 0.1669
Batch 370, Loss: 0.2339
Batch 380, Loss: 0.1792
Batch 390, Loss: 0.2249
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.237434148788452 seconds
Epoch 168 accuracy: 95.01%
Batch 10, Loss: 0.2084
Batch 20, Loss: 0.2236
Batch 30, Loss: 0.1686
Batch 40, Loss: 0.1825
Batch 50, Loss: 0.2022
Batch 60, Loss: 0.2091
Batch 70, Loss: 0.2085
Batch 80, Loss: 0.2043
Batch 90, Loss: 0.1818
Batch 100, Loss: 0.2054
Batch 110, Loss: 0.1925
Batch 120, Loss: 0.2079
Batch 130, Loss: 0.1570
Batch 140, Loss: 0.2003
Batch 150, Loss: 0.2088
Batch 160, Loss: 0.1889
Batch 170, Loss: 0.1759
Batch 180, Loss: 0.1904
Batch 190, Loss: 0.1996
Batch 200, Loss: 0.2027
Batch 210, Loss: 0.2049
Batch 220, Loss: 0.2001
Batch 230, Loss: 0.1891
Batch 240, Loss: 0.1938
Batch 250, Loss: 0.2090
Batch 260, Loss: 0.2174
Batch 270, Loss: 0.2239
Batch 280, Loss: 0.2167
Batch 290, Loss: 0.2086
Batch 300, Loss: 0.2097
Batch 310, Loss: 0.1554
Batch 320, Loss: 0.2165
Batch 330, Loss: 0.1903
Batch 340, Loss: 0.1788
Batch 350, Loss: 0.2251
Batch 360, Loss: 0.1991
Batch 370, Loss: 0.1922
Batch 380, Loss: 0.2143
Batch 390, Loss: 0.2110
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.12088179588318 seconds
Epoch 169 accuracy: 95.0%
Batch 10, Loss: 0.1648
Batch 20, Loss: 0.1901
Batch 30, Loss: 0.1977
Batch 40, Loss: 0.2304
Batch 50, Loss: 0.1971
Batch 60, Loss: 0.1757
Batch 70, Loss: 0.2164
Batch 80, Loss: 0.1937
Batch 90, Loss: 0.2062
Batch 100, Loss: 0.1756
Batch 110, Loss: 0.1993
Batch 120, Loss: 0.1862
Batch 130, Loss: 0.1908
Batch 140, Loss: 0.2075
Batch 150, Loss: 0.1939
Batch 160, Loss: 0.1962
Batch 170, Loss: 0.2006
Batch 180, Loss: 0.1852
Batch 190, Loss: 0.2183
Batch 200, Loss: 0.1906
Batch 210, Loss: 0.1798
Batch 220, Loss: 0.1693
Batch 230, Loss: 0.1726
Batch 240, Loss: 0.2099
Batch 250, Loss: 0.1744
Batch 260, Loss: 0.1878
Batch 270, Loss: 0.2103
Batch 280, Loss: 0.1899
Batch 290, Loss: 0.2163
Batch 300, Loss: 0.2083
Batch 310, Loss: 0.1913
Batch 320, Loss: 0.1916
Batch 330, Loss: 0.1937
Batch 340, Loss: 0.1779
Batch 350, Loss: 0.2079
Batch 360, Loss: 0.2213
Batch 370, Loss: 0.2120
Batch 380, Loss: 0.2180
Batch 390, Loss: 0.2164
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.113927602767944 seconds
Epoch 170 accuracy: 94.95%
Batch 10, Loss: 0.1915
Batch 20, Loss: 0.1872
Batch 30, Loss: 0.1859
Batch 40, Loss: 0.1949
Batch 50, Loss: 0.1806
Batch 60, Loss: 0.1854
Batch 70, Loss: 0.2149
Batch 80, Loss: 0.2186
Batch 90, Loss: 0.1865
Batch 100, Loss: 0.1804
Batch 110, Loss: 0.1872
Batch 120, Loss: 0.2042
Batch 130, Loss: 0.1803
Batch 140, Loss: 0.1856
Batch 150, Loss: 0.1778
Batch 160, Loss: 0.1829
Batch 170, Loss: 0.2300
Batch 180, Loss: 0.1902
Batch 190, Loss: 0.1782
Batch 200, Loss: 0.1900
Batch 210, Loss: 0.1708
Batch 220, Loss: 0.1978
Batch 230, Loss: 0.2312
Batch 240, Loss: 0.2018
Batch 250, Loss: 0.1645
Batch 260, Loss: 0.2030
Batch 270, Loss: 0.1994
Batch 280, Loss: 0.2029
Batch 290, Loss: 0.1864
Batch 300, Loss: 0.1878
Batch 310, Loss: 0.2072
Batch 320, Loss: 0.2100
Batch 330, Loss: 0.2010
Batch 340, Loss: 0.1929
Batch 350, Loss: 0.1844
Batch 360, Loss: 0.1667
Batch 370, Loss: 0.1915
Batch 380, Loss: 0.1637
Batch 390, Loss: 0.1870
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.04889965057373 seconds
Epoch 171 accuracy: 95.26%
Batch 10, Loss: 0.2156
Batch 20, Loss: 0.1690
Batch 30, Loss: 0.1793
Batch 40, Loss: 0.1627
Batch 50, Loss: 0.1987
Batch 60, Loss: 0.2079
Batch 70, Loss: 0.1770
Batch 80, Loss: 0.1820
Batch 90, Loss: 0.2096
Batch 100, Loss: 0.1906
Batch 110, Loss: 0.1951
Batch 120, Loss: 0.1870
Batch 130, Loss: 0.1692
Batch 140, Loss: 0.1600
Batch 150, Loss: 0.1775
Batch 160, Loss: 0.2090
Batch 170, Loss: 0.1997
Batch 180, Loss: 0.2078
Batch 190, Loss: 0.1509
Batch 200, Loss: 0.2080
Batch 210, Loss: 0.1959
Batch 220, Loss: 0.1770
Batch 230, Loss: 0.2098
Batch 240, Loss: 0.2344
Batch 250, Loss: 0.1827
Batch 260, Loss: 0.1991
Batch 270, Loss: 0.1561
Batch 280, Loss: 0.2208
Batch 290, Loss: 0.1766
Batch 300, Loss: 0.1906
Batch 310, Loss: 0.2285
Batch 320, Loss: 0.2073
Batch 330, Loss: 0.1912
Batch 340, Loss: 0.1905
Batch 350, Loss: 0.1782
Batch 360, Loss: 0.1934
Batch 370, Loss: 0.1980
Batch 380, Loss: 0.1825
Batch 390, Loss: 0.1923
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.084014892578125 seconds
Epoch 172 accuracy: 95.29%
Batch 10, Loss: 0.1669
Batch 20, Loss: 0.1979
Batch 30, Loss: 0.1933
Batch 40, Loss: 0.1900
Batch 50, Loss: 0.1897
Batch 60, Loss: 0.1828
Batch 70, Loss: 0.1998
Batch 80, Loss: 0.2052
Batch 90, Loss: 0.1851
Batch 100, Loss: 0.1572
Batch 110, Loss: 0.1708
Batch 120, Loss: 0.1760
Batch 130, Loss: 0.1742
Batch 140, Loss: 0.1672
Batch 150, Loss: 0.1786
Batch 160, Loss: 0.1649
Batch 170, Loss: 0.1925
Batch 180, Loss: 0.1822
Batch 190, Loss: 0.1718
Batch 200, Loss: 0.1864
Batch 210, Loss: 0.1821
Batch 220, Loss: 0.1822
Batch 230, Loss: 0.1556
Batch 240, Loss: 0.2025
Batch 250, Loss: 0.2004
Batch 260, Loss: 0.1859
Batch 270, Loss: 0.1788
Batch 280, Loss: 0.1713
Batch 290, Loss: 0.1826
Batch 300, Loss: 0.1909
Batch 310, Loss: 0.1833
Batch 320, Loss: 0.1762
Batch 330, Loss: 0.1752
Batch 340, Loss: 0.2069
Batch 350, Loss: 0.2083
Batch 360, Loss: 0.1868
Batch 370, Loss: 0.1759
Batch 380, Loss: 0.1792
Batch 390, Loss: 0.2062
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.169042348861694 seconds
Epoch 173 accuracy: 95.43%
Batch 10, Loss: 0.1623
Batch 20, Loss: 0.1632
Batch 30, Loss: 0.1892
Batch 40, Loss: 0.1928
Batch 50, Loss: 0.1884
Batch 60, Loss: 0.2025
Batch 70, Loss: 0.1745
Batch 80, Loss: 0.1753
Batch 90, Loss: 0.1721
Batch 100, Loss: 0.1716
Batch 110, Loss: 0.2034
Batch 120, Loss: 0.1661
Batch 130, Loss: 0.1853
Batch 140, Loss: 0.1893
Batch 150, Loss: 0.2093
Batch 160, Loss: 0.1932
Batch 170, Loss: 0.1686
Batch 180, Loss: 0.1751
Batch 190, Loss: 0.1775
Batch 200, Loss: 0.1919
Batch 210, Loss: 0.1869
Batch 220, Loss: 0.1611
Batch 230, Loss: 0.1727
Batch 240, Loss: 0.1755
Batch 250, Loss: 0.1887
Batch 260, Loss: 0.2231
Batch 270, Loss: 0.1790
Batch 280, Loss: 0.1606
Batch 290, Loss: 0.1998
Batch 300, Loss: 0.1759
Batch 310, Loss: 0.1681
Batch 320, Loss: 0.1803
Batch 330, Loss: 0.1689
Batch 340, Loss: 0.1810
Batch 350, Loss: 0.1900
Batch 360, Loss: 0.1894
Batch 370, Loss: 0.1772
Batch 380, Loss: 0.1841
Batch 390, Loss: 0.1886
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.194279670715332 seconds
Epoch 174 accuracy: 95.67%
Batch 10, Loss: 0.1820
Batch 20, Loss: 0.1924
Batch 30, Loss: 0.1677
Batch 40, Loss: 0.1812
Batch 50, Loss: 0.1571
Batch 60, Loss: 0.1974
Batch 70, Loss: 0.1537
Batch 80, Loss: 0.1839
Batch 90, Loss: 0.1694
Batch 100, Loss: 0.2226
Batch 110, Loss: 0.1798
Batch 120, Loss: 0.1783
Batch 130, Loss: 0.1887
Batch 140, Loss: 0.1726
Batch 150, Loss: 0.1656
Batch 160, Loss: 0.1891
Batch 170, Loss: 0.1910
Batch 180, Loss: 0.1924
Batch 190, Loss: 0.1986
Batch 200, Loss: 0.1680
Batch 210, Loss: 0.1710
Batch 220, Loss: 0.1855
Batch 230, Loss: 0.1781
Batch 240, Loss: 0.1785
Batch 250, Loss: 0.1762
Batch 260, Loss: 0.1560
Batch 270, Loss: 0.1610
Batch 280, Loss: 0.1563
Batch 290, Loss: 0.2119
Batch 300, Loss: 0.2083
Batch 310, Loss: 0.1588
Batch 320, Loss: 0.1990
Batch 330, Loss: 0.1697
Batch 340, Loss: 0.1865
Batch 350, Loss: 0.1960
Batch 360, Loss: 0.1790
Batch 370, Loss: 0.1683
Batch 380, Loss: 0.1632
Batch 390, Loss: 0.1754
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.06824016571045 seconds
Epoch 175 accuracy: 95.64%
Batch 10, Loss: 0.1759
Batch 20, Loss: 0.1646
Batch 30, Loss: 0.1749
Batch 40, Loss: 0.1758
Batch 50, Loss: 0.1563
Batch 60, Loss: 0.1883
Batch 70, Loss: 0.1777
Batch 80, Loss: 0.1670
Batch 90, Loss: 0.1755
Batch 100, Loss: 0.1590
Batch 110, Loss: 0.1582
Batch 120, Loss: 0.1846
Batch 130, Loss: 0.1665
Batch 140, Loss: 0.1606
Batch 150, Loss: 0.1780
Batch 160, Loss: 0.2007
Batch 170, Loss: 0.1568
Batch 180, Loss: 0.1613
Batch 190, Loss: 0.1643
Batch 200, Loss: 0.1872
Batch 210, Loss: 0.1723
Batch 220, Loss: 0.1804
Batch 230, Loss: 0.1776
Batch 240, Loss: 0.1904
Batch 250, Loss: 0.1630
Batch 260, Loss: 0.1586
Batch 270, Loss: 0.1841
Batch 280, Loss: 0.1790
Batch 290, Loss: 0.1619
Batch 300, Loss: 0.1760
Batch 310, Loss: 0.1649
Batch 320, Loss: 0.1921
Batch 330, Loss: 0.1495
Batch 340, Loss: 0.1572
Batch 350, Loss: 0.1503
Batch 360, Loss: 0.1869
Batch 370, Loss: 0.1830
Batch 380, Loss: 0.1781
Batch 390, Loss: 0.1878
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.322657585144043 seconds
Epoch 176 accuracy: 95.74%
Batch 10, Loss: 0.1917
Batch 20, Loss: 0.1826
Batch 30, Loss: 0.1837
Batch 40, Loss: 0.1633
Batch 50, Loss: 0.1668
Batch 60, Loss: 0.1579
Batch 70, Loss: 0.1673
Batch 80, Loss: 0.1769
Batch 90, Loss: 0.1534
Batch 100, Loss: 0.1788
Batch 110, Loss: 0.1584
Batch 120, Loss: 0.1536
Batch 130, Loss: 0.1689
Batch 140, Loss: 0.1730
Batch 150, Loss: 0.1667
Batch 160, Loss: 0.1613
Batch 170, Loss: 0.1723
Batch 180, Loss: 0.1437
Batch 190, Loss: 0.1767
Batch 200, Loss: 0.1616
Batch 210, Loss: 0.1598
Batch 220, Loss: 0.1947
Batch 230, Loss: 0.1682
Batch 240, Loss: 0.1477
Batch 250, Loss: 0.1709
Batch 260, Loss: 0.1701
Batch 270, Loss: 0.1747
Batch 280, Loss: 0.1940
Batch 290, Loss: 0.1851
Batch 300, Loss: 0.1452
Batch 310, Loss: 0.1808
Batch 320, Loss: 0.1634
Batch 330, Loss: 0.1466
Batch 340, Loss: 0.1559
Batch 350, Loss: 0.1613
Batch 360, Loss: 0.2151
Batch 370, Loss: 0.1955
Batch 380, Loss: 0.1886
Batch 390, Loss: 0.1772
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.25973343849182 seconds
Epoch 177 accuracy: 95.53%
Batch 10, Loss: 0.1456
Batch 20, Loss: 0.1488
Batch 30, Loss: 0.1721
Batch 40, Loss: 0.1761
Batch 50, Loss: 0.1656
Batch 60, Loss: 0.1354
Batch 70, Loss: 0.1677
Batch 80, Loss: 0.1689
Batch 90, Loss: 0.1753
Batch 100, Loss: 0.1571
Batch 110, Loss: 0.1446
Batch 120, Loss: 0.1470
Batch 130, Loss: 0.1562
Batch 140, Loss: 0.1837
Batch 150, Loss: 0.1683
Batch 160, Loss: 0.1769
Batch 170, Loss: 0.1574
Batch 180, Loss: 0.1671
Batch 190, Loss: 0.1881
Batch 200, Loss: 0.1274
Batch 210, Loss: 0.1649
Batch 220, Loss: 0.1624
Batch 230, Loss: 0.1847
Batch 240, Loss: 0.1512
Batch 250, Loss: 0.1633
Batch 260, Loss: 0.1890
Batch 270, Loss: 0.1606
Batch 280, Loss: 0.1616
Batch 290, Loss: 0.1299
Batch 300, Loss: 0.1597
Batch 310, Loss: 0.1776
Batch 320, Loss: 0.1454
Batch 330, Loss: 0.1629
Batch 340, Loss: 0.1666
Batch 350, Loss: 0.1829
Batch 360, Loss: 0.1481
Batch 370, Loss: 0.1651
Batch 380, Loss: 0.1666
Batch 390, Loss: 0.1674
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.14421534538269 seconds
Epoch 178 accuracy: 95.39%
Batch 10, Loss: 0.1593
Batch 20, Loss: 0.1653
Batch 30, Loss: 0.1432
Batch 40, Loss: 0.1459
Batch 50, Loss: 0.1582
Batch 60, Loss: 0.1785
Batch 70, Loss: 0.1617
Batch 80, Loss: 0.1564
Batch 90, Loss: 0.1780
Batch 100, Loss: 0.1702
Batch 110, Loss: 0.1627
Batch 120, Loss: 0.1587
Batch 130, Loss: 0.1773
Batch 140, Loss: 0.1794
Batch 150, Loss: 0.1779
Batch 160, Loss: 0.1620
Batch 170, Loss: 0.1699
Batch 180, Loss: 0.1492
Batch 190, Loss: 0.1647
Batch 200, Loss: 0.1572
Batch 210, Loss: 0.1753
Batch 220, Loss: 0.1507
Batch 230, Loss: 0.1514
Batch 240, Loss: 0.1730
Batch 250, Loss: 0.1917
Batch 260, Loss: 0.1706
Batch 270, Loss: 0.1549
Batch 280, Loss: 0.1683
Batch 290, Loss: 0.1659
Batch 300, Loss: 0.1606
Batch 310, Loss: 0.1714
Batch 320, Loss: 0.1731
Batch 330, Loss: 0.1711
Batch 340, Loss: 0.1932
Batch 350, Loss: 0.1751
Batch 360, Loss: 0.1656
Batch 370, Loss: 0.1829
Batch 380, Loss: 0.1799
Batch 390, Loss: 0.1519
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.11737608909607 seconds
Epoch 179 accuracy: 95.7%
Batch 10, Loss: 0.1488
Batch 20, Loss: 0.1322
Batch 30, Loss: 0.1653
Batch 40, Loss: 0.1596
Batch 50, Loss: 0.1528
Batch 60, Loss: 0.1443
Batch 70, Loss: 0.1680
Batch 80, Loss: 0.1651
Batch 90, Loss: 0.1371
Batch 100, Loss: 0.1562
Batch 110, Loss: 0.1876
Batch 120, Loss: 0.1569
Batch 130, Loss: 0.1755
Batch 140, Loss: 0.1378
Batch 150, Loss: 0.1671
Batch 160, Loss: 0.1707
Batch 170, Loss: 0.1692
Batch 180, Loss: 0.1583
Batch 190, Loss: 0.1430
Batch 200, Loss: 0.1717
Batch 210, Loss: 0.1651
Batch 220, Loss: 0.1663
Batch 230, Loss: 0.1857
Batch 240, Loss: 0.1531
Batch 250, Loss: 0.1410
Batch 260, Loss: 0.1587
Batch 270, Loss: 0.1715
Batch 280, Loss: 0.1628
Batch 290, Loss: 0.1520
Batch 300, Loss: 0.1506
Batch 310, Loss: 0.1498
Batch 320, Loss: 0.1362
Batch 330, Loss: 0.1807
Batch 340, Loss: 0.1677
Batch 350, Loss: 0.1666
Batch 360, Loss: 0.1517
Batch 370, Loss: 0.1550
Batch 380, Loss: 0.1571
Batch 390, Loss: 0.1537
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.10671043395996 seconds
Epoch 180 accuracy: 95.78%
Batch 10, Loss: 0.1454
Batch 20, Loss: 0.1590
Batch 30, Loss: 0.1490
Batch 40, Loss: 0.1862
Batch 50, Loss: 0.1625
Batch 60, Loss: 0.1555
Batch 70, Loss: 0.1230
Batch 80, Loss: 0.1607
Batch 90, Loss: 0.1398
Batch 100, Loss: 0.1780
Batch 110, Loss: 0.1460
Batch 120, Loss: 0.1533
Batch 130, Loss: 0.1390
Batch 140, Loss: 0.1736
Batch 150, Loss: 0.1753
Batch 160, Loss: 0.1360
Batch 170, Loss: 0.1877
Batch 180, Loss: 0.1443
Batch 190, Loss: 0.1733
Batch 200, Loss: 0.1356
Batch 210, Loss: 0.1633
Batch 220, Loss: 0.1447
Batch 230, Loss: 0.1726
Batch 240, Loss: 0.1503
Batch 250, Loss: 0.1676
Batch 260, Loss: 0.1481
Batch 270, Loss: 0.1412
Batch 280, Loss: 0.1625
Batch 290, Loss: 0.1507
Batch 300, Loss: 0.1507
Batch 310, Loss: 0.1510
Batch 320, Loss: 0.1678
Batch 330, Loss: 0.1344
Batch 340, Loss: 0.1558
Batch 350, Loss: 0.1571
Batch 360, Loss: 0.1447
Batch 370, Loss: 0.1586
Batch 380, Loss: 0.1432
Batch 390, Loss: 0.1527
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.156890630722046 seconds
Epoch 181 accuracy: 95.92%
Batch 10, Loss: 0.1240
Batch 20, Loss: 0.1350
Batch 30, Loss: 0.1623
Batch 40, Loss: 0.1537
Batch 50, Loss: 0.1350
Batch 60, Loss: 0.1556
Batch 70, Loss: 0.1355
Batch 80, Loss: 0.1393
Batch 90, Loss: 0.1703
Batch 100, Loss: 0.1410
Batch 110, Loss: 0.1574
Batch 120, Loss: 0.1559
Batch 130, Loss: 0.1599
Batch 140, Loss: 0.1435
Batch 150, Loss: 0.1351
Batch 160, Loss: 0.1266
Batch 170, Loss: 0.1734
Batch 180, Loss: 0.1565
Batch 190, Loss: 0.1603
Batch 200, Loss: 0.1465
Batch 210, Loss: 0.1524
Batch 220, Loss: 0.1677
Batch 230, Loss: 0.1650
Batch 240, Loss: 0.1667
Batch 250, Loss: 0.1443
Batch 260, Loss: 0.1505
Batch 270, Loss: 0.1603
Batch 280, Loss: 0.1641
Batch 290, Loss: 0.1250
Batch 300, Loss: 0.1571
Batch 310, Loss: 0.1618
Batch 320, Loss: 0.1581
Batch 330, Loss: 0.1523
Batch 340, Loss: 0.1330
Batch 350, Loss: 0.1221
Batch 360, Loss: 0.1484
Batch 370, Loss: 0.1650
Batch 380, Loss: 0.1611
Batch 390, Loss: 0.1271
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.113120079040527 seconds
Epoch 182 accuracy: 95.67%
Batch 10, Loss: 0.1219
Batch 20, Loss: 0.1407
Batch 30, Loss: 0.1455
Batch 40, Loss: 0.1352
Batch 50, Loss: 0.1299
Batch 60, Loss: 0.1266
Batch 70, Loss: 0.1321
Batch 80, Loss: 0.1343
Batch 90, Loss: 0.1409
Batch 100, Loss: 0.1470
Batch 110, Loss: 0.1386
Batch 120, Loss: 0.1276
Batch 130, Loss: 0.1787
Batch 140, Loss: 0.1471
Batch 150, Loss: 0.1478
Batch 160, Loss: 0.1613
Batch 170, Loss: 0.1666
Batch 180, Loss: 0.1555
Batch 190, Loss: 0.1643
Batch 200, Loss: 0.1526
Batch 210, Loss: 0.1503
Batch 220, Loss: 0.1712
Batch 230, Loss: 0.1526
Batch 240, Loss: 0.1424
Batch 250, Loss: 0.1427
Batch 260, Loss: 0.1525
Batch 270, Loss: 0.1610
Batch 280, Loss: 0.1484
Batch 290, Loss: 0.1589
Batch 300, Loss: 0.1509
Batch 310, Loss: 0.1463
Batch 320, Loss: 0.1497
Batch 330, Loss: 0.1408
Batch 340, Loss: 0.1618
Batch 350, Loss: 0.1306
Batch 360, Loss: 0.1410
Batch 370, Loss: 0.1498
Batch 380, Loss: 0.1454
Batch 390, Loss: 0.1535
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.024566173553467 seconds
Epoch 183 accuracy: 95.98%
Batch 10, Loss: 0.1407
Batch 20, Loss: 0.1406
Batch 30, Loss: 0.1332
Batch 40, Loss: 0.1603
Batch 50, Loss: 0.1378
Batch 60, Loss: 0.1680
Batch 70, Loss: 0.1282
Batch 80, Loss: 0.1867
Batch 90, Loss: 0.1265
Batch 100, Loss: 0.1516
Batch 110, Loss: 0.1578
Batch 120, Loss: 0.1513
Batch 130, Loss: 0.1269
Batch 140, Loss: 0.1568
Batch 150, Loss: 0.1507
Batch 160, Loss: 0.1657
Batch 170, Loss: 0.1512
Batch 180, Loss: 0.1320
Batch 190, Loss: 0.1691
Batch 200, Loss: 0.1446
Batch 210, Loss: 0.1355
Batch 220, Loss: 0.1516
Batch 230, Loss: 0.1227
Batch 240, Loss: 0.1654
Batch 250, Loss: 0.1409
Batch 260, Loss: 0.1335
Batch 270, Loss: 0.1539
Batch 280, Loss: 0.1480
Batch 290, Loss: 0.1392
Batch 300, Loss: 0.1377
Batch 310, Loss: 0.1448
Batch 320, Loss: 0.1440
Batch 330, Loss: 0.1406
Batch 340, Loss: 0.1562
Batch 350, Loss: 0.1426
Batch 360, Loss: 0.1600
Batch 370, Loss: 0.1540
Batch 380, Loss: 0.1393
Batch 390, Loss: 0.1432
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.056833744049072 seconds
Epoch 184 accuracy: 95.91%
Batch 10, Loss: 0.1516
Batch 20, Loss: 0.1404
Batch 30, Loss: 0.1485
Batch 40, Loss: 0.1588
Batch 50, Loss: 0.1233
Batch 60, Loss: 0.1285
Batch 70, Loss: 0.1322
Batch 80, Loss: 0.1483
Batch 90, Loss: 0.1457
Batch 100, Loss: 0.1504
Batch 110, Loss: 0.1507
Batch 120, Loss: 0.1327
Batch 130, Loss: 0.1208
Batch 140, Loss: 0.1377
Batch 150, Loss: 0.1229
Batch 160, Loss: 0.1298
Batch 170, Loss: 0.1532
Batch 180, Loss: 0.1591
Batch 190, Loss: 0.1480
Batch 200, Loss: 0.1255
Batch 210, Loss: 0.1292
Batch 220, Loss: 0.1376
Batch 230, Loss: 0.1355
Batch 240, Loss: 0.1563
Batch 250, Loss: 0.1731
Batch 260, Loss: 0.1439
Batch 270, Loss: 0.1238
Batch 280, Loss: 0.1422
Batch 290, Loss: 0.1388
Batch 300, Loss: 0.1556
Batch 310, Loss: 0.1371
Batch 320, Loss: 0.1582
Batch 330, Loss: 0.1323
Batch 340, Loss: 0.1239
Batch 350, Loss: 0.1443
Batch 360, Loss: 0.1333
Batch 370, Loss: 0.1175
Batch 380, Loss: 0.1281
Batch 390, Loss: 0.1331
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.2456955909729 seconds
Epoch 185 accuracy: 96.16%
Batch 10, Loss: 0.1326
Batch 20, Loss: 0.1390
Batch 30, Loss: 0.1489
Batch 40, Loss: 0.1296
Batch 50, Loss: 0.1500
Batch 60, Loss: 0.1437
Batch 70, Loss: 0.1404
Batch 80, Loss: 0.1383
Batch 90, Loss: 0.1415
Batch 100, Loss: 0.1521
Batch 110, Loss: 0.1544
Batch 120, Loss: 0.1424
Batch 130, Loss: 0.1217
Batch 140, Loss: 0.1397
Batch 150, Loss: 0.1286
Batch 160, Loss: 0.1311
Batch 170, Loss: 0.1164
Batch 180, Loss: 0.1193
Batch 190, Loss: 0.1411
Batch 200, Loss: 0.1335
Batch 210, Loss: 0.1251
Batch 220, Loss: 0.1715
Batch 230, Loss: 0.1469
Batch 240, Loss: 0.1293
Batch 250, Loss: 0.1331
Batch 260, Loss: 0.1422
Batch 270, Loss: 0.1412
Batch 280, Loss: 0.1434
Batch 290, Loss: 0.1347
Batch 300, Loss: 0.1406
Batch 310, Loss: 0.1542
Batch 320, Loss: 0.1323
Batch 330, Loss: 0.1326
Batch 340, Loss: 0.1323
Batch 350, Loss: 0.1349
Batch 360, Loss: 0.1354
Batch 370, Loss: 0.1028
Batch 380, Loss: 0.1341
Batch 390, Loss: 0.1415
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.17935037612915 seconds
Epoch 186 accuracy: 96.13%
Batch 10, Loss: 0.1175
Batch 20, Loss: 0.1326
Batch 30, Loss: 0.1582
Batch 40, Loss: 0.1370
Batch 50, Loss: 0.1321
Batch 60, Loss: 0.1426
Batch 70, Loss: 0.1447
Batch 80, Loss: 0.1338
Batch 90, Loss: 0.1101
Batch 100, Loss: 0.1604
Batch 110, Loss: 0.1548
Batch 120, Loss: 0.1266
Batch 130, Loss: 0.1207
Batch 140, Loss: 0.1186
Batch 150, Loss: 0.1359
Batch 160, Loss: 0.1170
Batch 170, Loss: 0.1369
Batch 180, Loss: 0.1377
Batch 190, Loss: 0.1245
Batch 200, Loss: 0.1213
Batch 210, Loss: 0.1492
Batch 220, Loss: 0.1378
Batch 230, Loss: 0.1525
Batch 240, Loss: 0.1454
Batch 250, Loss: 0.1593
Batch 260, Loss: 0.1174
Batch 270, Loss: 0.1229
Batch 280, Loss: 0.1426
Batch 290, Loss: 0.1388
Batch 300, Loss: 0.1269
Batch 310, Loss: 0.1453
Batch 320, Loss: 0.1300
Batch 330, Loss: 0.1383
Batch 340, Loss: 0.1094
Batch 350, Loss: 0.1409
Batch 360, Loss: 0.1097
Batch 370, Loss: 0.1511
Batch 380, Loss: 0.1342
Batch 390, Loss: 0.1222
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.113770246505737 seconds
Epoch 187 accuracy: 96.24%
Batch 10, Loss: 0.1351
Batch 20, Loss: 0.1259
Batch 30, Loss: 0.1199
Batch 40, Loss: 0.1396
Batch 50, Loss: 0.1317
Batch 60, Loss: 0.1387
Batch 70, Loss: 0.1409
Batch 80, Loss: 0.1339
Batch 90, Loss: 0.1570
Batch 100, Loss: 0.1309
Batch 110, Loss: 0.1360
Batch 120, Loss: 0.1287
Batch 130, Loss: 0.1217
Batch 140, Loss: 0.1362
Batch 150, Loss: 0.1325
Batch 160, Loss: 0.1509
Batch 170, Loss: 0.1390
Batch 180, Loss: 0.1304
Batch 190, Loss: 0.1598
Batch 200, Loss: 0.1380
Batch 210, Loss: 0.1232
Batch 220, Loss: 0.1138
Batch 230, Loss: 0.1155
Batch 240, Loss: 0.1194
Batch 250, Loss: 0.1393
Batch 260, Loss: 0.1353
Batch 270, Loss: 0.1246
Batch 280, Loss: 0.1143
Batch 290, Loss: 0.1348
Batch 300, Loss: 0.1327
Batch 310, Loss: 0.1321
Batch 320, Loss: 0.1132
Batch 330, Loss: 0.1200
Batch 340, Loss: 0.1497
Batch 350, Loss: 0.1264
Batch 360, Loss: 0.1312
Batch 370, Loss: 0.1583
Batch 380, Loss: 0.1213
Batch 390, Loss: 0.1273
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.27430295944214 seconds
Epoch 188 accuracy: 96.28%
Batch 10, Loss: 0.1393
Batch 20, Loss: 0.1533
Batch 30, Loss: 0.1337
Batch 40, Loss: 0.1342
Batch 50, Loss: 0.1270
Batch 60, Loss: 0.1382
Batch 70, Loss: 0.1471
Batch 80, Loss: 0.1115
Batch 90, Loss: 0.1291
Batch 100, Loss: 0.1369
Batch 110, Loss: 0.1340
Batch 120, Loss: 0.1420
Batch 130, Loss: 0.1344
Batch 140, Loss: 0.1322
Batch 150, Loss: 0.1240
Batch 160, Loss: 0.1225
Batch 170, Loss: 0.1388
Batch 180, Loss: 0.1425
Batch 190, Loss: 0.1339
Batch 200, Loss: 0.1375
Batch 210, Loss: 0.1431
Batch 220, Loss: 0.1068
Batch 230, Loss: 0.1326
Batch 240, Loss: 0.1242
Batch 250, Loss: 0.1349
Batch 260, Loss: 0.1241
Batch 270, Loss: 0.1288
Batch 280, Loss: 0.1276
Batch 290, Loss: 0.1407
Batch 300, Loss: 0.1448
Batch 310, Loss: 0.1365
Batch 320, Loss: 0.1256
Batch 330, Loss: 0.1384
Batch 340, Loss: 0.1340
Batch 350, Loss: 0.1246
Batch 360, Loss: 0.1333
Batch 370, Loss: 0.1319
Batch 380, Loss: 0.1479
Batch 390, Loss: 0.1347
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.141549348831177 seconds
Epoch 189 accuracy: 96.24%
Batch 10, Loss: 0.1263
Batch 20, Loss: 0.1264
Batch 30, Loss: 0.1331
Batch 40, Loss: 0.1157
Batch 50, Loss: 0.1216
Batch 60, Loss: 0.1516
Batch 70, Loss: 0.1416
Batch 80, Loss: 0.1381
Batch 90, Loss: 0.1269
Batch 100, Loss: 0.1305
Batch 110, Loss: 0.1443
Batch 120, Loss: 0.1268
Batch 130, Loss: 0.0979
Batch 140, Loss: 0.1211
Batch 150, Loss: 0.1317
Batch 160, Loss: 0.1173
Batch 170, Loss: 0.1252
Batch 180, Loss: 0.1668
Batch 190, Loss: 0.1236
Batch 200, Loss: 0.1206
Batch 210, Loss: 0.1282
Batch 220, Loss: 0.1184
Batch 230, Loss: 0.1302
Batch 240, Loss: 0.1428
Batch 250, Loss: 0.1251
Batch 260, Loss: 0.1585
Batch 270, Loss: 0.1243
Batch 280, Loss: 0.1223
Batch 290, Loss: 0.1167
Batch 300, Loss: 0.1157
Batch 310, Loss: 0.1368
Batch 320, Loss: 0.1316
Batch 330, Loss: 0.1360
Batch 340, Loss: 0.1337
Batch 350, Loss: 0.1401
Batch 360, Loss: 0.1170
Batch 370, Loss: 0.1325
Batch 380, Loss: 0.1083
Batch 390, Loss: 0.1248
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.15855360031128 seconds
Epoch 190 accuracy: 96.17%
Batch 10, Loss: 0.1387
Batch 20, Loss: 0.1225
Batch 30, Loss: 0.1213
Batch 40, Loss: 0.1364
Batch 50, Loss: 0.1109
Batch 60, Loss: 0.1361
Batch 70, Loss: 0.1534
Batch 80, Loss: 0.1234
Batch 90, Loss: 0.1315
Batch 100, Loss: 0.1371
Batch 110, Loss: 0.1156
Batch 120, Loss: 0.1279
Batch 130, Loss: 0.1404
Batch 140, Loss: 0.1171
Batch 150, Loss: 0.1175
Batch 160, Loss: 0.1126
Batch 170, Loss: 0.1263
Batch 180, Loss: 0.1218
Batch 190, Loss: 0.1156
Batch 200, Loss: 0.1357
Batch 210, Loss: 0.1574
Batch 220, Loss: 0.1204
Batch 230, Loss: 0.1452
Batch 240, Loss: 0.1346
Batch 250, Loss: 0.1296
Batch 260, Loss: 0.1024
Batch 270, Loss: 0.1244
Batch 280, Loss: 0.1203
Batch 290, Loss: 0.1366
Batch 300, Loss: 0.1194
Batch 310, Loss: 0.1337
Batch 320, Loss: 0.1127
Batch 330, Loss: 0.1186
Batch 340, Loss: 0.1364
Batch 350, Loss: 0.1351
Batch 360, Loss: 0.1172
Batch 370, Loss: 0.1317
Batch 380, Loss: 0.1301
Batch 390, Loss: 0.1289
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.119652032852173 seconds
Epoch 191 accuracy: 96.23%
Batch 10, Loss: 0.1528
Batch 20, Loss: 0.1101
Batch 30, Loss: 0.1206
Batch 40, Loss: 0.1356
Batch 50, Loss: 0.1411
Batch 60, Loss: 0.1120
Batch 70, Loss: 0.1277
Batch 80, Loss: 0.1117
Batch 90, Loss: 0.1285
Batch 100, Loss: 0.1218
Batch 110, Loss: 0.1315
Batch 120, Loss: 0.1198
Batch 130, Loss: 0.1207
Batch 140, Loss: 0.1176
Batch 150, Loss: 0.1377
Batch 160, Loss: 0.1242
Batch 170, Loss: 0.1219
Batch 180, Loss: 0.1384
Batch 190, Loss: 0.1270
Batch 200, Loss: 0.1295
Batch 210, Loss: 0.1278
Batch 220, Loss: 0.1449
Batch 230, Loss: 0.1087
Batch 240, Loss: 0.1423
Batch 250, Loss: 0.1419
Batch 260, Loss: 0.1278
Batch 270, Loss: 0.1165
Batch 280, Loss: 0.1153
Batch 290, Loss: 0.1416
Batch 300, Loss: 0.1258
Batch 310, Loss: 0.1336
Batch 320, Loss: 0.1148
Batch 330, Loss: 0.1315
Batch 340, Loss: 0.1168
Batch 350, Loss: 0.1330
Batch 360, Loss: 0.1282
Batch 370, Loss: 0.1107
Batch 380, Loss: 0.1274
Batch 390, Loss: 0.1201
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.249114274978638 seconds
Epoch 192 accuracy: 96.32%
Batch 10, Loss: 0.1141
Batch 20, Loss: 0.1347
Batch 30, Loss: 0.1332
Batch 40, Loss: 0.1295
Batch 50, Loss: 0.1406
Batch 60, Loss: 0.1204
Batch 70, Loss: 0.1235
Batch 80, Loss: 0.1293
Batch 90, Loss: 0.1312
Batch 100, Loss: 0.1032
Batch 110, Loss: 0.1159
Batch 120, Loss: 0.1131
Batch 130, Loss: 0.1424
Batch 140, Loss: 0.1294
Batch 150, Loss: 0.1309
Batch 160, Loss: 0.1232
Batch 170, Loss: 0.1215
Batch 180, Loss: 0.1293
Batch 190, Loss: 0.1495
Batch 200, Loss: 0.1213
Batch 210, Loss: 0.1234
Batch 220, Loss: 0.1375
Batch 230, Loss: 0.1236
Batch 240, Loss: 0.1288
Batch 250, Loss: 0.1072
Batch 260, Loss: 0.1255
Batch 270, Loss: 0.1026
Batch 280, Loss: 0.1238
Batch 290, Loss: 0.1477
Batch 300, Loss: 0.1338
Batch 310, Loss: 0.1095
Batch 320, Loss: 0.1197
Batch 330, Loss: 0.1238
Batch 340, Loss: 0.1318
Batch 350, Loss: 0.1216
Batch 360, Loss: 0.1472
Batch 370, Loss: 0.1204
Batch 380, Loss: 0.1206
Batch 390, Loss: 0.1316
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.09841299057007 seconds
Epoch 193 accuracy: 96.39%
Batch 10, Loss: 0.1225
Batch 20, Loss: 0.1169
Batch 30, Loss: 0.1232
Batch 40, Loss: 0.1313
Batch 50, Loss: 0.1293
Batch 60, Loss: 0.1202
Batch 70, Loss: 0.1250
Batch 80, Loss: 0.1206
Batch 90, Loss: 0.1303
Batch 100, Loss: 0.1237
Batch 110, Loss: 0.1278
Batch 120, Loss: 0.1366
Batch 130, Loss: 0.1293
Batch 140, Loss: 0.1330
Batch 150, Loss: 0.1311
Batch 160, Loss: 0.1117
Batch 170, Loss: 0.1247
Batch 180, Loss: 0.1292
Batch 190, Loss: 0.1289
Batch 200, Loss: 0.1381
Batch 210, Loss: 0.1306
Batch 220, Loss: 0.1442
Batch 230, Loss: 0.1085
Batch 240, Loss: 0.1210
Batch 250, Loss: 0.1325
Batch 260, Loss: 0.1255
Batch 270, Loss: 0.1236
Batch 280, Loss: 0.1154
Batch 290, Loss: 0.1118
Batch 300, Loss: 0.1171
Batch 310, Loss: 0.1239
Batch 320, Loss: 0.1066
Batch 330, Loss: 0.1133
Batch 340, Loss: 0.1376
Batch 350, Loss: 0.1483
Batch 360, Loss: 0.1262
Batch 370, Loss: 0.1170
Batch 380, Loss: 0.1132
Batch 390, Loss: 0.1114
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.234932899475098 seconds
Epoch 194 accuracy: 96.44%
Batch 10, Loss: 0.1280
Batch 20, Loss: 0.1316
Batch 30, Loss: 0.1166
Batch 40, Loss: 0.1204
Batch 50, Loss: 0.1355
Batch 60, Loss: 0.1476
Batch 70, Loss: 0.1539
Batch 80, Loss: 0.1146
Batch 90, Loss: 0.1317
Batch 100, Loss: 0.1334
Batch 110, Loss: 0.1231
Batch 120, Loss: 0.0977
Batch 130, Loss: 0.1182
Batch 140, Loss: 0.1278
Batch 150, Loss: 0.1326
Batch 160, Loss: 0.1434
Batch 170, Loss: 0.1441
Batch 180, Loss: 0.1207
Batch 190, Loss: 0.1203
Batch 200, Loss: 0.1314
Batch 210, Loss: 0.1205
Batch 220, Loss: 0.1275
Batch 230, Loss: 0.1211
Batch 240, Loss: 0.1357
Batch 250, Loss: 0.1306
Batch 260, Loss: 0.1183
Batch 270, Loss: 0.1219
Batch 280, Loss: 0.1254
Batch 290, Loss: 0.1299
Batch 300, Loss: 0.1231
Batch 310, Loss: 0.1052
Batch 320, Loss: 0.1037
Batch 330, Loss: 0.1211
Batch 340, Loss: 0.1261
Batch 350, Loss: 0.1241
Batch 360, Loss: 0.1314
Batch 370, Loss: 0.1095
Batch 380, Loss: 0.1140
Batch 390, Loss: 0.1299
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.12909960746765 seconds
Epoch 195 accuracy: 96.49%
Batch 10, Loss: 0.1021
Batch 20, Loss: 0.1172
Batch 30, Loss: 0.1305
Batch 40, Loss: 0.1231
Batch 50, Loss: 0.1235
Batch 60, Loss: 0.1370
Batch 70, Loss: 0.1246
Batch 80, Loss: 0.1274
Batch 90, Loss: 0.1390
Batch 100, Loss: 0.1196
Batch 110, Loss: 0.1145
Batch 120, Loss: 0.1253
Batch 130, Loss: 0.1354
Batch 140, Loss: 0.1196
Batch 150, Loss: 0.1300
Batch 160, Loss: 0.1101
Batch 170, Loss: 0.1347
Batch 180, Loss: 0.1303
Batch 190, Loss: 0.1175
Batch 200, Loss: 0.1341
Batch 210, Loss: 0.1290
Batch 220, Loss: 0.1136
Batch 230, Loss: 0.1113
Batch 240, Loss: 0.1165
Batch 250, Loss: 0.1109
Batch 260, Loss: 0.1134
Batch 270, Loss: 0.1237
Batch 280, Loss: 0.1149
Batch 290, Loss: 0.1304
Batch 300, Loss: 0.1242
Batch 310, Loss: 0.1371
Batch 320, Loss: 0.1181
Batch 330, Loss: 0.1161
Batch 340, Loss: 0.1239
Batch 350, Loss: 0.1147
Batch 360, Loss: 0.1249
Batch 370, Loss: 0.1030
Batch 380, Loss: 0.1250
Batch 390, Loss: 0.1457
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.14826726913452 seconds
Epoch 196 accuracy: 96.42%
Batch 10, Loss: 0.1399
Batch 20, Loss: 0.1205
Batch 30, Loss: 0.1232
Batch 40, Loss: 0.1196
Batch 50, Loss: 0.1319
Batch 60, Loss: 0.1308
Batch 70, Loss: 0.1161
Batch 80, Loss: 0.1204
Batch 90, Loss: 0.1336
Batch 100, Loss: 0.1286
Batch 110, Loss: 0.1445
Batch 120, Loss: 0.1365
Batch 130, Loss: 0.1120
Batch 140, Loss: 0.1192
Batch 150, Loss: 0.1263
Batch 160, Loss: 0.1390
Batch 170, Loss: 0.1159
Batch 180, Loss: 0.1187
Batch 190, Loss: 0.1406
Batch 200, Loss: 0.1175
Batch 210, Loss: 0.1152
Batch 220, Loss: 0.1226
Batch 230, Loss: 0.1047
Batch 240, Loss: 0.1177
Batch 250, Loss: 0.1266
Batch 260, Loss: 0.1217
Batch 270, Loss: 0.1245
Batch 280, Loss: 0.1319
Batch 290, Loss: 0.1332
Batch 300, Loss: 0.1096
Batch 310, Loss: 0.1210
Batch 320, Loss: 0.1066
Batch 330, Loss: 0.1156
Batch 340, Loss: 0.1286
Batch 350, Loss: 0.1164
Batch 360, Loss: 0.1455
Batch 370, Loss: 0.1148
Batch 380, Loss: 0.1304
Batch 390, Loss: 0.1174
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.235303163528442 seconds
Epoch 197 accuracy: 96.46%
Batch 10, Loss: 0.1277
Batch 20, Loss: 0.1200
Batch 30, Loss: 0.0998
Batch 40, Loss: 0.1202
Batch 50, Loss: 0.1283
Batch 60, Loss: 0.1101
Batch 70, Loss: 0.1310
Batch 80, Loss: 0.1271
Batch 90, Loss: 0.1181
Batch 100, Loss: 0.1199
Batch 110, Loss: 0.1163
Batch 120, Loss: 0.1354
Batch 130, Loss: 0.1272
Batch 140, Loss: 0.1316
Batch 150, Loss: 0.1152
Batch 160, Loss: 0.1294
Batch 170, Loss: 0.1152
Batch 180, Loss: 0.1370
Batch 190, Loss: 0.1314
Batch 200, Loss: 0.1139
Batch 210, Loss: 0.1176
Batch 220, Loss: 0.1298
Batch 230, Loss: 0.1307
Batch 240, Loss: 0.1168
Batch 250, Loss: 0.1228
Batch 260, Loss: 0.1278
Batch 270, Loss: 0.1288
Batch 280, Loss: 0.1180
Batch 290, Loss: 0.1091
Batch 300, Loss: 0.1432
Batch 310, Loss: 0.1214
Batch 320, Loss: 0.1208
Batch 330, Loss: 0.1317
Batch 340, Loss: 0.1358
Batch 350, Loss: 0.1067
Batch 360, Loss: 0.1237
Batch 370, Loss: 0.1149
Batch 380, Loss: 0.1238
Batch 390, Loss: 0.1192
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.227057933807373 seconds
Epoch 198 accuracy: 96.43%
Batch 10, Loss: 0.1175
Batch 20, Loss: 0.1157
Batch 30, Loss: 0.1424
Batch 40, Loss: 0.1136
Batch 50, Loss: 0.1184
Batch 60, Loss: 0.1278
Batch 70, Loss: 0.1301
Batch 80, Loss: 0.1216
Batch 90, Loss: 0.1389
Batch 100, Loss: 0.1405
Batch 110, Loss: 0.1595
Batch 120, Loss: 0.1145
Batch 130, Loss: 0.1395
Batch 140, Loss: 0.1172
Batch 150, Loss: 0.1369
Batch 160, Loss: 0.1188
Batch 170, Loss: 0.1325
Batch 180, Loss: 0.1170
Batch 190, Loss: 0.1296
Batch 200, Loss: 0.1030
Batch 210, Loss: 0.1147
Batch 220, Loss: 0.1332
Batch 230, Loss: 0.1070
Batch 240, Loss: 0.1470
Batch 250, Loss: 0.1275
Batch 260, Loss: 0.1146
Batch 270, Loss: 0.1127
Batch 280, Loss: 0.1134
Batch 290, Loss: 0.1247
Batch 300, Loss: 0.1479
Batch 310, Loss: 0.1281
Batch 320, Loss: 0.1155
Batch 330, Loss: 0.1243
Batch 340, Loss: 0.1247
Batch 350, Loss: 0.1338
Batch 360, Loss: 0.1090
Batch 370, Loss: 0.1221
Batch 380, Loss: 0.1151
Batch 390, Loss: 0.1315
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.02826976776123 seconds
Epoch 199 accuracy: 96.46%
Batch 10, Loss: 0.1227
Batch 20, Loss: 0.1101
Batch 30, Loss: 0.1119
Batch 40, Loss: 0.1245
Batch 50, Loss: 0.1172
Batch 60, Loss: 0.1495
Batch 70, Loss: 0.1311
Batch 80, Loss: 0.1443
Batch 90, Loss: 0.1086
Batch 100, Loss: 0.1142
Batch 110, Loss: 0.1253
Batch 120, Loss: 0.1150
Batch 130, Loss: 0.1519
Batch 140, Loss: 0.1328
Batch 150, Loss: 0.1257
Batch 160, Loss: 0.1407
Batch 170, Loss: 0.1200
Batch 180, Loss: 0.1196
Batch 190, Loss: 0.1241
Batch 200, Loss: 0.1105
Batch 210, Loss: 0.1277
Batch 220, Loss: 0.1388
Batch 230, Loss: 0.1051
Batch 240, Loss: 0.1185
Batch 250, Loss: 0.1327
Batch 260, Loss: 0.1200
Batch 270, Loss: 0.1093
Batch 280, Loss: 0.1215
Batch 290, Loss: 0.1350
Batch 300, Loss: 0.1293
Batch 310, Loss: 0.1289
Batch 320, Loss: 0.1181
Batch 330, Loss: 0.1201
Batch 340, Loss: 0.1156
Batch 350, Loss: 0.1196
Batch 360, Loss: 0.1304
Batch 370, Loss: 0.1273
Batch 380, Loss: 0.1321
Batch 390, Loss: 0.1095
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.185184001922607 seconds
Epoch 200 accuracy: 96.52%
Total training time: 5038.730136871338 seconds
