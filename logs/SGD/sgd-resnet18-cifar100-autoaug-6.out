The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1021
Batch 20, Loss: 4.1674
Batch 30, Loss: 3.8856
Batch 40, Loss: 3.8385
Batch 50, Loss: 3.7742
Batch 60, Loss: 3.7641
Batch 70, Loss: 3.7541
Batch 80, Loss: 3.7378
Batch 90, Loss: 3.6997
Batch 100, Loss: 3.6869
Batch 110, Loss: 3.6641
Batch 120, Loss: 3.6403
Batch 130, Loss: 3.5919
Batch 140, Loss: 3.6109
Batch 150, Loss: 3.5917
Batch 160, Loss: 3.5853
Batch 170, Loss: 3.5924
Batch 180, Loss: 3.5915
Batch 190, Loss: 3.5689
Batch 200, Loss: 3.5158
Batch 210, Loss: 3.5487
Batch 220, Loss: 3.5241
Batch 230, Loss: 3.5186
Batch 240, Loss: 3.4991
Batch 250, Loss: 3.5301
Batch 260, Loss: 3.5249
Batch 270, Loss: 3.5230
Batch 280, Loss: 3.5141
Batch 290, Loss: 3.5046
Batch 300, Loss: 3.4627
Batch 310, Loss: 3.4616
Batch 320, Loss: 3.4356
Batch 330, Loss: 3.4812
Batch 340, Loss: 3.4588
Batch 350, Loss: 3.4326
Batch 360, Loss: 3.4638
Batch 370, Loss: 3.4816
Batch 380, Loss: 3.4504
Batch 390, Loss: 3.4043
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.292569875717163 seconds
Epoch 1 accuracy: 9.45%
Batch 10, Loss: 3.4777
Batch 20, Loss: 3.4269
Batch 30, Loss: 3.4033
Batch 40, Loss: 3.3679
Batch 50, Loss: 3.4132
Batch 60, Loss: 3.3783
Batch 70, Loss: 3.3793
Batch 80, Loss: 3.3793
Batch 90, Loss: 3.4080
Batch 100, Loss: 3.3244
Batch 110, Loss: 3.4222
Batch 120, Loss: 3.3923
Batch 130, Loss: 3.3131
Batch 140, Loss: 3.3326
Batch 150, Loss: 3.3349
Batch 160, Loss: 3.3324
Batch 170, Loss: 3.3337
Batch 180, Loss: 3.3311
Batch 190, Loss: 3.3326
Batch 200, Loss: 3.2327
Batch 210, Loss: 3.3205
Batch 220, Loss: 3.3012
Batch 230, Loss: 3.2666
Batch 240, Loss: 3.2940
Batch 250, Loss: 3.2898
Batch 260, Loss: 3.2898
Batch 270, Loss: 3.2857
Batch 280, Loss: 3.2421
Batch 290, Loss: 3.2229
Batch 300, Loss: 3.2287
Batch 310, Loss: 3.2648
Batch 320, Loss: 3.2137
Batch 330, Loss: 3.2381
Batch 340, Loss: 3.2374
Batch 350, Loss: 3.2165
Batch 360, Loss: 3.2104
Batch 370, Loss: 3.2043
Batch 380, Loss: 3.1986
Batch 390, Loss: 3.2059
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.414600133895874 seconds
Epoch 2 accuracy: 13.15%
Batch 10, Loss: 3.2492
Batch 20, Loss: 3.1819
Batch 30, Loss: 3.1741
Batch 40, Loss: 3.2030
Batch 50, Loss: 3.1781
Batch 60, Loss: 3.1868
Batch 70, Loss: 3.1700
Batch 80, Loss: 3.1512
Batch 90, Loss: 3.1561
Batch 100, Loss: 3.0933
Batch 110, Loss: 3.1373
Batch 120, Loss: 3.1741
Batch 130, Loss: 3.1532
Batch 140, Loss: 3.0921
Batch 150, Loss: 3.1078
Batch 160, Loss: 3.0996
Batch 170, Loss: 3.1210
Batch 180, Loss: 3.0715
Batch 190, Loss: 3.0847
Batch 200, Loss: 3.0714
Batch 210, Loss: 3.0448
Batch 220, Loss: 3.0667
Batch 230, Loss: 3.0585
Batch 240, Loss: 2.9980
Batch 250, Loss: 3.0259
Batch 260, Loss: 2.9848
Batch 270, Loss: 3.0587
Batch 280, Loss: 3.0323
Batch 290, Loss: 3.0262
Batch 300, Loss: 3.0013
Batch 310, Loss: 3.0030
Batch 320, Loss: 3.0349
Batch 330, Loss: 2.9639
Batch 340, Loss: 2.9956
Batch 350, Loss: 2.9865
Batch 360, Loss: 2.9330
Batch 370, Loss: 2.9636
Batch 380, Loss: 2.9499
Batch 390, Loss: 2.9105
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.466856718063354 seconds
Epoch 3 accuracy: 20.31%
Batch 10, Loss: 2.9112
Batch 20, Loss: 2.8466
Batch 30, Loss: 2.8803
Batch 40, Loss: 2.8838
Batch 50, Loss: 2.8655
Batch 60, Loss: 2.9085
Batch 70, Loss: 2.8675
Batch 80, Loss: 2.8712
Batch 90, Loss: 2.8485
Batch 100, Loss: 2.8077
Batch 110, Loss: 2.8331
Batch 120, Loss: 2.8426
Batch 130, Loss: 2.8156
Batch 140, Loss: 2.7628
Batch 150, Loss: 2.7649
Batch 160, Loss: 2.7862
Batch 170, Loss: 2.8109
Batch 180, Loss: 2.7906
Batch 190, Loss: 2.7534
Batch 200, Loss: 2.8424
Batch 210, Loss: 2.8081
Batch 220, Loss: 2.7937
Batch 230, Loss: 2.7343
Batch 240, Loss: 2.6993
Batch 250, Loss: 2.6310
Batch 260, Loss: 2.6705
Batch 270, Loss: 2.7342
Batch 280, Loss: 2.7360
Batch 290, Loss: 2.7153
Batch 300, Loss: 2.6737
Batch 310, Loss: 2.6963
Batch 320, Loss: 2.7193
Batch 330, Loss: 2.6815
Batch 340, Loss: 2.6667
Batch 350, Loss: 2.6825
Batch 360, Loss: 2.6929
Batch 370, Loss: 2.6912
Batch 380, Loss: 2.6657
Batch 390, Loss: 2.6453
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.388233184814453 seconds
Epoch 4 accuracy: 28.55%
Batch 10, Loss: 2.5578
Batch 20, Loss: 2.5536
Batch 30, Loss: 2.5459
Batch 40, Loss: 2.5490
Batch 50, Loss: 2.6060
Batch 60, Loss: 2.5076
Batch 70, Loss: 2.5587
Batch 80, Loss: 2.6041
Batch 90, Loss: 2.5451
Batch 100, Loss: 2.5661
Batch 110, Loss: 2.5417
Batch 120, Loss: 2.5541
Batch 130, Loss: 2.5494
Batch 140, Loss: 2.5620
Batch 150, Loss: 2.4945
Batch 160, Loss: 2.5169
Batch 170, Loss: 2.5104
Batch 180, Loss: 2.5692
Batch 190, Loss: 2.5314
Batch 200, Loss: 2.5064
Batch 210, Loss: 2.4638
Batch 220, Loss: 2.5237
Batch 230, Loss: 2.4740
Batch 240, Loss: 2.4882
Batch 250, Loss: 2.4704
Batch 260, Loss: 2.4772
Batch 270, Loss: 2.4277
Batch 280, Loss: 2.4220
Batch 290, Loss: 2.4648
Batch 300, Loss: 2.4065
Batch 310, Loss: 2.4942
Batch 320, Loss: 2.4162
Batch 330, Loss: 2.4093
Batch 340, Loss: 2.4393
Batch 350, Loss: 2.3844
Batch 360, Loss: 2.4452
Batch 370, Loss: 2.3588
Batch 380, Loss: 2.3596
Batch 390, Loss: 2.4414
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.351632356643677 seconds
Epoch 5 accuracy: 35.24%
Batch 10, Loss: 2.3299
Batch 20, Loss: 2.4276
Batch 30, Loss: 2.3388
Batch 40, Loss: 2.4436
Batch 50, Loss: 2.3254
Batch 60, Loss: 2.2953
Batch 70, Loss: 2.3497
Batch 80, Loss: 2.3620
Batch 90, Loss: 2.3482
Batch 100, Loss: 2.3244
Batch 110, Loss: 2.2799
Batch 120, Loss: 2.3126
Batch 130, Loss: 2.2907
Batch 140, Loss: 2.2754
Batch 150, Loss: 2.3501
Batch 160, Loss: 2.2667
Batch 170, Loss: 2.2161
Batch 180, Loss: 2.3194
Batch 190, Loss: 2.3041
Batch 200, Loss: 2.3152
Batch 210, Loss: 2.2677
Batch 220, Loss: 2.2526
Batch 230, Loss: 2.2994
Batch 240, Loss: 2.2514
Batch 250, Loss: 2.2704
Batch 260, Loss: 2.3204
Batch 270, Loss: 2.2437
Batch 280, Loss: 2.2257
Batch 290, Loss: 2.2746
Batch 300, Loss: 2.2368
Batch 310, Loss: 2.2389
Batch 320, Loss: 2.2399
Batch 330, Loss: 2.2216
Batch 340, Loss: 2.2031
Batch 350, Loss: 2.2859
Batch 360, Loss: 2.2196
Batch 370, Loss: 2.2288
Batch 380, Loss: 2.2208
Batch 390, Loss: 2.2292
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.38312578201294 seconds
Epoch 6 accuracy: 37.28%
Batch 10, Loss: 2.1751
Batch 20, Loss: 2.1692
Batch 30, Loss: 2.1449
Batch 40, Loss: 2.2001
Batch 50, Loss: 2.1573
Batch 60, Loss: 2.1323
Batch 70, Loss: 2.2261
Batch 80, Loss: 2.1809
Batch 90, Loss: 2.1798
Batch 100, Loss: 2.1444
Batch 110, Loss: 2.1045
Batch 120, Loss: 2.1182
Batch 130, Loss: 2.1480
Batch 140, Loss: 2.1213
Batch 150, Loss: 2.1408
Batch 160, Loss: 2.1685
Batch 170, Loss: 2.1095
Batch 180, Loss: 2.0949
Batch 190, Loss: 2.1456
Batch 200, Loss: 2.2009
Batch 210, Loss: 2.1430
Batch 220, Loss: 2.1549
Batch 230, Loss: 2.1355
Batch 240, Loss: 2.1578
Batch 250, Loss: 2.1574
Batch 260, Loss: 2.1454
Batch 270, Loss: 2.0721
Batch 280, Loss: 2.0667
Batch 290, Loss: 2.1412
Batch 300, Loss: 2.1752
Batch 310, Loss: 2.1309
Batch 320, Loss: 2.1558
Batch 330, Loss: 2.1767
Batch 340, Loss: 2.1191
Batch 350, Loss: 2.0323
Batch 360, Loss: 2.1024
Batch 370, Loss: 2.1469
Batch 380, Loss: 2.1348
Batch 390, Loss: 2.1306
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.35930299758911 seconds
Epoch 7 accuracy: 39.88%
Batch 10, Loss: 2.0548
Batch 20, Loss: 2.0598
Batch 30, Loss: 2.0218
Batch 40, Loss: 2.0406
Batch 50, Loss: 2.0019
Batch 60, Loss: 2.0331
Batch 70, Loss: 2.0829
Batch 80, Loss: 2.0581
Batch 90, Loss: 2.0574
Batch 100, Loss: 2.0724
Batch 110, Loss: 2.0439
Batch 120, Loss: 2.0615
Batch 130, Loss: 1.9476
Batch 140, Loss: 2.0363
Batch 150, Loss: 2.0303
Batch 160, Loss: 1.9854
Batch 170, Loss: 2.0662
Batch 180, Loss: 2.0869
Batch 190, Loss: 2.0832
Batch 200, Loss: 2.0388
Batch 210, Loss: 1.9955
Batch 220, Loss: 2.0119
Batch 230, Loss: 1.9857
Batch 240, Loss: 1.9995
Batch 250, Loss: 2.0580
Batch 260, Loss: 2.0067
Batch 270, Loss: 1.9156
Batch 280, Loss: 1.9415
Batch 290, Loss: 2.0170
Batch 300, Loss: 2.0423
Batch 310, Loss: 2.0210
Batch 320, Loss: 2.0607
Batch 330, Loss: 2.0442
Batch 340, Loss: 1.9809
Batch 350, Loss: 2.0384
Batch 360, Loss: 2.0425
Batch 370, Loss: 1.9898
Batch 380, Loss: 1.9769
Batch 390, Loss: 2.0234
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.419736623764038 seconds
Epoch 8 accuracy: 41.3%
Batch 10, Loss: 1.9594
Batch 20, Loss: 1.9529
Batch 30, Loss: 1.8984
Batch 40, Loss: 1.9807
Batch 50, Loss: 1.9622
Batch 60, Loss: 2.0052
Batch 70, Loss: 1.9630
Batch 80, Loss: 1.9634
Batch 90, Loss: 1.9770
Batch 100, Loss: 1.9685
Batch 110, Loss: 1.9485
Batch 120, Loss: 1.9975
Batch 130, Loss: 2.0375
Batch 140, Loss: 1.9583
Batch 150, Loss: 1.9196
Batch 160, Loss: 1.9221
Batch 170, Loss: 1.9656
Batch 180, Loss: 1.9822
Batch 190, Loss: 1.9992
Batch 200, Loss: 1.9248
Batch 210, Loss: 2.0052
Batch 220, Loss: 1.9504
Batch 230, Loss: 1.9026
Batch 240, Loss: 1.9158
Batch 250, Loss: 1.9744
Batch 260, Loss: 1.8562
Batch 270, Loss: 1.9407
Batch 280, Loss: 1.9303
Batch 290, Loss: 1.9385
Batch 300, Loss: 2.0238
Batch 310, Loss: 1.9700
Batch 320, Loss: 1.9640
Batch 330, Loss: 1.9810
Batch 340, Loss: 1.9225
Batch 350, Loss: 1.9114
Batch 360, Loss: 1.9409
Batch 370, Loss: 1.9662
Batch 380, Loss: 1.9261
Batch 390, Loss: 1.9152
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.37877917289734 seconds
Epoch 9 accuracy: 37.02%
Batch 10, Loss: 1.8901
Batch 20, Loss: 1.9376
Batch 30, Loss: 1.9402
Batch 40, Loss: 1.7844
Batch 50, Loss: 1.8991
Batch 60, Loss: 1.8849
Batch 70, Loss: 1.9437
Batch 80, Loss: 1.9554
Batch 90, Loss: 1.8793
Batch 100, Loss: 1.8650
Batch 110, Loss: 1.8423
Batch 120, Loss: 1.9064
Batch 130, Loss: 1.8134
Batch 140, Loss: 1.8504
Batch 150, Loss: 1.8868
Batch 160, Loss: 1.8497
Batch 170, Loss: 1.8399
Batch 180, Loss: 1.9207
Batch 190, Loss: 1.9388
Batch 200, Loss: 1.9186
Batch 210, Loss: 1.9187
Batch 220, Loss: 1.8971
Batch 230, Loss: 1.8926
Batch 240, Loss: 1.8369
Batch 250, Loss: 1.8683
Batch 260, Loss: 1.9843
Batch 270, Loss: 1.8644
Batch 280, Loss: 1.9108
Batch 290, Loss: 1.8764
Batch 300, Loss: 1.8557
Batch 310, Loss: 1.8568
Batch 320, Loss: 1.8597
Batch 330, Loss: 1.8750
Batch 340, Loss: 1.8775
Batch 350, Loss: 1.8479
Batch 360, Loss: 1.9017
Batch 370, Loss: 1.8705
Batch 380, Loss: 1.9326
Batch 390, Loss: 1.8993
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.41151714324951 seconds
Epoch 10 accuracy: 45.84%
Batch 10, Loss: 1.8226
Batch 20, Loss: 1.7745
Batch 30, Loss: 1.9247
Batch 40, Loss: 1.8174
Batch 50, Loss: 1.8006
Batch 60, Loss: 1.8176
Batch 70, Loss: 1.8668
Batch 80, Loss: 1.8643
Batch 90, Loss: 1.8906
Batch 100, Loss: 1.8569
Batch 110, Loss: 1.8771
Batch 120, Loss: 1.8532
Batch 130, Loss: 1.8906
Batch 140, Loss: 1.8458
Batch 150, Loss: 1.8571
Batch 160, Loss: 1.8220
Batch 170, Loss: 1.8402
Batch 180, Loss: 1.8980
Batch 190, Loss: 1.9188
Batch 200, Loss: 1.7986
Batch 210, Loss: 1.8149
Batch 220, Loss: 1.8222
Batch 230, Loss: 1.8821
Batch 240, Loss: 1.7901
Batch 250, Loss: 1.8205
Batch 260, Loss: 1.8824
Batch 270, Loss: 1.8192
Batch 280, Loss: 1.8635
Batch 290, Loss: 1.7841
Batch 300, Loss: 1.8503
Batch 310, Loss: 1.8602
Batch 320, Loss: 1.8080
Batch 330, Loss: 1.8778
Batch 340, Loss: 1.8699
Batch 350, Loss: 1.8003
Batch 360, Loss: 1.8283
Batch 370, Loss: 1.8122
Batch 380, Loss: 1.7897
Batch 390, Loss: 1.8302
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.341115951538086 seconds
Epoch 11 accuracy: 43.57%
Batch 10, Loss: 1.7874
Batch 20, Loss: 1.8142
Batch 30, Loss: 1.7754
Batch 40, Loss: 1.7228
Batch 50, Loss: 1.8186
Batch 60, Loss: 1.8674
Batch 70, Loss: 1.7715
Batch 80, Loss: 1.8297
Batch 90, Loss: 1.7502
Batch 100, Loss: 1.7702
Batch 110, Loss: 1.8225
Batch 120, Loss: 1.8273
Batch 130, Loss: 1.8514
Batch 140, Loss: 1.8334
Batch 150, Loss: 1.8187
Batch 160, Loss: 1.8296
Batch 170, Loss: 1.7488
Batch 180, Loss: 1.7810
Batch 190, Loss: 1.7911
Batch 200, Loss: 1.7007
Batch 210, Loss: 1.8259
Batch 220, Loss: 1.8051
Batch 230, Loss: 1.8386
Batch 240, Loss: 1.8440
Batch 250, Loss: 1.7649
Batch 260, Loss: 1.7499
Batch 270, Loss: 1.7484
Batch 280, Loss: 1.8216
Batch 290, Loss: 1.8445
Batch 300, Loss: 1.8554
Batch 310, Loss: 1.7958
Batch 320, Loss: 1.7075
Batch 330, Loss: 1.8151
Batch 340, Loss: 1.7781
Batch 350, Loss: 1.7482
Batch 360, Loss: 1.8187
Batch 370, Loss: 1.7649
Batch 380, Loss: 1.7471
Batch 390, Loss: 1.7977
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.422601222991943 seconds
Epoch 12 accuracy: 47.75%
Batch 10, Loss: 1.7240
Batch 20, Loss: 1.7444
Batch 30, Loss: 1.8085
Batch 40, Loss: 1.7349
Batch 50, Loss: 1.7733
Batch 60, Loss: 1.7620
Batch 70, Loss: 1.6959
Batch 80, Loss: 1.7877
Batch 90, Loss: 1.7579
Batch 100, Loss: 1.7431
Batch 110, Loss: 1.8368
Batch 120, Loss: 1.7435
Batch 130, Loss: 1.7850
Batch 140, Loss: 1.7649
Batch 150, Loss: 1.7907
Batch 160, Loss: 1.7712
Batch 170, Loss: 1.7707
Batch 180, Loss: 1.7664
Batch 190, Loss: 1.7285
Batch 200, Loss: 1.7726
Batch 210, Loss: 1.7591
Batch 220, Loss: 1.7707
Batch 230, Loss: 1.7420
Batch 240, Loss: 1.7935
Batch 250, Loss: 1.7525
Batch 260, Loss: 1.7598
Batch 270, Loss: 1.8253
Batch 280, Loss: 1.7339
Batch 290, Loss: 1.8115
Batch 300, Loss: 1.7482
Batch 310, Loss: 1.7656
Batch 320, Loss: 1.7735
Batch 330, Loss: 1.6771
Batch 340, Loss: 1.7278
Batch 350, Loss: 1.7345
Batch 360, Loss: 1.8438
Batch 370, Loss: 1.7340
Batch 380, Loss: 1.7551
Batch 390, Loss: 1.7136
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.386106967926025 seconds
Epoch 13 accuracy: 51.51%
Batch 10, Loss: 1.7361
Batch 20, Loss: 1.6946
Batch 30, Loss: 1.6621
Batch 40, Loss: 1.7568
Batch 50, Loss: 1.7017
Batch 60, Loss: 1.7704
Batch 70, Loss: 1.7738
Batch 80, Loss: 1.7414
Batch 90, Loss: 1.6416
Batch 100, Loss: 1.7616
Batch 110, Loss: 1.7070
Batch 120, Loss: 1.7199
Batch 130, Loss: 1.7561
Batch 140, Loss: 1.7372
Batch 150, Loss: 1.7320
Batch 160, Loss: 1.6530
Batch 170, Loss: 1.7308
Batch 180, Loss: 1.7574
Batch 190, Loss: 1.6848
Batch 200, Loss: 1.6928
Batch 210, Loss: 1.6775
Batch 220, Loss: 1.7272
Batch 230, Loss: 1.7471
Batch 240, Loss: 1.7090
Batch 250, Loss: 1.8722
Batch 260, Loss: 1.7793
Batch 270, Loss: 1.7510
Batch 280, Loss: 1.7558
Batch 290, Loss: 1.7638
Batch 300, Loss: 1.7319
Batch 310, Loss: 1.7576
Batch 320, Loss: 1.7334
Batch 330, Loss: 1.7845
Batch 340, Loss: 1.7362
Batch 350, Loss: 1.7152
Batch 360, Loss: 1.7775
Batch 370, Loss: 1.6953
Batch 380, Loss: 1.7057
Batch 390, Loss: 1.6453
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.453004121780396 seconds
Epoch 14 accuracy: 49.51%
Batch 10, Loss: 1.7054
Batch 20, Loss: 1.6461
Batch 30, Loss: 1.6848
Batch 40, Loss: 1.7022
Batch 50, Loss: 1.6788
Batch 60, Loss: 1.7233
Batch 70, Loss: 1.6958
Batch 80, Loss: 1.7100
Batch 90, Loss: 1.6779
Batch 100, Loss: 1.7375
Batch 110, Loss: 1.7286
Batch 120, Loss: 1.6961
Batch 130, Loss: 1.6872
Batch 140, Loss: 1.7461
Batch 150, Loss: 1.7425
Batch 160, Loss: 1.6991
Batch 170, Loss: 1.6945
Batch 180, Loss: 1.6672
Batch 190, Loss: 1.6759
Batch 200, Loss: 1.7388
Batch 210, Loss: 1.7148
Batch 220, Loss: 1.7060
Batch 230, Loss: 1.7436
Batch 240, Loss: 1.6714
Batch 250, Loss: 1.7312
Batch 260, Loss: 1.7226
Batch 270, Loss: 1.7060
Batch 280, Loss: 1.7789
Batch 290, Loss: 1.7516
Batch 300, Loss: 1.7059
Batch 310, Loss: 1.7335
Batch 320, Loss: 1.6887
Batch 330, Loss: 1.6790
Batch 340, Loss: 1.6736
Batch 350, Loss: 1.6774
Batch 360, Loss: 1.6760
Batch 370, Loss: 1.7122
Batch 380, Loss: 1.6921
Batch 390, Loss: 1.6795
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.37101125717163 seconds
Epoch 15 accuracy: 50.02%
Batch 10, Loss: 1.5736
Batch 20, Loss: 1.6714
Batch 30, Loss: 1.6162
Batch 40, Loss: 1.6296
Batch 50, Loss: 1.7102
Batch 60, Loss: 1.7211
Batch 70, Loss: 1.6584
Batch 80, Loss: 1.6128
Batch 90, Loss: 1.6989
Batch 100, Loss: 1.7065
Batch 110, Loss: 1.6491
Batch 120, Loss: 1.6949
Batch 130, Loss: 1.6974
Batch 140, Loss: 1.7193
Batch 150, Loss: 1.6903
Batch 160, Loss: 1.6639
Batch 170, Loss: 1.5595
Batch 180, Loss: 1.6268
Batch 190, Loss: 1.6559
Batch 200, Loss: 1.6715
Batch 210, Loss: 1.6581
Batch 220, Loss: 1.7574
Batch 230, Loss: 1.6724
Batch 240, Loss: 1.6905
Batch 250, Loss: 1.6802
Batch 260, Loss: 1.6202
Batch 270, Loss: 1.6813
Batch 280, Loss: 1.6622
Batch 290, Loss: 1.6433
Batch 300, Loss: 1.6798
Batch 310, Loss: 1.7075
Batch 320, Loss: 1.6690
Batch 330, Loss: 1.7135
Batch 340, Loss: 1.7314
Batch 350, Loss: 1.7179
Batch 360, Loss: 1.7987
Batch 370, Loss: 1.6754
Batch 380, Loss: 1.6866
Batch 390, Loss: 1.6247
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.343416213989258 seconds
Epoch 16 accuracy: 54.83%
Batch 10, Loss: 1.6488
Batch 20, Loss: 1.5972
Batch 30, Loss: 1.5806
Batch 40, Loss: 1.5544
Batch 50, Loss: 1.6506
Batch 60, Loss: 1.6395
Batch 70, Loss: 1.6677
Batch 80, Loss: 1.6799
Batch 90, Loss: 1.6303
Batch 100, Loss: 1.5488
Batch 110, Loss: 1.5880
Batch 120, Loss: 1.6257
Batch 130, Loss: 1.5967
Batch 140, Loss: 1.6359
Batch 150, Loss: 1.6904
Batch 160, Loss: 1.6986
Batch 170, Loss: 1.6808
Batch 180, Loss: 1.7185
Batch 190, Loss: 1.6635
Batch 200, Loss: 1.5795
Batch 210, Loss: 1.6240
Batch 220, Loss: 1.6718
Batch 230, Loss: 1.6099
Batch 240, Loss: 1.6672
Batch 250, Loss: 1.6564
Batch 260, Loss: 1.7270
Batch 270, Loss: 1.6972
Batch 280, Loss: 1.6976
Batch 290, Loss: 1.7554
Batch 300, Loss: 1.7040
Batch 310, Loss: 1.6710
Batch 320, Loss: 1.6784
Batch 330, Loss: 1.6913
Batch 340, Loss: 1.6590
Batch 350, Loss: 1.7103
Batch 360, Loss: 1.7152
Batch 370, Loss: 1.6928
Batch 380, Loss: 1.7330
Batch 390, Loss: 1.6667
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.282808303833008 seconds
Epoch 17 accuracy: 50.25%
Batch 10, Loss: 1.5885
Batch 20, Loss: 1.6547
Batch 30, Loss: 1.6340
Batch 40, Loss: 1.6454
Batch 50, Loss: 1.6813
Batch 60, Loss: 1.7030
Batch 70, Loss: 1.5964
Batch 80, Loss: 1.6081
Batch 90, Loss: 1.6213
Batch 100, Loss: 1.6761
Batch 110, Loss: 1.5853
Batch 120, Loss: 1.5977
Batch 130, Loss: 1.6678
Batch 140, Loss: 1.6033
Batch 150, Loss: 1.6471
Batch 160, Loss: 1.5861
Batch 170, Loss: 1.5945
Batch 180, Loss: 1.6649
Batch 190, Loss: 1.6834
Batch 200, Loss: 1.6639
Batch 210, Loss: 1.5692
Batch 220, Loss: 1.6995
Batch 230, Loss: 1.6192
Batch 240, Loss: 1.6181
Batch 250, Loss: 1.6955
Batch 260, Loss: 1.6191
Batch 270, Loss: 1.6701
Batch 280, Loss: 1.6538
Batch 290, Loss: 1.6175
Batch 300, Loss: 1.5965
Batch 310, Loss: 1.7291
Batch 320, Loss: 1.6195
Batch 330, Loss: 1.7073
Batch 340, Loss: 1.6659
Batch 350, Loss: 1.6721
Batch 360, Loss: 1.5964
Batch 370, Loss: 1.6870
Batch 380, Loss: 1.6625
Batch 390, Loss: 1.6370
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.36657404899597 seconds
Epoch 18 accuracy: 51.27%
Batch 10, Loss: 1.6370
Batch 20, Loss: 1.5631
Batch 30, Loss: 1.6459
Batch 40, Loss: 1.6130
Batch 50, Loss: 1.6024
Batch 60, Loss: 1.5951
Batch 70, Loss: 1.6184
Batch 80, Loss: 1.6109
Batch 90, Loss: 1.5804
Batch 100, Loss: 1.6306
Batch 110, Loss: 1.5799
Batch 120, Loss: 1.5959
Batch 130, Loss: 1.6499
Batch 140, Loss: 1.6041
Batch 150, Loss: 1.5422
Batch 160, Loss: 1.6639
Batch 170, Loss: 1.5931
Batch 180, Loss: 1.6486
Batch 190, Loss: 1.5819
Batch 200, Loss: 1.7326
Batch 210, Loss: 1.6092
Batch 220, Loss: 1.6681
Batch 230, Loss: 1.6084
Batch 240, Loss: 1.6061
Batch 250, Loss: 1.7164
Batch 260, Loss: 1.6875
Batch 270, Loss: 1.6452
Batch 280, Loss: 1.6358
Batch 290, Loss: 1.6767
Batch 300, Loss: 1.5989
Batch 310, Loss: 1.7092
Batch 320, Loss: 1.6870
Batch 330, Loss: 1.6549
Batch 340, Loss: 1.6280
Batch 350, Loss: 1.6543
Batch 360, Loss: 1.6573
Batch 370, Loss: 1.6220
Batch 380, Loss: 1.6238
Batch 390, Loss: 1.6214
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.346097707748413 seconds
Epoch 19 accuracy: 52.78%
Batch 10, Loss: 1.6803
Batch 20, Loss: 1.6019
Batch 30, Loss: 1.6041
Batch 40, Loss: 1.5736
Batch 50, Loss: 1.6453
Batch 60, Loss: 1.6727
Batch 70, Loss: 1.6449
Batch 80, Loss: 1.5526
Batch 90, Loss: 1.5948
Batch 100, Loss: 1.6645
Batch 110, Loss: 1.5728
Batch 120, Loss: 1.6468
Batch 130, Loss: 1.6097
Batch 140, Loss: 1.6319
Batch 150, Loss: 1.6087
Batch 160, Loss: 1.5892
Batch 170, Loss: 1.5720
Batch 180, Loss: 1.6364
Batch 190, Loss: 1.6436
Batch 200, Loss: 1.5993
Batch 210, Loss: 1.5795
Batch 220, Loss: 1.5663
Batch 230, Loss: 1.5867
Batch 240, Loss: 1.5503
Batch 250, Loss: 1.5769
Batch 260, Loss: 1.5874
Batch 270, Loss: 1.7324
Batch 280, Loss: 1.6112
Batch 290, Loss: 1.6480
Batch 300, Loss: 1.6308
Batch 310, Loss: 1.6062
Batch 320, Loss: 1.6883
Batch 330, Loss: 1.6301
Batch 340, Loss: 1.5629
Batch 350, Loss: 1.5790
Batch 360, Loss: 1.6080
Batch 370, Loss: 1.6442
Batch 380, Loss: 1.6422
Batch 390, Loss: 1.6873
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.292474269866943 seconds
Epoch 20 accuracy: 50.78%
Batch 10, Loss: 1.6480
Batch 20, Loss: 1.5381
Batch 30, Loss: 1.5952
Batch 40, Loss: 1.5170
Batch 50, Loss: 1.5384
Batch 60, Loss: 1.5364
Batch 70, Loss: 1.5646
Batch 80, Loss: 1.5506
Batch 90, Loss: 1.5665
Batch 100, Loss: 1.6037
Batch 110, Loss: 1.5503
Batch 120, Loss: 1.5555
Batch 130, Loss: 1.6292
Batch 140, Loss: 1.6208
Batch 150, Loss: 1.6056
Batch 160, Loss: 1.6930
Batch 170, Loss: 1.6336
Batch 180, Loss: 1.6983
Batch 190, Loss: 1.6598
Batch 200, Loss: 1.6087
Batch 210, Loss: 1.6230
Batch 220, Loss: 1.6064
Batch 230, Loss: 1.6542
Batch 240, Loss: 1.6422
Batch 250, Loss: 1.5601
Batch 260, Loss: 1.6276
Batch 270, Loss: 1.6038
Batch 280, Loss: 1.5655
Batch 290, Loss: 1.5448
Batch 300, Loss: 1.5872
Batch 310, Loss: 1.6054
Batch 320, Loss: 1.6072
Batch 330, Loss: 1.5970
Batch 340, Loss: 1.5928
Batch 350, Loss: 1.5288
Batch 360, Loss: 1.6108
Batch 370, Loss: 1.6067
Batch 380, Loss: 1.6050
Batch 390, Loss: 1.6579
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.384138822555542 seconds
Epoch 21 accuracy: 53.14%
Batch 10, Loss: 1.5468
Batch 20, Loss: 1.5516
Batch 30, Loss: 1.6063
Batch 40, Loss: 1.5073
Batch 50, Loss: 1.5059
Batch 60, Loss: 1.5253
Batch 70, Loss: 1.5622
Batch 80, Loss: 1.6173
Batch 90, Loss: 1.5634
Batch 100, Loss: 1.5487
Batch 110, Loss: 1.5720
Batch 120, Loss: 1.6130
Batch 130, Loss: 1.5981
Batch 140, Loss: 1.6191
Batch 150, Loss: 1.5927
Batch 160, Loss: 1.5395
Batch 170, Loss: 1.6147
Batch 180, Loss: 1.6271
Batch 190, Loss: 1.6017
Batch 200, Loss: 1.5878
Batch 210, Loss: 1.5637
Batch 220, Loss: 1.5997
Batch 230, Loss: 1.6260
Batch 240, Loss: 1.5209
Batch 250, Loss: 1.6149
Batch 260, Loss: 1.6059
Batch 270, Loss: 1.6420
Batch 280, Loss: 1.6061
Batch 290, Loss: 1.6300
Batch 300, Loss: 1.6218
Batch 310, Loss: 1.5809
Batch 320, Loss: 1.5641
Batch 330, Loss: 1.6514
Batch 340, Loss: 1.6554
Batch 350, Loss: 1.6504
Batch 360, Loss: 1.5351
Batch 370, Loss: 1.5806
Batch 380, Loss: 1.6413
Batch 390, Loss: 1.6146
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.45066499710083 seconds
Epoch 22 accuracy: 52.05%
Batch 10, Loss: 1.6269
Batch 20, Loss: 1.5561
Batch 30, Loss: 1.5550
Batch 40, Loss: 1.5864
Batch 50, Loss: 1.5709
Batch 60, Loss: 1.5367
Batch 70, Loss: 1.5679
Batch 80, Loss: 1.5472
Batch 90, Loss: 1.5153
Batch 100, Loss: 1.5987
Batch 110, Loss: 1.5556
Batch 120, Loss: 1.5303
Batch 130, Loss: 1.5654
Batch 140, Loss: 1.6044
Batch 150, Loss: 1.4925
Batch 160, Loss: 1.5205
Batch 170, Loss: 1.5388
Batch 180, Loss: 1.5751
Batch 190, Loss: 1.5669
Batch 200, Loss: 1.6572
Batch 210, Loss: 1.5639
Batch 220, Loss: 1.5804
Batch 230, Loss: 1.5372
Batch 240, Loss: 1.6545
Batch 250, Loss: 1.6092
Batch 260, Loss: 1.5533
Batch 270, Loss: 1.5871
Batch 280, Loss: 1.5051
Batch 290, Loss: 1.5641
Batch 300, Loss: 1.6044
Batch 310, Loss: 1.6453
Batch 320, Loss: 1.6214
Batch 330, Loss: 1.5699
Batch 340, Loss: 1.5761
Batch 350, Loss: 1.6108
Batch 360, Loss: 1.6571
Batch 370, Loss: 1.5755
Batch 380, Loss: 1.6588
Batch 390, Loss: 1.6303
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.439602851867676 seconds
Epoch 23 accuracy: 49.92%
Batch 10, Loss: 1.5906
Batch 20, Loss: 1.5575
Batch 30, Loss: 1.5871
Batch 40, Loss: 1.5153
Batch 50, Loss: 1.5834
Batch 60, Loss: 1.4923
Batch 70, Loss: 1.5319
Batch 80, Loss: 1.5568
Batch 90, Loss: 1.5207
Batch 100, Loss: 1.4809
Batch 110, Loss: 1.5698
Batch 120, Loss: 1.5209
Batch 130, Loss: 1.5307
Batch 140, Loss: 1.5284
Batch 150, Loss: 1.5374
Batch 160, Loss: 1.5567
Batch 170, Loss: 1.5577
Batch 180, Loss: 1.5637
Batch 190, Loss: 1.5932
Batch 200, Loss: 1.5014
Batch 210, Loss: 1.5696
Batch 220, Loss: 1.6143
Batch 230, Loss: 1.6158
Batch 240, Loss: 1.6335
Batch 250, Loss: 1.5444
Batch 260, Loss: 1.5531
Batch 270, Loss: 1.6211
Batch 280, Loss: 1.5715
Batch 290, Loss: 1.6223
Batch 300, Loss: 1.5200
Batch 310, Loss: 1.5541
Batch 320, Loss: 1.5484
Batch 330, Loss: 1.5908
Batch 340, Loss: 1.6013
Batch 350, Loss: 1.5812
Batch 360, Loss: 1.6296
Batch 370, Loss: 1.5588
Batch 380, Loss: 1.5229
Batch 390, Loss: 1.5671
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.358231782913208 seconds
Epoch 24 accuracy: 54.31%
Batch 10, Loss: 1.5004
Batch 20, Loss: 1.5227
Batch 30, Loss: 1.4983
Batch 40, Loss: 1.5096
Batch 50, Loss: 1.5079
Batch 60, Loss: 1.4765
Batch 70, Loss: 1.5441
Batch 80, Loss: 1.5874
Batch 90, Loss: 1.5805
Batch 100, Loss: 1.6454
Batch 110, Loss: 1.5415
Batch 120, Loss: 1.5770
Batch 130, Loss: 1.5309
Batch 140, Loss: 1.5986
Batch 150, Loss: 1.6016
Batch 160, Loss: 1.5336
Batch 170, Loss: 1.5215
Batch 180, Loss: 1.5139
Batch 190, Loss: 1.5392
Batch 200, Loss: 1.5546
Batch 210, Loss: 1.5681
Batch 220, Loss: 1.5148
Batch 230, Loss: 1.5381
Batch 240, Loss: 1.5795
Batch 250, Loss: 1.6523
Batch 260, Loss: 1.6302
Batch 270, Loss: 1.5742
Batch 280, Loss: 1.5468
Batch 290, Loss: 1.5294
Batch 300, Loss: 1.5645
Batch 310, Loss: 1.5269
Batch 320, Loss: 1.5759
Batch 330, Loss: 1.5646
Batch 340, Loss: 1.5506
Batch 350, Loss: 1.5801
Batch 360, Loss: 1.5942
Batch 370, Loss: 1.5911
Batch 380, Loss: 1.5239
Batch 390, Loss: 1.5481
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.418452501296997 seconds
Epoch 25 accuracy: 55.89%
Batch 10, Loss: 1.4864
Batch 20, Loss: 1.4757
Batch 30, Loss: 1.4784
Batch 40, Loss: 1.5499
Batch 50, Loss: 1.5152
Batch 60, Loss: 1.5351
Batch 70, Loss: 1.5508
Batch 80, Loss: 1.4971
Batch 90, Loss: 1.5311
Batch 100, Loss: 1.5546
Batch 110, Loss: 1.5331
Batch 120, Loss: 1.5235
Batch 130, Loss: 1.6047
Batch 140, Loss: 1.5556
Batch 150, Loss: 1.5680
Batch 160, Loss: 1.5847
Batch 170, Loss: 1.5621
Batch 180, Loss: 1.5682
Batch 190, Loss: 1.5247
Batch 200, Loss: 1.5825
Batch 210, Loss: 1.4990
Batch 220, Loss: 1.5953
Batch 230, Loss: 1.5638
Batch 240, Loss: 1.5433
Batch 250, Loss: 1.5272
Batch 260, Loss: 1.6460
Batch 270, Loss: 1.5283
Batch 280, Loss: 1.5699
Batch 290, Loss: 1.5468
Batch 300, Loss: 1.5876
Batch 310, Loss: 1.6074
Batch 320, Loss: 1.6148
Batch 330, Loss: 1.5811
Batch 340, Loss: 1.6184
Batch 350, Loss: 1.5931
Batch 360, Loss: 1.5872
Batch 370, Loss: 1.6276
Batch 380, Loss: 1.5655
Batch 390, Loss: 1.4694
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.3176486492157 seconds
Epoch 26 accuracy: 55.1%
Batch 10, Loss: 1.4838
Batch 20, Loss: 1.4965
Batch 30, Loss: 1.4711
Batch 40, Loss: 1.4879
Batch 50, Loss: 1.5085
Batch 60, Loss: 1.4781
Batch 70, Loss: 1.5135
Batch 80, Loss: 1.5115
Batch 90, Loss: 1.4586
Batch 100, Loss: 1.5023
Batch 110, Loss: 1.5542
Batch 120, Loss: 1.5330
Batch 130, Loss: 1.5395
Batch 140, Loss: 1.4991
Batch 150, Loss: 1.4938
Batch 160, Loss: 1.5106
Batch 170, Loss: 1.5288
Batch 180, Loss: 1.4619
Batch 190, Loss: 1.5702
Batch 200, Loss: 1.5138
Batch 210, Loss: 1.6742
Batch 220, Loss: 1.5266
Batch 230, Loss: 1.5554
Batch 240, Loss: 1.4959
Batch 250, Loss: 1.5400
Batch 260, Loss: 1.5470
Batch 270, Loss: 1.5020
Batch 280, Loss: 1.6045
Batch 290, Loss: 1.4735
Batch 300, Loss: 1.5850
Batch 310, Loss: 1.5386
Batch 320, Loss: 1.6498
Batch 330, Loss: 1.5555
Batch 340, Loss: 1.5794
Batch 350, Loss: 1.5133
Batch 360, Loss: 1.5883
Batch 370, Loss: 1.6074
Batch 380, Loss: 1.6168
Batch 390, Loss: 1.5900
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.367038011550903 seconds
Epoch 27 accuracy: 54.45%
Batch 10, Loss: 1.5120
Batch 20, Loss: 1.5354
Batch 30, Loss: 1.5258
Batch 40, Loss: 1.4669
Batch 50, Loss: 1.5054
Batch 60, Loss: 1.4562
Batch 70, Loss: 1.5489
Batch 80, Loss: 1.5209
Batch 90, Loss: 1.5337
Batch 100, Loss: 1.5698
Batch 110, Loss: 1.5807
Batch 120, Loss: 1.5224
Batch 130, Loss: 1.4789
Batch 140, Loss: 1.5750
Batch 150, Loss: 1.6138
Batch 160, Loss: 1.5770
Batch 170, Loss: 1.5161
Batch 180, Loss: 1.5441
Batch 190, Loss: 1.5359
Batch 200, Loss: 1.5698
Batch 210, Loss: 1.6044
Batch 220, Loss: 1.5155
Batch 230, Loss: 1.5362
Batch 240, Loss: 1.5340
Batch 250, Loss: 1.5162
Batch 260, Loss: 1.5207
Batch 270, Loss: 1.5174
Batch 280, Loss: 1.5684
Batch 290, Loss: 1.5438
Batch 300, Loss: 1.5397
Batch 310, Loss: 1.5668
Batch 320, Loss: 1.5376
Batch 330, Loss: 1.5406
Batch 340, Loss: 1.5505
Batch 350, Loss: 1.4598
Batch 360, Loss: 1.4835
Batch 370, Loss: 1.5558
Batch 380, Loss: 1.5831
Batch 390, Loss: 1.5603
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.3500337600708 seconds
Epoch 28 accuracy: 53.65%
Batch 10, Loss: 1.5308
Batch 20, Loss: 1.4530
Batch 30, Loss: 1.5296
Batch 40, Loss: 1.4677
Batch 50, Loss: 1.4747
Batch 60, Loss: 1.5407
Batch 70, Loss: 1.5094
Batch 80, Loss: 1.4567
Batch 90, Loss: 1.4654
Batch 100, Loss: 1.4749
Batch 110, Loss: 1.5094
Batch 120, Loss: 1.4776
Batch 130, Loss: 1.5165
Batch 140, Loss: 1.5113
Batch 150, Loss: 1.5124
Batch 160, Loss: 1.5386
Batch 170, Loss: 1.5809
Batch 180, Loss: 1.5005
Batch 190, Loss: 1.5177
Batch 200, Loss: 1.5995
Batch 210, Loss: 1.4976
Batch 220, Loss: 1.5268
Batch 230, Loss: 1.5041
Batch 240, Loss: 1.5325
Batch 250, Loss: 1.5330
Batch 260, Loss: 1.4934
Batch 270, Loss: 1.5810
Batch 280, Loss: 1.4704
Batch 290, Loss: 1.5524
Batch 300, Loss: 1.5157
Batch 310, Loss: 1.5160
Batch 320, Loss: 1.6181
Batch 330, Loss: 1.5778
Batch 340, Loss: 1.5564
Batch 350, Loss: 1.5545
Batch 360, Loss: 1.5198
Batch 370, Loss: 1.4080
Batch 380, Loss: 1.5246
Batch 390, Loss: 1.5021
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.38925862312317 seconds
Epoch 29 accuracy: 57.47%
Batch 10, Loss: 1.5159
Batch 20, Loss: 1.4401
Batch 30, Loss: 1.4809
Batch 40, Loss: 1.4761
Batch 50, Loss: 1.4887
Batch 60, Loss: 1.5201
Batch 70, Loss: 1.5206
Batch 80, Loss: 1.4722
Batch 90, Loss: 1.5462
Batch 100, Loss: 1.4802
Batch 110, Loss: 1.4984
Batch 120, Loss: 1.4970
Batch 130, Loss: 1.4620
Batch 140, Loss: 1.4865
Batch 150, Loss: 1.4775
Batch 160, Loss: 1.5294
Batch 170, Loss: 1.6393
Batch 180, Loss: 1.6196
Batch 190, Loss: 1.5338
Batch 200, Loss: 1.6230
Batch 210, Loss: 1.5173
Batch 220, Loss: 1.5876
Batch 230, Loss: 1.5288
Batch 240, Loss: 1.5456
Batch 250, Loss: 1.5000
Batch 260, Loss: 1.4926
Batch 270, Loss: 1.5808
Batch 280, Loss: 1.5139
Batch 290, Loss: 1.5204
Batch 300, Loss: 1.5922
Batch 310, Loss: 1.5525
Batch 320, Loss: 1.5367
Batch 330, Loss: 1.4872
Batch 340, Loss: 1.5169
Batch 350, Loss: 1.4795
Batch 360, Loss: 1.5307
Batch 370, Loss: 1.4903
Batch 380, Loss: 1.5603
Batch 390, Loss: 1.5256
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.442433834075928 seconds
Epoch 30 accuracy: 57.76%
Batch 10, Loss: 1.4210
Batch 20, Loss: 1.4881
Batch 30, Loss: 1.4647
Batch 40, Loss: 1.5049
Batch 50, Loss: 1.5299
Batch 60, Loss: 1.5145
Batch 70, Loss: 1.5238
Batch 80, Loss: 1.5210
Batch 90, Loss: 1.5273
Batch 100, Loss: 1.5404
Batch 110, Loss: 1.4269
Batch 120, Loss: 1.4608
Batch 130, Loss: 1.4751
Batch 140, Loss: 1.5304
Batch 150, Loss: 1.5037
Batch 160, Loss: 1.4762
Batch 170, Loss: 1.4623
Batch 180, Loss: 1.4195
Batch 190, Loss: 1.4650
Batch 200, Loss: 1.5569
Batch 210, Loss: 1.5050
Batch 220, Loss: 1.5268
Batch 230, Loss: 1.5760
Batch 240, Loss: 1.6172
Batch 250, Loss: 1.5645
Batch 260, Loss: 1.5126
Batch 270, Loss: 1.4629
Batch 280, Loss: 1.5445
Batch 290, Loss: 1.5500
Batch 300, Loss: 1.5286
Batch 310, Loss: 1.6132
Batch 320, Loss: 1.4759
Batch 330, Loss: 1.5041
Batch 340, Loss: 1.5141
Batch 350, Loss: 1.4961
Batch 360, Loss: 1.5391
Batch 370, Loss: 1.5698
Batch 380, Loss: 1.4952
Batch 390, Loss: 1.5004
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.472673416137695 seconds
Epoch 31 accuracy: 56.93%
Batch 10, Loss: 1.4623
Batch 20, Loss: 1.4141
Batch 30, Loss: 1.4760
Batch 40, Loss: 1.3783
Batch 50, Loss: 1.5225
Batch 60, Loss: 1.4405
Batch 70, Loss: 1.5208
Batch 80, Loss: 1.4365
Batch 90, Loss: 1.4567
Batch 100, Loss: 1.4627
Batch 110, Loss: 1.5390
Batch 120, Loss: 1.5537
Batch 130, Loss: 1.5550
Batch 140, Loss: 1.5110
Batch 150, Loss: 1.4410
Batch 160, Loss: 1.5516
Batch 170, Loss: 1.5769
Batch 180, Loss: 1.5482
Batch 190, Loss: 1.5303
Batch 200, Loss: 1.5720
Batch 210, Loss: 1.5354
Batch 220, Loss: 1.5436
Batch 230, Loss: 1.5161
Batch 240, Loss: 1.5301
Batch 250, Loss: 1.5265
Batch 260, Loss: 1.5252
Batch 270, Loss: 1.5715
Batch 280, Loss: 1.5277
Batch 290, Loss: 1.4744
Batch 300, Loss: 1.4819
Batch 310, Loss: 1.5163
Batch 320, Loss: 1.4421
Batch 330, Loss: 1.5272
Batch 340, Loss: 1.4229
Batch 350, Loss: 1.4916
Batch 360, Loss: 1.5296
Batch 370, Loss: 1.5413
Batch 380, Loss: 1.5101
Batch 390, Loss: 1.5595
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.37904119491577 seconds
Epoch 32 accuracy: 53.71%
Batch 10, Loss: 1.4421
Batch 20, Loss: 1.4110
Batch 30, Loss: 1.4883
Batch 40, Loss: 1.3841
Batch 50, Loss: 1.4293
Batch 60, Loss: 1.5328
Batch 70, Loss: 1.4611
Batch 80, Loss: 1.5016
Batch 90, Loss: 1.4560
Batch 100, Loss: 1.4608
Batch 110, Loss: 1.4987
Batch 120, Loss: 1.4575
Batch 130, Loss: 1.4514
Batch 140, Loss: 1.5071
Batch 150, Loss: 1.4785
Batch 160, Loss: 1.4590
Batch 170, Loss: 1.4987
Batch 180, Loss: 1.5255
Batch 190, Loss: 1.5312
Batch 200, Loss: 1.5129
Batch 210, Loss: 1.5621
Batch 220, Loss: 1.5044
Batch 230, Loss: 1.5461
Batch 240, Loss: 1.4876
Batch 250, Loss: 1.5731
Batch 260, Loss: 1.5927
Batch 270, Loss: 1.5422
Batch 280, Loss: 1.5839
Batch 290, Loss: 1.5365
Batch 300, Loss: 1.5668
Batch 310, Loss: 1.5098
Batch 320, Loss: 1.5091
Batch 330, Loss: 1.5584
Batch 340, Loss: 1.4869
Batch 350, Loss: 1.5420
Batch 360, Loss: 1.4491
Batch 370, Loss: 1.4653
Batch 380, Loss: 1.5848
Batch 390, Loss: 1.5178
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.395277500152588 seconds
Epoch 33 accuracy: 52.12%
Batch 10, Loss: 1.4726
Batch 20, Loss: 1.4880
Batch 30, Loss: 1.4730
Batch 40, Loss: 1.4372
Batch 50, Loss: 1.4387
Batch 60, Loss: 1.3817
Batch 70, Loss: 1.4250
Batch 80, Loss: 1.4815
Batch 90, Loss: 1.4743
Batch 100, Loss: 1.4388
Batch 110, Loss: 1.5509
Batch 120, Loss: 1.5230
Batch 130, Loss: 1.4850
Batch 140, Loss: 1.5000
Batch 150, Loss: 1.4873
Batch 160, Loss: 1.4731
Batch 170, Loss: 1.4208
Batch 180, Loss: 1.4790
Batch 190, Loss: 1.5545
Batch 200, Loss: 1.5526
Batch 210, Loss: 1.4572
Batch 220, Loss: 1.4313
Batch 230, Loss: 1.5046
Batch 240, Loss: 1.4948
Batch 250, Loss: 1.5518
Batch 260, Loss: 1.5265
Batch 270, Loss: 1.4812
Batch 280, Loss: 1.5051
Batch 290, Loss: 1.5202
Batch 300, Loss: 1.5079
Batch 310, Loss: 1.5231
Batch 320, Loss: 1.5120
Batch 330, Loss: 1.5173
Batch 340, Loss: 1.4076
Batch 350, Loss: 1.4219
Batch 360, Loss: 1.5243
Batch 370, Loss: 1.5940
Batch 380, Loss: 1.5738
Batch 390, Loss: 1.5133
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.359185934066772 seconds
Epoch 34 accuracy: 56.85%
Batch 10, Loss: 1.4326
Batch 20, Loss: 1.4360
Batch 30, Loss: 1.4464
Batch 40, Loss: 1.4463
Batch 50, Loss: 1.4499
Batch 60, Loss: 1.4492
Batch 70, Loss: 1.5048
Batch 80, Loss: 1.5143
Batch 90, Loss: 1.4408
Batch 100, Loss: 1.5084
Batch 110, Loss: 1.4555
Batch 120, Loss: 1.4415
Batch 130, Loss: 1.4361
Batch 140, Loss: 1.4646
Batch 150, Loss: 1.4808
Batch 160, Loss: 1.5264
Batch 170, Loss: 1.5164
Batch 180, Loss: 1.4510
Batch 190, Loss: 1.4965
Batch 200, Loss: 1.4837
Batch 210, Loss: 1.4342
Batch 220, Loss: 1.5170
Batch 230, Loss: 1.4971
Batch 240, Loss: 1.4705
Batch 250, Loss: 1.4798
Batch 260, Loss: 1.5144
Batch 270, Loss: 1.4518
Batch 280, Loss: 1.4677
Batch 290, Loss: 1.4929
Batch 300, Loss: 1.5332
Batch 310, Loss: 1.5431
Batch 320, Loss: 1.4391
Batch 330, Loss: 1.4530
Batch 340, Loss: 1.4838
Batch 350, Loss: 1.4965
Batch 360, Loss: 1.5001
Batch 370, Loss: 1.4960
Batch 380, Loss: 1.5931
Batch 390, Loss: 1.5248
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.313448190689087 seconds
Epoch 35 accuracy: 55.42%
Batch 10, Loss: 1.4785
Batch 20, Loss: 1.4373
Batch 30, Loss: 1.4024
Batch 40, Loss: 1.3952
Batch 50, Loss: 1.4633
Batch 60, Loss: 1.5192
Batch 70, Loss: 1.4849
Batch 80, Loss: 1.4289
Batch 90, Loss: 1.4966
Batch 100, Loss: 1.4096
Batch 110, Loss: 1.4711
Batch 120, Loss: 1.4685
Batch 130, Loss: 1.5026
Batch 140, Loss: 1.4463
Batch 150, Loss: 1.4920
Batch 160, Loss: 1.5108
Batch 170, Loss: 1.4258
Batch 180, Loss: 1.4366
Batch 190, Loss: 1.5059
Batch 200, Loss: 1.5154
Batch 210, Loss: 1.4915
Batch 220, Loss: 1.4771
Batch 230, Loss: 1.4800
Batch 240, Loss: 1.5025
Batch 250, Loss: 1.5065
Batch 260, Loss: 1.4758
Batch 270, Loss: 1.4271
Batch 280, Loss: 1.4635
Batch 290, Loss: 1.5349
Batch 300, Loss: 1.5545
Batch 310, Loss: 1.5358
Batch 320, Loss: 1.4606
Batch 330, Loss: 1.4921
Batch 340, Loss: 1.4694
Batch 350, Loss: 1.5320
Batch 360, Loss: 1.4758
Batch 370, Loss: 1.5122
Batch 380, Loss: 1.4465
Batch 390, Loss: 1.5113
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.343880653381348 seconds
Epoch 36 accuracy: 56.9%
Batch 10, Loss: 1.4471
Batch 20, Loss: 1.4854
Batch 30, Loss: 1.3885
Batch 40, Loss: 1.4437
Batch 50, Loss: 1.4291
Batch 60, Loss: 1.4898
Batch 70, Loss: 1.4995
Batch 80, Loss: 1.3495
Batch 90, Loss: 1.4294
Batch 100, Loss: 1.3588
Batch 110, Loss: 1.4558
Batch 120, Loss: 1.4357
Batch 130, Loss: 1.4756
Batch 140, Loss: 1.5139
Batch 150, Loss: 1.4875
Batch 160, Loss: 1.4922
Batch 170, Loss: 1.5075
Batch 180, Loss: 1.5304
Batch 190, Loss: 1.3928
Batch 200, Loss: 1.5179
Batch 210, Loss: 1.4711
Batch 220, Loss: 1.4523
Batch 230, Loss: 1.4197
Batch 240, Loss: 1.5117
Batch 250, Loss: 1.5391
Batch 260, Loss: 1.5389
Batch 270, Loss: 1.4940
Batch 280, Loss: 1.4718
Batch 290, Loss: 1.4927
Batch 300, Loss: 1.4420
Batch 310, Loss: 1.4318
Batch 320, Loss: 1.4425
Batch 330, Loss: 1.5263
Batch 340, Loss: 1.4715
Batch 350, Loss: 1.5142
Batch 360, Loss: 1.4922
Batch 370, Loss: 1.5032
Batch 380, Loss: 1.4329
Batch 390, Loss: 1.5996
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.394655227661133 seconds
Epoch 37 accuracy: 57.89%
Batch 10, Loss: 1.4497
Batch 20, Loss: 1.3778
Batch 30, Loss: 1.4322
Batch 40, Loss: 1.3841
Batch 50, Loss: 1.3841
Batch 60, Loss: 1.4238
Batch 70, Loss: 1.3776
Batch 80, Loss: 1.4266
Batch 90, Loss: 1.4273
Batch 100, Loss: 1.4990
Batch 110, Loss: 1.5924
Batch 120, Loss: 1.4667
Batch 130, Loss: 1.4812
Batch 140, Loss: 1.4389
Batch 150, Loss: 1.4853
Batch 160, Loss: 1.4601
Batch 170, Loss: 1.4418
Batch 180, Loss: 1.5328
Batch 190, Loss: 1.5396
Batch 200, Loss: 1.4498
Batch 210, Loss: 1.4282
Batch 220, Loss: 1.4558
Batch 230, Loss: 1.3907
Batch 240, Loss: 1.5044
Batch 250, Loss: 1.4912
Batch 260, Loss: 1.4619
Batch 270, Loss: 1.4890
Batch 280, Loss: 1.5226
Batch 290, Loss: 1.4980
Batch 300, Loss: 1.4439
Batch 310, Loss: 1.4864
Batch 320, Loss: 1.4776
Batch 330, Loss: 1.4080
Batch 340, Loss: 1.5578
Batch 350, Loss: 1.4924
Batch 360, Loss: 1.4575
Batch 370, Loss: 1.5238
Batch 380, Loss: 1.5289
Batch 390, Loss: 1.5580
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.311503887176514 seconds
Epoch 38 accuracy: 57.91%
Batch 10, Loss: 1.4732
Batch 20, Loss: 1.4439
Batch 30, Loss: 1.3865
Batch 40, Loss: 1.4271
Batch 50, Loss: 1.4278
Batch 60, Loss: 1.3794
Batch 70, Loss: 1.4230
Batch 80, Loss: 1.4552
Batch 90, Loss: 1.4239
Batch 100, Loss: 1.4657
Batch 110, Loss: 1.4735
Batch 120, Loss: 1.3941
Batch 130, Loss: 1.4745
Batch 140, Loss: 1.4597
Batch 150, Loss: 1.4417
Batch 160, Loss: 1.5086
Batch 170, Loss: 1.4771
Batch 180, Loss: 1.4826
Batch 190, Loss: 1.4434
Batch 200, Loss: 1.4875
Batch 210, Loss: 1.4553
Batch 220, Loss: 1.4690
Batch 230, Loss: 1.4831
Batch 240, Loss: 1.5407
Batch 250, Loss: 1.4898
Batch 260, Loss: 1.4121
Batch 270, Loss: 1.4779
Batch 280, Loss: 1.4019
Batch 290, Loss: 1.4790
Batch 300, Loss: 1.4615
Batch 310, Loss: 1.4646
Batch 320, Loss: 1.4759
Batch 330, Loss: 1.4603
Batch 340, Loss: 1.5406
Batch 350, Loss: 1.5490
Batch 360, Loss: 1.4869
Batch 370, Loss: 1.4841
Batch 380, Loss: 1.3552
Batch 390, Loss: 1.4283
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.37268352508545 seconds
Epoch 39 accuracy: 56.83%
Batch 10, Loss: 1.3877
Batch 20, Loss: 1.4269
Batch 30, Loss: 1.3784
Batch 40, Loss: 1.4502
Batch 50, Loss: 1.4122
Batch 60, Loss: 1.3963
Batch 70, Loss: 1.4301
Batch 80, Loss: 1.4047
Batch 90, Loss: 1.4355
Batch 100, Loss: 1.3767
Batch 110, Loss: 1.3946
Batch 120, Loss: 1.4014
Batch 130, Loss: 1.4245
Batch 140, Loss: 1.4011
Batch 150, Loss: 1.5197
Batch 160, Loss: 1.4176
Batch 170, Loss: 1.4308
Batch 180, Loss: 1.4783
Batch 190, Loss: 1.4727
Batch 200, Loss: 1.4861
Batch 210, Loss: 1.4660
Batch 220, Loss: 1.4034
Batch 230, Loss: 1.4059
Batch 240, Loss: 1.4880
Batch 250, Loss: 1.5125
Batch 260, Loss: 1.4738
Batch 270, Loss: 1.5103
Batch 280, Loss: 1.5187
Batch 290, Loss: 1.4302
Batch 300, Loss: 1.4467
Batch 310, Loss: 1.4341
Batch 320, Loss: 1.4693
Batch 330, Loss: 1.5354
Batch 340, Loss: 1.4646
Batch 350, Loss: 1.4599
Batch 360, Loss: 1.4585
Batch 370, Loss: 1.5046
Batch 380, Loss: 1.4516
Batch 390, Loss: 1.4891
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.399144411087036 seconds
Epoch 40 accuracy: 58.69%
Batch 10, Loss: 1.4176
Batch 20, Loss: 1.4024
Batch 30, Loss: 1.4040
Batch 40, Loss: 1.4112
Batch 50, Loss: 1.4155
Batch 60, Loss: 1.4578
Batch 70, Loss: 1.4443
Batch 80, Loss: 1.3722
Batch 90, Loss: 1.4064
Batch 100, Loss: 1.4387
Batch 110, Loss: 1.4806
Batch 120, Loss: 1.4420
Batch 130, Loss: 1.4625
Batch 140, Loss: 1.4597
Batch 150, Loss: 1.4806
Batch 160, Loss: 1.4952
Batch 170, Loss: 1.4152
Batch 180, Loss: 1.4728
Batch 190, Loss: 1.4302
Batch 200, Loss: 1.4394
Batch 210, Loss: 1.4516
Batch 220, Loss: 1.4904
Batch 230, Loss: 1.4944
Batch 240, Loss: 1.4709
Batch 250, Loss: 1.4128
Batch 260, Loss: 1.4000
Batch 270, Loss: 1.4765
Batch 280, Loss: 1.4322
Batch 290, Loss: 1.4313
Batch 300, Loss: 1.4463
Batch 310, Loss: 1.4160
Batch 320, Loss: 1.3790
Batch 330, Loss: 1.5057
Batch 340, Loss: 1.5391
Batch 350, Loss: 1.4485
Batch 360, Loss: 1.4074
Batch 370, Loss: 1.4329
Batch 380, Loss: 1.5033
Batch 390, Loss: 1.3825
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.401880502700806 seconds
Epoch 41 accuracy: 56.91%
Batch 10, Loss: 1.4746
Batch 20, Loss: 1.4309
Batch 30, Loss: 1.3378
Batch 40, Loss: 1.4374
Batch 50, Loss: 1.3320
Batch 60, Loss: 1.3782
Batch 70, Loss: 1.3718
Batch 80, Loss: 1.4176
Batch 90, Loss: 1.4058
Batch 100, Loss: 1.4235
Batch 110, Loss: 1.5393
Batch 120, Loss: 1.4281
Batch 130, Loss: 1.4981
Batch 140, Loss: 1.5134
Batch 150, Loss: 1.4272
Batch 160, Loss: 1.5293
Batch 170, Loss: 1.4843
Batch 180, Loss: 1.4906
Batch 190, Loss: 1.4578
Batch 200, Loss: 1.3913
Batch 210, Loss: 1.4205
Batch 220, Loss: 1.4513
Batch 230, Loss: 1.3988
Batch 240, Loss: 1.5487
Batch 250, Loss: 1.4486
Batch 260, Loss: 1.4142
Batch 270, Loss: 1.4486
Batch 280, Loss: 1.5354
Batch 290, Loss: 1.4945
Batch 300, Loss: 1.5187
Batch 310, Loss: 1.4377
Batch 320, Loss: 1.5405
Batch 330, Loss: 1.4933
Batch 340, Loss: 1.4140
Batch 350, Loss: 1.4592
Batch 360, Loss: 1.4572
Batch 370, Loss: 1.4537
Batch 380, Loss: 1.4381
Batch 390, Loss: 1.4240
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.365983724594116 seconds
Epoch 42 accuracy: 57.61%
Batch 10, Loss: 1.4429
Batch 20, Loss: 1.4507
Batch 30, Loss: 1.4363
Batch 40, Loss: 1.4495
Batch 50, Loss: 1.4366
Batch 60, Loss: 1.3854
Batch 70, Loss: 1.4106
Batch 80, Loss: 1.4232
Batch 90, Loss: 1.4375
Batch 100, Loss: 1.4451
Batch 110, Loss: 1.3795
Batch 120, Loss: 1.4329
Batch 130, Loss: 1.4239
Batch 140, Loss: 1.4250
Batch 150, Loss: 1.4299
Batch 160, Loss: 1.4526
Batch 170, Loss: 1.4235
Batch 180, Loss: 1.4151
Batch 190, Loss: 1.4171
Batch 200, Loss: 1.4496
Batch 210, Loss: 1.4689
Batch 220, Loss: 1.4720
Batch 230, Loss: 1.4803
Batch 240, Loss: 1.5420
Batch 250, Loss: 1.4457
Batch 260, Loss: 1.4498
Batch 270, Loss: 1.4533
Batch 280, Loss: 1.4425
Batch 290, Loss: 1.4517
Batch 300, Loss: 1.4699
Batch 310, Loss: 1.5296
Batch 320, Loss: 1.4617
Batch 330, Loss: 1.4489
Batch 340, Loss: 1.3845
Batch 350, Loss: 1.4411
Batch 360, Loss: 1.4740
Batch 370, Loss: 1.4158
Batch 380, Loss: 1.4489
Batch 390, Loss: 1.4527
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.292462587356567 seconds
Epoch 43 accuracy: 55.94%
Batch 10, Loss: 1.3431
Batch 20, Loss: 1.3323
Batch 30, Loss: 1.3680
Batch 40, Loss: 1.3330
Batch 50, Loss: 1.3366
Batch 60, Loss: 1.3683
Batch 70, Loss: 1.4705
Batch 80, Loss: 1.4524
Batch 90, Loss: 1.4456
Batch 100, Loss: 1.3820
Batch 110, Loss: 1.4135
Batch 120, Loss: 1.3965
Batch 130, Loss: 1.4127
Batch 140, Loss: 1.4025
Batch 150, Loss: 1.4080
Batch 160, Loss: 1.4785
Batch 170, Loss: 1.4683
Batch 180, Loss: 1.4625
Batch 190, Loss: 1.4427
Batch 200, Loss: 1.4270
Batch 210, Loss: 1.4291
Batch 220, Loss: 1.3814
Batch 230, Loss: 1.4459
Batch 240, Loss: 1.4096
Batch 250, Loss: 1.4520
Batch 260, Loss: 1.3566
Batch 270, Loss: 1.5202
Batch 280, Loss: 1.4613
Batch 290, Loss: 1.4232
Batch 300, Loss: 1.4970
Batch 310, Loss: 1.4012
Batch 320, Loss: 1.4883
Batch 330, Loss: 1.4112
Batch 340, Loss: 1.4763
Batch 350, Loss: 1.4126
Batch 360, Loss: 1.4707
Batch 370, Loss: 1.4551
Batch 380, Loss: 1.4634
Batch 390, Loss: 1.5074
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.374240398406982 seconds
Epoch 44 accuracy: 59.97%
Batch 10, Loss: 1.3729
Batch 20, Loss: 1.4054
Batch 30, Loss: 1.3957
Batch 40, Loss: 1.4523
Batch 50, Loss: 1.3904
Batch 60, Loss: 1.3619
Batch 70, Loss: 1.3883
Batch 80, Loss: 1.3667
Batch 90, Loss: 1.3809
Batch 100, Loss: 1.4354
Batch 110, Loss: 1.4224
Batch 120, Loss: 1.3732
Batch 130, Loss: 1.4544
Batch 140, Loss: 1.3934
Batch 150, Loss: 1.4374
Batch 160, Loss: 1.4230
Batch 170, Loss: 1.4644
Batch 180, Loss: 1.4860
Batch 190, Loss: 1.4528
Batch 200, Loss: 1.4150
Batch 210, Loss: 1.4517
Batch 220, Loss: 1.4684
Batch 230, Loss: 1.3735
Batch 240, Loss: 1.4230
Batch 250, Loss: 1.4446
Batch 260, Loss: 1.4476
Batch 270, Loss: 1.4323
Batch 280, Loss: 1.4303
Batch 290, Loss: 1.4583
Batch 300, Loss: 1.4434
Batch 310, Loss: 1.4842
Batch 320, Loss: 1.5220
Batch 330, Loss: 1.5070
Batch 340, Loss: 1.3682
Batch 350, Loss: 1.4454
Batch 360, Loss: 1.5232
Batch 370, Loss: 1.5095
Batch 380, Loss: 1.4231
Batch 390, Loss: 1.4017
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.225828647613525 seconds
Epoch 45 accuracy: 55.76%
Batch 10, Loss: 1.4015
Batch 20, Loss: 1.3514
Batch 30, Loss: 1.3250
Batch 40, Loss: 1.3776
Batch 50, Loss: 1.4290
Batch 60, Loss: 1.3936
Batch 70, Loss: 1.3720
Batch 80, Loss: 1.3518
Batch 90, Loss: 1.4410
Batch 100, Loss: 1.4024
Batch 110, Loss: 1.4378
Batch 120, Loss: 1.4002
Batch 130, Loss: 1.4154
Batch 140, Loss: 1.4443
Batch 150, Loss: 1.4494
Batch 160, Loss: 1.3752
Batch 170, Loss: 1.4101
Batch 180, Loss: 1.4227
Batch 190, Loss: 1.4141
Batch 200, Loss: 1.4488
Batch 210, Loss: 1.4260
Batch 220, Loss: 1.4078
Batch 230, Loss: 1.4433
Batch 240, Loss: 1.3756
Batch 250, Loss: 1.4464
Batch 260, Loss: 1.3708
Batch 270, Loss: 1.3390
Batch 280, Loss: 1.4414
Batch 290, Loss: 1.3897
Batch 300, Loss: 1.4203
Batch 310, Loss: 1.4168
Batch 320, Loss: 1.4597
Batch 330, Loss: 1.3925
Batch 340, Loss: 1.4466
Batch 350, Loss: 1.4445
Batch 360, Loss: 1.4713
Batch 370, Loss: 1.4162
Batch 380, Loss: 1.4368
Batch 390, Loss: 1.4735
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.42681860923767 seconds
Epoch 46 accuracy: 57.1%
Batch 10, Loss: 1.4013
Batch 20, Loss: 1.3481
Batch 30, Loss: 1.4214
Batch 40, Loss: 1.3617
Batch 50, Loss: 1.4281
Batch 60, Loss: 1.4524
Batch 70, Loss: 1.4260
Batch 80, Loss: 1.3323
Batch 90, Loss: 1.3489
Batch 100, Loss: 1.3898
Batch 110, Loss: 1.4317
Batch 120, Loss: 1.4143
Batch 130, Loss: 1.4108
Batch 140, Loss: 1.4062
Batch 150, Loss: 1.4353
Batch 160, Loss: 1.4474
Batch 170, Loss: 1.4282
Batch 180, Loss: 1.4038
Batch 190, Loss: 1.4801
Batch 200, Loss: 1.4357
Batch 210, Loss: 1.4227
Batch 220, Loss: 1.3916
Batch 230, Loss: 1.4776
Batch 240, Loss: 1.3904
Batch 250, Loss: 1.4428
Batch 260, Loss: 1.4515
Batch 270, Loss: 1.3801
Batch 280, Loss: 1.4312
Batch 290, Loss: 1.4151
Batch 300, Loss: 1.4427
Batch 310, Loss: 1.4338
Batch 320, Loss: 1.3963
Batch 330, Loss: 1.4875
Batch 340, Loss: 1.4042
Batch 350, Loss: 1.4717
Batch 360, Loss: 1.4630
Batch 370, Loss: 1.4356
Batch 380, Loss: 1.3933
Batch 390, Loss: 1.4250
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.28751301765442 seconds
Epoch 47 accuracy: 57.83%
Batch 10, Loss: 1.3280
Batch 20, Loss: 1.3175
Batch 30, Loss: 1.3798
Batch 40, Loss: 1.3336
Batch 50, Loss: 1.4300
Batch 60, Loss: 1.4519
Batch 70, Loss: 1.3875
Batch 80, Loss: 1.3022
Batch 90, Loss: 1.4209
Batch 100, Loss: 1.4243
Batch 110, Loss: 1.4385
Batch 120, Loss: 1.4094
Batch 130, Loss: 1.4404
Batch 140, Loss: 1.4342
Batch 150, Loss: 1.3960
Batch 160, Loss: 1.4088
Batch 170, Loss: 1.3697
Batch 180, Loss: 1.4397
Batch 190, Loss: 1.4203
Batch 200, Loss: 1.3426
Batch 210, Loss: 1.3972
Batch 220, Loss: 1.4098
Batch 230, Loss: 1.3590
Batch 240, Loss: 1.4306
Batch 250, Loss: 1.4034
Batch 260, Loss: 1.3894
Batch 270, Loss: 1.4268
Batch 280, Loss: 1.3720
Batch 290, Loss: 1.3562
Batch 300, Loss: 1.4437
Batch 310, Loss: 1.4669
Batch 320, Loss: 1.4225
Batch 330, Loss: 1.4546
Batch 340, Loss: 1.4105
Batch 350, Loss: 1.4280
Batch 360, Loss: 1.3751
Batch 370, Loss: 1.3991
Batch 380, Loss: 1.4020
Batch 390, Loss: 1.5108
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.332977056503296 seconds
Epoch 48 accuracy: 55.51%
Batch 10, Loss: 1.3731
Batch 20, Loss: 1.3837
Batch 30, Loss: 1.3866
Batch 40, Loss: 1.3743
Batch 50, Loss: 1.4156
Batch 60, Loss: 1.3737
Batch 70, Loss: 1.4564
Batch 80, Loss: 1.3771
Batch 90, Loss: 1.4189
Batch 100, Loss: 1.4186
Batch 110, Loss: 1.4051
Batch 120, Loss: 1.3673
Batch 130, Loss: 1.4147
Batch 140, Loss: 1.3820
Batch 150, Loss: 1.4669
Batch 160, Loss: 1.4347
Batch 170, Loss: 1.3620
Batch 180, Loss: 1.4458
Batch 190, Loss: 1.4461
Batch 200, Loss: 1.4257
Batch 210, Loss: 1.3107
Batch 220, Loss: 1.4196
Batch 230, Loss: 1.4479
Batch 240, Loss: 1.4915
Batch 250, Loss: 1.4332
Batch 260, Loss: 1.4332
Batch 270, Loss: 1.4211
Batch 280, Loss: 1.4665
Batch 290, Loss: 1.4333
Batch 300, Loss: 1.3839
Batch 310, Loss: 1.4293
Batch 320, Loss: 1.3734
Batch 330, Loss: 1.4857
Batch 340, Loss: 1.4119
Batch 350, Loss: 1.4385
Batch 360, Loss: 1.3761
Batch 370, Loss: 1.3758
Batch 380, Loss: 1.4159
Batch 390, Loss: 1.4067
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.360055446624756 seconds
Epoch 49 accuracy: 54.87%
Batch 10, Loss: 1.3509
Batch 20, Loss: 1.3884
Batch 30, Loss: 1.4222
Batch 40, Loss: 1.4363
Batch 50, Loss: 1.3287
Batch 60, Loss: 1.3533
Batch 70, Loss: 1.3648
Batch 80, Loss: 1.3905
Batch 90, Loss: 1.3648
Batch 100, Loss: 1.4595
Batch 110, Loss: 1.4056
Batch 120, Loss: 1.3983
Batch 130, Loss: 1.3291
Batch 140, Loss: 1.3834
Batch 150, Loss: 1.3786
Batch 160, Loss: 1.3546
Batch 170, Loss: 1.3783
Batch 180, Loss: 1.4601
Batch 190, Loss: 1.4036
Batch 200, Loss: 1.3875
Batch 210, Loss: 1.3820
Batch 220, Loss: 1.4205
Batch 230, Loss: 1.3595
Batch 240, Loss: 1.4055
Batch 250, Loss: 1.3067
Batch 260, Loss: 1.3888
Batch 270, Loss: 1.4393
Batch 280, Loss: 1.3463
Batch 290, Loss: 1.4670
Batch 300, Loss: 1.4909
Batch 310, Loss: 1.4343
Batch 320, Loss: 1.4388
Batch 330, Loss: 1.3899
Batch 340, Loss: 1.3724
Batch 350, Loss: 1.4439
Batch 360, Loss: 1.4184
Batch 370, Loss: 1.4825
Batch 380, Loss: 1.4375
Batch 390, Loss: 1.3799
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.424859046936035 seconds
Epoch 50 accuracy: 55.73%
Batch 10, Loss: 1.4281
Batch 20, Loss: 1.3681
Batch 30, Loss: 1.2934
Batch 40, Loss: 1.3837
Batch 50, Loss: 1.3700
Batch 60, Loss: 1.3581
Batch 70, Loss: 1.4009
Batch 80, Loss: 1.3140
Batch 90, Loss: 1.4062
Batch 100, Loss: 1.3889
Batch 110, Loss: 1.4050
Batch 120, Loss: 1.3626
Batch 130, Loss: 1.3839
Batch 140, Loss: 1.3503
Batch 150, Loss: 1.3977
Batch 160, Loss: 1.4042
Batch 170, Loss: 1.4604
Batch 180, Loss: 1.4421
Batch 190, Loss: 1.4022
Batch 200, Loss: 1.3826
Batch 210, Loss: 1.4546
Batch 220, Loss: 1.3736
Batch 230, Loss: 1.3932
Batch 240, Loss: 1.3761
Batch 250, Loss: 1.3613
Batch 260, Loss: 1.4219
Batch 270, Loss: 1.3974
Batch 280, Loss: 1.3569
Batch 290, Loss: 1.4047
Batch 300, Loss: 1.4024
Batch 310, Loss: 1.4305
Batch 320, Loss: 1.4759
Batch 330, Loss: 1.4311
Batch 340, Loss: 1.4587
Batch 350, Loss: 1.4430
Batch 360, Loss: 1.4171
Batch 370, Loss: 1.4442
Batch 380, Loss: 1.4802
Batch 390, Loss: 1.3772
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.360798358917236 seconds
Epoch 51 accuracy: 61.49%
Batch 10, Loss: 1.3720
Batch 20, Loss: 1.3882
Batch 30, Loss: 1.3215
Batch 40, Loss: 1.4351
Batch 50, Loss: 1.3371
Batch 60, Loss: 1.4170
Batch 70, Loss: 1.3599
Batch 80, Loss: 1.4375
Batch 90, Loss: 1.3363
Batch 100, Loss: 1.3168
Batch 110, Loss: 1.3692
Batch 120, Loss: 1.5185
Batch 130, Loss: 1.3974
Batch 140, Loss: 1.3587
Batch 150, Loss: 1.3720
Batch 160, Loss: 1.3891
Batch 170, Loss: 1.3381
Batch 180, Loss: 1.4072
Batch 190, Loss: 1.4330
Batch 200, Loss: 1.4128
Batch 210, Loss: 1.3879
Batch 220, Loss: 1.3607
Batch 230, Loss: 1.3153
Batch 240, Loss: 1.4116
Batch 250, Loss: 1.3502
Batch 260, Loss: 1.4259
Batch 270, Loss: 1.3464
Batch 280, Loss: 1.3965
Batch 290, Loss: 1.3586
Batch 300, Loss: 1.4444
Batch 310, Loss: 1.3970
Batch 320, Loss: 1.4679
Batch 330, Loss: 1.3853
Batch 340, Loss: 1.3949
Batch 350, Loss: 1.4308
Batch 360, Loss: 1.4430
Batch 370, Loss: 1.3918
Batch 380, Loss: 1.3939
Batch 390, Loss: 1.4567
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.491018772125244 seconds
Epoch 52 accuracy: 58.19%
Batch 10, Loss: 1.3714
Batch 20, Loss: 1.3252
Batch 30, Loss: 1.3008
Batch 40, Loss: 1.3209
Batch 50, Loss: 1.3474
Batch 60, Loss: 1.3229
Batch 70, Loss: 1.3656
Batch 80, Loss: 1.3958
Batch 90, Loss: 1.3468
Batch 100, Loss: 1.4140
Batch 110, Loss: 1.3618
Batch 120, Loss: 1.3686
Batch 130, Loss: 1.3312
Batch 140, Loss: 1.3180
Batch 150, Loss: 1.4622
Batch 160, Loss: 1.2895
Batch 170, Loss: 1.3782
Batch 180, Loss: 1.4287
Batch 190, Loss: 1.4011
Batch 200, Loss: 1.3970
Batch 210, Loss: 1.3866
Batch 220, Loss: 1.3787
Batch 230, Loss: 1.3264
Batch 240, Loss: 1.3945
Batch 250, Loss: 1.3918
Batch 260, Loss: 1.3458
Batch 270, Loss: 1.4379
Batch 280, Loss: 1.4390
Batch 290, Loss: 1.4032
Batch 300, Loss: 1.4299
Batch 310, Loss: 1.4012
Batch 320, Loss: 1.4283
Batch 330, Loss: 1.3376
Batch 340, Loss: 1.3380
Batch 350, Loss: 1.3774
Batch 360, Loss: 1.3598
Batch 370, Loss: 1.3636
Batch 380, Loss: 1.3885
Batch 390, Loss: 1.5006
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.38750195503235 seconds
Epoch 53 accuracy: 58.99%
Batch 10, Loss: 1.3234
Batch 20, Loss: 1.2996
Batch 30, Loss: 1.3572
Batch 40, Loss: 1.3186
Batch 50, Loss: 1.3497
Batch 60, Loss: 1.2914
Batch 70, Loss: 1.3038
Batch 80, Loss: 1.3821
Batch 90, Loss: 1.4481
Batch 100, Loss: 1.4212
Batch 110, Loss: 1.4033
Batch 120, Loss: 1.3397
Batch 130, Loss: 1.3912
Batch 140, Loss: 1.3450
Batch 150, Loss: 1.3584
Batch 160, Loss: 1.4037
Batch 170, Loss: 1.4467
Batch 180, Loss: 1.4107
Batch 190, Loss: 1.4409
Batch 200, Loss: 1.4085
Batch 210, Loss: 1.3942
Batch 220, Loss: 1.3591
Batch 230, Loss: 1.3597
Batch 240, Loss: 1.3739
Batch 250, Loss: 1.4211
Batch 260, Loss: 1.4988
Batch 270, Loss: 1.4148
Batch 280, Loss: 1.3779
Batch 290, Loss: 1.3915
Batch 300, Loss: 1.3807
Batch 310, Loss: 1.3953
Batch 320, Loss: 1.4419
Batch 330, Loss: 1.4151
Batch 340, Loss: 1.3371
Batch 350, Loss: 1.4238
Batch 360, Loss: 1.4226
Batch 370, Loss: 1.3671
Batch 380, Loss: 1.4153
Batch 390, Loss: 1.4500
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.31629252433777 seconds
Epoch 54 accuracy: 56.87%
Batch 10, Loss: 1.3684
Batch 20, Loss: 1.2931
Batch 30, Loss: 1.3073
Batch 40, Loss: 1.3465
Batch 50, Loss: 1.3543
Batch 60, Loss: 1.3474
Batch 70, Loss: 1.3155
Batch 80, Loss: 1.3623
Batch 90, Loss: 1.3368
Batch 100, Loss: 1.3554
Batch 110, Loss: 1.4345
Batch 120, Loss: 1.3442
Batch 130, Loss: 1.3208
Batch 140, Loss: 1.3425
Batch 150, Loss: 1.3996
Batch 160, Loss: 1.3495
Batch 170, Loss: 1.3715
Batch 180, Loss: 1.4116
Batch 190, Loss: 1.4084
Batch 200, Loss: 1.3633
Batch 210, Loss: 1.3906
Batch 220, Loss: 1.3845
Batch 230, Loss: 1.3935
Batch 240, Loss: 1.4109
Batch 250, Loss: 1.3935
Batch 260, Loss: 1.4412
Batch 270, Loss: 1.3454
Batch 280, Loss: 1.4118
Batch 290, Loss: 1.4028
Batch 300, Loss: 1.3747
Batch 310, Loss: 1.4264
Batch 320, Loss: 1.4208
Batch 330, Loss: 1.4018
Batch 340, Loss: 1.4033
Batch 350, Loss: 1.3954
Batch 360, Loss: 1.4041
Batch 370, Loss: 1.3696
Batch 380, Loss: 1.3881
Batch 390, Loss: 1.3852
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.247339725494385 seconds
Epoch 55 accuracy: 58.66%
Batch 10, Loss: 1.3140
Batch 20, Loss: 1.3366
Batch 30, Loss: 1.3058
Batch 40, Loss: 1.3313
Batch 50, Loss: 1.2656
Batch 60, Loss: 1.2734
Batch 70, Loss: 1.3935
Batch 80, Loss: 1.3598
Batch 90, Loss: 1.3509
Batch 100, Loss: 1.3360
Batch 110, Loss: 1.3267
Batch 120, Loss: 1.3105
Batch 130, Loss: 1.3627
Batch 140, Loss: 1.4348
Batch 150, Loss: 1.4098
Batch 160, Loss: 1.3784
Batch 170, Loss: 1.3962
Batch 180, Loss: 1.4303
Batch 190, Loss: 1.3316
Batch 200, Loss: 1.3746
Batch 210, Loss: 1.3858
Batch 220, Loss: 1.4297
Batch 230, Loss: 1.4065
Batch 240, Loss: 1.3982
Batch 250, Loss: 1.4378
Batch 260, Loss: 1.4371
Batch 270, Loss: 1.3482
Batch 280, Loss: 1.3855
Batch 290, Loss: 1.4337
Batch 300, Loss: 1.3896
Batch 310, Loss: 1.4077
Batch 320, Loss: 1.3764
Batch 330, Loss: 1.3608
Batch 340, Loss: 1.4014
Batch 350, Loss: 1.4434
Batch 360, Loss: 1.4094
Batch 370, Loss: 1.4527
Batch 380, Loss: 1.4323
Batch 390, Loss: 1.3982
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.319013595581055 seconds
Epoch 56 accuracy: 56.44%
Batch 10, Loss: 1.3505
Batch 20, Loss: 1.2965
Batch 30, Loss: 1.2307
Batch 40, Loss: 1.3328
Batch 50, Loss: 1.3341
Batch 60, Loss: 1.3770
Batch 70, Loss: 1.3325
Batch 80, Loss: 1.2993
Batch 90, Loss: 1.3440
Batch 100, Loss: 1.3899
Batch 110, Loss: 1.4173
Batch 120, Loss: 1.3794
Batch 130, Loss: 1.3763
Batch 140, Loss: 1.3753
Batch 150, Loss: 1.4118
Batch 160, Loss: 1.3611
Batch 170, Loss: 1.3093
Batch 180, Loss: 1.3437
Batch 190, Loss: 1.4106
Batch 200, Loss: 1.4319
Batch 210, Loss: 1.3177
Batch 220, Loss: 1.3428
Batch 230, Loss: 1.3362
Batch 240, Loss: 1.3487
Batch 250, Loss: 1.3744
Batch 260, Loss: 1.3257
Batch 270, Loss: 1.3928
Batch 280, Loss: 1.3661
Batch 290, Loss: 1.4153
Batch 300, Loss: 1.3772
Batch 310, Loss: 1.4631
Batch 320, Loss: 1.3358
Batch 330, Loss: 1.3178
Batch 340, Loss: 1.3671
Batch 350, Loss: 1.4302
Batch 360, Loss: 1.4069
Batch 370, Loss: 1.3986
Batch 380, Loss: 1.3729
Batch 390, Loss: 1.4157
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.32988142967224 seconds
Epoch 57 accuracy: 59.34%
Batch 10, Loss: 1.3594
Batch 20, Loss: 1.3057
Batch 30, Loss: 1.3442
Batch 40, Loss: 1.3041
Batch 50, Loss: 1.3244
Batch 60, Loss: 1.3346
Batch 70, Loss: 1.3057
Batch 80, Loss: 1.3380
Batch 90, Loss: 1.4075
Batch 100, Loss: 1.3265
Batch 110, Loss: 1.3561
Batch 120, Loss: 1.3571
Batch 130, Loss: 1.3555
Batch 140, Loss: 1.3187
Batch 150, Loss: 1.3573
Batch 160, Loss: 1.4090
Batch 170, Loss: 1.2987
Batch 180, Loss: 1.4033
Batch 190, Loss: 1.3487
Batch 200, Loss: 1.2954
Batch 210, Loss: 1.3755
Batch 220, Loss: 1.3344
Batch 230, Loss: 1.3378
Batch 240, Loss: 1.3807
Batch 250, Loss: 1.3716
Batch 260, Loss: 1.2925
Batch 270, Loss: 1.3760
Batch 280, Loss: 1.3449
Batch 290, Loss: 1.3612
Batch 300, Loss: 1.3726
Batch 310, Loss: 1.4358
Batch 320, Loss: 1.3452
Batch 330, Loss: 1.4086
Batch 340, Loss: 1.4259
Batch 350, Loss: 1.4327
Batch 360, Loss: 1.4294
Batch 370, Loss: 1.4269
Batch 380, Loss: 1.3823
Batch 390, Loss: 1.3473
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.24948763847351 seconds
Epoch 58 accuracy: 59.45%
Batch 10, Loss: 1.2728
Batch 20, Loss: 1.3295
Batch 30, Loss: 1.3377
Batch 40, Loss: 1.3294
Batch 50, Loss: 1.2687
Batch 60, Loss: 1.2819
Batch 70, Loss: 1.2951
Batch 80, Loss: 1.3164
Batch 90, Loss: 1.3764
Batch 100, Loss: 1.3294
Batch 110, Loss: 1.3637
Batch 120, Loss: 1.3239
Batch 130, Loss: 1.2780
Batch 140, Loss: 1.2904
Batch 150, Loss: 1.4271
Batch 160, Loss: 1.3625
Batch 170, Loss: 1.3131
Batch 180, Loss: 1.3358
Batch 190, Loss: 1.3453
Batch 200, Loss: 1.3520
Batch 210, Loss: 1.2965
Batch 220, Loss: 1.3689
Batch 230, Loss: 1.3133
Batch 240, Loss: 1.4426
Batch 250, Loss: 1.3621
Batch 260, Loss: 1.4176
Batch 270, Loss: 1.3877
Batch 280, Loss: 1.3508
Batch 290, Loss: 1.4042
Batch 300, Loss: 1.3583
Batch 310, Loss: 1.3623
Batch 320, Loss: 1.3207
Batch 330, Loss: 1.3681
Batch 340, Loss: 1.3563
Batch 350, Loss: 1.3663
Batch 360, Loss: 1.3516
Batch 370, Loss: 1.3192
Batch 380, Loss: 1.3919
Batch 390, Loss: 1.4269
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.32110905647278 seconds
Epoch 59 accuracy: 60.3%
Batch 10, Loss: 1.3759
Batch 20, Loss: 1.2908
Batch 30, Loss: 1.3350
Batch 40, Loss: 1.2678
Batch 50, Loss: 1.3117
Batch 60, Loss: 1.2801
Batch 70, Loss: 1.3370
Batch 80, Loss: 1.2944
Batch 90, Loss: 1.3551
Batch 100, Loss: 1.3819
Batch 110, Loss: 1.3782
Batch 120, Loss: 1.3542
Batch 130, Loss: 1.3785
Batch 140, Loss: 1.3086
Batch 150, Loss: 1.3240
Batch 160, Loss: 1.3979
Batch 170, Loss: 1.3628
Batch 180, Loss: 1.3241
Batch 190, Loss: 1.3838
Batch 200, Loss: 1.3203
Batch 210, Loss: 1.3276
Batch 220, Loss: 1.4003
Batch 230, Loss: 1.4006
Batch 240, Loss: 1.3060
Batch 250, Loss: 1.3413
Batch 260, Loss: 1.3437
Batch 270, Loss: 1.3629
Batch 280, Loss: 1.3779
Batch 290, Loss: 1.3549
Batch 300, Loss: 1.3649
Batch 310, Loss: 1.3643
Batch 320, Loss: 1.3710
Batch 330, Loss: 1.3584
Batch 340, Loss: 1.3645
Batch 350, Loss: 1.3763
Batch 360, Loss: 1.3569
Batch 370, Loss: 1.3232
Batch 380, Loss: 1.4978
Batch 390, Loss: 1.2783
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.274761199951172 seconds
Epoch 60 accuracy: 60.66%
Batch 10, Loss: 1.3017
Batch 20, Loss: 1.2758
Batch 30, Loss: 1.3539
Batch 40, Loss: 1.3711
Batch 50, Loss: 1.3196
Batch 60, Loss: 1.2511
Batch 70, Loss: 1.3224
Batch 80, Loss: 1.3175
Batch 90, Loss: 1.3153
Batch 100, Loss: 1.3101
Batch 110, Loss: 1.3143
Batch 120, Loss: 1.3265
Batch 130, Loss: 1.3649
Batch 140, Loss: 1.3071
Batch 150, Loss: 1.4110
Batch 160, Loss: 1.3848
Batch 170, Loss: 1.4423
Batch 180, Loss: 1.3713
Batch 190, Loss: 1.3587
Batch 200, Loss: 1.3370
Batch 210, Loss: 1.4153
Batch 220, Loss: 1.3927
Batch 230, Loss: 1.2996
Batch 240, Loss: 1.3193
Batch 250, Loss: 1.3409
Batch 260, Loss: 1.3883
Batch 270, Loss: 1.3750
Batch 280, Loss: 1.3260
Batch 290, Loss: 1.3507
Batch 300, Loss: 1.3845
Batch 310, Loss: 1.3652
Batch 320, Loss: 1.3300
Batch 330, Loss: 1.3928
Batch 340, Loss: 1.2717
Batch 350, Loss: 1.3343
Batch 360, Loss: 1.3216
Batch 370, Loss: 1.3943
Batch 380, Loss: 1.3093
Batch 390, Loss: 1.3324
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.43600583076477 seconds
Epoch 61 accuracy: 60.2%
Batch 10, Loss: 1.2891
Batch 20, Loss: 1.2786
Batch 30, Loss: 1.3335
Batch 40, Loss: 1.3207
Batch 50, Loss: 1.2487
Batch 60, Loss: 1.3366
Batch 70, Loss: 1.3333
Batch 80, Loss: 1.3393
Batch 90, Loss: 1.2719
Batch 100, Loss: 1.3064
Batch 110, Loss: 1.3183
Batch 120, Loss: 1.3795
Batch 130, Loss: 1.3400
Batch 140, Loss: 1.3471
Batch 150, Loss: 1.2781
Batch 160, Loss: 1.3207
Batch 170, Loss: 1.3955
Batch 180, Loss: 1.2676
Batch 190, Loss: 1.2435
Batch 200, Loss: 1.3161
Batch 210, Loss: 1.3178
Batch 220, Loss: 1.3089
Batch 230, Loss: 1.3682
Batch 240, Loss: 1.3584
Batch 250, Loss: 1.3597
Batch 260, Loss: 1.3343
Batch 270, Loss: 1.3795
Batch 280, Loss: 1.3749
Batch 290, Loss: 1.4066
Batch 300, Loss: 1.3659
Batch 310, Loss: 1.3744
Batch 320, Loss: 1.3808
Batch 330, Loss: 1.3652
Batch 340, Loss: 1.3790
Batch 350, Loss: 1.4362
Batch 360, Loss: 1.3149
Batch 370, Loss: 1.3556
Batch 380, Loss: 1.2947
Batch 390, Loss: 1.3170
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.466140031814575 seconds
Epoch 62 accuracy: 59.25%
Batch 10, Loss: 1.3141
Batch 20, Loss: 1.2528
Batch 30, Loss: 1.3404
Batch 40, Loss: 1.2798
Batch 50, Loss: 1.3166
Batch 60, Loss: 1.2898
Batch 70, Loss: 1.3530
Batch 80, Loss: 1.2902
Batch 90, Loss: 1.2439
Batch 100, Loss: 1.3067
Batch 110, Loss: 1.3150
Batch 120, Loss: 1.3371
Batch 130, Loss: 1.3971
Batch 140, Loss: 1.3251
Batch 150, Loss: 1.3478
Batch 160, Loss: 1.3388
Batch 170, Loss: 1.3219
Batch 180, Loss: 1.3564
Batch 190, Loss: 1.3538
Batch 200, Loss: 1.3292
Batch 210, Loss: 1.3731
Batch 220, Loss: 1.2984
Batch 230, Loss: 1.3662
Batch 240, Loss: 1.3524
Batch 250, Loss: 1.3641
Batch 260, Loss: 1.3534
Batch 270, Loss: 1.3435
Batch 280, Loss: 1.3254
Batch 290, Loss: 1.3950
Batch 300, Loss: 1.4070
Batch 310, Loss: 1.3740
Batch 320, Loss: 1.3533
Batch 330, Loss: 1.3532
Batch 340, Loss: 1.3837
Batch 350, Loss: 1.3453
Batch 360, Loss: 1.3330
Batch 370, Loss: 1.4045
Batch 380, Loss: 1.3881
Batch 390, Loss: 1.3828
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.329294443130493 seconds
Epoch 63 accuracy: 61.43%
Batch 10, Loss: 1.2372
Batch 20, Loss: 1.2649
Batch 30, Loss: 1.2545
Batch 40, Loss: 1.2524
Batch 50, Loss: 1.2381
Batch 60, Loss: 1.3269
Batch 70, Loss: 1.3104
Batch 80, Loss: 1.2890
Batch 90, Loss: 1.3425
Batch 100, Loss: 1.3483
Batch 110, Loss: 1.3384
Batch 120, Loss: 1.3107
Batch 130, Loss: 1.3065
Batch 140, Loss: 1.2707
Batch 150, Loss: 1.4007
Batch 160, Loss: 1.3821
Batch 170, Loss: 1.3064
Batch 180, Loss: 1.3624
Batch 190, Loss: 1.3388
Batch 200, Loss: 1.3056
Batch 210, Loss: 1.3265
Batch 220, Loss: 1.2916
Batch 230, Loss: 1.2490
Batch 240, Loss: 1.3302
Batch 250, Loss: 1.4170
Batch 260, Loss: 1.3723
Batch 270, Loss: 1.3642
Batch 280, Loss: 1.3057
Batch 290, Loss: 1.3500
Batch 300, Loss: 1.3751
Batch 310, Loss: 1.4004
Batch 320, Loss: 1.3344
Batch 330, Loss: 1.3303
Batch 340, Loss: 1.3386
Batch 350, Loss: 1.3425
Batch 360, Loss: 1.3633
Batch 370, Loss: 1.4208
Batch 380, Loss: 1.3674
Batch 390, Loss: 1.3610
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.379592180252075 seconds
Epoch 64 accuracy: 60.39%
Batch 10, Loss: 1.2887
Batch 20, Loss: 1.2876
Batch 30, Loss: 1.2572
Batch 40, Loss: 1.2484
Batch 50, Loss: 1.3027
Batch 60, Loss: 1.2872
Batch 70, Loss: 1.2745
Batch 80, Loss: 1.2077
Batch 90, Loss: 1.2710
Batch 100, Loss: 1.3237
Batch 110, Loss: 1.3835
Batch 120, Loss: 1.4079
Batch 130, Loss: 1.3878
Batch 140, Loss: 1.3097
Batch 150, Loss: 1.3584
Batch 160, Loss: 1.2822
Batch 170, Loss: 1.3180
Batch 180, Loss: 1.3272
Batch 190, Loss: 1.3523
Batch 200, Loss: 1.2834
Batch 210, Loss: 1.2793
Batch 220, Loss: 1.3511
Batch 230, Loss: 1.3559
Batch 240, Loss: 1.3058
Batch 250, Loss: 1.3600
Batch 260, Loss: 1.3312
Batch 270, Loss: 1.2844
Batch 280, Loss: 1.3288
Batch 290, Loss: 1.2926
Batch 300, Loss: 1.3630
Batch 310, Loss: 1.3733
Batch 320, Loss: 1.2541
Batch 330, Loss: 1.3051
Batch 340, Loss: 1.3229
Batch 350, Loss: 1.2591
Batch 360, Loss: 1.3634
Batch 370, Loss: 1.3563
Batch 380, Loss: 1.4081
Batch 390, Loss: 1.3418
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.399757146835327 seconds
Epoch 65 accuracy: 59.81%
Batch 10, Loss: 1.3423
Batch 20, Loss: 1.3663
Batch 30, Loss: 1.2389
Batch 40, Loss: 1.2450
Batch 50, Loss: 1.3167
Batch 60, Loss: 1.2824
Batch 70, Loss: 1.3182
Batch 80, Loss: 1.2915
Batch 90, Loss: 1.2193
Batch 100, Loss: 1.2334
Batch 110, Loss: 1.2485
Batch 120, Loss: 1.2733
Batch 130, Loss: 1.2888
Batch 140, Loss: 1.2681
Batch 150, Loss: 1.3498
Batch 160, Loss: 1.3563
Batch 170, Loss: 1.3554
Batch 180, Loss: 1.3478
Batch 190, Loss: 1.3484
Batch 200, Loss: 1.2906
Batch 210, Loss: 1.3090
Batch 220, Loss: 1.2932
Batch 230, Loss: 1.3270
Batch 240, Loss: 1.3545
Batch 250, Loss: 1.2939
Batch 260, Loss: 1.3788
Batch 270, Loss: 1.3371
Batch 280, Loss: 1.4025
Batch 290, Loss: 1.3360
Batch 300, Loss: 1.3065
Batch 310, Loss: 1.4028
Batch 320, Loss: 1.3524
Batch 330, Loss: 1.3175
Batch 340, Loss: 1.3921
Batch 350, Loss: 1.2991
Batch 360, Loss: 1.4218
Batch 370, Loss: 1.4159
Batch 380, Loss: 1.3201
Batch 390, Loss: 1.3387
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.263270378112793 seconds
Epoch 66 accuracy: 59.58%
Batch 10, Loss: 1.2698
Batch 20, Loss: 1.2287
Batch 30, Loss: 1.2700
Batch 40, Loss: 1.2855
Batch 50, Loss: 1.2392
Batch 60, Loss: 1.2963
Batch 70, Loss: 1.2929
Batch 80, Loss: 1.2179
Batch 90, Loss: 1.2668
Batch 100, Loss: 1.3331
Batch 110, Loss: 1.3490
Batch 120, Loss: 1.3229
Batch 130, Loss: 1.3613
Batch 140, Loss: 1.4199
Batch 150, Loss: 1.3499
Batch 160, Loss: 1.3037
Batch 170, Loss: 1.3313
Batch 180, Loss: 1.3717
Batch 190, Loss: 1.2995
Batch 200, Loss: 1.3196
Batch 210, Loss: 1.3737
Batch 220, Loss: 1.2272
Batch 230, Loss: 1.3131
Batch 240, Loss: 1.3515
Batch 250, Loss: 1.3361
Batch 260, Loss: 1.3315
Batch 270, Loss: 1.2599
Batch 280, Loss: 1.2778
Batch 290, Loss: 1.3311
Batch 300, Loss: 1.2950
Batch 310, Loss: 1.3560
Batch 320, Loss: 1.3503
Batch 330, Loss: 1.3636
Batch 340, Loss: 1.3194
Batch 350, Loss: 1.3014
Batch 360, Loss: 1.3324
Batch 370, Loss: 1.2821
Batch 380, Loss: 1.3588
Batch 390, Loss: 1.3819
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 26.058346033096313 seconds
Epoch 67 accuracy: 60.0%
Batch 10, Loss: 1.2393
Batch 20, Loss: 1.2643
Batch 30, Loss: 1.2323
Batch 40, Loss: 1.2455
Batch 50, Loss: 1.3147
Batch 60, Loss: 1.1960
Batch 70, Loss: 1.2814
Batch 80, Loss: 1.3548
Batch 90, Loss: 1.3457
Batch 100, Loss: 1.2589
Batch 110, Loss: 1.2781
Batch 120, Loss: 1.2545
Batch 130, Loss: 1.3060
Batch 140, Loss: 1.3962
Batch 150, Loss: 1.3216
Batch 160, Loss: 1.3501
Batch 170, Loss: 1.3346
Batch 180, Loss: 1.3072
Batch 190, Loss: 1.3058
Batch 200, Loss: 1.2803
Batch 210, Loss: 1.3225
Batch 220, Loss: 1.3714
Batch 230, Loss: 1.2691
Batch 240, Loss: 1.2624
Batch 250, Loss: 1.2701
Batch 260, Loss: 1.3150
Batch 270, Loss: 1.3246
Batch 280, Loss: 1.3121
Batch 290, Loss: 1.3823
Batch 300, Loss: 1.2919
Batch 310, Loss: 1.3122
Batch 320, Loss: 1.3491
Batch 330, Loss: 1.3207
Batch 340, Loss: 1.3357
Batch 350, Loss: 1.2866
Batch 360, Loss: 1.3413
Batch 370, Loss: 1.3021
Batch 380, Loss: 1.2779
Batch 390, Loss: 1.3814
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.344771146774292 seconds
Epoch 68 accuracy: 59.62%
Batch 10, Loss: 1.2894
Batch 20, Loss: 1.2766
Batch 30, Loss: 1.2920
Batch 40, Loss: 1.2907
Batch 50, Loss: 1.2927
Batch 60, Loss: 1.2783
Batch 70, Loss: 1.2323
Batch 80, Loss: 1.1980
Batch 90, Loss: 1.3570
Batch 100, Loss: 1.2911
Batch 110, Loss: 1.3235
Batch 120, Loss: 1.2890
Batch 130, Loss: 1.3182
Batch 140, Loss: 1.2795
Batch 150, Loss: 1.2613
Batch 160, Loss: 1.2936
Batch 170, Loss: 1.2533
Batch 180, Loss: 1.3256
Batch 190, Loss: 1.2556
Batch 200, Loss: 1.2711
Batch 210, Loss: 1.3143
Batch 220, Loss: 1.2461
Batch 230, Loss: 1.3737
Batch 240, Loss: 1.3381
Batch 250, Loss: 1.3737
Batch 260, Loss: 1.3398
Batch 270, Loss: 1.3381
Batch 280, Loss: 1.3116
Batch 290, Loss: 1.2726
Batch 300, Loss: 1.3122
Batch 310, Loss: 1.3178
Batch 320, Loss: 1.3028
Batch 330, Loss: 1.2886
Batch 340, Loss: 1.2821
Batch 350, Loss: 1.3247
Batch 360, Loss: 1.3825
Batch 370, Loss: 1.3559
Batch 380, Loss: 1.3155
Batch 390, Loss: 1.3108
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.32173228263855 seconds
Epoch 69 accuracy: 61.55%
Batch 10, Loss: 1.1808
Batch 20, Loss: 1.2414
Batch 30, Loss: 1.2703
Batch 40, Loss: 1.2422
Batch 50, Loss: 1.2310
Batch 60, Loss: 1.2928
Batch 70, Loss: 1.1834
Batch 80, Loss: 1.2551
Batch 90, Loss: 1.3025
Batch 100, Loss: 1.2728
Batch 110, Loss: 1.2983
Batch 120, Loss: 1.3514
Batch 130, Loss: 1.2219
Batch 140, Loss: 1.2486
Batch 150, Loss: 1.2676
Batch 160, Loss: 1.3324
Batch 170, Loss: 1.2760
Batch 180, Loss: 1.3169
Batch 190, Loss: 1.2699
Batch 200, Loss: 1.3682
Batch 210, Loss: 1.3516
Batch 220, Loss: 1.3122
Batch 230, Loss: 1.3307
Batch 240, Loss: 1.3388
Batch 250, Loss: 1.3348
Batch 260, Loss: 1.2978
Batch 270, Loss: 1.3172
Batch 280, Loss: 1.3298
Batch 290, Loss: 1.3225
Batch 300, Loss: 1.2890
Batch 310, Loss: 1.3491
Batch 320, Loss: 1.3143
Batch 330, Loss: 1.2848
Batch 340, Loss: 1.3552
Batch 350, Loss: 1.3467
Batch 360, Loss: 1.3154
Batch 370, Loss: 1.3619
Batch 380, Loss: 1.2736
Batch 390, Loss: 1.3124
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.361855030059814 seconds
Epoch 70 accuracy: 58.78%
Batch 10, Loss: 1.2915
Batch 20, Loss: 1.3479
Batch 30, Loss: 1.3249
Batch 40, Loss: 1.2249
Batch 50, Loss: 1.2603
Batch 60, Loss: 1.1930
Batch 70, Loss: 1.2968
Batch 80, Loss: 1.2617
Batch 90, Loss: 1.2824
Batch 100, Loss: 1.2695
Batch 110, Loss: 1.3258
Batch 120, Loss: 1.2671
Batch 130, Loss: 1.2730
Batch 140, Loss: 1.2835
Batch 150, Loss: 1.2931
Batch 160, Loss: 1.2233
Batch 170, Loss: 1.3689
Batch 180, Loss: 1.2836
Batch 190, Loss: 1.2945
Batch 200, Loss: 1.2718
Batch 210, Loss: 1.3410
Batch 220, Loss: 1.3265
Batch 230, Loss: 1.2745
Batch 240, Loss: 1.2872
Batch 250, Loss: 1.2334
Batch 260, Loss: 1.3079
Batch 270, Loss: 1.2702
Batch 280, Loss: 1.3252
Batch 290, Loss: 1.2989
Batch 300, Loss: 1.3035
Batch 310, Loss: 1.3254
Batch 320, Loss: 1.2923
Batch 330, Loss: 1.3130
Batch 340, Loss: 1.3117
Batch 350, Loss: 1.2631
Batch 360, Loss: 1.3516
Batch 370, Loss: 1.2847
Batch 380, Loss: 1.3706
Batch 390, Loss: 1.2901
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.347211360931396 seconds
Epoch 71 accuracy: 63.14%
Batch 10, Loss: 1.2723
Batch 20, Loss: 1.2213
Batch 30, Loss: 1.2529
Batch 40, Loss: 1.2481
Batch 50, Loss: 1.1973
Batch 60, Loss: 1.2226
Batch 70, Loss: 1.2305
Batch 80, Loss: 1.2348
Batch 90, Loss: 1.2558
Batch 100, Loss: 1.2514
Batch 110, Loss: 1.2995
Batch 120, Loss: 1.3226
Batch 130, Loss: 1.2778
Batch 140, Loss: 1.3090
Batch 150, Loss: 1.2580
Batch 160, Loss: 1.2761
Batch 170, Loss: 1.2902
Batch 180, Loss: 1.3270
Batch 190, Loss: 1.3593
Batch 200, Loss: 1.2785
Batch 210, Loss: 1.3728
Batch 220, Loss: 1.3510
Batch 230, Loss: 1.2960
Batch 240, Loss: 1.3203
Batch 250, Loss: 1.2949
Batch 260, Loss: 1.2251
Batch 270, Loss: 1.1922
Batch 280, Loss: 1.3359
Batch 290, Loss: 1.3187
Batch 300, Loss: 1.3492
Batch 310, Loss: 1.3061
Batch 320, Loss: 1.2871
Batch 330, Loss: 1.3262
Batch 340, Loss: 1.2699
Batch 350, Loss: 1.3239
Batch 360, Loss: 1.2982
Batch 370, Loss: 1.3143
Batch 380, Loss: 1.2579
Batch 390, Loss: 1.2887
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.357765436172485 seconds
Epoch 72 accuracy: 60.04%
Batch 10, Loss: 1.2686
Batch 20, Loss: 1.2761
Batch 30, Loss: 1.2368
Batch 40, Loss: 1.2844
Batch 50, Loss: 1.2137
Batch 60, Loss: 1.2242
Batch 70, Loss: 1.2486
Batch 80, Loss: 1.2377
Batch 90, Loss: 1.2530
Batch 100, Loss: 1.2904
Batch 110, Loss: 1.2390
Batch 120, Loss: 1.2706
Batch 130, Loss: 1.2170
Batch 140, Loss: 1.3012
Batch 150, Loss: 1.2974
Batch 160, Loss: 1.3000
Batch 170, Loss: 1.3046
Batch 180, Loss: 1.2464
Batch 190, Loss: 1.2749
Batch 200, Loss: 1.2737
Batch 210, Loss: 1.2294
Batch 220, Loss: 1.2859
Batch 230, Loss: 1.2943
Batch 240, Loss: 1.2972
Batch 250, Loss: 1.3666
Batch 260, Loss: 1.3556
Batch 270, Loss: 1.2461
Batch 280, Loss: 1.2983
Batch 290, Loss: 1.3144
Batch 300, Loss: 1.3088
Batch 310, Loss: 1.2735
Batch 320, Loss: 1.3644
Batch 330, Loss: 1.3730
Batch 340, Loss: 1.3635
Batch 350, Loss: 1.3341
Batch 360, Loss: 1.2848
Batch 370, Loss: 1.3300
Batch 380, Loss: 1.2872
Batch 390, Loss: 1.2524
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.30106520652771 seconds
Epoch 73 accuracy: 61.9%
Batch 10, Loss: 1.1941
Batch 20, Loss: 1.2435
Batch 30, Loss: 1.2778
Batch 40, Loss: 1.2169
Batch 50, Loss: 1.2287
Batch 60, Loss: 1.2269
Batch 70, Loss: 1.2032
Batch 80, Loss: 1.2774
Batch 90, Loss: 1.2597
Batch 100, Loss: 1.2750
Batch 110, Loss: 1.2764
Batch 120, Loss: 1.2711
Batch 130, Loss: 1.2336
Batch 140, Loss: 1.2971
Batch 150, Loss: 1.2193
Batch 160, Loss: 1.2642
Batch 170, Loss: 1.1813
Batch 180, Loss: 1.2784
Batch 190, Loss: 1.3171
Batch 200, Loss: 1.2445
Batch 210, Loss: 1.2919
Batch 220, Loss: 1.3170
Batch 230, Loss: 1.2753
Batch 240, Loss: 1.2756
Batch 250, Loss: 1.2961
Batch 260, Loss: 1.2966
Batch 270, Loss: 1.2443
Batch 280, Loss: 1.3722
Batch 290, Loss: 1.3128
Batch 300, Loss: 1.3157
Batch 310, Loss: 1.2969
Batch 320, Loss: 1.3290
Batch 330, Loss: 1.2929
Batch 340, Loss: 1.3492
Batch 350, Loss: 1.2947
Batch 360, Loss: 1.3172
Batch 370, Loss: 1.2893
Batch 380, Loss: 1.2926
Batch 390, Loss: 1.2981
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.347404718399048 seconds
Epoch 74 accuracy: 62.67%
Batch 10, Loss: 1.1935
Batch 20, Loss: 1.2193
Batch 30, Loss: 1.2348
Batch 40, Loss: 1.1818
Batch 50, Loss: 1.1907
Batch 60, Loss: 1.2096
Batch 70, Loss: 1.2739
Batch 80, Loss: 1.2213
Batch 90, Loss: 1.2097
Batch 100, Loss: 1.2439
Batch 110, Loss: 1.3009
Batch 120, Loss: 1.2392
Batch 130, Loss: 1.3080
Batch 140, Loss: 1.2142
Batch 150, Loss: 1.2887
Batch 160, Loss: 1.2863
Batch 170, Loss: 1.2240
Batch 180, Loss: 1.3633
Batch 190, Loss: 1.3138
Batch 200, Loss: 1.2628
Batch 210, Loss: 1.2406
Batch 220, Loss: 1.2997
Batch 230, Loss: 1.2634
Batch 240, Loss: 1.2426
Batch 250, Loss: 1.3511
Batch 260, Loss: 1.2585
Batch 270, Loss: 1.2562
Batch 280, Loss: 1.3544
Batch 290, Loss: 1.3209
Batch 300, Loss: 1.2418
Batch 310, Loss: 1.2893
Batch 320, Loss: 1.2532
Batch 330, Loss: 1.3073
Batch 340, Loss: 1.3011
Batch 350, Loss: 1.3359
Batch 360, Loss: 1.2841
Batch 370, Loss: 1.3490
Batch 380, Loss: 1.3179
Batch 390, Loss: 1.3024
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.39298939704895 seconds
Epoch 75 accuracy: 63.11%
Batch 10, Loss: 1.1997
Batch 20, Loss: 1.2297
Batch 30, Loss: 1.3313
Batch 40, Loss: 1.2223
Batch 50, Loss: 1.1953
Batch 60, Loss: 1.2942
Batch 70, Loss: 1.2331
Batch 80, Loss: 1.2952
Batch 90, Loss: 1.2371
Batch 100, Loss: 1.2131
Batch 110, Loss: 1.2115
Batch 120, Loss: 1.2054
Batch 130, Loss: 1.2864
Batch 140, Loss: 1.1918
Batch 150, Loss: 1.3201
Batch 160, Loss: 1.2343
Batch 170, Loss: 1.3030
Batch 180, Loss: 1.2725
Batch 190, Loss: 1.2383
Batch 200, Loss: 1.2517
Batch 210, Loss: 1.2747
Batch 220, Loss: 1.2737
Batch 230, Loss: 1.2549
Batch 240, Loss: 1.2402
Batch 250, Loss: 1.2424
Batch 260, Loss: 1.2358
Batch 270, Loss: 1.2608
Batch 280, Loss: 1.2336
Batch 290, Loss: 1.2582
Batch 300, Loss: 1.2761
Batch 310, Loss: 1.2680
Batch 320, Loss: 1.2654
Batch 330, Loss: 1.3167
Batch 340, Loss: 1.2108
Batch 350, Loss: 1.3169
Batch 360, Loss: 1.3437
Batch 370, Loss: 1.3214
Batch 380, Loss: 1.2061
Batch 390, Loss: 1.2600
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.479953289031982 seconds
Epoch 76 accuracy: 61.54%
Batch 10, Loss: 1.2286
Batch 20, Loss: 1.2265
Batch 30, Loss: 1.2142
Batch 40, Loss: 1.2259
Batch 50, Loss: 1.2433
Batch 60, Loss: 1.1679
Batch 70, Loss: 1.2234
Batch 80, Loss: 1.2254
Batch 90, Loss: 1.2439
Batch 100, Loss: 1.2475
Batch 110, Loss: 1.2605
Batch 120, Loss: 1.2498
Batch 130, Loss: 1.2394
Batch 140, Loss: 1.2528
Batch 150, Loss: 1.2955
Batch 160, Loss: 1.3201
Batch 170, Loss: 1.2559
Batch 180, Loss: 1.2179
Batch 190, Loss: 1.3331
Batch 200, Loss: 1.2650
Batch 210, Loss: 1.2898
Batch 220, Loss: 1.2921
Batch 230, Loss: 1.2554
Batch 240, Loss: 1.3045
Batch 250, Loss: 1.2086
Batch 260, Loss: 1.2298
Batch 270, Loss: 1.2997
Batch 280, Loss: 1.2692
Batch 290, Loss: 1.2874
Batch 300, Loss: 1.3290
Batch 310, Loss: 1.3630
Batch 320, Loss: 1.3383
Batch 330, Loss: 1.2603
Batch 340, Loss: 1.2309
Batch 350, Loss: 1.3348
Batch 360, Loss: 1.2686
Batch 370, Loss: 1.2600
Batch 380, Loss: 1.3036
Batch 390, Loss: 1.2688
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.303791999816895 seconds
Epoch 77 accuracy: 59.73%
Batch 10, Loss: 1.2246
Batch 20, Loss: 1.2046
Batch 30, Loss: 1.2373
Batch 40, Loss: 1.1656
Batch 50, Loss: 1.1693
Batch 60, Loss: 1.1803
Batch 70, Loss: 1.2031
Batch 80, Loss: 1.2375
Batch 90, Loss: 1.2321
Batch 100, Loss: 1.2492
Batch 110, Loss: 1.2117
Batch 120, Loss: 1.1752
Batch 130, Loss: 1.2455
Batch 140, Loss: 1.2762
Batch 150, Loss: 1.2509
Batch 160, Loss: 1.2054
Batch 170, Loss: 1.2686
Batch 180, Loss: 1.3049
Batch 190, Loss: 1.2550
Batch 200, Loss: 1.2446
Batch 210, Loss: 1.2588
Batch 220, Loss: 1.1773
Batch 230, Loss: 1.2340
Batch 240, Loss: 1.2405
Batch 250, Loss: 1.3407
Batch 260, Loss: 1.2564
Batch 270, Loss: 1.1805
Batch 280, Loss: 1.2967
Batch 290, Loss: 1.2303
Batch 300, Loss: 1.2763
Batch 310, Loss: 1.2760
Batch 320, Loss: 1.3056
Batch 330, Loss: 1.3152
Batch 340, Loss: 1.2812
Batch 350, Loss: 1.2912
Batch 360, Loss: 1.2389
Batch 370, Loss: 1.2646
Batch 380, Loss: 1.2373
Batch 390, Loss: 1.2592
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.39753746986389 seconds
Epoch 78 accuracy: 59.82%
Batch 10, Loss: 1.2557
Batch 20, Loss: 1.2252
Batch 30, Loss: 1.1984
Batch 40, Loss: 1.2316
Batch 50, Loss: 1.2637
Batch 60, Loss: 1.1713
Batch 70, Loss: 1.2017
Batch 80, Loss: 1.2595
Batch 90, Loss: 1.2492
Batch 100, Loss: 1.1791
Batch 110, Loss: 1.1909
Batch 120, Loss: 1.1995
Batch 130, Loss: 1.2562
Batch 140, Loss: 1.3047
Batch 150, Loss: 1.2064
Batch 160, Loss: 1.3030
Batch 170, Loss: 1.1181
Batch 180, Loss: 1.2059
Batch 190, Loss: 1.2844
Batch 200, Loss: 1.2483
Batch 210, Loss: 1.1855
Batch 220, Loss: 1.2197
Batch 230, Loss: 1.3051
Batch 240, Loss: 1.2328
Batch 250, Loss: 1.2169
Batch 260, Loss: 1.2512
Batch 270, Loss: 1.2126
Batch 280, Loss: 1.3018
Batch 290, Loss: 1.2549
Batch 300, Loss: 1.2741
Batch 310, Loss: 1.3108
Batch 320, Loss: 1.2871
Batch 330, Loss: 1.2721
Batch 340, Loss: 1.2416
Batch 350, Loss: 1.3163
Batch 360, Loss: 1.2328
Batch 370, Loss: 1.3329
Batch 380, Loss: 1.3158
Batch 390, Loss: 1.2478
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.44483518600464 seconds
Epoch 79 accuracy: 63.76%
Batch 10, Loss: 1.2020
Batch 20, Loss: 1.1581
Batch 30, Loss: 1.1366
Batch 40, Loss: 1.2154
Batch 50, Loss: 1.1854
Batch 60, Loss: 1.1573
Batch 70, Loss: 1.1804
Batch 80, Loss: 1.2140
Batch 90, Loss: 1.2220
Batch 100, Loss: 1.2324
Batch 110, Loss: 1.2476
Batch 120, Loss: 1.2141
Batch 130, Loss: 1.2187
Batch 140, Loss: 1.2418
Batch 150, Loss: 1.3069
Batch 160, Loss: 1.2405
Batch 170, Loss: 1.2741
Batch 180, Loss: 1.1847
Batch 190, Loss: 1.2789
Batch 200, Loss: 1.2644
Batch 210, Loss: 1.2003
Batch 220, Loss: 1.2039
Batch 230, Loss: 1.1844
Batch 240, Loss: 1.2464
Batch 250, Loss: 1.2163
Batch 260, Loss: 1.2683
Batch 270, Loss: 1.2786
Batch 280, Loss: 1.2585
Batch 290, Loss: 1.2462
Batch 300, Loss: 1.2531
Batch 310, Loss: 1.2636
Batch 320, Loss: 1.2282
Batch 330, Loss: 1.3325
Batch 340, Loss: 1.2691
Batch 350, Loss: 1.2987
Batch 360, Loss: 1.1794
Batch 370, Loss: 1.2514
Batch 380, Loss: 1.3168
Batch 390, Loss: 1.2300
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.421981811523438 seconds
Epoch 80 accuracy: 61.95%
Batch 10, Loss: 1.1470
Batch 20, Loss: 1.1719
Batch 30, Loss: 1.1976
Batch 40, Loss: 1.1946
Batch 50, Loss: 1.2424
Batch 60, Loss: 1.1957
Batch 70, Loss: 1.2299
Batch 80, Loss: 1.2456
Batch 90, Loss: 1.1825
Batch 100, Loss: 1.2280
Batch 110, Loss: 1.2469
Batch 120, Loss: 1.2362
Batch 130, Loss: 1.2959
Batch 140, Loss: 1.1969
Batch 150, Loss: 1.2327
Batch 160, Loss: 1.2334
Batch 170, Loss: 1.2700
Batch 180, Loss: 1.2550
Batch 190, Loss: 1.1857
Batch 200, Loss: 1.2141
Batch 210, Loss: 1.1810
Batch 220, Loss: 1.2365
Batch 230, Loss: 1.3209
Batch 240, Loss: 1.1978
Batch 250, Loss: 1.2369
Batch 260, Loss: 1.2449
Batch 270, Loss: 1.2487
Batch 280, Loss: 1.2191
Batch 290, Loss: 1.2355
Batch 300, Loss: 1.1898
Batch 310, Loss: 1.2352
Batch 320, Loss: 1.2590
Batch 330, Loss: 1.2489
Batch 340, Loss: 1.2181
Batch 350, Loss: 1.2591
Batch 360, Loss: 1.2629
Batch 370, Loss: 1.2498
Batch 380, Loss: 1.2404
Batch 390, Loss: 1.2609
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.371087789535522 seconds
Epoch 81 accuracy: 62.05%
Batch 10, Loss: 1.1693
Batch 20, Loss: 1.2052
Batch 30, Loss: 1.2021
Batch 40, Loss: 1.1681
Batch 50, Loss: 1.2741
Batch 60, Loss: 1.2472
Batch 70, Loss: 1.2339
Batch 80, Loss: 1.1624
Batch 90, Loss: 1.2213
Batch 100, Loss: 1.2266
Batch 110, Loss: 1.1969
Batch 120, Loss: 1.2447
Batch 130, Loss: 1.2434
Batch 140, Loss: 1.2505
Batch 150, Loss: 1.2093
Batch 160, Loss: 1.2746
Batch 170, Loss: 1.1990
Batch 180, Loss: 1.2302
Batch 190, Loss: 1.2703
Batch 200, Loss: 1.2493
Batch 210, Loss: 1.2128
Batch 220, Loss: 1.2886
Batch 230, Loss: 1.2362
Batch 240, Loss: 1.2273
Batch 250, Loss: 1.2008
Batch 260, Loss: 1.2014
Batch 270, Loss: 1.2527
Batch 280, Loss: 1.2696
Batch 290, Loss: 1.1860
Batch 300, Loss: 1.2967
Batch 310, Loss: 1.2213
Batch 320, Loss: 1.2869
Batch 330, Loss: 1.3085
Batch 340, Loss: 1.2788
Batch 350, Loss: 1.2461
Batch 360, Loss: 1.2087
Batch 370, Loss: 1.2539
Batch 380, Loss: 1.2668
Batch 390, Loss: 1.2081
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.353638172149658 seconds
Epoch 82 accuracy: 64.39%
Batch 10, Loss: 1.1766
Batch 20, Loss: 1.1269
Batch 30, Loss: 1.1670
Batch 40, Loss: 1.1787
Batch 50, Loss: 1.1917
Batch 60, Loss: 1.2098
Batch 70, Loss: 1.2487
Batch 80, Loss: 1.2276
Batch 90, Loss: 1.1773
Batch 100, Loss: 1.2865
Batch 110, Loss: 1.1823
Batch 120, Loss: 1.1526
Batch 130, Loss: 1.1994
Batch 140, Loss: 1.1912
Batch 150, Loss: 1.2188
Batch 160, Loss: 1.1922
Batch 170, Loss: 1.2493
Batch 180, Loss: 1.1644
Batch 190, Loss: 1.2349
Batch 200, Loss: 1.1988
Batch 210, Loss: 1.2155
Batch 220, Loss: 1.2566
Batch 230, Loss: 1.2488
Batch 240, Loss: 1.2372
Batch 250, Loss: 1.2526
Batch 260, Loss: 1.2302
Batch 270, Loss: 1.2656
Batch 280, Loss: 1.2755
Batch 290, Loss: 1.2471
Batch 300, Loss: 1.2199
Batch 310, Loss: 1.2369
Batch 320, Loss: 1.2631
Batch 330, Loss: 1.2291
Batch 340, Loss: 1.2132
Batch 350, Loss: 1.2977
Batch 360, Loss: 1.2431
Batch 370, Loss: 1.2321
Batch 380, Loss: 1.2980
Batch 390, Loss: 1.2803
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.460668087005615 seconds
Epoch 83 accuracy: 61.71%
Batch 10, Loss: 1.1246
Batch 20, Loss: 1.2020
Batch 30, Loss: 1.1375
Batch 40, Loss: 1.2109
Batch 50, Loss: 1.1960
Batch 60, Loss: 1.1647
Batch 70, Loss: 1.1763
Batch 80, Loss: 1.1925
Batch 90, Loss: 1.2074
Batch 100, Loss: 1.2176
Batch 110, Loss: 1.2091
Batch 120, Loss: 1.1096
Batch 130, Loss: 1.2675
Batch 140, Loss: 1.2155
Batch 150, Loss: 1.2512
Batch 160, Loss: 1.2173
Batch 170, Loss: 1.1088
Batch 180, Loss: 1.1863
Batch 190, Loss: 1.1990
Batch 200, Loss: 1.2041
Batch 210, Loss: 1.2272
Batch 220, Loss: 1.2139
Batch 230, Loss: 1.1992
Batch 240, Loss: 1.2460
Batch 250, Loss: 1.2893
Batch 260, Loss: 1.1624
Batch 270, Loss: 1.2680
Batch 280, Loss: 1.2417
Batch 290, Loss: 1.2399
Batch 300, Loss: 1.2744
Batch 310, Loss: 1.1950
Batch 320, Loss: 1.2052
Batch 330, Loss: 1.2283
Batch 340, Loss: 1.1985
Batch 350, Loss: 1.2298
Batch 360, Loss: 1.1604
Batch 370, Loss: 1.2305
Batch 380, Loss: 1.2068
Batch 390, Loss: 1.2608
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.438175678253174 seconds
Epoch 84 accuracy: 62.66%
Batch 10, Loss: 1.1958
Batch 20, Loss: 1.2006
Batch 30, Loss: 1.2198
Batch 40, Loss: 1.1739
Batch 50, Loss: 1.2384
Batch 60, Loss: 1.2102
Batch 70, Loss: 1.1968
Batch 80, Loss: 1.1886
Batch 90, Loss: 1.1868
Batch 100, Loss: 1.1759
Batch 110, Loss: 1.1544
Batch 120, Loss: 1.2837
Batch 130, Loss: 1.2101
Batch 140, Loss: 1.1316
Batch 150, Loss: 1.1614
Batch 160, Loss: 1.1903
Batch 170, Loss: 1.2204
Batch 180, Loss: 1.2381
Batch 190, Loss: 1.2082
Batch 200, Loss: 1.2471
Batch 210, Loss: 1.1950
Batch 220, Loss: 1.2234
Batch 230, Loss: 1.1616
Batch 240, Loss: 1.2775
Batch 250, Loss: 1.1741
Batch 260, Loss: 1.2412
Batch 270, Loss: 1.1555
Batch 280, Loss: 1.1816
Batch 290, Loss: 1.2304
Batch 300, Loss: 1.2121
Batch 310, Loss: 1.1864
Batch 320, Loss: 1.2774
Batch 330, Loss: 1.2149
Batch 340, Loss: 1.2251
Batch 350, Loss: 1.2559
Batch 360, Loss: 1.2209
Batch 370, Loss: 1.2090
Batch 380, Loss: 1.2586
Batch 390, Loss: 1.2849
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.297728300094604 seconds
Epoch 85 accuracy: 61.85%
Batch 10, Loss: 1.1383
Batch 20, Loss: 1.1463
Batch 30, Loss: 1.1826
Batch 40, Loss: 1.1117
Batch 50, Loss: 1.0914
Batch 60, Loss: 1.1337
Batch 70, Loss: 1.0953
Batch 80, Loss: 1.1353
Batch 90, Loss: 1.1380
Batch 100, Loss: 1.1327
Batch 110, Loss: 1.1170
Batch 120, Loss: 1.2169
Batch 130, Loss: 1.2601
Batch 140, Loss: 1.2787
Batch 150, Loss: 1.2190
Batch 160, Loss: 1.2375
Batch 170, Loss: 1.2504
Batch 180, Loss: 1.2286
Batch 190, Loss: 1.2354
Batch 200, Loss: 1.2505
Batch 210, Loss: 1.2453
Batch 220, Loss: 1.2102
Batch 230, Loss: 1.2299
Batch 240, Loss: 1.2001
Batch 250, Loss: 1.2122
Batch 260, Loss: 1.1936
Batch 270, Loss: 1.2648
Batch 280, Loss: 1.1725
Batch 290, Loss: 1.1875
Batch 300, Loss: 1.2564
Batch 310, Loss: 1.2774
Batch 320, Loss: 1.1586
Batch 330, Loss: 1.2405
Batch 340, Loss: 1.2221
Batch 350, Loss: 1.1869
Batch 360, Loss: 1.2158
Batch 370, Loss: 1.2403
Batch 380, Loss: 1.2440
Batch 390, Loss: 1.2131
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.359753370285034 seconds
Epoch 86 accuracy: 58.43%
Batch 10, Loss: 1.1591
Batch 20, Loss: 1.1483
Batch 30, Loss: 1.1564
Batch 40, Loss: 1.1497
Batch 50, Loss: 1.1983
Batch 60, Loss: 1.1530
Batch 70, Loss: 1.1501
Batch 80, Loss: 1.2317
Batch 90, Loss: 1.2075
Batch 100, Loss: 1.2290
Batch 110, Loss: 1.0906
Batch 120, Loss: 1.1889
Batch 130, Loss: 1.2126
Batch 140, Loss: 1.2041
Batch 150, Loss: 1.1558
Batch 160, Loss: 1.1779
Batch 170, Loss: 1.1873
Batch 180, Loss: 1.2274
Batch 190, Loss: 1.2470
Batch 200, Loss: 1.2075
Batch 210, Loss: 1.1838
Batch 220, Loss: 1.2325
Batch 230, Loss: 1.2484
Batch 240, Loss: 1.1566
Batch 250, Loss: 1.2779
Batch 260, Loss: 1.2001
Batch 270, Loss: 1.1954
Batch 280, Loss: 1.2012
Batch 290, Loss: 1.1900
Batch 300, Loss: 1.2551
Batch 310, Loss: 1.1896
Batch 320, Loss: 1.1936
Batch 330, Loss: 1.1830
Batch 340, Loss: 1.2061
Batch 350, Loss: 1.1902
Batch 360, Loss: 1.2269
Batch 370, Loss: 1.2231
Batch 380, Loss: 1.2550
Batch 390, Loss: 1.1333
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.368825674057007 seconds
Epoch 87 accuracy: 65.93%
Batch 10, Loss: 1.1652
Batch 20, Loss: 1.1216
Batch 30, Loss: 1.1108
Batch 40, Loss: 1.1498
Batch 50, Loss: 1.1074
Batch 60, Loss: 1.0683
Batch 70, Loss: 1.1859
Batch 80, Loss: 1.1887
Batch 90, Loss: 1.2129
Batch 100, Loss: 1.1886
Batch 110, Loss: 1.2012
Batch 120, Loss: 1.0992
Batch 130, Loss: 1.0817
Batch 140, Loss: 1.2413
Batch 150, Loss: 1.1853
Batch 160, Loss: 1.1799
Batch 170, Loss: 1.1420
Batch 180, Loss: 1.2089
Batch 190, Loss: 1.1871
Batch 200, Loss: 1.1657
Batch 210, Loss: 1.1297
Batch 220, Loss: 1.2478
Batch 230, Loss: 1.2226
Batch 240, Loss: 1.1976
Batch 250, Loss: 1.2330
Batch 260, Loss: 1.2690
Batch 270, Loss: 1.1991
Batch 280, Loss: 1.2548
Batch 290, Loss: 1.1962
Batch 300, Loss: 1.1589
Batch 310, Loss: 1.2401
Batch 320, Loss: 1.1932
Batch 330, Loss: 1.2456
Batch 340, Loss: 1.2134
Batch 350, Loss: 1.2132
Batch 360, Loss: 1.2043
Batch 370, Loss: 1.1752
Batch 380, Loss: 1.2398
Batch 390, Loss: 1.2086
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.420785427093506 seconds
Epoch 88 accuracy: 63.73%
Batch 10, Loss: 1.1323
Batch 20, Loss: 1.1356
Batch 30, Loss: 1.0894
Batch 40, Loss: 1.1389
Batch 50, Loss: 1.1454
Batch 60, Loss: 1.1813
Batch 70, Loss: 1.1307
Batch 80, Loss: 1.1289
Batch 90, Loss: 1.1401
Batch 100, Loss: 1.1945
Batch 110, Loss: 1.1500
Batch 120, Loss: 1.2016
Batch 130, Loss: 1.1720
Batch 140, Loss: 1.1829
Batch 150, Loss: 1.1792
Batch 160, Loss: 1.1891
Batch 170, Loss: 1.2404
Batch 180, Loss: 1.1892
Batch 190, Loss: 1.1967
Batch 200, Loss: 1.1799
Batch 210, Loss: 1.2264
Batch 220, Loss: 1.2548
Batch 230, Loss: 1.1744
Batch 240, Loss: 1.2274
Batch 250, Loss: 1.1958
Batch 260, Loss: 1.2234
Batch 270, Loss: 1.1803
Batch 280, Loss: 1.2366
Batch 290, Loss: 1.2026
Batch 300, Loss: 1.1444
Batch 310, Loss: 1.2425
Batch 320, Loss: 1.1804
Batch 330, Loss: 1.2244
Batch 340, Loss: 1.1197
Batch 350, Loss: 1.1985
Batch 360, Loss: 1.1784
Batch 370, Loss: 1.2060
Batch 380, Loss: 1.1479
Batch 390, Loss: 1.2477
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.333330154418945 seconds
Epoch 89 accuracy: 61.83%
Batch 10, Loss: 1.1300
Batch 20, Loss: 1.1762
Batch 30, Loss: 1.1453
Batch 40, Loss: 1.0968
Batch 50, Loss: 1.1084
Batch 60, Loss: 1.1225
Batch 70, Loss: 1.1635
Batch 80, Loss: 1.1157
Batch 90, Loss: 1.1479
Batch 100, Loss: 1.0763
Batch 110, Loss: 1.1167
Batch 120, Loss: 1.1580
Batch 130, Loss: 1.1594
Batch 140, Loss: 1.1968
Batch 150, Loss: 1.2117
Batch 160, Loss: 1.1772
Batch 170, Loss: 1.2057
Batch 180, Loss: 1.1424
Batch 190, Loss: 1.1625
Batch 200, Loss: 1.1536
Batch 210, Loss: 1.2183
Batch 220, Loss: 1.2313
Batch 230, Loss: 1.2232
Batch 240, Loss: 1.2213
Batch 250, Loss: 1.2041
Batch 260, Loss: 1.2071
Batch 270, Loss: 1.2260
Batch 280, Loss: 1.1759
Batch 290, Loss: 1.1536
Batch 300, Loss: 1.1914
Batch 310, Loss: 1.1921
Batch 320, Loss: 1.2124
Batch 330, Loss: 1.1761
Batch 340, Loss: 1.1942
Batch 350, Loss: 1.2240
Batch 360, Loss: 1.1948
Batch 370, Loss: 1.2163
Batch 380, Loss: 1.1997
Batch 390, Loss: 1.1814
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.377284049987793 seconds
Epoch 90 accuracy: 64.18%
Batch 10, Loss: 1.1100
Batch 20, Loss: 1.0789
Batch 30, Loss: 1.1097
Batch 40, Loss: 1.1351
Batch 50, Loss: 1.1380
Batch 60, Loss: 1.1055
Batch 70, Loss: 1.1179
Batch 80, Loss: 1.1310
Batch 90, Loss: 1.1554
Batch 100, Loss: 1.1441
Batch 110, Loss: 1.1164
Batch 120, Loss: 1.1179
Batch 130, Loss: 1.1226
Batch 140, Loss: 1.1622
Batch 150, Loss: 1.1468
Batch 160, Loss: 1.1687
Batch 170, Loss: 1.1628
Batch 180, Loss: 1.1339
Batch 190, Loss: 1.1927
Batch 200, Loss: 1.2152
Batch 210, Loss: 1.1813
Batch 220, Loss: 1.1507
Batch 230, Loss: 1.2093
Batch 240, Loss: 1.1983
Batch 250, Loss: 1.1515
Batch 260, Loss: 1.1488
Batch 270, Loss: 1.2333
Batch 280, Loss: 1.1991
Batch 290, Loss: 1.1724
Batch 300, Loss: 1.1232
Batch 310, Loss: 1.1543
Batch 320, Loss: 1.1408
Batch 330, Loss: 1.1882
Batch 340, Loss: 1.1709
Batch 350, Loss: 1.1615
Batch 360, Loss: 1.2208
Batch 370, Loss: 1.1853
Batch 380, Loss: 1.2460
Batch 390, Loss: 1.2012
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.37009859085083 seconds
Epoch 91 accuracy: 60.5%
Batch 10, Loss: 1.1131
Batch 20, Loss: 1.1579
Batch 30, Loss: 1.1014
Batch 40, Loss: 1.0393
Batch 50, Loss: 1.1436
Batch 60, Loss: 1.1227
Batch 70, Loss: 1.1748
Batch 80, Loss: 1.1257
Batch 90, Loss: 1.2129
Batch 100, Loss: 1.1962
Batch 110, Loss: 1.0967
Batch 120, Loss: 1.0840
Batch 130, Loss: 1.1013
Batch 140, Loss: 1.1816
Batch 150, Loss: 1.1162
Batch 160, Loss: 1.0955
Batch 170, Loss: 1.1762
Batch 180, Loss: 1.1742
Batch 190, Loss: 1.1939
Batch 200, Loss: 1.1616
Batch 210, Loss: 1.1635
Batch 220, Loss: 1.2090
Batch 230, Loss: 1.2108
Batch 240, Loss: 1.1800
Batch 250, Loss: 1.1362
Batch 260, Loss: 1.2369
Batch 270, Loss: 1.1488
Batch 280, Loss: 1.2304
Batch 290, Loss: 1.1277
Batch 300, Loss: 1.1556
Batch 310, Loss: 1.1864
Batch 320, Loss: 1.1286
Batch 330, Loss: 1.1543
Batch 340, Loss: 1.1947
Batch 350, Loss: 1.1736
Batch 360, Loss: 1.1593
Batch 370, Loss: 1.2226
Batch 380, Loss: 1.2245
Batch 390, Loss: 1.2275
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.450611114501953 seconds
Epoch 92 accuracy: 65.6%
Batch 10, Loss: 1.1431
Batch 20, Loss: 1.0742
Batch 30, Loss: 1.0879
Batch 40, Loss: 1.0929
Batch 50, Loss: 1.0996
Batch 60, Loss: 1.1350
Batch 70, Loss: 1.1752
Batch 80, Loss: 1.1422
Batch 90, Loss: 1.1100
Batch 100, Loss: 1.0870
Batch 110, Loss: 1.1235
Batch 120, Loss: 1.1590
Batch 130, Loss: 1.1829
Batch 140, Loss: 1.1294
Batch 150, Loss: 1.2486
Batch 160, Loss: 1.1251
Batch 170, Loss: 1.1461
Batch 180, Loss: 1.1729
Batch 190, Loss: 1.1121
Batch 200, Loss: 1.1257
Batch 210, Loss: 1.1857
Batch 220, Loss: 1.2036
Batch 230, Loss: 1.1602
Batch 240, Loss: 1.1917
Batch 250, Loss: 1.2334
Batch 260, Loss: 1.1124
Batch 270, Loss: 1.1551
Batch 280, Loss: 1.1799
Batch 290, Loss: 1.1396
Batch 300, Loss: 1.1195
Batch 310, Loss: 1.1099
Batch 320, Loss: 1.1676
Batch 330, Loss: 1.1616
Batch 340, Loss: 1.2272
Batch 350, Loss: 1.2243
Batch 360, Loss: 1.1839
Batch 370, Loss: 1.2001
Batch 380, Loss: 1.1618
Batch 390, Loss: 1.2115
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.39860510826111 seconds
Epoch 93 accuracy: 65.76%
Batch 10, Loss: 1.0813
Batch 20, Loss: 1.1461
Batch 30, Loss: 1.1648
Batch 40, Loss: 1.1695
Batch 50, Loss: 1.0655
Batch 60, Loss: 1.0529
Batch 70, Loss: 1.1079
Batch 80, Loss: 1.1345
Batch 90, Loss: 1.1428
Batch 100, Loss: 1.0882
Batch 110, Loss: 1.1555
Batch 120, Loss: 1.1627
Batch 130, Loss: 1.1575
Batch 140, Loss: 1.0921
Batch 150, Loss: 1.0410
Batch 160, Loss: 1.1240
Batch 170, Loss: 1.1399
Batch 180, Loss: 1.1036
Batch 190, Loss: 1.1465
Batch 200, Loss: 1.1754
Batch 210, Loss: 1.1695
Batch 220, Loss: 1.1062
Batch 230, Loss: 1.1624
Batch 240, Loss: 1.1984
Batch 250, Loss: 1.2754
Batch 260, Loss: 1.2172
Batch 270, Loss: 1.1648
Batch 280, Loss: 1.1306
Batch 290, Loss: 1.1881
Batch 300, Loss: 1.2432
Batch 310, Loss: 1.1739
Batch 320, Loss: 1.2033
Batch 330, Loss: 1.1214
Batch 340, Loss: 1.1405
Batch 350, Loss: 1.1579
Batch 360, Loss: 1.1749
Batch 370, Loss: 1.2082
Batch 380, Loss: 1.2071
Batch 390, Loss: 1.2734
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.413482904434204 seconds
Epoch 94 accuracy: 63.86%
Batch 10, Loss: 1.1001
Batch 20, Loss: 1.0568
Batch 30, Loss: 1.1142
Batch 40, Loss: 1.0644
Batch 50, Loss: 1.0940
Batch 60, Loss: 1.0686
Batch 70, Loss: 1.1354
Batch 80, Loss: 1.1409
Batch 90, Loss: 1.1092
Batch 100, Loss: 1.1316
Batch 110, Loss: 1.0458
Batch 120, Loss: 1.1636
Batch 130, Loss: 1.1398
Batch 140, Loss: 1.1586
Batch 150, Loss: 1.1937
Batch 160, Loss: 1.1701
Batch 170, Loss: 1.2044
Batch 180, Loss: 1.1362
Batch 190, Loss: 1.1601
Batch 200, Loss: 1.1656
Batch 210, Loss: 1.0920
Batch 220, Loss: 1.0856
Batch 230, Loss: 1.1243
Batch 240, Loss: 1.1296
Batch 250, Loss: 1.1641
Batch 260, Loss: 1.1758
Batch 270, Loss: 1.1296
Batch 280, Loss: 1.1852
Batch 290, Loss: 1.1083
Batch 300, Loss: 1.1975
Batch 310, Loss: 1.0804
Batch 320, Loss: 1.1309
Batch 330, Loss: 1.1357
Batch 340, Loss: 1.1879
Batch 350, Loss: 1.1408
Batch 360, Loss: 1.1839
Batch 370, Loss: 1.1688
Batch 380, Loss: 1.2294
Batch 390, Loss: 1.1473
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.502740621566772 seconds
Epoch 95 accuracy: 64.74%
Batch 10, Loss: 1.1049
Batch 20, Loss: 1.1515
Batch 30, Loss: 1.0777
Batch 40, Loss: 1.0543
Batch 50, Loss: 1.0831
Batch 60, Loss: 1.0608
Batch 70, Loss: 1.1512
Batch 80, Loss: 1.0979
Batch 90, Loss: 1.0850
Batch 100, Loss: 1.1327
Batch 110, Loss: 1.0978
Batch 120, Loss: 1.0983
Batch 130, Loss: 1.1066
Batch 140, Loss: 1.1276
Batch 150, Loss: 1.1543
Batch 160, Loss: 1.0817
Batch 170, Loss: 1.1089
Batch 180, Loss: 1.0960
Batch 190, Loss: 1.1281
Batch 200, Loss: 1.1220
Batch 210, Loss: 1.1156
Batch 220, Loss: 1.1815
Batch 230, Loss: 1.1452
Batch 240, Loss: 1.1968
Batch 250, Loss: 1.2119
Batch 260, Loss: 1.1798
Batch 270, Loss: 1.2010
Batch 280, Loss: 1.1732
Batch 290, Loss: 1.1739
Batch 300, Loss: 1.1516
Batch 310, Loss: 1.1535
Batch 320, Loss: 1.2089
Batch 330, Loss: 1.1561
Batch 340, Loss: 1.1401
Batch 350, Loss: 1.1280
Batch 360, Loss: 1.1949
Batch 370, Loss: 1.0863
Batch 380, Loss: 1.1380
Batch 390, Loss: 1.1349
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.355611562728882 seconds
Epoch 96 accuracy: 65.74%
Batch 10, Loss: 1.1013
Batch 20, Loss: 1.0268
Batch 30, Loss: 1.0455
Batch 40, Loss: 1.0888
Batch 50, Loss: 1.1522
Batch 60, Loss: 1.1500
Batch 70, Loss: 1.1698
Batch 80, Loss: 1.0654
Batch 90, Loss: 1.0915
Batch 100, Loss: 1.0614
Batch 110, Loss: 1.1071
Batch 120, Loss: 1.1103
Batch 130, Loss: 1.1154
Batch 140, Loss: 1.1007
Batch 150, Loss: 1.0914
Batch 160, Loss: 1.1527
Batch 170, Loss: 1.1615
Batch 180, Loss: 1.1887
Batch 190, Loss: 1.0913
Batch 200, Loss: 1.1149
Batch 210, Loss: 1.1801
Batch 220, Loss: 1.1364
Batch 230, Loss: 1.1485
Batch 240, Loss: 1.1069
Batch 250, Loss: 1.1420
Batch 260, Loss: 1.1417
Batch 270, Loss: 1.2133
Batch 280, Loss: 1.1270
Batch 290, Loss: 1.1644
Batch 300, Loss: 1.1031
Batch 310, Loss: 1.1329
Batch 320, Loss: 1.1274
Batch 330, Loss: 1.1814
Batch 340, Loss: 1.1149
Batch 350, Loss: 1.0878
Batch 360, Loss: 1.2109
Batch 370, Loss: 1.1779
Batch 380, Loss: 1.1264
Batch 390, Loss: 1.1379
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.336915254592896 seconds
Epoch 97 accuracy: 66.1%
Batch 10, Loss: 1.0651
Batch 20, Loss: 1.1218
Batch 30, Loss: 1.0393
Batch 40, Loss: 1.0774
Batch 50, Loss: 1.0913
Batch 60, Loss: 1.0608
Batch 70, Loss: 1.0695
Batch 80, Loss: 1.0960
Batch 90, Loss: 1.1162
Batch 100, Loss: 1.0758
Batch 110, Loss: 1.0863
Batch 120, Loss: 1.0826
Batch 130, Loss: 1.0743
Batch 140, Loss: 1.1259
Batch 150, Loss: 1.1041
Batch 160, Loss: 1.0578
Batch 170, Loss: 1.1553
Batch 180, Loss: 1.1370
Batch 190, Loss: 1.0718
Batch 200, Loss: 1.1939
Batch 210, Loss: 1.0389
Batch 220, Loss: 1.1248
Batch 230, Loss: 1.1242
Batch 240, Loss: 1.1275
Batch 250, Loss: 1.1614
Batch 260, Loss: 1.1465
Batch 270, Loss: 1.1219
Batch 280, Loss: 1.1178
Batch 290, Loss: 1.1370
Batch 300, Loss: 1.1238
Batch 310, Loss: 1.1432
Batch 320, Loss: 1.1524
Batch 330, Loss: 1.1741
Batch 340, Loss: 1.1675
Batch 350, Loss: 1.0837
Batch 360, Loss: 1.1205
Batch 370, Loss: 1.2374
Batch 380, Loss: 1.1525
Batch 390, Loss: 1.1139
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.411356925964355 seconds
Epoch 98 accuracy: 67.22%
Batch 10, Loss: 1.0287
Batch 20, Loss: 1.0690
Batch 30, Loss: 1.0751
Batch 40, Loss: 1.0607
Batch 50, Loss: 1.0352
Batch 60, Loss: 1.0819
Batch 70, Loss: 1.0327
Batch 80, Loss: 1.0165
Batch 90, Loss: 1.0565
Batch 100, Loss: 1.0122
Batch 110, Loss: 1.1284
Batch 120, Loss: 1.0787
Batch 130, Loss: 1.1122
Batch 140, Loss: 1.1332
Batch 150, Loss: 1.1379
Batch 160, Loss: 1.0533
Batch 170, Loss: 1.1397
Batch 180, Loss: 1.1591
Batch 190, Loss: 1.0893
Batch 200, Loss: 1.0945
Batch 210, Loss: 1.1329
Batch 220, Loss: 1.1094
Batch 230, Loss: 1.0881
Batch 240, Loss: 1.0957
Batch 250, Loss: 1.1272
Batch 260, Loss: 1.1781
Batch 270, Loss: 1.1264
Batch 280, Loss: 1.2057
Batch 290, Loss: 1.1142
Batch 300, Loss: 1.1587
Batch 310, Loss: 1.1593
Batch 320, Loss: 1.1397
Batch 330, Loss: 1.1179
Batch 340, Loss: 1.1320
Batch 350, Loss: 1.0983
Batch 360, Loss: 1.0762
Batch 370, Loss: 1.1031
Batch 380, Loss: 1.1860
Batch 390, Loss: 1.1661
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.326125144958496 seconds
Epoch 99 accuracy: 65.15%
Batch 10, Loss: 1.0985
Batch 20, Loss: 1.0262
Batch 30, Loss: 1.1280
Batch 40, Loss: 1.1020
Batch 50, Loss: 0.9862
Batch 60, Loss: 1.0233
Batch 70, Loss: 1.0721
Batch 80, Loss: 1.0979
Batch 90, Loss: 1.1102
Batch 100, Loss: 1.1417
Batch 110, Loss: 1.1021
Batch 120, Loss: 1.0539
Batch 130, Loss: 1.1571
Batch 140, Loss: 1.0788
Batch 150, Loss: 1.0868
Batch 160, Loss: 1.0899
Batch 170, Loss: 1.0579
Batch 180, Loss: 1.0520
Batch 190, Loss: 1.1310
Batch 200, Loss: 1.1544
Batch 210, Loss: 1.1517
Batch 220, Loss: 1.0703
Batch 230, Loss: 1.0924
Batch 240, Loss: 1.1334
Batch 250, Loss: 1.1271
Batch 260, Loss: 1.1635
Batch 270, Loss: 1.0934
Batch 280, Loss: 1.1343
Batch 290, Loss: 1.1449
Batch 300, Loss: 1.1004
Batch 310, Loss: 1.1209
Batch 320, Loss: 1.1001
Batch 330, Loss: 1.1342
Batch 340, Loss: 1.0843
Batch 350, Loss: 1.1900
Batch 360, Loss: 1.1413
Batch 370, Loss: 1.0986
Batch 380, Loss: 1.1905
Batch 390, Loss: 1.0975
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.243120193481445 seconds
Epoch 100 accuracy: 66.42%
Batch 10, Loss: 1.0568
Batch 20, Loss: 1.0606
Batch 30, Loss: 1.0789
Batch 40, Loss: 1.0933
Batch 50, Loss: 1.0712
Batch 60, Loss: 1.0587
Batch 70, Loss: 1.0520
Batch 80, Loss: 1.0278
Batch 90, Loss: 1.0702
Batch 100, Loss: 1.0883
Batch 110, Loss: 1.0840
Batch 120, Loss: 1.1008
Batch 130, Loss: 1.0393
Batch 140, Loss: 1.1595
Batch 150, Loss: 1.0862
Batch 160, Loss: 1.0401
Batch 170, Loss: 1.1154
Batch 180, Loss: 1.1348
Batch 190, Loss: 1.0510
Batch 200, Loss: 1.0903
Batch 210, Loss: 1.0786
Batch 220, Loss: 1.0791
Batch 230, Loss: 1.1575
Batch 240, Loss: 1.1197
Batch 250, Loss: 1.0948
Batch 260, Loss: 1.0883
Batch 270, Loss: 1.1612
Batch 280, Loss: 1.0797
Batch 290, Loss: 1.0602
Batch 300, Loss: 1.1105
Batch 310, Loss: 1.0882
Batch 320, Loss: 1.1351
Batch 330, Loss: 1.1082
Batch 340, Loss: 1.1137
Batch 350, Loss: 1.1459
Batch 360, Loss: 1.0840
Batch 370, Loss: 1.1209
Batch 380, Loss: 1.0954
Batch 390, Loss: 1.1595
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.365004539489746 seconds
Epoch 101 accuracy: 62.17%
Batch 10, Loss: 1.1347
Batch 20, Loss: 1.0557
Batch 30, Loss: 1.0933
Batch 40, Loss: 1.0235
Batch 50, Loss: 1.0155
Batch 60, Loss: 1.0675
Batch 70, Loss: 1.0426
Batch 80, Loss: 1.1129
Batch 90, Loss: 1.0557
Batch 100, Loss: 1.1056
Batch 110, Loss: 1.0829
Batch 120, Loss: 1.0518
Batch 130, Loss: 1.0277
Batch 140, Loss: 1.0434
Batch 150, Loss: 1.1361
Batch 160, Loss: 1.0631
Batch 170, Loss: 1.0586
Batch 180, Loss: 1.0864
Batch 190, Loss: 1.1122
Batch 200, Loss: 1.1258
Batch 210, Loss: 1.0677
Batch 220, Loss: 1.1171
Batch 230, Loss: 1.0217
Batch 240, Loss: 1.0589
Batch 250, Loss: 1.0855
Batch 260, Loss: 1.1294
Batch 270, Loss: 1.0743
Batch 280, Loss: 1.1288
Batch 290, Loss: 1.1102
Batch 300, Loss: 1.1064
Batch 310, Loss: 1.0565
Batch 320, Loss: 1.1121
Batch 330, Loss: 1.0719
Batch 340, Loss: 1.1677
Batch 350, Loss: 1.0779
Batch 360, Loss: 1.1153
Batch 370, Loss: 1.1205
Batch 380, Loss: 1.1002
Batch 390, Loss: 1.1478
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.409958839416504 seconds
Epoch 102 accuracy: 66.39%
Batch 10, Loss: 1.0899
Batch 20, Loss: 1.0525
Batch 30, Loss: 0.9751
Batch 40, Loss: 0.9780
Batch 50, Loss: 1.0161
Batch 60, Loss: 1.0469
Batch 70, Loss: 1.0683
Batch 80, Loss: 0.9834
Batch 90, Loss: 1.0688
Batch 100, Loss: 1.0654
Batch 110, Loss: 1.0500
Batch 120, Loss: 1.0045
Batch 130, Loss: 1.0211
Batch 140, Loss: 1.0632
Batch 150, Loss: 1.1004
Batch 160, Loss: 1.0921
Batch 170, Loss: 1.0590
Batch 180, Loss: 1.0368
Batch 190, Loss: 1.0848
Batch 200, Loss: 1.1157
Batch 210, Loss: 1.1602
Batch 220, Loss: 1.1410
Batch 230, Loss: 1.0830
Batch 240, Loss: 1.0751
Batch 250, Loss: 1.0975
Batch 260, Loss: 1.1354
Batch 270, Loss: 1.0958
Batch 280, Loss: 1.1134
Batch 290, Loss: 1.1012
Batch 300, Loss: 1.0689
Batch 310, Loss: 1.1030
Batch 320, Loss: 1.0803
Batch 330, Loss: 1.0378
Batch 340, Loss: 1.0561
Batch 350, Loss: 1.0481
Batch 360, Loss: 1.0894
Batch 370, Loss: 1.1411
Batch 380, Loss: 1.0480
Batch 390, Loss: 1.1559
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.34829616546631 seconds
Epoch 103 accuracy: 66.04%
Batch 10, Loss: 1.0283
Batch 20, Loss: 1.0331
Batch 30, Loss: 1.0296
Batch 40, Loss: 1.0269
Batch 50, Loss: 1.0304
Batch 60, Loss: 1.0717
Batch 70, Loss: 1.0094
Batch 80, Loss: 1.0133
Batch 90, Loss: 1.0298
Batch 100, Loss: 1.0913
Batch 110, Loss: 1.0461
Batch 120, Loss: 1.0063
Batch 130, Loss: 1.0923
Batch 140, Loss: 1.1118
Batch 150, Loss: 1.0422
Batch 160, Loss: 1.0774
Batch 170, Loss: 1.0610
Batch 180, Loss: 1.1261
Batch 190, Loss: 1.0644
Batch 200, Loss: 1.0972
Batch 210, Loss: 1.0770
Batch 220, Loss: 1.0080
Batch 230, Loss: 1.0543
Batch 240, Loss: 1.0628
Batch 250, Loss: 1.0751
Batch 260, Loss: 1.1361
Batch 270, Loss: 1.0755
Batch 280, Loss: 1.1620
Batch 290, Loss: 1.0774
Batch 300, Loss: 1.0451
Batch 310, Loss: 1.1416
Batch 320, Loss: 1.1344
Batch 330, Loss: 1.1193
Batch 340, Loss: 1.1065
Batch 350, Loss: 1.1104
Batch 360, Loss: 1.1218
Batch 370, Loss: 1.1773
Batch 380, Loss: 1.0911
Batch 390, Loss: 1.0615
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.363696098327637 seconds
Epoch 104 accuracy: 66.88%
Batch 10, Loss: 0.9959
Batch 20, Loss: 1.0230
Batch 30, Loss: 1.0380
Batch 40, Loss: 1.0429
Batch 50, Loss: 0.9893
Batch 60, Loss: 0.9497
Batch 70, Loss: 0.9951
Batch 80, Loss: 0.9902
Batch 90, Loss: 0.9919
Batch 100, Loss: 1.0378
Batch 110, Loss: 1.0945
Batch 120, Loss: 1.0541
Batch 130, Loss: 1.0215
Batch 140, Loss: 1.0894
Batch 150, Loss: 1.0637
Batch 160, Loss: 1.0688
Batch 170, Loss: 1.0754
Batch 180, Loss: 1.1198
Batch 190, Loss: 1.0168
Batch 200, Loss: 1.0424
Batch 210, Loss: 1.0375
Batch 220, Loss: 1.0521
Batch 230, Loss: 1.0686
Batch 240, Loss: 1.0265
Batch 250, Loss: 1.0551
Batch 260, Loss: 1.1312
Batch 270, Loss: 1.0678
Batch 280, Loss: 1.1242
Batch 290, Loss: 1.0331
Batch 300, Loss: 1.1040
Batch 310, Loss: 1.1028
Batch 320, Loss: 1.0773
Batch 330, Loss: 1.0707
Batch 340, Loss: 1.0257
Batch 350, Loss: 1.0593
Batch 360, Loss: 1.0251
Batch 370, Loss: 1.0612
Batch 380, Loss: 1.0927
Batch 390, Loss: 1.0986
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.29592990875244 seconds
Epoch 105 accuracy: 65.3%
Batch 10, Loss: 1.0851
Batch 20, Loss: 1.0191
Batch 30, Loss: 0.9744
Batch 40, Loss: 0.9829
Batch 50, Loss: 0.9451
Batch 60, Loss: 1.0236
Batch 70, Loss: 1.0211
Batch 80, Loss: 1.0498
Batch 90, Loss: 1.0356
Batch 100, Loss: 1.0749
Batch 110, Loss: 1.0315
Batch 120, Loss: 1.0655
Batch 130, Loss: 1.0480
Batch 140, Loss: 1.0312
Batch 150, Loss: 1.0798
Batch 160, Loss: 1.0096
Batch 170, Loss: 1.0662
Batch 180, Loss: 1.0794
Batch 190, Loss: 1.0542
Batch 200, Loss: 1.0080
Batch 210, Loss: 1.0584
Batch 220, Loss: 1.0027
Batch 230, Loss: 1.0667
Batch 240, Loss: 1.0798
Batch 250, Loss: 1.0338
Batch 260, Loss: 1.0648
Batch 270, Loss: 1.0395
Batch 280, Loss: 1.0983
Batch 290, Loss: 1.0233
Batch 300, Loss: 1.0930
Batch 310, Loss: 0.9656
Batch 320, Loss: 1.0932
Batch 330, Loss: 1.0871
Batch 340, Loss: 1.1239
Batch 350, Loss: 1.1517
Batch 360, Loss: 1.0602
Batch 370, Loss: 1.1165
Batch 380, Loss: 1.1235
Batch 390, Loss: 1.0864
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.425743103027344 seconds
Epoch 106 accuracy: 67.53%
Batch 10, Loss: 0.9773
Batch 20, Loss: 1.0775
Batch 30, Loss: 1.0401
Batch 40, Loss: 1.0048
Batch 50, Loss: 1.0750
Batch 60, Loss: 1.0215
Batch 70, Loss: 0.9913
Batch 80, Loss: 0.9899
Batch 90, Loss: 0.9609
Batch 100, Loss: 1.0010
Batch 110, Loss: 1.0136
Batch 120, Loss: 1.0520
Batch 130, Loss: 1.0774
Batch 140, Loss: 1.0375
Batch 150, Loss: 1.0393
Batch 160, Loss: 1.0510
Batch 170, Loss: 1.0376
Batch 180, Loss: 1.0655
Batch 190, Loss: 1.0490
Batch 200, Loss: 1.0125
Batch 210, Loss: 1.0670
Batch 220, Loss: 1.0272
Batch 230, Loss: 1.0081
Batch 240, Loss: 1.1003
Batch 250, Loss: 1.0700
Batch 260, Loss: 1.0670
Batch 270, Loss: 1.0550
Batch 280, Loss: 1.0855
Batch 290, Loss: 0.9843
Batch 300, Loss: 1.0561
Batch 310, Loss: 1.1043
Batch 320, Loss: 1.0833
Batch 330, Loss: 1.0695
Batch 340, Loss: 1.0681
Batch 350, Loss: 1.0803
Batch 360, Loss: 1.0702
Batch 370, Loss: 1.0546
Batch 380, Loss: 1.1141
Batch 390, Loss: 1.1067
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.432679414749146 seconds
Epoch 107 accuracy: 67.09%
Batch 10, Loss: 1.0586
Batch 20, Loss: 0.9379
Batch 30, Loss: 1.0305
Batch 40, Loss: 0.9516
Batch 50, Loss: 1.0196
Batch 60, Loss: 0.9868
Batch 70, Loss: 1.0495
Batch 80, Loss: 1.0027
Batch 90, Loss: 1.0108
Batch 100, Loss: 1.0356
Batch 110, Loss: 0.9834
Batch 120, Loss: 0.9994
Batch 130, Loss: 0.8947
Batch 140, Loss: 1.0072
Batch 150, Loss: 1.0760
Batch 160, Loss: 1.0275
Batch 170, Loss: 0.9495
Batch 180, Loss: 1.0414
Batch 190, Loss: 1.0126
Batch 200, Loss: 1.0205
Batch 210, Loss: 0.9840
Batch 220, Loss: 1.0748
Batch 230, Loss: 1.0785
Batch 240, Loss: 1.0643
Batch 250, Loss: 1.0622
Batch 260, Loss: 0.9698
Batch 270, Loss: 1.0086
Batch 280, Loss: 1.0743
Batch 290, Loss: 1.1241
Batch 300, Loss: 1.0914
Batch 310, Loss: 1.0026
Batch 320, Loss: 1.1176
Batch 330, Loss: 1.0720
Batch 340, Loss: 1.0461
Batch 350, Loss: 1.0508
Batch 360, Loss: 1.0583
Batch 370, Loss: 1.1229
Batch 380, Loss: 1.1117
Batch 390, Loss: 1.0776
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.322568893432617 seconds
Epoch 108 accuracy: 65.81%
Batch 10, Loss: 0.9810
Batch 20, Loss: 1.0276
Batch 30, Loss: 0.9654
Batch 40, Loss: 1.0281
Batch 50, Loss: 1.0958
Batch 60, Loss: 1.0108
Batch 70, Loss: 0.9531
Batch 80, Loss: 1.0010
Batch 90, Loss: 1.0063
Batch 100, Loss: 0.9762
Batch 110, Loss: 0.9720
Batch 120, Loss: 1.0098
Batch 130, Loss: 1.0244
Batch 140, Loss: 0.9922
Batch 150, Loss: 1.0156
Batch 160, Loss: 0.9922
Batch 170, Loss: 1.0432
Batch 180, Loss: 1.0815
Batch 190, Loss: 1.0479
Batch 200, Loss: 0.9906
Batch 210, Loss: 1.0341
Batch 220, Loss: 1.0752
Batch 230, Loss: 1.0396
Batch 240, Loss: 1.0096
Batch 250, Loss: 1.0427
Batch 260, Loss: 1.0890
Batch 270, Loss: 1.0036
Batch 280, Loss: 1.0112
Batch 290, Loss: 1.0833
Batch 300, Loss: 1.0690
Batch 310, Loss: 1.0358
Batch 320, Loss: 1.0205
Batch 330, Loss: 1.0373
Batch 340, Loss: 1.0535
Batch 350, Loss: 1.0333
Batch 360, Loss: 1.0808
Batch 370, Loss: 1.0908
Batch 380, Loss: 1.0526
Batch 390, Loss: 1.0400
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.45456051826477 seconds
Epoch 109 accuracy: 66.03%
Batch 10, Loss: 1.0583
Batch 20, Loss: 0.9711
Batch 30, Loss: 1.0205
Batch 40, Loss: 0.9500
Batch 50, Loss: 0.9776
Batch 60, Loss: 0.9931
Batch 70, Loss: 0.9347
Batch 80, Loss: 0.9853
Batch 90, Loss: 1.0069
Batch 100, Loss: 0.9571
Batch 110, Loss: 0.9607
Batch 120, Loss: 1.0662
Batch 130, Loss: 1.0807
Batch 140, Loss: 1.0041
Batch 150, Loss: 0.9772
Batch 160, Loss: 1.0275
Batch 170, Loss: 1.0654
Batch 180, Loss: 1.0453
Batch 190, Loss: 0.9428
Batch 200, Loss: 1.0456
Batch 210, Loss: 1.0399
Batch 220, Loss: 1.0266
Batch 230, Loss: 1.0236
Batch 240, Loss: 1.0819
Batch 250, Loss: 1.0244
Batch 260, Loss: 1.0135
Batch 270, Loss: 1.0202
Batch 280, Loss: 1.0328
Batch 290, Loss: 1.0215
Batch 300, Loss: 1.0286
Batch 310, Loss: 1.0584
Batch 320, Loss: 1.0335
Batch 330, Loss: 0.9975
Batch 340, Loss: 0.9988
Batch 350, Loss: 1.0191
Batch 360, Loss: 1.0100
Batch 370, Loss: 1.0315
Batch 380, Loss: 1.1062
Batch 390, Loss: 1.0466
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.42649221420288 seconds
Epoch 110 accuracy: 67.16%
Batch 10, Loss: 1.0179
Batch 20, Loss: 0.9849
Batch 30, Loss: 1.0062
Batch 40, Loss: 0.9813
Batch 50, Loss: 0.9430
Batch 60, Loss: 0.9750
Batch 70, Loss: 0.9397
Batch 80, Loss: 0.9213
Batch 90, Loss: 0.9676
Batch 100, Loss: 0.9740
Batch 110, Loss: 1.0076
Batch 120, Loss: 1.0288
Batch 130, Loss: 1.0199
Batch 140, Loss: 1.0001
Batch 150, Loss: 1.0130
Batch 160, Loss: 1.0475
Batch 170, Loss: 0.9323
Batch 180, Loss: 0.9985
Batch 190, Loss: 0.9271
Batch 200, Loss: 0.9859
Batch 210, Loss: 1.0596
Batch 220, Loss: 1.0353
Batch 230, Loss: 1.0704
Batch 240, Loss: 1.0385
Batch 250, Loss: 1.0940
Batch 260, Loss: 0.9874
Batch 270, Loss: 1.0236
Batch 280, Loss: 1.0517
Batch 290, Loss: 1.0020
Batch 300, Loss: 1.0251
Batch 310, Loss: 1.0406
Batch 320, Loss: 0.9898
Batch 330, Loss: 1.0295
Batch 340, Loss: 1.0207
Batch 350, Loss: 1.0456
Batch 360, Loss: 1.0442
Batch 370, Loss: 1.0308
Batch 380, Loss: 1.0089
Batch 390, Loss: 1.0567
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.326338291168213 seconds
Epoch 111 accuracy: 69.29%
Batch 10, Loss: 0.9431
Batch 20, Loss: 0.9685
Batch 30, Loss: 0.9807
Batch 40, Loss: 0.9833
Batch 50, Loss: 0.9969
Batch 60, Loss: 0.9543
Batch 70, Loss: 0.9646
Batch 80, Loss: 0.9891
Batch 90, Loss: 0.9539
Batch 100, Loss: 0.9757
Batch 110, Loss: 1.0231
Batch 120, Loss: 0.9977
Batch 130, Loss: 0.9620
Batch 140, Loss: 0.9811
Batch 150, Loss: 0.9783
Batch 160, Loss: 1.0146
Batch 170, Loss: 1.0274
Batch 180, Loss: 1.0546
Batch 190, Loss: 1.0488
Batch 200, Loss: 1.0338
Batch 210, Loss: 0.9909
Batch 220, Loss: 0.9861
Batch 230, Loss: 0.9725
Batch 240, Loss: 1.0511
Batch 250, Loss: 1.0541
Batch 260, Loss: 0.9582
Batch 270, Loss: 1.0211
Batch 280, Loss: 0.9835
Batch 290, Loss: 1.0935
Batch 300, Loss: 1.0154
Batch 310, Loss: 1.0030
Batch 320, Loss: 1.0479
Batch 330, Loss: 0.9849
Batch 340, Loss: 1.0276
Batch 350, Loss: 0.9874
Batch 360, Loss: 1.0425
Batch 370, Loss: 0.9846
Batch 380, Loss: 1.0462
Batch 390, Loss: 1.0577
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.365707874298096 seconds
Epoch 112 accuracy: 67.07%
Batch 10, Loss: 0.9739
Batch 20, Loss: 0.9855
Batch 30, Loss: 0.9464
Batch 40, Loss: 0.9707
Batch 50, Loss: 0.9805
Batch 60, Loss: 0.9814
Batch 70, Loss: 0.9908
Batch 80, Loss: 0.9218
Batch 90, Loss: 0.9803
Batch 100, Loss: 0.9368
Batch 110, Loss: 0.9542
Batch 120, Loss: 1.0401
Batch 130, Loss: 0.9615
Batch 140, Loss: 0.9865
Batch 150, Loss: 0.9782
Batch 160, Loss: 0.9497
Batch 170, Loss: 0.9869
Batch 180, Loss: 0.9559
Batch 190, Loss: 0.9993
Batch 200, Loss: 0.9451
Batch 210, Loss: 1.0398
Batch 220, Loss: 0.9798
Batch 230, Loss: 1.0265
Batch 240, Loss: 1.0280
Batch 250, Loss: 1.0197
Batch 260, Loss: 1.0168
Batch 270, Loss: 0.9715
Batch 280, Loss: 1.0315
Batch 290, Loss: 0.9744
Batch 300, Loss: 0.9812
Batch 310, Loss: 0.9980
Batch 320, Loss: 1.0700
Batch 330, Loss: 1.0346
Batch 340, Loss: 1.0564
Batch 350, Loss: 1.0523
Batch 360, Loss: 0.9937
Batch 370, Loss: 1.0885
Batch 380, Loss: 1.0445
Batch 390, Loss: 1.0171
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.4682035446167 seconds
Epoch 113 accuracy: 67.21%
Batch 10, Loss: 0.9781
Batch 20, Loss: 0.9441
Batch 30, Loss: 0.9699
Batch 40, Loss: 0.9154
Batch 50, Loss: 0.9277
Batch 60, Loss: 0.9887
Batch 70, Loss: 0.9726
Batch 80, Loss: 0.9252
Batch 90, Loss: 0.9596
Batch 100, Loss: 0.9037
Batch 110, Loss: 0.9270
Batch 120, Loss: 0.9529
Batch 130, Loss: 0.9324
Batch 140, Loss: 0.9781
Batch 150, Loss: 0.9919
Batch 160, Loss: 0.9270
Batch 170, Loss: 1.0069
Batch 180, Loss: 0.9988
Batch 190, Loss: 1.0250
Batch 200, Loss: 0.9579
Batch 210, Loss: 0.9719
Batch 220, Loss: 1.0326
Batch 230, Loss: 1.0268
Batch 240, Loss: 0.9592
Batch 250, Loss: 1.0090
Batch 260, Loss: 1.0196
Batch 270, Loss: 0.9685
Batch 280, Loss: 1.0411
Batch 290, Loss: 0.9482
Batch 300, Loss: 1.0371
Batch 310, Loss: 0.9889
Batch 320, Loss: 1.0296
Batch 330, Loss: 1.0267
Batch 340, Loss: 0.9554
Batch 350, Loss: 0.9866
Batch 360, Loss: 0.9526
Batch 370, Loss: 0.9780
Batch 380, Loss: 1.0028
Batch 390, Loss: 0.9915
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.3489248752594 seconds
Epoch 114 accuracy: 69.04%
Batch 10, Loss: 0.8808
Batch 20, Loss: 0.9337
Batch 30, Loss: 0.9029
Batch 40, Loss: 0.9432
Batch 50, Loss: 0.9022
Batch 60, Loss: 0.9561
Batch 70, Loss: 0.9738
Batch 80, Loss: 0.9811
Batch 90, Loss: 0.9860
Batch 100, Loss: 0.9925
Batch 110, Loss: 0.9306
Batch 120, Loss: 0.9672
Batch 130, Loss: 0.9825
Batch 140, Loss: 0.9774
Batch 150, Loss: 0.9402
Batch 160, Loss: 0.9420
Batch 170, Loss: 0.9484
Batch 180, Loss: 0.9896
Batch 190, Loss: 0.9917
Batch 200, Loss: 1.0333
Batch 210, Loss: 1.0072
Batch 220, Loss: 0.9982
Batch 230, Loss: 0.9757
Batch 240, Loss: 0.9990
Batch 250, Loss: 0.9603
Batch 260, Loss: 0.9826
Batch 270, Loss: 1.0309
Batch 280, Loss: 0.9611
Batch 290, Loss: 0.9933
Batch 300, Loss: 1.0189
Batch 310, Loss: 0.9117
Batch 320, Loss: 1.0193
Batch 330, Loss: 0.9955
Batch 340, Loss: 1.0177
Batch 350, Loss: 0.9883
Batch 360, Loss: 0.9528
Batch 370, Loss: 1.0761
Batch 380, Loss: 1.0519
Batch 390, Loss: 0.9862
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.35003638267517 seconds
Epoch 115 accuracy: 67.66%
Batch 10, Loss: 0.9847
Batch 20, Loss: 0.9323
Batch 30, Loss: 0.9480
Batch 40, Loss: 0.9397
Batch 50, Loss: 0.9213
Batch 60, Loss: 0.9403
Batch 70, Loss: 0.9398
Batch 80, Loss: 0.9099
Batch 90, Loss: 0.9093
Batch 100, Loss: 0.9060
Batch 110, Loss: 0.9661
Batch 120, Loss: 0.9326
Batch 130, Loss: 0.9791
Batch 140, Loss: 0.9387
Batch 150, Loss: 0.9193
Batch 160, Loss: 0.9902
Batch 170, Loss: 0.9060
Batch 180, Loss: 0.9421
Batch 190, Loss: 0.9730
Batch 200, Loss: 1.0147
Batch 210, Loss: 0.9629
Batch 220, Loss: 1.0009
Batch 230, Loss: 0.9714
Batch 240, Loss: 0.9934
Batch 250, Loss: 0.9515
Batch 260, Loss: 0.9519
Batch 270, Loss: 1.0005
Batch 280, Loss: 0.9226
Batch 290, Loss: 0.9690
Batch 300, Loss: 1.0111
Batch 310, Loss: 1.0220
Batch 320, Loss: 1.0062
Batch 330, Loss: 1.0058
Batch 340, Loss: 1.0376
Batch 350, Loss: 1.0380
Batch 360, Loss: 1.0028
Batch 370, Loss: 0.9873
Batch 380, Loss: 0.9751
Batch 390, Loss: 1.0258
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.426340579986572 seconds
Epoch 116 accuracy: 68.56%
Batch 10, Loss: 0.9899
Batch 20, Loss: 0.9419
Batch 30, Loss: 0.9145
Batch 40, Loss: 0.8555
Batch 50, Loss: 0.9890
Batch 60, Loss: 0.9331
Batch 70, Loss: 0.9508
Batch 80, Loss: 0.9580
Batch 90, Loss: 0.9100
Batch 100, Loss: 0.9138
Batch 110, Loss: 0.9182
Batch 120, Loss: 0.9282
Batch 130, Loss: 0.9517
Batch 140, Loss: 0.9300
Batch 150, Loss: 0.9960
Batch 160, Loss: 0.9454
Batch 170, Loss: 0.9366
Batch 180, Loss: 0.9894
Batch 190, Loss: 1.0302
Batch 200, Loss: 0.9974
Batch 210, Loss: 1.0166
Batch 220, Loss: 0.9473
Batch 230, Loss: 1.0316
Batch 240, Loss: 0.9264
Batch 250, Loss: 0.9778
Batch 260, Loss: 1.0189
Batch 270, Loss: 1.0006
Batch 280, Loss: 1.0107
Batch 290, Loss: 0.9901
Batch 300, Loss: 0.9712
Batch 310, Loss: 0.9573
Batch 320, Loss: 0.9632
Batch 330, Loss: 0.9096
Batch 340, Loss: 0.9742
Batch 350, Loss: 1.0274
Batch 360, Loss: 1.0207
Batch 370, Loss: 0.9139
Batch 380, Loss: 0.9841
Batch 390, Loss: 1.0124
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.450634002685547 seconds
Epoch 117 accuracy: 70.14%
Batch 10, Loss: 0.9925
Batch 20, Loss: 0.8698
Batch 30, Loss: 0.9291
Batch 40, Loss: 0.9209
Batch 50, Loss: 0.9426
Batch 60, Loss: 0.9337
Batch 70, Loss: 0.9415
Batch 80, Loss: 0.9198
Batch 90, Loss: 0.9132
Batch 100, Loss: 0.9086
Batch 110, Loss: 0.9620
Batch 120, Loss: 0.9378
Batch 130, Loss: 0.9266
Batch 140, Loss: 0.8910
Batch 150, Loss: 0.9533
Batch 160, Loss: 0.8990
Batch 170, Loss: 0.9037
Batch 180, Loss: 0.9612
Batch 190, Loss: 0.9178
Batch 200, Loss: 0.9001
Batch 210, Loss: 0.9358
Batch 220, Loss: 0.9383
Batch 230, Loss: 0.9771
Batch 240, Loss: 0.9267
Batch 250, Loss: 0.9298
Batch 260, Loss: 0.9188
Batch 270, Loss: 0.9796
Batch 280, Loss: 1.0120
Batch 290, Loss: 1.0001
Batch 300, Loss: 0.9454
Batch 310, Loss: 0.9811
Batch 320, Loss: 0.9640
Batch 330, Loss: 0.9413
Batch 340, Loss: 0.9468
Batch 350, Loss: 0.9217
Batch 360, Loss: 1.0350
Batch 370, Loss: 0.9723
Batch 380, Loss: 0.9652
Batch 390, Loss: 1.0085
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.413910150527954 seconds
Epoch 118 accuracy: 66.85%
Batch 10, Loss: 0.9135
Batch 20, Loss: 0.9783
Batch 30, Loss: 0.8892
Batch 40, Loss: 0.8981
Batch 50, Loss: 0.8961
Batch 60, Loss: 0.8683
Batch 70, Loss: 0.8653
Batch 80, Loss: 0.8908
Batch 90, Loss: 0.8799
Batch 100, Loss: 0.9279
Batch 110, Loss: 0.9169
Batch 120, Loss: 0.9475
Batch 130, Loss: 0.9455
Batch 140, Loss: 0.9269
Batch 150, Loss: 0.9349
Batch 160, Loss: 0.9339
Batch 170, Loss: 0.9996
Batch 180, Loss: 0.9406
Batch 190, Loss: 0.9362
Batch 200, Loss: 0.9354
Batch 210, Loss: 1.0204
Batch 220, Loss: 0.9027
Batch 230, Loss: 0.9732
Batch 240, Loss: 0.9340
Batch 250, Loss: 0.9335
Batch 260, Loss: 0.9077
Batch 270, Loss: 0.9131
Batch 280, Loss: 0.9358
Batch 290, Loss: 0.9191
Batch 300, Loss: 1.0015
Batch 310, Loss: 0.9380
Batch 320, Loss: 0.9191
Batch 330, Loss: 0.9398
Batch 340, Loss: 0.9824
Batch 350, Loss: 0.9403
Batch 360, Loss: 0.8895
Batch 370, Loss: 0.9380
Batch 380, Loss: 0.9502
Batch 390, Loss: 0.9488
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.46097755432129 seconds
Epoch 119 accuracy: 68.87%
Batch 10, Loss: 0.8774
Batch 20, Loss: 0.8555
Batch 30, Loss: 0.8571
Batch 40, Loss: 0.8560
Batch 50, Loss: 0.8615
Batch 60, Loss: 0.8913
Batch 70, Loss: 0.8860
Batch 80, Loss: 0.9167
Batch 90, Loss: 0.8989
Batch 100, Loss: 0.9554
Batch 110, Loss: 0.9311
Batch 120, Loss: 0.8585
Batch 130, Loss: 0.9509
Batch 140, Loss: 0.8915
Batch 150, Loss: 0.9468
Batch 160, Loss: 0.9301
Batch 170, Loss: 0.9597
Batch 180, Loss: 0.9387
Batch 190, Loss: 0.9142
Batch 200, Loss: 0.9641
Batch 210, Loss: 0.8947
Batch 220, Loss: 0.9076
Batch 230, Loss: 0.9088
Batch 240, Loss: 0.9150
Batch 250, Loss: 0.9284
Batch 260, Loss: 0.9639
Batch 270, Loss: 0.9649
Batch 280, Loss: 0.9563
Batch 290, Loss: 1.0023
Batch 300, Loss: 0.8743
Batch 310, Loss: 0.9625
Batch 320, Loss: 0.9317
Batch 330, Loss: 0.9333
Batch 340, Loss: 0.9328
Batch 350, Loss: 0.9344
Batch 360, Loss: 1.0027
Batch 370, Loss: 1.0179
Batch 380, Loss: 0.9985
Batch 390, Loss: 0.8941
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.33540153503418 seconds
Epoch 120 accuracy: 69.65%
Batch 10, Loss: 0.8858
Batch 20, Loss: 0.8869
Batch 30, Loss: 0.9473
Batch 40, Loss: 0.8997
Batch 50, Loss: 0.9256
Batch 60, Loss: 0.8783
Batch 70, Loss: 0.8836
Batch 80, Loss: 0.8831
Batch 90, Loss: 0.9103
Batch 100, Loss: 0.9609
Batch 110, Loss: 0.9161
Batch 120, Loss: 0.8513
Batch 130, Loss: 0.9351
Batch 140, Loss: 0.8925
Batch 150, Loss: 0.9420
Batch 160, Loss: 0.9025
Batch 170, Loss: 0.9203
Batch 180, Loss: 1.0147
Batch 190, Loss: 0.8971
Batch 200, Loss: 0.8456
Batch 210, Loss: 0.9632
Batch 220, Loss: 0.9440
Batch 230, Loss: 0.9282
Batch 240, Loss: 0.9512
Batch 250, Loss: 0.9208
Batch 260, Loss: 0.9386
Batch 270, Loss: 0.9120
Batch 280, Loss: 0.9642
Batch 290, Loss: 0.9666
Batch 300, Loss: 0.9196
Batch 310, Loss: 0.9058
Batch 320, Loss: 0.8924
Batch 330, Loss: 0.9412
Batch 340, Loss: 0.9553
Batch 350, Loss: 0.9893
Batch 360, Loss: 0.9888
Batch 370, Loss: 0.9321
Batch 380, Loss: 0.9048
Batch 390, Loss: 0.9077
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.30406904220581 seconds
Epoch 121 accuracy: 70.56%
Batch 10, Loss: 0.9077
Batch 20, Loss: 0.9181
Batch 30, Loss: 0.8730
Batch 40, Loss: 0.8779
Batch 50, Loss: 0.8821
Batch 60, Loss: 0.8609
Batch 70, Loss: 0.8903
Batch 80, Loss: 0.8796
Batch 90, Loss: 0.8563
Batch 100, Loss: 0.8308
Batch 110, Loss: 0.9019
Batch 120, Loss: 0.8913
Batch 130, Loss: 0.8557
Batch 140, Loss: 0.9279
Batch 150, Loss: 0.9073
Batch 160, Loss: 0.8782
Batch 170, Loss: 0.8772
Batch 180, Loss: 0.9232
Batch 190, Loss: 0.9535
Batch 200, Loss: 0.9259
Batch 210, Loss: 0.9236
Batch 220, Loss: 0.9331
Batch 230, Loss: 0.8763
Batch 240, Loss: 0.8749
Batch 250, Loss: 0.9403
Batch 260, Loss: 0.9053
Batch 270, Loss: 0.9148
Batch 280, Loss: 0.9376
Batch 290, Loss: 0.9212
Batch 300, Loss: 0.9112
Batch 310, Loss: 0.9488
Batch 320, Loss: 0.9622
Batch 330, Loss: 0.9750
Batch 340, Loss: 0.9305
Batch 350, Loss: 0.8812
Batch 360, Loss: 0.9246
Batch 370, Loss: 0.8809
Batch 380, Loss: 0.9358
Batch 390, Loss: 0.9478
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.45029354095459 seconds
Epoch 122 accuracy: 70.77%
Batch 10, Loss: 0.8866
Batch 20, Loss: 0.8704
Batch 30, Loss: 0.8896
Batch 40, Loss: 0.8722
Batch 50, Loss: 0.8340
Batch 60, Loss: 0.8744
Batch 70, Loss: 0.9279
Batch 80, Loss: 0.9146
Batch 90, Loss: 0.9239
Batch 100, Loss: 0.8995
Batch 110, Loss: 0.8152
Batch 120, Loss: 0.9216
Batch 130, Loss: 0.9503
Batch 140, Loss: 0.9298
Batch 150, Loss: 0.8679
Batch 160, Loss: 0.8753
Batch 170, Loss: 0.8867
Batch 180, Loss: 0.9094
Batch 190, Loss: 0.9224
Batch 200, Loss: 0.9075
Batch 210, Loss: 0.9052
Batch 220, Loss: 0.9231
Batch 230, Loss: 0.9013
Batch 240, Loss: 0.8908
Batch 250, Loss: 0.9299
Batch 260, Loss: 0.8629
Batch 270, Loss: 0.8542
Batch 280, Loss: 0.8861
Batch 290, Loss: 0.9028
Batch 300, Loss: 0.9036
Batch 310, Loss: 0.9485
Batch 320, Loss: 0.9482
Batch 330, Loss: 0.9420
Batch 340, Loss: 0.8843
Batch 350, Loss: 0.9487
Batch 360, Loss: 0.9410
Batch 370, Loss: 0.9102
Batch 380, Loss: 0.9622
Batch 390, Loss: 0.9293
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.375553846359253 seconds
Epoch 123 accuracy: 68.49%
Batch 10, Loss: 0.8085
Batch 20, Loss: 0.8624
Batch 30, Loss: 0.8106
Batch 40, Loss: 0.9075
Batch 50, Loss: 0.8341
Batch 60, Loss: 0.8966
Batch 70, Loss: 0.8363
Batch 80, Loss: 0.8746
Batch 90, Loss: 0.8487
Batch 100, Loss: 0.9002
Batch 110, Loss: 0.8552
Batch 120, Loss: 0.8644
Batch 130, Loss: 0.8559
Batch 140, Loss: 0.9437
Batch 150, Loss: 0.8724
Batch 160, Loss: 0.9413
Batch 170, Loss: 0.8632
Batch 180, Loss: 0.9180
Batch 190, Loss: 0.9567
Batch 200, Loss: 0.8919
Batch 210, Loss: 0.8849
Batch 220, Loss: 0.8680
Batch 230, Loss: 0.8973
Batch 240, Loss: 0.9182
Batch 250, Loss: 0.8920
Batch 260, Loss: 0.8852
Batch 270, Loss: 0.9466
Batch 280, Loss: 0.8555
Batch 290, Loss: 0.9084
Batch 300, Loss: 0.9159
Batch 310, Loss: 0.8864
Batch 320, Loss: 0.8973
Batch 330, Loss: 0.9191
Batch 340, Loss: 0.8683
Batch 350, Loss: 0.9626
Batch 360, Loss: 0.9298
Batch 370, Loss: 0.8847
Batch 380, Loss: 0.8936
Batch 390, Loss: 0.9152
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.389163732528687 seconds
Epoch 124 accuracy: 69.41%
Batch 10, Loss: 0.8778
Batch 20, Loss: 0.8956
Batch 30, Loss: 0.8117
Batch 40, Loss: 0.8060
Batch 50, Loss: 0.8396
Batch 60, Loss: 0.9014
Batch 70, Loss: 0.8130
Batch 80, Loss: 0.8718
Batch 90, Loss: 0.8341
Batch 100, Loss: 0.9001
Batch 110, Loss: 0.9153
Batch 120, Loss: 0.8580
Batch 130, Loss: 0.8832
Batch 140, Loss: 0.8742
Batch 150, Loss: 0.8694
Batch 160, Loss: 0.8228
Batch 170, Loss: 0.8700
Batch 180, Loss: 0.8547
Batch 190, Loss: 0.8889
Batch 200, Loss: 0.8933
Batch 210, Loss: 0.7908
Batch 220, Loss: 0.8897
Batch 230, Loss: 0.9447
Batch 240, Loss: 0.9348
Batch 250, Loss: 0.8849
Batch 260, Loss: 0.8654
Batch 270, Loss: 0.8791
Batch 280, Loss: 0.9403
Batch 290, Loss: 0.8427
Batch 300, Loss: 0.8489
Batch 310, Loss: 0.8778
Batch 320, Loss: 0.9078
Batch 330, Loss: 0.9097
Batch 340, Loss: 0.9109
Batch 350, Loss: 0.8924
Batch 360, Loss: 0.8581
Batch 370, Loss: 0.9114
Batch 380, Loss: 0.9237
Batch 390, Loss: 0.8988
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.40647864341736 seconds
Epoch 125 accuracy: 69.88%
Batch 10, Loss: 0.7962
Batch 20, Loss: 0.8457
Batch 30, Loss: 0.7971
Batch 40, Loss: 0.8653
Batch 50, Loss: 0.8306
Batch 60, Loss: 0.8407
Batch 70, Loss: 0.8045
Batch 80, Loss: 0.8675
Batch 90, Loss: 0.8271
Batch 100, Loss: 0.8445
Batch 110, Loss: 0.8530
Batch 120, Loss: 0.8949
Batch 130, Loss: 0.8325
Batch 140, Loss: 0.8944
Batch 150, Loss: 0.8440
Batch 160, Loss: 0.8294
Batch 170, Loss: 0.8772
Batch 180, Loss: 0.8972
Batch 190, Loss: 0.8811
Batch 200, Loss: 0.8690
Batch 210, Loss: 0.8401
Batch 220, Loss: 0.8498
Batch 230, Loss: 0.8497
Batch 240, Loss: 0.9101
Batch 250, Loss: 0.9328
Batch 260, Loss: 0.8626
Batch 270, Loss: 0.8587
Batch 280, Loss: 0.8505
Batch 290, Loss: 0.8163
Batch 300, Loss: 0.9337
Batch 310, Loss: 0.9123
Batch 320, Loss: 0.8474
Batch 330, Loss: 0.8687
Batch 340, Loss: 0.8918
Batch 350, Loss: 0.9285
Batch 360, Loss: 0.8943
Batch 370, Loss: 0.8562
Batch 380, Loss: 0.9334
Batch 390, Loss: 0.9382
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.439149856567383 seconds
Epoch 126 accuracy: 68.1%
Batch 10, Loss: 0.8346
Batch 20, Loss: 0.8685
Batch 30, Loss: 0.8303
Batch 40, Loss: 0.8200
Batch 50, Loss: 0.8030
Batch 60, Loss: 0.8624
Batch 70, Loss: 0.8540
Batch 80, Loss: 0.7712
Batch 90, Loss: 0.8756
Batch 100, Loss: 0.8270
Batch 110, Loss: 0.8027
Batch 120, Loss: 0.8866
Batch 130, Loss: 0.8644
Batch 140, Loss: 0.8788
Batch 150, Loss: 0.8160
Batch 160, Loss: 0.8785
Batch 170, Loss: 0.8411
Batch 180, Loss: 0.8825
Batch 190, Loss: 0.8500
Batch 200, Loss: 0.8510
Batch 210, Loss: 0.8254
Batch 220, Loss: 0.7953
Batch 230, Loss: 0.8865
Batch 240, Loss: 0.9062
Batch 250, Loss: 0.9307
Batch 260, Loss: 0.8226
Batch 270, Loss: 0.8221
Batch 280, Loss: 0.9034
Batch 290, Loss: 0.8638
Batch 300, Loss: 0.8314
Batch 310, Loss: 0.8404
Batch 320, Loss: 0.9001
Batch 330, Loss: 0.8726
Batch 340, Loss: 0.8782
Batch 350, Loss: 0.9280
Batch 360, Loss: 0.9189
Batch 370, Loss: 0.8670
Batch 380, Loss: 0.8477
Batch 390, Loss: 0.9187
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.295799255371094 seconds
Epoch 127 accuracy: 69.8%
Batch 10, Loss: 0.8313
Batch 20, Loss: 0.8555
Batch 30, Loss: 0.8397
Batch 40, Loss: 0.7984
Batch 50, Loss: 0.7925
Batch 60, Loss: 0.8195
Batch 70, Loss: 0.7971
Batch 80, Loss: 0.8440
Batch 90, Loss: 0.7877
Batch 100, Loss: 0.8403
Batch 110, Loss: 0.7969
Batch 120, Loss: 0.8576
Batch 130, Loss: 0.8298
Batch 140, Loss: 0.8195
Batch 150, Loss: 0.8368
Batch 160, Loss: 0.8523
Batch 170, Loss: 0.8281
Batch 180, Loss: 0.8453
Batch 190, Loss: 0.8270
Batch 200, Loss: 0.8451
Batch 210, Loss: 0.8119
Batch 220, Loss: 0.8608
Batch 230, Loss: 0.9138
Batch 240, Loss: 0.8796
Batch 250, Loss: 0.8270
Batch 260, Loss: 0.8221
Batch 270, Loss: 0.8885
Batch 280, Loss: 0.8604
Batch 290, Loss: 0.8849
Batch 300, Loss: 0.9099
Batch 310, Loss: 0.8214
Batch 320, Loss: 0.8747
Batch 330, Loss: 0.8889
Batch 340, Loss: 0.7824
Batch 350, Loss: 0.8612
Batch 360, Loss: 0.8400
Batch 370, Loss: 0.8869
Batch 380, Loss: 0.8483
Batch 390, Loss: 0.8813
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.288785696029663 seconds
Epoch 128 accuracy: 69.9%
Batch 10, Loss: 0.7763
Batch 20, Loss: 0.8225
Batch 30, Loss: 0.8311
Batch 40, Loss: 0.8096
Batch 50, Loss: 0.8001
Batch 60, Loss: 0.8351
Batch 70, Loss: 0.8552
Batch 80, Loss: 0.7971
Batch 90, Loss: 0.7669
Batch 100, Loss: 0.7654
Batch 110, Loss: 0.8223
Batch 120, Loss: 0.8345
Batch 130, Loss: 0.8024
Batch 140, Loss: 0.8603
Batch 150, Loss: 0.8590
Batch 160, Loss: 0.7889
Batch 170, Loss: 0.7949
Batch 180, Loss: 0.7837
Batch 190, Loss: 0.8507
Batch 200, Loss: 0.8327
Batch 210, Loss: 0.8685
Batch 220, Loss: 0.8406
Batch 230, Loss: 0.8557
Batch 240, Loss: 0.8819
Batch 250, Loss: 0.8548
Batch 260, Loss: 0.8408
Batch 270, Loss: 0.8407
Batch 280, Loss: 0.8475
Batch 290, Loss: 0.9147
Batch 300, Loss: 0.8502
Batch 310, Loss: 0.8338
Batch 320, Loss: 0.8826
Batch 330, Loss: 0.7837
Batch 340, Loss: 0.8303
Batch 350, Loss: 0.8734
Batch 360, Loss: 0.9275
Batch 370, Loss: 0.8997
Batch 380, Loss: 0.8519
Batch 390, Loss: 0.8903
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.29966163635254 seconds
Epoch 129 accuracy: 69.26%
Batch 10, Loss: 0.8430
Batch 20, Loss: 0.7794
Batch 30, Loss: 0.7604
Batch 40, Loss: 0.8137
Batch 50, Loss: 0.7723
Batch 60, Loss: 0.7771
Batch 70, Loss: 0.7927
Batch 80, Loss: 0.8100
Batch 90, Loss: 0.7979
Batch 100, Loss: 0.7931
Batch 110, Loss: 0.8143
Batch 120, Loss: 0.8068
Batch 130, Loss: 0.8264
Batch 140, Loss: 0.8229
Batch 150, Loss: 0.7966
Batch 160, Loss: 0.7886
Batch 170, Loss: 0.8023
Batch 180, Loss: 0.8184
Batch 190, Loss: 0.7896
Batch 200, Loss: 0.7994
Batch 210, Loss: 0.8425
Batch 220, Loss: 0.8017
Batch 230, Loss: 0.8074
Batch 240, Loss: 0.8405
Batch 250, Loss: 0.8462
Batch 260, Loss: 0.8513
Batch 270, Loss: 0.8149
Batch 280, Loss: 0.8519
Batch 290, Loss: 0.7966
Batch 300, Loss: 0.8075
Batch 310, Loss: 0.8484
Batch 320, Loss: 0.8150
Batch 330, Loss: 0.8859
Batch 340, Loss: 0.8852
Batch 350, Loss: 0.8823
Batch 360, Loss: 0.8775
Batch 370, Loss: 0.8096
Batch 380, Loss: 0.9414
Batch 390, Loss: 0.8584
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.508045196533203 seconds
Epoch 130 accuracy: 70.72%
Batch 10, Loss: 0.7971
Batch 20, Loss: 0.8017
Batch 30, Loss: 0.8066
Batch 40, Loss: 0.7809
Batch 50, Loss: 0.7395
Batch 60, Loss: 0.7828
Batch 70, Loss: 0.7937
Batch 80, Loss: 0.8308
Batch 90, Loss: 0.8241
Batch 100, Loss: 0.8196
Batch 110, Loss: 0.8292
Batch 120, Loss: 0.7992
Batch 130, Loss: 0.8009
Batch 140, Loss: 0.7603
Batch 150, Loss: 0.8290
Batch 160, Loss: 0.7885
Batch 170, Loss: 0.8051
Batch 180, Loss: 0.8023
Batch 190, Loss: 0.7874
Batch 200, Loss: 0.8423
Batch 210, Loss: 0.7989
Batch 220, Loss: 0.7970
Batch 230, Loss: 0.7613
Batch 240, Loss: 0.7874
Batch 250, Loss: 0.8394
Batch 260, Loss: 0.7994
Batch 270, Loss: 0.8358
Batch 280, Loss: 0.8392
Batch 290, Loss: 0.9017
Batch 300, Loss: 0.8201
Batch 310, Loss: 0.8630
Batch 320, Loss: 0.8565
Batch 330, Loss: 0.8264
Batch 340, Loss: 0.7822
Batch 350, Loss: 0.7978
Batch 360, Loss: 0.8664
Batch 370, Loss: 0.8773
Batch 380, Loss: 0.8253
Batch 390, Loss: 0.8761
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.32204818725586 seconds
Epoch 131 accuracy: 70.99%
Batch 10, Loss: 0.7860
Batch 20, Loss: 0.7921
Batch 30, Loss: 0.7600
Batch 40, Loss: 0.7349
Batch 50, Loss: 0.7748
Batch 60, Loss: 0.7412
Batch 70, Loss: 0.7648
Batch 80, Loss: 0.7421
Batch 90, Loss: 0.7960
Batch 100, Loss: 0.7723
Batch 110, Loss: 0.7527
Batch 120, Loss: 0.7711
Batch 130, Loss: 0.8201
Batch 140, Loss: 0.8115
Batch 150, Loss: 0.7994
Batch 160, Loss: 0.7648
Batch 170, Loss: 0.8813
Batch 180, Loss: 0.8339
Batch 190, Loss: 0.8016
Batch 200, Loss: 0.7930
Batch 210, Loss: 0.8534
Batch 220, Loss: 0.7807
Batch 230, Loss: 0.8193
Batch 240, Loss: 0.8114
Batch 250, Loss: 0.8374
Batch 260, Loss: 0.8469
Batch 270, Loss: 0.8001
Batch 280, Loss: 0.8092
Batch 290, Loss: 0.8350
Batch 300, Loss: 0.7940
Batch 310, Loss: 0.8425
Batch 320, Loss: 0.8505
Batch 330, Loss: 0.8889
Batch 340, Loss: 0.8158
Batch 350, Loss: 0.8287
Batch 360, Loss: 0.8354
Batch 370, Loss: 0.8752
Batch 380, Loss: 0.8600
Batch 390, Loss: 0.8738
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.348636150360107 seconds
Epoch 132 accuracy: 70.95%
Batch 10, Loss: 0.7767
Batch 20, Loss: 0.7846
Batch 30, Loss: 0.7690
Batch 40, Loss: 0.7718
Batch 50, Loss: 0.7839
Batch 60, Loss: 0.7640
Batch 70, Loss: 0.7597
Batch 80, Loss: 0.7766
Batch 90, Loss: 0.7577
Batch 100, Loss: 0.7683
Batch 110, Loss: 0.7683
Batch 120, Loss: 0.7789
Batch 130, Loss: 0.8388
Batch 140, Loss: 0.8119
Batch 150, Loss: 0.7866
Batch 160, Loss: 0.7964
Batch 170, Loss: 0.8118
Batch 180, Loss: 0.8099
Batch 190, Loss: 0.7729
Batch 200, Loss: 0.8043
Batch 210, Loss: 0.8306
Batch 220, Loss: 0.7776
Batch 230, Loss: 0.8657
Batch 240, Loss: 0.7968
Batch 250, Loss: 0.8156
Batch 260, Loss: 0.7875
Batch 270, Loss: 0.8108
Batch 280, Loss: 0.7743
Batch 290, Loss: 0.8764
Batch 300, Loss: 0.8365
Batch 310, Loss: 0.7918
Batch 320, Loss: 0.7985
Batch 330, Loss: 0.7747
Batch 340, Loss: 0.8396
Batch 350, Loss: 0.8423
Batch 360, Loss: 0.8357
Batch 370, Loss: 0.8059
Batch 380, Loss: 0.8247
Batch 390, Loss: 0.7651
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.373199939727783 seconds
Epoch 133 accuracy: 71.58%
Batch 10, Loss: 0.7916
Batch 20, Loss: 0.7340
Batch 30, Loss: 0.7400
Batch 40, Loss: 0.7154
Batch 50, Loss: 0.7915
Batch 60, Loss: 0.7762
Batch 70, Loss: 0.7889
Batch 80, Loss: 0.7840
Batch 90, Loss: 0.7967
Batch 100, Loss: 0.8307
Batch 110, Loss: 0.7492
Batch 120, Loss: 0.7869
Batch 130, Loss: 0.7726
Batch 140, Loss: 0.7858
Batch 150, Loss: 0.7224
Batch 160, Loss: 0.7809
Batch 170, Loss: 0.7784
Batch 180, Loss: 0.8246
Batch 190, Loss: 0.7630
Batch 200, Loss: 0.7833
Batch 210, Loss: 0.7691
Batch 220, Loss: 0.7581
Batch 230, Loss: 0.8021
Batch 240, Loss: 0.8097
Batch 250, Loss: 0.8434
Batch 260, Loss: 0.7650
Batch 270, Loss: 0.8319
Batch 280, Loss: 0.8002
Batch 290, Loss: 0.8329
Batch 300, Loss: 0.8046
Batch 310, Loss: 0.8161
Batch 320, Loss: 0.7886
Batch 330, Loss: 0.7523
Batch 340, Loss: 0.7997
Batch 350, Loss: 0.7604
Batch 360, Loss: 0.7653
Batch 370, Loss: 0.7988
Batch 380, Loss: 0.8362
Batch 390, Loss: 0.7924
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.319175958633423 seconds
Epoch 134 accuracy: 71.93%
Batch 10, Loss: 0.7229
Batch 20, Loss: 0.7296
Batch 30, Loss: 0.7547
Batch 40, Loss: 0.7436
Batch 50, Loss: 0.7047
Batch 60, Loss: 0.7438
Batch 70, Loss: 0.7548
Batch 80, Loss: 0.7891
Batch 90, Loss: 0.7306
Batch 100, Loss: 0.7802
Batch 110, Loss: 0.7216
Batch 120, Loss: 0.7631
Batch 130, Loss: 0.7399
Batch 140, Loss: 0.7774
Batch 150, Loss: 0.7953
Batch 160, Loss: 0.8679
Batch 170, Loss: 0.7433
Batch 180, Loss: 0.7188
Batch 190, Loss: 0.7568
Batch 200, Loss: 0.8420
Batch 210, Loss: 0.8108
Batch 220, Loss: 0.7690
Batch 230, Loss: 0.7573
Batch 240, Loss: 0.8095
Batch 250, Loss: 0.8110
Batch 260, Loss: 0.7932
Batch 270, Loss: 0.8451
Batch 280, Loss: 0.7497
Batch 290, Loss: 0.8141
Batch 300, Loss: 0.7977
Batch 310, Loss: 0.8176
Batch 320, Loss: 0.7992
Batch 330, Loss: 0.7877
Batch 340, Loss: 0.8107
Batch 350, Loss: 0.7821
Batch 360, Loss: 0.8163
Batch 370, Loss: 0.7857
Batch 380, Loss: 0.7800
Batch 390, Loss: 0.7911
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.48997163772583 seconds
Epoch 135 accuracy: 72.01%
Batch 10, Loss: 0.7213
Batch 20, Loss: 0.7616
Batch 30, Loss: 0.7158
Batch 40, Loss: 0.7368
Batch 50, Loss: 0.7331
Batch 60, Loss: 0.7498
Batch 70, Loss: 0.7323
Batch 80, Loss: 0.7256
Batch 90, Loss: 0.7728
Batch 100, Loss: 0.7688
Batch 110, Loss: 0.7776
Batch 120, Loss: 0.7770
Batch 130, Loss: 0.7253
Batch 140, Loss: 0.7326
Batch 150, Loss: 0.7298
Batch 160, Loss: 0.7424
Batch 170, Loss: 0.7440
Batch 180, Loss: 0.7769
Batch 190, Loss: 0.7160
Batch 200, Loss: 0.7309
Batch 210, Loss: 0.7462
Batch 220, Loss: 0.7544
Batch 230, Loss: 0.7949
Batch 240, Loss: 0.7632
Batch 250, Loss: 0.7772
Batch 260, Loss: 0.7765
Batch 270, Loss: 0.8202
Batch 280, Loss: 0.7939
Batch 290, Loss: 0.7443
Batch 300, Loss: 0.7547
Batch 310, Loss: 0.7685
Batch 320, Loss: 0.7675
Batch 330, Loss: 0.6997
Batch 340, Loss: 0.7911
Batch 350, Loss: 0.7107
Batch 360, Loss: 0.8157
Batch 370, Loss: 0.7274
Batch 380, Loss: 0.7624
Batch 390, Loss: 0.8201
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.39115810394287 seconds
Epoch 136 accuracy: 72.41%
Batch 10, Loss: 0.7123
Batch 20, Loss: 0.7475
Batch 30, Loss: 0.7265
Batch 40, Loss: 0.7105
Batch 50, Loss: 0.7630
Batch 60, Loss: 0.6758
Batch 70, Loss: 0.7127
Batch 80, Loss: 0.7462
Batch 90, Loss: 0.7432
Batch 100, Loss: 0.7386
Batch 110, Loss: 0.7358
Batch 120, Loss: 0.7250
Batch 130, Loss: 0.7704
Batch 140, Loss: 0.7411
Batch 150, Loss: 0.6866
Batch 160, Loss: 0.7164
Batch 170, Loss: 0.7117
Batch 180, Loss: 0.7562
Batch 190, Loss: 0.7526
Batch 200, Loss: 0.7486
Batch 210, Loss: 0.7294
Batch 220, Loss: 0.7663
Batch 230, Loss: 0.8091
Batch 240, Loss: 0.7934
Batch 250, Loss: 0.8001
Batch 260, Loss: 0.8190
Batch 270, Loss: 0.8082
Batch 280, Loss: 0.7438
Batch 290, Loss: 0.7005
Batch 300, Loss: 0.7575
Batch 310, Loss: 0.8178
Batch 320, Loss: 0.8001
Batch 330, Loss: 0.8031
Batch 340, Loss: 0.7871
Batch 350, Loss: 0.7916
Batch 360, Loss: 0.7869
Batch 370, Loss: 0.7729
Batch 380, Loss: 0.7662
Batch 390, Loss: 0.7984
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.27587056159973 seconds
Epoch 137 accuracy: 72.58%
Batch 10, Loss: 0.7052
Batch 20, Loss: 0.6599
Batch 30, Loss: 0.7207
Batch 40, Loss: 0.7199
Batch 50, Loss: 0.7416
Batch 60, Loss: 0.7078
Batch 70, Loss: 0.6828
Batch 80, Loss: 0.7425
Batch 90, Loss: 0.7060
Batch 100, Loss: 0.7554
Batch 110, Loss: 0.7328
Batch 120, Loss: 0.7148
Batch 130, Loss: 0.7296
Batch 140, Loss: 0.7619
Batch 150, Loss: 0.7383
Batch 160, Loss: 0.7408
Batch 170, Loss: 0.7388
Batch 180, Loss: 0.7963
Batch 190, Loss: 0.7527
Batch 200, Loss: 0.8539
Batch 210, Loss: 0.7525
Batch 220, Loss: 0.7748
Batch 230, Loss: 0.7448
Batch 240, Loss: 0.7204
Batch 250, Loss: 0.7577
Batch 260, Loss: 0.7393
Batch 270, Loss: 0.7555
Batch 280, Loss: 0.7267
Batch 290, Loss: 0.7583
Batch 300, Loss: 0.7274
Batch 310, Loss: 0.7394
Batch 320, Loss: 0.7719
Batch 330, Loss: 0.7312
Batch 340, Loss: 0.7795
Batch 350, Loss: 0.6856
Batch 360, Loss: 0.7424
Batch 370, Loss: 0.7464
Batch 380, Loss: 0.7766
Batch 390, Loss: 0.7679
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.2790310382843 seconds
Epoch 138 accuracy: 72.58%
Batch 10, Loss: 0.6822
Batch 20, Loss: 0.7119
Batch 30, Loss: 0.6968
Batch 40, Loss: 0.7276
Batch 50, Loss: 0.7348
Batch 60, Loss: 0.7278
Batch 70, Loss: 0.7207
Batch 80, Loss: 0.6484
Batch 90, Loss: 0.7500
Batch 100, Loss: 0.6897
Batch 110, Loss: 0.7621
Batch 120, Loss: 0.7157
Batch 130, Loss: 0.6865
Batch 140, Loss: 0.7552
Batch 150, Loss: 0.7731
Batch 160, Loss: 0.6601
Batch 170, Loss: 0.7746
Batch 180, Loss: 0.7112
Batch 190, Loss: 0.7399
Batch 200, Loss: 0.7266
Batch 210, Loss: 0.6654
Batch 220, Loss: 0.6876
Batch 230, Loss: 0.7299
Batch 240, Loss: 0.7169
Batch 250, Loss: 0.7631
Batch 260, Loss: 0.7153
Batch 270, Loss: 0.7267
Batch 280, Loss: 0.7357
Batch 290, Loss: 0.7253
Batch 300, Loss: 0.7572
Batch 310, Loss: 0.7391
Batch 320, Loss: 0.7818
Batch 330, Loss: 0.7760
Batch 340, Loss: 0.7990
Batch 350, Loss: 0.7046
Batch 360, Loss: 0.7657
Batch 370, Loss: 0.7838
Batch 380, Loss: 0.7808
Batch 390, Loss: 0.7364
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.266011714935303 seconds
Epoch 139 accuracy: 70.63%
Batch 10, Loss: 0.7086
Batch 20, Loss: 0.6984
Batch 30, Loss: 0.7173
Batch 40, Loss: 0.6775
Batch 50, Loss: 0.7117
Batch 60, Loss: 0.6957
Batch 70, Loss: 0.6833
Batch 80, Loss: 0.7232
Batch 90, Loss: 0.7355
Batch 100, Loss: 0.7422
Batch 110, Loss: 0.7202
Batch 120, Loss: 0.6704
Batch 130, Loss: 0.7494
Batch 140, Loss: 0.7398
Batch 150, Loss: 0.7071
Batch 160, Loss: 0.7057
Batch 170, Loss: 0.7247
Batch 180, Loss: 0.7142
Batch 190, Loss: 0.7363
Batch 200, Loss: 0.6882
Batch 210, Loss: 0.7209
Batch 220, Loss: 0.6998
Batch 230, Loss: 0.6835
Batch 240, Loss: 0.7273
Batch 250, Loss: 0.7212
Batch 260, Loss: 0.7371
Batch 270, Loss: 0.7401
Batch 280, Loss: 0.7203
Batch 290, Loss: 0.7037
Batch 300, Loss: 0.7378
Batch 310, Loss: 0.7811
Batch 320, Loss: 0.7291
Batch 330, Loss: 0.7511
Batch 340, Loss: 0.6754
Batch 350, Loss: 0.7010
Batch 360, Loss: 0.6763
Batch 370, Loss: 0.7493
Batch 380, Loss: 0.7632
Batch 390, Loss: 0.7538
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.386370182037354 seconds
Epoch 140 accuracy: 71.99%
Batch 10, Loss: 0.6510
Batch 20, Loss: 0.6704
Batch 30, Loss: 0.6552
Batch 40, Loss: 0.6674
Batch 50, Loss: 0.6389
Batch 60, Loss: 0.6831
Batch 70, Loss: 0.7047
Batch 80, Loss: 0.6888
Batch 90, Loss: 0.7152
Batch 100, Loss: 0.6748
Batch 110, Loss: 0.6761
Batch 120, Loss: 0.6860
Batch 130, Loss: 0.6732
Batch 140, Loss: 0.7156
Batch 150, Loss: 0.6957
Batch 160, Loss: 0.7714
Batch 170, Loss: 0.6612
Batch 180, Loss: 0.7069
Batch 190, Loss: 0.7223
Batch 200, Loss: 0.7187
Batch 210, Loss: 0.6934
Batch 220, Loss: 0.7288
Batch 230, Loss: 0.6673
Batch 240, Loss: 0.6935
Batch 250, Loss: 0.6932
Batch 260, Loss: 0.7225
Batch 270, Loss: 0.7148
Batch 280, Loss: 0.7273
Batch 290, Loss: 0.7654
Batch 300, Loss: 0.7040
Batch 310, Loss: 0.7425
Batch 320, Loss: 0.7512
Batch 330, Loss: 0.7128
Batch 340, Loss: 0.7071
Batch 350, Loss: 0.7283
Batch 360, Loss: 0.7220
Batch 370, Loss: 0.7411
Batch 380, Loss: 0.7225
Batch 390, Loss: 0.7197
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.391122102737427 seconds
Epoch 141 accuracy: 73.14%
Batch 10, Loss: 0.6309
Batch 20, Loss: 0.6474
Batch 30, Loss: 0.6718
Batch 40, Loss: 0.6027
Batch 50, Loss: 0.6461
Batch 60, Loss: 0.6427
Batch 70, Loss: 0.6539
Batch 80, Loss: 0.6535
Batch 90, Loss: 0.6582
Batch 100, Loss: 0.6273
Batch 110, Loss: 0.6925
Batch 120, Loss: 0.6658
Batch 130, Loss: 0.6651
Batch 140, Loss: 0.7108
Batch 150, Loss: 0.6454
Batch 160, Loss: 0.6985
Batch 170, Loss: 0.6907
Batch 180, Loss: 0.6582
Batch 190, Loss: 0.6689
Batch 200, Loss: 0.7429
Batch 210, Loss: 0.6890
Batch 220, Loss: 0.6506
Batch 230, Loss: 0.7501
Batch 240, Loss: 0.7111
Batch 250, Loss: 0.7046
Batch 260, Loss: 0.6666
Batch 270, Loss: 0.7600
Batch 280, Loss: 0.7076
Batch 290, Loss: 0.7020
Batch 300, Loss: 0.7703
Batch 310, Loss: 0.6814
Batch 320, Loss: 0.7127
Batch 330, Loss: 0.7286
Batch 340, Loss: 0.7005
Batch 350, Loss: 0.7251
Batch 360, Loss: 0.7011
Batch 370, Loss: 0.7017
Batch 380, Loss: 0.7472
Batch 390, Loss: 0.7352
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.285107135772705 seconds
Epoch 142 accuracy: 70.58%
Batch 10, Loss: 0.6551
Batch 20, Loss: 0.7299
Batch 30, Loss: 0.6458
Batch 40, Loss: 0.6718
Batch 50, Loss: 0.7088
Batch 60, Loss: 0.6358
Batch 70, Loss: 0.6778
Batch 80, Loss: 0.6432
Batch 90, Loss: 0.6704
Batch 100, Loss: 0.7011
Batch 110, Loss: 0.6285
Batch 120, Loss: 0.6518
Batch 130, Loss: 0.6797
Batch 140, Loss: 0.6957
Batch 150, Loss: 0.6506
Batch 160, Loss: 0.6521
Batch 170, Loss: 0.6659
Batch 180, Loss: 0.6779
Batch 190, Loss: 0.6916
Batch 200, Loss: 0.6724
Batch 210, Loss: 0.6700
Batch 220, Loss: 0.6774
Batch 230, Loss: 0.7501
Batch 240, Loss: 0.7187
Batch 250, Loss: 0.7017
Batch 260, Loss: 0.6886
Batch 270, Loss: 0.7384
Batch 280, Loss: 0.7041
Batch 290, Loss: 0.7111
Batch 300, Loss: 0.7099
Batch 310, Loss: 0.7419
Batch 320, Loss: 0.7224
Batch 330, Loss: 0.6715
Batch 340, Loss: 0.7316
Batch 350, Loss: 0.6894
Batch 360, Loss: 0.7050
Batch 370, Loss: 0.7467
Batch 380, Loss: 0.6902
Batch 390, Loss: 0.6404
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.513294458389282 seconds
Epoch 143 accuracy: 72.7%
Batch 10, Loss: 0.7112
Batch 20, Loss: 0.6866
Batch 30, Loss: 0.6437
Batch 40, Loss: 0.6605
Batch 50, Loss: 0.6639
Batch 60, Loss: 0.6099
Batch 70, Loss: 0.6231
Batch 80, Loss: 0.6203
Batch 90, Loss: 0.6621
Batch 100, Loss: 0.6528
Batch 110, Loss: 0.6344
Batch 120, Loss: 0.6766
Batch 130, Loss: 0.6331
Batch 140, Loss: 0.7084
Batch 150, Loss: 0.6899
Batch 160, Loss: 0.6620
Batch 170, Loss: 0.6950
Batch 180, Loss: 0.7264
Batch 190, Loss: 0.6758
Batch 200, Loss: 0.6490
Batch 210, Loss: 0.6721
Batch 220, Loss: 0.6559
Batch 230, Loss: 0.6705
Batch 240, Loss: 0.6758
Batch 250, Loss: 0.6669
Batch 260, Loss: 0.6821
Batch 270, Loss: 0.7107
Batch 280, Loss: 0.7344
Batch 290, Loss: 0.6661
Batch 300, Loss: 0.6722
Batch 310, Loss: 0.6945
Batch 320, Loss: 0.6525
Batch 330, Loss: 0.6272
Batch 340, Loss: 0.6856
Batch 350, Loss: 0.6905
Batch 360, Loss: 0.6911
Batch 370, Loss: 0.6624
Batch 380, Loss: 0.6683
Batch 390, Loss: 0.6480
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.260967016220093 seconds
Epoch 144 accuracy: 74.25%
Batch 10, Loss: 0.6622
Batch 20, Loss: 0.6373
Batch 30, Loss: 0.5968
Batch 40, Loss: 0.6513
Batch 50, Loss: 0.5777
Batch 60, Loss: 0.6166
Batch 70, Loss: 0.6326
Batch 80, Loss: 0.5954
Batch 90, Loss: 0.6263
Batch 100, Loss: 0.5900
Batch 110, Loss: 0.6420
Batch 120, Loss: 0.6620
Batch 130, Loss: 0.6199
Batch 140, Loss: 0.6149
Batch 150, Loss: 0.6984
Batch 160, Loss: 0.6499
Batch 170, Loss: 0.6745
Batch 180, Loss: 0.6437
Batch 190, Loss: 0.6861
Batch 200, Loss: 0.6953
Batch 210, Loss: 0.6135
Batch 220, Loss: 0.6365
Batch 230, Loss: 0.6493
Batch 240, Loss: 0.6468
Batch 250, Loss: 0.6549
Batch 260, Loss: 0.7187
Batch 270, Loss: 0.6405
Batch 280, Loss: 0.6812
Batch 290, Loss: 0.6616
Batch 300, Loss: 0.6145
Batch 310, Loss: 0.6127
Batch 320, Loss: 0.7202
Batch 330, Loss: 0.6445
Batch 340, Loss: 0.6914
Batch 350, Loss: 0.6921
Batch 360, Loss: 0.6829
Batch 370, Loss: 0.6525
Batch 380, Loss: 0.6967
Batch 390, Loss: 0.7232
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.427850008010864 seconds
Epoch 145 accuracy: 73.05%
Batch 10, Loss: 0.6110
Batch 20, Loss: 0.6654
Batch 30, Loss: 0.6117
Batch 40, Loss: 0.6335
Batch 50, Loss: 0.6185
Batch 60, Loss: 0.5974
Batch 70, Loss: 0.6343
Batch 80, Loss: 0.5843
Batch 90, Loss: 0.6088
Batch 100, Loss: 0.6311
Batch 110, Loss: 0.6440
Batch 120, Loss: 0.6230
Batch 130, Loss: 0.6215
Batch 140, Loss: 0.6068
Batch 150, Loss: 0.6212
Batch 160, Loss: 0.6428
Batch 170, Loss: 0.6045
Batch 180, Loss: 0.6080
Batch 190, Loss: 0.6255
Batch 200, Loss: 0.6493
Batch 210, Loss: 0.5893
Batch 220, Loss: 0.6650
Batch 230, Loss: 0.6975
Batch 240, Loss: 0.6303
Batch 250, Loss: 0.6630
Batch 260, Loss: 0.6779
Batch 270, Loss: 0.6536
Batch 280, Loss: 0.7059
Batch 290, Loss: 0.6501
Batch 300, Loss: 0.6489
Batch 310, Loss: 0.6400
Batch 320, Loss: 0.6694
Batch 330, Loss: 0.6520
Batch 340, Loss: 0.6680
Batch 350, Loss: 0.6382
Batch 360, Loss: 0.6527
Batch 370, Loss: 0.6416
Batch 380, Loss: 0.6841
Batch 390, Loss: 0.7177
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.3672091960907 seconds
Epoch 146 accuracy: 73.03%
Batch 10, Loss: 0.5870
Batch 20, Loss: 0.6083
Batch 30, Loss: 0.5856
Batch 40, Loss: 0.6221
Batch 50, Loss: 0.6041
Batch 60, Loss: 0.5983
Batch 70, Loss: 0.6088
Batch 80, Loss: 0.6664
Batch 90, Loss: 0.6522
Batch 100, Loss: 0.5909
Batch 110, Loss: 0.5969
Batch 120, Loss: 0.6481
Batch 130, Loss: 0.6494
Batch 140, Loss: 0.6283
Batch 150, Loss: 0.5984
Batch 160, Loss: 0.6353
Batch 170, Loss: 0.6533
Batch 180, Loss: 0.6353
Batch 190, Loss: 0.6600
Batch 200, Loss: 0.6179
Batch 210, Loss: 0.6414
Batch 220, Loss: 0.6421
Batch 230, Loss: 0.6116
Batch 240, Loss: 0.6116
Batch 250, Loss: 0.6915
Batch 260, Loss: 0.6076
Batch 270, Loss: 0.6266
Batch 280, Loss: 0.6248
Batch 290, Loss: 0.5883
Batch 300, Loss: 0.6433
Batch 310, Loss: 0.6055
Batch 320, Loss: 0.6415
Batch 330, Loss: 0.6670
Batch 340, Loss: 0.6487
Batch 350, Loss: 0.6408
Batch 360, Loss: 0.7006
Batch 370, Loss: 0.6362
Batch 380, Loss: 0.6620
Batch 390, Loss: 0.7188
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.35672616958618 seconds
Epoch 147 accuracy: 73.07%
Batch 10, Loss: 0.6423
Batch 20, Loss: 0.5921
Batch 30, Loss: 0.6288
Batch 40, Loss: 0.6039
Batch 50, Loss: 0.6356
Batch 60, Loss: 0.5951
Batch 70, Loss: 0.5946
Batch 80, Loss: 0.6209
Batch 90, Loss: 0.6257
Batch 100, Loss: 0.6284
Batch 110, Loss: 0.5824
Batch 120, Loss: 0.6424
Batch 130, Loss: 0.5971
Batch 140, Loss: 0.5933
Batch 150, Loss: 0.5967
Batch 160, Loss: 0.6156
Batch 170, Loss: 0.6363
Batch 180, Loss: 0.6882
Batch 190, Loss: 0.6318
Batch 200, Loss: 0.6051
Batch 210, Loss: 0.6787
Batch 220, Loss: 0.6193
Batch 230, Loss: 0.6121
Batch 240, Loss: 0.6150
Batch 250, Loss: 0.6738
Batch 260, Loss: 0.6438
Batch 270, Loss: 0.6820
Batch 280, Loss: 0.6430
Batch 290, Loss: 0.6059
Batch 300, Loss: 0.6270
Batch 310, Loss: 0.6333
Batch 320, Loss: 0.6627
Batch 330, Loss: 0.5820
Batch 340, Loss: 0.6377
Batch 350, Loss: 0.6609
Batch 360, Loss: 0.6715
Batch 370, Loss: 0.6022
Batch 380, Loss: 0.6156
Batch 390, Loss: 0.6685
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.232450008392334 seconds
Epoch 148 accuracy: 73.32%
Batch 10, Loss: 0.5931
Batch 20, Loss: 0.6344
Batch 30, Loss: 0.5653
Batch 40, Loss: 0.6064
Batch 50, Loss: 0.5591
Batch 60, Loss: 0.5539
Batch 70, Loss: 0.6213
Batch 80, Loss: 0.5723
Batch 90, Loss: 0.5683
Batch 100, Loss: 0.6284
Batch 110, Loss: 0.5610
Batch 120, Loss: 0.5933
Batch 130, Loss: 0.5624
Batch 140, Loss: 0.5895
Batch 150, Loss: 0.6013
Batch 160, Loss: 0.6194
Batch 170, Loss: 0.5626
Batch 180, Loss: 0.6357
Batch 190, Loss: 0.5558
Batch 200, Loss: 0.5820
Batch 210, Loss: 0.6149
Batch 220, Loss: 0.6022
Batch 230, Loss: 0.6351
Batch 240, Loss: 0.5931
Batch 250, Loss: 0.6220
Batch 260, Loss: 0.6100
Batch 270, Loss: 0.6344
Batch 280, Loss: 0.6083
Batch 290, Loss: 0.6692
Batch 300, Loss: 0.6500
Batch 310, Loss: 0.7085
Batch 320, Loss: 0.5945
Batch 330, Loss: 0.6352
Batch 340, Loss: 0.6374
Batch 350, Loss: 0.5750
Batch 360, Loss: 0.6363
Batch 370, Loss: 0.5861
Batch 380, Loss: 0.6112
Batch 390, Loss: 0.6695
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.378929376602173 seconds
Epoch 149 accuracy: 75.33%
Batch 10, Loss: 0.6288
Batch 20, Loss: 0.5873
Batch 30, Loss: 0.6089
Batch 40, Loss: 0.5591
Batch 50, Loss: 0.6044
Batch 60, Loss: 0.5860
Batch 70, Loss: 0.5744
Batch 80, Loss: 0.5935
Batch 90, Loss: 0.5535
Batch 100, Loss: 0.5334
Batch 110, Loss: 0.6024
Batch 120, Loss: 0.5576
Batch 130, Loss: 0.6024
Batch 140, Loss: 0.6141
Batch 150, Loss: 0.5964
Batch 160, Loss: 0.6566
Batch 170, Loss: 0.5898
Batch 180, Loss: 0.6129
Batch 190, Loss: 0.6214
Batch 200, Loss: 0.5829
Batch 210, Loss: 0.6451
Batch 220, Loss: 0.5765
Batch 230, Loss: 0.5960
Batch 240, Loss: 0.5548
Batch 250, Loss: 0.6082
Batch 260, Loss: 0.5549
Batch 270, Loss: 0.5817
Batch 280, Loss: 0.5940
Batch 290, Loss: 0.6240
Batch 300, Loss: 0.6332
Batch 310, Loss: 0.6110
Batch 320, Loss: 0.5727
Batch 330, Loss: 0.5846
Batch 340, Loss: 0.6042
Batch 350, Loss: 0.5934
Batch 360, Loss: 0.6054
Batch 370, Loss: 0.6150
Batch 380, Loss: 0.6419
Batch 390, Loss: 0.6079
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.22844934463501 seconds
Epoch 150 accuracy: 74.67%
Batch 10, Loss: 0.5771
Batch 20, Loss: 0.5889
Batch 30, Loss: 0.5476
Batch 40, Loss: 0.5660
Batch 50, Loss: 0.5493
Batch 60, Loss: 0.6228
Batch 70, Loss: 0.6318
Batch 80, Loss: 0.5818
Batch 90, Loss: 0.5416
Batch 100, Loss: 0.5650
Batch 110, Loss: 0.5290
Batch 120, Loss: 0.5524
Batch 130, Loss: 0.5518
Batch 140, Loss: 0.5460
Batch 150, Loss: 0.5554
Batch 160, Loss: 0.5255
Batch 170, Loss: 0.6005
Batch 180, Loss: 0.5333
Batch 190, Loss: 0.5747
Batch 200, Loss: 0.6023
Batch 210, Loss: 0.6685
Batch 220, Loss: 0.6049
Batch 230, Loss: 0.6336
Batch 240, Loss: 0.5535
Batch 250, Loss: 0.5465
Batch 260, Loss: 0.5961
Batch 270, Loss: 0.5655
Batch 280, Loss: 0.5959
Batch 290, Loss: 0.5781
Batch 300, Loss: 0.5626
Batch 310, Loss: 0.5398
Batch 320, Loss: 0.6552
Batch 330, Loss: 0.5951
Batch 340, Loss: 0.5880
Batch 350, Loss: 0.6193
Batch 360, Loss: 0.5902
Batch 370, Loss: 0.6099
Batch 380, Loss: 0.5676
Batch 390, Loss: 0.6412
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.22638964653015 seconds
Epoch 151 accuracy: 74.47%
Batch 10, Loss: 0.5490
Batch 20, Loss: 0.5895
Batch 30, Loss: 0.5351
Batch 40, Loss: 0.5827
Batch 50, Loss: 0.5599
Batch 60, Loss: 0.5578
Batch 70, Loss: 0.5435
Batch 80, Loss: 0.5682
Batch 90, Loss: 0.5220
Batch 100, Loss: 0.5461
Batch 110, Loss: 0.5737
Batch 120, Loss: 0.5691
Batch 130, Loss: 0.5434
Batch 140, Loss: 0.5513
Batch 150, Loss: 0.5566
Batch 160, Loss: 0.5727
Batch 170, Loss: 0.5735
Batch 180, Loss: 0.5732
Batch 190, Loss: 0.5866
Batch 200, Loss: 0.5860
Batch 210, Loss: 0.5583
Batch 220, Loss: 0.6146
Batch 230, Loss: 0.5878
Batch 240, Loss: 0.5765
Batch 250, Loss: 0.5140
Batch 260, Loss: 0.5720
Batch 270, Loss: 0.5771
Batch 280, Loss: 0.5933
Batch 290, Loss: 0.5983
Batch 300, Loss: 0.5750
Batch 310, Loss: 0.6044
Batch 320, Loss: 0.5794
Batch 330, Loss: 0.5512
Batch 340, Loss: 0.5863
Batch 350, Loss: 0.6106
Batch 360, Loss: 0.5848
Batch 370, Loss: 0.6490
Batch 380, Loss: 0.5687
Batch 390, Loss: 0.5621
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.278029203414917 seconds
Epoch 152 accuracy: 75.42%
Batch 10, Loss: 0.5456
Batch 20, Loss: 0.5359
Batch 30, Loss: 0.5659
Batch 40, Loss: 0.5443
Batch 50, Loss: 0.5634
Batch 60, Loss: 0.5866
Batch 70, Loss: 0.5779
Batch 80, Loss: 0.5626
Batch 90, Loss: 0.5481
Batch 100, Loss: 0.5622
Batch 110, Loss: 0.5019
Batch 120, Loss: 0.6129
Batch 130, Loss: 0.5603
Batch 140, Loss: 0.5727
Batch 150, Loss: 0.5688
Batch 160, Loss: 0.5792
Batch 170, Loss: 0.5707
Batch 180, Loss: 0.6084
Batch 190, Loss: 0.5803
Batch 200, Loss: 0.5475
Batch 210, Loss: 0.5574
Batch 220, Loss: 0.5317
Batch 230, Loss: 0.5805
Batch 240, Loss: 0.5160
Batch 250, Loss: 0.5815
Batch 260, Loss: 0.5529
Batch 270, Loss: 0.5869
Batch 280, Loss: 0.6116
Batch 290, Loss: 0.5864
Batch 300, Loss: 0.5412
Batch 310, Loss: 0.5333
Batch 320, Loss: 0.6316
Batch 330, Loss: 0.5870
Batch 340, Loss: 0.5832
Batch 350, Loss: 0.5699
Batch 360, Loss: 0.5934
Batch 370, Loss: 0.5605
Batch 380, Loss: 0.5705
Batch 390, Loss: 0.5470
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.278628826141357 seconds
Epoch 153 accuracy: 75.45%
Batch 10, Loss: 0.5606
Batch 20, Loss: 0.4827
Batch 30, Loss: 0.4950
Batch 40, Loss: 0.5939
Batch 50, Loss: 0.5633
Batch 60, Loss: 0.5257
Batch 70, Loss: 0.5704
Batch 80, Loss: 0.5500
Batch 90, Loss: 0.5301
Batch 100, Loss: 0.5056
Batch 110, Loss: 0.5167
Batch 120, Loss: 0.5240
Batch 130, Loss: 0.5083
Batch 140, Loss: 0.5433
Batch 150, Loss: 0.5729
Batch 160, Loss: 0.5759
Batch 170, Loss: 0.5617
Batch 180, Loss: 0.5400
Batch 190, Loss: 0.5530
Batch 200, Loss: 0.5980
Batch 210, Loss: 0.5681
Batch 220, Loss: 0.5471
Batch 230, Loss: 0.5518
Batch 240, Loss: 0.5766
Batch 250, Loss: 0.5358
Batch 260, Loss: 0.5319
Batch 270, Loss: 0.5531
Batch 280, Loss: 0.5633
Batch 290, Loss: 0.5440
Batch 300, Loss: 0.5599
Batch 310, Loss: 0.5429
Batch 320, Loss: 0.5257
Batch 330, Loss: 0.5750
Batch 340, Loss: 0.5698
Batch 350, Loss: 0.5649
Batch 360, Loss: 0.5629
Batch 370, Loss: 0.5546
Batch 380, Loss: 0.6027
Batch 390, Loss: 0.5852
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.324885368347168 seconds
Epoch 154 accuracy: 75.42%
Batch 10, Loss: 0.5558
Batch 20, Loss: 0.5462
Batch 30, Loss: 0.5180
Batch 40, Loss: 0.5325
Batch 50, Loss: 0.4995
Batch 60, Loss: 0.5008
Batch 70, Loss: 0.5290
Batch 80, Loss: 0.5286
Batch 90, Loss: 0.5324
Batch 100, Loss: 0.5360
Batch 110, Loss: 0.5462
Batch 120, Loss: 0.5196
Batch 130, Loss: 0.5328
Batch 140, Loss: 0.5244
Batch 150, Loss: 0.5264
Batch 160, Loss: 0.5177
Batch 170, Loss: 0.5446
Batch 180, Loss: 0.5561
Batch 190, Loss: 0.5053
Batch 200, Loss: 0.5282
Batch 210, Loss: 0.5211
Batch 220, Loss: 0.4612
Batch 230, Loss: 0.5246
Batch 240, Loss: 0.5371
Batch 250, Loss: 0.6000
Batch 260, Loss: 0.5365
Batch 270, Loss: 0.5330
Batch 280, Loss: 0.5787
Batch 290, Loss: 0.5574
Batch 300, Loss: 0.5280
Batch 310, Loss: 0.6096
Batch 320, Loss: 0.5868
Batch 330, Loss: 0.5738
Batch 340, Loss: 0.5150
Batch 350, Loss: 0.5316
Batch 360, Loss: 0.5362
Batch 370, Loss: 0.5037
Batch 380, Loss: 0.5980
Batch 390, Loss: 0.5711
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.3067786693573 seconds
Epoch 155 accuracy: 75.19%
Batch 10, Loss: 0.5184
Batch 20, Loss: 0.5126
Batch 30, Loss: 0.5145
Batch 40, Loss: 0.5239
Batch 50, Loss: 0.5478
Batch 60, Loss: 0.5125
Batch 70, Loss: 0.5071
Batch 80, Loss: 0.5021
Batch 90, Loss: 0.5319
Batch 100, Loss: 0.5520
Batch 110, Loss: 0.5257
Batch 120, Loss: 0.5487
Batch 130, Loss: 0.5039
Batch 140, Loss: 0.5464
Batch 150, Loss: 0.4960
Batch 160, Loss: 0.5426
Batch 170, Loss: 0.5176
Batch 180, Loss: 0.5427
Batch 190, Loss: 0.5159
Batch 200, Loss: 0.5314
Batch 210, Loss: 0.5425
Batch 220, Loss: 0.5645
Batch 230, Loss: 0.4938
Batch 240, Loss: 0.5107
Batch 250, Loss: 0.4990
Batch 260, Loss: 0.5136
Batch 270, Loss: 0.5493
Batch 280, Loss: 0.5095
Batch 290, Loss: 0.5528
Batch 300, Loss: 0.5060
Batch 310, Loss: 0.5033
Batch 320, Loss: 0.5211
Batch 330, Loss: 0.5359
Batch 340, Loss: 0.5096
Batch 350, Loss: 0.5284
Batch 360, Loss: 0.5264
Batch 370, Loss: 0.5701
Batch 380, Loss: 0.5284
Batch 390, Loss: 0.5562
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.24206256866455 seconds
Epoch 156 accuracy: 75.97%
Batch 10, Loss: 0.5144
Batch 20, Loss: 0.5139
Batch 30, Loss: 0.4837
Batch 40, Loss: 0.5172
Batch 50, Loss: 0.5135
Batch 60, Loss: 0.5162
Batch 70, Loss: 0.5156
Batch 80, Loss: 0.5569
Batch 90, Loss: 0.5069
Batch 100, Loss: 0.4680
Batch 110, Loss: 0.4943
Batch 120, Loss: 0.5091
Batch 130, Loss: 0.5215
Batch 140, Loss: 0.4840
Batch 150, Loss: 0.4666
Batch 160, Loss: 0.5210
Batch 170, Loss: 0.5275
Batch 180, Loss: 0.5111
Batch 190, Loss: 0.4797
Batch 200, Loss: 0.5234
Batch 210, Loss: 0.4876
Batch 220, Loss: 0.4916
Batch 230, Loss: 0.5122
Batch 240, Loss: 0.5174
Batch 250, Loss: 0.4999
Batch 260, Loss: 0.5416
Batch 270, Loss: 0.5256
Batch 280, Loss: 0.4599
Batch 290, Loss: 0.5436
Batch 300, Loss: 0.5269
Batch 310, Loss: 0.4756
Batch 320, Loss: 0.5510
Batch 330, Loss: 0.5394
Batch 340, Loss: 0.4948
Batch 350, Loss: 0.5016
Batch 360, Loss: 0.5273
Batch 370, Loss: 0.5652
Batch 380, Loss: 0.4718
Batch 390, Loss: 0.5120
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.37400460243225 seconds
Epoch 157 accuracy: 75.72%
Batch 10, Loss: 0.4849
Batch 20, Loss: 0.4967
Batch 30, Loss: 0.4650
Batch 40, Loss: 0.4694
Batch 50, Loss: 0.4990
Batch 60, Loss: 0.4788
Batch 70, Loss: 0.5025
Batch 80, Loss: 0.4726
Batch 90, Loss: 0.4991
Batch 100, Loss: 0.4802
Batch 110, Loss: 0.4646
Batch 120, Loss: 0.4455
Batch 130, Loss: 0.5089
Batch 140, Loss: 0.5007
Batch 150, Loss: 0.4861
Batch 160, Loss: 0.4788
Batch 170, Loss: 0.5082
Batch 180, Loss: 0.4903
Batch 190, Loss: 0.5043
Batch 200, Loss: 0.5375
Batch 210, Loss: 0.5066
Batch 220, Loss: 0.4973
Batch 230, Loss: 0.4794
Batch 240, Loss: 0.5009
Batch 250, Loss: 0.5011
Batch 260, Loss: 0.4721
Batch 270, Loss: 0.4693
Batch 280, Loss: 0.5394
Batch 290, Loss: 0.5162
Batch 300, Loss: 0.5198
Batch 310, Loss: 0.5292
Batch 320, Loss: 0.4910
Batch 330, Loss: 0.5343
Batch 340, Loss: 0.4769
Batch 350, Loss: 0.5204
Batch 360, Loss: 0.5012
Batch 370, Loss: 0.4648
Batch 380, Loss: 0.5765
Batch 390, Loss: 0.4942
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.20883822441101 seconds
Epoch 158 accuracy: 76.46%
Batch 10, Loss: 0.4628
Batch 20, Loss: 0.4376
Batch 30, Loss: 0.4836
Batch 40, Loss: 0.5103
Batch 50, Loss: 0.5110
Batch 60, Loss: 0.4384
Batch 70, Loss: 0.4485
Batch 80, Loss: 0.4395
Batch 90, Loss: 0.4558
Batch 100, Loss: 0.4663
Batch 110, Loss: 0.5025
Batch 120, Loss: 0.4911
Batch 130, Loss: 0.5173
Batch 140, Loss: 0.5025
Batch 150, Loss: 0.4788
Batch 160, Loss: 0.4820
Batch 170, Loss: 0.5098
Batch 180, Loss: 0.5104
Batch 190, Loss: 0.4686
Batch 200, Loss: 0.4762
Batch 210, Loss: 0.4859
Batch 220, Loss: 0.5380
Batch 230, Loss: 0.4845
Batch 240, Loss: 0.4641
Batch 250, Loss: 0.5585
Batch 260, Loss: 0.4891
Batch 270, Loss: 0.4904
Batch 280, Loss: 0.4329
Batch 290, Loss: 0.4891
Batch 300, Loss: 0.4905
Batch 310, Loss: 0.5219
Batch 320, Loss: 0.5569
Batch 330, Loss: 0.4935
Batch 340, Loss: 0.5508
Batch 350, Loss: 0.5019
Batch 360, Loss: 0.5442
Batch 370, Loss: 0.4989
Batch 380, Loss: 0.4727
Batch 390, Loss: 0.4875
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.174232006072998 seconds
Epoch 159 accuracy: 77.08%
Batch 10, Loss: 0.4675
Batch 20, Loss: 0.4781
Batch 30, Loss: 0.4605
Batch 40, Loss: 0.5267
Batch 50, Loss: 0.4741
Batch 60, Loss: 0.4542
Batch 70, Loss: 0.4633
Batch 80, Loss: 0.4212
Batch 90, Loss: 0.4624
Batch 100, Loss: 0.4762
Batch 110, Loss: 0.4916
Batch 120, Loss: 0.5098
Batch 130, Loss: 0.4822
Batch 140, Loss: 0.4577
Batch 150, Loss: 0.4538
Batch 160, Loss: 0.4613
Batch 170, Loss: 0.4996
Batch 180, Loss: 0.4636
Batch 190, Loss: 0.4914
Batch 200, Loss: 0.4678
Batch 210, Loss: 0.4506
Batch 220, Loss: 0.5498
Batch 230, Loss: 0.4701
Batch 240, Loss: 0.4750
Batch 250, Loss: 0.4981
Batch 260, Loss: 0.4859
Batch 270, Loss: 0.4797
Batch 280, Loss: 0.5026
Batch 290, Loss: 0.5129
Batch 300, Loss: 0.4671
Batch 310, Loss: 0.5254
Batch 320, Loss: 0.4664
Batch 330, Loss: 0.5530
Batch 340, Loss: 0.4846
Batch 350, Loss: 0.5060
Batch 360, Loss: 0.4973
Batch 370, Loss: 0.5007
Batch 380, Loss: 0.4941
Batch 390, Loss: 0.5290
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.434248208999634 seconds
Epoch 160 accuracy: 76.23%
Batch 10, Loss: 0.4642
Batch 20, Loss: 0.4367
Batch 30, Loss: 0.4412
Batch 40, Loss: 0.4674
Batch 50, Loss: 0.4762
Batch 60, Loss: 0.4710
Batch 70, Loss: 0.4576
Batch 80, Loss: 0.4448
Batch 90, Loss: 0.4919
Batch 100, Loss: 0.4592
Batch 110, Loss: 0.4659
Batch 120, Loss: 0.4820
Batch 130, Loss: 0.5323
Batch 140, Loss: 0.4498
Batch 150, Loss: 0.4683
Batch 160, Loss: 0.4631
Batch 170, Loss: 0.4877
Batch 180, Loss: 0.4515
Batch 190, Loss: 0.4503
Batch 200, Loss: 0.4122
Batch 210, Loss: 0.4423
Batch 220, Loss: 0.4799
Batch 230, Loss: 0.4990
Batch 240, Loss: 0.4870
Batch 250, Loss: 0.4814
Batch 260, Loss: 0.4938
Batch 270, Loss: 0.4370
Batch 280, Loss: 0.4863
Batch 290, Loss: 0.4311
Batch 300, Loss: 0.4623
Batch 310, Loss: 0.4881
Batch 320, Loss: 0.4630
Batch 330, Loss: 0.4727
Batch 340, Loss: 0.4789
Batch 350, Loss: 0.4443
Batch 360, Loss: 0.4664
Batch 370, Loss: 0.4741
Batch 380, Loss: 0.5201
Batch 390, Loss: 0.4692
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.288454294204712 seconds
Epoch 161 accuracy: 76.58%
Batch 10, Loss: 0.4405
Batch 20, Loss: 0.4548
Batch 30, Loss: 0.4657
Batch 40, Loss: 0.4510
Batch 50, Loss: 0.4825
Batch 60, Loss: 0.4438
Batch 70, Loss: 0.4548
Batch 80, Loss: 0.4707
Batch 90, Loss: 0.4180
Batch 100, Loss: 0.4833
Batch 110, Loss: 0.4776
Batch 120, Loss: 0.4110
Batch 130, Loss: 0.4571
Batch 140, Loss: 0.4655
Batch 150, Loss: 0.4606
Batch 160, Loss: 0.4283
Batch 170, Loss: 0.4150
Batch 180, Loss: 0.4396
Batch 190, Loss: 0.4966
Batch 200, Loss: 0.4667
Batch 210, Loss: 0.4867
Batch 220, Loss: 0.4764
Batch 230, Loss: 0.4465
Batch 240, Loss: 0.4565
Batch 250, Loss: 0.4478
Batch 260, Loss: 0.4544
Batch 270, Loss: 0.4310
Batch 280, Loss: 0.4701
Batch 290, Loss: 0.4462
Batch 300, Loss: 0.4521
Batch 310, Loss: 0.4518
Batch 320, Loss: 0.4392
Batch 330, Loss: 0.5092
Batch 340, Loss: 0.4860
Batch 350, Loss: 0.4687
Batch 360, Loss: 0.4426
Batch 370, Loss: 0.4945
Batch 380, Loss: 0.4757
Batch 390, Loss: 0.5044
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.2789249420166 seconds
Epoch 162 accuracy: 76.91%
Batch 10, Loss: 0.4547
Batch 20, Loss: 0.4394
Batch 30, Loss: 0.4416
Batch 40, Loss: 0.4308
Batch 50, Loss: 0.4385
Batch 60, Loss: 0.3889
Batch 70, Loss: 0.4455
Batch 80, Loss: 0.4143
Batch 90, Loss: 0.4805
Batch 100, Loss: 0.4250
Batch 110, Loss: 0.4613
Batch 120, Loss: 0.4528
Batch 130, Loss: 0.4690
Batch 140, Loss: 0.4517
Batch 150, Loss: 0.4935
Batch 160, Loss: 0.4628
Batch 170, Loss: 0.4512
Batch 180, Loss: 0.4517
Batch 190, Loss: 0.4682
Batch 200, Loss: 0.4411
Batch 210, Loss: 0.4425
Batch 220, Loss: 0.4722
Batch 230, Loss: 0.4606
Batch 240, Loss: 0.4431
Batch 250, Loss: 0.4142
Batch 260, Loss: 0.4583
Batch 270, Loss: 0.4745
Batch 280, Loss: 0.4750
Batch 290, Loss: 0.4122
Batch 300, Loss: 0.4393
Batch 310, Loss: 0.4555
Batch 320, Loss: 0.4594
Batch 330, Loss: 0.4522
Batch 340, Loss: 0.4538
Batch 350, Loss: 0.4519
Batch 360, Loss: 0.4664
Batch 370, Loss: 0.4639
Batch 380, Loss: 0.4658
Batch 390, Loss: 0.4904
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.367331743240356 seconds
Epoch 163 accuracy: 76.41%
Batch 10, Loss: 0.4316
Batch 20, Loss: 0.4136
Batch 30, Loss: 0.4036
Batch 40, Loss: 0.4245
Batch 50, Loss: 0.4319
Batch 60, Loss: 0.4414
Batch 70, Loss: 0.4528
Batch 80, Loss: 0.4586
Batch 90, Loss: 0.4100
Batch 100, Loss: 0.4430
Batch 110, Loss: 0.4326
Batch 120, Loss: 0.4056
Batch 130, Loss: 0.3945
Batch 140, Loss: 0.4487
Batch 150, Loss: 0.4398
Batch 160, Loss: 0.4105
Batch 170, Loss: 0.4612
Batch 180, Loss: 0.3936
Batch 190, Loss: 0.4177
Batch 200, Loss: 0.4159
Batch 210, Loss: 0.4268
Batch 220, Loss: 0.4450
Batch 230, Loss: 0.4295
Batch 240, Loss: 0.4084
Batch 250, Loss: 0.4493
Batch 260, Loss: 0.4202
Batch 270, Loss: 0.4788
Batch 280, Loss: 0.4385
Batch 290, Loss: 0.4484
Batch 300, Loss: 0.4237
Batch 310, Loss: 0.4436
Batch 320, Loss: 0.4142
Batch 330, Loss: 0.4251
Batch 340, Loss: 0.4495
Batch 350, Loss: 0.4219
Batch 360, Loss: 0.4346
Batch 370, Loss: 0.4325
Batch 380, Loss: 0.4462
Batch 390, Loss: 0.4286
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.348975658416748 seconds
Epoch 164 accuracy: 76.7%
Batch 10, Loss: 0.4222
Batch 20, Loss: 0.4341
Batch 30, Loss: 0.4128
Batch 40, Loss: 0.3768
Batch 50, Loss: 0.4285
Batch 60, Loss: 0.4131
Batch 70, Loss: 0.3723
Batch 80, Loss: 0.4184
Batch 90, Loss: 0.4209
Batch 100, Loss: 0.4258
Batch 110, Loss: 0.4558
Batch 120, Loss: 0.4607
Batch 130, Loss: 0.4043
Batch 140, Loss: 0.4181
Batch 150, Loss: 0.4172
Batch 160, Loss: 0.4243
Batch 170, Loss: 0.4472
Batch 180, Loss: 0.4341
Batch 190, Loss: 0.4435
Batch 200, Loss: 0.4489
Batch 210, Loss: 0.4167
Batch 220, Loss: 0.4080
Batch 230, Loss: 0.3952
Batch 240, Loss: 0.4362
Batch 250, Loss: 0.4382
Batch 260, Loss: 0.4059
Batch 270, Loss: 0.4371
Batch 280, Loss: 0.4458
Batch 290, Loss: 0.4576
Batch 300, Loss: 0.3819
Batch 310, Loss: 0.3990
Batch 320, Loss: 0.4208
Batch 330, Loss: 0.4299
Batch 340, Loss: 0.4282
Batch 350, Loss: 0.4376
Batch 360, Loss: 0.4575
Batch 370, Loss: 0.4351
Batch 380, Loss: 0.4496
Batch 390, Loss: 0.4230
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.30680274963379 seconds
Epoch 165 accuracy: 77.65%
Batch 10, Loss: 0.3766
Batch 20, Loss: 0.3526
Batch 30, Loss: 0.4389
Batch 40, Loss: 0.4290
Batch 50, Loss: 0.3978
Batch 60, Loss: 0.3574
Batch 70, Loss: 0.4017
Batch 80, Loss: 0.4022
Batch 90, Loss: 0.3914
Batch 100, Loss: 0.4181
Batch 110, Loss: 0.4064
Batch 120, Loss: 0.4200
Batch 130, Loss: 0.4270
Batch 140, Loss: 0.4251
Batch 150, Loss: 0.4289
Batch 160, Loss: 0.4688
Batch 170, Loss: 0.4151
Batch 180, Loss: 0.3939
Batch 190, Loss: 0.4354
Batch 200, Loss: 0.3919
Batch 210, Loss: 0.4552
Batch 220, Loss: 0.4048
Batch 230, Loss: 0.4197
Batch 240, Loss: 0.4211
Batch 250, Loss: 0.4645
Batch 260, Loss: 0.3971
Batch 270, Loss: 0.4107
Batch 280, Loss: 0.3957
Batch 290, Loss: 0.4160
Batch 300, Loss: 0.4217
Batch 310, Loss: 0.4221
Batch 320, Loss: 0.4132
Batch 330, Loss: 0.4084
Batch 340, Loss: 0.4145
Batch 350, Loss: 0.4251
Batch 360, Loss: 0.4359
Batch 370, Loss: 0.4312
Batch 380, Loss: 0.4531
Batch 390, Loss: 0.4448
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.382052183151245 seconds
Epoch 166 accuracy: 77.01%
Batch 10, Loss: 0.3830
Batch 20, Loss: 0.3834
Batch 30, Loss: 0.4035
Batch 40, Loss: 0.3786
Batch 50, Loss: 0.3904
Batch 60, Loss: 0.3747
Batch 70, Loss: 0.4084
Batch 80, Loss: 0.4118
Batch 90, Loss: 0.3719
Batch 100, Loss: 0.4033
Batch 110, Loss: 0.3809
Batch 120, Loss: 0.3880
Batch 130, Loss: 0.4265
Batch 140, Loss: 0.4015
Batch 150, Loss: 0.4114
Batch 160, Loss: 0.3945
Batch 170, Loss: 0.3943
Batch 180, Loss: 0.4476
Batch 190, Loss: 0.4086
Batch 200, Loss: 0.3576
Batch 210, Loss: 0.4131
Batch 220, Loss: 0.4002
Batch 230, Loss: 0.4270
Batch 240, Loss: 0.4315
Batch 250, Loss: 0.4182
Batch 260, Loss: 0.4284
Batch 270, Loss: 0.4084
Batch 280, Loss: 0.4009
Batch 290, Loss: 0.3539
Batch 300, Loss: 0.4260
Batch 310, Loss: 0.4420
Batch 320, Loss: 0.4277
Batch 330, Loss: 0.4274
Batch 340, Loss: 0.3931
Batch 350, Loss: 0.4271
Batch 360, Loss: 0.4090
Batch 370, Loss: 0.4219
Batch 380, Loss: 0.4354
Batch 390, Loss: 0.4121
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.458762884140015 seconds
Epoch 167 accuracy: 77.83%
Batch 10, Loss: 0.3662
Batch 20, Loss: 0.3984
Batch 30, Loss: 0.3896
Batch 40, Loss: 0.3778
Batch 50, Loss: 0.3692
Batch 60, Loss: 0.3623
Batch 70, Loss: 0.3591
Batch 80, Loss: 0.3561
Batch 90, Loss: 0.3962
Batch 100, Loss: 0.3978
Batch 110, Loss: 0.3740
Batch 120, Loss: 0.3704
Batch 130, Loss: 0.3647
Batch 140, Loss: 0.3970
Batch 150, Loss: 0.4199
Batch 160, Loss: 0.3697
Batch 170, Loss: 0.3823
Batch 180, Loss: 0.3599
Batch 190, Loss: 0.3875
Batch 200, Loss: 0.3981
Batch 210, Loss: 0.3915
Batch 220, Loss: 0.3982
Batch 230, Loss: 0.4157
Batch 240, Loss: 0.3999
Batch 250, Loss: 0.3465
Batch 260, Loss: 0.3765
Batch 270, Loss: 0.4087
Batch 280, Loss: 0.3694
Batch 290, Loss: 0.3987
Batch 300, Loss: 0.4214
Batch 310, Loss: 0.3926
Batch 320, Loss: 0.4226
Batch 330, Loss: 0.3896
Batch 340, Loss: 0.3840
Batch 350, Loss: 0.4015
Batch 360, Loss: 0.3757
Batch 370, Loss: 0.4410
Batch 380, Loss: 0.3912
Batch 390, Loss: 0.4276
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.25287127494812 seconds
Epoch 168 accuracy: 77.72%
Batch 10, Loss: 0.3643
Batch 20, Loss: 0.3935
Batch 30, Loss: 0.3907
Batch 40, Loss: 0.3612
Batch 50, Loss: 0.3695
Batch 60, Loss: 0.3889
Batch 70, Loss: 0.3654
Batch 80, Loss: 0.3917
Batch 90, Loss: 0.3850
Batch 100, Loss: 0.4207
Batch 110, Loss: 0.4106
Batch 120, Loss: 0.3619
Batch 130, Loss: 0.3690
Batch 140, Loss: 0.4106
Batch 150, Loss: 0.3865
Batch 160, Loss: 0.4159
Batch 170, Loss: 0.3322
Batch 180, Loss: 0.3786
Batch 190, Loss: 0.4018
Batch 200, Loss: 0.3496
Batch 210, Loss: 0.3983
Batch 220, Loss: 0.3915
Batch 230, Loss: 0.3855
Batch 240, Loss: 0.3973
Batch 250, Loss: 0.3946
Batch 260, Loss: 0.3724
Batch 270, Loss: 0.3763
Batch 280, Loss: 0.3885
Batch 290, Loss: 0.3608
Batch 300, Loss: 0.3726
Batch 310, Loss: 0.3874
Batch 320, Loss: 0.3672
Batch 330, Loss: 0.3790
Batch 340, Loss: 0.3685
Batch 350, Loss: 0.3493
Batch 360, Loss: 0.3882
Batch 370, Loss: 0.4100
Batch 380, Loss: 0.3924
Batch 390, Loss: 0.3670
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.440606117248535 seconds
Epoch 169 accuracy: 78.06%
Batch 10, Loss: 0.3710
Batch 20, Loss: 0.3396
Batch 30, Loss: 0.3528
Batch 40, Loss: 0.3739
Batch 50, Loss: 0.3924
Batch 60, Loss: 0.3487
Batch 70, Loss: 0.3868
Batch 80, Loss: 0.4283
Batch 90, Loss: 0.3789
Batch 100, Loss: 0.3459
Batch 110, Loss: 0.3638
Batch 120, Loss: 0.3658
Batch 130, Loss: 0.3201
Batch 140, Loss: 0.4066
Batch 150, Loss: 0.3779
Batch 160, Loss: 0.3818
Batch 170, Loss: 0.3771
Batch 180, Loss: 0.3500
Batch 190, Loss: 0.3624
Batch 200, Loss: 0.3909
Batch 210, Loss: 0.3630
Batch 220, Loss: 0.4065
Batch 230, Loss: 0.3776
Batch 240, Loss: 0.3585
Batch 250, Loss: 0.3830
Batch 260, Loss: 0.3594
Batch 270, Loss: 0.3821
Batch 280, Loss: 0.3638
Batch 290, Loss: 0.3476
Batch 300, Loss: 0.3488
Batch 310, Loss: 0.3642
Batch 320, Loss: 0.3900
Batch 330, Loss: 0.3655
Batch 340, Loss: 0.3987
Batch 350, Loss: 0.3517
Batch 360, Loss: 0.4033
Batch 370, Loss: 0.4086
Batch 380, Loss: 0.3751
Batch 390, Loss: 0.4084
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.274289846420288 seconds
Epoch 170 accuracy: 78.11%
Batch 10, Loss: 0.3863
Batch 20, Loss: 0.3431
Batch 30, Loss: 0.3614
Batch 40, Loss: 0.3429
Batch 50, Loss: 0.3686
Batch 60, Loss: 0.3841
Batch 70, Loss: 0.3572
Batch 80, Loss: 0.3748
Batch 90, Loss: 0.3646
Batch 100, Loss: 0.3496
Batch 110, Loss: 0.3545
Batch 120, Loss: 0.3499
Batch 130, Loss: 0.3608
Batch 140, Loss: 0.3817
Batch 150, Loss: 0.3716
Batch 160, Loss: 0.3646
Batch 170, Loss: 0.3383
Batch 180, Loss: 0.3445
Batch 190, Loss: 0.3601
Batch 200, Loss: 0.3645
Batch 210, Loss: 0.3238
Batch 220, Loss: 0.3976
Batch 230, Loss: 0.3804
Batch 240, Loss: 0.3775
Batch 250, Loss: 0.3776
Batch 260, Loss: 0.3677
Batch 270, Loss: 0.3456
Batch 280, Loss: 0.3629
Batch 290, Loss: 0.3564
Batch 300, Loss: 0.3674
Batch 310, Loss: 0.3547
Batch 320, Loss: 0.3460
Batch 330, Loss: 0.3879
Batch 340, Loss: 0.3406
Batch 350, Loss: 0.3842
Batch 360, Loss: 0.4192
Batch 370, Loss: 0.3671
Batch 380, Loss: 0.4074
Batch 390, Loss: 0.3862
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.403876066207886 seconds
Epoch 171 accuracy: 78.16%
Batch 10, Loss: 0.3350
Batch 20, Loss: 0.3360
Batch 30, Loss: 0.3640
Batch 40, Loss: 0.3969
Batch 50, Loss: 0.3328
Batch 60, Loss: 0.3451
Batch 70, Loss: 0.3653
Batch 80, Loss: 0.3385
Batch 90, Loss: 0.3727
Batch 100, Loss: 0.3670
Batch 110, Loss: 0.3449
Batch 120, Loss: 0.3421
Batch 130, Loss: 0.3201
Batch 140, Loss: 0.3627
Batch 150, Loss: 0.3585
Batch 160, Loss: 0.3606
Batch 170, Loss: 0.3455
Batch 180, Loss: 0.3592
Batch 190, Loss: 0.3239
Batch 200, Loss: 0.3231
Batch 210, Loss: 0.3595
Batch 220, Loss: 0.3393
Batch 230, Loss: 0.3678
Batch 240, Loss: 0.3574
Batch 250, Loss: 0.3458
Batch 260, Loss: 0.3400
Batch 270, Loss: 0.3759
Batch 280, Loss: 0.3419
Batch 290, Loss: 0.3778
Batch 300, Loss: 0.3829
Batch 310, Loss: 0.3931
Batch 320, Loss: 0.3120
Batch 330, Loss: 0.3655
Batch 340, Loss: 0.3497
Batch 350, Loss: 0.3319
Batch 360, Loss: 0.3916
Batch 370, Loss: 0.3865
Batch 380, Loss: 0.3739
Batch 390, Loss: 0.3426
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.391030073165894 seconds
Epoch 172 accuracy: 78.8%
Batch 10, Loss: 0.3263
Batch 20, Loss: 0.3325
Batch 30, Loss: 0.3031
Batch 40, Loss: 0.3545
Batch 50, Loss: 0.3454
Batch 60, Loss: 0.3362
Batch 70, Loss: 0.3327
Batch 80, Loss: 0.3204
Batch 90, Loss: 0.3512
Batch 100, Loss: 0.3384
Batch 110, Loss: 0.3510
Batch 120, Loss: 0.3371
Batch 130, Loss: 0.3079
Batch 140, Loss: 0.3211
Batch 150, Loss: 0.3708
Batch 160, Loss: 0.3830
Batch 170, Loss: 0.3347
Batch 180, Loss: 0.3444
Batch 190, Loss: 0.3582
Batch 200, Loss: 0.3470
Batch 210, Loss: 0.2806
Batch 220, Loss: 0.3726
Batch 230, Loss: 0.3193
Batch 240, Loss: 0.3556
Batch 250, Loss: 0.3655
Batch 260, Loss: 0.3332
Batch 270, Loss: 0.3815
Batch 280, Loss: 0.3527
Batch 290, Loss: 0.3703
Batch 300, Loss: 0.3406
Batch 310, Loss: 0.3630
Batch 320, Loss: 0.3323
Batch 330, Loss: 0.3340
Batch 340, Loss: 0.3305
Batch 350, Loss: 0.3348
Batch 360, Loss: 0.3605
Batch 370, Loss: 0.3285
Batch 380, Loss: 0.3187
Batch 390, Loss: 0.3516
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.326225757598877 seconds
Epoch 173 accuracy: 78.49%
Batch 10, Loss: 0.3571
Batch 20, Loss: 0.3160
Batch 30, Loss: 0.3750
Batch 40, Loss: 0.3105
Batch 50, Loss: 0.3425
Batch 60, Loss: 0.3396
Batch 70, Loss: 0.3440
Batch 80, Loss: 0.3411
Batch 90, Loss: 0.3310
Batch 100, Loss: 0.3538
Batch 110, Loss: 0.3127
Batch 120, Loss: 0.3039
Batch 130, Loss: 0.3044
Batch 140, Loss: 0.3416
Batch 150, Loss: 0.3366
Batch 160, Loss: 0.3344
Batch 170, Loss: 0.3079
Batch 180, Loss: 0.3429
Batch 190, Loss: 0.3076
Batch 200, Loss: 0.3604
Batch 210, Loss: 0.2915
Batch 220, Loss: 0.3329
Batch 230, Loss: 0.3247
Batch 240, Loss: 0.3523
Batch 250, Loss: 0.3125
Batch 260, Loss: 0.2898
Batch 270, Loss: 0.3358
Batch 280, Loss: 0.3190
Batch 290, Loss: 0.3635
Batch 300, Loss: 0.3421
Batch 310, Loss: 0.3324
Batch 320, Loss: 0.3472
Batch 330, Loss: 0.3284
Batch 340, Loss: 0.3551
Batch 350, Loss: 0.3382
Batch 360, Loss: 0.3508
Batch 370, Loss: 0.3525
Batch 380, Loss: 0.3349
Batch 390, Loss: 0.3144
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.41064476966858 seconds
Epoch 174 accuracy: 78.4%
Batch 10, Loss: 0.3324
Batch 20, Loss: 0.3576
Batch 30, Loss: 0.3122
Batch 40, Loss: 0.3053
Batch 50, Loss: 0.2999
Batch 60, Loss: 0.3454
Batch 70, Loss: 0.3064
Batch 80, Loss: 0.3308
Batch 90, Loss: 0.3201
Batch 100, Loss: 0.3507
Batch 110, Loss: 0.3508
Batch 120, Loss: 0.3238
Batch 130, Loss: 0.3386
Batch 140, Loss: 0.3451
Batch 150, Loss: 0.3189
Batch 160, Loss: 0.3299
Batch 170, Loss: 0.3113
Batch 180, Loss: 0.3585
Batch 190, Loss: 0.3100
Batch 200, Loss: 0.3291
Batch 210, Loss: 0.3107
Batch 220, Loss: 0.3218
Batch 230, Loss: 0.3467
Batch 240, Loss: 0.3601
Batch 250, Loss: 0.3599
Batch 260, Loss: 0.3491
Batch 270, Loss: 0.3196
Batch 280, Loss: 0.3545
Batch 290, Loss: 0.3219
Batch 300, Loss: 0.3232
Batch 310, Loss: 0.3424
Batch 320, Loss: 0.3237
Batch 330, Loss: 0.3527
Batch 340, Loss: 0.3080
Batch 350, Loss: 0.3242
Batch 360, Loss: 0.3484
Batch 370, Loss: 0.3500
Batch 380, Loss: 0.3464
Batch 390, Loss: 0.3268
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.383963584899902 seconds
Epoch 175 accuracy: 78.51%
Batch 10, Loss: 0.3376
Batch 20, Loss: 0.3155
Batch 30, Loss: 0.3236
Batch 40, Loss: 0.3019
Batch 50, Loss: 0.3511
Batch 60, Loss: 0.3251
Batch 70, Loss: 0.3236
Batch 80, Loss: 0.3094
Batch 90, Loss: 0.3059
Batch 100, Loss: 0.3059
Batch 110, Loss: 0.3510
Batch 120, Loss: 0.3121
Batch 130, Loss: 0.3296
Batch 140, Loss: 0.3361
Batch 150, Loss: 0.3149
Batch 160, Loss: 0.3451
Batch 170, Loss: 0.3103
Batch 180, Loss: 0.3513
Batch 190, Loss: 0.2925
Batch 200, Loss: 0.3252
Batch 210, Loss: 0.2991
Batch 220, Loss: 0.3141
Batch 230, Loss: 0.2998
Batch 240, Loss: 0.3333
Batch 250, Loss: 0.3251
Batch 260, Loss: 0.3208
Batch 270, Loss: 0.3052
Batch 280, Loss: 0.3212
Batch 290, Loss: 0.3204
Batch 300, Loss: 0.3135
Batch 310, Loss: 0.3007
Batch 320, Loss: 0.3120
Batch 330, Loss: 0.3298
Batch 340, Loss: 0.3022
Batch 350, Loss: 0.3119
Batch 360, Loss: 0.3303
Batch 370, Loss: 0.3136
Batch 380, Loss: 0.3283
Batch 390, Loss: 0.3259
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.187244415283203 seconds
Epoch 176 accuracy: 78.75%
Batch 10, Loss: 0.3105
Batch 20, Loss: 0.3002
Batch 30, Loss: 0.3134
Batch 40, Loss: 0.2905
Batch 50, Loss: 0.2962
Batch 60, Loss: 0.3432
Batch 70, Loss: 0.3335
Batch 80, Loss: 0.2949
Batch 90, Loss: 0.3098
Batch 100, Loss: 0.2963
Batch 110, Loss: 0.2697
Batch 120, Loss: 0.3522
Batch 130, Loss: 0.3088
Batch 140, Loss: 0.3043
Batch 150, Loss: 0.3101
Batch 160, Loss: 0.3001
Batch 170, Loss: 0.3222
Batch 180, Loss: 0.3081
Batch 190, Loss: 0.2837
Batch 200, Loss: 0.3280
Batch 210, Loss: 0.2501
Batch 220, Loss: 0.3393
Batch 230, Loss: 0.3021
Batch 240, Loss: 0.3372
Batch 250, Loss: 0.3112
Batch 260, Loss: 0.3408
Batch 270, Loss: 0.3024
Batch 280, Loss: 0.3018
Batch 290, Loss: 0.2935
Batch 300, Loss: 0.3236
Batch 310, Loss: 0.2742
Batch 320, Loss: 0.3206
Batch 330, Loss: 0.3369
Batch 340, Loss: 0.3422
Batch 350, Loss: 0.3406
Batch 360, Loss: 0.2959
Batch 370, Loss: 0.2946
Batch 380, Loss: 0.3077
Batch 390, Loss: 0.3211
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.282007932662964 seconds
Epoch 177 accuracy: 78.83%
Batch 10, Loss: 0.3062
Batch 20, Loss: 0.3052
Batch 30, Loss: 0.3165
Batch 40, Loss: 0.2978
Batch 50, Loss: 0.3131
Batch 60, Loss: 0.2888
Batch 70, Loss: 0.3333
Batch 80, Loss: 0.3340
Batch 90, Loss: 0.2978
Batch 100, Loss: 0.2848
Batch 110, Loss: 0.2882
Batch 120, Loss: 0.2965
Batch 130, Loss: 0.2864
Batch 140, Loss: 0.3052
Batch 150, Loss: 0.3188
Batch 160, Loss: 0.3077
Batch 170, Loss: 0.3327
Batch 180, Loss: 0.2769
Batch 190, Loss: 0.3369
Batch 200, Loss: 0.3344
Batch 210, Loss: 0.3194
Batch 220, Loss: 0.3105
Batch 230, Loss: 0.3178
Batch 240, Loss: 0.3313
Batch 250, Loss: 0.3205
Batch 260, Loss: 0.2731
Batch 270, Loss: 0.3093
Batch 280, Loss: 0.3114
Batch 290, Loss: 0.2955
Batch 300, Loss: 0.3499
Batch 310, Loss: 0.3082
Batch 320, Loss: 0.2693
Batch 330, Loss: 0.2738
Batch 340, Loss: 0.2752
Batch 350, Loss: 0.3116
Batch 360, Loss: 0.2978
Batch 370, Loss: 0.2885
Batch 380, Loss: 0.3177
Batch 390, Loss: 0.2990
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.432175397872925 seconds
Epoch 178 accuracy: 79.29%
Batch 10, Loss: 0.2743
Batch 20, Loss: 0.2854
Batch 30, Loss: 0.2572
Batch 40, Loss: 0.2454
Batch 50, Loss: 0.2755
Batch 60, Loss: 0.3003
Batch 70, Loss: 0.3087
Batch 80, Loss: 0.3331
Batch 90, Loss: 0.2548
Batch 100, Loss: 0.3028
Batch 110, Loss: 0.3180
Batch 120, Loss: 0.3120
Batch 130, Loss: 0.2708
Batch 140, Loss: 0.2941
Batch 150, Loss: 0.2986
Batch 160, Loss: 0.2866
Batch 170, Loss: 0.3192
Batch 180, Loss: 0.3172
Batch 190, Loss: 0.2657
Batch 200, Loss: 0.3028
Batch 210, Loss: 0.2846
Batch 220, Loss: 0.2708
Batch 230, Loss: 0.3185
Batch 240, Loss: 0.2954
Batch 250, Loss: 0.2881
Batch 260, Loss: 0.2865
Batch 270, Loss: 0.2914
Batch 280, Loss: 0.3101
Batch 290, Loss: 0.3149
Batch 300, Loss: 0.2735
Batch 310, Loss: 0.2959
Batch 320, Loss: 0.3061
Batch 330, Loss: 0.3355
Batch 340, Loss: 0.2694
Batch 350, Loss: 0.2776
Batch 360, Loss: 0.3005
Batch 370, Loss: 0.3303
Batch 380, Loss: 0.3135
Batch 390, Loss: 0.3299
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.341684818267822 seconds
Epoch 179 accuracy: 79.13%
Batch 10, Loss: 0.2860
Batch 20, Loss: 0.2957
Batch 30, Loss: 0.2878
Batch 40, Loss: 0.3137
Batch 50, Loss: 0.2730
Batch 60, Loss: 0.3061
Batch 70, Loss: 0.2893
Batch 80, Loss: 0.2559
Batch 90, Loss: 0.2878
Batch 100, Loss: 0.3129
Batch 110, Loss: 0.2759
Batch 120, Loss: 0.2869
Batch 130, Loss: 0.3195
Batch 140, Loss: 0.2634
Batch 150, Loss: 0.2938
Batch 160, Loss: 0.2916
Batch 170, Loss: 0.2720
Batch 180, Loss: 0.2759
Batch 190, Loss: 0.3249
Batch 200, Loss: 0.2790
Batch 210, Loss: 0.3080
Batch 220, Loss: 0.2830
Batch 230, Loss: 0.2924
Batch 240, Loss: 0.2637
Batch 250, Loss: 0.3081
Batch 260, Loss: 0.3179
Batch 270, Loss: 0.2795
Batch 280, Loss: 0.3077
Batch 290, Loss: 0.3266
Batch 300, Loss: 0.2759
Batch 310, Loss: 0.3092
Batch 320, Loss: 0.2803
Batch 330, Loss: 0.2948
Batch 340, Loss: 0.2793
Batch 350, Loss: 0.2806
Batch 360, Loss: 0.2764
Batch 370, Loss: 0.3001
Batch 380, Loss: 0.3209
Batch 390, Loss: 0.3162
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.380013704299927 seconds
Epoch 180 accuracy: 79.57%
Batch 10, Loss: 0.2675
Batch 20, Loss: 0.2886
Batch 30, Loss: 0.3054
Batch 40, Loss: 0.2713
Batch 50, Loss: 0.2715
Batch 60, Loss: 0.2815
Batch 70, Loss: 0.3047
Batch 80, Loss: 0.2646
Batch 90, Loss: 0.2980
Batch 100, Loss: 0.3105
Batch 110, Loss: 0.2966
Batch 120, Loss: 0.2860
Batch 130, Loss: 0.2830
Batch 140, Loss: 0.2650
Batch 150, Loss: 0.2811
Batch 160, Loss: 0.3038
Batch 170, Loss: 0.2934
Batch 180, Loss: 0.2805
Batch 190, Loss: 0.2715
Batch 200, Loss: 0.2978
Batch 210, Loss: 0.2941
Batch 220, Loss: 0.3078
Batch 230, Loss: 0.2763
Batch 240, Loss: 0.2723
Batch 250, Loss: 0.3046
Batch 260, Loss: 0.2667
Batch 270, Loss: 0.3209
Batch 280, Loss: 0.2744
Batch 290, Loss: 0.2712
Batch 300, Loss: 0.2853
Batch 310, Loss: 0.2825
Batch 320, Loss: 0.3047
Batch 330, Loss: 0.2784
Batch 340, Loss: 0.2670
Batch 350, Loss: 0.2944
Batch 360, Loss: 0.2839
Batch 370, Loss: 0.2791
Batch 380, Loss: 0.2850
Batch 390, Loss: 0.3149
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.406046390533447 seconds
Epoch 181 accuracy: 79.3%
Batch 10, Loss: 0.2858
Batch 20, Loss: 0.2917
Batch 30, Loss: 0.3017
Batch 40, Loss: 0.3046
Batch 50, Loss: 0.2921
Batch 60, Loss: 0.2624
Batch 70, Loss: 0.2805
Batch 80, Loss: 0.2413
Batch 90, Loss: 0.2841
Batch 100, Loss: 0.2727
Batch 110, Loss: 0.2784
Batch 120, Loss: 0.2750
Batch 130, Loss: 0.2880
Batch 140, Loss: 0.3095
Batch 150, Loss: 0.2553
Batch 160, Loss: 0.2767
Batch 170, Loss: 0.2698
Batch 180, Loss: 0.2781
Batch 190, Loss: 0.2636
Batch 200, Loss: 0.2854
Batch 210, Loss: 0.2954
Batch 220, Loss: 0.2637
Batch 230, Loss: 0.2893
Batch 240, Loss: 0.2932
Batch 250, Loss: 0.2870
Batch 260, Loss: 0.2769
Batch 270, Loss: 0.2414
Batch 280, Loss: 0.2901
Batch 290, Loss: 0.2624
Batch 300, Loss: 0.2965
Batch 310, Loss: 0.2888
Batch 320, Loss: 0.2923
Batch 330, Loss: 0.2889
Batch 340, Loss: 0.2920
Batch 350, Loss: 0.2887
Batch 360, Loss: 0.2809
Batch 370, Loss: 0.2927
Batch 380, Loss: 0.2771
Batch 390, Loss: 0.2667
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.396390914916992 seconds
Epoch 182 accuracy: 79.86%
Batch 10, Loss: 0.2732
Batch 20, Loss: 0.2626
Batch 30, Loss: 0.2727
Batch 40, Loss: 0.3018
Batch 50, Loss: 0.2744
Batch 60, Loss: 0.2741
Batch 70, Loss: 0.2608
Batch 80, Loss: 0.2414
Batch 90, Loss: 0.2555
Batch 100, Loss: 0.2941
Batch 110, Loss: 0.2797
Batch 120, Loss: 0.2763
Batch 130, Loss: 0.2714
Batch 140, Loss: 0.2793
Batch 150, Loss: 0.2705
Batch 160, Loss: 0.2759
Batch 170, Loss: 0.2702
Batch 180, Loss: 0.2498
Batch 190, Loss: 0.2564
Batch 200, Loss: 0.2821
Batch 210, Loss: 0.2796
Batch 220, Loss: 0.2537
Batch 230, Loss: 0.2845
Batch 240, Loss: 0.2691
Batch 250, Loss: 0.3024
Batch 260, Loss: 0.2921
Batch 270, Loss: 0.2742
Batch 280, Loss: 0.2667
Batch 290, Loss: 0.2881
Batch 300, Loss: 0.2814
Batch 310, Loss: 0.2635
Batch 320, Loss: 0.3195
Batch 330, Loss: 0.2720
Batch 340, Loss: 0.3030
Batch 350, Loss: 0.2607
Batch 360, Loss: 0.2918
Batch 370, Loss: 0.2790
Batch 380, Loss: 0.2666
Batch 390, Loss: 0.2827
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.443925142288208 seconds
Epoch 183 accuracy: 79.72%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2938
Batch 30, Loss: 0.2840
Batch 40, Loss: 0.3023
Batch 50, Loss: 0.3057
Batch 60, Loss: 0.2976
Batch 70, Loss: 0.2826
Batch 80, Loss: 0.2534
Batch 90, Loss: 0.2654
Batch 100, Loss: 0.2698
Batch 110, Loss: 0.2968
Batch 120, Loss: 0.2572
Batch 130, Loss: 0.2578
Batch 140, Loss: 0.2516
Batch 150, Loss: 0.2953
Batch 160, Loss: 0.2647
Batch 170, Loss: 0.2589
Batch 180, Loss: 0.2591
Batch 190, Loss: 0.2618
Batch 200, Loss: 0.2728
Batch 210, Loss: 0.2479
Batch 220, Loss: 0.2935
Batch 230, Loss: 0.2925
Batch 240, Loss: 0.2449
Batch 250, Loss: 0.2545
Batch 260, Loss: 0.2497
Batch 270, Loss: 0.2787
Batch 280, Loss: 0.3033
Batch 290, Loss: 0.2654
Batch 300, Loss: 0.2404
Batch 310, Loss: 0.2917
Batch 320, Loss: 0.2929
Batch 330, Loss: 0.2833
Batch 340, Loss: 0.2799
Batch 350, Loss: 0.2692
Batch 360, Loss: 0.3063
Batch 370, Loss: 0.2838
Batch 380, Loss: 0.2379
Batch 390, Loss: 0.2649
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.352250814437866 seconds
Epoch 184 accuracy: 79.82%
Batch 10, Loss: 0.3025
Batch 20, Loss: 0.2854
Batch 30, Loss: 0.2537
Batch 40, Loss: 0.2629
Batch 50, Loss: 0.2468
Batch 60, Loss: 0.2314
Batch 70, Loss: 0.2743
Batch 80, Loss: 0.2599
Batch 90, Loss: 0.2520
Batch 100, Loss: 0.2745
Batch 110, Loss: 0.2617
Batch 120, Loss: 0.2485
Batch 130, Loss: 0.2420
Batch 140, Loss: 0.3029
Batch 150, Loss: 0.2739
Batch 160, Loss: 0.2696
Batch 170, Loss: 0.2783
Batch 180, Loss: 0.2765
Batch 190, Loss: 0.2819
Batch 200, Loss: 0.2672
Batch 210, Loss: 0.2732
Batch 220, Loss: 0.2343
Batch 230, Loss: 0.2420
Batch 240, Loss: 0.2513
Batch 250, Loss: 0.2508
Batch 260, Loss: 0.2564
Batch 270, Loss: 0.2736
Batch 280, Loss: 0.2842
Batch 290, Loss: 0.2627
Batch 300, Loss: 0.2870
Batch 310, Loss: 0.2484
Batch 320, Loss: 0.2659
Batch 330, Loss: 0.2789
Batch 340, Loss: 0.2667
Batch 350, Loss: 0.3048
Batch 360, Loss: 0.2581
Batch 370, Loss: 0.3097
Batch 380, Loss: 0.2478
Batch 390, Loss: 0.2528
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.259732723236084 seconds
Epoch 185 accuracy: 79.53%
Batch 10, Loss: 0.2601
Batch 20, Loss: 0.2580
Batch 30, Loss: 0.2525
Batch 40, Loss: 0.2874
Batch 50, Loss: 0.2653
Batch 60, Loss: 0.2573
Batch 70, Loss: 0.2910
Batch 80, Loss: 0.2375
Batch 90, Loss: 0.2402
Batch 100, Loss: 0.2665
Batch 110, Loss: 0.2755
Batch 120, Loss: 0.2948
Batch 130, Loss: 0.2501
Batch 140, Loss: 0.2490
Batch 150, Loss: 0.2650
Batch 160, Loss: 0.2592
Batch 170, Loss: 0.2808
Batch 180, Loss: 0.2519
Batch 190, Loss: 0.2519
Batch 200, Loss: 0.2960
Batch 210, Loss: 0.2590
Batch 220, Loss: 0.2367
Batch 230, Loss: 0.2744
Batch 240, Loss: 0.2815
Batch 250, Loss: 0.2790
Batch 260, Loss: 0.2276
Batch 270, Loss: 0.2757
Batch 280, Loss: 0.2772
Batch 290, Loss: 0.2686
Batch 300, Loss: 0.2735
Batch 310, Loss: 0.2566
Batch 320, Loss: 0.2534
Batch 330, Loss: 0.2585
Batch 340, Loss: 0.2781
Batch 350, Loss: 0.2720
Batch 360, Loss: 0.2698
Batch 370, Loss: 0.2801
Batch 380, Loss: 0.2498
Batch 390, Loss: 0.3233
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.448972702026367 seconds
Epoch 186 accuracy: 80.0%
Batch 10, Loss: 0.2704
Batch 20, Loss: 0.2654
Batch 30, Loss: 0.2576
Batch 40, Loss: 0.2632
Batch 50, Loss: 0.2413
Batch 60, Loss: 0.2709
Batch 70, Loss: 0.2878
Batch 80, Loss: 0.2475
Batch 90, Loss: 0.2278
Batch 100, Loss: 0.2498
Batch 110, Loss: 0.2597
Batch 120, Loss: 0.2535
Batch 130, Loss: 0.2529
Batch 140, Loss: 0.2805
Batch 150, Loss: 0.2654
Batch 160, Loss: 0.2659
Batch 170, Loss: 0.2591
Batch 180, Loss: 0.2331
Batch 190, Loss: 0.2640
Batch 200, Loss: 0.2932
Batch 210, Loss: 0.2604
Batch 220, Loss: 0.2570
Batch 230, Loss: 0.2505
Batch 240, Loss: 0.2599
Batch 250, Loss: 0.2673
Batch 260, Loss: 0.2864
Batch 270, Loss: 0.2322
Batch 280, Loss: 0.2668
Batch 290, Loss: 0.2549
Batch 300, Loss: 0.2252
Batch 310, Loss: 0.2883
Batch 320, Loss: 0.2494
Batch 330, Loss: 0.2523
Batch 340, Loss: 0.2412
Batch 350, Loss: 0.2611
Batch 360, Loss: 0.2608
Batch 370, Loss: 0.2577
Batch 380, Loss: 0.2455
Batch 390, Loss: 0.2675
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.464817762374878 seconds
Epoch 187 accuracy: 80.17%
Batch 10, Loss: 0.2506
Batch 20, Loss: 0.2782
Batch 30, Loss: 0.2608
Batch 40, Loss: 0.2121
Batch 50, Loss: 0.2614
Batch 60, Loss: 0.2646
Batch 70, Loss: 0.2481
Batch 80, Loss: 0.2547
Batch 90, Loss: 0.2690
Batch 100, Loss: 0.2477
Batch 110, Loss: 0.2443
Batch 120, Loss: 0.2534
Batch 130, Loss: 0.2385
Batch 140, Loss: 0.2408
Batch 150, Loss: 0.2393
Batch 160, Loss: 0.2639
Batch 170, Loss: 0.2612
Batch 180, Loss: 0.2593
Batch 190, Loss: 0.2713
Batch 200, Loss: 0.2650
Batch 210, Loss: 0.2529
Batch 220, Loss: 0.2527
Batch 230, Loss: 0.2435
Batch 240, Loss: 0.2439
Batch 250, Loss: 0.2450
Batch 260, Loss: 0.2570
Batch 270, Loss: 0.2520
Batch 280, Loss: 0.2617
Batch 290, Loss: 0.2658
Batch 300, Loss: 0.2774
Batch 310, Loss: 0.2518
Batch 320, Loss: 0.2321
Batch 330, Loss: 0.2650
Batch 340, Loss: 0.2365
Batch 350, Loss: 0.2835
Batch 360, Loss: 0.2435
Batch 370, Loss: 0.2320
Batch 380, Loss: 0.2571
Batch 390, Loss: 0.2641
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.354787826538086 seconds
Epoch 188 accuracy: 80.13%
Batch 10, Loss: 0.2622
Batch 20, Loss: 0.2648
Batch 30, Loss: 0.2432
Batch 40, Loss: 0.2492
Batch 50, Loss: 0.2718
Batch 60, Loss: 0.2489
Batch 70, Loss: 0.2439
Batch 80, Loss: 0.2379
Batch 90, Loss: 0.2646
Batch 100, Loss: 0.2182
Batch 110, Loss: 0.2701
Batch 120, Loss: 0.2663
Batch 130, Loss: 0.2635
Batch 140, Loss: 0.2271
Batch 150, Loss: 0.2918
Batch 160, Loss: 0.2541
Batch 170, Loss: 0.2472
Batch 180, Loss: 0.2374
Batch 190, Loss: 0.2627
Batch 200, Loss: 0.2304
Batch 210, Loss: 0.2560
Batch 220, Loss: 0.2664
Batch 230, Loss: 0.2035
Batch 240, Loss: 0.2328
Batch 250, Loss: 0.2723
Batch 260, Loss: 0.2743
Batch 270, Loss: 0.2636
Batch 280, Loss: 0.2440
Batch 290, Loss: 0.2404
Batch 300, Loss: 0.2574
Batch 310, Loss: 0.2717
Batch 320, Loss: 0.2642
Batch 330, Loss: 0.2667
Batch 340, Loss: 0.2564
Batch 350, Loss: 0.2372
Batch 360, Loss: 0.2525
Batch 370, Loss: 0.2594
Batch 380, Loss: 0.2507
Batch 390, Loss: 0.2604
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.26537251472473 seconds
Epoch 189 accuracy: 80.41%
Batch 10, Loss: 0.2571
Batch 20, Loss: 0.2493
Batch 30, Loss: 0.2617
Batch 40, Loss: 0.2455
Batch 50, Loss: 0.2241
Batch 60, Loss: 0.2576
Batch 70, Loss: 0.2537
Batch 80, Loss: 0.2512
Batch 90, Loss: 0.2700
Batch 100, Loss: 0.2643
Batch 110, Loss: 0.2467
Batch 120, Loss: 0.2939
Batch 130, Loss: 0.2494
Batch 140, Loss: 0.2239
Batch 150, Loss: 0.2531
Batch 160, Loss: 0.2250
Batch 170, Loss: 0.2330
Batch 180, Loss: 0.2377
Batch 190, Loss: 0.2544
Batch 200, Loss: 0.2056
Batch 210, Loss: 0.2504
Batch 220, Loss: 0.2631
Batch 230, Loss: 0.2338
Batch 240, Loss: 0.2489
Batch 250, Loss: 0.2566
Batch 260, Loss: 0.2520
Batch 270, Loss: 0.2180
Batch 280, Loss: 0.2592
Batch 290, Loss: 0.2259
Batch 300, Loss: 0.2741
Batch 310, Loss: 0.2599
Batch 320, Loss: 0.2330
Batch 330, Loss: 0.2633
Batch 340, Loss: 0.2749
Batch 350, Loss: 0.2805
Batch 360, Loss: 0.2591
Batch 370, Loss: 0.2580
Batch 380, Loss: 0.2264
Batch 390, Loss: 0.2630
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.255465745925903 seconds
Epoch 190 accuracy: 80.38%
Batch 10, Loss: 0.2551
Batch 20, Loss: 0.2331
Batch 30, Loss: 0.2321
Batch 40, Loss: 0.2395
Batch 50, Loss: 0.2767
Batch 60, Loss: 0.2478
Batch 70, Loss: 0.2494
Batch 80, Loss: 0.2337
Batch 90, Loss: 0.2443
Batch 100, Loss: 0.2515
Batch 110, Loss: 0.2558
Batch 120, Loss: 0.2596
Batch 130, Loss: 0.2386
Batch 140, Loss: 0.2262
Batch 150, Loss: 0.2612
Batch 160, Loss: 0.2495
Batch 170, Loss: 0.2613
Batch 180, Loss: 0.2472
Batch 190, Loss: 0.2609
Batch 200, Loss: 0.2686
Batch 210, Loss: 0.2321
Batch 220, Loss: 0.2381
Batch 230, Loss: 0.2342
Batch 240, Loss: 0.2539
Batch 250, Loss: 0.2567
Batch 260, Loss: 0.2187
Batch 270, Loss: 0.2244
Batch 280, Loss: 0.2787
Batch 290, Loss: 0.2532
Batch 300, Loss: 0.2580
Batch 310, Loss: 0.2693
Batch 320, Loss: 0.2414
Batch 330, Loss: 0.2655
Batch 340, Loss: 0.2532
Batch 350, Loss: 0.2440
Batch 360, Loss: 0.2241
Batch 370, Loss: 0.2401
Batch 380, Loss: 0.2342
Batch 390, Loss: 0.2909
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.239716291427612 seconds
Epoch 191 accuracy: 80.25%
Batch 10, Loss: 0.2387
Batch 20, Loss: 0.2474
Batch 30, Loss: 0.2411
Batch 40, Loss: 0.2630
Batch 50, Loss: 0.2309
Batch 60, Loss: 0.2313
Batch 70, Loss: 0.2489
Batch 80, Loss: 0.2589
Batch 90, Loss: 0.2608
Batch 100, Loss: 0.2567
Batch 110, Loss: 0.2105
Batch 120, Loss: 0.2292
Batch 130, Loss: 0.2727
Batch 140, Loss: 0.2434
Batch 150, Loss: 0.2815
Batch 160, Loss: 0.2288
Batch 170, Loss: 0.2848
Batch 180, Loss: 0.2453
Batch 190, Loss: 0.2420
Batch 200, Loss: 0.2220
Batch 210, Loss: 0.2605
Batch 220, Loss: 0.2420
Batch 230, Loss: 0.2623
Batch 240, Loss: 0.2576
Batch 250, Loss: 0.2714
Batch 260, Loss: 0.2348
Batch 270, Loss: 0.2218
Batch 280, Loss: 0.2274
Batch 290, Loss: 0.2216
Batch 300, Loss: 0.2264
Batch 310, Loss: 0.2616
Batch 320, Loss: 0.2548
Batch 330, Loss: 0.2405
Batch 340, Loss: 0.2436
Batch 350, Loss: 0.2592
Batch 360, Loss: 0.2669
Batch 370, Loss: 0.2378
Batch 380, Loss: 0.2106
Batch 390, Loss: 0.2397
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.379088401794434 seconds
Epoch 192 accuracy: 80.27%
Batch 10, Loss: 0.2251
Batch 20, Loss: 0.2655
Batch 30, Loss: 0.2175
Batch 40, Loss: 0.2488
Batch 50, Loss: 0.2393
Batch 60, Loss: 0.2450
Batch 70, Loss: 0.2275
Batch 80, Loss: 0.2286
Batch 90, Loss: 0.2216
Batch 100, Loss: 0.2541
Batch 110, Loss: 0.2596
Batch 120, Loss: 0.2531
Batch 130, Loss: 0.2295
Batch 140, Loss: 0.2807
Batch 150, Loss: 0.2462
Batch 160, Loss: 0.2106
Batch 170, Loss: 0.2447
Batch 180, Loss: 0.2364
Batch 190, Loss: 0.2329
Batch 200, Loss: 0.2281
Batch 210, Loss: 0.2705
Batch 220, Loss: 0.2445
Batch 230, Loss: 0.2553
Batch 240, Loss: 0.2505
Batch 250, Loss: 0.2548
Batch 260, Loss: 0.2366
Batch 270, Loss: 0.2485
Batch 280, Loss: 0.2057
Batch 290, Loss: 0.2584
Batch 300, Loss: 0.2503
Batch 310, Loss: 0.2276
Batch 320, Loss: 0.2357
Batch 330, Loss: 0.2754
Batch 340, Loss: 0.2125
Batch 350, Loss: 0.2600
Batch 360, Loss: 0.2568
Batch 370, Loss: 0.2412
Batch 380, Loss: 0.2344
Batch 390, Loss: 0.2159
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.315135717391968 seconds
Epoch 193 accuracy: 80.3%
Batch 10, Loss: 0.2549
Batch 20, Loss: 0.2365
Batch 30, Loss: 0.2672
Batch 40, Loss: 0.2224
Batch 50, Loss: 0.2524
Batch 60, Loss: 0.2366
Batch 70, Loss: 0.2391
Batch 80, Loss: 0.2225
Batch 90, Loss: 0.2485
Batch 100, Loss: 0.2502
Batch 110, Loss: 0.2366
Batch 120, Loss: 0.2058
Batch 130, Loss: 0.2216
Batch 140, Loss: 0.2507
Batch 150, Loss: 0.2318
Batch 160, Loss: 0.2363
Batch 170, Loss: 0.2571
Batch 180, Loss: 0.2396
Batch 190, Loss: 0.2212
Batch 200, Loss: 0.2288
Batch 210, Loss: 0.2453
Batch 220, Loss: 0.2537
Batch 230, Loss: 0.2493
Batch 240, Loss: 0.2837
Batch 250, Loss: 0.2578
Batch 260, Loss: 0.2162
Batch 270, Loss: 0.2036
Batch 280, Loss: 0.2426
Batch 290, Loss: 0.2643
Batch 300, Loss: 0.2379
Batch 310, Loss: 0.2237
Batch 320, Loss: 0.2595
Batch 330, Loss: 0.2416
Batch 340, Loss: 0.2534
Batch 350, Loss: 0.2500
Batch 360, Loss: 0.2390
Batch 370, Loss: 0.2285
Batch 380, Loss: 0.2157
Batch 390, Loss: 0.2116
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.500338792800903 seconds
Epoch 194 accuracy: 80.28%
Batch 10, Loss: 0.2514
Batch 20, Loss: 0.2405
Batch 30, Loss: 0.2262
Batch 40, Loss: 0.2422
Batch 50, Loss: 0.2604
Batch 60, Loss: 0.2339
Batch 70, Loss: 0.2253
Batch 80, Loss: 0.2571
Batch 90, Loss: 0.1980
Batch 100, Loss: 0.2471
Batch 110, Loss: 0.2332
Batch 120, Loss: 0.2353
Batch 130, Loss: 0.2377
Batch 140, Loss: 0.2618
Batch 150, Loss: 0.2558
Batch 160, Loss: 0.2332
Batch 170, Loss: 0.2453
Batch 180, Loss: 0.2459
Batch 190, Loss: 0.2200
Batch 200, Loss: 0.2283
Batch 210, Loss: 0.2403
Batch 220, Loss: 0.2363
Batch 230, Loss: 0.2218
Batch 240, Loss: 0.2188
Batch 250, Loss: 0.2403
Batch 260, Loss: 0.2380
Batch 270, Loss: 0.2243
Batch 280, Loss: 0.2448
Batch 290, Loss: 0.2438
Batch 300, Loss: 0.2252
Batch 310, Loss: 0.2285
Batch 320, Loss: 0.2327
Batch 330, Loss: 0.2210
Batch 340, Loss: 0.2278
Batch 350, Loss: 0.2222
Batch 360, Loss: 0.2657
Batch 370, Loss: 0.2279
Batch 380, Loss: 0.2200
Batch 390, Loss: 0.2657
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.291661977767944 seconds
Epoch 195 accuracy: 80.06%
Batch 10, Loss: 0.2418
Batch 20, Loss: 0.2443
Batch 30, Loss: 0.2356
Batch 40, Loss: 0.2382
Batch 50, Loss: 0.2137
Batch 60, Loss: 0.2527
Batch 70, Loss: 0.2397
Batch 80, Loss: 0.2393
Batch 90, Loss: 0.2707
Batch 100, Loss: 0.2296
Batch 110, Loss: 0.2473
Batch 120, Loss: 0.2324
Batch 130, Loss: 0.2277
Batch 140, Loss: 0.2405
Batch 150, Loss: 0.2560
Batch 160, Loss: 0.2363
Batch 170, Loss: 0.2177
Batch 180, Loss: 0.2378
Batch 190, Loss: 0.2554
Batch 200, Loss: 0.2435
Batch 210, Loss: 0.2488
Batch 220, Loss: 0.2236
Batch 230, Loss: 0.2195
Batch 240, Loss: 0.2548
Batch 250, Loss: 0.2400
Batch 260, Loss: 0.2439
Batch 270, Loss: 0.2515
Batch 280, Loss: 0.2399
Batch 290, Loss: 0.2457
Batch 300, Loss: 0.2560
Batch 310, Loss: 0.2309
Batch 320, Loss: 0.2492
Batch 330, Loss: 0.2261
Batch 340, Loss: 0.2612
Batch 350, Loss: 0.2443
Batch 360, Loss: 0.2721
Batch 370, Loss: 0.2554
Batch 380, Loss: 0.2317
Batch 390, Loss: 0.2362
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.359957933425903 seconds
Epoch 196 accuracy: 80.51%
Batch 10, Loss: 0.2307
Batch 20, Loss: 0.2468
Batch 30, Loss: 0.2805
Batch 40, Loss: 0.2336
Batch 50, Loss: 0.2119
Batch 60, Loss: 0.2171
Batch 70, Loss: 0.2215
Batch 80, Loss: 0.2519
Batch 90, Loss: 0.2330
Batch 100, Loss: 0.2614
Batch 110, Loss: 0.2284
Batch 120, Loss: 0.2464
Batch 130, Loss: 0.2688
Batch 140, Loss: 0.2646
Batch 150, Loss: 0.2453
Batch 160, Loss: 0.2497
Batch 170, Loss: 0.2512
Batch 180, Loss: 0.2417
Batch 190, Loss: 0.2510
Batch 200, Loss: 0.2330
Batch 210, Loss: 0.2578
Batch 220, Loss: 0.2231
Batch 230, Loss: 0.2677
Batch 240, Loss: 0.2188
Batch 250, Loss: 0.2269
Batch 260, Loss: 0.2131
Batch 270, Loss: 0.2342
Batch 280, Loss: 0.2380
Batch 290, Loss: 0.2027
Batch 300, Loss: 0.2244
Batch 310, Loss: 0.2289
Batch 320, Loss: 0.2483
Batch 330, Loss: 0.2022
Batch 340, Loss: 0.2405
Batch 350, Loss: 0.2178
Batch 360, Loss: 0.2274
Batch 370, Loss: 0.2415
Batch 380, Loss: 0.2219
Batch 390, Loss: 0.2032
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.41833734512329 seconds
Epoch 197 accuracy: 80.17%
Batch 10, Loss: 0.2530
Batch 20, Loss: 0.2253
Batch 30, Loss: 0.2323
Batch 40, Loss: 0.2431
Batch 50, Loss: 0.2525
Batch 60, Loss: 0.2356
Batch 70, Loss: 0.2312
Batch 80, Loss: 0.2424
Batch 90, Loss: 0.2334
Batch 100, Loss: 0.2395
Batch 110, Loss: 0.2204
Batch 120, Loss: 0.2709
Batch 130, Loss: 0.2577
Batch 140, Loss: 0.2191
Batch 150, Loss: 0.2215
Batch 160, Loss: 0.2601
Batch 170, Loss: 0.2257
Batch 180, Loss: 0.2157
Batch 190, Loss: 0.2284
Batch 200, Loss: 0.2460
Batch 210, Loss: 0.2231
Batch 220, Loss: 0.2593
Batch 230, Loss: 0.2466
Batch 240, Loss: 0.2244
Batch 250, Loss: 0.2538
Batch 260, Loss: 0.2281
Batch 270, Loss: 0.2400
Batch 280, Loss: 0.2403
Batch 290, Loss: 0.2721
Batch 300, Loss: 0.2324
Batch 310, Loss: 0.2300
Batch 320, Loss: 0.2285
Batch 330, Loss: 0.2132
Batch 340, Loss: 0.2342
Batch 350, Loss: 0.2200
Batch 360, Loss: 0.2647
Batch 370, Loss: 0.2361
Batch 380, Loss: 0.2234
Batch 390, Loss: 0.2292
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.212438344955444 seconds
Epoch 198 accuracy: 80.29%
Batch 10, Loss: 0.2422
Batch 20, Loss: 0.2466
Batch 30, Loss: 0.2605
Batch 40, Loss: 0.2220
Batch 50, Loss: 0.2285
Batch 60, Loss: 0.2323
Batch 70, Loss: 0.2226
Batch 80, Loss: 0.2268
Batch 90, Loss: 0.2496
Batch 100, Loss: 0.2209
Batch 110, Loss: 0.2268
Batch 120, Loss: 0.2004
Batch 130, Loss: 0.2638
Batch 140, Loss: 0.2355
Batch 150, Loss: 0.2092
Batch 160, Loss: 0.1980
Batch 170, Loss: 0.2029
Batch 180, Loss: 0.2186
Batch 190, Loss: 0.2363
Batch 200, Loss: 0.2349
Batch 210, Loss: 0.2376
Batch 220, Loss: 0.2411
Batch 230, Loss: 0.2556
Batch 240, Loss: 0.2658
Batch 250, Loss: 0.2222
Batch 260, Loss: 0.2467
Batch 270, Loss: 0.2129
Batch 280, Loss: 0.2461
Batch 290, Loss: 0.2393
Batch 300, Loss: 0.2363
Batch 310, Loss: 0.2335
Batch 320, Loss: 0.2515
Batch 330, Loss: 0.2461
Batch 340, Loss: 0.2659
Batch 350, Loss: 0.2336
Batch 360, Loss: 0.2321
Batch 370, Loss: 0.2290
Batch 380, Loss: 0.2540
Batch 390, Loss: 0.2458
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.346306085586548 seconds
Epoch 199 accuracy: 80.32%
Batch 10, Loss: 0.2296
Batch 20, Loss: 0.2570
Batch 30, Loss: 0.2208
Batch 40, Loss: 0.1983
Batch 50, Loss: 0.2099
Batch 60, Loss: 0.2614
Batch 70, Loss: 0.2300
Batch 80, Loss: 0.2303
Batch 90, Loss: 0.2290
Batch 100, Loss: 0.2177
Batch 110, Loss: 0.2444
Batch 120, Loss: 0.2435
Batch 130, Loss: 0.2442
Batch 140, Loss: 0.2418
Batch 150, Loss: 0.2415
Batch 160, Loss: 0.2671
Batch 170, Loss: 0.2062
Batch 180, Loss: 0.2469
Batch 190, Loss: 0.2206
Batch 200, Loss: 0.2415
Batch 210, Loss: 0.2408
Batch 220, Loss: 0.2398
Batch 230, Loss: 0.2497
Batch 240, Loss: 0.2182
Batch 250, Loss: 0.2241
Batch 260, Loss: 0.2399
Batch 270, Loss: 0.2258
Batch 280, Loss: 0.2261
Batch 290, Loss: 0.2184
Batch 300, Loss: 0.2347
Batch 310, Loss: 0.2425
Batch 320, Loss: 0.2605
Batch 330, Loss: 0.2450
Batch 340, Loss: 0.2600
Batch 350, Loss: 0.2240
Batch 360, Loss: 0.2498
Batch 370, Loss: 0.2530
Batch 380, Loss: 0.2156
Batch 390, Loss: 0.2375
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.31683921813965 seconds
Epoch 200 accuracy: 80.29%
Total training time: 5079.083475351334 seconds
