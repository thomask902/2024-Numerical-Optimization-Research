The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1795
Batch 20, Loss: 4.0416
Batch 30, Loss: 3.7461
Batch 40, Loss: 3.7423
Batch 50, Loss: 3.6046
Batch 60, Loss: 3.5985
Batch 70, Loss: 3.5498
Batch 80, Loss: 3.4407
Batch 90, Loss: 3.4526
Batch 100, Loss: 3.4454
Batch 110, Loss: 3.3997
Batch 120, Loss: 3.4000
Batch 130, Loss: 3.4035
Batch 140, Loss: 3.3336
Batch 150, Loss: 3.3637
Batch 160, Loss: 3.3583
Batch 170, Loss: 3.3078
Batch 180, Loss: 3.3081
Batch 190, Loss: 3.2806
Batch 200, Loss: 3.2398
Batch 210, Loss: 3.2742
Batch 220, Loss: 3.2628
Batch 230, Loss: 3.2119
Batch 240, Loss: 3.2012
Batch 250, Loss: 3.2037
Batch 260, Loss: 3.2114
Batch 270, Loss: 3.1784
Batch 280, Loss: 3.1974
Batch 290, Loss: 3.1628
Batch 300, Loss: 3.1947
Batch 310, Loss: 3.1465
Batch 320, Loss: 3.1311
Batch 330, Loss: 3.1858
Batch 340, Loss: 3.1511
Batch 350, Loss: 3.1716
Batch 360, Loss: 3.1676
Batch 370, Loss: 3.1003
Batch 380, Loss: 3.1408
Batch 390, Loss: 3.0248
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.50144362449646 seconds
Epoch 1 accuracy: 12.17%
Batch 10, Loss: 3.0302
Batch 20, Loss: 3.0490
Batch 30, Loss: 3.0372
Batch 40, Loss: 3.0489
Batch 50, Loss: 3.0660
Batch 60, Loss: 2.9980
Batch 70, Loss: 3.0413
Batch 80, Loss: 2.9666
Batch 90, Loss: 3.0027
Batch 100, Loss: 3.0320
Batch 110, Loss: 2.9159
Batch 120, Loss: 3.0042
Batch 130, Loss: 2.9753
Batch 140, Loss: 2.9691
Batch 150, Loss: 2.9654
Batch 160, Loss: 2.9098
Batch 170, Loss: 2.8827
Batch 180, Loss: 2.9379
Batch 190, Loss: 2.8989
Batch 200, Loss: 2.8750
Batch 210, Loss: 2.9004
Batch 220, Loss: 2.8302
Batch 230, Loss: 2.9354
Batch 240, Loss: 2.8548
Batch 250, Loss: 2.8786
Batch 260, Loss: 2.8881
Batch 270, Loss: 2.8278
Batch 280, Loss: 2.8233
Batch 290, Loss: 2.8251
Batch 300, Loss: 2.8267
Batch 310, Loss: 2.8719
Batch 320, Loss: 2.8360
Batch 330, Loss: 2.8009
Batch 340, Loss: 2.8347
Batch 350, Loss: 2.7867
Batch 360, Loss: 2.8094
Batch 370, Loss: 2.7781
Batch 380, Loss: 2.6669
Batch 390, Loss: 2.7222
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.097094297409058 seconds
Epoch 2 accuracy: 20.41%
Batch 10, Loss: 2.6704
Batch 20, Loss: 2.6769
Batch 30, Loss: 2.6954
Batch 40, Loss: 2.7608
Batch 50, Loss: 2.7217
Batch 60, Loss: 2.7022
Batch 70, Loss: 2.6647
Batch 80, Loss: 2.6498
Batch 90, Loss: 2.7201
Batch 100, Loss: 2.6636
Batch 110, Loss: 2.6518
Batch 120, Loss: 2.6333
Batch 130, Loss: 2.6445
Batch 140, Loss: 2.6374
Batch 150, Loss: 2.6367
Batch 160, Loss: 2.6548
Batch 170, Loss: 2.6268
Batch 180, Loss: 2.5882
Batch 190, Loss: 2.6570
Batch 200, Loss: 2.6427
Batch 210, Loss: 2.5687
Batch 220, Loss: 2.5560
Batch 230, Loss: 2.5466
Batch 240, Loss: 2.5126
Batch 250, Loss: 2.5314
Batch 260, Loss: 2.5220
Batch 270, Loss: 2.5208
Batch 280, Loss: 2.5347
Batch 290, Loss: 2.5354
Batch 300, Loss: 2.5200
Batch 310, Loss: 2.4747
Batch 320, Loss: 2.4606
Batch 330, Loss: 2.5106
Batch 340, Loss: 2.4750
Batch 350, Loss: 2.4455
Batch 360, Loss: 2.4727
Batch 370, Loss: 2.4857
Batch 380, Loss: 2.4658
Batch 390, Loss: 2.4594
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.129146099090576 seconds
Epoch 3 accuracy: 27.36%
Batch 10, Loss: 2.4124
Batch 20, Loss: 2.4049
Batch 30, Loss: 2.4475
Batch 40, Loss: 2.3743
Batch 50, Loss: 2.2818
Batch 60, Loss: 2.4079
Batch 70, Loss: 2.3402
Batch 80, Loss: 2.3855
Batch 90, Loss: 2.3950
Batch 100, Loss: 2.2748
Batch 110, Loss: 2.3117
Batch 120, Loss: 2.3464
Batch 130, Loss: 2.3858
Batch 140, Loss: 2.3740
Batch 150, Loss: 2.3543
Batch 160, Loss: 2.3106
Batch 170, Loss: 2.3268
Batch 180, Loss: 2.3029
Batch 190, Loss: 2.3093
Batch 200, Loss: 2.2986
Batch 210, Loss: 2.2643
Batch 220, Loss: 2.2879
Batch 230, Loss: 2.2534
Batch 240, Loss: 2.2440
Batch 250, Loss: 2.2272
Batch 260, Loss: 2.2797
Batch 270, Loss: 2.2553
Batch 280, Loss: 2.2366
Batch 290, Loss: 2.1902
Batch 300, Loss: 2.2452
Batch 310, Loss: 2.2323
Batch 320, Loss: 2.2378
Batch 330, Loss: 2.1896
Batch 340, Loss: 2.1515
Batch 350, Loss: 2.2072
Batch 360, Loss: 2.2698
Batch 370, Loss: 2.2149
Batch 380, Loss: 2.2054
Batch 390, Loss: 2.1661
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.083611965179443 seconds
Epoch 4 accuracy: 30.29%
Batch 10, Loss: 2.1435
Batch 20, Loss: 2.0721
Batch 30, Loss: 2.0637
Batch 40, Loss: 2.0887
Batch 50, Loss: 2.0953
Batch 60, Loss: 2.0795
Batch 70, Loss: 2.0048
Batch 80, Loss: 2.0911
Batch 90, Loss: 2.0902
Batch 100, Loss: 2.0289
Batch 110, Loss: 2.0330
Batch 120, Loss: 2.0330
Batch 130, Loss: 2.0533
Batch 140, Loss: 2.0846
Batch 150, Loss: 2.0562
Batch 160, Loss: 2.0007
Batch 170, Loss: 1.9935
Batch 180, Loss: 1.9487
Batch 190, Loss: 2.0000
Batch 200, Loss: 2.0258
Batch 210, Loss: 1.9832
Batch 220, Loss: 1.9980
Batch 230, Loss: 2.0070
Batch 240, Loss: 2.0050
Batch 250, Loss: 1.9125
Batch 260, Loss: 1.9967
Batch 270, Loss: 1.9116
Batch 280, Loss: 2.0376
Batch 290, Loss: 1.9271
Batch 300, Loss: 1.9605
Batch 310, Loss: 1.9683
Batch 320, Loss: 1.9909
Batch 330, Loss: 1.8913
Batch 340, Loss: 1.9049
Batch 350, Loss: 1.9137
Batch 360, Loss: 1.9156
Batch 370, Loss: 1.8543
Batch 380, Loss: 1.9411
Batch 390, Loss: 1.9097
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.152953147888184 seconds
Epoch 5 accuracy: 40.31%
Batch 10, Loss: 1.8270
Batch 20, Loss: 1.8356
Batch 30, Loss: 1.7953
Batch 40, Loss: 1.7921
Batch 50, Loss: 1.8126
Batch 60, Loss: 1.7994
Batch 70, Loss: 1.8435
Batch 80, Loss: 1.8368
Batch 90, Loss: 1.8321
Batch 100, Loss: 1.8359
Batch 110, Loss: 1.8118
Batch 120, Loss: 1.8063
Batch 130, Loss: 1.8402
Batch 140, Loss: 1.8955
Batch 150, Loss: 1.8023
Batch 160, Loss: 1.8148
Batch 170, Loss: 1.7906
Batch 180, Loss: 1.7698
Batch 190, Loss: 1.8473
Batch 200, Loss: 1.8085
Batch 210, Loss: 1.7823
Batch 220, Loss: 1.7713
Batch 230, Loss: 1.8482
Batch 240, Loss: 1.7539
Batch 250, Loss: 1.6677
Batch 260, Loss: 1.7518
Batch 270, Loss: 1.7829
Batch 280, Loss: 1.7530
Batch 290, Loss: 1.7482
Batch 300, Loss: 1.7244
Batch 310, Loss: 1.7491
Batch 320, Loss: 1.7804
Batch 330, Loss: 1.6664
Batch 340, Loss: 1.6985
Batch 350, Loss: 1.8085
Batch 360, Loss: 1.7642
Batch 370, Loss: 1.7356
Batch 380, Loss: 1.7420
Batch 390, Loss: 1.7114
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.111855506896973 seconds
Epoch 6 accuracy: 39.12%
Batch 10, Loss: 1.7135
Batch 20, Loss: 1.6401
Batch 30, Loss: 1.6195
Batch 40, Loss: 1.6629
Batch 50, Loss: 1.6561
Batch 60, Loss: 1.6494
Batch 70, Loss: 1.6376
Batch 80, Loss: 1.6987
Batch 90, Loss: 1.6774
Batch 100, Loss: 1.6985
Batch 110, Loss: 1.6717
Batch 120, Loss: 1.5745
Batch 130, Loss: 1.5674
Batch 140, Loss: 1.6057
Batch 150, Loss: 1.6245
Batch 160, Loss: 1.6337
Batch 170, Loss: 1.6512
Batch 180, Loss: 1.6004
Batch 190, Loss: 1.5804
Batch 200, Loss: 1.5942
Batch 210, Loss: 1.6139
Batch 220, Loss: 1.6665
Batch 230, Loss: 1.6518
Batch 240, Loss: 1.6451
Batch 250, Loss: 1.7199
Batch 260, Loss: 1.7254
Batch 270, Loss: 1.6130
Batch 280, Loss: 1.6322
Batch 290, Loss: 1.6073
Batch 300, Loss: 1.6583
Batch 310, Loss: 1.6178
Batch 320, Loss: 1.5904
Batch 330, Loss: 1.6718
Batch 340, Loss: 1.6895
Batch 350, Loss: 1.6157
Batch 360, Loss: 1.6529
Batch 370, Loss: 1.6030
Batch 380, Loss: 1.6273
Batch 390, Loss: 1.6210
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.097095727920532 seconds
Epoch 7 accuracy: 45.68%
Batch 10, Loss: 1.5072
Batch 20, Loss: 1.5087
Batch 30, Loss: 1.4596
Batch 40, Loss: 1.6235
Batch 50, Loss: 1.5598
Batch 60, Loss: 1.5229
Batch 70, Loss: 1.5205
Batch 80, Loss: 1.5292
Batch 90, Loss: 1.5127
Batch 100, Loss: 1.5345
Batch 110, Loss: 1.5410
Batch 120, Loss: 1.5647
Batch 130, Loss: 1.5187
Batch 140, Loss: 1.5215
Batch 150, Loss: 1.5233
Batch 160, Loss: 1.5200
Batch 170, Loss: 1.5282
Batch 180, Loss: 1.5678
Batch 190, Loss: 1.5309
Batch 200, Loss: 1.5693
Batch 210, Loss: 1.5330
Batch 220, Loss: 1.5129
Batch 230, Loss: 1.5673
Batch 240, Loss: 1.5623
Batch 250, Loss: 1.5281
Batch 260, Loss: 1.5774
Batch 270, Loss: 1.5102
Batch 280, Loss: 1.6089
Batch 290, Loss: 1.4969
Batch 300, Loss: 1.5519
Batch 310, Loss: 1.5552
Batch 320, Loss: 1.4804
Batch 330, Loss: 1.5503
Batch 340, Loss: 1.5706
Batch 350, Loss: 1.5187
Batch 360, Loss: 1.5322
Batch 370, Loss: 1.5053
Batch 380, Loss: 1.5610
Batch 390, Loss: 1.5435
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.09306287765503 seconds
Epoch 8 accuracy: 46.04%
Batch 10, Loss: 1.4772
Batch 20, Loss: 1.4943
Batch 30, Loss: 1.4590
Batch 40, Loss: 1.4711
Batch 50, Loss: 1.4443
Batch 60, Loss: 1.5236
Batch 70, Loss: 1.4290
Batch 80, Loss: 1.4432
Batch 90, Loss: 1.4777
Batch 100, Loss: 1.4761
Batch 110, Loss: 1.4381
Batch 120, Loss: 1.5639
Batch 130, Loss: 1.4602
Batch 140, Loss: 1.4336
Batch 150, Loss: 1.4512
Batch 160, Loss: 1.4498
Batch 170, Loss: 1.4121
Batch 180, Loss: 1.4312
Batch 190, Loss: 1.4928
Batch 200, Loss: 1.4970
Batch 210, Loss: 1.4597
Batch 220, Loss: 1.4774
Batch 230, Loss: 1.4447
Batch 240, Loss: 1.4910
Batch 250, Loss: 1.5375
Batch 260, Loss: 1.4947
Batch 270, Loss: 1.5256
Batch 280, Loss: 1.4651
Batch 290, Loss: 1.4599
Batch 300, Loss: 1.4901
Batch 310, Loss: 1.4763
Batch 320, Loss: 1.4767
Batch 330, Loss: 1.4820
Batch 340, Loss: 1.4943
Batch 350, Loss: 1.4485
Batch 360, Loss: 1.4674
Batch 370, Loss: 1.4617
Batch 380, Loss: 1.4712
Batch 390, Loss: 1.4259
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.07689595222473 seconds
Epoch 9 accuracy: 48.51%
Batch 10, Loss: 1.3844
Batch 20, Loss: 1.3924
Batch 30, Loss: 1.3357
Batch 40, Loss: 1.4253
Batch 50, Loss: 1.3639
Batch 60, Loss: 1.4107
Batch 70, Loss: 1.3709
Batch 80, Loss: 1.3320
Batch 90, Loss: 1.4196
Batch 100, Loss: 1.3628
Batch 110, Loss: 1.3878
Batch 120, Loss: 1.4245
Batch 130, Loss: 1.4057
Batch 140, Loss: 1.3560
Batch 150, Loss: 1.4079
Batch 160, Loss: 1.4738
Batch 170, Loss: 1.4098
Batch 180, Loss: 1.3602
Batch 190, Loss: 1.3887
Batch 200, Loss: 1.3801
Batch 210, Loss: 1.3801
Batch 220, Loss: 1.4143
Batch 230, Loss: 1.4890
Batch 240, Loss: 1.4551
Batch 250, Loss: 1.4169
Batch 260, Loss: 1.3725
Batch 270, Loss: 1.4555
Batch 280, Loss: 1.3970
Batch 290, Loss: 1.4086
Batch 300, Loss: 1.4527
Batch 310, Loss: 1.3530
Batch 320, Loss: 1.3767
Batch 330, Loss: 1.5475
Batch 340, Loss: 1.4617
Batch 350, Loss: 1.5019
Batch 360, Loss: 1.3786
Batch 370, Loss: 1.4434
Batch 380, Loss: 1.3895
Batch 390, Loss: 1.3442
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.084296703338623 seconds
Epoch 10 accuracy: 52.15%
Batch 10, Loss: 1.3413
Batch 20, Loss: 1.2750
Batch 30, Loss: 1.2840
Batch 40, Loss: 1.2618
Batch 50, Loss: 1.3203
Batch 60, Loss: 1.2965
Batch 70, Loss: 1.3078
Batch 80, Loss: 1.3841
Batch 90, Loss: 1.3804
Batch 100, Loss: 1.3497
Batch 110, Loss: 1.2456
Batch 120, Loss: 1.3139
Batch 130, Loss: 1.3338
Batch 140, Loss: 1.4218
Batch 150, Loss: 1.3794
Batch 160, Loss: 1.3573
Batch 170, Loss: 1.3712
Batch 180, Loss: 1.3677
Batch 190, Loss: 1.4307
Batch 200, Loss: 1.3849
Batch 210, Loss: 1.4284
Batch 220, Loss: 1.2840
Batch 230, Loss: 1.4216
Batch 240, Loss: 1.3991
Batch 250, Loss: 1.4114
Batch 260, Loss: 1.3822
Batch 270, Loss: 1.3493
Batch 280, Loss: 1.3507
Batch 290, Loss: 1.4469
Batch 300, Loss: 1.3717
Batch 310, Loss: 1.3863
Batch 320, Loss: 1.3119
Batch 330, Loss: 1.3683
Batch 340, Loss: 1.3397
Batch 350, Loss: 1.3365
Batch 360, Loss: 1.3832
Batch 370, Loss: 1.3845
Batch 380, Loss: 1.3094
Batch 390, Loss: 1.4324
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.033716917037964 seconds
Epoch 11 accuracy: 52.46%
Batch 10, Loss: 1.3108
Batch 20, Loss: 1.2594
Batch 30, Loss: 1.2747
Batch 40, Loss: 1.2731
Batch 50, Loss: 1.3155
Batch 60, Loss: 1.2574
Batch 70, Loss: 1.3430
Batch 80, Loss: 1.2903
Batch 90, Loss: 1.3015
Batch 100, Loss: 1.2904
Batch 110, Loss: 1.3694
Batch 120, Loss: 1.3564
Batch 130, Loss: 1.3966
Batch 140, Loss: 1.3236
Batch 150, Loss: 1.2547
Batch 160, Loss: 1.3526
Batch 170, Loss: 1.3006
Batch 180, Loss: 1.3526
Batch 190, Loss: 1.3671
Batch 200, Loss: 1.2740
Batch 210, Loss: 1.3346
Batch 220, Loss: 1.2756
Batch 230, Loss: 1.2489
Batch 240, Loss: 1.3350
Batch 250, Loss: 1.3541
Batch 260, Loss: 1.2951
Batch 270, Loss: 1.2783
Batch 280, Loss: 1.2937
Batch 290, Loss: 1.2968
Batch 300, Loss: 1.2590
Batch 310, Loss: 1.3240
Batch 320, Loss: 1.2829
Batch 330, Loss: 1.3458
Batch 340, Loss: 1.3048
Batch 350, Loss: 1.3233
Batch 360, Loss: 1.3986
Batch 370, Loss: 1.3822
Batch 380, Loss: 1.2544
Batch 390, Loss: 1.3564
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.100716829299927 seconds
Epoch 12 accuracy: 52.74%
Batch 10, Loss: 1.2550
Batch 20, Loss: 1.2466
Batch 30, Loss: 1.1763
Batch 40, Loss: 1.2236
Batch 50, Loss: 1.2166
Batch 60, Loss: 1.2657
Batch 70, Loss: 1.1741
Batch 80, Loss: 1.1693
Batch 90, Loss: 1.2680
Batch 100, Loss: 1.3287
Batch 110, Loss: 1.2784
Batch 120, Loss: 1.2237
Batch 130, Loss: 1.2752
Batch 140, Loss: 1.2670
Batch 150, Loss: 1.3488
Batch 160, Loss: 1.2863
Batch 170, Loss: 1.3022
Batch 180, Loss: 1.2772
Batch 190, Loss: 1.3196
Batch 200, Loss: 1.3304
Batch 210, Loss: 1.3013
Batch 220, Loss: 1.2607
Batch 230, Loss: 1.2754
Batch 240, Loss: 1.2731
Batch 250, Loss: 1.3432
Batch 260, Loss: 1.3036
Batch 270, Loss: 1.2290
Batch 280, Loss: 1.3330
Batch 290, Loss: 1.2979
Batch 300, Loss: 1.3711
Batch 310, Loss: 1.3309
Batch 320, Loss: 1.2615
Batch 330, Loss: 1.2550
Batch 340, Loss: 1.2881
Batch 350, Loss: 1.2710
Batch 360, Loss: 1.3060
Batch 370, Loss: 1.2955
Batch 380, Loss: 1.2928
Batch 390, Loss: 1.3363
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.046559810638428 seconds
Epoch 13 accuracy: 51.26%
Batch 10, Loss: 1.1679
Batch 20, Loss: 1.2195
Batch 30, Loss: 1.2445
Batch 40, Loss: 1.1711
Batch 50, Loss: 1.2640
Batch 60, Loss: 1.2090
Batch 70, Loss: 1.1700
Batch 80, Loss: 1.2114
Batch 90, Loss: 1.2293
Batch 100, Loss: 1.2232
Batch 110, Loss: 1.2858
Batch 120, Loss: 1.2270
Batch 130, Loss: 1.2585
Batch 140, Loss: 1.2696
Batch 150, Loss: 1.2545
Batch 160, Loss: 1.2940
Batch 170, Loss: 1.2733
Batch 180, Loss: 1.2591
Batch 190, Loss: 1.3165
Batch 200, Loss: 1.2733
Batch 210, Loss: 1.2589
Batch 220, Loss: 1.2476
Batch 230, Loss: 1.2246
Batch 240, Loss: 1.2245
Batch 250, Loss: 1.2255
Batch 260, Loss: 1.3267
Batch 270, Loss: 1.2516
Batch 280, Loss: 1.3003
Batch 290, Loss: 1.2575
Batch 300, Loss: 1.2541
Batch 310, Loss: 1.2377
Batch 320, Loss: 1.2595
Batch 330, Loss: 1.3648
Batch 340, Loss: 1.2789
Batch 350, Loss: 1.2464
Batch 360, Loss: 1.2492
Batch 370, Loss: 1.3063
Batch 380, Loss: 1.3151
Batch 390, Loss: 1.2539
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.078653573989868 seconds
Epoch 14 accuracy: 53.03%
Batch 10, Loss: 1.2511
Batch 20, Loss: 1.1600
Batch 30, Loss: 1.1048
Batch 40, Loss: 1.1465
Batch 50, Loss: 1.2118
Batch 60, Loss: 1.1963
Batch 70, Loss: 1.2295
Batch 80, Loss: 1.2488
Batch 90, Loss: 1.2023
Batch 100, Loss: 1.1650
Batch 110, Loss: 1.2424
Batch 120, Loss: 1.1670
Batch 130, Loss: 1.2229
Batch 140, Loss: 1.3037
Batch 150, Loss: 1.2106
Batch 160, Loss: 1.1395
Batch 170, Loss: 1.2096
Batch 180, Loss: 1.2134
Batch 190, Loss: 1.2778
Batch 200, Loss: 1.2742
Batch 210, Loss: 1.2447
Batch 220, Loss: 1.1713
Batch 230, Loss: 1.3401
Batch 240, Loss: 1.3168
Batch 250, Loss: 1.3221
Batch 260, Loss: 1.2757
Batch 270, Loss: 1.2510
Batch 280, Loss: 1.1636
Batch 290, Loss: 1.2238
Batch 300, Loss: 1.2050
Batch 310, Loss: 1.2541
Batch 320, Loss: 1.2959
Batch 330, Loss: 1.2372
Batch 340, Loss: 1.2776
Batch 350, Loss: 1.2725
Batch 360, Loss: 1.2420
Batch 370, Loss: 1.2492
Batch 380, Loss: 1.2174
Batch 390, Loss: 1.2562
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.042283296585083 seconds
Epoch 15 accuracy: 54.62%
Batch 10, Loss: 1.1731
Batch 20, Loss: 1.1280
Batch 30, Loss: 1.1646
Batch 40, Loss: 1.1488
Batch 50, Loss: 1.1436
Batch 60, Loss: 1.1371
Batch 70, Loss: 1.0866
Batch 80, Loss: 1.1806
Batch 90, Loss: 1.1739
Batch 100, Loss: 1.1601
Batch 110, Loss: 1.1423
Batch 120, Loss: 1.1415
Batch 130, Loss: 1.2100
Batch 140, Loss: 1.1703
Batch 150, Loss: 1.1651
Batch 160, Loss: 1.2184
Batch 170, Loss: 1.2320
Batch 180, Loss: 1.1836
Batch 190, Loss: 1.2069
Batch 200, Loss: 1.1767
Batch 210, Loss: 1.2050
Batch 220, Loss: 1.2383
Batch 230, Loss: 1.2112
Batch 240, Loss: 1.2054
Batch 250, Loss: 1.2400
Batch 260, Loss: 1.1722
Batch 270, Loss: 1.2059
Batch 280, Loss: 1.1998
Batch 290, Loss: 1.2333
Batch 300, Loss: 1.2254
Batch 310, Loss: 1.2521
Batch 320, Loss: 1.2663
Batch 330, Loss: 1.2469
Batch 340, Loss: 1.2383
Batch 350, Loss: 1.2242
Batch 360, Loss: 1.2350
Batch 370, Loss: 1.2218
Batch 380, Loss: 1.2604
Batch 390, Loss: 1.2207
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.050102472305298 seconds
Epoch 16 accuracy: 47.04%
Batch 10, Loss: 1.1693
Batch 20, Loss: 1.0990
Batch 30, Loss: 1.1161
Batch 40, Loss: 1.1352
Batch 50, Loss: 1.1175
Batch 60, Loss: 1.1169
Batch 70, Loss: 1.0796
Batch 80, Loss: 1.0598
Batch 90, Loss: 1.1338
Batch 100, Loss: 1.1385
Batch 110, Loss: 1.1562
Batch 120, Loss: 1.1236
Batch 130, Loss: 1.2222
Batch 140, Loss: 1.2172
Batch 150, Loss: 1.1314
Batch 160, Loss: 1.2474
Batch 170, Loss: 1.2189
Batch 180, Loss: 1.2181
Batch 190, Loss: 1.2080
Batch 200, Loss: 1.1727
Batch 210, Loss: 1.1358
Batch 220, Loss: 1.2046
Batch 230, Loss: 1.2237
Batch 240, Loss: 1.2150
Batch 250, Loss: 1.1540
Batch 260, Loss: 1.2383
Batch 270, Loss: 1.1516
Batch 280, Loss: 1.2323
Batch 290, Loss: 1.2139
Batch 300, Loss: 1.2016
Batch 310, Loss: 1.2016
Batch 320, Loss: 1.2351
Batch 330, Loss: 1.1742
Batch 340, Loss: 1.2523
Batch 350, Loss: 1.2192
Batch 360, Loss: 1.2246
Batch 370, Loss: 1.2668
Batch 380, Loss: 1.1638
Batch 390, Loss: 1.2394
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.07603621482849 seconds
Epoch 17 accuracy: 52.46%
Batch 10, Loss: 1.1252
Batch 20, Loss: 1.1368
Batch 30, Loss: 1.0804
Batch 40, Loss: 1.1232
Batch 50, Loss: 1.1514
Batch 60, Loss: 1.0989
Batch 70, Loss: 1.1444
Batch 80, Loss: 1.1218
Batch 90, Loss: 1.1173
Batch 100, Loss: 1.1443
Batch 110, Loss: 1.1558
Batch 120, Loss: 1.1947
Batch 130, Loss: 1.1784
Batch 140, Loss: 1.1830
Batch 150, Loss: 1.1044
Batch 160, Loss: 1.0985
Batch 170, Loss: 1.1768
Batch 180, Loss: 1.1754
Batch 190, Loss: 1.2034
Batch 200, Loss: 1.2304
Batch 210, Loss: 1.1866
Batch 220, Loss: 1.1847
Batch 230, Loss: 1.1444
Batch 240, Loss: 1.1744
Batch 250, Loss: 1.2190
Batch 260, Loss: 1.1742
Batch 270, Loss: 1.2028
Batch 280, Loss: 1.1220
Batch 290, Loss: 1.1444
Batch 300, Loss: 1.1996
Batch 310, Loss: 1.2148
Batch 320, Loss: 1.2266
Batch 330, Loss: 1.1693
Batch 340, Loss: 1.1409
Batch 350, Loss: 1.1986
Batch 360, Loss: 1.1735
Batch 370, Loss: 1.1375
Batch 380, Loss: 1.2076
Batch 390, Loss: 1.2123
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.074488639831543 seconds
Epoch 18 accuracy: 52.53%
Batch 10, Loss: 1.0707
Batch 20, Loss: 1.1072
Batch 30, Loss: 1.1141
Batch 40, Loss: 1.0455
Batch 50, Loss: 1.0619
Batch 60, Loss: 1.0766
Batch 70, Loss: 1.1333
Batch 80, Loss: 1.1710
Batch 90, Loss: 1.0730
Batch 100, Loss: 1.0936
Batch 110, Loss: 1.0947
Batch 120, Loss: 1.1601
Batch 130, Loss: 1.1632
Batch 140, Loss: 1.0814
Batch 150, Loss: 1.0993
Batch 160, Loss: 1.1526
Batch 170, Loss: 1.1612
Batch 180, Loss: 1.1484
Batch 190, Loss: 1.2385
Batch 200, Loss: 1.1557
Batch 210, Loss: 1.1034
Batch 220, Loss: 1.0978
Batch 230, Loss: 1.1064
Batch 240, Loss: 1.1144
Batch 250, Loss: 1.1913
Batch 260, Loss: 1.1541
Batch 270, Loss: 1.1604
Batch 280, Loss: 1.2088
Batch 290, Loss: 1.2365
Batch 300, Loss: 1.2211
Batch 310, Loss: 1.1836
Batch 320, Loss: 1.1031
Batch 330, Loss: 1.1885
Batch 340, Loss: 1.1048
Batch 350, Loss: 1.1585
Batch 360, Loss: 1.2270
Batch 370, Loss: 1.1245
Batch 380, Loss: 1.1690
Batch 390, Loss: 1.1426
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.049747228622437 seconds
Epoch 19 accuracy: 53.27%
Batch 10, Loss: 1.1026
Batch 20, Loss: 1.0649
Batch 30, Loss: 1.1110
Batch 40, Loss: 1.1323
Batch 50, Loss: 1.0331
Batch 60, Loss: 1.1128
Batch 70, Loss: 1.0619
Batch 80, Loss: 1.1088
Batch 90, Loss: 1.1440
Batch 100, Loss: 1.0757
Batch 110, Loss: 1.1020
Batch 120, Loss: 1.1022
Batch 130, Loss: 1.1490
Batch 140, Loss: 1.0780
Batch 150, Loss: 1.0974
Batch 160, Loss: 1.1344
Batch 170, Loss: 1.0693
Batch 180, Loss: 1.1469
Batch 190, Loss: 1.0861
Batch 200, Loss: 1.1673
Batch 210, Loss: 1.1448
Batch 220, Loss: 1.1433
Batch 230, Loss: 1.1804
Batch 240, Loss: 1.1407
Batch 250, Loss: 1.1537
Batch 260, Loss: 1.1403
Batch 270, Loss: 1.1105
Batch 280, Loss: 1.1886
Batch 290, Loss: 1.1231
Batch 300, Loss: 1.2118
Batch 310, Loss: 1.1314
Batch 320, Loss: 1.1111
Batch 330, Loss: 1.1439
Batch 340, Loss: 1.1673
Batch 350, Loss: 1.1511
Batch 360, Loss: 1.1245
Batch 370, Loss: 1.1643
Batch 380, Loss: 1.1946
Batch 390, Loss: 1.1158
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.056769371032715 seconds
Epoch 20 accuracy: 56.83%
Batch 10, Loss: 1.1133
Batch 20, Loss: 1.0771
Batch 30, Loss: 1.0508
Batch 40, Loss: 0.9892
Batch 50, Loss: 1.0544
Batch 60, Loss: 1.0125
Batch 70, Loss: 1.0507
Batch 80, Loss: 1.0691
Batch 90, Loss: 1.0758
Batch 100, Loss: 1.0460
Batch 110, Loss: 1.0764
Batch 120, Loss: 1.0632
Batch 130, Loss: 1.0843
Batch 140, Loss: 1.1780
Batch 150, Loss: 1.1469
Batch 160, Loss: 1.0807
Batch 170, Loss: 1.0522
Batch 180, Loss: 1.1575
Batch 190, Loss: 1.1299
Batch 200, Loss: 1.1076
Batch 210, Loss: 1.1279
Batch 220, Loss: 1.1495
Batch 230, Loss: 1.1904
Batch 240, Loss: 1.1368
Batch 250, Loss: 1.1381
Batch 260, Loss: 1.2226
Batch 270, Loss: 1.1964
Batch 280, Loss: 1.1733
Batch 290, Loss: 1.1404
Batch 300, Loss: 1.1358
Batch 310, Loss: 1.1088
Batch 320, Loss: 1.1540
Batch 330, Loss: 1.2019
Batch 340, Loss: 1.1400
Batch 350, Loss: 1.1544
Batch 360, Loss: 1.1465
Batch 370, Loss: 1.1534
Batch 380, Loss: 1.1524
Batch 390, Loss: 1.1586
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.06934118270874 seconds
Epoch 21 accuracy: 55.05%
Batch 10, Loss: 1.0822
Batch 20, Loss: 0.9949
Batch 30, Loss: 1.0070
Batch 40, Loss: 1.0788
Batch 50, Loss: 1.0520
Batch 60, Loss: 1.0612
Batch 70, Loss: 1.1007
Batch 80, Loss: 1.0443
Batch 90, Loss: 1.1129
Batch 100, Loss: 1.1669
Batch 110, Loss: 1.0990
Batch 120, Loss: 1.1100
Batch 130, Loss: 1.1020
Batch 140, Loss: 1.1128
Batch 150, Loss: 1.1316
Batch 160, Loss: 1.1380
Batch 170, Loss: 1.1273
Batch 180, Loss: 1.0789
Batch 190, Loss: 1.0624
Batch 200, Loss: 1.1278
Batch 210, Loss: 1.1096
Batch 220, Loss: 1.0770
Batch 230, Loss: 1.1376
Batch 240, Loss: 1.1678
Batch 250, Loss: 1.1056
Batch 260, Loss: 1.0672
Batch 270, Loss: 1.1248
Batch 280, Loss: 1.1350
Batch 290, Loss: 1.0988
Batch 300, Loss: 1.1270
Batch 310, Loss: 1.1016
Batch 320, Loss: 1.1446
Batch 330, Loss: 1.1237
Batch 340, Loss: 1.0732
Batch 350, Loss: 1.1286
Batch 360, Loss: 1.0997
Batch 370, Loss: 1.1232
Batch 380, Loss: 1.0936
Batch 390, Loss: 1.0922
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.047021627426147 seconds
Epoch 22 accuracy: 59.43%
Batch 10, Loss: 1.0383
Batch 20, Loss: 1.0177
Batch 30, Loss: 0.9586
Batch 40, Loss: 1.0137
Batch 50, Loss: 1.0335
Batch 60, Loss: 1.0201
Batch 70, Loss: 1.0575
Batch 80, Loss: 1.0625
Batch 90, Loss: 1.0897
Batch 100, Loss: 1.0241
Batch 110, Loss: 1.0349
Batch 120, Loss: 1.0494
Batch 130, Loss: 1.0938
Batch 140, Loss: 1.1321
Batch 150, Loss: 1.0382
Batch 160, Loss: 1.0489
Batch 170, Loss: 1.1401
Batch 180, Loss: 1.0635
Batch 190, Loss: 1.0577
Batch 200, Loss: 1.1233
Batch 210, Loss: 1.1276
Batch 220, Loss: 1.0799
Batch 230, Loss: 1.1753
Batch 240, Loss: 1.1183
Batch 250, Loss: 1.2049
Batch 260, Loss: 1.1461
Batch 270, Loss: 1.0577
Batch 280, Loss: 1.0866
Batch 290, Loss: 1.0943
Batch 300, Loss: 1.0722
Batch 310, Loss: 1.0908
Batch 320, Loss: 1.1480
Batch 330, Loss: 1.0889
Batch 340, Loss: 1.1491
Batch 350, Loss: 1.1408
Batch 360, Loss: 1.1160
Batch 370, Loss: 1.1143
Batch 380, Loss: 1.1488
Batch 390, Loss: 1.1550
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.068612337112427 seconds
Epoch 23 accuracy: 55.27%
Batch 10, Loss: 1.0525
Batch 20, Loss: 1.0356
Batch 30, Loss: 0.9502
Batch 40, Loss: 1.0365
Batch 50, Loss: 1.0247
Batch 60, Loss: 1.0429
Batch 70, Loss: 1.0323
Batch 80, Loss: 1.1099
Batch 90, Loss: 1.0672
Batch 100, Loss: 1.0454
Batch 110, Loss: 1.0565
Batch 120, Loss: 1.0149
Batch 130, Loss: 1.0947
Batch 140, Loss: 1.0592
Batch 150, Loss: 1.0471
Batch 160, Loss: 1.0861
Batch 170, Loss: 1.0217
Batch 180, Loss: 1.0623
Batch 190, Loss: 1.0832
Batch 200, Loss: 1.0703
Batch 210, Loss: 1.0953
Batch 220, Loss: 1.0967
Batch 230, Loss: 1.1262
Batch 240, Loss: 1.1343
Batch 250, Loss: 1.0710
Batch 260, Loss: 1.1081
Batch 270, Loss: 1.1056
Batch 280, Loss: 1.0910
Batch 290, Loss: 1.1025
Batch 300, Loss: 1.1183
Batch 310, Loss: 1.1457
Batch 320, Loss: 1.1218
Batch 330, Loss: 1.1176
Batch 340, Loss: 1.1559
Batch 350, Loss: 1.0617
Batch 360, Loss: 1.1433
Batch 370, Loss: 1.1015
Batch 380, Loss: 1.1314
Batch 390, Loss: 1.1493
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.061506748199463 seconds
Epoch 24 accuracy: 57.45%
Batch 10, Loss: 1.0532
Batch 20, Loss: 0.9754
Batch 30, Loss: 0.9464
Batch 40, Loss: 1.0147
Batch 50, Loss: 1.0043
Batch 60, Loss: 1.0491
Batch 70, Loss: 1.0278
Batch 80, Loss: 1.0026
Batch 90, Loss: 1.0300
Batch 100, Loss: 1.0367
Batch 110, Loss: 1.0256
Batch 120, Loss: 1.0627
Batch 130, Loss: 1.0667
Batch 140, Loss: 1.0619
Batch 150, Loss: 1.1102
Batch 160, Loss: 1.0504
Batch 170, Loss: 1.0203
Batch 180, Loss: 1.0881
Batch 190, Loss: 1.1102
Batch 200, Loss: 1.0721
Batch 210, Loss: 1.1584
Batch 220, Loss: 1.1112
Batch 230, Loss: 1.1073
Batch 240, Loss: 1.1026
Batch 250, Loss: 1.0838
Batch 260, Loss: 1.0736
Batch 270, Loss: 1.0693
Batch 280, Loss: 1.0859
Batch 290, Loss: 1.0549
Batch 300, Loss: 1.0698
Batch 310, Loss: 1.1628
Batch 320, Loss: 1.0997
Batch 330, Loss: 1.0703
Batch 340, Loss: 1.1463
Batch 350, Loss: 1.1208
Batch 360, Loss: 1.1126
Batch 370, Loss: 1.1093
Batch 380, Loss: 1.1134
Batch 390, Loss: 1.1090
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.109714031219482 seconds
Epoch 25 accuracy: 60.38%
Batch 10, Loss: 1.0056
Batch 20, Loss: 1.0021
Batch 30, Loss: 1.0533
Batch 40, Loss: 0.9751
Batch 50, Loss: 1.0621
Batch 60, Loss: 1.0268
Batch 70, Loss: 1.0124
Batch 80, Loss: 1.0689
Batch 90, Loss: 1.0952
Batch 100, Loss: 1.0440
Batch 110, Loss: 1.0149
Batch 120, Loss: 1.0366
Batch 130, Loss: 1.1109
Batch 140, Loss: 1.0456
Batch 150, Loss: 1.0740
Batch 160, Loss: 1.0240
Batch 170, Loss: 1.0437
Batch 180, Loss: 1.0087
Batch 190, Loss: 1.0861
Batch 200, Loss: 1.0835
Batch 210, Loss: 1.0605
Batch 220, Loss: 1.0424
Batch 230, Loss: 1.1037
Batch 240, Loss: 1.0574
Batch 250, Loss: 1.1179
Batch 260, Loss: 1.0570
Batch 270, Loss: 1.1044
Batch 280, Loss: 1.1095
Batch 290, Loss: 1.0947
Batch 300, Loss: 1.0153
Batch 310, Loss: 1.0386
Batch 320, Loss: 1.0469
Batch 330, Loss: 1.0740
Batch 340, Loss: 1.1198
Batch 350, Loss: 1.1570
Batch 360, Loss: 1.1279
Batch 370, Loss: 1.1160
Batch 380, Loss: 1.0945
Batch 390, Loss: 1.0980
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.047470331192017 seconds
Epoch 26 accuracy: 59.47%
Batch 10, Loss: 1.0407
Batch 20, Loss: 1.0543
Batch 30, Loss: 0.9837
Batch 40, Loss: 0.9606
Batch 50, Loss: 0.9607
Batch 60, Loss: 1.0187
Batch 70, Loss: 1.0014
Batch 80, Loss: 1.0199
Batch 90, Loss: 1.0260
Batch 100, Loss: 1.0704
Batch 110, Loss: 1.0789
Batch 120, Loss: 1.0366
Batch 130, Loss: 1.0461
Batch 140, Loss: 1.0311
Batch 150, Loss: 1.0445
Batch 160, Loss: 1.0923
Batch 170, Loss: 1.0237
Batch 180, Loss: 1.0905
Batch 190, Loss: 1.0951
Batch 200, Loss: 1.0546
Batch 210, Loss: 1.0354
Batch 220, Loss: 1.0423
Batch 230, Loss: 1.0788
Batch 240, Loss: 1.0458
Batch 250, Loss: 1.0413
Batch 260, Loss: 1.0984
Batch 270, Loss: 1.0378
Batch 280, Loss: 1.1238
Batch 290, Loss: 1.0293
Batch 300, Loss: 1.0298
Batch 310, Loss: 1.0530
Batch 320, Loss: 1.0554
Batch 330, Loss: 1.0502
Batch 340, Loss: 1.0949
Batch 350, Loss: 1.1815
Batch 360, Loss: 1.0878
Batch 370, Loss: 1.0761
Batch 380, Loss: 1.1095
Batch 390, Loss: 1.1073
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.090665102005005 seconds
Epoch 27 accuracy: 57.43%
Batch 10, Loss: 0.9805
Batch 20, Loss: 0.9858
Batch 30, Loss: 1.0211
Batch 40, Loss: 1.0266
Batch 50, Loss: 1.0117
Batch 60, Loss: 1.0134
Batch 70, Loss: 0.9789
Batch 80, Loss: 0.9994
Batch 90, Loss: 1.0807
Batch 100, Loss: 1.0579
Batch 110, Loss: 1.0108
Batch 120, Loss: 1.0583
Batch 130, Loss: 1.0882
Batch 140, Loss: 1.0199
Batch 150, Loss: 0.9663
Batch 160, Loss: 1.0075
Batch 170, Loss: 1.0738
Batch 180, Loss: 1.0270
Batch 190, Loss: 1.0263
Batch 200, Loss: 0.9818
Batch 210, Loss: 1.0608
Batch 220, Loss: 1.0226
Batch 230, Loss: 1.0122
Batch 240, Loss: 1.0235
Batch 250, Loss: 1.0378
Batch 260, Loss: 1.0727
Batch 270, Loss: 1.0262
Batch 280, Loss: 1.0759
Batch 290, Loss: 1.0256
Batch 300, Loss: 1.0302
Batch 310, Loss: 1.0928
Batch 320, Loss: 1.1211
Batch 330, Loss: 1.0829
Batch 340, Loss: 1.1186
Batch 350, Loss: 1.0905
Batch 360, Loss: 1.0925
Batch 370, Loss: 1.1076
Batch 380, Loss: 1.0985
Batch 390, Loss: 1.0922
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.079483032226562 seconds
Epoch 28 accuracy: 58.46%
Batch 10, Loss: 0.9880
Batch 20, Loss: 0.9429
Batch 30, Loss: 0.9714
Batch 40, Loss: 0.9257
Batch 50, Loss: 0.9672
Batch 60, Loss: 0.9803
Batch 70, Loss: 1.0297
Batch 80, Loss: 1.0365
Batch 90, Loss: 1.0086
Batch 100, Loss: 1.0778
Batch 110, Loss: 0.9555
Batch 120, Loss: 1.0274
Batch 130, Loss: 0.9689
Batch 140, Loss: 0.9873
Batch 150, Loss: 0.9906
Batch 160, Loss: 0.9629
Batch 170, Loss: 1.0432
Batch 180, Loss: 1.0708
Batch 190, Loss: 1.0595
Batch 200, Loss: 1.0354
Batch 210, Loss: 1.0333
Batch 220, Loss: 1.0513
Batch 230, Loss: 1.0424
Batch 240, Loss: 0.9971
Batch 250, Loss: 1.1065
Batch 260, Loss: 1.0368
Batch 270, Loss: 1.0568
Batch 280, Loss: 1.0568
Batch 290, Loss: 1.0458
Batch 300, Loss: 1.0295
Batch 310, Loss: 1.1059
Batch 320, Loss: 1.0748
Batch 330, Loss: 1.1213
Batch 340, Loss: 1.1173
Batch 350, Loss: 1.0899
Batch 360, Loss: 1.0468
Batch 370, Loss: 1.0618
Batch 380, Loss: 1.0458
Batch 390, Loss: 1.0624
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.04789900779724 seconds
Epoch 29 accuracy: 56.82%
Batch 10, Loss: 0.9230
Batch 20, Loss: 0.9359
Batch 30, Loss: 0.9390
Batch 40, Loss: 0.9986
Batch 50, Loss: 0.9892
Batch 60, Loss: 0.9836
Batch 70, Loss: 1.0171
Batch 80, Loss: 1.0263
Batch 90, Loss: 0.9894
Batch 100, Loss: 1.0478
Batch 110, Loss: 1.0228
Batch 120, Loss: 1.0576
Batch 130, Loss: 0.9669
Batch 140, Loss: 1.0176
Batch 150, Loss: 1.0037
Batch 160, Loss: 0.9943
Batch 170, Loss: 1.0603
Batch 180, Loss: 1.0049
Batch 190, Loss: 1.0225
Batch 200, Loss: 1.0035
Batch 210, Loss: 1.0507
Batch 220, Loss: 1.0349
Batch 230, Loss: 1.0408
Batch 240, Loss: 1.0668
Batch 250, Loss: 1.0811
Batch 260, Loss: 1.0706
Batch 270, Loss: 1.1094
Batch 280, Loss: 1.0517
Batch 290, Loss: 1.0377
Batch 300, Loss: 1.0453
Batch 310, Loss: 1.0728
Batch 320, Loss: 1.0066
Batch 330, Loss: 1.1007
Batch 340, Loss: 1.1064
Batch 350, Loss: 1.0824
Batch 360, Loss: 1.0773
Batch 370, Loss: 1.1069
Batch 380, Loss: 1.0252
Batch 390, Loss: 1.0788
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.084137439727783 seconds
Epoch 30 accuracy: 58.21%
Batch 10, Loss: 0.9103
Batch 20, Loss: 0.9076
Batch 30, Loss: 0.8896
Batch 40, Loss: 0.9191
Batch 50, Loss: 0.9441
Batch 60, Loss: 0.9055
Batch 70, Loss: 0.9568
Batch 80, Loss: 0.9564
Batch 90, Loss: 1.0271
Batch 100, Loss: 1.0405
Batch 110, Loss: 0.9949
Batch 120, Loss: 0.9935
Batch 130, Loss: 0.9665
Batch 140, Loss: 0.9793
Batch 150, Loss: 1.0549
Batch 160, Loss: 1.0406
Batch 170, Loss: 1.1102
Batch 180, Loss: 1.0588
Batch 190, Loss: 1.0594
Batch 200, Loss: 1.0349
Batch 210, Loss: 1.0828
Batch 220, Loss: 1.0177
Batch 230, Loss: 1.0407
Batch 240, Loss: 1.0635
Batch 250, Loss: 0.9930
Batch 260, Loss: 1.0741
Batch 270, Loss: 1.1108
Batch 280, Loss: 1.0692
Batch 290, Loss: 1.0305
Batch 300, Loss: 1.0447
Batch 310, Loss: 1.0453
Batch 320, Loss: 1.1079
Batch 330, Loss: 1.0335
Batch 340, Loss: 0.9860
Batch 350, Loss: 1.0182
Batch 360, Loss: 1.0368
Batch 370, Loss: 1.0843
Batch 380, Loss: 1.0688
Batch 390, Loss: 1.0389
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.082430124282837 seconds
Epoch 31 accuracy: 58.03%
Batch 10, Loss: 1.0019
Batch 20, Loss: 0.9647
Batch 30, Loss: 0.9828
Batch 40, Loss: 0.9304
Batch 50, Loss: 0.8960
Batch 60, Loss: 0.9316
Batch 70, Loss: 0.9685
Batch 80, Loss: 1.0047
Batch 90, Loss: 0.9740
Batch 100, Loss: 0.9425
Batch 110, Loss: 0.9611
Batch 120, Loss: 1.0543
Batch 130, Loss: 1.0081
Batch 140, Loss: 0.9699
Batch 150, Loss: 1.0979
Batch 160, Loss: 1.0127
Batch 170, Loss: 1.0783
Batch 180, Loss: 0.9883
Batch 190, Loss: 0.9881
Batch 200, Loss: 1.0221
Batch 210, Loss: 1.0511
Batch 220, Loss: 1.0787
Batch 230, Loss: 1.0219
Batch 240, Loss: 1.0191
Batch 250, Loss: 1.1178
Batch 260, Loss: 1.0782
Batch 270, Loss: 1.0883
Batch 280, Loss: 1.0013
Batch 290, Loss: 1.0493
Batch 300, Loss: 1.0049
Batch 310, Loss: 1.0682
Batch 320, Loss: 1.0403
Batch 330, Loss: 1.0319
Batch 340, Loss: 1.0354
Batch 350, Loss: 1.0272
Batch 360, Loss: 1.0298
Batch 370, Loss: 1.0124
Batch 380, Loss: 1.0185
Batch 390, Loss: 1.0330
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.12276840209961 seconds
Epoch 32 accuracy: 59.96%
Batch 10, Loss: 0.9505
Batch 20, Loss: 0.9539
Batch 30, Loss: 0.9357
Batch 40, Loss: 0.9304
Batch 50, Loss: 0.9518
Batch 60, Loss: 0.9014
Batch 70, Loss: 0.9598
Batch 80, Loss: 0.9674
Batch 90, Loss: 0.9141
Batch 100, Loss: 1.0169
Batch 110, Loss: 1.0164
Batch 120, Loss: 0.9783
Batch 130, Loss: 1.0345
Batch 140, Loss: 0.9711
Batch 150, Loss: 1.0155
Batch 160, Loss: 1.0336
Batch 170, Loss: 1.0418
Batch 180, Loss: 1.0134
Batch 190, Loss: 0.9973
Batch 200, Loss: 1.0319
Batch 210, Loss: 1.0173
Batch 220, Loss: 1.0558
Batch 230, Loss: 1.0133
Batch 240, Loss: 1.0383
Batch 250, Loss: 1.0321
Batch 260, Loss: 0.9664
Batch 270, Loss: 1.0145
Batch 280, Loss: 0.9922
Batch 290, Loss: 1.0418
Batch 300, Loss: 0.9798
Batch 310, Loss: 1.0518
Batch 320, Loss: 1.0816
Batch 330, Loss: 1.0049
Batch 340, Loss: 1.0768
Batch 350, Loss: 1.0366
Batch 360, Loss: 1.0612
Batch 370, Loss: 1.0335
Batch 380, Loss: 0.9658
Batch 390, Loss: 1.0022
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.11211133003235 seconds
Epoch 33 accuracy: 56.63%
Batch 10, Loss: 0.9216
Batch 20, Loss: 0.9605
Batch 30, Loss: 0.9718
Batch 40, Loss: 0.9608
Batch 50, Loss: 0.9429
Batch 60, Loss: 0.9221
Batch 70, Loss: 0.8842
Batch 80, Loss: 0.8835
Batch 90, Loss: 0.8889
Batch 100, Loss: 0.9330
Batch 110, Loss: 0.9106
Batch 120, Loss: 0.9509
Batch 130, Loss: 1.0300
Batch 140, Loss: 1.0145
Batch 150, Loss: 1.0125
Batch 160, Loss: 0.9708
Batch 170, Loss: 1.0170
Batch 180, Loss: 0.9943
Batch 190, Loss: 1.0612
Batch 200, Loss: 1.0308
Batch 210, Loss: 0.9816
Batch 220, Loss: 1.0331
Batch 230, Loss: 0.9763
Batch 240, Loss: 1.0576
Batch 250, Loss: 1.0632
Batch 260, Loss: 1.0544
Batch 270, Loss: 1.0515
Batch 280, Loss: 1.0225
Batch 290, Loss: 1.0466
Batch 300, Loss: 1.0318
Batch 310, Loss: 0.9850
Batch 320, Loss: 1.0677
Batch 330, Loss: 1.0581
Batch 340, Loss: 1.0067
Batch 350, Loss: 1.0876
Batch 360, Loss: 1.0576
Batch 370, Loss: 1.0604
Batch 380, Loss: 1.0334
Batch 390, Loss: 1.0265
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.053558826446533 seconds
Epoch 34 accuracy: 60.17%
Batch 10, Loss: 0.9728
Batch 20, Loss: 0.9650
Batch 30, Loss: 0.8986
Batch 40, Loss: 0.9403
Batch 50, Loss: 0.9498
Batch 60, Loss: 0.9740
Batch 70, Loss: 0.9033
Batch 80, Loss: 0.9447
Batch 90, Loss: 0.9755
Batch 100, Loss: 0.9830
Batch 110, Loss: 0.9415
Batch 120, Loss: 0.9936
Batch 130, Loss: 1.0042
Batch 140, Loss: 1.0086
Batch 150, Loss: 1.0058
Batch 160, Loss: 0.9993
Batch 170, Loss: 0.9565
Batch 180, Loss: 1.0773
Batch 190, Loss: 0.9626
Batch 200, Loss: 0.9725
Batch 210, Loss: 0.9535
Batch 220, Loss: 1.0364
Batch 230, Loss: 1.0257
Batch 240, Loss: 1.0240
Batch 250, Loss: 1.0022
Batch 260, Loss: 0.9679
Batch 270, Loss: 1.0276
Batch 280, Loss: 0.9834
Batch 290, Loss: 1.0344
Batch 300, Loss: 1.0046
Batch 310, Loss: 1.0191
Batch 320, Loss: 1.0038
Batch 330, Loss: 0.9994
Batch 340, Loss: 1.0242
Batch 350, Loss: 1.0513
Batch 360, Loss: 1.0496
Batch 370, Loss: 1.0356
Batch 380, Loss: 1.0069
Batch 390, Loss: 1.0598
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.093854904174805 seconds
Epoch 35 accuracy: 60.08%
Batch 10, Loss: 0.8497
Batch 20, Loss: 0.8883
Batch 30, Loss: 0.9206
Batch 40, Loss: 0.9109
Batch 50, Loss: 0.9074
Batch 60, Loss: 0.9415
Batch 70, Loss: 0.9479
Batch 80, Loss: 0.9239
Batch 90, Loss: 0.9513
Batch 100, Loss: 0.9388
Batch 110, Loss: 0.9340
Batch 120, Loss: 0.8960
Batch 130, Loss: 0.9375
Batch 140, Loss: 0.9383
Batch 150, Loss: 0.9797
Batch 160, Loss: 0.9974
Batch 170, Loss: 0.9714
Batch 180, Loss: 1.0090
Batch 190, Loss: 1.0418
Batch 200, Loss: 1.0253
Batch 210, Loss: 1.0396
Batch 220, Loss: 1.0015
Batch 230, Loss: 1.0298
Batch 240, Loss: 1.0481
Batch 250, Loss: 0.9971
Batch 260, Loss: 0.9687
Batch 270, Loss: 1.0412
Batch 280, Loss: 0.9973
Batch 290, Loss: 0.9702
Batch 300, Loss: 0.9933
Batch 310, Loss: 0.9776
Batch 320, Loss: 0.9993
Batch 330, Loss: 1.0007
Batch 340, Loss: 1.0532
Batch 350, Loss: 1.0783
Batch 360, Loss: 1.0349
Batch 370, Loss: 1.0187
Batch 380, Loss: 1.0468
Batch 390, Loss: 1.0365
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.051185369491577 seconds
Epoch 36 accuracy: 59.72%
Batch 10, Loss: 0.8840
Batch 20, Loss: 0.9631
Batch 30, Loss: 0.9600
Batch 40, Loss: 0.9128
Batch 50, Loss: 0.9364
Batch 60, Loss: 0.9245
Batch 70, Loss: 0.8763
Batch 80, Loss: 0.8726
Batch 90, Loss: 0.9154
Batch 100, Loss: 0.9793
Batch 110, Loss: 1.0180
Batch 120, Loss: 0.9574
Batch 130, Loss: 1.0002
Batch 140, Loss: 0.9704
Batch 150, Loss: 0.9630
Batch 160, Loss: 0.9387
Batch 170, Loss: 0.9430
Batch 180, Loss: 0.9484
Batch 190, Loss: 1.0001
Batch 200, Loss: 1.0149
Batch 210, Loss: 0.9883
Batch 220, Loss: 1.0269
Batch 230, Loss: 1.0469
Batch 240, Loss: 1.0244
Batch 250, Loss: 0.9768
Batch 260, Loss: 1.0032
Batch 270, Loss: 1.0141
Batch 280, Loss: 1.0051
Batch 290, Loss: 1.0392
Batch 300, Loss: 0.9761
Batch 310, Loss: 1.0137
Batch 320, Loss: 1.0653
Batch 330, Loss: 1.0090
Batch 340, Loss: 0.9751
Batch 350, Loss: 0.9919
Batch 360, Loss: 0.9903
Batch 370, Loss: 0.9655
Batch 380, Loss: 1.0121
Batch 390, Loss: 0.9765
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.052278995513916 seconds
Epoch 37 accuracy: 59.96%
Batch 10, Loss: 0.9386
Batch 20, Loss: 0.9207
Batch 30, Loss: 0.8862
Batch 40, Loss: 0.9580
Batch 50, Loss: 0.9545
Batch 60, Loss: 0.8643
Batch 70, Loss: 0.9050
Batch 80, Loss: 1.0084
Batch 90, Loss: 0.9082
Batch 100, Loss: 0.9585
Batch 110, Loss: 0.9415
Batch 120, Loss: 0.9242
Batch 130, Loss: 0.9337
Batch 140, Loss: 0.9528
Batch 150, Loss: 1.0209
Batch 160, Loss: 1.0185
Batch 170, Loss: 1.0128
Batch 180, Loss: 0.9970
Batch 190, Loss: 1.0109
Batch 200, Loss: 0.9396
Batch 210, Loss: 0.9792
Batch 220, Loss: 1.0162
Batch 230, Loss: 0.9750
Batch 240, Loss: 1.0105
Batch 250, Loss: 1.0010
Batch 260, Loss: 0.9678
Batch 270, Loss: 0.9557
Batch 280, Loss: 0.9447
Batch 290, Loss: 0.9563
Batch 300, Loss: 1.0021
Batch 310, Loss: 0.9337
Batch 320, Loss: 1.0600
Batch 330, Loss: 1.0299
Batch 340, Loss: 0.9756
Batch 350, Loss: 0.9949
Batch 360, Loss: 1.0099
Batch 370, Loss: 1.0441
Batch 380, Loss: 1.0294
Batch 390, Loss: 0.9404
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.07923412322998 seconds
Epoch 38 accuracy: 59.31%
Batch 10, Loss: 0.8513
Batch 20, Loss: 0.8787
Batch 30, Loss: 0.8898
Batch 40, Loss: 0.9289
Batch 50, Loss: 0.8912
Batch 60, Loss: 0.9570
Batch 70, Loss: 0.9030
Batch 80, Loss: 0.9908
Batch 90, Loss: 0.9438
Batch 100, Loss: 0.9590
Batch 110, Loss: 0.9645
Batch 120, Loss: 0.9091
Batch 130, Loss: 0.9834
Batch 140, Loss: 1.0086
Batch 150, Loss: 0.9648
Batch 160, Loss: 1.0438
Batch 170, Loss: 0.9971
Batch 180, Loss: 0.9665
Batch 190, Loss: 0.9708
Batch 200, Loss: 0.9832
Batch 210, Loss: 0.9070
Batch 220, Loss: 0.9268
Batch 230, Loss: 0.9342
Batch 240, Loss: 0.9338
Batch 250, Loss: 0.9809
Batch 260, Loss: 0.9718
Batch 270, Loss: 0.9807
Batch 280, Loss: 0.9895
Batch 290, Loss: 0.9688
Batch 300, Loss: 0.9801
Batch 310, Loss: 0.9921
Batch 320, Loss: 0.9806
Batch 330, Loss: 0.9962
Batch 340, Loss: 0.9792
Batch 350, Loss: 0.9869
Batch 360, Loss: 1.0333
Batch 370, Loss: 1.0063
Batch 380, Loss: 1.0025
Batch 390, Loss: 1.0225
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.03994393348694 seconds
Epoch 39 accuracy: 58.37%
Batch 10, Loss: 0.9045
Batch 20, Loss: 0.9025
Batch 30, Loss: 0.9585
Batch 40, Loss: 0.8699
Batch 50, Loss: 0.9049
Batch 60, Loss: 0.9474
Batch 70, Loss: 0.9296
Batch 80, Loss: 0.8395
Batch 90, Loss: 0.8882
Batch 100, Loss: 0.9559
Batch 110, Loss: 0.8677
Batch 120, Loss: 0.9155
Batch 130, Loss: 0.9382
Batch 140, Loss: 0.9570
Batch 150, Loss: 0.9963
Batch 160, Loss: 1.0019
Batch 170, Loss: 0.9793
Batch 180, Loss: 0.9719
Batch 190, Loss: 0.9829
Batch 200, Loss: 0.9840
Batch 210, Loss: 0.9863
Batch 220, Loss: 1.0191
Batch 230, Loss: 0.9273
Batch 240, Loss: 0.9571
Batch 250, Loss: 0.9560
Batch 260, Loss: 1.0060
Batch 270, Loss: 1.0163
Batch 280, Loss: 0.9894
Batch 290, Loss: 0.9506
Batch 300, Loss: 0.9714
Batch 310, Loss: 1.0298
Batch 320, Loss: 1.0013
Batch 330, Loss: 0.9742
Batch 340, Loss: 0.9062
Batch 350, Loss: 0.9841
Batch 360, Loss: 1.0032
Batch 370, Loss: 1.0440
Batch 380, Loss: 1.0365
Batch 390, Loss: 1.0066
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.043028116226196 seconds
Epoch 40 accuracy: 58.75%
Batch 10, Loss: 0.9523
Batch 20, Loss: 0.9105
Batch 30, Loss: 0.8908
Batch 40, Loss: 0.8885
Batch 50, Loss: 0.9178
Batch 60, Loss: 0.8681
Batch 70, Loss: 0.9189
Batch 80, Loss: 0.9463
Batch 90, Loss: 0.9289
Batch 100, Loss: 0.9198
Batch 110, Loss: 0.9735
Batch 120, Loss: 0.9403
Batch 130, Loss: 1.0168
Batch 140, Loss: 0.9827
Batch 150, Loss: 0.8947
Batch 160, Loss: 0.9497
Batch 170, Loss: 0.9403
Batch 180, Loss: 0.9661
Batch 190, Loss: 0.9565
Batch 200, Loss: 0.9517
Batch 210, Loss: 0.9754
Batch 220, Loss: 0.9439
Batch 230, Loss: 0.9670
Batch 240, Loss: 0.9731
Batch 250, Loss: 0.9684
Batch 260, Loss: 0.9913
Batch 270, Loss: 0.9477
Batch 280, Loss: 0.9951
Batch 290, Loss: 0.9282
Batch 300, Loss: 0.9777
Batch 310, Loss: 0.9068
Batch 320, Loss: 1.0396
Batch 330, Loss: 0.9848
Batch 340, Loss: 1.0179
Batch 350, Loss: 0.9998
Batch 360, Loss: 0.9976
Batch 370, Loss: 0.9616
Batch 380, Loss: 0.9671
Batch 390, Loss: 1.0425
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.04147434234619 seconds
Epoch 41 accuracy: 57.86%
Batch 10, Loss: 0.9183
Batch 20, Loss: 0.8363
Batch 30, Loss: 0.8868
Batch 40, Loss: 0.8551
Batch 50, Loss: 0.8555
Batch 60, Loss: 0.8967
Batch 70, Loss: 0.9617
Batch 80, Loss: 0.9101
Batch 90, Loss: 0.8665
Batch 100, Loss: 0.9409
Batch 110, Loss: 0.9492
Batch 120, Loss: 0.9195
Batch 130, Loss: 0.8673
Batch 140, Loss: 0.8891
Batch 150, Loss: 0.9590
Batch 160, Loss: 0.9046
Batch 170, Loss: 0.9997
Batch 180, Loss: 0.9845
Batch 190, Loss: 0.9585
Batch 200, Loss: 0.9335
Batch 210, Loss: 0.9811
Batch 220, Loss: 0.9666
Batch 230, Loss: 0.9775
Batch 240, Loss: 0.9911
Batch 250, Loss: 0.9900
Batch 260, Loss: 1.0014
Batch 270, Loss: 0.9568
Batch 280, Loss: 1.0043
Batch 290, Loss: 1.0173
Batch 300, Loss: 1.0242
Batch 310, Loss: 0.9631
Batch 320, Loss: 0.9338
Batch 330, Loss: 0.9692
Batch 340, Loss: 1.0118
Batch 350, Loss: 1.0518
Batch 360, Loss: 0.9575
Batch 370, Loss: 0.9944
Batch 380, Loss: 0.9651
Batch 390, Loss: 1.0360
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.0239315032959 seconds
Epoch 42 accuracy: 58.05%
Batch 10, Loss: 0.8952
Batch 20, Loss: 0.8721
Batch 30, Loss: 0.8925
Batch 40, Loss: 0.8946
Batch 50, Loss: 0.9055
Batch 60, Loss: 0.8977
Batch 70, Loss: 0.9256
Batch 80, Loss: 0.8989
Batch 90, Loss: 0.9330
Batch 100, Loss: 0.9150
Batch 110, Loss: 0.8822
Batch 120, Loss: 0.9035
Batch 130, Loss: 0.9439
Batch 140, Loss: 0.9221
Batch 150, Loss: 0.8609
Batch 160, Loss: 0.9488
Batch 170, Loss: 0.9418
Batch 180, Loss: 0.9446
Batch 190, Loss: 0.8943
Batch 200, Loss: 0.9602
Batch 210, Loss: 0.9408
Batch 220, Loss: 0.9762
Batch 230, Loss: 0.9600
Batch 240, Loss: 0.9910
Batch 250, Loss: 0.9836
Batch 260, Loss: 0.9150
Batch 270, Loss: 0.9839
Batch 280, Loss: 0.9740
Batch 290, Loss: 0.9985
Batch 300, Loss: 0.9770
Batch 310, Loss: 1.0308
Batch 320, Loss: 0.9863
Batch 330, Loss: 1.0197
Batch 340, Loss: 0.9479
Batch 350, Loss: 0.9806
Batch 360, Loss: 0.9774
Batch 370, Loss: 0.9589
Batch 380, Loss: 0.9452
Batch 390, Loss: 0.9793
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.07564663887024 seconds
Epoch 43 accuracy: 61.01%
Batch 10, Loss: 0.8423
Batch 20, Loss: 0.8645
Batch 30, Loss: 0.8516
Batch 40, Loss: 0.8462
Batch 50, Loss: 0.8062
Batch 60, Loss: 0.8862
Batch 70, Loss: 0.8963
Batch 80, Loss: 0.9169
Batch 90, Loss: 0.8658
Batch 100, Loss: 0.8893
Batch 110, Loss: 0.9664
Batch 120, Loss: 0.9533
Batch 130, Loss: 0.9266
Batch 140, Loss: 0.8997
Batch 150, Loss: 0.9563
Batch 160, Loss: 0.8544
Batch 170, Loss: 0.8920
Batch 180, Loss: 0.9282
Batch 190, Loss: 0.8864
Batch 200, Loss: 0.9429
Batch 210, Loss: 0.9769
Batch 220, Loss: 0.9470
Batch 230, Loss: 0.9380
Batch 240, Loss: 0.9282
Batch 250, Loss: 0.8960
Batch 260, Loss: 0.9360
Batch 270, Loss: 0.9630
Batch 280, Loss: 0.9641
Batch 290, Loss: 0.9977
Batch 300, Loss: 0.9840
Batch 310, Loss: 1.0156
Batch 320, Loss: 0.9685
Batch 330, Loss: 1.0182
Batch 340, Loss: 1.0061
Batch 350, Loss: 0.9680
Batch 360, Loss: 0.9294
Batch 370, Loss: 1.0470
Batch 380, Loss: 0.9151
Batch 390, Loss: 0.9783
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.123953580856323 seconds
Epoch 44 accuracy: 61.19%
Batch 10, Loss: 0.9144
Batch 20, Loss: 0.8884
Batch 30, Loss: 0.8805
Batch 40, Loss: 0.8836
Batch 50, Loss: 0.8855
Batch 60, Loss: 0.8155
Batch 70, Loss: 0.8419
Batch 80, Loss: 0.9100
Batch 90, Loss: 0.9869
Batch 100, Loss: 0.9380
Batch 110, Loss: 0.9296
Batch 120, Loss: 0.9308
Batch 130, Loss: 0.9605
Batch 140, Loss: 0.9572
Batch 150, Loss: 0.9399
Batch 160, Loss: 0.9049
Batch 170, Loss: 0.8513
Batch 180, Loss: 0.9545
Batch 190, Loss: 0.9290
Batch 200, Loss: 0.9510
Batch 210, Loss: 0.9582
Batch 220, Loss: 0.9508
Batch 230, Loss: 0.9388
Batch 240, Loss: 0.9590
Batch 250, Loss: 0.9012
Batch 260, Loss: 0.9662
Batch 270, Loss: 0.9497
Batch 280, Loss: 1.0033
Batch 290, Loss: 1.0131
Batch 300, Loss: 0.9290
Batch 310, Loss: 0.9644
Batch 320, Loss: 1.0073
Batch 330, Loss: 1.0161
Batch 340, Loss: 0.9395
Batch 350, Loss: 0.9169
Batch 360, Loss: 0.9774
Batch 370, Loss: 1.0118
Batch 380, Loss: 0.9381
Batch 390, Loss: 0.9774
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.047411680221558 seconds
Epoch 45 accuracy: 59.27%
Batch 10, Loss: 0.8659
Batch 20, Loss: 0.8438
Batch 30, Loss: 0.8541
Batch 40, Loss: 0.8744
Batch 50, Loss: 0.8834
Batch 60, Loss: 0.9578
Batch 70, Loss: 0.8793
Batch 80, Loss: 0.9171
Batch 90, Loss: 0.9119
Batch 100, Loss: 0.9059
Batch 110, Loss: 0.8734
Batch 120, Loss: 0.8560
Batch 130, Loss: 0.8274
Batch 140, Loss: 0.8708
Batch 150, Loss: 0.9046
Batch 160, Loss: 0.8973
Batch 170, Loss: 0.9402
Batch 180, Loss: 0.9362
Batch 190, Loss: 0.9387
Batch 200, Loss: 0.9423
Batch 210, Loss: 0.9361
Batch 220, Loss: 0.9258
Batch 230, Loss: 0.9581
Batch 240, Loss: 0.9395
Batch 250, Loss: 0.9291
Batch 260, Loss: 0.9897
Batch 270, Loss: 0.9431
Batch 280, Loss: 0.8986
Batch 290, Loss: 0.9563
Batch 300, Loss: 0.9583
Batch 310, Loss: 0.9448
Batch 320, Loss: 0.9513
Batch 330, Loss: 0.9489
Batch 340, Loss: 1.0116
Batch 350, Loss: 0.9611
Batch 360, Loss: 0.9257
Batch 370, Loss: 0.9567
Batch 380, Loss: 0.9969
Batch 390, Loss: 0.9697
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.083210468292236 seconds
Epoch 46 accuracy: 59.47%
Batch 10, Loss: 0.8545
Batch 20, Loss: 0.8590
Batch 30, Loss: 0.8299
Batch 40, Loss: 0.8470
Batch 50, Loss: 0.8724
Batch 60, Loss: 0.8613
Batch 70, Loss: 0.9038
Batch 80, Loss: 0.9123
Batch 90, Loss: 0.8273
Batch 100, Loss: 0.9018
Batch 110, Loss: 0.8550
Batch 120, Loss: 0.9194
Batch 130, Loss: 0.8953
Batch 140, Loss: 0.9073
Batch 150, Loss: 0.9088
Batch 160, Loss: 0.9116
Batch 170, Loss: 0.9248
Batch 180, Loss: 0.8806
Batch 190, Loss: 0.9265
Batch 200, Loss: 0.9202
Batch 210, Loss: 0.9275
Batch 220, Loss: 0.9308
Batch 230, Loss: 0.9682
Batch 240, Loss: 0.9644
Batch 250, Loss: 0.9283
Batch 260, Loss: 0.9131
Batch 270, Loss: 0.9401
Batch 280, Loss: 0.9508
Batch 290, Loss: 0.8972
Batch 300, Loss: 0.9195
Batch 310, Loss: 0.8965
Batch 320, Loss: 0.9643
Batch 330, Loss: 1.0065
Batch 340, Loss: 1.0199
Batch 350, Loss: 0.9677
Batch 360, Loss: 0.9551
Batch 370, Loss: 0.9247
Batch 380, Loss: 1.0106
Batch 390, Loss: 0.9708
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.08247470855713 seconds
Epoch 47 accuracy: 59.0%
Batch 10, Loss: 0.8808
Batch 20, Loss: 0.8650
Batch 30, Loss: 0.8909
Batch 40, Loss: 0.8862
Batch 50, Loss: 0.8402
Batch 60, Loss: 0.8383
Batch 70, Loss: 0.9002
Batch 80, Loss: 0.8479
Batch 90, Loss: 0.8763
Batch 100, Loss: 0.8763
Batch 110, Loss: 0.9360
Batch 120, Loss: 0.8806
Batch 130, Loss: 0.9084
Batch 140, Loss: 0.9176
Batch 150, Loss: 0.8792
Batch 160, Loss: 0.9252
Batch 170, Loss: 0.9247
Batch 180, Loss: 0.9418
Batch 190, Loss: 0.9444
Batch 200, Loss: 0.9215
Batch 210, Loss: 0.8821
Batch 220, Loss: 0.9227
Batch 230, Loss: 0.9513
Batch 240, Loss: 0.9218
Batch 250, Loss: 0.9318
Batch 260, Loss: 0.9461
Batch 270, Loss: 0.9111
Batch 280, Loss: 0.9398
Batch 290, Loss: 0.9563
Batch 300, Loss: 0.9650
Batch 310, Loss: 0.8970
Batch 320, Loss: 0.9661
Batch 330, Loss: 0.9178
Batch 340, Loss: 0.9079
Batch 350, Loss: 0.9776
Batch 360, Loss: 0.9641
Batch 370, Loss: 0.9595
Batch 380, Loss: 1.0044
Batch 390, Loss: 0.9582
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.068480253219604 seconds
Epoch 48 accuracy: 58.13%
Batch 10, Loss: 0.8221
Batch 20, Loss: 0.8831
Batch 30, Loss: 0.8306
Batch 40, Loss: 0.8662
Batch 50, Loss: 0.8663
Batch 60, Loss: 0.8862
Batch 70, Loss: 0.9218
Batch 80, Loss: 0.8823
Batch 90, Loss: 0.8691
Batch 100, Loss: 0.8741
Batch 110, Loss: 0.9179
Batch 120, Loss: 0.8984
Batch 130, Loss: 0.9147
Batch 140, Loss: 0.9223
Batch 150, Loss: 0.8572
Batch 160, Loss: 0.8621
Batch 170, Loss: 0.9093
Batch 180, Loss: 0.9272
Batch 190, Loss: 0.9524
Batch 200, Loss: 0.8665
Batch 210, Loss: 0.9137
Batch 220, Loss: 0.9562
Batch 230, Loss: 0.8845
Batch 240, Loss: 0.9231
Batch 250, Loss: 0.9488
Batch 260, Loss: 0.9001
Batch 270, Loss: 0.9681
Batch 280, Loss: 0.9031
Batch 290, Loss: 0.9351
Batch 300, Loss: 0.9331
Batch 310, Loss: 0.9256
Batch 320, Loss: 0.9121
Batch 330, Loss: 0.9432
Batch 340, Loss: 0.9783
Batch 350, Loss: 0.9501
Batch 360, Loss: 0.9767
Batch 370, Loss: 0.9498
Batch 380, Loss: 0.9502
Batch 390, Loss: 0.9831
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.106518268585205 seconds
Epoch 49 accuracy: 58.7%
Batch 10, Loss: 0.8221
Batch 20, Loss: 0.8307
Batch 30, Loss: 0.8292
Batch 40, Loss: 0.7896
Batch 50, Loss: 0.8285
Batch 60, Loss: 0.8099
Batch 70, Loss: 0.7738
Batch 80, Loss: 0.8577
Batch 90, Loss: 0.8564
Batch 100, Loss: 0.8979
Batch 110, Loss: 0.8768
Batch 120, Loss: 0.9028
Batch 130, Loss: 0.9130
Batch 140, Loss: 0.9189
Batch 150, Loss: 0.8535
Batch 160, Loss: 0.8649
Batch 170, Loss: 0.9116
Batch 180, Loss: 0.8607
Batch 190, Loss: 0.8993
Batch 200, Loss: 0.9005
Batch 210, Loss: 0.9458
Batch 220, Loss: 0.8541
Batch 230, Loss: 0.9435
Batch 240, Loss: 0.9140
Batch 250, Loss: 0.9176
Batch 260, Loss: 0.8887
Batch 270, Loss: 0.9584
Batch 280, Loss: 0.8942
Batch 290, Loss: 0.9721
Batch 300, Loss: 0.9924
Batch 310, Loss: 0.9675
Batch 320, Loss: 1.0116
Batch 330, Loss: 0.9529
Batch 340, Loss: 0.9709
Batch 350, Loss: 0.9008
Batch 360, Loss: 0.9376
Batch 370, Loss: 0.9671
Batch 380, Loss: 0.9660
Batch 390, Loss: 0.9456
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.061546802520752 seconds
Epoch 50 accuracy: 58.47%
Batch 10, Loss: 0.8304
Batch 20, Loss: 0.8159
Batch 30, Loss: 0.8559
Batch 40, Loss: 0.8414
Batch 50, Loss: 0.8633
Batch 60, Loss: 0.7905
Batch 70, Loss: 0.8719
Batch 80, Loss: 0.8641
Batch 90, Loss: 0.8890
Batch 100, Loss: 0.8730
Batch 110, Loss: 0.9398
Batch 120, Loss: 0.8645
Batch 130, Loss: 0.8416
Batch 140, Loss: 0.9473
Batch 150, Loss: 0.8981
Batch 160, Loss: 0.8667
Batch 170, Loss: 0.9014
Batch 180, Loss: 0.9346
Batch 190, Loss: 0.8728
Batch 200, Loss: 0.8952
Batch 210, Loss: 0.9245
Batch 220, Loss: 0.9021
Batch 230, Loss: 0.9058
Batch 240, Loss: 0.8371
Batch 250, Loss: 0.9229
Batch 260, Loss: 0.9105
Batch 270, Loss: 0.8838
Batch 280, Loss: 0.9356
Batch 290, Loss: 0.8906
Batch 300, Loss: 0.9494
Batch 310, Loss: 0.9074
Batch 320, Loss: 0.9435
Batch 330, Loss: 0.9263
Batch 340, Loss: 1.0026
Batch 350, Loss: 0.9383
Batch 360, Loss: 0.8730
Batch 370, Loss: 0.9129
Batch 380, Loss: 0.9334
Batch 390, Loss: 0.9285
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.065196752548218 seconds
Epoch 51 accuracy: 61.46%
Batch 10, Loss: 0.8191
Batch 20, Loss: 0.8353
Batch 30, Loss: 0.8152
Batch 40, Loss: 0.8303
Batch 50, Loss: 0.7571
Batch 60, Loss: 0.8681
Batch 70, Loss: 0.8519
Batch 80, Loss: 0.8332
Batch 90, Loss: 0.8361
Batch 100, Loss: 0.8819
Batch 110, Loss: 0.8953
Batch 120, Loss: 0.8389
Batch 130, Loss: 0.9097
Batch 140, Loss: 0.8514
Batch 150, Loss: 0.8950
Batch 160, Loss: 0.8343
Batch 170, Loss: 0.8712
Batch 180, Loss: 0.9264
Batch 190, Loss: 0.8819
Batch 200, Loss: 0.8847
Batch 210, Loss: 0.9017
Batch 220, Loss: 0.8596
Batch 230, Loss: 0.8966
Batch 240, Loss: 0.9023
Batch 250, Loss: 0.8988
Batch 260, Loss: 0.8810
Batch 270, Loss: 0.9453
Batch 280, Loss: 0.9161
Batch 290, Loss: 0.9161
Batch 300, Loss: 0.9381
Batch 310, Loss: 0.9135
Batch 320, Loss: 0.8919
Batch 330, Loss: 0.9316
Batch 340, Loss: 0.9194
Batch 350, Loss: 0.9203
Batch 360, Loss: 0.9889
Batch 370, Loss: 0.9595
Batch 380, Loss: 0.9714
Batch 390, Loss: 0.9469
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.027279138565063 seconds
Epoch 52 accuracy: 62.55%
Batch 10, Loss: 0.8708
Batch 20, Loss: 0.8236
Batch 30, Loss: 0.8141
Batch 40, Loss: 0.7922
Batch 50, Loss: 0.7990
Batch 60, Loss: 0.8735
Batch 70, Loss: 0.8140
Batch 80, Loss: 0.8343
Batch 90, Loss: 0.8821
Batch 100, Loss: 0.8853
Batch 110, Loss: 0.7615
Batch 120, Loss: 0.8380
Batch 130, Loss: 0.8837
Batch 140, Loss: 0.9220
Batch 150, Loss: 0.8724
Batch 160, Loss: 0.8977
Batch 170, Loss: 0.9160
Batch 180, Loss: 0.9084
Batch 190, Loss: 0.8868
Batch 200, Loss: 0.8728
Batch 210, Loss: 0.9124
Batch 220, Loss: 0.9336
Batch 230, Loss: 0.8544
Batch 240, Loss: 0.9729
Batch 250, Loss: 0.9139
Batch 260, Loss: 0.9115
Batch 270, Loss: 0.9119
Batch 280, Loss: 0.8962
Batch 290, Loss: 0.9401
Batch 300, Loss: 0.9252
Batch 310, Loss: 0.9127
Batch 320, Loss: 0.9409
Batch 330, Loss: 0.9362
Batch 340, Loss: 0.9163
Batch 350, Loss: 0.9455
Batch 360, Loss: 0.8879
Batch 370, Loss: 0.9567
Batch 380, Loss: 0.9486
Batch 390, Loss: 0.9149
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.091490268707275 seconds
Epoch 53 accuracy: 60.28%
Batch 10, Loss: 0.8449
Batch 20, Loss: 0.8623
Batch 30, Loss: 0.8458
Batch 40, Loss: 0.8312
Batch 50, Loss: 0.8161
Batch 60, Loss: 0.8204
Batch 70, Loss: 0.8645
Batch 80, Loss: 0.8676
Batch 90, Loss: 0.8740
Batch 100, Loss: 0.7994
Batch 110, Loss: 0.8574
Batch 120, Loss: 0.8375
Batch 130, Loss: 0.8977
Batch 140, Loss: 0.8625
Batch 150, Loss: 0.9407
Batch 160, Loss: 0.8768
Batch 170, Loss: 0.9038
Batch 180, Loss: 0.9141
Batch 190, Loss: 0.8421
Batch 200, Loss: 0.8527
Batch 210, Loss: 0.8890
Batch 220, Loss: 0.9339
Batch 230, Loss: 0.9099
Batch 240, Loss: 0.9822
Batch 250, Loss: 0.8917
Batch 260, Loss: 0.9312
Batch 270, Loss: 0.8854
Batch 280, Loss: 0.9029
Batch 290, Loss: 0.8850
Batch 300, Loss: 0.9177
Batch 310, Loss: 0.8950
Batch 320, Loss: 0.9759
Batch 330, Loss: 0.9089
Batch 340, Loss: 0.9064
Batch 350, Loss: 0.9112
Batch 360, Loss: 0.8450
Batch 370, Loss: 0.9075
Batch 380, Loss: 0.9268
Batch 390, Loss: 0.9343
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.077327489852905 seconds
Epoch 54 accuracy: 62.43%
Batch 10, Loss: 0.8105
Batch 20, Loss: 0.8080
Batch 30, Loss: 0.7987
Batch 40, Loss: 0.8212
Batch 50, Loss: 0.7740
Batch 60, Loss: 0.8371
Batch 70, Loss: 0.8309
Batch 80, Loss: 0.8492
Batch 90, Loss: 0.8473
Batch 100, Loss: 0.8478
Batch 110, Loss: 0.8301
Batch 120, Loss: 0.8738
Batch 130, Loss: 0.8807
Batch 140, Loss: 0.8633
Batch 150, Loss: 0.8543
Batch 160, Loss: 0.8467
Batch 170, Loss: 0.8758
Batch 180, Loss: 0.8560
Batch 190, Loss: 0.8566
Batch 200, Loss: 0.8510
Batch 210, Loss: 0.8826
Batch 220, Loss: 0.8794
Batch 230, Loss: 0.9034
Batch 240, Loss: 0.8815
Batch 250, Loss: 0.9215
Batch 260, Loss: 0.8645
Batch 270, Loss: 0.9074
Batch 280, Loss: 0.9514
Batch 290, Loss: 0.9004
Batch 300, Loss: 0.9102
Batch 310, Loss: 0.9695
Batch 320, Loss: 0.9497
Batch 330, Loss: 0.9339
Batch 340, Loss: 0.9476
Batch 350, Loss: 0.9475
Batch 360, Loss: 0.8864
Batch 370, Loss: 0.9144
Batch 380, Loss: 0.9161
Batch 390, Loss: 0.8801
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.093228816986084 seconds
Epoch 55 accuracy: 56.39%
Batch 10, Loss: 0.8227
Batch 20, Loss: 0.8586
Batch 30, Loss: 0.8265
Batch 40, Loss: 0.8486
Batch 50, Loss: 0.8317
Batch 60, Loss: 0.7461
Batch 70, Loss: 0.8093
Batch 80, Loss: 0.8524
Batch 90, Loss: 0.8038
Batch 100, Loss: 0.8236
Batch 110, Loss: 0.8202
Batch 120, Loss: 0.8003
Batch 130, Loss: 0.8144
Batch 140, Loss: 0.8427
Batch 150, Loss: 0.7985
Batch 160, Loss: 0.8472
Batch 170, Loss: 0.8779
Batch 180, Loss: 0.9292
Batch 190, Loss: 0.9247
Batch 200, Loss: 0.8682
Batch 210, Loss: 0.8211
Batch 220, Loss: 0.8662
Batch 230, Loss: 0.8912
Batch 240, Loss: 0.8612
Batch 250, Loss: 0.8798
Batch 260, Loss: 0.8652
Batch 270, Loss: 0.8490
Batch 280, Loss: 0.9080
Batch 290, Loss: 0.9146
Batch 300, Loss: 0.8907
Batch 310, Loss: 0.9654
Batch 320, Loss: 0.9322
Batch 330, Loss: 0.9111
Batch 340, Loss: 0.9011
Batch 350, Loss: 0.9380
Batch 360, Loss: 0.9242
Batch 370, Loss: 0.9414
Batch 380, Loss: 0.9131
Batch 390, Loss: 0.8940
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.05182147026062 seconds
Epoch 56 accuracy: 61.07%
Batch 10, Loss: 0.8211
Batch 20, Loss: 0.8220
Batch 30, Loss: 0.7987
Batch 40, Loss: 0.8229
Batch 50, Loss: 0.8196
Batch 60, Loss: 0.8377
Batch 70, Loss: 0.8035
Batch 80, Loss: 0.7933
Batch 90, Loss: 0.8202
Batch 100, Loss: 0.8499
Batch 110, Loss: 0.8342
Batch 120, Loss: 0.7889
Batch 130, Loss: 0.8286
Batch 140, Loss: 0.7851
Batch 150, Loss: 0.8890
Batch 160, Loss: 0.8979
Batch 170, Loss: 0.8131
Batch 180, Loss: 0.8987
Batch 190, Loss: 0.8467
Batch 200, Loss: 0.8123
Batch 210, Loss: 0.8091
Batch 220, Loss: 0.8754
Batch 230, Loss: 0.9224
Batch 240, Loss: 0.8520
Batch 250, Loss: 0.8960
Batch 260, Loss: 0.9283
Batch 270, Loss: 0.8893
Batch 280, Loss: 0.8332
Batch 290, Loss: 0.8842
Batch 300, Loss: 0.8847
Batch 310, Loss: 0.9037
Batch 320, Loss: 0.8786
Batch 330, Loss: 0.9324
Batch 340, Loss: 0.8944
Batch 350, Loss: 0.9364
Batch 360, Loss: 0.8869
Batch 370, Loss: 0.9068
Batch 380, Loss: 0.9518
Batch 390, Loss: 0.9099
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.043081760406494 seconds
Epoch 57 accuracy: 57.69%
Batch 10, Loss: 0.8527
Batch 20, Loss: 0.7918
Batch 30, Loss: 0.8256
Batch 40, Loss: 0.7790
Batch 50, Loss: 0.8154
Batch 60, Loss: 0.7880
Batch 70, Loss: 0.7824
Batch 80, Loss: 0.8027
Batch 90, Loss: 0.7824
Batch 100, Loss: 0.8097
Batch 110, Loss: 0.8649
Batch 120, Loss: 0.8389
Batch 130, Loss: 0.8153
Batch 140, Loss: 0.8401
Batch 150, Loss: 0.8736
Batch 160, Loss: 0.8451
Batch 170, Loss: 0.8552
Batch 180, Loss: 0.8287
Batch 190, Loss: 0.8482
Batch 200, Loss: 0.8574
Batch 210, Loss: 0.8476
Batch 220, Loss: 0.9194
Batch 230, Loss: 0.8964
Batch 240, Loss: 0.8904
Batch 250, Loss: 0.9107
Batch 260, Loss: 0.9254
Batch 270, Loss: 0.9411
Batch 280, Loss: 0.8682
Batch 290, Loss: 0.9196
Batch 300, Loss: 0.8720
Batch 310, Loss: 0.9290
Batch 320, Loss: 0.8803
Batch 330, Loss: 0.8722
Batch 340, Loss: 0.9440
Batch 350, Loss: 0.9676
Batch 360, Loss: 0.9251
Batch 370, Loss: 0.8837
Batch 380, Loss: 0.9270
Batch 390, Loss: 0.8808
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.09263324737549 seconds
Epoch 58 accuracy: 62.8%
Batch 10, Loss: 0.7869
Batch 20, Loss: 0.7845
Batch 30, Loss: 0.7842
Batch 40, Loss: 0.8075
Batch 50, Loss: 0.7872
Batch 60, Loss: 0.7943
Batch 70, Loss: 0.8064
Batch 80, Loss: 0.7447
Batch 90, Loss: 0.7670
Batch 100, Loss: 0.8109
Batch 110, Loss: 0.8607
Batch 120, Loss: 0.7963
Batch 130, Loss: 0.8254
Batch 140, Loss: 0.8854
Batch 150, Loss: 0.8619
Batch 160, Loss: 0.8629
Batch 170, Loss: 0.8453
Batch 180, Loss: 0.8723
Batch 190, Loss: 0.8658
Batch 200, Loss: 0.8112
Batch 210, Loss: 0.8566
Batch 220, Loss: 0.8280
Batch 230, Loss: 0.8460
Batch 240, Loss: 0.9140
Batch 250, Loss: 0.9099
Batch 260, Loss: 0.9118
Batch 270, Loss: 0.8242
Batch 280, Loss: 0.8568
Batch 290, Loss: 0.9232
Batch 300, Loss: 0.9012
Batch 310, Loss: 0.8426
Batch 320, Loss: 0.8756
Batch 330, Loss: 0.8729
Batch 340, Loss: 0.9165
Batch 350, Loss: 0.8813
Batch 360, Loss: 0.8810
Batch 370, Loss: 0.9189
Batch 380, Loss: 0.8742
Batch 390, Loss: 0.9021
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.065210580825806 seconds
Epoch 59 accuracy: 60.01%
Batch 10, Loss: 0.7318
Batch 20, Loss: 0.7556
Batch 30, Loss: 0.7486
Batch 40, Loss: 0.7848
Batch 50, Loss: 0.7697
Batch 60, Loss: 0.7981
Batch 70, Loss: 0.7860
Batch 80, Loss: 0.7937
Batch 90, Loss: 0.7906
Batch 100, Loss: 0.7742
Batch 110, Loss: 0.7979
Batch 120, Loss: 0.8661
Batch 130, Loss: 0.8288
Batch 140, Loss: 0.8189
Batch 150, Loss: 0.8731
Batch 160, Loss: 0.8323
Batch 170, Loss: 0.8863
Batch 180, Loss: 0.8587
Batch 190, Loss: 0.8725
Batch 200, Loss: 0.8111
Batch 210, Loss: 0.8149
Batch 220, Loss: 0.9315
Batch 230, Loss: 0.8931
Batch 240, Loss: 0.8704
Batch 250, Loss: 0.8655
Batch 260, Loss: 0.8616
Batch 270, Loss: 0.8437
Batch 280, Loss: 0.8889
Batch 290, Loss: 0.8789
Batch 300, Loss: 0.8765
Batch 310, Loss: 0.8502
Batch 320, Loss: 0.8784
Batch 330, Loss: 0.8876
Batch 340, Loss: 0.9592
Batch 350, Loss: 0.8592
Batch 360, Loss: 0.8958
Batch 370, Loss: 0.8631
Batch 380, Loss: 0.8852
Batch 390, Loss: 0.8791
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.044857263565063 seconds
Epoch 60 accuracy: 64.87%
Batch 10, Loss: 0.8010
Batch 20, Loss: 0.7903
Batch 30, Loss: 0.7835
Batch 40, Loss: 0.7605
Batch 50, Loss: 0.7883
Batch 60, Loss: 0.7605
Batch 70, Loss: 0.7977
Batch 80, Loss: 0.8294
Batch 90, Loss: 0.8156
Batch 100, Loss: 0.8411
Batch 110, Loss: 0.8134
Batch 120, Loss: 0.8245
Batch 130, Loss: 0.8612
Batch 140, Loss: 0.8829
Batch 150, Loss: 0.8847
Batch 160, Loss: 0.8504
Batch 170, Loss: 0.8545
Batch 180, Loss: 0.9093
Batch 190, Loss: 0.8554
Batch 200, Loss: 0.8486
Batch 210, Loss: 0.8574
Batch 220, Loss: 0.8099
Batch 230, Loss: 0.8098
Batch 240, Loss: 0.8418
Batch 250, Loss: 0.8998
Batch 260, Loss: 0.8693
Batch 270, Loss: 0.8802
Batch 280, Loss: 0.9268
Batch 290, Loss: 0.8497
Batch 300, Loss: 0.9007
Batch 310, Loss: 0.8940
Batch 320, Loss: 0.7842
Batch 330, Loss: 0.8818
Batch 340, Loss: 0.8959
Batch 350, Loss: 0.8610
Batch 360, Loss: 0.8375
Batch 370, Loss: 0.8204
Batch 380, Loss: 0.9178
Batch 390, Loss: 0.8790
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.000985145568848 seconds
Epoch 61 accuracy: 62.23%
Batch 10, Loss: 0.7975
Batch 20, Loss: 0.7975
Batch 30, Loss: 0.7262
Batch 40, Loss: 0.7410
Batch 50, Loss: 0.7852
Batch 60, Loss: 0.6922
Batch 70, Loss: 0.7741
Batch 80, Loss: 0.7470
Batch 90, Loss: 0.7404
Batch 100, Loss: 0.7923
Batch 110, Loss: 0.7869
Batch 120, Loss: 0.8115
Batch 130, Loss: 0.7828
Batch 140, Loss: 0.8394
Batch 150, Loss: 0.8527
Batch 160, Loss: 0.7992
Batch 170, Loss: 0.7950
Batch 180, Loss: 0.8253
Batch 190, Loss: 0.8046
Batch 200, Loss: 0.8186
Batch 210, Loss: 0.8535
Batch 220, Loss: 0.8170
Batch 230, Loss: 0.8070
Batch 240, Loss: 0.8054
Batch 250, Loss: 0.8924
Batch 260, Loss: 0.8133
Batch 270, Loss: 0.8903
Batch 280, Loss: 0.8135
Batch 290, Loss: 0.8812
Batch 300, Loss: 0.9227
Batch 310, Loss: 0.8675
Batch 320, Loss: 0.9352
Batch 330, Loss: 0.9368
Batch 340, Loss: 0.8881
Batch 350, Loss: 0.8655
Batch 360, Loss: 0.8727
Batch 370, Loss: 0.9057
Batch 380, Loss: 0.9420
Batch 390, Loss: 0.7943
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.01954483985901 seconds
Epoch 62 accuracy: 61.66%
Batch 10, Loss: 0.7356
Batch 20, Loss: 0.7627
Batch 30, Loss: 0.7808
Batch 40, Loss: 0.7473
Batch 50, Loss: 0.7833
Batch 60, Loss: 0.7550
Batch 70, Loss: 0.7921
Batch 80, Loss: 0.7723
Batch 90, Loss: 0.8123
Batch 100, Loss: 0.8087
Batch 110, Loss: 0.8331
Batch 120, Loss: 0.8615
Batch 130, Loss: 0.8295
Batch 140, Loss: 0.7794
Batch 150, Loss: 0.8579
Batch 160, Loss: 0.7524
Batch 170, Loss: 0.8054
Batch 180, Loss: 0.8078
Batch 190, Loss: 0.8338
Batch 200, Loss: 0.8600
Batch 210, Loss: 0.8573
Batch 220, Loss: 0.7857
Batch 230, Loss: 0.9050
Batch 240, Loss: 0.8798
Batch 250, Loss: 0.8116
Batch 260, Loss: 0.8998
Batch 270, Loss: 0.8731
Batch 280, Loss: 0.9102
Batch 290, Loss: 0.8449
Batch 300, Loss: 0.9329
Batch 310, Loss: 0.8411
Batch 320, Loss: 0.8710
Batch 330, Loss: 0.8941
Batch 340, Loss: 0.8289
Batch 350, Loss: 0.8791
Batch 360, Loss: 0.8602
Batch 370, Loss: 0.9219
Batch 380, Loss: 0.8444
Batch 390, Loss: 0.8932
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.031357049942017 seconds
Epoch 63 accuracy: 62.39%
Batch 10, Loss: 0.7272
Batch 20, Loss: 0.7702
Batch 30, Loss: 0.7843
Batch 40, Loss: 0.7509
Batch 50, Loss: 0.7785
Batch 60, Loss: 0.7402
Batch 70, Loss: 0.7437
Batch 80, Loss: 0.7991
Batch 90, Loss: 0.7537
Batch 100, Loss: 0.7363
Batch 110, Loss: 0.8060
Batch 120, Loss: 0.7764
Batch 130, Loss: 0.7945
Batch 140, Loss: 0.8644
Batch 150, Loss: 0.8177
Batch 160, Loss: 0.8025
Batch 170, Loss: 0.7895
Batch 180, Loss: 0.8082
Batch 190, Loss: 0.8259
Batch 200, Loss: 0.8627
Batch 210, Loss: 0.8428
Batch 220, Loss: 0.8576
Batch 230, Loss: 0.8787
Batch 240, Loss: 0.8150
Batch 250, Loss: 0.8465
Batch 260, Loss: 0.8233
Batch 270, Loss: 0.8616
Batch 280, Loss: 0.8367
Batch 290, Loss: 0.8469
Batch 300, Loss: 0.8915
Batch 310, Loss: 0.8769
Batch 320, Loss: 0.8725
Batch 330, Loss: 0.8398
Batch 340, Loss: 0.8569
Batch 350, Loss: 0.8919
Batch 360, Loss: 0.8985
Batch 370, Loss: 0.8934
Batch 380, Loss: 0.8429
Batch 390, Loss: 0.8846
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.091400623321533 seconds
Epoch 64 accuracy: 60.53%
Batch 10, Loss: 0.7337
Batch 20, Loss: 0.7367
Batch 30, Loss: 0.7334
Batch 40, Loss: 0.7507
Batch 50, Loss: 0.7249
Batch 60, Loss: 0.7349
Batch 70, Loss: 0.7180
Batch 80, Loss: 0.7752
Batch 90, Loss: 0.8096
Batch 100, Loss: 0.8219
Batch 110, Loss: 0.7499
Batch 120, Loss: 0.8150
Batch 130, Loss: 0.7428
Batch 140, Loss: 0.7833
Batch 150, Loss: 0.7924
Batch 160, Loss: 0.7894
Batch 170, Loss: 0.7724
Batch 180, Loss: 0.8685
Batch 190, Loss: 0.8296
Batch 200, Loss: 0.8318
Batch 210, Loss: 0.7988
Batch 220, Loss: 0.7992
Batch 230, Loss: 0.8001
Batch 240, Loss: 0.8642
Batch 250, Loss: 0.8089
Batch 260, Loss: 0.8131
Batch 270, Loss: 0.8214
Batch 280, Loss: 0.8237
Batch 290, Loss: 0.9182
Batch 300, Loss: 0.8949
Batch 310, Loss: 0.8501
Batch 320, Loss: 0.8617
Batch 330, Loss: 0.8405
Batch 340, Loss: 0.8382
Batch 350, Loss: 0.8481
Batch 360, Loss: 0.9383
Batch 370, Loss: 0.8358
Batch 380, Loss: 0.9016
Batch 390, Loss: 0.8558
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.063815355300903 seconds
Epoch 65 accuracy: 63.19%
Batch 10, Loss: 0.7464
Batch 20, Loss: 0.8167
Batch 30, Loss: 0.7500
Batch 40, Loss: 0.7646
Batch 50, Loss: 0.7540
Batch 60, Loss: 0.8133
Batch 70, Loss: 0.7647
Batch 80, Loss: 0.7669
Batch 90, Loss: 0.7096
Batch 100, Loss: 0.7635
Batch 110, Loss: 0.7936
Batch 120, Loss: 0.7718
Batch 130, Loss: 0.7792
Batch 140, Loss: 0.7994
Batch 150, Loss: 0.7817
Batch 160, Loss: 0.7995
Batch 170, Loss: 0.7760
Batch 180, Loss: 0.8214
Batch 190, Loss: 0.8619
Batch 200, Loss: 0.8632
Batch 210, Loss: 0.7990
Batch 220, Loss: 0.8552
Batch 230, Loss: 0.7844
Batch 240, Loss: 0.8328
Batch 250, Loss: 0.8213
Batch 260, Loss: 0.8170
Batch 270, Loss: 0.8168
Batch 280, Loss: 0.8738
Batch 290, Loss: 0.8879
Batch 300, Loss: 0.8443
Batch 310, Loss: 0.8164
Batch 320, Loss: 0.8530
Batch 330, Loss: 0.8351
Batch 340, Loss: 0.8304
Batch 350, Loss: 0.8414
Batch 360, Loss: 0.8784
Batch 370, Loss: 0.8696
Batch 380, Loss: 0.8799
Batch 390, Loss: 0.8522
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.065536499023438 seconds
Epoch 66 accuracy: 57.85%
Batch 10, Loss: 0.7648
Batch 20, Loss: 0.7764
Batch 30, Loss: 0.7582
Batch 40, Loss: 0.7714
Batch 50, Loss: 0.7071
Batch 60, Loss: 0.7356
Batch 70, Loss: 0.7428
Batch 80, Loss: 0.7527
Batch 90, Loss: 0.7497
Batch 100, Loss: 0.7948
Batch 110, Loss: 0.7314
Batch 120, Loss: 0.7644
Batch 130, Loss: 0.7663
Batch 140, Loss: 0.7778
Batch 150, Loss: 0.7694
Batch 160, Loss: 0.7584
Batch 170, Loss: 0.8084
Batch 180, Loss: 0.8397
Batch 190, Loss: 0.8368
Batch 200, Loss: 0.7725
Batch 210, Loss: 0.8230
Batch 220, Loss: 0.7641
Batch 230, Loss: 0.7876
Batch 240, Loss: 0.8656
Batch 250, Loss: 0.8398
Batch 260, Loss: 0.7970
Batch 270, Loss: 0.7911
Batch 280, Loss: 0.8903
Batch 290, Loss: 0.7838
Batch 300, Loss: 0.8675
Batch 310, Loss: 0.8185
Batch 320, Loss: 0.8593
Batch 330, Loss: 0.8984
Batch 340, Loss: 0.8546
Batch 350, Loss: 0.8457
Batch 360, Loss: 0.8476
Batch 370, Loss: 0.8351
Batch 380, Loss: 0.8797
Batch 390, Loss: 0.8316
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.077382564544678 seconds
Epoch 67 accuracy: 62.49%
Batch 10, Loss: 0.7736
Batch 20, Loss: 0.6973
Batch 30, Loss: 0.7408
Batch 40, Loss: 0.7498
Batch 50, Loss: 0.7263
Batch 60, Loss: 0.7505
Batch 70, Loss: 0.7620
Batch 80, Loss: 0.7597
Batch 90, Loss: 0.7304
Batch 100, Loss: 0.7463
Batch 110, Loss: 0.7578
Batch 120, Loss: 0.7722
Batch 130, Loss: 0.7516
Batch 140, Loss: 0.7842
Batch 150, Loss: 0.7911
Batch 160, Loss: 0.7756
Batch 170, Loss: 0.8338
Batch 180, Loss: 0.7681
Batch 190, Loss: 0.8106
Batch 200, Loss: 0.7395
Batch 210, Loss: 0.7932
Batch 220, Loss: 0.8636
Batch 230, Loss: 0.8511
Batch 240, Loss: 0.7890
Batch 250, Loss: 0.8195
Batch 260, Loss: 0.8353
Batch 270, Loss: 0.7996
Batch 280, Loss: 0.8176
Batch 290, Loss: 0.8804
Batch 300, Loss: 0.7800
Batch 310, Loss: 0.8503
Batch 320, Loss: 0.8304
Batch 330, Loss: 0.8708
Batch 340, Loss: 0.8259
Batch 350, Loss: 0.8015
Batch 360, Loss: 0.8570
Batch 370, Loss: 0.8000
Batch 380, Loss: 0.9260
Batch 390, Loss: 0.7964
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.043285846710205 seconds
Epoch 68 accuracy: 58.37%
Batch 10, Loss: 0.7729
Batch 20, Loss: 0.7463
Batch 30, Loss: 0.7420
Batch 40, Loss: 0.7293
Batch 50, Loss: 0.7748
Batch 60, Loss: 0.7463
Batch 70, Loss: 0.7725
Batch 80, Loss: 0.7831
Batch 90, Loss: 0.7318
Batch 100, Loss: 0.7823
Batch 110, Loss: 0.7930
Batch 120, Loss: 0.7712
Batch 130, Loss: 0.7599
Batch 140, Loss: 0.8014
Batch 150, Loss: 0.7589
Batch 160, Loss: 0.7622
Batch 170, Loss: 0.7408
Batch 180, Loss: 0.7363
Batch 190, Loss: 0.8030
Batch 200, Loss: 0.8006
Batch 210, Loss: 0.7919
Batch 220, Loss: 0.7732
Batch 230, Loss: 0.7982
Batch 240, Loss: 0.7970
Batch 250, Loss: 0.7961
Batch 260, Loss: 0.8462
Batch 270, Loss: 0.8291
Batch 280, Loss: 0.8840
Batch 290, Loss: 0.8530
Batch 300, Loss: 0.8149
Batch 310, Loss: 0.8265
Batch 320, Loss: 0.8166
Batch 330, Loss: 0.7986
Batch 340, Loss: 0.8789
Batch 350, Loss: 0.8363
Batch 360, Loss: 0.8910
Batch 370, Loss: 0.8666
Batch 380, Loss: 0.8767
Batch 390, Loss: 0.8162
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.077044010162354 seconds
Epoch 69 accuracy: 62.29%
Batch 10, Loss: 0.7649
Batch 20, Loss: 0.7279
Batch 30, Loss: 0.7291
Batch 40, Loss: 0.7300
Batch 50, Loss: 0.7015
Batch 60, Loss: 0.7173
Batch 70, Loss: 0.7437
Batch 80, Loss: 0.7019
Batch 90, Loss: 0.7191
Batch 100, Loss: 0.6944
Batch 110, Loss: 0.7623
Batch 120, Loss: 0.7913
Batch 130, Loss: 0.7842
Batch 140, Loss: 0.7529
Batch 150, Loss: 0.7949
Batch 160, Loss: 0.7722
Batch 170, Loss: 0.7747
Batch 180, Loss: 0.7864
Batch 190, Loss: 0.7957
Batch 200, Loss: 0.7748
Batch 210, Loss: 0.8056
Batch 220, Loss: 0.7807
Batch 230, Loss: 0.7993
Batch 240, Loss: 0.7948
Batch 250, Loss: 0.7951
Batch 260, Loss: 0.8402
Batch 270, Loss: 0.7611
Batch 280, Loss: 0.7962
Batch 290, Loss: 0.8237
Batch 300, Loss: 0.8772
Batch 310, Loss: 0.8419
Batch 320, Loss: 0.8522
Batch 330, Loss: 0.8683
Batch 340, Loss: 0.7765
Batch 350, Loss: 0.8176
Batch 360, Loss: 0.8355
Batch 370, Loss: 0.8577
Batch 380, Loss: 0.8330
Batch 390, Loss: 0.8718
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.10168147087097 seconds
Epoch 70 accuracy: 59.31%
Batch 10, Loss: 0.7288
Batch 20, Loss: 0.7550
Batch 30, Loss: 0.7142
Batch 40, Loss: 0.7050
Batch 50, Loss: 0.6948
Batch 60, Loss: 0.6995
Batch 70, Loss: 0.7694
Batch 80, Loss: 0.7258
Batch 90, Loss: 0.7433
Batch 100, Loss: 0.7395
Batch 110, Loss: 0.7675
Batch 120, Loss: 0.7583
Batch 130, Loss: 0.7303
Batch 140, Loss: 0.7945
Batch 150, Loss: 0.7950
Batch 160, Loss: 0.7439
Batch 170, Loss: 0.7269
Batch 180, Loss: 0.7383
Batch 190, Loss: 0.8273
Batch 200, Loss: 0.8299
Batch 210, Loss: 0.8140
Batch 220, Loss: 0.7982
Batch 230, Loss: 0.8101
Batch 240, Loss: 0.8000
Batch 250, Loss: 0.7768
Batch 260, Loss: 0.8251
Batch 270, Loss: 0.8098
Batch 280, Loss: 0.7867
Batch 290, Loss: 0.8168
Batch 300, Loss: 0.7809
Batch 310, Loss: 0.8577
Batch 320, Loss: 0.8402
Batch 330, Loss: 0.8839
Batch 340, Loss: 0.8629
Batch 350, Loss: 0.8631
Batch 360, Loss: 0.7887
Batch 370, Loss: 0.7985
Batch 380, Loss: 0.8257
Batch 390, Loss: 0.8028
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.333116054534912 seconds
Epoch 71 accuracy: 63.51%
Batch 10, Loss: 0.7042
Batch 20, Loss: 0.7432
Batch 30, Loss: 0.7291
Batch 40, Loss: 0.7322
Batch 50, Loss: 0.6939
Batch 60, Loss: 0.7114
Batch 70, Loss: 0.6994
Batch 80, Loss: 0.7481
Batch 90, Loss: 0.7161
Batch 100, Loss: 0.7691
Batch 110, Loss: 0.7633
Batch 120, Loss: 0.7604
Batch 130, Loss: 0.7316
Batch 140, Loss: 0.7659
Batch 150, Loss: 0.7449
Batch 160, Loss: 0.7193
Batch 170, Loss: 0.7565
Batch 180, Loss: 0.8013
Batch 190, Loss: 0.7730
Batch 200, Loss: 0.8203
Batch 210, Loss: 0.7882
Batch 220, Loss: 0.7715
Batch 230, Loss: 0.7644
Batch 240, Loss: 0.7873
Batch 250, Loss: 0.8422
Batch 260, Loss: 0.7679
Batch 270, Loss: 0.7501
Batch 280, Loss: 0.7816
Batch 290, Loss: 0.7912
Batch 300, Loss: 0.7672
Batch 310, Loss: 0.8185
Batch 320, Loss: 0.8270
Batch 330, Loss: 0.8301
Batch 340, Loss: 0.8632
Batch 350, Loss: 0.8433
Batch 360, Loss: 0.8638
Batch 370, Loss: 0.8431
Batch 380, Loss: 0.8006
Batch 390, Loss: 0.8331
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.029130220413208 seconds
Epoch 72 accuracy: 63.22%
Batch 10, Loss: 0.7463
Batch 20, Loss: 0.7074
Batch 30, Loss: 0.7229
Batch 40, Loss: 0.7172
Batch 50, Loss: 0.7033
Batch 60, Loss: 0.6744
Batch 70, Loss: 0.7414
Batch 80, Loss: 0.7442
Batch 90, Loss: 0.7510
Batch 100, Loss: 0.7396
Batch 110, Loss: 0.7324
Batch 120, Loss: 0.7199
Batch 130, Loss: 0.7383
Batch 140, Loss: 0.7375
Batch 150, Loss: 0.7236
Batch 160, Loss: 0.7195
Batch 170, Loss: 0.7625
Batch 180, Loss: 0.7873
Batch 190, Loss: 0.8225
Batch 200, Loss: 0.8030
Batch 210, Loss: 0.7610
Batch 220, Loss: 0.7748
Batch 230, Loss: 0.7750
Batch 240, Loss: 0.7175
Batch 250, Loss: 0.7734
Batch 260, Loss: 0.7939
Batch 270, Loss: 0.7575
Batch 280, Loss: 0.8172
Batch 290, Loss: 0.7872
Batch 300, Loss: 0.7578
Batch 310, Loss: 0.8246
Batch 320, Loss: 0.8300
Batch 330, Loss: 0.8090
Batch 340, Loss: 0.8145
Batch 350, Loss: 0.7602
Batch 360, Loss: 0.8069
Batch 370, Loss: 0.8548
Batch 380, Loss: 0.8050
Batch 390, Loss: 0.7915
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.10227942466736 seconds
Epoch 73 accuracy: 62.38%
Batch 10, Loss: 0.7359
Batch 20, Loss: 0.6594
Batch 30, Loss: 0.6913
Batch 40, Loss: 0.7033
Batch 50, Loss: 0.6697
Batch 60, Loss: 0.6800
Batch 70, Loss: 0.7086
Batch 80, Loss: 0.6918
Batch 90, Loss: 0.7269
Batch 100, Loss: 0.6763
Batch 110, Loss: 0.7266
Batch 120, Loss: 0.7127
Batch 130, Loss: 0.7487
Batch 140, Loss: 0.7212
Batch 150, Loss: 0.7191
Batch 160, Loss: 0.7518
Batch 170, Loss: 0.7965
Batch 180, Loss: 0.7299
Batch 190, Loss: 0.7721
Batch 200, Loss: 0.7729
Batch 210, Loss: 0.7816
Batch 220, Loss: 0.7598
Batch 230, Loss: 0.8068
Batch 240, Loss: 0.8432
Batch 250, Loss: 0.8087
Batch 260, Loss: 0.8323
Batch 270, Loss: 0.7275
Batch 280, Loss: 0.7689
Batch 290, Loss: 0.7824
Batch 300, Loss: 0.7918
Batch 310, Loss: 0.7689
Batch 320, Loss: 0.8466
Batch 330, Loss: 0.8552
Batch 340, Loss: 0.8740
Batch 350, Loss: 0.8436
Batch 360, Loss: 0.7982
Batch 370, Loss: 0.8054
Batch 380, Loss: 0.8355
Batch 390, Loss: 0.7934
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.113516330718994 seconds
Epoch 74 accuracy: 63.09%
Batch 10, Loss: 0.7027
Batch 20, Loss: 0.7560
Batch 30, Loss: 0.6540
Batch 40, Loss: 0.7212
Batch 50, Loss: 0.7197
Batch 60, Loss: 0.7302
Batch 70, Loss: 0.7114
Batch 80, Loss: 0.6838
Batch 90, Loss: 0.7030
Batch 100, Loss: 0.6958
Batch 110, Loss: 0.6926
Batch 120, Loss: 0.6859
Batch 130, Loss: 0.7571
Batch 140, Loss: 0.7280
Batch 150, Loss: 0.6874
Batch 160, Loss: 0.6820
Batch 170, Loss: 0.7317
Batch 180, Loss: 0.7666
Batch 190, Loss: 0.8023
Batch 200, Loss: 0.7917
Batch 210, Loss: 0.7378
Batch 220, Loss: 0.7591
Batch 230, Loss: 0.7759
Batch 240, Loss: 0.7927
Batch 250, Loss: 0.7823
Batch 260, Loss: 0.7891
Batch 270, Loss: 0.7820
Batch 280, Loss: 0.7845
Batch 290, Loss: 0.7792
Batch 300, Loss: 0.8044
Batch 310, Loss: 0.7532
Batch 320, Loss: 0.7501
Batch 330, Loss: 0.8087
Batch 340, Loss: 0.7757
Batch 350, Loss: 0.8129
Batch 360, Loss: 0.8064
Batch 370, Loss: 0.8424
Batch 380, Loss: 0.8337
Batch 390, Loss: 0.8253
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.101118326187134 seconds
Epoch 75 accuracy: 64.91%
Batch 10, Loss: 0.7107
Batch 20, Loss: 0.7151
Batch 30, Loss: 0.7181
Batch 40, Loss: 0.7036
Batch 50, Loss: 0.7134
Batch 60, Loss: 0.6398
Batch 70, Loss: 0.6907
Batch 80, Loss: 0.7071
Batch 90, Loss: 0.7113
Batch 100, Loss: 0.6663
Batch 110, Loss: 0.7186
Batch 120, Loss: 0.6775
Batch 130, Loss: 0.7005
Batch 140, Loss: 0.7065
Batch 150, Loss: 0.7467
Batch 160, Loss: 0.7134
Batch 170, Loss: 0.7675
Batch 180, Loss: 0.6995
Batch 190, Loss: 0.7750
Batch 200, Loss: 0.7251
Batch 210, Loss: 0.7425
Batch 220, Loss: 0.7587
Batch 230, Loss: 0.7645
Batch 240, Loss: 0.7825
Batch 250, Loss: 0.7232
Batch 260, Loss: 0.7869
Batch 270, Loss: 0.8383
Batch 280, Loss: 0.7895
Batch 290, Loss: 0.7927
Batch 300, Loss: 0.7917
Batch 310, Loss: 0.7236
Batch 320, Loss: 0.7712
Batch 330, Loss: 0.7688
Batch 340, Loss: 0.7851
Batch 350, Loss: 0.7992
Batch 360, Loss: 0.7955
Batch 370, Loss: 0.8065
Batch 380, Loss: 0.7912
Batch 390, Loss: 0.7392
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.059904098510742 seconds
Epoch 76 accuracy: 63.75%
Batch 10, Loss: 0.7029
Batch 20, Loss: 0.7203
Batch 30, Loss: 0.6585
Batch 40, Loss: 0.6988
Batch 50, Loss: 0.6678
Batch 60, Loss: 0.6793
Batch 70, Loss: 0.7068
Batch 80, Loss: 0.6759
Batch 90, Loss: 0.6961
Batch 100, Loss: 0.6871
Batch 110, Loss: 0.6713
Batch 120, Loss: 0.7135
Batch 130, Loss: 0.7259
Batch 140, Loss: 0.7321
Batch 150, Loss: 0.7090
Batch 160, Loss: 0.7250
Batch 170, Loss: 0.6858
Batch 180, Loss: 0.6765
Batch 190, Loss: 0.7504
Batch 200, Loss: 0.7184
Batch 210, Loss: 0.7656
Batch 220, Loss: 0.7368
Batch 230, Loss: 0.7409
Batch 240, Loss: 0.7675
Batch 250, Loss: 0.7479
Batch 260, Loss: 0.7527
Batch 270, Loss: 0.7744
Batch 280, Loss: 0.7887
Batch 290, Loss: 0.7739
Batch 300, Loss: 0.8272
Batch 310, Loss: 0.8133
Batch 320, Loss: 0.8124
Batch 330, Loss: 0.7901
Batch 340, Loss: 0.7783
Batch 350, Loss: 0.7338
Batch 360, Loss: 0.8105
Batch 370, Loss: 0.7669
Batch 380, Loss: 0.7845
Batch 390, Loss: 0.7634
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.026138067245483 seconds
Epoch 77 accuracy: 64.88%
Batch 10, Loss: 0.7008
Batch 20, Loss: 0.7119
Batch 30, Loss: 0.6251
Batch 40, Loss: 0.6339
Batch 50, Loss: 0.6611
Batch 60, Loss: 0.7057
Batch 70, Loss: 0.7054
Batch 80, Loss: 0.6653
Batch 90, Loss: 0.7306
Batch 100, Loss: 0.6638
Batch 110, Loss: 0.6763
Batch 120, Loss: 0.6511
Batch 130, Loss: 0.7148
Batch 140, Loss: 0.7196
Batch 150, Loss: 0.7234
Batch 160, Loss: 0.7258
Batch 170, Loss: 0.7078
Batch 180, Loss: 0.7527
Batch 190, Loss: 0.7392
Batch 200, Loss: 0.7458
Batch 210, Loss: 0.7471
Batch 220, Loss: 0.7009
Batch 230, Loss: 0.7901
Batch 240, Loss: 0.7284
Batch 250, Loss: 0.7715
Batch 260, Loss: 0.7793
Batch 270, Loss: 0.7913
Batch 280, Loss: 0.7674
Batch 290, Loss: 0.7779
Batch 300, Loss: 0.7805
Batch 310, Loss: 0.8139
Batch 320, Loss: 0.7630
Batch 330, Loss: 0.7512
Batch 340, Loss: 0.7771
Batch 350, Loss: 0.8012
Batch 360, Loss: 0.7427
Batch 370, Loss: 0.7885
Batch 380, Loss: 0.7654
Batch 390, Loss: 0.7837
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 24.98966121673584 seconds
Epoch 78 accuracy: 63.19%
Batch 10, Loss: 0.6378
Batch 20, Loss: 0.6549
Batch 30, Loss: 0.6421
Batch 40, Loss: 0.6322
Batch 50, Loss: 0.6745
Batch 60, Loss: 0.6611
Batch 70, Loss: 0.6829
Batch 80, Loss: 0.6750
Batch 90, Loss: 0.6846
Batch 100, Loss: 0.6717
Batch 110, Loss: 0.7377
Batch 120, Loss: 0.7198
Batch 130, Loss: 0.6978
Batch 140, Loss: 0.6877
Batch 150, Loss: 0.7268
Batch 160, Loss: 0.7396
Batch 170, Loss: 0.6949
Batch 180, Loss: 0.7429
Batch 190, Loss: 0.7248
Batch 200, Loss: 0.7060
Batch 210, Loss: 0.7460
Batch 220, Loss: 0.7531
Batch 230, Loss: 0.7584
Batch 240, Loss: 0.7570
Batch 250, Loss: 0.7325
Batch 260, Loss: 0.7536
Batch 270, Loss: 0.7536
Batch 280, Loss: 0.7612
Batch 290, Loss: 0.7259
Batch 300, Loss: 0.7330
Batch 310, Loss: 0.7438
Batch 320, Loss: 0.7692
Batch 330, Loss: 0.7316
Batch 340, Loss: 0.8040
Batch 350, Loss: 0.7721
Batch 360, Loss: 0.7793
Batch 370, Loss: 0.8014
Batch 380, Loss: 0.8343
Batch 390, Loss: 0.8037
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.08699059486389 seconds
Epoch 79 accuracy: 66.4%
Batch 10, Loss: 0.6889
Batch 20, Loss: 0.6568
Batch 30, Loss: 0.6531
Batch 40, Loss: 0.6475
Batch 50, Loss: 0.6284
Batch 60, Loss: 0.6767
Batch 70, Loss: 0.6116
Batch 80, Loss: 0.6523
Batch 90, Loss: 0.6805
Batch 100, Loss: 0.6741
Batch 110, Loss: 0.7059
Batch 120, Loss: 0.7514
Batch 130, Loss: 0.6977
Batch 140, Loss: 0.7267
Batch 150, Loss: 0.7366
Batch 160, Loss: 0.7275
Batch 170, Loss: 0.7338
Batch 180, Loss: 0.7136
Batch 190, Loss: 0.6944
Batch 200, Loss: 0.7246
Batch 210, Loss: 0.7239
Batch 220, Loss: 0.7439
Batch 230, Loss: 0.7155
Batch 240, Loss: 0.7188
Batch 250, Loss: 0.7419
Batch 260, Loss: 0.7512
Batch 270, Loss: 0.7275
Batch 280, Loss: 0.8125
Batch 290, Loss: 0.7476
Batch 300, Loss: 0.7159
Batch 310, Loss: 0.7533
Batch 320, Loss: 0.7505
Batch 330, Loss: 0.7670
Batch 340, Loss: 0.7700
Batch 350, Loss: 0.7495
Batch 360, Loss: 0.7869
Batch 370, Loss: 0.7772
Batch 380, Loss: 0.7671
Batch 390, Loss: 0.7541
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.036658763885498 seconds
Epoch 80 accuracy: 63.18%
Batch 10, Loss: 0.6573
Batch 20, Loss: 0.6740
Batch 30, Loss: 0.6164
Batch 40, Loss: 0.6297
Batch 50, Loss: 0.6720
Batch 60, Loss: 0.6349
Batch 70, Loss: 0.6550
Batch 80, Loss: 0.7053
Batch 90, Loss: 0.6553
Batch 100, Loss: 0.6662
Batch 110, Loss: 0.6781
Batch 120, Loss: 0.6908
Batch 130, Loss: 0.6621
Batch 140, Loss: 0.6708
Batch 150, Loss: 0.7196
Batch 160, Loss: 0.7009
Batch 170, Loss: 0.7283
Batch 180, Loss: 0.6853
Batch 190, Loss: 0.7036
Batch 200, Loss: 0.7398
Batch 210, Loss: 0.7563
Batch 220, Loss: 0.7198
Batch 230, Loss: 0.7085
Batch 240, Loss: 0.6666
Batch 250, Loss: 0.6941
Batch 260, Loss: 0.7518
Batch 270, Loss: 0.7658
Batch 280, Loss: 0.7163
Batch 290, Loss: 0.7021
Batch 300, Loss: 0.7821
Batch 310, Loss: 0.7448
Batch 320, Loss: 0.7522
Batch 330, Loss: 0.7558
Batch 340, Loss: 0.7431
Batch 350, Loss: 0.7440
Batch 360, Loss: 0.7699
Batch 370, Loss: 0.7171
Batch 380, Loss: 0.7381
Batch 390, Loss: 0.7557
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.0465350151062 seconds
Epoch 81 accuracy: 64.88%
Batch 10, Loss: 0.6548
Batch 20, Loss: 0.6812
Batch 30, Loss: 0.6300
Batch 40, Loss: 0.6411
Batch 50, Loss: 0.6288
Batch 60, Loss: 0.6011
Batch 70, Loss: 0.6594
Batch 80, Loss: 0.6411
Batch 90, Loss: 0.6398
Batch 100, Loss: 0.6620
Batch 110, Loss: 0.7000
Batch 120, Loss: 0.6931
Batch 130, Loss: 0.6649
Batch 140, Loss: 0.6786
Batch 150, Loss: 0.6692
Batch 160, Loss: 0.6699
Batch 170, Loss: 0.6812
Batch 180, Loss: 0.6638
Batch 190, Loss: 0.6818
Batch 200, Loss: 0.7445
Batch 210, Loss: 0.7157
Batch 220, Loss: 0.7101
Batch 230, Loss: 0.7123
Batch 240, Loss: 0.7278
Batch 250, Loss: 0.7769
Batch 260, Loss: 0.7747
Batch 270, Loss: 0.7295
Batch 280, Loss: 0.7558
Batch 290, Loss: 0.7664
Batch 300, Loss: 0.7543
Batch 310, Loss: 0.7304
Batch 320, Loss: 0.7392
Batch 330, Loss: 0.7266
Batch 340, Loss: 0.7862
Batch 350, Loss: 0.7927
Batch 360, Loss: 0.7842
Batch 370, Loss: 0.7784
Batch 380, Loss: 0.7670
Batch 390, Loss: 0.7845
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.059388399124146 seconds
Epoch 82 accuracy: 64.26%
Batch 10, Loss: 0.6396
Batch 20, Loss: 0.6354
Batch 30, Loss: 0.6350
Batch 40, Loss: 0.6523
Batch 50, Loss: 0.6342
Batch 60, Loss: 0.6118
Batch 70, Loss: 0.6664
Batch 80, Loss: 0.6784
Batch 90, Loss: 0.6530
Batch 100, Loss: 0.6991
Batch 110, Loss: 0.6898
Batch 120, Loss: 0.6990
Batch 130, Loss: 0.6738
Batch 140, Loss: 0.6958
Batch 150, Loss: 0.7281
Batch 160, Loss: 0.7214
Batch 170, Loss: 0.7194
Batch 180, Loss: 0.6555
Batch 190, Loss: 0.7302
Batch 200, Loss: 0.7029
Batch 210, Loss: 0.7081
Batch 220, Loss: 0.7126
Batch 230, Loss: 0.6987
Batch 240, Loss: 0.7045
Batch 250, Loss: 0.6586
Batch 260, Loss: 0.7037
Batch 270, Loss: 0.7545
Batch 280, Loss: 0.7373
Batch 290, Loss: 0.7383
Batch 300, Loss: 0.7223
Batch 310, Loss: 0.7252
Batch 320, Loss: 0.7314
Batch 330, Loss: 0.7338
Batch 340, Loss: 0.7036
Batch 350, Loss: 0.7109
Batch 360, Loss: 0.7614
Batch 370, Loss: 0.7294
Batch 380, Loss: 0.7331
Batch 390, Loss: 0.7397
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 24.99846577644348 seconds
Epoch 83 accuracy: 62.27%
Batch 10, Loss: 0.6954
Batch 20, Loss: 0.6438
Batch 30, Loss: 0.6468
Batch 40, Loss: 0.6465
Batch 50, Loss: 0.6713
Batch 60, Loss: 0.6416
Batch 70, Loss: 0.6111
Batch 80, Loss: 0.6788
Batch 90, Loss: 0.7048
Batch 100, Loss: 0.6402
Batch 110, Loss: 0.6318
Batch 120, Loss: 0.6523
Batch 130, Loss: 0.6615
Batch 140, Loss: 0.6694
Batch 150, Loss: 0.6615
Batch 160, Loss: 0.6896
Batch 170, Loss: 0.6789
Batch 180, Loss: 0.6637
Batch 190, Loss: 0.6910
Batch 200, Loss: 0.6905
Batch 210, Loss: 0.7262
Batch 220, Loss: 0.6495
Batch 230, Loss: 0.7338
Batch 240, Loss: 0.7356
Batch 250, Loss: 0.7592
Batch 260, Loss: 0.7630
Batch 270, Loss: 0.7262
Batch 280, Loss: 0.7265
Batch 290, Loss: 0.7089
Batch 300, Loss: 0.7174
Batch 310, Loss: 0.6631
Batch 320, Loss: 0.7508
Batch 330, Loss: 0.6980
Batch 340, Loss: 0.7113
Batch 350, Loss: 0.7342
Batch 360, Loss: 0.7124
Batch 370, Loss: 0.7426
Batch 380, Loss: 0.6899
Batch 390, Loss: 0.7531
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.00810742378235 seconds
Epoch 84 accuracy: 59.86%
Batch 10, Loss: 0.6658
Batch 20, Loss: 0.6300
Batch 30, Loss: 0.5971
Batch 40, Loss: 0.6377
Batch 50, Loss: 0.5745
Batch 60, Loss: 0.6093
Batch 70, Loss: 0.6357
Batch 80, Loss: 0.6460
Batch 90, Loss: 0.6101
Batch 100, Loss: 0.6963
Batch 110, Loss: 0.6659
Batch 120, Loss: 0.6297
Batch 130, Loss: 0.6401
Batch 140, Loss: 0.6425
Batch 150, Loss: 0.6691
Batch 160, Loss: 0.6484
Batch 170, Loss: 0.6550
Batch 180, Loss: 0.7017
Batch 190, Loss: 0.7189
Batch 200, Loss: 0.6771
Batch 210, Loss: 0.7283
Batch 220, Loss: 0.7091
Batch 230, Loss: 0.6836
Batch 240, Loss: 0.7390
Batch 250, Loss: 0.6672
Batch 260, Loss: 0.6792
Batch 270, Loss: 0.7260
Batch 280, Loss: 0.7070
Batch 290, Loss: 0.7258
Batch 300, Loss: 0.7003
Batch 310, Loss: 0.7201
Batch 320, Loss: 0.6925
Batch 330, Loss: 0.7427
Batch 340, Loss: 0.7788
Batch 350, Loss: 0.7256
Batch 360, Loss: 0.7505
Batch 370, Loss: 0.7253
Batch 380, Loss: 0.7489
Batch 390, Loss: 0.7788
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.12076210975647 seconds
Epoch 85 accuracy: 65.6%
Batch 10, Loss: 0.6289
Batch 20, Loss: 0.5912
Batch 30, Loss: 0.6360
Batch 40, Loss: 0.6398
Batch 50, Loss: 0.6322
Batch 60, Loss: 0.6132
Batch 70, Loss: 0.6492
Batch 80, Loss: 0.6550
Batch 90, Loss: 0.6453
Batch 100, Loss: 0.6088
Batch 110, Loss: 0.5873
Batch 120, Loss: 0.6065
Batch 130, Loss: 0.6592
Batch 140, Loss: 0.6816
Batch 150, Loss: 0.6727
Batch 160, Loss: 0.6636
Batch 170, Loss: 0.6607
Batch 180, Loss: 0.7048
Batch 190, Loss: 0.6725
Batch 200, Loss: 0.7064
Batch 210, Loss: 0.6585
Batch 220, Loss: 0.6229
Batch 230, Loss: 0.6547
Batch 240, Loss: 0.7189
Batch 250, Loss: 0.6912
Batch 260, Loss: 0.6968
Batch 270, Loss: 0.7559
Batch 280, Loss: 0.7561
Batch 290, Loss: 0.6598
Batch 300, Loss: 0.6713
Batch 310, Loss: 0.6817
Batch 320, Loss: 0.6901
Batch 330, Loss: 0.7110
Batch 340, Loss: 0.7506
Batch 350, Loss: 0.7456
Batch 360, Loss: 0.7160
Batch 370, Loss: 0.7310
Batch 380, Loss: 0.7579
Batch 390, Loss: 0.7532
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.05617928504944 seconds
Epoch 86 accuracy: 63.92%
Batch 10, Loss: 0.6014
Batch 20, Loss: 0.6382
Batch 30, Loss: 0.6274
Batch 40, Loss: 0.6030
Batch 50, Loss: 0.5606
Batch 60, Loss: 0.5899
Batch 70, Loss: 0.6338
Batch 80, Loss: 0.6417
Batch 90, Loss: 0.6093
Batch 100, Loss: 0.5806
Batch 110, Loss: 0.6220
Batch 120, Loss: 0.6433
Batch 130, Loss: 0.6523
Batch 140, Loss: 0.6377
Batch 150, Loss: 0.6237
Batch 160, Loss: 0.6454
Batch 170, Loss: 0.6241
Batch 180, Loss: 0.6828
Batch 190, Loss: 0.6542
Batch 200, Loss: 0.6738
Batch 210, Loss: 0.6540
Batch 220, Loss: 0.6708
Batch 230, Loss: 0.7110
Batch 240, Loss: 0.6894
Batch 250, Loss: 0.6747
Batch 260, Loss: 0.6961
Batch 270, Loss: 0.6865
Batch 280, Loss: 0.6921
Batch 290, Loss: 0.7237
Batch 300, Loss: 0.7082
Batch 310, Loss: 0.6821
Batch 320, Loss: 0.6835
Batch 330, Loss: 0.7086
Batch 340, Loss: 0.7154
Batch 350, Loss: 0.7214
Batch 360, Loss: 0.7455
Batch 370, Loss: 0.7005
Batch 380, Loss: 0.7266
Batch 390, Loss: 0.7523
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.025725603103638 seconds
Epoch 87 accuracy: 64.03%
Batch 10, Loss: 0.6558
Batch 20, Loss: 0.6425
Batch 30, Loss: 0.6182
Batch 40, Loss: 0.5978
Batch 50, Loss: 0.5760
Batch 60, Loss: 0.5852
Batch 70, Loss: 0.5791
Batch 80, Loss: 0.5981
Batch 90, Loss: 0.6125
Batch 100, Loss: 0.6535
Batch 110, Loss: 0.6261
Batch 120, Loss: 0.6574
Batch 130, Loss: 0.6416
Batch 140, Loss: 0.6779
Batch 150, Loss: 0.6491
Batch 160, Loss: 0.6076
Batch 170, Loss: 0.6416
Batch 180, Loss: 0.6639
Batch 190, Loss: 0.6419
Batch 200, Loss: 0.6855
Batch 210, Loss: 0.6750
Batch 220, Loss: 0.6411
Batch 230, Loss: 0.6635
Batch 240, Loss: 0.6896
Batch 250, Loss: 0.7241
Batch 260, Loss: 0.7204
Batch 270, Loss: 0.6959
Batch 280, Loss: 0.6694
Batch 290, Loss: 0.7062
Batch 300, Loss: 0.6869
Batch 310, Loss: 0.6987
Batch 320, Loss: 0.6483
Batch 330, Loss: 0.6759
Batch 340, Loss: 0.7216
Batch 350, Loss: 0.7320
Batch 360, Loss: 0.7195
Batch 370, Loss: 0.7346
Batch 380, Loss: 0.7398
Batch 390, Loss: 0.7192
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.009968996047974 seconds
Epoch 88 accuracy: 64.96%
Batch 10, Loss: 0.6105
Batch 20, Loss: 0.6054
Batch 30, Loss: 0.5879
Batch 40, Loss: 0.5683
Batch 50, Loss: 0.5929
Batch 60, Loss: 0.5546
Batch 70, Loss: 0.5668
Batch 80, Loss: 0.6070
Batch 90, Loss: 0.6592
Batch 100, Loss: 0.6503
Batch 110, Loss: 0.6774
Batch 120, Loss: 0.6448
Batch 130, Loss: 0.6540
Batch 140, Loss: 0.6158
Batch 150, Loss: 0.5858
Batch 160, Loss: 0.6497
Batch 170, Loss: 0.7089
Batch 180, Loss: 0.6689
Batch 190, Loss: 0.6617
Batch 200, Loss: 0.6430
Batch 210, Loss: 0.6226
Batch 220, Loss: 0.6515
Batch 230, Loss: 0.6811
Batch 240, Loss: 0.6877
Batch 250, Loss: 0.6651
Batch 260, Loss: 0.6891
Batch 270, Loss: 0.6896
Batch 280, Loss: 0.6589
Batch 290, Loss: 0.6722
Batch 300, Loss: 0.6309
Batch 310, Loss: 0.7227
Batch 320, Loss: 0.6682
Batch 330, Loss: 0.6941
Batch 340, Loss: 0.7248
Batch 350, Loss: 0.7067
Batch 360, Loss: 0.7065
Batch 370, Loss: 0.6777
Batch 380, Loss: 0.7102
Batch 390, Loss: 0.7041
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.03313970565796 seconds
Epoch 89 accuracy: 65.19%
Batch 10, Loss: 0.6155
Batch 20, Loss: 0.6260
Batch 30, Loss: 0.5891
Batch 40, Loss: 0.6148
Batch 50, Loss: 0.6078
Batch 60, Loss: 0.5751
Batch 70, Loss: 0.5995
Batch 80, Loss: 0.6006
Batch 90, Loss: 0.5459
Batch 100, Loss: 0.5736
Batch 110, Loss: 0.5658
Batch 120, Loss: 0.5463
Batch 130, Loss: 0.6000
Batch 140, Loss: 0.6328
Batch 150, Loss: 0.5978
Batch 160, Loss: 0.6402
Batch 170, Loss: 0.6126
Batch 180, Loss: 0.6283
Batch 190, Loss: 0.6409
Batch 200, Loss: 0.6610
Batch 210, Loss: 0.6013
Batch 220, Loss: 0.6551
Batch 230, Loss: 0.6331
Batch 240, Loss: 0.6424
Batch 250, Loss: 0.6884
Batch 260, Loss: 0.6438
Batch 270, Loss: 0.6403
Batch 280, Loss: 0.6570
Batch 290, Loss: 0.6654
Batch 300, Loss: 0.6291
Batch 310, Loss: 0.7163
Batch 320, Loss: 0.7119
Batch 330, Loss: 0.6878
Batch 340, Loss: 0.7402
Batch 350, Loss: 0.7126
Batch 360, Loss: 0.6669
Batch 370, Loss: 0.7092
Batch 380, Loss: 0.7178
Batch 390, Loss: 0.6766
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.044075965881348 seconds
Epoch 90 accuracy: 65.57%
Batch 10, Loss: 0.5603
Batch 20, Loss: 0.5962
Batch 30, Loss: 0.5833
Batch 40, Loss: 0.5675
Batch 50, Loss: 0.6058
Batch 60, Loss: 0.5919
Batch 70, Loss: 0.6024
Batch 80, Loss: 0.5799
Batch 90, Loss: 0.6488
Batch 100, Loss: 0.6333
Batch 110, Loss: 0.6315
Batch 120, Loss: 0.6316
Batch 130, Loss: 0.6413
Batch 140, Loss: 0.6342
Batch 150, Loss: 0.6339
Batch 160, Loss: 0.6202
Batch 170, Loss: 0.6182
Batch 180, Loss: 0.5799
Batch 190, Loss: 0.6149
Batch 200, Loss: 0.6234
Batch 210, Loss: 0.6680
Batch 220, Loss: 0.6511
Batch 230, Loss: 0.5989
Batch 240, Loss: 0.6382
Batch 250, Loss: 0.6513
Batch 260, Loss: 0.6474
Batch 270, Loss: 0.6956
Batch 280, Loss: 0.6754
Batch 290, Loss: 0.6956
Batch 300, Loss: 0.6904
Batch 310, Loss: 0.6586
Batch 320, Loss: 0.6991
Batch 330, Loss: 0.6779
Batch 340, Loss: 0.7196
Batch 350, Loss: 0.7224
Batch 360, Loss: 0.7486
Batch 370, Loss: 0.6873
Batch 380, Loss: 0.7016
Batch 390, Loss: 0.7343
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.028238773345947 seconds
Epoch 91 accuracy: 65.09%
Batch 10, Loss: 0.5874
Batch 20, Loss: 0.5923
Batch 30, Loss: 0.5473
Batch 40, Loss: 0.5693
Batch 50, Loss: 0.5908
Batch 60, Loss: 0.5955
Batch 70, Loss: 0.5831
Batch 80, Loss: 0.5474
Batch 90, Loss: 0.5905
Batch 100, Loss: 0.5553
Batch 110, Loss: 0.5645
Batch 120, Loss: 0.5761
Batch 130, Loss: 0.6324
Batch 140, Loss: 0.6129
Batch 150, Loss: 0.6349
Batch 160, Loss: 0.5751
Batch 170, Loss: 0.6288
Batch 180, Loss: 0.6014
Batch 190, Loss: 0.6149
Batch 200, Loss: 0.6429
Batch 210, Loss: 0.6590
Batch 220, Loss: 0.6854
Batch 230, Loss: 0.6337
Batch 240, Loss: 0.6270
Batch 250, Loss: 0.6260
Batch 260, Loss: 0.6762
Batch 270, Loss: 0.6273
Batch 280, Loss: 0.6713
Batch 290, Loss: 0.7211
Batch 300, Loss: 0.6632
Batch 310, Loss: 0.6283
Batch 320, Loss: 0.6966
Batch 330, Loss: 0.6873
Batch 340, Loss: 0.6731
Batch 350, Loss: 0.6816
Batch 360, Loss: 0.7358
Batch 370, Loss: 0.6629
Batch 380, Loss: 0.6402
Batch 390, Loss: 0.6658
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.084146976470947 seconds
Epoch 92 accuracy: 64.33%
Batch 10, Loss: 0.6158
Batch 20, Loss: 0.5523
Batch 30, Loss: 0.5854
Batch 40, Loss: 0.5631
Batch 50, Loss: 0.6008
Batch 60, Loss: 0.5526
Batch 70, Loss: 0.5167
Batch 80, Loss: 0.5836
Batch 90, Loss: 0.5550
Batch 100, Loss: 0.5786
Batch 110, Loss: 0.5523
Batch 120, Loss: 0.5807
Batch 130, Loss: 0.5957
Batch 140, Loss: 0.6068
Batch 150, Loss: 0.5944
Batch 160, Loss: 0.6572
Batch 170, Loss: 0.6585
Batch 180, Loss: 0.6592
Batch 190, Loss: 0.6496
Batch 200, Loss: 0.6513
Batch 210, Loss: 0.6207
Batch 220, Loss: 0.6318
Batch 230, Loss: 0.6356
Batch 240, Loss: 0.6500
Batch 250, Loss: 0.6129
Batch 260, Loss: 0.6280
Batch 270, Loss: 0.6793
Batch 280, Loss: 0.6703
Batch 290, Loss: 0.6162
Batch 300, Loss: 0.6996
Batch 310, Loss: 0.6490
Batch 320, Loss: 0.6833
Batch 330, Loss: 0.7212
Batch 340, Loss: 0.6875
Batch 350, Loss: 0.6681
Batch 360, Loss: 0.6703
Batch 370, Loss: 0.6538
Batch 380, Loss: 0.6520
Batch 390, Loss: 0.6838
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.02540135383606 seconds
Epoch 93 accuracy: 63.87%
Batch 10, Loss: 0.6021
Batch 20, Loss: 0.5861
Batch 30, Loss: 0.5486
Batch 40, Loss: 0.5411
Batch 50, Loss: 0.5780
Batch 60, Loss: 0.5408
Batch 70, Loss: 0.5745
Batch 80, Loss: 0.5787
Batch 90, Loss: 0.5537
Batch 100, Loss: 0.5599
Batch 110, Loss: 0.5729
Batch 120, Loss: 0.5535
Batch 130, Loss: 0.5868
Batch 140, Loss: 0.5876
Batch 150, Loss: 0.6079
Batch 160, Loss: 0.5871
Batch 170, Loss: 0.6007
Batch 180, Loss: 0.6147
Batch 190, Loss: 0.6300
Batch 200, Loss: 0.6067
Batch 210, Loss: 0.6137
Batch 220, Loss: 0.6700
Batch 230, Loss: 0.6101
Batch 240, Loss: 0.6691
Batch 250, Loss: 0.6663
Batch 260, Loss: 0.6931
Batch 270, Loss: 0.7021
Batch 280, Loss: 0.6144
Batch 290, Loss: 0.6828
Batch 300, Loss: 0.6473
Batch 310, Loss: 0.6514
Batch 320, Loss: 0.6650
Batch 330, Loss: 0.6570
Batch 340, Loss: 0.6395
Batch 350, Loss: 0.6610
Batch 360, Loss: 0.6671
Batch 370, Loss: 0.6655
Batch 380, Loss: 0.6443
Batch 390, Loss: 0.6336
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.03086829185486 seconds
Epoch 94 accuracy: 65.78%
Batch 10, Loss: 0.5630
Batch 20, Loss: 0.5532
Batch 30, Loss: 0.5381
Batch 40, Loss: 0.5352
Batch 50, Loss: 0.5573
Batch 60, Loss: 0.5780
Batch 70, Loss: 0.5730
Batch 80, Loss: 0.5511
Batch 90, Loss: 0.5669
Batch 100, Loss: 0.5794
Batch 110, Loss: 0.5559
Batch 120, Loss: 0.5694
Batch 130, Loss: 0.5660
Batch 140, Loss: 0.5633
Batch 150, Loss: 0.5935
Batch 160, Loss: 0.5749
Batch 170, Loss: 0.5663
Batch 180, Loss: 0.5675
Batch 190, Loss: 0.5889
Batch 200, Loss: 0.6268
Batch 210, Loss: 0.6067
Batch 220, Loss: 0.6045
Batch 230, Loss: 0.5996
Batch 240, Loss: 0.6232
Batch 250, Loss: 0.6354
Batch 260, Loss: 0.6182
Batch 270, Loss: 0.6257
Batch 280, Loss: 0.6257
Batch 290, Loss: 0.6641
Batch 300, Loss: 0.5988
Batch 310, Loss: 0.6487
Batch 320, Loss: 0.6592
Batch 330, Loss: 0.6714
Batch 340, Loss: 0.6698
Batch 350, Loss: 0.6125
Batch 360, Loss: 0.6671
Batch 370, Loss: 0.6719
Batch 380, Loss: 0.6689
Batch 390, Loss: 0.6496
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 24.96945834159851 seconds
Epoch 95 accuracy: 67.92%
Batch 10, Loss: 0.5173
Batch 20, Loss: 0.5574
Batch 30, Loss: 0.5493
Batch 40, Loss: 0.5333
Batch 50, Loss: 0.5471
Batch 60, Loss: 0.5449
Batch 70, Loss: 0.5697
Batch 80, Loss: 0.5395
Batch 90, Loss: 0.5452
Batch 100, Loss: 0.5357
Batch 110, Loss: 0.5878
Batch 120, Loss: 0.5875
Batch 130, Loss: 0.6157
Batch 140, Loss: 0.6035
Batch 150, Loss: 0.5765
Batch 160, Loss: 0.6020
Batch 170, Loss: 0.5717
Batch 180, Loss: 0.5451
Batch 190, Loss: 0.6007
Batch 200, Loss: 0.5497
Batch 210, Loss: 0.6398
Batch 220, Loss: 0.6345
Batch 230, Loss: 0.5511
Batch 240, Loss: 0.5828
Batch 250, Loss: 0.5796
Batch 260, Loss: 0.5773
Batch 270, Loss: 0.5715
Batch 280, Loss: 0.5949
Batch 290, Loss: 0.6398
Batch 300, Loss: 0.6324
Batch 310, Loss: 0.6354
Batch 320, Loss: 0.6202
Batch 330, Loss: 0.6483
Batch 340, Loss: 0.6473
Batch 350, Loss: 0.6474
Batch 360, Loss: 0.6527
Batch 370, Loss: 0.6412
Batch 380, Loss: 0.6670
Batch 390, Loss: 0.6710
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.05247712135315 seconds
Epoch 96 accuracy: 65.39%
Batch 10, Loss: 0.5542
Batch 20, Loss: 0.4927
Batch 30, Loss: 0.5404
Batch 40, Loss: 0.5325
Batch 50, Loss: 0.5524
Batch 60, Loss: 0.5703
Batch 70, Loss: 0.5567
Batch 80, Loss: 0.5366
Batch 90, Loss: 0.5660
Batch 100, Loss: 0.5273
Batch 110, Loss: 0.5654
Batch 120, Loss: 0.5645
Batch 130, Loss: 0.5830
Batch 140, Loss: 0.5822
Batch 150, Loss: 0.6121
Batch 160, Loss: 0.5675
Batch 170, Loss: 0.5953
Batch 180, Loss: 0.5477
Batch 190, Loss: 0.5764
Batch 200, Loss: 0.5673
Batch 210, Loss: 0.5494
Batch 220, Loss: 0.6250
Batch 230, Loss: 0.5520
Batch 240, Loss: 0.6357
Batch 250, Loss: 0.6096
Batch 260, Loss: 0.6307
Batch 270, Loss: 0.6171
Batch 280, Loss: 0.6355
Batch 290, Loss: 0.6269
Batch 300, Loss: 0.6773
Batch 310, Loss: 0.6338
Batch 320, Loss: 0.6384
Batch 330, Loss: 0.6218
Batch 340, Loss: 0.6479
Batch 350, Loss: 0.6521
Batch 360, Loss: 0.6243
Batch 370, Loss: 0.6296
Batch 380, Loss: 0.6382
Batch 390, Loss: 0.6559
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.012015104293823 seconds
Epoch 97 accuracy: 64.35%
Batch 10, Loss: 0.5716
Batch 20, Loss: 0.5356
Batch 30, Loss: 0.5279
Batch 40, Loss: 0.5184
Batch 50, Loss: 0.5132
Batch 60, Loss: 0.5721
Batch 70, Loss: 0.5591
Batch 80, Loss: 0.5561
Batch 90, Loss: 0.5420
Batch 100, Loss: 0.5501
Batch 110, Loss: 0.5260
Batch 120, Loss: 0.5453
Batch 130, Loss: 0.5541
Batch 140, Loss: 0.5528
Batch 150, Loss: 0.5628
Batch 160, Loss: 0.5385
Batch 170, Loss: 0.5861
Batch 180, Loss: 0.6020
Batch 190, Loss: 0.5762
Batch 200, Loss: 0.5835
Batch 210, Loss: 0.5913
Batch 220, Loss: 0.6057
Batch 230, Loss: 0.5729
Batch 240, Loss: 0.5919
Batch 250, Loss: 0.5910
Batch 260, Loss: 0.5726
Batch 270, Loss: 0.5814
Batch 280, Loss: 0.5790
Batch 290, Loss: 0.6387
Batch 300, Loss: 0.6338
Batch 310, Loss: 0.6321
Batch 320, Loss: 0.6548
Batch 330, Loss: 0.5696
Batch 340, Loss: 0.6165
Batch 350, Loss: 0.6200
Batch 360, Loss: 0.6306
Batch 370, Loss: 0.6177
Batch 380, Loss: 0.6307
Batch 390, Loss: 0.6727
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.005980253219604 seconds
Epoch 98 accuracy: 66.45%
Batch 10, Loss: 0.5485
Batch 20, Loss: 0.4954
Batch 30, Loss: 0.5233
Batch 40, Loss: 0.4950
Batch 50, Loss: 0.5348
Batch 60, Loss: 0.5137
Batch 70, Loss: 0.5219
Batch 80, Loss: 0.5660
Batch 90, Loss: 0.5156
Batch 100, Loss: 0.5606
Batch 110, Loss: 0.5365
Batch 120, Loss: 0.5355
Batch 130, Loss: 0.5745
Batch 140, Loss: 0.5432
Batch 150, Loss: 0.5724
Batch 160, Loss: 0.5729
Batch 170, Loss: 0.5254
Batch 180, Loss: 0.5449
Batch 190, Loss: 0.5652
Batch 200, Loss: 0.5587
Batch 210, Loss: 0.5579
Batch 220, Loss: 0.5661
Batch 230, Loss: 0.5464
Batch 240, Loss: 0.5643
Batch 250, Loss: 0.5821
Batch 260, Loss: 0.6131
Batch 270, Loss: 0.5735
Batch 280, Loss: 0.6334
Batch 290, Loss: 0.6060
Batch 300, Loss: 0.6072
Batch 310, Loss: 0.5796
Batch 320, Loss: 0.6198
Batch 330, Loss: 0.5930
Batch 340, Loss: 0.6073
Batch 350, Loss: 0.6170
Batch 360, Loss: 0.6194
Batch 370, Loss: 0.5813
Batch 380, Loss: 0.6135
Batch 390, Loss: 0.6560
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.005420923233032 seconds
Epoch 99 accuracy: 66.2%
Batch 10, Loss: 0.5581
Batch 20, Loss: 0.5229
Batch 30, Loss: 0.4998
Batch 40, Loss: 0.4637
Batch 50, Loss: 0.5068
Batch 60, Loss: 0.5696
Batch 70, Loss: 0.5296
Batch 80, Loss: 0.5313
Batch 90, Loss: 0.5100
Batch 100, Loss: 0.5520
Batch 110, Loss: 0.5403
Batch 120, Loss: 0.5243
Batch 130, Loss: 0.5360
Batch 140, Loss: 0.5207
Batch 150, Loss: 0.5476
Batch 160, Loss: 0.5491
Batch 170, Loss: 0.5468
Batch 180, Loss: 0.5161
Batch 190, Loss: 0.5637
Batch 200, Loss: 0.5549
Batch 210, Loss: 0.6059
Batch 220, Loss: 0.5195
Batch 230, Loss: 0.5605
Batch 240, Loss: 0.5702
Batch 250, Loss: 0.5219
Batch 260, Loss: 0.6160
Batch 270, Loss: 0.5984
Batch 280, Loss: 0.5284
Batch 290, Loss: 0.6303
Batch 300, Loss: 0.6321
Batch 310, Loss: 0.6107
Batch 320, Loss: 0.5920
Batch 330, Loss: 0.6218
Batch 340, Loss: 0.6330
Batch 350, Loss: 0.6311
Batch 360, Loss: 0.5957
Batch 370, Loss: 0.6378
Batch 380, Loss: 0.5876
Batch 390, Loss: 0.6545
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.07366180419922 seconds
Epoch 100 accuracy: 64.6%
Batch 10, Loss: 0.5284
Batch 20, Loss: 0.4932
Batch 30, Loss: 0.4951
Batch 40, Loss: 0.4676
Batch 50, Loss: 0.5101
Batch 60, Loss: 0.5014
Batch 70, Loss: 0.4548
Batch 80, Loss: 0.4947
Batch 90, Loss: 0.4911
Batch 100, Loss: 0.4974
Batch 110, Loss: 0.5183
Batch 120, Loss: 0.5196
Batch 130, Loss: 0.5525
Batch 140, Loss: 0.5814
Batch 150, Loss: 0.5276
Batch 160, Loss: 0.5225
Batch 170, Loss: 0.5335
Batch 180, Loss: 0.5392
Batch 190, Loss: 0.5698
Batch 200, Loss: 0.5679
Batch 210, Loss: 0.5833
Batch 220, Loss: 0.5395
Batch 230, Loss: 0.5554
Batch 240, Loss: 0.5593
Batch 250, Loss: 0.5686
Batch 260, Loss: 0.5510
Batch 270, Loss: 0.5549
Batch 280, Loss: 0.5594
Batch 290, Loss: 0.5530
Batch 300, Loss: 0.5530
Batch 310, Loss: 0.5922
Batch 320, Loss: 0.6188
Batch 330, Loss: 0.5763
Batch 340, Loss: 0.6172
Batch 350, Loss: 0.5895
Batch 360, Loss: 0.6007
Batch 370, Loss: 0.6015
Batch 380, Loss: 0.6343
Batch 390, Loss: 0.6324
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.04293465614319 seconds
Epoch 101 accuracy: 65.2%
Batch 10, Loss: 0.5227
Batch 20, Loss: 0.5069
Batch 30, Loss: 0.4794
Batch 40, Loss: 0.4964
Batch 50, Loss: 0.4985
Batch 60, Loss: 0.5250
Batch 70, Loss: 0.5037
Batch 80, Loss: 0.4985
Batch 90, Loss: 0.5055
Batch 100, Loss: 0.4612
Batch 110, Loss: 0.4946
Batch 120, Loss: 0.5462
Batch 130, Loss: 0.5213
Batch 140, Loss: 0.5337
Batch 150, Loss: 0.5075
Batch 160, Loss: 0.5225
Batch 170, Loss: 0.5370
Batch 180, Loss: 0.5353
Batch 190, Loss: 0.5213
Batch 200, Loss: 0.5748
Batch 210, Loss: 0.5900
Batch 220, Loss: 0.5651
Batch 230, Loss: 0.6135
Batch 240, Loss: 0.5518
Batch 250, Loss: 0.5874
Batch 260, Loss: 0.6422
Batch 270, Loss: 0.5848
Batch 280, Loss: 0.6103
Batch 290, Loss: 0.5723
Batch 300, Loss: 0.5923
Batch 310, Loss: 0.5927
Batch 320, Loss: 0.6347
Batch 330, Loss: 0.5729
Batch 340, Loss: 0.5932
Batch 350, Loss: 0.5723
Batch 360, Loss: 0.5819
Batch 370, Loss: 0.6415
Batch 380, Loss: 0.5996
Batch 390, Loss: 0.6193
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 24.987797737121582 seconds
Epoch 102 accuracy: 62.64%
Batch 10, Loss: 0.5205
Batch 20, Loss: 0.4649
Batch 30, Loss: 0.4778
Batch 40, Loss: 0.4786
Batch 50, Loss: 0.5010
Batch 60, Loss: 0.4996
Batch 70, Loss: 0.4959
Batch 80, Loss: 0.4902
Batch 90, Loss: 0.5120
Batch 100, Loss: 0.4611
Batch 110, Loss: 0.4911
Batch 120, Loss: 0.5010
Batch 130, Loss: 0.5034
Batch 140, Loss: 0.4976
Batch 150, Loss: 0.5435
Batch 160, Loss: 0.5003
Batch 170, Loss: 0.5263
Batch 180, Loss: 0.5052
Batch 190, Loss: 0.5583
Batch 200, Loss: 0.5228
Batch 210, Loss: 0.5670
Batch 220, Loss: 0.5478
Batch 230, Loss: 0.5449
Batch 240, Loss: 0.6034
Batch 250, Loss: 0.5443
Batch 260, Loss: 0.5700
Batch 270, Loss: 0.5913
Batch 280, Loss: 0.5418
Batch 290, Loss: 0.5644
Batch 300, Loss: 0.6082
Batch 310, Loss: 0.5827
Batch 320, Loss: 0.6165
Batch 330, Loss: 0.5677
Batch 340, Loss: 0.5812
Batch 350, Loss: 0.5808
Batch 360, Loss: 0.5733
Batch 370, Loss: 0.5796
Batch 380, Loss: 0.6101
Batch 390, Loss: 0.5701
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.019047260284424 seconds
Epoch 103 accuracy: 66.81%
Batch 10, Loss: 0.4961
Batch 20, Loss: 0.4994
Batch 30, Loss: 0.4730
Batch 40, Loss: 0.4831
Batch 50, Loss: 0.4835
Batch 60, Loss: 0.4718
Batch 70, Loss: 0.4736
Batch 80, Loss: 0.4729
Batch 90, Loss: 0.5047
Batch 100, Loss: 0.5349
Batch 110, Loss: 0.4935
Batch 120, Loss: 0.5186
Batch 130, Loss: 0.4978
Batch 140, Loss: 0.4958
Batch 150, Loss: 0.5258
Batch 160, Loss: 0.5291
Batch 170, Loss: 0.4912
Batch 180, Loss: 0.5532
Batch 190, Loss: 0.5466
Batch 200, Loss: 0.5129
Batch 210, Loss: 0.4712
Batch 220, Loss: 0.5266
Batch 230, Loss: 0.5171
Batch 240, Loss: 0.5349
Batch 250, Loss: 0.5656
Batch 260, Loss: 0.5544
Batch 270, Loss: 0.5691
Batch 280, Loss: 0.5699
Batch 290, Loss: 0.5693
Batch 300, Loss: 0.5511
Batch 310, Loss: 0.5495
Batch 320, Loss: 0.5321
Batch 330, Loss: 0.5681
Batch 340, Loss: 0.5380
Batch 350, Loss: 0.5754
Batch 360, Loss: 0.5802
Batch 370, Loss: 0.5799
Batch 380, Loss: 0.6158
Batch 390, Loss: 0.5743
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 24.97829556465149 seconds
Epoch 104 accuracy: 65.97%
Batch 10, Loss: 0.4715
Batch 20, Loss: 0.5049
Batch 30, Loss: 0.4562
Batch 40, Loss: 0.5112
Batch 50, Loss: 0.4507
Batch 60, Loss: 0.4951
Batch 70, Loss: 0.4635
Batch 80, Loss: 0.4790
Batch 90, Loss: 0.4797
Batch 100, Loss: 0.4606
Batch 110, Loss: 0.4553
Batch 120, Loss: 0.5003
Batch 130, Loss: 0.4736
Batch 140, Loss: 0.4998
Batch 150, Loss: 0.4993
Batch 160, Loss: 0.4854
Batch 170, Loss: 0.5234
Batch 180, Loss: 0.5285
Batch 190, Loss: 0.5414
Batch 200, Loss: 0.5090
Batch 210, Loss: 0.5378
Batch 220, Loss: 0.5321
Batch 230, Loss: 0.5043
Batch 240, Loss: 0.5324
Batch 250, Loss: 0.5332
Batch 260, Loss: 0.5188
Batch 270, Loss: 0.5573
Batch 280, Loss: 0.5228
Batch 290, Loss: 0.5769
Batch 300, Loss: 0.5664
Batch 310, Loss: 0.5932
Batch 320, Loss: 0.5029
Batch 330, Loss: 0.5752
Batch 340, Loss: 0.5575
Batch 350, Loss: 0.5821
Batch 360, Loss: 0.5359
Batch 370, Loss: 0.5699
Batch 380, Loss: 0.5645
Batch 390, Loss: 0.5821
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.04197669029236 seconds
Epoch 105 accuracy: 66.47%
Batch 10, Loss: 0.4471
Batch 20, Loss: 0.4670
Batch 30, Loss: 0.4754
Batch 40, Loss: 0.4383
Batch 50, Loss: 0.4622
Batch 60, Loss: 0.4747
Batch 70, Loss: 0.4672
Batch 80, Loss: 0.4804
Batch 90, Loss: 0.4655
Batch 100, Loss: 0.4906
Batch 110, Loss: 0.4925
Batch 120, Loss: 0.4753
Batch 130, Loss: 0.5273
Batch 140, Loss: 0.5056
Batch 150, Loss: 0.4846
Batch 160, Loss: 0.5285
Batch 170, Loss: 0.5365
Batch 180, Loss: 0.5037
Batch 190, Loss: 0.4893
Batch 200, Loss: 0.4921
Batch 210, Loss: 0.5411
Batch 220, Loss: 0.5406
Batch 230, Loss: 0.5150
Batch 240, Loss: 0.4868
Batch 250, Loss: 0.5505
Batch 260, Loss: 0.5372
Batch 270, Loss: 0.5606
Batch 280, Loss: 0.5395
Batch 290, Loss: 0.5459
Batch 300, Loss: 0.5351
Batch 310, Loss: 0.5446
Batch 320, Loss: 0.5227
Batch 330, Loss: 0.5423
Batch 340, Loss: 0.5139
Batch 350, Loss: 0.5653
Batch 360, Loss: 0.5372
Batch 370, Loss: 0.5843
Batch 380, Loss: 0.5512
Batch 390, Loss: 0.5464
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 24.976282119750977 seconds
Epoch 106 accuracy: 67.13%
Batch 10, Loss: 0.5111
Batch 20, Loss: 0.4632
Batch 30, Loss: 0.4691
Batch 40, Loss: 0.4767
Batch 50, Loss: 0.4670
Batch 60, Loss: 0.4618
Batch 70, Loss: 0.4458
Batch 80, Loss: 0.4612
Batch 90, Loss: 0.4545
Batch 100, Loss: 0.4650
Batch 110, Loss: 0.4676
Batch 120, Loss: 0.4618
Batch 130, Loss: 0.5039
Batch 140, Loss: 0.4897
Batch 150, Loss: 0.5054
Batch 160, Loss: 0.5095
Batch 170, Loss: 0.5076
Batch 180, Loss: 0.5444
Batch 190, Loss: 0.4720
Batch 200, Loss: 0.5010
Batch 210, Loss: 0.4949
Batch 220, Loss: 0.4873
Batch 230, Loss: 0.5028
Batch 240, Loss: 0.4971
Batch 250, Loss: 0.5106
Batch 260, Loss: 0.4975
Batch 270, Loss: 0.4944
Batch 280, Loss: 0.4950
Batch 290, Loss: 0.5096
Batch 300, Loss: 0.5076
Batch 310, Loss: 0.5287
Batch 320, Loss: 0.5277
Batch 330, Loss: 0.5192
Batch 340, Loss: 0.5326
Batch 350, Loss: 0.5501
Batch 360, Loss: 0.5579
Batch 370, Loss: 0.5351
Batch 380, Loss: 0.5594
Batch 390, Loss: 0.5770
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.08785390853882 seconds
Epoch 107 accuracy: 66.43%
Batch 10, Loss: 0.4633
Batch 20, Loss: 0.4802
Batch 30, Loss: 0.4263
Batch 40, Loss: 0.4297
Batch 50, Loss: 0.4720
Batch 60, Loss: 0.4344
Batch 70, Loss: 0.4855
Batch 80, Loss: 0.4494
Batch 90, Loss: 0.4658
Batch 100, Loss: 0.4683
Batch 110, Loss: 0.4199
Batch 120, Loss: 0.4466
Batch 130, Loss: 0.4628
Batch 140, Loss: 0.4595
Batch 150, Loss: 0.4492
Batch 160, Loss: 0.4746
Batch 170, Loss: 0.4899
Batch 180, Loss: 0.5112
Batch 190, Loss: 0.4594
Batch 200, Loss: 0.5177
Batch 210, Loss: 0.5011
Batch 220, Loss: 0.4880
Batch 230, Loss: 0.4920
Batch 240, Loss: 0.5088
Batch 250, Loss: 0.5403
Batch 260, Loss: 0.5256
Batch 270, Loss: 0.5266
Batch 280, Loss: 0.5204
Batch 290, Loss: 0.5500
Batch 300, Loss: 0.5553
Batch 310, Loss: 0.5132
Batch 320, Loss: 0.5388
Batch 330, Loss: 0.5215
Batch 340, Loss: 0.5311
Batch 350, Loss: 0.5449
Batch 360, Loss: 0.4973
Batch 370, Loss: 0.5685
Batch 380, Loss: 0.5261
Batch 390, Loss: 0.5295
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.05901002883911 seconds
Epoch 108 accuracy: 67.39%
Batch 10, Loss: 0.4287
Batch 20, Loss: 0.4270
Batch 30, Loss: 0.4457
Batch 40, Loss: 0.4700
Batch 50, Loss: 0.4230
Batch 60, Loss: 0.4372
Batch 70, Loss: 0.4450
Batch 80, Loss: 0.4742
Batch 90, Loss: 0.4455
Batch 100, Loss: 0.4440
Batch 110, Loss: 0.4590
Batch 120, Loss: 0.4700
Batch 130, Loss: 0.4716
Batch 140, Loss: 0.4354
Batch 150, Loss: 0.4549
Batch 160, Loss: 0.4426
Batch 170, Loss: 0.4602
Batch 180, Loss: 0.4684
Batch 190, Loss: 0.4663
Batch 200, Loss: 0.5057
Batch 210, Loss: 0.4886
Batch 220, Loss: 0.5071
Batch 230, Loss: 0.4983
Batch 240, Loss: 0.4777
Batch 250, Loss: 0.5176
Batch 260, Loss: 0.5376
Batch 270, Loss: 0.5070
Batch 280, Loss: 0.5041
Batch 290, Loss: 0.4658
Batch 300, Loss: 0.5106
Batch 310, Loss: 0.4751
Batch 320, Loss: 0.5243
Batch 330, Loss: 0.5095
Batch 340, Loss: 0.5071
Batch 350, Loss: 0.5128
Batch 360, Loss: 0.5789
Batch 370, Loss: 0.5676
Batch 380, Loss: 0.5868
Batch 390, Loss: 0.5267
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.025973320007324 seconds
Epoch 109 accuracy: 63.87%
Batch 10, Loss: 0.4517
Batch 20, Loss: 0.4660
Batch 30, Loss: 0.4484
Batch 40, Loss: 0.4465
Batch 50, Loss: 0.4587
Batch 60, Loss: 0.4330
Batch 70, Loss: 0.4663
Batch 80, Loss: 0.4486
Batch 90, Loss: 0.4527
Batch 100, Loss: 0.4449
Batch 110, Loss: 0.4502
Batch 120, Loss: 0.4198
Batch 130, Loss: 0.4259
Batch 140, Loss: 0.4564
Batch 150, Loss: 0.4219
Batch 160, Loss: 0.4099
Batch 170, Loss: 0.4640
Batch 180, Loss: 0.4254
Batch 190, Loss: 0.4939
Batch 200, Loss: 0.4708
Batch 210, Loss: 0.5116
Batch 220, Loss: 0.5246
Batch 230, Loss: 0.4915
Batch 240, Loss: 0.4523
Batch 250, Loss: 0.5034
Batch 260, Loss: 0.5208
Batch 270, Loss: 0.5000
Batch 280, Loss: 0.4599
Batch 290, Loss: 0.4877
Batch 300, Loss: 0.4935
Batch 310, Loss: 0.5175
Batch 320, Loss: 0.5408
Batch 330, Loss: 0.4997
Batch 340, Loss: 0.5357
Batch 350, Loss: 0.5435
Batch 360, Loss: 0.5095
Batch 370, Loss: 0.5588
Batch 380, Loss: 0.5307
Batch 390, Loss: 0.5596
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.04730725288391 seconds
Epoch 110 accuracy: 67.43%
Batch 10, Loss: 0.4201
Batch 20, Loss: 0.4375
Batch 30, Loss: 0.4360
Batch 40, Loss: 0.4528
Batch 50, Loss: 0.3942
Batch 60, Loss: 0.4187
Batch 70, Loss: 0.4234
Batch 80, Loss: 0.4227
Batch 90, Loss: 0.4233
Batch 100, Loss: 0.4371
Batch 110, Loss: 0.4455
Batch 120, Loss: 0.4803
Batch 130, Loss: 0.4375
Batch 140, Loss: 0.4341
Batch 150, Loss: 0.4369
Batch 160, Loss: 0.4891
Batch 170, Loss: 0.4931
Batch 180, Loss: 0.4897
Batch 190, Loss: 0.4594
Batch 200, Loss: 0.4680
Batch 210, Loss: 0.4378
Batch 220, Loss: 0.4765
Batch 230, Loss: 0.4862
Batch 240, Loss: 0.4856
Batch 250, Loss: 0.5071
Batch 260, Loss: 0.5111
Batch 270, Loss: 0.5350
Batch 280, Loss: 0.4985
Batch 290, Loss: 0.5315
Batch 300, Loss: 0.5271
Batch 310, Loss: 0.4946
Batch 320, Loss: 0.5001
Batch 330, Loss: 0.4991
Batch 340, Loss: 0.5171
Batch 350, Loss: 0.5440
Batch 360, Loss: 0.5184
Batch 370, Loss: 0.4962
Batch 380, Loss: 0.5179
Batch 390, Loss: 0.5114
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.996062517166138 seconds
Epoch 111 accuracy: 65.15%
Batch 10, Loss: 0.4217
Batch 20, Loss: 0.4135
Batch 30, Loss: 0.4208
Batch 40, Loss: 0.4058
Batch 50, Loss: 0.4110
Batch 60, Loss: 0.3829
Batch 70, Loss: 0.4197
Batch 80, Loss: 0.4064
Batch 90, Loss: 0.4134
Batch 100, Loss: 0.4172
Batch 110, Loss: 0.4807
Batch 120, Loss: 0.4144
Batch 130, Loss: 0.4953
Batch 140, Loss: 0.4282
Batch 150, Loss: 0.4512
Batch 160, Loss: 0.4348
Batch 170, Loss: 0.4180
Batch 180, Loss: 0.4967
Batch 190, Loss: 0.4795
Batch 200, Loss: 0.4746
Batch 210, Loss: 0.4749
Batch 220, Loss: 0.4524
Batch 230, Loss: 0.4608
Batch 240, Loss: 0.4441
Batch 250, Loss: 0.4604
Batch 260, Loss: 0.4967
Batch 270, Loss: 0.5038
Batch 280, Loss: 0.4820
Batch 290, Loss: 0.4920
Batch 300, Loss: 0.5016
Batch 310, Loss: 0.5044
Batch 320, Loss: 0.4616
Batch 330, Loss: 0.5380
Batch 340, Loss: 0.4872
Batch 350, Loss: 0.5035
Batch 360, Loss: 0.5020
Batch 370, Loss: 0.5820
Batch 380, Loss: 0.5108
Batch 390, Loss: 0.5326
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 24.992623329162598 seconds
Epoch 112 accuracy: 67.47%
Batch 10, Loss: 0.4253
Batch 20, Loss: 0.4261
Batch 30, Loss: 0.4138
Batch 40, Loss: 0.3920
Batch 50, Loss: 0.4326
Batch 60, Loss: 0.3856
Batch 70, Loss: 0.4144
Batch 80, Loss: 0.4027
Batch 90, Loss: 0.4611
Batch 100, Loss: 0.3842
Batch 110, Loss: 0.4172
Batch 120, Loss: 0.4010
Batch 130, Loss: 0.4203
Batch 140, Loss: 0.4355
Batch 150, Loss: 0.4281
Batch 160, Loss: 0.4648
Batch 170, Loss: 0.4404
Batch 180, Loss: 0.4599
Batch 190, Loss: 0.4219
Batch 200, Loss: 0.4400
Batch 210, Loss: 0.4380
Batch 220, Loss: 0.4328
Batch 230, Loss: 0.4579
Batch 240, Loss: 0.4422
Batch 250, Loss: 0.4288
Batch 260, Loss: 0.4502
Batch 270, Loss: 0.4505
Batch 280, Loss: 0.4752
Batch 290, Loss: 0.4860
Batch 300, Loss: 0.4749
Batch 310, Loss: 0.4715
Batch 320, Loss: 0.4842
Batch 330, Loss: 0.4700
Batch 340, Loss: 0.4875
Batch 350, Loss: 0.5330
Batch 360, Loss: 0.5146
Batch 370, Loss: 0.4767
Batch 380, Loss: 0.5094
Batch 390, Loss: 0.5295
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.022414207458496 seconds
Epoch 113 accuracy: 68.1%
Batch 10, Loss: 0.4215
Batch 20, Loss: 0.3926
Batch 30, Loss: 0.4107
Batch 40, Loss: 0.4271
Batch 50, Loss: 0.3853
Batch 60, Loss: 0.4204
Batch 70, Loss: 0.3746
Batch 80, Loss: 0.4231
Batch 90, Loss: 0.3887
Batch 100, Loss: 0.4397
Batch 110, Loss: 0.3854
Batch 120, Loss: 0.4364
Batch 130, Loss: 0.4017
Batch 140, Loss: 0.4290
Batch 150, Loss: 0.4162
Batch 160, Loss: 0.4099
Batch 170, Loss: 0.3980
Batch 180, Loss: 0.4257
Batch 190, Loss: 0.4021
Batch 200, Loss: 0.4177
Batch 210, Loss: 0.4506
Batch 220, Loss: 0.4575
Batch 230, Loss: 0.4628
Batch 240, Loss: 0.4402
Batch 250, Loss: 0.4796
Batch 260, Loss: 0.4520
Batch 270, Loss: 0.4655
Batch 280, Loss: 0.4898
Batch 290, Loss: 0.4631
Batch 300, Loss: 0.4657
Batch 310, Loss: 0.5044
Batch 320, Loss: 0.5093
Batch 330, Loss: 0.4867
Batch 340, Loss: 0.4506
Batch 350, Loss: 0.4899
Batch 360, Loss: 0.5051
Batch 370, Loss: 0.5015
Batch 380, Loss: 0.5081
Batch 390, Loss: 0.4882
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.01395893096924 seconds
Epoch 114 accuracy: 67.32%
Batch 10, Loss: 0.4387
Batch 20, Loss: 0.4172
Batch 30, Loss: 0.3977
Batch 40, Loss: 0.3867
Batch 50, Loss: 0.4281
Batch 60, Loss: 0.3870
Batch 70, Loss: 0.4030
Batch 80, Loss: 0.4236
Batch 90, Loss: 0.3964
Batch 100, Loss: 0.4144
Batch 110, Loss: 0.4075
Batch 120, Loss: 0.4010
Batch 130, Loss: 0.3823
Batch 140, Loss: 0.4127
Batch 150, Loss: 0.4247
Batch 160, Loss: 0.4394
Batch 170, Loss: 0.4357
Batch 180, Loss: 0.4504
Batch 190, Loss: 0.4130
Batch 200, Loss: 0.4298
Batch 210, Loss: 0.4067
Batch 220, Loss: 0.4439
Batch 230, Loss: 0.4242
Batch 240, Loss: 0.4496
Batch 250, Loss: 0.4214
Batch 260, Loss: 0.4207
Batch 270, Loss: 0.4456
Batch 280, Loss: 0.4243
Batch 290, Loss: 0.4638
Batch 300, Loss: 0.4761
Batch 310, Loss: 0.4723
Batch 320, Loss: 0.4092
Batch 330, Loss: 0.4589
Batch 340, Loss: 0.4364
Batch 350, Loss: 0.4830
Batch 360, Loss: 0.4463
Batch 370, Loss: 0.4719
Batch 380, Loss: 0.4677
Batch 390, Loss: 0.4502
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.043819904327393 seconds
Epoch 115 accuracy: 68.23%
Batch 10, Loss: 0.4025
Batch 20, Loss: 0.4011
Batch 30, Loss: 0.3658
Batch 40, Loss: 0.3956
Batch 50, Loss: 0.3886
Batch 60, Loss: 0.3812
Batch 70, Loss: 0.4002
Batch 80, Loss: 0.3710
Batch 90, Loss: 0.3983
Batch 100, Loss: 0.4009
Batch 110, Loss: 0.4211
Batch 120, Loss: 0.4137
Batch 130, Loss: 0.4208
Batch 140, Loss: 0.3969
Batch 150, Loss: 0.4205
Batch 160, Loss: 0.4367
Batch 170, Loss: 0.4225
Batch 180, Loss: 0.4236
Batch 190, Loss: 0.4350
Batch 200, Loss: 0.4692
Batch 210, Loss: 0.4151
Batch 220, Loss: 0.4424
Batch 230, Loss: 0.4227
Batch 240, Loss: 0.4707
Batch 250, Loss: 0.4403
Batch 260, Loss: 0.4161
Batch 270, Loss: 0.4307
Batch 280, Loss: 0.4636
Batch 290, Loss: 0.4305
Batch 300, Loss: 0.4464
Batch 310, Loss: 0.4645
Batch 320, Loss: 0.4382
Batch 330, Loss: 0.4604
Batch 340, Loss: 0.4709
Batch 350, Loss: 0.4491
Batch 360, Loss: 0.4430
Batch 370, Loss: 0.4890
Batch 380, Loss: 0.5012
Batch 390, Loss: 0.5034
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.067053079605103 seconds
Epoch 116 accuracy: 67.97%
Batch 10, Loss: 0.3781
Batch 20, Loss: 0.3679
Batch 30, Loss: 0.4001
Batch 40, Loss: 0.3746
Batch 50, Loss: 0.4085
Batch 60, Loss: 0.3603
Batch 70, Loss: 0.3667
Batch 80, Loss: 0.3881
Batch 90, Loss: 0.4015
Batch 100, Loss: 0.3801
Batch 110, Loss: 0.3625
Batch 120, Loss: 0.3722
Batch 130, Loss: 0.3590
Batch 140, Loss: 0.3553
Batch 150, Loss: 0.4086
Batch 160, Loss: 0.4108
Batch 170, Loss: 0.3903
Batch 180, Loss: 0.4039
Batch 190, Loss: 0.4219
Batch 200, Loss: 0.4145
Batch 210, Loss: 0.4029
Batch 220, Loss: 0.3781
Batch 230, Loss: 0.4047
Batch 240, Loss: 0.3979
Batch 250, Loss: 0.3973
Batch 260, Loss: 0.4140
Batch 270, Loss: 0.4359
Batch 280, Loss: 0.4134
Batch 290, Loss: 0.4314
Batch 300, Loss: 0.4908
Batch 310, Loss: 0.4281
Batch 320, Loss: 0.4416
Batch 330, Loss: 0.4605
Batch 340, Loss: 0.4651
Batch 350, Loss: 0.4765
Batch 360, Loss: 0.4578
Batch 370, Loss: 0.4733
Batch 380, Loss: 0.4975
Batch 390, Loss: 0.4821
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.039249897003174 seconds
Epoch 117 accuracy: 67.49%
Batch 10, Loss: 0.3615
Batch 20, Loss: 0.3931
Batch 30, Loss: 0.3798
Batch 40, Loss: 0.3619
Batch 50, Loss: 0.3667
Batch 60, Loss: 0.3558
Batch 70, Loss: 0.3883
Batch 80, Loss: 0.3816
Batch 90, Loss: 0.3506
Batch 100, Loss: 0.4098
Batch 110, Loss: 0.3796
Batch 120, Loss: 0.3619
Batch 130, Loss: 0.3853
Batch 140, Loss: 0.3726
Batch 150, Loss: 0.3599
Batch 160, Loss: 0.3526
Batch 170, Loss: 0.4206
Batch 180, Loss: 0.4035
Batch 190, Loss: 0.3979
Batch 200, Loss: 0.4068
Batch 210, Loss: 0.3847
Batch 220, Loss: 0.4266
Batch 230, Loss: 0.4187
Batch 240, Loss: 0.4297
Batch 250, Loss: 0.4125
Batch 260, Loss: 0.4113
Batch 270, Loss: 0.4097
Batch 280, Loss: 0.4036
Batch 290, Loss: 0.4292
Batch 300, Loss: 0.4323
Batch 310, Loss: 0.4351
Batch 320, Loss: 0.4387
Batch 330, Loss: 0.4575
Batch 340, Loss: 0.4476
Batch 350, Loss: 0.4431
Batch 360, Loss: 0.4443
Batch 370, Loss: 0.4440
Batch 380, Loss: 0.4709
Batch 390, Loss: 0.4514
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.09577703475952 seconds
Epoch 118 accuracy: 67.07%
Batch 10, Loss: 0.3952
Batch 20, Loss: 0.3359
Batch 30, Loss: 0.3402
Batch 40, Loss: 0.3322
Batch 50, Loss: 0.3393
Batch 60, Loss: 0.3480
Batch 70, Loss: 0.3625
Batch 80, Loss: 0.3732
Batch 90, Loss: 0.4036
Batch 100, Loss: 0.3541
Batch 110, Loss: 0.3791
Batch 120, Loss: 0.3568
Batch 130, Loss: 0.3623
Batch 140, Loss: 0.3629
Batch 150, Loss: 0.3536
Batch 160, Loss: 0.3724
Batch 170, Loss: 0.3676
Batch 180, Loss: 0.3921
Batch 190, Loss: 0.4175
Batch 200, Loss: 0.3809
Batch 210, Loss: 0.4250
Batch 220, Loss: 0.4146
Batch 230, Loss: 0.4168
Batch 240, Loss: 0.4018
Batch 250, Loss: 0.4069
Batch 260, Loss: 0.3880
Batch 270, Loss: 0.4074
Batch 280, Loss: 0.4109
Batch 290, Loss: 0.4133
Batch 300, Loss: 0.4628
Batch 310, Loss: 0.4155
Batch 320, Loss: 0.4586
Batch 330, Loss: 0.3950
Batch 340, Loss: 0.4027
Batch 350, Loss: 0.3905
Batch 360, Loss: 0.4204
Batch 370, Loss: 0.4316
Batch 380, Loss: 0.4486
Batch 390, Loss: 0.4550
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 24.99656343460083 seconds
Epoch 119 accuracy: 68.32%
Batch 10, Loss: 0.3806
Batch 20, Loss: 0.3734
Batch 30, Loss: 0.3690
Batch 40, Loss: 0.3552
Batch 50, Loss: 0.3293
Batch 60, Loss: 0.3496
Batch 70, Loss: 0.3269
Batch 80, Loss: 0.3599
Batch 90, Loss: 0.3445
Batch 100, Loss: 0.3690
Batch 110, Loss: 0.3585
Batch 120, Loss: 0.3725
Batch 130, Loss: 0.3627
Batch 140, Loss: 0.3774
Batch 150, Loss: 0.3604
Batch 160, Loss: 0.3710
Batch 170, Loss: 0.3899
Batch 180, Loss: 0.3640
Batch 190, Loss: 0.3572
Batch 200, Loss: 0.3754
Batch 210, Loss: 0.3815
Batch 220, Loss: 0.3762
Batch 230, Loss: 0.3932
Batch 240, Loss: 0.3797
Batch 250, Loss: 0.4052
Batch 260, Loss: 0.3878
Batch 270, Loss: 0.4063
Batch 280, Loss: 0.4413
Batch 290, Loss: 0.4234
Batch 300, Loss: 0.4101
Batch 310, Loss: 0.4345
Batch 320, Loss: 0.4177
Batch 330, Loss: 0.4359
Batch 340, Loss: 0.4370
Batch 350, Loss: 0.4469
Batch 360, Loss: 0.4225
Batch 370, Loss: 0.4121
Batch 380, Loss: 0.4329
Batch 390, Loss: 0.4254
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 24.998520135879517 seconds
Epoch 120 accuracy: 67.44%
Batch 10, Loss: 0.3767
Batch 20, Loss: 0.3698
Batch 30, Loss: 0.3231
Batch 40, Loss: 0.3635
Batch 50, Loss: 0.3504
Batch 60, Loss: 0.3036
Batch 70, Loss: 0.3309
Batch 80, Loss: 0.3515
Batch 90, Loss: 0.3406
Batch 100, Loss: 0.3481
Batch 110, Loss: 0.3477
Batch 120, Loss: 0.3728
Batch 130, Loss: 0.3454
Batch 140, Loss: 0.3538
Batch 150, Loss: 0.3608
Batch 160, Loss: 0.3590
Batch 170, Loss: 0.3653
Batch 180, Loss: 0.3838
Batch 190, Loss: 0.3754
Batch 200, Loss: 0.3598
Batch 210, Loss: 0.3741
Batch 220, Loss: 0.3919
Batch 230, Loss: 0.3647
Batch 240, Loss: 0.3903
Batch 250, Loss: 0.3636
Batch 260, Loss: 0.3795
Batch 270, Loss: 0.3695
Batch 280, Loss: 0.3758
Batch 290, Loss: 0.3890
Batch 300, Loss: 0.4029
Batch 310, Loss: 0.4214
Batch 320, Loss: 0.3964
Batch 330, Loss: 0.4231
Batch 340, Loss: 0.4202
Batch 350, Loss: 0.3987
Batch 360, Loss: 0.4751
Batch 370, Loss: 0.4260
Batch 380, Loss: 0.3964
Batch 390, Loss: 0.4417
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.02293872833252 seconds
Epoch 121 accuracy: 69.22%
Batch 10, Loss: 0.3598
Batch 20, Loss: 0.3682
Batch 30, Loss: 0.3361
Batch 40, Loss: 0.3411
Batch 50, Loss: 0.3558
Batch 60, Loss: 0.3325
Batch 70, Loss: 0.3689
Batch 80, Loss: 0.3376
Batch 90, Loss: 0.3434
Batch 100, Loss: 0.3805
Batch 110, Loss: 0.3231
Batch 120, Loss: 0.3574
Batch 130, Loss: 0.3718
Batch 140, Loss: 0.3335
Batch 150, Loss: 0.3593
Batch 160, Loss: 0.3497
Batch 170, Loss: 0.3495
Batch 180, Loss: 0.4142
Batch 190, Loss: 0.3748
Batch 200, Loss: 0.3712
Batch 210, Loss: 0.3832
Batch 220, Loss: 0.3909
Batch 230, Loss: 0.4338
Batch 240, Loss: 0.4049
Batch 250, Loss: 0.3628
Batch 260, Loss: 0.3703
Batch 270, Loss: 0.3830
Batch 280, Loss: 0.3898
Batch 290, Loss: 0.4233
Batch 300, Loss: 0.4006
Batch 310, Loss: 0.4048
Batch 320, Loss: 0.3993
Batch 330, Loss: 0.4236
Batch 340, Loss: 0.4114
Batch 350, Loss: 0.3985
Batch 360, Loss: 0.4146
Batch 370, Loss: 0.4442
Batch 380, Loss: 0.4110
Batch 390, Loss: 0.4224
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.029349088668823 seconds
Epoch 122 accuracy: 69.54%
Batch 10, Loss: 0.3490
Batch 20, Loss: 0.3698
Batch 30, Loss: 0.3218
Batch 40, Loss: 0.3109
Batch 50, Loss: 0.3223
Batch 60, Loss: 0.3128
Batch 70, Loss: 0.3043
Batch 80, Loss: 0.3246
Batch 90, Loss: 0.3312
Batch 100, Loss: 0.3438
Batch 110, Loss: 0.3009
Batch 120, Loss: 0.3261
Batch 130, Loss: 0.3470
Batch 140, Loss: 0.3535
Batch 150, Loss: 0.3519
Batch 160, Loss: 0.3574
Batch 170, Loss: 0.3564
Batch 180, Loss: 0.3487
Batch 190, Loss: 0.3406
Batch 200, Loss: 0.3294
Batch 210, Loss: 0.3593
Batch 220, Loss: 0.3491
Batch 230, Loss: 0.3776
Batch 240, Loss: 0.3695
Batch 250, Loss: 0.3727
Batch 260, Loss: 0.3648
Batch 270, Loss: 0.3873
Batch 280, Loss: 0.4052
Batch 290, Loss: 0.3626
Batch 300, Loss: 0.3961
Batch 310, Loss: 0.3786
Batch 320, Loss: 0.3745
Batch 330, Loss: 0.3843
Batch 340, Loss: 0.4016
Batch 350, Loss: 0.3856
Batch 360, Loss: 0.4047
Batch 370, Loss: 0.3918
Batch 380, Loss: 0.4232
Batch 390, Loss: 0.4212
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.014580488204956 seconds
Epoch 123 accuracy: 69.45%
Batch 10, Loss: 0.3360
Batch 20, Loss: 0.3306
Batch 30, Loss: 0.3039
Batch 40, Loss: 0.3191
Batch 50, Loss: 0.3103
Batch 60, Loss: 0.3157
Batch 70, Loss: 0.3415
Batch 80, Loss: 0.3174
Batch 90, Loss: 0.3162
Batch 100, Loss: 0.3284
Batch 110, Loss: 0.3377
Batch 120, Loss: 0.3170
Batch 130, Loss: 0.3105
Batch 140, Loss: 0.3247
Batch 150, Loss: 0.3230
Batch 160, Loss: 0.3337
Batch 170, Loss: 0.3558
Batch 180, Loss: 0.3380
Batch 190, Loss: 0.3275
Batch 200, Loss: 0.3414
Batch 210, Loss: 0.3835
Batch 220, Loss: 0.3698
Batch 230, Loss: 0.3531
Batch 240, Loss: 0.3696
Batch 250, Loss: 0.3622
Batch 260, Loss: 0.3548
Batch 270, Loss: 0.3301
Batch 280, Loss: 0.4040
Batch 290, Loss: 0.3725
Batch 300, Loss: 0.4036
Batch 310, Loss: 0.3730
Batch 320, Loss: 0.3770
Batch 330, Loss: 0.3706
Batch 340, Loss: 0.4110
Batch 350, Loss: 0.4287
Batch 360, Loss: 0.3644
Batch 370, Loss: 0.3850
Batch 380, Loss: 0.3946
Batch 390, Loss: 0.4054
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.020511865615845 seconds
Epoch 124 accuracy: 69.75%
Batch 10, Loss: 0.3230
Batch 20, Loss: 0.3122
Batch 30, Loss: 0.3425
Batch 40, Loss: 0.3322
Batch 50, Loss: 0.2934
Batch 60, Loss: 0.3171
Batch 70, Loss: 0.3058
Batch 80, Loss: 0.3279
Batch 90, Loss: 0.2997
Batch 100, Loss: 0.3035
Batch 110, Loss: 0.3354
Batch 120, Loss: 0.3368
Batch 130, Loss: 0.3252
Batch 140, Loss: 0.3256
Batch 150, Loss: 0.3422
Batch 160, Loss: 0.3577
Batch 170, Loss: 0.3448
Batch 180, Loss: 0.3307
Batch 190, Loss: 0.3566
Batch 200, Loss: 0.3372
Batch 210, Loss: 0.3724
Batch 220, Loss: 0.3434
Batch 230, Loss: 0.3568
Batch 240, Loss: 0.3664
Batch 250, Loss: 0.3671
Batch 260, Loss: 0.3652
Batch 270, Loss: 0.3835
Batch 280, Loss: 0.3523
Batch 290, Loss: 0.3427
Batch 300, Loss: 0.3531
Batch 310, Loss: 0.3572
Batch 320, Loss: 0.3662
Batch 330, Loss: 0.3769
Batch 340, Loss: 0.3811
Batch 350, Loss: 0.3915
Batch 360, Loss: 0.3822
Batch 370, Loss: 0.3918
Batch 380, Loss: 0.3522
Batch 390, Loss: 0.3666
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.00354790687561 seconds
Epoch 125 accuracy: 70.38%
Batch 10, Loss: 0.3041
Batch 20, Loss: 0.3078
Batch 30, Loss: 0.3086
Batch 40, Loss: 0.3103
Batch 50, Loss: 0.2943
Batch 60, Loss: 0.2792
Batch 70, Loss: 0.2873
Batch 80, Loss: 0.3061
Batch 90, Loss: 0.2974
Batch 100, Loss: 0.2815
Batch 110, Loss: 0.2923
Batch 120, Loss: 0.2787
Batch 130, Loss: 0.3027
Batch 140, Loss: 0.3040
Batch 150, Loss: 0.3433
Batch 160, Loss: 0.3099
Batch 170, Loss: 0.3035
Batch 180, Loss: 0.3224
Batch 190, Loss: 0.3310
Batch 200, Loss: 0.3195
Batch 210, Loss: 0.3338
Batch 220, Loss: 0.3218
Batch 230, Loss: 0.3268
Batch 240, Loss: 0.3319
Batch 250, Loss: 0.3411
Batch 260, Loss: 0.3388
Batch 270, Loss: 0.3372
Batch 280, Loss: 0.3217
Batch 290, Loss: 0.3367
Batch 300, Loss: 0.3294
Batch 310, Loss: 0.3659
Batch 320, Loss: 0.3369
Batch 330, Loss: 0.3464
Batch 340, Loss: 0.3547
Batch 350, Loss: 0.3481
Batch 360, Loss: 0.3888
Batch 370, Loss: 0.3462
Batch 380, Loss: 0.3862
Batch 390, Loss: 0.3877
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.013044595718384 seconds
Epoch 126 accuracy: 68.36%
Batch 10, Loss: 0.2954
Batch 20, Loss: 0.2992
Batch 30, Loss: 0.3042
Batch 40, Loss: 0.2886
Batch 50, Loss: 0.2971
Batch 60, Loss: 0.2981
Batch 70, Loss: 0.2883
Batch 80, Loss: 0.2937
Batch 90, Loss: 0.3123
Batch 100, Loss: 0.2869
Batch 110, Loss: 0.2939
Batch 120, Loss: 0.2983
Batch 130, Loss: 0.3060
Batch 140, Loss: 0.3341
Batch 150, Loss: 0.2972
Batch 160, Loss: 0.2982
Batch 170, Loss: 0.3212
Batch 180, Loss: 0.3052
Batch 190, Loss: 0.3024
Batch 200, Loss: 0.3219
Batch 210, Loss: 0.3020
Batch 220, Loss: 0.3382
Batch 230, Loss: 0.3019
Batch 240, Loss: 0.3542
Batch 250, Loss: 0.3174
Batch 260, Loss: 0.3201
Batch 270, Loss: 0.3034
Batch 280, Loss: 0.3458
Batch 290, Loss: 0.3344
Batch 300, Loss: 0.3367
Batch 310, Loss: 0.3175
Batch 320, Loss: 0.3339
Batch 330, Loss: 0.3223
Batch 340, Loss: 0.3703
Batch 350, Loss: 0.3483
Batch 360, Loss: 0.3779
Batch 370, Loss: 0.3668
Batch 380, Loss: 0.3611
Batch 390, Loss: 0.4142
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.03916835784912 seconds
Epoch 127 accuracy: 69.32%
Batch 10, Loss: 0.3114
Batch 20, Loss: 0.2824
Batch 30, Loss: 0.3008
Batch 40, Loss: 0.2819
Batch 50, Loss: 0.2887
Batch 60, Loss: 0.2571
Batch 70, Loss: 0.3188
Batch 80, Loss: 0.3060
Batch 90, Loss: 0.2824
Batch 100, Loss: 0.2509
Batch 110, Loss: 0.2904
Batch 120, Loss: 0.2877
Batch 130, Loss: 0.2667
Batch 140, Loss: 0.2839
Batch 150, Loss: 0.2759
Batch 160, Loss: 0.3091
Batch 170, Loss: 0.2993
Batch 180, Loss: 0.3087
Batch 190, Loss: 0.3174
Batch 200, Loss: 0.3080
Batch 210, Loss: 0.2928
Batch 220, Loss: 0.3241
Batch 230, Loss: 0.3185
Batch 240, Loss: 0.3425
Batch 250, Loss: 0.3102
Batch 260, Loss: 0.3457
Batch 270, Loss: 0.3448
Batch 280, Loss: 0.3206
Batch 290, Loss: 0.3468
Batch 300, Loss: 0.3492
Batch 310, Loss: 0.3395
Batch 320, Loss: 0.3141
Batch 330, Loss: 0.3544
Batch 340, Loss: 0.3504
Batch 350, Loss: 0.3708
Batch 360, Loss: 0.3436
Batch 370, Loss: 0.3655
Batch 380, Loss: 0.3437
Batch 390, Loss: 0.3607
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.032249212265015 seconds
Epoch 128 accuracy: 70.33%
Batch 10, Loss: 0.2998
Batch 20, Loss: 0.2932
Batch 30, Loss: 0.2949
Batch 40, Loss: 0.2974
Batch 50, Loss: 0.2668
Batch 60, Loss: 0.2924
Batch 70, Loss: 0.2899
Batch 80, Loss: 0.2852
Batch 90, Loss: 0.2863
Batch 100, Loss: 0.2756
Batch 110, Loss: 0.2895
Batch 120, Loss: 0.3007
Batch 130, Loss: 0.2878
Batch 140, Loss: 0.3257
Batch 150, Loss: 0.2959
Batch 160, Loss: 0.3071
Batch 170, Loss: 0.3112
Batch 180, Loss: 0.2910
Batch 190, Loss: 0.3390
Batch 200, Loss: 0.2985
Batch 210, Loss: 0.3098
Batch 220, Loss: 0.2832
Batch 230, Loss: 0.3259
Batch 240, Loss: 0.3151
Batch 250, Loss: 0.3169
Batch 260, Loss: 0.3203
Batch 270, Loss: 0.3338
Batch 280, Loss: 0.3015
Batch 290, Loss: 0.3107
Batch 300, Loss: 0.3276
Batch 310, Loss: 0.3086
Batch 320, Loss: 0.3189
Batch 330, Loss: 0.3466
Batch 340, Loss: 0.3434
Batch 350, Loss: 0.3409
Batch 360, Loss: 0.3605
Batch 370, Loss: 0.3437
Batch 380, Loss: 0.3402
Batch 390, Loss: 0.3798
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.001686334609985 seconds
Epoch 129 accuracy: 70.63%
Batch 10, Loss: 0.2979
Batch 20, Loss: 0.2924
Batch 30, Loss: 0.2810
Batch 40, Loss: 0.2594
Batch 50, Loss: 0.2578
Batch 60, Loss: 0.2961
Batch 70, Loss: 0.2652
Batch 80, Loss: 0.2888
Batch 90, Loss: 0.2705
Batch 100, Loss: 0.2970
Batch 110, Loss: 0.2679
Batch 120, Loss: 0.2867
Batch 130, Loss: 0.2734
Batch 140, Loss: 0.2748
Batch 150, Loss: 0.2898
Batch 160, Loss: 0.2774
Batch 170, Loss: 0.2690
Batch 180, Loss: 0.2955
Batch 190, Loss: 0.2890
Batch 200, Loss: 0.2759
Batch 210, Loss: 0.2811
Batch 220, Loss: 0.2922
Batch 230, Loss: 0.3103
Batch 240, Loss: 0.2982
Batch 250, Loss: 0.3143
Batch 260, Loss: 0.3044
Batch 270, Loss: 0.3405
Batch 280, Loss: 0.3108
Batch 290, Loss: 0.3259
Batch 300, Loss: 0.3223
Batch 310, Loss: 0.3325
Batch 320, Loss: 0.2898
Batch 330, Loss: 0.3135
Batch 340, Loss: 0.3285
Batch 350, Loss: 0.3238
Batch 360, Loss: 0.3402
Batch 370, Loss: 0.3313
Batch 380, Loss: 0.3435
Batch 390, Loss: 0.3522
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.0150625705719 seconds
Epoch 130 accuracy: 70.4%
Batch 10, Loss: 0.3024
Batch 20, Loss: 0.2994
Batch 30, Loss: 0.2672
Batch 40, Loss: 0.2554
Batch 50, Loss: 0.2463
Batch 60, Loss: 0.2426
Batch 70, Loss: 0.2669
Batch 80, Loss: 0.2700
Batch 90, Loss: 0.2927
Batch 100, Loss: 0.2818
Batch 110, Loss: 0.2694
Batch 120, Loss: 0.2696
Batch 130, Loss: 0.2869
Batch 140, Loss: 0.2697
Batch 150, Loss: 0.2808
Batch 160, Loss: 0.2749
Batch 170, Loss: 0.2757
Batch 180, Loss: 0.2907
Batch 190, Loss: 0.2676
Batch 200, Loss: 0.2775
Batch 210, Loss: 0.2880
Batch 220, Loss: 0.2874
Batch 230, Loss: 0.2911
Batch 240, Loss: 0.2557
Batch 250, Loss: 0.2859
Batch 260, Loss: 0.3051
Batch 270, Loss: 0.2806
Batch 280, Loss: 0.2701
Batch 290, Loss: 0.2915
Batch 300, Loss: 0.3357
Batch 310, Loss: 0.3070
Batch 320, Loss: 0.2908
Batch 330, Loss: 0.3200
Batch 340, Loss: 0.3112
Batch 350, Loss: 0.3329
Batch 360, Loss: 0.3052
Batch 370, Loss: 0.3035
Batch 380, Loss: 0.2994
Batch 390, Loss: 0.3273
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.021685123443604 seconds
Epoch 131 accuracy: 70.39%
Batch 10, Loss: 0.2573
Batch 20, Loss: 0.2717
Batch 30, Loss: 0.2541
Batch 40, Loss: 0.2627
Batch 50, Loss: 0.2599
Batch 60, Loss: 0.2503
Batch 70, Loss: 0.2533
Batch 80, Loss: 0.2465
Batch 90, Loss: 0.2473
Batch 100, Loss: 0.2492
Batch 110, Loss: 0.2495
Batch 120, Loss: 0.2673
Batch 130, Loss: 0.2684
Batch 140, Loss: 0.2495
Batch 150, Loss: 0.2331
Batch 160, Loss: 0.2361
Batch 170, Loss: 0.2564
Batch 180, Loss: 0.2451
Batch 190, Loss: 0.2476
Batch 200, Loss: 0.2568
Batch 210, Loss: 0.2442
Batch 220, Loss: 0.2814
Batch 230, Loss: 0.2628
Batch 240, Loss: 0.2615
Batch 250, Loss: 0.2851
Batch 260, Loss: 0.2717
Batch 270, Loss: 0.2692
Batch 280, Loss: 0.2586
Batch 290, Loss: 0.2589
Batch 300, Loss: 0.2731
Batch 310, Loss: 0.2630
Batch 320, Loss: 0.2820
Batch 330, Loss: 0.2967
Batch 340, Loss: 0.2895
Batch 350, Loss: 0.3024
Batch 360, Loss: 0.2844
Batch 370, Loss: 0.3090
Batch 380, Loss: 0.3098
Batch 390, Loss: 0.3194
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.018630981445312 seconds
Epoch 132 accuracy: 70.62%
Batch 10, Loss: 0.2515
Batch 20, Loss: 0.2642
Batch 30, Loss: 0.2432
Batch 40, Loss: 0.2258
Batch 50, Loss: 0.2693
Batch 60, Loss: 0.2414
Batch 70, Loss: 0.2626
Batch 80, Loss: 0.2558
Batch 90, Loss: 0.2647
Batch 100, Loss: 0.2366
Batch 110, Loss: 0.2415
Batch 120, Loss: 0.2482
Batch 130, Loss: 0.2601
Batch 140, Loss: 0.2439
Batch 150, Loss: 0.2635
Batch 160, Loss: 0.2568
Batch 170, Loss: 0.2693
Batch 180, Loss: 0.2543
Batch 190, Loss: 0.2637
Batch 200, Loss: 0.2505
Batch 210, Loss: 0.2712
Batch 220, Loss: 0.2760
Batch 230, Loss: 0.2882
Batch 240, Loss: 0.2639
Batch 250, Loss: 0.2642
Batch 260, Loss: 0.2883
Batch 270, Loss: 0.2843
Batch 280, Loss: 0.2754
Batch 290, Loss: 0.2800
Batch 300, Loss: 0.2699
Batch 310, Loss: 0.2884
Batch 320, Loss: 0.2907
Batch 330, Loss: 0.2794
Batch 340, Loss: 0.2809
Batch 350, Loss: 0.2998
Batch 360, Loss: 0.2993
Batch 370, Loss: 0.3005
Batch 380, Loss: 0.3022
Batch 390, Loss: 0.3319
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 24.979151248931885 seconds
Epoch 133 accuracy: 69.91%
Batch 10, Loss: 0.2560
Batch 20, Loss: 0.2499
Batch 30, Loss: 0.2429
Batch 40, Loss: 0.2461
Batch 50, Loss: 0.2365
Batch 60, Loss: 0.2221
Batch 70, Loss: 0.2336
Batch 80, Loss: 0.2387
Batch 90, Loss: 0.2444
Batch 100, Loss: 0.2497
Batch 110, Loss: 0.2630
Batch 120, Loss: 0.2480
Batch 130, Loss: 0.2508
Batch 140, Loss: 0.2295
Batch 150, Loss: 0.2389
Batch 160, Loss: 0.2478
Batch 170, Loss: 0.2414
Batch 180, Loss: 0.2634
Batch 190, Loss: 0.2465
Batch 200, Loss: 0.2593
Batch 210, Loss: 0.2379
Batch 220, Loss: 0.2559
Batch 230, Loss: 0.2512
Batch 240, Loss: 0.2539
Batch 250, Loss: 0.2581
Batch 260, Loss: 0.2697
Batch 270, Loss: 0.2675
Batch 280, Loss: 0.2625
Batch 290, Loss: 0.2586
Batch 300, Loss: 0.2645
Batch 310, Loss: 0.2822
Batch 320, Loss: 0.2809
Batch 330, Loss: 0.2711
Batch 340, Loss: 0.3092
Batch 350, Loss: 0.2956
Batch 360, Loss: 0.2684
Batch 370, Loss: 0.2929
Batch 380, Loss: 0.3053
Batch 390, Loss: 0.3162
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.056199312210083 seconds
Epoch 134 accuracy: 70.69%
Batch 10, Loss: 0.2292
Batch 20, Loss: 0.2530
Batch 30, Loss: 0.2381
Batch 40, Loss: 0.2540
Batch 50, Loss: 0.2416
Batch 60, Loss: 0.2445
Batch 70, Loss: 0.2317
Batch 80, Loss: 0.2408
Batch 90, Loss: 0.2115
Batch 100, Loss: 0.2251
Batch 110, Loss: 0.2373
Batch 120, Loss: 0.2250
Batch 130, Loss: 0.2340
Batch 140, Loss: 0.2347
Batch 150, Loss: 0.2503
Batch 160, Loss: 0.2549
Batch 170, Loss: 0.2430
Batch 180, Loss: 0.2368
Batch 190, Loss: 0.2327
Batch 200, Loss: 0.2663
Batch 210, Loss: 0.2389
Batch 220, Loss: 0.2675
Batch 230, Loss: 0.2568
Batch 240, Loss: 0.2722
Batch 250, Loss: 0.2568
Batch 260, Loss: 0.2834
Batch 270, Loss: 0.2551
Batch 280, Loss: 0.2352
Batch 290, Loss: 0.2413
Batch 300, Loss: 0.2647
Batch 310, Loss: 0.2746
Batch 320, Loss: 0.2865
Batch 330, Loss: 0.2794
Batch 340, Loss: 0.2479
Batch 350, Loss: 0.2889
Batch 360, Loss: 0.2771
Batch 370, Loss: 0.2919
Batch 380, Loss: 0.2862
Batch 390, Loss: 0.2920
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.006404876708984 seconds
Epoch 135 accuracy: 71.97%
Batch 10, Loss: 0.2350
Batch 20, Loss: 0.2612
Batch 30, Loss: 0.2255
Batch 40, Loss: 0.2332
Batch 50, Loss: 0.2244
Batch 60, Loss: 0.2338
Batch 70, Loss: 0.2193
Batch 80, Loss: 0.2162
Batch 90, Loss: 0.2443
Batch 100, Loss: 0.2242
Batch 110, Loss: 0.2292
Batch 120, Loss: 0.2293
Batch 130, Loss: 0.2316
Batch 140, Loss: 0.2320
Batch 150, Loss: 0.2315
Batch 160, Loss: 0.2352
Batch 170, Loss: 0.2177
Batch 180, Loss: 0.2380
Batch 190, Loss: 0.2369
Batch 200, Loss: 0.2336
Batch 210, Loss: 0.2483
Batch 220, Loss: 0.2407
Batch 230, Loss: 0.2433
Batch 240, Loss: 0.2547
Batch 250, Loss: 0.2415
Batch 260, Loss: 0.2281
Batch 270, Loss: 0.2297
Batch 280, Loss: 0.2477
Batch 290, Loss: 0.2718
Batch 300, Loss: 0.2537
Batch 310, Loss: 0.2644
Batch 320, Loss: 0.2455
Batch 330, Loss: 0.2256
Batch 340, Loss: 0.2653
Batch 350, Loss: 0.2421
Batch 360, Loss: 0.2691
Batch 370, Loss: 0.2569
Batch 380, Loss: 0.2665
Batch 390, Loss: 0.2978
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.017818689346313 seconds
Epoch 136 accuracy: 71.88%
Batch 10, Loss: 0.2441
Batch 20, Loss: 0.2266
Batch 30, Loss: 0.2397
Batch 40, Loss: 0.2149
Batch 50, Loss: 0.2415
Batch 60, Loss: 0.2297
Batch 70, Loss: 0.2141
Batch 80, Loss: 0.2142
Batch 90, Loss: 0.2405
Batch 100, Loss: 0.2150
Batch 110, Loss: 0.2112
Batch 120, Loss: 0.2205
Batch 130, Loss: 0.2244
Batch 140, Loss: 0.2359
Batch 150, Loss: 0.2226
Batch 160, Loss: 0.2253
Batch 170, Loss: 0.2292
Batch 180, Loss: 0.2331
Batch 190, Loss: 0.2141
Batch 200, Loss: 0.2244
Batch 210, Loss: 0.2061
Batch 220, Loss: 0.2271
Batch 230, Loss: 0.2180
Batch 240, Loss: 0.2309
Batch 250, Loss: 0.2433
Batch 260, Loss: 0.2569
Batch 270, Loss: 0.2337
Batch 280, Loss: 0.2540
Batch 290, Loss: 0.2298
Batch 300, Loss: 0.2348
Batch 310, Loss: 0.2819
Batch 320, Loss: 0.2647
Batch 330, Loss: 0.2356
Batch 340, Loss: 0.2447
Batch 350, Loss: 0.2512
Batch 360, Loss: 0.2533
Batch 370, Loss: 0.2757
Batch 380, Loss: 0.2272
Batch 390, Loss: 0.2703
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.048988580703735 seconds
Epoch 137 accuracy: 70.81%
Batch 10, Loss: 0.2660
Batch 20, Loss: 0.2234
Batch 30, Loss: 0.2196
Batch 40, Loss: 0.2073
Batch 50, Loss: 0.2090
Batch 60, Loss: 0.2141
Batch 70, Loss: 0.2076
Batch 80, Loss: 0.2057
Batch 90, Loss: 0.2321
Batch 100, Loss: 0.1920
Batch 110, Loss: 0.2079
Batch 120, Loss: 0.1983
Batch 130, Loss: 0.2140
Batch 140, Loss: 0.2380
Batch 150, Loss: 0.2272
Batch 160, Loss: 0.2207
Batch 170, Loss: 0.2248
Batch 180, Loss: 0.2237
Batch 190, Loss: 0.2283
Batch 200, Loss: 0.2119
Batch 210, Loss: 0.2398
Batch 220, Loss: 0.2296
Batch 230, Loss: 0.2412
Batch 240, Loss: 0.2283
Batch 250, Loss: 0.2136
Batch 260, Loss: 0.2430
Batch 270, Loss: 0.2102
Batch 280, Loss: 0.2461
Batch 290, Loss: 0.2355
Batch 300, Loss: 0.2235
Batch 310, Loss: 0.2259
Batch 320, Loss: 0.2288
Batch 330, Loss: 0.2476
Batch 340, Loss: 0.2516
Batch 350, Loss: 0.2552
Batch 360, Loss: 0.2427
Batch 370, Loss: 0.2545
Batch 380, Loss: 0.2381
Batch 390, Loss: 0.2481
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.03381109237671 seconds
Epoch 138 accuracy: 71.37%
Batch 10, Loss: 0.2143
Batch 20, Loss: 0.2003
Batch 30, Loss: 0.2049
Batch 40, Loss: 0.2002
Batch 50, Loss: 0.1941
Batch 60, Loss: 0.1890
Batch 70, Loss: 0.1747
Batch 80, Loss: 0.1956
Batch 90, Loss: 0.2155
Batch 100, Loss: 0.1895
Batch 110, Loss: 0.2189
Batch 120, Loss: 0.2161
Batch 130, Loss: 0.2229
Batch 140, Loss: 0.2147
Batch 150, Loss: 0.2089
Batch 160, Loss: 0.2079
Batch 170, Loss: 0.2174
Batch 180, Loss: 0.2097
Batch 190, Loss: 0.2415
Batch 200, Loss: 0.2158
Batch 210, Loss: 0.2226
Batch 220, Loss: 0.2268
Batch 230, Loss: 0.2001
Batch 240, Loss: 0.2413
Batch 250, Loss: 0.2401
Batch 260, Loss: 0.2203
Batch 270, Loss: 0.2152
Batch 280, Loss: 0.2200
Batch 290, Loss: 0.2155
Batch 300, Loss: 0.2348
Batch 310, Loss: 0.2149
Batch 320, Loss: 0.2335
Batch 330, Loss: 0.2219
Batch 340, Loss: 0.1899
Batch 350, Loss: 0.2428
Batch 360, Loss: 0.2275
Batch 370, Loss: 0.2374
Batch 380, Loss: 0.2498
Batch 390, Loss: 0.2277
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.01416802406311 seconds
Epoch 139 accuracy: 72.39%
Batch 10, Loss: 0.1986
Batch 20, Loss: 0.2047
Batch 30, Loss: 0.2195
Batch 40, Loss: 0.1934
Batch 50, Loss: 0.1949
Batch 60, Loss: 0.2193
Batch 70, Loss: 0.2257
Batch 80, Loss: 0.2073
Batch 90, Loss: 0.1980
Batch 100, Loss: 0.1928
Batch 110, Loss: 0.1956
Batch 120, Loss: 0.2037
Batch 130, Loss: 0.1969
Batch 140, Loss: 0.2127
Batch 150, Loss: 0.1928
Batch 160, Loss: 0.2112
Batch 170, Loss: 0.2008
Batch 180, Loss: 0.2189
Batch 190, Loss: 0.2162
Batch 200, Loss: 0.1990
Batch 210, Loss: 0.2274
Batch 220, Loss: 0.2064
Batch 230, Loss: 0.2213
Batch 240, Loss: 0.2226
Batch 250, Loss: 0.2248
Batch 260, Loss: 0.2084
Batch 270, Loss: 0.2209
Batch 280, Loss: 0.2163
Batch 290, Loss: 0.2189
Batch 300, Loss: 0.2139
Batch 310, Loss: 0.2054
Batch 320, Loss: 0.2141
Batch 330, Loss: 0.2203
Batch 340, Loss: 0.2249
Batch 350, Loss: 0.2481
Batch 360, Loss: 0.2320
Batch 370, Loss: 0.2338
Batch 380, Loss: 0.2278
Batch 390, Loss: 0.2331
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.014124155044556 seconds
Epoch 140 accuracy: 72.95%
Batch 10, Loss: 0.1910
Batch 20, Loss: 0.1863
Batch 30, Loss: 0.2005
Batch 40, Loss: 0.2014
Batch 50, Loss: 0.1823
Batch 60, Loss: 0.1875
Batch 70, Loss: 0.1820
Batch 80, Loss: 0.2082
Batch 90, Loss: 0.1933
Batch 100, Loss: 0.2046
Batch 110, Loss: 0.1736
Batch 120, Loss: 0.1818
Batch 130, Loss: 0.1779
Batch 140, Loss: 0.1809
Batch 150, Loss: 0.1781
Batch 160, Loss: 0.1882
Batch 170, Loss: 0.1935
Batch 180, Loss: 0.2073
Batch 190, Loss: 0.1861
Batch 200, Loss: 0.1843
Batch 210, Loss: 0.2071
Batch 220, Loss: 0.2057
Batch 230, Loss: 0.1909
Batch 240, Loss: 0.2167
Batch 250, Loss: 0.2140
Batch 260, Loss: 0.1939
Batch 270, Loss: 0.2075
Batch 280, Loss: 0.2013
Batch 290, Loss: 0.2126
Batch 300, Loss: 0.2320
Batch 310, Loss: 0.2188
Batch 320, Loss: 0.2078
Batch 330, Loss: 0.2107
Batch 340, Loss: 0.2330
Batch 350, Loss: 0.2334
Batch 360, Loss: 0.2188
Batch 370, Loss: 0.2260
Batch 380, Loss: 0.2415
Batch 390, Loss: 0.2145
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.040916681289673 seconds
Epoch 141 accuracy: 71.99%
Batch 10, Loss: 0.1946
Batch 20, Loss: 0.2186
Batch 30, Loss: 0.2022
Batch 40, Loss: 0.1780
Batch 50, Loss: 0.1890
Batch 60, Loss: 0.1805
Batch 70, Loss: 0.1816
Batch 80, Loss: 0.1849
Batch 90, Loss: 0.1853
Batch 100, Loss: 0.1809
Batch 110, Loss: 0.2024
Batch 120, Loss: 0.1844
Batch 130, Loss: 0.1863
Batch 140, Loss: 0.1863
Batch 150, Loss: 0.2229
Batch 160, Loss: 0.2047
Batch 170, Loss: 0.1934
Batch 180, Loss: 0.1904
Batch 190, Loss: 0.2005
Batch 200, Loss: 0.1842
Batch 210, Loss: 0.2031
Batch 220, Loss: 0.2065
Batch 230, Loss: 0.1988
Batch 240, Loss: 0.1955
Batch 250, Loss: 0.2038
Batch 260, Loss: 0.2297
Batch 270, Loss: 0.2080
Batch 280, Loss: 0.1960
Batch 290, Loss: 0.2011
Batch 300, Loss: 0.2123
Batch 310, Loss: 0.2204
Batch 320, Loss: 0.2108
Batch 330, Loss: 0.2180
Batch 340, Loss: 0.2192
Batch 350, Loss: 0.2237
Batch 360, Loss: 0.2070
Batch 370, Loss: 0.2379
Batch 380, Loss: 0.2030
Batch 390, Loss: 0.2157
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 24.97706151008606 seconds
Epoch 142 accuracy: 71.8%
Batch 10, Loss: 0.1878
Batch 20, Loss: 0.1833
Batch 30, Loss: 0.1927
Batch 40, Loss: 0.1932
Batch 50, Loss: 0.1713
Batch 60, Loss: 0.1839
Batch 70, Loss: 0.1750
Batch 80, Loss: 0.1900
Batch 90, Loss: 0.1697
Batch 100, Loss: 0.1777
Batch 110, Loss: 0.1885
Batch 120, Loss: 0.1768
Batch 130, Loss: 0.1786
Batch 140, Loss: 0.1771
Batch 150, Loss: 0.1668
Batch 160, Loss: 0.1837
Batch 170, Loss: 0.1921
Batch 180, Loss: 0.1645
Batch 190, Loss: 0.1722
Batch 200, Loss: 0.1988
Batch 210, Loss: 0.1673
Batch 220, Loss: 0.1765
Batch 230, Loss: 0.1983
Batch 240, Loss: 0.1740
Batch 250, Loss: 0.1856
Batch 260, Loss: 0.1879
Batch 270, Loss: 0.1996
Batch 280, Loss: 0.1958
Batch 290, Loss: 0.1974
Batch 300, Loss: 0.1906
Batch 310, Loss: 0.1892
Batch 320, Loss: 0.1899
Batch 330, Loss: 0.1878
Batch 340, Loss: 0.2050
Batch 350, Loss: 0.2145
Batch 360, Loss: 0.2069
Batch 370, Loss: 0.2093
Batch 380, Loss: 0.2016
Batch 390, Loss: 0.2133
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.0731999874115 seconds
Epoch 143 accuracy: 72.85%
Batch 10, Loss: 0.1761
Batch 20, Loss: 0.1813
Batch 30, Loss: 0.1686
Batch 40, Loss: 0.1644
Batch 50, Loss: 0.1652
Batch 60, Loss: 0.1563
Batch 70, Loss: 0.1787
Batch 80, Loss: 0.1586
Batch 90, Loss: 0.1600
Batch 100, Loss: 0.1772
Batch 110, Loss: 0.1574
Batch 120, Loss: 0.1651
Batch 130, Loss: 0.1723
Batch 140, Loss: 0.1672
Batch 150, Loss: 0.1694
Batch 160, Loss: 0.1681
Batch 170, Loss: 0.1755
Batch 180, Loss: 0.1778
Batch 190, Loss: 0.1749
Batch 200, Loss: 0.1982
Batch 210, Loss: 0.1832
Batch 220, Loss: 0.1866
Batch 230, Loss: 0.1776
Batch 240, Loss: 0.1932
Batch 250, Loss: 0.1978
Batch 260, Loss: 0.2030
Batch 270, Loss: 0.1981
Batch 280, Loss: 0.1882
Batch 290, Loss: 0.1970
Batch 300, Loss: 0.1915
Batch 310, Loss: 0.1940
Batch 320, Loss: 0.1999
Batch 330, Loss: 0.1920
Batch 340, Loss: 0.2044
Batch 350, Loss: 0.2085
Batch 360, Loss: 0.2057
Batch 370, Loss: 0.1946
Batch 380, Loss: 0.2201
Batch 390, Loss: 0.1724
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.025801420211792 seconds
Epoch 144 accuracy: 73.05%
Batch 10, Loss: 0.1704
Batch 20, Loss: 0.1640
Batch 30, Loss: 0.1555
Batch 40, Loss: 0.1617
Batch 50, Loss: 0.1698
Batch 60, Loss: 0.1711
Batch 70, Loss: 0.1657
Batch 80, Loss: 0.1618
Batch 90, Loss: 0.1678
Batch 100, Loss: 0.1672
Batch 110, Loss: 0.1602
Batch 120, Loss: 0.1666
Batch 130, Loss: 0.1656
Batch 140, Loss: 0.1788
Batch 150, Loss: 0.1616
Batch 160, Loss: 0.1464
Batch 170, Loss: 0.1641
Batch 180, Loss: 0.1703
Batch 190, Loss: 0.1750
Batch 200, Loss: 0.1718
Batch 210, Loss: 0.1703
Batch 220, Loss: 0.1715
Batch 230, Loss: 0.1602
Batch 240, Loss: 0.1690
Batch 250, Loss: 0.1725
Batch 260, Loss: 0.1938
Batch 270, Loss: 0.1726
Batch 280, Loss: 0.1638
Batch 290, Loss: 0.1695
Batch 300, Loss: 0.1688
Batch 310, Loss: 0.1728
Batch 320, Loss: 0.1938
Batch 330, Loss: 0.1766
Batch 340, Loss: 0.1964
Batch 350, Loss: 0.1786
Batch 360, Loss: 0.1769
Batch 370, Loss: 0.1906
Batch 380, Loss: 0.1829
Batch 390, Loss: 0.1782
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.035911083221436 seconds
Epoch 145 accuracy: 72.03%
Batch 10, Loss: 0.1475
Batch 20, Loss: 0.1671
Batch 30, Loss: 0.1716
Batch 40, Loss: 0.1604
Batch 50, Loss: 0.1517
Batch 60, Loss: 0.1544
Batch 70, Loss: 0.1584
Batch 80, Loss: 0.1532
Batch 90, Loss: 0.1648
Batch 100, Loss: 0.1539
Batch 110, Loss: 0.1510
Batch 120, Loss: 0.1661
Batch 130, Loss: 0.1539
Batch 140, Loss: 0.1471
Batch 150, Loss: 0.1709
Batch 160, Loss: 0.1543
Batch 170, Loss: 0.1596
Batch 180, Loss: 0.1732
Batch 190, Loss: 0.1627
Batch 200, Loss: 0.1778
Batch 210, Loss: 0.1736
Batch 220, Loss: 0.1745
Batch 230, Loss: 0.1716
Batch 240, Loss: 0.1790
Batch 250, Loss: 0.1694
Batch 260, Loss: 0.1748
Batch 270, Loss: 0.1678
Batch 280, Loss: 0.1750
Batch 290, Loss: 0.1639
Batch 300, Loss: 0.1712
Batch 310, Loss: 0.1759
Batch 320, Loss: 0.1722
Batch 330, Loss: 0.1720
Batch 340, Loss: 0.1790
Batch 350, Loss: 0.1901
Batch 360, Loss: 0.1944
Batch 370, Loss: 0.1817
Batch 380, Loss: 0.1637
Batch 390, Loss: 0.1819
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.042714595794678 seconds
Epoch 146 accuracy: 72.14%
Batch 10, Loss: 0.1581
Batch 20, Loss: 0.1582
Batch 30, Loss: 0.1421
Batch 40, Loss: 0.1600
Batch 50, Loss: 0.1474
Batch 60, Loss: 0.1560
Batch 70, Loss: 0.1589
Batch 80, Loss: 0.1472
Batch 90, Loss: 0.1814
Batch 100, Loss: 0.1571
Batch 110, Loss: 0.1604
Batch 120, Loss: 0.1656
Batch 130, Loss: 0.1700
Batch 140, Loss: 0.1378
Batch 150, Loss: 0.1537
Batch 160, Loss: 0.1557
Batch 170, Loss: 0.1691
Batch 180, Loss: 0.1661
Batch 190, Loss: 0.1493
Batch 200, Loss: 0.1560
Batch 210, Loss: 0.1527
Batch 220, Loss: 0.1848
Batch 230, Loss: 0.1582
Batch 240, Loss: 0.1753
Batch 250, Loss: 0.1615
Batch 260, Loss: 0.1635
Batch 270, Loss: 0.1546
Batch 280, Loss: 0.1506
Batch 290, Loss: 0.1594
Batch 300, Loss: 0.1602
Batch 310, Loss: 0.1536
Batch 320, Loss: 0.1613
Batch 330, Loss: 0.1744
Batch 340, Loss: 0.1658
Batch 350, Loss: 0.1607
Batch 360, Loss: 0.1897
Batch 370, Loss: 0.1752
Batch 380, Loss: 0.1643
Batch 390, Loss: 0.1763
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.028185606002808 seconds
Epoch 147 accuracy: 72.72%
Batch 10, Loss: 0.1594
Batch 20, Loss: 0.1613
Batch 30, Loss: 0.1529
Batch 40, Loss: 0.1466
Batch 50, Loss: 0.1314
Batch 60, Loss: 0.1464
Batch 70, Loss: 0.1468
Batch 80, Loss: 0.1327
Batch 90, Loss: 0.1353
Batch 100, Loss: 0.1438
Batch 110, Loss: 0.1448
Batch 120, Loss: 0.1479
Batch 130, Loss: 0.1561
Batch 140, Loss: 0.1448
Batch 150, Loss: 0.1308
Batch 160, Loss: 0.1420
Batch 170, Loss: 0.1413
Batch 180, Loss: 0.1574
Batch 190, Loss: 0.1521
Batch 200, Loss: 0.1553
Batch 210, Loss: 0.1433
Batch 220, Loss: 0.1647
Batch 230, Loss: 0.1551
Batch 240, Loss: 0.1471
Batch 250, Loss: 0.1503
Batch 260, Loss: 0.1460
Batch 270, Loss: 0.1435
Batch 280, Loss: 0.1492
Batch 290, Loss: 0.1486
Batch 300, Loss: 0.1641
Batch 310, Loss: 0.1777
Batch 320, Loss: 0.1502
Batch 330, Loss: 0.1627
Batch 340, Loss: 0.1542
Batch 350, Loss: 0.1645
Batch 360, Loss: 0.1427
Batch 370, Loss: 0.1651
Batch 380, Loss: 0.1715
Batch 390, Loss: 0.1467
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 24.973315477371216 seconds
Epoch 148 accuracy: 72.51%
Batch 10, Loss: 0.1418
Batch 20, Loss: 0.1356
Batch 30, Loss: 0.1426
Batch 40, Loss: 0.1324
Batch 50, Loss: 0.1363
Batch 60, Loss: 0.1439
Batch 70, Loss: 0.1335
Batch 80, Loss: 0.1443
Batch 90, Loss: 0.1315
Batch 100, Loss: 0.1305
Batch 110, Loss: 0.1197
Batch 120, Loss: 0.1435
Batch 130, Loss: 0.1480
Batch 140, Loss: 0.1433
Batch 150, Loss: 0.1467
Batch 160, Loss: 0.1381
Batch 170, Loss: 0.1390
Batch 180, Loss: 0.1355
Batch 190, Loss: 0.1578
Batch 200, Loss: 0.1398
Batch 210, Loss: 0.1542
Batch 220, Loss: 0.1329
Batch 230, Loss: 0.1454
Batch 240, Loss: 0.1484
Batch 250, Loss: 0.1486
Batch 260, Loss: 0.1495
Batch 270, Loss: 0.1301
Batch 280, Loss: 0.1516
Batch 290, Loss: 0.1460
Batch 300, Loss: 0.1733
Batch 310, Loss: 0.1528
Batch 320, Loss: 0.1476
Batch 330, Loss: 0.1592
Batch 340, Loss: 0.1664
Batch 350, Loss: 0.1867
Batch 360, Loss: 0.1483
Batch 370, Loss: 0.1609
Batch 380, Loss: 0.1441
Batch 390, Loss: 0.1530
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 24.999607801437378 seconds
Epoch 149 accuracy: 74.08%
Batch 10, Loss: 0.1340
Batch 20, Loss: 0.1352
Batch 30, Loss: 0.1335
Batch 40, Loss: 0.1315
Batch 50, Loss: 0.1253
Batch 60, Loss: 0.1320
Batch 70, Loss: 0.1346
Batch 80, Loss: 0.1209
Batch 90, Loss: 0.1220
Batch 100, Loss: 0.1345
Batch 110, Loss: 0.1326
Batch 120, Loss: 0.1290
Batch 130, Loss: 0.1240
Batch 140, Loss: 0.1264
Batch 150, Loss: 0.1442
Batch 160, Loss: 0.1351
Batch 170, Loss: 0.1408
Batch 180, Loss: 0.1416
Batch 190, Loss: 0.1293
Batch 200, Loss: 0.1394
Batch 210, Loss: 0.1442
Batch 220, Loss: 0.1336
Batch 230, Loss: 0.1289
Batch 240, Loss: 0.1303
Batch 250, Loss: 0.1448
Batch 260, Loss: 0.1531
Batch 270, Loss: 0.1408
Batch 280, Loss: 0.1335
Batch 290, Loss: 0.1322
Batch 300, Loss: 0.1355
Batch 310, Loss: 0.1299
Batch 320, Loss: 0.1335
Batch 330, Loss: 0.1462
Batch 340, Loss: 0.1531
Batch 350, Loss: 0.1444
Batch 360, Loss: 0.1442
Batch 370, Loss: 0.1520
Batch 380, Loss: 0.1532
Batch 390, Loss: 0.1582
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.085166454315186 seconds
Epoch 150 accuracy: 73.3%
Batch 10, Loss: 0.1165
Batch 20, Loss: 0.1206
Batch 30, Loss: 0.1223
Batch 40, Loss: 0.1214
Batch 50, Loss: 0.1212
Batch 60, Loss: 0.1199
Batch 70, Loss: 0.1223
Batch 80, Loss: 0.1230
Batch 90, Loss: 0.1215
Batch 100, Loss: 0.1212
Batch 110, Loss: 0.1133
Batch 120, Loss: 0.1156
Batch 130, Loss: 0.1206
Batch 140, Loss: 0.1160
Batch 150, Loss: 0.1170
Batch 160, Loss: 0.1304
Batch 170, Loss: 0.1130
Batch 180, Loss: 0.1274
Batch 190, Loss: 0.1198
Batch 200, Loss: 0.1374
Batch 210, Loss: 0.1372
Batch 220, Loss: 0.1269
Batch 230, Loss: 0.1335
Batch 240, Loss: 0.1325
Batch 250, Loss: 0.1371
Batch 260, Loss: 0.1278
Batch 270, Loss: 0.1234
Batch 280, Loss: 0.1293
Batch 290, Loss: 0.1355
Batch 300, Loss: 0.1247
Batch 310, Loss: 0.1557
Batch 320, Loss: 0.1429
Batch 330, Loss: 0.1402
Batch 340, Loss: 0.1432
Batch 350, Loss: 0.1460
Batch 360, Loss: 0.1381
Batch 370, Loss: 0.1500
Batch 380, Loss: 0.1278
Batch 390, Loss: 0.1379
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.025968551635742 seconds
Epoch 151 accuracy: 74.42%
Batch 10, Loss: 0.1217
Batch 20, Loss: 0.1162
Batch 30, Loss: 0.1106
Batch 40, Loss: 0.1168
Batch 50, Loss: 0.1235
Batch 60, Loss: 0.1188
Batch 70, Loss: 0.1170
Batch 80, Loss: 0.1216
Batch 90, Loss: 0.1225
Batch 100, Loss: 0.1174
Batch 110, Loss: 0.1209
Batch 120, Loss: 0.1179
Batch 130, Loss: 0.1106
Batch 140, Loss: 0.1232
Batch 150, Loss: 0.1165
Batch 160, Loss: 0.1216
Batch 170, Loss: 0.1142
Batch 180, Loss: 0.1107
Batch 190, Loss: 0.1335
Batch 200, Loss: 0.1094
Batch 210, Loss: 0.1167
Batch 220, Loss: 0.1151
Batch 230, Loss: 0.1268
Batch 240, Loss: 0.1352
Batch 250, Loss: 0.1223
Batch 260, Loss: 0.1421
Batch 270, Loss: 0.1139
Batch 280, Loss: 0.1257
Batch 290, Loss: 0.1258
Batch 300, Loss: 0.1327
Batch 310, Loss: 0.1175
Batch 320, Loss: 0.1387
Batch 330, Loss: 0.1285
Batch 340, Loss: 0.1292
Batch 350, Loss: 0.1316
Batch 360, Loss: 0.1277
Batch 370, Loss: 0.1402
Batch 380, Loss: 0.1316
Batch 390, Loss: 0.1430
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 24.986576080322266 seconds
Epoch 152 accuracy: 74.69%
Batch 10, Loss: 0.1231
Batch 20, Loss: 0.1160
Batch 30, Loss: 0.1116
Batch 40, Loss: 0.1150
Batch 50, Loss: 0.1076
Batch 60, Loss: 0.0986
Batch 70, Loss: 0.1200
Batch 80, Loss: 0.1043
Batch 90, Loss: 0.1190
Batch 100, Loss: 0.1173
Batch 110, Loss: 0.1018
Batch 120, Loss: 0.1081
Batch 130, Loss: 0.1064
Batch 140, Loss: 0.1141
Batch 150, Loss: 0.1053
Batch 160, Loss: 0.1169
Batch 170, Loss: 0.1196
Batch 180, Loss: 0.1078
Batch 190, Loss: 0.1124
Batch 200, Loss: 0.1319
Batch 210, Loss: 0.1165
Batch 220, Loss: 0.1234
Batch 230, Loss: 0.1181
Batch 240, Loss: 0.1189
Batch 250, Loss: 0.1070
Batch 260, Loss: 0.1104
Batch 270, Loss: 0.1098
Batch 280, Loss: 0.1118
Batch 290, Loss: 0.1245
Batch 300, Loss: 0.1154
Batch 310, Loss: 0.1169
Batch 320, Loss: 0.1081
Batch 330, Loss: 0.1174
Batch 340, Loss: 0.1146
Batch 350, Loss: 0.1229
Batch 360, Loss: 0.1209
Batch 370, Loss: 0.1193
Batch 380, Loss: 0.1162
Batch 390, Loss: 0.1109
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.020644664764404 seconds
Epoch 153 accuracy: 74.54%
Batch 10, Loss: 0.1178
Batch 20, Loss: 0.1028
Batch 30, Loss: 0.1097
Batch 40, Loss: 0.0993
Batch 50, Loss: 0.0987
Batch 60, Loss: 0.1125
Batch 70, Loss: 0.1038
Batch 80, Loss: 0.1045
Batch 90, Loss: 0.1023
Batch 100, Loss: 0.0931
Batch 110, Loss: 0.1175
Batch 120, Loss: 0.1056
Batch 130, Loss: 0.1055
Batch 140, Loss: 0.0993
Batch 150, Loss: 0.1055
Batch 160, Loss: 0.1112
Batch 170, Loss: 0.1099
Batch 180, Loss: 0.1067
Batch 190, Loss: 0.1149
Batch 200, Loss: 0.1171
Batch 210, Loss: 0.1115
Batch 220, Loss: 0.1071
Batch 230, Loss: 0.1166
Batch 240, Loss: 0.1115
Batch 250, Loss: 0.1097
Batch 260, Loss: 0.1150
Batch 270, Loss: 0.1123
Batch 280, Loss: 0.1125
Batch 290, Loss: 0.1079
Batch 300, Loss: 0.1157
Batch 310, Loss: 0.1142
Batch 320, Loss: 0.1192
Batch 330, Loss: 0.1083
Batch 340, Loss: 0.1126
Batch 350, Loss: 0.1215
Batch 360, Loss: 0.1160
Batch 370, Loss: 0.1282
Batch 380, Loss: 0.1114
Batch 390, Loss: 0.1156
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.029212713241577 seconds
Epoch 154 accuracy: 74.67%
Batch 10, Loss: 0.1061
Batch 20, Loss: 0.1090
Batch 30, Loss: 0.1008
Batch 40, Loss: 0.1067
Batch 50, Loss: 0.1043
Batch 60, Loss: 0.1096
Batch 70, Loss: 0.1010
Batch 80, Loss: 0.1085
Batch 90, Loss: 0.0899
Batch 100, Loss: 0.0977
Batch 110, Loss: 0.0971
Batch 120, Loss: 0.1081
Batch 130, Loss: 0.1058
Batch 140, Loss: 0.1006
Batch 150, Loss: 0.1022
Batch 160, Loss: 0.1007
Batch 170, Loss: 0.1134
Batch 180, Loss: 0.0895
Batch 190, Loss: 0.1072
Batch 200, Loss: 0.0954
Batch 210, Loss: 0.1008
Batch 220, Loss: 0.1026
Batch 230, Loss: 0.0991
Batch 240, Loss: 0.1064
Batch 250, Loss: 0.1040
Batch 260, Loss: 0.1118
Batch 270, Loss: 0.1009
Batch 280, Loss: 0.0982
Batch 290, Loss: 0.0992
Batch 300, Loss: 0.1079
Batch 310, Loss: 0.0980
Batch 320, Loss: 0.1011
Batch 330, Loss: 0.1026
Batch 340, Loss: 0.1214
Batch 350, Loss: 0.0966
Batch 360, Loss: 0.1047
Batch 370, Loss: 0.1080
Batch 380, Loss: 0.1269
Batch 390, Loss: 0.1093
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.005335330963135 seconds
Epoch 155 accuracy: 74.48%
Batch 10, Loss: 0.0942
Batch 20, Loss: 0.1022
Batch 30, Loss: 0.1006
Batch 40, Loss: 0.0920
Batch 50, Loss: 0.0889
Batch 60, Loss: 0.0949
Batch 70, Loss: 0.0930
Batch 80, Loss: 0.1016
Batch 90, Loss: 0.0919
Batch 100, Loss: 0.0961
Batch 110, Loss: 0.0996
Batch 120, Loss: 0.0999
Batch 130, Loss: 0.0964
Batch 140, Loss: 0.0919
Batch 150, Loss: 0.0975
Batch 160, Loss: 0.0949
Batch 170, Loss: 0.0990
Batch 180, Loss: 0.1017
Batch 190, Loss: 0.0961
Batch 200, Loss: 0.0995
Batch 210, Loss: 0.1092
Batch 220, Loss: 0.0973
Batch 230, Loss: 0.1051
Batch 240, Loss: 0.1107
Batch 250, Loss: 0.0927
Batch 260, Loss: 0.1059
Batch 270, Loss: 0.1046
Batch 280, Loss: 0.0938
Batch 290, Loss: 0.0922
Batch 300, Loss: 0.0964
Batch 310, Loss: 0.1018
Batch 320, Loss: 0.1031
Batch 330, Loss: 0.1063
Batch 340, Loss: 0.1055
Batch 350, Loss: 0.1079
Batch 360, Loss: 0.1010
Batch 370, Loss: 0.1135
Batch 380, Loss: 0.1148
Batch 390, Loss: 0.1082
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.00310492515564 seconds
Epoch 156 accuracy: 74.93%
Batch 10, Loss: 0.1007
Batch 20, Loss: 0.1005
Batch 30, Loss: 0.0950
Batch 40, Loss: 0.0848
Batch 50, Loss: 0.0871
Batch 60, Loss: 0.0941
Batch 70, Loss: 0.0867
Batch 80, Loss: 0.0835
Batch 90, Loss: 0.0926
Batch 100, Loss: 0.0804
Batch 110, Loss: 0.0994
Batch 120, Loss: 0.0974
Batch 130, Loss: 0.0891
Batch 140, Loss: 0.0911
Batch 150, Loss: 0.1052
Batch 160, Loss: 0.0990
Batch 170, Loss: 0.0967
Batch 180, Loss: 0.0868
Batch 190, Loss: 0.0876
Batch 200, Loss: 0.0951
Batch 210, Loss: 0.0961
Batch 220, Loss: 0.0874
Batch 230, Loss: 0.0851
Batch 240, Loss: 0.0979
Batch 250, Loss: 0.0864
Batch 260, Loss: 0.0911
Batch 270, Loss: 0.0969
Batch 280, Loss: 0.1001
Batch 290, Loss: 0.0926
Batch 300, Loss: 0.0855
Batch 310, Loss: 0.0981
Batch 320, Loss: 0.0885
Batch 330, Loss: 0.0955
Batch 340, Loss: 0.0895
Batch 350, Loss: 0.0943
Batch 360, Loss: 0.0954
Batch 370, Loss: 0.0850
Batch 380, Loss: 0.0915
Batch 390, Loss: 0.1065
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.006436586380005 seconds
Epoch 157 accuracy: 75.58%
Batch 10, Loss: 0.0801
Batch 20, Loss: 0.0890
Batch 30, Loss: 0.0836
Batch 40, Loss: 0.0875
Batch 50, Loss: 0.0901
Batch 60, Loss: 0.0853
Batch 70, Loss: 0.0912
Batch 80, Loss: 0.0973
Batch 90, Loss: 0.0879
Batch 100, Loss: 0.0854
Batch 110, Loss: 0.0833
Batch 120, Loss: 0.0791
Batch 130, Loss: 0.0724
Batch 140, Loss: 0.0871
Batch 150, Loss: 0.0778
Batch 160, Loss: 0.0899
Batch 170, Loss: 0.0808
Batch 180, Loss: 0.0870
Batch 190, Loss: 0.0757
Batch 200, Loss: 0.0837
Batch 210, Loss: 0.0850
Batch 220, Loss: 0.0897
Batch 230, Loss: 0.0921
Batch 240, Loss: 0.0797
Batch 250, Loss: 0.0826
Batch 260, Loss: 0.0826
Batch 270, Loss: 0.0860
Batch 280, Loss: 0.0899
Batch 290, Loss: 0.0828
Batch 300, Loss: 0.1002
Batch 310, Loss: 0.0908
Batch 320, Loss: 0.0915
Batch 330, Loss: 0.0977
Batch 340, Loss: 0.0774
Batch 350, Loss: 0.0861
Batch 360, Loss: 0.0972
Batch 370, Loss: 0.0914
Batch 380, Loss: 0.0889
Batch 390, Loss: 0.0971
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.057599544525146 seconds
Epoch 158 accuracy: 75.74%
Batch 10, Loss: 0.0804
Batch 20, Loss: 0.0801
Batch 30, Loss: 0.0869
Batch 40, Loss: 0.0797
Batch 50, Loss: 0.0821
Batch 60, Loss: 0.0766
Batch 70, Loss: 0.0891
Batch 80, Loss: 0.0843
Batch 90, Loss: 0.0773
Batch 100, Loss: 0.0736
Batch 110, Loss: 0.0783
Batch 120, Loss: 0.0830
Batch 130, Loss: 0.0797
Batch 140, Loss: 0.0783
Batch 150, Loss: 0.0867
Batch 160, Loss: 0.0807
Batch 170, Loss: 0.0828
Batch 180, Loss: 0.0820
Batch 190, Loss: 0.0762
Batch 200, Loss: 0.0800
Batch 210, Loss: 0.0746
Batch 220, Loss: 0.0816
Batch 230, Loss: 0.0761
Batch 240, Loss: 0.0766
Batch 250, Loss: 0.0790
Batch 260, Loss: 0.0838
Batch 270, Loss: 0.0844
Batch 280, Loss: 0.0860
Batch 290, Loss: 0.0760
Batch 300, Loss: 0.0749
Batch 310, Loss: 0.0868
Batch 320, Loss: 0.0734
Batch 330, Loss: 0.0861
Batch 340, Loss: 0.0864
Batch 350, Loss: 0.0809
Batch 360, Loss: 0.0828
Batch 370, Loss: 0.0892
Batch 380, Loss: 0.0874
Batch 390, Loss: 0.0895
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.06607437133789 seconds
Epoch 159 accuracy: 75.78%
Batch 10, Loss: 0.0813
Batch 20, Loss: 0.0783
Batch 30, Loss: 0.0794
Batch 40, Loss: 0.0792
Batch 50, Loss: 0.0713
Batch 60, Loss: 0.0727
Batch 70, Loss: 0.0798
Batch 80, Loss: 0.0663
Batch 90, Loss: 0.0676
Batch 100, Loss: 0.0744
Batch 110, Loss: 0.0657
Batch 120, Loss: 0.0790
Batch 130, Loss: 0.0787
Batch 140, Loss: 0.0701
Batch 150, Loss: 0.0670
Batch 160, Loss: 0.0755
Batch 170, Loss: 0.0812
Batch 180, Loss: 0.0825
Batch 190, Loss: 0.0815
Batch 200, Loss: 0.0734
Batch 210, Loss: 0.0797
Batch 220, Loss: 0.0830
Batch 230, Loss: 0.0718
Batch 240, Loss: 0.0805
Batch 250, Loss: 0.0767
Batch 260, Loss: 0.0800
Batch 270, Loss: 0.0784
Batch 280, Loss: 0.0673
Batch 290, Loss: 0.0759
Batch 300, Loss: 0.0683
Batch 310, Loss: 0.0793
Batch 320, Loss: 0.0701
Batch 330, Loss: 0.0840
Batch 340, Loss: 0.0733
Batch 350, Loss: 0.0727
Batch 360, Loss: 0.0766
Batch 370, Loss: 0.0795
Batch 380, Loss: 0.0865
Batch 390, Loss: 0.0853
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.031164169311523 seconds
Epoch 160 accuracy: 76.65%
Batch 10, Loss: 0.0643
Batch 20, Loss: 0.0782
Batch 30, Loss: 0.0716
Batch 40, Loss: 0.0749
Batch 50, Loss: 0.0747
Batch 60, Loss: 0.0704
Batch 70, Loss: 0.0734
Batch 80, Loss: 0.0731
Batch 90, Loss: 0.0678
Batch 100, Loss: 0.0715
Batch 110, Loss: 0.0701
Batch 120, Loss: 0.0682
Batch 130, Loss: 0.0687
Batch 140, Loss: 0.0712
Batch 150, Loss: 0.0659
Batch 160, Loss: 0.0794
Batch 170, Loss: 0.0720
Batch 180, Loss: 0.0678
Batch 190, Loss: 0.0728
Batch 200, Loss: 0.0764
Batch 210, Loss: 0.0664
Batch 220, Loss: 0.0734
Batch 230, Loss: 0.0731
Batch 240, Loss: 0.0757
Batch 250, Loss: 0.0814
Batch 260, Loss: 0.0807
Batch 270, Loss: 0.0713
Batch 280, Loss: 0.0786
Batch 290, Loss: 0.0701
Batch 300, Loss: 0.0780
Batch 310, Loss: 0.0694
Batch 320, Loss: 0.0730
Batch 330, Loss: 0.0803
Batch 340, Loss: 0.0866
Batch 350, Loss: 0.0822
Batch 360, Loss: 0.0835
Batch 370, Loss: 0.0806
Batch 380, Loss: 0.0787
Batch 390, Loss: 0.0742
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.037468910217285 seconds
Epoch 161 accuracy: 76.0%
Batch 10, Loss: 0.0714
Batch 20, Loss: 0.0762
Batch 30, Loss: 0.0660
Batch 40, Loss: 0.0746
Batch 50, Loss: 0.0667
Batch 60, Loss: 0.0716
Batch 70, Loss: 0.0667
Batch 80, Loss: 0.0672
Batch 90, Loss: 0.0677
Batch 100, Loss: 0.0687
Batch 110, Loss: 0.0681
Batch 120, Loss: 0.0642
Batch 130, Loss: 0.0700
Batch 140, Loss: 0.0598
Batch 150, Loss: 0.0586
Batch 160, Loss: 0.0627
Batch 170, Loss: 0.0693
Batch 180, Loss: 0.0650
Batch 190, Loss: 0.0672
Batch 200, Loss: 0.0734
Batch 210, Loss: 0.0663
Batch 220, Loss: 0.0769
Batch 230, Loss: 0.0655
Batch 240, Loss: 0.0775
Batch 250, Loss: 0.0723
Batch 260, Loss: 0.0640
Batch 270, Loss: 0.0691
Batch 280, Loss: 0.0722
Batch 290, Loss: 0.0804
Batch 300, Loss: 0.0687
Batch 310, Loss: 0.0722
Batch 320, Loss: 0.0669
Batch 330, Loss: 0.0676
Batch 340, Loss: 0.0710
Batch 350, Loss: 0.0677
Batch 360, Loss: 0.0768
Batch 370, Loss: 0.0644
Batch 380, Loss: 0.0735
Batch 390, Loss: 0.0735
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.052292346954346 seconds
Epoch 162 accuracy: 76.59%
Batch 10, Loss: 0.0663
Batch 20, Loss: 0.0662
Batch 30, Loss: 0.0684
Batch 40, Loss: 0.0610
Batch 50, Loss: 0.0665
Batch 60, Loss: 0.0626
Batch 70, Loss: 0.0616
Batch 80, Loss: 0.0595
Batch 90, Loss: 0.0592
Batch 100, Loss: 0.0621
Batch 110, Loss: 0.0598
Batch 120, Loss: 0.0606
Batch 130, Loss: 0.0676
Batch 140, Loss: 0.0641
Batch 150, Loss: 0.0649
Batch 160, Loss: 0.0681
Batch 170, Loss: 0.0671
Batch 180, Loss: 0.0691
Batch 190, Loss: 0.0689
Batch 200, Loss: 0.0646
Batch 210, Loss: 0.0615
Batch 220, Loss: 0.0613
Batch 230, Loss: 0.0618
Batch 240, Loss: 0.0674
Batch 250, Loss: 0.0615
Batch 260, Loss: 0.0658
Batch 270, Loss: 0.0656
Batch 280, Loss: 0.0603
Batch 290, Loss: 0.0612
Batch 300, Loss: 0.0615
Batch 310, Loss: 0.0601
Batch 320, Loss: 0.0634
Batch 330, Loss: 0.0613
Batch 340, Loss: 0.0701
Batch 350, Loss: 0.0622
Batch 360, Loss: 0.0598
Batch 370, Loss: 0.0617
Batch 380, Loss: 0.0676
Batch 390, Loss: 0.0649
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.10388970375061 seconds
Epoch 163 accuracy: 77.07%
Batch 10, Loss: 0.0672
Batch 20, Loss: 0.0576
Batch 30, Loss: 0.0597
Batch 40, Loss: 0.0654
Batch 50, Loss: 0.0573
Batch 60, Loss: 0.0612
Batch 70, Loss: 0.0565
Batch 80, Loss: 0.0521
Batch 90, Loss: 0.0554
Batch 100, Loss: 0.0605
Batch 110, Loss: 0.0565
Batch 120, Loss: 0.0518
Batch 130, Loss: 0.0547
Batch 140, Loss: 0.0578
Batch 150, Loss: 0.0574
Batch 160, Loss: 0.0602
Batch 170, Loss: 0.0634
Batch 180, Loss: 0.0632
Batch 190, Loss: 0.0595
Batch 200, Loss: 0.0591
Batch 210, Loss: 0.0530
Batch 220, Loss: 0.0607
Batch 230, Loss: 0.0581
Batch 240, Loss: 0.0518
Batch 250, Loss: 0.0561
Batch 260, Loss: 0.0610
Batch 270, Loss: 0.0552
Batch 280, Loss: 0.0643
Batch 290, Loss: 0.0655
Batch 300, Loss: 0.0568
Batch 310, Loss: 0.0613
Batch 320, Loss: 0.0659
Batch 330, Loss: 0.0713
Batch 340, Loss: 0.0595
Batch 350, Loss: 0.0543
Batch 360, Loss: 0.0616
Batch 370, Loss: 0.0582
Batch 380, Loss: 0.0652
Batch 390, Loss: 0.0628
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.04112458229065 seconds
Epoch 164 accuracy: 77.23%
Batch 10, Loss: 0.0550
Batch 20, Loss: 0.0562
Batch 30, Loss: 0.0634
Batch 40, Loss: 0.0606
Batch 50, Loss: 0.0616
Batch 60, Loss: 0.0585
Batch 70, Loss: 0.0541
Batch 80, Loss: 0.0595
Batch 90, Loss: 0.0578
Batch 100, Loss: 0.0547
Batch 110, Loss: 0.0499
Batch 120, Loss: 0.0563
Batch 130, Loss: 0.0603
Batch 140, Loss: 0.0587
Batch 150, Loss: 0.0600
Batch 160, Loss: 0.0523
Batch 170, Loss: 0.0547
Batch 180, Loss: 0.0512
Batch 190, Loss: 0.0596
Batch 200, Loss: 0.0495
Batch 210, Loss: 0.0602
Batch 220, Loss: 0.0555
Batch 230, Loss: 0.0535
Batch 240, Loss: 0.0620
Batch 250, Loss: 0.0521
Batch 260, Loss: 0.0601
Batch 270, Loss: 0.0477
Batch 280, Loss: 0.0521
Batch 290, Loss: 0.0542
Batch 300, Loss: 0.0580
Batch 310, Loss: 0.0538
Batch 320, Loss: 0.0611
Batch 330, Loss: 0.0600
Batch 340, Loss: 0.0512
Batch 350, Loss: 0.0632
Batch 360, Loss: 0.0666
Batch 370, Loss: 0.0610
Batch 380, Loss: 0.0606
Batch 390, Loss: 0.0603
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 24.978917360305786 seconds
Epoch 165 accuracy: 77.06%
Batch 10, Loss: 0.0539
Batch 20, Loss: 0.0538
Batch 30, Loss: 0.0631
Batch 40, Loss: 0.0556
Batch 50, Loss: 0.0546
Batch 60, Loss: 0.0609
Batch 70, Loss: 0.0488
Batch 80, Loss: 0.0530
Batch 90, Loss: 0.0558
Batch 100, Loss: 0.0581
Batch 110, Loss: 0.0542
Batch 120, Loss: 0.0617
Batch 130, Loss: 0.0527
Batch 140, Loss: 0.0549
Batch 150, Loss: 0.0520
Batch 160, Loss: 0.0557
Batch 170, Loss: 0.0502
Batch 180, Loss: 0.0563
Batch 190, Loss: 0.0554
Batch 200, Loss: 0.0493
Batch 210, Loss: 0.0548
Batch 220, Loss: 0.0578
Batch 230, Loss: 0.0538
Batch 240, Loss: 0.0533
Batch 250, Loss: 0.0572
Batch 260, Loss: 0.0570
Batch 270, Loss: 0.0526
Batch 280, Loss: 0.0492
Batch 290, Loss: 0.0592
Batch 300, Loss: 0.0606
Batch 310, Loss: 0.0549
Batch 320, Loss: 0.0623
Batch 330, Loss: 0.0543
Batch 340, Loss: 0.0615
Batch 350, Loss: 0.0605
Batch 360, Loss: 0.0497
Batch 370, Loss: 0.0618
Batch 380, Loss: 0.0562
Batch 390, Loss: 0.0535
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.01228427886963 seconds
Epoch 166 accuracy: 77.57%
Batch 10, Loss: 0.0466
Batch 20, Loss: 0.0472
Batch 30, Loss: 0.0527
Batch 40, Loss: 0.0471
Batch 50, Loss: 0.0492
Batch 60, Loss: 0.0496
Batch 70, Loss: 0.0539
Batch 80, Loss: 0.0533
Batch 90, Loss: 0.0503
Batch 100, Loss: 0.0471
Batch 110, Loss: 0.0531
Batch 120, Loss: 0.0533
Batch 130, Loss: 0.0534
Batch 140, Loss: 0.0530
Batch 150, Loss: 0.0538
Batch 160, Loss: 0.0577
Batch 170, Loss: 0.0563
Batch 180, Loss: 0.0479
Batch 190, Loss: 0.0491
Batch 200, Loss: 0.0528
Batch 210, Loss: 0.0473
Batch 220, Loss: 0.0519
Batch 230, Loss: 0.0542
Batch 240, Loss: 0.0572
Batch 250, Loss: 0.0568
Batch 260, Loss: 0.0537
Batch 270, Loss: 0.0480
Batch 280, Loss: 0.0528
Batch 290, Loss: 0.0552
Batch 300, Loss: 0.0549
Batch 310, Loss: 0.0510
Batch 320, Loss: 0.0541
Batch 330, Loss: 0.0541
Batch 340, Loss: 0.0554
Batch 350, Loss: 0.0463
Batch 360, Loss: 0.0500
Batch 370, Loss: 0.0585
Batch 380, Loss: 0.0527
Batch 390, Loss: 0.0510
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.010987281799316 seconds
Epoch 167 accuracy: 77.73%
Batch 10, Loss: 0.0485
Batch 20, Loss: 0.0549
Batch 30, Loss: 0.0461
Batch 40, Loss: 0.0471
Batch 50, Loss: 0.0509
Batch 60, Loss: 0.0465
Batch 70, Loss: 0.0484
Batch 80, Loss: 0.0476
Batch 90, Loss: 0.0493
Batch 100, Loss: 0.0493
Batch 110, Loss: 0.0448
Batch 120, Loss: 0.0510
Batch 130, Loss: 0.0499
Batch 140, Loss: 0.0411
Batch 150, Loss: 0.0494
Batch 160, Loss: 0.0499
Batch 170, Loss: 0.0476
Batch 180, Loss: 0.0483
Batch 190, Loss: 0.0537
Batch 200, Loss: 0.0515
Batch 210, Loss: 0.0487
Batch 220, Loss: 0.0548
Batch 230, Loss: 0.0439
Batch 240, Loss: 0.0447
Batch 250, Loss: 0.0476
Batch 260, Loss: 0.0539
Batch 270, Loss: 0.0522
Batch 280, Loss: 0.0456
Batch 290, Loss: 0.0469
Batch 300, Loss: 0.0529
Batch 310, Loss: 0.0576
Batch 320, Loss: 0.0515
Batch 330, Loss: 0.0497
Batch 340, Loss: 0.0494
Batch 350, Loss: 0.0509
Batch 360, Loss: 0.0479
Batch 370, Loss: 0.0455
Batch 380, Loss: 0.0441
Batch 390, Loss: 0.0519
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.01125407218933 seconds
Epoch 168 accuracy: 78.06%
Batch 10, Loss: 0.0425
Batch 20, Loss: 0.0492
Batch 30, Loss: 0.0483
Batch 40, Loss: 0.0479
Batch 50, Loss: 0.0440
Batch 60, Loss: 0.0520
Batch 70, Loss: 0.0504
Batch 80, Loss: 0.0475
Batch 90, Loss: 0.0479
Batch 100, Loss: 0.0483
Batch 110, Loss: 0.0444
Batch 120, Loss: 0.0492
Batch 130, Loss: 0.0482
Batch 140, Loss: 0.0488
Batch 150, Loss: 0.0463
Batch 160, Loss: 0.0423
Batch 170, Loss: 0.0502
Batch 180, Loss: 0.0443
Batch 190, Loss: 0.0476
Batch 200, Loss: 0.0515
Batch 210, Loss: 0.0495
Batch 220, Loss: 0.0526
Batch 230, Loss: 0.0462
Batch 240, Loss: 0.0461
Batch 250, Loss: 0.0451
Batch 260, Loss: 0.0440
Batch 270, Loss: 0.0476
Batch 280, Loss: 0.0491
Batch 290, Loss: 0.0450
Batch 300, Loss: 0.0464
Batch 310, Loss: 0.0443
Batch 320, Loss: 0.0499
Batch 330, Loss: 0.0542
Batch 340, Loss: 0.0502
Batch 350, Loss: 0.0480
Batch 360, Loss: 0.0435
Batch 370, Loss: 0.0507
Batch 380, Loss: 0.0479
Batch 390, Loss: 0.0498
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.028347730636597 seconds
Epoch 169 accuracy: 78.07%
Batch 10, Loss: 0.0429
Batch 20, Loss: 0.0381
Batch 30, Loss: 0.0415
Batch 40, Loss: 0.0443
Batch 50, Loss: 0.0415
Batch 60, Loss: 0.0422
Batch 70, Loss: 0.0455
Batch 80, Loss: 0.0437
Batch 90, Loss: 0.0458
Batch 100, Loss: 0.0393
Batch 110, Loss: 0.0516
Batch 120, Loss: 0.0454
Batch 130, Loss: 0.0407
Batch 140, Loss: 0.0396
Batch 150, Loss: 0.0406
Batch 160, Loss: 0.0461
Batch 170, Loss: 0.0475
Batch 180, Loss: 0.0525
Batch 190, Loss: 0.0420
Batch 200, Loss: 0.0481
Batch 210, Loss: 0.0491
Batch 220, Loss: 0.0491
Batch 230, Loss: 0.0449
Batch 240, Loss: 0.0398
Batch 250, Loss: 0.0479
Batch 260, Loss: 0.0425
Batch 270, Loss: 0.0416
Batch 280, Loss: 0.0426
Batch 290, Loss: 0.0450
Batch 300, Loss: 0.0467
Batch 310, Loss: 0.0493
Batch 320, Loss: 0.0432
Batch 330, Loss: 0.0502
Batch 340, Loss: 0.0425
Batch 350, Loss: 0.0409
Batch 360, Loss: 0.0420
Batch 370, Loss: 0.0482
Batch 380, Loss: 0.0402
Batch 390, Loss: 0.0500
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.055772066116333 seconds
Epoch 170 accuracy: 78.42%
Batch 10, Loss: 0.0420
Batch 20, Loss: 0.0380
Batch 30, Loss: 0.0354
Batch 40, Loss: 0.0388
Batch 50, Loss: 0.0369
Batch 60, Loss: 0.0439
Batch 70, Loss: 0.0439
Batch 80, Loss: 0.0383
Batch 90, Loss: 0.0433
Batch 100, Loss: 0.0376
Batch 110, Loss: 0.0375
Batch 120, Loss: 0.0444
Batch 130, Loss: 0.0388
Batch 140, Loss: 0.0448
Batch 150, Loss: 0.0455
Batch 160, Loss: 0.0409
Batch 170, Loss: 0.0418
Batch 180, Loss: 0.0407
Batch 190, Loss: 0.0417
Batch 200, Loss: 0.0412
Batch 210, Loss: 0.0425
Batch 220, Loss: 0.0429
Batch 230, Loss: 0.0405
Batch 240, Loss: 0.0422
Batch 250, Loss: 0.0408
Batch 260, Loss: 0.0434
Batch 270, Loss: 0.0363
Batch 280, Loss: 0.0476
Batch 290, Loss: 0.0387
Batch 300, Loss: 0.0400
Batch 310, Loss: 0.0412
Batch 320, Loss: 0.0437
Batch 330, Loss: 0.0417
Batch 340, Loss: 0.0403
Batch 350, Loss: 0.0408
Batch 360, Loss: 0.0359
Batch 370, Loss: 0.0431
Batch 380, Loss: 0.0430
Batch 390, Loss: 0.0448
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.043723821640015 seconds
Epoch 171 accuracy: 78.43%
Batch 10, Loss: 0.0425
Batch 20, Loss: 0.0377
Batch 30, Loss: 0.0420
Batch 40, Loss: 0.0376
Batch 50, Loss: 0.0422
Batch 60, Loss: 0.0403
Batch 70, Loss: 0.0412
Batch 80, Loss: 0.0420
Batch 90, Loss: 0.0401
Batch 100, Loss: 0.0434
Batch 110, Loss: 0.0396
Batch 120, Loss: 0.0389
Batch 130, Loss: 0.0431
Batch 140, Loss: 0.0365
Batch 150, Loss: 0.0381
Batch 160, Loss: 0.0427
Batch 170, Loss: 0.0347
Batch 180, Loss: 0.0378
Batch 190, Loss: 0.0412
Batch 200, Loss: 0.0428
Batch 210, Loss: 0.0347
Batch 220, Loss: 0.0411
Batch 230, Loss: 0.0409
Batch 240, Loss: 0.0423
Batch 250, Loss: 0.0390
Batch 260, Loss: 0.0402
Batch 270, Loss: 0.0413
Batch 280, Loss: 0.0484
Batch 290, Loss: 0.0458
Batch 300, Loss: 0.0417
Batch 310, Loss: 0.0403
Batch 320, Loss: 0.0357
Batch 330, Loss: 0.0431
Batch 340, Loss: 0.0433
Batch 350, Loss: 0.0453
Batch 360, Loss: 0.0408
Batch 370, Loss: 0.0444
Batch 380, Loss: 0.0413
Batch 390, Loss: 0.0404
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.018889904022217 seconds
Epoch 172 accuracy: 78.47%
Batch 10, Loss: 0.0380
Batch 20, Loss: 0.0391
Batch 30, Loss: 0.0368
Batch 40, Loss: 0.0377
Batch 50, Loss: 0.0382
Batch 60, Loss: 0.0361
Batch 70, Loss: 0.0332
Batch 80, Loss: 0.0400
Batch 90, Loss: 0.0405
Batch 100, Loss: 0.0375
Batch 110, Loss: 0.0374
Batch 120, Loss: 0.0335
Batch 130, Loss: 0.0361
Batch 140, Loss: 0.0388
Batch 150, Loss: 0.0349
Batch 160, Loss: 0.0421
Batch 170, Loss: 0.0405
Batch 180, Loss: 0.0404
Batch 190, Loss: 0.0392
Batch 200, Loss: 0.0392
Batch 210, Loss: 0.0394
Batch 220, Loss: 0.0404
Batch 230, Loss: 0.0367
Batch 240, Loss: 0.0357
Batch 250, Loss: 0.0406
Batch 260, Loss: 0.0326
Batch 270, Loss: 0.0432
Batch 280, Loss: 0.0413
Batch 290, Loss: 0.0384
Batch 300, Loss: 0.0393
Batch 310, Loss: 0.0432
Batch 320, Loss: 0.0376
Batch 330, Loss: 0.0348
Batch 340, Loss: 0.0374
Batch 350, Loss: 0.0423
Batch 360, Loss: 0.0382
Batch 370, Loss: 0.0444
Batch 380, Loss: 0.0382
Batch 390, Loss: 0.0359
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.041661739349365 seconds
Epoch 173 accuracy: 78.35%
Batch 10, Loss: 0.0376
Batch 20, Loss: 0.0343
Batch 30, Loss: 0.0335
Batch 40, Loss: 0.0367
Batch 50, Loss: 0.0344
Batch 60, Loss: 0.0426
Batch 70, Loss: 0.0346
Batch 80, Loss: 0.0372
Batch 90, Loss: 0.0389
Batch 100, Loss: 0.0354
Batch 110, Loss: 0.0358
Batch 120, Loss: 0.0352
Batch 130, Loss: 0.0357
Batch 140, Loss: 0.0358
Batch 150, Loss: 0.0360
Batch 160, Loss: 0.0375
Batch 170, Loss: 0.0354
Batch 180, Loss: 0.0378
Batch 190, Loss: 0.0358
Batch 200, Loss: 0.0365
Batch 210, Loss: 0.0370
Batch 220, Loss: 0.0353
Batch 230, Loss: 0.0373
Batch 240, Loss: 0.0365
Batch 250, Loss: 0.0361
Batch 260, Loss: 0.0389
Batch 270, Loss: 0.0367
Batch 280, Loss: 0.0355
Batch 290, Loss: 0.0372
Batch 300, Loss: 0.0415
Batch 310, Loss: 0.0385
Batch 320, Loss: 0.0382
Batch 330, Loss: 0.0386
Batch 340, Loss: 0.0337
Batch 350, Loss: 0.0398
Batch 360, Loss: 0.0380
Batch 370, Loss: 0.0371
Batch 380, Loss: 0.0376
Batch 390, Loss: 0.0367
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.00816059112549 seconds
Epoch 174 accuracy: 78.54%
Batch 10, Loss: 0.0375
Batch 20, Loss: 0.0356
Batch 30, Loss: 0.0352
Batch 40, Loss: 0.0359
Batch 50, Loss: 0.0359
Batch 60, Loss: 0.0366
Batch 70, Loss: 0.0352
Batch 80, Loss: 0.0348
Batch 90, Loss: 0.0306
Batch 100, Loss: 0.0329
Batch 110, Loss: 0.0323
Batch 120, Loss: 0.0330
Batch 130, Loss: 0.0323
Batch 140, Loss: 0.0342
Batch 150, Loss: 0.0311
Batch 160, Loss: 0.0380
Batch 170, Loss: 0.0356
Batch 180, Loss: 0.0333
Batch 190, Loss: 0.0362
Batch 200, Loss: 0.0327
Batch 210, Loss: 0.0316
Batch 220, Loss: 0.0355
Batch 230, Loss: 0.0375
Batch 240, Loss: 0.0352
Batch 250, Loss: 0.0355
Batch 260, Loss: 0.0348
Batch 270, Loss: 0.0310
Batch 280, Loss: 0.0384
Batch 290, Loss: 0.0336
Batch 300, Loss: 0.0331
Batch 310, Loss: 0.0383
Batch 320, Loss: 0.0355
Batch 330, Loss: 0.0363
Batch 340, Loss: 0.0378
Batch 350, Loss: 0.0375
Batch 360, Loss: 0.0331
Batch 370, Loss: 0.0343
Batch 380, Loss: 0.0359
Batch 390, Loss: 0.0352
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.018193244934082 seconds
Epoch 175 accuracy: 78.71%
Batch 10, Loss: 0.0319
Batch 20, Loss: 0.0322
Batch 30, Loss: 0.0324
Batch 40, Loss: 0.0341
Batch 50, Loss: 0.0337
Batch 60, Loss: 0.0337
Batch 70, Loss: 0.0335
Batch 80, Loss: 0.0346
Batch 90, Loss: 0.0330
Batch 100, Loss: 0.0334
Batch 110, Loss: 0.0368
Batch 120, Loss: 0.0375
Batch 130, Loss: 0.0309
Batch 140, Loss: 0.0333
Batch 150, Loss: 0.0303
Batch 160, Loss: 0.0378
Batch 170, Loss: 0.0344
Batch 180, Loss: 0.0348
Batch 190, Loss: 0.0323
Batch 200, Loss: 0.0344
Batch 210, Loss: 0.0284
Batch 220, Loss: 0.0302
Batch 230, Loss: 0.0339
Batch 240, Loss: 0.0348
Batch 250, Loss: 0.0302
Batch 260, Loss: 0.0325
Batch 270, Loss: 0.0317
Batch 280, Loss: 0.0313
Batch 290, Loss: 0.0339
Batch 300, Loss: 0.0325
Batch 310, Loss: 0.0345
Batch 320, Loss: 0.0339
Batch 330, Loss: 0.0362
Batch 340, Loss: 0.0297
Batch 350, Loss: 0.0379
Batch 360, Loss: 0.0344
Batch 370, Loss: 0.0318
Batch 380, Loss: 0.0325
Batch 390, Loss: 0.0313
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.033706426620483 seconds
Epoch 176 accuracy: 78.75%
Batch 10, Loss: 0.0341
Batch 20, Loss: 0.0341
Batch 30, Loss: 0.0339
Batch 40, Loss: 0.0299
Batch 50, Loss: 0.0306
Batch 60, Loss: 0.0321
Batch 70, Loss: 0.0327
Batch 80, Loss: 0.0329
Batch 90, Loss: 0.0332
Batch 100, Loss: 0.0351
Batch 110, Loss: 0.0372
Batch 120, Loss: 0.0327
Batch 130, Loss: 0.0371
Batch 140, Loss: 0.0319
Batch 150, Loss: 0.0338
Batch 160, Loss: 0.0325
Batch 170, Loss: 0.0331
Batch 180, Loss: 0.0309
Batch 190, Loss: 0.0281
Batch 200, Loss: 0.0289
Batch 210, Loss: 0.0352
Batch 220, Loss: 0.0339
Batch 230, Loss: 0.0315
Batch 240, Loss: 0.0309
Batch 250, Loss: 0.0349
Batch 260, Loss: 0.0292
Batch 270, Loss: 0.0315
Batch 280, Loss: 0.0341
Batch 290, Loss: 0.0344
Batch 300, Loss: 0.0318
Batch 310, Loss: 0.0318
Batch 320, Loss: 0.0326
Batch 330, Loss: 0.0335
Batch 340, Loss: 0.0307
Batch 350, Loss: 0.0394
Batch 360, Loss: 0.0318
Batch 370, Loss: 0.0339
Batch 380, Loss: 0.0355
Batch 390, Loss: 0.0323
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.045917987823486 seconds
Epoch 177 accuracy: 78.96%
Batch 10, Loss: 0.0285
Batch 20, Loss: 0.0300
Batch 30, Loss: 0.0293
Batch 40, Loss: 0.0326
Batch 50, Loss: 0.0335
Batch 60, Loss: 0.0287
Batch 70, Loss: 0.0307
Batch 80, Loss: 0.0299
Batch 90, Loss: 0.0308
Batch 100, Loss: 0.0320
Batch 110, Loss: 0.0305
Batch 120, Loss: 0.0348
Batch 130, Loss: 0.0314
Batch 140, Loss: 0.0323
Batch 150, Loss: 0.0313
Batch 160, Loss: 0.0360
Batch 170, Loss: 0.0287
Batch 180, Loss: 0.0299
Batch 190, Loss: 0.0288
Batch 200, Loss: 0.0283
Batch 210, Loss: 0.0353
Batch 220, Loss: 0.0343
Batch 230, Loss: 0.0352
Batch 240, Loss: 0.0331
Batch 250, Loss: 0.0304
Batch 260, Loss: 0.0317
Batch 270, Loss: 0.0317
Batch 280, Loss: 0.0293
Batch 290, Loss: 0.0327
Batch 300, Loss: 0.0309
Batch 310, Loss: 0.0322
Batch 320, Loss: 0.0341
Batch 330, Loss: 0.0301
Batch 340, Loss: 0.0318
Batch 350, Loss: 0.0281
Batch 360, Loss: 0.0341
Batch 370, Loss: 0.0336
Batch 380, Loss: 0.0330
Batch 390, Loss: 0.0329
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.029783487319946 seconds
Epoch 178 accuracy: 79.01%
Batch 10, Loss: 0.0305
Batch 20, Loss: 0.0261
Batch 30, Loss: 0.0340
Batch 40, Loss: 0.0322
Batch 50, Loss: 0.0267
Batch 60, Loss: 0.0323
Batch 70, Loss: 0.0308
Batch 80, Loss: 0.0317
Batch 90, Loss: 0.0277
Batch 100, Loss: 0.0335
Batch 110, Loss: 0.0319
Batch 120, Loss: 0.0284
Batch 130, Loss: 0.0293
Batch 140, Loss: 0.0304
Batch 150, Loss: 0.0313
Batch 160, Loss: 0.0333
Batch 170, Loss: 0.0317
Batch 180, Loss: 0.0330
Batch 190, Loss: 0.0276
Batch 200, Loss: 0.0347
Batch 210, Loss: 0.0304
Batch 220, Loss: 0.0309
Batch 230, Loss: 0.0285
Batch 240, Loss: 0.0316
Batch 250, Loss: 0.0329
Batch 260, Loss: 0.0307
Batch 270, Loss: 0.0312
Batch 280, Loss: 0.0329
Batch 290, Loss: 0.0334
Batch 300, Loss: 0.0313
Batch 310, Loss: 0.0324
Batch 320, Loss: 0.0293
Batch 330, Loss: 0.0313
Batch 340, Loss: 0.0296
Batch 350, Loss: 0.0321
Batch 360, Loss: 0.0325
Batch 370, Loss: 0.0318
Batch 380, Loss: 0.0335
Batch 390, Loss: 0.0316
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 24.986563444137573 seconds
Epoch 179 accuracy: 78.77%
Batch 10, Loss: 0.0326
Batch 20, Loss: 0.0287
Batch 30, Loss: 0.0282
Batch 40, Loss: 0.0287
Batch 50, Loss: 0.0270
Batch 60, Loss: 0.0260
Batch 70, Loss: 0.0341
Batch 80, Loss: 0.0278
Batch 90, Loss: 0.0291
Batch 100, Loss: 0.0294
Batch 110, Loss: 0.0258
Batch 120, Loss: 0.0328
Batch 130, Loss: 0.0288
Batch 140, Loss: 0.0311
Batch 150, Loss: 0.0273
Batch 160, Loss: 0.0274
Batch 170, Loss: 0.0348
Batch 180, Loss: 0.0280
Batch 190, Loss: 0.0341
Batch 200, Loss: 0.0286
Batch 210, Loss: 0.0293
Batch 220, Loss: 0.0338
Batch 230, Loss: 0.0279
Batch 240, Loss: 0.0355
Batch 250, Loss: 0.0337
Batch 260, Loss: 0.0294
Batch 270, Loss: 0.0373
Batch 280, Loss: 0.0279
Batch 290, Loss: 0.0341
Batch 300, Loss: 0.0281
Batch 310, Loss: 0.0296
Batch 320, Loss: 0.0276
Batch 330, Loss: 0.0315
Batch 340, Loss: 0.0275
Batch 350, Loss: 0.0285
Batch 360, Loss: 0.0300
Batch 370, Loss: 0.0314
Batch 380, Loss: 0.0285
Batch 390, Loss: 0.0322
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.03587579727173 seconds
Epoch 180 accuracy: 78.98%
Batch 10, Loss: 0.0276
Batch 20, Loss: 0.0291
Batch 30, Loss: 0.0269
Batch 40, Loss: 0.0281
Batch 50, Loss: 0.0281
Batch 60, Loss: 0.0334
Batch 70, Loss: 0.0318
Batch 80, Loss: 0.0278
Batch 90, Loss: 0.0269
Batch 100, Loss: 0.0337
Batch 110, Loss: 0.0302
Batch 120, Loss: 0.0281
Batch 130, Loss: 0.0278
Batch 140, Loss: 0.0332
Batch 150, Loss: 0.0302
Batch 160, Loss: 0.0288
Batch 170, Loss: 0.0294
Batch 180, Loss: 0.0293
Batch 190, Loss: 0.0308
Batch 200, Loss: 0.0285
Batch 210, Loss: 0.0316
Batch 220, Loss: 0.0281
Batch 230, Loss: 0.0274
Batch 240, Loss: 0.0266
Batch 250, Loss: 0.0271
Batch 260, Loss: 0.0283
Batch 270, Loss: 0.0294
Batch 280, Loss: 0.0311
Batch 290, Loss: 0.0278
Batch 300, Loss: 0.0345
Batch 310, Loss: 0.0257
Batch 320, Loss: 0.0292
Batch 330, Loss: 0.0281
Batch 340, Loss: 0.0282
Batch 350, Loss: 0.0294
Batch 360, Loss: 0.0304
Batch 370, Loss: 0.0281
Batch 380, Loss: 0.0252
Batch 390, Loss: 0.0328
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.013904333114624 seconds
Epoch 181 accuracy: 78.86%
Batch 10, Loss: 0.0317
Batch 20, Loss: 0.0258
Batch 30, Loss: 0.0260
Batch 40, Loss: 0.0275
Batch 50, Loss: 0.0295
Batch 60, Loss: 0.0295
Batch 70, Loss: 0.0305
Batch 80, Loss: 0.0285
Batch 90, Loss: 0.0294
Batch 100, Loss: 0.0294
Batch 110, Loss: 0.0285
Batch 120, Loss: 0.0313
Batch 130, Loss: 0.0275
Batch 140, Loss: 0.0320
Batch 150, Loss: 0.0279
Batch 160, Loss: 0.0332
Batch 170, Loss: 0.0263
Batch 180, Loss: 0.0296
Batch 190, Loss: 0.0274
Batch 200, Loss: 0.0284
Batch 210, Loss: 0.0263
Batch 220, Loss: 0.0289
Batch 230, Loss: 0.0293
Batch 240, Loss: 0.0289
Batch 250, Loss: 0.0286
Batch 260, Loss: 0.0293
Batch 270, Loss: 0.0292
Batch 280, Loss: 0.0313
Batch 290, Loss: 0.0277
Batch 300, Loss: 0.0301
Batch 310, Loss: 0.0285
Batch 320, Loss: 0.0262
Batch 330, Loss: 0.0289
Batch 340, Loss: 0.0304
Batch 350, Loss: 0.0281
Batch 360, Loss: 0.0312
Batch 370, Loss: 0.0255
Batch 380, Loss: 0.0276
Batch 390, Loss: 0.0312
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 24.96546697616577 seconds
Epoch 182 accuracy: 79.21%
Batch 10, Loss: 0.0271
Batch 20, Loss: 0.0242
Batch 30, Loss: 0.0286
Batch 40, Loss: 0.0343
Batch 50, Loss: 0.0295
Batch 60, Loss: 0.0254
Batch 70, Loss: 0.0333
Batch 80, Loss: 0.0264
Batch 90, Loss: 0.0257
Batch 100, Loss: 0.0263
Batch 110, Loss: 0.0317
Batch 120, Loss: 0.0267
Batch 130, Loss: 0.0290
Batch 140, Loss: 0.0281
Batch 150, Loss: 0.0297
Batch 160, Loss: 0.0286
Batch 170, Loss: 0.0292
Batch 180, Loss: 0.0293
Batch 190, Loss: 0.0277
Batch 200, Loss: 0.0302
Batch 210, Loss: 0.0301
Batch 220, Loss: 0.0269
Batch 230, Loss: 0.0283
Batch 240, Loss: 0.0263
Batch 250, Loss: 0.0304
Batch 260, Loss: 0.0269
Batch 270, Loss: 0.0232
Batch 280, Loss: 0.0304
Batch 290, Loss: 0.0263
Batch 300, Loss: 0.0275
Batch 310, Loss: 0.0296
Batch 320, Loss: 0.0279
Batch 330, Loss: 0.0266
Batch 340, Loss: 0.0276
Batch 350, Loss: 0.0267
Batch 360, Loss: 0.0273
Batch 370, Loss: 0.0264
Batch 380, Loss: 0.0272
Batch 390, Loss: 0.0242
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.042320489883423 seconds
Epoch 183 accuracy: 78.99%
Batch 10, Loss: 0.0304
Batch 20, Loss: 0.0238
Batch 30, Loss: 0.0255
Batch 40, Loss: 0.0263
Batch 50, Loss: 0.0307
Batch 60, Loss: 0.0291
Batch 70, Loss: 0.0285
Batch 80, Loss: 0.0243
Batch 90, Loss: 0.0247
Batch 100, Loss: 0.0274
Batch 110, Loss: 0.0274
Batch 120, Loss: 0.0273
Batch 130, Loss: 0.0266
Batch 140, Loss: 0.0282
Batch 150, Loss: 0.0282
Batch 160, Loss: 0.0262
Batch 170, Loss: 0.0266
Batch 180, Loss: 0.0266
Batch 190, Loss: 0.0247
Batch 200, Loss: 0.0277
Batch 210, Loss: 0.0268
Batch 220, Loss: 0.0249
Batch 230, Loss: 0.0277
Batch 240, Loss: 0.0249
Batch 250, Loss: 0.0246
Batch 260, Loss: 0.0306
Batch 270, Loss: 0.0258
Batch 280, Loss: 0.0240
Batch 290, Loss: 0.0307
Batch 300, Loss: 0.0261
Batch 310, Loss: 0.0263
Batch 320, Loss: 0.0243
Batch 330, Loss: 0.0289
Batch 340, Loss: 0.0267
Batch 350, Loss: 0.0252
Batch 360, Loss: 0.0324
Batch 370, Loss: 0.0253
Batch 380, Loss: 0.0276
Batch 390, Loss: 0.0293
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.029687643051147 seconds
Epoch 184 accuracy: 79.0%
Batch 10, Loss: 0.0254
Batch 20, Loss: 0.0260
Batch 30, Loss: 0.0271
Batch 40, Loss: 0.0289
Batch 50, Loss: 0.0240
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0276
Batch 80, Loss: 0.0303
Batch 90, Loss: 0.0297
Batch 100, Loss: 0.0275
Batch 110, Loss: 0.0293
Batch 120, Loss: 0.0259
Batch 130, Loss: 0.0294
Batch 140, Loss: 0.0293
Batch 150, Loss: 0.0234
Batch 160, Loss: 0.0268
Batch 170, Loss: 0.0264
Batch 180, Loss: 0.0264
Batch 190, Loss: 0.0259
Batch 200, Loss: 0.0259
Batch 210, Loss: 0.0247
Batch 220, Loss: 0.0251
Batch 230, Loss: 0.0276
Batch 240, Loss: 0.0274
Batch 250, Loss: 0.0250
Batch 260, Loss: 0.0310
Batch 270, Loss: 0.0268
Batch 280, Loss: 0.0262
Batch 290, Loss: 0.0306
Batch 300, Loss: 0.0257
Batch 310, Loss: 0.0267
Batch 320, Loss: 0.0326
Batch 330, Loss: 0.0284
Batch 340, Loss: 0.0263
Batch 350, Loss: 0.0305
Batch 360, Loss: 0.0265
Batch 370, Loss: 0.0291
Batch 380, Loss: 0.0285
Batch 390, Loss: 0.0276
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 24.99467945098877 seconds
Epoch 185 accuracy: 79.07%
Batch 10, Loss: 0.0241
Batch 20, Loss: 0.0237
Batch 30, Loss: 0.0257
Batch 40, Loss: 0.0251
Batch 50, Loss: 0.0277
Batch 60, Loss: 0.0258
Batch 70, Loss: 0.0297
Batch 80, Loss: 0.0257
Batch 90, Loss: 0.0257
Batch 100, Loss: 0.0253
Batch 110, Loss: 0.0232
Batch 120, Loss: 0.0271
Batch 130, Loss: 0.0249
Batch 140, Loss: 0.0236
Batch 150, Loss: 0.0262
Batch 160, Loss: 0.0271
Batch 170, Loss: 0.0276
Batch 180, Loss: 0.0290
Batch 190, Loss: 0.0253
Batch 200, Loss: 0.0270
Batch 210, Loss: 0.0269
Batch 220, Loss: 0.0315
Batch 230, Loss: 0.0296
Batch 240, Loss: 0.0264
Batch 250, Loss: 0.0259
Batch 260, Loss: 0.0268
Batch 270, Loss: 0.0272
Batch 280, Loss: 0.0257
Batch 290, Loss: 0.0251
Batch 300, Loss: 0.0250
Batch 310, Loss: 0.0305
Batch 320, Loss: 0.0248
Batch 330, Loss: 0.0258
Batch 340, Loss: 0.0254
Batch 350, Loss: 0.0245
Batch 360, Loss: 0.0284
Batch 370, Loss: 0.0277
Batch 380, Loss: 0.0279
Batch 390, Loss: 0.0266
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.001585245132446 seconds
Epoch 186 accuracy: 79.18%
Batch 10, Loss: 0.0249
Batch 20, Loss: 0.0266
Batch 30, Loss: 0.0283
Batch 40, Loss: 0.0261
Batch 50, Loss: 0.0239
Batch 60, Loss: 0.0304
Batch 70, Loss: 0.0248
Batch 80, Loss: 0.0258
Batch 90, Loss: 0.0253
Batch 100, Loss: 0.0218
Batch 110, Loss: 0.0287
Batch 120, Loss: 0.0251
Batch 130, Loss: 0.0244
Batch 140, Loss: 0.0235
Batch 150, Loss: 0.0267
Batch 160, Loss: 0.0256
Batch 170, Loss: 0.0250
Batch 180, Loss: 0.0239
Batch 190, Loss: 0.0249
Batch 200, Loss: 0.0252
Batch 210, Loss: 0.0261
Batch 220, Loss: 0.0261
Batch 230, Loss: 0.0259
Batch 240, Loss: 0.0242
Batch 250, Loss: 0.0253
Batch 260, Loss: 0.0262
Batch 270, Loss: 0.0232
Batch 280, Loss: 0.0247
Batch 290, Loss: 0.0227
Batch 300, Loss: 0.0274
Batch 310, Loss: 0.0236
Batch 320, Loss: 0.0260
Batch 330, Loss: 0.0255
Batch 340, Loss: 0.0246
Batch 350, Loss: 0.0242
Batch 360, Loss: 0.0244
Batch 370, Loss: 0.0234
Batch 380, Loss: 0.0240
Batch 390, Loss: 0.0282
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.04641628265381 seconds
Epoch 187 accuracy: 78.99%
Batch 10, Loss: 0.0259
Batch 20, Loss: 0.0243
Batch 30, Loss: 0.0275
Batch 40, Loss: 0.0261
Batch 50, Loss: 0.0247
Batch 60, Loss: 0.0232
Batch 70, Loss: 0.0289
Batch 80, Loss: 0.0242
Batch 90, Loss: 0.0251
Batch 100, Loss: 0.0226
Batch 110, Loss: 0.0242
Batch 120, Loss: 0.0274
Batch 130, Loss: 0.0276
Batch 140, Loss: 0.0267
Batch 150, Loss: 0.0273
Batch 160, Loss: 0.0282
Batch 170, Loss: 0.0294
Batch 180, Loss: 0.0244
Batch 190, Loss: 0.0240
Batch 200, Loss: 0.0277
Batch 210, Loss: 0.0262
Batch 220, Loss: 0.0260
Batch 230, Loss: 0.0219
Batch 240, Loss: 0.0282
Batch 250, Loss: 0.0313
Batch 260, Loss: 0.0227
Batch 270, Loss: 0.0228
Batch 280, Loss: 0.0283
Batch 290, Loss: 0.0247
Batch 300, Loss: 0.0238
Batch 310, Loss: 0.0266
Batch 320, Loss: 0.0231
Batch 330, Loss: 0.0243
Batch 340, Loss: 0.0255
Batch 350, Loss: 0.0294
Batch 360, Loss: 0.0258
Batch 370, Loss: 0.0249
Batch 380, Loss: 0.0237
Batch 390, Loss: 0.0256
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.03169274330139 seconds
Epoch 188 accuracy: 79.2%
Batch 10, Loss: 0.0262
Batch 20, Loss: 0.0240
Batch 30, Loss: 0.0276
Batch 40, Loss: 0.0246
Batch 50, Loss: 0.0250
Batch 60, Loss: 0.0283
Batch 70, Loss: 0.0270
Batch 80, Loss: 0.0226
Batch 90, Loss: 0.0233
Batch 100, Loss: 0.0260
Batch 110, Loss: 0.0233
Batch 120, Loss: 0.0226
Batch 130, Loss: 0.0293
Batch 140, Loss: 0.0232
Batch 150, Loss: 0.0231
Batch 160, Loss: 0.0248
Batch 170, Loss: 0.0246
Batch 180, Loss: 0.0234
Batch 190, Loss: 0.0253
Batch 200, Loss: 0.0230
Batch 210, Loss: 0.0241
Batch 220, Loss: 0.0236
Batch 230, Loss: 0.0271
Batch 240, Loss: 0.0229
Batch 250, Loss: 0.0247
Batch 260, Loss: 0.0250
Batch 270, Loss: 0.0260
Batch 280, Loss: 0.0235
Batch 290, Loss: 0.0266
Batch 300, Loss: 0.0241
Batch 310, Loss: 0.0289
Batch 320, Loss: 0.0254
Batch 330, Loss: 0.0239
Batch 340, Loss: 0.0272
Batch 350, Loss: 0.0237
Batch 360, Loss: 0.0221
Batch 370, Loss: 0.0272
Batch 380, Loss: 0.0255
Batch 390, Loss: 0.0266
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.000858068466187 seconds
Epoch 189 accuracy: 79.25%
Batch 10, Loss: 0.0269
Batch 20, Loss: 0.0249
Batch 30, Loss: 0.0253
Batch 40, Loss: 0.0241
Batch 50, Loss: 0.0254
Batch 60, Loss: 0.0237
Batch 70, Loss: 0.0255
Batch 80, Loss: 0.0228
Batch 90, Loss: 0.0253
Batch 100, Loss: 0.0253
Batch 110, Loss: 0.0231
Batch 120, Loss: 0.0235
Batch 130, Loss: 0.0255
Batch 140, Loss: 0.0260
Batch 150, Loss: 0.0218
Batch 160, Loss: 0.0267
Batch 170, Loss: 0.0242
Batch 180, Loss: 0.0241
Batch 190, Loss: 0.0220
Batch 200, Loss: 0.0227
Batch 210, Loss: 0.0242
Batch 220, Loss: 0.0276
Batch 230, Loss: 0.0282
Batch 240, Loss: 0.0243
Batch 250, Loss: 0.0253
Batch 260, Loss: 0.0284
Batch 270, Loss: 0.0259
Batch 280, Loss: 0.0254
Batch 290, Loss: 0.0245
Batch 300, Loss: 0.0234
Batch 310, Loss: 0.0254
Batch 320, Loss: 0.0242
Batch 330, Loss: 0.0230
Batch 340, Loss: 0.0217
Batch 350, Loss: 0.0214
Batch 360, Loss: 0.0245
Batch 370, Loss: 0.0266
Batch 380, Loss: 0.0239
Batch 390, Loss: 0.0230
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 24.98378086090088 seconds
Epoch 190 accuracy: 79.14%
Batch 10, Loss: 0.0281
Batch 20, Loss: 0.0247
Batch 30, Loss: 0.0243
Batch 40, Loss: 0.0274
Batch 50, Loss: 0.0257
Batch 60, Loss: 0.0265
Batch 70, Loss: 0.0302
Batch 80, Loss: 0.0244
Batch 90, Loss: 0.0241
Batch 100, Loss: 0.0254
Batch 110, Loss: 0.0247
Batch 120, Loss: 0.0247
Batch 130, Loss: 0.0244
Batch 140, Loss: 0.0245
Batch 150, Loss: 0.0248
Batch 160, Loss: 0.0217
Batch 170, Loss: 0.0249
Batch 180, Loss: 0.0234
Batch 190, Loss: 0.0211
Batch 200, Loss: 0.0233
Batch 210, Loss: 0.0238
Batch 220, Loss: 0.0237
Batch 230, Loss: 0.0276
Batch 240, Loss: 0.0265
Batch 250, Loss: 0.0291
Batch 260, Loss: 0.0246
Batch 270, Loss: 0.0251
Batch 280, Loss: 0.0285
Batch 290, Loss: 0.0224
Batch 300, Loss: 0.0252
Batch 310, Loss: 0.0234
Batch 320, Loss: 0.0238
Batch 330, Loss: 0.0267
Batch 340, Loss: 0.0236
Batch 350, Loss: 0.0197
Batch 360, Loss: 0.0244
Batch 370, Loss: 0.0259
Batch 380, Loss: 0.0236
Batch 390, Loss: 0.0253
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.02361035346985 seconds
Epoch 191 accuracy: 79.15%
Batch 10, Loss: 0.0259
Batch 20, Loss: 0.0241
Batch 30, Loss: 0.0252
Batch 40, Loss: 0.0217
Batch 50, Loss: 0.0212
Batch 60, Loss: 0.0236
Batch 70, Loss: 0.0245
Batch 80, Loss: 0.0215
Batch 90, Loss: 0.0228
Batch 100, Loss: 0.0243
Batch 110, Loss: 0.0254
Batch 120, Loss: 0.0224
Batch 130, Loss: 0.0240
Batch 140, Loss: 0.0215
Batch 150, Loss: 0.0256
Batch 160, Loss: 0.0232
Batch 170, Loss: 0.0253
Batch 180, Loss: 0.0235
Batch 190, Loss: 0.0232
Batch 200, Loss: 0.0234
Batch 210, Loss: 0.0257
Batch 220, Loss: 0.0236
Batch 230, Loss: 0.0254
Batch 240, Loss: 0.0254
Batch 250, Loss: 0.0263
Batch 260, Loss: 0.0245
Batch 270, Loss: 0.0254
Batch 280, Loss: 0.0254
Batch 290, Loss: 0.0279
Batch 300, Loss: 0.0258
Batch 310, Loss: 0.0269
Batch 320, Loss: 0.0229
Batch 330, Loss: 0.0240
Batch 340, Loss: 0.0232
Batch 350, Loss: 0.0231
Batch 360, Loss: 0.0228
Batch 370, Loss: 0.0241
Batch 380, Loss: 0.0222
Batch 390, Loss: 0.0279
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 24.998091459274292 seconds
Epoch 192 accuracy: 79.14%
Batch 10, Loss: 0.0249
Batch 20, Loss: 0.0241
Batch 30, Loss: 0.0221
Batch 40, Loss: 0.0208
Batch 50, Loss: 0.0240
Batch 60, Loss: 0.0260
Batch 70, Loss: 0.0233
Batch 80, Loss: 0.0234
Batch 90, Loss: 0.0219
Batch 100, Loss: 0.0242
Batch 110, Loss: 0.0252
Batch 120, Loss: 0.0216
Batch 130, Loss: 0.0243
Batch 140, Loss: 0.0242
Batch 150, Loss: 0.0215
Batch 160, Loss: 0.0282
Batch 170, Loss: 0.0229
Batch 180, Loss: 0.0253
Batch 190, Loss: 0.0212
Batch 200, Loss: 0.0236
Batch 210, Loss: 0.0260
Batch 220, Loss: 0.0242
Batch 230, Loss: 0.0242
Batch 240, Loss: 0.0252
Batch 250, Loss: 0.0238
Batch 260, Loss: 0.0246
Batch 270, Loss: 0.0203
Batch 280, Loss: 0.0254
Batch 290, Loss: 0.0244
Batch 300, Loss: 0.0233
Batch 310, Loss: 0.0233
Batch 320, Loss: 0.0269
Batch 330, Loss: 0.0259
Batch 340, Loss: 0.0243
Batch 350, Loss: 0.0264
Batch 360, Loss: 0.0218
Batch 370, Loss: 0.0227
Batch 380, Loss: 0.0242
Batch 390, Loss: 0.0257
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.010916709899902 seconds
Epoch 193 accuracy: 79.15%
Batch 10, Loss: 0.0227
Batch 20, Loss: 0.0232
Batch 30, Loss: 0.0253
Batch 40, Loss: 0.0253
Batch 50, Loss: 0.0228
Batch 60, Loss: 0.0261
Batch 70, Loss: 0.0234
Batch 80, Loss: 0.0258
Batch 90, Loss: 0.0237
Batch 100, Loss: 0.0246
Batch 110, Loss: 0.0225
Batch 120, Loss: 0.0241
Batch 130, Loss: 0.0244
Batch 140, Loss: 0.0258
Batch 150, Loss: 0.0281
Batch 160, Loss: 0.0235
Batch 170, Loss: 0.0237
Batch 180, Loss: 0.0272
Batch 190, Loss: 0.0251
Batch 200, Loss: 0.0218
Batch 210, Loss: 0.0224
Batch 220, Loss: 0.0227
Batch 230, Loss: 0.0202
Batch 240, Loss: 0.0213
Batch 250, Loss: 0.0235
Batch 260, Loss: 0.0223
Batch 270, Loss: 0.0187
Batch 280, Loss: 0.0233
Batch 290, Loss: 0.0260
Batch 300, Loss: 0.0226
Batch 310, Loss: 0.0236
Batch 320, Loss: 0.0247
Batch 330, Loss: 0.0234
Batch 340, Loss: 0.0248
Batch 350, Loss: 0.0242
Batch 360, Loss: 0.0238
Batch 370, Loss: 0.0268
Batch 380, Loss: 0.0250
Batch 390, Loss: 0.0245
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.024576902389526 seconds
Epoch 194 accuracy: 79.15%
Batch 10, Loss: 0.0236
Batch 20, Loss: 0.0239
Batch 30, Loss: 0.0253
Batch 40, Loss: 0.0258
Batch 50, Loss: 0.0260
Batch 60, Loss: 0.0227
Batch 70, Loss: 0.0213
Batch 80, Loss: 0.0229
Batch 90, Loss: 0.0208
Batch 100, Loss: 0.0226
Batch 110, Loss: 0.0225
Batch 120, Loss: 0.0258
Batch 130, Loss: 0.0220
Batch 140, Loss: 0.0252
Batch 150, Loss: 0.0271
Batch 160, Loss: 0.0250
Batch 170, Loss: 0.0255
Batch 180, Loss: 0.0242
Batch 190, Loss: 0.0227
Batch 200, Loss: 0.0254
Batch 210, Loss: 0.0234
Batch 220, Loss: 0.0233
Batch 230, Loss: 0.0209
Batch 240, Loss: 0.0230
Batch 250, Loss: 0.0239
Batch 260, Loss: 0.0246
Batch 270, Loss: 0.0233
Batch 280, Loss: 0.0253
Batch 290, Loss: 0.0282
Batch 300, Loss: 0.0252
Batch 310, Loss: 0.0255
Batch 320, Loss: 0.0235
Batch 330, Loss: 0.0226
Batch 340, Loss: 0.0234
Batch 350, Loss: 0.0234
Batch 360, Loss: 0.0240
Batch 370, Loss: 0.0253
Batch 380, Loss: 0.0259
Batch 390, Loss: 0.0261
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.052141666412354 seconds
Epoch 195 accuracy: 79.14%
Batch 10, Loss: 0.0214
Batch 20, Loss: 0.0199
Batch 30, Loss: 0.0228
Batch 40, Loss: 0.0254
Batch 50, Loss: 0.0256
Batch 60, Loss: 0.0257
Batch 70, Loss: 0.0230
Batch 80, Loss: 0.0239
Batch 90, Loss: 0.0258
Batch 100, Loss: 0.0222
Batch 110, Loss: 0.0207
Batch 120, Loss: 0.0256
Batch 130, Loss: 0.0276
Batch 140, Loss: 0.0212
Batch 150, Loss: 0.0224
Batch 160, Loss: 0.0255
Batch 170, Loss: 0.0216
Batch 180, Loss: 0.0253
Batch 190, Loss: 0.0245
Batch 200, Loss: 0.0281
Batch 210, Loss: 0.0252
Batch 220, Loss: 0.0226
Batch 230, Loss: 0.0210
Batch 240, Loss: 0.0250
Batch 250, Loss: 0.0270
Batch 260, Loss: 0.0245
Batch 270, Loss: 0.0253
Batch 280, Loss: 0.0235
Batch 290, Loss: 0.0267
Batch 300, Loss: 0.0231
Batch 310, Loss: 0.0240
Batch 320, Loss: 0.0234
Batch 330, Loss: 0.0284
Batch 340, Loss: 0.0240
Batch 350, Loss: 0.0233
Batch 360, Loss: 0.0215
Batch 370, Loss: 0.0239
Batch 380, Loss: 0.0270
Batch 390, Loss: 0.0259
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.018549919128418 seconds
Epoch 196 accuracy: 79.14%
Batch 10, Loss: 0.0240
Batch 20, Loss: 0.0258
Batch 30, Loss: 0.0263
Batch 40, Loss: 0.0265
Batch 50, Loss: 0.0276
Batch 60, Loss: 0.0224
Batch 70, Loss: 0.0210
Batch 80, Loss: 0.0244
Batch 90, Loss: 0.0242
Batch 100, Loss: 0.0249
Batch 110, Loss: 0.0249
Batch 120, Loss: 0.0254
Batch 130, Loss: 0.0234
Batch 140, Loss: 0.0238
Batch 150, Loss: 0.0237
Batch 160, Loss: 0.0227
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0233
Batch 190, Loss: 0.0253
Batch 200, Loss: 0.0242
Batch 210, Loss: 0.0228
Batch 220, Loss: 0.0275
Batch 230, Loss: 0.0236
Batch 240, Loss: 0.0231
Batch 250, Loss: 0.0218
Batch 260, Loss: 0.0250
Batch 270, Loss: 0.0250
Batch 280, Loss: 0.0230
Batch 290, Loss: 0.0246
Batch 300, Loss: 0.0227
Batch 310, Loss: 0.0267
Batch 320, Loss: 0.0218
Batch 330, Loss: 0.0231
Batch 340, Loss: 0.0247
Batch 350, Loss: 0.0218
Batch 360, Loss: 0.0213
Batch 370, Loss: 0.0274
Batch 380, Loss: 0.0236
Batch 390, Loss: 0.0263
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.04241681098938 seconds
Epoch 197 accuracy: 79.09%
Batch 10, Loss: 0.0247
Batch 20, Loss: 0.0218
Batch 30, Loss: 0.0231
Batch 40, Loss: 0.0260
Batch 50, Loss: 0.0266
Batch 60, Loss: 0.0240
Batch 70, Loss: 0.0220
Batch 80, Loss: 0.0239
Batch 90, Loss: 0.0225
Batch 100, Loss: 0.0266
Batch 110, Loss: 0.0218
Batch 120, Loss: 0.0231
Batch 130, Loss: 0.0230
Batch 140, Loss: 0.0243
Batch 150, Loss: 0.0250
Batch 160, Loss: 0.0218
Batch 170, Loss: 0.0211
Batch 180, Loss: 0.0241
Batch 190, Loss: 0.0217
Batch 200, Loss: 0.0235
Batch 210, Loss: 0.0213
Batch 220, Loss: 0.0229
Batch 230, Loss: 0.0231
Batch 240, Loss: 0.0261
Batch 250, Loss: 0.0231
Batch 260, Loss: 0.0268
Batch 270, Loss: 0.0235
Batch 280, Loss: 0.0251
Batch 290, Loss: 0.0244
Batch 300, Loss: 0.0250
Batch 310, Loss: 0.0221
Batch 320, Loss: 0.0252
Batch 330, Loss: 0.0223
Batch 340, Loss: 0.0219
Batch 350, Loss: 0.0248
Batch 360, Loss: 0.0257
Batch 370, Loss: 0.0230
Batch 380, Loss: 0.0260
Batch 390, Loss: 0.0223
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.03968381881714 seconds
Epoch 198 accuracy: 79.09%
Batch 10, Loss: 0.0206
Batch 20, Loss: 0.0251
Batch 30, Loss: 0.0232
Batch 40, Loss: 0.0200
Batch 50, Loss: 0.0245
Batch 60, Loss: 0.0245
Batch 70, Loss: 0.0238
Batch 80, Loss: 0.0219
Batch 90, Loss: 0.0200
Batch 100, Loss: 0.0255
Batch 110, Loss: 0.0233
Batch 120, Loss: 0.0226
Batch 130, Loss: 0.0216
Batch 140, Loss: 0.0270
Batch 150, Loss: 0.0272
Batch 160, Loss: 0.0211
Batch 170, Loss: 0.0233
Batch 180, Loss: 0.0219
Batch 190, Loss: 0.0233
Batch 200, Loss: 0.0243
Batch 210, Loss: 0.0259
Batch 220, Loss: 0.0224
Batch 230, Loss: 0.0218
Batch 240, Loss: 0.0259
Batch 250, Loss: 0.0241
Batch 260, Loss: 0.0215
Batch 270, Loss: 0.0229
Batch 280, Loss: 0.0241
Batch 290, Loss: 0.0218
Batch 300, Loss: 0.0243
Batch 310, Loss: 0.0210
Batch 320, Loss: 0.0215
Batch 330, Loss: 0.0229
Batch 340, Loss: 0.0224
Batch 350, Loss: 0.0239
Batch 360, Loss: 0.0239
Batch 370, Loss: 0.0221
Batch 380, Loss: 0.0237
Batch 390, Loss: 0.0284
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.028316974639893 seconds
Epoch 199 accuracy: 79.14%
Batch 10, Loss: 0.0237
Batch 20, Loss: 0.0225
Batch 30, Loss: 0.0249
Batch 40, Loss: 0.0206
Batch 50, Loss: 0.0267
Batch 60, Loss: 0.0222
Batch 70, Loss: 0.0261
Batch 80, Loss: 0.0219
Batch 90, Loss: 0.0224
Batch 100, Loss: 0.0255
Batch 110, Loss: 0.0212
Batch 120, Loss: 0.0250
Batch 130, Loss: 0.0255
Batch 140, Loss: 0.0248
Batch 150, Loss: 0.0242
Batch 160, Loss: 0.0239
Batch 170, Loss: 0.0244
Batch 180, Loss: 0.0226
Batch 190, Loss: 0.0247
Batch 200, Loss: 0.0247
Batch 210, Loss: 0.0258
Batch 220, Loss: 0.0226
Batch 230, Loss: 0.0236
Batch 240, Loss: 0.0224
Batch 250, Loss: 0.0234
Batch 260, Loss: 0.0250
Batch 270, Loss: 0.0257
Batch 280, Loss: 0.0211
Batch 290, Loss: 0.0240
Batch 300, Loss: 0.0239
Batch 310, Loss: 0.0254
Batch 320, Loss: 0.0222
Batch 330, Loss: 0.0231
Batch 340, Loss: 0.0227
Batch 350, Loss: 0.0245
Batch 360, Loss: 0.0230
Batch 370, Loss: 0.0241
Batch 380, Loss: 0.0203
Batch 390, Loss: 0.0241
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.029966592788696 seconds
Epoch 200 accuracy: 79.04%
Total training time: 5015.497808456421 seconds
