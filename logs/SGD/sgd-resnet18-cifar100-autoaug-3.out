The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1461
Batch 20, Loss: 4.1967
Batch 30, Loss: 4.0840
Batch 40, Loss: 3.9489
Batch 50, Loss: 3.8480
Batch 60, Loss: 3.7792
Batch 70, Loss: 3.7627
Batch 80, Loss: 3.6903
Batch 90, Loss: 3.6967
Batch 100, Loss: 3.6257
Batch 110, Loss: 3.6913
Batch 120, Loss: 3.6351
Batch 130, Loss: 3.6196
Batch 140, Loss: 3.6302
Batch 150, Loss: 3.5897
Batch 160, Loss: 3.6025
Batch 170, Loss: 3.5676
Batch 180, Loss: 3.5652
Batch 190, Loss: 3.5952
Batch 200, Loss: 3.5573
Batch 210, Loss: 3.5713
Batch 220, Loss: 3.5484
Batch 230, Loss: 3.5100
Batch 240, Loss: 3.5309
Batch 250, Loss: 3.5430
Batch 260, Loss: 3.4974
Batch 270, Loss: 3.4839
Batch 280, Loss: 3.4801
Batch 290, Loss: 3.4794
Batch 300, Loss: 3.5076
Batch 310, Loss: 3.4789
Batch 320, Loss: 3.4198
Batch 330, Loss: 3.4887
Batch 340, Loss: 3.4597
Batch 350, Loss: 3.4588
Batch 360, Loss: 3.4651
Batch 370, Loss: 3.4209
Batch 380, Loss: 3.4635
Batch 390, Loss: 3.4361
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.273217916488647 seconds
Epoch 1 accuracy: 8.97%
Batch 10, Loss: 3.4100
Batch 20, Loss: 3.4069
Batch 30, Loss: 3.4189
Batch 40, Loss: 3.4065
Batch 50, Loss: 3.4229
Batch 60, Loss: 3.4205
Batch 70, Loss: 3.3808
Batch 80, Loss: 3.3589
Batch 90, Loss: 3.3344
Batch 100, Loss: 3.3672
Batch 110, Loss: 3.3424
Batch 120, Loss: 3.3020
Batch 130, Loss: 3.3189
Batch 140, Loss: 3.3584
Batch 150, Loss: 3.2552
Batch 160, Loss: 3.2672
Batch 170, Loss: 3.3735
Batch 180, Loss: 3.2563
Batch 190, Loss: 3.2959
Batch 200, Loss: 3.2469
Batch 210, Loss: 3.2827
Batch 220, Loss: 3.2828
Batch 230, Loss: 3.3133
Batch 240, Loss: 3.2869
Batch 250, Loss: 3.2528
Batch 260, Loss: 3.2784
Batch 270, Loss: 3.2392
Batch 280, Loss: 3.2657
Batch 290, Loss: 3.2038
Batch 300, Loss: 3.1894
Batch 310, Loss: 3.2339
Batch 320, Loss: 3.2160
Batch 330, Loss: 3.1779
Batch 340, Loss: 3.1609
Batch 350, Loss: 3.2367
Batch 360, Loss: 3.1676
Batch 370, Loss: 3.1684
Batch 380, Loss: 3.2526
Batch 390, Loss: 3.1782
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.180041551589966 seconds
Epoch 2 accuracy: 16.26%
Batch 10, Loss: 3.1853
Batch 20, Loss: 3.2097
Batch 30, Loss: 3.1372
Batch 40, Loss: 3.1212
Batch 50, Loss: 3.1136
Batch 60, Loss: 3.1292
Batch 70, Loss: 3.1836
Batch 80, Loss: 3.1241
Batch 90, Loss: 3.0579
Batch 100, Loss: 3.1097
Batch 110, Loss: 3.0759
Batch 120, Loss: 3.0776
Batch 130, Loss: 3.0372
Batch 140, Loss: 3.0829
Batch 150, Loss: 3.0881
Batch 160, Loss: 3.1287
Batch 170, Loss: 3.1203
Batch 180, Loss: 3.0814
Batch 190, Loss: 2.9899
Batch 200, Loss: 3.0552
Batch 210, Loss: 3.0201
Batch 220, Loss: 2.9298
Batch 230, Loss: 2.9650
Batch 240, Loss: 2.9842
Batch 250, Loss: 3.0300
Batch 260, Loss: 2.9684
Batch 270, Loss: 3.0073
Batch 280, Loss: 2.9969
Batch 290, Loss: 3.0467
Batch 300, Loss: 2.9746
Batch 310, Loss: 2.9687
Batch 320, Loss: 2.9345
Batch 330, Loss: 3.0020
Batch 340, Loss: 2.9345
Batch 350, Loss: 3.0175
Batch 360, Loss: 2.9848
Batch 370, Loss: 2.9313
Batch 380, Loss: 2.9239
Batch 390, Loss: 2.9510
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.246764183044434 seconds
Epoch 3 accuracy: 20.48%
Batch 10, Loss: 2.9102
Batch 20, Loss: 2.8283
Batch 30, Loss: 2.8115
Batch 40, Loss: 2.9090
Batch 50, Loss: 2.8834
Batch 60, Loss: 2.8507
Batch 70, Loss: 2.8997
Batch 80, Loss: 2.8526
Batch 90, Loss: 2.8967
Batch 100, Loss: 2.8175
Batch 110, Loss: 2.8632
Batch 120, Loss: 2.7467
Batch 130, Loss: 2.8288
Batch 140, Loss: 2.8644
Batch 150, Loss: 2.7867
Batch 160, Loss: 2.8481
Batch 170, Loss: 2.7535
Batch 180, Loss: 2.8406
Batch 190, Loss: 2.8274
Batch 200, Loss: 2.8122
Batch 210, Loss: 2.7667
Batch 220, Loss: 2.7985
Batch 230, Loss: 2.8000
Batch 240, Loss: 2.7861
Batch 250, Loss: 2.7498
Batch 260, Loss: 2.8246
Batch 270, Loss: 2.7507
Batch 280, Loss: 2.7414
Batch 290, Loss: 2.7556
Batch 300, Loss: 2.7551
Batch 310, Loss: 2.6968
Batch 320, Loss: 2.6706
Batch 330, Loss: 2.7278
Batch 340, Loss: 2.7235
Batch 350, Loss: 2.6936
Batch 360, Loss: 2.6482
Batch 370, Loss: 2.6376
Batch 380, Loss: 2.6480
Batch 390, Loss: 2.7130
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.300710678100586 seconds
Epoch 4 accuracy: 27.31%
Batch 10, Loss: 2.6306
Batch 20, Loss: 2.6725
Batch 30, Loss: 2.6455
Batch 40, Loss: 2.6701
Batch 50, Loss: 2.6092
Batch 60, Loss: 2.6155
Batch 70, Loss: 2.6085
Batch 80, Loss: 2.6802
Batch 90, Loss: 2.5852
Batch 100, Loss: 2.5355
Batch 110, Loss: 2.5750
Batch 120, Loss: 2.5733
Batch 130, Loss: 2.5884
Batch 140, Loss: 2.6186
Batch 150, Loss: 2.5263
Batch 160, Loss: 2.5843
Batch 170, Loss: 2.5650
Batch 180, Loss: 2.5153
Batch 190, Loss: 2.5449
Batch 200, Loss: 2.5638
Batch 210, Loss: 2.5331
Batch 220, Loss: 2.5215
Batch 230, Loss: 2.5507
Batch 240, Loss: 2.5012
Batch 250, Loss: 2.5357
Batch 260, Loss: 2.4805
Batch 270, Loss: 2.5343
Batch 280, Loss: 2.5698
Batch 290, Loss: 2.5216
Batch 300, Loss: 2.5945
Batch 310, Loss: 2.4915
Batch 320, Loss: 2.5378
Batch 330, Loss: 2.5570
Batch 340, Loss: 2.5384
Batch 350, Loss: 2.4897
Batch 360, Loss: 2.4468
Batch 370, Loss: 2.4214
Batch 380, Loss: 2.4621
Batch 390, Loss: 2.4455
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.190770626068115 seconds
Epoch 5 accuracy: 33.61%
Batch 10, Loss: 2.4261
Batch 20, Loss: 2.3213
Batch 30, Loss: 2.3814
Batch 40, Loss: 2.3767
Batch 50, Loss: 2.4423
Batch 60, Loss: 2.4030
Batch 70, Loss: 2.3324
Batch 80, Loss: 2.3349
Batch 90, Loss: 2.3365
Batch 100, Loss: 2.3458
Batch 110, Loss: 2.3888
Batch 120, Loss: 2.3903
Batch 130, Loss: 2.4355
Batch 140, Loss: 2.4118
Batch 150, Loss: 2.4230
Batch 160, Loss: 2.3255
Batch 170, Loss: 2.4197
Batch 180, Loss: 2.2688
Batch 190, Loss: 2.3356
Batch 200, Loss: 2.3552
Batch 210, Loss: 2.4025
Batch 220, Loss: 2.3612
Batch 230, Loss: 2.3583
Batch 240, Loss: 2.2649
Batch 250, Loss: 2.4131
Batch 260, Loss: 2.3566
Batch 270, Loss: 2.3283
Batch 280, Loss: 2.2876
Batch 290, Loss: 2.3527
Batch 300, Loss: 2.3598
Batch 310, Loss: 2.3060
Batch 320, Loss: 2.2851
Batch 330, Loss: 2.2738
Batch 340, Loss: 2.3510
Batch 350, Loss: 2.2460
Batch 360, Loss: 2.2627
Batch 370, Loss: 2.2771
Batch 380, Loss: 2.3424
Batch 390, Loss: 2.2988
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.20160722732544 seconds
Epoch 6 accuracy: 36.7%
Batch 10, Loss: 2.2937
Batch 20, Loss: 2.2552
Batch 30, Loss: 2.2717
Batch 40, Loss: 2.1891
Batch 50, Loss: 2.2790
Batch 60, Loss: 2.2696
Batch 70, Loss: 2.2422
Batch 80, Loss: 2.2014
Batch 90, Loss: 2.2605
Batch 100, Loss: 2.2387
Batch 110, Loss: 2.1945
Batch 120, Loss: 2.2222
Batch 130, Loss: 2.1902
Batch 140, Loss: 2.2459
Batch 150, Loss: 2.2787
Batch 160, Loss: 2.1916
Batch 170, Loss: 2.1981
Batch 180, Loss: 2.2432
Batch 190, Loss: 2.2210
Batch 200, Loss: 2.2251
Batch 210, Loss: 2.1846
Batch 220, Loss: 2.1785
Batch 230, Loss: 2.1106
Batch 240, Loss: 2.1701
Batch 250, Loss: 2.1757
Batch 260, Loss: 2.1136
Batch 270, Loss: 2.1268
Batch 280, Loss: 2.1464
Batch 290, Loss: 2.2240
Batch 300, Loss: 2.2037
Batch 310, Loss: 2.1275
Batch 320, Loss: 2.1375
Batch 330, Loss: 2.1957
Batch 340, Loss: 2.1173
Batch 350, Loss: 2.1436
Batch 360, Loss: 2.1450
Batch 370, Loss: 2.1453
Batch 380, Loss: 2.1315
Batch 390, Loss: 2.1470
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.37213897705078 seconds
Epoch 7 accuracy: 43.13%
Batch 10, Loss: 2.1250
Batch 20, Loss: 2.0831
Batch 30, Loss: 2.0702
Batch 40, Loss: 2.1380
Batch 50, Loss: 2.0801
Batch 60, Loss: 2.1292
Batch 70, Loss: 2.0144
Batch 80, Loss: 2.1025
Batch 90, Loss: 2.0142
Batch 100, Loss: 2.1985
Batch 110, Loss: 2.0665
Batch 120, Loss: 2.0567
Batch 130, Loss: 2.0472
Batch 140, Loss: 2.1123
Batch 150, Loss: 2.1242
Batch 160, Loss: 2.0972
Batch 170, Loss: 2.1355
Batch 180, Loss: 2.1204
Batch 190, Loss: 2.1080
Batch 200, Loss: 2.0518
Batch 210, Loss: 2.1073
Batch 220, Loss: 2.0675
Batch 230, Loss: 2.0686
Batch 240, Loss: 2.0980
Batch 250, Loss: 2.0353
Batch 260, Loss: 2.0307
Batch 270, Loss: 2.1016
Batch 280, Loss: 2.1446
Batch 290, Loss: 2.0792
Batch 300, Loss: 2.0377
Batch 310, Loss: 2.0578
Batch 320, Loss: 2.0022
Batch 330, Loss: 1.9707
Batch 340, Loss: 2.0027
Batch 350, Loss: 2.0931
Batch 360, Loss: 1.9688
Batch 370, Loss: 2.0638
Batch 380, Loss: 2.0621
Batch 390, Loss: 1.9990
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.377681493759155 seconds
Epoch 8 accuracy: 42.38%
Batch 10, Loss: 1.9582
Batch 20, Loss: 2.0469
Batch 30, Loss: 2.0347
Batch 40, Loss: 2.0511
Batch 50, Loss: 2.0310
Batch 60, Loss: 2.0629
Batch 70, Loss: 2.0655
Batch 80, Loss: 1.9966
Batch 90, Loss: 1.9735
Batch 100, Loss: 1.9528
Batch 110, Loss: 2.0543
Batch 120, Loss: 2.1059
Batch 130, Loss: 1.9989
Batch 140, Loss: 1.9980
Batch 150, Loss: 1.9869
Batch 160, Loss: 1.9253
Batch 170, Loss: 1.9952
Batch 180, Loss: 1.9053
Batch 190, Loss: 2.0733
Batch 200, Loss: 1.9753
Batch 210, Loss: 2.0126
Batch 220, Loss: 1.9451
Batch 230, Loss: 1.9855
Batch 240, Loss: 1.9550
Batch 250, Loss: 2.0076
Batch 260, Loss: 1.9181
Batch 270, Loss: 1.9562
Batch 280, Loss: 1.9421
Batch 290, Loss: 1.9742
Batch 300, Loss: 1.9820
Batch 310, Loss: 1.9726
Batch 320, Loss: 1.9413
Batch 330, Loss: 1.9765
Batch 340, Loss: 2.0138
Batch 350, Loss: 1.9440
Batch 360, Loss: 1.9717
Batch 370, Loss: 1.9723
Batch 380, Loss: 1.9338
Batch 390, Loss: 1.9755
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.308177709579468 seconds
Epoch 9 accuracy: 47.48%
Batch 10, Loss: 1.8760
Batch 20, Loss: 1.9422
Batch 30, Loss: 1.9208
Batch 40, Loss: 1.8982
Batch 50, Loss: 1.9215
Batch 60, Loss: 1.8861
Batch 70, Loss: 1.9548
Batch 80, Loss: 1.9132
Batch 90, Loss: 1.9095
Batch 100, Loss: 1.8989
Batch 110, Loss: 1.9642
Batch 120, Loss: 1.9730
Batch 130, Loss: 1.9727
Batch 140, Loss: 1.9784
Batch 150, Loss: 1.9339
Batch 160, Loss: 1.9269
Batch 170, Loss: 1.8969
Batch 180, Loss: 1.9000
Batch 190, Loss: 1.9087
Batch 200, Loss: 1.8375
Batch 210, Loss: 1.9733
Batch 220, Loss: 1.8909
Batch 230, Loss: 1.9285
Batch 240, Loss: 1.9650
Batch 250, Loss: 1.8245
Batch 260, Loss: 1.8484
Batch 270, Loss: 1.9153
Batch 280, Loss: 1.8548
Batch 290, Loss: 1.8725
Batch 300, Loss: 1.9798
Batch 310, Loss: 1.9190
Batch 320, Loss: 1.8606
Batch 330, Loss: 1.9061
Batch 340, Loss: 1.9061
Batch 350, Loss: 1.9372
Batch 360, Loss: 1.9440
Batch 370, Loss: 1.8872
Batch 380, Loss: 1.8902
Batch 390, Loss: 1.9193
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.284422159194946 seconds
Epoch 10 accuracy: 48.21%
Batch 10, Loss: 1.8326
Batch 20, Loss: 1.8441
Batch 30, Loss: 1.8742
Batch 40, Loss: 1.8246
Batch 50, Loss: 1.8404
Batch 60, Loss: 1.8651
Batch 70, Loss: 1.9299
Batch 80, Loss: 1.9310
Batch 90, Loss: 1.8016
Batch 100, Loss: 1.8665
Batch 110, Loss: 1.8675
Batch 120, Loss: 1.9015
Batch 130, Loss: 1.8424
Batch 140, Loss: 1.8719
Batch 150, Loss: 1.8949
Batch 160, Loss: 1.8712
Batch 170, Loss: 1.8480
Batch 180, Loss: 1.8250
Batch 190, Loss: 1.8555
Batch 200, Loss: 1.8290
Batch 210, Loss: 1.8608
Batch 220, Loss: 1.8227
Batch 230, Loss: 1.8753
Batch 240, Loss: 1.8445
Batch 250, Loss: 1.7937
Batch 260, Loss: 1.8418
Batch 270, Loss: 1.8622
Batch 280, Loss: 1.8537
Batch 290, Loss: 1.8477
Batch 300, Loss: 1.8985
Batch 310, Loss: 1.8183
Batch 320, Loss: 1.8123
Batch 330, Loss: 1.8221
Batch 340, Loss: 1.8610
Batch 350, Loss: 1.8707
Batch 360, Loss: 1.8818
Batch 370, Loss: 1.8983
Batch 380, Loss: 1.8729
Batch 390, Loss: 1.8690
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.209041357040405 seconds
Epoch 11 accuracy: 48.49%
Batch 10, Loss: 1.8260
Batch 20, Loss: 1.8170
Batch 30, Loss: 1.8099
Batch 40, Loss: 1.8728
Batch 50, Loss: 1.8176
Batch 60, Loss: 1.7957
Batch 70, Loss: 1.8236
Batch 80, Loss: 1.8183
Batch 90, Loss: 1.8423
Batch 100, Loss: 1.8249
Batch 110, Loss: 1.7751
Batch 120, Loss: 1.7778
Batch 130, Loss: 1.8433
Batch 140, Loss: 1.7485
Batch 150, Loss: 1.7772
Batch 160, Loss: 1.8151
Batch 170, Loss: 1.7786
Batch 180, Loss: 1.8237
Batch 190, Loss: 1.8270
Batch 200, Loss: 1.7687
Batch 210, Loss: 1.8195
Batch 220, Loss: 1.7922
Batch 230, Loss: 1.8238
Batch 240, Loss: 1.8295
Batch 250, Loss: 1.7951
Batch 260, Loss: 1.8278
Batch 270, Loss: 1.8221
Batch 280, Loss: 1.8175
Batch 290, Loss: 1.8113
Batch 300, Loss: 1.8108
Batch 310, Loss: 1.8464
Batch 320, Loss: 1.8028
Batch 330, Loss: 1.7769
Batch 340, Loss: 1.8220
Batch 350, Loss: 1.7884
Batch 360, Loss: 1.8092
Batch 370, Loss: 1.8077
Batch 380, Loss: 1.8497
Batch 390, Loss: 1.8193
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.300564527511597 seconds
Epoch 12 accuracy: 48.84%
Batch 10, Loss: 1.7648
Batch 20, Loss: 1.7072
Batch 30, Loss: 1.7445
Batch 40, Loss: 1.8150
Batch 50, Loss: 1.7184
Batch 60, Loss: 1.7466
Batch 70, Loss: 1.7924
Batch 80, Loss: 1.8289
Batch 90, Loss: 1.8423
Batch 100, Loss: 1.7779
Batch 110, Loss: 1.7452
Batch 120, Loss: 1.7952
Batch 130, Loss: 1.7283
Batch 140, Loss: 1.7304
Batch 150, Loss: 1.7828
Batch 160, Loss: 1.7937
Batch 170, Loss: 1.8458
Batch 180, Loss: 1.7616
Batch 190, Loss: 1.8121
Batch 200, Loss: 1.7966
Batch 210, Loss: 1.8183
Batch 220, Loss: 1.7487
Batch 230, Loss: 1.7349
Batch 240, Loss: 1.7140
Batch 250, Loss: 1.7660
Batch 260, Loss: 1.7236
Batch 270, Loss: 1.8594
Batch 280, Loss: 1.7853
Batch 290, Loss: 1.7825
Batch 300, Loss: 1.7157
Batch 310, Loss: 1.8094
Batch 320, Loss: 1.8174
Batch 330, Loss: 1.8242
Batch 340, Loss: 1.8775
Batch 350, Loss: 1.7382
Batch 360, Loss: 1.8215
Batch 370, Loss: 1.8352
Batch 380, Loss: 1.7768
Batch 390, Loss: 1.8081
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.215638637542725 seconds
Epoch 13 accuracy: 53.41%
Batch 10, Loss: 1.6950
Batch 20, Loss: 1.7446
Batch 30, Loss: 1.8069
Batch 40, Loss: 1.6731
Batch 50, Loss: 1.7499
Batch 60, Loss: 1.7728
Batch 70, Loss: 1.7419
Batch 80, Loss: 1.7623
Batch 90, Loss: 1.7302
Batch 100, Loss: 1.7872
Batch 110, Loss: 1.8139
Batch 120, Loss: 1.8359
Batch 130, Loss: 1.7144
Batch 140, Loss: 1.6797
Batch 150, Loss: 1.7362
Batch 160, Loss: 1.7999
Batch 170, Loss: 1.7784
Batch 180, Loss: 1.7137
Batch 190, Loss: 1.6775
Batch 200, Loss: 1.7305
Batch 210, Loss: 1.7999
Batch 220, Loss: 1.7266
Batch 230, Loss: 1.7743
Batch 240, Loss: 1.7657
Batch 250, Loss: 1.7606
Batch 260, Loss: 1.7331
Batch 270, Loss: 1.6365
Batch 280, Loss: 1.7886
Batch 290, Loss: 1.7142
Batch 300, Loss: 1.6661
Batch 310, Loss: 1.8091
Batch 320, Loss: 1.7444
Batch 330, Loss: 1.7473
Batch 340, Loss: 1.7501
Batch 350, Loss: 1.7562
Batch 360, Loss: 1.7355
Batch 370, Loss: 1.8164
Batch 380, Loss: 1.7324
Batch 390, Loss: 1.7496
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.24747133255005 seconds
Epoch 14 accuracy: 49.38%
Batch 10, Loss: 1.6935
Batch 20, Loss: 1.7818
Batch 30, Loss: 1.6498
Batch 40, Loss: 1.6766
Batch 50, Loss: 1.6273
Batch 60, Loss: 1.6672
Batch 70, Loss: 1.6760
Batch 80, Loss: 1.7628
Batch 90, Loss: 1.6973
Batch 100, Loss: 1.6695
Batch 110, Loss: 1.7205
Batch 120, Loss: 1.6227
Batch 130, Loss: 1.6881
Batch 140, Loss: 1.7418
Batch 150, Loss: 1.6405
Batch 160, Loss: 1.7387
Batch 170, Loss: 1.6992
Batch 180, Loss: 1.6919
Batch 190, Loss: 1.7285
Batch 200, Loss: 1.7566
Batch 210, Loss: 1.7370
Batch 220, Loss: 1.7866
Batch 230, Loss: 1.7371
Batch 240, Loss: 1.7243
Batch 250, Loss: 1.6747
Batch 260, Loss: 1.7348
Batch 270, Loss: 1.7397
Batch 280, Loss: 1.7340
Batch 290, Loss: 1.7572
Batch 300, Loss: 1.7775
Batch 310, Loss: 1.6151
Batch 320, Loss: 1.7086
Batch 330, Loss: 1.7602
Batch 340, Loss: 1.7321
Batch 350, Loss: 1.6850
Batch 360, Loss: 1.6934
Batch 370, Loss: 1.7784
Batch 380, Loss: 1.7580
Batch 390, Loss: 1.7039
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.198835134506226 seconds
Epoch 15 accuracy: 46.69%
Batch 10, Loss: 1.6947
Batch 20, Loss: 1.6391
Batch 30, Loss: 1.6711
Batch 40, Loss: 1.7076
Batch 50, Loss: 1.6162
Batch 60, Loss: 1.6993
Batch 70, Loss: 1.6433
Batch 80, Loss: 1.6508
Batch 90, Loss: 1.6964
Batch 100, Loss: 1.7515
Batch 110, Loss: 1.6878
Batch 120, Loss: 1.7145
Batch 130, Loss: 1.6880
Batch 140, Loss: 1.7226
Batch 150, Loss: 1.7765
Batch 160, Loss: 1.6683
Batch 170, Loss: 1.6191
Batch 180, Loss: 1.6749
Batch 190, Loss: 1.6740
Batch 200, Loss: 1.6898
Batch 210, Loss: 1.6577
Batch 220, Loss: 1.6958
Batch 230, Loss: 1.7354
Batch 240, Loss: 1.6749
Batch 250, Loss: 1.6685
Batch 260, Loss: 1.6774
Batch 270, Loss: 1.7682
Batch 280, Loss: 1.7502
Batch 290, Loss: 1.7255
Batch 300, Loss: 1.6948
Batch 310, Loss: 1.7778
Batch 320, Loss: 1.7270
Batch 330, Loss: 1.6809
Batch 340, Loss: 1.7008
Batch 350, Loss: 1.6936
Batch 360, Loss: 1.6430
Batch 370, Loss: 1.6946
Batch 380, Loss: 1.6216
Batch 390, Loss: 1.7099
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.197673082351685 seconds
Epoch 16 accuracy: 47.14%
Batch 10, Loss: 1.6302
Batch 20, Loss: 1.6078
Batch 30, Loss: 1.6030
Batch 40, Loss: 1.5870
Batch 50, Loss: 1.6612
Batch 60, Loss: 1.6955
Batch 70, Loss: 1.7114
Batch 80, Loss: 1.7049
Batch 90, Loss: 1.7069
Batch 100, Loss: 1.6661
Batch 110, Loss: 1.6734
Batch 120, Loss: 1.6908
Batch 130, Loss: 1.6512
Batch 140, Loss: 1.6472
Batch 150, Loss: 1.6662
Batch 160, Loss: 1.6658
Batch 170, Loss: 1.6969
Batch 180, Loss: 1.6868
Batch 190, Loss: 1.7088
Batch 200, Loss: 1.6427
Batch 210, Loss: 1.7270
Batch 220, Loss: 1.6309
Batch 230, Loss: 1.7251
Batch 240, Loss: 1.7019
Batch 250, Loss: 1.7045
Batch 260, Loss: 1.6172
Batch 270, Loss: 1.6855
Batch 280, Loss: 1.6309
Batch 290, Loss: 1.7155
Batch 300, Loss: 1.6125
Batch 310, Loss: 1.6454
Batch 320, Loss: 1.6920
Batch 330, Loss: 1.7126
Batch 340, Loss: 1.6787
Batch 350, Loss: 1.7302
Batch 360, Loss: 1.7175
Batch 370, Loss: 1.7179
Batch 380, Loss: 1.6953
Batch 390, Loss: 1.6877
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.20895290374756 seconds
Epoch 17 accuracy: 53.59%
Batch 10, Loss: 1.6093
Batch 20, Loss: 1.5995
Batch 30, Loss: 1.6587
Batch 40, Loss: 1.6223
Batch 50, Loss: 1.5871
Batch 60, Loss: 1.5542
Batch 70, Loss: 1.6895
Batch 80, Loss: 1.6649
Batch 90, Loss: 1.6927
Batch 100, Loss: 1.6086
Batch 110, Loss: 1.5418
Batch 120, Loss: 1.5897
Batch 130, Loss: 1.6212
Batch 140, Loss: 1.6809
Batch 150, Loss: 1.6985
Batch 160, Loss: 1.6238
Batch 170, Loss: 1.6995
Batch 180, Loss: 1.6150
Batch 190, Loss: 1.6418
Batch 200, Loss: 1.6807
Batch 210, Loss: 1.6657
Batch 220, Loss: 1.6711
Batch 230, Loss: 1.6803
Batch 240, Loss: 1.6566
Batch 250, Loss: 1.6567
Batch 260, Loss: 1.6446
Batch 270, Loss: 1.6514
Batch 280, Loss: 1.7110
Batch 290, Loss: 1.7386
Batch 300, Loss: 1.6669
Batch 310, Loss: 1.6342
Batch 320, Loss: 1.6570
Batch 330, Loss: 1.6685
Batch 340, Loss: 1.6992
Batch 350, Loss: 1.6303
Batch 360, Loss: 1.6451
Batch 370, Loss: 1.6640
Batch 380, Loss: 1.6846
Batch 390, Loss: 1.6514
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.21712851524353 seconds
Epoch 18 accuracy: 52.24%
Batch 10, Loss: 1.5964
Batch 20, Loss: 1.6204
Batch 30, Loss: 1.6097
Batch 40, Loss: 1.6122
Batch 50, Loss: 1.5805
Batch 60, Loss: 1.6761
Batch 70, Loss: 1.6939
Batch 80, Loss: 1.6884
Batch 90, Loss: 1.6774
Batch 100, Loss: 1.6632
Batch 110, Loss: 1.6055
Batch 120, Loss: 1.6139
Batch 130, Loss: 1.6674
Batch 140, Loss: 1.6063
Batch 150, Loss: 1.6011
Batch 160, Loss: 1.7196
Batch 170, Loss: 1.6011
Batch 180, Loss: 1.5953
Batch 190, Loss: 1.7024
Batch 200, Loss: 1.6195
Batch 210, Loss: 1.5820
Batch 220, Loss: 1.6415
Batch 230, Loss: 1.6370
Batch 240, Loss: 1.6687
Batch 250, Loss: 1.5966
Batch 260, Loss: 1.6105
Batch 270, Loss: 1.6945
Batch 280, Loss: 1.6657
Batch 290, Loss: 1.6813
Batch 300, Loss: 1.6922
Batch 310, Loss: 1.6195
Batch 320, Loss: 1.5931
Batch 330, Loss: 1.6187
Batch 340, Loss: 1.7036
Batch 350, Loss: 1.6590
Batch 360, Loss: 1.6220
Batch 370, Loss: 1.5075
Batch 380, Loss: 1.5995
Batch 390, Loss: 1.6596
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.188443183898926 seconds
Epoch 19 accuracy: 52.12%
Batch 10, Loss: 1.6124
Batch 20, Loss: 1.6454
Batch 30, Loss: 1.6172
Batch 40, Loss: 1.6098
Batch 50, Loss: 1.6187
Batch 60, Loss: 1.6252
Batch 70, Loss: 1.5860
Batch 80, Loss: 1.5502
Batch 90, Loss: 1.5976
Batch 100, Loss: 1.6362
Batch 110, Loss: 1.6319
Batch 120, Loss: 1.6264
Batch 130, Loss: 1.6520
Batch 140, Loss: 1.5098
Batch 150, Loss: 1.5950
Batch 160, Loss: 1.5925
Batch 170, Loss: 1.6512
Batch 180, Loss: 1.7006
Batch 190, Loss: 1.5362
Batch 200, Loss: 1.6240
Batch 210, Loss: 1.5962
Batch 220, Loss: 1.6143
Batch 230, Loss: 1.6487
Batch 240, Loss: 1.6119
Batch 250, Loss: 1.6478
Batch 260, Loss: 1.6311
Batch 270, Loss: 1.6558
Batch 280, Loss: 1.6558
Batch 290, Loss: 1.6522
Batch 300, Loss: 1.6139
Batch 310, Loss: 1.6169
Batch 320, Loss: 1.6667
Batch 330, Loss: 1.6312
Batch 340, Loss: 1.6264
Batch 350, Loss: 1.6058
Batch 360, Loss: 1.6206
Batch 370, Loss: 1.6769
Batch 380, Loss: 1.6052
Batch 390, Loss: 1.6258
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.214548349380493 seconds
Epoch 20 accuracy: 50.33%
Batch 10, Loss: 1.6138
Batch 20, Loss: 1.5669
Batch 30, Loss: 1.5889
Batch 40, Loss: 1.5188
Batch 50, Loss: 1.6141
Batch 60, Loss: 1.5338
Batch 70, Loss: 1.5833
Batch 80, Loss: 1.6678
Batch 90, Loss: 1.5352
Batch 100, Loss: 1.5702
Batch 110, Loss: 1.6042
Batch 120, Loss: 1.5859
Batch 130, Loss: 1.5834
Batch 140, Loss: 1.6506
Batch 150, Loss: 1.6340
Batch 160, Loss: 1.6720
Batch 170, Loss: 1.5856
Batch 180, Loss: 1.5897
Batch 190, Loss: 1.6409
Batch 200, Loss: 1.5680
Batch 210, Loss: 1.6683
Batch 220, Loss: 1.7007
Batch 230, Loss: 1.6689
Batch 240, Loss: 1.6162
Batch 250, Loss: 1.6380
Batch 260, Loss: 1.6322
Batch 270, Loss: 1.5963
Batch 280, Loss: 1.5477
Batch 290, Loss: 1.5828
Batch 300, Loss: 1.5981
Batch 310, Loss: 1.6416
Batch 320, Loss: 1.6258
Batch 330, Loss: 1.6131
Batch 340, Loss: 1.5578
Batch 350, Loss: 1.7026
Batch 360, Loss: 1.6293
Batch 370, Loss: 1.6386
Batch 380, Loss: 1.5818
Batch 390, Loss: 1.6136
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.188040018081665 seconds
Epoch 21 accuracy: 53.95%
Batch 10, Loss: 1.5433
Batch 20, Loss: 1.4685
Batch 30, Loss: 1.5848
Batch 40, Loss: 1.5958
Batch 50, Loss: 1.6220
Batch 60, Loss: 1.5670
Batch 70, Loss: 1.6082
Batch 80, Loss: 1.5880
Batch 90, Loss: 1.5660
Batch 100, Loss: 1.5994
Batch 110, Loss: 1.5652
Batch 120, Loss: 1.6167
Batch 130, Loss: 1.5650
Batch 140, Loss: 1.5946
Batch 150, Loss: 1.6130
Batch 160, Loss: 1.5951
Batch 170, Loss: 1.5999
Batch 180, Loss: 1.6805
Batch 190, Loss: 1.5899
Batch 200, Loss: 1.5520
Batch 210, Loss: 1.5776
Batch 220, Loss: 1.5970
Batch 230, Loss: 1.6642
Batch 240, Loss: 1.6131
Batch 250, Loss: 1.5504
Batch 260, Loss: 1.6196
Batch 270, Loss: 1.6260
Batch 280, Loss: 1.6493
Batch 290, Loss: 1.5804
Batch 300, Loss: 1.6760
Batch 310, Loss: 1.6467
Batch 320, Loss: 1.6204
Batch 330, Loss: 1.5799
Batch 340, Loss: 1.5945
Batch 350, Loss: 1.6264
Batch 360, Loss: 1.5716
Batch 370, Loss: 1.6195
Batch 380, Loss: 1.5747
Batch 390, Loss: 1.5218
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.231842279434204 seconds
Epoch 22 accuracy: 50.4%
Batch 10, Loss: 1.6193
Batch 20, Loss: 1.5342
Batch 30, Loss: 1.6136
Batch 40, Loss: 1.5883
Batch 50, Loss: 1.5513
Batch 60, Loss: 1.5400
Batch 70, Loss: 1.6203
Batch 80, Loss: 1.5968
Batch 90, Loss: 1.5532
Batch 100, Loss: 1.5547
Batch 110, Loss: 1.5660
Batch 120, Loss: 1.6168
Batch 130, Loss: 1.5409
Batch 140, Loss: 1.5240
Batch 150, Loss: 1.6057
Batch 160, Loss: 1.6253
Batch 170, Loss: 1.6158
Batch 180, Loss: 1.5743
Batch 190, Loss: 1.5488
Batch 200, Loss: 1.6003
Batch 210, Loss: 1.6225
Batch 220, Loss: 1.5776
Batch 230, Loss: 1.5443
Batch 240, Loss: 1.6064
Batch 250, Loss: 1.5524
Batch 260, Loss: 1.6741
Batch 270, Loss: 1.6252
Batch 280, Loss: 1.5746
Batch 290, Loss: 1.6033
Batch 300, Loss: 1.5810
Batch 310, Loss: 1.5462
Batch 320, Loss: 1.5408
Batch 330, Loss: 1.6021
Batch 340, Loss: 1.6326
Batch 350, Loss: 1.5466
Batch 360, Loss: 1.5127
Batch 370, Loss: 1.5301
Batch 380, Loss: 1.5858
Batch 390, Loss: 1.6173
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.081626415252686 seconds
Epoch 23 accuracy: 53.61%
Batch 10, Loss: 1.5144
Batch 20, Loss: 1.5524
Batch 30, Loss: 1.5238
Batch 40, Loss: 1.5933
Batch 50, Loss: 1.4891
Batch 60, Loss: 1.5820
Batch 70, Loss: 1.5278
Batch 80, Loss: 1.5719
Batch 90, Loss: 1.6283
Batch 100, Loss: 1.5428
Batch 110, Loss: 1.5077
Batch 120, Loss: 1.4773
Batch 130, Loss: 1.5263
Batch 140, Loss: 1.5313
Batch 150, Loss: 1.5459
Batch 160, Loss: 1.5854
Batch 170, Loss: 1.6136
Batch 180, Loss: 1.5980
Batch 190, Loss: 1.5699
Batch 200, Loss: 1.5783
Batch 210, Loss: 1.5529
Batch 220, Loss: 1.5197
Batch 230, Loss: 1.5572
Batch 240, Loss: 1.5301
Batch 250, Loss: 1.6535
Batch 260, Loss: 1.5731
Batch 270, Loss: 1.6325
Batch 280, Loss: 1.6110
Batch 290, Loss: 1.6226
Batch 300, Loss: 1.5878
Batch 310, Loss: 1.6017
Batch 320, Loss: 1.6161
Batch 330, Loss: 1.6443
Batch 340, Loss: 1.5743
Batch 350, Loss: 1.5905
Batch 360, Loss: 1.6457
Batch 370, Loss: 1.5906
Batch 380, Loss: 1.6186
Batch 390, Loss: 1.6131
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.281058311462402 seconds
Epoch 24 accuracy: 54.8%
Batch 10, Loss: 1.5368
Batch 20, Loss: 1.5555
Batch 30, Loss: 1.5903
Batch 40, Loss: 1.5103
Batch 50, Loss: 1.5116
Batch 60, Loss: 1.5264
Batch 70, Loss: 1.4868
Batch 80, Loss: 1.5193
Batch 90, Loss: 1.5338
Batch 100, Loss: 1.5569
Batch 110, Loss: 1.5699
Batch 120, Loss: 1.5475
Batch 130, Loss: 1.5266
Batch 140, Loss: 1.5023
Batch 150, Loss: 1.5255
Batch 160, Loss: 1.5540
Batch 170, Loss: 1.6110
Batch 180, Loss: 1.5772
Batch 190, Loss: 1.5200
Batch 200, Loss: 1.5521
Batch 210, Loss: 1.5458
Batch 220, Loss: 1.5863
Batch 230, Loss: 1.5946
Batch 240, Loss: 1.5686
Batch 250, Loss: 1.6246
Batch 260, Loss: 1.5812
Batch 270, Loss: 1.5729
Batch 280, Loss: 1.5632
Batch 290, Loss: 1.5936
Batch 300, Loss: 1.5834
Batch 310, Loss: 1.5446
Batch 320, Loss: 1.5250
Batch 330, Loss: 1.5893
Batch 340, Loss: 1.5833
Batch 350, Loss: 1.6173
Batch 360, Loss: 1.6061
Batch 370, Loss: 1.5184
Batch 380, Loss: 1.5641
Batch 390, Loss: 1.6439
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.175633430480957 seconds
Epoch 25 accuracy: 51.93%
Batch 10, Loss: 1.5188
Batch 20, Loss: 1.5332
Batch 30, Loss: 1.4937
Batch 40, Loss: 1.4667
Batch 50, Loss: 1.5627
Batch 60, Loss: 1.5674
Batch 70, Loss: 1.5638
Batch 80, Loss: 1.5798
Batch 90, Loss: 1.5377
Batch 100, Loss: 1.5747
Batch 110, Loss: 1.4731
Batch 120, Loss: 1.4879
Batch 130, Loss: 1.5497
Batch 140, Loss: 1.5763
Batch 150, Loss: 1.5337
Batch 160, Loss: 1.5586
Batch 170, Loss: 1.5999
Batch 180, Loss: 1.5163
Batch 190, Loss: 1.5849
Batch 200, Loss: 1.5577
Batch 210, Loss: 1.4896
Batch 220, Loss: 1.6264
Batch 230, Loss: 1.5652
Batch 240, Loss: 1.5681
Batch 250, Loss: 1.6440
Batch 260, Loss: 1.5048
Batch 270, Loss: 1.6285
Batch 280, Loss: 1.5862
Batch 290, Loss: 1.5457
Batch 300, Loss: 1.5196
Batch 310, Loss: 1.5437
Batch 320, Loss: 1.5488
Batch 330, Loss: 1.5862
Batch 340, Loss: 1.5584
Batch 350, Loss: 1.5612
Batch 360, Loss: 1.6097
Batch 370, Loss: 1.5620
Batch 380, Loss: 1.5140
Batch 390, Loss: 1.5997
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.255646467208862 seconds
Epoch 26 accuracy: 53.34%
Batch 10, Loss: 1.4662
Batch 20, Loss: 1.5307
Batch 30, Loss: 1.5263
Batch 40, Loss: 1.4992
Batch 50, Loss: 1.5795
Batch 60, Loss: 1.5394
Batch 70, Loss: 1.5815
Batch 80, Loss: 1.5482
Batch 90, Loss: 1.5183
Batch 100, Loss: 1.4954
Batch 110, Loss: 1.5524
Batch 120, Loss: 1.5208
Batch 130, Loss: 1.5574
Batch 140, Loss: 1.5839
Batch 150, Loss: 1.6314
Batch 160, Loss: 1.5522
Batch 170, Loss: 1.4379
Batch 180, Loss: 1.4901
Batch 190, Loss: 1.5870
Batch 200, Loss: 1.6005
Batch 210, Loss: 1.5699
Batch 220, Loss: 1.5419
Batch 230, Loss: 1.4828
Batch 240, Loss: 1.5191
Batch 250, Loss: 1.5491
Batch 260, Loss: 1.5922
Batch 270, Loss: 1.5411
Batch 280, Loss: 1.5541
Batch 290, Loss: 1.5557
Batch 300, Loss: 1.5567
Batch 310, Loss: 1.5854
Batch 320, Loss: 1.5975
Batch 330, Loss: 1.5685
Batch 340, Loss: 1.5931
Batch 350, Loss: 1.5576
Batch 360, Loss: 1.5958
Batch 370, Loss: 1.5945
Batch 380, Loss: 1.5513
Batch 390, Loss: 1.5621
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.23112916946411 seconds
Epoch 27 accuracy: 54.97%
Batch 10, Loss: 1.5381
Batch 20, Loss: 1.5276
Batch 30, Loss: 1.4875
Batch 40, Loss: 1.4911
Batch 50, Loss: 1.4727
Batch 60, Loss: 1.5064
Batch 70, Loss: 1.5453
Batch 80, Loss: 1.5403
Batch 90, Loss: 1.6161
Batch 100, Loss: 1.5041
Batch 110, Loss: 1.5217
Batch 120, Loss: 1.5037
Batch 130, Loss: 1.4842
Batch 140, Loss: 1.5390
Batch 150, Loss: 1.5007
Batch 160, Loss: 1.5466
Batch 170, Loss: 1.5845
Batch 180, Loss: 1.6058
Batch 190, Loss: 1.5231
Batch 200, Loss: 1.5169
Batch 210, Loss: 1.5130
Batch 220, Loss: 1.5727
Batch 230, Loss: 1.5521
Batch 240, Loss: 1.5785
Batch 250, Loss: 1.5340
Batch 260, Loss: 1.5429
Batch 270, Loss: 1.5402
Batch 280, Loss: 1.5827
Batch 290, Loss: 1.6003
Batch 300, Loss: 1.5354
Batch 310, Loss: 1.5464
Batch 320, Loss: 1.5569
Batch 330, Loss: 1.6006
Batch 340, Loss: 1.5176
Batch 350, Loss: 1.5368
Batch 360, Loss: 1.5482
Batch 370, Loss: 1.5237
Batch 380, Loss: 1.5640
Batch 390, Loss: 1.5272
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.217212677001953 seconds
Epoch 28 accuracy: 53.3%
Batch 10, Loss: 1.4962
Batch 20, Loss: 1.4837
Batch 30, Loss: 1.4632
Batch 40, Loss: 1.4482
Batch 50, Loss: 1.5025
Batch 60, Loss: 1.5449
Batch 70, Loss: 1.5529
Batch 80, Loss: 1.5029
Batch 90, Loss: 1.4524
Batch 100, Loss: 1.4788
Batch 110, Loss: 1.4893
Batch 120, Loss: 1.5261
Batch 130, Loss: 1.5307
Batch 140, Loss: 1.5869
Batch 150, Loss: 1.4654
Batch 160, Loss: 1.4932
Batch 170, Loss: 1.4689
Batch 180, Loss: 1.5544
Batch 190, Loss: 1.5491
Batch 200, Loss: 1.5092
Batch 210, Loss: 1.4655
Batch 220, Loss: 1.5414
Batch 230, Loss: 1.5383
Batch 240, Loss: 1.5404
Batch 250, Loss: 1.5411
Batch 260, Loss: 1.5315
Batch 270, Loss: 1.4923
Batch 280, Loss: 1.5074
Batch 290, Loss: 1.5691
Batch 300, Loss: 1.4844
Batch 310, Loss: 1.5539
Batch 320, Loss: 1.5861
Batch 330, Loss: 1.5774
Batch 340, Loss: 1.5433
Batch 350, Loss: 1.5579
Batch 360, Loss: 1.5481
Batch 370, Loss: 1.5628
Batch 380, Loss: 1.5229
Batch 390, Loss: 1.5603
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.1556077003479 seconds
Epoch 29 accuracy: 54.55%
Batch 10, Loss: 1.4569
Batch 20, Loss: 1.5899
Batch 30, Loss: 1.4313
Batch 40, Loss: 1.4377
Batch 50, Loss: 1.5165
Batch 60, Loss: 1.4944
Batch 70, Loss: 1.5438
Batch 80, Loss: 1.4685
Batch 90, Loss: 1.5174
Batch 100, Loss: 1.5007
Batch 110, Loss: 1.4245
Batch 120, Loss: 1.5026
Batch 130, Loss: 1.4908
Batch 140, Loss: 1.4796
Batch 150, Loss: 1.5566
Batch 160, Loss: 1.4974
Batch 170, Loss: 1.5749
Batch 180, Loss: 1.4993
Batch 190, Loss: 1.5278
Batch 200, Loss: 1.5530
Batch 210, Loss: 1.4942
Batch 220, Loss: 1.6115
Batch 230, Loss: 1.5321
Batch 240, Loss: 1.5984
Batch 250, Loss: 1.5805
Batch 260, Loss: 1.4776
Batch 270, Loss: 1.5469
Batch 280, Loss: 1.5983
Batch 290, Loss: 1.5529
Batch 300, Loss: 1.5252
Batch 310, Loss: 1.4788
Batch 320, Loss: 1.5616
Batch 330, Loss: 1.5580
Batch 340, Loss: 1.4823
Batch 350, Loss: 1.4931
Batch 360, Loss: 1.5460
Batch 370, Loss: 1.5781
Batch 380, Loss: 1.5487
Batch 390, Loss: 1.5780
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.249898672103882 seconds
Epoch 30 accuracy: 53.34%
Batch 10, Loss: 1.4418
Batch 20, Loss: 1.5141
Batch 30, Loss: 1.4277
Batch 40, Loss: 1.4833
Batch 50, Loss: 1.4921
Batch 60, Loss: 1.4496
Batch 70, Loss: 1.5157
Batch 80, Loss: 1.4540
Batch 90, Loss: 1.4182
Batch 100, Loss: 1.4688
Batch 110, Loss: 1.4375
Batch 120, Loss: 1.5279
Batch 130, Loss: 1.4711
Batch 140, Loss: 1.4422
Batch 150, Loss: 1.4793
Batch 160, Loss: 1.5684
Batch 170, Loss: 1.5468
Batch 180, Loss: 1.5840
Batch 190, Loss: 1.5377
Batch 200, Loss: 1.5735
Batch 210, Loss: 1.5388
Batch 220, Loss: 1.5102
Batch 230, Loss: 1.4993
Batch 240, Loss: 1.5350
Batch 250, Loss: 1.5352
Batch 260, Loss: 1.5553
Batch 270, Loss: 1.4318
Batch 280, Loss: 1.5233
Batch 290, Loss: 1.5712
Batch 300, Loss: 1.5790
Batch 310, Loss: 1.4994
Batch 320, Loss: 1.5589
Batch 330, Loss: 1.5394
Batch 340, Loss: 1.5566
Batch 350, Loss: 1.5054
Batch 360, Loss: 1.4976
Batch 370, Loss: 1.5766
Batch 380, Loss: 1.5365
Batch 390, Loss: 1.5413
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.121192693710327 seconds
Epoch 31 accuracy: 56.22%
Batch 10, Loss: 1.4243
Batch 20, Loss: 1.4574
Batch 30, Loss: 1.5075
Batch 40, Loss: 1.5222
Batch 50, Loss: 1.4302
Batch 60, Loss: 1.4811
Batch 70, Loss: 1.4537
Batch 80, Loss: 1.4403
Batch 90, Loss: 1.4681
Batch 100, Loss: 1.5005
Batch 110, Loss: 1.4505
Batch 120, Loss: 1.5089
Batch 130, Loss: 1.5637
Batch 140, Loss: 1.5379
Batch 150, Loss: 1.5096
Batch 160, Loss: 1.4892
Batch 170, Loss: 1.4799
Batch 180, Loss: 1.4410
Batch 190, Loss: 1.5148
Batch 200, Loss: 1.5191
Batch 210, Loss: 1.5376
Batch 220, Loss: 1.5315
Batch 230, Loss: 1.5379
Batch 240, Loss: 1.5410
Batch 250, Loss: 1.5915
Batch 260, Loss: 1.5734
Batch 270, Loss: 1.5140
Batch 280, Loss: 1.4633
Batch 290, Loss: 1.5386
Batch 300, Loss: 1.5282
Batch 310, Loss: 1.5656
Batch 320, Loss: 1.6398
Batch 330, Loss: 1.5765
Batch 340, Loss: 1.6103
Batch 350, Loss: 1.5222
Batch 360, Loss: 1.6042
Batch 370, Loss: 1.5357
Batch 380, Loss: 1.4965
Batch 390, Loss: 1.4843
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.20238494873047 seconds
Epoch 32 accuracy: 53.84%
Batch 10, Loss: 1.4660
Batch 20, Loss: 1.5110
Batch 30, Loss: 1.4352
Batch 40, Loss: 1.4982
Batch 50, Loss: 1.4623
Batch 60, Loss: 1.3939
Batch 70, Loss: 1.4411
Batch 80, Loss: 1.4654
Batch 90, Loss: 1.5329
Batch 100, Loss: 1.4886
Batch 110, Loss: 1.4975
Batch 120, Loss: 1.5028
Batch 130, Loss: 1.5181
Batch 140, Loss: 1.5019
Batch 150, Loss: 1.4850
Batch 160, Loss: 1.4739
Batch 170, Loss: 1.3864
Batch 180, Loss: 1.4574
Batch 190, Loss: 1.4322
Batch 200, Loss: 1.5013
Batch 210, Loss: 1.4863
Batch 220, Loss: 1.4881
Batch 230, Loss: 1.5276
Batch 240, Loss: 1.5477
Batch 250, Loss: 1.5050
Batch 260, Loss: 1.4676
Batch 270, Loss: 1.4730
Batch 280, Loss: 1.5260
Batch 290, Loss: 1.4496
Batch 300, Loss: 1.4311
Batch 310, Loss: 1.5335
Batch 320, Loss: 1.5086
Batch 330, Loss: 1.5408
Batch 340, Loss: 1.5272
Batch 350, Loss: 1.5382
Batch 360, Loss: 1.5343
Batch 370, Loss: 1.5469
Batch 380, Loss: 1.5175
Batch 390, Loss: 1.4821
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.22083282470703 seconds
Epoch 33 accuracy: 55.95%
Batch 10, Loss: 1.4893
Batch 20, Loss: 1.4397
Batch 30, Loss: 1.4297
Batch 40, Loss: 1.4586
Batch 50, Loss: 1.4662
Batch 60, Loss: 1.3954
Batch 70, Loss: 1.4798
Batch 80, Loss: 1.4274
Batch 90, Loss: 1.4370
Batch 100, Loss: 1.4362
Batch 110, Loss: 1.4881
Batch 120, Loss: 1.5259
Batch 130, Loss: 1.4810
Batch 140, Loss: 1.4996
Batch 150, Loss: 1.5143
Batch 160, Loss: 1.4112
Batch 170, Loss: 1.4363
Batch 180, Loss: 1.4594
Batch 190, Loss: 1.5003
Batch 200, Loss: 1.4857
Batch 210, Loss: 1.4540
Batch 220, Loss: 1.5219
Batch 230, Loss: 1.5592
Batch 240, Loss: 1.5466
Batch 250, Loss: 1.5104
Batch 260, Loss: 1.5776
Batch 270, Loss: 1.5520
Batch 280, Loss: 1.4721
Batch 290, Loss: 1.4885
Batch 300, Loss: 1.4781
Batch 310, Loss: 1.5050
Batch 320, Loss: 1.5753
Batch 330, Loss: 1.4780
Batch 340, Loss: 1.5081
Batch 350, Loss: 1.4944
Batch 360, Loss: 1.6315
Batch 370, Loss: 1.4959
Batch 380, Loss: 1.5777
Batch 390, Loss: 1.5506
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.175111532211304 seconds
Epoch 34 accuracy: 53.58%
Batch 10, Loss: 1.4547
Batch 20, Loss: 1.4259
Batch 30, Loss: 1.4662
Batch 40, Loss: 1.4544
Batch 50, Loss: 1.5357
Batch 60, Loss: 1.4622
Batch 70, Loss: 1.4920
Batch 80, Loss: 1.4037
Batch 90, Loss: 1.4562
Batch 100, Loss: 1.4801
Batch 110, Loss: 1.4975
Batch 120, Loss: 1.4576
Batch 130, Loss: 1.3703
Batch 140, Loss: 1.4448
Batch 150, Loss: 1.5760
Batch 160, Loss: 1.4720
Batch 170, Loss: 1.4709
Batch 180, Loss: 1.4373
Batch 190, Loss: 1.5473
Batch 200, Loss: 1.5135
Batch 210, Loss: 1.4686
Batch 220, Loss: 1.4749
Batch 230, Loss: 1.5542
Batch 240, Loss: 1.5312
Batch 250, Loss: 1.4845
Batch 260, Loss: 1.4897
Batch 270, Loss: 1.4665
Batch 280, Loss: 1.5021
Batch 290, Loss: 1.5367
Batch 300, Loss: 1.4842
Batch 310, Loss: 1.5142
Batch 320, Loss: 1.4914
Batch 330, Loss: 1.5173
Batch 340, Loss: 1.4751
Batch 350, Loss: 1.5319
Batch 360, Loss: 1.5211
Batch 370, Loss: 1.4615
Batch 380, Loss: 1.4552
Batch 390, Loss: 1.4812
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.275126457214355 seconds
Epoch 35 accuracy: 54.64%
Batch 10, Loss: 1.4565
Batch 20, Loss: 1.5192
Batch 30, Loss: 1.3508
Batch 40, Loss: 1.4333
Batch 50, Loss: 1.3849
Batch 60, Loss: 1.4832
Batch 70, Loss: 1.4341
Batch 80, Loss: 1.5085
Batch 90, Loss: 1.5368
Batch 100, Loss: 1.4820
Batch 110, Loss: 1.5015
Batch 120, Loss: 1.4869
Batch 130, Loss: 1.4668
Batch 140, Loss: 1.4871
Batch 150, Loss: 1.4826
Batch 160, Loss: 1.4790
Batch 170, Loss: 1.4695
Batch 180, Loss: 1.4742
Batch 190, Loss: 1.3946
Batch 200, Loss: 1.4558
Batch 210, Loss: 1.4915
Batch 220, Loss: 1.5109
Batch 230, Loss: 1.4874
Batch 240, Loss: 1.4416
Batch 250, Loss: 1.5585
Batch 260, Loss: 1.5231
Batch 270, Loss: 1.5157
Batch 280, Loss: 1.4915
Batch 290, Loss: 1.5963
Batch 300, Loss: 1.4966
Batch 310, Loss: 1.5181
Batch 320, Loss: 1.3995
Batch 330, Loss: 1.4827
Batch 340, Loss: 1.4833
Batch 350, Loss: 1.4911
Batch 360, Loss: 1.5696
Batch 370, Loss: 1.5792
Batch 380, Loss: 1.5409
Batch 390, Loss: 1.4444
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.266566514968872 seconds
Epoch 36 accuracy: 55.33%
Batch 10, Loss: 1.4769
Batch 20, Loss: 1.3897
Batch 30, Loss: 1.3729
Batch 40, Loss: 1.3924
Batch 50, Loss: 1.4501
Batch 60, Loss: 1.5249
Batch 70, Loss: 1.4705
Batch 80, Loss: 1.4622
Batch 90, Loss: 1.4953
Batch 100, Loss: 1.5250
Batch 110, Loss: 1.4892
Batch 120, Loss: 1.4711
Batch 130, Loss: 1.5343
Batch 140, Loss: 1.4827
Batch 150, Loss: 1.4455
Batch 160, Loss: 1.4348
Batch 170, Loss: 1.4196
Batch 180, Loss: 1.4638
Batch 190, Loss: 1.5334
Batch 200, Loss: 1.4798
Batch 210, Loss: 1.5664
Batch 220, Loss: 1.4728
Batch 230, Loss: 1.4555
Batch 240, Loss: 1.4871
Batch 250, Loss: 1.4153
Batch 260, Loss: 1.4726
Batch 270, Loss: 1.4726
Batch 280, Loss: 1.4320
Batch 290, Loss: 1.4727
Batch 300, Loss: 1.4727
Batch 310, Loss: 1.5520
Batch 320, Loss: 1.4752
Batch 330, Loss: 1.4678
Batch 340, Loss: 1.5043
Batch 350, Loss: 1.5526
Batch 360, Loss: 1.5004
Batch 370, Loss: 1.4982
Batch 380, Loss: 1.4413
Batch 390, Loss: 1.5042
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.13729739189148 seconds
Epoch 37 accuracy: 58.06%
Batch 10, Loss: 1.4693
Batch 20, Loss: 1.4605
Batch 30, Loss: 1.4313
Batch 40, Loss: 1.4172
Batch 50, Loss: 1.4144
Batch 60, Loss: 1.4598
Batch 70, Loss: 1.4810
Batch 80, Loss: 1.4121
Batch 90, Loss: 1.4284
Batch 100, Loss: 1.4829
Batch 110, Loss: 1.4483
Batch 120, Loss: 1.5534
Batch 130, Loss: 1.4652
Batch 140, Loss: 1.4702
Batch 150, Loss: 1.5350
Batch 160, Loss: 1.5083
Batch 170, Loss: 1.5192
Batch 180, Loss: 1.4629
Batch 190, Loss: 1.4752
Batch 200, Loss: 1.5130
Batch 210, Loss: 1.4857
Batch 220, Loss: 1.4125
Batch 230, Loss: 1.4935
Batch 240, Loss: 1.4221
Batch 250, Loss: 1.4767
Batch 260, Loss: 1.4802
Batch 270, Loss: 1.4784
Batch 280, Loss: 1.4898
Batch 290, Loss: 1.4804
Batch 300, Loss: 1.4645
Batch 310, Loss: 1.5171
Batch 320, Loss: 1.4591
Batch 330, Loss: 1.4428
Batch 340, Loss: 1.4673
Batch 350, Loss: 1.4755
Batch 360, Loss: 1.5301
Batch 370, Loss: 1.4563
Batch 380, Loss: 1.5940
Batch 390, Loss: 1.5041
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.11988925933838 seconds
Epoch 38 accuracy: 57.22%
Batch 10, Loss: 1.5266
Batch 20, Loss: 1.3707
Batch 30, Loss: 1.4075
Batch 40, Loss: 1.4053
Batch 50, Loss: 1.4233
Batch 60, Loss: 1.3963
Batch 70, Loss: 1.4018
Batch 80, Loss: 1.4053
Batch 90, Loss: 1.4113
Batch 100, Loss: 1.3828
Batch 110, Loss: 1.4820
Batch 120, Loss: 1.4223
Batch 130, Loss: 1.4093
Batch 140, Loss: 1.4727
Batch 150, Loss: 1.4602
Batch 160, Loss: 1.4605
Batch 170, Loss: 1.5250
Batch 180, Loss: 1.4901
Batch 190, Loss: 1.5008
Batch 200, Loss: 1.4507
Batch 210, Loss: 1.4755
Batch 220, Loss: 1.4180
Batch 230, Loss: 1.4411
Batch 240, Loss: 1.4012
Batch 250, Loss: 1.4259
Batch 260, Loss: 1.4280
Batch 270, Loss: 1.4789
Batch 280, Loss: 1.5363
Batch 290, Loss: 1.4239
Batch 300, Loss: 1.5256
Batch 310, Loss: 1.4809
Batch 320, Loss: 1.4704
Batch 330, Loss: 1.4866
Batch 340, Loss: 1.5384
Batch 350, Loss: 1.4720
Batch 360, Loss: 1.4861
Batch 370, Loss: 1.4903
Batch 380, Loss: 1.4977
Batch 390, Loss: 1.5063
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.194952726364136 seconds
Epoch 39 accuracy: 57.22%
Batch 10, Loss: 1.4575
Batch 20, Loss: 1.4056
Batch 30, Loss: 1.3962
Batch 40, Loss: 1.3987
Batch 50, Loss: 1.4587
Batch 60, Loss: 1.4804
Batch 70, Loss: 1.4024
Batch 80, Loss: 1.4503
Batch 90, Loss: 1.4632
Batch 100, Loss: 1.4518
Batch 110, Loss: 1.3568
Batch 120, Loss: 1.3254
Batch 130, Loss: 1.4621
Batch 140, Loss: 1.4316
Batch 150, Loss: 1.4833
Batch 160, Loss: 1.4346
Batch 170, Loss: 1.3856
Batch 180, Loss: 1.3924
Batch 190, Loss: 1.4116
Batch 200, Loss: 1.4319
Batch 210, Loss: 1.4146
Batch 220, Loss: 1.5106
Batch 230, Loss: 1.4272
Batch 240, Loss: 1.5313
Batch 250, Loss: 1.4752
Batch 260, Loss: 1.4052
Batch 270, Loss: 1.4609
Batch 280, Loss: 1.4538
Batch 290, Loss: 1.3900
Batch 300, Loss: 1.4979
Batch 310, Loss: 1.2966
Batch 320, Loss: 1.4610
Batch 330, Loss: 1.4291
Batch 340, Loss: 1.4947
Batch 350, Loss: 1.3917
Batch 360, Loss: 1.5119
Batch 370, Loss: 1.4513
Batch 380, Loss: 1.4287
Batch 390, Loss: 1.4881
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.260852575302124 seconds
Epoch 40 accuracy: 57.7%
Batch 10, Loss: 1.3598
Batch 20, Loss: 1.4917
Batch 30, Loss: 1.4422
Batch 40, Loss: 1.4167
Batch 50, Loss: 1.4749
Batch 60, Loss: 1.4705
Batch 70, Loss: 1.3979
Batch 80, Loss: 1.4515
Batch 90, Loss: 1.4340
Batch 100, Loss: 1.4395
Batch 110, Loss: 1.4406
Batch 120, Loss: 1.4930
Batch 130, Loss: 1.4462
Batch 140, Loss: 1.4927
Batch 150, Loss: 1.4319
Batch 160, Loss: 1.4637
Batch 170, Loss: 1.4948
Batch 180, Loss: 1.4022
Batch 190, Loss: 1.3842
Batch 200, Loss: 1.4841
Batch 210, Loss: 1.5088
Batch 220, Loss: 1.4599
Batch 230, Loss: 1.4586
Batch 240, Loss: 1.4768
Batch 250, Loss: 1.4503
Batch 260, Loss: 1.4659
Batch 270, Loss: 1.4649
Batch 280, Loss: 1.4570
Batch 290, Loss: 1.5282
Batch 300, Loss: 1.4794
Batch 310, Loss: 1.4743
Batch 320, Loss: 1.4699
Batch 330, Loss: 1.4693
Batch 340, Loss: 1.4233
Batch 350, Loss: 1.4246
Batch 360, Loss: 1.4520
Batch 370, Loss: 1.4365
Batch 380, Loss: 1.5229
Batch 390, Loss: 1.4338
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.10501217842102 seconds
Epoch 41 accuracy: 59.17%
Batch 10, Loss: 1.3689
Batch 20, Loss: 1.4298
Batch 30, Loss: 1.4083
Batch 40, Loss: 1.5190
Batch 50, Loss: 1.4127
Batch 60, Loss: 1.4027
Batch 70, Loss: 1.3794
Batch 80, Loss: 1.4357
Batch 90, Loss: 1.4729
Batch 100, Loss: 1.4148
Batch 110, Loss: 1.4062
Batch 120, Loss: 1.4098
Batch 130, Loss: 1.4944
Batch 140, Loss: 1.5003
Batch 150, Loss: 1.3942
Batch 160, Loss: 1.3719
Batch 170, Loss: 1.4209
Batch 180, Loss: 1.4182
Batch 190, Loss: 1.4415
Batch 200, Loss: 1.4743
Batch 210, Loss: 1.4626
Batch 220, Loss: 1.4287
Batch 230, Loss: 1.4555
Batch 240, Loss: 1.4520
Batch 250, Loss: 1.4807
Batch 260, Loss: 1.4491
Batch 270, Loss: 1.4286
Batch 280, Loss: 1.4771
Batch 290, Loss: 1.4105
Batch 300, Loss: 1.4301
Batch 310, Loss: 1.4422
Batch 320, Loss: 1.5162
Batch 330, Loss: 1.4909
Batch 340, Loss: 1.4770
Batch 350, Loss: 1.4377
Batch 360, Loss: 1.4570
Batch 370, Loss: 1.4457
Batch 380, Loss: 1.4342
Batch 390, Loss: 1.4875
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.137681484222412 seconds
Epoch 42 accuracy: 54.16%
Batch 10, Loss: 1.4233
Batch 20, Loss: 1.3961
Batch 30, Loss: 1.4236
Batch 40, Loss: 1.4340
Batch 50, Loss: 1.3979
Batch 60, Loss: 1.4452
Batch 70, Loss: 1.4021
Batch 80, Loss: 1.3963
Batch 90, Loss: 1.4650
Batch 100, Loss: 1.3917
Batch 110, Loss: 1.3857
Batch 120, Loss: 1.3924
Batch 130, Loss: 1.4562
Batch 140, Loss: 1.4081
Batch 150, Loss: 1.3932
Batch 160, Loss: 1.4508
Batch 170, Loss: 1.3964
Batch 180, Loss: 1.3890
Batch 190, Loss: 1.3862
Batch 200, Loss: 1.4219
Batch 210, Loss: 1.4226
Batch 220, Loss: 1.3889
Batch 230, Loss: 1.3745
Batch 240, Loss: 1.4585
Batch 250, Loss: 1.4219
Batch 260, Loss: 1.4460
Batch 270, Loss: 1.4772
Batch 280, Loss: 1.4694
Batch 290, Loss: 1.4939
Batch 300, Loss: 1.4104
Batch 310, Loss: 1.4788
Batch 320, Loss: 1.4271
Batch 330, Loss: 1.4643
Batch 340, Loss: 1.4156
Batch 350, Loss: 1.3909
Batch 360, Loss: 1.4700
Batch 370, Loss: 1.4538
Batch 380, Loss: 1.4925
Batch 390, Loss: 1.4806
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.228272199630737 seconds
Epoch 43 accuracy: 56.61%
Batch 10, Loss: 1.3435
Batch 20, Loss: 1.3925
Batch 30, Loss: 1.4282
Batch 40, Loss: 1.4467
Batch 50, Loss: 1.3933
Batch 60, Loss: 1.3513
Batch 70, Loss: 1.4026
Batch 80, Loss: 1.4230
Batch 90, Loss: 1.4543
Batch 100, Loss: 1.4633
Batch 110, Loss: 1.3700
Batch 120, Loss: 1.3861
Batch 130, Loss: 1.4642
Batch 140, Loss: 1.4371
Batch 150, Loss: 1.4616
Batch 160, Loss: 1.3907
Batch 170, Loss: 1.3968
Batch 180, Loss: 1.4023
Batch 190, Loss: 1.4619
Batch 200, Loss: 1.4544
Batch 210, Loss: 1.3595
Batch 220, Loss: 1.4317
Batch 230, Loss: 1.4288
Batch 240, Loss: 1.4528
Batch 250, Loss: 1.4856
Batch 260, Loss: 1.5126
Batch 270, Loss: 1.5280
Batch 280, Loss: 1.4568
Batch 290, Loss: 1.4699
Batch 300, Loss: 1.4271
Batch 310, Loss: 1.4660
Batch 320, Loss: 1.3909
Batch 330, Loss: 1.3945
Batch 340, Loss: 1.4953
Batch 350, Loss: 1.4609
Batch 360, Loss: 1.5033
Batch 370, Loss: 1.4212
Batch 380, Loss: 1.4740
Batch 390, Loss: 1.4819
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.197311878204346 seconds
Epoch 44 accuracy: 56.09%
Batch 10, Loss: 1.4033
Batch 20, Loss: 1.3840
Batch 30, Loss: 1.3466
Batch 40, Loss: 1.3885
Batch 50, Loss: 1.4218
Batch 60, Loss: 1.4421
Batch 70, Loss: 1.4102
Batch 80, Loss: 1.4518
Batch 90, Loss: 1.4798
Batch 100, Loss: 1.3647
Batch 110, Loss: 1.4826
Batch 120, Loss: 1.4337
Batch 130, Loss: 1.3731
Batch 140, Loss: 1.3901
Batch 150, Loss: 1.3996
Batch 160, Loss: 1.3930
Batch 170, Loss: 1.3545
Batch 180, Loss: 1.4197
Batch 190, Loss: 1.4460
Batch 200, Loss: 1.3866
Batch 210, Loss: 1.5038
Batch 220, Loss: 1.4298
Batch 230, Loss: 1.4595
Batch 240, Loss: 1.4284
Batch 250, Loss: 1.4439
Batch 260, Loss: 1.4583
Batch 270, Loss: 1.4154
Batch 280, Loss: 1.4265
Batch 290, Loss: 1.4059
Batch 300, Loss: 1.4470
Batch 310, Loss: 1.4207
Batch 320, Loss: 1.4016
Batch 330, Loss: 1.3836
Batch 340, Loss: 1.4764
Batch 350, Loss: 1.4122
Batch 360, Loss: 1.4630
Batch 370, Loss: 1.4258
Batch 380, Loss: 1.4540
Batch 390, Loss: 1.5047
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.318169355392456 seconds
Epoch 45 accuracy: 58.12%
Batch 10, Loss: 1.3945
Batch 20, Loss: 1.3741
Batch 30, Loss: 1.4566
Batch 40, Loss: 1.3435
Batch 50, Loss: 1.4197
Batch 60, Loss: 1.4242
Batch 70, Loss: 1.4466
Batch 80, Loss: 1.3904
Batch 90, Loss: 1.3617
Batch 100, Loss: 1.4286
Batch 110, Loss: 1.3474
Batch 120, Loss: 1.4090
Batch 130, Loss: 1.4420
Batch 140, Loss: 1.4753
Batch 150, Loss: 1.4195
Batch 160, Loss: 1.4226
Batch 170, Loss: 1.4824
Batch 180, Loss: 1.3987
Batch 190, Loss: 1.3550
Batch 200, Loss: 1.4232
Batch 210, Loss: 1.5121
Batch 220, Loss: 1.3987
Batch 230, Loss: 1.4754
Batch 240, Loss: 1.4151
Batch 250, Loss: 1.4581
Batch 260, Loss: 1.4474
Batch 270, Loss: 1.4343
Batch 280, Loss: 1.4793
Batch 290, Loss: 1.4998
Batch 300, Loss: 1.4350
Batch 310, Loss: 1.3861
Batch 320, Loss: 1.4541
Batch 330, Loss: 1.4030
Batch 340, Loss: 1.3967
Batch 350, Loss: 1.4190
Batch 360, Loss: 1.4330
Batch 370, Loss: 1.4612
Batch 380, Loss: 1.4929
Batch 390, Loss: 1.4244
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.23552107810974 seconds
Epoch 46 accuracy: 55.95%
Batch 10, Loss: 1.3780
Batch 20, Loss: 1.3024
Batch 30, Loss: 1.4383
Batch 40, Loss: 1.3697
Batch 50, Loss: 1.3345
Batch 60, Loss: 1.3750
Batch 70, Loss: 1.3835
Batch 80, Loss: 1.3316
Batch 90, Loss: 1.4117
Batch 100, Loss: 1.4295
Batch 110, Loss: 1.4852
Batch 120, Loss: 1.3894
Batch 130, Loss: 1.4815
Batch 140, Loss: 1.4196
Batch 150, Loss: 1.4534
Batch 160, Loss: 1.3909
Batch 170, Loss: 1.4400
Batch 180, Loss: 1.4622
Batch 190, Loss: 1.4039
Batch 200, Loss: 1.4025
Batch 210, Loss: 1.4224
Batch 220, Loss: 1.4193
Batch 230, Loss: 1.3650
Batch 240, Loss: 1.4867
Batch 250, Loss: 1.4287
Batch 260, Loss: 1.4516
Batch 270, Loss: 1.4645
Batch 280, Loss: 1.3953
Batch 290, Loss: 1.3777
Batch 300, Loss: 1.4396
Batch 310, Loss: 1.4049
Batch 320, Loss: 1.4311
Batch 330, Loss: 1.4682
Batch 340, Loss: 1.4542
Batch 350, Loss: 1.4246
Batch 360, Loss: 1.4138
Batch 370, Loss: 1.5235
Batch 380, Loss: 1.4113
Batch 390, Loss: 1.4321
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.139803886413574 seconds
Epoch 47 accuracy: 60.1%
Batch 10, Loss: 1.3746
Batch 20, Loss: 1.3656
Batch 30, Loss: 1.3425
Batch 40, Loss: 1.3770
Batch 50, Loss: 1.4285
Batch 60, Loss: 1.3936
Batch 70, Loss: 1.4027
Batch 80, Loss: 1.3689
Batch 90, Loss: 1.3730
Batch 100, Loss: 1.3489
Batch 110, Loss: 1.3902
Batch 120, Loss: 1.4146
Batch 130, Loss: 1.4190
Batch 140, Loss: 1.3489
Batch 150, Loss: 1.4392
Batch 160, Loss: 1.3833
Batch 170, Loss: 1.3657
Batch 180, Loss: 1.4628
Batch 190, Loss: 1.4426
Batch 200, Loss: 1.4070
Batch 210, Loss: 1.4560
Batch 220, Loss: 1.3869
Batch 230, Loss: 1.4503
Batch 240, Loss: 1.3520
Batch 250, Loss: 1.4125
Batch 260, Loss: 1.4027
Batch 270, Loss: 1.4565
Batch 280, Loss: 1.3632
Batch 290, Loss: 1.4081
Batch 300, Loss: 1.4543
Batch 310, Loss: 1.3509
Batch 320, Loss: 1.4424
Batch 330, Loss: 1.4731
Batch 340, Loss: 1.3847
Batch 350, Loss: 1.3584
Batch 360, Loss: 1.3807
Batch 370, Loss: 1.4284
Batch 380, Loss: 1.5506
Batch 390, Loss: 1.4305
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.11825132369995 seconds
Epoch 48 accuracy: 59.33%
Batch 10, Loss: 1.4192
Batch 20, Loss: 1.3994
Batch 30, Loss: 1.3964
Batch 40, Loss: 1.3285
Batch 50, Loss: 1.3158
Batch 60, Loss: 1.3499
Batch 70, Loss: 1.4216
Batch 80, Loss: 1.3551
Batch 90, Loss: 1.4102
Batch 100, Loss: 1.3733
Batch 110, Loss: 1.3874
Batch 120, Loss: 1.4194
Batch 130, Loss: 1.3598
Batch 140, Loss: 1.3938
Batch 150, Loss: 1.4205
Batch 160, Loss: 1.3974
Batch 170, Loss: 1.3824
Batch 180, Loss: 1.3935
Batch 190, Loss: 1.3429
Batch 200, Loss: 1.3932
Batch 210, Loss: 1.4294
Batch 220, Loss: 1.4203
Batch 230, Loss: 1.3702
Batch 240, Loss: 1.4545
Batch 250, Loss: 1.4162
Batch 260, Loss: 1.4242
Batch 270, Loss: 1.4872
Batch 280, Loss: 1.4400
Batch 290, Loss: 1.4444
Batch 300, Loss: 1.4218
Batch 310, Loss: 1.4445
Batch 320, Loss: 1.3659
Batch 330, Loss: 1.4251
Batch 340, Loss: 1.4508
Batch 350, Loss: 1.4272
Batch 360, Loss: 1.3978
Batch 370, Loss: 1.4677
Batch 380, Loss: 1.3888
Batch 390, Loss: 1.4516
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.268454790115356 seconds
Epoch 49 accuracy: 60.16%
Batch 10, Loss: 1.3427
Batch 20, Loss: 1.3979
Batch 30, Loss: 1.3632
Batch 40, Loss: 1.2998
Batch 50, Loss: 1.4068
Batch 60, Loss: 1.3537
Batch 70, Loss: 1.4350
Batch 80, Loss: 1.3056
Batch 90, Loss: 1.4073
Batch 100, Loss: 1.4683
Batch 110, Loss: 1.4351
Batch 120, Loss: 1.4159
Batch 130, Loss: 1.3307
Batch 140, Loss: 1.3560
Batch 150, Loss: 1.4926
Batch 160, Loss: 1.4001
Batch 170, Loss: 1.3012
Batch 180, Loss: 1.3764
Batch 190, Loss: 1.3882
Batch 200, Loss: 1.4923
Batch 210, Loss: 1.5021
Batch 220, Loss: 1.4418
Batch 230, Loss: 1.4048
Batch 240, Loss: 1.3610
Batch 250, Loss: 1.4350
Batch 260, Loss: 1.4735
Batch 270, Loss: 1.4954
Batch 280, Loss: 1.4430
Batch 290, Loss: 1.3181
Batch 300, Loss: 1.4695
Batch 310, Loss: 1.4276
Batch 320, Loss: 1.4178
Batch 330, Loss: 1.4464
Batch 340, Loss: 1.4012
Batch 350, Loss: 1.4954
Batch 360, Loss: 1.3893
Batch 370, Loss: 1.3986
Batch 380, Loss: 1.4633
Batch 390, Loss: 1.3983
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.215460538864136 seconds
Epoch 50 accuracy: 57.46%
Batch 10, Loss: 1.3905
Batch 20, Loss: 1.3275
Batch 30, Loss: 1.3243
Batch 40, Loss: 1.3783
Batch 50, Loss: 1.3322
Batch 60, Loss: 1.3904
Batch 70, Loss: 1.4379
Batch 80, Loss: 1.3460
Batch 90, Loss: 1.3269
Batch 100, Loss: 1.4212
Batch 110, Loss: 1.3665
Batch 120, Loss: 1.3844
Batch 130, Loss: 1.3726
Batch 140, Loss: 1.3881
Batch 150, Loss: 1.4003
Batch 160, Loss: 1.4273
Batch 170, Loss: 1.4059
Batch 180, Loss: 1.4287
Batch 190, Loss: 1.4146
Batch 200, Loss: 1.4079
Batch 210, Loss: 1.3985
Batch 220, Loss: 1.3434
Batch 230, Loss: 1.4078
Batch 240, Loss: 1.3668
Batch 250, Loss: 1.4683
Batch 260, Loss: 1.4104
Batch 270, Loss: 1.4212
Batch 280, Loss: 1.4874
Batch 290, Loss: 1.4605
Batch 300, Loss: 1.4044
Batch 310, Loss: 1.4260
Batch 320, Loss: 1.3554
Batch 330, Loss: 1.3878
Batch 340, Loss: 1.3868
Batch 350, Loss: 1.3785
Batch 360, Loss: 1.5111
Batch 370, Loss: 1.4233
Batch 380, Loss: 1.3638
Batch 390, Loss: 1.3719
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.13662576675415 seconds
Epoch 51 accuracy: 59.16%
Batch 10, Loss: 1.3798
Batch 20, Loss: 1.3872
Batch 30, Loss: 1.3735
Batch 40, Loss: 1.3134
Batch 50, Loss: 1.4080
Batch 60, Loss: 1.4037
Batch 70, Loss: 1.4112
Batch 80, Loss: 1.3398
Batch 90, Loss: 1.3673
Batch 100, Loss: 1.3263
Batch 110, Loss: 1.4032
Batch 120, Loss: 1.3635
Batch 130, Loss: 1.3405
Batch 140, Loss: 1.3460
Batch 150, Loss: 1.3794
Batch 160, Loss: 1.3623
Batch 170, Loss: 1.3880
Batch 180, Loss: 1.4224
Batch 190, Loss: 1.4664
Batch 200, Loss: 1.3999
Batch 210, Loss: 1.3748
Batch 220, Loss: 1.4157
Batch 230, Loss: 1.4113
Batch 240, Loss: 1.3973
Batch 250, Loss: 1.3859
Batch 260, Loss: 1.4088
Batch 270, Loss: 1.3639
Batch 280, Loss: 1.3528
Batch 290, Loss: 1.3821
Batch 300, Loss: 1.5066
Batch 310, Loss: 1.4235
Batch 320, Loss: 1.3697
Batch 330, Loss: 1.3867
Batch 340, Loss: 1.3539
Batch 350, Loss: 1.4574
Batch 360, Loss: 1.3599
Batch 370, Loss: 1.3707
Batch 380, Loss: 1.4474
Batch 390, Loss: 1.4584
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.177122592926025 seconds
Epoch 52 accuracy: 56.96%
Batch 10, Loss: 1.3320
Batch 20, Loss: 1.3658
Batch 30, Loss: 1.3381
Batch 40, Loss: 1.4106
Batch 50, Loss: 1.3470
Batch 60, Loss: 1.3453
Batch 70, Loss: 1.3550
Batch 80, Loss: 1.3393
Batch 90, Loss: 1.3412
Batch 100, Loss: 1.3370
Batch 110, Loss: 1.4062
Batch 120, Loss: 1.4017
Batch 130, Loss: 1.4418
Batch 140, Loss: 1.4306
Batch 150, Loss: 1.4544
Batch 160, Loss: 1.3821
Batch 170, Loss: 1.3874
Batch 180, Loss: 1.3872
Batch 190, Loss: 1.3413
Batch 200, Loss: 1.4357
Batch 210, Loss: 1.3986
Batch 220, Loss: 1.4231
Batch 230, Loss: 1.4343
Batch 240, Loss: 1.4302
Batch 250, Loss: 1.3835
Batch 260, Loss: 1.3734
Batch 270, Loss: 1.4453
Batch 280, Loss: 1.3652
Batch 290, Loss: 1.4195
Batch 300, Loss: 1.3872
Batch 310, Loss: 1.4364
Batch 320, Loss: 1.3888
Batch 330, Loss: 1.3138
Batch 340, Loss: 1.4257
Batch 350, Loss: 1.4385
Batch 360, Loss: 1.3704
Batch 370, Loss: 1.4555
Batch 380, Loss: 1.4305
Batch 390, Loss: 1.3668
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.161205768585205 seconds
Epoch 53 accuracy: 59.98%
Batch 10, Loss: 1.3502
Batch 20, Loss: 1.3404
Batch 30, Loss: 1.2940
Batch 40, Loss: 1.4052
Batch 50, Loss: 1.3603
Batch 60, Loss: 1.4450
Batch 70, Loss: 1.3725
Batch 80, Loss: 1.3310
Batch 90, Loss: 1.4335
Batch 100, Loss: 1.4253
Batch 110, Loss: 1.3267
Batch 120, Loss: 1.4333
Batch 130, Loss: 1.3483
Batch 140, Loss: 1.2926
Batch 150, Loss: 1.3597
Batch 160, Loss: 1.3621
Batch 170, Loss: 1.3775
Batch 180, Loss: 1.3721
Batch 190, Loss: 1.4319
Batch 200, Loss: 1.3888
Batch 210, Loss: 1.3753
Batch 220, Loss: 1.3363
Batch 230, Loss: 1.3772
Batch 240, Loss: 1.3409
Batch 250, Loss: 1.3836
Batch 260, Loss: 1.3964
Batch 270, Loss: 1.3836
Batch 280, Loss: 1.4359
Batch 290, Loss: 1.4193
Batch 300, Loss: 1.4359
Batch 310, Loss: 1.4214
Batch 320, Loss: 1.3881
Batch 330, Loss: 1.3944
Batch 340, Loss: 1.3820
Batch 350, Loss: 1.4505
Batch 360, Loss: 1.3459
Batch 370, Loss: 1.4052
Batch 380, Loss: 1.3947
Batch 390, Loss: 1.3605
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.24254822731018 seconds
Epoch 54 accuracy: 57.53%
Batch 10, Loss: 1.3407
Batch 20, Loss: 1.3307
Batch 30, Loss: 1.3372
Batch 40, Loss: 1.3235
Batch 50, Loss: 1.3208
Batch 60, Loss: 1.2955
Batch 70, Loss: 1.3957
Batch 80, Loss: 1.3571
Batch 90, Loss: 1.3256
Batch 100, Loss: 1.3740
Batch 110, Loss: 1.4001
Batch 120, Loss: 1.4330
Batch 130, Loss: 1.3419
Batch 140, Loss: 1.4172
Batch 150, Loss: 1.3438
Batch 160, Loss: 1.3417
Batch 170, Loss: 1.3528
Batch 180, Loss: 1.4446
Batch 190, Loss: 1.3246
Batch 200, Loss: 1.3569
Batch 210, Loss: 1.3688
Batch 220, Loss: 1.3459
Batch 230, Loss: 1.3664
Batch 240, Loss: 1.3766
Batch 250, Loss: 1.4349
Batch 260, Loss: 1.3528
Batch 270, Loss: 1.3708
Batch 280, Loss: 1.4025
Batch 290, Loss: 1.3640
Batch 300, Loss: 1.4161
Batch 310, Loss: 1.4058
Batch 320, Loss: 1.4466
Batch 330, Loss: 1.4323
Batch 340, Loss: 1.3576
Batch 350, Loss: 1.3998
Batch 360, Loss: 1.4037
Batch 370, Loss: 1.3971
Batch 380, Loss: 1.4198
Batch 390, Loss: 1.4302
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.220591068267822 seconds
Epoch 55 accuracy: 56.26%
Batch 10, Loss: 1.3453
Batch 20, Loss: 1.3847
Batch 30, Loss: 1.3081
Batch 40, Loss: 1.3361
Batch 50, Loss: 1.3403
Batch 60, Loss: 1.3683
Batch 70, Loss: 1.3655
Batch 80, Loss: 1.2995
Batch 90, Loss: 1.3439
Batch 100, Loss: 1.3029
Batch 110, Loss: 1.3781
Batch 120, Loss: 1.3490
Batch 130, Loss: 1.3134
Batch 140, Loss: 1.3194
Batch 150, Loss: 1.3154
Batch 160, Loss: 1.3339
Batch 170, Loss: 1.3754
Batch 180, Loss: 1.3813
Batch 190, Loss: 1.4310
Batch 200, Loss: 1.3976
Batch 210, Loss: 1.4527
Batch 220, Loss: 1.3767
Batch 230, Loss: 1.4074
Batch 240, Loss: 1.3611
Batch 250, Loss: 1.3871
Batch 260, Loss: 1.3929
Batch 270, Loss: 1.4002
Batch 280, Loss: 1.4114
Batch 290, Loss: 1.3738
Batch 300, Loss: 1.3675
Batch 310, Loss: 1.3757
Batch 320, Loss: 1.4962
Batch 330, Loss: 1.3627
Batch 340, Loss: 1.4190
Batch 350, Loss: 1.4047
Batch 360, Loss: 1.3773
Batch 370, Loss: 1.3120
Batch 380, Loss: 1.3617
Batch 390, Loss: 1.3817
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.151800632476807 seconds
Epoch 56 accuracy: 57.51%
Batch 10, Loss: 1.3188
Batch 20, Loss: 1.3087
Batch 30, Loss: 1.3139
Batch 40, Loss: 1.3174
Batch 50, Loss: 1.3610
Batch 60, Loss: 1.3542
Batch 70, Loss: 1.3662
Batch 80, Loss: 1.3240
Batch 90, Loss: 1.3666
Batch 100, Loss: 1.3605
Batch 110, Loss: 1.3617
Batch 120, Loss: 1.3446
Batch 130, Loss: 1.3139
Batch 140, Loss: 1.2838
Batch 150, Loss: 1.3972
Batch 160, Loss: 1.3576
Batch 170, Loss: 1.3806
Batch 180, Loss: 1.3692
Batch 190, Loss: 1.3587
Batch 200, Loss: 1.3560
Batch 210, Loss: 1.3161
Batch 220, Loss: 1.3575
Batch 230, Loss: 1.4258
Batch 240, Loss: 1.4220
Batch 250, Loss: 1.3650
Batch 260, Loss: 1.4408
Batch 270, Loss: 1.3650
Batch 280, Loss: 1.3661
Batch 290, Loss: 1.3040
Batch 300, Loss: 1.3415
Batch 310, Loss: 1.3343
Batch 320, Loss: 1.3878
Batch 330, Loss: 1.3621
Batch 340, Loss: 1.4112
Batch 350, Loss: 1.4379
Batch 360, Loss: 1.4403
Batch 370, Loss: 1.3549
Batch 380, Loss: 1.4006
Batch 390, Loss: 1.4028
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.19094967842102 seconds
Epoch 57 accuracy: 59.01%
Batch 10, Loss: 1.2987
Batch 20, Loss: 1.3139
Batch 30, Loss: 1.2853
Batch 40, Loss: 1.2949
Batch 50, Loss: 1.3281
Batch 60, Loss: 1.2736
Batch 70, Loss: 1.3791
Batch 80, Loss: 1.3738
Batch 90, Loss: 1.3758
Batch 100, Loss: 1.3186
Batch 110, Loss: 1.3847
Batch 120, Loss: 1.3328
Batch 130, Loss: 1.2738
Batch 140, Loss: 1.3499
Batch 150, Loss: 1.3963
Batch 160, Loss: 1.3059
Batch 170, Loss: 1.3199
Batch 180, Loss: 1.3941
Batch 190, Loss: 1.3787
Batch 200, Loss: 1.3489
Batch 210, Loss: 1.3458
Batch 220, Loss: 1.3527
Batch 230, Loss: 1.4255
Batch 240, Loss: 1.4018
Batch 250, Loss: 1.3495
Batch 260, Loss: 1.4521
Batch 270, Loss: 1.4097
Batch 280, Loss: 1.3511
Batch 290, Loss: 1.3551
Batch 300, Loss: 1.3016
Batch 310, Loss: 1.4157
Batch 320, Loss: 1.3602
Batch 330, Loss: 1.3449
Batch 340, Loss: 1.2955
Batch 350, Loss: 1.3615
Batch 360, Loss: 1.4194
Batch 370, Loss: 1.3986
Batch 380, Loss: 1.4109
Batch 390, Loss: 1.3797
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.119937658309937 seconds
Epoch 58 accuracy: 61.83%
Batch 10, Loss: 1.3391
Batch 20, Loss: 1.3599
Batch 30, Loss: 1.3460
Batch 40, Loss: 1.3873
Batch 50, Loss: 1.2914
Batch 60, Loss: 1.3374
Batch 70, Loss: 1.3233
Batch 80, Loss: 1.3787
Batch 90, Loss: 1.3042
Batch 100, Loss: 1.3641
Batch 110, Loss: 1.3072
Batch 120, Loss: 1.3058
Batch 130, Loss: 1.3224
Batch 140, Loss: 1.4223
Batch 150, Loss: 1.3349
Batch 160, Loss: 1.3965
Batch 170, Loss: 1.3197
Batch 180, Loss: 1.4405
Batch 190, Loss: 1.3322
Batch 200, Loss: 1.3531
Batch 210, Loss: 1.3383
Batch 220, Loss: 1.4058
Batch 230, Loss: 1.3933
Batch 240, Loss: 1.3294
Batch 250, Loss: 1.3674
Batch 260, Loss: 1.3458
Batch 270, Loss: 1.3776
Batch 280, Loss: 1.3856
Batch 290, Loss: 1.3839
Batch 300, Loss: 1.3897
Batch 310, Loss: 1.3948
Batch 320, Loss: 1.3005
Batch 330, Loss: 1.3836
Batch 340, Loss: 1.3547
Batch 350, Loss: 1.3841
Batch 360, Loss: 1.3886
Batch 370, Loss: 1.3603
Batch 380, Loss: 1.3675
Batch 390, Loss: 1.3575
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.24230694770813 seconds
Epoch 59 accuracy: 54.4%
Batch 10, Loss: 1.2921
Batch 20, Loss: 1.2751
Batch 30, Loss: 1.2504
Batch 40, Loss: 1.2533
Batch 50, Loss: 1.4012
Batch 60, Loss: 1.3486
Batch 70, Loss: 1.3244
Batch 80, Loss: 1.3574
Batch 90, Loss: 1.2621
Batch 100, Loss: 1.3258
Batch 110, Loss: 1.3359
Batch 120, Loss: 1.3188
Batch 130, Loss: 1.2410
Batch 140, Loss: 1.2997
Batch 150, Loss: 1.3060
Batch 160, Loss: 1.3489
Batch 170, Loss: 1.3491
Batch 180, Loss: 1.3509
Batch 190, Loss: 1.3695
Batch 200, Loss: 1.3613
Batch 210, Loss: 1.2645
Batch 220, Loss: 1.3607
Batch 230, Loss: 1.3201
Batch 240, Loss: 1.3756
Batch 250, Loss: 1.3780
Batch 260, Loss: 1.3456
Batch 270, Loss: 1.4401
Batch 280, Loss: 1.3764
Batch 290, Loss: 1.3871
Batch 300, Loss: 1.3019
Batch 310, Loss: 1.3757
Batch 320, Loss: 1.3686
Batch 330, Loss: 1.3695
Batch 340, Loss: 1.3988
Batch 350, Loss: 1.4369
Batch 360, Loss: 1.4178
Batch 370, Loss: 1.4685
Batch 380, Loss: 1.3653
Batch 390, Loss: 1.3618
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.1709041595459 seconds
Epoch 60 accuracy: 59.81%
Batch 10, Loss: 1.3522
Batch 20, Loss: 1.3420
Batch 30, Loss: 1.3025
Batch 40, Loss: 1.2708
Batch 50, Loss: 1.2764
Batch 60, Loss: 1.2961
Batch 70, Loss: 1.3429
Batch 80, Loss: 1.2939
Batch 90, Loss: 1.3923
Batch 100, Loss: 1.2931
Batch 110, Loss: 1.3565
Batch 120, Loss: 1.2993
Batch 130, Loss: 1.3140
Batch 140, Loss: 1.3296
Batch 150, Loss: 1.3668
Batch 160, Loss: 1.2972
Batch 170, Loss: 1.3665
Batch 180, Loss: 1.3874
Batch 190, Loss: 1.3112
Batch 200, Loss: 1.3476
Batch 210, Loss: 1.3710
Batch 220, Loss: 1.4208
Batch 230, Loss: 1.2760
Batch 240, Loss: 1.2709
Batch 250, Loss: 1.3293
Batch 260, Loss: 1.3107
Batch 270, Loss: 1.3795
Batch 280, Loss: 1.3735
Batch 290, Loss: 1.3789
Batch 300, Loss: 1.3635
Batch 310, Loss: 1.3733
Batch 320, Loss: 1.3201
Batch 330, Loss: 1.3396
Batch 340, Loss: 1.3438
Batch 350, Loss: 1.3552
Batch 360, Loss: 1.3614
Batch 370, Loss: 1.3864
Batch 380, Loss: 1.4135
Batch 390, Loss: 1.3698
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.27341055870056 seconds
Epoch 61 accuracy: 60.39%
Batch 10, Loss: 1.2242
Batch 20, Loss: 1.3123
Batch 30, Loss: 1.2503
Batch 40, Loss: 1.2408
Batch 50, Loss: 1.3354
Batch 60, Loss: 1.2860
Batch 70, Loss: 1.3183
Batch 80, Loss: 1.3146
Batch 90, Loss: 1.2853
Batch 100, Loss: 1.4352
Batch 110, Loss: 1.3903
Batch 120, Loss: 1.3038
Batch 130, Loss: 1.2937
Batch 140, Loss: 1.2518
Batch 150, Loss: 1.3066
Batch 160, Loss: 1.3286
Batch 170, Loss: 1.2883
Batch 180, Loss: 1.3858
Batch 190, Loss: 1.3521
Batch 200, Loss: 1.4010
Batch 210, Loss: 1.3734
Batch 220, Loss: 1.3432
Batch 230, Loss: 1.3162
Batch 240, Loss: 1.3634
Batch 250, Loss: 1.3535
Batch 260, Loss: 1.3637
Batch 270, Loss: 1.3571
Batch 280, Loss: 1.4600
Batch 290, Loss: 1.3378
Batch 300, Loss: 1.3632
Batch 310, Loss: 1.3599
Batch 320, Loss: 1.3162
Batch 330, Loss: 1.3065
Batch 340, Loss: 1.3118
Batch 350, Loss: 1.3330
Batch 360, Loss: 1.3028
Batch 370, Loss: 1.4109
Batch 380, Loss: 1.3753
Batch 390, Loss: 1.3742
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.24845838546753 seconds
Epoch 62 accuracy: 59.88%
Batch 10, Loss: 1.2591
Batch 20, Loss: 1.3176
Batch 30, Loss: 1.3602
Batch 40, Loss: 1.2751
Batch 50, Loss: 1.2135
Batch 60, Loss: 1.2288
Batch 70, Loss: 1.3482
Batch 80, Loss: 1.3088
Batch 90, Loss: 1.2842
Batch 100, Loss: 1.3219
Batch 110, Loss: 1.3521
Batch 120, Loss: 1.3418
Batch 130, Loss: 1.3207
Batch 140, Loss: 1.4038
Batch 150, Loss: 1.4050
Batch 160, Loss: 1.3637
Batch 170, Loss: 1.3774
Batch 180, Loss: 1.3286
Batch 190, Loss: 1.3002
Batch 200, Loss: 1.3573
Batch 210, Loss: 1.3059
Batch 220, Loss: 1.2778
Batch 230, Loss: 1.3034
Batch 240, Loss: 1.3861
Batch 250, Loss: 1.3449
Batch 260, Loss: 1.2837
Batch 270, Loss: 1.3828
Batch 280, Loss: 1.3119
Batch 290, Loss: 1.4205
Batch 300, Loss: 1.3407
Batch 310, Loss: 1.3895
Batch 320, Loss: 1.3720
Batch 330, Loss: 1.3567
Batch 340, Loss: 1.3661
Batch 350, Loss: 1.4231
Batch 360, Loss: 1.3371
Batch 370, Loss: 1.4078
Batch 380, Loss: 1.3668
Batch 390, Loss: 1.3502
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.231873273849487 seconds
Epoch 63 accuracy: 62.44%
Batch 10, Loss: 1.3112
Batch 20, Loss: 1.2730
Batch 30, Loss: 1.3070
Batch 40, Loss: 1.3226
Batch 50, Loss: 1.2459
Batch 60, Loss: 1.3577
Batch 70, Loss: 1.3319
Batch 80, Loss: 1.3129
Batch 90, Loss: 1.3433
Batch 100, Loss: 1.3495
Batch 110, Loss: 1.3686
Batch 120, Loss: 1.3274
Batch 130, Loss: 1.3004
Batch 140, Loss: 1.2984
Batch 150, Loss: 1.3422
Batch 160, Loss: 1.3453
Batch 170, Loss: 1.3373
Batch 180, Loss: 1.2554
Batch 190, Loss: 1.3663
Batch 200, Loss: 1.3079
Batch 210, Loss: 1.3530
Batch 220, Loss: 1.3481
Batch 230, Loss: 1.3340
Batch 240, Loss: 1.3460
Batch 250, Loss: 1.3367
Batch 260, Loss: 1.4008
Batch 270, Loss: 1.3168
Batch 280, Loss: 1.3318
Batch 290, Loss: 1.2956
Batch 300, Loss: 1.3105
Batch 310, Loss: 1.3403
Batch 320, Loss: 1.2977
Batch 330, Loss: 1.3520
Batch 340, Loss: 1.3585
Batch 350, Loss: 1.3264
Batch 360, Loss: 1.3354
Batch 370, Loss: 1.3518
Batch 380, Loss: 1.3814
Batch 390, Loss: 1.3496
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.228244304656982 seconds
Epoch 64 accuracy: 59.79%
Batch 10, Loss: 1.3539
Batch 20, Loss: 1.3109
Batch 30, Loss: 1.3235
Batch 40, Loss: 1.2626
Batch 50, Loss: 1.2286
Batch 60, Loss: 1.2983
Batch 70, Loss: 1.2764
Batch 80, Loss: 1.2665
Batch 90, Loss: 1.2936
Batch 100, Loss: 1.2972
Batch 110, Loss: 1.3184
Batch 120, Loss: 1.3104
Batch 130, Loss: 1.3604
Batch 140, Loss: 1.2279
Batch 150, Loss: 1.3086
Batch 160, Loss: 1.3405
Batch 170, Loss: 1.2829
Batch 180, Loss: 1.3597
Batch 190, Loss: 1.3221
Batch 200, Loss: 1.3236
Batch 210, Loss: 1.3969
Batch 220, Loss: 1.4250
Batch 230, Loss: 1.2543
Batch 240, Loss: 1.3416
Batch 250, Loss: 1.3093
Batch 260, Loss: 1.3117
Batch 270, Loss: 1.3249
Batch 280, Loss: 1.3386
Batch 290, Loss: 1.3959
Batch 300, Loss: 1.3444
Batch 310, Loss: 1.3012
Batch 320, Loss: 1.3562
Batch 330, Loss: 1.3207
Batch 340, Loss: 1.3838
Batch 350, Loss: 1.3314
Batch 360, Loss: 1.3453
Batch 370, Loss: 1.3046
Batch 380, Loss: 1.2987
Batch 390, Loss: 1.3350
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.2925763130188 seconds
Epoch 65 accuracy: 58.02%
Batch 10, Loss: 1.2006
Batch 20, Loss: 1.3274
Batch 30, Loss: 1.2271
Batch 40, Loss: 1.2888
Batch 50, Loss: 1.3632
Batch 60, Loss: 1.2872
Batch 70, Loss: 1.2955
Batch 80, Loss: 1.3322
Batch 90, Loss: 1.3236
Batch 100, Loss: 1.3293
Batch 110, Loss: 1.3196
Batch 120, Loss: 1.3253
Batch 130, Loss: 1.3171
Batch 140, Loss: 1.3153
Batch 150, Loss: 1.2806
Batch 160, Loss: 1.3649
Batch 170, Loss: 1.3296
Batch 180, Loss: 1.4055
Batch 190, Loss: 1.2463
Batch 200, Loss: 1.3746
Batch 210, Loss: 1.2841
Batch 220, Loss: 1.3347
Batch 230, Loss: 1.2625
Batch 240, Loss: 1.3131
Batch 250, Loss: 1.3789
Batch 260, Loss: 1.3866
Batch 270, Loss: 1.3664
Batch 280, Loss: 1.3226
Batch 290, Loss: 1.3140
Batch 300, Loss: 1.2931
Batch 310, Loss: 1.3840
Batch 320, Loss: 1.3825
Batch 330, Loss: 1.3670
Batch 340, Loss: 1.3135
Batch 350, Loss: 1.3839
Batch 360, Loss: 1.3330
Batch 370, Loss: 1.2967
Batch 380, Loss: 1.2671
Batch 390, Loss: 1.2901
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.254101276397705 seconds
Epoch 66 accuracy: 60.79%
Batch 10, Loss: 1.2196
Batch 20, Loss: 1.2056
Batch 30, Loss: 1.2489
Batch 40, Loss: 1.2295
Batch 50, Loss: 1.2459
Batch 60, Loss: 1.2738
Batch 70, Loss: 1.2612
Batch 80, Loss: 1.2553
Batch 90, Loss: 1.2743
Batch 100, Loss: 1.2746
Batch 110, Loss: 1.2811
Batch 120, Loss: 1.3214
Batch 130, Loss: 1.2987
Batch 140, Loss: 1.2783
Batch 150, Loss: 1.3216
Batch 160, Loss: 1.3259
Batch 170, Loss: 1.3152
Batch 180, Loss: 1.2886
Batch 190, Loss: 1.2657
Batch 200, Loss: 1.3272
Batch 210, Loss: 1.3174
Batch 220, Loss: 1.2742
Batch 230, Loss: 1.2762
Batch 240, Loss: 1.3054
Batch 250, Loss: 1.3102
Batch 260, Loss: 1.3606
Batch 270, Loss: 1.3397
Batch 280, Loss: 1.2814
Batch 290, Loss: 1.3270
Batch 300, Loss: 1.3877
Batch 310, Loss: 1.3567
Batch 320, Loss: 1.3446
Batch 330, Loss: 1.3127
Batch 340, Loss: 1.2985
Batch 350, Loss: 1.3491
Batch 360, Loss: 1.2385
Batch 370, Loss: 1.3736
Batch 380, Loss: 1.3490
Batch 390, Loss: 1.2850
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.204373359680176 seconds
Epoch 67 accuracy: 61.06%
Batch 10, Loss: 1.2410
Batch 20, Loss: 1.2603
Batch 30, Loss: 1.2968
Batch 40, Loss: 1.2904
Batch 50, Loss: 1.2469
Batch 60, Loss: 1.1967
Batch 70, Loss: 1.3652
Batch 80, Loss: 1.3230
Batch 90, Loss: 1.2559
Batch 100, Loss: 1.3681
Batch 110, Loss: 1.3063
Batch 120, Loss: 1.3357
Batch 130, Loss: 1.2593
Batch 140, Loss: 1.2680
Batch 150, Loss: 1.2528
Batch 160, Loss: 1.2814
Batch 170, Loss: 1.3164
Batch 180, Loss: 1.3274
Batch 190, Loss: 1.2899
Batch 200, Loss: 1.2685
Batch 210, Loss: 1.3402
Batch 220, Loss: 1.3299
Batch 230, Loss: 1.2644
Batch 240, Loss: 1.3473
Batch 250, Loss: 1.3574
Batch 260, Loss: 1.2903
Batch 270, Loss: 1.3751
Batch 280, Loss: 1.3974
Batch 290, Loss: 1.3553
Batch 300, Loss: 1.2809
Batch 310, Loss: 1.3561
Batch 320, Loss: 1.3538
Batch 330, Loss: 1.3104
Batch 340, Loss: 1.3493
Batch 350, Loss: 1.3397
Batch 360, Loss: 1.3694
Batch 370, Loss: 1.3056
Batch 380, Loss: 1.3618
Batch 390, Loss: 1.3073
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.08246088027954 seconds
Epoch 68 accuracy: 58.56%
Batch 10, Loss: 1.2032
Batch 20, Loss: 1.2841
Batch 30, Loss: 1.2349
Batch 40, Loss: 1.2476
Batch 50, Loss: 1.3002
Batch 60, Loss: 1.2796
Batch 70, Loss: 1.3049
Batch 80, Loss: 1.3315
Batch 90, Loss: 1.2721
Batch 100, Loss: 1.2862
Batch 110, Loss: 1.2805
Batch 120, Loss: 1.2770
Batch 130, Loss: 1.2056
Batch 140, Loss: 1.2814
Batch 150, Loss: 1.3378
Batch 160, Loss: 1.2918
Batch 170, Loss: 1.2942
Batch 180, Loss: 1.3717
Batch 190, Loss: 1.3070
Batch 200, Loss: 1.2895
Batch 210, Loss: 1.3360
Batch 220, Loss: 1.3267
Batch 230, Loss: 1.2938
Batch 240, Loss: 1.2494
Batch 250, Loss: 1.3084
Batch 260, Loss: 1.3091
Batch 270, Loss: 1.3496
Batch 280, Loss: 1.3713
Batch 290, Loss: 1.2906
Batch 300, Loss: 1.3108
Batch 310, Loss: 1.2441
Batch 320, Loss: 1.3359
Batch 330, Loss: 1.3482
Batch 340, Loss: 1.3332
Batch 350, Loss: 1.3451
Batch 360, Loss: 1.3203
Batch 370, Loss: 1.2929
Batch 380, Loss: 1.3391
Batch 390, Loss: 1.3801
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.11663269996643 seconds
Epoch 69 accuracy: 61.74%
Batch 10, Loss: 1.2248
Batch 20, Loss: 1.3010
Batch 30, Loss: 1.2876
Batch 40, Loss: 1.2357
Batch 50, Loss: 1.2268
Batch 60, Loss: 1.2944
Batch 70, Loss: 1.2467
Batch 80, Loss: 1.3105
Batch 90, Loss: 1.3282
Batch 100, Loss: 1.3397
Batch 110, Loss: 1.2701
Batch 120, Loss: 1.3319
Batch 130, Loss: 1.2526
Batch 140, Loss: 1.2698
Batch 150, Loss: 1.2502
Batch 160, Loss: 1.2593
Batch 170, Loss: 1.3080
Batch 180, Loss: 1.3196
Batch 190, Loss: 1.3068
Batch 200, Loss: 1.2603
Batch 210, Loss: 1.2846
Batch 220, Loss: 1.3179
Batch 230, Loss: 1.2515
Batch 240, Loss: 1.3472
Batch 250, Loss: 1.3216
Batch 260, Loss: 1.2870
Batch 270, Loss: 1.3019
Batch 280, Loss: 1.2805
Batch 290, Loss: 1.3245
Batch 300, Loss: 1.2822
Batch 310, Loss: 1.3167
Batch 320, Loss: 1.3581
Batch 330, Loss: 1.3442
Batch 340, Loss: 1.3300
Batch 350, Loss: 1.3684
Batch 360, Loss: 1.2669
Batch 370, Loss: 1.3307
Batch 380, Loss: 1.3212
Batch 390, Loss: 1.2863
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.24561834335327 seconds
Epoch 70 accuracy: 62.41%
Batch 10, Loss: 1.2325
Batch 20, Loss: 1.1737
Batch 30, Loss: 1.2568
Batch 40, Loss: 1.2132
Batch 50, Loss: 1.2509
Batch 60, Loss: 1.2549
Batch 70, Loss: 1.2178
Batch 80, Loss: 1.2715
Batch 90, Loss: 1.2758
Batch 100, Loss: 1.2428
Batch 110, Loss: 1.2491
Batch 120, Loss: 1.3176
Batch 130, Loss: 1.3077
Batch 140, Loss: 1.2961
Batch 150, Loss: 1.2964
Batch 160, Loss: 1.3034
Batch 170, Loss: 1.3484
Batch 180, Loss: 1.2970
Batch 190, Loss: 1.3206
Batch 200, Loss: 1.3088
Batch 210, Loss: 1.3367
Batch 220, Loss: 1.3363
Batch 230, Loss: 1.3251
Batch 240, Loss: 1.3429
Batch 250, Loss: 1.2821
Batch 260, Loss: 1.2874
Batch 270, Loss: 1.3017
Batch 280, Loss: 1.2335
Batch 290, Loss: 1.2914
Batch 300, Loss: 1.3395
Batch 310, Loss: 1.2929
Batch 320, Loss: 1.2601
Batch 330, Loss: 1.2959
Batch 340, Loss: 1.3299
Batch 350, Loss: 1.3466
Batch 360, Loss: 1.3402
Batch 370, Loss: 1.3001
Batch 380, Loss: 1.3369
Batch 390, Loss: 1.2875
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.282742977142334 seconds
Epoch 71 accuracy: 56.31%
Batch 10, Loss: 1.2404
Batch 20, Loss: 1.2273
Batch 30, Loss: 1.2303
Batch 40, Loss: 1.2166
Batch 50, Loss: 1.2454
Batch 60, Loss: 1.2761
Batch 70, Loss: 1.2745
Batch 80, Loss: 1.2469
Batch 90, Loss: 1.3108
Batch 100, Loss: 1.3255
Batch 110, Loss: 1.1992
Batch 120, Loss: 1.2835
Batch 130, Loss: 1.2762
Batch 140, Loss: 1.2487
Batch 150, Loss: 1.2691
Batch 160, Loss: 1.2346
Batch 170, Loss: 1.2829
Batch 180, Loss: 1.3539
Batch 190, Loss: 1.2384
Batch 200, Loss: 1.2532
Batch 210, Loss: 1.2979
Batch 220, Loss: 1.2261
Batch 230, Loss: 1.2884
Batch 240, Loss: 1.2907
Batch 250, Loss: 1.3156
Batch 260, Loss: 1.3441
Batch 270, Loss: 1.2579
Batch 280, Loss: 1.2582
Batch 290, Loss: 1.2670
Batch 300, Loss: 1.3139
Batch 310, Loss: 1.3717
Batch 320, Loss: 1.3073
Batch 330, Loss: 1.3602
Batch 340, Loss: 1.3193
Batch 350, Loss: 1.3301
Batch 360, Loss: 1.3421
Batch 370, Loss: 1.2998
Batch 380, Loss: 1.2884
Batch 390, Loss: 1.3789
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.13133144378662 seconds
Epoch 72 accuracy: 61.74%
Batch 10, Loss: 1.2266
Batch 20, Loss: 1.2857
Batch 30, Loss: 1.2120
Batch 40, Loss: 1.2668
Batch 50, Loss: 1.2329
Batch 60, Loss: 1.2186
Batch 70, Loss: 1.2008
Batch 80, Loss: 1.2693
Batch 90, Loss: 1.2049
Batch 100, Loss: 1.3318
Batch 110, Loss: 1.2890
Batch 120, Loss: 1.2701
Batch 130, Loss: 1.3121
Batch 140, Loss: 1.2280
Batch 150, Loss: 1.2667
Batch 160, Loss: 1.2801
Batch 170, Loss: 1.3576
Batch 180, Loss: 1.2747
Batch 190, Loss: 1.2659
Batch 200, Loss: 1.2605
Batch 210, Loss: 1.2344
Batch 220, Loss: 1.2550
Batch 230, Loss: 1.2332
Batch 240, Loss: 1.2724
Batch 250, Loss: 1.2705
Batch 260, Loss: 1.3206
Batch 270, Loss: 1.3591
Batch 280, Loss: 1.2868
Batch 290, Loss: 1.3201
Batch 300, Loss: 1.2410
Batch 310, Loss: 1.3220
Batch 320, Loss: 1.3429
Batch 330, Loss: 1.2896
Batch 340, Loss: 1.2264
Batch 350, Loss: 1.2813
Batch 360, Loss: 1.3123
Batch 370, Loss: 1.3086
Batch 380, Loss: 1.3171
Batch 390, Loss: 1.3128
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.235039234161377 seconds
Epoch 73 accuracy: 60.11%
Batch 10, Loss: 1.2882
Batch 20, Loss: 1.2163
Batch 30, Loss: 1.1681
Batch 40, Loss: 1.2194
Batch 50, Loss: 1.2102
Batch 60, Loss: 1.2571
Batch 70, Loss: 1.3227
Batch 80, Loss: 1.2734
Batch 90, Loss: 1.2342
Batch 100, Loss: 1.2885
Batch 110, Loss: 1.2510
Batch 120, Loss: 1.2423
Batch 130, Loss: 1.2151
Batch 140, Loss: 1.2344
Batch 150, Loss: 1.3099
Batch 160, Loss: 1.3169
Batch 170, Loss: 1.3332
Batch 180, Loss: 1.3280
Batch 190, Loss: 1.3081
Batch 200, Loss: 1.2402
Batch 210, Loss: 1.2515
Batch 220, Loss: 1.2149
Batch 230, Loss: 1.2106
Batch 240, Loss: 1.1974
Batch 250, Loss: 1.2575
Batch 260, Loss: 1.3049
Batch 270, Loss: 1.2471
Batch 280, Loss: 1.2909
Batch 290, Loss: 1.2916
Batch 300, Loss: 1.2896
Batch 310, Loss: 1.3065
Batch 320, Loss: 1.2935
Batch 330, Loss: 1.3124
Batch 340, Loss: 1.3309
Batch 350, Loss: 1.2822
Batch 360, Loss: 1.3526
Batch 370, Loss: 1.3110
Batch 380, Loss: 1.3054
Batch 390, Loss: 1.2761
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.313258171081543 seconds
Epoch 74 accuracy: 62.12%
Batch 10, Loss: 1.2807
Batch 20, Loss: 1.1629
Batch 30, Loss: 1.1983
Batch 40, Loss: 1.2341
Batch 50, Loss: 1.2416
Batch 60, Loss: 1.2261
Batch 70, Loss: 1.2109
Batch 80, Loss: 1.2463
Batch 90, Loss: 1.2199
Batch 100, Loss: 1.1967
Batch 110, Loss: 1.2250
Batch 120, Loss: 1.2251
Batch 130, Loss: 1.2785
Batch 140, Loss: 1.2620
Batch 150, Loss: 1.3137
Batch 160, Loss: 1.2796
Batch 170, Loss: 1.2628
Batch 180, Loss: 1.2825
Batch 190, Loss: 1.2204
Batch 200, Loss: 1.2633
Batch 210, Loss: 1.2349
Batch 220, Loss: 1.2994
Batch 230, Loss: 1.2449
Batch 240, Loss: 1.3228
Batch 250, Loss: 1.2716
Batch 260, Loss: 1.2670
Batch 270, Loss: 1.3523
Batch 280, Loss: 1.2472
Batch 290, Loss: 1.3076
Batch 300, Loss: 1.2402
Batch 310, Loss: 1.2831
Batch 320, Loss: 1.3418
Batch 330, Loss: 1.3178
Batch 340, Loss: 1.3302
Batch 350, Loss: 1.3554
Batch 360, Loss: 1.2896
Batch 370, Loss: 1.3071
Batch 380, Loss: 1.2535
Batch 390, Loss: 1.2842
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.494749784469604 seconds
Epoch 75 accuracy: 62.01%
Batch 10, Loss: 1.1603
Batch 20, Loss: 1.1378
Batch 30, Loss: 1.2217
Batch 40, Loss: 1.2993
Batch 50, Loss: 1.2618
Batch 60, Loss: 1.2565
Batch 70, Loss: 1.2516
Batch 80, Loss: 1.2296
Batch 90, Loss: 1.2525
Batch 100, Loss: 1.2876
Batch 110, Loss: 1.2785
Batch 120, Loss: 1.2574
Batch 130, Loss: 1.2570
Batch 140, Loss: 1.2962
Batch 150, Loss: 1.1644
Batch 160, Loss: 1.2261
Batch 170, Loss: 1.2344
Batch 180, Loss: 1.2530
Batch 190, Loss: 1.2542
Batch 200, Loss: 1.2943
Batch 210, Loss: 1.2842
Batch 220, Loss: 1.2181
Batch 230, Loss: 1.3067
Batch 240, Loss: 1.3387
Batch 250, Loss: 1.2289
Batch 260, Loss: 1.2877
Batch 270, Loss: 1.2526
Batch 280, Loss: 1.2724
Batch 290, Loss: 1.2011
Batch 300, Loss: 1.3482
Batch 310, Loss: 1.3054
Batch 320, Loss: 1.2650
Batch 330, Loss: 1.3548
Batch 340, Loss: 1.2538
Batch 350, Loss: 1.3129
Batch 360, Loss: 1.2612
Batch 370, Loss: 1.3089
Batch 380, Loss: 1.2787
Batch 390, Loss: 1.3080
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.182426691055298 seconds
Epoch 76 accuracy: 61.42%
Batch 10, Loss: 1.1835
Batch 20, Loss: 1.1948
Batch 30, Loss: 1.2384
Batch 40, Loss: 1.1708
Batch 50, Loss: 1.1791
Batch 60, Loss: 1.2489
Batch 70, Loss: 1.1578
Batch 80, Loss: 1.2660
Batch 90, Loss: 1.2456
Batch 100, Loss: 1.2308
Batch 110, Loss: 1.2337
Batch 120, Loss: 1.2783
Batch 130, Loss: 1.2995
Batch 140, Loss: 1.2129
Batch 150, Loss: 1.2446
Batch 160, Loss: 1.2603
Batch 170, Loss: 1.2507
Batch 180, Loss: 1.3367
Batch 190, Loss: 1.1569
Batch 200, Loss: 1.2868
Batch 210, Loss: 1.2664
Batch 220, Loss: 1.2305
Batch 230, Loss: 1.2281
Batch 240, Loss: 1.2633
Batch 250, Loss: 1.2792
Batch 260, Loss: 1.2688
Batch 270, Loss: 1.2387
Batch 280, Loss: 1.3056
Batch 290, Loss: 1.3236
Batch 300, Loss: 1.1939
Batch 310, Loss: 1.2654
Batch 320, Loss: 1.3096
Batch 330, Loss: 1.3571
Batch 340, Loss: 1.3247
Batch 350, Loss: 1.2986
Batch 360, Loss: 1.2980
Batch 370, Loss: 1.2958
Batch 380, Loss: 1.2017
Batch 390, Loss: 1.3117
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.21575617790222 seconds
Epoch 77 accuracy: 62.09%
Batch 10, Loss: 1.2190
Batch 20, Loss: 1.1878
Batch 30, Loss: 1.2051
Batch 40, Loss: 1.2464
Batch 50, Loss: 1.1037
Batch 60, Loss: 1.1786
Batch 70, Loss: 1.2459
Batch 80, Loss: 1.2126
Batch 90, Loss: 1.2659
Batch 100, Loss: 1.2098
Batch 110, Loss: 1.2462
Batch 120, Loss: 1.2217
Batch 130, Loss: 1.2759
Batch 140, Loss: 1.2149
Batch 150, Loss: 1.2527
Batch 160, Loss: 1.3148
Batch 170, Loss: 1.2983
Batch 180, Loss: 1.2613
Batch 190, Loss: 1.2492
Batch 200, Loss: 1.2182
Batch 210, Loss: 1.2864
Batch 220, Loss: 1.2842
Batch 230, Loss: 1.2935
Batch 240, Loss: 1.2514
Batch 250, Loss: 1.2228
Batch 260, Loss: 1.2450
Batch 270, Loss: 1.3195
Batch 280, Loss: 1.2921
Batch 290, Loss: 1.3243
Batch 300, Loss: 1.2710
Batch 310, Loss: 1.1972
Batch 320, Loss: 1.2904
Batch 330, Loss: 1.3381
Batch 340, Loss: 1.2697
Batch 350, Loss: 1.2427
Batch 360, Loss: 1.2744
Batch 370, Loss: 1.3221
Batch 380, Loss: 1.2414
Batch 390, Loss: 1.3431
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.15005326271057 seconds
Epoch 78 accuracy: 61.02%
Batch 10, Loss: 1.2301
Batch 20, Loss: 1.2004
Batch 30, Loss: 1.2185
Batch 40, Loss: 1.1581
Batch 50, Loss: 1.2561
Batch 60, Loss: 1.2181
Batch 70, Loss: 1.2367
Batch 80, Loss: 1.2472
Batch 90, Loss: 1.2387
Batch 100, Loss: 1.2314
Batch 110, Loss: 1.2042
Batch 120, Loss: 1.2529
Batch 130, Loss: 1.2535
Batch 140, Loss: 1.3366
Batch 150, Loss: 1.2047
Batch 160, Loss: 1.2440
Batch 170, Loss: 1.2511
Batch 180, Loss: 1.2216
Batch 190, Loss: 1.2069
Batch 200, Loss: 1.2045
Batch 210, Loss: 1.2324
Batch 220, Loss: 1.2542
Batch 230, Loss: 1.2051
Batch 240, Loss: 1.2733
Batch 250, Loss: 1.2182
Batch 260, Loss: 1.2912
Batch 270, Loss: 1.2269
Batch 280, Loss: 1.2932
Batch 290, Loss: 1.2537
Batch 300, Loss: 1.2942
Batch 310, Loss: 1.2641
Batch 320, Loss: 1.2989
Batch 330, Loss: 1.1969
Batch 340, Loss: 1.3035
Batch 350, Loss: 1.2374
Batch 360, Loss: 1.2719
Batch 370, Loss: 1.2663
Batch 380, Loss: 1.2899
Batch 390, Loss: 1.2988
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.12777829170227 seconds
Epoch 79 accuracy: 63.36%
Batch 10, Loss: 1.2030
Batch 20, Loss: 1.1561
Batch 30, Loss: 1.2485
Batch 40, Loss: 1.1766
Batch 50, Loss: 1.2052
Batch 60, Loss: 1.1181
Batch 70, Loss: 1.2007
Batch 80, Loss: 1.2917
Batch 90, Loss: 1.1918
Batch 100, Loss: 1.2282
Batch 110, Loss: 1.2522
Batch 120, Loss: 1.2742
Batch 130, Loss: 1.1556
Batch 140, Loss: 1.2800
Batch 150, Loss: 1.2508
Batch 160, Loss: 1.2825
Batch 170, Loss: 1.2153
Batch 180, Loss: 1.2053
Batch 190, Loss: 1.2252
Batch 200, Loss: 1.2144
Batch 210, Loss: 1.2419
Batch 220, Loss: 1.1739
Batch 230, Loss: 1.3020
Batch 240, Loss: 1.2488
Batch 250, Loss: 1.2130
Batch 260, Loss: 1.2032
Batch 270, Loss: 1.2221
Batch 280, Loss: 1.2247
Batch 290, Loss: 1.2659
Batch 300, Loss: 1.2558
Batch 310, Loss: 1.3056
Batch 320, Loss: 1.2734
Batch 330, Loss: 1.2593
Batch 340, Loss: 1.2746
Batch 350, Loss: 1.2607
Batch 360, Loss: 1.2976
Batch 370, Loss: 1.3030
Batch 380, Loss: 1.2966
Batch 390, Loss: 1.2012
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.18411922454834 seconds
Epoch 80 accuracy: 62.08%
Batch 10, Loss: 1.1756
Batch 20, Loss: 1.2160
Batch 30, Loss: 1.1766
Batch 40, Loss: 1.1515
Batch 50, Loss: 1.1651
Batch 60, Loss: 1.1597
Batch 70, Loss: 1.1834
Batch 80, Loss: 1.2056
Batch 90, Loss: 1.1795
Batch 100, Loss: 1.2104
Batch 110, Loss: 1.2696
Batch 120, Loss: 1.2248
Batch 130, Loss: 1.2093
Batch 140, Loss: 1.2194
Batch 150, Loss: 1.2463
Batch 160, Loss: 1.2819
Batch 170, Loss: 1.1692
Batch 180, Loss: 1.2180
Batch 190, Loss: 1.2077
Batch 200, Loss: 1.2253
Batch 210, Loss: 1.2114
Batch 220, Loss: 1.1974
Batch 230, Loss: 1.1720
Batch 240, Loss: 1.1869
Batch 250, Loss: 1.2073
Batch 260, Loss: 1.2449
Batch 270, Loss: 1.2841
Batch 280, Loss: 1.2395
Batch 290, Loss: 1.2057
Batch 300, Loss: 1.2309
Batch 310, Loss: 1.2724
Batch 320, Loss: 1.2737
Batch 330, Loss: 1.2854
Batch 340, Loss: 1.2216
Batch 350, Loss: 1.2459
Batch 360, Loss: 1.2860
Batch 370, Loss: 1.2772
Batch 380, Loss: 1.1947
Batch 390, Loss: 1.2431
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.17214322090149 seconds
Epoch 81 accuracy: 63.16%
Batch 10, Loss: 1.1521
Batch 20, Loss: 1.1224
Batch 30, Loss: 1.2240
Batch 40, Loss: 1.1888
Batch 50, Loss: 1.1824
Batch 60, Loss: 1.1743
Batch 70, Loss: 1.2439
Batch 80, Loss: 1.2059
Batch 90, Loss: 1.2345
Batch 100, Loss: 1.2285
Batch 110, Loss: 1.2543
Batch 120, Loss: 1.2384
Batch 130, Loss: 1.1862
Batch 140, Loss: 1.2221
Batch 150, Loss: 1.2781
Batch 160, Loss: 1.1918
Batch 170, Loss: 1.2574
Batch 180, Loss: 1.1902
Batch 190, Loss: 1.2737
Batch 200, Loss: 1.2039
Batch 210, Loss: 1.1783
Batch 220, Loss: 1.2571
Batch 230, Loss: 1.2153
Batch 240, Loss: 1.2439
Batch 250, Loss: 1.2447
Batch 260, Loss: 1.2437
Batch 270, Loss: 1.2040
Batch 280, Loss: 1.2575
Batch 290, Loss: 1.2647
Batch 300, Loss: 1.2516
Batch 310, Loss: 1.2530
Batch 320, Loss: 1.2681
Batch 330, Loss: 1.2795
Batch 340, Loss: 1.3057
Batch 350, Loss: 1.2086
Batch 360, Loss: 1.2250
Batch 370, Loss: 1.2937
Batch 380, Loss: 1.2692
Batch 390, Loss: 1.2359
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.197708129882812 seconds
Epoch 82 accuracy: 64.77%
Batch 10, Loss: 1.1666
Batch 20, Loss: 1.1305
Batch 30, Loss: 1.1699
Batch 40, Loss: 1.1844
Batch 50, Loss: 1.1838
Batch 60, Loss: 1.2041
Batch 70, Loss: 1.1534
Batch 80, Loss: 1.2179
Batch 90, Loss: 1.2347
Batch 100, Loss: 1.2596
Batch 110, Loss: 1.2491
Batch 120, Loss: 1.2355
Batch 130, Loss: 1.1242
Batch 140, Loss: 1.2322
Batch 150, Loss: 1.2610
Batch 160, Loss: 1.2215
Batch 170, Loss: 1.2474
Batch 180, Loss: 1.2690
Batch 190, Loss: 1.2122
Batch 200, Loss: 1.2414
Batch 210, Loss: 1.2267
Batch 220, Loss: 1.2218
Batch 230, Loss: 1.1758
Batch 240, Loss: 1.2107
Batch 250, Loss: 1.2080
Batch 260, Loss: 1.2506
Batch 270, Loss: 1.1973
Batch 280, Loss: 1.1973
Batch 290, Loss: 1.2380
Batch 300, Loss: 1.2670
Batch 310, Loss: 1.2040
Batch 320, Loss: 1.2201
Batch 330, Loss: 1.2195
Batch 340, Loss: 1.2466
Batch 350, Loss: 1.3023
Batch 360, Loss: 1.2733
Batch 370, Loss: 1.2193
Batch 380, Loss: 1.2185
Batch 390, Loss: 1.2554
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.26420283317566 seconds
Epoch 83 accuracy: 64.28%
Batch 10, Loss: 1.1543
Batch 20, Loss: 1.2026
Batch 30, Loss: 1.1763
Batch 40, Loss: 1.1377
Batch 50, Loss: 1.1627
Batch 60, Loss: 1.1569
Batch 70, Loss: 1.1893
Batch 80, Loss: 1.1171
Batch 90, Loss: 1.1362
Batch 100, Loss: 1.1941
Batch 110, Loss: 1.2463
Batch 120, Loss: 1.2072
Batch 130, Loss: 1.1703
Batch 140, Loss: 1.1974
Batch 150, Loss: 1.1858
Batch 160, Loss: 1.1987
Batch 170, Loss: 1.2179
Batch 180, Loss: 1.1895
Batch 190, Loss: 1.2505
Batch 200, Loss: 1.2019
Batch 210, Loss: 1.2260
Batch 220, Loss: 1.1835
Batch 230, Loss: 1.2236
Batch 240, Loss: 1.2303
Batch 250, Loss: 1.2017
Batch 260, Loss: 1.2426
Batch 270, Loss: 1.2182
Batch 280, Loss: 1.2647
Batch 290, Loss: 1.2557
Batch 300, Loss: 1.2754
Batch 310, Loss: 1.1803
Batch 320, Loss: 1.2286
Batch 330, Loss: 1.1798
Batch 340, Loss: 1.2317
Batch 350, Loss: 1.1900
Batch 360, Loss: 1.2792
Batch 370, Loss: 1.2636
Batch 380, Loss: 1.2025
Batch 390, Loss: 1.2391
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.260229110717773 seconds
Epoch 84 accuracy: 63.43%
Batch 10, Loss: 1.2008
Batch 20, Loss: 1.1005
Batch 30, Loss: 1.1282
Batch 40, Loss: 1.1621
Batch 50, Loss: 1.1524
Batch 60, Loss: 1.2113
Batch 70, Loss: 1.1476
Batch 80, Loss: 1.1466
Batch 90, Loss: 1.2498
Batch 100, Loss: 1.1483
Batch 110, Loss: 1.2432
Batch 120, Loss: 1.2168
Batch 130, Loss: 1.2054
Batch 140, Loss: 1.1479
Batch 150, Loss: 1.2460
Batch 160, Loss: 1.1665
Batch 170, Loss: 1.1512
Batch 180, Loss: 1.2070
Batch 190, Loss: 1.2052
Batch 200, Loss: 1.2834
Batch 210, Loss: 1.2244
Batch 220, Loss: 1.2120
Batch 230, Loss: 1.1990
Batch 240, Loss: 1.2483
Batch 250, Loss: 1.2169
Batch 260, Loss: 1.2786
Batch 270, Loss: 1.1834
Batch 280, Loss: 1.1832
Batch 290, Loss: 1.1840
Batch 300, Loss: 1.2546
Batch 310, Loss: 1.2383
Batch 320, Loss: 1.2617
Batch 330, Loss: 1.2288
Batch 340, Loss: 1.2376
Batch 350, Loss: 1.2387
Batch 360, Loss: 1.2337
Batch 370, Loss: 1.2431
Batch 380, Loss: 1.1965
Batch 390, Loss: 1.2817
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.11853861808777 seconds
Epoch 85 accuracy: 63.1%
Batch 10, Loss: 1.2115
Batch 20, Loss: 1.1980
Batch 30, Loss: 1.1786
Batch 40, Loss: 1.1433
Batch 50, Loss: 1.1564
Batch 60, Loss: 1.1607
Batch 70, Loss: 1.1618
Batch 80, Loss: 1.1488
Batch 90, Loss: 1.2082
Batch 100, Loss: 1.1853
Batch 110, Loss: 1.2002
Batch 120, Loss: 1.2133
Batch 130, Loss: 1.2557
Batch 140, Loss: 1.2140
Batch 150, Loss: 1.2303
Batch 160, Loss: 1.1969
Batch 170, Loss: 1.1744
Batch 180, Loss: 1.1855
Batch 190, Loss: 1.2245
Batch 200, Loss: 1.2421
Batch 210, Loss: 1.1402
Batch 220, Loss: 1.2114
Batch 230, Loss: 1.2007
Batch 240, Loss: 1.1421
Batch 250, Loss: 1.1797
Batch 260, Loss: 1.1529
Batch 270, Loss: 1.2219
Batch 280, Loss: 1.2206
Batch 290, Loss: 1.2115
Batch 300, Loss: 1.2173
Batch 310, Loss: 1.2767
Batch 320, Loss: 1.2174
Batch 330, Loss: 1.1615
Batch 340, Loss: 1.2344
Batch 350, Loss: 1.1298
Batch 360, Loss: 1.1432
Batch 370, Loss: 1.2388
Batch 380, Loss: 1.1905
Batch 390, Loss: 1.2283
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.056381464004517 seconds
Epoch 86 accuracy: 59.82%
Batch 10, Loss: 1.0928
Batch 20, Loss: 1.1969
Batch 30, Loss: 1.1631
Batch 40, Loss: 1.1273
Batch 50, Loss: 1.2262
Batch 60, Loss: 1.1707
Batch 70, Loss: 1.1495
Batch 80, Loss: 1.1223
Batch 90, Loss: 1.1769
Batch 100, Loss: 1.1098
Batch 110, Loss: 1.1525
Batch 120, Loss: 1.1914
Batch 130, Loss: 1.1645
Batch 140, Loss: 1.2269
Batch 150, Loss: 1.1920
Batch 160, Loss: 1.1461
Batch 170, Loss: 1.1615
Batch 180, Loss: 1.1635
Batch 190, Loss: 1.1379
Batch 200, Loss: 1.2998
Batch 210, Loss: 1.1717
Batch 220, Loss: 1.2283
Batch 230, Loss: 1.2620
Batch 240, Loss: 1.2148
Batch 250, Loss: 1.1747
Batch 260, Loss: 1.1625
Batch 270, Loss: 1.1872
Batch 280, Loss: 1.2414
Batch 290, Loss: 1.1901
Batch 300, Loss: 1.2447
Batch 310, Loss: 1.2141
Batch 320, Loss: 1.2262
Batch 330, Loss: 1.2275
Batch 340, Loss: 1.2679
Batch 350, Loss: 1.1705
Batch 360, Loss: 1.1839
Batch 370, Loss: 1.1075
Batch 380, Loss: 1.2515
Batch 390, Loss: 1.2137
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.195199728012085 seconds
Epoch 87 accuracy: 60.5%
Batch 10, Loss: 1.1313
Batch 20, Loss: 1.1654
Batch 30, Loss: 1.1337
Batch 40, Loss: 1.1009
Batch 50, Loss: 1.1653
Batch 60, Loss: 1.1955
Batch 70, Loss: 1.1586
Batch 80, Loss: 1.1157
Batch 90, Loss: 1.2363
Batch 100, Loss: 1.2078
Batch 110, Loss: 1.2244
Batch 120, Loss: 1.1536
Batch 130, Loss: 1.1666
Batch 140, Loss: 1.1197
Batch 150, Loss: 1.2149
Batch 160, Loss: 1.1765
Batch 170, Loss: 1.1226
Batch 180, Loss: 1.1842
Batch 190, Loss: 1.1547
Batch 200, Loss: 1.1988
Batch 210, Loss: 1.2336
Batch 220, Loss: 1.1696
Batch 230, Loss: 1.1573
Batch 240, Loss: 1.1628
Batch 250, Loss: 1.1833
Batch 260, Loss: 1.2386
Batch 270, Loss: 1.2702
Batch 280, Loss: 1.2335
Batch 290, Loss: 1.1783
Batch 300, Loss: 1.2638
Batch 310, Loss: 1.1719
Batch 320, Loss: 1.2215
Batch 330, Loss: 1.2164
Batch 340, Loss: 1.1678
Batch 350, Loss: 1.1939
Batch 360, Loss: 1.2363
Batch 370, Loss: 1.1972
Batch 380, Loss: 1.2102
Batch 390, Loss: 1.1699
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.295923709869385 seconds
Epoch 88 accuracy: 61.53%
Batch 10, Loss: 1.2270
Batch 20, Loss: 1.0964
Batch 30, Loss: 1.1258
Batch 40, Loss: 1.1248
Batch 50, Loss: 1.0879
Batch 60, Loss: 1.1295
Batch 70, Loss: 1.1421
Batch 80, Loss: 1.1938
Batch 90, Loss: 1.1417
Batch 100, Loss: 1.2827
Batch 110, Loss: 1.2371
Batch 120, Loss: 1.1990
Batch 130, Loss: 1.1425
Batch 140, Loss: 1.1693
Batch 150, Loss: 1.1688
Batch 160, Loss: 1.1443
Batch 170, Loss: 1.1628
Batch 180, Loss: 1.1851
Batch 190, Loss: 1.1450
Batch 200, Loss: 1.1483
Batch 210, Loss: 1.1985
Batch 220, Loss: 1.1875
Batch 230, Loss: 1.1334
Batch 240, Loss: 1.1654
Batch 250, Loss: 1.1900
Batch 260, Loss: 1.1910
Batch 270, Loss: 1.1716
Batch 280, Loss: 1.1520
Batch 290, Loss: 1.1812
Batch 300, Loss: 1.1992
Batch 310, Loss: 1.1676
Batch 320, Loss: 1.1811
Batch 330, Loss: 1.1701
Batch 340, Loss: 1.2254
Batch 350, Loss: 1.2218
Batch 360, Loss: 1.1905
Batch 370, Loss: 1.2600
Batch 380, Loss: 1.2217
Batch 390, Loss: 1.2270
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.200407028198242 seconds
Epoch 89 accuracy: 66.32%
Batch 10, Loss: 1.1340
Batch 20, Loss: 1.1185
Batch 30, Loss: 1.1280
Batch 40, Loss: 1.0672
Batch 50, Loss: 1.1063
Batch 60, Loss: 1.1071
Batch 70, Loss: 1.1456
Batch 80, Loss: 1.1347
Batch 90, Loss: 1.1804
Batch 100, Loss: 1.1450
Batch 110, Loss: 1.1503
Batch 120, Loss: 1.1678
Batch 130, Loss: 1.1538
Batch 140, Loss: 1.1931
Batch 150, Loss: 1.1463
Batch 160, Loss: 1.1514
Batch 170, Loss: 1.2254
Batch 180, Loss: 1.1218
Batch 190, Loss: 1.2122
Batch 200, Loss: 1.1447
Batch 210, Loss: 1.1575
Batch 220, Loss: 1.1820
Batch 230, Loss: 1.2059
Batch 240, Loss: 1.1936
Batch 250, Loss: 1.2067
Batch 260, Loss: 1.2343
Batch 270, Loss: 1.1715
Batch 280, Loss: 1.1954
Batch 290, Loss: 1.1589
Batch 300, Loss: 1.1623
Batch 310, Loss: 1.2109
Batch 320, Loss: 1.2228
Batch 330, Loss: 1.2054
Batch 340, Loss: 1.1921
Batch 350, Loss: 1.1701
Batch 360, Loss: 1.1031
Batch 370, Loss: 1.1804
Batch 380, Loss: 1.1629
Batch 390, Loss: 1.1717
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.18531584739685 seconds
Epoch 90 accuracy: 62.75%
Batch 10, Loss: 1.0804
Batch 20, Loss: 1.1059
Batch 30, Loss: 1.1379
Batch 40, Loss: 1.1900
Batch 50, Loss: 1.1167
Batch 60, Loss: 1.1255
Batch 70, Loss: 1.1599
Batch 80, Loss: 1.1278
Batch 90, Loss: 1.1365
Batch 100, Loss: 1.1581
Batch 110, Loss: 1.1397
Batch 120, Loss: 1.1329
Batch 130, Loss: 1.1854
Batch 140, Loss: 1.1565
Batch 150, Loss: 1.1156
Batch 160, Loss: 1.1677
Batch 170, Loss: 1.1152
Batch 180, Loss: 1.1219
Batch 190, Loss: 1.1872
Batch 200, Loss: 1.2251
Batch 210, Loss: 1.1330
Batch 220, Loss: 1.1906
Batch 230, Loss: 1.1867
Batch 240, Loss: 1.1541
Batch 250, Loss: 1.1609
Batch 260, Loss: 1.1446
Batch 270, Loss: 1.1177
Batch 280, Loss: 1.1769
Batch 290, Loss: 1.2235
Batch 300, Loss: 1.1903
Batch 310, Loss: 1.1620
Batch 320, Loss: 1.1538
Batch 330, Loss: 1.1688
Batch 340, Loss: 1.1980
Batch 350, Loss: 1.1607
Batch 360, Loss: 1.1934
Batch 370, Loss: 1.1698
Batch 380, Loss: 1.1597
Batch 390, Loss: 1.2360
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.181406021118164 seconds
Epoch 91 accuracy: 62.47%
Batch 10, Loss: 1.1430
Batch 20, Loss: 1.1282
Batch 30, Loss: 1.0628
Batch 40, Loss: 1.1854
Batch 50, Loss: 1.1383
Batch 60, Loss: 1.2317
Batch 70, Loss: 1.0960
Batch 80, Loss: 1.1561
Batch 90, Loss: 1.1354
Batch 100, Loss: 1.1410
Batch 110, Loss: 1.0300
Batch 120, Loss: 1.1102
Batch 130, Loss: 1.1564
Batch 140, Loss: 1.1462
Batch 150, Loss: 1.0969
Batch 160, Loss: 1.1422
Batch 170, Loss: 1.1410
Batch 180, Loss: 1.0979
Batch 190, Loss: 1.2174
Batch 200, Loss: 1.1978
Batch 210, Loss: 1.2253
Batch 220, Loss: 1.1649
Batch 230, Loss: 1.2253
Batch 240, Loss: 1.1845
Batch 250, Loss: 1.2157
Batch 260, Loss: 1.1623
Batch 270, Loss: 1.1887
Batch 280, Loss: 1.1636
Batch 290, Loss: 1.1672
Batch 300, Loss: 1.1832
Batch 310, Loss: 1.1717
Batch 320, Loss: 1.1753
Batch 330, Loss: 1.1385
Batch 340, Loss: 1.1768
Batch 350, Loss: 1.1566
Batch 360, Loss: 1.2373
Batch 370, Loss: 1.1432
Batch 380, Loss: 1.1582
Batch 390, Loss: 1.2013
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.134830474853516 seconds
Epoch 92 accuracy: 63.95%
Batch 10, Loss: 1.0936
Batch 20, Loss: 1.1138
Batch 30, Loss: 1.0888
Batch 40, Loss: 1.0956
Batch 50, Loss: 1.1291
Batch 60, Loss: 1.0657
Batch 70, Loss: 1.1468
Batch 80, Loss: 1.1068
Batch 90, Loss: 1.1746
Batch 100, Loss: 1.1306
Batch 110, Loss: 1.1336
Batch 120, Loss: 1.1193
Batch 130, Loss: 1.1384
Batch 140, Loss: 1.1485
Batch 150, Loss: 1.1804
Batch 160, Loss: 1.1351
Batch 170, Loss: 1.1621
Batch 180, Loss: 1.1931
Batch 190, Loss: 1.1398
Batch 200, Loss: 1.1724
Batch 210, Loss: 1.1569
Batch 220, Loss: 1.0901
Batch 230, Loss: 1.1634
Batch 240, Loss: 1.1335
Batch 250, Loss: 1.1916
Batch 260, Loss: 1.1577
Batch 270, Loss: 1.2101
Batch 280, Loss: 1.1361
Batch 290, Loss: 1.1645
Batch 300, Loss: 1.1737
Batch 310, Loss: 1.1425
Batch 320, Loss: 1.1619
Batch 330, Loss: 1.1907
Batch 340, Loss: 1.1593
Batch 350, Loss: 1.1361
Batch 360, Loss: 1.1558
Batch 370, Loss: 1.1488
Batch 380, Loss: 1.1822
Batch 390, Loss: 1.1689
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.215860843658447 seconds
Epoch 93 accuracy: 65.17%
Batch 10, Loss: 1.1190
Batch 20, Loss: 1.1706
Batch 30, Loss: 1.0418
Batch 40, Loss: 1.1790
Batch 50, Loss: 1.1385
Batch 60, Loss: 1.0287
Batch 70, Loss: 1.1181
Batch 80, Loss: 1.0761
Batch 90, Loss: 1.1194
Batch 100, Loss: 1.1301
Batch 110, Loss: 1.1047
Batch 120, Loss: 1.1240
Batch 130, Loss: 1.1703
Batch 140, Loss: 1.1168
Batch 150, Loss: 1.1646
Batch 160, Loss: 1.1315
Batch 170, Loss: 1.1091
Batch 180, Loss: 1.1760
Batch 190, Loss: 1.1177
Batch 200, Loss: 1.1705
Batch 210, Loss: 1.1725
Batch 220, Loss: 1.1406
Batch 230, Loss: 1.1422
Batch 240, Loss: 1.2458
Batch 250, Loss: 1.1505
Batch 260, Loss: 1.1059
Batch 270, Loss: 1.1172
Batch 280, Loss: 1.1943
Batch 290, Loss: 1.1731
Batch 300, Loss: 1.1967
Batch 310, Loss: 1.1574
Batch 320, Loss: 1.1933
Batch 330, Loss: 1.1756
Batch 340, Loss: 1.1168
Batch 350, Loss: 1.1551
Batch 360, Loss: 1.1068
Batch 370, Loss: 1.1551
Batch 380, Loss: 1.2361
Batch 390, Loss: 1.1906
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.10261583328247 seconds
Epoch 94 accuracy: 65.46%
Batch 10, Loss: 1.0925
Batch 20, Loss: 1.1144
Batch 30, Loss: 1.0765
Batch 40, Loss: 1.0926
Batch 50, Loss: 1.1280
Batch 60, Loss: 1.1402
Batch 70, Loss: 1.0949
Batch 80, Loss: 1.1169
Batch 90, Loss: 1.1059
Batch 100, Loss: 1.1103
Batch 110, Loss: 1.1217
Batch 120, Loss: 1.1464
Batch 130, Loss: 1.1611
Batch 140, Loss: 1.1550
Batch 150, Loss: 1.1111
Batch 160, Loss: 1.1138
Batch 170, Loss: 1.1170
Batch 180, Loss: 1.1529
Batch 190, Loss: 1.1164
Batch 200, Loss: 1.1210
Batch 210, Loss: 1.1631
Batch 220, Loss: 1.0755
Batch 230, Loss: 1.0868
Batch 240, Loss: 1.1754
Batch 250, Loss: 1.1538
Batch 260, Loss: 1.1406
Batch 270, Loss: 1.1551
Batch 280, Loss: 1.1670
Batch 290, Loss: 1.1539
Batch 300, Loss: 1.0921
Batch 310, Loss: 1.2064
Batch 320, Loss: 1.1634
Batch 330, Loss: 1.1318
Batch 340, Loss: 1.1361
Batch 350, Loss: 1.1816
Batch 360, Loss: 1.1760
Batch 370, Loss: 1.1454
Batch 380, Loss: 1.1339
Batch 390, Loss: 1.1531
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.13146471977234 seconds
Epoch 95 accuracy: 65.57%
Batch 10, Loss: 1.1488
Batch 20, Loss: 1.1250
Batch 30, Loss: 1.0305
Batch 40, Loss: 1.1163
Batch 50, Loss: 1.0336
Batch 60, Loss: 1.0935
Batch 70, Loss: 1.0794
Batch 80, Loss: 1.1253
Batch 90, Loss: 1.1049
Batch 100, Loss: 1.1408
Batch 110, Loss: 1.1019
Batch 120, Loss: 1.0728
Batch 130, Loss: 1.1608
Batch 140, Loss: 1.1361
Batch 150, Loss: 1.1121
Batch 160, Loss: 1.0867
Batch 170, Loss: 1.2118
Batch 180, Loss: 1.1256
Batch 190, Loss: 1.0946
Batch 200, Loss: 1.1006
Batch 210, Loss: 1.1598
Batch 220, Loss: 1.1362
Batch 230, Loss: 1.1729
Batch 240, Loss: 1.1419
Batch 250, Loss: 1.0867
Batch 260, Loss: 1.2275
Batch 270, Loss: 1.0860
Batch 280, Loss: 1.1614
Batch 290, Loss: 1.1579
Batch 300, Loss: 1.1254
Batch 310, Loss: 1.1069
Batch 320, Loss: 1.1519
Batch 330, Loss: 1.0917
Batch 340, Loss: 1.1501
Batch 350, Loss: 1.1545
Batch 360, Loss: 1.1055
Batch 370, Loss: 1.1513
Batch 380, Loss: 1.1773
Batch 390, Loss: 1.1423
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.24576187133789 seconds
Epoch 96 accuracy: 67.53%
Batch 10, Loss: 1.0488
Batch 20, Loss: 1.0035
Batch 30, Loss: 1.0751
Batch 40, Loss: 1.1193
Batch 50, Loss: 1.1002
Batch 60, Loss: 1.1187
Batch 70, Loss: 1.0850
Batch 80, Loss: 1.0692
Batch 90, Loss: 1.1275
Batch 100, Loss: 1.0834
Batch 110, Loss: 1.0884
Batch 120, Loss: 1.0989
Batch 130, Loss: 1.1056
Batch 140, Loss: 1.0953
Batch 150, Loss: 1.1045
Batch 160, Loss: 1.0695
Batch 170, Loss: 1.0635
Batch 180, Loss: 1.1040
Batch 190, Loss: 1.1217
Batch 200, Loss: 1.1060
Batch 210, Loss: 1.1583
Batch 220, Loss: 1.1578
Batch 230, Loss: 1.1131
Batch 240, Loss: 1.1213
Batch 250, Loss: 1.0878
Batch 260, Loss: 1.1168
Batch 270, Loss: 1.1643
Batch 280, Loss: 1.1063
Batch 290, Loss: 1.1649
Batch 300, Loss: 1.0987
Batch 310, Loss: 1.1304
Batch 320, Loss: 1.1413
Batch 330, Loss: 1.1297
Batch 340, Loss: 1.1431
Batch 350, Loss: 1.1703
Batch 360, Loss: 1.1171
Batch 370, Loss: 1.1427
Batch 380, Loss: 1.1323
Batch 390, Loss: 1.1803
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.160255432128906 seconds
Epoch 97 accuracy: 65.81%
Batch 10, Loss: 1.1521
Batch 20, Loss: 1.0774
Batch 30, Loss: 1.1068
Batch 40, Loss: 1.0609
Batch 50, Loss: 1.0877
Batch 60, Loss: 1.0461
Batch 70, Loss: 1.0769
Batch 80, Loss: 1.0293
Batch 90, Loss: 1.0074
Batch 100, Loss: 1.0505
Batch 110, Loss: 1.0984
Batch 120, Loss: 1.0717
Batch 130, Loss: 1.1071
Batch 140, Loss: 1.1297
Batch 150, Loss: 1.0951
Batch 160, Loss: 1.0742
Batch 170, Loss: 1.1339
Batch 180, Loss: 1.1124
Batch 190, Loss: 1.1623
Batch 200, Loss: 1.0550
Batch 210, Loss: 1.1701
Batch 220, Loss: 1.1175
Batch 230, Loss: 1.1556
Batch 240, Loss: 1.1697
Batch 250, Loss: 1.1339
Batch 260, Loss: 1.1092
Batch 270, Loss: 1.0996
Batch 280, Loss: 1.0992
Batch 290, Loss: 1.1661
Batch 300, Loss: 1.0855
Batch 310, Loss: 1.1198
Batch 320, Loss: 1.1778
Batch 330, Loss: 1.1514
Batch 340, Loss: 1.1397
Batch 350, Loss: 1.1162
Batch 360, Loss: 1.1096
Batch 370, Loss: 1.2038
Batch 380, Loss: 1.1256
Batch 390, Loss: 1.1158
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.171783924102783 seconds
Epoch 98 accuracy: 62.78%
Batch 10, Loss: 1.0796
Batch 20, Loss: 1.0254
Batch 30, Loss: 1.0459
Batch 40, Loss: 1.0798
Batch 50, Loss: 1.0770
Batch 60, Loss: 1.0954
Batch 70, Loss: 1.1409
Batch 80, Loss: 1.1117
Batch 90, Loss: 1.1155
Batch 100, Loss: 1.1132
Batch 110, Loss: 1.1857
Batch 120, Loss: 1.0582
Batch 130, Loss: 1.0512
Batch 140, Loss: 1.0952
Batch 150, Loss: 1.1003
Batch 160, Loss: 1.1330
Batch 170, Loss: 1.0735
Batch 180, Loss: 1.0374
Batch 190, Loss: 1.0976
Batch 200, Loss: 1.0543
Batch 210, Loss: 1.1511
Batch 220, Loss: 1.0449
Batch 230, Loss: 1.2057
Batch 240, Loss: 1.1384
Batch 250, Loss: 1.0933
Batch 260, Loss: 1.1079
Batch 270, Loss: 1.1830
Batch 280, Loss: 1.1373
Batch 290, Loss: 1.1504
Batch 300, Loss: 1.1150
Batch 310, Loss: 1.1321
Batch 320, Loss: 1.1479
Batch 330, Loss: 1.1997
Batch 340, Loss: 1.1075
Batch 350, Loss: 1.1067
Batch 360, Loss: 1.1649
Batch 370, Loss: 1.1063
Batch 380, Loss: 1.1226
Batch 390, Loss: 1.1262
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.190218925476074 seconds
Epoch 99 accuracy: 65.21%
Batch 10, Loss: 1.0497
Batch 20, Loss: 1.0682
Batch 30, Loss: 1.0382
Batch 40, Loss: 1.1040
Batch 50, Loss: 1.0268
Batch 60, Loss: 1.1299
Batch 70, Loss: 1.0768
Batch 80, Loss: 1.1669
Batch 90, Loss: 1.0659
Batch 100, Loss: 1.1187
Batch 110, Loss: 1.1525
Batch 120, Loss: 1.0707
Batch 130, Loss: 1.1263
Batch 140, Loss: 1.1315
Batch 150, Loss: 1.1029
Batch 160, Loss: 1.0558
Batch 170, Loss: 1.0935
Batch 180, Loss: 1.1291
Batch 190, Loss: 1.1486
Batch 200, Loss: 1.1547
Batch 210, Loss: 1.1625
Batch 220, Loss: 1.1235
Batch 230, Loss: 1.1545
Batch 240, Loss: 1.1237
Batch 250, Loss: 1.1035
Batch 260, Loss: 1.1604
Batch 270, Loss: 1.0916
Batch 280, Loss: 1.1224
Batch 290, Loss: 1.0801
Batch 300, Loss: 1.0598
Batch 310, Loss: 1.0844
Batch 320, Loss: 1.1176
Batch 330, Loss: 1.1003
Batch 340, Loss: 1.1157
Batch 350, Loss: 1.0924
Batch 360, Loss: 1.0865
Batch 370, Loss: 1.1010
Batch 380, Loss: 1.1089
Batch 390, Loss: 1.1136
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.198113441467285 seconds
Epoch 100 accuracy: 68.0%
Batch 10, Loss: 1.1113
Batch 20, Loss: 1.0318
Batch 30, Loss: 0.9785
Batch 40, Loss: 1.0519
Batch 50, Loss: 1.0266
Batch 60, Loss: 1.0851
Batch 70, Loss: 1.0336
Batch 80, Loss: 1.0296
Batch 90, Loss: 1.0318
Batch 100, Loss: 1.1005
Batch 110, Loss: 1.0432
Batch 120, Loss: 1.0425
Batch 130, Loss: 1.0675
Batch 140, Loss: 1.0532
Batch 150, Loss: 1.0641
Batch 160, Loss: 1.0622
Batch 170, Loss: 1.1062
Batch 180, Loss: 1.0799
Batch 190, Loss: 1.1030
Batch 200, Loss: 1.0735
Batch 210, Loss: 1.0873
Batch 220, Loss: 1.1629
Batch 230, Loss: 1.1505
Batch 240, Loss: 1.1010
Batch 250, Loss: 1.0705
Batch 260, Loss: 1.0377
Batch 270, Loss: 1.0519
Batch 280, Loss: 1.1356
Batch 290, Loss: 1.0853
Batch 300, Loss: 1.1679
Batch 310, Loss: 1.1299
Batch 320, Loss: 1.1069
Batch 330, Loss: 1.1092
Batch 340, Loss: 1.2036
Batch 350, Loss: 1.1778
Batch 360, Loss: 1.1966
Batch 370, Loss: 1.1604
Batch 380, Loss: 1.1275
Batch 390, Loss: 1.0624
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.160650491714478 seconds
Epoch 101 accuracy: 65.68%
Batch 10, Loss: 1.0722
Batch 20, Loss: 0.9922
Batch 30, Loss: 1.0513
Batch 40, Loss: 1.0583
Batch 50, Loss: 1.0614
Batch 60, Loss: 1.0778
Batch 70, Loss: 1.1089
Batch 80, Loss: 1.0833
Batch 90, Loss: 1.0182
Batch 100, Loss: 1.0440
Batch 110, Loss: 1.0472
Batch 120, Loss: 1.0498
Batch 130, Loss: 1.0704
Batch 140, Loss: 1.0291
Batch 150, Loss: 1.0539
Batch 160, Loss: 1.1308
Batch 170, Loss: 1.0986
Batch 180, Loss: 1.0971
Batch 190, Loss: 1.0294
Batch 200, Loss: 1.1110
Batch 210, Loss: 1.1470
Batch 220, Loss: 1.1365
Batch 230, Loss: 1.0718
Batch 240, Loss: 1.0894
Batch 250, Loss: 1.1011
Batch 260, Loss: 1.1220
Batch 270, Loss: 1.0584
Batch 280, Loss: 1.1051
Batch 290, Loss: 1.1336
Batch 300, Loss: 1.0702
Batch 310, Loss: 1.0905
Batch 320, Loss: 1.0913
Batch 330, Loss: 1.0975
Batch 340, Loss: 1.1214
Batch 350, Loss: 1.0886
Batch 360, Loss: 1.2128
Batch 370, Loss: 1.1547
Batch 380, Loss: 1.1466
Batch 390, Loss: 1.1524
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.120333909988403 seconds
Epoch 102 accuracy: 66.4%
Batch 10, Loss: 1.0101
Batch 20, Loss: 1.0848
Batch 30, Loss: 1.0896
Batch 40, Loss: 0.9914
Batch 50, Loss: 1.0156
Batch 60, Loss: 1.0732
Batch 70, Loss: 0.9748
Batch 80, Loss: 1.0535
Batch 90, Loss: 1.0232
Batch 100, Loss: 1.0631
Batch 110, Loss: 1.1336
Batch 120, Loss: 1.1201
Batch 130, Loss: 1.0471
Batch 140, Loss: 1.0776
Batch 150, Loss: 1.0627
Batch 160, Loss: 1.0778
Batch 170, Loss: 1.0273
Batch 180, Loss: 1.0657
Batch 190, Loss: 1.0517
Batch 200, Loss: 1.0733
Batch 210, Loss: 1.0899
Batch 220, Loss: 1.1060
Batch 230, Loss: 1.1286
Batch 240, Loss: 1.1474
Batch 250, Loss: 1.0230
Batch 260, Loss: 1.0931
Batch 270, Loss: 1.0746
Batch 280, Loss: 1.1277
Batch 290, Loss: 1.0162
Batch 300, Loss: 1.1487
Batch 310, Loss: 1.1165
Batch 320, Loss: 1.1278
Batch 330, Loss: 1.0433
Batch 340, Loss: 1.0942
Batch 350, Loss: 1.0853
Batch 360, Loss: 1.1219
Batch 370, Loss: 1.1667
Batch 380, Loss: 1.1171
Batch 390, Loss: 1.1055
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.25087261199951 seconds
Epoch 103 accuracy: 67.54%
Batch 10, Loss: 1.0406
Batch 20, Loss: 1.0019
Batch 30, Loss: 1.0624
Batch 40, Loss: 0.9890
Batch 50, Loss: 1.0148
Batch 60, Loss: 1.0171
Batch 70, Loss: 1.0490
Batch 80, Loss: 1.1068
Batch 90, Loss: 0.9875
Batch 100, Loss: 1.0207
Batch 110, Loss: 1.0399
Batch 120, Loss: 1.0533
Batch 130, Loss: 1.0460
Batch 140, Loss: 1.0692
Batch 150, Loss: 1.0416
Batch 160, Loss: 1.0346
Batch 170, Loss: 1.1445
Batch 180, Loss: 1.0525
Batch 190, Loss: 1.0610
Batch 200, Loss: 1.1170
Batch 210, Loss: 1.0443
Batch 220, Loss: 1.0995
Batch 230, Loss: 1.0673
Batch 240, Loss: 1.0952
Batch 250, Loss: 1.0235
Batch 260, Loss: 1.1069
Batch 270, Loss: 1.1086
Batch 280, Loss: 1.0854
Batch 290, Loss: 1.1098
Batch 300, Loss: 1.0351
Batch 310, Loss: 1.0677
Batch 320, Loss: 1.1230
Batch 330, Loss: 1.0952
Batch 340, Loss: 1.0767
Batch 350, Loss: 1.1102
Batch 360, Loss: 1.0763
Batch 370, Loss: 1.1336
Batch 380, Loss: 1.1137
Batch 390, Loss: 1.0164
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.199892282485962 seconds
Epoch 104 accuracy: 66.26%
Batch 10, Loss: 1.0171
Batch 20, Loss: 1.0315
Batch 30, Loss: 1.0329
Batch 40, Loss: 0.9801
Batch 50, Loss: 1.0111
Batch 60, Loss: 1.0148
Batch 70, Loss: 1.0545
Batch 80, Loss: 1.0353
Batch 90, Loss: 1.0269
Batch 100, Loss: 1.0797
Batch 110, Loss: 0.9738
Batch 120, Loss: 1.0743
Batch 130, Loss: 1.0316
Batch 140, Loss: 1.0988
Batch 150, Loss: 1.0118
Batch 160, Loss: 1.0307
Batch 170, Loss: 1.0425
Batch 180, Loss: 1.1030
Batch 190, Loss: 1.0450
Batch 200, Loss: 1.1007
Batch 210, Loss: 1.0482
Batch 220, Loss: 1.0622
Batch 230, Loss: 1.0523
Batch 240, Loss: 1.0531
Batch 250, Loss: 1.0626
Batch 260, Loss: 1.0678
Batch 270, Loss: 1.0397
Batch 280, Loss: 1.0692
Batch 290, Loss: 1.0261
Batch 300, Loss: 1.0900
Batch 310, Loss: 1.0695
Batch 320, Loss: 1.0840
Batch 330, Loss: 1.0503
Batch 340, Loss: 1.0938
Batch 350, Loss: 1.0668
Batch 360, Loss: 1.0858
Batch 370, Loss: 1.0084
Batch 380, Loss: 1.1235
Batch 390, Loss: 1.1255
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.187745094299316 seconds
Epoch 105 accuracy: 66.78%
Batch 10, Loss: 1.0359
Batch 20, Loss: 0.9712
Batch 30, Loss: 1.0566
Batch 40, Loss: 1.0038
Batch 50, Loss: 1.0212
Batch 60, Loss: 1.0359
Batch 70, Loss: 1.0649
Batch 80, Loss: 0.9690
Batch 90, Loss: 1.0331
Batch 100, Loss: 1.0532
Batch 110, Loss: 0.9835
Batch 120, Loss: 1.0682
Batch 130, Loss: 1.0481
Batch 140, Loss: 1.0563
Batch 150, Loss: 1.0205
Batch 160, Loss: 1.0520
Batch 170, Loss: 1.0250
Batch 180, Loss: 1.0283
Batch 190, Loss: 1.0645
Batch 200, Loss: 1.0502
Batch 210, Loss: 1.0869
Batch 220, Loss: 1.1008
Batch 230, Loss: 1.0416
Batch 240, Loss: 1.1023
Batch 250, Loss: 1.0597
Batch 260, Loss: 1.0036
Batch 270, Loss: 1.0832
Batch 280, Loss: 0.9889
Batch 290, Loss: 1.0213
Batch 300, Loss: 1.0879
Batch 310, Loss: 1.0516
Batch 320, Loss: 1.0903
Batch 330, Loss: 1.0740
Batch 340, Loss: 1.0929
Batch 350, Loss: 1.0433
Batch 360, Loss: 1.0985
Batch 370, Loss: 1.0865
Batch 380, Loss: 1.0910
Batch 390, Loss: 1.0925
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.204674243927002 seconds
Epoch 106 accuracy: 67.2%
Batch 10, Loss: 1.0407
Batch 20, Loss: 1.0502
Batch 30, Loss: 1.0207
Batch 40, Loss: 0.9860
Batch 50, Loss: 1.0061
Batch 60, Loss: 0.9682
Batch 70, Loss: 0.9737
Batch 80, Loss: 0.9934
Batch 90, Loss: 1.0198
Batch 100, Loss: 0.9884
Batch 110, Loss: 1.0350
Batch 120, Loss: 1.0136
Batch 130, Loss: 0.9697
Batch 140, Loss: 1.0676
Batch 150, Loss: 1.0887
Batch 160, Loss: 1.0285
Batch 170, Loss: 1.1260
Batch 180, Loss: 1.0155
Batch 190, Loss: 1.0136
Batch 200, Loss: 1.0748
Batch 210, Loss: 0.9659
Batch 220, Loss: 1.0397
Batch 230, Loss: 1.0605
Batch 240, Loss: 1.0560
Batch 250, Loss: 1.1288
Batch 260, Loss: 1.0385
Batch 270, Loss: 0.9896
Batch 280, Loss: 1.0052
Batch 290, Loss: 1.0254
Batch 300, Loss: 1.0526
Batch 310, Loss: 1.0737
Batch 320, Loss: 1.0652
Batch 330, Loss: 1.0996
Batch 340, Loss: 1.1080
Batch 350, Loss: 1.2092
Batch 360, Loss: 1.1176
Batch 370, Loss: 1.1243
Batch 380, Loss: 1.0371
Batch 390, Loss: 1.1375
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.17815136909485 seconds
Epoch 107 accuracy: 67.2%
Batch 10, Loss: 0.9901
Batch 20, Loss: 1.0085
Batch 30, Loss: 1.0214
Batch 40, Loss: 1.0371
Batch 50, Loss: 0.9945
Batch 60, Loss: 0.9373
Batch 70, Loss: 1.0488
Batch 80, Loss: 0.9053
Batch 90, Loss: 0.9605
Batch 100, Loss: 0.9807
Batch 110, Loss: 1.0048
Batch 120, Loss: 1.0244
Batch 130, Loss: 0.9798
Batch 140, Loss: 1.0901
Batch 150, Loss: 1.0327
Batch 160, Loss: 1.0122
Batch 170, Loss: 1.0446
Batch 180, Loss: 1.0363
Batch 190, Loss: 1.0567
Batch 200, Loss: 1.0366
Batch 210, Loss: 0.9885
Batch 220, Loss: 1.0695
Batch 230, Loss: 1.0082
Batch 240, Loss: 1.0865
Batch 250, Loss: 1.0108
Batch 260, Loss: 1.0659
Batch 270, Loss: 1.0508
Batch 280, Loss: 1.0613
Batch 290, Loss: 1.0322
Batch 300, Loss: 1.0233
Batch 310, Loss: 1.0499
Batch 320, Loss: 1.0421
Batch 330, Loss: 1.0212
Batch 340, Loss: 1.0776
Batch 350, Loss: 1.0366
Batch 360, Loss: 1.0605
Batch 370, Loss: 1.0602
Batch 380, Loss: 1.0546
Batch 390, Loss: 1.0024
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.204538106918335 seconds
Epoch 108 accuracy: 65.82%
Batch 10, Loss: 0.9633
Batch 20, Loss: 0.9808
Batch 30, Loss: 0.9267
Batch 40, Loss: 1.0398
Batch 50, Loss: 0.9712
Batch 60, Loss: 0.9884
Batch 70, Loss: 0.9946
Batch 80, Loss: 0.9794
Batch 90, Loss: 0.9649
Batch 100, Loss: 1.0703
Batch 110, Loss: 1.0215
Batch 120, Loss: 0.9968
Batch 130, Loss: 1.0844
Batch 140, Loss: 1.0114
Batch 150, Loss: 0.9555
Batch 160, Loss: 1.0417
Batch 170, Loss: 1.0619
Batch 180, Loss: 0.9978
Batch 190, Loss: 1.0169
Batch 200, Loss: 1.0536
Batch 210, Loss: 1.0001
Batch 220, Loss: 1.0547
Batch 230, Loss: 0.9960
Batch 240, Loss: 1.1051
Batch 250, Loss: 1.0429
Batch 260, Loss: 1.0855
Batch 270, Loss: 1.0621
Batch 280, Loss: 1.0633
Batch 290, Loss: 1.0263
Batch 300, Loss: 1.0445
Batch 310, Loss: 0.9932
Batch 320, Loss: 1.0251
Batch 330, Loss: 1.0755
Batch 340, Loss: 1.1105
Batch 350, Loss: 1.0294
Batch 360, Loss: 1.0658
Batch 370, Loss: 1.0815
Batch 380, Loss: 1.1172
Batch 390, Loss: 1.0724
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.115566968917847 seconds
Epoch 109 accuracy: 65.68%
Batch 10, Loss: 1.0262
Batch 20, Loss: 0.9277
Batch 30, Loss: 0.9600
Batch 40, Loss: 1.0061
Batch 50, Loss: 0.9697
Batch 60, Loss: 1.0118
Batch 70, Loss: 0.9930
Batch 80, Loss: 0.9583
Batch 90, Loss: 0.9147
Batch 100, Loss: 1.0380
Batch 110, Loss: 1.0039
Batch 120, Loss: 1.0022
Batch 130, Loss: 1.0056
Batch 140, Loss: 1.0374
Batch 150, Loss: 0.9958
Batch 160, Loss: 1.0284
Batch 170, Loss: 1.0463
Batch 180, Loss: 1.0838
Batch 190, Loss: 1.0496
Batch 200, Loss: 1.0180
Batch 210, Loss: 1.0570
Batch 220, Loss: 1.0228
Batch 230, Loss: 1.0164
Batch 240, Loss: 1.0880
Batch 250, Loss: 1.0557
Batch 260, Loss: 1.0564
Batch 270, Loss: 1.0071
Batch 280, Loss: 0.9809
Batch 290, Loss: 0.9730
Batch 300, Loss: 0.9814
Batch 310, Loss: 1.0386
Batch 320, Loss: 1.0363
Batch 330, Loss: 1.0104
Batch 340, Loss: 0.9862
Batch 350, Loss: 1.0087
Batch 360, Loss: 1.0245
Batch 370, Loss: 1.0545
Batch 380, Loss: 1.0225
Batch 390, Loss: 1.0311
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.26178789138794 seconds
Epoch 110 accuracy: 68.26%
Batch 10, Loss: 0.9216
Batch 20, Loss: 0.9717
Batch 30, Loss: 1.0151
Batch 40, Loss: 0.9591
Batch 50, Loss: 0.9651
Batch 60, Loss: 0.9557
Batch 70, Loss: 0.9588
Batch 80, Loss: 1.0085
Batch 90, Loss: 1.0103
Batch 100, Loss: 1.0043
Batch 110, Loss: 0.9329
Batch 120, Loss: 1.0043
Batch 130, Loss: 0.9803
Batch 140, Loss: 1.0417
Batch 150, Loss: 1.0286
Batch 160, Loss: 0.9655
Batch 170, Loss: 1.0043
Batch 180, Loss: 0.9783
Batch 190, Loss: 0.9736
Batch 200, Loss: 0.9901
Batch 210, Loss: 0.9466
Batch 220, Loss: 0.9880
Batch 230, Loss: 1.0076
Batch 240, Loss: 0.9660
Batch 250, Loss: 0.9801
Batch 260, Loss: 1.0819
Batch 270, Loss: 1.0626
Batch 280, Loss: 1.0300
Batch 290, Loss: 1.0230
Batch 300, Loss: 1.0255
Batch 310, Loss: 1.0600
Batch 320, Loss: 1.0508
Batch 330, Loss: 0.9677
Batch 340, Loss: 0.9988
Batch 350, Loss: 0.9997
Batch 360, Loss: 1.0440
Batch 370, Loss: 1.0540
Batch 380, Loss: 1.0807
Batch 390, Loss: 1.0231
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.12355661392212 seconds
Epoch 111 accuracy: 66.91%
Batch 10, Loss: 0.9390
Batch 20, Loss: 0.9511
Batch 30, Loss: 0.9709
Batch 40, Loss: 0.9521
Batch 50, Loss: 0.9844
Batch 60, Loss: 0.9703
Batch 70, Loss: 0.9434
Batch 80, Loss: 0.9789
Batch 90, Loss: 0.9307
Batch 100, Loss: 0.9632
Batch 110, Loss: 1.0028
Batch 120, Loss: 1.0103
Batch 130, Loss: 0.9999
Batch 140, Loss: 0.9659
Batch 150, Loss: 1.0062
Batch 160, Loss: 0.9933
Batch 170, Loss: 1.0351
Batch 180, Loss: 1.0256
Batch 190, Loss: 1.0819
Batch 200, Loss: 1.0159
Batch 210, Loss: 0.9900
Batch 220, Loss: 1.0365
Batch 230, Loss: 0.9768
Batch 240, Loss: 1.0030
Batch 250, Loss: 0.9579
Batch 260, Loss: 1.0886
Batch 270, Loss: 1.0509
Batch 280, Loss: 1.0685
Batch 290, Loss: 1.0195
Batch 300, Loss: 1.1017
Batch 310, Loss: 1.0249
Batch 320, Loss: 1.0740
Batch 330, Loss: 1.0118
Batch 340, Loss: 1.0325
Batch 350, Loss: 1.0201
Batch 360, Loss: 1.0202
Batch 370, Loss: 0.9989
Batch 380, Loss: 0.9914
Batch 390, Loss: 1.0152
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.22633695602417 seconds
Epoch 112 accuracy: 67.52%
Batch 10, Loss: 0.9469
Batch 20, Loss: 0.9395
Batch 30, Loss: 0.9483
Batch 40, Loss: 0.9023
Batch 50, Loss: 0.9235
Batch 60, Loss: 1.0126
Batch 70, Loss: 0.9261
Batch 80, Loss: 1.0326
Batch 90, Loss: 0.9786
Batch 100, Loss: 1.0010
Batch 110, Loss: 1.0041
Batch 120, Loss: 1.0104
Batch 130, Loss: 1.0475
Batch 140, Loss: 0.9631
Batch 150, Loss: 0.9536
Batch 160, Loss: 1.0120
Batch 170, Loss: 0.9916
Batch 180, Loss: 1.0043
Batch 190, Loss: 1.0525
Batch 200, Loss: 1.0076
Batch 210, Loss: 0.9759
Batch 220, Loss: 0.9813
Batch 230, Loss: 0.9911
Batch 240, Loss: 0.9906
Batch 250, Loss: 0.9460
Batch 260, Loss: 1.0126
Batch 270, Loss: 0.9751
Batch 280, Loss: 0.9923
Batch 290, Loss: 0.9813
Batch 300, Loss: 1.0084
Batch 310, Loss: 0.9973
Batch 320, Loss: 1.0549
Batch 330, Loss: 1.0708
Batch 340, Loss: 1.0188
Batch 350, Loss: 1.0647
Batch 360, Loss: 0.9627
Batch 370, Loss: 1.0899
Batch 380, Loss: 1.0452
Batch 390, Loss: 0.9793
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.071110248565674 seconds
Epoch 113 accuracy: 67.47%
Batch 10, Loss: 0.9852
Batch 20, Loss: 0.9739
Batch 30, Loss: 0.9461
Batch 40, Loss: 0.9773
Batch 50, Loss: 0.9115
Batch 60, Loss: 0.9394
Batch 70, Loss: 0.9496
Batch 80, Loss: 0.8803
Batch 90, Loss: 0.9948
Batch 100, Loss: 0.9421
Batch 110, Loss: 0.9993
Batch 120, Loss: 0.9352
Batch 130, Loss: 1.0128
Batch 140, Loss: 0.8981
Batch 150, Loss: 0.9897
Batch 160, Loss: 0.9635
Batch 170, Loss: 0.9439
Batch 180, Loss: 0.9710
Batch 190, Loss: 0.9762
Batch 200, Loss: 0.9485
Batch 210, Loss: 0.9558
Batch 220, Loss: 0.9925
Batch 230, Loss: 1.0456
Batch 240, Loss: 0.9905
Batch 250, Loss: 1.0033
Batch 260, Loss: 1.0070
Batch 270, Loss: 0.9752
Batch 280, Loss: 1.0012
Batch 290, Loss: 1.0425
Batch 300, Loss: 0.9670
Batch 310, Loss: 1.0823
Batch 320, Loss: 1.0260
Batch 330, Loss: 0.9607
Batch 340, Loss: 1.0225
Batch 350, Loss: 1.0413
Batch 360, Loss: 1.0386
Batch 370, Loss: 1.0044
Batch 380, Loss: 0.9981
Batch 390, Loss: 1.0510
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.060702800750732 seconds
Epoch 114 accuracy: 67.42%
Batch 10, Loss: 1.0024
Batch 20, Loss: 0.8826
Batch 30, Loss: 0.9385
Batch 40, Loss: 0.9582
Batch 50, Loss: 0.9330
Batch 60, Loss: 0.9458
Batch 70, Loss: 0.9875
Batch 80, Loss: 0.9382
Batch 90, Loss: 0.8592
Batch 100, Loss: 0.9509
Batch 110, Loss: 0.9243
Batch 120, Loss: 0.9325
Batch 130, Loss: 1.0403
Batch 140, Loss: 1.0308
Batch 150, Loss: 0.9945
Batch 160, Loss: 0.9377
Batch 170, Loss: 0.9775
Batch 180, Loss: 0.9768
Batch 190, Loss: 0.9452
Batch 200, Loss: 0.9876
Batch 210, Loss: 0.9751
Batch 220, Loss: 0.9445
Batch 230, Loss: 1.0574
Batch 240, Loss: 0.9681
Batch 250, Loss: 0.9929
Batch 260, Loss: 1.0115
Batch 270, Loss: 1.0198
Batch 280, Loss: 0.9775
Batch 290, Loss: 0.9728
Batch 300, Loss: 1.0147
Batch 310, Loss: 0.9854
Batch 320, Loss: 1.0380
Batch 330, Loss: 1.0306
Batch 340, Loss: 0.9902
Batch 350, Loss: 1.0648
Batch 360, Loss: 0.9170
Batch 370, Loss: 1.0037
Batch 380, Loss: 1.0063
Batch 390, Loss: 0.9129
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.18646764755249 seconds
Epoch 115 accuracy: 69.02%
Batch 10, Loss: 0.9109
Batch 20, Loss: 0.8479
Batch 30, Loss: 0.9750
Batch 40, Loss: 0.9810
Batch 50, Loss: 0.9493
Batch 60, Loss: 0.9627
Batch 70, Loss: 0.9937
Batch 80, Loss: 0.9322
Batch 90, Loss: 0.9090
Batch 100, Loss: 0.9052
Batch 110, Loss: 0.9542
Batch 120, Loss: 0.9515
Batch 130, Loss: 0.9130
Batch 140, Loss: 0.8889
Batch 150, Loss: 0.9410
Batch 160, Loss: 0.9812
Batch 170, Loss: 0.9794
Batch 180, Loss: 0.9617
Batch 190, Loss: 0.8951
Batch 200, Loss: 0.9327
Batch 210, Loss: 0.9567
Batch 220, Loss: 0.9822
Batch 230, Loss: 0.9378
Batch 240, Loss: 0.9717
Batch 250, Loss: 0.9589
Batch 260, Loss: 0.9702
Batch 270, Loss: 0.9961
Batch 280, Loss: 1.0527
Batch 290, Loss: 0.9864
Batch 300, Loss: 0.9901
Batch 310, Loss: 1.0180
Batch 320, Loss: 0.9713
Batch 330, Loss: 0.9327
Batch 340, Loss: 1.0286
Batch 350, Loss: 1.0234
Batch 360, Loss: 1.0036
Batch 370, Loss: 1.0012
Batch 380, Loss: 0.9623
Batch 390, Loss: 0.9871
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.141863346099854 seconds
Epoch 116 accuracy: 65.72%
Batch 10, Loss: 0.9928
Batch 20, Loss: 0.9352
Batch 30, Loss: 0.9337
Batch 40, Loss: 0.8769
Batch 50, Loss: 0.9095
Batch 60, Loss: 0.9086
Batch 70, Loss: 0.9133
Batch 80, Loss: 0.9649
Batch 90, Loss: 0.9465
Batch 100, Loss: 0.9468
Batch 110, Loss: 0.9620
Batch 120, Loss: 0.8956
Batch 130, Loss: 0.9593
Batch 140, Loss: 0.9150
Batch 150, Loss: 0.9013
Batch 160, Loss: 0.9362
Batch 170, Loss: 0.9873
Batch 180, Loss: 0.9688
Batch 190, Loss: 1.0353
Batch 200, Loss: 0.9832
Batch 210, Loss: 0.9245
Batch 220, Loss: 0.9076
Batch 230, Loss: 0.9602
Batch 240, Loss: 0.9648
Batch 250, Loss: 0.8660
Batch 260, Loss: 0.9827
Batch 270, Loss: 0.9909
Batch 280, Loss: 0.9932
Batch 290, Loss: 0.9326
Batch 300, Loss: 0.9839
Batch 310, Loss: 0.9966
Batch 320, Loss: 0.9483
Batch 330, Loss: 0.9840
Batch 340, Loss: 1.0052
Batch 350, Loss: 0.9210
Batch 360, Loss: 0.9885
Batch 370, Loss: 0.9777
Batch 380, Loss: 1.0017
Batch 390, Loss: 0.9825
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.2385094165802 seconds
Epoch 117 accuracy: 70.07%
Batch 10, Loss: 0.9283
Batch 20, Loss: 0.9443
Batch 30, Loss: 0.9531
Batch 40, Loss: 0.9124
Batch 50, Loss: 0.9355
Batch 60, Loss: 0.9347
Batch 70, Loss: 0.9071
Batch 80, Loss: 0.8861
Batch 90, Loss: 0.9276
Batch 100, Loss: 0.8825
Batch 110, Loss: 0.9654
Batch 120, Loss: 0.9441
Batch 130, Loss: 0.9229
Batch 140, Loss: 0.9374
Batch 150, Loss: 0.8914
Batch 160, Loss: 0.8926
Batch 170, Loss: 0.9136
Batch 180, Loss: 0.9724
Batch 190, Loss: 0.9657
Batch 200, Loss: 0.9882
Batch 210, Loss: 1.0181
Batch 220, Loss: 0.9698
Batch 230, Loss: 0.9384
Batch 240, Loss: 0.9582
Batch 250, Loss: 0.9614
Batch 260, Loss: 0.9842
Batch 270, Loss: 0.9805
Batch 280, Loss: 0.9590
Batch 290, Loss: 0.8911
Batch 300, Loss: 0.9344
Batch 310, Loss: 0.9423
Batch 320, Loss: 0.9345
Batch 330, Loss: 0.9876
Batch 340, Loss: 0.9644
Batch 350, Loss: 0.9601
Batch 360, Loss: 0.9194
Batch 370, Loss: 0.9817
Batch 380, Loss: 0.9429
Batch 390, Loss: 1.0010
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.197265148162842 seconds
Epoch 118 accuracy: 68.52%
Batch 10, Loss: 0.8998
Batch 20, Loss: 0.8867
Batch 30, Loss: 0.8790
Batch 40, Loss: 0.9086
Batch 50, Loss: 0.9571
Batch 60, Loss: 0.8761
Batch 70, Loss: 0.8780
Batch 80, Loss: 0.8618
Batch 90, Loss: 0.8641
Batch 100, Loss: 0.8950
Batch 110, Loss: 0.8763
Batch 120, Loss: 0.9076
Batch 130, Loss: 0.9650
Batch 140, Loss: 1.0118
Batch 150, Loss: 0.9271
Batch 160, Loss: 0.8916
Batch 170, Loss: 0.9321
Batch 180, Loss: 0.9707
Batch 190, Loss: 0.9651
Batch 200, Loss: 0.9433
Batch 210, Loss: 0.9541
Batch 220, Loss: 0.9464
Batch 230, Loss: 0.9338
Batch 240, Loss: 0.9694
Batch 250, Loss: 0.9168
Batch 260, Loss: 0.9172
Batch 270, Loss: 0.9203
Batch 280, Loss: 0.9912
Batch 290, Loss: 0.9886
Batch 300, Loss: 1.0035
Batch 310, Loss: 0.8496
Batch 320, Loss: 0.9247
Batch 330, Loss: 0.9050
Batch 340, Loss: 0.9269
Batch 350, Loss: 0.9446
Batch 360, Loss: 1.0069
Batch 370, Loss: 0.9402
Batch 380, Loss: 0.9486
Batch 390, Loss: 0.9947
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.231571197509766 seconds
Epoch 119 accuracy: 67.97%
Batch 10, Loss: 0.9212
Batch 20, Loss: 0.8760
Batch 30, Loss: 0.8961
Batch 40, Loss: 0.9406
Batch 50, Loss: 0.8989
Batch 60, Loss: 0.8997
Batch 70, Loss: 0.8670
Batch 80, Loss: 0.9043
Batch 90, Loss: 0.8815
Batch 100, Loss: 0.9550
Batch 110, Loss: 0.8869
Batch 120, Loss: 0.9111
Batch 130, Loss: 0.9378
Batch 140, Loss: 0.9200
Batch 150, Loss: 0.8941
Batch 160, Loss: 0.9192
Batch 170, Loss: 0.8523
Batch 180, Loss: 0.9039
Batch 190, Loss: 0.9339
Batch 200, Loss: 0.9512
Batch 210, Loss: 0.9454
Batch 220, Loss: 1.0354
Batch 230, Loss: 0.9313
Batch 240, Loss: 0.9831
Batch 250, Loss: 0.9456
Batch 260, Loss: 0.9163
Batch 270, Loss: 0.9346
Batch 280, Loss: 0.9388
Batch 290, Loss: 0.8861
Batch 300, Loss: 0.9600
Batch 310, Loss: 0.9211
Batch 320, Loss: 0.9843
Batch 330, Loss: 0.9472
Batch 340, Loss: 0.9223
Batch 350, Loss: 1.0108
Batch 360, Loss: 0.9326
Batch 370, Loss: 0.9574
Batch 380, Loss: 0.9992
Batch 390, Loss: 0.9911
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.193708896636963 seconds
Epoch 120 accuracy: 68.8%
Batch 10, Loss: 0.9398
Batch 20, Loss: 0.9329
Batch 30, Loss: 0.8796
Batch 40, Loss: 0.8777
Batch 50, Loss: 0.8765
Batch 60, Loss: 0.9063
Batch 70, Loss: 0.9308
Batch 80, Loss: 0.9114
Batch 90, Loss: 0.9047
Batch 100, Loss: 0.8679
Batch 110, Loss: 0.9197
Batch 120, Loss: 0.8776
Batch 130, Loss: 0.9006
Batch 140, Loss: 0.8955
Batch 150, Loss: 0.9010
Batch 160, Loss: 0.8925
Batch 170, Loss: 0.8914
Batch 180, Loss: 0.9201
Batch 190, Loss: 0.9189
Batch 200, Loss: 0.9744
Batch 210, Loss: 0.8843
Batch 220, Loss: 0.9151
Batch 230, Loss: 0.8708
Batch 240, Loss: 0.9328
Batch 250, Loss: 0.9383
Batch 260, Loss: 0.8785
Batch 270, Loss: 0.9116
Batch 280, Loss: 0.9556
Batch 290, Loss: 0.9638
Batch 300, Loss: 0.9151
Batch 310, Loss: 0.9322
Batch 320, Loss: 0.9138
Batch 330, Loss: 0.9143
Batch 340, Loss: 0.9256
Batch 350, Loss: 0.9586
Batch 360, Loss: 0.9409
Batch 370, Loss: 0.9654
Batch 380, Loss: 0.9258
Batch 390, Loss: 0.9584
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.117966890335083 seconds
Epoch 121 accuracy: 66.72%
Batch 10, Loss: 0.9414
Batch 20, Loss: 0.8769
Batch 30, Loss: 0.8602
Batch 40, Loss: 0.8932
Batch 50, Loss: 0.8079
Batch 60, Loss: 0.8838
Batch 70, Loss: 0.9020
Batch 80, Loss: 0.8321
Batch 90, Loss: 0.8424
Batch 100, Loss: 0.8994
Batch 110, Loss: 0.9126
Batch 120, Loss: 0.8994
Batch 130, Loss: 0.9039
Batch 140, Loss: 0.8933
Batch 150, Loss: 0.8559
Batch 160, Loss: 0.8785
Batch 170, Loss: 0.8819
Batch 180, Loss: 0.9212
Batch 190, Loss: 0.8963
Batch 200, Loss: 0.9085
Batch 210, Loss: 0.9428
Batch 220, Loss: 0.8896
Batch 230, Loss: 0.8827
Batch 240, Loss: 0.9135
Batch 250, Loss: 0.8987
Batch 260, Loss: 0.9017
Batch 270, Loss: 0.8646
Batch 280, Loss: 0.9259
Batch 290, Loss: 0.9350
Batch 300, Loss: 0.9265
Batch 310, Loss: 0.9148
Batch 320, Loss: 0.9094
Batch 330, Loss: 0.9453
Batch 340, Loss: 0.9256
Batch 350, Loss: 0.9468
Batch 360, Loss: 0.9573
Batch 370, Loss: 0.9788
Batch 380, Loss: 0.9680
Batch 390, Loss: 0.9512
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.224746704101562 seconds
Epoch 122 accuracy: 69.07%
Batch 10, Loss: 0.8684
Batch 20, Loss: 0.8516
Batch 30, Loss: 0.8750
Batch 40, Loss: 0.8490
Batch 50, Loss: 0.9173
Batch 60, Loss: 0.8916
Batch 70, Loss: 0.9177
Batch 80, Loss: 0.9193
Batch 90, Loss: 0.8509
Batch 100, Loss: 0.8887
Batch 110, Loss: 0.8788
Batch 120, Loss: 0.8776
Batch 130, Loss: 0.8555
Batch 140, Loss: 0.8721
Batch 150, Loss: 0.9248
Batch 160, Loss: 0.8913
Batch 170, Loss: 0.9216
Batch 180, Loss: 0.8976
Batch 190, Loss: 0.8683
Batch 200, Loss: 0.8679
Batch 210, Loss: 0.8931
Batch 220, Loss: 0.9146
Batch 230, Loss: 0.9244
Batch 240, Loss: 0.9081
Batch 250, Loss: 0.9027
Batch 260, Loss: 0.9449
Batch 270, Loss: 0.9374
Batch 280, Loss: 0.9269
Batch 290, Loss: 0.9412
Batch 300, Loss: 0.9085
Batch 310, Loss: 0.9062
Batch 320, Loss: 0.9146
Batch 330, Loss: 0.9325
Batch 340, Loss: 0.9160
Batch 350, Loss: 0.9761
Batch 360, Loss: 0.9295
Batch 370, Loss: 0.9505
Batch 380, Loss: 0.9579
Batch 390, Loss: 0.9508
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.191707372665405 seconds
Epoch 123 accuracy: 68.72%
Batch 10, Loss: 0.8488
Batch 20, Loss: 0.8360
Batch 30, Loss: 0.8662
Batch 40, Loss: 0.8791
Batch 50, Loss: 0.8136
Batch 60, Loss: 0.9160
Batch 70, Loss: 0.9125
Batch 80, Loss: 0.8005
Batch 90, Loss: 0.8538
Batch 100, Loss: 0.8364
Batch 110, Loss: 0.8364
Batch 120, Loss: 0.8938
Batch 130, Loss: 0.8775
Batch 140, Loss: 0.8989
Batch 150, Loss: 0.8595
Batch 160, Loss: 0.9257
Batch 170, Loss: 0.8487
Batch 180, Loss: 0.8966
Batch 190, Loss: 0.8864
Batch 200, Loss: 0.8525
Batch 210, Loss: 0.8763
Batch 220, Loss: 0.9363
Batch 230, Loss: 0.9174
Batch 240, Loss: 0.8720
Batch 250, Loss: 0.8358
Batch 260, Loss: 0.8555
Batch 270, Loss: 0.9499
Batch 280, Loss: 0.9201
Batch 290, Loss: 0.9356
Batch 300, Loss: 0.8883
Batch 310, Loss: 0.9307
Batch 320, Loss: 0.8497
Batch 330, Loss: 0.9520
Batch 340, Loss: 0.9382
Batch 350, Loss: 0.8723
Batch 360, Loss: 0.8757
Batch 370, Loss: 0.9219
Batch 380, Loss: 0.9349
Batch 390, Loss: 0.8749
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.035950422286987 seconds
Epoch 124 accuracy: 68.54%
Batch 10, Loss: 0.8545
Batch 20, Loss: 0.8132
Batch 30, Loss: 0.8875
Batch 40, Loss: 0.8653
Batch 50, Loss: 0.9091
Batch 60, Loss: 0.8690
Batch 70, Loss: 0.8385
Batch 80, Loss: 0.8303
Batch 90, Loss: 0.8758
Batch 100, Loss: 0.8990
Batch 110, Loss: 0.8423
Batch 120, Loss: 0.8642
Batch 130, Loss: 0.9076
Batch 140, Loss: 0.8456
Batch 150, Loss: 0.8984
Batch 160, Loss: 0.8710
Batch 170, Loss: 0.9038
Batch 180, Loss: 0.8388
Batch 190, Loss: 0.9583
Batch 200, Loss: 0.8969
Batch 210, Loss: 0.8811
Batch 220, Loss: 0.8784
Batch 230, Loss: 0.8651
Batch 240, Loss: 0.8565
Batch 250, Loss: 0.9051
Batch 260, Loss: 0.8816
Batch 270, Loss: 0.8788
Batch 280, Loss: 0.8462
Batch 290, Loss: 0.8332
Batch 300, Loss: 0.9265
Batch 310, Loss: 0.9120
Batch 320, Loss: 0.8816
Batch 330, Loss: 0.9027
Batch 340, Loss: 0.9009
Batch 350, Loss: 0.9191
Batch 360, Loss: 0.9074
Batch 370, Loss: 0.9070
Batch 380, Loss: 0.8880
Batch 390, Loss: 0.8846
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.27581787109375 seconds
Epoch 125 accuracy: 70.9%
Batch 10, Loss: 0.8630
Batch 20, Loss: 0.8710
Batch 30, Loss: 0.7645
Batch 40, Loss: 0.7566
Batch 50, Loss: 0.8430
Batch 60, Loss: 0.8044
Batch 70, Loss: 0.8006
Batch 80, Loss: 0.8729
Batch 90, Loss: 0.8325
Batch 100, Loss: 0.7723
Batch 110, Loss: 0.8938
Batch 120, Loss: 0.8298
Batch 130, Loss: 0.8389
Batch 140, Loss: 0.8417
Batch 150, Loss: 0.8402
Batch 160, Loss: 0.8642
Batch 170, Loss: 0.8759
Batch 180, Loss: 0.8233
Batch 190, Loss: 0.8422
Batch 200, Loss: 0.9078
Batch 210, Loss: 0.8935
Batch 220, Loss: 0.9020
Batch 230, Loss: 0.9171
Batch 240, Loss: 0.9336
Batch 250, Loss: 0.8447
Batch 260, Loss: 0.9097
Batch 270, Loss: 0.8736
Batch 280, Loss: 0.8541
Batch 290, Loss: 0.8887
Batch 300, Loss: 0.8347
Batch 310, Loss: 0.8911
Batch 320, Loss: 0.8789
Batch 330, Loss: 0.8786
Batch 340, Loss: 0.8801
Batch 350, Loss: 0.9389
Batch 360, Loss: 0.8731
Batch 370, Loss: 0.8928
Batch 380, Loss: 0.8789
Batch 390, Loss: 0.8900
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.257694482803345 seconds
Epoch 126 accuracy: 70.85%
Batch 10, Loss: 0.7780
Batch 20, Loss: 0.8498
Batch 30, Loss: 0.8632
Batch 40, Loss: 0.8734
Batch 50, Loss: 0.8200
Batch 60, Loss: 0.8337
Batch 70, Loss: 0.8740
Batch 80, Loss: 0.8472
Batch 90, Loss: 0.8415
Batch 100, Loss: 0.8353
Batch 110, Loss: 0.7857
Batch 120, Loss: 0.8247
Batch 130, Loss: 0.8515
Batch 140, Loss: 0.8946
Batch 150, Loss: 0.8586
Batch 160, Loss: 0.8071
Batch 170, Loss: 0.7918
Batch 180, Loss: 0.8715
Batch 190, Loss: 0.9074
Batch 200, Loss: 0.8766
Batch 210, Loss: 0.8310
Batch 220, Loss: 0.9343
Batch 230, Loss: 0.8540
Batch 240, Loss: 0.8522
Batch 250, Loss: 0.8669
Batch 260, Loss: 0.8695
Batch 270, Loss: 0.8474
Batch 280, Loss: 0.8929
Batch 290, Loss: 0.8677
Batch 300, Loss: 0.8252
Batch 310, Loss: 0.9152
Batch 320, Loss: 0.8304
Batch 330, Loss: 0.8955
Batch 340, Loss: 0.8637
Batch 350, Loss: 0.9084
Batch 360, Loss: 0.8654
Batch 370, Loss: 0.8526
Batch 380, Loss: 0.9088
Batch 390, Loss: 0.8905
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.193015575408936 seconds
Epoch 127 accuracy: 70.35%
Batch 10, Loss: 0.8619
Batch 20, Loss: 0.8710
Batch 30, Loss: 0.8094
Batch 40, Loss: 0.7599
Batch 50, Loss: 0.7821
Batch 60, Loss: 0.7918
Batch 70, Loss: 0.8007
Batch 80, Loss: 0.8246
Batch 90, Loss: 0.8076
Batch 100, Loss: 0.8225
Batch 110, Loss: 0.7584
Batch 120, Loss: 0.8410
Batch 130, Loss: 0.8328
Batch 140, Loss: 0.8370
Batch 150, Loss: 0.8564
Batch 160, Loss: 0.8511
Batch 170, Loss: 0.8281
Batch 180, Loss: 0.8474
Batch 190, Loss: 0.8191
Batch 200, Loss: 0.8688
Batch 210, Loss: 0.8143
Batch 220, Loss: 0.8567
Batch 230, Loss: 0.8667
Batch 240, Loss: 0.7859
Batch 250, Loss: 0.8524
Batch 260, Loss: 0.8145
Batch 270, Loss: 0.8560
Batch 280, Loss: 0.8605
Batch 290, Loss: 0.8341
Batch 300, Loss: 0.8208
Batch 310, Loss: 0.8247
Batch 320, Loss: 0.8972
Batch 330, Loss: 0.8476
Batch 340, Loss: 0.8592
Batch 350, Loss: 0.8367
Batch 360, Loss: 0.8157
Batch 370, Loss: 0.8759
Batch 380, Loss: 0.8761
Batch 390, Loss: 0.8595
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.18779683113098 seconds
Epoch 128 accuracy: 68.92%
Batch 10, Loss: 0.8503
Batch 20, Loss: 0.8198
Batch 30, Loss: 0.7518
Batch 40, Loss: 0.7887
Batch 50, Loss: 0.8115
Batch 60, Loss: 0.8061
Batch 70, Loss: 0.8068
Batch 80, Loss: 0.8411
Batch 90, Loss: 0.7883
Batch 100, Loss: 0.8224
Batch 110, Loss: 0.7626
Batch 120, Loss: 0.8245
Batch 130, Loss: 0.8423
Batch 140, Loss: 0.8171
Batch 150, Loss: 0.7818
Batch 160, Loss: 0.8137
Batch 170, Loss: 0.8388
Batch 180, Loss: 0.8285
Batch 190, Loss: 0.8301
Batch 200, Loss: 0.7874
Batch 210, Loss: 0.8267
Batch 220, Loss: 0.8023
Batch 230, Loss: 0.8449
Batch 240, Loss: 0.8340
Batch 250, Loss: 0.8524
Batch 260, Loss: 0.8404
Batch 270, Loss: 0.8351
Batch 280, Loss: 0.8814
Batch 290, Loss: 0.8241
Batch 300, Loss: 0.8688
Batch 310, Loss: 0.8796
Batch 320, Loss: 0.9043
Batch 330, Loss: 0.8614
Batch 340, Loss: 0.8265
Batch 350, Loss: 0.8674
Batch 360, Loss: 0.8235
Batch 370, Loss: 0.8563
Batch 380, Loss: 0.8125
Batch 390, Loss: 0.8331
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.08916449546814 seconds
Epoch 129 accuracy: 70.3%
Batch 10, Loss: 0.8305
Batch 20, Loss: 0.7928
Batch 30, Loss: 0.7839
Batch 40, Loss: 0.7666
Batch 50, Loss: 0.7825
Batch 60, Loss: 0.8040
Batch 70, Loss: 0.8170
Batch 80, Loss: 0.8038
Batch 90, Loss: 0.7821
Batch 100, Loss: 0.7657
Batch 110, Loss: 0.7933
Batch 120, Loss: 0.8482
Batch 130, Loss: 0.7730
Batch 140, Loss: 0.8073
Batch 150, Loss: 0.7928
Batch 160, Loss: 0.7656
Batch 170, Loss: 0.8207
Batch 180, Loss: 0.8347
Batch 190, Loss: 0.8378
Batch 200, Loss: 0.8386
Batch 210, Loss: 0.7801
Batch 220, Loss: 0.8726
Batch 230, Loss: 0.7768
Batch 240, Loss: 0.8093
Batch 250, Loss: 0.7935
Batch 260, Loss: 0.8197
Batch 270, Loss: 0.8075
Batch 280, Loss: 0.8131
Batch 290, Loss: 0.8661
Batch 300, Loss: 0.8476
Batch 310, Loss: 0.8397
Batch 320, Loss: 0.8020
Batch 330, Loss: 0.8683
Batch 340, Loss: 0.8333
Batch 350, Loss: 0.8284
Batch 360, Loss: 0.9277
Batch 370, Loss: 0.8942
Batch 380, Loss: 0.8518
Batch 390, Loss: 0.8399
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.15250539779663 seconds
Epoch 130 accuracy: 67.63%
Batch 10, Loss: 0.8093
Batch 20, Loss: 0.7815
Batch 30, Loss: 0.7686
Batch 40, Loss: 0.7494
Batch 50, Loss: 0.7647
Batch 60, Loss: 0.8305
Batch 70, Loss: 0.7296
Batch 80, Loss: 0.8428
Batch 90, Loss: 0.7696
Batch 100, Loss: 0.7880
Batch 110, Loss: 0.7121
Batch 120, Loss: 0.8157
Batch 130, Loss: 0.7686
Batch 140, Loss: 0.7892
Batch 150, Loss: 0.7754
Batch 160, Loss: 0.8100
Batch 170, Loss: 0.8126
Batch 180, Loss: 0.7936
Batch 190, Loss: 0.8280
Batch 200, Loss: 0.8235
Batch 210, Loss: 0.8238
Batch 220, Loss: 0.8575
Batch 230, Loss: 0.7922
Batch 240, Loss: 0.8530
Batch 250, Loss: 0.8336
Batch 260, Loss: 0.8188
Batch 270, Loss: 0.8146
Batch 280, Loss: 0.8393
Batch 290, Loss: 0.8190
Batch 300, Loss: 0.8459
Batch 310, Loss: 0.8481
Batch 320, Loss: 0.8539
Batch 330, Loss: 0.8130
Batch 340, Loss: 0.7829
Batch 350, Loss: 0.8334
Batch 360, Loss: 0.8276
Batch 370, Loss: 0.8768
Batch 380, Loss: 0.8610
Batch 390, Loss: 0.9037
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.211151599884033 seconds
Epoch 131 accuracy: 70.5%
Batch 10, Loss: 0.7676
Batch 20, Loss: 0.8002
Batch 30, Loss: 0.7421
Batch 40, Loss: 0.8062
Batch 50, Loss: 0.7399
Batch 60, Loss: 0.7905
Batch 70, Loss: 0.6937
Batch 80, Loss: 0.7267
Batch 90, Loss: 0.8063
Batch 100, Loss: 0.7496
Batch 110, Loss: 0.8489
Batch 120, Loss: 0.8008
Batch 130, Loss: 0.7849
Batch 140, Loss: 0.8388
Batch 150, Loss: 0.7794
Batch 160, Loss: 0.8197
Batch 170, Loss: 0.7894
Batch 180, Loss: 0.8151
Batch 190, Loss: 0.8375
Batch 200, Loss: 0.8244
Batch 210, Loss: 0.8425
Batch 220, Loss: 0.8589
Batch 230, Loss: 0.8433
Batch 240, Loss: 0.7876
Batch 250, Loss: 0.7843
Batch 260, Loss: 0.8204
Batch 270, Loss: 0.7907
Batch 280, Loss: 0.7965
Batch 290, Loss: 0.7465
Batch 300, Loss: 0.8049
Batch 310, Loss: 0.8214
Batch 320, Loss: 0.7796
Batch 330, Loss: 0.8793
Batch 340, Loss: 0.8493
Batch 350, Loss: 0.8405
Batch 360, Loss: 0.8593
Batch 370, Loss: 0.9032
Batch 380, Loss: 0.8293
Batch 390, Loss: 0.7967
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.120068788528442 seconds
Epoch 132 accuracy: 71.0%
Batch 10, Loss: 0.7506
Batch 20, Loss: 0.7468
Batch 30, Loss: 0.8014
Batch 40, Loss: 0.7139
Batch 50, Loss: 0.8287
Batch 60, Loss: 0.7160
Batch 70, Loss: 0.7442
Batch 80, Loss: 0.7357
Batch 90, Loss: 0.7136
Batch 100, Loss: 0.7822
Batch 110, Loss: 0.7907
Batch 120, Loss: 0.7996
Batch 130, Loss: 0.7962
Batch 140, Loss: 0.7836
Batch 150, Loss: 0.7967
Batch 160, Loss: 0.7531
Batch 170, Loss: 0.7990
Batch 180, Loss: 0.7917
Batch 190, Loss: 0.8409
Batch 200, Loss: 0.7404
Batch 210, Loss: 0.7919
Batch 220, Loss: 0.8464
Batch 230, Loss: 0.7907
Batch 240, Loss: 0.8330
Batch 250, Loss: 0.8199
Batch 260, Loss: 0.8196
Batch 270, Loss: 0.7358
Batch 280, Loss: 0.7799
Batch 290, Loss: 0.8567
Batch 300, Loss: 0.7970
Batch 310, Loss: 0.7774
Batch 320, Loss: 0.8222
Batch 330, Loss: 0.7806
Batch 340, Loss: 0.8332
Batch 350, Loss: 0.8603
Batch 360, Loss: 0.8255
Batch 370, Loss: 0.8927
Batch 380, Loss: 0.8427
Batch 390, Loss: 0.8753
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.183422565460205 seconds
Epoch 133 accuracy: 71.14%
Batch 10, Loss: 0.7578
Batch 20, Loss: 0.7881
Batch 30, Loss: 0.6989
Batch 40, Loss: 0.7525
Batch 50, Loss: 0.6913
Batch 60, Loss: 0.7481
Batch 70, Loss: 0.7463
Batch 80, Loss: 0.7939
Batch 90, Loss: 0.7996
Batch 100, Loss: 0.7732
Batch 110, Loss: 0.7349
Batch 120, Loss: 0.7507
Batch 130, Loss: 0.7935
Batch 140, Loss: 0.7617
Batch 150, Loss: 0.7911
Batch 160, Loss: 0.7547
Batch 170, Loss: 0.7768
Batch 180, Loss: 0.8106
Batch 190, Loss: 0.8189
Batch 200, Loss: 0.7493
Batch 210, Loss: 0.7734
Batch 220, Loss: 0.7160
Batch 230, Loss: 0.8065
Batch 240, Loss: 0.8029
Batch 250, Loss: 0.8001
Batch 260, Loss: 0.8155
Batch 270, Loss: 0.7848
Batch 280, Loss: 0.8047
Batch 290, Loss: 0.7901
Batch 300, Loss: 0.7894
Batch 310, Loss: 0.7221
Batch 320, Loss: 0.8330
Batch 330, Loss: 0.8444
Batch 340, Loss: 0.8163
Batch 350, Loss: 0.8494
Batch 360, Loss: 0.8804
Batch 370, Loss: 0.8161
Batch 380, Loss: 0.7779
Batch 390, Loss: 0.8029
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.11070680618286 seconds
Epoch 134 accuracy: 72.33%
Batch 10, Loss: 0.7559
Batch 20, Loss: 0.7544
Batch 30, Loss: 0.7181
Batch 40, Loss: 0.7178
Batch 50, Loss: 0.6982
Batch 60, Loss: 0.7613
Batch 70, Loss: 0.7413
Batch 80, Loss: 0.7596
Batch 90, Loss: 0.7532
Batch 100, Loss: 0.7638
Batch 110, Loss: 0.7227
Batch 120, Loss: 0.7837
Batch 130, Loss: 0.7780
Batch 140, Loss: 0.7294
Batch 150, Loss: 0.7716
Batch 160, Loss: 0.7530
Batch 170, Loss: 0.7723
Batch 180, Loss: 0.7649
Batch 190, Loss: 0.8098
Batch 200, Loss: 0.7874
Batch 210, Loss: 0.7641
Batch 220, Loss: 0.7969
Batch 230, Loss: 0.8103
Batch 240, Loss: 0.7811
Batch 250, Loss: 0.7442
Batch 260, Loss: 0.7372
Batch 270, Loss: 0.7817
Batch 280, Loss: 0.7998
Batch 290, Loss: 0.8046
Batch 300, Loss: 0.7986
Batch 310, Loss: 0.7841
Batch 320, Loss: 0.8680
Batch 330, Loss: 0.7435
Batch 340, Loss: 0.8595
Batch 350, Loss: 0.8126
Batch 360, Loss: 0.7595
Batch 370, Loss: 0.8183
Batch 380, Loss: 0.7607
Batch 390, Loss: 0.8107
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.14088273048401 seconds
Epoch 135 accuracy: 72.24%
Batch 10, Loss: 0.7364
Batch 20, Loss: 0.7219
Batch 30, Loss: 0.7258
Batch 40, Loss: 0.7014
Batch 50, Loss: 0.7087
Batch 60, Loss: 0.6945
Batch 70, Loss: 0.7090
Batch 80, Loss: 0.7268
Batch 90, Loss: 0.7634
Batch 100, Loss: 0.7445
Batch 110, Loss: 0.7954
Batch 120, Loss: 0.6852
Batch 130, Loss: 0.7692
Batch 140, Loss: 0.7900
Batch 150, Loss: 0.7434
Batch 160, Loss: 0.7399
Batch 170, Loss: 0.7983
Batch 180, Loss: 0.7749
Batch 190, Loss: 0.7464
Batch 200, Loss: 0.7767
Batch 210, Loss: 0.7437
Batch 220, Loss: 0.7431
Batch 230, Loss: 0.7468
Batch 240, Loss: 0.7618
Batch 250, Loss: 0.8383
Batch 260, Loss: 0.7950
Batch 270, Loss: 0.7718
Batch 280, Loss: 0.8159
Batch 290, Loss: 0.7900
Batch 300, Loss: 0.7910
Batch 310, Loss: 0.8147
Batch 320, Loss: 0.8295
Batch 330, Loss: 0.8144
Batch 340, Loss: 0.8054
Batch 350, Loss: 0.8201
Batch 360, Loss: 0.8353
Batch 370, Loss: 0.7738
Batch 380, Loss: 0.7288
Batch 390, Loss: 0.7061
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.11161732673645 seconds
Epoch 136 accuracy: 72.65%
Batch 10, Loss: 0.6739
Batch 20, Loss: 0.6918
Batch 30, Loss: 0.7755
Batch 40, Loss: 0.7703
Batch 50, Loss: 0.7918
Batch 60, Loss: 0.7200
Batch 70, Loss: 0.7464
Batch 80, Loss: 0.7241
Batch 90, Loss: 0.7126
Batch 100, Loss: 0.7931
Batch 110, Loss: 0.7314
Batch 120, Loss: 0.7314
Batch 130, Loss: 0.7166
Batch 140, Loss: 0.7540
Batch 150, Loss: 0.6510
Batch 160, Loss: 0.7770
Batch 170, Loss: 0.7378
Batch 180, Loss: 0.7625
Batch 190, Loss: 0.7362
Batch 200, Loss: 0.7582
Batch 210, Loss: 0.7774
Batch 220, Loss: 0.7346
Batch 230, Loss: 0.7509
Batch 240, Loss: 0.7776
Batch 250, Loss: 0.7578
Batch 260, Loss: 0.7494
Batch 270, Loss: 0.7795
Batch 280, Loss: 0.8372
Batch 290, Loss: 0.7808
Batch 300, Loss: 0.7929
Batch 310, Loss: 0.7229
Batch 320, Loss: 0.7188
Batch 330, Loss: 0.7420
Batch 340, Loss: 0.7603
Batch 350, Loss: 0.7070
Batch 360, Loss: 0.8144
Batch 370, Loss: 0.7409
Batch 380, Loss: 0.7786
Batch 390, Loss: 0.7499
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.08271026611328 seconds
Epoch 137 accuracy: 72.94%
Batch 10, Loss: 0.7441
Batch 20, Loss: 0.6734
Batch 30, Loss: 0.7508
Batch 40, Loss: 0.7520
Batch 50, Loss: 0.7026
Batch 60, Loss: 0.7037
Batch 70, Loss: 0.7060
Batch 80, Loss: 0.7622
Batch 90, Loss: 0.7225
Batch 100, Loss: 0.6681
Batch 110, Loss: 0.6645
Batch 120, Loss: 0.6848
Batch 130, Loss: 0.7047
Batch 140, Loss: 0.6939
Batch 150, Loss: 0.7133
Batch 160, Loss: 0.7052
Batch 170, Loss: 0.7349
Batch 180, Loss: 0.7781
Batch 190, Loss: 0.7183
Batch 200, Loss: 0.7750
Batch 210, Loss: 0.7345
Batch 220, Loss: 0.7493
Batch 230, Loss: 0.7390
Batch 240, Loss: 0.7390
Batch 250, Loss: 0.7588
Batch 260, Loss: 0.7085
Batch 270, Loss: 0.7385
Batch 280, Loss: 0.7683
Batch 290, Loss: 0.7848
Batch 300, Loss: 0.7601
Batch 310, Loss: 0.7758
Batch 320, Loss: 0.7749
Batch 330, Loss: 0.7879
Batch 340, Loss: 0.7773
Batch 350, Loss: 0.7522
Batch 360, Loss: 0.7403
Batch 370, Loss: 0.8016
Batch 380, Loss: 0.7510
Batch 390, Loss: 0.7346
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.192365169525146 seconds
Epoch 138 accuracy: 72.87%
Batch 10, Loss: 0.6736
Batch 20, Loss: 0.7172
Batch 30, Loss: 0.7028
Batch 40, Loss: 0.7289
Batch 50, Loss: 0.6788
Batch 60, Loss: 0.7611
Batch 70, Loss: 0.7165
Batch 80, Loss: 0.7270
Batch 90, Loss: 0.6995
Batch 100, Loss: 0.7062
Batch 110, Loss: 0.7051
Batch 120, Loss: 0.6962
Batch 130, Loss: 0.6838
Batch 140, Loss: 0.7193
Batch 150, Loss: 0.6910
Batch 160, Loss: 0.6603
Batch 170, Loss: 0.7987
Batch 180, Loss: 0.7666
Batch 190, Loss: 0.7110
Batch 200, Loss: 0.7427
Batch 210, Loss: 0.7261
Batch 220, Loss: 0.6917
Batch 230, Loss: 0.6989
Batch 240, Loss: 0.7411
Batch 250, Loss: 0.7775
Batch 260, Loss: 0.7230
Batch 270, Loss: 0.7226
Batch 280, Loss: 0.6712
Batch 290, Loss: 0.7692
Batch 300, Loss: 0.7380
Batch 310, Loss: 0.7353
Batch 320, Loss: 0.7649
Batch 330, Loss: 0.7669
Batch 340, Loss: 0.7748
Batch 350, Loss: 0.7434
Batch 360, Loss: 0.8590
Batch 370, Loss: 0.7155
Batch 380, Loss: 0.7488
Batch 390, Loss: 0.7647
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.184544801712036 seconds
Epoch 139 accuracy: 72.68%
Batch 10, Loss: 0.7631
Batch 20, Loss: 0.6565
Batch 30, Loss: 0.6880
Batch 40, Loss: 0.6971
Batch 50, Loss: 0.7016
Batch 60, Loss: 0.6706
Batch 70, Loss: 0.6939
Batch 80, Loss: 0.7149
Batch 90, Loss: 0.6757
Batch 100, Loss: 0.6950
Batch 110, Loss: 0.7026
Batch 120, Loss: 0.6975
Batch 130, Loss: 0.7234
Batch 140, Loss: 0.6770
Batch 150, Loss: 0.6727
Batch 160, Loss: 0.7273
Batch 170, Loss: 0.7005
Batch 180, Loss: 0.7427
Batch 190, Loss: 0.7557
Batch 200, Loss: 0.7303
Batch 210, Loss: 0.6921
Batch 220, Loss: 0.6930
Batch 230, Loss: 0.7579
Batch 240, Loss: 0.7405
Batch 250, Loss: 0.7028
Batch 260, Loss: 0.7283
Batch 270, Loss: 0.7275
Batch 280, Loss: 0.7324
Batch 290, Loss: 0.7174
Batch 300, Loss: 0.7194
Batch 310, Loss: 0.7027
Batch 320, Loss: 0.7282
Batch 330, Loss: 0.7865
Batch 340, Loss: 0.7588
Batch 350, Loss: 0.7642
Batch 360, Loss: 0.8103
Batch 370, Loss: 0.7722
Batch 380, Loss: 0.7384
Batch 390, Loss: 0.7199
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.151437282562256 seconds
Epoch 140 accuracy: 72.98%
Batch 10, Loss: 0.7366
Batch 20, Loss: 0.6551
Batch 30, Loss: 0.6886
Batch 40, Loss: 0.6797
Batch 50, Loss: 0.6932
Batch 60, Loss: 0.6799
Batch 70, Loss: 0.6537
Batch 80, Loss: 0.6634
Batch 90, Loss: 0.7077
Batch 100, Loss: 0.6640
Batch 110, Loss: 0.7060
Batch 120, Loss: 0.6948
Batch 130, Loss: 0.7632
Batch 140, Loss: 0.6551
Batch 150, Loss: 0.6877
Batch 160, Loss: 0.7325
Batch 170, Loss: 0.6549
Batch 180, Loss: 0.6831
Batch 190, Loss: 0.6938
Batch 200, Loss: 0.7356
Batch 210, Loss: 0.7294
Batch 220, Loss: 0.7171
Batch 230, Loss: 0.7183
Batch 240, Loss: 0.7278
Batch 250, Loss: 0.6805
Batch 260, Loss: 0.6879
Batch 270, Loss: 0.7519
Batch 280, Loss: 0.6566
Batch 290, Loss: 0.7135
Batch 300, Loss: 0.7557
Batch 310, Loss: 0.7289
Batch 320, Loss: 0.7331
Batch 330, Loss: 0.7279
Batch 340, Loss: 0.7502
Batch 350, Loss: 0.6975
Batch 360, Loss: 0.7252
Batch 370, Loss: 0.7324
Batch 380, Loss: 0.7544
Batch 390, Loss: 0.7149
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.136136054992676 seconds
Epoch 141 accuracy: 72.92%
Batch 10, Loss: 0.6397
Batch 20, Loss: 0.6684
Batch 30, Loss: 0.6706
Batch 40, Loss: 0.6796
Batch 50, Loss: 0.6384
Batch 60, Loss: 0.7164
Batch 70, Loss: 0.6628
Batch 80, Loss: 0.6626
Batch 90, Loss: 0.6473
Batch 100, Loss: 0.6675
Batch 110, Loss: 0.6711
Batch 120, Loss: 0.6405
Batch 130, Loss: 0.6286
Batch 140, Loss: 0.6468
Batch 150, Loss: 0.6806
Batch 160, Loss: 0.6776
Batch 170, Loss: 0.7013
Batch 180, Loss: 0.7214
Batch 190, Loss: 0.6758
Batch 200, Loss: 0.7134
Batch 210, Loss: 0.6727
Batch 220, Loss: 0.6732
Batch 230, Loss: 0.6565
Batch 240, Loss: 0.6698
Batch 250, Loss: 0.6591
Batch 260, Loss: 0.6398
Batch 270, Loss: 0.6872
Batch 280, Loss: 0.7198
Batch 290, Loss: 0.7799
Batch 300, Loss: 0.7364
Batch 310, Loss: 0.7211
Batch 320, Loss: 0.7399
Batch 330, Loss: 0.6956
Batch 340, Loss: 0.6671
Batch 350, Loss: 0.7617
Batch 360, Loss: 0.7316
Batch 370, Loss: 0.6930
Batch 380, Loss: 0.7493
Batch 390, Loss: 0.7143
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.29263424873352 seconds
Epoch 142 accuracy: 72.48%
Batch 10, Loss: 0.6541
Batch 20, Loss: 0.7061
Batch 30, Loss: 0.6252
Batch 40, Loss: 0.6111
Batch 50, Loss: 0.6207
Batch 60, Loss: 0.6530
Batch 70, Loss: 0.6863
Batch 80, Loss: 0.6691
Batch 90, Loss: 0.7056
Batch 100, Loss: 0.6934
Batch 110, Loss: 0.6764
Batch 120, Loss: 0.6444
Batch 130, Loss: 0.6426
Batch 140, Loss: 0.6840
Batch 150, Loss: 0.6882
Batch 160, Loss: 0.6965
Batch 170, Loss: 0.7158
Batch 180, Loss: 0.7051
Batch 190, Loss: 0.6840
Batch 200, Loss: 0.6933
Batch 210, Loss: 0.7010
Batch 220, Loss: 0.6777
Batch 230, Loss: 0.7099
Batch 240, Loss: 0.7212
Batch 250, Loss: 0.6815
Batch 260, Loss: 0.6718
Batch 270, Loss: 0.6612
Batch 280, Loss: 0.6569
Batch 290, Loss: 0.6689
Batch 300, Loss: 0.6781
Batch 310, Loss: 0.7121
Batch 320, Loss: 0.6782
Batch 330, Loss: 0.7080
Batch 340, Loss: 0.6996
Batch 350, Loss: 0.6853
Batch 360, Loss: 0.6701
Batch 370, Loss: 0.6839
Batch 380, Loss: 0.7316
Batch 390, Loss: 0.6989
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.1865177154541 seconds
Epoch 143 accuracy: 73.26%
Batch 10, Loss: 0.6667
Batch 20, Loss: 0.5976
Batch 30, Loss: 0.6471
Batch 40, Loss: 0.6346
Batch 50, Loss: 0.6286
Batch 60, Loss: 0.6416
Batch 70, Loss: 0.6306
Batch 80, Loss: 0.6970
Batch 90, Loss: 0.6099
Batch 100, Loss: 0.6626
Batch 110, Loss: 0.6524
Batch 120, Loss: 0.6394
Batch 130, Loss: 0.6340
Batch 140, Loss: 0.6337
Batch 150, Loss: 0.6362
Batch 160, Loss: 0.6072
Batch 170, Loss: 0.6647
Batch 180, Loss: 0.6593
Batch 190, Loss: 0.6958
Batch 200, Loss: 0.6721
Batch 210, Loss: 0.6200
Batch 220, Loss: 0.6005
Batch 230, Loss: 0.6966
Batch 240, Loss: 0.6983
Batch 250, Loss: 0.6994
Batch 260, Loss: 0.7107
Batch 270, Loss: 0.7019
Batch 280, Loss: 0.7082
Batch 290, Loss: 0.6698
Batch 300, Loss: 0.6924
Batch 310, Loss: 0.6519
Batch 320, Loss: 0.6921
Batch 330, Loss: 0.7182
Batch 340, Loss: 0.6889
Batch 350, Loss: 0.6870
Batch 360, Loss: 0.6513
Batch 370, Loss: 0.6675
Batch 380, Loss: 0.6993
Batch 390, Loss: 0.6552
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.220134496688843 seconds
Epoch 144 accuracy: 73.49%
Batch 10, Loss: 0.6365
Batch 20, Loss: 0.6010
Batch 30, Loss: 0.6101
Batch 40, Loss: 0.6277
Batch 50, Loss: 0.6374
Batch 60, Loss: 0.6409
Batch 70, Loss: 0.6052
Batch 80, Loss: 0.6678
Batch 90, Loss: 0.6291
Batch 100, Loss: 0.6060
Batch 110, Loss: 0.6424
Batch 120, Loss: 0.6388
Batch 130, Loss: 0.6529
Batch 140, Loss: 0.6805
Batch 150, Loss: 0.6618
Batch 160, Loss: 0.6909
Batch 170, Loss: 0.6997
Batch 180, Loss: 0.6479
Batch 190, Loss: 0.6455
Batch 200, Loss: 0.6705
Batch 210, Loss: 0.6767
Batch 220, Loss: 0.6465
Batch 230, Loss: 0.7300
Batch 240, Loss: 0.6326
Batch 250, Loss: 0.6733
Batch 260, Loss: 0.6514
Batch 270, Loss: 0.6773
Batch 280, Loss: 0.6506
Batch 290, Loss: 0.6678
Batch 300, Loss: 0.7158
Batch 310, Loss: 0.6815
Batch 320, Loss: 0.6841
Batch 330, Loss: 0.6954
Batch 340, Loss: 0.6436
Batch 350, Loss: 0.6951
Batch 360, Loss: 0.7157
Batch 370, Loss: 0.6448
Batch 380, Loss: 0.6352
Batch 390, Loss: 0.6075
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.27631902694702 seconds
Epoch 145 accuracy: 73.84%
Batch 10, Loss: 0.5736
Batch 20, Loss: 0.6055
Batch 30, Loss: 0.6110
Batch 40, Loss: 0.6273
Batch 50, Loss: 0.5871
Batch 60, Loss: 0.6125
Batch 70, Loss: 0.6519
Batch 80, Loss: 0.5887
Batch 90, Loss: 0.6604
Batch 100, Loss: 0.6067
Batch 110, Loss: 0.6579
Batch 120, Loss: 0.6186
Batch 130, Loss: 0.6177
Batch 140, Loss: 0.6043
Batch 150, Loss: 0.6244
Batch 160, Loss: 0.6375
Batch 170, Loss: 0.6400
Batch 180, Loss: 0.6185
Batch 190, Loss: 0.6516
Batch 200, Loss: 0.6217
Batch 210, Loss: 0.6654
Batch 220, Loss: 0.6620
Batch 230, Loss: 0.6521
Batch 240, Loss: 0.6063
Batch 250, Loss: 0.6736
Batch 260, Loss: 0.6938
Batch 270, Loss: 0.6472
Batch 280, Loss: 0.6768
Batch 290, Loss: 0.6396
Batch 300, Loss: 0.6517
Batch 310, Loss: 0.6522
Batch 320, Loss: 0.6454
Batch 330, Loss: 0.6426
Batch 340, Loss: 0.6702
Batch 350, Loss: 0.6455
Batch 360, Loss: 0.7183
Batch 370, Loss: 0.6912
Batch 380, Loss: 0.6449
Batch 390, Loss: 0.6842
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.170913457870483 seconds
Epoch 146 accuracy: 73.1%
Batch 10, Loss: 0.5996
Batch 20, Loss: 0.6430
Batch 30, Loss: 0.6021
Batch 40, Loss: 0.5841
Batch 50, Loss: 0.6156
Batch 60, Loss: 0.6356
Batch 70, Loss: 0.6787
Batch 80, Loss: 0.5878
Batch 90, Loss: 0.6323
Batch 100, Loss: 0.6442
Batch 110, Loss: 0.6567
Batch 120, Loss: 0.6617
Batch 130, Loss: 0.6124
Batch 140, Loss: 0.6363
Batch 150, Loss: 0.6566
Batch 160, Loss: 0.6412
Batch 170, Loss: 0.6228
Batch 180, Loss: 0.5994
Batch 190, Loss: 0.6628
Batch 200, Loss: 0.6665
Batch 210, Loss: 0.6342
Batch 220, Loss: 0.6168
Batch 230, Loss: 0.6642
Batch 240, Loss: 0.6282
Batch 250, Loss: 0.6627
Batch 260, Loss: 0.6331
Batch 270, Loss: 0.6146
Batch 280, Loss: 0.6343
Batch 290, Loss: 0.5963
Batch 300, Loss: 0.6432
Batch 310, Loss: 0.6338
Batch 320, Loss: 0.6610
Batch 330, Loss: 0.6326
Batch 340, Loss: 0.6761
Batch 350, Loss: 0.6332
Batch 360, Loss: 0.6568
Batch 370, Loss: 0.6530
Batch 380, Loss: 0.7001
Batch 390, Loss: 0.6232
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.27190589904785 seconds
Epoch 147 accuracy: 74.0%
Batch 10, Loss: 0.5926
Batch 20, Loss: 0.5838
Batch 30, Loss: 0.5784
Batch 40, Loss: 0.5510
Batch 50, Loss: 0.5610
Batch 60, Loss: 0.5648
Batch 70, Loss: 0.5814
Batch 80, Loss: 0.6320
Batch 90, Loss: 0.6130
Batch 100, Loss: 0.5758
Batch 110, Loss: 0.6110
Batch 120, Loss: 0.5947
Batch 130, Loss: 0.6052
Batch 140, Loss: 0.6100
Batch 150, Loss: 0.6016
Batch 160, Loss: 0.6088
Batch 170, Loss: 0.6583
Batch 180, Loss: 0.6113
Batch 190, Loss: 0.5696
Batch 200, Loss: 0.6014
Batch 210, Loss: 0.6116
Batch 220, Loss: 0.6268
Batch 230, Loss: 0.6587
Batch 240, Loss: 0.5921
Batch 250, Loss: 0.6392
Batch 260, Loss: 0.5947
Batch 270, Loss: 0.6222
Batch 280, Loss: 0.6201
Batch 290, Loss: 0.6422
Batch 300, Loss: 0.6314
Batch 310, Loss: 0.6529
Batch 320, Loss: 0.6525
Batch 330, Loss: 0.6518
Batch 340, Loss: 0.6340
Batch 350, Loss: 0.6514
Batch 360, Loss: 0.6004
Batch 370, Loss: 0.6419
Batch 380, Loss: 0.6561
Batch 390, Loss: 0.6362
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.24119520187378 seconds
Epoch 148 accuracy: 72.54%
Batch 10, Loss: 0.5824
Batch 20, Loss: 0.5716
Batch 30, Loss: 0.5804
Batch 40, Loss: 0.5751
Batch 50, Loss: 0.6023
Batch 60, Loss: 0.6064
Batch 70, Loss: 0.6354
Batch 80, Loss: 0.5750
Batch 90, Loss: 0.6282
Batch 100, Loss: 0.5883
Batch 110, Loss: 0.6161
Batch 120, Loss: 0.6242
Batch 130, Loss: 0.6058
Batch 140, Loss: 0.5644
Batch 150, Loss: 0.6293
Batch 160, Loss: 0.6029
Batch 170, Loss: 0.6120
Batch 180, Loss: 0.5937
Batch 190, Loss: 0.6304
Batch 200, Loss: 0.6315
Batch 210, Loss: 0.6006
Batch 220, Loss: 0.5942
Batch 230, Loss: 0.6106
Batch 240, Loss: 0.5959
Batch 250, Loss: 0.6302
Batch 260, Loss: 0.6031
Batch 270, Loss: 0.5842
Batch 280, Loss: 0.6160
Batch 290, Loss: 0.6122
Batch 300, Loss: 0.5722
Batch 310, Loss: 0.6678
Batch 320, Loss: 0.6272
Batch 330, Loss: 0.6737
Batch 340, Loss: 0.6397
Batch 350, Loss: 0.6090
Batch 360, Loss: 0.6038
Batch 370, Loss: 0.6465
Batch 380, Loss: 0.5722
Batch 390, Loss: 0.6331
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.204593420028687 seconds
Epoch 149 accuracy: 74.39%
Batch 10, Loss: 0.5224
Batch 20, Loss: 0.5763
Batch 30, Loss: 0.5741
Batch 40, Loss: 0.5442
Batch 50, Loss: 0.5322
Batch 60, Loss: 0.5689
Batch 70, Loss: 0.6016
Batch 80, Loss: 0.5758
Batch 90, Loss: 0.5690
Batch 100, Loss: 0.5711
Batch 110, Loss: 0.5771
Batch 120, Loss: 0.5846
Batch 130, Loss: 0.5641
Batch 140, Loss: 0.5674
Batch 150, Loss: 0.5743
Batch 160, Loss: 0.6038
Batch 170, Loss: 0.5604
Batch 180, Loss: 0.6093
Batch 190, Loss: 0.5863
Batch 200, Loss: 0.6254
Batch 210, Loss: 0.5789
Batch 220, Loss: 0.6320
Batch 230, Loss: 0.5923
Batch 240, Loss: 0.5836
Batch 250, Loss: 0.6244
Batch 260, Loss: 0.6074
Batch 270, Loss: 0.6318
Batch 280, Loss: 0.6053
Batch 290, Loss: 0.5765
Batch 300, Loss: 0.6174
Batch 310, Loss: 0.6182
Batch 320, Loss: 0.6417
Batch 330, Loss: 0.5984
Batch 340, Loss: 0.5691
Batch 350, Loss: 0.6252
Batch 360, Loss: 0.5968
Batch 370, Loss: 0.6379
Batch 380, Loss: 0.6547
Batch 390, Loss: 0.6099
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.09083843231201 seconds
Epoch 150 accuracy: 74.37%
Batch 10, Loss: 0.5864
Batch 20, Loss: 0.5257
Batch 30, Loss: 0.5362
Batch 40, Loss: 0.5653
Batch 50, Loss: 0.5794
Batch 60, Loss: 0.5528
Batch 70, Loss: 0.5667
Batch 80, Loss: 0.5670
Batch 90, Loss: 0.5535
Batch 100, Loss: 0.5842
Batch 110, Loss: 0.5591
Batch 120, Loss: 0.6336
Batch 130, Loss: 0.5788
Batch 140, Loss: 0.5716
Batch 150, Loss: 0.5381
Batch 160, Loss: 0.5702
Batch 170, Loss: 0.6043
Batch 180, Loss: 0.5284
Batch 190, Loss: 0.5775
Batch 200, Loss: 0.5982
Batch 210, Loss: 0.5535
Batch 220, Loss: 0.5633
Batch 230, Loss: 0.5548
Batch 240, Loss: 0.6060
Batch 250, Loss: 0.6336
Batch 260, Loss: 0.6011
Batch 270, Loss: 0.5703
Batch 280, Loss: 0.6015
Batch 290, Loss: 0.6009
Batch 300, Loss: 0.5807
Batch 310, Loss: 0.5765
Batch 320, Loss: 0.5953
Batch 330, Loss: 0.5871
Batch 340, Loss: 0.5996
Batch 350, Loss: 0.6100
Batch 360, Loss: 0.5844
Batch 370, Loss: 0.6068
Batch 380, Loss: 0.6308
Batch 390, Loss: 0.6164
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.16498851776123 seconds
Epoch 151 accuracy: 73.98%
Batch 10, Loss: 0.5352
Batch 20, Loss: 0.5875
Batch 30, Loss: 0.5284
Batch 40, Loss: 0.5466
Batch 50, Loss: 0.5662
Batch 60, Loss: 0.5802
Batch 70, Loss: 0.5618
Batch 80, Loss: 0.5743
Batch 90, Loss: 0.5339
Batch 100, Loss: 0.5997
Batch 110, Loss: 0.5699
Batch 120, Loss: 0.5566
Batch 130, Loss: 0.5783
Batch 140, Loss: 0.5887
Batch 150, Loss: 0.5360
Batch 160, Loss: 0.5762
Batch 170, Loss: 0.5786
Batch 180, Loss: 0.5751
Batch 190, Loss: 0.5717
Batch 200, Loss: 0.6116
Batch 210, Loss: 0.5043
Batch 220, Loss: 0.5249
Batch 230, Loss: 0.5557
Batch 240, Loss: 0.5858
Batch 250, Loss: 0.5659
Batch 260, Loss: 0.6213
Batch 270, Loss: 0.5472
Batch 280, Loss: 0.5601
Batch 290, Loss: 0.5644
Batch 300, Loss: 0.5608
Batch 310, Loss: 0.5975
Batch 320, Loss: 0.5324
Batch 330, Loss: 0.5359
Batch 340, Loss: 0.6048
Batch 350, Loss: 0.6134
Batch 360, Loss: 0.6181
Batch 370, Loss: 0.5692
Batch 380, Loss: 0.5731
Batch 390, Loss: 0.5907
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.181888103485107 seconds
Epoch 152 accuracy: 74.56%
Batch 10, Loss: 0.5364
Batch 20, Loss: 0.5791
Batch 30, Loss: 0.5512
Batch 40, Loss: 0.5922
Batch 50, Loss: 0.5584
Batch 60, Loss: 0.5698
Batch 70, Loss: 0.5847
Batch 80, Loss: 0.5434
Batch 90, Loss: 0.4710
Batch 100, Loss: 0.5667
Batch 110, Loss: 0.5232
Batch 120, Loss: 0.5312
Batch 130, Loss: 0.5458
Batch 140, Loss: 0.5397
Batch 150, Loss: 0.5450
Batch 160, Loss: 0.5007
Batch 170, Loss: 0.5530
Batch 180, Loss: 0.5332
Batch 190, Loss: 0.5044
Batch 200, Loss: 0.5350
Batch 210, Loss: 0.5668
Batch 220, Loss: 0.5800
Batch 230, Loss: 0.6033
Batch 240, Loss: 0.5184
Batch 250, Loss: 0.5789
Batch 260, Loss: 0.5707
Batch 270, Loss: 0.5774
Batch 280, Loss: 0.5438
Batch 290, Loss: 0.5686
Batch 300, Loss: 0.5644
Batch 310, Loss: 0.5334
Batch 320, Loss: 0.5544
Batch 330, Loss: 0.5610
Batch 340, Loss: 0.5448
Batch 350, Loss: 0.5879
Batch 360, Loss: 0.5730
Batch 370, Loss: 0.5663
Batch 380, Loss: 0.6049
Batch 390, Loss: 0.5614
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.256103038787842 seconds
Epoch 153 accuracy: 74.34%
Batch 10, Loss: 0.5679
Batch 20, Loss: 0.5481
Batch 30, Loss: 0.5473
Batch 40, Loss: 0.4826
Batch 50, Loss: 0.5064
Batch 60, Loss: 0.5232
Batch 70, Loss: 0.5576
Batch 80, Loss: 0.5204
Batch 90, Loss: 0.5410
Batch 100, Loss: 0.5459
Batch 110, Loss: 0.5353
Batch 120, Loss: 0.4980
Batch 130, Loss: 0.5615
Batch 140, Loss: 0.5735
Batch 150, Loss: 0.5478
Batch 160, Loss: 0.5249
Batch 170, Loss: 0.5315
Batch 180, Loss: 0.5712
Batch 190, Loss: 0.5296
Batch 200, Loss: 0.5548
Batch 210, Loss: 0.5228
Batch 220, Loss: 0.5105
Batch 230, Loss: 0.5629
Batch 240, Loss: 0.5512
Batch 250, Loss: 0.5893
Batch 260, Loss: 0.5483
Batch 270, Loss: 0.5788
Batch 280, Loss: 0.5538
Batch 290, Loss: 0.5285
Batch 300, Loss: 0.5491
Batch 310, Loss: 0.5724
Batch 320, Loss: 0.5478
Batch 330, Loss: 0.5378
Batch 340, Loss: 0.5136
Batch 350, Loss: 0.5466
Batch 360, Loss: 0.5363
Batch 370, Loss: 0.5663
Batch 380, Loss: 0.5608
Batch 390, Loss: 0.5245
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.314693450927734 seconds
Epoch 154 accuracy: 75.22%
Batch 10, Loss: 0.4860
Batch 20, Loss: 0.4979
Batch 30, Loss: 0.5187
Batch 40, Loss: 0.5158
Batch 50, Loss: 0.5185
Batch 60, Loss: 0.5209
Batch 70, Loss: 0.5584
Batch 80, Loss: 0.4917
Batch 90, Loss: 0.5293
Batch 100, Loss: 0.4912
Batch 110, Loss: 0.5482
Batch 120, Loss: 0.5405
Batch 130, Loss: 0.5359
Batch 140, Loss: 0.5176
Batch 150, Loss: 0.5433
Batch 160, Loss: 0.5672
Batch 170, Loss: 0.5769
Batch 180, Loss: 0.5541
Batch 190, Loss: 0.5054
Batch 200, Loss: 0.5551
Batch 210, Loss: 0.5180
Batch 220, Loss: 0.5396
Batch 230, Loss: 0.5487
Batch 240, Loss: 0.5323
Batch 250, Loss: 0.5262
Batch 260, Loss: 0.5372
Batch 270, Loss: 0.5771
Batch 280, Loss: 0.5731
Batch 290, Loss: 0.5504
Batch 300, Loss: 0.5542
Batch 310, Loss: 0.5642
Batch 320, Loss: 0.6082
Batch 330, Loss: 0.5639
Batch 340, Loss: 0.5536
Batch 350, Loss: 0.5214
Batch 360, Loss: 0.5113
Batch 370, Loss: 0.5371
Batch 380, Loss: 0.5225
Batch 390, Loss: 0.5464
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.071998596191406 seconds
Epoch 155 accuracy: 74.99%
Batch 10, Loss: 0.5096
Batch 20, Loss: 0.4342
Batch 30, Loss: 0.4714
Batch 40, Loss: 0.4972
Batch 50, Loss: 0.4404
Batch 60, Loss: 0.5183
Batch 70, Loss: 0.5047
Batch 80, Loss: 0.4934
Batch 90, Loss: 0.5103
Batch 100, Loss: 0.5334
Batch 110, Loss: 0.5525
Batch 120, Loss: 0.4702
Batch 130, Loss: 0.4989
Batch 140, Loss: 0.4926
Batch 150, Loss: 0.5507
Batch 160, Loss: 0.5426
Batch 170, Loss: 0.5077
Batch 180, Loss: 0.5109
Batch 190, Loss: 0.4985
Batch 200, Loss: 0.5353
Batch 210, Loss: 0.5341
Batch 220, Loss: 0.5143
Batch 230, Loss: 0.5194
Batch 240, Loss: 0.5220
Batch 250, Loss: 0.4939
Batch 260, Loss: 0.4696
Batch 270, Loss: 0.5057
Batch 280, Loss: 0.5115
Batch 290, Loss: 0.5273
Batch 300, Loss: 0.5238
Batch 310, Loss: 0.4882
Batch 320, Loss: 0.5674
Batch 330, Loss: 0.5387
Batch 340, Loss: 0.5436
Batch 350, Loss: 0.5580
Batch 360, Loss: 0.5267
Batch 370, Loss: 0.5274
Batch 380, Loss: 0.5646
Batch 390, Loss: 0.4994
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.24211835861206 seconds
Epoch 156 accuracy: 74.53%
Batch 10, Loss: 0.4985
Batch 20, Loss: 0.5269
Batch 30, Loss: 0.4905
Batch 40, Loss: 0.4902
Batch 50, Loss: 0.4999
Batch 60, Loss: 0.4762
Batch 70, Loss: 0.4782
Batch 80, Loss: 0.5029
Batch 90, Loss: 0.4897
Batch 100, Loss: 0.4860
Batch 110, Loss: 0.4366
Batch 120, Loss: 0.5093
Batch 130, Loss: 0.5042
Batch 140, Loss: 0.4927
Batch 150, Loss: 0.5148
Batch 160, Loss: 0.5154
Batch 170, Loss: 0.5493
Batch 180, Loss: 0.5077
Batch 190, Loss: 0.4706
Batch 200, Loss: 0.5190
Batch 210, Loss: 0.4938
Batch 220, Loss: 0.4968
Batch 230, Loss: 0.4928
Batch 240, Loss: 0.5096
Batch 250, Loss: 0.5057
Batch 260, Loss: 0.5247
Batch 270, Loss: 0.5267
Batch 280, Loss: 0.4973
Batch 290, Loss: 0.5327
Batch 300, Loss: 0.5321
Batch 310, Loss: 0.5271
Batch 320, Loss: 0.5194
Batch 330, Loss: 0.5539
Batch 340, Loss: 0.5295
Batch 350, Loss: 0.5360
Batch 360, Loss: 0.5257
Batch 370, Loss: 0.4549
Batch 380, Loss: 0.5707
Batch 390, Loss: 0.5740
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.18487858772278 seconds
Epoch 157 accuracy: 76.05%
Batch 10, Loss: 0.4778
Batch 20, Loss: 0.5278
Batch 30, Loss: 0.5142
Batch 40, Loss: 0.4746
Batch 50, Loss: 0.4964
Batch 60, Loss: 0.4840
Batch 70, Loss: 0.4553
Batch 80, Loss: 0.4480
Batch 90, Loss: 0.4725
Batch 100, Loss: 0.5103
Batch 110, Loss: 0.5177
Batch 120, Loss: 0.5056
Batch 130, Loss: 0.5391
Batch 140, Loss: 0.4834
Batch 150, Loss: 0.4252
Batch 160, Loss: 0.4731
Batch 170, Loss: 0.4569
Batch 180, Loss: 0.5059
Batch 190, Loss: 0.4454
Batch 200, Loss: 0.5123
Batch 210, Loss: 0.4720
Batch 220, Loss: 0.5532
Batch 230, Loss: 0.5126
Batch 240, Loss: 0.5046
Batch 250, Loss: 0.5370
Batch 260, Loss: 0.4785
Batch 270, Loss: 0.4792
Batch 280, Loss: 0.4802
Batch 290, Loss: 0.4922
Batch 300, Loss: 0.5313
Batch 310, Loss: 0.5048
Batch 320, Loss: 0.5329
Batch 330, Loss: 0.5432
Batch 340, Loss: 0.4927
Batch 350, Loss: 0.4793
Batch 360, Loss: 0.5152
Batch 370, Loss: 0.5379
Batch 380, Loss: 0.4855
Batch 390, Loss: 0.5582
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.256683588027954 seconds
Epoch 158 accuracy: 74.92%
Batch 10, Loss: 0.4852
Batch 20, Loss: 0.5089
Batch 30, Loss: 0.4432
Batch 40, Loss: 0.4716
Batch 50, Loss: 0.4788
Batch 60, Loss: 0.4513
Batch 70, Loss: 0.4691
Batch 80, Loss: 0.4764
Batch 90, Loss: 0.4822
Batch 100, Loss: 0.4905
Batch 110, Loss: 0.4127
Batch 120, Loss: 0.4837
Batch 130, Loss: 0.4533
Batch 140, Loss: 0.4936
Batch 150, Loss: 0.4479
Batch 160, Loss: 0.4476
Batch 170, Loss: 0.4836
Batch 180, Loss: 0.4571
Batch 190, Loss: 0.4767
Batch 200, Loss: 0.5092
Batch 210, Loss: 0.4582
Batch 220, Loss: 0.4966
Batch 230, Loss: 0.4778
Batch 240, Loss: 0.4803
Batch 250, Loss: 0.4876
Batch 260, Loss: 0.5102
Batch 270, Loss: 0.5479
Batch 280, Loss: 0.4752
Batch 290, Loss: 0.4774
Batch 300, Loss: 0.4823
Batch 310, Loss: 0.4831
Batch 320, Loss: 0.5296
Batch 330, Loss: 0.5441
Batch 340, Loss: 0.5247
Batch 350, Loss: 0.4737
Batch 360, Loss: 0.4767
Batch 370, Loss: 0.4661
Batch 380, Loss: 0.5214
Batch 390, Loss: 0.4799
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.12403917312622 seconds
Epoch 159 accuracy: 76.04%
Batch 10, Loss: 0.4649
Batch 20, Loss: 0.4816
Batch 30, Loss: 0.4825
Batch 40, Loss: 0.4942
Batch 50, Loss: 0.4771
Batch 60, Loss: 0.4632
Batch 70, Loss: 0.4932
Batch 80, Loss: 0.4792
Batch 90, Loss: 0.4339
Batch 100, Loss: 0.4113
Batch 110, Loss: 0.4926
Batch 120, Loss: 0.4379
Batch 130, Loss: 0.4574
Batch 140, Loss: 0.4859
Batch 150, Loss: 0.5449
Batch 160, Loss: 0.4766
Batch 170, Loss: 0.4820
Batch 180, Loss: 0.4916
Batch 190, Loss: 0.4382
Batch 200, Loss: 0.4867
Batch 210, Loss: 0.4627
Batch 220, Loss: 0.4942
Batch 230, Loss: 0.4423
Batch 240, Loss: 0.4855
Batch 250, Loss: 0.4729
Batch 260, Loss: 0.5004
Batch 270, Loss: 0.4549
Batch 280, Loss: 0.5548
Batch 290, Loss: 0.4734
Batch 300, Loss: 0.4950
Batch 310, Loss: 0.4609
Batch 320, Loss: 0.5291
Batch 330, Loss: 0.4541
Batch 340, Loss: 0.4860
Batch 350, Loss: 0.5259
Batch 360, Loss: 0.4524
Batch 370, Loss: 0.4456
Batch 380, Loss: 0.4818
Batch 390, Loss: 0.4783
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.081749439239502 seconds
Epoch 160 accuracy: 75.43%
Batch 10, Loss: 0.4344
Batch 20, Loss: 0.5031
Batch 30, Loss: 0.4596
Batch 40, Loss: 0.4375
Batch 50, Loss: 0.4475
Batch 60, Loss: 0.4564
Batch 70, Loss: 0.4182
Batch 80, Loss: 0.4230
Batch 90, Loss: 0.4753
Batch 100, Loss: 0.4497
Batch 110, Loss: 0.4522
Batch 120, Loss: 0.4733
Batch 130, Loss: 0.4758
Batch 140, Loss: 0.4721
Batch 150, Loss: 0.4777
Batch 160, Loss: 0.4563
Batch 170, Loss: 0.4753
Batch 180, Loss: 0.4331
Batch 190, Loss: 0.4738
Batch 200, Loss: 0.4468
Batch 210, Loss: 0.4826
Batch 220, Loss: 0.4577
Batch 230, Loss: 0.5147
Batch 240, Loss: 0.4798
Batch 250, Loss: 0.4668
Batch 260, Loss: 0.4642
Batch 270, Loss: 0.4464
Batch 280, Loss: 0.4710
Batch 290, Loss: 0.4564
Batch 300, Loss: 0.4551
Batch 310, Loss: 0.4744
Batch 320, Loss: 0.4685
Batch 330, Loss: 0.4576
Batch 340, Loss: 0.4580
Batch 350, Loss: 0.4797
Batch 360, Loss: 0.4919
Batch 370, Loss: 0.4946
Batch 380, Loss: 0.4604
Batch 390, Loss: 0.4460
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.16309905052185 seconds
Epoch 161 accuracy: 76.4%
Batch 10, Loss: 0.4509
Batch 20, Loss: 0.4354
Batch 30, Loss: 0.4073
Batch 40, Loss: 0.4185
Batch 50, Loss: 0.4295
Batch 60, Loss: 0.4280
Batch 70, Loss: 0.4380
Batch 80, Loss: 0.4254
Batch 90, Loss: 0.4576
Batch 100, Loss: 0.4171
Batch 110, Loss: 0.4703
Batch 120, Loss: 0.4590
Batch 130, Loss: 0.4386
Batch 140, Loss: 0.4609
Batch 150, Loss: 0.4127
Batch 160, Loss: 0.4158
Batch 170, Loss: 0.4223
Batch 180, Loss: 0.4717
Batch 190, Loss: 0.4106
Batch 200, Loss: 0.4860
Batch 210, Loss: 0.4430
Batch 220, Loss: 0.4395
Batch 230, Loss: 0.4568
Batch 240, Loss: 0.4351
Batch 250, Loss: 0.4143
Batch 260, Loss: 0.4595
Batch 270, Loss: 0.4348
Batch 280, Loss: 0.4539
Batch 290, Loss: 0.4258
Batch 300, Loss: 0.4823
Batch 310, Loss: 0.4951
Batch 320, Loss: 0.4541
Batch 330, Loss: 0.4879
Batch 340, Loss: 0.4491
Batch 350, Loss: 0.4521
Batch 360, Loss: 0.4881
Batch 370, Loss: 0.4338
Batch 380, Loss: 0.4593
Batch 390, Loss: 0.4848
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.12033438682556 seconds
Epoch 162 accuracy: 76.09%
Batch 10, Loss: 0.4573
Batch 20, Loss: 0.4435
Batch 30, Loss: 0.4569
Batch 40, Loss: 0.4519
Batch 50, Loss: 0.4515
Batch 60, Loss: 0.4521
Batch 70, Loss: 0.4142
Batch 80, Loss: 0.4870
Batch 90, Loss: 0.4624
Batch 100, Loss: 0.4546
Batch 110, Loss: 0.4763
Batch 120, Loss: 0.3830
Batch 130, Loss: 0.4277
Batch 140, Loss: 0.4440
Batch 150, Loss: 0.4566
Batch 160, Loss: 0.4447
Batch 170, Loss: 0.4453
Batch 180, Loss: 0.4222
Batch 190, Loss: 0.4325
Batch 200, Loss: 0.4246
Batch 210, Loss: 0.4585
Batch 220, Loss: 0.4387
Batch 230, Loss: 0.4161
Batch 240, Loss: 0.4590
Batch 250, Loss: 0.4414
Batch 260, Loss: 0.4256
Batch 270, Loss: 0.4359
Batch 280, Loss: 0.4593
Batch 290, Loss: 0.4435
Batch 300, Loss: 0.4233
Batch 310, Loss: 0.4171
Batch 320, Loss: 0.4680
Batch 330, Loss: 0.4073
Batch 340, Loss: 0.4611
Batch 350, Loss: 0.4414
Batch 360, Loss: 0.4695
Batch 370, Loss: 0.4495
Batch 380, Loss: 0.4671
Batch 390, Loss: 0.4937
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.22841477394104 seconds
Epoch 163 accuracy: 76.86%
Batch 10, Loss: 0.4253
Batch 20, Loss: 0.4410
Batch 30, Loss: 0.4145
Batch 40, Loss: 0.4656
Batch 50, Loss: 0.4217
Batch 60, Loss: 0.4378
Batch 70, Loss: 0.4025
Batch 80, Loss: 0.4367
Batch 90, Loss: 0.4171
Batch 100, Loss: 0.3737
Batch 110, Loss: 0.3575
Batch 120, Loss: 0.3889
Batch 130, Loss: 0.3992
Batch 140, Loss: 0.4291
Batch 150, Loss: 0.4623
Batch 160, Loss: 0.4373
Batch 170, Loss: 0.4854
Batch 180, Loss: 0.3827
Batch 190, Loss: 0.4023
Batch 200, Loss: 0.4127
Batch 210, Loss: 0.4215
Batch 220, Loss: 0.3975
Batch 230, Loss: 0.4197
Batch 240, Loss: 0.3864
Batch 250, Loss: 0.4461
Batch 260, Loss: 0.4102
Batch 270, Loss: 0.4343
Batch 280, Loss: 0.4589
Batch 290, Loss: 0.4350
Batch 300, Loss: 0.4134
Batch 310, Loss: 0.4454
Batch 320, Loss: 0.4460
Batch 330, Loss: 0.4549
Batch 340, Loss: 0.4815
Batch 350, Loss: 0.4930
Batch 360, Loss: 0.4251
Batch 370, Loss: 0.4737
Batch 380, Loss: 0.4169
Batch 390, Loss: 0.4338
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.18375587463379 seconds
Epoch 164 accuracy: 76.84%
Batch 10, Loss: 0.4086
Batch 20, Loss: 0.4337
Batch 30, Loss: 0.3990
Batch 40, Loss: 0.4200
Batch 50, Loss: 0.4228
Batch 60, Loss: 0.3622
Batch 70, Loss: 0.4088
Batch 80, Loss: 0.4327
Batch 90, Loss: 0.4161
Batch 100, Loss: 0.4076
Batch 110, Loss: 0.4454
Batch 120, Loss: 0.4000
Batch 130, Loss: 0.4015
Batch 140, Loss: 0.4289
Batch 150, Loss: 0.4132
Batch 160, Loss: 0.4148
Batch 170, Loss: 0.4349
Batch 180, Loss: 0.4555
Batch 190, Loss: 0.3833
Batch 200, Loss: 0.4516
Batch 210, Loss: 0.4190
Batch 220, Loss: 0.3923
Batch 230, Loss: 0.3918
Batch 240, Loss: 0.4371
Batch 250, Loss: 0.3858
Batch 260, Loss: 0.4147
Batch 270, Loss: 0.4071
Batch 280, Loss: 0.4393
Batch 290, Loss: 0.4415
Batch 300, Loss: 0.4039
Batch 310, Loss: 0.4329
Batch 320, Loss: 0.4522
Batch 330, Loss: 0.4412
Batch 340, Loss: 0.4845
Batch 350, Loss: 0.4293
Batch 360, Loss: 0.4145
Batch 370, Loss: 0.4053
Batch 380, Loss: 0.3868
Batch 390, Loss: 0.4357
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.116570234298706 seconds
Epoch 165 accuracy: 77.45%
Batch 10, Loss: 0.3978
Batch 20, Loss: 0.4305
Batch 30, Loss: 0.3835
Batch 40, Loss: 0.4120
Batch 50, Loss: 0.4217
Batch 60, Loss: 0.3904
Batch 70, Loss: 0.3992
Batch 80, Loss: 0.3873
Batch 90, Loss: 0.4293
Batch 100, Loss: 0.3982
Batch 110, Loss: 0.4355
Batch 120, Loss: 0.3731
Batch 130, Loss: 0.4101
Batch 140, Loss: 0.4105
Batch 150, Loss: 0.4012
Batch 160, Loss: 0.3823
Batch 170, Loss: 0.4276
Batch 180, Loss: 0.3972
Batch 190, Loss: 0.4349
Batch 200, Loss: 0.4032
Batch 210, Loss: 0.4021
Batch 220, Loss: 0.4160
Batch 230, Loss: 0.4168
Batch 240, Loss: 0.4075
Batch 250, Loss: 0.3987
Batch 260, Loss: 0.4239
Batch 270, Loss: 0.4066
Batch 280, Loss: 0.3865
Batch 290, Loss: 0.4079
Batch 300, Loss: 0.3804
Batch 310, Loss: 0.4241
Batch 320, Loss: 0.4229
Batch 330, Loss: 0.4222
Batch 340, Loss: 0.4083
Batch 350, Loss: 0.4496
Batch 360, Loss: 0.4320
Batch 370, Loss: 0.4002
Batch 380, Loss: 0.4403
Batch 390, Loss: 0.4186
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.218408584594727 seconds
Epoch 166 accuracy: 77.26%
Batch 10, Loss: 0.3815
Batch 20, Loss: 0.4274
Batch 30, Loss: 0.3588
Batch 40, Loss: 0.4222
Batch 50, Loss: 0.4486
Batch 60, Loss: 0.4069
Batch 70, Loss: 0.4185
Batch 80, Loss: 0.3912
Batch 90, Loss: 0.4287
Batch 100, Loss: 0.3935
Batch 110, Loss: 0.3829
Batch 120, Loss: 0.4036
Batch 130, Loss: 0.4260
Batch 140, Loss: 0.3833
Batch 150, Loss: 0.3663
Batch 160, Loss: 0.4563
Batch 170, Loss: 0.3977
Batch 180, Loss: 0.3895
Batch 190, Loss: 0.4018
Batch 200, Loss: 0.3883
Batch 210, Loss: 0.3972
Batch 220, Loss: 0.3899
Batch 230, Loss: 0.3633
Batch 240, Loss: 0.3903
Batch 250, Loss: 0.3911
Batch 260, Loss: 0.4055
Batch 270, Loss: 0.4155
Batch 280, Loss: 0.4126
Batch 290, Loss: 0.3690
Batch 300, Loss: 0.3961
Batch 310, Loss: 0.4392
Batch 320, Loss: 0.3818
Batch 330, Loss: 0.3804
Batch 340, Loss: 0.4234
Batch 350, Loss: 0.4404
Batch 360, Loss: 0.3921
Batch 370, Loss: 0.4592
Batch 380, Loss: 0.3713
Batch 390, Loss: 0.4425
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.12779474258423 seconds
Epoch 167 accuracy: 77.26%
Batch 10, Loss: 0.3781
Batch 20, Loss: 0.4062
Batch 30, Loss: 0.4225
Batch 40, Loss: 0.3889
Batch 50, Loss: 0.3732
Batch 60, Loss: 0.3760
Batch 70, Loss: 0.3715
Batch 80, Loss: 0.3903
Batch 90, Loss: 0.3790
Batch 100, Loss: 0.3676
Batch 110, Loss: 0.3984
Batch 120, Loss: 0.3764
Batch 130, Loss: 0.3996
Batch 140, Loss: 0.3629
Batch 150, Loss: 0.3575
Batch 160, Loss: 0.3869
Batch 170, Loss: 0.3911
Batch 180, Loss: 0.3914
Batch 190, Loss: 0.3912
Batch 200, Loss: 0.3862
Batch 210, Loss: 0.3667
Batch 220, Loss: 0.4193
Batch 230, Loss: 0.3724
Batch 240, Loss: 0.3702
Batch 250, Loss: 0.3823
Batch 260, Loss: 0.4245
Batch 270, Loss: 0.4199
Batch 280, Loss: 0.4323
Batch 290, Loss: 0.3857
Batch 300, Loss: 0.4114
Batch 310, Loss: 0.4004
Batch 320, Loss: 0.3603
Batch 330, Loss: 0.3692
Batch 340, Loss: 0.3636
Batch 350, Loss: 0.3855
Batch 360, Loss: 0.3636
Batch 370, Loss: 0.3794
Batch 380, Loss: 0.4115
Batch 390, Loss: 0.4164
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.059720277786255 seconds
Epoch 168 accuracy: 77.28%
Batch 10, Loss: 0.3749
Batch 20, Loss: 0.3576
Batch 30, Loss: 0.3727
Batch 40, Loss: 0.3542
Batch 50, Loss: 0.4206
Batch 60, Loss: 0.3744
Batch 70, Loss: 0.3798
Batch 80, Loss: 0.3733
Batch 90, Loss: 0.3907
Batch 100, Loss: 0.3685
Batch 110, Loss: 0.3881
Batch 120, Loss: 0.3702
Batch 130, Loss: 0.3289
Batch 140, Loss: 0.3810
Batch 150, Loss: 0.3748
Batch 160, Loss: 0.3224
Batch 170, Loss: 0.3526
Batch 180, Loss: 0.3843
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.3871
Batch 210, Loss: 0.3575
Batch 220, Loss: 0.3931
Batch 230, Loss: 0.3956
Batch 240, Loss: 0.3847
Batch 250, Loss: 0.3383
Batch 260, Loss: 0.3756
Batch 270, Loss: 0.3967
Batch 280, Loss: 0.3870
Batch 290, Loss: 0.4050
Batch 300, Loss: 0.3881
Batch 310, Loss: 0.3393
Batch 320, Loss: 0.3676
Batch 330, Loss: 0.4173
Batch 340, Loss: 0.3587
Batch 350, Loss: 0.3919
Batch 360, Loss: 0.3596
Batch 370, Loss: 0.3870
Batch 380, Loss: 0.3839
Batch 390, Loss: 0.3684
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.279053211212158 seconds
Epoch 169 accuracy: 77.61%
Batch 10, Loss: 0.3313
Batch 20, Loss: 0.3637
Batch 30, Loss: 0.3972
Batch 40, Loss: 0.3671
Batch 50, Loss: 0.3778
Batch 60, Loss: 0.3914
Batch 70, Loss: 0.3831
Batch 80, Loss: 0.3855
Batch 90, Loss: 0.3596
Batch 100, Loss: 0.3877
Batch 110, Loss: 0.3622
Batch 120, Loss: 0.3366
Batch 130, Loss: 0.3724
Batch 140, Loss: 0.3483
Batch 150, Loss: 0.3509
Batch 160, Loss: 0.3786
Batch 170, Loss: 0.3640
Batch 180, Loss: 0.3601
Batch 190, Loss: 0.4073
Batch 200, Loss: 0.3691
Batch 210, Loss: 0.3521
Batch 220, Loss: 0.3632
Batch 230, Loss: 0.3691
Batch 240, Loss: 0.3453
Batch 250, Loss: 0.3860
Batch 260, Loss: 0.3613
Batch 270, Loss: 0.3713
Batch 280, Loss: 0.3768
Batch 290, Loss: 0.3611
Batch 300, Loss: 0.3713
Batch 310, Loss: 0.3668
Batch 320, Loss: 0.3675
Batch 330, Loss: 0.3916
Batch 340, Loss: 0.4071
Batch 350, Loss: 0.3708
Batch 360, Loss: 0.3827
Batch 370, Loss: 0.3838
Batch 380, Loss: 0.3959
Batch 390, Loss: 0.3730
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.199371814727783 seconds
Epoch 170 accuracy: 77.65%
Batch 10, Loss: 0.4020
Batch 20, Loss: 0.3656
Batch 30, Loss: 0.3111
Batch 40, Loss: 0.3635
Batch 50, Loss: 0.3581
Batch 60, Loss: 0.3345
Batch 70, Loss: 0.3510
Batch 80, Loss: 0.3806
Batch 90, Loss: 0.3797
Batch 100, Loss: 0.3548
Batch 110, Loss: 0.3787
Batch 120, Loss: 0.3573
Batch 130, Loss: 0.3622
Batch 140, Loss: 0.3689
Batch 150, Loss: 0.3813
Batch 160, Loss: 0.3433
Batch 170, Loss: 0.3841
Batch 180, Loss: 0.3341
Batch 190, Loss: 0.3779
Batch 200, Loss: 0.3422
Batch 210, Loss: 0.3534
Batch 220, Loss: 0.3255
Batch 230, Loss: 0.3404
Batch 240, Loss: 0.3738
Batch 250, Loss: 0.3999
Batch 260, Loss: 0.3500
Batch 270, Loss: 0.3502
Batch 280, Loss: 0.3661
Batch 290, Loss: 0.3438
Batch 300, Loss: 0.3944
Batch 310, Loss: 0.3510
Batch 320, Loss: 0.3674
Batch 330, Loss: 0.3630
Batch 340, Loss: 0.3717
Batch 350, Loss: 0.3665
Batch 360, Loss: 0.3545
Batch 370, Loss: 0.4016
Batch 380, Loss: 0.3549
Batch 390, Loss: 0.3606
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.17567491531372 seconds
Epoch 171 accuracy: 77.91%
Batch 10, Loss: 0.3584
Batch 20, Loss: 0.3365
Batch 30, Loss: 0.3505
Batch 40, Loss: 0.3440
Batch 50, Loss: 0.3250
Batch 60, Loss: 0.3768
Batch 70, Loss: 0.3464
Batch 80, Loss: 0.3433
Batch 90, Loss: 0.3406
Batch 100, Loss: 0.3265
Batch 110, Loss: 0.3390
Batch 120, Loss: 0.3330
Batch 130, Loss: 0.3604
Batch 140, Loss: 0.3540
Batch 150, Loss: 0.3324
Batch 160, Loss: 0.3248
Batch 170, Loss: 0.3641
Batch 180, Loss: 0.3533
Batch 190, Loss: 0.3600
Batch 200, Loss: 0.3388
Batch 210, Loss: 0.3626
Batch 220, Loss: 0.3075
Batch 230, Loss: 0.3515
Batch 240, Loss: 0.3583
Batch 250, Loss: 0.3555
Batch 260, Loss: 0.3717
Batch 270, Loss: 0.3519
Batch 280, Loss: 0.3171
Batch 290, Loss: 0.3657
Batch 300, Loss: 0.3665
Batch 310, Loss: 0.3477
Batch 320, Loss: 0.3856
Batch 330, Loss: 0.3297
Batch 340, Loss: 0.4109
Batch 350, Loss: 0.3898
Batch 360, Loss: 0.3588
Batch 370, Loss: 0.3453
Batch 380, Loss: 0.3504
Batch 390, Loss: 0.3304
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.10531258583069 seconds
Epoch 172 accuracy: 78.34%
Batch 10, Loss: 0.3056
Batch 20, Loss: 0.3425
Batch 30, Loss: 0.3573
Batch 40, Loss: 0.3273
Batch 50, Loss: 0.3133
Batch 60, Loss: 0.3177
Batch 70, Loss: 0.3191
Batch 80, Loss: 0.3556
Batch 90, Loss: 0.3373
Batch 100, Loss: 0.3235
Batch 110, Loss: 0.3620
Batch 120, Loss: 0.3214
Batch 130, Loss: 0.3360
Batch 140, Loss: 0.3797
Batch 150, Loss: 0.3227
Batch 160, Loss: 0.3571
Batch 170, Loss: 0.3486
Batch 180, Loss: 0.3478
Batch 190, Loss: 0.3451
Batch 200, Loss: 0.3757
Batch 210, Loss: 0.3301
Batch 220, Loss: 0.3168
Batch 230, Loss: 0.3518
Batch 240, Loss: 0.3553
Batch 250, Loss: 0.3380
Batch 260, Loss: 0.3405
Batch 270, Loss: 0.3404
Batch 280, Loss: 0.3305
Batch 290, Loss: 0.3867
Batch 300, Loss: 0.3807
Batch 310, Loss: 0.3315
Batch 320, Loss: 0.3127
Batch 330, Loss: 0.3488
Batch 340, Loss: 0.3479
Batch 350, Loss: 0.3410
Batch 360, Loss: 0.3303
Batch 370, Loss: 0.3840
Batch 380, Loss: 0.3286
Batch 390, Loss: 0.3447
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.098946571350098 seconds
Epoch 173 accuracy: 78.13%
Batch 10, Loss: 0.3400
Batch 20, Loss: 0.3336
Batch 30, Loss: 0.3099
Batch 40, Loss: 0.3466
Batch 50, Loss: 0.3560
Batch 60, Loss: 0.3478
Batch 70, Loss: 0.3215
Batch 80, Loss: 0.3606
Batch 90, Loss: 0.3270
Batch 100, Loss: 0.3221
Batch 110, Loss: 0.3490
Batch 120, Loss: 0.3371
Batch 130, Loss: 0.3258
Batch 140, Loss: 0.3244
Batch 150, Loss: 0.3434
Batch 160, Loss: 0.3561
Batch 170, Loss: 0.3258
Batch 180, Loss: 0.3496
Batch 190, Loss: 0.3041
Batch 200, Loss: 0.3885
Batch 210, Loss: 0.3231
Batch 220, Loss: 0.3116
Batch 230, Loss: 0.3501
Batch 240, Loss: 0.3700
Batch 250, Loss: 0.3740
Batch 260, Loss: 0.3355
Batch 270, Loss: 0.3412
Batch 280, Loss: 0.3525
Batch 290, Loss: 0.3368
Batch 300, Loss: 0.3546
Batch 310, Loss: 0.3670
Batch 320, Loss: 0.3461
Batch 330, Loss: 0.3723
Batch 340, Loss: 0.3426
Batch 350, Loss: 0.3432
Batch 360, Loss: 0.3131
Batch 370, Loss: 0.3707
Batch 380, Loss: 0.2924
Batch 390, Loss: 0.3302
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.243958234786987 seconds
Epoch 174 accuracy: 78.33%
Batch 10, Loss: 0.3359
Batch 20, Loss: 0.3110
Batch 30, Loss: 0.3065
Batch 40, Loss: 0.3122
Batch 50, Loss: 0.3150
Batch 60, Loss: 0.3413
Batch 70, Loss: 0.3189
Batch 80, Loss: 0.3111
Batch 90, Loss: 0.2993
Batch 100, Loss: 0.3233
Batch 110, Loss: 0.2918
Batch 120, Loss: 0.3094
Batch 130, Loss: 0.3317
Batch 140, Loss: 0.3203
Batch 150, Loss: 0.3263
Batch 160, Loss: 0.3297
Batch 170, Loss: 0.3346
Batch 180, Loss: 0.3103
Batch 190, Loss: 0.3123
Batch 200, Loss: 0.3084
Batch 210, Loss: 0.3164
Batch 220, Loss: 0.3559
Batch 230, Loss: 0.3301
Batch 240, Loss: 0.3437
Batch 250, Loss: 0.3627
Batch 260, Loss: 0.3344
Batch 270, Loss: 0.3414
Batch 280, Loss: 0.3354
Batch 290, Loss: 0.3133
Batch 300, Loss: 0.3364
Batch 310, Loss: 0.3422
Batch 320, Loss: 0.2869
Batch 330, Loss: 0.3062
Batch 340, Loss: 0.3314
Batch 350, Loss: 0.3793
Batch 360, Loss: 0.3350
Batch 370, Loss: 0.3128
Batch 380, Loss: 0.2919
Batch 390, Loss: 0.3473
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.30717968940735 seconds
Epoch 175 accuracy: 78.75%
Batch 10, Loss: 0.3033
Batch 20, Loss: 0.3027
Batch 30, Loss: 0.2946
Batch 40, Loss: 0.3124
Batch 50, Loss: 0.3081
Batch 60, Loss: 0.3047
Batch 70, Loss: 0.3309
Batch 80, Loss: 0.3001
Batch 90, Loss: 0.3141
Batch 100, Loss: 0.3454
Batch 110, Loss: 0.3252
Batch 120, Loss: 0.3317
Batch 130, Loss: 0.3029
Batch 140, Loss: 0.3143
Batch 150, Loss: 0.3023
Batch 160, Loss: 0.2949
Batch 170, Loss: 0.3089
Batch 180, Loss: 0.2977
Batch 190, Loss: 0.2926
Batch 200, Loss: 0.3323
Batch 210, Loss: 0.3119
Batch 220, Loss: 0.3052
Batch 230, Loss: 0.3232
Batch 240, Loss: 0.3483
Batch 250, Loss: 0.3236
Batch 260, Loss: 0.2926
Batch 270, Loss: 0.2951
Batch 280, Loss: 0.3079
Batch 290, Loss: 0.3445
Batch 300, Loss: 0.3336
Batch 310, Loss: 0.2996
Batch 320, Loss: 0.3297
Batch 330, Loss: 0.3515
Batch 340, Loss: 0.3091
Batch 350, Loss: 0.3155
Batch 360, Loss: 0.3013
Batch 370, Loss: 0.3164
Batch 380, Loss: 0.3498
Batch 390, Loss: 0.3443
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.1847562789917 seconds
Epoch 176 accuracy: 78.9%
Batch 10, Loss: 0.3432
Batch 20, Loss: 0.3051
Batch 30, Loss: 0.2712
Batch 40, Loss: 0.3172
Batch 50, Loss: 0.2902
Batch 60, Loss: 0.3097
Batch 70, Loss: 0.3150
Batch 80, Loss: 0.2982
Batch 90, Loss: 0.3336
Batch 100, Loss: 0.2794
Batch 110, Loss: 0.3014
Batch 120, Loss: 0.2858
Batch 130, Loss: 0.2778
Batch 140, Loss: 0.3257
Batch 150, Loss: 0.3427
Batch 160, Loss: 0.2898
Batch 170, Loss: 0.3198
Batch 180, Loss: 0.3005
Batch 190, Loss: 0.3333
Batch 200, Loss: 0.3537
Batch 210, Loss: 0.3201
Batch 220, Loss: 0.2981
Batch 230, Loss: 0.3185
Batch 240, Loss: 0.3468
Batch 250, Loss: 0.3126
Batch 260, Loss: 0.3028
Batch 270, Loss: 0.2870
Batch 280, Loss: 0.3043
Batch 290, Loss: 0.3236
Batch 300, Loss: 0.3179
Batch 310, Loss: 0.3016
Batch 320, Loss: 0.2886
Batch 330, Loss: 0.3122
Batch 340, Loss: 0.3176
Batch 350, Loss: 0.3367
Batch 360, Loss: 0.3151
Batch 370, Loss: 0.2770
Batch 380, Loss: 0.2888
Batch 390, Loss: 0.2718
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.24933385848999 seconds
Epoch 177 accuracy: 79.02%
Batch 10, Loss: 0.2944
Batch 20, Loss: 0.2965
Batch 30, Loss: 0.3124
Batch 40, Loss: 0.2760
Batch 50, Loss: 0.2700
Batch 60, Loss: 0.3219
Batch 70, Loss: 0.2840
Batch 80, Loss: 0.2878
Batch 90, Loss: 0.2994
Batch 100, Loss: 0.3093
Batch 110, Loss: 0.3134
Batch 120, Loss: 0.3267
Batch 130, Loss: 0.2925
Batch 140, Loss: 0.3233
Batch 150, Loss: 0.2882
Batch 160, Loss: 0.3072
Batch 170, Loss: 0.2894
Batch 180, Loss: 0.2836
Batch 190, Loss: 0.3110
Batch 200, Loss: 0.3170
Batch 210, Loss: 0.3256
Batch 220, Loss: 0.3021
Batch 230, Loss: 0.3290
Batch 240, Loss: 0.2964
Batch 250, Loss: 0.3135
Batch 260, Loss: 0.3158
Batch 270, Loss: 0.3442
Batch 280, Loss: 0.3445
Batch 290, Loss: 0.2918
Batch 300, Loss: 0.3163
Batch 310, Loss: 0.3031
Batch 320, Loss: 0.3322
Batch 330, Loss: 0.3176
Batch 340, Loss: 0.3514
Batch 350, Loss: 0.3534
Batch 360, Loss: 0.3293
Batch 370, Loss: 0.3046
Batch 380, Loss: 0.3087
Batch 390, Loss: 0.3113
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.14081573486328 seconds
Epoch 178 accuracy: 78.96%
Batch 10, Loss: 0.2814
Batch 20, Loss: 0.2785
Batch 30, Loss: 0.2652
Batch 40, Loss: 0.2829
Batch 50, Loss: 0.3260
Batch 60, Loss: 0.3059
Batch 70, Loss: 0.3037
Batch 80, Loss: 0.3017
Batch 90, Loss: 0.3042
Batch 100, Loss: 0.2699
Batch 110, Loss: 0.3399
Batch 120, Loss: 0.3097
Batch 130, Loss: 0.2968
Batch 140, Loss: 0.2906
Batch 150, Loss: 0.3398
Batch 160, Loss: 0.2979
Batch 170, Loss: 0.2974
Batch 180, Loss: 0.3010
Batch 190, Loss: 0.2815
Batch 200, Loss: 0.3179
Batch 210, Loss: 0.3166
Batch 220, Loss: 0.3096
Batch 230, Loss: 0.3041
Batch 240, Loss: 0.3121
Batch 250, Loss: 0.2777
Batch 260, Loss: 0.2983
Batch 270, Loss: 0.2840
Batch 280, Loss: 0.3162
Batch 290, Loss: 0.2940
Batch 300, Loss: 0.3162
Batch 310, Loss: 0.2606
Batch 320, Loss: 0.3098
Batch 330, Loss: 0.3127
Batch 340, Loss: 0.2977
Batch 350, Loss: 0.3137
Batch 360, Loss: 0.2885
Batch 370, Loss: 0.2699
Batch 380, Loss: 0.3158
Batch 390, Loss: 0.2971
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.203619241714478 seconds
Epoch 179 accuracy: 79.4%
Batch 10, Loss: 0.2955
Batch 20, Loss: 0.2801
Batch 30, Loss: 0.2785
Batch 40, Loss: 0.3089
Batch 50, Loss: 0.3125
Batch 60, Loss: 0.2676
Batch 70, Loss: 0.2995
Batch 80, Loss: 0.2899
Batch 90, Loss: 0.2856
Batch 100, Loss: 0.2991
Batch 110, Loss: 0.2955
Batch 120, Loss: 0.2878
Batch 130, Loss: 0.2708
Batch 140, Loss: 0.3121
Batch 150, Loss: 0.2714
Batch 160, Loss: 0.2811
Batch 170, Loss: 0.2922
Batch 180, Loss: 0.2880
Batch 190, Loss: 0.2924
Batch 200, Loss: 0.3075
Batch 210, Loss: 0.2664
Batch 220, Loss: 0.2892
Batch 230, Loss: 0.2886
Batch 240, Loss: 0.2888
Batch 250, Loss: 0.2938
Batch 260, Loss: 0.2653
Batch 270, Loss: 0.2758
Batch 280, Loss: 0.2960
Batch 290, Loss: 0.2865
Batch 300, Loss: 0.2903
Batch 310, Loss: 0.3017
Batch 320, Loss: 0.2955
Batch 330, Loss: 0.2560
Batch 340, Loss: 0.3146
Batch 350, Loss: 0.2643
Batch 360, Loss: 0.3096
Batch 370, Loss: 0.2896
Batch 380, Loss: 0.3003
Batch 390, Loss: 0.2816
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.187458992004395 seconds
Epoch 180 accuracy: 79.15%
Batch 10, Loss: 0.2524
Batch 20, Loss: 0.2882
Batch 30, Loss: 0.2732
Batch 40, Loss: 0.2702
Batch 50, Loss: 0.2684
Batch 60, Loss: 0.3048
Batch 70, Loss: 0.2954
Batch 80, Loss: 0.2862
Batch 90, Loss: 0.2631
Batch 100, Loss: 0.3075
Batch 110, Loss: 0.2696
Batch 120, Loss: 0.2858
Batch 130, Loss: 0.2842
Batch 140, Loss: 0.2789
Batch 150, Loss: 0.3134
Batch 160, Loss: 0.2904
Batch 170, Loss: 0.3008
Batch 180, Loss: 0.3081
Batch 190, Loss: 0.2900
Batch 200, Loss: 0.3070
Batch 210, Loss: 0.2820
Batch 220, Loss: 0.3040
Batch 230, Loss: 0.2997
Batch 240, Loss: 0.2760
Batch 250, Loss: 0.2869
Batch 260, Loss: 0.3230
Batch 270, Loss: 0.3027
Batch 280, Loss: 0.2677
Batch 290, Loss: 0.2495
Batch 300, Loss: 0.2929
Batch 310, Loss: 0.2714
Batch 320, Loss: 0.2498
Batch 330, Loss: 0.3062
Batch 340, Loss: 0.3045
Batch 350, Loss: 0.2905
Batch 360, Loss: 0.2853
Batch 370, Loss: 0.2954
Batch 380, Loss: 0.2691
Batch 390, Loss: 0.3005
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.213491439819336 seconds
Epoch 181 accuracy: 79.32%
Batch 10, Loss: 0.2439
Batch 20, Loss: 0.2836
Batch 30, Loss: 0.2797
Batch 40, Loss: 0.3122
Batch 50, Loss: 0.3009
Batch 60, Loss: 0.2936
Batch 70, Loss: 0.3024
Batch 80, Loss: 0.2535
Batch 90, Loss: 0.2509
Batch 100, Loss: 0.2913
Batch 110, Loss: 0.2839
Batch 120, Loss: 0.2781
Batch 130, Loss: 0.2691
Batch 140, Loss: 0.2593
Batch 150, Loss: 0.2660
Batch 160, Loss: 0.2688
Batch 170, Loss: 0.3018
Batch 180, Loss: 0.2559
Batch 190, Loss: 0.2747
Batch 200, Loss: 0.2985
Batch 210, Loss: 0.2700
Batch 220, Loss: 0.3033
Batch 230, Loss: 0.2768
Batch 240, Loss: 0.2897
Batch 250, Loss: 0.2795
Batch 260, Loss: 0.2665
Batch 270, Loss: 0.2491
Batch 280, Loss: 0.2469
Batch 290, Loss: 0.2929
Batch 300, Loss: 0.3018
Batch 310, Loss: 0.3218
Batch 320, Loss: 0.2917
Batch 330, Loss: 0.3048
Batch 340, Loss: 0.3039
Batch 350, Loss: 0.2844
Batch 360, Loss: 0.2708
Batch 370, Loss: 0.2852
Batch 380, Loss: 0.2697
Batch 390, Loss: 0.3128
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.10407853126526 seconds
Epoch 182 accuracy: 79.39%
Batch 10, Loss: 0.2738
Batch 20, Loss: 0.2636
Batch 30, Loss: 0.2762
Batch 40, Loss: 0.2649
Batch 50, Loss: 0.2724
Batch 60, Loss: 0.2915
Batch 70, Loss: 0.2597
Batch 80, Loss: 0.2582
Batch 90, Loss: 0.2390
Batch 100, Loss: 0.2555
Batch 110, Loss: 0.2798
Batch 120, Loss: 0.2738
Batch 130, Loss: 0.2911
Batch 140, Loss: 0.3106
Batch 150, Loss: 0.2824
Batch 160, Loss: 0.2647
Batch 170, Loss: 0.2506
Batch 180, Loss: 0.2715
Batch 190, Loss: 0.2473
Batch 200, Loss: 0.2665
Batch 210, Loss: 0.3060
Batch 220, Loss: 0.2508
Batch 230, Loss: 0.2733
Batch 240, Loss: 0.2390
Batch 250, Loss: 0.2824
Batch 260, Loss: 0.2764
Batch 270, Loss: 0.2914
Batch 280, Loss: 0.2343
Batch 290, Loss: 0.2820
Batch 300, Loss: 0.2682
Batch 310, Loss: 0.2631
Batch 320, Loss: 0.2487
Batch 330, Loss: 0.2841
Batch 340, Loss: 0.2627
Batch 350, Loss: 0.2664
Batch 360, Loss: 0.2800
Batch 370, Loss: 0.2966
Batch 380, Loss: 0.2976
Batch 390, Loss: 0.3090
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.204219818115234 seconds
Epoch 183 accuracy: 79.4%
Batch 10, Loss: 0.2553
Batch 20, Loss: 0.2962
Batch 30, Loss: 0.2727
Batch 40, Loss: 0.2424
Batch 50, Loss: 0.2565
Batch 60, Loss: 0.2555
Batch 70, Loss: 0.2594
Batch 80, Loss: 0.2871
Batch 90, Loss: 0.2523
Batch 100, Loss: 0.2653
Batch 110, Loss: 0.2835
Batch 120, Loss: 0.2875
Batch 130, Loss: 0.2790
Batch 140, Loss: 0.2458
Batch 150, Loss: 0.2641
Batch 160, Loss: 0.2585
Batch 170, Loss: 0.2710
Batch 180, Loss: 0.2884
Batch 190, Loss: 0.2634
Batch 200, Loss: 0.2795
Batch 210, Loss: 0.2915
Batch 220, Loss: 0.2702
Batch 230, Loss: 0.2627
Batch 240, Loss: 0.2745
Batch 250, Loss: 0.2723
Batch 260, Loss: 0.2807
Batch 270, Loss: 0.2403
Batch 280, Loss: 0.2398
Batch 290, Loss: 0.2498
Batch 300, Loss: 0.2662
Batch 310, Loss: 0.2580
Batch 320, Loss: 0.2714
Batch 330, Loss: 0.2433
Batch 340, Loss: 0.2898
Batch 350, Loss: 0.2859
Batch 360, Loss: 0.3001
Batch 370, Loss: 0.2536
Batch 380, Loss: 0.2696
Batch 390, Loss: 0.2571
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.12194514274597 seconds
Epoch 184 accuracy: 79.78%
Batch 10, Loss: 0.2457
Batch 20, Loss: 0.2561
Batch 30, Loss: 0.2619
Batch 40, Loss: 0.2709
Batch 50, Loss: 0.2495
Batch 60, Loss: 0.2527
Batch 70, Loss: 0.2446
Batch 80, Loss: 0.2711
Batch 90, Loss: 0.2988
Batch 100, Loss: 0.2319
Batch 110, Loss: 0.2731
Batch 120, Loss: 0.2595
Batch 130, Loss: 0.2600
Batch 140, Loss: 0.2805
Batch 150, Loss: 0.2497
Batch 160, Loss: 0.2509
Batch 170, Loss: 0.2774
Batch 180, Loss: 0.2616
Batch 190, Loss: 0.2788
Batch 200, Loss: 0.2408
Batch 210, Loss: 0.2864
Batch 220, Loss: 0.2517
Batch 230, Loss: 0.2757
Batch 240, Loss: 0.2368
Batch 250, Loss: 0.2664
Batch 260, Loss: 0.2817
Batch 270, Loss: 0.2603
Batch 280, Loss: 0.2736
Batch 290, Loss: 0.2823
Batch 300, Loss: 0.2497
Batch 310, Loss: 0.2516
Batch 320, Loss: 0.2675
Batch 330, Loss: 0.2773
Batch 340, Loss: 0.2620
Batch 350, Loss: 0.2603
Batch 360, Loss: 0.2628
Batch 370, Loss: 0.2575
Batch 380, Loss: 0.2749
Batch 390, Loss: 0.2627
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.183215856552124 seconds
Epoch 185 accuracy: 79.88%
Batch 10, Loss: 0.2895
Batch 20, Loss: 0.2689
Batch 30, Loss: 0.2400
Batch 40, Loss: 0.3033
Batch 50, Loss: 0.2836
Batch 60, Loss: 0.2445
Batch 70, Loss: 0.2321
Batch 80, Loss: 0.2653
Batch 90, Loss: 0.2365
Batch 100, Loss: 0.2731
Batch 110, Loss: 0.2756
Batch 120, Loss: 0.2519
Batch 130, Loss: 0.2454
Batch 140, Loss: 0.2363
Batch 150, Loss: 0.2320
Batch 160, Loss: 0.2951
Batch 170, Loss: 0.2805
Batch 180, Loss: 0.2605
Batch 190, Loss: 0.2596
Batch 200, Loss: 0.2549
Batch 210, Loss: 0.2656
Batch 220, Loss: 0.2756
Batch 230, Loss: 0.2751
Batch 240, Loss: 0.2370
Batch 250, Loss: 0.2519
Batch 260, Loss: 0.2980
Batch 270, Loss: 0.2695
Batch 280, Loss: 0.2831
Batch 290, Loss: 0.2513
Batch 300, Loss: 0.2737
Batch 310, Loss: 0.2576
Batch 320, Loss: 0.2415
Batch 330, Loss: 0.2445
Batch 340, Loss: 0.2385
Batch 350, Loss: 0.2559
Batch 360, Loss: 0.2300
Batch 370, Loss: 0.2487
Batch 380, Loss: 0.2500
Batch 390, Loss: 0.2785
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.183732271194458 seconds
Epoch 186 accuracy: 79.82%
Batch 10, Loss: 0.2836
Batch 20, Loss: 0.2598
Batch 30, Loss: 0.2446
Batch 40, Loss: 0.2292
Batch 50, Loss: 0.2518
Batch 60, Loss: 0.2611
Batch 70, Loss: 0.2495
Batch 80, Loss: 0.2401
Batch 90, Loss: 0.2686
Batch 100, Loss: 0.2751
Batch 110, Loss: 0.2583
Batch 120, Loss: 0.2637
Batch 130, Loss: 0.2709
Batch 140, Loss: 0.2678
Batch 150, Loss: 0.2551
Batch 160, Loss: 0.2653
Batch 170, Loss: 0.2732
Batch 180, Loss: 0.2759
Batch 190, Loss: 0.2476
Batch 200, Loss: 0.2615
Batch 210, Loss: 0.3025
Batch 220, Loss: 0.2561
Batch 230, Loss: 0.2801
Batch 240, Loss: 0.2658
Batch 250, Loss: 0.2447
Batch 260, Loss: 0.2641
Batch 270, Loss: 0.2649
Batch 280, Loss: 0.2580
Batch 290, Loss: 0.2652
Batch 300, Loss: 0.2524
Batch 310, Loss: 0.2099
Batch 320, Loss: 0.2605
Batch 330, Loss: 0.2314
Batch 340, Loss: 0.2626
Batch 350, Loss: 0.2616
Batch 360, Loss: 0.2668
Batch 370, Loss: 0.2593
Batch 380, Loss: 0.2709
Batch 390, Loss: 0.2427
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.160528421401978 seconds
Epoch 187 accuracy: 79.73%
Batch 10, Loss: 0.2625
Batch 20, Loss: 0.2254
Batch 30, Loss: 0.2558
Batch 40, Loss: 0.2442
Batch 50, Loss: 0.2590
Batch 60, Loss: 0.2305
Batch 70, Loss: 0.2451
Batch 80, Loss: 0.2524
Batch 90, Loss: 0.2612
Batch 100, Loss: 0.2606
Batch 110, Loss: 0.2734
Batch 120, Loss: 0.2484
Batch 130, Loss: 0.2698
Batch 140, Loss: 0.2816
Batch 150, Loss: 0.2370
Batch 160, Loss: 0.2370
Batch 170, Loss: 0.2599
Batch 180, Loss: 0.2645
Batch 190, Loss: 0.2507
Batch 200, Loss: 0.2437
Batch 210, Loss: 0.2454
Batch 220, Loss: 0.2707
Batch 230, Loss: 0.2567
Batch 240, Loss: 0.2516
Batch 250, Loss: 0.2310
Batch 260, Loss: 0.2437
Batch 270, Loss: 0.2492
Batch 280, Loss: 0.2521
Batch 290, Loss: 0.2396
Batch 300, Loss: 0.2473
Batch 310, Loss: 0.2335
Batch 320, Loss: 0.2754
Batch 330, Loss: 0.2676
Batch 340, Loss: 0.2708
Batch 350, Loss: 0.2359
Batch 360, Loss: 0.2367
Batch 370, Loss: 0.2837
Batch 380, Loss: 0.2362
Batch 390, Loss: 0.2530
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.071144819259644 seconds
Epoch 188 accuracy: 79.75%
Batch 10, Loss: 0.2413
Batch 20, Loss: 0.2372
Batch 30, Loss: 0.2637
Batch 40, Loss: 0.2618
Batch 50, Loss: 0.2461
Batch 60, Loss: 0.2508
Batch 70, Loss: 0.2475
Batch 80, Loss: 0.2425
Batch 90, Loss: 0.2587
Batch 100, Loss: 0.2472
Batch 110, Loss: 0.2533
Batch 120, Loss: 0.2637
Batch 130, Loss: 0.2226
Batch 140, Loss: 0.2724
Batch 150, Loss: 0.2467
Batch 160, Loss: 0.2378
Batch 170, Loss: 0.2222
Batch 180, Loss: 0.2864
Batch 190, Loss: 0.2573
Batch 200, Loss: 0.2386
Batch 210, Loss: 0.2392
Batch 220, Loss: 0.2457
Batch 230, Loss: 0.2499
Batch 240, Loss: 0.2522
Batch 250, Loss: 0.2345
Batch 260, Loss: 0.2666
Batch 270, Loss: 0.2556
Batch 280, Loss: 0.2157
Batch 290, Loss: 0.2419
Batch 300, Loss: 0.2834
Batch 310, Loss: 0.2606
Batch 320, Loss: 0.2694
Batch 330, Loss: 0.2788
Batch 340, Loss: 0.2580
Batch 350, Loss: 0.2379
Batch 360, Loss: 0.2891
Batch 370, Loss: 0.2834
Batch 380, Loss: 0.2660
Batch 390, Loss: 0.2423
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.20456075668335 seconds
Epoch 189 accuracy: 80.1%
Batch 10, Loss: 0.2326
Batch 20, Loss: 0.2529
Batch 30, Loss: 0.2504
Batch 40, Loss: 0.2479
Batch 50, Loss: 0.2547
Batch 60, Loss: 0.2416
Batch 70, Loss: 0.2231
Batch 80, Loss: 0.2607
Batch 90, Loss: 0.2367
Batch 100, Loss: 0.2250
Batch 110, Loss: 0.2165
Batch 120, Loss: 0.2845
Batch 130, Loss: 0.2541
Batch 140, Loss: 0.2201
Batch 150, Loss: 0.2646
Batch 160, Loss: 0.2151
Batch 170, Loss: 0.2511
Batch 180, Loss: 0.2162
Batch 190, Loss: 0.2681
Batch 200, Loss: 0.2654
Batch 210, Loss: 0.2500
Batch 220, Loss: 0.2400
Batch 230, Loss: 0.2492
Batch 240, Loss: 0.2813
Batch 250, Loss: 0.2563
Batch 260, Loss: 0.2280
Batch 270, Loss: 0.2367
Batch 280, Loss: 0.2637
Batch 290, Loss: 0.2494
Batch 300, Loss: 0.2815
Batch 310, Loss: 0.2133
Batch 320, Loss: 0.2450
Batch 330, Loss: 0.2797
Batch 340, Loss: 0.2429
Batch 350, Loss: 0.2742
Batch 360, Loss: 0.2759
Batch 370, Loss: 0.2481
Batch 380, Loss: 0.2531
Batch 390, Loss: 0.2465
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.081175804138184 seconds
Epoch 190 accuracy: 80.01%
Batch 10, Loss: 0.2411
Batch 20, Loss: 0.2309
Batch 30, Loss: 0.2458
Batch 40, Loss: 0.2486
Batch 50, Loss: 0.2497
Batch 60, Loss: 0.2323
Batch 70, Loss: 0.2446
Batch 80, Loss: 0.2220
Batch 90, Loss: 0.2452
Batch 100, Loss: 0.2679
Batch 110, Loss: 0.2445
Batch 120, Loss: 0.2371
Batch 130, Loss: 0.2443
Batch 140, Loss: 0.2568
Batch 150, Loss: 0.2363
Batch 160, Loss: 0.2381
Batch 170, Loss: 0.2270
Batch 180, Loss: 0.2483
Batch 190, Loss: 0.2481
Batch 200, Loss: 0.2498
Batch 210, Loss: 0.2757
Batch 220, Loss: 0.2555
Batch 230, Loss: 0.2399
Batch 240, Loss: 0.2359
Batch 250, Loss: 0.2624
Batch 260, Loss: 0.2586
Batch 270, Loss: 0.2169
Batch 280, Loss: 0.2421
Batch 290, Loss: 0.2300
Batch 300, Loss: 0.2155
Batch 310, Loss: 0.2462
Batch 320, Loss: 0.2516
Batch 330, Loss: 0.2595
Batch 340, Loss: 0.2549
Batch 350, Loss: 0.2462
Batch 360, Loss: 0.2936
Batch 370, Loss: 0.2415
Batch 380, Loss: 0.2696
Batch 390, Loss: 0.2505
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.20023512840271 seconds
Epoch 191 accuracy: 80.09%
Batch 10, Loss: 0.2538
Batch 20, Loss: 0.2574
Batch 30, Loss: 0.2750
Batch 40, Loss: 0.2277
Batch 50, Loss: 0.2693
Batch 60, Loss: 0.2420
Batch 70, Loss: 0.2503
Batch 80, Loss: 0.2305
Batch 90, Loss: 0.2225
Batch 100, Loss: 0.2384
Batch 110, Loss: 0.2437
Batch 120, Loss: 0.2379
Batch 130, Loss: 0.2105
Batch 140, Loss: 0.2347
Batch 150, Loss: 0.2487
Batch 160, Loss: 0.2865
Batch 170, Loss: 0.2535
Batch 180, Loss: 0.2577
Batch 190, Loss: 0.2527
Batch 200, Loss: 0.2371
Batch 210, Loss: 0.2587
Batch 220, Loss: 0.2315
Batch 230, Loss: 0.2369
Batch 240, Loss: 0.2667
Batch 250, Loss: 0.2297
Batch 260, Loss: 0.2326
Batch 270, Loss: 0.2252
Batch 280, Loss: 0.2349
Batch 290, Loss: 0.2616
Batch 300, Loss: 0.2259
Batch 310, Loss: 0.2479
Batch 320, Loss: 0.2249
Batch 330, Loss: 0.2382
Batch 340, Loss: 0.2738
Batch 350, Loss: 0.2525
Batch 360, Loss: 0.2144
Batch 370, Loss: 0.2453
Batch 380, Loss: 0.2318
Batch 390, Loss: 0.2593
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.27464985847473 seconds
Epoch 192 accuracy: 79.73%
Batch 10, Loss: 0.2578
Batch 20, Loss: 0.2250
Batch 30, Loss: 0.2534
Batch 40, Loss: 0.2134
Batch 50, Loss: 0.2402
Batch 60, Loss: 0.2597
Batch 70, Loss: 0.2671
Batch 80, Loss: 0.2616
Batch 90, Loss: 0.2355
Batch 100, Loss: 0.2304
Batch 110, Loss: 0.2600
Batch 120, Loss: 0.2381
Batch 130, Loss: 0.2364
Batch 140, Loss: 0.2496
Batch 150, Loss: 0.2350
Batch 160, Loss: 0.2474
Batch 170, Loss: 0.2386
Batch 180, Loss: 0.2614
Batch 190, Loss: 0.2424
Batch 200, Loss: 0.2209
Batch 210, Loss: 0.2323
Batch 220, Loss: 0.2382
Batch 230, Loss: 0.2561
Batch 240, Loss: 0.2375
Batch 250, Loss: 0.2659
Batch 260, Loss: 0.2115
Batch 270, Loss: 0.2451
Batch 280, Loss: 0.2088
Batch 290, Loss: 0.2102
Batch 300, Loss: 0.2171
Batch 310, Loss: 0.2440
Batch 320, Loss: 0.2370
Batch 330, Loss: 0.2622
Batch 340, Loss: 0.2578
Batch 350, Loss: 0.2316
Batch 360, Loss: 0.2413
Batch 370, Loss: 0.2705
Batch 380, Loss: 0.2407
Batch 390, Loss: 0.2536
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.311326265335083 seconds
Epoch 193 accuracy: 79.99%
Batch 10, Loss: 0.2650
Batch 20, Loss: 0.2237
Batch 30, Loss: 0.2417
Batch 40, Loss: 0.2251
Batch 50, Loss: 0.2258
Batch 60, Loss: 0.2439
Batch 70, Loss: 0.1976
Batch 80, Loss: 0.2199
Batch 90, Loss: 0.2627
Batch 100, Loss: 0.2370
Batch 110, Loss: 0.2241
Batch 120, Loss: 0.2425
Batch 130, Loss: 0.2198
Batch 140, Loss: 0.2436
Batch 150, Loss: 0.2483
Batch 160, Loss: 0.2291
Batch 170, Loss: 0.2102
Batch 180, Loss: 0.2515
Batch 190, Loss: 0.2313
Batch 200, Loss: 0.2462
Batch 210, Loss: 0.2315
Batch 220, Loss: 0.2359
Batch 230, Loss: 0.2300
Batch 240, Loss: 0.2192
Batch 250, Loss: 0.2282
Batch 260, Loss: 0.2374
Batch 270, Loss: 0.2350
Batch 280, Loss: 0.2634
Batch 290, Loss: 0.2514
Batch 300, Loss: 0.2064
Batch 310, Loss: 0.2341
Batch 320, Loss: 0.2416
Batch 330, Loss: 0.2310
Batch 340, Loss: 0.2375
Batch 350, Loss: 0.2119
Batch 360, Loss: 0.2598
Batch 370, Loss: 0.2109
Batch 380, Loss: 0.2170
Batch 390, Loss: 0.2433
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.321701765060425 seconds
Epoch 194 accuracy: 79.93%
Batch 10, Loss: 0.2462
Batch 20, Loss: 0.2483
Batch 30, Loss: 0.2437
Batch 40, Loss: 0.2330
Batch 50, Loss: 0.2561
Batch 60, Loss: 0.2482
Batch 70, Loss: 0.2391
Batch 80, Loss: 0.2198
Batch 90, Loss: 0.2185
Batch 100, Loss: 0.2603
Batch 110, Loss: 0.2507
Batch 120, Loss: 0.2324
Batch 130, Loss: 0.2414
Batch 140, Loss: 0.2190
Batch 150, Loss: 0.2346
Batch 160, Loss: 0.2534
Batch 170, Loss: 0.2259
Batch 180, Loss: 0.2393
Batch 190, Loss: 0.2199
Batch 200, Loss: 0.2554
Batch 210, Loss: 0.2729
Batch 220, Loss: 0.2717
Batch 230, Loss: 0.2057
Batch 240, Loss: 0.2225
Batch 250, Loss: 0.2339
Batch 260, Loss: 0.2595
Batch 270, Loss: 0.2368
Batch 280, Loss: 0.2393
Batch 290, Loss: 0.2546
Batch 300, Loss: 0.2395
Batch 310, Loss: 0.2248
Batch 320, Loss: 0.2328
Batch 330, Loss: 0.2388
Batch 340, Loss: 0.2517
Batch 350, Loss: 0.2397
Batch 360, Loss: 0.2601
Batch 370, Loss: 0.2448
Batch 380, Loss: 0.2695
Batch 390, Loss: 0.2199
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.21415686607361 seconds
Epoch 195 accuracy: 80.17%
Batch 10, Loss: 0.2437
Batch 20, Loss: 0.2177
Batch 30, Loss: 0.2202
Batch 40, Loss: 0.2288
Batch 50, Loss: 0.2395
Batch 60, Loss: 0.2738
Batch 70, Loss: 0.2097
Batch 80, Loss: 0.2189
Batch 90, Loss: 0.2569
Batch 100, Loss: 0.2179
Batch 110, Loss: 0.2199
Batch 120, Loss: 0.2259
Batch 130, Loss: 0.2469
Batch 140, Loss: 0.2473
Batch 150, Loss: 0.2418
Batch 160, Loss: 0.2404
Batch 170, Loss: 0.2455
Batch 180, Loss: 0.2562
Batch 190, Loss: 0.2483
Batch 200, Loss: 0.2077
Batch 210, Loss: 0.2410
Batch 220, Loss: 0.2213
Batch 230, Loss: 0.2469
Batch 240, Loss: 0.2129
Batch 250, Loss: 0.2299
Batch 260, Loss: 0.2253
Batch 270, Loss: 0.2371
Batch 280, Loss: 0.2403
Batch 290, Loss: 0.2471
Batch 300, Loss: 0.2552
Batch 310, Loss: 0.2120
Batch 320, Loss: 0.2389
Batch 330, Loss: 0.2405
Batch 340, Loss: 0.2646
Batch 350, Loss: 0.2242
Batch 360, Loss: 0.2475
Batch 370, Loss: 0.2269
Batch 380, Loss: 0.2280
Batch 390, Loss: 0.2117
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.08227777481079 seconds
Epoch 196 accuracy: 80.12%
Batch 10, Loss: 0.2261
Batch 20, Loss: 0.2396
Batch 30, Loss: 0.2212
Batch 40, Loss: 0.2432
Batch 50, Loss: 0.2297
Batch 60, Loss: 0.2201
Batch 70, Loss: 0.2548
Batch 80, Loss: 0.2652
Batch 90, Loss: 0.2480
Batch 100, Loss: 0.2193
Batch 110, Loss: 0.2405
Batch 120, Loss: 0.2377
Batch 130, Loss: 0.2253
Batch 140, Loss: 0.2323
Batch 150, Loss: 0.2499
Batch 160, Loss: 0.2350
Batch 170, Loss: 0.2058
Batch 180, Loss: 0.2058
Batch 190, Loss: 0.2435
Batch 200, Loss: 0.2206
Batch 210, Loss: 0.2391
Batch 220, Loss: 0.2465
Batch 230, Loss: 0.2335
Batch 240, Loss: 0.2320
Batch 250, Loss: 0.2334
Batch 260, Loss: 0.2770
Batch 270, Loss: 0.2442
Batch 280, Loss: 0.2267
Batch 290, Loss: 0.2079
Batch 300, Loss: 0.2191
Batch 310, Loss: 0.2496
Batch 320, Loss: 0.2511
Batch 330, Loss: 0.2458
Batch 340, Loss: 0.2257
Batch 350, Loss: 0.2446
Batch 360, Loss: 0.2335
Batch 370, Loss: 0.2276
Batch 380, Loss: 0.2073
Batch 390, Loss: 0.2390
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.167317390441895 seconds
Epoch 197 accuracy: 80.3%
Batch 10, Loss: 0.2254
Batch 20, Loss: 0.2443
Batch 30, Loss: 0.2552
Batch 40, Loss: 0.2447
Batch 50, Loss: 0.2274
Batch 60, Loss: 0.2116
Batch 70, Loss: 0.2432
Batch 80, Loss: 0.2280
Batch 90, Loss: 0.2674
Batch 100, Loss: 0.2425
Batch 110, Loss: 0.2464
Batch 120, Loss: 0.2480
Batch 130, Loss: 0.2623
Batch 140, Loss: 0.2298
Batch 150, Loss: 0.2435
Batch 160, Loss: 0.2302
Batch 170, Loss: 0.2368
Batch 180, Loss: 0.2256
Batch 190, Loss: 0.2247
Batch 200, Loss: 0.2110
Batch 210, Loss: 0.2255
Batch 220, Loss: 0.2406
Batch 230, Loss: 0.2449
Batch 240, Loss: 0.2329
Batch 250, Loss: 0.2031
Batch 260, Loss: 0.2517
Batch 270, Loss: 0.2391
Batch 280, Loss: 0.2335
Batch 290, Loss: 0.2220
Batch 300, Loss: 0.2536
Batch 310, Loss: 0.2211
Batch 320, Loss: 0.2733
Batch 330, Loss: 0.2218
Batch 340, Loss: 0.2308
Batch 350, Loss: 0.2340
Batch 360, Loss: 0.2083
Batch 370, Loss: 0.2472
Batch 380, Loss: 0.2475
Batch 390, Loss: 0.2331
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.178791046142578 seconds
Epoch 198 accuracy: 80.3%
Batch 10, Loss: 0.2545
Batch 20, Loss: 0.2440
Batch 30, Loss: 0.2468
Batch 40, Loss: 0.2904
Batch 50, Loss: 0.2201
Batch 60, Loss: 0.2427
Batch 70, Loss: 0.2304
Batch 80, Loss: 0.2116
Batch 90, Loss: 0.2533
Batch 100, Loss: 0.2058
Batch 110, Loss: 0.1892
Batch 120, Loss: 0.2399
Batch 130, Loss: 0.2351
Batch 140, Loss: 0.2244
Batch 150, Loss: 0.2557
Batch 160, Loss: 0.2289
Batch 170, Loss: 0.2354
Batch 180, Loss: 0.2569
Batch 190, Loss: 0.2359
Batch 200, Loss: 0.2772
Batch 210, Loss: 0.2514
Batch 220, Loss: 0.2416
Batch 230, Loss: 0.2376
Batch 240, Loss: 0.2469
Batch 250, Loss: 0.2252
Batch 260, Loss: 0.2367
Batch 270, Loss: 0.2319
Batch 280, Loss: 0.2054
Batch 290, Loss: 0.2347
Batch 300, Loss: 0.2529
Batch 310, Loss: 0.2210
Batch 320, Loss: 0.2414
Batch 330, Loss: 0.2565
Batch 340, Loss: 0.2388
Batch 350, Loss: 0.2443
Batch 360, Loss: 0.2169
Batch 370, Loss: 0.2165
Batch 380, Loss: 0.2313
Batch 390, Loss: 0.2357
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.158029079437256 seconds
Epoch 199 accuracy: 80.15%
Batch 10, Loss: 0.2537
Batch 20, Loss: 0.2270
Batch 30, Loss: 0.2237
Batch 40, Loss: 0.2219
Batch 50, Loss: 0.2171
Batch 60, Loss: 0.2527
Batch 70, Loss: 0.2262
Batch 80, Loss: 0.2240
Batch 90, Loss: 0.2329
Batch 100, Loss: 0.2341
Batch 110, Loss: 0.2120
Batch 120, Loss: 0.2628
Batch 130, Loss: 0.2198
Batch 140, Loss: 0.2242
Batch 150, Loss: 0.2432
Batch 160, Loss: 0.2380
Batch 170, Loss: 0.2204
Batch 180, Loss: 0.2474
Batch 190, Loss: 0.2498
Batch 200, Loss: 0.2266
Batch 210, Loss: 0.2303
Batch 220, Loss: 0.2346
Batch 230, Loss: 0.2053
Batch 240, Loss: 0.2123
Batch 250, Loss: 0.2337
Batch 260, Loss: 0.2585
Batch 270, Loss: 0.2344
Batch 280, Loss: 0.2421
Batch 290, Loss: 0.2476
Batch 300, Loss: 0.2475
Batch 310, Loss: 0.2403
Batch 320, Loss: 0.2248
Batch 330, Loss: 0.2364
Batch 340, Loss: 0.2171
Batch 350, Loss: 0.2319
Batch 360, Loss: 0.2286
Batch 370, Loss: 0.2718
Batch 380, Loss: 0.2189
Batch 390, Loss: 0.2474
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.248345613479614 seconds
Epoch 200 accuracy: 80.04%
Total training time: 5045.11163687706 seconds
