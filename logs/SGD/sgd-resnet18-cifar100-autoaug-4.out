The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.2549
Batch 20, Loss: 4.2222
Batch 30, Loss: 3.9758
Batch 40, Loss: 3.8747
Batch 50, Loss: 3.7519
Batch 60, Loss: 3.7636
Batch 70, Loss: 3.7126
Batch 80, Loss: 3.7097
Batch 90, Loss: 3.6897
Batch 100, Loss: 3.6589
Batch 110, Loss: 3.6689
Batch 120, Loss: 3.6389
Batch 130, Loss: 3.6200
Batch 140, Loss: 3.6019
Batch 150, Loss: 3.6313
Batch 160, Loss: 3.6036
Batch 170, Loss: 3.5899
Batch 180, Loss: 3.5792
Batch 190, Loss: 3.5551
Batch 200, Loss: 3.5176
Batch 210, Loss: 3.5408
Batch 220, Loss: 3.5217
Batch 230, Loss: 3.5410
Batch 240, Loss: 3.5512
Batch 250, Loss: 3.5112
Batch 260, Loss: 3.4648
Batch 270, Loss: 3.4977
Batch 280, Loss: 3.5263
Batch 290, Loss: 3.4991
Batch 300, Loss: 3.4447
Batch 310, Loss: 3.4948
Batch 320, Loss: 3.5199
Batch 330, Loss: 3.4865
Batch 340, Loss: 3.4687
Batch 350, Loss: 3.4635
Batch 360, Loss: 3.4425
Batch 370, Loss: 3.4295
Batch 380, Loss: 3.4221
Batch 390, Loss: 3.4245
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.404343128204346 seconds
Epoch 1 accuracy: 9.66%
Batch 10, Loss: 3.4021
Batch 20, Loss: 3.3655
Batch 30, Loss: 3.3989
Batch 40, Loss: 3.3877
Batch 50, Loss: 3.4113
Batch 60, Loss: 3.3926
Batch 70, Loss: 3.3765
Batch 80, Loss: 3.4404
Batch 90, Loss: 3.3953
Batch 100, Loss: 3.3409
Batch 110, Loss: 3.4100
Batch 120, Loss: 3.3834
Batch 130, Loss: 3.3276
Batch 140, Loss: 3.3721
Batch 150, Loss: 3.3773
Batch 160, Loss: 3.3470
Batch 170, Loss: 3.3351
Batch 180, Loss: 3.3865
Batch 190, Loss: 3.3118
Batch 200, Loss: 3.3081
Batch 210, Loss: 3.3613
Batch 220, Loss: 3.2969
Batch 230, Loss: 3.2700
Batch 240, Loss: 3.2567
Batch 250, Loss: 3.2455
Batch 260, Loss: 3.2373
Batch 270, Loss: 3.2494
Batch 280, Loss: 3.2612
Batch 290, Loss: 3.2227
Batch 300, Loss: 3.2648
Batch 310, Loss: 3.2525
Batch 320, Loss: 3.2335
Batch 330, Loss: 3.2027
Batch 340, Loss: 3.2115
Batch 350, Loss: 3.1906
Batch 360, Loss: 3.1521
Batch 370, Loss: 3.1885
Batch 380, Loss: 3.2051
Batch 390, Loss: 3.1394
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.282291412353516 seconds
Epoch 2 accuracy: 13.58%
Batch 10, Loss: 3.1120
Batch 20, Loss: 3.1723
Batch 30, Loss: 3.1307
Batch 40, Loss: 3.1508
Batch 50, Loss: 3.1637
Batch 60, Loss: 3.1257
Batch 70, Loss: 3.1467
Batch 80, Loss: 3.1064
Batch 90, Loss: 3.0834
Batch 100, Loss: 3.0897
Batch 110, Loss: 3.1084
Batch 120, Loss: 3.0994
Batch 130, Loss: 3.0914
Batch 140, Loss: 3.0706
Batch 150, Loss: 3.0760
Batch 160, Loss: 3.0287
Batch 170, Loss: 3.0745
Batch 180, Loss: 3.0581
Batch 190, Loss: 3.0346
Batch 200, Loss: 3.0433
Batch 210, Loss: 3.0051
Batch 220, Loss: 3.0715
Batch 230, Loss: 2.9977
Batch 240, Loss: 2.9562
Batch 250, Loss: 2.9919
Batch 260, Loss: 3.0274
Batch 270, Loss: 2.9883
Batch 280, Loss: 2.9757
Batch 290, Loss: 3.0289
Batch 300, Loss: 2.9039
Batch 310, Loss: 2.9158
Batch 320, Loss: 2.8960
Batch 330, Loss: 2.9690
Batch 340, Loss: 2.9776
Batch 350, Loss: 2.8920
Batch 360, Loss: 2.8874
Batch 370, Loss: 2.8848
Batch 380, Loss: 2.9020
Batch 390, Loss: 2.8873
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.23055601119995 seconds
Epoch 3 accuracy: 20.49%
Batch 10, Loss: 2.8860
Batch 20, Loss: 2.8656
Batch 30, Loss: 2.8384
Batch 40, Loss: 2.8936
Batch 50, Loss: 2.8629
Batch 60, Loss: 2.8057
Batch 70, Loss: 2.8076
Batch 80, Loss: 2.7979
Batch 90, Loss: 2.7194
Batch 100, Loss: 2.8220
Batch 110, Loss: 2.7700
Batch 120, Loss: 2.8448
Batch 130, Loss: 2.8271
Batch 140, Loss: 2.8101
Batch 150, Loss: 2.8199
Batch 160, Loss: 2.7468
Batch 170, Loss: 2.7081
Batch 180, Loss: 2.6935
Batch 190, Loss: 2.8003
Batch 200, Loss: 2.7679
Batch 210, Loss: 2.7448
Batch 220, Loss: 2.6928
Batch 230, Loss: 2.7620
Batch 240, Loss: 2.7188
Batch 250, Loss: 2.6816
Batch 260, Loss: 2.7206
Batch 270, Loss: 2.7468
Batch 280, Loss: 2.7986
Batch 290, Loss: 2.6965
Batch 300, Loss: 2.7163
Batch 310, Loss: 2.7258
Batch 320, Loss: 2.6693
Batch 330, Loss: 2.6380
Batch 340, Loss: 2.6746
Batch 350, Loss: 2.6254
Batch 360, Loss: 2.6216
Batch 370, Loss: 2.6384
Batch 380, Loss: 2.5900
Batch 390, Loss: 2.6813
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.272164583206177 seconds
Epoch 4 accuracy: 28.28%
Batch 10, Loss: 2.6627
Batch 20, Loss: 2.6211
Batch 30, Loss: 2.5322
Batch 40, Loss: 2.5652
Batch 50, Loss: 2.5173
Batch 60, Loss: 2.5497
Batch 70, Loss: 2.5841
Batch 80, Loss: 2.5795
Batch 90, Loss: 2.5198
Batch 100, Loss: 2.5959
Batch 110, Loss: 2.5057
Batch 120, Loss: 2.5316
Batch 130, Loss: 2.5253
Batch 140, Loss: 2.5064
Batch 150, Loss: 2.5621
Batch 160, Loss: 2.4518
Batch 170, Loss: 2.5007
Batch 180, Loss: 2.5161
Batch 190, Loss: 2.4924
Batch 200, Loss: 2.4669
Batch 210, Loss: 2.4407
Batch 220, Loss: 2.5144
Batch 230, Loss: 2.4725
Batch 240, Loss: 2.5174
Batch 250, Loss: 2.4486
Batch 260, Loss: 2.4244
Batch 270, Loss: 2.4540
Batch 280, Loss: 2.3918
Batch 290, Loss: 2.5300
Batch 300, Loss: 2.5371
Batch 310, Loss: 2.4687
Batch 320, Loss: 2.4820
Batch 330, Loss: 2.4352
Batch 340, Loss: 2.4438
Batch 350, Loss: 2.4742
Batch 360, Loss: 2.3785
Batch 370, Loss: 2.4151
Batch 380, Loss: 2.3863
Batch 390, Loss: 2.4315
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.264060735702515 seconds
Epoch 5 accuracy: 33.85%
Batch 10, Loss: 2.3531
Batch 20, Loss: 2.3658
Batch 30, Loss: 2.3943
Batch 40, Loss: 2.3472
Batch 50, Loss: 2.3812
Batch 60, Loss: 2.3010
Batch 70, Loss: 2.3190
Batch 80, Loss: 2.3689
Batch 90, Loss: 2.3799
Batch 100, Loss: 2.4046
Batch 110, Loss: 2.4149
Batch 120, Loss: 2.3207
Batch 130, Loss: 2.3682
Batch 140, Loss: 2.3493
Batch 150, Loss: 2.3977
Batch 160, Loss: 2.3051
Batch 170, Loss: 2.3337
Batch 180, Loss: 2.2867
Batch 190, Loss: 2.1991
Batch 200, Loss: 2.2769
Batch 210, Loss: 2.2805
Batch 220, Loss: 2.2856
Batch 230, Loss: 2.2812
Batch 240, Loss: 2.2106
Batch 250, Loss: 2.3002
Batch 260, Loss: 2.3140
Batch 270, Loss: 2.2910
Batch 280, Loss: 2.2967
Batch 290, Loss: 2.2327
Batch 300, Loss: 2.2706
Batch 310, Loss: 2.2726
Batch 320, Loss: 2.2310
Batch 330, Loss: 2.2503
Batch 340, Loss: 2.2574
Batch 350, Loss: 2.2251
Batch 360, Loss: 2.1734
Batch 370, Loss: 2.2654
Batch 380, Loss: 2.2651
Batch 390, Loss: 2.2387
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.305066347122192 seconds
Epoch 6 accuracy: 38.92%
Batch 10, Loss: 2.2032
Batch 20, Loss: 2.2142
Batch 30, Loss: 2.2354
Batch 40, Loss: 2.1298
Batch 50, Loss: 2.2208
Batch 60, Loss: 2.1672
Batch 70, Loss: 2.2139
Batch 80, Loss: 2.2201
Batch 90, Loss: 2.2238
Batch 100, Loss: 2.2246
Batch 110, Loss: 2.1574
Batch 120, Loss: 2.1551
Batch 130, Loss: 2.2252
Batch 140, Loss: 2.1408
Batch 150, Loss: 2.1834
Batch 160, Loss: 2.2330
Batch 170, Loss: 2.2318
Batch 180, Loss: 2.1447
Batch 190, Loss: 2.1005
Batch 200, Loss: 2.1347
Batch 210, Loss: 2.2476
Batch 220, Loss: 2.1997
Batch 230, Loss: 2.1116
Batch 240, Loss: 2.1014
Batch 250, Loss: 2.0453
Batch 260, Loss: 2.1153
Batch 270, Loss: 2.0800
Batch 280, Loss: 2.1224
Batch 290, Loss: 2.0967
Batch 300, Loss: 2.0892
Batch 310, Loss: 2.2016
Batch 320, Loss: 2.1339
Batch 330, Loss: 2.1711
Batch 340, Loss: 2.1497
Batch 350, Loss: 2.1569
Batch 360, Loss: 2.1572
Batch 370, Loss: 2.0573
Batch 380, Loss: 2.1541
Batch 390, Loss: 2.1263
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.15477204322815 seconds
Epoch 7 accuracy: 39.67%
Batch 10, Loss: 2.0841
Batch 20, Loss: 2.0527
Batch 30, Loss: 2.0102
Batch 40, Loss: 2.0089
Batch 50, Loss: 2.0489
Batch 60, Loss: 2.0998
Batch 70, Loss: 2.0578
Batch 80, Loss: 2.0467
Batch 90, Loss: 2.0210
Batch 100, Loss: 2.1586
Batch 110, Loss: 2.1086
Batch 120, Loss: 2.0941
Batch 130, Loss: 2.0002
Batch 140, Loss: 2.0814
Batch 150, Loss: 2.0293
Batch 160, Loss: 2.0430
Batch 170, Loss: 2.0043
Batch 180, Loss: 2.0743
Batch 190, Loss: 2.0513
Batch 200, Loss: 2.1216
Batch 210, Loss: 2.0447
Batch 220, Loss: 2.0009
Batch 230, Loss: 2.0667
Batch 240, Loss: 2.0367
Batch 250, Loss: 1.9791
Batch 260, Loss: 2.0319
Batch 270, Loss: 2.0958
Batch 280, Loss: 2.0786
Batch 290, Loss: 2.0759
Batch 300, Loss: 1.9826
Batch 310, Loss: 2.0188
Batch 320, Loss: 1.9583
Batch 330, Loss: 2.0474
Batch 340, Loss: 2.0337
Batch 350, Loss: 2.0127
Batch 360, Loss: 2.0447
Batch 370, Loss: 2.0685
Batch 380, Loss: 2.0231
Batch 390, Loss: 1.9657
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.199026346206665 seconds
Epoch 8 accuracy: 43.21%
Batch 10, Loss: 1.9620
Batch 20, Loss: 1.9909
Batch 30, Loss: 2.0111
Batch 40, Loss: 2.0242
Batch 50, Loss: 1.9911
Batch 60, Loss: 1.9954
Batch 70, Loss: 1.9951
Batch 80, Loss: 1.9167
Batch 90, Loss: 1.9465
Batch 100, Loss: 1.9841
Batch 110, Loss: 2.0077
Batch 120, Loss: 2.0089
Batch 130, Loss: 1.9330
Batch 140, Loss: 2.0053
Batch 150, Loss: 2.0030
Batch 160, Loss: 2.0338
Batch 170, Loss: 1.9658
Batch 180, Loss: 1.9133
Batch 190, Loss: 1.9499
Batch 200, Loss: 1.9607
Batch 210, Loss: 1.9469
Batch 220, Loss: 1.9664
Batch 230, Loss: 2.0545
Batch 240, Loss: 1.9506
Batch 250, Loss: 2.0417
Batch 260, Loss: 1.9516
Batch 270, Loss: 1.9401
Batch 280, Loss: 1.9523
Batch 290, Loss: 2.0308
Batch 300, Loss: 2.0109
Batch 310, Loss: 1.9488
Batch 320, Loss: 1.9738
Batch 330, Loss: 1.9719
Batch 340, Loss: 1.9795
Batch 350, Loss: 1.9581
Batch 360, Loss: 1.9085
Batch 370, Loss: 1.9780
Batch 380, Loss: 1.9325
Batch 390, Loss: 1.9721
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.198282718658447 seconds
Epoch 9 accuracy: 46.95%
Batch 10, Loss: 1.9788
Batch 20, Loss: 1.9360
Batch 30, Loss: 1.8331
Batch 40, Loss: 1.9075
Batch 50, Loss: 1.9572
Batch 60, Loss: 1.9198
Batch 70, Loss: 1.8968
Batch 80, Loss: 1.8691
Batch 90, Loss: 1.8762
Batch 100, Loss: 1.8988
Batch 110, Loss: 1.9263
Batch 120, Loss: 1.8987
Batch 130, Loss: 1.9148
Batch 140, Loss: 1.8769
Batch 150, Loss: 1.9301
Batch 160, Loss: 1.9241
Batch 170, Loss: 1.8973
Batch 180, Loss: 1.9318
Batch 190, Loss: 1.8559
Batch 200, Loss: 1.9551
Batch 210, Loss: 1.9029
Batch 220, Loss: 1.8927
Batch 230, Loss: 1.9129
Batch 240, Loss: 1.8721
Batch 250, Loss: 1.8561
Batch 260, Loss: 1.9780
Batch 270, Loss: 1.8484
Batch 280, Loss: 1.8821
Batch 290, Loss: 1.8371
Batch 300, Loss: 1.9187
Batch 310, Loss: 1.9196
Batch 320, Loss: 1.8955
Batch 330, Loss: 1.8493
Batch 340, Loss: 1.9152
Batch 350, Loss: 1.8521
Batch 360, Loss: 1.9418
Batch 370, Loss: 1.8916
Batch 380, Loss: 1.8458
Batch 390, Loss: 1.8712
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.233920335769653 seconds
Epoch 10 accuracy: 50.24%
Batch 10, Loss: 1.8103
Batch 20, Loss: 1.8379
Batch 30, Loss: 1.8541
Batch 40, Loss: 1.8631
Batch 50, Loss: 1.8180
Batch 60, Loss: 1.8343
Batch 70, Loss: 1.8814
Batch 80, Loss: 1.8171
Batch 90, Loss: 1.8646
Batch 100, Loss: 1.7743
Batch 110, Loss: 1.8348
Batch 120, Loss: 1.8247
Batch 130, Loss: 1.9245
Batch 140, Loss: 1.8907
Batch 150, Loss: 1.8277
Batch 160, Loss: 1.8821
Batch 170, Loss: 1.8950
Batch 180, Loss: 1.8263
Batch 190, Loss: 1.8742
Batch 200, Loss: 1.8552
Batch 210, Loss: 1.8958
Batch 220, Loss: 1.7729
Batch 230, Loss: 1.8052
Batch 240, Loss: 1.8118
Batch 250, Loss: 1.8222
Batch 260, Loss: 1.8590
Batch 270, Loss: 1.8832
Batch 280, Loss: 1.8624
Batch 290, Loss: 1.8410
Batch 300, Loss: 1.8764
Batch 310, Loss: 1.8543
Batch 320, Loss: 1.8732
Batch 330, Loss: 1.9011
Batch 340, Loss: 1.8239
Batch 350, Loss: 1.8611
Batch 360, Loss: 1.8334
Batch 370, Loss: 1.8254
Batch 380, Loss: 1.8433
Batch 390, Loss: 1.7757
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.304348468780518 seconds
Epoch 11 accuracy: 42.0%
Batch 10, Loss: 1.7424
Batch 20, Loss: 1.7584
Batch 30, Loss: 1.7436
Batch 40, Loss: 1.8138
Batch 50, Loss: 1.8539
Batch 60, Loss: 1.8281
Batch 70, Loss: 1.7823
Batch 80, Loss: 1.7370
Batch 90, Loss: 1.8276
Batch 100, Loss: 1.7684
Batch 110, Loss: 1.7742
Batch 120, Loss: 1.7895
Batch 130, Loss: 1.7819
Batch 140, Loss: 1.8232
Batch 150, Loss: 1.7880
Batch 160, Loss: 1.8306
Batch 170, Loss: 1.8990
Batch 180, Loss: 1.8047
Batch 190, Loss: 1.7909
Batch 200, Loss: 1.7878
Batch 210, Loss: 1.8249
Batch 220, Loss: 1.8384
Batch 230, Loss: 1.8490
Batch 240, Loss: 1.8380
Batch 250, Loss: 1.8604
Batch 260, Loss: 1.8733
Batch 270, Loss: 1.8607
Batch 280, Loss: 1.8067
Batch 290, Loss: 1.7866
Batch 300, Loss: 1.8441
Batch 310, Loss: 1.8571
Batch 320, Loss: 1.8486
Batch 330, Loss: 1.7580
Batch 340, Loss: 1.7657
Batch 350, Loss: 1.7988
Batch 360, Loss: 1.8067
Batch 370, Loss: 1.7548
Batch 380, Loss: 1.8332
Batch 390, Loss: 1.8488
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.174739122390747 seconds
Epoch 12 accuracy: 50.49%
Batch 10, Loss: 1.6827
Batch 20, Loss: 1.7388
Batch 30, Loss: 1.7689
Batch 40, Loss: 1.7168
Batch 50, Loss: 1.7442
Batch 60, Loss: 1.7637
Batch 70, Loss: 1.7556
Batch 80, Loss: 1.7218
Batch 90, Loss: 1.7223
Batch 100, Loss: 1.7673
Batch 110, Loss: 1.7807
Batch 120, Loss: 1.7492
Batch 130, Loss: 1.7938
Batch 140, Loss: 1.7454
Batch 150, Loss: 1.7991
Batch 160, Loss: 1.7523
Batch 170, Loss: 1.7286
Batch 180, Loss: 1.7801
Batch 190, Loss: 1.7799
Batch 200, Loss: 1.8184
Batch 210, Loss: 1.7796
Batch 220, Loss: 1.7684
Batch 230, Loss: 1.7805
Batch 240, Loss: 1.7749
Batch 250, Loss: 1.7970
Batch 260, Loss: 1.7763
Batch 270, Loss: 1.7471
Batch 280, Loss: 1.8119
Batch 290, Loss: 1.7961
Batch 300, Loss: 1.8110
Batch 310, Loss: 1.8116
Batch 320, Loss: 1.7806
Batch 330, Loss: 1.7598
Batch 340, Loss: 1.7854
Batch 350, Loss: 1.7192
Batch 360, Loss: 1.7783
Batch 370, Loss: 1.7362
Batch 380, Loss: 1.7380
Batch 390, Loss: 1.7823
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.134737968444824 seconds
Epoch 13 accuracy: 50.33%
Batch 10, Loss: 1.7515
Batch 20, Loss: 1.7218
Batch 30, Loss: 1.7346
Batch 40, Loss: 1.6942
Batch 50, Loss: 1.7248
Batch 60, Loss: 1.6701
Batch 70, Loss: 1.7145
Batch 80, Loss: 1.6754
Batch 90, Loss: 1.7139
Batch 100, Loss: 1.7421
Batch 110, Loss: 1.7756
Batch 120, Loss: 1.6217
Batch 130, Loss: 1.7511
Batch 140, Loss: 1.7492
Batch 150, Loss: 1.7632
Batch 160, Loss: 1.7805
Batch 170, Loss: 1.7738
Batch 180, Loss: 1.7309
Batch 190, Loss: 1.6578
Batch 200, Loss: 1.7354
Batch 210, Loss: 1.7260
Batch 220, Loss: 1.7092
Batch 230, Loss: 1.7021
Batch 240, Loss: 1.7735
Batch 250, Loss: 1.7717
Batch 260, Loss: 1.7419
Batch 270, Loss: 1.7149
Batch 280, Loss: 1.7693
Batch 290, Loss: 1.7646
Batch 300, Loss: 1.7660
Batch 310, Loss: 1.8186
Batch 320, Loss: 1.7238
Batch 330, Loss: 1.7709
Batch 340, Loss: 1.6802
Batch 350, Loss: 1.6999
Batch 360, Loss: 1.7730
Batch 370, Loss: 1.7564
Batch 380, Loss: 1.7572
Batch 390, Loss: 1.7303
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.192272424697876 seconds
Epoch 14 accuracy: 52.2%
Batch 10, Loss: 1.6052
Batch 20, Loss: 1.6491
Batch 30, Loss: 1.7245
Batch 40, Loss: 1.7270
Batch 50, Loss: 1.6599
Batch 60, Loss: 1.6809
Batch 70, Loss: 1.6904
Batch 80, Loss: 1.6906
Batch 90, Loss: 1.7556
Batch 100, Loss: 1.7036
Batch 110, Loss: 1.6574
Batch 120, Loss: 1.7217
Batch 130, Loss: 1.6742
Batch 140, Loss: 1.6122
Batch 150, Loss: 1.6644
Batch 160, Loss: 1.7123
Batch 170, Loss: 1.7282
Batch 180, Loss: 1.7039
Batch 190, Loss: 1.7346
Batch 200, Loss: 1.6560
Batch 210, Loss: 1.7123
Batch 220, Loss: 1.6996
Batch 230, Loss: 1.7615
Batch 240, Loss: 1.6478
Batch 250, Loss: 1.6400
Batch 260, Loss: 1.7157
Batch 270, Loss: 1.7080
Batch 280, Loss: 1.7716
Batch 290, Loss: 1.7617
Batch 300, Loss: 1.6889
Batch 310, Loss: 1.7134
Batch 320, Loss: 1.8001
Batch 330, Loss: 1.7260
Batch 340, Loss: 1.7072
Batch 350, Loss: 1.8026
Batch 360, Loss: 1.7353
Batch 370, Loss: 1.7104
Batch 380, Loss: 1.7103
Batch 390, Loss: 1.6958
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.322243213653564 seconds
Epoch 15 accuracy: 50.55%
Batch 10, Loss: 1.6522
Batch 20, Loss: 1.5807
Batch 30, Loss: 1.6644
Batch 40, Loss: 1.7151
Batch 50, Loss: 1.6339
Batch 60, Loss: 1.7007
Batch 70, Loss: 1.6792
Batch 80, Loss: 1.6319
Batch 90, Loss: 1.7537
Batch 100, Loss: 1.6858
Batch 110, Loss: 1.6913
Batch 120, Loss: 1.7086
Batch 130, Loss: 1.7412
Batch 140, Loss: 1.7125
Batch 150, Loss: 1.6995
Batch 160, Loss: 1.6793
Batch 170, Loss: 1.6780
Batch 180, Loss: 1.7123
Batch 190, Loss: 1.6740
Batch 200, Loss: 1.6873
Batch 210, Loss: 1.6787
Batch 220, Loss: 1.7221
Batch 230, Loss: 1.6451
Batch 240, Loss: 1.6438
Batch 250, Loss: 1.7071
Batch 260, Loss: 1.7171
Batch 270, Loss: 1.6747
Batch 280, Loss: 1.6613
Batch 290, Loss: 1.7622
Batch 300, Loss: 1.7038
Batch 310, Loss: 1.6807
Batch 320, Loss: 1.6353
Batch 330, Loss: 1.6866
Batch 340, Loss: 1.7228
Batch 350, Loss: 1.6735
Batch 360, Loss: 1.6875
Batch 370, Loss: 1.6523
Batch 380, Loss: 1.6925
Batch 390, Loss: 1.6861
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.125632286071777 seconds
Epoch 16 accuracy: 53.0%
Batch 10, Loss: 1.6174
Batch 20, Loss: 1.5466
Batch 30, Loss: 1.6138
Batch 40, Loss: 1.6462
Batch 50, Loss: 1.6226
Batch 60, Loss: 1.7324
Batch 70, Loss: 1.6535
Batch 80, Loss: 1.6247
Batch 90, Loss: 1.6909
Batch 100, Loss: 1.7001
Batch 110, Loss: 1.6813
Batch 120, Loss: 1.6445
Batch 130, Loss: 1.6599
Batch 140, Loss: 1.6397
Batch 150, Loss: 1.7204
Batch 160, Loss: 1.6175
Batch 170, Loss: 1.6698
Batch 180, Loss: 1.7146
Batch 190, Loss: 1.6267
Batch 200, Loss: 1.7136
Batch 210, Loss: 1.7020
Batch 220, Loss: 1.6893
Batch 230, Loss: 1.6474
Batch 240, Loss: 1.7170
Batch 250, Loss: 1.7042
Batch 260, Loss: 1.6930
Batch 270, Loss: 1.6399
Batch 280, Loss: 1.7052
Batch 290, Loss: 1.6600
Batch 300, Loss: 1.6803
Batch 310, Loss: 1.6573
Batch 320, Loss: 1.7446
Batch 330, Loss: 1.6894
Batch 340, Loss: 1.6479
Batch 350, Loss: 1.6893
Batch 360, Loss: 1.6788
Batch 370, Loss: 1.6877
Batch 380, Loss: 1.6478
Batch 390, Loss: 1.6087
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.190680503845215 seconds
Epoch 17 accuracy: 54.3%
Batch 10, Loss: 1.5681
Batch 20, Loss: 1.6448
Batch 30, Loss: 1.5808
Batch 40, Loss: 1.6130
Batch 50, Loss: 1.6520
Batch 60, Loss: 1.6160
Batch 70, Loss: 1.6289
Batch 80, Loss: 1.6604
Batch 90, Loss: 1.6372
Batch 100, Loss: 1.6732
Batch 110, Loss: 1.6543
Batch 120, Loss: 1.5715
Batch 130, Loss: 1.5584
Batch 140, Loss: 1.6887
Batch 150, Loss: 1.6428
Batch 160, Loss: 1.6087
Batch 170, Loss: 1.5562
Batch 180, Loss: 1.6346
Batch 190, Loss: 1.6953
Batch 200, Loss: 1.6087
Batch 210, Loss: 1.6070
Batch 220, Loss: 1.6986
Batch 230, Loss: 1.6218
Batch 240, Loss: 1.6513
Batch 250, Loss: 1.6974
Batch 260, Loss: 1.6565
Batch 270, Loss: 1.6518
Batch 280, Loss: 1.7218
Batch 290, Loss: 1.6902
Batch 300, Loss: 1.6500
Batch 310, Loss: 1.6992
Batch 320, Loss: 1.6857
Batch 330, Loss: 1.6590
Batch 340, Loss: 1.7608
Batch 350, Loss: 1.7478
Batch 360, Loss: 1.5814
Batch 370, Loss: 1.6374
Batch 380, Loss: 1.6536
Batch 390, Loss: 1.6876
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.156638145446777 seconds
Epoch 18 accuracy: 54.38%
Batch 10, Loss: 1.6001
Batch 20, Loss: 1.5470
Batch 30, Loss: 1.7049
Batch 40, Loss: 1.6409
Batch 50, Loss: 1.5469
Batch 60, Loss: 1.6235
Batch 70, Loss: 1.5832
Batch 80, Loss: 1.6524
Batch 90, Loss: 1.6619
Batch 100, Loss: 1.6742
Batch 110, Loss: 1.6282
Batch 120, Loss: 1.6015
Batch 130, Loss: 1.6419
Batch 140, Loss: 1.6249
Batch 150, Loss: 1.5436
Batch 160, Loss: 1.6625
Batch 170, Loss: 1.6020
Batch 180, Loss: 1.6101
Batch 190, Loss: 1.6421
Batch 200, Loss: 1.6191
Batch 210, Loss: 1.6020
Batch 220, Loss: 1.6665
Batch 230, Loss: 1.7073
Batch 240, Loss: 1.6053
Batch 250, Loss: 1.6107
Batch 260, Loss: 1.6207
Batch 270, Loss: 1.6071
Batch 280, Loss: 1.6049
Batch 290, Loss: 1.6375
Batch 300, Loss: 1.6554
Batch 310, Loss: 1.6227
Batch 320, Loss: 1.6495
Batch 330, Loss: 1.6353
Batch 340, Loss: 1.5589
Batch 350, Loss: 1.6346
Batch 360, Loss: 1.6356
Batch 370, Loss: 1.6217
Batch 380, Loss: 1.6253
Batch 390, Loss: 1.6222
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.153077125549316 seconds
Epoch 19 accuracy: 52.26%
Batch 10, Loss: 1.6148
Batch 20, Loss: 1.5460
Batch 30, Loss: 1.5871
Batch 40, Loss: 1.5917
Batch 50, Loss: 1.6742
Batch 60, Loss: 1.5257
Batch 70, Loss: 1.5872
Batch 80, Loss: 1.6082
Batch 90, Loss: 1.6655
Batch 100, Loss: 1.5870
Batch 110, Loss: 1.5689
Batch 120, Loss: 1.6221
Batch 130, Loss: 1.6424
Batch 140, Loss: 1.6073
Batch 150, Loss: 1.6485
Batch 160, Loss: 1.6761
Batch 170, Loss: 1.5991
Batch 180, Loss: 1.6144
Batch 190, Loss: 1.5899
Batch 200, Loss: 1.5855
Batch 210, Loss: 1.6126
Batch 220, Loss: 1.6426
Batch 230, Loss: 1.5878
Batch 240, Loss: 1.5896
Batch 250, Loss: 1.5676
Batch 260, Loss: 1.6383
Batch 270, Loss: 1.5461
Batch 280, Loss: 1.6133
Batch 290, Loss: 1.5906
Batch 300, Loss: 1.6351
Batch 310, Loss: 1.6640
Batch 320, Loss: 1.6068
Batch 330, Loss: 1.6892
Batch 340, Loss: 1.6092
Batch 350, Loss: 1.6454
Batch 360, Loss: 1.6300
Batch 370, Loss: 1.6473
Batch 380, Loss: 1.5979
Batch 390, Loss: 1.6139
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.210991382598877 seconds
Epoch 20 accuracy: 51.82%
Batch 10, Loss: 1.5878
Batch 20, Loss: 1.5732
Batch 30, Loss: 1.5412
Batch 40, Loss: 1.5717
Batch 50, Loss: 1.5887
Batch 60, Loss: 1.6310
Batch 70, Loss: 1.5353
Batch 80, Loss: 1.5686
Batch 90, Loss: 1.6073
Batch 100, Loss: 1.6234
Batch 110, Loss: 1.5851
Batch 120, Loss: 1.6257
Batch 130, Loss: 1.6447
Batch 140, Loss: 1.6287
Batch 150, Loss: 1.6131
Batch 160, Loss: 1.5971
Batch 170, Loss: 1.5662
Batch 180, Loss: 1.5699
Batch 190, Loss: 1.6342
Batch 200, Loss: 1.6123
Batch 210, Loss: 1.6433
Batch 220, Loss: 1.6162
Batch 230, Loss: 1.5983
Batch 240, Loss: 1.5908
Batch 250, Loss: 1.6137
Batch 260, Loss: 1.6331
Batch 270, Loss: 1.7134
Batch 280, Loss: 1.6038
Batch 290, Loss: 1.6348
Batch 300, Loss: 1.6698
Batch 310, Loss: 1.6273
Batch 320, Loss: 1.5885
Batch 330, Loss: 1.5553
Batch 340, Loss: 1.5925
Batch 350, Loss: 1.5760
Batch 360, Loss: 1.5706
Batch 370, Loss: 1.6085
Batch 380, Loss: 1.6437
Batch 390, Loss: 1.5644
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.286201000213623 seconds
Epoch 21 accuracy: 52.81%
Batch 10, Loss: 1.5249
Batch 20, Loss: 1.5284
Batch 30, Loss: 1.5508
Batch 40, Loss: 1.5579
Batch 50, Loss: 1.6632
Batch 60, Loss: 1.5997
Batch 70, Loss: 1.5682
Batch 80, Loss: 1.5514
Batch 90, Loss: 1.4950
Batch 100, Loss: 1.5359
Batch 110, Loss: 1.5301
Batch 120, Loss: 1.5775
Batch 130, Loss: 1.5316
Batch 140, Loss: 1.5490
Batch 150, Loss: 1.6092
Batch 160, Loss: 1.6030
Batch 170, Loss: 1.6144
Batch 180, Loss: 1.5492
Batch 190, Loss: 1.6161
Batch 200, Loss: 1.6082
Batch 210, Loss: 1.5490
Batch 220, Loss: 1.6084
Batch 230, Loss: 1.6139
Batch 240, Loss: 1.5978
Batch 250, Loss: 1.6417
Batch 260, Loss: 1.6243
Batch 270, Loss: 1.5637
Batch 280, Loss: 1.6081
Batch 290, Loss: 1.6500
Batch 300, Loss: 1.6160
Batch 310, Loss: 1.5787
Batch 320, Loss: 1.5830
Batch 330, Loss: 1.6549
Batch 340, Loss: 1.5912
Batch 350, Loss: 1.5585
Batch 360, Loss: 1.6165
Batch 370, Loss: 1.5861
Batch 380, Loss: 1.6439
Batch 390, Loss: 1.6265
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.20430064201355 seconds
Epoch 22 accuracy: 55.04%
Batch 10, Loss: 1.5926
Batch 20, Loss: 1.5712
Batch 30, Loss: 1.5161
Batch 40, Loss: 1.5772
Batch 50, Loss: 1.5804
Batch 60, Loss: 1.5555
Batch 70, Loss: 1.5483
Batch 80, Loss: 1.5305
Batch 90, Loss: 1.5060
Batch 100, Loss: 1.5354
Batch 110, Loss: 1.5671
Batch 120, Loss: 1.6540
Batch 130, Loss: 1.6346
Batch 140, Loss: 1.5813
Batch 150, Loss: 1.5737
Batch 160, Loss: 1.6347
Batch 170, Loss: 1.5994
Batch 180, Loss: 1.5536
Batch 190, Loss: 1.5254
Batch 200, Loss: 1.5827
Batch 210, Loss: 1.5556
Batch 220, Loss: 1.5974
Batch 230, Loss: 1.5755
Batch 240, Loss: 1.5631
Batch 250, Loss: 1.6340
Batch 260, Loss: 1.5974
Batch 270, Loss: 1.6244
Batch 280, Loss: 1.5417
Batch 290, Loss: 1.5356
Batch 300, Loss: 1.6225
Batch 310, Loss: 1.6216
Batch 320, Loss: 1.5448
Batch 330, Loss: 1.5562
Batch 340, Loss: 1.5611
Batch 350, Loss: 1.6784
Batch 360, Loss: 1.6012
Batch 370, Loss: 1.6329
Batch 380, Loss: 1.6277
Batch 390, Loss: 1.5631
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.08322525024414 seconds
Epoch 23 accuracy: 49.13%
Batch 10, Loss: 1.5070
Batch 20, Loss: 1.5175
Batch 30, Loss: 1.5189
Batch 40, Loss: 1.5485
Batch 50, Loss: 1.4943
Batch 60, Loss: 1.5440
Batch 70, Loss: 1.5588
Batch 80, Loss: 1.5090
Batch 90, Loss: 1.5478
Batch 100, Loss: 1.5626
Batch 110, Loss: 1.6099
Batch 120, Loss: 1.6129
Batch 130, Loss: 1.4736
Batch 140, Loss: 1.5157
Batch 150, Loss: 1.5856
Batch 160, Loss: 1.6131
Batch 170, Loss: 1.5013
Batch 180, Loss: 1.6309
Batch 190, Loss: 1.5727
Batch 200, Loss: 1.6052
Batch 210, Loss: 1.5551
Batch 220, Loss: 1.5645
Batch 230, Loss: 1.5825
Batch 240, Loss: 1.5867
Batch 250, Loss: 1.5717
Batch 260, Loss: 1.5305
Batch 270, Loss: 1.5279
Batch 280, Loss: 1.5519
Batch 290, Loss: 1.5831
Batch 300, Loss: 1.6066
Batch 310, Loss: 1.5685
Batch 320, Loss: 1.5646
Batch 330, Loss: 1.5452
Batch 340, Loss: 1.5375
Batch 350, Loss: 1.5948
Batch 360, Loss: 1.6252
Batch 370, Loss: 1.6492
Batch 380, Loss: 1.5659
Batch 390, Loss: 1.6230
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.319518566131592 seconds
Epoch 24 accuracy: 55.01%
Batch 10, Loss: 1.5417
Batch 20, Loss: 1.5955
Batch 30, Loss: 1.5324
Batch 40, Loss: 1.5015
Batch 50, Loss: 1.5227
Batch 60, Loss: 1.4736
Batch 70, Loss: 1.5426
Batch 80, Loss: 1.5680
Batch 90, Loss: 1.5208
Batch 100, Loss: 1.5635
Batch 110, Loss: 1.5061
Batch 120, Loss: 1.5056
Batch 130, Loss: 1.5224
Batch 140, Loss: 1.5834
Batch 150, Loss: 1.5542
Batch 160, Loss: 1.5392
Batch 170, Loss: 1.6201
Batch 180, Loss: 1.6951
Batch 190, Loss: 1.5490
Batch 200, Loss: 1.5976
Batch 210, Loss: 1.5864
Batch 220, Loss: 1.5155
Batch 230, Loss: 1.5192
Batch 240, Loss: 1.5667
Batch 250, Loss: 1.5271
Batch 260, Loss: 1.5517
Batch 270, Loss: 1.6082
Batch 280, Loss: 1.5460
Batch 290, Loss: 1.5563
Batch 300, Loss: 1.5342
Batch 310, Loss: 1.5781
Batch 320, Loss: 1.5315
Batch 330, Loss: 1.5769
Batch 340, Loss: 1.6054
Batch 350, Loss: 1.5296
Batch 360, Loss: 1.6141
Batch 370, Loss: 1.6485
Batch 380, Loss: 1.5513
Batch 390, Loss: 1.5732
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.156238317489624 seconds
Epoch 25 accuracy: 57.45%
Batch 10, Loss: 1.4565
Batch 20, Loss: 1.5104
Batch 30, Loss: 1.4913
Batch 40, Loss: 1.4846
Batch 50, Loss: 1.5533
Batch 60, Loss: 1.5314
Batch 70, Loss: 1.4932
Batch 80, Loss: 1.5714
Batch 90, Loss: 1.5148
Batch 100, Loss: 1.4980
Batch 110, Loss: 1.5744
Batch 120, Loss: 1.5213
Batch 130, Loss: 1.5832
Batch 140, Loss: 1.4733
Batch 150, Loss: 1.5316
Batch 160, Loss: 1.6275
Batch 170, Loss: 1.5605
Batch 180, Loss: 1.5408
Batch 190, Loss: 1.5239
Batch 200, Loss: 1.5459
Batch 210, Loss: 1.5603
Batch 220, Loss: 1.5120
Batch 230, Loss: 1.4975
Batch 240, Loss: 1.5163
Batch 250, Loss: 1.5937
Batch 260, Loss: 1.6108
Batch 270, Loss: 1.5672
Batch 280, Loss: 1.5266
Batch 290, Loss: 1.5123
Batch 300, Loss: 1.6743
Batch 310, Loss: 1.5859
Batch 320, Loss: 1.5176
Batch 330, Loss: 1.5120
Batch 340, Loss: 1.5487
Batch 350, Loss: 1.5405
Batch 360, Loss: 1.5496
Batch 370, Loss: 1.5884
Batch 380, Loss: 1.5509
Batch 390, Loss: 1.5505
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.2089626789093 seconds
Epoch 26 accuracy: 56.49%
Batch 10, Loss: 1.4694
Batch 20, Loss: 1.5179
Batch 30, Loss: 1.5102
Batch 40, Loss: 1.5621
Batch 50, Loss: 1.5586
Batch 60, Loss: 1.5204
Batch 70, Loss: 1.5087
Batch 80, Loss: 1.5295
Batch 90, Loss: 1.4717
Batch 100, Loss: 1.4853
Batch 110, Loss: 1.5842
Batch 120, Loss: 1.4702
Batch 130, Loss: 1.5616
Batch 140, Loss: 1.4774
Batch 150, Loss: 1.5868
Batch 160, Loss: 1.5354
Batch 170, Loss: 1.5334
Batch 180, Loss: 1.5998
Batch 190, Loss: 1.5426
Batch 200, Loss: 1.5162
Batch 210, Loss: 1.5671
Batch 220, Loss: 1.5852
Batch 230, Loss: 1.5718
Batch 240, Loss: 1.5584
Batch 250, Loss: 1.5125
Batch 260, Loss: 1.5720
Batch 270, Loss: 1.5672
Batch 280, Loss: 1.5004
Batch 290, Loss: 1.5323
Batch 300, Loss: 1.5160
Batch 310, Loss: 1.5556
Batch 320, Loss: 1.5533
Batch 330, Loss: 1.5458
Batch 340, Loss: 1.5548
Batch 350, Loss: 1.4785
Batch 360, Loss: 1.5819
Batch 370, Loss: 1.6087
Batch 380, Loss: 1.5335
Batch 390, Loss: 1.5223
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.25957417488098 seconds
Epoch 27 accuracy: 53.3%
Batch 10, Loss: 1.4841
Batch 20, Loss: 1.5039
Batch 30, Loss: 1.4821
Batch 40, Loss: 1.4656
Batch 50, Loss: 1.4547
Batch 60, Loss: 1.4245
Batch 70, Loss: 1.5201
Batch 80, Loss: 1.4697
Batch 90, Loss: 1.5368
Batch 100, Loss: 1.5760
Batch 110, Loss: 1.5707
Batch 120, Loss: 1.5338
Batch 130, Loss: 1.4971
Batch 140, Loss: 1.4976
Batch 150, Loss: 1.5349
Batch 160, Loss: 1.5344
Batch 170, Loss: 1.5365
Batch 180, Loss: 1.5523
Batch 190, Loss: 1.4902
Batch 200, Loss: 1.5208
Batch 210, Loss: 1.5730
Batch 220, Loss: 1.5715
Batch 230, Loss: 1.5356
Batch 240, Loss: 1.5226
Batch 250, Loss: 1.5970
Batch 260, Loss: 1.5690
Batch 270, Loss: 1.5510
Batch 280, Loss: 1.4923
Batch 290, Loss: 1.5106
Batch 300, Loss: 1.5063
Batch 310, Loss: 1.5773
Batch 320, Loss: 1.6115
Batch 330, Loss: 1.5637
Batch 340, Loss: 1.5182
Batch 350, Loss: 1.5688
Batch 360, Loss: 1.4621
Batch 370, Loss: 1.5534
Batch 380, Loss: 1.6015
Batch 390, Loss: 1.5354
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.198918342590332 seconds
Epoch 28 accuracy: 59.2%
Batch 10, Loss: 1.4617
Batch 20, Loss: 1.4885
Batch 30, Loss: 1.4539
Batch 40, Loss: 1.4344
Batch 50, Loss: 1.4339
Batch 60, Loss: 1.4979
Batch 70, Loss: 1.5196
Batch 80, Loss: 1.4514
Batch 90, Loss: 1.4395
Batch 100, Loss: 1.4923
Batch 110, Loss: 1.5614
Batch 120, Loss: 1.5269
Batch 130, Loss: 1.5444
Batch 140, Loss: 1.5189
Batch 150, Loss: 1.4629
Batch 160, Loss: 1.5103
Batch 170, Loss: 1.5711
Batch 180, Loss: 1.5379
Batch 190, Loss: 1.5645
Batch 200, Loss: 1.5050
Batch 210, Loss: 1.6038
Batch 220, Loss: 1.5688
Batch 230, Loss: 1.6017
Batch 240, Loss: 1.5532
Batch 250, Loss: 1.5783
Batch 260, Loss: 1.5597
Batch 270, Loss: 1.5489
Batch 280, Loss: 1.4917
Batch 290, Loss: 1.5461
Batch 300, Loss: 1.4844
Batch 310, Loss: 1.4904
Batch 320, Loss: 1.5381
Batch 330, Loss: 1.5535
Batch 340, Loss: 1.5358
Batch 350, Loss: 1.5204
Batch 360, Loss: 1.5762
Batch 370, Loss: 1.4717
Batch 380, Loss: 1.5252
Batch 390, Loss: 1.5601
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.225126028060913 seconds
Epoch 29 accuracy: 52.96%
Batch 10, Loss: 1.5165
Batch 20, Loss: 1.4129
Batch 30, Loss: 1.4758
Batch 40, Loss: 1.4944
Batch 50, Loss: 1.4758
Batch 60, Loss: 1.4830
Batch 70, Loss: 1.4454
Batch 80, Loss: 1.4366
Batch 90, Loss: 1.5202
Batch 100, Loss: 1.5641
Batch 110, Loss: 1.5512
Batch 120, Loss: 1.5554
Batch 130, Loss: 1.5173
Batch 140, Loss: 1.5033
Batch 150, Loss: 1.5355
Batch 160, Loss: 1.4979
Batch 170, Loss: 1.4905
Batch 180, Loss: 1.5083
Batch 190, Loss: 1.5311
Batch 200, Loss: 1.5394
Batch 210, Loss: 1.4868
Batch 220, Loss: 1.5361
Batch 230, Loss: 1.5467
Batch 240, Loss: 1.6032
Batch 250, Loss: 1.5546
Batch 260, Loss: 1.5366
Batch 270, Loss: 1.5101
Batch 280, Loss: 1.5534
Batch 290, Loss: 1.5122
Batch 300, Loss: 1.5392
Batch 310, Loss: 1.4985
Batch 320, Loss: 1.4075
Batch 330, Loss: 1.5239
Batch 340, Loss: 1.5400
Batch 350, Loss: 1.5647
Batch 360, Loss: 1.5235
Batch 370, Loss: 1.5417
Batch 380, Loss: 1.5404
Batch 390, Loss: 1.5678
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.082449436187744 seconds
Epoch 30 accuracy: 55.58%
Batch 10, Loss: 1.5143
Batch 20, Loss: 1.4690
Batch 30, Loss: 1.4979
Batch 40, Loss: 1.4937
Batch 50, Loss: 1.5399
Batch 60, Loss: 1.4461
Batch 70, Loss: 1.4842
Batch 80, Loss: 1.4409
Batch 90, Loss: 1.4585
Batch 100, Loss: 1.4528
Batch 110, Loss: 1.4633
Batch 120, Loss: 1.4399
Batch 130, Loss: 1.4728
Batch 140, Loss: 1.4335
Batch 150, Loss: 1.5419
Batch 160, Loss: 1.5762
Batch 170, Loss: 1.4859
Batch 180, Loss: 1.4912
Batch 190, Loss: 1.5716
Batch 200, Loss: 1.4492
Batch 210, Loss: 1.6242
Batch 220, Loss: 1.4734
Batch 230, Loss: 1.5182
Batch 240, Loss: 1.5078
Batch 250, Loss: 1.4997
Batch 260, Loss: 1.5242
Batch 270, Loss: 1.5380
Batch 280, Loss: 1.5635
Batch 290, Loss: 1.5238
Batch 300, Loss: 1.5675
Batch 310, Loss: 1.6078
Batch 320, Loss: 1.5622
Batch 330, Loss: 1.5163
Batch 340, Loss: 1.5842
Batch 350, Loss: 1.5378
Batch 360, Loss: 1.5040
Batch 370, Loss: 1.4755
Batch 380, Loss: 1.5219
Batch 390, Loss: 1.5756
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.12987732887268 seconds
Epoch 31 accuracy: 55.2%
Batch 10, Loss: 1.4901
Batch 20, Loss: 1.4587
Batch 30, Loss: 1.4175
Batch 40, Loss: 1.4659
Batch 50, Loss: 1.4198
Batch 60, Loss: 1.4557
Batch 70, Loss: 1.5459
Batch 80, Loss: 1.5557
Batch 90, Loss: 1.4637
Batch 100, Loss: 1.4357
Batch 110, Loss: 1.5186
Batch 120, Loss: 1.4736
Batch 130, Loss: 1.4830
Batch 140, Loss: 1.5292
Batch 150, Loss: 1.4088
Batch 160, Loss: 1.4500
Batch 170, Loss: 1.4768
Batch 180, Loss: 1.5116
Batch 190, Loss: 1.5211
Batch 200, Loss: 1.4660
Batch 210, Loss: 1.5779
Batch 220, Loss: 1.5162
Batch 230, Loss: 1.5340
Batch 240, Loss: 1.5926
Batch 250, Loss: 1.5263
Batch 260, Loss: 1.5106
Batch 270, Loss: 1.5003
Batch 280, Loss: 1.4702
Batch 290, Loss: 1.5078
Batch 300, Loss: 1.4966
Batch 310, Loss: 1.5625
Batch 320, Loss: 1.5102
Batch 330, Loss: 1.5744
Batch 340, Loss: 1.5247
Batch 350, Loss: 1.5517
Batch 360, Loss: 1.5030
Batch 370, Loss: 1.5454
Batch 380, Loss: 1.5224
Batch 390, Loss: 1.5720
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.19663429260254 seconds
Epoch 32 accuracy: 54.91%
Batch 10, Loss: 1.4866
Batch 20, Loss: 1.4178
Batch 30, Loss: 1.4258
Batch 40, Loss: 1.4375
Batch 50, Loss: 1.4557
Batch 60, Loss: 1.4530
Batch 70, Loss: 1.4177
Batch 80, Loss: 1.4198
Batch 90, Loss: 1.4351
Batch 100, Loss: 1.4873
Batch 110, Loss: 1.5369
Batch 120, Loss: 1.4564
Batch 130, Loss: 1.4887
Batch 140, Loss: 1.5471
Batch 150, Loss: 1.4729
Batch 160, Loss: 1.4613
Batch 170, Loss: 1.4775
Batch 180, Loss: 1.5324
Batch 190, Loss: 1.4971
Batch 200, Loss: 1.5127
Batch 210, Loss: 1.5307
Batch 220, Loss: 1.4962
Batch 230, Loss: 1.4984
Batch 240, Loss: 1.4875
Batch 250, Loss: 1.4850
Batch 260, Loss: 1.4602
Batch 270, Loss: 1.5537
Batch 280, Loss: 1.5472
Batch 290, Loss: 1.5681
Batch 300, Loss: 1.4275
Batch 310, Loss: 1.4472
Batch 320, Loss: 1.5261
Batch 330, Loss: 1.5015
Batch 340, Loss: 1.5590
Batch 350, Loss: 1.5087
Batch 360, Loss: 1.5327
Batch 370, Loss: 1.5064
Batch 380, Loss: 1.4162
Batch 390, Loss: 1.5488
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.149365186691284 seconds
Epoch 33 accuracy: 58.07%
Batch 10, Loss: 1.4800
Batch 20, Loss: 1.5287
Batch 30, Loss: 1.4551
Batch 40, Loss: 1.3726
Batch 50, Loss: 1.4082
Batch 60, Loss: 1.3757
Batch 70, Loss: 1.5134
Batch 80, Loss: 1.4635
Batch 90, Loss: 1.4423
Batch 100, Loss: 1.4285
Batch 110, Loss: 1.4204
Batch 120, Loss: 1.4670
Batch 130, Loss: 1.4904
Batch 140, Loss: 1.4693
Batch 150, Loss: 1.5096
Batch 160, Loss: 1.5509
Batch 170, Loss: 1.5343
Batch 180, Loss: 1.4663
Batch 190, Loss: 1.4624
Batch 200, Loss: 1.4935
Batch 210, Loss: 1.5166
Batch 220, Loss: 1.5367
Batch 230, Loss: 1.5299
Batch 240, Loss: 1.4924
Batch 250, Loss: 1.4621
Batch 260, Loss: 1.5814
Batch 270, Loss: 1.5419
Batch 280, Loss: 1.5038
Batch 290, Loss: 1.5041
Batch 300, Loss: 1.4765
Batch 310, Loss: 1.5787
Batch 320, Loss: 1.4758
Batch 330, Loss: 1.5113
Batch 340, Loss: 1.4546
Batch 350, Loss: 1.5366
Batch 360, Loss: 1.5227
Batch 370, Loss: 1.4795
Batch 380, Loss: 1.5310
Batch 390, Loss: 1.5327
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.23624849319458 seconds
Epoch 34 accuracy: 56.14%
Batch 10, Loss: 1.4706
Batch 20, Loss: 1.4608
Batch 30, Loss: 1.4402
Batch 40, Loss: 1.5115
Batch 50, Loss: 1.3588
Batch 60, Loss: 1.4286
Batch 70, Loss: 1.4615
Batch 80, Loss: 1.4235
Batch 90, Loss: 1.4417
Batch 100, Loss: 1.4736
Batch 110, Loss: 1.4357
Batch 120, Loss: 1.4621
Batch 130, Loss: 1.4522
Batch 140, Loss: 1.5083
Batch 150, Loss: 1.4584
Batch 160, Loss: 1.4710
Batch 170, Loss: 1.4349
Batch 180, Loss: 1.4149
Batch 190, Loss: 1.5246
Batch 200, Loss: 1.5419
Batch 210, Loss: 1.4758
Batch 220, Loss: 1.5247
Batch 230, Loss: 1.4974
Batch 240, Loss: 1.4777
Batch 250, Loss: 1.4795
Batch 260, Loss: 1.4649
Batch 270, Loss: 1.4948
Batch 280, Loss: 1.5026
Batch 290, Loss: 1.4961
Batch 300, Loss: 1.5135
Batch 310, Loss: 1.5230
Batch 320, Loss: 1.5208
Batch 330, Loss: 1.4910
Batch 340, Loss: 1.4957
Batch 350, Loss: 1.4604
Batch 360, Loss: 1.5465
Batch 370, Loss: 1.4800
Batch 380, Loss: 1.5073
Batch 390, Loss: 1.5493
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.125272274017334 seconds
Epoch 35 accuracy: 53.64%
Batch 10, Loss: 1.4588
Batch 20, Loss: 1.4481
Batch 30, Loss: 1.4413
Batch 40, Loss: 1.4104
Batch 50, Loss: 1.4119
Batch 60, Loss: 1.4212
Batch 70, Loss: 1.4685
Batch 80, Loss: 1.4135
Batch 90, Loss: 1.4985
Batch 100, Loss: 1.4578
Batch 110, Loss: 1.4906
Batch 120, Loss: 1.4875
Batch 130, Loss: 1.4030
Batch 140, Loss: 1.4352
Batch 150, Loss: 1.4343
Batch 160, Loss: 1.4066
Batch 170, Loss: 1.5111
Batch 180, Loss: 1.4601
Batch 190, Loss: 1.4979
Batch 200, Loss: 1.4887
Batch 210, Loss: 1.4817
Batch 220, Loss: 1.4993
Batch 230, Loss: 1.5217
Batch 240, Loss: 1.5907
Batch 250, Loss: 1.5763
Batch 260, Loss: 1.5269
Batch 270, Loss: 1.4755
Batch 280, Loss: 1.4826
Batch 290, Loss: 1.5272
Batch 300, Loss: 1.4505
Batch 310, Loss: 1.4577
Batch 320, Loss: 1.4788
Batch 330, Loss: 1.5515
Batch 340, Loss: 1.4367
Batch 350, Loss: 1.4495
Batch 360, Loss: 1.4680
Batch 370, Loss: 1.4583
Batch 380, Loss: 1.4890
Batch 390, Loss: 1.4875
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.176701545715332 seconds
Epoch 36 accuracy: 56.08%
Batch 10, Loss: 1.3458
Batch 20, Loss: 1.4432
Batch 30, Loss: 1.4241
Batch 40, Loss: 1.4338
Batch 50, Loss: 1.4521
Batch 60, Loss: 1.4884
Batch 70, Loss: 1.5039
Batch 80, Loss: 1.5052
Batch 90, Loss: 1.4359
Batch 100, Loss: 1.4623
Batch 110, Loss: 1.5232
Batch 120, Loss: 1.4314
Batch 130, Loss: 1.4444
Batch 140, Loss: 1.4223
Batch 150, Loss: 1.5452
Batch 160, Loss: 1.4173
Batch 170, Loss: 1.5204
Batch 180, Loss: 1.4782
Batch 190, Loss: 1.4655
Batch 200, Loss: 1.5094
Batch 210, Loss: 1.4587
Batch 220, Loss: 1.4452
Batch 230, Loss: 1.5073
Batch 240, Loss: 1.4832
Batch 250, Loss: 1.5198
Batch 260, Loss: 1.5004
Batch 270, Loss: 1.4113
Batch 280, Loss: 1.4105
Batch 290, Loss: 1.4492
Batch 300, Loss: 1.5064
Batch 310, Loss: 1.5086
Batch 320, Loss: 1.4896
Batch 330, Loss: 1.5414
Batch 340, Loss: 1.5256
Batch 350, Loss: 1.4858
Batch 360, Loss: 1.5206
Batch 370, Loss: 1.4547
Batch 380, Loss: 1.4325
Batch 390, Loss: 1.5022
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.169132471084595 seconds
Epoch 37 accuracy: 55.27%
Batch 10, Loss: 1.4117
Batch 20, Loss: 1.4336
Batch 30, Loss: 1.3942
Batch 40, Loss: 1.4010
Batch 50, Loss: 1.4683
Batch 60, Loss: 1.4379
Batch 70, Loss: 1.4449
Batch 80, Loss: 1.4665
Batch 90, Loss: 1.4346
Batch 100, Loss: 1.4021
Batch 110, Loss: 1.4263
Batch 120, Loss: 1.4739
Batch 130, Loss: 1.4122
Batch 140, Loss: 1.5128
Batch 150, Loss: 1.4467
Batch 160, Loss: 1.4792
Batch 170, Loss: 1.4716
Batch 180, Loss: 1.5397
Batch 190, Loss: 1.4956
Batch 200, Loss: 1.5045
Batch 210, Loss: 1.5204
Batch 220, Loss: 1.3971
Batch 230, Loss: 1.4235
Batch 240, Loss: 1.4712
Batch 250, Loss: 1.5965
Batch 260, Loss: 1.5006
Batch 270, Loss: 1.4545
Batch 280, Loss: 1.5679
Batch 290, Loss: 1.4780
Batch 300, Loss: 1.4875
Batch 310, Loss: 1.4258
Batch 320, Loss: 1.5093
Batch 330, Loss: 1.4548
Batch 340, Loss: 1.4703
Batch 350, Loss: 1.4664
Batch 360, Loss: 1.4824
Batch 370, Loss: 1.4689
Batch 380, Loss: 1.5320
Batch 390, Loss: 1.4664
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.0934579372406 seconds
Epoch 38 accuracy: 50.75%
Batch 10, Loss: 1.5048
Batch 20, Loss: 1.4224
Batch 30, Loss: 1.4540
Batch 40, Loss: 1.3315
Batch 50, Loss: 1.4348
Batch 60, Loss: 1.4344
Batch 70, Loss: 1.4187
Batch 80, Loss: 1.4655
Batch 90, Loss: 1.4043
Batch 100, Loss: 1.3914
Batch 110, Loss: 1.3611
Batch 120, Loss: 1.4577
Batch 130, Loss: 1.4671
Batch 140, Loss: 1.5162
Batch 150, Loss: 1.4207
Batch 160, Loss: 1.4531
Batch 170, Loss: 1.4261
Batch 180, Loss: 1.4586
Batch 190, Loss: 1.4736
Batch 200, Loss: 1.5218
Batch 210, Loss: 1.4106
Batch 220, Loss: 1.4479
Batch 230, Loss: 1.4614
Batch 240, Loss: 1.4861
Batch 250, Loss: 1.5418
Batch 260, Loss: 1.4600
Batch 270, Loss: 1.4668
Batch 280, Loss: 1.5132
Batch 290, Loss: 1.4819
Batch 300, Loss: 1.4922
Batch 310, Loss: 1.4331
Batch 320, Loss: 1.4503
Batch 330, Loss: 1.4498
Batch 340, Loss: 1.5226
Batch 350, Loss: 1.4465
Batch 360, Loss: 1.5283
Batch 370, Loss: 1.4455
Batch 380, Loss: 1.4380
Batch 390, Loss: 1.5166
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.156442403793335 seconds
Epoch 39 accuracy: 53.77%
Batch 10, Loss: 1.4617
Batch 20, Loss: 1.4285
Batch 30, Loss: 1.4173
Batch 40, Loss: 1.3995
Batch 50, Loss: 1.4624
Batch 60, Loss: 1.4084
Batch 70, Loss: 1.4318
Batch 80, Loss: 1.3971
Batch 90, Loss: 1.4862
Batch 100, Loss: 1.4562
Batch 110, Loss: 1.4045
Batch 120, Loss: 1.4065
Batch 130, Loss: 1.4702
Batch 140, Loss: 1.4039
Batch 150, Loss: 1.4014
Batch 160, Loss: 1.4843
Batch 170, Loss: 1.4504
Batch 180, Loss: 1.4355
Batch 190, Loss: 1.4721
Batch 200, Loss: 1.4032
Batch 210, Loss: 1.4925
Batch 220, Loss: 1.4521
Batch 230, Loss: 1.4545
Batch 240, Loss: 1.4588
Batch 250, Loss: 1.5119
Batch 260, Loss: 1.5165
Batch 270, Loss: 1.4802
Batch 280, Loss: 1.4441
Batch 290, Loss: 1.5049
Batch 300, Loss: 1.4203
Batch 310, Loss: 1.4497
Batch 320, Loss: 1.4500
Batch 330, Loss: 1.4123
Batch 340, Loss: 1.4603
Batch 350, Loss: 1.4809
Batch 360, Loss: 1.4432
Batch 370, Loss: 1.4395
Batch 380, Loss: 1.4330
Batch 390, Loss: 1.4618
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.223738431930542 seconds
Epoch 40 accuracy: 55.63%
Batch 10, Loss: 1.3756
Batch 20, Loss: 1.3957
Batch 30, Loss: 1.4059
Batch 40, Loss: 1.4768
Batch 50, Loss: 1.3933
Batch 60, Loss: 1.3576
Batch 70, Loss: 1.4741
Batch 80, Loss: 1.3835
Batch 90, Loss: 1.4638
Batch 100, Loss: 1.3437
Batch 110, Loss: 1.4281
Batch 120, Loss: 1.4657
Batch 130, Loss: 1.4783
Batch 140, Loss: 1.5159
Batch 150, Loss: 1.4152
Batch 160, Loss: 1.4491
Batch 170, Loss: 1.4600
Batch 180, Loss: 1.4535
Batch 190, Loss: 1.4342
Batch 200, Loss: 1.4670
Batch 210, Loss: 1.4290
Batch 220, Loss: 1.4162
Batch 230, Loss: 1.4591
Batch 240, Loss: 1.5102
Batch 250, Loss: 1.4723
Batch 260, Loss: 1.4406
Batch 270, Loss: 1.4728
Batch 280, Loss: 1.4740
Batch 290, Loss: 1.4532
Batch 300, Loss: 1.4628
Batch 310, Loss: 1.5297
Batch 320, Loss: 1.5140
Batch 330, Loss: 1.4657
Batch 340, Loss: 1.4642
Batch 350, Loss: 1.5177
Batch 360, Loss: 1.3731
Batch 370, Loss: 1.4730
Batch 380, Loss: 1.4645
Batch 390, Loss: 1.4293
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.135685443878174 seconds
Epoch 41 accuracy: 58.85%
Batch 10, Loss: 1.4003
Batch 20, Loss: 1.4437
Batch 30, Loss: 1.3986
Batch 40, Loss: 1.4203
Batch 50, Loss: 1.3974
Batch 60, Loss: 1.4471
Batch 70, Loss: 1.4399
Batch 80, Loss: 1.3784
Batch 90, Loss: 1.4446
Batch 100, Loss: 1.3767
Batch 110, Loss: 1.3524
Batch 120, Loss: 1.4247
Batch 130, Loss: 1.3830
Batch 140, Loss: 1.4690
Batch 150, Loss: 1.4077
Batch 160, Loss: 1.4665
Batch 170, Loss: 1.4531
Batch 180, Loss: 1.4929
Batch 190, Loss: 1.4373
Batch 200, Loss: 1.3907
Batch 210, Loss: 1.4644
Batch 220, Loss: 1.4462
Batch 230, Loss: 1.3919
Batch 240, Loss: 1.4908
Batch 250, Loss: 1.4480
Batch 260, Loss: 1.4825
Batch 270, Loss: 1.5087
Batch 280, Loss: 1.4991
Batch 290, Loss: 1.4607
Batch 300, Loss: 1.4243
Batch 310, Loss: 1.4753
Batch 320, Loss: 1.5037
Batch 330, Loss: 1.4195
Batch 340, Loss: 1.4759
Batch 350, Loss: 1.4087
Batch 360, Loss: 1.5087
Batch 370, Loss: 1.4511
Batch 380, Loss: 1.5091
Batch 390, Loss: 1.4574
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.209416389465332 seconds
Epoch 42 accuracy: 52.45%
Batch 10, Loss: 1.3367
Batch 20, Loss: 1.4273
Batch 30, Loss: 1.4109
Batch 40, Loss: 1.3846
Batch 50, Loss: 1.4283
Batch 60, Loss: 1.4440
Batch 70, Loss: 1.3835
Batch 80, Loss: 1.4082
Batch 90, Loss: 1.4042
Batch 100, Loss: 1.4851
Batch 110, Loss: 1.4029
Batch 120, Loss: 1.4249
Batch 130, Loss: 1.4162
Batch 140, Loss: 1.4734
Batch 150, Loss: 1.4407
Batch 160, Loss: 1.4075
Batch 170, Loss: 1.4163
Batch 180, Loss: 1.5109
Batch 190, Loss: 1.5301
Batch 200, Loss: 1.4414
Batch 210, Loss: 1.3972
Batch 220, Loss: 1.4102
Batch 230, Loss: 1.4851
Batch 240, Loss: 1.5028
Batch 250, Loss: 1.4454
Batch 260, Loss: 1.4484
Batch 270, Loss: 1.4705
Batch 280, Loss: 1.4651
Batch 290, Loss: 1.4557
Batch 300, Loss: 1.4792
Batch 310, Loss: 1.4747
Batch 320, Loss: 1.4143
Batch 330, Loss: 1.3861
Batch 340, Loss: 1.5068
Batch 350, Loss: 1.4685
Batch 360, Loss: 1.4477
Batch 370, Loss: 1.5614
Batch 380, Loss: 1.4759
Batch 390, Loss: 1.4605
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.136147260665894 seconds
Epoch 43 accuracy: 55.08%
Batch 10, Loss: 1.4269
Batch 20, Loss: 1.3835
Batch 30, Loss: 1.3910
Batch 40, Loss: 1.4038
Batch 50, Loss: 1.3638
Batch 60, Loss: 1.3769
Batch 70, Loss: 1.4274
Batch 80, Loss: 1.3925
Batch 90, Loss: 1.3644
Batch 100, Loss: 1.3971
Batch 110, Loss: 1.2909
Batch 120, Loss: 1.4568
Batch 130, Loss: 1.4130
Batch 140, Loss: 1.4828
Batch 150, Loss: 1.3879
Batch 160, Loss: 1.4449
Batch 170, Loss: 1.4136
Batch 180, Loss: 1.4164
Batch 190, Loss: 1.4078
Batch 200, Loss: 1.4640
Batch 210, Loss: 1.4862
Batch 220, Loss: 1.5100
Batch 230, Loss: 1.4777
Batch 240, Loss: 1.4766
Batch 250, Loss: 1.4052
Batch 260, Loss: 1.5226
Batch 270, Loss: 1.4820
Batch 280, Loss: 1.4239
Batch 290, Loss: 1.4019
Batch 300, Loss: 1.5060
Batch 310, Loss: 1.4674
Batch 320, Loss: 1.4482
Batch 330, Loss: 1.4097
Batch 340, Loss: 1.3549
Batch 350, Loss: 1.4211
Batch 360, Loss: 1.3884
Batch 370, Loss: 1.4987
Batch 380, Loss: 1.4770
Batch 390, Loss: 1.4428
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.166516304016113 seconds
Epoch 44 accuracy: 58.84%
Batch 10, Loss: 1.4045
Batch 20, Loss: 1.3959
Batch 30, Loss: 1.4238
Batch 40, Loss: 1.4012
Batch 50, Loss: 1.4102
Batch 60, Loss: 1.3638
Batch 70, Loss: 1.3633
Batch 80, Loss: 1.3709
Batch 90, Loss: 1.4458
Batch 100, Loss: 1.4749
Batch 110, Loss: 1.4501
Batch 120, Loss: 1.3776
Batch 130, Loss: 1.3535
Batch 140, Loss: 1.4537
Batch 150, Loss: 1.4759
Batch 160, Loss: 1.3562
Batch 170, Loss: 1.4009
Batch 180, Loss: 1.4243
Batch 190, Loss: 1.4257
Batch 200, Loss: 1.4123
Batch 210, Loss: 1.5271
Batch 220, Loss: 1.4755
Batch 230, Loss: 1.4155
Batch 240, Loss: 1.4209
Batch 250, Loss: 1.3987
Batch 260, Loss: 1.4518
Batch 270, Loss: 1.4577
Batch 280, Loss: 1.5128
Batch 290, Loss: 1.4668
Batch 300, Loss: 1.4254
Batch 310, Loss: 1.4290
Batch 320, Loss: 1.4382
Batch 330, Loss: 1.4347
Batch 340, Loss: 1.4422
Batch 350, Loss: 1.3706
Batch 360, Loss: 1.5017
Batch 370, Loss: 1.4698
Batch 380, Loss: 1.4460
Batch 390, Loss: 1.4667
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.1485698223114 seconds
Epoch 45 accuracy: 60.24%
Batch 10, Loss: 1.3788
Batch 20, Loss: 1.3892
Batch 30, Loss: 1.4069
Batch 40, Loss: 1.3605
Batch 50, Loss: 1.3861
Batch 60, Loss: 1.4098
Batch 70, Loss: 1.4102
Batch 80, Loss: 1.3831
Batch 90, Loss: 1.4508
Batch 100, Loss: 1.3845
Batch 110, Loss: 1.4084
Batch 120, Loss: 1.4313
Batch 130, Loss: 1.3738
Batch 140, Loss: 1.4316
Batch 150, Loss: 1.3954
Batch 160, Loss: 1.3736
Batch 170, Loss: 1.3640
Batch 180, Loss: 1.3728
Batch 190, Loss: 1.4400
Batch 200, Loss: 1.4017
Batch 210, Loss: 1.4093
Batch 220, Loss: 1.3819
Batch 230, Loss: 1.4330
Batch 240, Loss: 1.3494
Batch 250, Loss: 1.4663
Batch 260, Loss: 1.4490
Batch 270, Loss: 1.4271
Batch 280, Loss: 1.4598
Batch 290, Loss: 1.4802
Batch 300, Loss: 1.4158
Batch 310, Loss: 1.4938
Batch 320, Loss: 1.4633
Batch 330, Loss: 1.5023
Batch 340, Loss: 1.4599
Batch 350, Loss: 1.4070
Batch 360, Loss: 1.5017
Batch 370, Loss: 1.4463
Batch 380, Loss: 1.4328
Batch 390, Loss: 1.5110
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.25430679321289 seconds
Epoch 46 accuracy: 59.68%
Batch 10, Loss: 1.3741
Batch 20, Loss: 1.3510
Batch 30, Loss: 1.3852
Batch 40, Loss: 1.3531
Batch 50, Loss: 1.3881
Batch 60, Loss: 1.3665
Batch 70, Loss: 1.3583
Batch 80, Loss: 1.4183
Batch 90, Loss: 1.3040
Batch 100, Loss: 1.4401
Batch 110, Loss: 1.4044
Batch 120, Loss: 1.3915
Batch 130, Loss: 1.3434
Batch 140, Loss: 1.3915
Batch 150, Loss: 1.4518
Batch 160, Loss: 1.3736
Batch 170, Loss: 1.4182
Batch 180, Loss: 1.3956
Batch 190, Loss: 1.3997
Batch 200, Loss: 1.5008
Batch 210, Loss: 1.4417
Batch 220, Loss: 1.3627
Batch 230, Loss: 1.4035
Batch 240, Loss: 1.4452
Batch 250, Loss: 1.4780
Batch 260, Loss: 1.4272
Batch 270, Loss: 1.4123
Batch 280, Loss: 1.5293
Batch 290, Loss: 1.4576
Batch 300, Loss: 1.4251
Batch 310, Loss: 1.4964
Batch 320, Loss: 1.4464
Batch 330, Loss: 1.4478
Batch 340, Loss: 1.3789
Batch 350, Loss: 1.4171
Batch 360, Loss: 1.4605
Batch 370, Loss: 1.4175
Batch 380, Loss: 1.5105
Batch 390, Loss: 1.4813
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.144654512405396 seconds
Epoch 47 accuracy: 55.96%
Batch 10, Loss: 1.3667
Batch 20, Loss: 1.3859
Batch 30, Loss: 1.3430
Batch 40, Loss: 1.3574
Batch 50, Loss: 1.3640
Batch 60, Loss: 1.3346
Batch 70, Loss: 1.4189
Batch 80, Loss: 1.3953
Batch 90, Loss: 1.4023
Batch 100, Loss: 1.3921
Batch 110, Loss: 1.3465
Batch 120, Loss: 1.3900
Batch 130, Loss: 1.4488
Batch 140, Loss: 1.3969
Batch 150, Loss: 1.4004
Batch 160, Loss: 1.4535
Batch 170, Loss: 1.4101
Batch 180, Loss: 1.4000
Batch 190, Loss: 1.4844
Batch 200, Loss: 1.4166
Batch 210, Loss: 1.3171
Batch 220, Loss: 1.4065
Batch 230, Loss: 1.3893
Batch 240, Loss: 1.3910
Batch 250, Loss: 1.4141
Batch 260, Loss: 1.4618
Batch 270, Loss: 1.4847
Batch 280, Loss: 1.4737
Batch 290, Loss: 1.3970
Batch 300, Loss: 1.4227
Batch 310, Loss: 1.3673
Batch 320, Loss: 1.4488
Batch 330, Loss: 1.3819
Batch 340, Loss: 1.3791
Batch 350, Loss: 1.4216
Batch 360, Loss: 1.4227
Batch 370, Loss: 1.4133
Batch 380, Loss: 1.4134
Batch 390, Loss: 1.4253
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.22410011291504 seconds
Epoch 48 accuracy: 53.52%
Batch 10, Loss: 1.3396
Batch 20, Loss: 1.3982
Batch 30, Loss: 1.4546
Batch 40, Loss: 1.3853
Batch 50, Loss: 1.3619
Batch 60, Loss: 1.3549
Batch 70, Loss: 1.4154
Batch 80, Loss: 1.4128
Batch 90, Loss: 1.3331
Batch 100, Loss: 1.3205
Batch 110, Loss: 1.4589
Batch 120, Loss: 1.3894
Batch 130, Loss: 1.4004
Batch 140, Loss: 1.3721
Batch 150, Loss: 1.4057
Batch 160, Loss: 1.4022
Batch 170, Loss: 1.4058
Batch 180, Loss: 1.3560
Batch 190, Loss: 1.4330
Batch 200, Loss: 1.3644
Batch 210, Loss: 1.4999
Batch 220, Loss: 1.4311
Batch 230, Loss: 1.4206
Batch 240, Loss: 1.5051
Batch 250, Loss: 1.3717
Batch 260, Loss: 1.4445
Batch 270, Loss: 1.3826
Batch 280, Loss: 1.4137
Batch 290, Loss: 1.4498
Batch 300, Loss: 1.4293
Batch 310, Loss: 1.4424
Batch 320, Loss: 1.4047
Batch 330, Loss: 1.4268
Batch 340, Loss: 1.4269
Batch 350, Loss: 1.4346
Batch 360, Loss: 1.3831
Batch 370, Loss: 1.4132
Batch 380, Loss: 1.4448
Batch 390, Loss: 1.3696
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.113072156906128 seconds
Epoch 49 accuracy: 59.55%
Batch 10, Loss: 1.3636
Batch 20, Loss: 1.3528
Batch 30, Loss: 1.3602
Batch 40, Loss: 1.3680
Batch 50, Loss: 1.3527
Batch 60, Loss: 1.3433
Batch 70, Loss: 1.3326
Batch 80, Loss: 1.3752
Batch 90, Loss: 1.3503
Batch 100, Loss: 1.4162
Batch 110, Loss: 1.3670
Batch 120, Loss: 1.3990
Batch 130, Loss: 1.4230
Batch 140, Loss: 1.3971
Batch 150, Loss: 1.4518
Batch 160, Loss: 1.4129
Batch 170, Loss: 1.3784
Batch 180, Loss: 1.3948
Batch 190, Loss: 1.3991
Batch 200, Loss: 1.3578
Batch 210, Loss: 1.4709
Batch 220, Loss: 1.3917
Batch 230, Loss: 1.4042
Batch 240, Loss: 1.4054
Batch 250, Loss: 1.3385
Batch 260, Loss: 1.3826
Batch 270, Loss: 1.3641
Batch 280, Loss: 1.3324
Batch 290, Loss: 1.4360
Batch 300, Loss: 1.3680
Batch 310, Loss: 1.4200
Batch 320, Loss: 1.4854
Batch 330, Loss: 1.4800
Batch 340, Loss: 1.4651
Batch 350, Loss: 1.4847
Batch 360, Loss: 1.3588
Batch 370, Loss: 1.4320
Batch 380, Loss: 1.4444
Batch 390, Loss: 1.4610
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.11575722694397 seconds
Epoch 50 accuracy: 56.05%
Batch 10, Loss: 1.3977
Batch 20, Loss: 1.3503
Batch 30, Loss: 1.3634
Batch 40, Loss: 1.2929
Batch 50, Loss: 1.3394
Batch 60, Loss: 1.3088
Batch 70, Loss: 1.3101
Batch 80, Loss: 1.3650
Batch 90, Loss: 1.3454
Batch 100, Loss: 1.3727
Batch 110, Loss: 1.3719
Batch 120, Loss: 1.3419
Batch 130, Loss: 1.3539
Batch 140, Loss: 1.4344
Batch 150, Loss: 1.4412
Batch 160, Loss: 1.4181
Batch 170, Loss: 1.4270
Batch 180, Loss: 1.3516
Batch 190, Loss: 1.3604
Batch 200, Loss: 1.4378
Batch 210, Loss: 1.4638
Batch 220, Loss: 1.4255
Batch 230, Loss: 1.4046
Batch 240, Loss: 1.4460
Batch 250, Loss: 1.5013
Batch 260, Loss: 1.4532
Batch 270, Loss: 1.4167
Batch 280, Loss: 1.4301
Batch 290, Loss: 1.4097
Batch 300, Loss: 1.4205
Batch 310, Loss: 1.3837
Batch 320, Loss: 1.4043
Batch 330, Loss: 1.4160
Batch 340, Loss: 1.3453
Batch 350, Loss: 1.3927
Batch 360, Loss: 1.4514
Batch 370, Loss: 1.4463
Batch 380, Loss: 1.4706
Batch 390, Loss: 1.4468
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.18661594390869 seconds
Epoch 51 accuracy: 58.49%
Batch 10, Loss: 1.3346
Batch 20, Loss: 1.3907
Batch 30, Loss: 1.3209
Batch 40, Loss: 1.3750
Batch 50, Loss: 1.3469
Batch 60, Loss: 1.3810
Batch 70, Loss: 1.3288
Batch 80, Loss: 1.3570
Batch 90, Loss: 1.3403
Batch 100, Loss: 1.3263
Batch 110, Loss: 1.4054
Batch 120, Loss: 1.3669
Batch 130, Loss: 1.3320
Batch 140, Loss: 1.3801
Batch 150, Loss: 1.4259
Batch 160, Loss: 1.4151
Batch 170, Loss: 1.3612
Batch 180, Loss: 1.4077
Batch 190, Loss: 1.3883
Batch 200, Loss: 1.3077
Batch 210, Loss: 1.4019
Batch 220, Loss: 1.3859
Batch 230, Loss: 1.4258
Batch 240, Loss: 1.3908
Batch 250, Loss: 1.3556
Batch 260, Loss: 1.4075
Batch 270, Loss: 1.3370
Batch 280, Loss: 1.4226
Batch 290, Loss: 1.4905
Batch 300, Loss: 1.4483
Batch 310, Loss: 1.4297
Batch 320, Loss: 1.4114
Batch 330, Loss: 1.3928
Batch 340, Loss: 1.3857
Batch 350, Loss: 1.4175
Batch 360, Loss: 1.3762
Batch 370, Loss: 1.4165
Batch 380, Loss: 1.4537
Batch 390, Loss: 1.4284
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.118749618530273 seconds
Epoch 52 accuracy: 54.38%
Batch 10, Loss: 1.3232
Batch 20, Loss: 1.2858
Batch 30, Loss: 1.3999
Batch 40, Loss: 1.3782
Batch 50, Loss: 1.4256
Batch 60, Loss: 1.3400
Batch 70, Loss: 1.3416
Batch 80, Loss: 1.3930
Batch 90, Loss: 1.3972
Batch 100, Loss: 1.3638
Batch 110, Loss: 1.3623
Batch 120, Loss: 1.3559
Batch 130, Loss: 1.3907
Batch 140, Loss: 1.3719
Batch 150, Loss: 1.3772
Batch 160, Loss: 1.3805
Batch 170, Loss: 1.3438
Batch 180, Loss: 1.4035
Batch 190, Loss: 1.3706
Batch 200, Loss: 1.3828
Batch 210, Loss: 1.3931
Batch 220, Loss: 1.4499
Batch 230, Loss: 1.3926
Batch 240, Loss: 1.4217
Batch 250, Loss: 1.3550
Batch 260, Loss: 1.3869
Batch 270, Loss: 1.3563
Batch 280, Loss: 1.4640
Batch 290, Loss: 1.4213
Batch 300, Loss: 1.4422
Batch 310, Loss: 1.4150
Batch 320, Loss: 1.3777
Batch 330, Loss: 1.4144
Batch 340, Loss: 1.3786
Batch 350, Loss: 1.4450
Batch 360, Loss: 1.3314
Batch 370, Loss: 1.3991
Batch 380, Loss: 1.4362
Batch 390, Loss: 1.4682
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.110846519470215 seconds
Epoch 53 accuracy: 56.72%
Batch 10, Loss: 1.2778
Batch 20, Loss: 1.3510
Batch 30, Loss: 1.2987
Batch 40, Loss: 1.2826
Batch 50, Loss: 1.3077
Batch 60, Loss: 1.4052
Batch 70, Loss: 1.2931
Batch 80, Loss: 1.3237
Batch 90, Loss: 1.4037
Batch 100, Loss: 1.3513
Batch 110, Loss: 1.3558
Batch 120, Loss: 1.4415
Batch 130, Loss: 1.4405
Batch 140, Loss: 1.4081
Batch 150, Loss: 1.3727
Batch 160, Loss: 1.3722
Batch 170, Loss: 1.3423
Batch 180, Loss: 1.4290
Batch 190, Loss: 1.4221
Batch 200, Loss: 1.4075
Batch 210, Loss: 1.4032
Batch 220, Loss: 1.3766
Batch 230, Loss: 1.3380
Batch 240, Loss: 1.4480
Batch 250, Loss: 1.4392
Batch 260, Loss: 1.3630
Batch 270, Loss: 1.4273
Batch 280, Loss: 1.4203
Batch 290, Loss: 1.3455
Batch 300, Loss: 1.4614
Batch 310, Loss: 1.3976
Batch 320, Loss: 1.4042
Batch 330, Loss: 1.4170
Batch 340, Loss: 1.4190
Batch 350, Loss: 1.4030
Batch 360, Loss: 1.4144
Batch 370, Loss: 1.4143
Batch 380, Loss: 1.3488
Batch 390, Loss: 1.4034
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.06996750831604 seconds
Epoch 54 accuracy: 59.47%
Batch 10, Loss: 1.3506
Batch 20, Loss: 1.3618
Batch 30, Loss: 1.2579
Batch 40, Loss: 1.3131
Batch 50, Loss: 1.3591
Batch 60, Loss: 1.3414
Batch 70, Loss: 1.3757
Batch 80, Loss: 1.2938
Batch 90, Loss: 1.3025
Batch 100, Loss: 1.2928
Batch 110, Loss: 1.3425
Batch 120, Loss: 1.4093
Batch 130, Loss: 1.3936
Batch 140, Loss: 1.3786
Batch 150, Loss: 1.3633
Batch 160, Loss: 1.3813
Batch 170, Loss: 1.4039
Batch 180, Loss: 1.4130
Batch 190, Loss: 1.4048
Batch 200, Loss: 1.3655
Batch 210, Loss: 1.3751
Batch 220, Loss: 1.4513
Batch 230, Loss: 1.3547
Batch 240, Loss: 1.4085
Batch 250, Loss: 1.3669
Batch 260, Loss: 1.3705
Batch 270, Loss: 1.4062
Batch 280, Loss: 1.4104
Batch 290, Loss: 1.4279
Batch 300, Loss: 1.4264
Batch 310, Loss: 1.3729
Batch 320, Loss: 1.4519
Batch 330, Loss: 1.3373
Batch 340, Loss: 1.3709
Batch 350, Loss: 1.4005
Batch 360, Loss: 1.3948
Batch 370, Loss: 1.3794
Batch 380, Loss: 1.2911
Batch 390, Loss: 1.3197
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.140517234802246 seconds
Epoch 55 accuracy: 59.36%
Batch 10, Loss: 1.3137
Batch 20, Loss: 1.3895
Batch 30, Loss: 1.3955
Batch 40, Loss: 1.2877
Batch 50, Loss: 1.3059
Batch 60, Loss: 1.3011
Batch 70, Loss: 1.3486
Batch 80, Loss: 1.3061
Batch 90, Loss: 1.3738
Batch 100, Loss: 1.4080
Batch 110, Loss: 1.4127
Batch 120, Loss: 1.3801
Batch 130, Loss: 1.3855
Batch 140, Loss: 1.3855
Batch 150, Loss: 1.3333
Batch 160, Loss: 1.4024
Batch 170, Loss: 1.3818
Batch 180, Loss: 1.3958
Batch 190, Loss: 1.4193
Batch 200, Loss: 1.4052
Batch 210, Loss: 1.3600
Batch 220, Loss: 1.3215
Batch 230, Loss: 1.3393
Batch 240, Loss: 1.3850
Batch 250, Loss: 1.3787
Batch 260, Loss: 1.3492
Batch 270, Loss: 1.4154
Batch 280, Loss: 1.4263
Batch 290, Loss: 1.4248
Batch 300, Loss: 1.3442
Batch 310, Loss: 1.3637
Batch 320, Loss: 1.4137
Batch 330, Loss: 1.4330
Batch 340, Loss: 1.3681
Batch 350, Loss: 1.3726
Batch 360, Loss: 1.4209
Batch 370, Loss: 1.3827
Batch 380, Loss: 1.4023
Batch 390, Loss: 1.4106
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.26041030883789 seconds
Epoch 56 accuracy: 58.82%
Batch 10, Loss: 1.3402
Batch 20, Loss: 1.3552
Batch 30, Loss: 1.3521
Batch 40, Loss: 1.3646
Batch 50, Loss: 1.3450
Batch 60, Loss: 1.2932
Batch 70, Loss: 1.2992
Batch 80, Loss: 1.3093
Batch 90, Loss: 1.3075
Batch 100, Loss: 1.4265
Batch 110, Loss: 1.4160
Batch 120, Loss: 1.4040
Batch 130, Loss: 1.3948
Batch 140, Loss: 1.4220
Batch 150, Loss: 1.4324
Batch 160, Loss: 1.4276
Batch 170, Loss: 1.3824
Batch 180, Loss: 1.3564
Batch 190, Loss: 1.3407
Batch 200, Loss: 1.3196
Batch 210, Loss: 1.3122
Batch 220, Loss: 1.3237
Batch 230, Loss: 1.4169
Batch 240, Loss: 1.3931
Batch 250, Loss: 1.3894
Batch 260, Loss: 1.3572
Batch 270, Loss: 1.3182
Batch 280, Loss: 1.3544
Batch 290, Loss: 1.3749
Batch 300, Loss: 1.4944
Batch 310, Loss: 1.3723
Batch 320, Loss: 1.3864
Batch 330, Loss: 1.3247
Batch 340, Loss: 1.4163
Batch 350, Loss: 1.3070
Batch 360, Loss: 1.4009
Batch 370, Loss: 1.4128
Batch 380, Loss: 1.4239
Batch 390, Loss: 1.3308
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.17512583732605 seconds
Epoch 57 accuracy: 59.03%
Batch 10, Loss: 1.3033
Batch 20, Loss: 1.2427
Batch 30, Loss: 1.3031
Batch 40, Loss: 1.2717
Batch 50, Loss: 1.3079
Batch 60, Loss: 1.3110
Batch 70, Loss: 1.2509
Batch 80, Loss: 1.3083
Batch 90, Loss: 1.2954
Batch 100, Loss: 1.4116
Batch 110, Loss: 1.3431
Batch 120, Loss: 1.3609
Batch 130, Loss: 1.3812
Batch 140, Loss: 1.3802
Batch 150, Loss: 1.3477
Batch 160, Loss: 1.3621
Batch 170, Loss: 1.3162
Batch 180, Loss: 1.4145
Batch 190, Loss: 1.3727
Batch 200, Loss: 1.3980
Batch 210, Loss: 1.3852
Batch 220, Loss: 1.3568
Batch 230, Loss: 1.3984
Batch 240, Loss: 1.3851
Batch 250, Loss: 1.4168
Batch 260, Loss: 1.3548
Batch 270, Loss: 1.4193
Batch 280, Loss: 1.3630
Batch 290, Loss: 1.3380
Batch 300, Loss: 1.3259
Batch 310, Loss: 1.3423
Batch 320, Loss: 1.3544
Batch 330, Loss: 1.3111
Batch 340, Loss: 1.3542
Batch 350, Loss: 1.4212
Batch 360, Loss: 1.4443
Batch 370, Loss: 1.3937
Batch 380, Loss: 1.3614
Batch 390, Loss: 1.4039
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.22153925895691 seconds
Epoch 58 accuracy: 58.0%
Batch 10, Loss: 1.2429
Batch 20, Loss: 1.2681
Batch 30, Loss: 1.2897
Batch 40, Loss: 1.2865
Batch 50, Loss: 1.2118
Batch 60, Loss: 1.2536
Batch 70, Loss: 1.2862
Batch 80, Loss: 1.3068
Batch 90, Loss: 1.3564
Batch 100, Loss: 1.2759
Batch 110, Loss: 1.3368
Batch 120, Loss: 1.3630
Batch 130, Loss: 1.4153
Batch 140, Loss: 1.2477
Batch 150, Loss: 1.2787
Batch 160, Loss: 1.3663
Batch 170, Loss: 1.3522
Batch 180, Loss: 1.3853
Batch 190, Loss: 1.3873
Batch 200, Loss: 1.3720
Batch 210, Loss: 1.3835
Batch 220, Loss: 1.3851
Batch 230, Loss: 1.4066
Batch 240, Loss: 1.4223
Batch 250, Loss: 1.3204
Batch 260, Loss: 1.3685
Batch 270, Loss: 1.3693
Batch 280, Loss: 1.3523
Batch 290, Loss: 1.3109
Batch 300, Loss: 1.4395
Batch 310, Loss: 1.4026
Batch 320, Loss: 1.4064
Batch 330, Loss: 1.3406
Batch 340, Loss: 1.4120
Batch 350, Loss: 1.3176
Batch 360, Loss: 1.4303
Batch 370, Loss: 1.4124
Batch 380, Loss: 1.3518
Batch 390, Loss: 1.3709
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 24.989750385284424 seconds
Epoch 59 accuracy: 58.38%
Batch 10, Loss: 1.3574
Batch 20, Loss: 1.3518
Batch 30, Loss: 1.3102
Batch 40, Loss: 1.2792
Batch 50, Loss: 1.3312
Batch 60, Loss: 1.3130
Batch 70, Loss: 1.3246
Batch 80, Loss: 1.3203
Batch 90, Loss: 1.3541
Batch 100, Loss: 1.3256
Batch 110, Loss: 1.2911
Batch 120, Loss: 1.3439
Batch 130, Loss: 1.3692
Batch 140, Loss: 1.3946
Batch 150, Loss: 1.2815
Batch 160, Loss: 1.2628
Batch 170, Loss: 1.2942
Batch 180, Loss: 1.2693
Batch 190, Loss: 1.3317
Batch 200, Loss: 1.3916
Batch 210, Loss: 1.3774
Batch 220, Loss: 1.3926
Batch 230, Loss: 1.3217
Batch 240, Loss: 1.3696
Batch 250, Loss: 1.3181
Batch 260, Loss: 1.3056
Batch 270, Loss: 1.3820
Batch 280, Loss: 1.3264
Batch 290, Loss: 1.3578
Batch 300, Loss: 1.3488
Batch 310, Loss: 1.3757
Batch 320, Loss: 1.3674
Batch 330, Loss: 1.4027
Batch 340, Loss: 1.3955
Batch 350, Loss: 1.3855
Batch 360, Loss: 1.4535
Batch 370, Loss: 1.4049
Batch 380, Loss: 1.3736
Batch 390, Loss: 1.3905
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.168169498443604 seconds
Epoch 60 accuracy: 61.47%
Batch 10, Loss: 1.3283
Batch 20, Loss: 1.3219
Batch 30, Loss: 1.2751
Batch 40, Loss: 1.2789
Batch 50, Loss: 1.3034
Batch 60, Loss: 1.3183
Batch 70, Loss: 1.3015
Batch 80, Loss: 1.3459
Batch 90, Loss: 1.4067
Batch 100, Loss: 1.3294
Batch 110, Loss: 1.2788
Batch 120, Loss: 1.3471
Batch 130, Loss: 1.3218
Batch 140, Loss: 1.3402
Batch 150, Loss: 1.3297
Batch 160, Loss: 1.2972
Batch 170, Loss: 1.3533
Batch 180, Loss: 1.3301
Batch 190, Loss: 1.3859
Batch 200, Loss: 1.3321
Batch 210, Loss: 1.3718
Batch 220, Loss: 1.4264
Batch 230, Loss: 1.4079
Batch 240, Loss: 1.3324
Batch 250, Loss: 1.3474
Batch 260, Loss: 1.3731
Batch 270, Loss: 1.2760
Batch 280, Loss: 1.3322
Batch 290, Loss: 1.3375
Batch 300, Loss: 1.2881
Batch 310, Loss: 1.4020
Batch 320, Loss: 1.3709
Batch 330, Loss: 1.3349
Batch 340, Loss: 1.3330
Batch 350, Loss: 1.2985
Batch 360, Loss: 1.3197
Batch 370, Loss: 1.3913
Batch 380, Loss: 1.3299
Batch 390, Loss: 1.2984
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.24514365196228 seconds
Epoch 61 accuracy: 61.12%
Batch 10, Loss: 1.2805
Batch 20, Loss: 1.3580
Batch 30, Loss: 1.3115
Batch 40, Loss: 1.3315
Batch 50, Loss: 1.2624
Batch 60, Loss: 1.2617
Batch 70, Loss: 1.2958
Batch 80, Loss: 1.2690
Batch 90, Loss: 1.3569
Batch 100, Loss: 1.2797
Batch 110, Loss: 1.3182
Batch 120, Loss: 1.3296
Batch 130, Loss: 1.3160
Batch 140, Loss: 1.3570
Batch 150, Loss: 1.3199
Batch 160, Loss: 1.3507
Batch 170, Loss: 1.3697
Batch 180, Loss: 1.3438
Batch 190, Loss: 1.3631
Batch 200, Loss: 1.3578
Batch 210, Loss: 1.3832
Batch 220, Loss: 1.3569
Batch 230, Loss: 1.3018
Batch 240, Loss: 1.3870
Batch 250, Loss: 1.3253
Batch 260, Loss: 1.3391
Batch 270, Loss: 1.3156
Batch 280, Loss: 1.3164
Batch 290, Loss: 1.2353
Batch 300, Loss: 1.3696
Batch 310, Loss: 1.4158
Batch 320, Loss: 1.3510
Batch 330, Loss: 1.3318
Batch 340, Loss: 1.3116
Batch 350, Loss: 1.3459
Batch 360, Loss: 1.3667
Batch 370, Loss: 1.3367
Batch 380, Loss: 1.3570
Batch 390, Loss: 1.3400
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.19127631187439 seconds
Epoch 62 accuracy: 61.3%
Batch 10, Loss: 1.2817
Batch 20, Loss: 1.2767
Batch 30, Loss: 1.2842
Batch 40, Loss: 1.2788
Batch 50, Loss: 1.3171
Batch 60, Loss: 1.3322
Batch 70, Loss: 1.2915
Batch 80, Loss: 1.2551
Batch 90, Loss: 1.3166
Batch 100, Loss: 1.3431
Batch 110, Loss: 1.2851
Batch 120, Loss: 1.3132
Batch 130, Loss: 1.3601
Batch 140, Loss: 1.3302
Batch 150, Loss: 1.3363
Batch 160, Loss: 1.3433
Batch 170, Loss: 1.3044
Batch 180, Loss: 1.3547
Batch 190, Loss: 1.2905
Batch 200, Loss: 1.4043
Batch 210, Loss: 1.3723
Batch 220, Loss: 1.3459
Batch 230, Loss: 1.3934
Batch 240, Loss: 1.4066
Batch 250, Loss: 1.2956
Batch 260, Loss: 1.2825
Batch 270, Loss: 1.3400
Batch 280, Loss: 1.3593
Batch 290, Loss: 1.3589
Batch 300, Loss: 1.3585
Batch 310, Loss: 1.3317
Batch 320, Loss: 1.4556
Batch 330, Loss: 1.3635
Batch 340, Loss: 1.3309
Batch 350, Loss: 1.3567
Batch 360, Loss: 1.3513
Batch 370, Loss: 1.4583
Batch 380, Loss: 1.3846
Batch 390, Loss: 1.4218
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.140052795410156 seconds
Epoch 63 accuracy: 57.84%
Batch 10, Loss: 1.3880
Batch 20, Loss: 1.2647
Batch 30, Loss: 1.2964
Batch 40, Loss: 1.2746
Batch 50, Loss: 1.2871
Batch 60, Loss: 1.2942
Batch 70, Loss: 1.3144
Batch 80, Loss: 1.3390
Batch 90, Loss: 1.3068
Batch 100, Loss: 1.3795
Batch 110, Loss: 1.3761
Batch 120, Loss: 1.3086
Batch 130, Loss: 1.3534
Batch 140, Loss: 1.3358
Batch 150, Loss: 1.3275
Batch 160, Loss: 1.3565
Batch 170, Loss: 1.2957
Batch 180, Loss: 1.2746
Batch 190, Loss: 1.3234
Batch 200, Loss: 1.3312
Batch 210, Loss: 1.3463
Batch 220, Loss: 1.3416
Batch 230, Loss: 1.3780
Batch 240, Loss: 1.2920
Batch 250, Loss: 1.3584
Batch 260, Loss: 1.3390
Batch 270, Loss: 1.3704
Batch 280, Loss: 1.3442
Batch 290, Loss: 1.3156
Batch 300, Loss: 1.3637
Batch 310, Loss: 1.2893
Batch 320, Loss: 1.3511
Batch 330, Loss: 1.3472
Batch 340, Loss: 1.3426
Batch 350, Loss: 1.3385
Batch 360, Loss: 1.2955
Batch 370, Loss: 1.3195
Batch 380, Loss: 1.3519
Batch 390, Loss: 1.3462
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.24107575416565 seconds
Epoch 64 accuracy: 58.13%
Batch 10, Loss: 1.2475
Batch 20, Loss: 1.2408
Batch 30, Loss: 1.2874
Batch 40, Loss: 1.2126
Batch 50, Loss: 1.3175
Batch 60, Loss: 1.2741
Batch 70, Loss: 1.3260
Batch 80, Loss: 1.2514
Batch 90, Loss: 1.2948
Batch 100, Loss: 1.3576
Batch 110, Loss: 1.3187
Batch 120, Loss: 1.3450
Batch 130, Loss: 1.3058
Batch 140, Loss: 1.3049
Batch 150, Loss: 1.2933
Batch 160, Loss: 1.3355
Batch 170, Loss: 1.3743
Batch 180, Loss: 1.2968
Batch 190, Loss: 1.3174
Batch 200, Loss: 1.3586
Batch 210, Loss: 1.3750
Batch 220, Loss: 1.4016
Batch 230, Loss: 1.2542
Batch 240, Loss: 1.3344
Batch 250, Loss: 1.3146
Batch 260, Loss: 1.2771
Batch 270, Loss: 1.3037
Batch 280, Loss: 1.3133
Batch 290, Loss: 1.3413
Batch 300, Loss: 1.3427
Batch 310, Loss: 1.3371
Batch 320, Loss: 1.2968
Batch 330, Loss: 1.3310
Batch 340, Loss: 1.3856
Batch 350, Loss: 1.3027
Batch 360, Loss: 1.3441
Batch 370, Loss: 1.3252
Batch 380, Loss: 1.3181
Batch 390, Loss: 1.3669
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.098955631256104 seconds
Epoch 65 accuracy: 59.47%
Batch 10, Loss: 1.2833
Batch 20, Loss: 1.2861
Batch 30, Loss: 1.2879
Batch 40, Loss: 1.2576
Batch 50, Loss: 1.2366
Batch 60, Loss: 1.3356
Batch 70, Loss: 1.2720
Batch 80, Loss: 1.3054
Batch 90, Loss: 1.2890
Batch 100, Loss: 1.2875
Batch 110, Loss: 1.3146
Batch 120, Loss: 1.2581
Batch 130, Loss: 1.2905
Batch 140, Loss: 1.2847
Batch 150, Loss: 1.2823
Batch 160, Loss: 1.3038
Batch 170, Loss: 1.3128
Batch 180, Loss: 1.3228
Batch 190, Loss: 1.3713
Batch 200, Loss: 1.3081
Batch 210, Loss: 1.3042
Batch 220, Loss: 1.4089
Batch 230, Loss: 1.3226
Batch 240, Loss: 1.2990
Batch 250, Loss: 1.3252
Batch 260, Loss: 1.3697
Batch 270, Loss: 1.3570
Batch 280, Loss: 1.3612
Batch 290, Loss: 1.2923
Batch 300, Loss: 1.2917
Batch 310, Loss: 1.2997
Batch 320, Loss: 1.3087
Batch 330, Loss: 1.2985
Batch 340, Loss: 1.3220
Batch 350, Loss: 1.3231
Batch 360, Loss: 1.3933
Batch 370, Loss: 1.3754
Batch 380, Loss: 1.2218
Batch 390, Loss: 1.3367
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.09465765953064 seconds
Epoch 66 accuracy: 59.54%
Batch 10, Loss: 1.3245
Batch 20, Loss: 1.2504
Batch 30, Loss: 1.2076
Batch 40, Loss: 1.3013
Batch 50, Loss: 1.3505
Batch 60, Loss: 1.2229
Batch 70, Loss: 1.2235
Batch 80, Loss: 1.3274
Batch 90, Loss: 1.2398
Batch 100, Loss: 1.2833
Batch 110, Loss: 1.3130
Batch 120, Loss: 1.2953
Batch 130, Loss: 1.3648
Batch 140, Loss: 1.2599
Batch 150, Loss: 1.2741
Batch 160, Loss: 1.2838
Batch 170, Loss: 1.2799
Batch 180, Loss: 1.3078
Batch 190, Loss: 1.3508
Batch 200, Loss: 1.2976
Batch 210, Loss: 1.3321
Batch 220, Loss: 1.3189
Batch 230, Loss: 1.3136
Batch 240, Loss: 1.3530
Batch 250, Loss: 1.3073
Batch 260, Loss: 1.3337
Batch 270, Loss: 1.3983
Batch 280, Loss: 1.3589
Batch 290, Loss: 1.2023
Batch 300, Loss: 1.3322
Batch 310, Loss: 1.2926
Batch 320, Loss: 1.3859
Batch 330, Loss: 1.3259
Batch 340, Loss: 1.3355
Batch 350, Loss: 1.3544
Batch 360, Loss: 1.3322
Batch 370, Loss: 1.3318
Batch 380, Loss: 1.2980
Batch 390, Loss: 1.3059
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.079489946365356 seconds
Epoch 67 accuracy: 62.85%
Batch 10, Loss: 1.2289
Batch 20, Loss: 1.2197
Batch 30, Loss: 1.2596
Batch 40, Loss: 1.2647
Batch 50, Loss: 1.2819
Batch 60, Loss: 1.2351
Batch 70, Loss: 1.2649
Batch 80, Loss: 1.3399
Batch 90, Loss: 1.3329
Batch 100, Loss: 1.3158
Batch 110, Loss: 1.3444
Batch 120, Loss: 1.2546
Batch 130, Loss: 1.3001
Batch 140, Loss: 1.3189
Batch 150, Loss: 1.2931
Batch 160, Loss: 1.3705
Batch 170, Loss: 1.3231
Batch 180, Loss: 1.2656
Batch 190, Loss: 1.3209
Batch 200, Loss: 1.3115
Batch 210, Loss: 1.2586
Batch 220, Loss: 1.3373
Batch 230, Loss: 1.2927
Batch 240, Loss: 1.3264
Batch 250, Loss: 1.3118
Batch 260, Loss: 1.3520
Batch 270, Loss: 1.2577
Batch 280, Loss: 1.3483
Batch 290, Loss: 1.3605
Batch 300, Loss: 1.4266
Batch 310, Loss: 1.3345
Batch 320, Loss: 1.3131
Batch 330, Loss: 1.3382
Batch 340, Loss: 1.3671
Batch 350, Loss: 1.3615
Batch 360, Loss: 1.3405
Batch 370, Loss: 1.3600
Batch 380, Loss: 1.3248
Batch 390, Loss: 1.3283
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.060057640075684 seconds
Epoch 68 accuracy: 61.98%
Batch 10, Loss: 1.2652
Batch 20, Loss: 1.2355
Batch 30, Loss: 1.2352
Batch 40, Loss: 1.2099
Batch 50, Loss: 1.2597
Batch 60, Loss: 1.2998
Batch 70, Loss: 1.3143
Batch 80, Loss: 1.3290
Batch 90, Loss: 1.2617
Batch 100, Loss: 1.3200
Batch 110, Loss: 1.2456
Batch 120, Loss: 1.2393
Batch 130, Loss: 1.3003
Batch 140, Loss: 1.3367
Batch 150, Loss: 1.3144
Batch 160, Loss: 1.2731
Batch 170, Loss: 1.2910
Batch 180, Loss: 1.2863
Batch 190, Loss: 1.2811
Batch 200, Loss: 1.3308
Batch 210, Loss: 1.2617
Batch 220, Loss: 1.3026
Batch 230, Loss: 1.2950
Batch 240, Loss: 1.2340
Batch 250, Loss: 1.2896
Batch 260, Loss: 1.3018
Batch 270, Loss: 1.3325
Batch 280, Loss: 1.2933
Batch 290, Loss: 1.2653
Batch 300, Loss: 1.3289
Batch 310, Loss: 1.2843
Batch 320, Loss: 1.3036
Batch 330, Loss: 1.2881
Batch 340, Loss: 1.3027
Batch 350, Loss: 1.3034
Batch 360, Loss: 1.2558
Batch 370, Loss: 1.2589
Batch 380, Loss: 1.3234
Batch 390, Loss: 1.3506
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.21433186531067 seconds
Epoch 69 accuracy: 61.15%
Batch 10, Loss: 1.2651
Batch 20, Loss: 1.2815
Batch 30, Loss: 1.2450
Batch 40, Loss: 1.2422
Batch 50, Loss: 1.2143
Batch 60, Loss: 1.1935
Batch 70, Loss: 1.2744
Batch 80, Loss: 1.2953
Batch 90, Loss: 1.2519
Batch 100, Loss: 1.2396
Batch 110, Loss: 1.2288
Batch 120, Loss: 1.3379
Batch 130, Loss: 1.2953
Batch 140, Loss: 1.2465
Batch 150, Loss: 1.2577
Batch 160, Loss: 1.2812
Batch 170, Loss: 1.3784
Batch 180, Loss: 1.3017
Batch 190, Loss: 1.2821
Batch 200, Loss: 1.2383
Batch 210, Loss: 1.3445
Batch 220, Loss: 1.3231
Batch 230, Loss: 1.2798
Batch 240, Loss: 1.2388
Batch 250, Loss: 1.3206
Batch 260, Loss: 1.2439
Batch 270, Loss: 1.3822
Batch 280, Loss: 1.3239
Batch 290, Loss: 1.2740
Batch 300, Loss: 1.3223
Batch 310, Loss: 1.2994
Batch 320, Loss: 1.3518
Batch 330, Loss: 1.3397
Batch 340, Loss: 1.3454
Batch 350, Loss: 1.3474
Batch 360, Loss: 1.3616
Batch 370, Loss: 1.3468
Batch 380, Loss: 1.2964
Batch 390, Loss: 1.3364
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.233883142471313 seconds
Epoch 70 accuracy: 61.65%
Batch 10, Loss: 1.2629
Batch 20, Loss: 1.2475
Batch 30, Loss: 1.2659
Batch 40, Loss: 1.2730
Batch 50, Loss: 1.2817
Batch 60, Loss: 1.2183
Batch 70, Loss: 1.2327
Batch 80, Loss: 1.2278
Batch 90, Loss: 1.2635
Batch 100, Loss: 1.3385
Batch 110, Loss: 1.2216
Batch 120, Loss: 1.3373
Batch 130, Loss: 1.2388
Batch 140, Loss: 1.3262
Batch 150, Loss: 1.3196
Batch 160, Loss: 1.3099
Batch 170, Loss: 1.2866
Batch 180, Loss: 1.2802
Batch 190, Loss: 1.2561
Batch 200, Loss: 1.2586
Batch 210, Loss: 1.3251
Batch 220, Loss: 1.2556
Batch 230, Loss: 1.2678
Batch 240, Loss: 1.3388
Batch 250, Loss: 1.2844
Batch 260, Loss: 1.2658
Batch 270, Loss: 1.2885
Batch 280, Loss: 1.3070
Batch 290, Loss: 1.3306
Batch 300, Loss: 1.3427
Batch 310, Loss: 1.3220
Batch 320, Loss: 1.3507
Batch 330, Loss: 1.3552
Batch 340, Loss: 1.3136
Batch 350, Loss: 1.3404
Batch 360, Loss: 1.3096
Batch 370, Loss: 1.3351
Batch 380, Loss: 1.2830
Batch 390, Loss: 1.3835
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.127246379852295 seconds
Epoch 71 accuracy: 60.12%
Batch 10, Loss: 1.3087
Batch 20, Loss: 1.2026
Batch 30, Loss: 1.2152
Batch 40, Loss: 1.2415
Batch 50, Loss: 1.2502
Batch 60, Loss: 1.2029
Batch 70, Loss: 1.2339
Batch 80, Loss: 1.2298
Batch 90, Loss: 1.2665
Batch 100, Loss: 1.2431
Batch 110, Loss: 1.3207
Batch 120, Loss: 1.3141
Batch 130, Loss: 1.3285
Batch 140, Loss: 1.2508
Batch 150, Loss: 1.3528
Batch 160, Loss: 1.3209
Batch 170, Loss: 1.2725
Batch 180, Loss: 1.2787
Batch 190, Loss: 1.2492
Batch 200, Loss: 1.3007
Batch 210, Loss: 1.2381
Batch 220, Loss: 1.2642
Batch 230, Loss: 1.3208
Batch 240, Loss: 1.2283
Batch 250, Loss: 1.1998
Batch 260, Loss: 1.2720
Batch 270, Loss: 1.3489
Batch 280, Loss: 1.3361
Batch 290, Loss: 1.3581
Batch 300, Loss: 1.2943
Batch 310, Loss: 1.3181
Batch 320, Loss: 1.2801
Batch 330, Loss: 1.2693
Batch 340, Loss: 1.2415
Batch 350, Loss: 1.2384
Batch 360, Loss: 1.3000
Batch 370, Loss: 1.2508
Batch 380, Loss: 1.3034
Batch 390, Loss: 1.2967
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.254124402999878 seconds
Epoch 72 accuracy: 62.22%
Batch 10, Loss: 1.2162
Batch 20, Loss: 1.2279
Batch 30, Loss: 1.2465
Batch 40, Loss: 1.1753
Batch 50, Loss: 1.2197
Batch 60, Loss: 1.2542
Batch 70, Loss: 1.2487
Batch 80, Loss: 1.3074
Batch 90, Loss: 1.2901
Batch 100, Loss: 1.2672
Batch 110, Loss: 1.3025
Batch 120, Loss: 1.3230
Batch 130, Loss: 1.2326
Batch 140, Loss: 1.2777
Batch 150, Loss: 1.3704
Batch 160, Loss: 1.3098
Batch 170, Loss: 1.2351
Batch 180, Loss: 1.2562
Batch 190, Loss: 1.2134
Batch 200, Loss: 1.2385
Batch 210, Loss: 1.3136
Batch 220, Loss: 1.2791
Batch 230, Loss: 1.2930
Batch 240, Loss: 1.2735
Batch 250, Loss: 1.2538
Batch 260, Loss: 1.3049
Batch 270, Loss: 1.2479
Batch 280, Loss: 1.2737
Batch 290, Loss: 1.3297
Batch 300, Loss: 1.3127
Batch 310, Loss: 1.2511
Batch 320, Loss: 1.2914
Batch 330, Loss: 1.2597
Batch 340, Loss: 1.3040
Batch 350, Loss: 1.3016
Batch 360, Loss: 1.3311
Batch 370, Loss: 1.2646
Batch 380, Loss: 1.3424
Batch 390, Loss: 1.2988
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.202743530273438 seconds
Epoch 73 accuracy: 61.88%
Batch 10, Loss: 1.2156
Batch 20, Loss: 1.2077
Batch 30, Loss: 1.2294
Batch 40, Loss: 1.2218
Batch 50, Loss: 1.2323
Batch 60, Loss: 1.3123
Batch 70, Loss: 1.2534
Batch 80, Loss: 1.3178
Batch 90, Loss: 1.2356
Batch 100, Loss: 1.3269
Batch 110, Loss: 1.1996
Batch 120, Loss: 1.2138
Batch 130, Loss: 1.1681
Batch 140, Loss: 1.3299
Batch 150, Loss: 1.2739
Batch 160, Loss: 1.1911
Batch 170, Loss: 1.2782
Batch 180, Loss: 1.1979
Batch 190, Loss: 1.3720
Batch 200, Loss: 1.2683
Batch 210, Loss: 1.3352
Batch 220, Loss: 1.2532
Batch 230, Loss: 1.2503
Batch 240, Loss: 1.2891
Batch 250, Loss: 1.3203
Batch 260, Loss: 1.2549
Batch 270, Loss: 1.2697
Batch 280, Loss: 1.2964
Batch 290, Loss: 1.3274
Batch 300, Loss: 1.2724
Batch 310, Loss: 1.2667
Batch 320, Loss: 1.3345
Batch 330, Loss: 1.2655
Batch 340, Loss: 1.3233
Batch 350, Loss: 1.2912
Batch 360, Loss: 1.2775
Batch 370, Loss: 1.3341
Batch 380, Loss: 1.3085
Batch 390, Loss: 1.2689
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.13097381591797 seconds
Epoch 74 accuracy: 56.11%
Batch 10, Loss: 1.2611
Batch 20, Loss: 1.2814
Batch 30, Loss: 1.2042
Batch 40, Loss: 1.2465
Batch 50, Loss: 1.1973
Batch 60, Loss: 1.2052
Batch 70, Loss: 1.2487
Batch 80, Loss: 1.2749
Batch 90, Loss: 1.2359
Batch 100, Loss: 1.2225
Batch 110, Loss: 1.2492
Batch 120, Loss: 1.2458
Batch 130, Loss: 1.2429
Batch 140, Loss: 1.2395
Batch 150, Loss: 1.2219
Batch 160, Loss: 1.2567
Batch 170, Loss: 1.2880
Batch 180, Loss: 1.2903
Batch 190, Loss: 1.2223
Batch 200, Loss: 1.3021
Batch 210, Loss: 1.2411
Batch 220, Loss: 1.2255
Batch 230, Loss: 1.3268
Batch 240, Loss: 1.2447
Batch 250, Loss: 1.2275
Batch 260, Loss: 1.2311
Batch 270, Loss: 1.2501
Batch 280, Loss: 1.2337
Batch 290, Loss: 1.2758
Batch 300, Loss: 1.3684
Batch 310, Loss: 1.2675
Batch 320, Loss: 1.2990
Batch 330, Loss: 1.3417
Batch 340, Loss: 1.3218
Batch 350, Loss: 1.2598
Batch 360, Loss: 1.3589
Batch 370, Loss: 1.3311
Batch 380, Loss: 1.3732
Batch 390, Loss: 1.3102
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.3708233833313 seconds
Epoch 75 accuracy: 62.67%
Batch 10, Loss: 1.1903
Batch 20, Loss: 1.1600
Batch 30, Loss: 1.1823
Batch 40, Loss: 1.1297
Batch 50, Loss: 1.2783
Batch 60, Loss: 1.2098
Batch 70, Loss: 1.2619
Batch 80, Loss: 1.2192
Batch 90, Loss: 1.2466
Batch 100, Loss: 1.2261
Batch 110, Loss: 1.2808
Batch 120, Loss: 1.2818
Batch 130, Loss: 1.2495
Batch 140, Loss: 1.2954
Batch 150, Loss: 1.2312
Batch 160, Loss: 1.2532
Batch 170, Loss: 1.3061
Batch 180, Loss: 1.3486
Batch 190, Loss: 1.2017
Batch 200, Loss: 1.2823
Batch 210, Loss: 1.3127
Batch 220, Loss: 1.2980
Batch 230, Loss: 1.2697
Batch 240, Loss: 1.2554
Batch 250, Loss: 1.2567
Batch 260, Loss: 1.2607
Batch 270, Loss: 1.2781
Batch 280, Loss: 1.3200
Batch 290, Loss: 1.2552
Batch 300, Loss: 1.2788
Batch 310, Loss: 1.2472
Batch 320, Loss: 1.3312
Batch 330, Loss: 1.3445
Batch 340, Loss: 1.2688
Batch 350, Loss: 1.2387
Batch 360, Loss: 1.2594
Batch 370, Loss: 1.2567
Batch 380, Loss: 1.3587
Batch 390, Loss: 1.2773
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.171826601028442 seconds
Epoch 76 accuracy: 58.0%
Batch 10, Loss: 1.2189
Batch 20, Loss: 1.1991
Batch 30, Loss: 1.2223
Batch 40, Loss: 1.1463
Batch 50, Loss: 1.2382
Batch 60, Loss: 1.2314
Batch 70, Loss: 1.2150
Batch 80, Loss: 1.2657
Batch 90, Loss: 1.2018
Batch 100, Loss: 1.2710
Batch 110, Loss: 1.2639
Batch 120, Loss: 1.2731
Batch 130, Loss: 1.1742
Batch 140, Loss: 1.2523
Batch 150, Loss: 1.1947
Batch 160, Loss: 1.2649
Batch 170, Loss: 1.1992
Batch 180, Loss: 1.3124
Batch 190, Loss: 1.2839
Batch 200, Loss: 1.2399
Batch 210, Loss: 1.2436
Batch 220, Loss: 1.2223
Batch 230, Loss: 1.2512
Batch 240, Loss: 1.2147
Batch 250, Loss: 1.2694
Batch 260, Loss: 1.2582
Batch 270, Loss: 1.3493
Batch 280, Loss: 1.2582
Batch 290, Loss: 1.2729
Batch 300, Loss: 1.2556
Batch 310, Loss: 1.3254
Batch 320, Loss: 1.2401
Batch 330, Loss: 1.3062
Batch 340, Loss: 1.2674
Batch 350, Loss: 1.3282
Batch 360, Loss: 1.2610
Batch 370, Loss: 1.2565
Batch 380, Loss: 1.3206
Batch 390, Loss: 1.2463
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.147225618362427 seconds
Epoch 77 accuracy: 58.71%
Batch 10, Loss: 1.3516
Batch 20, Loss: 1.2604
Batch 30, Loss: 1.1756
Batch 40, Loss: 1.1422
Batch 50, Loss: 1.2364
Batch 60, Loss: 1.1855
Batch 70, Loss: 1.1694
Batch 80, Loss: 1.2190
Batch 90, Loss: 1.2676
Batch 100, Loss: 1.2122
Batch 110, Loss: 1.2715
Batch 120, Loss: 1.2673
Batch 130, Loss: 1.2927
Batch 140, Loss: 1.2000
Batch 150, Loss: 1.2435
Batch 160, Loss: 1.2818
Batch 170, Loss: 1.2192
Batch 180, Loss: 1.2607
Batch 190, Loss: 1.2455
Batch 200, Loss: 1.2345
Batch 210, Loss: 1.2964
Batch 220, Loss: 1.2762
Batch 230, Loss: 1.3171
Batch 240, Loss: 1.3317
Batch 250, Loss: 1.2708
Batch 260, Loss: 1.2088
Batch 270, Loss: 1.2777
Batch 280, Loss: 1.2700
Batch 290, Loss: 1.2613
Batch 300, Loss: 1.3024
Batch 310, Loss: 1.2390
Batch 320, Loss: 1.2764
Batch 330, Loss: 1.1833
Batch 340, Loss: 1.2931
Batch 350, Loss: 1.2364
Batch 360, Loss: 1.2129
Batch 370, Loss: 1.1842
Batch 380, Loss: 1.2583
Batch 390, Loss: 1.2495
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.101309061050415 seconds
Epoch 78 accuracy: 61.77%
Batch 10, Loss: 1.2291
Batch 20, Loss: 1.2220
Batch 30, Loss: 1.1985
Batch 40, Loss: 1.1777
Batch 50, Loss: 1.2194
Batch 60, Loss: 1.1902
Batch 70, Loss: 1.2738
Batch 80, Loss: 1.2645
Batch 90, Loss: 1.2282
Batch 100, Loss: 1.2465
Batch 110, Loss: 1.2599
Batch 120, Loss: 1.2117
Batch 130, Loss: 1.2411
Batch 140, Loss: 1.2464
Batch 150, Loss: 1.2858
Batch 160, Loss: 1.2554
Batch 170, Loss: 1.2263
Batch 180, Loss: 1.2102
Batch 190, Loss: 1.2879
Batch 200, Loss: 1.3211
Batch 210, Loss: 1.2030
Batch 220, Loss: 1.2387
Batch 230, Loss: 1.3744
Batch 240, Loss: 1.2896
Batch 250, Loss: 1.2667
Batch 260, Loss: 1.2503
Batch 270, Loss: 1.1611
Batch 280, Loss: 1.2690
Batch 290, Loss: 1.3152
Batch 300, Loss: 1.2990
Batch 310, Loss: 1.2605
Batch 320, Loss: 1.2305
Batch 330, Loss: 1.2172
Batch 340, Loss: 1.2675
Batch 350, Loss: 1.2655
Batch 360, Loss: 1.2688
Batch 370, Loss: 1.2698
Batch 380, Loss: 1.2394
Batch 390, Loss: 1.3660
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.142460107803345 seconds
Epoch 79 accuracy: 63.49%
Batch 10, Loss: 1.2557
Batch 20, Loss: 1.1849
Batch 30, Loss: 1.2087
Batch 40, Loss: 1.1961
Batch 50, Loss: 1.2056
Batch 60, Loss: 1.1572
Batch 70, Loss: 1.1640
Batch 80, Loss: 1.2030
Batch 90, Loss: 1.1780
Batch 100, Loss: 1.2223
Batch 110, Loss: 1.2334
Batch 120, Loss: 1.2781
Batch 130, Loss: 1.1959
Batch 140, Loss: 1.1700
Batch 150, Loss: 1.2094
Batch 160, Loss: 1.1860
Batch 170, Loss: 1.1990
Batch 180, Loss: 1.2110
Batch 190, Loss: 1.2372
Batch 200, Loss: 1.2136
Batch 210, Loss: 1.1933
Batch 220, Loss: 1.2562
Batch 230, Loss: 1.2089
Batch 240, Loss: 1.1953
Batch 250, Loss: 1.2329
Batch 260, Loss: 1.3589
Batch 270, Loss: 1.2156
Batch 280, Loss: 1.2490
Batch 290, Loss: 1.3417
Batch 300, Loss: 1.2465
Batch 310, Loss: 1.2554
Batch 320, Loss: 1.1994
Batch 330, Loss: 1.2459
Batch 340, Loss: 1.2500
Batch 350, Loss: 1.2720
Batch 360, Loss: 1.2188
Batch 370, Loss: 1.2537
Batch 380, Loss: 1.2858
Batch 390, Loss: 1.2540
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.251235008239746 seconds
Epoch 80 accuracy: 60.1%
Batch 10, Loss: 1.1607
Batch 20, Loss: 1.1044
Batch 30, Loss: 1.2763
Batch 40, Loss: 1.1673
Batch 50, Loss: 1.2012
Batch 60, Loss: 1.1643
Batch 70, Loss: 1.1521
Batch 80, Loss: 1.1956
Batch 90, Loss: 1.1656
Batch 100, Loss: 1.1533
Batch 110, Loss: 1.2332
Batch 120, Loss: 1.1547
Batch 130, Loss: 1.2072
Batch 140, Loss: 1.2556
Batch 150, Loss: 1.2765
Batch 160, Loss: 1.1832
Batch 170, Loss: 1.1939
Batch 180, Loss: 1.2185
Batch 190, Loss: 1.1613
Batch 200, Loss: 1.2381
Batch 210, Loss: 1.2198
Batch 220, Loss: 1.2352
Batch 230, Loss: 1.2341
Batch 240, Loss: 1.2297
Batch 250, Loss: 1.2467
Batch 260, Loss: 1.2515
Batch 270, Loss: 1.2647
Batch 280, Loss: 1.2031
Batch 290, Loss: 1.2538
Batch 300, Loss: 1.2563
Batch 310, Loss: 1.2866
Batch 320, Loss: 1.2285
Batch 330, Loss: 1.3172
Batch 340, Loss: 1.2616
Batch 350, Loss: 1.2585
Batch 360, Loss: 1.2867
Batch 370, Loss: 1.2722
Batch 380, Loss: 1.2129
Batch 390, Loss: 1.2316
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.24175238609314 seconds
Epoch 81 accuracy: 59.94%
Batch 10, Loss: 1.2204
Batch 20, Loss: 1.1830
Batch 30, Loss: 1.1676
Batch 40, Loss: 1.1444
Batch 50, Loss: 1.2297
Batch 60, Loss: 1.1456
Batch 70, Loss: 1.1993
Batch 80, Loss: 1.2655
Batch 90, Loss: 1.2044
Batch 100, Loss: 1.1623
Batch 110, Loss: 1.1890
Batch 120, Loss: 1.2382
Batch 130, Loss: 1.2187
Batch 140, Loss: 1.2104
Batch 150, Loss: 1.2068
Batch 160, Loss: 1.2029
Batch 170, Loss: 1.2844
Batch 180, Loss: 1.1803
Batch 190, Loss: 1.1600
Batch 200, Loss: 1.2186
Batch 210, Loss: 1.2108
Batch 220, Loss: 1.2542
Batch 230, Loss: 1.2711
Batch 240, Loss: 1.2645
Batch 250, Loss: 1.2900
Batch 260, Loss: 1.2021
Batch 270, Loss: 1.2406
Batch 280, Loss: 1.2367
Batch 290, Loss: 1.2518
Batch 300, Loss: 1.2914
Batch 310, Loss: 1.2807
Batch 320, Loss: 1.2855
Batch 330, Loss: 1.2024
Batch 340, Loss: 1.2726
Batch 350, Loss: 1.2429
Batch 360, Loss: 1.2734
Batch 370, Loss: 1.2421
Batch 380, Loss: 1.3039
Batch 390, Loss: 1.2997
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.13263177871704 seconds
Epoch 82 accuracy: 63.85%
Batch 10, Loss: 1.1661
Batch 20, Loss: 1.1591
Batch 30, Loss: 1.1670
Batch 40, Loss: 1.1466
Batch 50, Loss: 1.2020
Batch 60, Loss: 1.1481
Batch 70, Loss: 1.1610
Batch 80, Loss: 1.1343
Batch 90, Loss: 1.1753
Batch 100, Loss: 1.1443
Batch 110, Loss: 1.1686
Batch 120, Loss: 1.1529
Batch 130, Loss: 1.2400
Batch 140, Loss: 1.2082
Batch 150, Loss: 1.2660
Batch 160, Loss: 1.2506
Batch 170, Loss: 1.2212
Batch 180, Loss: 1.1383
Batch 190, Loss: 1.2199
Batch 200, Loss: 1.1904
Batch 210, Loss: 1.2110
Batch 220, Loss: 1.2327
Batch 230, Loss: 1.2321
Batch 240, Loss: 1.2593
Batch 250, Loss: 1.2417
Batch 260, Loss: 1.2207
Batch 270, Loss: 1.1966
Batch 280, Loss: 1.2847
Batch 290, Loss: 1.2068
Batch 300, Loss: 1.2304
Batch 310, Loss: 1.2770
Batch 320, Loss: 1.2437
Batch 330, Loss: 1.2297
Batch 340, Loss: 1.2366
Batch 350, Loss: 1.2260
Batch 360, Loss: 1.2627
Batch 370, Loss: 1.1987
Batch 380, Loss: 1.2552
Batch 390, Loss: 1.2347
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.159847259521484 seconds
Epoch 83 accuracy: 59.45%
Batch 10, Loss: 1.1981
Batch 20, Loss: 1.1451
Batch 30, Loss: 1.1861
Batch 40, Loss: 1.2267
Batch 50, Loss: 1.1236
Batch 60, Loss: 1.1530
Batch 70, Loss: 1.1978
Batch 80, Loss: 1.2678
Batch 90, Loss: 1.2002
Batch 100, Loss: 1.1961
Batch 110, Loss: 1.2209
Batch 120, Loss: 1.1259
Batch 130, Loss: 1.2553
Batch 140, Loss: 1.2778
Batch 150, Loss: 1.1362
Batch 160, Loss: 1.1813
Batch 170, Loss: 1.2149
Batch 180, Loss: 1.1940
Batch 190, Loss: 1.2145
Batch 200, Loss: 1.1885
Batch 210, Loss: 1.2061
Batch 220, Loss: 1.1881
Batch 230, Loss: 1.2336
Batch 240, Loss: 1.2194
Batch 250, Loss: 1.2804
Batch 260, Loss: 1.1954
Batch 270, Loss: 1.1041
Batch 280, Loss: 1.2273
Batch 290, Loss: 1.2625
Batch 300, Loss: 1.2161
Batch 310, Loss: 1.2888
Batch 320, Loss: 1.3123
Batch 330, Loss: 1.2888
Batch 340, Loss: 1.2611
Batch 350, Loss: 1.2801
Batch 360, Loss: 1.2859
Batch 370, Loss: 1.2288
Batch 380, Loss: 1.1888
Batch 390, Loss: 1.2699
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.159980535507202 seconds
Epoch 84 accuracy: 64.01%
Batch 10, Loss: 1.1462
Batch 20, Loss: 1.1504
Batch 30, Loss: 1.1245
Batch 40, Loss: 1.1719
Batch 50, Loss: 1.1545
Batch 60, Loss: 1.1833
Batch 70, Loss: 1.1301
Batch 80, Loss: 1.1205
Batch 90, Loss: 1.2062
Batch 100, Loss: 1.2084
Batch 110, Loss: 1.1664
Batch 120, Loss: 1.1858
Batch 130, Loss: 1.1843
Batch 140, Loss: 1.1785
Batch 150, Loss: 1.1986
Batch 160, Loss: 1.2608
Batch 170, Loss: 1.2103
Batch 180, Loss: 1.1633
Batch 190, Loss: 1.1815
Batch 200, Loss: 1.2962
Batch 210, Loss: 1.2019
Batch 220, Loss: 1.2349
Batch 230, Loss: 1.1184
Batch 240, Loss: 1.1877
Batch 250, Loss: 1.2431
Batch 260, Loss: 1.2418
Batch 270, Loss: 1.2079
Batch 280, Loss: 1.1704
Batch 290, Loss: 1.2361
Batch 300, Loss: 1.2082
Batch 310, Loss: 1.2287
Batch 320, Loss: 1.1501
Batch 330, Loss: 1.2092
Batch 340, Loss: 1.2515
Batch 350, Loss: 1.1946
Batch 360, Loss: 1.2637
Batch 370, Loss: 1.2244
Batch 380, Loss: 1.2544
Batch 390, Loss: 1.2704
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.11788821220398 seconds
Epoch 85 accuracy: 59.52%
Batch 10, Loss: 1.1615
Batch 20, Loss: 1.1782
Batch 30, Loss: 1.1797
Batch 40, Loss: 1.2115
Batch 50, Loss: 1.1500
Batch 60, Loss: 1.1520
Batch 70, Loss: 1.1443
Batch 80, Loss: 1.1339
Batch 90, Loss: 1.1752
Batch 100, Loss: 1.1416
Batch 110, Loss: 1.1927
Batch 120, Loss: 1.2242
Batch 130, Loss: 1.1438
Batch 140, Loss: 1.1643
Batch 150, Loss: 1.2084
Batch 160, Loss: 1.2049
Batch 170, Loss: 1.2598
Batch 180, Loss: 1.2190
Batch 190, Loss: 1.2042
Batch 200, Loss: 1.2255
Batch 210, Loss: 1.1703
Batch 220, Loss: 1.1681
Batch 230, Loss: 1.2074
Batch 240, Loss: 1.2285
Batch 250, Loss: 1.2148
Batch 260, Loss: 1.2063
Batch 270, Loss: 1.2311
Batch 280, Loss: 1.1438
Batch 290, Loss: 1.2489
Batch 300, Loss: 1.1619
Batch 310, Loss: 1.2310
Batch 320, Loss: 1.2708
Batch 330, Loss: 1.1583
Batch 340, Loss: 1.1605
Batch 350, Loss: 1.1796
Batch 360, Loss: 1.2518
Batch 370, Loss: 1.2548
Batch 380, Loss: 1.2124
Batch 390, Loss: 1.2210
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.11538529396057 seconds
Epoch 86 accuracy: 62.36%
Batch 10, Loss: 1.1568
Batch 20, Loss: 1.0943
Batch 30, Loss: 1.1673
Batch 40, Loss: 1.1448
Batch 50, Loss: 1.1577
Batch 60, Loss: 1.1693
Batch 70, Loss: 1.1192
Batch 80, Loss: 1.1834
Batch 90, Loss: 1.1497
Batch 100, Loss: 1.1613
Batch 110, Loss: 1.2189
Batch 120, Loss: 1.1731
Batch 130, Loss: 1.1110
Batch 140, Loss: 1.1880
Batch 150, Loss: 1.1250
Batch 160, Loss: 1.1966
Batch 170, Loss: 1.2129
Batch 180, Loss: 1.1685
Batch 190, Loss: 1.1844
Batch 200, Loss: 1.2316
Batch 210, Loss: 1.2496
Batch 220, Loss: 1.2042
Batch 230, Loss: 1.1452
Batch 240, Loss: 1.1592
Batch 250, Loss: 1.1826
Batch 260, Loss: 1.1885
Batch 270, Loss: 1.2053
Batch 280, Loss: 1.2244
Batch 290, Loss: 1.1797
Batch 300, Loss: 1.2524
Batch 310, Loss: 1.1675
Batch 320, Loss: 1.2198
Batch 330, Loss: 1.1896
Batch 340, Loss: 1.2359
Batch 350, Loss: 1.2436
Batch 360, Loss: 1.1668
Batch 370, Loss: 1.1944
Batch 380, Loss: 1.1778
Batch 390, Loss: 1.2071
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.074658632278442 seconds
Epoch 87 accuracy: 63.83%
Batch 10, Loss: 1.1699
Batch 20, Loss: 1.1498
Batch 30, Loss: 1.1540
Batch 40, Loss: 1.1374
Batch 50, Loss: 1.1182
Batch 60, Loss: 1.1182
Batch 70, Loss: 1.0936
Batch 80, Loss: 1.1033
Batch 90, Loss: 1.1368
Batch 100, Loss: 1.1462
Batch 110, Loss: 1.1912
Batch 120, Loss: 1.1334
Batch 130, Loss: 1.1732
Batch 140, Loss: 1.1715
Batch 150, Loss: 1.2042
Batch 160, Loss: 1.2113
Batch 170, Loss: 1.1204
Batch 180, Loss: 1.2015
Batch 190, Loss: 1.1458
Batch 200, Loss: 1.1621
Batch 210, Loss: 1.1579
Batch 220, Loss: 1.1920
Batch 230, Loss: 1.1579
Batch 240, Loss: 1.2113
Batch 250, Loss: 1.1860
Batch 260, Loss: 1.2274
Batch 270, Loss: 1.2490
Batch 280, Loss: 1.2580
Batch 290, Loss: 1.2069
Batch 300, Loss: 1.2155
Batch 310, Loss: 1.2387
Batch 320, Loss: 1.2106
Batch 330, Loss: 1.2604
Batch 340, Loss: 1.2181
Batch 350, Loss: 1.2830
Batch 360, Loss: 1.2045
Batch 370, Loss: 1.2229
Batch 380, Loss: 1.1469
Batch 390, Loss: 1.1855
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.076602458953857 seconds
Epoch 88 accuracy: 63.39%
Batch 10, Loss: 1.1319
Batch 20, Loss: 1.1576
Batch 30, Loss: 1.0617
Batch 40, Loss: 1.1293
Batch 50, Loss: 1.1728
Batch 60, Loss: 1.1621
Batch 70, Loss: 1.1459
Batch 80, Loss: 1.1761
Batch 90, Loss: 1.1585
Batch 100, Loss: 1.1720
Batch 110, Loss: 1.1969
Batch 120, Loss: 1.2241
Batch 130, Loss: 1.1258
Batch 140, Loss: 1.1804
Batch 150, Loss: 1.1147
Batch 160, Loss: 1.1468
Batch 170, Loss: 1.1790
Batch 180, Loss: 1.1725
Batch 190, Loss: 1.2055
Batch 200, Loss: 1.2038
Batch 210, Loss: 1.1057
Batch 220, Loss: 1.1873
Batch 230, Loss: 1.1618
Batch 240, Loss: 1.2027
Batch 250, Loss: 1.2166
Batch 260, Loss: 1.1469
Batch 270, Loss: 1.2137
Batch 280, Loss: 1.1930
Batch 290, Loss: 1.1326
Batch 300, Loss: 1.2383
Batch 310, Loss: 1.2049
Batch 320, Loss: 1.2058
Batch 330, Loss: 1.1780
Batch 340, Loss: 1.2072
Batch 350, Loss: 1.2167
Batch 360, Loss: 1.2069
Batch 370, Loss: 1.2091
Batch 380, Loss: 1.2299
Batch 390, Loss: 1.2000
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.047287464141846 seconds
Epoch 89 accuracy: 64.7%
Batch 10, Loss: 1.1307
Batch 20, Loss: 1.1066
Batch 30, Loss: 1.0189
Batch 40, Loss: 1.1292
Batch 50, Loss: 1.1887
Batch 60, Loss: 1.1448
Batch 70, Loss: 1.1607
Batch 80, Loss: 1.1099
Batch 90, Loss: 1.1269
Batch 100, Loss: 1.1525
Batch 110, Loss: 1.1880
Batch 120, Loss: 1.2353
Batch 130, Loss: 1.1966
Batch 140, Loss: 1.1146
Batch 150, Loss: 1.1660
Batch 160, Loss: 1.1350
Batch 170, Loss: 1.1967
Batch 180, Loss: 1.1797
Batch 190, Loss: 1.1917
Batch 200, Loss: 1.1536
Batch 210, Loss: 1.1869
Batch 220, Loss: 1.1472
Batch 230, Loss: 1.1959
Batch 240, Loss: 1.2056
Batch 250, Loss: 1.2150
Batch 260, Loss: 1.1867
Batch 270, Loss: 1.1646
Batch 280, Loss: 1.2024
Batch 290, Loss: 1.1927
Batch 300, Loss: 1.1874
Batch 310, Loss: 1.1718
Batch 320, Loss: 1.2400
Batch 330, Loss: 1.1532
Batch 340, Loss: 1.2095
Batch 350, Loss: 1.1691
Batch 360, Loss: 1.1346
Batch 370, Loss: 1.2017
Batch 380, Loss: 1.1446
Batch 390, Loss: 1.2143
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.215242624282837 seconds
Epoch 90 accuracy: 64.36%
Batch 10, Loss: 1.0656
Batch 20, Loss: 1.1290
Batch 30, Loss: 1.0853
Batch 40, Loss: 1.1667
Batch 50, Loss: 1.1558
Batch 60, Loss: 1.1385
Batch 70, Loss: 1.0581
Batch 80, Loss: 1.1055
Batch 90, Loss: 1.1720
Batch 100, Loss: 1.1260
Batch 110, Loss: 1.1131
Batch 120, Loss: 1.1493
Batch 130, Loss: 1.2316
Batch 140, Loss: 1.1534
Batch 150, Loss: 1.1579
Batch 160, Loss: 1.1155
Batch 170, Loss: 1.1407
Batch 180, Loss: 1.1793
Batch 190, Loss: 1.1640
Batch 200, Loss: 1.1667
Batch 210, Loss: 1.2091
Batch 220, Loss: 1.1291
Batch 230, Loss: 1.1508
Batch 240, Loss: 1.1481
Batch 250, Loss: 1.1976
Batch 260, Loss: 1.1395
Batch 270, Loss: 1.1707
Batch 280, Loss: 1.1649
Batch 290, Loss: 1.1738
Batch 300, Loss: 1.1676
Batch 310, Loss: 1.2190
Batch 320, Loss: 1.1932
Batch 330, Loss: 1.1965
Batch 340, Loss: 1.1963
Batch 350, Loss: 1.1830
Batch 360, Loss: 1.2188
Batch 370, Loss: 1.2242
Batch 380, Loss: 1.1903
Batch 390, Loss: 1.2064
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.09644913673401 seconds
Epoch 91 accuracy: 64.03%
Batch 10, Loss: 1.1142
Batch 20, Loss: 1.1251
Batch 30, Loss: 1.0961
Batch 40, Loss: 1.0976
Batch 50, Loss: 1.0539
Batch 60, Loss: 1.1812
Batch 70, Loss: 1.1401
Batch 80, Loss: 1.1729
Batch 90, Loss: 1.0958
Batch 100, Loss: 1.1479
Batch 110, Loss: 1.1658
Batch 120, Loss: 1.1354
Batch 130, Loss: 1.1322
Batch 140, Loss: 1.1555
Batch 150, Loss: 1.2297
Batch 160, Loss: 1.1886
Batch 170, Loss: 1.1224
Batch 180, Loss: 1.1559
Batch 190, Loss: 1.1333
Batch 200, Loss: 1.1429
Batch 210, Loss: 1.1734
Batch 220, Loss: 1.0887
Batch 230, Loss: 1.1320
Batch 240, Loss: 1.2221
Batch 250, Loss: 1.2028
Batch 260, Loss: 1.1828
Batch 270, Loss: 1.1567
Batch 280, Loss: 1.1878
Batch 290, Loss: 1.1889
Batch 300, Loss: 1.1609
Batch 310, Loss: 1.1503
Batch 320, Loss: 1.1609
Batch 330, Loss: 1.1739
Batch 340, Loss: 1.1011
Batch 350, Loss: 1.1795
Batch 360, Loss: 1.2312
Batch 370, Loss: 1.1759
Batch 380, Loss: 1.1832
Batch 390, Loss: 1.2078
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.061513900756836 seconds
Epoch 92 accuracy: 63.84%
Batch 10, Loss: 1.1340
Batch 20, Loss: 1.1429
Batch 30, Loss: 1.1147
Batch 40, Loss: 1.1685
Batch 50, Loss: 1.1580
Batch 60, Loss: 1.1163
Batch 70, Loss: 1.1273
Batch 80, Loss: 1.0799
Batch 90, Loss: 1.1551
Batch 100, Loss: 1.1184
Batch 110, Loss: 1.1423
Batch 120, Loss: 1.0849
Batch 130, Loss: 1.1687
Batch 140, Loss: 1.0824
Batch 150, Loss: 1.0467
Batch 160, Loss: 1.1883
Batch 170, Loss: 1.1339
Batch 180, Loss: 1.1418
Batch 190, Loss: 1.1272
Batch 200, Loss: 1.1405
Batch 210, Loss: 1.0765
Batch 220, Loss: 1.1845
Batch 230, Loss: 1.1433
Batch 240, Loss: 1.1297
Batch 250, Loss: 1.2027
Batch 260, Loss: 1.1529
Batch 270, Loss: 1.1348
Batch 280, Loss: 1.1265
Batch 290, Loss: 1.1142
Batch 300, Loss: 1.1346
Batch 310, Loss: 1.1592
Batch 320, Loss: 1.1969
Batch 330, Loss: 1.2502
Batch 340, Loss: 1.1920
Batch 350, Loss: 1.1276
Batch 360, Loss: 1.1922
Batch 370, Loss: 1.1536
Batch 380, Loss: 1.1271
Batch 390, Loss: 1.1540
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.216440200805664 seconds
Epoch 93 accuracy: 62.09%
Batch 10, Loss: 1.0866
Batch 20, Loss: 1.1391
Batch 30, Loss: 1.0325
Batch 40, Loss: 1.1531
Batch 50, Loss: 1.0620
Batch 60, Loss: 1.1492
Batch 70, Loss: 1.1080
Batch 80, Loss: 1.1439
Batch 90, Loss: 1.0716
Batch 100, Loss: 1.0889
Batch 110, Loss: 1.1125
Batch 120, Loss: 1.1029
Batch 130, Loss: 1.1597
Batch 140, Loss: 1.0755
Batch 150, Loss: 1.1834
Batch 160, Loss: 1.2148
Batch 170, Loss: 1.1187
Batch 180, Loss: 1.1015
Batch 190, Loss: 1.0666
Batch 200, Loss: 1.1091
Batch 210, Loss: 1.2153
Batch 220, Loss: 1.1938
Batch 230, Loss: 1.1945
Batch 240, Loss: 1.1439
Batch 250, Loss: 1.1540
Batch 260, Loss: 1.1333
Batch 270, Loss: 1.1273
Batch 280, Loss: 1.1607
Batch 290, Loss: 1.1277
Batch 300, Loss: 1.1894
Batch 310, Loss: 1.1620
Batch 320, Loss: 1.2276
Batch 330, Loss: 1.1993
Batch 340, Loss: 1.2043
Batch 350, Loss: 1.2058
Batch 360, Loss: 1.2285
Batch 370, Loss: 1.2006
Batch 380, Loss: 1.1572
Batch 390, Loss: 1.1754
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.210384130477905 seconds
Epoch 94 accuracy: 66.09%
Batch 10, Loss: 1.1036
Batch 20, Loss: 1.0576
Batch 30, Loss: 1.1333
Batch 40, Loss: 1.1055
Batch 50, Loss: 1.0686
Batch 60, Loss: 1.1354
Batch 70, Loss: 1.0904
Batch 80, Loss: 1.1540
Batch 90, Loss: 1.1126
Batch 100, Loss: 1.1390
Batch 110, Loss: 1.0854
Batch 120, Loss: 1.1480
Batch 130, Loss: 1.1043
Batch 140, Loss: 1.1532
Batch 150, Loss: 1.1408
Batch 160, Loss: 1.1257
Batch 170, Loss: 1.0919
Batch 180, Loss: 1.1117
Batch 190, Loss: 1.1356
Batch 200, Loss: 1.1604
Batch 210, Loss: 1.0898
Batch 220, Loss: 1.1754
Batch 230, Loss: 1.1862
Batch 240, Loss: 1.1840
Batch 250, Loss: 1.1927
Batch 260, Loss: 1.1730
Batch 270, Loss: 1.1232
Batch 280, Loss: 1.1368
Batch 290, Loss: 1.2002
Batch 300, Loss: 1.1181
Batch 310, Loss: 1.1305
Batch 320, Loss: 1.2050
Batch 330, Loss: 1.1539
Batch 340, Loss: 1.1937
Batch 350, Loss: 1.1589
Batch 360, Loss: 1.1714
Batch 370, Loss: 1.2255
Batch 380, Loss: 1.2008
Batch 390, Loss: 1.1683
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.186585187911987 seconds
Epoch 95 accuracy: 62.55%
Batch 10, Loss: 1.1057
Batch 20, Loss: 1.0789
Batch 30, Loss: 1.1099
Batch 40, Loss: 1.0166
Batch 50, Loss: 1.0738
Batch 60, Loss: 1.0674
Batch 70, Loss: 1.1331
Batch 80, Loss: 1.1407
Batch 90, Loss: 1.1113
Batch 100, Loss: 1.1048
Batch 110, Loss: 1.1025
Batch 120, Loss: 1.1368
Batch 130, Loss: 1.0994
Batch 140, Loss: 1.0349
Batch 150, Loss: 1.0995
Batch 160, Loss: 1.1470
Batch 170, Loss: 1.0870
Batch 180, Loss: 1.0847
Batch 190, Loss: 1.0652
Batch 200, Loss: 1.1266
Batch 210, Loss: 1.1145
Batch 220, Loss: 1.1364
Batch 230, Loss: 1.1571
Batch 240, Loss: 1.0956
Batch 250, Loss: 1.1619
Batch 260, Loss: 1.1456
Batch 270, Loss: 1.1335
Batch 280, Loss: 1.1050
Batch 290, Loss: 1.1742
Batch 300, Loss: 1.1392
Batch 310, Loss: 1.1062
Batch 320, Loss: 1.1917
Batch 330, Loss: 1.1587
Batch 340, Loss: 1.1823
Batch 350, Loss: 1.1572
Batch 360, Loss: 1.1530
Batch 370, Loss: 1.1770
Batch 380, Loss: 1.1568
Batch 390, Loss: 1.1145
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.146779537200928 seconds
Epoch 96 accuracy: 65.27%
Batch 10, Loss: 1.0643
Batch 20, Loss: 1.0740
Batch 30, Loss: 1.0687
Batch 40, Loss: 1.0891
Batch 50, Loss: 1.1425
Batch 60, Loss: 1.0438
Batch 70, Loss: 1.0556
Batch 80, Loss: 1.1073
Batch 90, Loss: 1.0869
Batch 100, Loss: 1.0868
Batch 110, Loss: 1.1359
Batch 120, Loss: 1.0721
Batch 130, Loss: 1.1254
Batch 140, Loss: 1.1364
Batch 150, Loss: 1.1717
Batch 160, Loss: 1.1200
Batch 170, Loss: 1.1058
Batch 180, Loss: 1.1115
Batch 190, Loss: 1.1315
Batch 200, Loss: 1.1172
Batch 210, Loss: 1.1667
Batch 220, Loss: 1.0916
Batch 230, Loss: 1.1011
Batch 240, Loss: 1.1569
Batch 250, Loss: 1.1706
Batch 260, Loss: 1.1337
Batch 270, Loss: 1.1176
Batch 280, Loss: 1.1381
Batch 290, Loss: 1.1367
Batch 300, Loss: 1.1228
Batch 310, Loss: 1.1782
Batch 320, Loss: 1.1655
Batch 330, Loss: 1.1625
Batch 340, Loss: 1.1713
Batch 350, Loss: 1.1402
Batch 360, Loss: 1.1393
Batch 370, Loss: 1.1397
Batch 380, Loss: 1.1805
Batch 390, Loss: 1.1265
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.17704725265503 seconds
Epoch 97 accuracy: 67.25%
Batch 10, Loss: 1.0581
Batch 20, Loss: 1.0329
Batch 30, Loss: 1.0858
Batch 40, Loss: 1.0677
Batch 50, Loss: 0.9942
Batch 60, Loss: 1.0425
Batch 70, Loss: 1.0727
Batch 80, Loss: 1.0471
Batch 90, Loss: 1.0401
Batch 100, Loss: 1.0631
Batch 110, Loss: 1.0613
Batch 120, Loss: 1.0743
Batch 130, Loss: 1.0734
Batch 140, Loss: 1.1601
Batch 150, Loss: 1.1272
Batch 160, Loss: 1.0793
Batch 170, Loss: 1.1366
Batch 180, Loss: 1.1972
Batch 190, Loss: 1.1358
Batch 200, Loss: 1.0955
Batch 210, Loss: 1.1051
Batch 220, Loss: 1.1434
Batch 230, Loss: 1.1533
Batch 240, Loss: 1.1426
Batch 250, Loss: 1.1320
Batch 260, Loss: 1.0822
Batch 270, Loss: 1.0996
Batch 280, Loss: 1.1130
Batch 290, Loss: 1.1501
Batch 300, Loss: 1.1695
Batch 310, Loss: 1.1366
Batch 320, Loss: 1.1062
Batch 330, Loss: 1.1202
Batch 340, Loss: 1.1916
Batch 350, Loss: 1.1319
Batch 360, Loss: 1.1204
Batch 370, Loss: 1.0802
Batch 380, Loss: 1.1469
Batch 390, Loss: 1.0963
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.23712968826294 seconds
Epoch 98 accuracy: 64.5%
Batch 10, Loss: 1.0582
Batch 20, Loss: 1.1025
Batch 30, Loss: 1.0954
Batch 40, Loss: 1.0423
Batch 50, Loss: 1.0563
Batch 60, Loss: 1.0931
Batch 70, Loss: 1.0550
Batch 80, Loss: 1.0679
Batch 90, Loss: 1.0647
Batch 100, Loss: 1.1476
Batch 110, Loss: 1.0747
Batch 120, Loss: 1.0818
Batch 130, Loss: 1.0501
Batch 140, Loss: 1.0852
Batch 150, Loss: 1.1383
Batch 160, Loss: 1.1504
Batch 170, Loss: 1.1377
Batch 180, Loss: 1.1117
Batch 190, Loss: 1.1315
Batch 200, Loss: 1.1235
Batch 210, Loss: 1.1776
Batch 220, Loss: 1.1225
Batch 230, Loss: 1.1279
Batch 240, Loss: 1.0935
Batch 250, Loss: 1.1381
Batch 260, Loss: 1.1900
Batch 270, Loss: 1.1353
Batch 280, Loss: 1.2112
Batch 290, Loss: 1.1417
Batch 300, Loss: 1.1343
Batch 310, Loss: 1.1699
Batch 320, Loss: 1.1126
Batch 330, Loss: 1.1398
Batch 340, Loss: 1.1637
Batch 350, Loss: 1.1730
Batch 360, Loss: 1.1636
Batch 370, Loss: 1.2337
Batch 380, Loss: 1.1338
Batch 390, Loss: 1.1006
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.287556409835815 seconds
Epoch 99 accuracy: 62.91%
Batch 10, Loss: 1.0494
Batch 20, Loss: 1.0585
Batch 30, Loss: 1.0440
Batch 40, Loss: 1.0562
Batch 50, Loss: 1.1335
Batch 60, Loss: 1.0780
Batch 70, Loss: 1.0415
Batch 80, Loss: 1.1146
Batch 90, Loss: 1.0649
Batch 100, Loss: 1.1030
Batch 110, Loss: 1.0760
Batch 120, Loss: 1.0395
Batch 130, Loss: 1.0985
Batch 140, Loss: 1.0197
Batch 150, Loss: 1.0573
Batch 160, Loss: 1.1090
Batch 170, Loss: 1.1129
Batch 180, Loss: 1.0951
Batch 190, Loss: 1.1010
Batch 200, Loss: 1.1427
Batch 210, Loss: 1.1329
Batch 220, Loss: 1.0583
Batch 230, Loss: 1.1330
Batch 240, Loss: 1.1473
Batch 250, Loss: 1.0553
Batch 260, Loss: 1.0232
Batch 270, Loss: 1.1297
Batch 280, Loss: 1.1399
Batch 290, Loss: 1.1803
Batch 300, Loss: 1.1126
Batch 310, Loss: 1.1290
Batch 320, Loss: 1.1274
Batch 330, Loss: 1.1391
Batch 340, Loss: 1.1720
Batch 350, Loss: 1.1173
Batch 360, Loss: 1.2030
Batch 370, Loss: 1.1179
Batch 380, Loss: 1.1194
Batch 390, Loss: 1.1609
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.13409924507141 seconds
Epoch 100 accuracy: 66.81%
Batch 10, Loss: 1.0454
Batch 20, Loss: 1.0305
Batch 30, Loss: 1.0409
Batch 40, Loss: 1.0359
Batch 50, Loss: 1.0069
Batch 60, Loss: 1.0572
Batch 70, Loss: 1.0841
Batch 80, Loss: 0.9918
Batch 90, Loss: 1.1201
Batch 100, Loss: 1.0924
Batch 110, Loss: 1.1209
Batch 120, Loss: 1.0531
Batch 130, Loss: 1.0742
Batch 140, Loss: 1.1241
Batch 150, Loss: 1.1080
Batch 160, Loss: 1.1141
Batch 170, Loss: 1.0586
Batch 180, Loss: 1.0932
Batch 190, Loss: 1.1045
Batch 200, Loss: 1.0672
Batch 210, Loss: 1.0856
Batch 220, Loss: 1.0662
Batch 230, Loss: 1.1026
Batch 240, Loss: 1.1209
Batch 250, Loss: 1.1796
Batch 260, Loss: 1.0721
Batch 270, Loss: 1.1010
Batch 280, Loss: 1.0741
Batch 290, Loss: 1.0964
Batch 300, Loss: 1.0887
Batch 310, Loss: 1.1659
Batch 320, Loss: 1.0113
Batch 330, Loss: 1.0836
Batch 340, Loss: 1.1023
Batch 350, Loss: 1.0615
Batch 360, Loss: 1.1210
Batch 370, Loss: 1.1550
Batch 380, Loss: 1.1380
Batch 390, Loss: 1.0641
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.064500331878662 seconds
Epoch 101 accuracy: 65.86%
Batch 10, Loss: 0.9755
Batch 20, Loss: 1.0260
Batch 30, Loss: 1.0559
Batch 40, Loss: 1.0819
Batch 50, Loss: 1.0937
Batch 60, Loss: 1.0298
Batch 70, Loss: 1.0708
Batch 80, Loss: 1.1315
Batch 90, Loss: 1.0623
Batch 100, Loss: 1.0663
Batch 110, Loss: 1.0331
Batch 120, Loss: 1.0253
Batch 130, Loss: 1.0374
Batch 140, Loss: 1.0922
Batch 150, Loss: 1.0973
Batch 160, Loss: 1.0605
Batch 170, Loss: 1.0600
Batch 180, Loss: 1.0907
Batch 190, Loss: 1.0930
Batch 200, Loss: 1.0944
Batch 210, Loss: 1.1156
Batch 220, Loss: 1.1434
Batch 230, Loss: 1.1014
Batch 240, Loss: 1.0746
Batch 250, Loss: 1.0922
Batch 260, Loss: 1.0980
Batch 270, Loss: 1.1074
Batch 280, Loss: 1.1340
Batch 290, Loss: 1.2188
Batch 300, Loss: 1.1119
Batch 310, Loss: 1.1557
Batch 320, Loss: 1.0770
Batch 330, Loss: 1.0609
Batch 340, Loss: 1.0933
Batch 350, Loss: 1.0827
Batch 360, Loss: 1.0946
Batch 370, Loss: 1.1222
Batch 380, Loss: 1.1078
Batch 390, Loss: 1.0510
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.15131640434265 seconds
Epoch 102 accuracy: 64.82%
Batch 10, Loss: 1.0566
Batch 20, Loss: 1.0559
Batch 30, Loss: 1.0114
Batch 40, Loss: 1.0091
Batch 50, Loss: 1.0156
Batch 60, Loss: 0.9724
Batch 70, Loss: 1.0545
Batch 80, Loss: 1.0484
Batch 90, Loss: 1.0109
Batch 100, Loss: 1.0277
Batch 110, Loss: 1.0973
Batch 120, Loss: 1.1184
Batch 130, Loss: 1.0369
Batch 140, Loss: 1.0048
Batch 150, Loss: 1.0421
Batch 160, Loss: 1.1291
Batch 170, Loss: 1.0941
Batch 180, Loss: 1.0606
Batch 190, Loss: 1.1057
Batch 200, Loss: 0.9666
Batch 210, Loss: 1.0729
Batch 220, Loss: 1.1641
Batch 230, Loss: 1.0797
Batch 240, Loss: 1.1030
Batch 250, Loss: 1.0809
Batch 260, Loss: 1.0666
Batch 270, Loss: 1.1206
Batch 280, Loss: 1.1511
Batch 290, Loss: 1.0233
Batch 300, Loss: 1.0285
Batch 310, Loss: 1.0752
Batch 320, Loss: 1.0753
Batch 330, Loss: 1.0937
Batch 340, Loss: 1.0640
Batch 350, Loss: 1.1093
Batch 360, Loss: 1.1214
Batch 370, Loss: 1.0506
Batch 380, Loss: 1.1437
Batch 390, Loss: 1.1344
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.211716651916504 seconds
Epoch 103 accuracy: 66.69%
Batch 10, Loss: 1.0935
Batch 20, Loss: 1.1172
Batch 30, Loss: 0.9865
Batch 40, Loss: 1.0183
Batch 50, Loss: 1.0678
Batch 60, Loss: 1.1285
Batch 70, Loss: 0.9824
Batch 80, Loss: 1.0460
Batch 90, Loss: 1.0462
Batch 100, Loss: 1.0574
Batch 110, Loss: 0.9893
Batch 120, Loss: 1.0300
Batch 130, Loss: 1.0672
Batch 140, Loss: 1.0165
Batch 150, Loss: 1.0183
Batch 160, Loss: 1.0967
Batch 170, Loss: 1.0418
Batch 180, Loss: 1.1038
Batch 190, Loss: 1.0212
Batch 200, Loss: 1.0247
Batch 210, Loss: 1.0299
Batch 220, Loss: 1.0473
Batch 230, Loss: 1.0785
Batch 240, Loss: 1.0138
Batch 250, Loss: 1.1130
Batch 260, Loss: 1.0769
Batch 270, Loss: 1.0901
Batch 280, Loss: 1.0736
Batch 290, Loss: 1.1935
Batch 300, Loss: 1.0934
Batch 310, Loss: 1.0762
Batch 320, Loss: 1.0620
Batch 330, Loss: 1.1310
Batch 340, Loss: 1.1009
Batch 350, Loss: 1.1235
Batch 360, Loss: 1.0669
Batch 370, Loss: 1.0855
Batch 380, Loss: 1.1401
Batch 390, Loss: 1.0352
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.139376401901245 seconds
Epoch 104 accuracy: 66.39%
Batch 10, Loss: 0.9612
Batch 20, Loss: 0.9708
Batch 30, Loss: 0.9581
Batch 40, Loss: 0.9979
Batch 50, Loss: 1.0069
Batch 60, Loss: 1.0392
Batch 70, Loss: 1.0460
Batch 80, Loss: 1.0236
Batch 90, Loss: 1.0567
Batch 100, Loss: 1.0290
Batch 110, Loss: 1.0351
Batch 120, Loss: 1.0500
Batch 130, Loss: 1.0407
Batch 140, Loss: 1.0634
Batch 150, Loss: 1.0386
Batch 160, Loss: 1.0218
Batch 170, Loss: 0.9735
Batch 180, Loss: 1.0685
Batch 190, Loss: 1.1092
Batch 200, Loss: 1.1194
Batch 210, Loss: 1.0447
Batch 220, Loss: 1.1041
Batch 230, Loss: 0.9946
Batch 240, Loss: 1.0623
Batch 250, Loss: 1.0592
Batch 260, Loss: 1.1144
Batch 270, Loss: 1.0919
Batch 280, Loss: 1.0586
Batch 290, Loss: 1.0847
Batch 300, Loss: 1.1150
Batch 310, Loss: 1.0452
Batch 320, Loss: 1.0583
Batch 330, Loss: 1.1226
Batch 340, Loss: 1.1245
Batch 350, Loss: 1.1359
Batch 360, Loss: 1.0874
Batch 370, Loss: 1.0897
Batch 380, Loss: 1.0968
Batch 390, Loss: 1.0827
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.1484215259552 seconds
Epoch 105 accuracy: 66.8%
Batch 10, Loss: 1.0346
Batch 20, Loss: 1.0099
Batch 30, Loss: 1.0645
Batch 40, Loss: 0.9920
Batch 50, Loss: 1.0662
Batch 60, Loss: 1.0622
Batch 70, Loss: 1.0290
Batch 80, Loss: 1.0294
Batch 90, Loss: 0.9914
Batch 100, Loss: 1.0454
Batch 110, Loss: 1.0107
Batch 120, Loss: 1.0134
Batch 130, Loss: 1.0247
Batch 140, Loss: 0.9858
Batch 150, Loss: 1.1087
Batch 160, Loss: 1.0118
Batch 170, Loss: 1.0477
Batch 180, Loss: 1.1094
Batch 190, Loss: 1.0108
Batch 200, Loss: 1.0497
Batch 210, Loss: 0.9933
Batch 220, Loss: 1.0153
Batch 230, Loss: 1.0574
Batch 240, Loss: 1.0151
Batch 250, Loss: 1.0628
Batch 260, Loss: 1.0745
Batch 270, Loss: 1.0370
Batch 280, Loss: 1.0703
Batch 290, Loss: 1.0983
Batch 300, Loss: 1.0602
Batch 310, Loss: 1.0811
Batch 320, Loss: 1.0955
Batch 330, Loss: 1.0588
Batch 340, Loss: 1.0458
Batch 350, Loss: 1.0542
Batch 360, Loss: 1.1287
Batch 370, Loss: 1.0953
Batch 380, Loss: 1.0628
Batch 390, Loss: 1.0642
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.217766046524048 seconds
Epoch 106 accuracy: 64.99%
Batch 10, Loss: 1.0025
Batch 20, Loss: 0.9613
Batch 30, Loss: 0.9906
Batch 40, Loss: 0.9773
Batch 50, Loss: 0.9757
Batch 60, Loss: 1.0212
Batch 70, Loss: 0.9438
Batch 80, Loss: 1.0247
Batch 90, Loss: 0.9956
Batch 100, Loss: 1.0112
Batch 110, Loss: 0.9941
Batch 120, Loss: 0.9991
Batch 130, Loss: 1.0511
Batch 140, Loss: 1.0493
Batch 150, Loss: 1.0375
Batch 160, Loss: 1.0275
Batch 170, Loss: 1.0520
Batch 180, Loss: 1.0741
Batch 190, Loss: 0.9996
Batch 200, Loss: 0.9936
Batch 210, Loss: 1.0626
Batch 220, Loss: 1.0504
Batch 230, Loss: 1.0548
Batch 240, Loss: 1.0517
Batch 250, Loss: 1.0160
Batch 260, Loss: 1.0595
Batch 270, Loss: 1.0796
Batch 280, Loss: 1.0394
Batch 290, Loss: 1.0895
Batch 300, Loss: 1.0977
Batch 310, Loss: 1.0366
Batch 320, Loss: 1.0965
Batch 330, Loss: 1.0855
Batch 340, Loss: 1.0709
Batch 350, Loss: 1.0765
Batch 360, Loss: 1.0888
Batch 370, Loss: 1.0303
Batch 380, Loss: 1.0521
Batch 390, Loss: 1.0120
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.121333360671997 seconds
Epoch 107 accuracy: 67.31%
Batch 10, Loss: 0.9664
Batch 20, Loss: 0.9958
Batch 30, Loss: 0.9974
Batch 40, Loss: 0.9512
Batch 50, Loss: 1.0020
Batch 60, Loss: 0.9674
Batch 70, Loss: 1.0134
Batch 80, Loss: 1.0806
Batch 90, Loss: 0.9977
Batch 100, Loss: 1.0018
Batch 110, Loss: 1.0011
Batch 120, Loss: 1.0291
Batch 130, Loss: 0.9835
Batch 140, Loss: 1.0003
Batch 150, Loss: 1.0369
Batch 160, Loss: 1.0219
Batch 170, Loss: 1.0256
Batch 180, Loss: 1.0092
Batch 190, Loss: 0.9716
Batch 200, Loss: 0.9989
Batch 210, Loss: 1.0044
Batch 220, Loss: 1.0279
Batch 230, Loss: 1.0256
Batch 240, Loss: 1.0459
Batch 250, Loss: 1.0853
Batch 260, Loss: 1.0566
Batch 270, Loss: 1.0650
Batch 280, Loss: 1.0382
Batch 290, Loss: 1.1053
Batch 300, Loss: 1.0487
Batch 310, Loss: 1.1228
Batch 320, Loss: 1.1396
Batch 330, Loss: 1.0229
Batch 340, Loss: 1.1229
Batch 350, Loss: 1.0702
Batch 360, Loss: 1.0685
Batch 370, Loss: 1.0650
Batch 380, Loss: 1.0711
Batch 390, Loss: 1.0940
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.149474382400513 seconds
Epoch 108 accuracy: 66.54%
Batch 10, Loss: 1.0233
Batch 20, Loss: 1.0093
Batch 30, Loss: 1.0321
Batch 40, Loss: 1.0194
Batch 50, Loss: 1.0093
Batch 60, Loss: 0.9479
Batch 70, Loss: 0.9733
Batch 80, Loss: 0.9475
Batch 90, Loss: 0.9915
Batch 100, Loss: 0.9793
Batch 110, Loss: 1.0038
Batch 120, Loss: 1.0243
Batch 130, Loss: 1.0692
Batch 140, Loss: 1.0621
Batch 150, Loss: 1.0029
Batch 160, Loss: 1.0073
Batch 170, Loss: 1.0526
Batch 180, Loss: 0.9564
Batch 190, Loss: 1.0626
Batch 200, Loss: 1.0185
Batch 210, Loss: 1.0882
Batch 220, Loss: 1.0183
Batch 230, Loss: 1.0036
Batch 240, Loss: 1.0568
Batch 250, Loss: 1.0364
Batch 260, Loss: 1.0896
Batch 270, Loss: 1.0467
Batch 280, Loss: 1.0681
Batch 290, Loss: 1.0441
Batch 300, Loss: 1.0430
Batch 310, Loss: 1.0172
Batch 320, Loss: 1.0360
Batch 330, Loss: 1.0694
Batch 340, Loss: 1.0442
Batch 350, Loss: 1.0325
Batch 360, Loss: 1.0810
Batch 370, Loss: 1.0942
Batch 380, Loss: 1.1198
Batch 390, Loss: 0.9939
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.155325889587402 seconds
Epoch 109 accuracy: 66.04%
Batch 10, Loss: 0.9768
Batch 20, Loss: 1.0422
Batch 30, Loss: 0.9302
Batch 40, Loss: 0.9693
Batch 50, Loss: 0.9726
Batch 60, Loss: 0.9679
Batch 70, Loss: 0.9617
Batch 80, Loss: 0.9951
Batch 90, Loss: 0.9316
Batch 100, Loss: 0.9866
Batch 110, Loss: 1.0555
Batch 120, Loss: 0.9631
Batch 130, Loss: 1.0305
Batch 140, Loss: 0.9997
Batch 150, Loss: 0.9952
Batch 160, Loss: 1.0224
Batch 170, Loss: 1.0482
Batch 180, Loss: 0.9808
Batch 190, Loss: 1.0595
Batch 200, Loss: 1.0030
Batch 210, Loss: 1.0307
Batch 220, Loss: 1.0355
Batch 230, Loss: 0.9706
Batch 240, Loss: 1.0646
Batch 250, Loss: 1.0231
Batch 260, Loss: 1.0322
Batch 270, Loss: 1.1005
Batch 280, Loss: 1.0350
Batch 290, Loss: 1.0406
Batch 300, Loss: 1.0651
Batch 310, Loss: 0.9998
Batch 320, Loss: 1.0538
Batch 330, Loss: 1.1116
Batch 340, Loss: 1.0366
Batch 350, Loss: 1.0368
Batch 360, Loss: 1.1171
Batch 370, Loss: 1.0572
Batch 380, Loss: 1.0252
Batch 390, Loss: 1.0781
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.205749034881592 seconds
Epoch 110 accuracy: 65.93%
Batch 10, Loss: 0.9867
Batch 20, Loss: 0.9925
Batch 30, Loss: 0.9343
Batch 40, Loss: 1.0018
Batch 50, Loss: 0.9616
Batch 60, Loss: 1.0319
Batch 70, Loss: 0.9266
Batch 80, Loss: 1.0351
Batch 90, Loss: 1.0022
Batch 100, Loss: 0.9780
Batch 110, Loss: 0.9614
Batch 120, Loss: 0.9786
Batch 130, Loss: 0.9876
Batch 140, Loss: 0.9508
Batch 150, Loss: 1.0230
Batch 160, Loss: 1.0323
Batch 170, Loss: 0.9835
Batch 180, Loss: 0.9379
Batch 190, Loss: 0.9608
Batch 200, Loss: 1.0216
Batch 210, Loss: 1.0019
Batch 220, Loss: 1.0005
Batch 230, Loss: 1.0573
Batch 240, Loss: 0.9300
Batch 250, Loss: 0.9903
Batch 260, Loss: 0.9705
Batch 270, Loss: 0.9768
Batch 280, Loss: 0.9898
Batch 290, Loss: 1.0012
Batch 300, Loss: 0.9816
Batch 310, Loss: 1.0522
Batch 320, Loss: 1.0105
Batch 330, Loss: 0.9978
Batch 340, Loss: 1.0228
Batch 350, Loss: 1.0591
Batch 360, Loss: 1.0340
Batch 370, Loss: 1.0541
Batch 380, Loss: 1.0965
Batch 390, Loss: 1.0302
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.273754358291626 seconds
Epoch 111 accuracy: 67.81%
Batch 10, Loss: 1.0173
Batch 20, Loss: 1.0156
Batch 30, Loss: 0.9748
Batch 40, Loss: 0.9485
Batch 50, Loss: 1.0245
Batch 60, Loss: 0.9500
Batch 70, Loss: 0.9612
Batch 80, Loss: 0.9643
Batch 90, Loss: 0.9624
Batch 100, Loss: 0.9827
Batch 110, Loss: 0.9481
Batch 120, Loss: 0.9828
Batch 130, Loss: 1.0027
Batch 140, Loss: 0.9754
Batch 150, Loss: 0.9746
Batch 160, Loss: 1.0067
Batch 170, Loss: 1.0216
Batch 180, Loss: 1.0354
Batch 190, Loss: 1.0465
Batch 200, Loss: 0.9861
Batch 210, Loss: 1.0137
Batch 220, Loss: 1.0256
Batch 230, Loss: 0.9754
Batch 240, Loss: 0.9970
Batch 250, Loss: 1.0207
Batch 260, Loss: 1.0162
Batch 270, Loss: 0.9900
Batch 280, Loss: 0.9712
Batch 290, Loss: 1.0609
Batch 300, Loss: 0.9973
Batch 310, Loss: 0.9621
Batch 320, Loss: 1.0142
Batch 330, Loss: 1.0327
Batch 340, Loss: 1.0412
Batch 350, Loss: 0.9988
Batch 360, Loss: 0.9790
Batch 370, Loss: 1.0379
Batch 380, Loss: 1.0506
Batch 390, Loss: 1.0038
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.170176029205322 seconds
Epoch 112 accuracy: 66.74%
Batch 10, Loss: 0.9257
Batch 20, Loss: 1.0151
Batch 30, Loss: 0.9615
Batch 40, Loss: 0.9573
Batch 50, Loss: 0.9283
Batch 60, Loss: 0.9096
Batch 70, Loss: 0.9752
Batch 80, Loss: 0.9131
Batch 90, Loss: 0.9302
Batch 100, Loss: 0.9477
Batch 110, Loss: 0.9257
Batch 120, Loss: 0.9562
Batch 130, Loss: 1.0152
Batch 140, Loss: 0.9531
Batch 150, Loss: 1.0215
Batch 160, Loss: 0.9417
Batch 170, Loss: 0.9336
Batch 180, Loss: 0.9825
Batch 190, Loss: 0.9937
Batch 200, Loss: 1.0114
Batch 210, Loss: 0.9885
Batch 220, Loss: 0.9307
Batch 230, Loss: 0.9838
Batch 240, Loss: 1.0247
Batch 250, Loss: 1.0251
Batch 260, Loss: 1.0112
Batch 270, Loss: 0.9873
Batch 280, Loss: 1.0258
Batch 290, Loss: 0.9689
Batch 300, Loss: 1.0712
Batch 310, Loss: 1.0179
Batch 320, Loss: 1.0365
Batch 330, Loss: 0.9986
Batch 340, Loss: 1.0524
Batch 350, Loss: 0.9683
Batch 360, Loss: 1.0604
Batch 370, Loss: 1.0360
Batch 380, Loss: 0.9905
Batch 390, Loss: 0.9788
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.126616716384888 seconds
Epoch 113 accuracy: 67.6%
Batch 10, Loss: 0.9743
Batch 20, Loss: 0.9163
Batch 30, Loss: 0.9321
Batch 40, Loss: 0.9415
Batch 50, Loss: 0.9441
Batch 60, Loss: 0.9468
Batch 70, Loss: 0.9377
Batch 80, Loss: 0.9951
Batch 90, Loss: 0.9904
Batch 100, Loss: 0.9430
Batch 110, Loss: 0.9606
Batch 120, Loss: 0.9902
Batch 130, Loss: 1.0348
Batch 140, Loss: 0.9369
Batch 150, Loss: 0.9772
Batch 160, Loss: 0.9866
Batch 170, Loss: 0.9193
Batch 180, Loss: 0.9443
Batch 190, Loss: 1.0019
Batch 200, Loss: 0.9717
Batch 210, Loss: 0.9860
Batch 220, Loss: 0.9652
Batch 230, Loss: 0.9606
Batch 240, Loss: 0.9944
Batch 250, Loss: 1.0219
Batch 260, Loss: 1.0043
Batch 270, Loss: 1.0266
Batch 280, Loss: 1.0186
Batch 290, Loss: 1.0003
Batch 300, Loss: 1.0143
Batch 310, Loss: 0.9810
Batch 320, Loss: 1.0523
Batch 330, Loss: 0.9950
Batch 340, Loss: 1.0418
Batch 350, Loss: 0.9937
Batch 360, Loss: 1.0335
Batch 370, Loss: 1.1188
Batch 380, Loss: 0.9918
Batch 390, Loss: 1.0226
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.12454843521118 seconds
Epoch 114 accuracy: 66.77%
Batch 10, Loss: 0.9288
Batch 20, Loss: 0.9504
Batch 30, Loss: 0.9284
Batch 40, Loss: 0.9498
Batch 50, Loss: 0.9771
Batch 60, Loss: 0.9232
Batch 70, Loss: 0.8730
Batch 80, Loss: 0.9003
Batch 90, Loss: 0.9540
Batch 100, Loss: 0.8932
Batch 110, Loss: 0.9401
Batch 120, Loss: 0.9663
Batch 130, Loss: 0.9844
Batch 140, Loss: 0.9382
Batch 150, Loss: 1.0020
Batch 160, Loss: 0.9611
Batch 170, Loss: 0.9202
Batch 180, Loss: 0.9298
Batch 190, Loss: 0.9593
Batch 200, Loss: 1.0081
Batch 210, Loss: 0.9822
Batch 220, Loss: 0.9658
Batch 230, Loss: 1.0055
Batch 240, Loss: 0.9800
Batch 250, Loss: 1.0101
Batch 260, Loss: 1.0142
Batch 270, Loss: 0.9394
Batch 280, Loss: 0.9413
Batch 290, Loss: 0.9463
Batch 300, Loss: 1.0049
Batch 310, Loss: 1.0108
Batch 320, Loss: 1.0342
Batch 330, Loss: 1.0184
Batch 340, Loss: 0.9594
Batch 350, Loss: 0.9846
Batch 360, Loss: 0.9752
Batch 370, Loss: 1.0297
Batch 380, Loss: 1.0047
Batch 390, Loss: 0.9528
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.134359121322632 seconds
Epoch 115 accuracy: 67.58%
Batch 10, Loss: 0.9630
Batch 20, Loss: 0.9278
Batch 30, Loss: 0.9541
Batch 40, Loss: 0.9300
Batch 50, Loss: 1.0024
Batch 60, Loss: 0.9165
Batch 70, Loss: 0.9010
Batch 80, Loss: 0.9511
Batch 90, Loss: 0.9376
Batch 100, Loss: 0.8987
Batch 110, Loss: 0.8884
Batch 120, Loss: 0.9558
Batch 130, Loss: 0.9503
Batch 140, Loss: 0.9411
Batch 150, Loss: 0.9357
Batch 160, Loss: 0.9350
Batch 170, Loss: 0.9453
Batch 180, Loss: 0.9886
Batch 190, Loss: 0.9370
Batch 200, Loss: 0.9508
Batch 210, Loss: 0.9473
Batch 220, Loss: 0.9723
Batch 230, Loss: 0.9757
Batch 240, Loss: 0.9770
Batch 250, Loss: 0.9366
Batch 260, Loss: 0.9757
Batch 270, Loss: 0.9664
Batch 280, Loss: 0.9908
Batch 290, Loss: 1.0510
Batch 300, Loss: 1.0174
Batch 310, Loss: 0.9714
Batch 320, Loss: 0.9917
Batch 330, Loss: 1.0279
Batch 340, Loss: 0.9961
Batch 350, Loss: 0.9925
Batch 360, Loss: 0.9980
Batch 370, Loss: 0.9737
Batch 380, Loss: 1.0313
Batch 390, Loss: 0.9539
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.137078523635864 seconds
Epoch 116 accuracy: 68.34%
Batch 10, Loss: 0.9248
Batch 20, Loss: 0.9024
Batch 30, Loss: 0.9261
Batch 40, Loss: 0.8833
Batch 50, Loss: 0.9458
Batch 60, Loss: 0.8623
Batch 70, Loss: 0.9660
Batch 80, Loss: 0.9227
Batch 90, Loss: 0.9405
Batch 100, Loss: 0.9347
Batch 110, Loss: 0.9545
Batch 120, Loss: 1.0004
Batch 130, Loss: 0.8707
Batch 140, Loss: 0.9973
Batch 150, Loss: 0.9121
Batch 160, Loss: 0.8774
Batch 170, Loss: 0.9104
Batch 180, Loss: 0.9722
Batch 190, Loss: 0.9182
Batch 200, Loss: 0.9668
Batch 210, Loss: 0.9254
Batch 220, Loss: 0.8872
Batch 230, Loss: 0.9816
Batch 240, Loss: 0.9220
Batch 250, Loss: 0.9196
Batch 260, Loss: 0.9997
Batch 270, Loss: 0.9156
Batch 280, Loss: 0.9665
Batch 290, Loss: 0.9563
Batch 300, Loss: 0.9908
Batch 310, Loss: 0.9550
Batch 320, Loss: 0.9416
Batch 330, Loss: 0.9587
Batch 340, Loss: 0.9846
Batch 350, Loss: 1.0013
Batch 360, Loss: 0.9935
Batch 370, Loss: 0.9766
Batch 380, Loss: 1.0123
Batch 390, Loss: 0.9475
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.17718482017517 seconds
Epoch 117 accuracy: 69.47%
Batch 10, Loss: 0.9214
Batch 20, Loss: 0.9347
Batch 30, Loss: 0.9115
Batch 40, Loss: 0.9124
Batch 50, Loss: 0.9288
Batch 60, Loss: 0.8725
Batch 70, Loss: 0.9409
Batch 80, Loss: 0.9457
Batch 90, Loss: 0.9474
Batch 100, Loss: 0.9606
Batch 110, Loss: 0.8818
Batch 120, Loss: 0.9334
Batch 130, Loss: 0.9201
Batch 140, Loss: 0.9042
Batch 150, Loss: 0.9142
Batch 160, Loss: 1.0105
Batch 170, Loss: 0.9101
Batch 180, Loss: 0.9352
Batch 190, Loss: 0.9554
Batch 200, Loss: 0.9507
Batch 210, Loss: 0.9741
Batch 220, Loss: 0.9022
Batch 230, Loss: 0.9695
Batch 240, Loss: 0.9643
Batch 250, Loss: 0.9272
Batch 260, Loss: 0.9478
Batch 270, Loss: 0.9868
Batch 280, Loss: 0.9242
Batch 290, Loss: 0.9440
Batch 300, Loss: 0.9740
Batch 310, Loss: 0.9291
Batch 320, Loss: 0.8905
Batch 330, Loss: 0.9738
Batch 340, Loss: 0.9196
Batch 350, Loss: 0.9507
Batch 360, Loss: 1.0147
Batch 370, Loss: 0.9862
Batch 380, Loss: 0.9528
Batch 390, Loss: 0.9676
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.216941118240356 seconds
Epoch 118 accuracy: 68.56%
Batch 10, Loss: 0.9206
Batch 20, Loss: 0.8619
Batch 30, Loss: 0.9321
Batch 40, Loss: 0.8779
Batch 50, Loss: 0.8585
Batch 60, Loss: 0.8595
Batch 70, Loss: 0.9396
Batch 80, Loss: 0.8955
Batch 90, Loss: 0.8867
Batch 100, Loss: 0.9868
Batch 110, Loss: 0.9205
Batch 120, Loss: 0.9125
Batch 130, Loss: 0.9373
Batch 140, Loss: 0.9195
Batch 150, Loss: 0.9172
Batch 160, Loss: 0.9440
Batch 170, Loss: 0.9098
Batch 180, Loss: 0.9976
Batch 190, Loss: 0.9134
Batch 200, Loss: 0.9726
Batch 210, Loss: 0.9626
Batch 220, Loss: 0.9344
Batch 230, Loss: 0.9790
Batch 240, Loss: 0.9338
Batch 250, Loss: 0.9849
Batch 260, Loss: 0.9534
Batch 270, Loss: 0.9068
Batch 280, Loss: 0.9663
Batch 290, Loss: 0.9402
Batch 300, Loss: 0.9093
Batch 310, Loss: 0.9102
Batch 320, Loss: 0.9204
Batch 330, Loss: 0.9069
Batch 340, Loss: 0.9278
Batch 350, Loss: 0.9261
Batch 360, Loss: 0.9780
Batch 370, Loss: 0.9871
Batch 380, Loss: 0.9324
Batch 390, Loss: 0.9236
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.21197271347046 seconds
Epoch 119 accuracy: 68.76%
Batch 10, Loss: 0.8533
Batch 20, Loss: 0.8843
Batch 30, Loss: 0.8642
Batch 40, Loss: 0.8376
Batch 50, Loss: 0.8274
Batch 60, Loss: 0.8985
Batch 70, Loss: 0.8855
Batch 80, Loss: 0.9179
Batch 90, Loss: 0.9637
Batch 100, Loss: 0.8959
Batch 110, Loss: 0.8985
Batch 120, Loss: 0.8892
Batch 130, Loss: 0.9049
Batch 140, Loss: 0.9366
Batch 150, Loss: 0.9860
Batch 160, Loss: 0.9579
Batch 170, Loss: 0.9316
Batch 180, Loss: 0.9791
Batch 190, Loss: 0.9938
Batch 200, Loss: 0.9683
Batch 210, Loss: 0.9233
Batch 220, Loss: 0.9458
Batch 230, Loss: 0.9083
Batch 240, Loss: 0.9416
Batch 250, Loss: 0.9326
Batch 260, Loss: 0.8780
Batch 270, Loss: 0.9021
Batch 280, Loss: 0.8903
Batch 290, Loss: 0.9423
Batch 300, Loss: 0.8928
Batch 310, Loss: 0.9347
Batch 320, Loss: 0.8766
Batch 330, Loss: 0.9400
Batch 340, Loss: 0.9768
Batch 350, Loss: 0.9505
Batch 360, Loss: 0.9531
Batch 370, Loss: 0.9428
Batch 380, Loss: 0.9362
Batch 390, Loss: 0.9925
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.08900237083435 seconds
Epoch 120 accuracy: 68.81%
Batch 10, Loss: 0.8474
Batch 20, Loss: 0.9224
Batch 30, Loss: 0.8727
Batch 40, Loss: 0.8553
Batch 50, Loss: 0.9045
Batch 60, Loss: 0.8733
Batch 70, Loss: 0.8672
Batch 80, Loss: 0.9069
Batch 90, Loss: 0.8315
Batch 100, Loss: 0.9192
Batch 110, Loss: 0.9232
Batch 120, Loss: 0.9090
Batch 130, Loss: 0.9236
Batch 140, Loss: 0.9241
Batch 150, Loss: 0.9183
Batch 160, Loss: 0.8951
Batch 170, Loss: 0.9012
Batch 180, Loss: 0.9543
Batch 190, Loss: 0.8780
Batch 200, Loss: 0.8978
Batch 210, Loss: 0.9156
Batch 220, Loss: 0.8431
Batch 230, Loss: 0.9491
Batch 240, Loss: 0.9805
Batch 250, Loss: 0.9400
Batch 260, Loss: 0.9035
Batch 270, Loss: 0.8838
Batch 280, Loss: 0.9379
Batch 290, Loss: 0.9015
Batch 300, Loss: 0.9294
Batch 310, Loss: 0.9028
Batch 320, Loss: 0.9296
Batch 330, Loss: 0.9814
Batch 340, Loss: 0.9859
Batch 350, Loss: 0.9052
Batch 360, Loss: 0.9624
Batch 370, Loss: 0.9208
Batch 380, Loss: 0.9305
Batch 390, Loss: 0.9652
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.080907106399536 seconds
Epoch 121 accuracy: 68.54%
Batch 10, Loss: 0.8721
Batch 20, Loss: 0.9089
Batch 30, Loss: 0.8882
Batch 40, Loss: 0.8726
Batch 50, Loss: 0.8541
Batch 60, Loss: 0.8047
Batch 70, Loss: 0.8851
Batch 80, Loss: 0.8843
Batch 90, Loss: 0.8781
Batch 100, Loss: 0.8744
Batch 110, Loss: 0.8751
Batch 120, Loss: 0.8479
Batch 130, Loss: 0.8474
Batch 140, Loss: 0.9022
Batch 150, Loss: 0.8763
Batch 160, Loss: 0.8881
Batch 170, Loss: 0.9341
Batch 180, Loss: 0.9101
Batch 190, Loss: 0.9583
Batch 200, Loss: 0.9113
Batch 210, Loss: 0.9194
Batch 220, Loss: 0.8882
Batch 230, Loss: 0.9043
Batch 240, Loss: 0.9237
Batch 250, Loss: 0.8885
Batch 260, Loss: 0.9273
Batch 270, Loss: 0.8633
Batch 280, Loss: 0.8872
Batch 290, Loss: 0.9234
Batch 300, Loss: 0.9092
Batch 310, Loss: 0.9617
Batch 320, Loss: 0.9381
Batch 330, Loss: 0.9758
Batch 340, Loss: 0.9921
Batch 350, Loss: 0.9630
Batch 360, Loss: 1.0077
Batch 370, Loss: 0.9494
Batch 380, Loss: 0.9942
Batch 390, Loss: 0.9734
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.08608341217041 seconds
Epoch 122 accuracy: 68.52%
Batch 10, Loss: 0.7719
Batch 20, Loss: 0.8380
Batch 30, Loss: 0.8819
Batch 40, Loss: 0.8303
Batch 50, Loss: 0.8968
Batch 60, Loss: 0.8205
Batch 70, Loss: 0.8851
Batch 80, Loss: 0.8786
Batch 90, Loss: 0.8570
Batch 100, Loss: 0.9410
Batch 110, Loss: 0.8973
Batch 120, Loss: 0.8606
Batch 130, Loss: 0.8500
Batch 140, Loss: 0.8946
Batch 150, Loss: 0.8443
Batch 160, Loss: 0.9024
Batch 170, Loss: 0.8812
Batch 180, Loss: 0.8658
Batch 190, Loss: 0.9063
Batch 200, Loss: 0.9106
Batch 210, Loss: 0.8964
Batch 220, Loss: 0.8870
Batch 230, Loss: 0.9319
Batch 240, Loss: 0.8907
Batch 250, Loss: 0.9037
Batch 260, Loss: 0.9029
Batch 270, Loss: 0.8503
Batch 280, Loss: 0.8970
Batch 290, Loss: 0.9715
Batch 300, Loss: 0.9127
Batch 310, Loss: 0.9217
Batch 320, Loss: 0.9009
Batch 330, Loss: 0.9414
Batch 340, Loss: 0.9028
Batch 350, Loss: 0.9170
Batch 360, Loss: 0.8645
Batch 370, Loss: 0.9502
Batch 380, Loss: 0.9090
Batch 390, Loss: 0.9371
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.131162881851196 seconds
Epoch 123 accuracy: 71.02%
Batch 10, Loss: 0.8895
Batch 20, Loss: 0.8484
Batch 30, Loss: 0.8413
Batch 40, Loss: 0.8829
Batch 50, Loss: 0.8081
Batch 60, Loss: 0.8898
Batch 70, Loss: 0.8321
Batch 80, Loss: 0.8499
Batch 90, Loss: 0.8774
Batch 100, Loss: 0.8708
Batch 110, Loss: 0.8819
Batch 120, Loss: 0.8875
Batch 130, Loss: 0.9228
Batch 140, Loss: 0.8357
Batch 150, Loss: 0.8582
Batch 160, Loss: 0.8749
Batch 170, Loss: 0.8554
Batch 180, Loss: 0.8933
Batch 190, Loss: 0.8797
Batch 200, Loss: 0.8893
Batch 210, Loss: 0.8761
Batch 220, Loss: 0.9010
Batch 230, Loss: 0.9296
Batch 240, Loss: 0.8911
Batch 250, Loss: 0.8821
Batch 260, Loss: 0.8409
Batch 270, Loss: 0.9411
Batch 280, Loss: 0.9432
Batch 290, Loss: 0.9126
Batch 300, Loss: 0.8929
Batch 310, Loss: 0.9556
Batch 320, Loss: 0.9229
Batch 330, Loss: 0.9171
Batch 340, Loss: 0.8662
Batch 350, Loss: 0.8954
Batch 360, Loss: 0.9208
Batch 370, Loss: 0.8848
Batch 380, Loss: 0.9296
Batch 390, Loss: 0.9014
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.120819091796875 seconds
Epoch 124 accuracy: 68.66%
Batch 10, Loss: 0.8710
Batch 20, Loss: 0.8390
Batch 30, Loss: 0.8151
Batch 40, Loss: 0.8997
Batch 50, Loss: 0.7892
Batch 60, Loss: 0.8290
Batch 70, Loss: 0.8593
Batch 80, Loss: 0.8214
Batch 90, Loss: 0.8436
Batch 100, Loss: 0.8080
Batch 110, Loss: 0.8158
Batch 120, Loss: 0.8362
Batch 130, Loss: 0.8147
Batch 140, Loss: 0.8580
Batch 150, Loss: 0.8610
Batch 160, Loss: 0.8769
Batch 170, Loss: 0.8740
Batch 180, Loss: 0.8872
Batch 190, Loss: 0.8901
Batch 200, Loss: 0.8241
Batch 210, Loss: 0.8633
Batch 220, Loss: 0.8755
Batch 230, Loss: 0.9053
Batch 240, Loss: 0.8732
Batch 250, Loss: 0.8819
Batch 260, Loss: 0.8972
Batch 270, Loss: 0.9353
Batch 280, Loss: 0.8777
Batch 290, Loss: 0.9130
Batch 300, Loss: 0.8809
Batch 310, Loss: 0.8928
Batch 320, Loss: 0.9007
Batch 330, Loss: 0.9211
Batch 340, Loss: 0.8909
Batch 350, Loss: 0.9308
Batch 360, Loss: 0.9342
Batch 370, Loss: 0.8683
Batch 380, Loss: 0.8335
Batch 390, Loss: 0.9078
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.13858199119568 seconds
Epoch 125 accuracy: 69.78%
Batch 10, Loss: 0.8084
Batch 20, Loss: 0.8145
Batch 30, Loss: 0.8341
Batch 40, Loss: 0.8338
Batch 50, Loss: 0.8196
Batch 60, Loss: 0.9013
Batch 70, Loss: 0.8007
Batch 80, Loss: 0.8227
Batch 90, Loss: 0.8943
Batch 100, Loss: 0.8799
Batch 110, Loss: 0.8299
Batch 120, Loss: 0.8501
Batch 130, Loss: 0.8977
Batch 140, Loss: 0.8028
Batch 150, Loss: 0.8529
Batch 160, Loss: 0.8793
Batch 170, Loss: 0.8833
Batch 180, Loss: 0.9126
Batch 190, Loss: 0.8722
Batch 200, Loss: 0.8367
Batch 210, Loss: 0.8623
Batch 220, Loss: 0.9155
Batch 230, Loss: 0.8791
Batch 240, Loss: 0.9209
Batch 250, Loss: 0.8832
Batch 260, Loss: 0.9027
Batch 270, Loss: 0.8832
Batch 280, Loss: 0.9178
Batch 290, Loss: 0.8627
Batch 300, Loss: 0.8806
Batch 310, Loss: 0.8591
Batch 320, Loss: 0.8888
Batch 330, Loss: 0.8831
Batch 340, Loss: 0.9023
Batch 350, Loss: 0.8853
Batch 360, Loss: 0.8862
Batch 370, Loss: 0.9367
Batch 380, Loss: 0.8716
Batch 390, Loss: 0.9201
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.188822746276855 seconds
Epoch 126 accuracy: 66.93%
Batch 10, Loss: 0.8437
Batch 20, Loss: 0.8773
Batch 30, Loss: 0.8051
Batch 40, Loss: 0.8675
Batch 50, Loss: 0.8521
Batch 60, Loss: 0.8438
Batch 70, Loss: 0.8093
Batch 80, Loss: 0.8668
Batch 90, Loss: 0.8559
Batch 100, Loss: 0.8333
Batch 110, Loss: 0.8704
Batch 120, Loss: 0.8599
Batch 130, Loss: 0.7555
Batch 140, Loss: 0.8288
Batch 150, Loss: 0.8605
Batch 160, Loss: 0.8132
Batch 170, Loss: 0.8452
Batch 180, Loss: 0.8384
Batch 190, Loss: 0.8511
Batch 200, Loss: 0.8806
Batch 210, Loss: 0.8847
Batch 220, Loss: 0.9060
Batch 230, Loss: 0.9146
Batch 240, Loss: 0.8956
Batch 250, Loss: 0.8871
Batch 260, Loss: 0.8980
Batch 270, Loss: 0.8188
Batch 280, Loss: 0.8801
Batch 290, Loss: 0.8485
Batch 300, Loss: 0.8980
Batch 310, Loss: 0.8714
Batch 320, Loss: 0.9033
Batch 330, Loss: 0.8955
Batch 340, Loss: 0.9056
Batch 350, Loss: 0.9018
Batch 360, Loss: 0.9245
Batch 370, Loss: 0.9393
Batch 380, Loss: 0.8614
Batch 390, Loss: 0.8881
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.127312660217285 seconds
Epoch 127 accuracy: 70.63%
Batch 10, Loss: 0.8393
Batch 20, Loss: 0.8176
Batch 30, Loss: 0.7901
Batch 40, Loss: 0.7814
Batch 50, Loss: 0.7274
Batch 60, Loss: 0.8189
Batch 70, Loss: 0.8234
Batch 80, Loss: 0.8029
Batch 90, Loss: 0.7613
Batch 100, Loss: 0.7974
Batch 110, Loss: 0.8281
Batch 120, Loss: 0.8209
Batch 130, Loss: 0.8189
Batch 140, Loss: 0.8557
Batch 150, Loss: 0.8592
Batch 160, Loss: 0.8412
Batch 170, Loss: 0.8717
Batch 180, Loss: 0.8884
Batch 190, Loss: 0.8448
Batch 200, Loss: 0.8759
Batch 210, Loss: 0.7911
Batch 220, Loss: 0.8337
Batch 230, Loss: 0.8373
Batch 240, Loss: 0.8332
Batch 250, Loss: 0.8414
Batch 260, Loss: 0.8691
Batch 270, Loss: 0.8623
Batch 280, Loss: 0.8683
Batch 290, Loss: 0.8452
Batch 300, Loss: 0.8131
Batch 310, Loss: 0.8485
Batch 320, Loss: 0.8712
Batch 330, Loss: 0.8667
Batch 340, Loss: 0.8330
Batch 350, Loss: 0.8382
Batch 360, Loss: 0.8380
Batch 370, Loss: 0.8734
Batch 380, Loss: 0.9237
Batch 390, Loss: 0.8873
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.08026099205017 seconds
Epoch 128 accuracy: 69.06%
Batch 10, Loss: 0.8181
Batch 20, Loss: 0.7739
Batch 30, Loss: 0.8093
Batch 40, Loss: 0.8029
Batch 50, Loss: 0.8069
Batch 60, Loss: 0.8011
Batch 70, Loss: 0.7569
Batch 80, Loss: 0.8295
Batch 90, Loss: 0.8280
Batch 100, Loss: 0.8137
Batch 110, Loss: 0.8325
Batch 120, Loss: 0.7845
Batch 130, Loss: 0.8212
Batch 140, Loss: 0.8397
Batch 150, Loss: 0.8018
Batch 160, Loss: 0.7679
Batch 170, Loss: 0.8470
Batch 180, Loss: 0.8494
Batch 190, Loss: 0.8625
Batch 200, Loss: 0.8484
Batch 210, Loss: 0.8348
Batch 220, Loss: 0.8287
Batch 230, Loss: 0.8385
Batch 240, Loss: 0.8529
Batch 250, Loss: 0.8026
Batch 260, Loss: 0.8329
Batch 270, Loss: 0.8696
Batch 280, Loss: 0.8945
Batch 290, Loss: 0.9586
Batch 300, Loss: 0.8716
Batch 310, Loss: 0.8175
Batch 320, Loss: 0.8301
Batch 330, Loss: 0.9033
Batch 340, Loss: 0.8231
Batch 350, Loss: 0.8502
Batch 360, Loss: 0.9427
Batch 370, Loss: 0.8653
Batch 380, Loss: 0.8803
Batch 390, Loss: 0.8959
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.02366876602173 seconds
Epoch 129 accuracy: 72.02%
Batch 10, Loss: 0.7482
Batch 20, Loss: 0.7542
Batch 30, Loss: 0.8039
Batch 40, Loss: 0.7568
Batch 50, Loss: 0.7937
Batch 60, Loss: 0.8061
Batch 70, Loss: 0.8036
Batch 80, Loss: 0.8169
Batch 90, Loss: 0.7809
Batch 100, Loss: 0.7582
Batch 110, Loss: 0.8090
Batch 120, Loss: 0.8520
Batch 130, Loss: 0.7892
Batch 140, Loss: 0.8249
Batch 150, Loss: 0.7802
Batch 160, Loss: 0.8566
Batch 170, Loss: 0.7824
Batch 180, Loss: 0.8073
Batch 190, Loss: 0.7696
Batch 200, Loss: 0.8391
Batch 210, Loss: 0.8710
Batch 220, Loss: 0.8291
Batch 230, Loss: 0.8372
Batch 240, Loss: 0.8096
Batch 250, Loss: 0.7909
Batch 260, Loss: 0.7942
Batch 270, Loss: 0.8481
Batch 280, Loss: 0.7923
Batch 290, Loss: 0.8332
Batch 300, Loss: 0.8275
Batch 310, Loss: 0.8728
Batch 320, Loss: 0.8647
Batch 330, Loss: 0.8458
Batch 340, Loss: 0.9147
Batch 350, Loss: 0.8561
Batch 360, Loss: 0.8720
Batch 370, Loss: 0.8658
Batch 380, Loss: 0.8581
Batch 390, Loss: 0.8174
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.07033133506775 seconds
Epoch 130 accuracy: 70.71%
Batch 10, Loss: 0.8337
Batch 20, Loss: 0.7816
Batch 30, Loss: 0.7627
Batch 40, Loss: 0.7842
Batch 50, Loss: 0.7928
Batch 60, Loss: 0.8069
Batch 70, Loss: 0.7460
Batch 80, Loss: 0.8360
Batch 90, Loss: 0.7940
Batch 100, Loss: 0.7806
Batch 110, Loss: 0.8121
Batch 120, Loss: 0.8098
Batch 130, Loss: 0.7747
Batch 140, Loss: 0.7945
Batch 150, Loss: 0.7907
Batch 160, Loss: 0.8142
Batch 170, Loss: 0.8491
Batch 180, Loss: 0.8112
Batch 190, Loss: 0.8065
Batch 200, Loss: 0.8088
Batch 210, Loss: 0.8352
Batch 220, Loss: 0.7843
Batch 230, Loss: 0.7902
Batch 240, Loss: 0.7909
Batch 250, Loss: 0.8261
Batch 260, Loss: 0.8096
Batch 270, Loss: 0.8318
Batch 280, Loss: 0.8853
Batch 290, Loss: 0.8117
Batch 300, Loss: 0.8231
Batch 310, Loss: 0.8262
Batch 320, Loss: 0.8903
Batch 330, Loss: 0.7996
Batch 340, Loss: 0.8132
Batch 350, Loss: 0.8910
Batch 360, Loss: 0.8587
Batch 370, Loss: 0.8291
Batch 380, Loss: 0.8399
Batch 390, Loss: 0.8172
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.127197980880737 seconds
Epoch 131 accuracy: 71.98%
Batch 10, Loss: 0.7292
Batch 20, Loss: 0.7275
Batch 30, Loss: 0.6915
Batch 40, Loss: 0.7867
Batch 50, Loss: 0.8124
Batch 60, Loss: 0.8013
Batch 70, Loss: 0.7954
Batch 80, Loss: 0.7829
Batch 90, Loss: 0.7590
Batch 100, Loss: 0.7537
Batch 110, Loss: 0.8093
Batch 120, Loss: 0.8267
Batch 130, Loss: 0.8240
Batch 140, Loss: 0.8655
Batch 150, Loss: 0.7911
Batch 160, Loss: 0.7811
Batch 170, Loss: 0.8066
Batch 180, Loss: 0.7670
Batch 190, Loss: 0.8306
Batch 200, Loss: 0.8252
Batch 210, Loss: 0.7660
Batch 220, Loss: 0.8562
Batch 230, Loss: 0.8509
Batch 240, Loss: 0.8335
Batch 250, Loss: 0.7990
Batch 260, Loss: 0.8447
Batch 270, Loss: 0.8500
Batch 280, Loss: 0.8042
Batch 290, Loss: 0.8571
Batch 300, Loss: 0.7860
Batch 310, Loss: 0.7990
Batch 320, Loss: 0.8630
Batch 330, Loss: 0.8248
Batch 340, Loss: 0.8999
Batch 350, Loss: 0.8355
Batch 360, Loss: 0.8311
Batch 370, Loss: 0.8619
Batch 380, Loss: 0.8411
Batch 390, Loss: 0.7822
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.192604541778564 seconds
Epoch 132 accuracy: 71.47%
Batch 10, Loss: 0.8053
Batch 20, Loss: 0.7877
Batch 30, Loss: 0.7442
Batch 40, Loss: 0.7921
Batch 50, Loss: 0.7595
Batch 60, Loss: 0.7996
Batch 70, Loss: 0.7723
Batch 80, Loss: 0.7440
Batch 90, Loss: 0.7643
Batch 100, Loss: 0.7677
Batch 110, Loss: 0.7775
Batch 120, Loss: 0.8141
Batch 130, Loss: 0.7673
Batch 140, Loss: 0.7988
Batch 150, Loss: 0.7717
Batch 160, Loss: 0.8378
Batch 170, Loss: 0.7633
Batch 180, Loss: 0.7971
Batch 190, Loss: 0.8108
Batch 200, Loss: 0.7924
Batch 210, Loss: 0.8264
Batch 220, Loss: 0.7922
Batch 230, Loss: 0.7809
Batch 240, Loss: 0.8527
Batch 250, Loss: 0.8062
Batch 260, Loss: 0.8473
Batch 270, Loss: 0.8459
Batch 280, Loss: 0.7878
Batch 290, Loss: 0.8013
Batch 300, Loss: 0.8059
Batch 310, Loss: 0.8855
Batch 320, Loss: 0.8232
Batch 330, Loss: 0.8282
Batch 340, Loss: 0.8590
Batch 350, Loss: 0.8750
Batch 360, Loss: 0.7906
Batch 370, Loss: 0.8619
Batch 380, Loss: 0.7984
Batch 390, Loss: 0.7768
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.15297508239746 seconds
Epoch 133 accuracy: 72.71%
Batch 10, Loss: 0.7740
Batch 20, Loss: 0.7630
Batch 30, Loss: 0.6988
Batch 40, Loss: 0.7396
Batch 50, Loss: 0.7811
Batch 60, Loss: 0.7420
Batch 70, Loss: 0.8004
Batch 80, Loss: 0.7362
Batch 90, Loss: 0.7177
Batch 100, Loss: 0.7892
Batch 110, Loss: 0.7942
Batch 120, Loss: 0.7769
Batch 130, Loss: 0.7958
Batch 140, Loss: 0.7727
Batch 150, Loss: 0.8010
Batch 160, Loss: 0.7365
Batch 170, Loss: 0.7782
Batch 180, Loss: 0.7750
Batch 190, Loss: 0.7842
Batch 200, Loss: 0.7890
Batch 210, Loss: 0.7226
Batch 220, Loss: 0.8097
Batch 230, Loss: 0.8418
Batch 240, Loss: 0.8252
Batch 250, Loss: 0.8116
Batch 260, Loss: 0.7900
Batch 270, Loss: 0.7842
Batch 280, Loss: 0.7715
Batch 290, Loss: 0.8321
Batch 300, Loss: 0.8102
Batch 310, Loss: 0.7555
Batch 320, Loss: 0.8048
Batch 330, Loss: 0.8547
Batch 340, Loss: 0.8181
Batch 350, Loss: 0.7652
Batch 360, Loss: 0.8863
Batch 370, Loss: 0.7791
Batch 380, Loss: 0.8071
Batch 390, Loss: 0.8314
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.216381549835205 seconds
Epoch 134 accuracy: 69.09%
Batch 10, Loss: 0.7505
Batch 20, Loss: 0.7421
Batch 30, Loss: 0.7972
Batch 40, Loss: 0.7425
Batch 50, Loss: 0.7884
Batch 60, Loss: 0.7037
Batch 70, Loss: 0.7876
Batch 80, Loss: 0.7294
Batch 90, Loss: 0.7842
Batch 100, Loss: 0.7617
Batch 110, Loss: 0.7601
Batch 120, Loss: 0.7420
Batch 130, Loss: 0.7544
Batch 140, Loss: 0.7548
Batch 150, Loss: 0.7406
Batch 160, Loss: 0.8044
Batch 170, Loss: 0.7540
Batch 180, Loss: 0.7516
Batch 190, Loss: 0.7746
Batch 200, Loss: 0.7450
Batch 210, Loss: 0.7839
Batch 220, Loss: 0.8031
Batch 230, Loss: 0.7823
Batch 240, Loss: 0.7527
Batch 250, Loss: 0.7956
Batch 260, Loss: 0.8502
Batch 270, Loss: 0.7680
Batch 280, Loss: 0.7689
Batch 290, Loss: 0.8183
Batch 300, Loss: 0.7468
Batch 310, Loss: 0.8316
Batch 320, Loss: 0.8019
Batch 330, Loss: 0.7794
Batch 340, Loss: 0.7774
Batch 350, Loss: 0.8243
Batch 360, Loss: 0.7756
Batch 370, Loss: 0.7954
Batch 380, Loss: 0.7828
Batch 390, Loss: 0.7722
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.08560848236084 seconds
Epoch 135 accuracy: 72.25%
Batch 10, Loss: 0.7392
Batch 20, Loss: 0.6680
Batch 30, Loss: 0.7396
Batch 40, Loss: 0.7222
Batch 50, Loss: 0.6811
Batch 60, Loss: 0.6820
Batch 70, Loss: 0.7587
Batch 80, Loss: 0.7461
Batch 90, Loss: 0.7213
Batch 100, Loss: 0.6919
Batch 110, Loss: 0.7115
Batch 120, Loss: 0.7271
Batch 130, Loss: 0.7161
Batch 140, Loss: 0.7277
Batch 150, Loss: 0.7666
Batch 160, Loss: 0.7525
Batch 170, Loss: 0.7076
Batch 180, Loss: 0.8008
Batch 190, Loss: 0.7544
Batch 200, Loss: 0.7005
Batch 210, Loss: 0.7694
Batch 220, Loss: 0.7772
Batch 230, Loss: 0.7623
Batch 240, Loss: 0.8308
Batch 250, Loss: 0.7836
Batch 260, Loss: 0.7949
Batch 270, Loss: 0.7621
Batch 280, Loss: 0.8252
Batch 290, Loss: 0.7904
Batch 300, Loss: 0.7797
Batch 310, Loss: 0.7878
Batch 320, Loss: 0.8265
Batch 330, Loss: 0.7531
Batch 340, Loss: 0.7300
Batch 350, Loss: 0.7801
Batch 360, Loss: 0.8001
Batch 370, Loss: 0.7710
Batch 380, Loss: 0.7562
Batch 390, Loss: 0.8023
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.23982286453247 seconds
Epoch 136 accuracy: 72.63%
Batch 10, Loss: 0.7157
Batch 20, Loss: 0.7501
Batch 30, Loss: 0.7150
Batch 40, Loss: 0.7826
Batch 50, Loss: 0.7036
Batch 60, Loss: 0.7273
Batch 70, Loss: 0.7359
Batch 80, Loss: 0.7057
Batch 90, Loss: 0.7499
Batch 100, Loss: 0.7289
Batch 110, Loss: 0.7059
Batch 120, Loss: 0.7111
Batch 130, Loss: 0.6724
Batch 140, Loss: 0.7341
Batch 150, Loss: 0.7551
Batch 160, Loss: 0.7408
Batch 170, Loss: 0.8207
Batch 180, Loss: 0.7362
Batch 190, Loss: 0.7548
Batch 200, Loss: 0.7477
Batch 210, Loss: 0.7525
Batch 220, Loss: 0.7696
Batch 230, Loss: 0.7698
Batch 240, Loss: 0.7249
Batch 250, Loss: 0.6999
Batch 260, Loss: 0.7108
Batch 270, Loss: 0.7776
Batch 280, Loss: 0.7890
Batch 290, Loss: 0.7794
Batch 300, Loss: 0.7798
Batch 310, Loss: 0.8153
Batch 320, Loss: 0.7616
Batch 330, Loss: 0.7916
Batch 340, Loss: 0.7766
Batch 350, Loss: 0.7701
Batch 360, Loss: 0.7460
Batch 370, Loss: 0.7648
Batch 380, Loss: 0.8252
Batch 390, Loss: 0.7869
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.100985288619995 seconds
Epoch 137 accuracy: 71.06%
Batch 10, Loss: 0.6798
Batch 20, Loss: 0.7017
Batch 30, Loss: 0.6844
Batch 40, Loss: 0.7318
Batch 50, Loss: 0.7160
Batch 60, Loss: 0.6916
Batch 70, Loss: 0.7004
Batch 80, Loss: 0.7160
Batch 90, Loss: 0.7015
Batch 100, Loss: 0.6989
Batch 110, Loss: 0.7060
Batch 120, Loss: 0.7265
Batch 130, Loss: 0.7016
Batch 140, Loss: 0.7359
Batch 150, Loss: 0.7165
Batch 160, Loss: 0.7161
Batch 170, Loss: 0.7646
Batch 180, Loss: 0.7153
Batch 190, Loss: 0.7318
Batch 200, Loss: 0.7364
Batch 210, Loss: 0.7316
Batch 220, Loss: 0.7488
Batch 230, Loss: 0.7465
Batch 240, Loss: 0.7010
Batch 250, Loss: 0.7396
Batch 260, Loss: 0.7290
Batch 270, Loss: 0.7941
Batch 280, Loss: 0.7668
Batch 290, Loss: 0.7566
Batch 300, Loss: 0.7654
Batch 310, Loss: 0.7324
Batch 320, Loss: 0.7815
Batch 330, Loss: 0.7949
Batch 340, Loss: 0.7739
Batch 350, Loss: 0.7551
Batch 360, Loss: 0.8016
Batch 370, Loss: 0.7603
Batch 380, Loss: 0.6713
Batch 390, Loss: 0.7351
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.11173677444458 seconds
Epoch 138 accuracy: 71.73%
Batch 10, Loss: 0.7081
Batch 20, Loss: 0.7340
Batch 30, Loss: 0.7537
Batch 40, Loss: 0.6280
Batch 50, Loss: 0.6741
Batch 60, Loss: 0.6838
Batch 70, Loss: 0.6826
Batch 80, Loss: 0.6831
Batch 90, Loss: 0.6945
Batch 100, Loss: 0.6855
Batch 110, Loss: 0.7039
Batch 120, Loss: 0.7427
Batch 130, Loss: 0.7091
Batch 140, Loss: 0.6818
Batch 150, Loss: 0.7177
Batch 160, Loss: 0.6900
Batch 170, Loss: 0.6607
Batch 180, Loss: 0.7705
Batch 190, Loss: 0.7274
Batch 200, Loss: 0.7713
Batch 210, Loss: 0.7230
Batch 220, Loss: 0.7118
Batch 230, Loss: 0.7384
Batch 240, Loss: 0.7191
Batch 250, Loss: 0.7178
Batch 260, Loss: 0.6958
Batch 270, Loss: 0.7193
Batch 280, Loss: 0.7205
Batch 290, Loss: 0.7556
Batch 300, Loss: 0.6919
Batch 310, Loss: 0.7247
Batch 320, Loss: 0.6948
Batch 330, Loss: 0.7590
Batch 340, Loss: 0.7457
Batch 350, Loss: 0.7360
Batch 360, Loss: 0.7114
Batch 370, Loss: 0.7369
Batch 380, Loss: 0.8070
Batch 390, Loss: 0.7605
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.054478645324707 seconds
Epoch 139 accuracy: 71.71%
Batch 10, Loss: 0.6533
Batch 20, Loss: 0.6851
Batch 30, Loss: 0.7138
Batch 40, Loss: 0.7291
Batch 50, Loss: 0.7002
Batch 60, Loss: 0.6959
Batch 70, Loss: 0.6995
Batch 80, Loss: 0.7343
Batch 90, Loss: 0.6694
Batch 100, Loss: 0.6966
Batch 110, Loss: 0.6777
Batch 120, Loss: 0.6573
Batch 130, Loss: 0.7328
Batch 140, Loss: 0.7223
Batch 150, Loss: 0.7590
Batch 160, Loss: 0.7166
Batch 170, Loss: 0.7054
Batch 180, Loss: 0.6779
Batch 190, Loss: 0.7251
Batch 200, Loss: 0.6781
Batch 210, Loss: 0.7108
Batch 220, Loss: 0.6637
Batch 230, Loss: 0.7580
Batch 240, Loss: 0.7216
Batch 250, Loss: 0.7622
Batch 260, Loss: 0.7508
Batch 270, Loss: 0.7161
Batch 280, Loss: 0.6816
Batch 290, Loss: 0.7432
Batch 300, Loss: 0.7413
Batch 310, Loss: 0.7152
Batch 320, Loss: 0.6951
Batch 330, Loss: 0.7475
Batch 340, Loss: 0.7227
Batch 350, Loss: 0.7593
Batch 360, Loss: 0.7391
Batch 370, Loss: 0.7725
Batch 380, Loss: 0.7487
Batch 390, Loss: 0.6924
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.22198510169983 seconds
Epoch 140 accuracy: 71.21%
Batch 10, Loss: 0.6865
Batch 20, Loss: 0.6724
Batch 30, Loss: 0.6696
Batch 40, Loss: 0.7181
Batch 50, Loss: 0.6830
Batch 60, Loss: 0.6378
Batch 70, Loss: 0.6545
Batch 80, Loss: 0.6872
Batch 90, Loss: 0.7344
Batch 100, Loss: 0.7146
Batch 110, Loss: 0.6809
Batch 120, Loss: 0.6543
Batch 130, Loss: 0.6970
Batch 140, Loss: 0.6797
Batch 150, Loss: 0.7082
Batch 160, Loss: 0.6779
Batch 170, Loss: 0.7167
Batch 180, Loss: 0.7307
Batch 190, Loss: 0.6942
Batch 200, Loss: 0.7293
Batch 210, Loss: 0.6456
Batch 220, Loss: 0.6809
Batch 230, Loss: 0.6897
Batch 240, Loss: 0.7076
Batch 250, Loss: 0.6972
Batch 260, Loss: 0.7365
Batch 270, Loss: 0.6878
Batch 280, Loss: 0.6884
Batch 290, Loss: 0.6734
Batch 300, Loss: 0.6968
Batch 310, Loss: 0.7454
Batch 320, Loss: 0.7139
Batch 330, Loss: 0.6502
Batch 340, Loss: 0.7546
Batch 350, Loss: 0.7460
Batch 360, Loss: 0.7037
Batch 370, Loss: 0.6529
Batch 380, Loss: 0.7166
Batch 390, Loss: 0.6922
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.187440872192383 seconds
Epoch 141 accuracy: 72.21%
Batch 10, Loss: 0.6603
Batch 20, Loss: 0.6424
Batch 30, Loss: 0.7069
Batch 40, Loss: 0.6275
Batch 50, Loss: 0.6616
Batch 60, Loss: 0.6689
Batch 70, Loss: 0.6838
Batch 80, Loss: 0.6767
Batch 90, Loss: 0.6733
Batch 100, Loss: 0.7320
Batch 110, Loss: 0.6723
Batch 120, Loss: 0.7012
Batch 130, Loss: 0.6761
Batch 140, Loss: 0.6990
Batch 150, Loss: 0.6944
Batch 160, Loss: 0.6896
Batch 170, Loss: 0.7222
Batch 180, Loss: 0.6558
Batch 190, Loss: 0.6629
Batch 200, Loss: 0.7532
Batch 210, Loss: 0.6750
Batch 220, Loss: 0.6885
Batch 230, Loss: 0.7076
Batch 240, Loss: 0.6981
Batch 250, Loss: 0.7258
Batch 260, Loss: 0.6616
Batch 270, Loss: 0.6669
Batch 280, Loss: 0.7122
Batch 290, Loss: 0.7103
Batch 300, Loss: 0.7044
Batch 310, Loss: 0.6799
Batch 320, Loss: 0.7152
Batch 330, Loss: 0.6908
Batch 340, Loss: 0.7113
Batch 350, Loss: 0.6741
Batch 360, Loss: 0.6779
Batch 370, Loss: 0.7361
Batch 380, Loss: 0.7111
Batch 390, Loss: 0.7115
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.1189923286438 seconds
Epoch 142 accuracy: 72.99%
Batch 10, Loss: 0.6757
Batch 20, Loss: 0.6240
Batch 30, Loss: 0.6438
Batch 40, Loss: 0.6558
Batch 50, Loss: 0.6449
Batch 60, Loss: 0.6659
Batch 70, Loss: 0.5924
Batch 80, Loss: 0.6513
Batch 90, Loss: 0.6421
Batch 100, Loss: 0.6912
Batch 110, Loss: 0.6078
Batch 120, Loss: 0.6397
Batch 130, Loss: 0.6858
Batch 140, Loss: 0.6678
Batch 150, Loss: 0.6813
Batch 160, Loss: 0.6404
Batch 170, Loss: 0.7170
Batch 180, Loss: 0.7023
Batch 190, Loss: 0.7266
Batch 200, Loss: 0.7057
Batch 210, Loss: 0.7024
Batch 220, Loss: 0.7282
Batch 230, Loss: 0.6841
Batch 240, Loss: 0.7030
Batch 250, Loss: 0.6675
Batch 260, Loss: 0.6753
Batch 270, Loss: 0.7234
Batch 280, Loss: 0.6949
Batch 290, Loss: 0.7312
Batch 300, Loss: 0.6783
Batch 310, Loss: 0.7243
Batch 320, Loss: 0.6539
Batch 330, Loss: 0.6924
Batch 340, Loss: 0.7209
Batch 350, Loss: 0.6726
Batch 360, Loss: 0.6994
Batch 370, Loss: 0.6676
Batch 380, Loss: 0.7404
Batch 390, Loss: 0.7381
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.209353923797607 seconds
Epoch 143 accuracy: 72.86%
Batch 10, Loss: 0.6342
Batch 20, Loss: 0.6311
Batch 30, Loss: 0.6883
Batch 40, Loss: 0.5924
Batch 50, Loss: 0.6361
Batch 60, Loss: 0.6273
Batch 70, Loss: 0.6335
Batch 80, Loss: 0.6254
Batch 90, Loss: 0.6596
Batch 100, Loss: 0.6723
Batch 110, Loss: 0.6716
Batch 120, Loss: 0.6390
Batch 130, Loss: 0.6559
Batch 140, Loss: 0.6395
Batch 150, Loss: 0.6379
Batch 160, Loss: 0.6277
Batch 170, Loss: 0.6528
Batch 180, Loss: 0.6563
Batch 190, Loss: 0.6879
Batch 200, Loss: 0.6356
Batch 210, Loss: 0.6797
Batch 220, Loss: 0.6294
Batch 230, Loss: 0.6561
Batch 240, Loss: 0.6869
Batch 250, Loss: 0.6734
Batch 260, Loss: 0.7020
Batch 270, Loss: 0.6823
Batch 280, Loss: 0.6272
Batch 290, Loss: 0.6588
Batch 300, Loss: 0.6716
Batch 310, Loss: 0.6598
Batch 320, Loss: 0.6800
Batch 330, Loss: 0.6882
Batch 340, Loss: 0.6739
Batch 350, Loss: 0.6706
Batch 360, Loss: 0.6253
Batch 370, Loss: 0.7025
Batch 380, Loss: 0.6679
Batch 390, Loss: 0.7309
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.100761651992798 seconds
Epoch 144 accuracy: 73.29%
Batch 10, Loss: 0.6497
Batch 20, Loss: 0.6417
Batch 30, Loss: 0.6012
Batch 40, Loss: 0.5901
Batch 50, Loss: 0.6397
Batch 60, Loss: 0.6343
Batch 70, Loss: 0.6588
Batch 80, Loss: 0.6233
Batch 90, Loss: 0.6708
Batch 100, Loss: 0.6720
Batch 110, Loss: 0.6531
Batch 120, Loss: 0.6585
Batch 130, Loss: 0.6431
Batch 140, Loss: 0.6308
Batch 150, Loss: 0.6434
Batch 160, Loss: 0.6829
Batch 170, Loss: 0.6274
Batch 180, Loss: 0.6639
Batch 190, Loss: 0.6700
Batch 200, Loss: 0.6349
Batch 210, Loss: 0.6654
Batch 220, Loss: 0.6488
Batch 230, Loss: 0.6323
Batch 240, Loss: 0.6624
Batch 250, Loss: 0.6552
Batch 260, Loss: 0.6816
Batch 270, Loss: 0.6761
Batch 280, Loss: 0.7225
Batch 290, Loss: 0.7294
Batch 300, Loss: 0.6445
Batch 310, Loss: 0.6509
Batch 320, Loss: 0.6555
Batch 330, Loss: 0.6531
Batch 340, Loss: 0.6834
Batch 350, Loss: 0.6814
Batch 360, Loss: 0.6725
Batch 370, Loss: 0.6335
Batch 380, Loss: 0.6737
Batch 390, Loss: 0.6659
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.114839553833008 seconds
Epoch 145 accuracy: 73.01%
Batch 10, Loss: 0.6200
Batch 20, Loss: 0.6310
Batch 30, Loss: 0.6418
Batch 40, Loss: 0.6153
Batch 50, Loss: 0.6567
Batch 60, Loss: 0.6369
Batch 70, Loss: 0.6025
Batch 80, Loss: 0.6420
Batch 90, Loss: 0.5786
Batch 100, Loss: 0.6510
Batch 110, Loss: 0.6129
Batch 120, Loss: 0.6202
Batch 130, Loss: 0.6129
Batch 140, Loss: 0.6417
Batch 150, Loss: 0.5943
Batch 160, Loss: 0.6456
Batch 170, Loss: 0.6043
Batch 180, Loss: 0.6144
Batch 190, Loss: 0.5975
Batch 200, Loss: 0.6482
Batch 210, Loss: 0.6005
Batch 220, Loss: 0.6482
Batch 230, Loss: 0.6428
Batch 240, Loss: 0.6491
Batch 250, Loss: 0.6615
Batch 260, Loss: 0.6190
Batch 270, Loss: 0.6114
Batch 280, Loss: 0.5900
Batch 290, Loss: 0.6742
Batch 300, Loss: 0.7175
Batch 310, Loss: 0.6287
Batch 320, Loss: 0.6412
Batch 330, Loss: 0.6192
Batch 340, Loss: 0.6332
Batch 350, Loss: 0.6664
Batch 360, Loss: 0.6911
Batch 370, Loss: 0.6783
Batch 380, Loss: 0.6184
Batch 390, Loss: 0.6943
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.044280290603638 seconds
Epoch 146 accuracy: 73.07%
Batch 10, Loss: 0.6277
Batch 20, Loss: 0.6086
Batch 30, Loss: 0.6361
Batch 40, Loss: 0.5327
Batch 50, Loss: 0.6094
Batch 60, Loss: 0.5989
Batch 70, Loss: 0.5953
Batch 80, Loss: 0.6271
Batch 90, Loss: 0.6149
Batch 100, Loss: 0.6171
Batch 110, Loss: 0.5975
Batch 120, Loss: 0.6251
Batch 130, Loss: 0.6024
Batch 140, Loss: 0.6373
Batch 150, Loss: 0.5764
Batch 160, Loss: 0.6057
Batch 170, Loss: 0.6116
Batch 180, Loss: 0.6500
Batch 190, Loss: 0.6640
Batch 200, Loss: 0.6119
Batch 210, Loss: 0.6214
Batch 220, Loss: 0.6145
Batch 230, Loss: 0.6437
Batch 240, Loss: 0.6663
Batch 250, Loss: 0.5946
Batch 260, Loss: 0.6644
Batch 270, Loss: 0.6249
Batch 280, Loss: 0.5905
Batch 290, Loss: 0.6412
Batch 300, Loss: 0.6331
Batch 310, Loss: 0.6469
Batch 320, Loss: 0.6353
Batch 330, Loss: 0.6116
Batch 340, Loss: 0.6698
Batch 350, Loss: 0.6456
Batch 360, Loss: 0.6459
Batch 370, Loss: 0.6999
Batch 380, Loss: 0.6251
Batch 390, Loss: 0.6451
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.179998874664307 seconds
Epoch 147 accuracy: 74.59%
Batch 10, Loss: 0.5868
Batch 20, Loss: 0.6041
Batch 30, Loss: 0.5979
Batch 40, Loss: 0.6143
Batch 50, Loss: 0.6452
Batch 60, Loss: 0.5835
Batch 70, Loss: 0.5840
Batch 80, Loss: 0.6019
Batch 90, Loss: 0.5719
Batch 100, Loss: 0.6433
Batch 110, Loss: 0.6115
Batch 120, Loss: 0.6124
Batch 130, Loss: 0.6254
Batch 140, Loss: 0.6313
Batch 150, Loss: 0.6720
Batch 160, Loss: 0.6424
Batch 170, Loss: 0.6340
Batch 180, Loss: 0.6466
Batch 190, Loss: 0.6066
Batch 200, Loss: 0.6304
Batch 210, Loss: 0.6101
Batch 220, Loss: 0.6201
Batch 230, Loss: 0.6217
Batch 240, Loss: 0.6266
Batch 250, Loss: 0.6324
Batch 260, Loss: 0.6340
Batch 270, Loss: 0.6515
Batch 280, Loss: 0.6156
Batch 290, Loss: 0.6562
Batch 300, Loss: 0.6424
Batch 310, Loss: 0.6592
Batch 320, Loss: 0.6582
Batch 330, Loss: 0.6213
Batch 340, Loss: 0.6846
Batch 350, Loss: 0.5988
Batch 360, Loss: 0.6657
Batch 370, Loss: 0.6594
Batch 380, Loss: 0.6442
Batch 390, Loss: 0.5999
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.202614307403564 seconds
Epoch 148 accuracy: 73.59%
Batch 10, Loss: 0.6035
Batch 20, Loss: 0.5841
Batch 30, Loss: 0.6095
Batch 40, Loss: 0.5668
Batch 50, Loss: 0.5342
Batch 60, Loss: 0.5852
Batch 70, Loss: 0.6223
Batch 80, Loss: 0.5992
Batch 90, Loss: 0.5849
Batch 100, Loss: 0.6061
Batch 110, Loss: 0.6214
Batch 120, Loss: 0.5948
Batch 130, Loss: 0.5918
Batch 140, Loss: 0.6171
Batch 150, Loss: 0.5749
Batch 160, Loss: 0.6181
Batch 170, Loss: 0.6119
Batch 180, Loss: 0.6130
Batch 190, Loss: 0.5830
Batch 200, Loss: 0.5991
Batch 210, Loss: 0.5976
Batch 220, Loss: 0.5849
Batch 230, Loss: 0.5726
Batch 240, Loss: 0.6334
Batch 250, Loss: 0.6857
Batch 260, Loss: 0.6112
Batch 270, Loss: 0.6005
Batch 280, Loss: 0.6564
Batch 290, Loss: 0.6216
Batch 300, Loss: 0.5761
Batch 310, Loss: 0.6593
Batch 320, Loss: 0.6390
Batch 330, Loss: 0.6200
Batch 340, Loss: 0.6009
Batch 350, Loss: 0.6205
Batch 360, Loss: 0.6430
Batch 370, Loss: 0.6528
Batch 380, Loss: 0.6389
Batch 390, Loss: 0.6294
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.171262741088867 seconds
Epoch 149 accuracy: 74.26%
Batch 10, Loss: 0.5596
Batch 20, Loss: 0.5256
Batch 30, Loss: 0.5253
Batch 40, Loss: 0.5782
Batch 50, Loss: 0.5793
Batch 60, Loss: 0.5675
Batch 70, Loss: 0.5804
Batch 80, Loss: 0.5600
Batch 90, Loss: 0.5920
Batch 100, Loss: 0.5615
Batch 110, Loss: 0.5750
Batch 120, Loss: 0.5553
Batch 130, Loss: 0.6225
Batch 140, Loss: 0.5645
Batch 150, Loss: 0.5603
Batch 160, Loss: 0.6196
Batch 170, Loss: 0.6088
Batch 180, Loss: 0.6140
Batch 190, Loss: 0.5748
Batch 200, Loss: 0.5828
Batch 210, Loss: 0.5619
Batch 220, Loss: 0.6109
Batch 230, Loss: 0.6021
Batch 240, Loss: 0.6185
Batch 250, Loss: 0.5520
Batch 260, Loss: 0.6146
Batch 270, Loss: 0.5524
Batch 280, Loss: 0.5814
Batch 290, Loss: 0.6000
Batch 300, Loss: 0.6303
Batch 310, Loss: 0.5824
Batch 320, Loss: 0.5853
Batch 330, Loss: 0.6128
Batch 340, Loss: 0.5633
Batch 350, Loss: 0.5866
Batch 360, Loss: 0.6057
Batch 370, Loss: 0.5769
Batch 380, Loss: 0.6309
Batch 390, Loss: 0.5709
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.196699619293213 seconds
Epoch 150 accuracy: 73.01%
Batch 10, Loss: 0.5998
Batch 20, Loss: 0.5891
Batch 30, Loss: 0.5238
Batch 40, Loss: 0.5691
Batch 50, Loss: 0.5540
Batch 60, Loss: 0.5117
Batch 70, Loss: 0.5248
Batch 80, Loss: 0.5516
Batch 90, Loss: 0.6079
Batch 100, Loss: 0.6000
Batch 110, Loss: 0.5919
Batch 120, Loss: 0.5777
Batch 130, Loss: 0.5977
Batch 140, Loss: 0.5772
Batch 150, Loss: 0.5830
Batch 160, Loss: 0.5791
Batch 170, Loss: 0.5790
Batch 180, Loss: 0.5882
Batch 190, Loss: 0.5718
Batch 200, Loss: 0.5704
Batch 210, Loss: 0.5675
Batch 220, Loss: 0.5946
Batch 230, Loss: 0.5810
Batch 240, Loss: 0.5876
Batch 250, Loss: 0.6003
Batch 260, Loss: 0.5971
Batch 270, Loss: 0.5534
Batch 280, Loss: 0.5904
Batch 290, Loss: 0.6022
Batch 300, Loss: 0.6004
Batch 310, Loss: 0.5762
Batch 320, Loss: 0.5798
Batch 330, Loss: 0.6505
Batch 340, Loss: 0.5574
Batch 350, Loss: 0.5478
Batch 360, Loss: 0.5929
Batch 370, Loss: 0.6277
Batch 380, Loss: 0.6063
Batch 390, Loss: 0.6294
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.18946385383606 seconds
Epoch 151 accuracy: 74.76%
Batch 10, Loss: 0.5455
Batch 20, Loss: 0.5117
Batch 30, Loss: 0.5287
Batch 40, Loss: 0.5530
Batch 50, Loss: 0.5178
Batch 60, Loss: 0.5676
Batch 70, Loss: 0.5808
Batch 80, Loss: 0.5662
Batch 90, Loss: 0.5485
Batch 100, Loss: 0.5681
Batch 110, Loss: 0.5423
Batch 120, Loss: 0.5169
Batch 130, Loss: 0.5883
Batch 140, Loss: 0.6076
Batch 150, Loss: 0.5629
Batch 160, Loss: 0.5863
Batch 170, Loss: 0.5954
Batch 180, Loss: 0.6033
Batch 190, Loss: 0.5885
Batch 200, Loss: 0.6333
Batch 210, Loss: 0.5875
Batch 220, Loss: 0.5941
Batch 230, Loss: 0.5801
Batch 240, Loss: 0.5557
Batch 250, Loss: 0.5348
Batch 260, Loss: 0.5356
Batch 270, Loss: 0.5548
Batch 280, Loss: 0.5867
Batch 290, Loss: 0.5272
Batch 300, Loss: 0.6119
Batch 310, Loss: 0.5830
Batch 320, Loss: 0.5975
Batch 330, Loss: 0.5793
Batch 340, Loss: 0.5430
Batch 350, Loss: 0.5462
Batch 360, Loss: 0.5693
Batch 370, Loss: 0.5673
Batch 380, Loss: 0.5781
Batch 390, Loss: 0.5823
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.178025722503662 seconds
Epoch 152 accuracy: 75.04%
Batch 10, Loss: 0.5221
Batch 20, Loss: 0.5213
Batch 30, Loss: 0.5821
Batch 40, Loss: 0.5016
Batch 50, Loss: 0.5407
Batch 60, Loss: 0.5428
Batch 70, Loss: 0.5398
Batch 80, Loss: 0.5495
Batch 90, Loss: 0.5620
Batch 100, Loss: 0.5471
Batch 110, Loss: 0.5396
Batch 120, Loss: 0.5365
Batch 130, Loss: 0.5547
Batch 140, Loss: 0.5499
Batch 150, Loss: 0.5791
Batch 160, Loss: 0.5368
Batch 170, Loss: 0.5470
Batch 180, Loss: 0.5220
Batch 190, Loss: 0.5429
Batch 200, Loss: 0.6012
Batch 210, Loss: 0.5740
Batch 220, Loss: 0.5668
Batch 230, Loss: 0.5574
Batch 240, Loss: 0.5988
Batch 250, Loss: 0.5259
Batch 260, Loss: 0.5059
Batch 270, Loss: 0.5880
Batch 280, Loss: 0.6036
Batch 290, Loss: 0.5432
Batch 300, Loss: 0.5478
Batch 310, Loss: 0.5724
Batch 320, Loss: 0.5539
Batch 330, Loss: 0.5554
Batch 340, Loss: 0.5511
Batch 350, Loss: 0.5403
Batch 360, Loss: 0.5636
Batch 370, Loss: 0.5696
Batch 380, Loss: 0.5659
Batch 390, Loss: 0.5522
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.11805486679077 seconds
Epoch 153 accuracy: 75.01%
Batch 10, Loss: 0.5971
Batch 20, Loss: 0.5275
Batch 30, Loss: 0.5641
Batch 40, Loss: 0.5383
Batch 50, Loss: 0.5036
Batch 60, Loss: 0.5211
Batch 70, Loss: 0.5240
Batch 80, Loss: 0.5418
Batch 90, Loss: 0.5095
Batch 100, Loss: 0.5241
Batch 110, Loss: 0.5299
Batch 120, Loss: 0.5511
Batch 130, Loss: 0.5088
Batch 140, Loss: 0.4973
Batch 150, Loss: 0.5540
Batch 160, Loss: 0.5594
Batch 170, Loss: 0.5590
Batch 180, Loss: 0.5785
Batch 190, Loss: 0.5790
Batch 200, Loss: 0.5640
Batch 210, Loss: 0.5582
Batch 220, Loss: 0.5470
Batch 230, Loss: 0.5347
Batch 240, Loss: 0.5469
Batch 250, Loss: 0.5593
Batch 260, Loss: 0.5607
Batch 270, Loss: 0.5590
Batch 280, Loss: 0.5603
Batch 290, Loss: 0.5474
Batch 300, Loss: 0.5851
Batch 310, Loss: 0.5822
Batch 320, Loss: 0.5460
Batch 330, Loss: 0.5667
Batch 340, Loss: 0.5756
Batch 350, Loss: 0.5483
Batch 360, Loss: 0.5744
Batch 370, Loss: 0.5847
Batch 380, Loss: 0.5360
Batch 390, Loss: 0.5672
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.14185333251953 seconds
Epoch 154 accuracy: 75.29%
Batch 10, Loss: 0.5010
Batch 20, Loss: 0.5344
Batch 30, Loss: 0.5339
Batch 40, Loss: 0.5039
Batch 50, Loss: 0.5079
Batch 60, Loss: 0.5648
Batch 70, Loss: 0.4839
Batch 80, Loss: 0.5448
Batch 90, Loss: 0.5208
Batch 100, Loss: 0.5023
Batch 110, Loss: 0.5540
Batch 120, Loss: 0.5444
Batch 130, Loss: 0.5064
Batch 140, Loss: 0.5408
Batch 150, Loss: 0.5265
Batch 160, Loss: 0.5878
Batch 170, Loss: 0.5089
Batch 180, Loss: 0.5373
Batch 190, Loss: 0.5551
Batch 200, Loss: 0.5070
Batch 210, Loss: 0.5434
Batch 220, Loss: 0.5378
Batch 230, Loss: 0.5246
Batch 240, Loss: 0.5734
Batch 250, Loss: 0.5003
Batch 260, Loss: 0.5408
Batch 270, Loss: 0.5002
Batch 280, Loss: 0.5514
Batch 290, Loss: 0.5522
Batch 300, Loss: 0.5262
Batch 310, Loss: 0.5329
Batch 320, Loss: 0.5875
Batch 330, Loss: 0.5569
Batch 340, Loss: 0.5417
Batch 350, Loss: 0.5621
Batch 360, Loss: 0.5764
Batch 370, Loss: 0.5479
Batch 380, Loss: 0.5344
Batch 390, Loss: 0.5393
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.103206634521484 seconds
Epoch 155 accuracy: 74.18%
Batch 10, Loss: 0.5063
Batch 20, Loss: 0.5046
Batch 30, Loss: 0.5201
Batch 40, Loss: 0.5196
Batch 50, Loss: 0.4565
Batch 60, Loss: 0.4792
Batch 70, Loss: 0.5159
Batch 80, Loss: 0.5282
Batch 90, Loss: 0.5229
Batch 100, Loss: 0.5270
Batch 110, Loss: 0.5118
Batch 120, Loss: 0.5398
Batch 130, Loss: 0.5001
Batch 140, Loss: 0.5304
Batch 150, Loss: 0.5287
Batch 160, Loss: 0.5053
Batch 170, Loss: 0.5062
Batch 180, Loss: 0.5508
Batch 190, Loss: 0.5050
Batch 200, Loss: 0.5342
Batch 210, Loss: 0.5445
Batch 220, Loss: 0.5520
Batch 230, Loss: 0.5345
Batch 240, Loss: 0.5345
Batch 250, Loss: 0.5550
Batch 260, Loss: 0.5205
Batch 270, Loss: 0.4773
Batch 280, Loss: 0.5174
Batch 290, Loss: 0.4991
Batch 300, Loss: 0.5191
Batch 310, Loss: 0.5346
Batch 320, Loss: 0.5363
Batch 330, Loss: 0.5578
Batch 340, Loss: 0.5863
Batch 350, Loss: 0.5512
Batch 360, Loss: 0.5636
Batch 370, Loss: 0.5579
Batch 380, Loss: 0.5385
Batch 390, Loss: 0.5246
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.166715145111084 seconds
Epoch 156 accuracy: 74.9%
Batch 10, Loss: 0.5590
Batch 20, Loss: 0.4893
Batch 30, Loss: 0.5105
Batch 40, Loss: 0.4518
Batch 50, Loss: 0.5024
Batch 60, Loss: 0.4961
Batch 70, Loss: 0.4794
Batch 80, Loss: 0.4859
Batch 90, Loss: 0.4566
Batch 100, Loss: 0.4924
Batch 110, Loss: 0.5282
Batch 120, Loss: 0.5109
Batch 130, Loss: 0.5287
Batch 140, Loss: 0.5082
Batch 150, Loss: 0.5659
Batch 160, Loss: 0.4720
Batch 170, Loss: 0.5148
Batch 180, Loss: 0.5072
Batch 190, Loss: 0.5824
Batch 200, Loss: 0.4772
Batch 210, Loss: 0.4777
Batch 220, Loss: 0.4820
Batch 230, Loss: 0.5403
Batch 240, Loss: 0.4552
Batch 250, Loss: 0.4919
Batch 260, Loss: 0.5246
Batch 270, Loss: 0.5119
Batch 280, Loss: 0.5281
Batch 290, Loss: 0.5291
Batch 300, Loss: 0.5038
Batch 310, Loss: 0.5121
Batch 320, Loss: 0.5389
Batch 330, Loss: 0.4918
Batch 340, Loss: 0.5302
Batch 350, Loss: 0.5371
Batch 360, Loss: 0.5439
Batch 370, Loss: 0.5770
Batch 380, Loss: 0.5167
Batch 390, Loss: 0.5386
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.08370804786682 seconds
Epoch 157 accuracy: 75.38%
Batch 10, Loss: 0.4609
Batch 20, Loss: 0.5088
Batch 30, Loss: 0.4529
Batch 40, Loss: 0.4865
Batch 50, Loss: 0.4748
Batch 60, Loss: 0.5103
Batch 70, Loss: 0.5134
Batch 80, Loss: 0.4627
Batch 90, Loss: 0.5451
Batch 100, Loss: 0.5243
Batch 110, Loss: 0.5104
Batch 120, Loss: 0.5074
Batch 130, Loss: 0.5263
Batch 140, Loss: 0.5090
Batch 150, Loss: 0.5419
Batch 160, Loss: 0.4810
Batch 170, Loss: 0.5073
Batch 180, Loss: 0.5375
Batch 190, Loss: 0.4933
Batch 200, Loss: 0.4843
Batch 210, Loss: 0.4671
Batch 220, Loss: 0.5223
Batch 230, Loss: 0.5077
Batch 240, Loss: 0.4824
Batch 250, Loss: 0.4882
Batch 260, Loss: 0.4979
Batch 270, Loss: 0.5332
Batch 280, Loss: 0.4960
Batch 290, Loss: 0.5520
Batch 300, Loss: 0.4939
Batch 310, Loss: 0.4983
Batch 320, Loss: 0.5125
Batch 330, Loss: 0.5323
Batch 340, Loss: 0.5112
Batch 350, Loss: 0.4799
Batch 360, Loss: 0.5202
Batch 370, Loss: 0.5361
Batch 380, Loss: 0.5014
Batch 390, Loss: 0.5015
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.12132716178894 seconds
Epoch 158 accuracy: 75.74%
Batch 10, Loss: 0.4904
Batch 20, Loss: 0.4724
Batch 30, Loss: 0.4921
Batch 40, Loss: 0.4582
Batch 50, Loss: 0.4963
Batch 60, Loss: 0.4824
Batch 70, Loss: 0.4926
Batch 80, Loss: 0.4395
Batch 90, Loss: 0.4713
Batch 100, Loss: 0.5141
Batch 110, Loss: 0.4984
Batch 120, Loss: 0.4724
Batch 130, Loss: 0.5149
Batch 140, Loss: 0.5117
Batch 150, Loss: 0.4991
Batch 160, Loss: 0.4640
Batch 170, Loss: 0.4929
Batch 180, Loss: 0.4538
Batch 190, Loss: 0.4524
Batch 200, Loss: 0.4717
Batch 210, Loss: 0.4934
Batch 220, Loss: 0.4857
Batch 230, Loss: 0.4990
Batch 240, Loss: 0.5089
Batch 250, Loss: 0.5014
Batch 260, Loss: 0.5042
Batch 270, Loss: 0.4676
Batch 280, Loss: 0.5075
Batch 290, Loss: 0.5091
Batch 300, Loss: 0.4689
Batch 310, Loss: 0.4812
Batch 320, Loss: 0.4691
Batch 330, Loss: 0.4836
Batch 340, Loss: 0.4711
Batch 350, Loss: 0.4926
Batch 360, Loss: 0.4745
Batch 370, Loss: 0.5036
Batch 380, Loss: 0.4711
Batch 390, Loss: 0.5286
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.147860050201416 seconds
Epoch 159 accuracy: 75.76%
Batch 10, Loss: 0.4542
Batch 20, Loss: 0.4635
Batch 30, Loss: 0.4524
Batch 40, Loss: 0.4766
Batch 50, Loss: 0.4805
Batch 60, Loss: 0.5019
Batch 70, Loss: 0.4474
Batch 80, Loss: 0.4497
Batch 90, Loss: 0.4635
Batch 100, Loss: 0.4401
Batch 110, Loss: 0.4371
Batch 120, Loss: 0.4194
Batch 130, Loss: 0.4582
Batch 140, Loss: 0.4301
Batch 150, Loss: 0.4572
Batch 160, Loss: 0.5044
Batch 170, Loss: 0.4627
Batch 180, Loss: 0.4679
Batch 190, Loss: 0.4606
Batch 200, Loss: 0.5092
Batch 210, Loss: 0.4664
Batch 220, Loss: 0.4822
Batch 230, Loss: 0.5069
Batch 240, Loss: 0.4816
Batch 250, Loss: 0.4880
Batch 260, Loss: 0.4674
Batch 270, Loss: 0.4342
Batch 280, Loss: 0.4859
Batch 290, Loss: 0.4940
Batch 300, Loss: 0.4933
Batch 310, Loss: 0.4869
Batch 320, Loss: 0.4789
Batch 330, Loss: 0.4943
Batch 340, Loss: 0.5061
Batch 350, Loss: 0.5197
Batch 360, Loss: 0.4646
Batch 370, Loss: 0.4772
Batch 380, Loss: 0.4955
Batch 390, Loss: 0.5011
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.153226613998413 seconds
Epoch 160 accuracy: 76.08%
Batch 10, Loss: 0.4619
Batch 20, Loss: 0.4789
Batch 30, Loss: 0.4884
Batch 40, Loss: 0.4726
Batch 50, Loss: 0.4522
Batch 60, Loss: 0.4523
Batch 70, Loss: 0.5200
Batch 80, Loss: 0.4333
Batch 90, Loss: 0.4179
Batch 100, Loss: 0.4352
Batch 110, Loss: 0.4245
Batch 120, Loss: 0.4617
Batch 130, Loss: 0.4601
Batch 140, Loss: 0.4712
Batch 150, Loss: 0.4583
Batch 160, Loss: 0.4440
Batch 170, Loss: 0.4868
Batch 180, Loss: 0.4850
Batch 190, Loss: 0.4924
Batch 200, Loss: 0.4235
Batch 210, Loss: 0.5232
Batch 220, Loss: 0.4510
Batch 230, Loss: 0.4573
Batch 240, Loss: 0.4729
Batch 250, Loss: 0.4763
Batch 260, Loss: 0.4475
Batch 270, Loss: 0.4605
Batch 280, Loss: 0.4628
Batch 290, Loss: 0.4690
Batch 300, Loss: 0.4846
Batch 310, Loss: 0.5043
Batch 320, Loss: 0.4684
Batch 330, Loss: 0.4333
Batch 340, Loss: 0.4618
Batch 350, Loss: 0.4490
Batch 360, Loss: 0.4573
Batch 370, Loss: 0.4809
Batch 380, Loss: 0.4676
Batch 390, Loss: 0.4606
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.107524871826172 seconds
Epoch 161 accuracy: 76.81%
Batch 10, Loss: 0.4228
Batch 20, Loss: 0.5041
Batch 30, Loss: 0.4940
Batch 40, Loss: 0.4326
Batch 50, Loss: 0.4429
Batch 60, Loss: 0.4684
Batch 70, Loss: 0.4465
Batch 80, Loss: 0.4582
Batch 90, Loss: 0.4560
Batch 100, Loss: 0.4394
Batch 110, Loss: 0.4268
Batch 120, Loss: 0.4792
Batch 130, Loss: 0.4587
Batch 140, Loss: 0.4386
Batch 150, Loss: 0.4419
Batch 160, Loss: 0.4599
Batch 170, Loss: 0.4704
Batch 180, Loss: 0.4533
Batch 190, Loss: 0.4756
Batch 200, Loss: 0.4713
Batch 210, Loss: 0.4908
Batch 220, Loss: 0.4589
Batch 230, Loss: 0.4576
Batch 240, Loss: 0.4356
Batch 250, Loss: 0.4611
Batch 260, Loss: 0.4240
Batch 270, Loss: 0.4387
Batch 280, Loss: 0.4611
Batch 290, Loss: 0.4426
Batch 300, Loss: 0.4303
Batch 310, Loss: 0.4748
Batch 320, Loss: 0.5128
Batch 330, Loss: 0.4246
Batch 340, Loss: 0.4019
Batch 350, Loss: 0.4530
Batch 360, Loss: 0.4456
Batch 370, Loss: 0.4552
Batch 380, Loss: 0.4308
Batch 390, Loss: 0.4616
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.133623361587524 seconds
Epoch 162 accuracy: 76.2%
Batch 10, Loss: 0.4509
Batch 20, Loss: 0.4136
Batch 30, Loss: 0.4410
Batch 40, Loss: 0.3787
Batch 50, Loss: 0.4095
Batch 60, Loss: 0.4156
Batch 70, Loss: 0.4624
Batch 80, Loss: 0.4083
Batch 90, Loss: 0.4107
Batch 100, Loss: 0.4470
Batch 110, Loss: 0.3969
Batch 120, Loss: 0.4513
Batch 130, Loss: 0.4319
Batch 140, Loss: 0.4283
Batch 150, Loss: 0.4481
Batch 160, Loss: 0.4475
Batch 170, Loss: 0.4450
Batch 180, Loss: 0.4177
Batch 190, Loss: 0.4011
Batch 200, Loss: 0.4367
Batch 210, Loss: 0.4252
Batch 220, Loss: 0.4799
Batch 230, Loss: 0.4294
Batch 240, Loss: 0.4686
Batch 250, Loss: 0.4740
Batch 260, Loss: 0.4674
Batch 270, Loss: 0.4485
Batch 280, Loss: 0.4812
Batch 290, Loss: 0.4333
Batch 300, Loss: 0.4440
Batch 310, Loss: 0.4694
Batch 320, Loss: 0.4611
Batch 330, Loss: 0.4458
Batch 340, Loss: 0.4582
Batch 350, Loss: 0.4269
Batch 360, Loss: 0.4542
Batch 370, Loss: 0.4537
Batch 380, Loss: 0.4459
Batch 390, Loss: 0.4924
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.163387298583984 seconds
Epoch 163 accuracy: 76.69%
Batch 10, Loss: 0.4296
Batch 20, Loss: 0.4437
Batch 30, Loss: 0.3874
Batch 40, Loss: 0.4431
Batch 50, Loss: 0.4267
Batch 60, Loss: 0.3762
Batch 70, Loss: 0.4326
Batch 80, Loss: 0.4195
Batch 90, Loss: 0.4167
Batch 100, Loss: 0.3936
Batch 110, Loss: 0.4177
Batch 120, Loss: 0.4123
Batch 130, Loss: 0.4189
Batch 140, Loss: 0.3922
Batch 150, Loss: 0.4367
Batch 160, Loss: 0.4421
Batch 170, Loss: 0.4357
Batch 180, Loss: 0.4255
Batch 190, Loss: 0.4175
Batch 200, Loss: 0.4316
Batch 210, Loss: 0.4341
Batch 220, Loss: 0.4238
Batch 230, Loss: 0.4248
Batch 240, Loss: 0.4032
Batch 250, Loss: 0.4397
Batch 260, Loss: 0.4702
Batch 270, Loss: 0.4080
Batch 280, Loss: 0.4698
Batch 290, Loss: 0.3941
Batch 300, Loss: 0.4168
Batch 310, Loss: 0.4196
Batch 320, Loss: 0.4063
Batch 330, Loss: 0.4230
Batch 340, Loss: 0.4373
Batch 350, Loss: 0.4385
Batch 360, Loss: 0.4154
Batch 370, Loss: 0.4313
Batch 380, Loss: 0.4403
Batch 390, Loss: 0.4871
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.168538570404053 seconds
Epoch 164 accuracy: 76.72%
Batch 10, Loss: 0.4588
Batch 20, Loss: 0.4689
Batch 30, Loss: 0.4289
Batch 40, Loss: 0.4265
Batch 50, Loss: 0.4046
Batch 60, Loss: 0.4150
Batch 70, Loss: 0.4465
Batch 80, Loss: 0.4053
Batch 90, Loss: 0.4131
Batch 100, Loss: 0.3841
Batch 110, Loss: 0.4227
Batch 120, Loss: 0.3970
Batch 130, Loss: 0.4504
Batch 140, Loss: 0.3859
Batch 150, Loss: 0.4549
Batch 160, Loss: 0.3903
Batch 170, Loss: 0.4121
Batch 180, Loss: 0.4037
Batch 190, Loss: 0.3808
Batch 200, Loss: 0.4258
Batch 210, Loss: 0.4093
Batch 220, Loss: 0.4492
Batch 230, Loss: 0.4146
Batch 240, Loss: 0.4063
Batch 250, Loss: 0.4029
Batch 260, Loss: 0.4263
Batch 270, Loss: 0.4407
Batch 280, Loss: 0.4214
Batch 290, Loss: 0.4090
Batch 300, Loss: 0.4316
Batch 310, Loss: 0.4155
Batch 320, Loss: 0.4154
Batch 330, Loss: 0.3996
Batch 340, Loss: 0.4214
Batch 350, Loss: 0.4145
Batch 360, Loss: 0.4030
Batch 370, Loss: 0.4079
Batch 380, Loss: 0.4078
Batch 390, Loss: 0.3959
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.15925931930542 seconds
Epoch 165 accuracy: 76.44%
Batch 10, Loss: 0.3885
Batch 20, Loss: 0.4237
Batch 30, Loss: 0.4070
Batch 40, Loss: 0.4164
Batch 50, Loss: 0.4285
Batch 60, Loss: 0.4384
Batch 70, Loss: 0.4051
Batch 80, Loss: 0.3876
Batch 90, Loss: 0.4245
Batch 100, Loss: 0.4253
Batch 110, Loss: 0.3874
Batch 120, Loss: 0.4301
Batch 130, Loss: 0.3487
Batch 140, Loss: 0.3984
Batch 150, Loss: 0.4134
Batch 160, Loss: 0.4067
Batch 170, Loss: 0.4149
Batch 180, Loss: 0.3771
Batch 190, Loss: 0.3930
Batch 200, Loss: 0.4274
Batch 210, Loss: 0.4101
Batch 220, Loss: 0.4360
Batch 230, Loss: 0.4528
Batch 240, Loss: 0.3918
Batch 250, Loss: 0.4005
Batch 260, Loss: 0.4309
Batch 270, Loss: 0.4180
Batch 280, Loss: 0.4078
Batch 290, Loss: 0.4421
Batch 300, Loss: 0.4143
Batch 310, Loss: 0.3969
Batch 320, Loss: 0.4241
Batch 330, Loss: 0.4390
Batch 340, Loss: 0.4442
Batch 350, Loss: 0.4248
Batch 360, Loss: 0.4356
Batch 370, Loss: 0.3996
Batch 380, Loss: 0.3982
Batch 390, Loss: 0.3944
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.218621015548706 seconds
Epoch 166 accuracy: 77.35%
Batch 10, Loss: 0.3891
Batch 20, Loss: 0.4210
Batch 30, Loss: 0.3678
Batch 40, Loss: 0.4090
Batch 50, Loss: 0.3467
Batch 60, Loss: 0.3756
Batch 70, Loss: 0.4273
Batch 80, Loss: 0.3693
Batch 90, Loss: 0.3951
Batch 100, Loss: 0.4035
Batch 110, Loss: 0.3762
Batch 120, Loss: 0.3674
Batch 130, Loss: 0.3933
Batch 140, Loss: 0.4032
Batch 150, Loss: 0.4029
Batch 160, Loss: 0.4128
Batch 170, Loss: 0.4018
Batch 180, Loss: 0.3743
Batch 190, Loss: 0.4135
Batch 200, Loss: 0.4243
Batch 210, Loss: 0.4073
Batch 220, Loss: 0.4174
Batch 230, Loss: 0.3926
Batch 240, Loss: 0.4137
Batch 250, Loss: 0.3995
Batch 260, Loss: 0.3796
Batch 270, Loss: 0.4093
Batch 280, Loss: 0.4024
Batch 290, Loss: 0.4208
Batch 300, Loss: 0.4046
Batch 310, Loss: 0.4196
Batch 320, Loss: 0.3870
Batch 330, Loss: 0.4088
Batch 340, Loss: 0.3995
Batch 350, Loss: 0.4447
Batch 360, Loss: 0.3811
Batch 370, Loss: 0.4157
Batch 380, Loss: 0.4033
Batch 390, Loss: 0.3756
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.14170265197754 seconds
Epoch 167 accuracy: 77.59%
Batch 10, Loss: 0.4083
Batch 20, Loss: 0.3569
Batch 30, Loss: 0.3835
Batch 40, Loss: 0.3960
Batch 50, Loss: 0.4156
Batch 60, Loss: 0.3795
Batch 70, Loss: 0.3632
Batch 80, Loss: 0.4109
Batch 90, Loss: 0.3760
Batch 100, Loss: 0.4357
Batch 110, Loss: 0.4057
Batch 120, Loss: 0.4039
Batch 130, Loss: 0.4066
Batch 140, Loss: 0.3888
Batch 150, Loss: 0.3835
Batch 160, Loss: 0.4204
Batch 170, Loss: 0.3525
Batch 180, Loss: 0.3970
Batch 190, Loss: 0.3743
Batch 200, Loss: 0.4245
Batch 210, Loss: 0.3930
Batch 220, Loss: 0.4065
Batch 230, Loss: 0.3800
Batch 240, Loss: 0.3603
Batch 250, Loss: 0.3820
Batch 260, Loss: 0.4059
Batch 270, Loss: 0.3848
Batch 280, Loss: 0.4089
Batch 290, Loss: 0.4377
Batch 300, Loss: 0.4163
Batch 310, Loss: 0.3892
Batch 320, Loss: 0.3886
Batch 330, Loss: 0.4205
Batch 340, Loss: 0.3587
Batch 350, Loss: 0.3773
Batch 360, Loss: 0.4173
Batch 370, Loss: 0.4125
Batch 380, Loss: 0.3518
Batch 390, Loss: 0.4221
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.14291024208069 seconds
Epoch 168 accuracy: 77.57%
Batch 10, Loss: 0.3679
Batch 20, Loss: 0.3799
Batch 30, Loss: 0.3953
Batch 40, Loss: 0.3292
Batch 50, Loss: 0.3329
Batch 60, Loss: 0.3840
Batch 70, Loss: 0.3519
Batch 80, Loss: 0.3752
Batch 90, Loss: 0.3793
Batch 100, Loss: 0.3300
Batch 110, Loss: 0.4005
Batch 120, Loss: 0.3402
Batch 130, Loss: 0.4190
Batch 140, Loss: 0.3782
Batch 150, Loss: 0.3450
Batch 160, Loss: 0.3868
Batch 170, Loss: 0.4026
Batch 180, Loss: 0.3700
Batch 190, Loss: 0.4044
Batch 200, Loss: 0.3560
Batch 210, Loss: 0.3738
Batch 220, Loss: 0.3916
Batch 230, Loss: 0.3687
Batch 240, Loss: 0.3934
Batch 250, Loss: 0.3627
Batch 260, Loss: 0.4160
Batch 270, Loss: 0.3724
Batch 280, Loss: 0.4011
Batch 290, Loss: 0.4100
Batch 300, Loss: 0.3661
Batch 310, Loss: 0.4068
Batch 320, Loss: 0.3742
Batch 330, Loss: 0.4213
Batch 340, Loss: 0.3590
Batch 350, Loss: 0.3895
Batch 360, Loss: 0.3710
Batch 370, Loss: 0.3975
Batch 380, Loss: 0.3745
Batch 390, Loss: 0.3800
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.191559553146362 seconds
Epoch 169 accuracy: 77.74%
Batch 10, Loss: 0.3631
Batch 20, Loss: 0.3873
Batch 30, Loss: 0.3701
Batch 40, Loss: 0.3993
Batch 50, Loss: 0.3667
Batch 60, Loss: 0.3662
Batch 70, Loss: 0.3724
Batch 80, Loss: 0.3546
Batch 90, Loss: 0.3534
Batch 100, Loss: 0.3353
Batch 110, Loss: 0.3470
Batch 120, Loss: 0.3959
Batch 130, Loss: 0.3566
Batch 140, Loss: 0.3602
Batch 150, Loss: 0.3758
Batch 160, Loss: 0.3824
Batch 170, Loss: 0.3840
Batch 180, Loss: 0.3827
Batch 190, Loss: 0.3733
Batch 200, Loss: 0.3974
Batch 210, Loss: 0.3460
Batch 220, Loss: 0.3661
Batch 230, Loss: 0.3972
Batch 240, Loss: 0.3797
Batch 250, Loss: 0.3378
Batch 260, Loss: 0.3675
Batch 270, Loss: 0.3906
Batch 280, Loss: 0.3479
Batch 290, Loss: 0.3829
Batch 300, Loss: 0.3459
Batch 310, Loss: 0.3700
Batch 320, Loss: 0.3502
Batch 330, Loss: 0.3862
Batch 340, Loss: 0.3438
Batch 350, Loss: 0.3666
Batch 360, Loss: 0.3255
Batch 370, Loss: 0.3989
Batch 380, Loss: 0.3462
Batch 390, Loss: 0.3357
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.053815603256226 seconds
Epoch 170 accuracy: 77.64%
Batch 10, Loss: 0.3646
Batch 20, Loss: 0.3399
Batch 30, Loss: 0.3449
Batch 40, Loss: 0.3389
Batch 50, Loss: 0.3424
Batch 60, Loss: 0.3627
Batch 70, Loss: 0.3467
Batch 80, Loss: 0.3703
Batch 90, Loss: 0.3318
Batch 100, Loss: 0.3665
Batch 110, Loss: 0.3226
Batch 120, Loss: 0.3722
Batch 130, Loss: 0.3405
Batch 140, Loss: 0.3655
Batch 150, Loss: 0.3466
Batch 160, Loss: 0.3511
Batch 170, Loss: 0.3685
Batch 180, Loss: 0.3817
Batch 190, Loss: 0.3128
Batch 200, Loss: 0.3650
Batch 210, Loss: 0.3351
Batch 220, Loss: 0.3591
Batch 230, Loss: 0.3477
Batch 240, Loss: 0.3539
Batch 250, Loss: 0.3261
Batch 260, Loss: 0.3255
Batch 270, Loss: 0.3747
Batch 280, Loss: 0.3570
Batch 290, Loss: 0.3937
Batch 300, Loss: 0.3847
Batch 310, Loss: 0.3291
Batch 320, Loss: 0.3571
Batch 330, Loss: 0.3762
Batch 340, Loss: 0.3253
Batch 350, Loss: 0.3502
Batch 360, Loss: 0.3556
Batch 370, Loss: 0.3478
Batch 380, Loss: 0.3636
Batch 390, Loss: 0.3365
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.111088514328003 seconds
Epoch 171 accuracy: 78.01%
Batch 10, Loss: 0.3322
Batch 20, Loss: 0.3569
Batch 30, Loss: 0.3546
Batch 40, Loss: 0.3703
Batch 50, Loss: 0.3623
Batch 60, Loss: 0.3494
Batch 70, Loss: 0.3484
Batch 80, Loss: 0.3588
Batch 90, Loss: 0.3203
Batch 100, Loss: 0.3200
Batch 110, Loss: 0.3801
Batch 120, Loss: 0.3542
Batch 130, Loss: 0.3338
Batch 140, Loss: 0.3378
Batch 150, Loss: 0.3202
Batch 160, Loss: 0.3386
Batch 170, Loss: 0.3784
Batch 180, Loss: 0.3307
Batch 190, Loss: 0.3465
Batch 200, Loss: 0.3536
Batch 210, Loss: 0.3780
Batch 220, Loss: 0.3774
Batch 230, Loss: 0.3612
Batch 240, Loss: 0.3568
Batch 250, Loss: 0.3473
Batch 260, Loss: 0.3438
Batch 270, Loss: 0.3064
Batch 280, Loss: 0.3316
Batch 290, Loss: 0.3489
Batch 300, Loss: 0.3577
Batch 310, Loss: 0.3593
Batch 320, Loss: 0.3753
Batch 330, Loss: 0.3241
Batch 340, Loss: 0.3249
Batch 350, Loss: 0.3508
Batch 360, Loss: 0.3186
Batch 370, Loss: 0.3335
Batch 380, Loss: 0.3585
Batch 390, Loss: 0.3067
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.12958073616028 seconds
Epoch 172 accuracy: 78.02%
Batch 10, Loss: 0.3160
Batch 20, Loss: 0.3463
Batch 30, Loss: 0.3536
Batch 40, Loss: 0.3058
Batch 50, Loss: 0.2933
Batch 60, Loss: 0.3074
Batch 70, Loss: 0.3453
Batch 80, Loss: 0.3263
Batch 90, Loss: 0.3385
Batch 100, Loss: 0.3335
Batch 110, Loss: 0.3249
Batch 120, Loss: 0.3212
Batch 130, Loss: 0.3461
Batch 140, Loss: 0.3341
Batch 150, Loss: 0.3224
Batch 160, Loss: 0.3393
Batch 170, Loss: 0.3342
Batch 180, Loss: 0.3335
Batch 190, Loss: 0.3395
Batch 200, Loss: 0.3517
Batch 210, Loss: 0.3097
Batch 220, Loss: 0.3365
Batch 230, Loss: 0.3327
Batch 240, Loss: 0.3580
Batch 250, Loss: 0.3408
Batch 260, Loss: 0.3349
Batch 270, Loss: 0.3400
Batch 280, Loss: 0.3440
Batch 290, Loss: 0.3258
Batch 300, Loss: 0.3539
Batch 310, Loss: 0.3657
Batch 320, Loss: 0.3328
Batch 330, Loss: 0.3413
Batch 340, Loss: 0.3427
Batch 350, Loss: 0.3800
Batch 360, Loss: 0.3061
Batch 370, Loss: 0.3432
Batch 380, Loss: 0.3442
Batch 390, Loss: 0.3334
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.138104915618896 seconds
Epoch 173 accuracy: 78.2%
Batch 10, Loss: 0.3216
Batch 20, Loss: 0.3100
Batch 30, Loss: 0.3348
Batch 40, Loss: 0.3316
Batch 50, Loss: 0.3130
Batch 60, Loss: 0.2741
Batch 70, Loss: 0.3422
Batch 80, Loss: 0.3171
Batch 90, Loss: 0.3301
Batch 100, Loss: 0.3335
Batch 110, Loss: 0.3401
Batch 120, Loss: 0.3227
Batch 130, Loss: 0.3235
Batch 140, Loss: 0.3498
Batch 150, Loss: 0.3354
Batch 160, Loss: 0.3437
Batch 170, Loss: 0.2978
Batch 180, Loss: 0.3596
Batch 190, Loss: 0.3265
Batch 200, Loss: 0.3323
Batch 210, Loss: 0.3069
Batch 220, Loss: 0.3373
Batch 230, Loss: 0.3378
Batch 240, Loss: 0.3240
Batch 250, Loss: 0.3202
Batch 260, Loss: 0.3143
Batch 270, Loss: 0.3319
Batch 280, Loss: 0.3272
Batch 290, Loss: 0.3068
Batch 300, Loss: 0.3141
Batch 310, Loss: 0.3529
Batch 320, Loss: 0.3227
Batch 330, Loss: 0.3284
Batch 340, Loss: 0.3357
Batch 350, Loss: 0.3322
Batch 360, Loss: 0.3245
Batch 370, Loss: 0.3091
Batch 380, Loss: 0.3509
Batch 390, Loss: 0.3433
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.1329665184021 seconds
Epoch 174 accuracy: 78.55%
Batch 10, Loss: 0.3234
Batch 20, Loss: 0.3467
Batch 30, Loss: 0.3648
Batch 40, Loss: 0.3336
Batch 50, Loss: 0.3092
Batch 60, Loss: 0.3224
Batch 70, Loss: 0.3361
Batch 80, Loss: 0.3190
Batch 90, Loss: 0.2881
Batch 100, Loss: 0.2863
Batch 110, Loss: 0.2910
Batch 120, Loss: 0.3040
Batch 130, Loss: 0.3369
Batch 140, Loss: 0.2849
Batch 150, Loss: 0.3159
Batch 160, Loss: 0.3062
Batch 170, Loss: 0.3280
Batch 180, Loss: 0.3108
Batch 190, Loss: 0.2852
Batch 200, Loss: 0.3208
Batch 210, Loss: 0.3282
Batch 220, Loss: 0.3440
Batch 230, Loss: 0.3254
Batch 240, Loss: 0.2914
Batch 250, Loss: 0.3224
Batch 260, Loss: 0.3295
Batch 270, Loss: 0.3517
Batch 280, Loss: 0.3201
Batch 290, Loss: 0.3562
Batch 300, Loss: 0.3544
Batch 310, Loss: 0.3259
Batch 320, Loss: 0.3218
Batch 330, Loss: 0.3006
Batch 340, Loss: 0.2891
Batch 350, Loss: 0.3051
Batch 360, Loss: 0.3348
Batch 370, Loss: 0.3616
Batch 380, Loss: 0.3457
Batch 390, Loss: 0.3642
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.10985231399536 seconds
Epoch 175 accuracy: 78.91%
Batch 10, Loss: 0.2957
Batch 20, Loss: 0.3243
Batch 30, Loss: 0.3418
Batch 40, Loss: 0.3236
Batch 50, Loss: 0.3178
Batch 60, Loss: 0.2958
Batch 70, Loss: 0.3031
Batch 80, Loss: 0.3250
Batch 90, Loss: 0.3397
Batch 100, Loss: 0.3063
Batch 110, Loss: 0.3127
Batch 120, Loss: 0.3002
Batch 130, Loss: 0.2817
Batch 140, Loss: 0.3118
Batch 150, Loss: 0.3350
Batch 160, Loss: 0.3108
Batch 170, Loss: 0.2672
Batch 180, Loss: 0.3181
Batch 190, Loss: 0.3247
Batch 200, Loss: 0.3189
Batch 210, Loss: 0.3124
Batch 220, Loss: 0.3171
Batch 230, Loss: 0.3648
Batch 240, Loss: 0.3259
Batch 250, Loss: 0.3067
Batch 260, Loss: 0.3155
Batch 270, Loss: 0.2937
Batch 280, Loss: 0.3185
Batch 290, Loss: 0.3094
Batch 300, Loss: 0.2968
Batch 310, Loss: 0.3304
Batch 320, Loss: 0.3086
Batch 330, Loss: 0.3424
Batch 340, Loss: 0.3302
Batch 350, Loss: 0.3294
Batch 360, Loss: 0.3117
Batch 370, Loss: 0.3204
Batch 380, Loss: 0.3083
Batch 390, Loss: 0.3459
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.081005811691284 seconds
Epoch 176 accuracy: 78.91%
Batch 10, Loss: 0.3002
Batch 20, Loss: 0.3000
Batch 30, Loss: 0.3200
Batch 40, Loss: 0.3056
Batch 50, Loss: 0.2831
Batch 60, Loss: 0.3096
Batch 70, Loss: 0.3217
Batch 80, Loss: 0.3065
Batch 90, Loss: 0.3082
Batch 100, Loss: 0.3077
Batch 110, Loss: 0.2920
Batch 120, Loss: 0.3267
Batch 130, Loss: 0.3419
Batch 140, Loss: 0.2827
Batch 150, Loss: 0.2959
Batch 160, Loss: 0.3058
Batch 170, Loss: 0.3092
Batch 180, Loss: 0.2793
Batch 190, Loss: 0.2949
Batch 200, Loss: 0.3133
Batch 210, Loss: 0.3037
Batch 220, Loss: 0.3062
Batch 230, Loss: 0.2869
Batch 240, Loss: 0.3292
Batch 250, Loss: 0.3202
Batch 260, Loss: 0.3297
Batch 270, Loss: 0.2918
Batch 280, Loss: 0.3160
Batch 290, Loss: 0.3176
Batch 300, Loss: 0.3105
Batch 310, Loss: 0.3444
Batch 320, Loss: 0.3027
Batch 330, Loss: 0.3137
Batch 340, Loss: 0.3463
Batch 350, Loss: 0.2937
Batch 360, Loss: 0.3339
Batch 370, Loss: 0.3027
Batch 380, Loss: 0.3118
Batch 390, Loss: 0.3379
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.105812311172485 seconds
Epoch 177 accuracy: 78.47%
Batch 10, Loss: 0.3097
Batch 20, Loss: 0.2899
Batch 30, Loss: 0.2846
Batch 40, Loss: 0.2928
Batch 50, Loss: 0.2941
Batch 60, Loss: 0.3003
Batch 70, Loss: 0.3036
Batch 80, Loss: 0.3262
Batch 90, Loss: 0.3288
Batch 100, Loss: 0.2973
Batch 110, Loss: 0.2955
Batch 120, Loss: 0.2745
Batch 130, Loss: 0.3152
Batch 140, Loss: 0.3056
Batch 150, Loss: 0.2823
Batch 160, Loss: 0.2517
Batch 170, Loss: 0.2896
Batch 180, Loss: 0.2631
Batch 190, Loss: 0.3234
Batch 200, Loss: 0.3279
Batch 210, Loss: 0.3432
Batch 220, Loss: 0.2862
Batch 230, Loss: 0.2870
Batch 240, Loss: 0.2854
Batch 250, Loss: 0.2929
Batch 260, Loss: 0.2893
Batch 270, Loss: 0.3393
Batch 280, Loss: 0.2996
Batch 290, Loss: 0.2892
Batch 300, Loss: 0.3121
Batch 310, Loss: 0.2850
Batch 320, Loss: 0.3181
Batch 330, Loss: 0.3235
Batch 340, Loss: 0.3026
Batch 350, Loss: 0.3095
Batch 360, Loss: 0.2769
Batch 370, Loss: 0.2798
Batch 380, Loss: 0.3032
Batch 390, Loss: 0.2860
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.17168164253235 seconds
Epoch 178 accuracy: 78.93%
Batch 10, Loss: 0.3045
Batch 20, Loss: 0.2807
Batch 30, Loss: 0.3292
Batch 40, Loss: 0.2697
Batch 50, Loss: 0.2752
Batch 60, Loss: 0.2928
Batch 70, Loss: 0.3107
Batch 80, Loss: 0.2785
Batch 90, Loss: 0.3101
Batch 100, Loss: 0.2670
Batch 110, Loss: 0.2932
Batch 120, Loss: 0.2741
Batch 130, Loss: 0.2802
Batch 140, Loss: 0.3150
Batch 150, Loss: 0.2751
Batch 160, Loss: 0.3177
Batch 170, Loss: 0.3168
Batch 180, Loss: 0.3034
Batch 190, Loss: 0.3002
Batch 200, Loss: 0.2896
Batch 210, Loss: 0.3183
Batch 220, Loss: 0.3307
Batch 230, Loss: 0.2744
Batch 240, Loss: 0.2931
Batch 250, Loss: 0.3025
Batch 260, Loss: 0.3053
Batch 270, Loss: 0.3015
Batch 280, Loss: 0.2970
Batch 290, Loss: 0.3105
Batch 300, Loss: 0.2722
Batch 310, Loss: 0.3007
Batch 320, Loss: 0.3093
Batch 330, Loss: 0.2806
Batch 340, Loss: 0.2940
Batch 350, Loss: 0.3029
Batch 360, Loss: 0.2993
Batch 370, Loss: 0.3068
Batch 380, Loss: 0.2927
Batch 390, Loss: 0.3188
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.249552011489868 seconds
Epoch 179 accuracy: 78.97%
Batch 10, Loss: 0.2661
Batch 20, Loss: 0.2911
Batch 30, Loss: 0.2860
Batch 40, Loss: 0.2812
Batch 50, Loss: 0.2818
Batch 60, Loss: 0.2738
Batch 70, Loss: 0.2854
Batch 80, Loss: 0.3166
Batch 90, Loss: 0.3295
Batch 100, Loss: 0.2708
Batch 110, Loss: 0.2648
Batch 120, Loss: 0.2676
Batch 130, Loss: 0.2861
Batch 140, Loss: 0.3134
Batch 150, Loss: 0.2982
Batch 160, Loss: 0.2954
Batch 170, Loss: 0.2732
Batch 180, Loss: 0.2932
Batch 190, Loss: 0.2995
Batch 200, Loss: 0.2725
Batch 210, Loss: 0.2765
Batch 220, Loss: 0.2545
Batch 230, Loss: 0.2971
Batch 240, Loss: 0.2848
Batch 250, Loss: 0.3326
Batch 260, Loss: 0.3243
Batch 270, Loss: 0.2901
Batch 280, Loss: 0.2999
Batch 290, Loss: 0.3264
Batch 300, Loss: 0.3094
Batch 310, Loss: 0.2930
Batch 320, Loss: 0.2773
Batch 330, Loss: 0.3078
Batch 340, Loss: 0.2505
Batch 350, Loss: 0.2856
Batch 360, Loss: 0.3260
Batch 370, Loss: 0.2906
Batch 380, Loss: 0.2810
Batch 390, Loss: 0.2653
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.10553479194641 seconds
Epoch 180 accuracy: 79.33%
Batch 10, Loss: 0.2832
Batch 20, Loss: 0.2821
Batch 30, Loss: 0.2747
Batch 40, Loss: 0.3025
Batch 50, Loss: 0.2600
Batch 60, Loss: 0.2773
Batch 70, Loss: 0.2765
Batch 80, Loss: 0.2790
Batch 90, Loss: 0.2634
Batch 100, Loss: 0.2766
Batch 110, Loss: 0.2863
Batch 120, Loss: 0.3085
Batch 130, Loss: 0.3067
Batch 140, Loss: 0.2708
Batch 150, Loss: 0.2963
Batch 160, Loss: 0.2578
Batch 170, Loss: 0.2769
Batch 180, Loss: 0.2633
Batch 190, Loss: 0.2772
Batch 200, Loss: 0.3049
Batch 210, Loss: 0.2895
Batch 220, Loss: 0.2910
Batch 230, Loss: 0.2445
Batch 240, Loss: 0.2922
Batch 250, Loss: 0.2814
Batch 260, Loss: 0.3024
Batch 270, Loss: 0.3119
Batch 280, Loss: 0.2715
Batch 290, Loss: 0.2797
Batch 300, Loss: 0.3365
Batch 310, Loss: 0.2804
Batch 320, Loss: 0.2680
Batch 330, Loss: 0.3032
Batch 340, Loss: 0.2898
Batch 350, Loss: 0.2701
Batch 360, Loss: 0.2557
Batch 370, Loss: 0.3190
Batch 380, Loss: 0.2646
Batch 390, Loss: 0.3076
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.129077672958374 seconds
Epoch 181 accuracy: 79.38%
Batch 10, Loss: 0.3290
Batch 20, Loss: 0.2888
Batch 30, Loss: 0.2875
Batch 40, Loss: 0.2549
Batch 50, Loss: 0.2804
Batch 60, Loss: 0.2879
Batch 70, Loss: 0.2579
Batch 80, Loss: 0.2729
Batch 90, Loss: 0.2623
Batch 100, Loss: 0.2926
Batch 110, Loss: 0.3015
Batch 120, Loss: 0.2864
Batch 130, Loss: 0.2606
Batch 140, Loss: 0.2715
Batch 150, Loss: 0.2854
Batch 160, Loss: 0.2548
Batch 170, Loss: 0.2607
Batch 180, Loss: 0.2468
Batch 190, Loss: 0.2908
Batch 200, Loss: 0.2810
Batch 210, Loss: 0.2769
Batch 220, Loss: 0.2787
Batch 230, Loss: 0.2611
Batch 240, Loss: 0.2967
Batch 250, Loss: 0.2714
Batch 260, Loss: 0.2715
Batch 270, Loss: 0.2706
Batch 280, Loss: 0.2971
Batch 290, Loss: 0.2602
Batch 300, Loss: 0.2625
Batch 310, Loss: 0.2703
Batch 320, Loss: 0.2726
Batch 330, Loss: 0.2694
Batch 340, Loss: 0.3065
Batch 350, Loss: 0.2308
Batch 360, Loss: 0.2621
Batch 370, Loss: 0.2804
Batch 380, Loss: 0.2749
Batch 390, Loss: 0.2688
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.207306385040283 seconds
Epoch 182 accuracy: 79.6%
Batch 10, Loss: 0.2118
Batch 20, Loss: 0.2745
Batch 30, Loss: 0.2988
Batch 40, Loss: 0.2847
Batch 50, Loss: 0.2850
Batch 60, Loss: 0.2593
Batch 70, Loss: 0.2861
Batch 80, Loss: 0.2479
Batch 90, Loss: 0.2749
Batch 100, Loss: 0.2588
Batch 110, Loss: 0.2738
Batch 120, Loss: 0.2406
Batch 130, Loss: 0.2724
Batch 140, Loss: 0.2968
Batch 150, Loss: 0.2705
Batch 160, Loss: 0.2686
Batch 170, Loss: 0.2408
Batch 180, Loss: 0.2618
Batch 190, Loss: 0.2997
Batch 200, Loss: 0.3002
Batch 210, Loss: 0.2710
Batch 220, Loss: 0.2899
Batch 230, Loss: 0.2754
Batch 240, Loss: 0.2538
Batch 250, Loss: 0.2681
Batch 260, Loss: 0.2558
Batch 270, Loss: 0.2713
Batch 280, Loss: 0.2492
Batch 290, Loss: 0.2645
Batch 300, Loss: 0.2295
Batch 310, Loss: 0.2786
Batch 320, Loss: 0.3095
Batch 330, Loss: 0.2957
Batch 340, Loss: 0.2929
Batch 350, Loss: 0.2628
Batch 360, Loss: 0.2655
Batch 370, Loss: 0.2695
Batch 380, Loss: 0.2882
Batch 390, Loss: 0.2836
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.20422673225403 seconds
Epoch 183 accuracy: 79.75%
Batch 10, Loss: 0.2507
Batch 20, Loss: 0.2556
Batch 30, Loss: 0.2711
Batch 40, Loss: 0.2554
Batch 50, Loss: 0.2763
Batch 60, Loss: 0.2749
Batch 70, Loss: 0.2663
Batch 80, Loss: 0.2938
Batch 90, Loss: 0.2739
Batch 100, Loss: 0.2787
Batch 110, Loss: 0.2939
Batch 120, Loss: 0.2330
Batch 130, Loss: 0.2533
Batch 140, Loss: 0.2710
Batch 150, Loss: 0.2842
Batch 160, Loss: 0.2409
Batch 170, Loss: 0.2523
Batch 180, Loss: 0.2968
Batch 190, Loss: 0.2599
Batch 200, Loss: 0.2621
Batch 210, Loss: 0.2678
Batch 220, Loss: 0.2970
Batch 230, Loss: 0.2641
Batch 240, Loss: 0.2553
Batch 250, Loss: 0.2551
Batch 260, Loss: 0.2808
Batch 270, Loss: 0.2577
Batch 280, Loss: 0.2928
Batch 290, Loss: 0.2498
Batch 300, Loss: 0.2766
Batch 310, Loss: 0.2595
Batch 320, Loss: 0.2879
Batch 330, Loss: 0.2557
Batch 340, Loss: 0.2553
Batch 350, Loss: 0.2859
Batch 360, Loss: 0.2424
Batch 370, Loss: 0.2428
Batch 380, Loss: 0.2871
Batch 390, Loss: 0.2775
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.156738758087158 seconds
Epoch 184 accuracy: 79.69%
Batch 10, Loss: 0.2276
Batch 20, Loss: 0.2687
Batch 30, Loss: 0.2350
Batch 40, Loss: 0.2297
Batch 50, Loss: 0.2232
Batch 60, Loss: 0.2610
Batch 70, Loss: 0.2557
Batch 80, Loss: 0.2913
Batch 90, Loss: 0.2515
Batch 100, Loss: 0.2835
Batch 110, Loss: 0.2269
Batch 120, Loss: 0.2799
Batch 130, Loss: 0.2726
Batch 140, Loss: 0.2463
Batch 150, Loss: 0.2986
Batch 160, Loss: 0.2540
Batch 170, Loss: 0.2819
Batch 180, Loss: 0.2485
Batch 190, Loss: 0.2560
Batch 200, Loss: 0.2586
Batch 210, Loss: 0.2814
Batch 220, Loss: 0.2833
Batch 230, Loss: 0.2613
Batch 240, Loss: 0.2652
Batch 250, Loss: 0.2846
Batch 260, Loss: 0.2716
Batch 270, Loss: 0.2427
Batch 280, Loss: 0.2784
Batch 290, Loss: 0.2345
Batch 300, Loss: 0.2961
Batch 310, Loss: 0.2787
Batch 320, Loss: 0.2577
Batch 330, Loss: 0.2683
Batch 340, Loss: 0.2923
Batch 350, Loss: 0.2388
Batch 360, Loss: 0.2576
Batch 370, Loss: 0.2709
Batch 380, Loss: 0.2581
Batch 390, Loss: 0.2318
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.121272087097168 seconds
Epoch 185 accuracy: 79.51%
Batch 10, Loss: 0.2396
Batch 20, Loss: 0.2666
Batch 30, Loss: 0.2786
Batch 40, Loss: 0.2610
Batch 50, Loss: 0.2606
Batch 60, Loss: 0.2326
Batch 70, Loss: 0.2325
Batch 80, Loss: 0.2713
Batch 90, Loss: 0.2612
Batch 100, Loss: 0.2911
Batch 110, Loss: 0.2725
Batch 120, Loss: 0.2838
Batch 130, Loss: 0.2711
Batch 140, Loss: 0.2378
Batch 150, Loss: 0.2641
Batch 160, Loss: 0.2867
Batch 170, Loss: 0.2802
Batch 180, Loss: 0.2840
Batch 190, Loss: 0.2274
Batch 200, Loss: 0.2857
Batch 210, Loss: 0.3002
Batch 220, Loss: 0.2587
Batch 230, Loss: 0.2977
Batch 240, Loss: 0.2463
Batch 250, Loss: 0.2490
Batch 260, Loss: 0.2541
Batch 270, Loss: 0.2410
Batch 280, Loss: 0.2428
Batch 290, Loss: 0.2655
Batch 300, Loss: 0.2365
Batch 310, Loss: 0.3062
Batch 320, Loss: 0.2576
Batch 330, Loss: 0.2681
Batch 340, Loss: 0.2750
Batch 350, Loss: 0.2576
Batch 360, Loss: 0.2753
Batch 370, Loss: 0.2241
Batch 380, Loss: 0.2573
Batch 390, Loss: 0.2657
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.195366382598877 seconds
Epoch 186 accuracy: 79.93%
Batch 10, Loss: 0.2277
Batch 20, Loss: 0.2597
Batch 30, Loss: 0.2690
Batch 40, Loss: 0.2544
Batch 50, Loss: 0.2390
Batch 60, Loss: 0.2336
Batch 70, Loss: 0.2379
Batch 80, Loss: 0.2638
Batch 90, Loss: 0.2453
Batch 100, Loss: 0.2438
Batch 110, Loss: 0.2743
Batch 120, Loss: 0.2702
Batch 130, Loss: 0.2396
Batch 140, Loss: 0.2662
Batch 150, Loss: 0.2485
Batch 160, Loss: 0.2537
Batch 170, Loss: 0.2252
Batch 180, Loss: 0.2255
Batch 190, Loss: 0.2734
Batch 200, Loss: 0.2592
Batch 210, Loss: 0.2609
Batch 220, Loss: 0.2423
Batch 230, Loss: 0.2324
Batch 240, Loss: 0.2299
Batch 250, Loss: 0.2805
Batch 260, Loss: 0.2512
Batch 270, Loss: 0.2290
Batch 280, Loss: 0.2618
Batch 290, Loss: 0.2713
Batch 300, Loss: 0.2648
Batch 310, Loss: 0.2535
Batch 320, Loss: 0.2436
Batch 330, Loss: 0.2628
Batch 340, Loss: 0.2478
Batch 350, Loss: 0.2776
Batch 360, Loss: 0.2704
Batch 370, Loss: 0.2400
Batch 380, Loss: 0.2835
Batch 390, Loss: 0.2568
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.17723560333252 seconds
Epoch 187 accuracy: 79.63%
Batch 10, Loss: 0.2521
Batch 20, Loss: 0.2683
Batch 30, Loss: 0.2519
Batch 40, Loss: 0.2443
Batch 50, Loss: 0.2253
Batch 60, Loss: 0.2536
Batch 70, Loss: 0.2570
Batch 80, Loss: 0.2530
Batch 90, Loss: 0.2509
Batch 100, Loss: 0.2398
Batch 110, Loss: 0.2585
Batch 120, Loss: 0.2732
Batch 130, Loss: 0.2451
Batch 140, Loss: 0.2664
Batch 150, Loss: 0.2718
Batch 160, Loss: 0.2761
Batch 170, Loss: 0.2451
Batch 180, Loss: 0.2593
Batch 190, Loss: 0.2594
Batch 200, Loss: 0.2642
Batch 210, Loss: 0.2480
Batch 220, Loss: 0.2795
Batch 230, Loss: 0.2468
Batch 240, Loss: 0.2353
Batch 250, Loss: 0.2353
Batch 260, Loss: 0.2455
Batch 270, Loss: 0.2605
Batch 280, Loss: 0.2579
Batch 290, Loss: 0.2765
Batch 300, Loss: 0.2597
Batch 310, Loss: 0.2552
Batch 320, Loss: 0.2645
Batch 330, Loss: 0.2361
Batch 340, Loss: 0.3136
Batch 350, Loss: 0.2673
Batch 360, Loss: 0.2735
Batch 370, Loss: 0.2497
Batch 380, Loss: 0.2201
Batch 390, Loss: 0.2418
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.165949821472168 seconds
Epoch 188 accuracy: 79.91%
Batch 10, Loss: 0.2445
Batch 20, Loss: 0.2633
Batch 30, Loss: 0.2413
Batch 40, Loss: 0.2568
Batch 50, Loss: 0.2505
Batch 60, Loss: 0.2606
Batch 70, Loss: 0.2259
Batch 80, Loss: 0.2649
Batch 90, Loss: 0.2421
Batch 100, Loss: 0.2541
Batch 110, Loss: 0.2613
Batch 120, Loss: 0.2410
Batch 130, Loss: 0.2725
Batch 140, Loss: 0.2644
Batch 150, Loss: 0.2334
Batch 160, Loss: 0.2511
Batch 170, Loss: 0.2869
Batch 180, Loss: 0.2334
Batch 190, Loss: 0.2260
Batch 200, Loss: 0.2394
Batch 210, Loss: 0.2584
Batch 220, Loss: 0.2475
Batch 230, Loss: 0.2677
Batch 240, Loss: 0.2268
Batch 250, Loss: 0.2293
Batch 260, Loss: 0.2661
Batch 270, Loss: 0.2541
Batch 280, Loss: 0.2367
Batch 290, Loss: 0.2587
Batch 300, Loss: 0.2288
Batch 310, Loss: 0.2547
Batch 320, Loss: 0.2657
Batch 330, Loss: 0.2431
Batch 340, Loss: 0.2375
Batch 350, Loss: 0.2451
Batch 360, Loss: 0.2475
Batch 370, Loss: 0.2687
Batch 380, Loss: 0.2633
Batch 390, Loss: 0.2333
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.167633533477783 seconds
Epoch 189 accuracy: 79.8%
Batch 10, Loss: 0.2349
Batch 20, Loss: 0.2221
Batch 30, Loss: 0.2691
Batch 40, Loss: 0.2322
Batch 50, Loss: 0.2499
Batch 60, Loss: 0.2290
Batch 70, Loss: 0.2495
Batch 80, Loss: 0.2095
Batch 90, Loss: 0.2445
Batch 100, Loss: 0.2599
Batch 110, Loss: 0.2210
Batch 120, Loss: 0.2472
Batch 130, Loss: 0.2432
Batch 140, Loss: 0.2566
Batch 150, Loss: 0.2249
Batch 160, Loss: 0.2350
Batch 170, Loss: 0.2923
Batch 180, Loss: 0.2784
Batch 190, Loss: 0.2202
Batch 200, Loss: 0.2601
Batch 210, Loss: 0.2386
Batch 220, Loss: 0.2367
Batch 230, Loss: 0.2356
Batch 240, Loss: 0.2313
Batch 250, Loss: 0.2446
Batch 260, Loss: 0.2218
Batch 270, Loss: 0.2544
Batch 280, Loss: 0.2343
Batch 290, Loss: 0.2442
Batch 300, Loss: 0.2524
Batch 310, Loss: 0.2379
Batch 320, Loss: 0.2365
Batch 330, Loss: 0.2411
Batch 340, Loss: 0.2472
Batch 350, Loss: 0.2326
Batch 360, Loss: 0.2544
Batch 370, Loss: 0.2513
Batch 380, Loss: 0.2394
Batch 390, Loss: 0.2469
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.173478364944458 seconds
Epoch 190 accuracy: 79.92%
Batch 10, Loss: 0.2024
Batch 20, Loss: 0.2597
Batch 30, Loss: 0.2466
Batch 40, Loss: 0.2406
Batch 50, Loss: 0.2499
Batch 60, Loss: 0.2395
Batch 70, Loss: 0.2741
Batch 80, Loss: 0.2538
Batch 90, Loss: 0.2378
Batch 100, Loss: 0.2462
Batch 110, Loss: 0.2610
Batch 120, Loss: 0.2821
Batch 130, Loss: 0.2039
Batch 140, Loss: 0.2469
Batch 150, Loss: 0.2410
Batch 160, Loss: 0.2396
Batch 170, Loss: 0.2668
Batch 180, Loss: 0.2203
Batch 190, Loss: 0.2468
Batch 200, Loss: 0.2047
Batch 210, Loss: 0.2690
Batch 220, Loss: 0.2204
Batch 230, Loss: 0.2168
Batch 240, Loss: 0.2206
Batch 250, Loss: 0.2306
Batch 260, Loss: 0.2179
Batch 270, Loss: 0.2638
Batch 280, Loss: 0.2209
Batch 290, Loss: 0.2483
Batch 300, Loss: 0.2497
Batch 310, Loss: 0.2559
Batch 320, Loss: 0.2520
Batch 330, Loss: 0.2387
Batch 340, Loss: 0.2309
Batch 350, Loss: 0.2500
Batch 360, Loss: 0.2332
Batch 370, Loss: 0.2566
Batch 380, Loss: 0.2201
Batch 390, Loss: 0.2367
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.131284475326538 seconds
Epoch 191 accuracy: 79.99%
Batch 10, Loss: 0.2262
Batch 20, Loss: 0.2336
Batch 30, Loss: 0.2636
Batch 40, Loss: 0.2463
Batch 50, Loss: 0.2426
Batch 60, Loss: 0.2527
Batch 70, Loss: 0.2351
Batch 80, Loss: 0.2318
Batch 90, Loss: 0.2223
Batch 100, Loss: 0.2782
Batch 110, Loss: 0.2363
Batch 120, Loss: 0.2252
Batch 130, Loss: 0.2447
Batch 140, Loss: 0.2471
Batch 150, Loss: 0.2251
Batch 160, Loss: 0.2180
Batch 170, Loss: 0.2422
Batch 180, Loss: 0.2507
Batch 190, Loss: 0.2129
Batch 200, Loss: 0.2308
Batch 210, Loss: 0.2349
Batch 220, Loss: 0.2270
Batch 230, Loss: 0.2279
Batch 240, Loss: 0.2584
Batch 250, Loss: 0.2256
Batch 260, Loss: 0.2547
Batch 270, Loss: 0.2782
Batch 280, Loss: 0.2698
Batch 290, Loss: 0.2592
Batch 300, Loss: 0.2225
Batch 310, Loss: 0.2377
Batch 320, Loss: 0.2229
Batch 330, Loss: 0.2374
Batch 340, Loss: 0.2026
Batch 350, Loss: 0.2288
Batch 360, Loss: 0.2235
Batch 370, Loss: 0.1938
Batch 380, Loss: 0.2419
Batch 390, Loss: 0.2363
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.179940700531006 seconds
Epoch 192 accuracy: 79.99%
Batch 10, Loss: 0.2635
Batch 20, Loss: 0.2017
Batch 30, Loss: 0.2576
Batch 40, Loss: 0.2548
Batch 50, Loss: 0.2444
Batch 60, Loss: 0.2768
Batch 70, Loss: 0.2485
Batch 80, Loss: 0.2272
Batch 90, Loss: 0.2284
Batch 100, Loss: 0.2598
Batch 110, Loss: 0.2171
Batch 120, Loss: 0.2471
Batch 130, Loss: 0.2467
Batch 140, Loss: 0.2428
Batch 150, Loss: 0.2452
Batch 160, Loss: 0.2502
Batch 170, Loss: 0.2524
Batch 180, Loss: 0.2285
Batch 190, Loss: 0.2156
Batch 200, Loss: 0.2525
Batch 210, Loss: 0.2481
Batch 220, Loss: 0.2532
Batch 230, Loss: 0.2685
Batch 240, Loss: 0.2513
Batch 250, Loss: 0.2607
Batch 260, Loss: 0.2453
Batch 270, Loss: 0.2637
Batch 280, Loss: 0.2329
Batch 290, Loss: 0.2546
Batch 300, Loss: 0.2513
Batch 310, Loss: 0.2257
Batch 320, Loss: 0.2377
Batch 330, Loss: 0.2239
Batch 340, Loss: 0.2477
Batch 350, Loss: 0.2268
Batch 360, Loss: 0.2512
Batch 370, Loss: 0.2450
Batch 380, Loss: 0.2199
Batch 390, Loss: 0.2351
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.0975079536438 seconds
Epoch 193 accuracy: 79.98%
Batch 10, Loss: 0.2677
Batch 20, Loss: 0.2609
Batch 30, Loss: 0.2451
Batch 40, Loss: 0.2786
Batch 50, Loss: 0.2500
Batch 60, Loss: 0.2420
Batch 70, Loss: 0.2565
Batch 80, Loss: 0.2296
Batch 90, Loss: 0.2354
Batch 100, Loss: 0.2776
Batch 110, Loss: 0.2194
Batch 120, Loss: 0.2478
Batch 130, Loss: 0.2231
Batch 140, Loss: 0.2039
Batch 150, Loss: 0.2282
Batch 160, Loss: 0.2458
Batch 170, Loss: 0.2380
Batch 180, Loss: 0.2662
Batch 190, Loss: 0.2422
Batch 200, Loss: 0.2174
Batch 210, Loss: 0.2703
Batch 220, Loss: 0.2302
Batch 230, Loss: 0.2212
Batch 240, Loss: 0.2479
Batch 250, Loss: 0.2543
Batch 260, Loss: 0.2387
Batch 270, Loss: 0.2438
Batch 280, Loss: 0.2629
Batch 290, Loss: 0.2199
Batch 300, Loss: 0.2324
Batch 310, Loss: 0.2227
Batch 320, Loss: 0.2583
Batch 330, Loss: 0.2358
Batch 340, Loss: 0.2205
Batch 350, Loss: 0.2241
Batch 360, Loss: 0.2596
Batch 370, Loss: 0.2492
Batch 380, Loss: 0.2204
Batch 390, Loss: 0.2157
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.152089595794678 seconds
Epoch 194 accuracy: 80.1%
Batch 10, Loss: 0.2372
Batch 20, Loss: 0.2197
Batch 30, Loss: 0.2272
Batch 40, Loss: 0.2268
Batch 50, Loss: 0.2143
Batch 60, Loss: 0.2353
Batch 70, Loss: 0.2529
Batch 80, Loss: 0.2228
Batch 90, Loss: 0.1982
Batch 100, Loss: 0.2343
Batch 110, Loss: 0.2302
Batch 120, Loss: 0.2058
Batch 130, Loss: 0.2516
Batch 140, Loss: 0.2235
Batch 150, Loss: 0.2568
Batch 160, Loss: 0.2348
Batch 170, Loss: 0.2449
Batch 180, Loss: 0.2520
Batch 190, Loss: 0.2234
Batch 200, Loss: 0.2392
Batch 210, Loss: 0.2421
Batch 220, Loss: 0.2525
Batch 230, Loss: 0.2284
Batch 240, Loss: 0.2022
Batch 250, Loss: 0.2533
Batch 260, Loss: 0.2322
Batch 270, Loss: 0.2323
Batch 280, Loss: 0.2271
Batch 290, Loss: 0.2368
Batch 300, Loss: 0.2273
Batch 310, Loss: 0.2406
Batch 320, Loss: 0.2438
Batch 330, Loss: 0.2585
Batch 340, Loss: 0.2356
Batch 350, Loss: 0.2302
Batch 360, Loss: 0.2565
Batch 370, Loss: 0.2287
Batch 380, Loss: 0.2236
Batch 390, Loss: 0.2642
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.19107484817505 seconds
Epoch 195 accuracy: 79.9%
Batch 10, Loss: 0.2331
Batch 20, Loss: 0.2315
Batch 30, Loss: 0.2047
Batch 40, Loss: 0.2594
Batch 50, Loss: 0.2478
Batch 60, Loss: 0.2194
Batch 70, Loss: 0.2286
Batch 80, Loss: 0.2260
Batch 90, Loss: 0.2431
Batch 100, Loss: 0.2416
Batch 110, Loss: 0.2092
Batch 120, Loss: 0.2401
Batch 130, Loss: 0.2029
Batch 140, Loss: 0.2446
Batch 150, Loss: 0.2100
Batch 160, Loss: 0.2156
Batch 170, Loss: 0.2320
Batch 180, Loss: 0.2338
Batch 190, Loss: 0.2261
Batch 200, Loss: 0.2290
Batch 210, Loss: 0.2550
Batch 220, Loss: 0.2388
Batch 230, Loss: 0.2648
Batch 240, Loss: 0.2481
Batch 250, Loss: 0.2274
Batch 260, Loss: 0.2472
Batch 270, Loss: 0.2506
Batch 280, Loss: 0.2606
Batch 290, Loss: 0.2172
Batch 300, Loss: 0.2535
Batch 310, Loss: 0.2667
Batch 320, Loss: 0.2696
Batch 330, Loss: 0.2377
Batch 340, Loss: 0.2487
Batch 350, Loss: 0.2207
Batch 360, Loss: 0.2157
Batch 370, Loss: 0.2680
Batch 380, Loss: 0.2291
Batch 390, Loss: 0.2252
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.0684654712677 seconds
Epoch 196 accuracy: 80.01%
Batch 10, Loss: 0.2659
Batch 20, Loss: 0.2347
Batch 30, Loss: 0.2218
Batch 40, Loss: 0.2213
Batch 50, Loss: 0.2149
Batch 60, Loss: 0.2470
Batch 70, Loss: 0.2475
Batch 80, Loss: 0.2332
Batch 90, Loss: 0.2397
Batch 100, Loss: 0.2582
Batch 110, Loss: 0.2257
Batch 120, Loss: 0.2392
Batch 130, Loss: 0.2535
Batch 140, Loss: 0.2456
Batch 150, Loss: 0.2328
Batch 160, Loss: 0.2382
Batch 170, Loss: 0.2341
Batch 180, Loss: 0.2513
Batch 190, Loss: 0.2170
Batch 200, Loss: 0.2763
Batch 210, Loss: 0.2206
Batch 220, Loss: 0.2176
Batch 230, Loss: 0.2202
Batch 240, Loss: 0.1992
Batch 250, Loss: 0.2536
Batch 260, Loss: 0.2118
Batch 270, Loss: 0.2348
Batch 280, Loss: 0.2159
Batch 290, Loss: 0.2099
Batch 300, Loss: 0.2489
Batch 310, Loss: 0.2432
Batch 320, Loss: 0.2319
Batch 330, Loss: 0.1841
Batch 340, Loss: 0.2251
Batch 350, Loss: 0.2378
Batch 360, Loss: 0.2284
Batch 370, Loss: 0.2213
Batch 380, Loss: 0.2337
Batch 390, Loss: 0.2475
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.10367441177368 seconds
Epoch 197 accuracy: 80.11%
Batch 10, Loss: 0.2285
Batch 20, Loss: 0.2541
Batch 30, Loss: 0.2083
Batch 40, Loss: 0.2279
Batch 50, Loss: 0.2327
Batch 60, Loss: 0.2592
Batch 70, Loss: 0.2658
Batch 80, Loss: 0.2122
Batch 90, Loss: 0.2600
Batch 100, Loss: 0.2432
Batch 110, Loss: 0.2231
Batch 120, Loss: 0.2525
Batch 130, Loss: 0.2126
Batch 140, Loss: 0.2336
Batch 150, Loss: 0.2122
Batch 160, Loss: 0.2603
Batch 170, Loss: 0.2549
Batch 180, Loss: 0.2807
Batch 190, Loss: 0.2259
Batch 200, Loss: 0.2487
Batch 210, Loss: 0.2207
Batch 220, Loss: 0.2605
Batch 230, Loss: 0.2401
Batch 240, Loss: 0.2265
Batch 250, Loss: 0.2137
Batch 260, Loss: 0.2109
Batch 270, Loss: 0.2462
Batch 280, Loss: 0.2054
Batch 290, Loss: 0.2321
Batch 300, Loss: 0.2180
Batch 310, Loss: 0.2452
Batch 320, Loss: 0.2145
Batch 330, Loss: 0.2276
Batch 340, Loss: 0.2232
Batch 350, Loss: 0.2543
Batch 360, Loss: 0.2468
Batch 370, Loss: 0.2477
Batch 380, Loss: 0.2454
Batch 390, Loss: 0.2336
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.18561291694641 seconds
Epoch 198 accuracy: 80.0%
Batch 10, Loss: 0.2406
Batch 20, Loss: 0.2333
Batch 30, Loss: 0.2382
Batch 40, Loss: 0.2516
Batch 50, Loss: 0.2300
Batch 60, Loss: 0.2240
Batch 70, Loss: 0.2479
Batch 80, Loss: 0.2510
Batch 90, Loss: 0.2494
Batch 100, Loss: 0.2490
Batch 110, Loss: 0.2431
Batch 120, Loss: 0.2176
Batch 130, Loss: 0.2253
Batch 140, Loss: 0.2185
Batch 150, Loss: 0.2238
Batch 160, Loss: 0.2492
Batch 170, Loss: 0.2298
Batch 180, Loss: 0.2563
Batch 190, Loss: 0.2201
Batch 200, Loss: 0.2375
Batch 210, Loss: 0.2260
Batch 220, Loss: 0.2492
Batch 230, Loss: 0.2125
Batch 240, Loss: 0.2500
Batch 250, Loss: 0.2441
Batch 260, Loss: 0.2232
Batch 270, Loss: 0.2334
Batch 280, Loss: 0.1998
Batch 290, Loss: 0.2396
Batch 300, Loss: 0.2180
Batch 310, Loss: 0.1992
Batch 320, Loss: 0.2475
Batch 330, Loss: 0.2570
Batch 340, Loss: 0.2165
Batch 350, Loss: 0.2192
Batch 360, Loss: 0.2363
Batch 370, Loss: 0.2357
Batch 380, Loss: 0.2388
Batch 390, Loss: 0.2307
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.02203869819641 seconds
Epoch 199 accuracy: 80.03%
Batch 10, Loss: 0.2233
Batch 20, Loss: 0.2151
Batch 30, Loss: 0.2198
Batch 40, Loss: 0.2375
Batch 50, Loss: 0.2486
Batch 60, Loss: 0.2364
Batch 70, Loss: 0.2570
Batch 80, Loss: 0.2337
Batch 90, Loss: 0.2257
Batch 100, Loss: 0.2138
Batch 110, Loss: 0.2438
Batch 120, Loss: 0.2400
Batch 130, Loss: 0.2180
Batch 140, Loss: 0.2702
Batch 150, Loss: 0.2150
Batch 160, Loss: 0.2096
Batch 170, Loss: 0.2506
Batch 180, Loss: 0.2553
Batch 190, Loss: 0.2096
Batch 200, Loss: 0.2534
Batch 210, Loss: 0.2322
Batch 220, Loss: 0.2451
Batch 230, Loss: 0.2248
Batch 240, Loss: 0.2438
Batch 250, Loss: 0.2174
Batch 260, Loss: 0.2261
Batch 270, Loss: 0.2540
Batch 280, Loss: 0.2606
Batch 290, Loss: 0.2784
Batch 300, Loss: 0.2258
Batch 310, Loss: 0.2403
Batch 320, Loss: 0.2414
Batch 330, Loss: 0.2357
Batch 340, Loss: 0.2324
Batch 350, Loss: 0.2544
Batch 360, Loss: 0.2505
Batch 370, Loss: 0.2464
Batch 380, Loss: 0.2299
Batch 390, Loss: 0.2144
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.119445085525513 seconds
Epoch 200 accuracy: 80.02%
Total training time: 5038.5090210437775 seconds
