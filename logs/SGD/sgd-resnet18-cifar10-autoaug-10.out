The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 4.0277
Batch 20, Loss: 3.1612
Batch 30, Loss: 1.9392
Batch 40, Loss: 1.8700
Batch 50, Loss: 1.7975
Batch 60, Loss: 1.7412
Batch 70, Loss: 1.7108
Batch 80, Loss: 1.7064
Batch 90, Loss: 1.7012
Batch 100, Loss: 1.6889
Batch 110, Loss: 1.6692
Batch 120, Loss: 1.6520
Batch 130, Loss: 1.6656
Batch 140, Loss: 1.6737
Batch 150, Loss: 1.6477
Batch 160, Loss: 1.6380
Batch 170, Loss: 1.6554
Batch 180, Loss: 1.6564
Batch 190, Loss: 1.6240
Batch 200, Loss: 1.6046
Batch 210, Loss: 1.5964
Batch 220, Loss: 1.5940
Batch 230, Loss: 1.6295
Batch 240, Loss: 1.5897
Batch 250, Loss: 1.6296
Batch 260, Loss: 1.5693
Batch 270, Loss: 1.6027
Batch 280, Loss: 1.5825
Batch 290, Loss: 1.5722
Batch 300, Loss: 1.5641
Batch 310, Loss: 1.5430
Batch 320, Loss: 1.5785
Batch 330, Loss: 1.5670
Batch 340, Loss: 1.5350
Batch 350, Loss: 1.5684
Batch 360, Loss: 1.5473
Batch 370, Loss: 1.5214
Batch 380, Loss: 1.5199
Batch 390, Loss: 1.5020
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.915217638015747 seconds
Epoch 1 accuracy: 31.36%
Batch 10, Loss: 1.4948
Batch 20, Loss: 1.5114
Batch 30, Loss: 1.5382
Batch 40, Loss: 1.5141
Batch 50, Loss: 1.5254
Batch 60, Loss: 1.4976
Batch 70, Loss: 1.5002
Batch 80, Loss: 1.5133
Batch 90, Loss: 1.5093
Batch 100, Loss: 1.4916
Batch 110, Loss: 1.4855
Batch 120, Loss: 1.5030
Batch 130, Loss: 1.5332
Batch 140, Loss: 1.5080
Batch 150, Loss: 1.4641
Batch 160, Loss: 1.4621
Batch 170, Loss: 1.4643
Batch 180, Loss: 1.4464
Batch 190, Loss: 1.4757
Batch 200, Loss: 1.4767
Batch 210, Loss: 1.4592
Batch 220, Loss: 1.4374
Batch 230, Loss: 1.4567
Batch 240, Loss: 1.4347
Batch 250, Loss: 1.4811
Batch 260, Loss: 1.4276
Batch 270, Loss: 1.4529
Batch 280, Loss: 1.4674
Batch 290, Loss: 1.4286
Batch 300, Loss: 1.4277
Batch 310, Loss: 1.4409
Batch 320, Loss: 1.4635
Batch 330, Loss: 1.4191
Batch 340, Loss: 1.4301
Batch 350, Loss: 1.4336
Batch 360, Loss: 1.4252
Batch 370, Loss: 1.4173
Batch 380, Loss: 1.3959
Batch 390, Loss: 1.3918
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.437788724899292 seconds
Epoch 2 accuracy: 40.22%
Batch 10, Loss: 1.4116
Batch 20, Loss: 1.3990
Batch 30, Loss: 1.3860
Batch 40, Loss: 1.4257
Batch 50, Loss: 1.4102
Batch 60, Loss: 1.3507
Batch 70, Loss: 1.4046
Batch 80, Loss: 1.3772
Batch 90, Loss: 1.3905
Batch 100, Loss: 1.3601
Batch 110, Loss: 1.3316
Batch 120, Loss: 1.3470
Batch 130, Loss: 1.3546
Batch 140, Loss: 1.3314
Batch 150, Loss: 1.3449
Batch 160, Loss: 1.3302
Batch 170, Loss: 1.3567
Batch 180, Loss: 1.3365
Batch 190, Loss: 1.3351
Batch 200, Loss: 1.3155
Batch 210, Loss: 1.3485
Batch 220, Loss: 1.3648
Batch 230, Loss: 1.3196
Batch 240, Loss: 1.3260
Batch 250, Loss: 1.3430
Batch 260, Loss: 1.2804
Batch 270, Loss: 1.3067
Batch 280, Loss: 1.2891
Batch 290, Loss: 1.2919
Batch 300, Loss: 1.3002
Batch 310, Loss: 1.2559
Batch 320, Loss: 1.2965
Batch 330, Loss: 1.2877
Batch 340, Loss: 1.2885
Batch 350, Loss: 1.3464
Batch 360, Loss: 1.3099
Batch 370, Loss: 1.2763
Batch 380, Loss: 1.2911
Batch 390, Loss: 1.2952
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.300760746002197 seconds
Epoch 3 accuracy: 48.46%
Batch 10, Loss: 1.2786
Batch 20, Loss: 1.2359
Batch 30, Loss: 1.2138
Batch 40, Loss: 1.2646
Batch 50, Loss: 1.3359
Batch 60, Loss: 1.3235
Batch 70, Loss: 1.2099
Batch 80, Loss: 1.2478
Batch 90, Loss: 1.2623
Batch 100, Loss: 1.2224
Batch 110, Loss: 1.2440
Batch 120, Loss: 1.2428
Batch 130, Loss: 1.2388
Batch 140, Loss: 1.2466
Batch 150, Loss: 1.2015
Batch 160, Loss: 1.2214
Batch 170, Loss: 1.2219
Batch 180, Loss: 1.2072
Batch 190, Loss: 1.2221
Batch 200, Loss: 1.1874
Batch 210, Loss: 1.1978
Batch 220, Loss: 1.1503
Batch 230, Loss: 1.1946
Batch 240, Loss: 1.1847
Batch 250, Loss: 1.1660
Batch 260, Loss: 1.1175
Batch 270, Loss: 1.1759
Batch 280, Loss: 1.1481
Batch 290, Loss: 1.1842
Batch 300, Loss: 1.2186
Batch 310, Loss: 1.1580
Batch 320, Loss: 1.1328
Batch 330, Loss: 1.1505
Batch 340, Loss: 1.1387
Batch 350, Loss: 1.1363
Batch 360, Loss: 1.1766
Batch 370, Loss: 1.1077
Batch 380, Loss: 1.1730
Batch 390, Loss: 1.1708
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.224936485290527 seconds
Epoch 4 accuracy: 50.41%
Batch 10, Loss: 1.1542
Batch 20, Loss: 1.0804
Batch 30, Loss: 1.1478
Batch 40, Loss: 1.1185
Batch 50, Loss: 1.0902
Batch 60, Loss: 1.1142
Batch 70, Loss: 1.1001
Batch 80, Loss: 1.1292
Batch 90, Loss: 1.0752
Batch 100, Loss: 1.1273
Batch 110, Loss: 1.1489
Batch 120, Loss: 1.1351
Batch 130, Loss: 1.1800
Batch 140, Loss: 1.0872
Batch 150, Loss: 1.1541
Batch 160, Loss: 1.0917
Batch 170, Loss: 1.0877
Batch 180, Loss: 1.1076
Batch 190, Loss: 1.0852
Batch 200, Loss: 1.0815
Batch 210, Loss: 1.0902
Batch 220, Loss: 1.0735
Batch 230, Loss: 1.0737
Batch 240, Loss: 1.1015
Batch 250, Loss: 1.0626
Batch 260, Loss: 1.1072
Batch 270, Loss: 1.0975
Batch 280, Loss: 1.0932
Batch 290, Loss: 1.1216
Batch 300, Loss: 1.0649
Batch 310, Loss: 1.1070
Batch 320, Loss: 1.0748
Batch 330, Loss: 1.0532
Batch 340, Loss: 1.0864
Batch 350, Loss: 1.1095
Batch 360, Loss: 1.1072
Batch 370, Loss: 1.0228
Batch 380, Loss: 1.0807
Batch 390, Loss: 1.0397
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.21609401702881 seconds
Epoch 5 accuracy: 57.7%
Batch 10, Loss: 1.0397
Batch 20, Loss: 1.0626
Batch 30, Loss: 1.0231
Batch 40, Loss: 1.0440
Batch 50, Loss: 1.0682
Batch 60, Loss: 1.0486
Batch 70, Loss: 1.0134
Batch 80, Loss: 1.0023
Batch 90, Loss: 1.0493
Batch 100, Loss: 1.0371
Batch 110, Loss: 1.0184
Batch 120, Loss: 1.0350
Batch 130, Loss: 1.0568
Batch 140, Loss: 1.0188
Batch 150, Loss: 1.0705
Batch 160, Loss: 1.0300
Batch 170, Loss: 1.0143
Batch 180, Loss: 1.0063
Batch 190, Loss: 1.0079
Batch 200, Loss: 1.0067
Batch 210, Loss: 0.9844
Batch 220, Loss: 1.0477
Batch 230, Loss: 0.9781
Batch 240, Loss: 1.0062
Batch 250, Loss: 1.0003
Batch 260, Loss: 0.9940
Batch 270, Loss: 0.9697
Batch 280, Loss: 0.9967
Batch 290, Loss: 0.9860
Batch 300, Loss: 1.0055
Batch 310, Loss: 1.0356
Batch 320, Loss: 1.0146
Batch 330, Loss: 0.9848
Batch 340, Loss: 0.9940
Batch 350, Loss: 0.9552
Batch 360, Loss: 0.9491
Batch 370, Loss: 0.9643
Batch 380, Loss: 1.0361
Batch 390, Loss: 1.0141
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.110609769821167 seconds
Epoch 6 accuracy: 58.99%
Batch 10, Loss: 0.9862
Batch 20, Loss: 0.9838
Batch 30, Loss: 1.0006
Batch 40, Loss: 1.0099
Batch 50, Loss: 0.9803
Batch 60, Loss: 0.9090
Batch 70, Loss: 0.9449
Batch 80, Loss: 1.0028
Batch 90, Loss: 0.9928
Batch 100, Loss: 0.9347
Batch 110, Loss: 0.9850
Batch 120, Loss: 0.9655
Batch 130, Loss: 0.9373
Batch 140, Loss: 0.9476
Batch 150, Loss: 0.9616
Batch 160, Loss: 0.9960
Batch 170, Loss: 0.9644
Batch 180, Loss: 0.9296
Batch 190, Loss: 0.9569
Batch 200, Loss: 0.9633
Batch 210, Loss: 0.9573
Batch 220, Loss: 0.9683
Batch 230, Loss: 0.9503
Batch 240, Loss: 0.9506
Batch 250, Loss: 0.9781
Batch 260, Loss: 0.9492
Batch 270, Loss: 0.9434
Batch 280, Loss: 0.8960
Batch 290, Loss: 0.9220
Batch 300, Loss: 0.9430
Batch 310, Loss: 1.0011
Batch 320, Loss: 0.9866
Batch 330, Loss: 0.9188
Batch 340, Loss: 0.8762
Batch 350, Loss: 0.9568
Batch 360, Loss: 0.9296
Batch 370, Loss: 0.9242
Batch 380, Loss: 0.9310
Batch 390, Loss: 0.9344
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.230523347854614 seconds
Epoch 7 accuracy: 61.59%
Batch 10, Loss: 0.9361
Batch 20, Loss: 0.9395
Batch 30, Loss: 0.9631
Batch 40, Loss: 0.9346
Batch 50, Loss: 0.9175
Batch 60, Loss: 0.9019
Batch 70, Loss: 0.8929
Batch 80, Loss: 0.8886
Batch 90, Loss: 0.9154
Batch 100, Loss: 0.9235
Batch 110, Loss: 0.9224
Batch 120, Loss: 0.9004
Batch 130, Loss: 0.8621
Batch 140, Loss: 0.9069
Batch 150, Loss: 0.9283
Batch 160, Loss: 0.9572
Batch 170, Loss: 0.8615
Batch 180, Loss: 0.9054
Batch 190, Loss: 0.8618
Batch 200, Loss: 0.8827
Batch 210, Loss: 0.9612
Batch 220, Loss: 0.8895
Batch 230, Loss: 0.9283
Batch 240, Loss: 0.8364
Batch 250, Loss: 0.8850
Batch 260, Loss: 0.9004
Batch 270, Loss: 0.9339
Batch 280, Loss: 0.9059
Batch 290, Loss: 0.9002
Batch 300, Loss: 0.8234
Batch 310, Loss: 0.8963
Batch 320, Loss: 0.8404
Batch 330, Loss: 0.8955
Batch 340, Loss: 0.8674
Batch 350, Loss: 0.9071
Batch 360, Loss: 0.8195
Batch 370, Loss: 0.8611
Batch 380, Loss: 0.8598
Batch 390, Loss: 0.8325
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.127944469451904 seconds
Epoch 8 accuracy: 70.34%
Batch 10, Loss: 0.8438
Batch 20, Loss: 0.8833
Batch 30, Loss: 0.8840
Batch 40, Loss: 0.8682
Batch 50, Loss: 0.8461
Batch 60, Loss: 0.8948
Batch 70, Loss: 0.8655
Batch 80, Loss: 0.8508
Batch 90, Loss: 0.8580
Batch 100, Loss: 0.8746
Batch 110, Loss: 0.8562
Batch 120, Loss: 0.8481
Batch 130, Loss: 0.8721
Batch 140, Loss: 0.8479
Batch 150, Loss: 0.8470
Batch 160, Loss: 0.8280
Batch 170, Loss: 0.8343
Batch 180, Loss: 0.8090
Batch 190, Loss: 0.8261
Batch 200, Loss: 0.8413
Batch 210, Loss: 0.8296
Batch 220, Loss: 0.8363
Batch 230, Loss: 0.7582
Batch 240, Loss: 0.8518
Batch 250, Loss: 0.8030
Batch 260, Loss: 0.8744
Batch 270, Loss: 0.8333
Batch 280, Loss: 0.8439
Batch 290, Loss: 0.8449
Batch 300, Loss: 0.8098
Batch 310, Loss: 0.8096
Batch 320, Loss: 0.8048
Batch 330, Loss: 0.8434
Batch 340, Loss: 0.8194
Batch 350, Loss: 0.8211
Batch 360, Loss: 0.7999
Batch 370, Loss: 0.8461
Batch 380, Loss: 0.8125
Batch 390, Loss: 0.8159
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.297934532165527 seconds
Epoch 9 accuracy: 70.91%
Batch 10, Loss: 0.8051
Batch 20, Loss: 0.8072
Batch 30, Loss: 0.7800
Batch 40, Loss: 0.7985
Batch 50, Loss: 0.8027
Batch 60, Loss: 0.8105
Batch 70, Loss: 0.8274
Batch 80, Loss: 0.7841
Batch 90, Loss: 0.8275
Batch 100, Loss: 0.7741
Batch 110, Loss: 0.7900
Batch 120, Loss: 0.7922
Batch 130, Loss: 0.7842
Batch 140, Loss: 0.7824
Batch 150, Loss: 0.8439
Batch 160, Loss: 0.8609
Batch 170, Loss: 0.8116
Batch 180, Loss: 0.8069
Batch 190, Loss: 0.7931
Batch 200, Loss: 0.7907
Batch 210, Loss: 0.7777
Batch 220, Loss: 0.8021
Batch 230, Loss: 0.7924
Batch 240, Loss: 0.7808
Batch 250, Loss: 0.8238
Batch 260, Loss: 0.8075
Batch 270, Loss: 0.7781
Batch 280, Loss: 0.7961
Batch 290, Loss: 0.7898
Batch 300, Loss: 0.7769
Batch 310, Loss: 0.7832
Batch 320, Loss: 0.8110
Batch 330, Loss: 0.7754
Batch 340, Loss: 0.7895
Batch 350, Loss: 0.8039
Batch 360, Loss: 0.7875
Batch 370, Loss: 0.7836
Batch 380, Loss: 0.8196
Batch 390, Loss: 0.7427
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.15956211090088 seconds
Epoch 10 accuracy: 72.69%
Batch 10, Loss: 0.8094
Batch 20, Loss: 0.7712
Batch 30, Loss: 0.7907
Batch 40, Loss: 0.8149
Batch 50, Loss: 0.7544
Batch 60, Loss: 0.7812
Batch 70, Loss: 0.7496
Batch 80, Loss: 0.8116
Batch 90, Loss: 0.7500
Batch 100, Loss: 0.7806
Batch 110, Loss: 0.7601
Batch 120, Loss: 0.7745
Batch 130, Loss: 0.7199
Batch 140, Loss: 0.7420
Batch 150, Loss: 0.8073
Batch 160, Loss: 0.7935
Batch 170, Loss: 0.7669
Batch 180, Loss: 0.7264
Batch 190, Loss: 0.7627
Batch 200, Loss: 0.7570
Batch 210, Loss: 0.7518
Batch 220, Loss: 0.7673
Batch 230, Loss: 0.7577
Batch 240, Loss: 0.7710
Batch 250, Loss: 0.7439
Batch 260, Loss: 0.7780
Batch 270, Loss: 0.7930
Batch 280, Loss: 0.7493
Batch 290, Loss: 0.7643
Batch 300, Loss: 0.7823
Batch 310, Loss: 0.7541
Batch 320, Loss: 0.7929
Batch 330, Loss: 0.7604
Batch 340, Loss: 0.7760
Batch 350, Loss: 0.8024
Batch 360, Loss: 0.7619
Batch 370, Loss: 0.7509
Batch 380, Loss: 0.7341
Batch 390, Loss: 0.7674
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.249857425689697 seconds
Epoch 11 accuracy: 71.3%
Batch 10, Loss: 0.7746
Batch 20, Loss: 0.7807
Batch 30, Loss: 0.7524
Batch 40, Loss: 0.7219
Batch 50, Loss: 0.7082
Batch 60, Loss: 0.7323
Batch 70, Loss: 0.7736
Batch 80, Loss: 0.7378
Batch 90, Loss: 0.7444
Batch 100, Loss: 0.7293
Batch 110, Loss: 0.7618
Batch 120, Loss: 0.7206
Batch 130, Loss: 0.8187
Batch 140, Loss: 0.7590
Batch 150, Loss: 0.7365
Batch 160, Loss: 0.7400
Batch 170, Loss: 0.7631
Batch 180, Loss: 0.7472
Batch 190, Loss: 0.7394
Batch 200, Loss: 0.7509
Batch 210, Loss: 0.7637
Batch 220, Loss: 0.7563
Batch 230, Loss: 0.7375
Batch 240, Loss: 0.7621
Batch 250, Loss: 0.7423
Batch 260, Loss: 0.7594
Batch 270, Loss: 0.7633
Batch 280, Loss: 0.7344
Batch 290, Loss: 0.7070
Batch 300, Loss: 0.7062
Batch 310, Loss: 0.7689
Batch 320, Loss: 0.7973
Batch 330, Loss: 0.7361
Batch 340, Loss: 0.7582
Batch 350, Loss: 0.7523
Batch 360, Loss: 0.7684
Batch 370, Loss: 0.7445
Batch 380, Loss: 0.7486
Batch 390, Loss: 0.7520
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.226884126663208 seconds
Epoch 12 accuracy: 74.75%
Batch 10, Loss: 0.7646
Batch 20, Loss: 0.7523
Batch 30, Loss: 0.7310
Batch 40, Loss: 0.7190
Batch 50, Loss: 0.6944
Batch 60, Loss: 0.7609
Batch 70, Loss: 0.7402
Batch 80, Loss: 0.7594
Batch 90, Loss: 0.6913
Batch 100, Loss: 0.7256
Batch 110, Loss: 0.6735
Batch 120, Loss: 0.7218
Batch 130, Loss: 0.7377
Batch 140, Loss: 0.7207
Batch 150, Loss: 0.7389
Batch 160, Loss: 0.7419
Batch 170, Loss: 0.7631
Batch 180, Loss: 0.7452
Batch 190, Loss: 0.7392
Batch 200, Loss: 0.7225
Batch 210, Loss: 0.7301
Batch 220, Loss: 0.7190
Batch 230, Loss: 0.7182
Batch 240, Loss: 0.7360
Batch 250, Loss: 0.7479
Batch 260, Loss: 0.7218
Batch 270, Loss: 0.7186
Batch 280, Loss: 0.7566
Batch 290, Loss: 0.7200
Batch 300, Loss: 0.7248
Batch 310, Loss: 0.7496
Batch 320, Loss: 0.7032
Batch 330, Loss: 0.6961
Batch 340, Loss: 0.7133
Batch 350, Loss: 0.6953
Batch 360, Loss: 0.7322
Batch 370, Loss: 0.7620
Batch 380, Loss: 0.7468
Batch 390, Loss: 0.7159
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.297309398651123 seconds
Epoch 13 accuracy: 75.39%
Batch 10, Loss: 0.7204
Batch 20, Loss: 0.6981
Batch 30, Loss: 0.7416
Batch 40, Loss: 0.7364
Batch 50, Loss: 0.6850
Batch 60, Loss: 0.7451
Batch 70, Loss: 0.6895
Batch 80, Loss: 0.6690
Batch 90, Loss: 0.6883
Batch 100, Loss: 0.7148
Batch 110, Loss: 0.7002
Batch 120, Loss: 0.6468
Batch 130, Loss: 0.7241
Batch 140, Loss: 0.7173
Batch 150, Loss: 0.7014
Batch 160, Loss: 0.7149
Batch 170, Loss: 0.6814
Batch 180, Loss: 0.7365
Batch 190, Loss: 0.6884
Batch 200, Loss: 0.6889
Batch 210, Loss: 0.7695
Batch 220, Loss: 0.7315
Batch 230, Loss: 0.6772
Batch 240, Loss: 0.7431
Batch 250, Loss: 0.6972
Batch 260, Loss: 0.6971
Batch 270, Loss: 0.7051
Batch 280, Loss: 0.7385
Batch 290, Loss: 0.7019
Batch 300, Loss: 0.7285
Batch 310, Loss: 0.7118
Batch 320, Loss: 0.7001
Batch 330, Loss: 0.7411
Batch 340, Loss: 0.7337
Batch 350, Loss: 0.6784
Batch 360, Loss: 0.7145
Batch 370, Loss: 0.7287
Batch 380, Loss: 0.6810
Batch 390, Loss: 0.6448
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.15088438987732 seconds
Epoch 14 accuracy: 75.91%
Batch 10, Loss: 0.6616
Batch 20, Loss: 0.7083
Batch 30, Loss: 0.7315
Batch 40, Loss: 0.7029
Batch 50, Loss: 0.7084
Batch 60, Loss: 0.6935
Batch 70, Loss: 0.6838
Batch 80, Loss: 0.6571
Batch 90, Loss: 0.6670
Batch 100, Loss: 0.6905
Batch 110, Loss: 0.7442
Batch 120, Loss: 0.6702
Batch 130, Loss: 0.7079
Batch 140, Loss: 0.7102
Batch 150, Loss: 0.7074
Batch 160, Loss: 0.7103
Batch 170, Loss: 0.6886
Batch 180, Loss: 0.6486
Batch 190, Loss: 0.6975
Batch 200, Loss: 0.6965
Batch 210, Loss: 0.6714
Batch 220, Loss: 0.7566
Batch 230, Loss: 0.7088
Batch 240, Loss: 0.6907
Batch 250, Loss: 0.7160
Batch 260, Loss: 0.6612
Batch 270, Loss: 0.6832
Batch 280, Loss: 0.6601
Batch 290, Loss: 0.6706
Batch 300, Loss: 0.7045
Batch 310, Loss: 0.7115
Batch 320, Loss: 0.6990
Batch 330, Loss: 0.6989
Batch 340, Loss: 0.6879
Batch 350, Loss: 0.7320
Batch 360, Loss: 0.7373
Batch 370, Loss: 0.6974
Batch 380, Loss: 0.6810
Batch 390, Loss: 0.7026
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.206234455108643 seconds
Epoch 15 accuracy: 77.06%
Batch 10, Loss: 0.6712
Batch 20, Loss: 0.6798
Batch 30, Loss: 0.6721
Batch 40, Loss: 0.6431
Batch 50, Loss: 0.6663
Batch 60, Loss: 0.6957
Batch 70, Loss: 0.6824
Batch 80, Loss: 0.6770
Batch 90, Loss: 0.6572
Batch 100, Loss: 0.6737
Batch 110, Loss: 0.7205
Batch 120, Loss: 0.6883
Batch 130, Loss: 0.6511
Batch 140, Loss: 0.6555
Batch 150, Loss: 0.6851
Batch 160, Loss: 0.7075
Batch 170, Loss: 0.6934
Batch 180, Loss: 0.7199
Batch 190, Loss: 0.6620
Batch 200, Loss: 0.6921
Batch 210, Loss: 0.6372
Batch 220, Loss: 0.6671
Batch 230, Loss: 0.6551
Batch 240, Loss: 0.6987
Batch 250, Loss: 0.6657
Batch 260, Loss: 0.6497
Batch 270, Loss: 0.6992
Batch 280, Loss: 0.7274
Batch 290, Loss: 0.6916
Batch 300, Loss: 0.6961
Batch 310, Loss: 0.6664
Batch 320, Loss: 0.6632
Batch 330, Loss: 0.6256
Batch 340, Loss: 0.6382
Batch 350, Loss: 0.6822
Batch 360, Loss: 0.6171
Batch 370, Loss: 0.6635
Batch 380, Loss: 0.6148
Batch 390, Loss: 0.6808
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.21312427520752 seconds
Epoch 16 accuracy: 80.02%
Batch 10, Loss: 0.6303
Batch 20, Loss: 0.6959
Batch 30, Loss: 0.6955
Batch 40, Loss: 0.6346
Batch 50, Loss: 0.6862
Batch 60, Loss: 0.6714
Batch 70, Loss: 0.6719
Batch 80, Loss: 0.6813
Batch 90, Loss: 0.6406
Batch 100, Loss: 0.6466
Batch 110, Loss: 0.6464
Batch 120, Loss: 0.6383
Batch 130, Loss: 0.6897
Batch 140, Loss: 0.7025
Batch 150, Loss: 0.7144
Batch 160, Loss: 0.6619
Batch 170, Loss: 0.6756
Batch 180, Loss: 0.6781
Batch 190, Loss: 0.6512
Batch 200, Loss: 0.6549
Batch 210, Loss: 0.6959
Batch 220, Loss: 0.7092
Batch 230, Loss: 0.6736
Batch 240, Loss: 0.6788
Batch 250, Loss: 0.6351
Batch 260, Loss: 0.6459
Batch 270, Loss: 0.6925
Batch 280, Loss: 0.6741
Batch 290, Loss: 0.6804
Batch 300, Loss: 0.6595
Batch 310, Loss: 0.6370
Batch 320, Loss: 0.6668
Batch 330, Loss: 0.6713
Batch 340, Loss: 0.6277
Batch 350, Loss: 0.6498
Batch 360, Loss: 0.6548
Batch 370, Loss: 0.6519
Batch 380, Loss: 0.6594
Batch 390, Loss: 0.6627
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.127531051635742 seconds
Epoch 17 accuracy: 80.33%
Batch 10, Loss: 0.6372
Batch 20, Loss: 0.6408
Batch 30, Loss: 0.6538
Batch 40, Loss: 0.6240
Batch 50, Loss: 0.6821
Batch 60, Loss: 0.6861
Batch 70, Loss: 0.6902
Batch 80, Loss: 0.6765
Batch 90, Loss: 0.6506
Batch 100, Loss: 0.6443
Batch 110, Loss: 0.6487
Batch 120, Loss: 0.6735
Batch 130, Loss: 0.6541
Batch 140, Loss: 0.6690
Batch 150, Loss: 0.6552
Batch 160, Loss: 0.6894
Batch 170, Loss: 0.6570
Batch 180, Loss: 0.5957
Batch 190, Loss: 0.6223
Batch 200, Loss: 0.6598
Batch 210, Loss: 0.6726
Batch 220, Loss: 0.6781
Batch 230, Loss: 0.6915
Batch 240, Loss: 0.6896
Batch 250, Loss: 0.6655
Batch 260, Loss: 0.6410
Batch 270, Loss: 0.6544
Batch 280, Loss: 0.6435
Batch 290, Loss: 0.6340
Batch 300, Loss: 0.6550
Batch 310, Loss: 0.6440
Batch 320, Loss: 0.6682
Batch 330, Loss: 0.6623
Batch 340, Loss: 0.6972
Batch 350, Loss: 0.6727
Batch 360, Loss: 0.6689
Batch 370, Loss: 0.6707
Batch 380, Loss: 0.6619
Batch 390, Loss: 0.6459
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.211280345916748 seconds
Epoch 18 accuracy: 79.91%
Batch 10, Loss: 0.6410
Batch 20, Loss: 0.5921
Batch 30, Loss: 0.6108
Batch 40, Loss: 0.6425
Batch 50, Loss: 0.6594
Batch 60, Loss: 0.6662
Batch 70, Loss: 0.6863
Batch 80, Loss: 0.6494
Batch 90, Loss: 0.6829
Batch 100, Loss: 0.6719
Batch 110, Loss: 0.7037
Batch 120, Loss: 0.6447
Batch 130, Loss: 0.6215
Batch 140, Loss: 0.6271
Batch 150, Loss: 0.6010
Batch 160, Loss: 0.6646
Batch 170, Loss: 0.6766
Batch 180, Loss: 0.6668
Batch 190, Loss: 0.6252
Batch 200, Loss: 0.6379
Batch 210, Loss: 0.6214
Batch 220, Loss: 0.6279
Batch 230, Loss: 0.6440
Batch 240, Loss: 0.5825
Batch 250, Loss: 0.6268
Batch 260, Loss: 0.6661
Batch 270, Loss: 0.6446
Batch 280, Loss: 0.6564
Batch 290, Loss: 0.7014
Batch 300, Loss: 0.6703
Batch 310, Loss: 0.6402
Batch 320, Loss: 0.6353
Batch 330, Loss: 0.6569
Batch 340, Loss: 0.6118
Batch 350, Loss: 0.6419
Batch 360, Loss: 0.5949
Batch 370, Loss: 0.6477
Batch 380, Loss: 0.6730
Batch 390, Loss: 0.6809
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.13827633857727 seconds
Epoch 19 accuracy: 80.14%
Batch 10, Loss: 0.6163
Batch 20, Loss: 0.6686
Batch 30, Loss: 0.6518
Batch 40, Loss: 0.6375
Batch 50, Loss: 0.6565
Batch 60, Loss: 0.6423
Batch 70, Loss: 0.6519
Batch 80, Loss: 0.6554
Batch 90, Loss: 0.6228
Batch 100, Loss: 0.6418
Batch 110, Loss: 0.6267
Batch 120, Loss: 0.6268
Batch 130, Loss: 0.6080
Batch 140, Loss: 0.6592
Batch 150, Loss: 0.6527
Batch 160, Loss: 0.6420
Batch 170, Loss: 0.6042
Batch 180, Loss: 0.6403
Batch 190, Loss: 0.6638
Batch 200, Loss: 0.6209
Batch 210, Loss: 0.6350
Batch 220, Loss: 0.6120
Batch 230, Loss: 0.6605
Batch 240, Loss: 0.6392
Batch 250, Loss: 0.6077
Batch 260, Loss: 0.6488
Batch 270, Loss: 0.6192
Batch 280, Loss: 0.6705
Batch 290, Loss: 0.6224
Batch 300, Loss: 0.6581
Batch 310, Loss: 0.6538
Batch 320, Loss: 0.6619
Batch 330, Loss: 0.6546
Batch 340, Loss: 0.6262
Batch 350, Loss: 0.6611
Batch 360, Loss: 0.6482
Batch 370, Loss: 0.6496
Batch 380, Loss: 0.6501
Batch 390, Loss: 0.6308
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.21613836288452 seconds
Epoch 20 accuracy: 81.13%
Batch 10, Loss: 0.6382
Batch 20, Loss: 0.6209
Batch 30, Loss: 0.6323
Batch 40, Loss: 0.6308
Batch 50, Loss: 0.6292
Batch 60, Loss: 0.6277
Batch 70, Loss: 0.6282
Batch 80, Loss: 0.6354
Batch 90, Loss: 0.6300
Batch 100, Loss: 0.6041
Batch 110, Loss: 0.6159
Batch 120, Loss: 0.6214
Batch 130, Loss: 0.6284
Batch 140, Loss: 0.6311
Batch 150, Loss: 0.6042
Batch 160, Loss: 0.6184
Batch 170, Loss: 0.6460
Batch 180, Loss: 0.6422
Batch 190, Loss: 0.6206
Batch 200, Loss: 0.6526
Batch 210, Loss: 0.6335
Batch 220, Loss: 0.6609
Batch 230, Loss: 0.6160
Batch 240, Loss: 0.6451
Batch 250, Loss: 0.6377
Batch 260, Loss: 0.6395
Batch 270, Loss: 0.6155
Batch 280, Loss: 0.6457
Batch 290, Loss: 0.6718
Batch 300, Loss: 0.6428
Batch 310, Loss: 0.6378
Batch 320, Loss: 0.6404
Batch 330, Loss: 0.6504
Batch 340, Loss: 0.6028
Batch 350, Loss: 0.6319
Batch 360, Loss: 0.6004
Batch 370, Loss: 0.6403
Batch 380, Loss: 0.6627
Batch 390, Loss: 0.6180
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.06627917289734 seconds
Epoch 21 accuracy: 73.02%
Batch 10, Loss: 0.6438
Batch 20, Loss: 0.6444
Batch 30, Loss: 0.6472
Batch 40, Loss: 0.6393
Batch 50, Loss: 0.6254
Batch 60, Loss: 0.6665
Batch 70, Loss: 0.5995
Batch 80, Loss: 0.6122
Batch 90, Loss: 0.6165
Batch 100, Loss: 0.6283
Batch 110, Loss: 0.6174
Batch 120, Loss: 0.5990
Batch 130, Loss: 0.6143
Batch 140, Loss: 0.6579
Batch 150, Loss: 0.6316
Batch 160, Loss: 0.6015
Batch 170, Loss: 0.6573
Batch 180, Loss: 0.6102
Batch 190, Loss: 0.5793
Batch 200, Loss: 0.6030
Batch 210, Loss: 0.6031
Batch 220, Loss: 0.6590
Batch 230, Loss: 0.6102
Batch 240, Loss: 0.6592
Batch 250, Loss: 0.6100
Batch 260, Loss: 0.6275
Batch 270, Loss: 0.6296
Batch 280, Loss: 0.5938
Batch 290, Loss: 0.6095
Batch 300, Loss: 0.6152
Batch 310, Loss: 0.6060
Batch 320, Loss: 0.6442
Batch 330, Loss: 0.6420
Batch 340, Loss: 0.6275
Batch 350, Loss: 0.6405
Batch 360, Loss: 0.6387
Batch 370, Loss: 0.6235
Batch 380, Loss: 0.6520
Batch 390, Loss: 0.6358
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.17264413833618 seconds
Epoch 22 accuracy: 80.03%
Batch 10, Loss: 0.6469
Batch 20, Loss: 0.6509
Batch 30, Loss: 0.6215
Batch 40, Loss: 0.6460
Batch 50, Loss: 0.6142
Batch 60, Loss: 0.6511
Batch 70, Loss: 0.6080
Batch 80, Loss: 0.6342
Batch 90, Loss: 0.6065
Batch 100, Loss: 0.6304
Batch 110, Loss: 0.5919
Batch 120, Loss: 0.6164
Batch 130, Loss: 0.6161
Batch 140, Loss: 0.5895
Batch 150, Loss: 0.6700
Batch 160, Loss: 0.5912
Batch 170, Loss: 0.6353
Batch 180, Loss: 0.6358
Batch 190, Loss: 0.5710
Batch 200, Loss: 0.6273
Batch 210, Loss: 0.6249
Batch 220, Loss: 0.6025
Batch 230, Loss: 0.6217
Batch 240, Loss: 0.6684
Batch 250, Loss: 0.6474
Batch 260, Loss: 0.6476
Batch 270, Loss: 0.5742
Batch 280, Loss: 0.6165
Batch 290, Loss: 0.6098
Batch 300, Loss: 0.6482
Batch 310, Loss: 0.5918
Batch 320, Loss: 0.6269
Batch 330, Loss: 0.6123
Batch 340, Loss: 0.6226
Batch 350, Loss: 0.6249
Batch 360, Loss: 0.6272
Batch 370, Loss: 0.6062
Batch 380, Loss: 0.5927
Batch 390, Loss: 0.6391
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.32033109664917 seconds
Epoch 23 accuracy: 78.9%
Batch 10, Loss: 0.5889
Batch 20, Loss: 0.6077
Batch 30, Loss: 0.6518
Batch 40, Loss: 0.6027
Batch 50, Loss: 0.6070
Batch 60, Loss: 0.6559
Batch 70, Loss: 0.6454
Batch 80, Loss: 0.6449
Batch 90, Loss: 0.5949
Batch 100, Loss: 0.5962
Batch 110, Loss: 0.6366
Batch 120, Loss: 0.6202
Batch 130, Loss: 0.6593
Batch 140, Loss: 0.6403
Batch 150, Loss: 0.6345
Batch 160, Loss: 0.6473
Batch 170, Loss: 0.6374
Batch 180, Loss: 0.6518
Batch 190, Loss: 0.5774
Batch 200, Loss: 0.5764
Batch 210, Loss: 0.5769
Batch 220, Loss: 0.5892
Batch 230, Loss: 0.6216
Batch 240, Loss: 0.5966
Batch 250, Loss: 0.5918
Batch 260, Loss: 0.5744
Batch 270, Loss: 0.5972
Batch 280, Loss: 0.5843
Batch 290, Loss: 0.6014
Batch 300, Loss: 0.6299
Batch 310, Loss: 0.6096
Batch 320, Loss: 0.6256
Batch 330, Loss: 0.6243
Batch 340, Loss: 0.6330
Batch 350, Loss: 0.5688
Batch 360, Loss: 0.5929
Batch 370, Loss: 0.6474
Batch 380, Loss: 0.6417
Batch 390, Loss: 0.6265
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.12373399734497 seconds
Epoch 24 accuracy: 82.08%
Batch 10, Loss: 0.5835
Batch 20, Loss: 0.6247
Batch 30, Loss: 0.6247
Batch 40, Loss: 0.5526
Batch 50, Loss: 0.5975
Batch 60, Loss: 0.6096
Batch 70, Loss: 0.5926
Batch 80, Loss: 0.6044
Batch 90, Loss: 0.5683
Batch 100, Loss: 0.5895
Batch 110, Loss: 0.6275
Batch 120, Loss: 0.6068
Batch 130, Loss: 0.6423
Batch 140, Loss: 0.6094
Batch 150, Loss: 0.5710
Batch 160, Loss: 0.5753
Batch 170, Loss: 0.5551
Batch 180, Loss: 0.5918
Batch 190, Loss: 0.6061
Batch 200, Loss: 0.6159
Batch 210, Loss: 0.6162
Batch 220, Loss: 0.6355
Batch 230, Loss: 0.6222
Batch 240, Loss: 0.6775
Batch 250, Loss: 0.6226
Batch 260, Loss: 0.6159
Batch 270, Loss: 0.6587
Batch 280, Loss: 0.5868
Batch 290, Loss: 0.6031
Batch 300, Loss: 0.6122
Batch 310, Loss: 0.6211
Batch 320, Loss: 0.6273
Batch 330, Loss: 0.5699
Batch 340, Loss: 0.6198
Batch 350, Loss: 0.6559
Batch 360, Loss: 0.6154
Batch 370, Loss: 0.6151
Batch 380, Loss: 0.6270
Batch 390, Loss: 0.5995
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.095773696899414 seconds
Epoch 25 accuracy: 81.16%
Batch 10, Loss: 0.5943
Batch 20, Loss: 0.5821
Batch 30, Loss: 0.5982
Batch 40, Loss: 0.6071
Batch 50, Loss: 0.6170
Batch 60, Loss: 0.5700
Batch 70, Loss: 0.6241
Batch 80, Loss: 0.6064
Batch 90, Loss: 0.5954
Batch 100, Loss: 0.5758
Batch 110, Loss: 0.6029
Batch 120, Loss: 0.5742
Batch 130, Loss: 0.5756
Batch 140, Loss: 0.6016
Batch 150, Loss: 0.6232
Batch 160, Loss: 0.6401
Batch 170, Loss: 0.6213
Batch 180, Loss: 0.6024
Batch 190, Loss: 0.6209
Batch 200, Loss: 0.6006
Batch 210, Loss: 0.6156
Batch 220, Loss: 0.5376
Batch 230, Loss: 0.6042
Batch 240, Loss: 0.5604
Batch 250, Loss: 0.5757
Batch 260, Loss: 0.6212
Batch 270, Loss: 0.5990
Batch 280, Loss: 0.6267
Batch 290, Loss: 0.5469
Batch 300, Loss: 0.6212
Batch 310, Loss: 0.6299
Batch 320, Loss: 0.6285
Batch 330, Loss: 0.6144
Batch 340, Loss: 0.5987
Batch 350, Loss: 0.6447
Batch 360, Loss: 0.6506
Batch 370, Loss: 0.5887
Batch 380, Loss: 0.6297
Batch 390, Loss: 0.6033
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.309160470962524 seconds
Epoch 26 accuracy: 81.93%
Batch 10, Loss: 0.6317
Batch 20, Loss: 0.6154
Batch 30, Loss: 0.5989
Batch 40, Loss: 0.5844
Batch 50, Loss: 0.6297
Batch 60, Loss: 0.6050
Batch 70, Loss: 0.6007
Batch 80, Loss: 0.5700
Batch 90, Loss: 0.5624
Batch 100, Loss: 0.5684
Batch 110, Loss: 0.5776
Batch 120, Loss: 0.6004
Batch 130, Loss: 0.5913
Batch 140, Loss: 0.6040
Batch 150, Loss: 0.6009
Batch 160, Loss: 0.5548
Batch 170, Loss: 0.6000
Batch 180, Loss: 0.6170
Batch 190, Loss: 0.5891
Batch 200, Loss: 0.6080
Batch 210, Loss: 0.6020
Batch 220, Loss: 0.6202
Batch 230, Loss: 0.5930
Batch 240, Loss: 0.6326
Batch 250, Loss: 0.6041
Batch 260, Loss: 0.5979
Batch 270, Loss: 0.6188
Batch 280, Loss: 0.6268
Batch 290, Loss: 0.6152
Batch 300, Loss: 0.6037
Batch 310, Loss: 0.5790
Batch 320, Loss: 0.5610
Batch 330, Loss: 0.5996
Batch 340, Loss: 0.5859
Batch 350, Loss: 0.5673
Batch 360, Loss: 0.6314
Batch 370, Loss: 0.5973
Batch 380, Loss: 0.5796
Batch 390, Loss: 0.5964
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.09468698501587 seconds
Epoch 27 accuracy: 83.31%
Batch 10, Loss: 0.6001
Batch 20, Loss: 0.6160
Batch 30, Loss: 0.5947
Batch 40, Loss: 0.6058
Batch 50, Loss: 0.5943
Batch 60, Loss: 0.5629
Batch 70, Loss: 0.6412
Batch 80, Loss: 0.6205
Batch 90, Loss: 0.5886
Batch 100, Loss: 0.6047
Batch 110, Loss: 0.6127
Batch 120, Loss: 0.5863
Batch 130, Loss: 0.5928
Batch 140, Loss: 0.6053
Batch 150, Loss: 0.6153
Batch 160, Loss: 0.6311
Batch 170, Loss: 0.6266
Batch 180, Loss: 0.5745
Batch 190, Loss: 0.6443
Batch 200, Loss: 0.6080
Batch 210, Loss: 0.5996
Batch 220, Loss: 0.5976
Batch 230, Loss: 0.5834
Batch 240, Loss: 0.6143
Batch 250, Loss: 0.6080
Batch 260, Loss: 0.6114
Batch 270, Loss: 0.6357
Batch 280, Loss: 0.5802
Batch 290, Loss: 0.5819
Batch 300, Loss: 0.5659
Batch 310, Loss: 0.6335
Batch 320, Loss: 0.5825
Batch 330, Loss: 0.5675
Batch 340, Loss: 0.5531
Batch 350, Loss: 0.5735
Batch 360, Loss: 0.5552
Batch 370, Loss: 0.5944
Batch 380, Loss: 0.6093
Batch 390, Loss: 0.6078
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.086764097213745 seconds
Epoch 28 accuracy: 82.52%
Batch 10, Loss: 0.5855
Batch 20, Loss: 0.6122
Batch 30, Loss: 0.5711
Batch 40, Loss: 0.6084
Batch 50, Loss: 0.5646
Batch 60, Loss: 0.5835
Batch 70, Loss: 0.5922
Batch 80, Loss: 0.6105
Batch 90, Loss: 0.6238
Batch 100, Loss: 0.5640
Batch 110, Loss: 0.5665
Batch 120, Loss: 0.5828
Batch 130, Loss: 0.6249
Batch 140, Loss: 0.5801
Batch 150, Loss: 0.6164
Batch 160, Loss: 0.6012
Batch 170, Loss: 0.6152
Batch 180, Loss: 0.5734
Batch 190, Loss: 0.5884
Batch 200, Loss: 0.6470
Batch 210, Loss: 0.5940
Batch 220, Loss: 0.5832
Batch 230, Loss: 0.5876
Batch 240, Loss: 0.5782
Batch 250, Loss: 0.6193
Batch 260, Loss: 0.5803
Batch 270, Loss: 0.6400
Batch 280, Loss: 0.5859
Batch 290, Loss: 0.5450
Batch 300, Loss: 0.6163
Batch 310, Loss: 0.6158
Batch 320, Loss: 0.5562
Batch 330, Loss: 0.6025
Batch 340, Loss: 0.5730
Batch 350, Loss: 0.5810
Batch 360, Loss: 0.5729
Batch 370, Loss: 0.6181
Batch 380, Loss: 0.6014
Batch 390, Loss: 0.5731
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.13899803161621 seconds
Epoch 29 accuracy: 82.22%
Batch 10, Loss: 0.5842
Batch 20, Loss: 0.6029
Batch 30, Loss: 0.5972
Batch 40, Loss: 0.6353
Batch 50, Loss: 0.6405
Batch 60, Loss: 0.6266
Batch 70, Loss: 0.5804
Batch 80, Loss: 0.5927
Batch 90, Loss: 0.6054
Batch 100, Loss: 0.6275
Batch 110, Loss: 0.6011
Batch 120, Loss: 0.5952
Batch 130, Loss: 0.5631
Batch 140, Loss: 0.5683
Batch 150, Loss: 0.5702
Batch 160, Loss: 0.5791
Batch 170, Loss: 0.6058
Batch 180, Loss: 0.6272
Batch 190, Loss: 0.5845
Batch 200, Loss: 0.5695
Batch 210, Loss: 0.5818
Batch 220, Loss: 0.5592
Batch 230, Loss: 0.5293
Batch 240, Loss: 0.5834
Batch 250, Loss: 0.6187
Batch 260, Loss: 0.5956
Batch 270, Loss: 0.6004
Batch 280, Loss: 0.5856
Batch 290, Loss: 0.6133
Batch 300, Loss: 0.5910
Batch 310, Loss: 0.6202
Batch 320, Loss: 0.5719
Batch 330, Loss: 0.5650
Batch 340, Loss: 0.5499
Batch 350, Loss: 0.5565
Batch 360, Loss: 0.6265
Batch 370, Loss: 0.5995
Batch 380, Loss: 0.5860
Batch 390, Loss: 0.5726
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.250195264816284 seconds
Epoch 30 accuracy: 85.5%
Batch 10, Loss: 0.5692
Batch 20, Loss: 0.5939
Batch 30, Loss: 0.5959
Batch 40, Loss: 0.5592
Batch 50, Loss: 0.5916
Batch 60, Loss: 0.5433
Batch 70, Loss: 0.5947
Batch 80, Loss: 0.5758
Batch 90, Loss: 0.5521
Batch 100, Loss: 0.5912
Batch 110, Loss: 0.5928
Batch 120, Loss: 0.5804
Batch 130, Loss: 0.5927
Batch 140, Loss: 0.5501
Batch 150, Loss: 0.5401
Batch 160, Loss: 0.5871
Batch 170, Loss: 0.6075
Batch 180, Loss: 0.5899
Batch 190, Loss: 0.6417
Batch 200, Loss: 0.6029
Batch 210, Loss: 0.5916
Batch 220, Loss: 0.6043
Batch 230, Loss: 0.6130
Batch 240, Loss: 0.5759
Batch 250, Loss: 0.5386
Batch 260, Loss: 0.6005
Batch 270, Loss: 0.6186
Batch 280, Loss: 0.5838
Batch 290, Loss: 0.5604
Batch 300, Loss: 0.6022
Batch 310, Loss: 0.6095
Batch 320, Loss: 0.5555
Batch 330, Loss: 0.5755
Batch 340, Loss: 0.5720
Batch 350, Loss: 0.5765
Batch 360, Loss: 0.5702
Batch 370, Loss: 0.5876
Batch 380, Loss: 0.5959
Batch 390, Loss: 0.5784
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.100910902023315 seconds
Epoch 31 accuracy: 84.31%
Batch 10, Loss: 0.5737
Batch 20, Loss: 0.5978
Batch 30, Loss: 0.6018
Batch 40, Loss: 0.5626
Batch 50, Loss: 0.5525
Batch 60, Loss: 0.5763
Batch 70, Loss: 0.5908
Batch 80, Loss: 0.5902
Batch 90, Loss: 0.6011
Batch 100, Loss: 0.5528
Batch 110, Loss: 0.5425
Batch 120, Loss: 0.5920
Batch 130, Loss: 0.6064
Batch 140, Loss: 0.5732
Batch 150, Loss: 0.6192
Batch 160, Loss: 0.5827
Batch 170, Loss: 0.5609
Batch 180, Loss: 0.5486
Batch 190, Loss: 0.5709
Batch 200, Loss: 0.5648
Batch 210, Loss: 0.6319
Batch 220, Loss: 0.5933
Batch 230, Loss: 0.5991
Batch 240, Loss: 0.5988
Batch 250, Loss: 0.5847
Batch 260, Loss: 0.5480
Batch 270, Loss: 0.5626
Batch 280, Loss: 0.5479
Batch 290, Loss: 0.5875
Batch 300, Loss: 0.6187
Batch 310, Loss: 0.5637
Batch 320, Loss: 0.5836
Batch 330, Loss: 0.5898
Batch 340, Loss: 0.5784
Batch 350, Loss: 0.6260
Batch 360, Loss: 0.6032
Batch 370, Loss: 0.5984
Batch 380, Loss: 0.6021
Batch 390, Loss: 0.5608
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.091486930847168 seconds
Epoch 32 accuracy: 80.24%
Batch 10, Loss: 0.5913
Batch 20, Loss: 0.5908
Batch 30, Loss: 0.5725
Batch 40, Loss: 0.5582
Batch 50, Loss: 0.6031
Batch 60, Loss: 0.5743
Batch 70, Loss: 0.6221
Batch 80, Loss: 0.5934
Batch 90, Loss: 0.5693
Batch 100, Loss: 0.5700
Batch 110, Loss: 0.5878
Batch 120, Loss: 0.5634
Batch 130, Loss: 0.5257
Batch 140, Loss: 0.5127
Batch 150, Loss: 0.6376
Batch 160, Loss: 0.5558
Batch 170, Loss: 0.5672
Batch 180, Loss: 0.5713
Batch 190, Loss: 0.5820
Batch 200, Loss: 0.5864
Batch 210, Loss: 0.5788
Batch 220, Loss: 0.5485
Batch 230, Loss: 0.6071
Batch 240, Loss: 0.6004
Batch 250, Loss: 0.5832
Batch 260, Loss: 0.5720
Batch 270, Loss: 0.5650
Batch 280, Loss: 0.5529
Batch 290, Loss: 0.5424
Batch 300, Loss: 0.5890
Batch 310, Loss: 0.6146
Batch 320, Loss: 0.6087
Batch 330, Loss: 0.5938
Batch 340, Loss: 0.5589
Batch 350, Loss: 0.6169
Batch 360, Loss: 0.5682
Batch 370, Loss: 0.5680
Batch 380, Loss: 0.5476
Batch 390, Loss: 0.5494
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.11279320716858 seconds
Epoch 33 accuracy: 81.46%
Batch 10, Loss: 0.5463
Batch 20, Loss: 0.5968
Batch 30, Loss: 0.5774
Batch 40, Loss: 0.5507
Batch 50, Loss: 0.5554
Batch 60, Loss: 0.5539
Batch 70, Loss: 0.5655
Batch 80, Loss: 0.5529
Batch 90, Loss: 0.5282
Batch 100, Loss: 0.5709
Batch 110, Loss: 0.5618
Batch 120, Loss: 0.6014
Batch 130, Loss: 0.5713
Batch 140, Loss: 0.5597
Batch 150, Loss: 0.6090
Batch 160, Loss: 0.5836
Batch 170, Loss: 0.5625
Batch 180, Loss: 0.5933
Batch 190, Loss: 0.5734
Batch 200, Loss: 0.5567
Batch 210, Loss: 0.5815
Batch 220, Loss: 0.5873
Batch 230, Loss: 0.5661
Batch 240, Loss: 0.6157
Batch 250, Loss: 0.5776
Batch 260, Loss: 0.5924
Batch 270, Loss: 0.5548
Batch 280, Loss: 0.6006
Batch 290, Loss: 0.5176
Batch 300, Loss: 0.5964
Batch 310, Loss: 0.6057
Batch 320, Loss: 0.5869
Batch 330, Loss: 0.5771
Batch 340, Loss: 0.5668
Batch 350, Loss: 0.5778
Batch 360, Loss: 0.6008
Batch 370, Loss: 0.5593
Batch 380, Loss: 0.5674
Batch 390, Loss: 0.5862
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.10462498664856 seconds
Epoch 34 accuracy: 80.89%
Batch 10, Loss: 0.6072
Batch 20, Loss: 0.5668
Batch 30, Loss: 0.5937
Batch 40, Loss: 0.5551
Batch 50, Loss: 0.6098
Batch 60, Loss: 0.5967
Batch 70, Loss: 0.5797
Batch 80, Loss: 0.5740
Batch 90, Loss: 0.5590
Batch 100, Loss: 0.5458
Batch 110, Loss: 0.6087
Batch 120, Loss: 0.5816
Batch 130, Loss: 0.5800
Batch 140, Loss: 0.5686
Batch 150, Loss: 0.5847
Batch 160, Loss: 0.5724
Batch 170, Loss: 0.5693
Batch 180, Loss: 0.5470
Batch 190, Loss: 0.5636
Batch 200, Loss: 0.5419
Batch 210, Loss: 0.5604
Batch 220, Loss: 0.5540
Batch 230, Loss: 0.5366
Batch 240, Loss: 0.5254
Batch 250, Loss: 0.5867
Batch 260, Loss: 0.5900
Batch 270, Loss: 0.5833
Batch 280, Loss: 0.5606
Batch 290, Loss: 0.5586
Batch 300, Loss: 0.5700
Batch 310, Loss: 0.6135
Batch 320, Loss: 0.5800
Batch 330, Loss: 0.5773
Batch 340, Loss: 0.6297
Batch 350, Loss: 0.5925
Batch 360, Loss: 0.5263
Batch 370, Loss: 0.5429
Batch 380, Loss: 0.5990
Batch 390, Loss: 0.5789
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.32211470603943 seconds
Epoch 35 accuracy: 81.63%
Batch 10, Loss: 0.5401
Batch 20, Loss: 0.5417
Batch 30, Loss: 0.5346
Batch 40, Loss: 0.5537
Batch 50, Loss: 0.5816
Batch 60, Loss: 0.5777
Batch 70, Loss: 0.5957
Batch 80, Loss: 0.5723
Batch 90, Loss: 0.5683
Batch 100, Loss: 0.5830
Batch 110, Loss: 0.5545
Batch 120, Loss: 0.5608
Batch 130, Loss: 0.5510
Batch 140, Loss: 0.5626
Batch 150, Loss: 0.6260
Batch 160, Loss: 0.6314
Batch 170, Loss: 0.5770
Batch 180, Loss: 0.5683
Batch 190, Loss: 0.5773
Batch 200, Loss: 0.6319
Batch 210, Loss: 0.6012
Batch 220, Loss: 0.6045
Batch 230, Loss: 0.5497
Batch 240, Loss: 0.5395
Batch 250, Loss: 0.5870
Batch 260, Loss: 0.5741
Batch 270, Loss: 0.5420
Batch 280, Loss: 0.6093
Batch 290, Loss: 0.5974
Batch 300, Loss: 0.5815
Batch 310, Loss: 0.5821
Batch 320, Loss: 0.6021
Batch 330, Loss: 0.6140
Batch 340, Loss: 0.5744
Batch 350, Loss: 0.5429
Batch 360, Loss: 0.5652
Batch 370, Loss: 0.5312
Batch 380, Loss: 0.6036
Batch 390, Loss: 0.5754
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.154273986816406 seconds
Epoch 36 accuracy: 78.09%
Batch 10, Loss: 0.6107
Batch 20, Loss: 0.5837
Batch 30, Loss: 0.5539
Batch 40, Loss: 0.5730
Batch 50, Loss: 0.5320
Batch 60, Loss: 0.6051
Batch 70, Loss: 0.5488
Batch 80, Loss: 0.5682
Batch 90, Loss: 0.5771
Batch 100, Loss: 0.5612
Batch 110, Loss: 0.5353
Batch 120, Loss: 0.5696
Batch 130, Loss: 0.5744
Batch 140, Loss: 0.5375
Batch 150, Loss: 0.5940
Batch 160, Loss: 0.5671
Batch 170, Loss: 0.5286
Batch 180, Loss: 0.5502
Batch 190, Loss: 0.5188
Batch 200, Loss: 0.5951
Batch 210, Loss: 0.5691
Batch 220, Loss: 0.5720
Batch 230, Loss: 0.5795
Batch 240, Loss: 0.5501
Batch 250, Loss: 0.5437
Batch 260, Loss: 0.5456
Batch 270, Loss: 0.5673
Batch 280, Loss: 0.5829
Batch 290, Loss: 0.6204
Batch 300, Loss: 0.5921
Batch 310, Loss: 0.5635
Batch 320, Loss: 0.5600
Batch 330, Loss: 0.5379
Batch 340, Loss: 0.5274
Batch 350, Loss: 0.5374
Batch 360, Loss: 0.5303
Batch 370, Loss: 0.5680
Batch 380, Loss: 0.5616
Batch 390, Loss: 0.5591
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.07205104827881 seconds
Epoch 37 accuracy: 79.66%
Batch 10, Loss: 0.5303
Batch 20, Loss: 0.5619
Batch 30, Loss: 0.5693
Batch 40, Loss: 0.5543
Batch 50, Loss: 0.5901
Batch 60, Loss: 0.5718
Batch 70, Loss: 0.5775
Batch 80, Loss: 0.5868
Batch 90, Loss: 0.6057
Batch 100, Loss: 0.5607
Batch 110, Loss: 0.5549
Batch 120, Loss: 0.5319
Batch 130, Loss: 0.5534
Batch 140, Loss: 0.5473
Batch 150, Loss: 0.5785
Batch 160, Loss: 0.5863
Batch 170, Loss: 0.6302
Batch 180, Loss: 0.5476
Batch 190, Loss: 0.5699
Batch 200, Loss: 0.5758
Batch 210, Loss: 0.6170
Batch 220, Loss: 0.5656
Batch 230, Loss: 0.5593
Batch 240, Loss: 0.5697
Batch 250, Loss: 0.5715
Batch 260, Loss: 0.5647
Batch 270, Loss: 0.5705
Batch 280, Loss: 0.5780
Batch 290, Loss: 0.5322
Batch 300, Loss: 0.5597
Batch 310, Loss: 0.5756
Batch 320, Loss: 0.5969
Batch 330, Loss: 0.5399
Batch 340, Loss: 0.5767
Batch 350, Loss: 0.5702
Batch 360, Loss: 0.5793
Batch 370, Loss: 0.5502
Batch 380, Loss: 0.5782
Batch 390, Loss: 0.5971
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.034669399261475 seconds
Epoch 38 accuracy: 83.59%
Batch 10, Loss: 0.5179
Batch 20, Loss: 0.5081
Batch 30, Loss: 0.5277
Batch 40, Loss: 0.5644
Batch 50, Loss: 0.5373
Batch 60, Loss: 0.5695
Batch 70, Loss: 0.5555
Batch 80, Loss: 0.5572
Batch 90, Loss: 0.5782
Batch 100, Loss: 0.5848
Batch 110, Loss: 0.5951
Batch 120, Loss: 0.5977
Batch 130, Loss: 0.5794
Batch 140, Loss: 0.6012
Batch 150, Loss: 0.5602
Batch 160, Loss: 0.5541
Batch 170, Loss: 0.4867
Batch 180, Loss: 0.5397
Batch 190, Loss: 0.5767
Batch 200, Loss: 0.5833
Batch 210, Loss: 0.5642
Batch 220, Loss: 0.5903
Batch 230, Loss: 0.5604
Batch 240, Loss: 0.5355
Batch 250, Loss: 0.5595
Batch 260, Loss: 0.5587
Batch 270, Loss: 0.5568
Batch 280, Loss: 0.5300
Batch 290, Loss: 0.5837
Batch 300, Loss: 0.5808
Batch 310, Loss: 0.5373
Batch 320, Loss: 0.5457
Batch 330, Loss: 0.6022
Batch 340, Loss: 0.5304
Batch 350, Loss: 0.5724
Batch 360, Loss: 0.5483
Batch 370, Loss: 0.5665
Batch 380, Loss: 0.5311
Batch 390, Loss: 0.5372
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.045058965682983 seconds
Epoch 39 accuracy: 84.02%
Batch 10, Loss: 0.5506
Batch 20, Loss: 0.6021
Batch 30, Loss: 0.5776
Batch 40, Loss: 0.5999
Batch 50, Loss: 0.5726
Batch 60, Loss: 0.5544
Batch 70, Loss: 0.5756
Batch 80, Loss: 0.5550
Batch 90, Loss: 0.5813
Batch 100, Loss: 0.5791
Batch 110, Loss: 0.5734
Batch 120, Loss: 0.5207
Batch 130, Loss: 0.6127
Batch 140, Loss: 0.5306
Batch 150, Loss: 0.5549
Batch 160, Loss: 0.5752
Batch 170, Loss: 0.5154
Batch 180, Loss: 0.5814
Batch 190, Loss: 0.5611
Batch 200, Loss: 0.5372
Batch 210, Loss: 0.5630
Batch 220, Loss: 0.5376
Batch 230, Loss: 0.5335
Batch 240, Loss: 0.5151
Batch 250, Loss: 0.5864
Batch 260, Loss: 0.5912
Batch 270, Loss: 0.6058
Batch 280, Loss: 0.5568
Batch 290, Loss: 0.5566
Batch 300, Loss: 0.5402
Batch 310, Loss: 0.5432
Batch 320, Loss: 0.5630
Batch 330, Loss: 0.5676
Batch 340, Loss: 0.5384
Batch 350, Loss: 0.5646
Batch 360, Loss: 0.5802
Batch 370, Loss: 0.5420
Batch 380, Loss: 0.5473
Batch 390, Loss: 0.5505
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.039292573928833 seconds
Epoch 40 accuracy: 81.91%
Batch 10, Loss: 0.5885
Batch 20, Loss: 0.5553
Batch 30, Loss: 0.5920
Batch 40, Loss: 0.6344
Batch 50, Loss: 0.5375
Batch 60, Loss: 0.6033
Batch 70, Loss: 0.5972
Batch 80, Loss: 0.5779
Batch 90, Loss: 0.5205
Batch 100, Loss: 0.5229
Batch 110, Loss: 0.5567
Batch 120, Loss: 0.5476
Batch 130, Loss: 0.5522
Batch 140, Loss: 0.5580
Batch 150, Loss: 0.5495
Batch 160, Loss: 0.5920
Batch 170, Loss: 0.5810
Batch 180, Loss: 0.5341
Batch 190, Loss: 0.5410
Batch 200, Loss: 0.5620
Batch 210, Loss: 0.6037
Batch 220, Loss: 0.5587
Batch 230, Loss: 0.5609
Batch 240, Loss: 0.5750
Batch 250, Loss: 0.5121
Batch 260, Loss: 0.5555
Batch 270, Loss: 0.5446
Batch 280, Loss: 0.5406
Batch 290, Loss: 0.5554
Batch 300, Loss: 0.5634
Batch 310, Loss: 0.5324
Batch 320, Loss: 0.5639
Batch 330, Loss: 0.5499
Batch 340, Loss: 0.5916
Batch 350, Loss: 0.5526
Batch 360, Loss: 0.5535
Batch 370, Loss: 0.5795
Batch 380, Loss: 0.5722
Batch 390, Loss: 0.5965
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.153207540512085 seconds
Epoch 41 accuracy: 81.81%
Batch 10, Loss: 0.5401
Batch 20, Loss: 0.5460
Batch 30, Loss: 0.5526
Batch 40, Loss: 0.5626
Batch 50, Loss: 0.5507
Batch 60, Loss: 0.5787
Batch 70, Loss: 0.5859
Batch 80, Loss: 0.5564
Batch 90, Loss: 0.5655
Batch 100, Loss: 0.5994
Batch 110, Loss: 0.5677
Batch 120, Loss: 0.5582
Batch 130, Loss: 0.5855
Batch 140, Loss: 0.5532
Batch 150, Loss: 0.5807
Batch 160, Loss: 0.5948
Batch 170, Loss: 0.5776
Batch 180, Loss: 0.5254
Batch 190, Loss: 0.5262
Batch 200, Loss: 0.6015
Batch 210, Loss: 0.5569
Batch 220, Loss: 0.5161
Batch 230, Loss: 0.5498
Batch 240, Loss: 0.5486
Batch 250, Loss: 0.5168
Batch 260, Loss: 0.6017
Batch 270, Loss: 0.5587
Batch 280, Loss: 0.5833
Batch 290, Loss: 0.5748
Batch 300, Loss: 0.5694
Batch 310, Loss: 0.5409
Batch 320, Loss: 0.5392
Batch 330, Loss: 0.5370
Batch 340, Loss: 0.5547
Batch 350, Loss: 0.5640
Batch 360, Loss: 0.5225
Batch 370, Loss: 0.5987
Batch 380, Loss: 0.5733
Batch 390, Loss: 0.5637
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.192476749420166 seconds
Epoch 42 accuracy: 81.24%
Batch 10, Loss: 0.5551
Batch 20, Loss: 0.5760
Batch 30, Loss: 0.5480
Batch 40, Loss: 0.5044
Batch 50, Loss: 0.5573
Batch 60, Loss: 0.5783
Batch 70, Loss: 0.5850
Batch 80, Loss: 0.5476
Batch 90, Loss: 0.5375
Batch 100, Loss: 0.5259
Batch 110, Loss: 0.5261
Batch 120, Loss: 0.5430
Batch 130, Loss: 0.5224
Batch 140, Loss: 0.5550
Batch 150, Loss: 0.5780
Batch 160, Loss: 0.5665
Batch 170, Loss: 0.5206
Batch 180, Loss: 0.5524
Batch 190, Loss: 0.5579
Batch 200, Loss: 0.5514
Batch 210, Loss: 0.5803
Batch 220, Loss: 0.5583
Batch 230, Loss: 0.5820
Batch 240, Loss: 0.5360
Batch 250, Loss: 0.5125
Batch 260, Loss: 0.5829
Batch 270, Loss: 0.5370
Batch 280, Loss: 0.5420
Batch 290, Loss: 0.5430
Batch 300, Loss: 0.5568
Batch 310, Loss: 0.5641
Batch 320, Loss: 0.5539
Batch 330, Loss: 0.5636
Batch 340, Loss: 0.5714
Batch 350, Loss: 0.5422
Batch 360, Loss: 0.5388
Batch 370, Loss: 0.5695
Batch 380, Loss: 0.5368
Batch 390, Loss: 0.5958
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.099345207214355 seconds
Epoch 43 accuracy: 82.36%
Batch 10, Loss: 0.5540
Batch 20, Loss: 0.5476
Batch 30, Loss: 0.5775
Batch 40, Loss: 0.5699
Batch 50, Loss: 0.4798
Batch 60, Loss: 0.5522
Batch 70, Loss: 0.5264
Batch 80, Loss: 0.5872
Batch 90, Loss: 0.5321
Batch 100, Loss: 0.5513
Batch 110, Loss: 0.5911
Batch 120, Loss: 0.5492
Batch 130, Loss: 0.5415
Batch 140, Loss: 0.5278
Batch 150, Loss: 0.5201
Batch 160, Loss: 0.5327
Batch 170, Loss: 0.5845
Batch 180, Loss: 0.5896
Batch 190, Loss: 0.5473
Batch 200, Loss: 0.6051
Batch 210, Loss: 0.5851
Batch 220, Loss: 0.5794
Batch 230, Loss: 0.5723
Batch 240, Loss: 0.5213
Batch 250, Loss: 0.5195
Batch 260, Loss: 0.5575
Batch 270, Loss: 0.5656
Batch 280, Loss: 0.5608
Batch 290, Loss: 0.4906
Batch 300, Loss: 0.5350
Batch 310, Loss: 0.5179
Batch 320, Loss: 0.5561
Batch 330, Loss: 0.5545
Batch 340, Loss: 0.5597
Batch 350, Loss: 0.5250
Batch 360, Loss: 0.5475
Batch 370, Loss: 0.5683
Batch 380, Loss: 0.6033
Batch 390, Loss: 0.5148
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.34940791130066 seconds
Epoch 44 accuracy: 78.6%
Batch 10, Loss: 0.5640
Batch 20, Loss: 0.5187
Batch 30, Loss: 0.5179
Batch 40, Loss: 0.4891
Batch 50, Loss: 0.5389
Batch 60, Loss: 0.5707
Batch 70, Loss: 0.5751
Batch 80, Loss: 0.5034
Batch 90, Loss: 0.5382
Batch 100, Loss: 0.5525
Batch 110, Loss: 0.5434
Batch 120, Loss: 0.5573
Batch 130, Loss: 0.5462
Batch 140, Loss: 0.5639
Batch 150, Loss: 0.5579
Batch 160, Loss: 0.5189
Batch 170, Loss: 0.4963
Batch 180, Loss: 0.5665
Batch 190, Loss: 0.5065
Batch 200, Loss: 0.5272
Batch 210, Loss: 0.5285
Batch 220, Loss: 0.5465
Batch 230, Loss: 0.5628
Batch 240, Loss: 0.5694
Batch 250, Loss: 0.5180
Batch 260, Loss: 0.5673
Batch 270, Loss: 0.5905
Batch 280, Loss: 0.5534
Batch 290, Loss: 0.5972
Batch 300, Loss: 0.5885
Batch 310, Loss: 0.5950
Batch 320, Loss: 0.5584
Batch 330, Loss: 0.5255
Batch 340, Loss: 0.5542
Batch 350, Loss: 0.5626
Batch 360, Loss: 0.5528
Batch 370, Loss: 0.5609
Batch 380, Loss: 0.5649
Batch 390, Loss: 0.5481
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.068626642227173 seconds
Epoch 45 accuracy: 81.22%
Batch 10, Loss: 0.5542
Batch 20, Loss: 0.5341
Batch 30, Loss: 0.5377
Batch 40, Loss: 0.5234
Batch 50, Loss: 0.4873
Batch 60, Loss: 0.5432
Batch 70, Loss: 0.5442
Batch 80, Loss: 0.5252
Batch 90, Loss: 0.5895
Batch 100, Loss: 0.5284
Batch 110, Loss: 0.5475
Batch 120, Loss: 0.5514
Batch 130, Loss: 0.5619
Batch 140, Loss: 0.5310
Batch 150, Loss: 0.5316
Batch 160, Loss: 0.5498
Batch 170, Loss: 0.5427
Batch 180, Loss: 0.5291
Batch 190, Loss: 0.5356
Batch 200, Loss: 0.5469
Batch 210, Loss: 0.5753
Batch 220, Loss: 0.5613
Batch 230, Loss: 0.5496
Batch 240, Loss: 0.5750
Batch 250, Loss: 0.5476
Batch 260, Loss: 0.5142
Batch 270, Loss: 0.5625
Batch 280, Loss: 0.5872
Batch 290, Loss: 0.5240
Batch 300, Loss: 0.5525
Batch 310, Loss: 0.5698
Batch 320, Loss: 0.5527
Batch 330, Loss: 0.5347
Batch 340, Loss: 0.5580
Batch 350, Loss: 0.5579
Batch 360, Loss: 0.5246
Batch 370, Loss: 0.5346
Batch 380, Loss: 0.5524
Batch 390, Loss: 0.5662
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.10633134841919 seconds
Epoch 46 accuracy: 80.38%
Batch 10, Loss: 0.5795
Batch 20, Loss: 0.5464
Batch 30, Loss: 0.5681
Batch 40, Loss: 0.5203
Batch 50, Loss: 0.5536
Batch 60, Loss: 0.5710
Batch 70, Loss: 0.5513
Batch 80, Loss: 0.5414
Batch 90, Loss: 0.5207
Batch 100, Loss: 0.5248
Batch 110, Loss: 0.5498
Batch 120, Loss: 0.5314
Batch 130, Loss: 0.5766
Batch 140, Loss: 0.5635
Batch 150, Loss: 0.5571
Batch 160, Loss: 0.5663
Batch 170, Loss: 0.5731
Batch 180, Loss: 0.5528
Batch 190, Loss: 0.5230
Batch 200, Loss: 0.5357
Batch 210, Loss: 0.5367
Batch 220, Loss: 0.5161
Batch 230, Loss: 0.5260
Batch 240, Loss: 0.4925
Batch 250, Loss: 0.5461
Batch 260, Loss: 0.5844
Batch 270, Loss: 0.5532
Batch 280, Loss: 0.5848
Batch 290, Loss: 0.5511
Batch 300, Loss: 0.5631
Batch 310, Loss: 0.5564
Batch 320, Loss: 0.5682
Batch 330, Loss: 0.5200
Batch 340, Loss: 0.5447
Batch 350, Loss: 0.5331
Batch 360, Loss: 0.5319
Batch 370, Loss: 0.5408
Batch 380, Loss: 0.5343
Batch 390, Loss: 0.4990
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.250913381576538 seconds
Epoch 47 accuracy: 83.54%
Batch 10, Loss: 0.5503
Batch 20, Loss: 0.5358
Batch 30, Loss: 0.5410
Batch 40, Loss: 0.5682
Batch 50, Loss: 0.5521
Batch 60, Loss: 0.5165
Batch 70, Loss: 0.5564
Batch 80, Loss: 0.5979
Batch 90, Loss: 0.5288
Batch 100, Loss: 0.5250
Batch 110, Loss: 0.5501
Batch 120, Loss: 0.5102
Batch 130, Loss: 0.5181
Batch 140, Loss: 0.5569
Batch 150, Loss: 0.5398
Batch 160, Loss: 0.5613
Batch 170, Loss: 0.5210
Batch 180, Loss: 0.5521
Batch 190, Loss: 0.5375
Batch 200, Loss: 0.5401
Batch 210, Loss: 0.5589
Batch 220, Loss: 0.4931
Batch 230, Loss: 0.5481
Batch 240, Loss: 0.5538
Batch 250, Loss: 0.5411
Batch 260, Loss: 0.5502
Batch 270, Loss: 0.5841
Batch 280, Loss: 0.5798
Batch 290, Loss: 0.5455
Batch 300, Loss: 0.5582
Batch 310, Loss: 0.5512
Batch 320, Loss: 0.5495
Batch 330, Loss: 0.5574
Batch 340, Loss: 0.5652
Batch 350, Loss: 0.5780
Batch 360, Loss: 0.5301
Batch 370, Loss: 0.5471
Batch 380, Loss: 0.5483
Batch 390, Loss: 0.5349
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.043237924575806 seconds
Epoch 48 accuracy: 81.43%
Batch 10, Loss: 0.5624
Batch 20, Loss: 0.5279
Batch 30, Loss: 0.5564
Batch 40, Loss: 0.5221
Batch 50, Loss: 0.5381
Batch 60, Loss: 0.5137
Batch 70, Loss: 0.5565
Batch 80, Loss: 0.5290
Batch 90, Loss: 0.5366
Batch 100, Loss: 0.5118
Batch 110, Loss: 0.5923
Batch 120, Loss: 0.5024
Batch 130, Loss: 0.5870
Batch 140, Loss: 0.5326
Batch 150, Loss: 0.5154
Batch 160, Loss: 0.4991
Batch 170, Loss: 0.5756
Batch 180, Loss: 0.5156
Batch 190, Loss: 0.5278
Batch 200, Loss: 0.5263
Batch 210, Loss: 0.5320
Batch 220, Loss: 0.5035
Batch 230, Loss: 0.5230
Batch 240, Loss: 0.5257
Batch 250, Loss: 0.5009
Batch 260, Loss: 0.5587
Batch 270, Loss: 0.5595
Batch 280, Loss: 0.6059
Batch 290, Loss: 0.5452
Batch 300, Loss: 0.4905
Batch 310, Loss: 0.5487
Batch 320, Loss: 0.5459
Batch 330, Loss: 0.5809
Batch 340, Loss: 0.5405
Batch 350, Loss: 0.5361
Batch 360, Loss: 0.5447
Batch 370, Loss: 0.5448
Batch 380, Loss: 0.5161
Batch 390, Loss: 0.5617
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.166945934295654 seconds
Epoch 49 accuracy: 84.2%
Batch 10, Loss: 0.5269
Batch 20, Loss: 0.5336
Batch 30, Loss: 0.5159
Batch 40, Loss: 0.5400
Batch 50, Loss: 0.5320
Batch 60, Loss: 0.5140
Batch 70, Loss: 0.5172
Batch 80, Loss: 0.5105
Batch 90, Loss: 0.5312
Batch 100, Loss: 0.5403
Batch 110, Loss: 0.5845
Batch 120, Loss: 0.5666
Batch 130, Loss: 0.5431
Batch 140, Loss: 0.5741
Batch 150, Loss: 0.5375
Batch 160, Loss: 0.5494
Batch 170, Loss: 0.5253
Batch 180, Loss: 0.5521
Batch 190, Loss: 0.5544
Batch 200, Loss: 0.5314
Batch 210, Loss: 0.5250
Batch 220, Loss: 0.5322
Batch 230, Loss: 0.5098
Batch 240, Loss: 0.5129
Batch 250, Loss: 0.5579
Batch 260, Loss: 0.5317
Batch 270, Loss: 0.5485
Batch 280, Loss: 0.5258
Batch 290, Loss: 0.5703
Batch 300, Loss: 0.5299
Batch 310, Loss: 0.5227
Batch 320, Loss: 0.5291
Batch 330, Loss: 0.5575
Batch 340, Loss: 0.5648
Batch 350, Loss: 0.5647
Batch 360, Loss: 0.5193
Batch 370, Loss: 0.5241
Batch 380, Loss: 0.5430
Batch 390, Loss: 0.5587
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.19296407699585 seconds
Epoch 50 accuracy: 76.54%
Batch 10, Loss: 0.5164
Batch 20, Loss: 0.5675
Batch 30, Loss: 0.5641
Batch 40, Loss: 0.5546
Batch 50, Loss: 0.5045
Batch 60, Loss: 0.5287
Batch 70, Loss: 0.5383
Batch 80, Loss: 0.5675
Batch 90, Loss: 0.5213
Batch 100, Loss: 0.5442
Batch 110, Loss: 0.5555
Batch 120, Loss: 0.5006
Batch 130, Loss: 0.5613
Batch 140, Loss: 0.5063
Batch 150, Loss: 0.5514
Batch 160, Loss: 0.5569
Batch 170, Loss: 0.5205
Batch 180, Loss: 0.4925
Batch 190, Loss: 0.5602
Batch 200, Loss: 0.5394
Batch 210, Loss: 0.5496
Batch 220, Loss: 0.5453
Batch 230, Loss: 0.5465
Batch 240, Loss: 0.5523
Batch 250, Loss: 0.5385
Batch 260, Loss: 0.5325
Batch 270, Loss: 0.5409
Batch 280, Loss: 0.5081
Batch 290, Loss: 0.5091
Batch 300, Loss: 0.4993
Batch 310, Loss: 0.5197
Batch 320, Loss: 0.5084
Batch 330, Loss: 0.5082
Batch 340, Loss: 0.5365
Batch 350, Loss: 0.5198
Batch 360, Loss: 0.5541
Batch 370, Loss: 0.5344
Batch 380, Loss: 0.5125
Batch 390, Loss: 0.5670
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.06762409210205 seconds
Epoch 51 accuracy: 83.24%
Batch 10, Loss: 0.5644
Batch 20, Loss: 0.5009
Batch 30, Loss: 0.5287
Batch 40, Loss: 0.5359
Batch 50, Loss: 0.5247
Batch 60, Loss: 0.5458
Batch 70, Loss: 0.5504
Batch 80, Loss: 0.5072
Batch 90, Loss: 0.5153
Batch 100, Loss: 0.5628
Batch 110, Loss: 0.5219
Batch 120, Loss: 0.5123
Batch 130, Loss: 0.5266
Batch 140, Loss: 0.5504
Batch 150, Loss: 0.5279
Batch 160, Loss: 0.5577
Batch 170, Loss: 0.5383
Batch 180, Loss: 0.5258
Batch 190, Loss: 0.4993
Batch 200, Loss: 0.5173
Batch 210, Loss: 0.5649
Batch 220, Loss: 0.5358
Batch 230, Loss: 0.5599
Batch 240, Loss: 0.5368
Batch 250, Loss: 0.5348
Batch 260, Loss: 0.5614
Batch 270, Loss: 0.5401
Batch 280, Loss: 0.5296
Batch 290, Loss: 0.5057
Batch 300, Loss: 0.5004
Batch 310, Loss: 0.5238
Batch 320, Loss: 0.5588
Batch 330, Loss: 0.5604
Batch 340, Loss: 0.5515
Batch 350, Loss: 0.5473
Batch 360, Loss: 0.5461
Batch 370, Loss: 0.5323
Batch 380, Loss: 0.5525
Batch 390, Loss: 0.5520
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.19722604751587 seconds
Epoch 52 accuracy: 85.73%
Batch 10, Loss: 0.5152
Batch 20, Loss: 0.5376
Batch 30, Loss: 0.5506
Batch 40, Loss: 0.5655
Batch 50, Loss: 0.5293
Batch 60, Loss: 0.5154
Batch 70, Loss: 0.5306
Batch 80, Loss: 0.5372
Batch 90, Loss: 0.5293
Batch 100, Loss: 0.5075
Batch 110, Loss: 0.5386
Batch 120, Loss: 0.5438
Batch 130, Loss: 0.5413
Batch 140, Loss: 0.5267
Batch 150, Loss: 0.5354
Batch 160, Loss: 0.4802
Batch 170, Loss: 0.5371
Batch 180, Loss: 0.5357
Batch 190, Loss: 0.5326
Batch 200, Loss: 0.5310
Batch 210, Loss: 0.5293
Batch 220, Loss: 0.5497
Batch 230, Loss: 0.5297
Batch 240, Loss: 0.5496
Batch 250, Loss: 0.4994
Batch 260, Loss: 0.5079
Batch 270, Loss: 0.5434
Batch 280, Loss: 0.5163
Batch 290, Loss: 0.5458
Batch 300, Loss: 0.5373
Batch 310, Loss: 0.5145
Batch 320, Loss: 0.5171
Batch 330, Loss: 0.4936
Batch 340, Loss: 0.5550
Batch 350, Loss: 0.5601
Batch 360, Loss: 0.5352
Batch 370, Loss: 0.5452
Batch 380, Loss: 0.5583
Batch 390, Loss: 0.5115
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.257386922836304 seconds
Epoch 53 accuracy: 83.76%
Batch 10, Loss: 0.4948
Batch 20, Loss: 0.5450
Batch 30, Loss: 0.5567
Batch 40, Loss: 0.5182
Batch 50, Loss: 0.5802
Batch 60, Loss: 0.5168
Batch 70, Loss: 0.5404
Batch 80, Loss: 0.5390
Batch 90, Loss: 0.5486
Batch 100, Loss: 0.5072
Batch 110, Loss: 0.5004
Batch 120, Loss: 0.5522
Batch 130, Loss: 0.5229
Batch 140, Loss: 0.5392
Batch 150, Loss: 0.5278
Batch 160, Loss: 0.5441
Batch 170, Loss: 0.4907
Batch 180, Loss: 0.5004
Batch 190, Loss: 0.5730
Batch 200, Loss: 0.5013
Batch 210, Loss: 0.5346
Batch 220, Loss: 0.5393
Batch 230, Loss: 0.5220
Batch 240, Loss: 0.5495
Batch 250, Loss: 0.5537
Batch 260, Loss: 0.6048
Batch 270, Loss: 0.5555
Batch 280, Loss: 0.5654
Batch 290, Loss: 0.5119
Batch 300, Loss: 0.4934
Batch 310, Loss: 0.5075
Batch 320, Loss: 0.4905
Batch 330, Loss: 0.5170
Batch 340, Loss: 0.5407
Batch 350, Loss: 0.5387
Batch 360, Loss: 0.5246
Batch 370, Loss: 0.5405
Batch 380, Loss: 0.5265
Batch 390, Loss: 0.5088
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.21418261528015 seconds
Epoch 54 accuracy: 86.19%
Batch 10, Loss: 0.5406
Batch 20, Loss: 0.5224
Batch 30, Loss: 0.5389
Batch 40, Loss: 0.5254
Batch 50, Loss: 0.5110
Batch 60, Loss: 0.5626
Batch 70, Loss: 0.5201
Batch 80, Loss: 0.5093
Batch 90, Loss: 0.5393
Batch 100, Loss: 0.5459
Batch 110, Loss: 0.5039
Batch 120, Loss: 0.5545
Batch 130, Loss: 0.5507
Batch 140, Loss: 0.5089
Batch 150, Loss: 0.5036
Batch 160, Loss: 0.5196
Batch 170, Loss: 0.5258
Batch 180, Loss: 0.5622
Batch 190, Loss: 0.5079
Batch 200, Loss: 0.5177
Batch 210, Loss: 0.4713
Batch 220, Loss: 0.5059
Batch 230, Loss: 0.5185
Batch 240, Loss: 0.5436
Batch 250, Loss: 0.4992
Batch 260, Loss: 0.5217
Batch 270, Loss: 0.5224
Batch 280, Loss: 0.5522
Batch 290, Loss: 0.5258
Batch 300, Loss: 0.5149
Batch 310, Loss: 0.5287
Batch 320, Loss: 0.5421
Batch 330, Loss: 0.5780
Batch 340, Loss: 0.5581
Batch 350, Loss: 0.5359
Batch 360, Loss: 0.5300
Batch 370, Loss: 0.4849
Batch 380, Loss: 0.5208
Batch 390, Loss: 0.5708
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.124287128448486 seconds
Epoch 55 accuracy: 82.58%
Batch 10, Loss: 0.5339
Batch 20, Loss: 0.5356
Batch 30, Loss: 0.5519
Batch 40, Loss: 0.5455
Batch 50, Loss: 0.4992
Batch 60, Loss: 0.5298
Batch 70, Loss: 0.5784
Batch 80, Loss: 0.5104
Batch 90, Loss: 0.5123
Batch 100, Loss: 0.5139
Batch 110, Loss: 0.5400
Batch 120, Loss: 0.5339
Batch 130, Loss: 0.5029
Batch 140, Loss: 0.4954
Batch 150, Loss: 0.5616
Batch 160, Loss: 0.5287
Batch 170, Loss: 0.5512
Batch 180, Loss: 0.5551
Batch 190, Loss: 0.5476
Batch 200, Loss: 0.4981
Batch 210, Loss: 0.5293
Batch 220, Loss: 0.5080
Batch 230, Loss: 0.5394
Batch 240, Loss: 0.5261
Batch 250, Loss: 0.5275
Batch 260, Loss: 0.5530
Batch 270, Loss: 0.5645
Batch 280, Loss: 0.5597
Batch 290, Loss: 0.4948
Batch 300, Loss: 0.5217
Batch 310, Loss: 0.5440
Batch 320, Loss: 0.5396
Batch 330, Loss: 0.5457
Batch 340, Loss: 0.5101
Batch 350, Loss: 0.4994
Batch 360, Loss: 0.5426
Batch 370, Loss: 0.5064
Batch 380, Loss: 0.5578
Batch 390, Loss: 0.5054
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.047630071640015 seconds
Epoch 56 accuracy: 81.27%
Batch 10, Loss: 0.5238
Batch 20, Loss: 0.5180
Batch 30, Loss: 0.5033
Batch 40, Loss: 0.5287
Batch 50, Loss: 0.5437
Batch 60, Loss: 0.5448
Batch 70, Loss: 0.5174
Batch 80, Loss: 0.4990
Batch 90, Loss: 0.5475
Batch 100, Loss: 0.5396
Batch 110, Loss: 0.5214
Batch 120, Loss: 0.5009
Batch 130, Loss: 0.5548
Batch 140, Loss: 0.5289
Batch 150, Loss: 0.5460
Batch 160, Loss: 0.5267
Batch 170, Loss: 0.5543
Batch 180, Loss: 0.5366
Batch 190, Loss: 0.5105
Batch 200, Loss: 0.4915
Batch 210, Loss: 0.5575
Batch 220, Loss: 0.5200
Batch 230, Loss: 0.4993
Batch 240, Loss: 0.5179
Batch 250, Loss: 0.5290
Batch 260, Loss: 0.5560
Batch 270, Loss: 0.5424
Batch 280, Loss: 0.5515
Batch 290, Loss: 0.5272
Batch 300, Loss: 0.5486
Batch 310, Loss: 0.5217
Batch 320, Loss: 0.5101
Batch 330, Loss: 0.5496
Batch 340, Loss: 0.4638
Batch 350, Loss: 0.5447
Batch 360, Loss: 0.5551
Batch 370, Loss: 0.5383
Batch 380, Loss: 0.5345
Batch 390, Loss: 0.5532
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.031073093414307 seconds
Epoch 57 accuracy: 82.24%
Batch 10, Loss: 0.5064
Batch 20, Loss: 0.4845
Batch 30, Loss: 0.5111
Batch 40, Loss: 0.5262
Batch 50, Loss: 0.5279
Batch 60, Loss: 0.5454
Batch 70, Loss: 0.4926
Batch 80, Loss: 0.5175
Batch 90, Loss: 0.5050
Batch 100, Loss: 0.4973
Batch 110, Loss: 0.5597
Batch 120, Loss: 0.5016
Batch 130, Loss: 0.5426
Batch 140, Loss: 0.5423
Batch 150, Loss: 0.5104
Batch 160, Loss: 0.5085
Batch 170, Loss: 0.5269
Batch 180, Loss: 0.5426
Batch 190, Loss: 0.5050
Batch 200, Loss: 0.5172
Batch 210, Loss: 0.5040
Batch 220, Loss: 0.5042
Batch 230, Loss: 0.5296
Batch 240, Loss: 0.4853
Batch 250, Loss: 0.5220
Batch 260, Loss: 0.5253
Batch 270, Loss: 0.5436
Batch 280, Loss: 0.5507
Batch 290, Loss: 0.5149
Batch 300, Loss: 0.5214
Batch 310, Loss: 0.5131
Batch 320, Loss: 0.5205
Batch 330, Loss: 0.5225
Batch 340, Loss: 0.5222
Batch 350, Loss: 0.5360
Batch 360, Loss: 0.5005
Batch 370, Loss: 0.5035
Batch 380, Loss: 0.5137
Batch 390, Loss: 0.5171
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.149158000946045 seconds
Epoch 58 accuracy: 83.15%
Batch 10, Loss: 0.4989
Batch 20, Loss: 0.5081
Batch 30, Loss: 0.5500
Batch 40, Loss: 0.5213
Batch 50, Loss: 0.5307
Batch 60, Loss: 0.5050
Batch 70, Loss: 0.5221
Batch 80, Loss: 0.4873
Batch 90, Loss: 0.5222
Batch 100, Loss: 0.4989
Batch 110, Loss: 0.5348
Batch 120, Loss: 0.5165
Batch 130, Loss: 0.4788
Batch 140, Loss: 0.5116
Batch 150, Loss: 0.5083
Batch 160, Loss: 0.5554
Batch 170, Loss: 0.5167
Batch 180, Loss: 0.5537
Batch 190, Loss: 0.5099
Batch 200, Loss: 0.4948
Batch 210, Loss: 0.5497
Batch 220, Loss: 0.5361
Batch 230, Loss: 0.5423
Batch 240, Loss: 0.5253
Batch 250, Loss: 0.5530
Batch 260, Loss: 0.5291
Batch 270, Loss: 0.5443
Batch 280, Loss: 0.5741
Batch 290, Loss: 0.5166
Batch 300, Loss: 0.5104
Batch 310, Loss: 0.4863
Batch 320, Loss: 0.5319
Batch 330, Loss: 0.5337
Batch 340, Loss: 0.5733
Batch 350, Loss: 0.5599
Batch 360, Loss: 0.5160
Batch 370, Loss: 0.5200
Batch 380, Loss: 0.4922
Batch 390, Loss: 0.4682
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.02722930908203 seconds
Epoch 59 accuracy: 82.06%
Batch 10, Loss: 0.5146
Batch 20, Loss: 0.5449
Batch 30, Loss: 0.5250
Batch 40, Loss: 0.5307
Batch 50, Loss: 0.5427
Batch 60, Loss: 0.5366
Batch 70, Loss: 0.5279
Batch 80, Loss: 0.5511
Batch 90, Loss: 0.4952
Batch 100, Loss: 0.5418
Batch 110, Loss: 0.5165
Batch 120, Loss: 0.5369
Batch 130, Loss: 0.5146
Batch 140, Loss: 0.5036
Batch 150, Loss: 0.4912
Batch 160, Loss: 0.5587
Batch 170, Loss: 0.4988
Batch 180, Loss: 0.5329
Batch 190, Loss: 0.5513
Batch 200, Loss: 0.5121
Batch 210, Loss: 0.5004
Batch 220, Loss: 0.4821
Batch 230, Loss: 0.5086
Batch 240, Loss: 0.5419
Batch 250, Loss: 0.4964
Batch 260, Loss: 0.5078
Batch 270, Loss: 0.4939
Batch 280, Loss: 0.4869
Batch 290, Loss: 0.5461
Batch 300, Loss: 0.4869
Batch 310, Loss: 0.5350
Batch 320, Loss: 0.5065
Batch 330, Loss: 0.5233
Batch 340, Loss: 0.5125
Batch 350, Loss: 0.5055
Batch 360, Loss: 0.5086
Batch 370, Loss: 0.5208
Batch 380, Loss: 0.5601
Batch 390, Loss: 0.5211
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 24.981518030166626 seconds
Epoch 60 accuracy: 81.73%
Batch 10, Loss: 0.5041
Batch 20, Loss: 0.5351
Batch 30, Loss: 0.4865
Batch 40, Loss: 0.5396
Batch 50, Loss: 0.4923
Batch 60, Loss: 0.5193
Batch 70, Loss: 0.5412
Batch 80, Loss: 0.5297
Batch 90, Loss: 0.4825
Batch 100, Loss: 0.4891
Batch 110, Loss: 0.5394
Batch 120, Loss: 0.5191
Batch 130, Loss: 0.5529
Batch 140, Loss: 0.5100
Batch 150, Loss: 0.5109
Batch 160, Loss: 0.4905
Batch 170, Loss: 0.5568
Batch 180, Loss: 0.5044
Batch 190, Loss: 0.5264
Batch 200, Loss: 0.5041
Batch 210, Loss: 0.5344
Batch 220, Loss: 0.5126
Batch 230, Loss: 0.5113
Batch 240, Loss: 0.5255
Batch 250, Loss: 0.5074
Batch 260, Loss: 0.5217
Batch 270, Loss: 0.5132
Batch 280, Loss: 0.5552
Batch 290, Loss: 0.5233
Batch 300, Loss: 0.5112
Batch 310, Loss: 0.4909
Batch 320, Loss: 0.5220
Batch 330, Loss: 0.5199
Batch 340, Loss: 0.5307
Batch 350, Loss: 0.5260
Batch 360, Loss: 0.5223
Batch 370, Loss: 0.5350
Batch 380, Loss: 0.4903
Batch 390, Loss: 0.5111
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.00303864479065 seconds
Epoch 61 accuracy: 82.76%
Batch 10, Loss: 0.5353
Batch 20, Loss: 0.4938
Batch 30, Loss: 0.4905
Batch 40, Loss: 0.4810
Batch 50, Loss: 0.4823
Batch 60, Loss: 0.5390
Batch 70, Loss: 0.5554
Batch 80, Loss: 0.5073
Batch 90, Loss: 0.4977
Batch 100, Loss: 0.5275
Batch 110, Loss: 0.5170
Batch 120, Loss: 0.4809
Batch 130, Loss: 0.4974
Batch 140, Loss: 0.4987
Batch 150, Loss: 0.5043
Batch 160, Loss: 0.4978
Batch 170, Loss: 0.4961
Batch 180, Loss: 0.5407
Batch 190, Loss: 0.5522
Batch 200, Loss: 0.5482
Batch 210, Loss: 0.5347
Batch 220, Loss: 0.5113
Batch 230, Loss: 0.5155
Batch 240, Loss: 0.5541
Batch 250, Loss: 0.5251
Batch 260, Loss: 0.5127
Batch 270, Loss: 0.5208
Batch 280, Loss: 0.5164
Batch 290, Loss: 0.4994
Batch 300, Loss: 0.4618
Batch 310, Loss: 0.5476
Batch 320, Loss: 0.5272
Batch 330, Loss: 0.4744
Batch 340, Loss: 0.5137
Batch 350, Loss: 0.5049
Batch 360, Loss: 0.5105
Batch 370, Loss: 0.5520
Batch 380, Loss: 0.5285
Batch 390, Loss: 0.4991
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.086789846420288 seconds
Epoch 62 accuracy: 82.38%
Batch 10, Loss: 0.5110
Batch 20, Loss: 0.5288
Batch 30, Loss: 0.4922
Batch 40, Loss: 0.4954
Batch 50, Loss: 0.5219
Batch 60, Loss: 0.4824
Batch 70, Loss: 0.4766
Batch 80, Loss: 0.4984
Batch 90, Loss: 0.5004
Batch 100, Loss: 0.4978
Batch 110, Loss: 0.5456
Batch 120, Loss: 0.5082
Batch 130, Loss: 0.4865
Batch 140, Loss: 0.5040
Batch 150, Loss: 0.5600
Batch 160, Loss: 0.4753
Batch 170, Loss: 0.5127
Batch 180, Loss: 0.5124
Batch 190, Loss: 0.5378
Batch 200, Loss: 0.5193
Batch 210, Loss: 0.5180
Batch 220, Loss: 0.5374
Batch 230, Loss: 0.5543
Batch 240, Loss: 0.5023
Batch 250, Loss: 0.5728
Batch 260, Loss: 0.5502
Batch 270, Loss: 0.5231
Batch 280, Loss: 0.5122
Batch 290, Loss: 0.5288
Batch 300, Loss: 0.5332
Batch 310, Loss: 0.4673
Batch 320, Loss: 0.4920
Batch 330, Loss: 0.5114
Batch 340, Loss: 0.5146
Batch 350, Loss: 0.4916
Batch 360, Loss: 0.5455
Batch 370, Loss: 0.5310
Batch 380, Loss: 0.5217
Batch 390, Loss: 0.5975
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 24.97669506072998 seconds
Epoch 63 accuracy: 79.71%
Batch 10, Loss: 0.5284
Batch 20, Loss: 0.5114
Batch 30, Loss: 0.5265
Batch 40, Loss: 0.5091
Batch 50, Loss: 0.5133
Batch 60, Loss: 0.4828
Batch 70, Loss: 0.5364
Batch 80, Loss: 0.5136
Batch 90, Loss: 0.4823
Batch 100, Loss: 0.4783
Batch 110, Loss: 0.4805
Batch 120, Loss: 0.5281
Batch 130, Loss: 0.5262
Batch 140, Loss: 0.5133
Batch 150, Loss: 0.5090
Batch 160, Loss: 0.5591
Batch 170, Loss: 0.5373
Batch 180, Loss: 0.5074
Batch 190, Loss: 0.5259
Batch 200, Loss: 0.5537
Batch 210, Loss: 0.5312
Batch 220, Loss: 0.5257
Batch 230, Loss: 0.4872
Batch 240, Loss: 0.5112
Batch 250, Loss: 0.5201
Batch 260, Loss: 0.5398
Batch 270, Loss: 0.4843
Batch 280, Loss: 0.5256
Batch 290, Loss: 0.5275
Batch 300, Loss: 0.5507
Batch 310, Loss: 0.4941
Batch 320, Loss: 0.4801
Batch 330, Loss: 0.5262
Batch 340, Loss: 0.5129
Batch 350, Loss: 0.4920
Batch 360, Loss: 0.5429
Batch 370, Loss: 0.5313
Batch 380, Loss: 0.5458
Batch 390, Loss: 0.5166
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.01263189315796 seconds
Epoch 64 accuracy: 82.14%
Batch 10, Loss: 0.4905
Batch 20, Loss: 0.5136
Batch 30, Loss: 0.4758
Batch 40, Loss: 0.4569
Batch 50, Loss: 0.4864
Batch 60, Loss: 0.5067
Batch 70, Loss: 0.5237
Batch 80, Loss: 0.5517
Batch 90, Loss: 0.4983
Batch 100, Loss: 0.5133
Batch 110, Loss: 0.5264
Batch 120, Loss: 0.5186
Batch 130, Loss: 0.5212
Batch 140, Loss: 0.5275
Batch 150, Loss: 0.5238
Batch 160, Loss: 0.5049
Batch 170, Loss: 0.5027
Batch 180, Loss: 0.5312
Batch 190, Loss: 0.5207
Batch 200, Loss: 0.5172
Batch 210, Loss: 0.4940
Batch 220, Loss: 0.4994
Batch 230, Loss: 0.4998
Batch 240, Loss: 0.4723
Batch 250, Loss: 0.5366
Batch 260, Loss: 0.5246
Batch 270, Loss: 0.5048
Batch 280, Loss: 0.4812
Batch 290, Loss: 0.4689
Batch 300, Loss: 0.5417
Batch 310, Loss: 0.5308
Batch 320, Loss: 0.5028
Batch 330, Loss: 0.4733
Batch 340, Loss: 0.5537
Batch 350, Loss: 0.5152
Batch 360, Loss: 0.5081
Batch 370, Loss: 0.5545
Batch 380, Loss: 0.5151
Batch 390, Loss: 0.5401
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.024333000183105 seconds
Epoch 65 accuracy: 85.3%
Batch 10, Loss: 0.4897
Batch 20, Loss: 0.5394
Batch 30, Loss: 0.4648
Batch 40, Loss: 0.5349
Batch 50, Loss: 0.5454
Batch 60, Loss: 0.4929
Batch 70, Loss: 0.5534
Batch 80, Loss: 0.5148
Batch 90, Loss: 0.5179
Batch 100, Loss: 0.5033
Batch 110, Loss: 0.5208
Batch 120, Loss: 0.4677
Batch 130, Loss: 0.5411
Batch 140, Loss: 0.4852
Batch 150, Loss: 0.5366
Batch 160, Loss: 0.5124
Batch 170, Loss: 0.5072
Batch 180, Loss: 0.4945
Batch 190, Loss: 0.5032
Batch 200, Loss: 0.5111
Batch 210, Loss: 0.4772
Batch 220, Loss: 0.4902
Batch 230, Loss: 0.4946
Batch 240, Loss: 0.5075
Batch 250, Loss: 0.4894
Batch 260, Loss: 0.5424
Batch 270, Loss: 0.4995
Batch 280, Loss: 0.4919
Batch 290, Loss: 0.5150
Batch 300, Loss: 0.5327
Batch 310, Loss: 0.5103
Batch 320, Loss: 0.5019
Batch 330, Loss: 0.5128
Batch 340, Loss: 0.5378
Batch 350, Loss: 0.5160
Batch 360, Loss: 0.4842
Batch 370, Loss: 0.4952
Batch 380, Loss: 0.4880
Batch 390, Loss: 0.5500
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.394617795944214 seconds
Epoch 66 accuracy: 86.36%
Batch 10, Loss: 0.4568
Batch 20, Loss: 0.4891
Batch 30, Loss: 0.5071
Batch 40, Loss: 0.4833
Batch 50, Loss: 0.5079
Batch 60, Loss: 0.5348
Batch 70, Loss: 0.5486
Batch 80, Loss: 0.5324
Batch 90, Loss: 0.5221
Batch 100, Loss: 0.4966
Batch 110, Loss: 0.5233
Batch 120, Loss: 0.4599
Batch 130, Loss: 0.4902
Batch 140, Loss: 0.4607
Batch 150, Loss: 0.4843
Batch 160, Loss: 0.5368
Batch 170, Loss: 0.5472
Batch 180, Loss: 0.4946
Batch 190, Loss: 0.4771
Batch 200, Loss: 0.4918
Batch 210, Loss: 0.4780
Batch 220, Loss: 0.5027
Batch 230, Loss: 0.5138
Batch 240, Loss: 0.4900
Batch 250, Loss: 0.4679
Batch 260, Loss: 0.4895
Batch 270, Loss: 0.5212
Batch 280, Loss: 0.5140
Batch 290, Loss: 0.4724
Batch 300, Loss: 0.5188
Batch 310, Loss: 0.5066
Batch 320, Loss: 0.5447
Batch 330, Loss: 0.5131
Batch 340, Loss: 0.4800
Batch 350, Loss: 0.4840
Batch 360, Loss: 0.5369
Batch 370, Loss: 0.5568
Batch 380, Loss: 0.5283
Batch 390, Loss: 0.4885
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.05078935623169 seconds
Epoch 67 accuracy: 87.37%
Batch 10, Loss: 0.4796
Batch 20, Loss: 0.4662
Batch 30, Loss: 0.5133
Batch 40, Loss: 0.4363
Batch 50, Loss: 0.5013
Batch 60, Loss: 0.5226
Batch 70, Loss: 0.4890
Batch 80, Loss: 0.4920
Batch 90, Loss: 0.4825
Batch 100, Loss: 0.5162
Batch 110, Loss: 0.4994
Batch 120, Loss: 0.5122
Batch 130, Loss: 0.5306
Batch 140, Loss: 0.5110
Batch 150, Loss: 0.4932
Batch 160, Loss: 0.5117
Batch 170, Loss: 0.4856
Batch 180, Loss: 0.4967
Batch 190, Loss: 0.4807
Batch 200, Loss: 0.4854
Batch 210, Loss: 0.4946
Batch 220, Loss: 0.4982
Batch 230, Loss: 0.4874
Batch 240, Loss: 0.5031
Batch 250, Loss: 0.5321
Batch 260, Loss: 0.4794
Batch 270, Loss: 0.4966
Batch 280, Loss: 0.5083
Batch 290, Loss: 0.4939
Batch 300, Loss: 0.5369
Batch 310, Loss: 0.5219
Batch 320, Loss: 0.4962
Batch 330, Loss: 0.5211
Batch 340, Loss: 0.5349
Batch 350, Loss: 0.5286
Batch 360, Loss: 0.4952
Batch 370, Loss: 0.4994
Batch 380, Loss: 0.5113
Batch 390, Loss: 0.5019
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.10524606704712 seconds
Epoch 68 accuracy: 86.04%
Batch 10, Loss: 0.5065
Batch 20, Loss: 0.4869
Batch 30, Loss: 0.5032
Batch 40, Loss: 0.5426
Batch 50, Loss: 0.5387
Batch 60, Loss: 0.5096
Batch 70, Loss: 0.5124
Batch 80, Loss: 0.5021
Batch 90, Loss: 0.4997
Batch 100, Loss: 0.4868
Batch 110, Loss: 0.5256
Batch 120, Loss: 0.5212
Batch 130, Loss: 0.5047
Batch 140, Loss: 0.4824
Batch 150, Loss: 0.5244
Batch 160, Loss: 0.5035
Batch 170, Loss: 0.4947
Batch 180, Loss: 0.5116
Batch 190, Loss: 0.4707
Batch 200, Loss: 0.4760
Batch 210, Loss: 0.4799
Batch 220, Loss: 0.5090
Batch 230, Loss: 0.4973
Batch 240, Loss: 0.4830
Batch 250, Loss: 0.5087
Batch 260, Loss: 0.4613
Batch 270, Loss: 0.5211
Batch 280, Loss: 0.5137
Batch 290, Loss: 0.5242
Batch 300, Loss: 0.4945
Batch 310, Loss: 0.4748
Batch 320, Loss: 0.4930
Batch 330, Loss: 0.4943
Batch 340, Loss: 0.5193
Batch 350, Loss: 0.5490
Batch 360, Loss: 0.4958
Batch 370, Loss: 0.4998
Batch 380, Loss: 0.4985
Batch 390, Loss: 0.4870
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.250779151916504 seconds
Epoch 69 accuracy: 86.58%
Batch 10, Loss: 0.4907
Batch 20, Loss: 0.5281
Batch 30, Loss: 0.4916
Batch 40, Loss: 0.4802
Batch 50, Loss: 0.5021
Batch 60, Loss: 0.4851
Batch 70, Loss: 0.4633
Batch 80, Loss: 0.4709
Batch 90, Loss: 0.4995
Batch 100, Loss: 0.4693
Batch 110, Loss: 0.4730
Batch 120, Loss: 0.5174
Batch 130, Loss: 0.5346
Batch 140, Loss: 0.4723
Batch 150, Loss: 0.5020
Batch 160, Loss: 0.5050
Batch 170, Loss: 0.5378
Batch 180, Loss: 0.5117
Batch 190, Loss: 0.5205
Batch 200, Loss: 0.4682
Batch 210, Loss: 0.4883
Batch 220, Loss: 0.4783
Batch 230, Loss: 0.4906
Batch 240, Loss: 0.4820
Batch 250, Loss: 0.5122
Batch 260, Loss: 0.5313
Batch 270, Loss: 0.5391
Batch 280, Loss: 0.5151
Batch 290, Loss: 0.4759
Batch 300, Loss: 0.5163
Batch 310, Loss: 0.4921
Batch 320, Loss: 0.5075
Batch 330, Loss: 0.4904
Batch 340, Loss: 0.5234
Batch 350, Loss: 0.5051
Batch 360, Loss: 0.5226
Batch 370, Loss: 0.4988
Batch 380, Loss: 0.4888
Batch 390, Loss: 0.4826
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.20889639854431 seconds
Epoch 70 accuracy: 86.48%
Batch 10, Loss: 0.4903
Batch 20, Loss: 0.5039
Batch 30, Loss: 0.5287
Batch 40, Loss: 0.5208
Batch 50, Loss: 0.5223
Batch 60, Loss: 0.5038
Batch 70, Loss: 0.4877
Batch 80, Loss: 0.4725
Batch 90, Loss: 0.4816
Batch 100, Loss: 0.4658
Batch 110, Loss: 0.5295
Batch 120, Loss: 0.5474
Batch 130, Loss: 0.5315
Batch 140, Loss: 0.4846
Batch 150, Loss: 0.4988
Batch 160, Loss: 0.5003
Batch 170, Loss: 0.4606
Batch 180, Loss: 0.5161
Batch 190, Loss: 0.4709
Batch 200, Loss: 0.4841
Batch 210, Loss: 0.4919
Batch 220, Loss: 0.5161
Batch 230, Loss: 0.4776
Batch 240, Loss: 0.4833
Batch 250, Loss: 0.4933
Batch 260, Loss: 0.5032
Batch 270, Loss: 0.5049
Batch 280, Loss: 0.4863
Batch 290, Loss: 0.5026
Batch 300, Loss: 0.4959
Batch 310, Loss: 0.5057
Batch 320, Loss: 0.5273
Batch 330, Loss: 0.4876
Batch 340, Loss: 0.4969
Batch 350, Loss: 0.5035
Batch 360, Loss: 0.4988
Batch 370, Loss: 0.4823
Batch 380, Loss: 0.4987
Batch 390, Loss: 0.5155
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.6467604637146 seconds
Epoch 71 accuracy: 85.13%
Batch 10, Loss: 0.4865
Batch 20, Loss: 0.5147
Batch 30, Loss: 0.5050
Batch 40, Loss: 0.5149
Batch 50, Loss: 0.4902
Batch 60, Loss: 0.4997
Batch 70, Loss: 0.5006
Batch 80, Loss: 0.5049
Batch 90, Loss: 0.4618
Batch 100, Loss: 0.4438
Batch 110, Loss: 0.5595
Batch 120, Loss: 0.5164
Batch 130, Loss: 0.5009
Batch 140, Loss: 0.4886
Batch 150, Loss: 0.4846
Batch 160, Loss: 0.4747
Batch 170, Loss: 0.5053
Batch 180, Loss: 0.4819
Batch 190, Loss: 0.4911
Batch 200, Loss: 0.4722
Batch 210, Loss: 0.5121
Batch 220, Loss: 0.5032
Batch 230, Loss: 0.4803
Batch 240, Loss: 0.5099
Batch 250, Loss: 0.5335
Batch 260, Loss: 0.4933
Batch 270, Loss: 0.5329
Batch 280, Loss: 0.5178
Batch 290, Loss: 0.4522
Batch 300, Loss: 0.4699
Batch 310, Loss: 0.4985
Batch 320, Loss: 0.4748
Batch 330, Loss: 0.4824
Batch 340, Loss: 0.5079
Batch 350, Loss: 0.5002
Batch 360, Loss: 0.4797
Batch 370, Loss: 0.4823
Batch 380, Loss: 0.4764
Batch 390, Loss: 0.5099
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.04266881942749 seconds
Epoch 72 accuracy: 85.95%
Batch 10, Loss: 0.5027
Batch 20, Loss: 0.4913
Batch 30, Loss: 0.5127
Batch 40, Loss: 0.5282
Batch 50, Loss: 0.5282
Batch 60, Loss: 0.4968
Batch 70, Loss: 0.4899
Batch 80, Loss: 0.4901
Batch 90, Loss: 0.4921
Batch 100, Loss: 0.5084
Batch 110, Loss: 0.4855
Batch 120, Loss: 0.4877
Batch 130, Loss: 0.5207
Batch 140, Loss: 0.5179
Batch 150, Loss: 0.5320
Batch 160, Loss: 0.4706
Batch 170, Loss: 0.4717
Batch 180, Loss: 0.4894
Batch 190, Loss: 0.4814
Batch 200, Loss: 0.4693
Batch 210, Loss: 0.5016
Batch 220, Loss: 0.5137
Batch 230, Loss: 0.4692
Batch 240, Loss: 0.5182
Batch 250, Loss: 0.4873
Batch 260, Loss: 0.5285
Batch 270, Loss: 0.5002
Batch 280, Loss: 0.4922
Batch 290, Loss: 0.5142
Batch 300, Loss: 0.5343
Batch 310, Loss: 0.5237
Batch 320, Loss: 0.4821
Batch 330, Loss: 0.4948
Batch 340, Loss: 0.5006
Batch 350, Loss: 0.4682
Batch 360, Loss: 0.4795
Batch 370, Loss: 0.4768
Batch 380, Loss: 0.5038
Batch 390, Loss: 0.4776
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.12515664100647 seconds
Epoch 73 accuracy: 84.74%
Batch 10, Loss: 0.4659
Batch 20, Loss: 0.4989
Batch 30, Loss: 0.4620
Batch 40, Loss: 0.4839
Batch 50, Loss: 0.4710
Batch 60, Loss: 0.4763
Batch 70, Loss: 0.4705
Batch 80, Loss: 0.5024
Batch 90, Loss: 0.5196
Batch 100, Loss: 0.4751
Batch 110, Loss: 0.4532
Batch 120, Loss: 0.4872
Batch 130, Loss: 0.5311
Batch 140, Loss: 0.4548
Batch 150, Loss: 0.5004
Batch 160, Loss: 0.5021
Batch 170, Loss: 0.4764
Batch 180, Loss: 0.4623
Batch 190, Loss: 0.4740
Batch 200, Loss: 0.4825
Batch 210, Loss: 0.4969
Batch 220, Loss: 0.5170
Batch 230, Loss: 0.5239
Batch 240, Loss: 0.5007
Batch 250, Loss: 0.4945
Batch 260, Loss: 0.5249
Batch 270, Loss: 0.5285
Batch 280, Loss: 0.4844
Batch 290, Loss: 0.5063
Batch 300, Loss: 0.4798
Batch 310, Loss: 0.5155
Batch 320, Loss: 0.5190
Batch 330, Loss: 0.4869
Batch 340, Loss: 0.4722
Batch 350, Loss: 0.5091
Batch 360, Loss: 0.5014
Batch 370, Loss: 0.4928
Batch 380, Loss: 0.4783
Batch 390, Loss: 0.4843
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.07690143585205 seconds
Epoch 74 accuracy: 83.97%
Batch 10, Loss: 0.4707
Batch 20, Loss: 0.4813
Batch 30, Loss: 0.4945
Batch 40, Loss: 0.4489
Batch 50, Loss: 0.4916
Batch 60, Loss: 0.4998
Batch 70, Loss: 0.4986
Batch 80, Loss: 0.4843
Batch 90, Loss: 0.5446
Batch 100, Loss: 0.4766
Batch 110, Loss: 0.4933
Batch 120, Loss: 0.5074
Batch 130, Loss: 0.5053
Batch 140, Loss: 0.4934
Batch 150, Loss: 0.4786
Batch 160, Loss: 0.4670
Batch 170, Loss: 0.5062
Batch 180, Loss: 0.5073
Batch 190, Loss: 0.4993
Batch 200, Loss: 0.5480
Batch 210, Loss: 0.5025
Batch 220, Loss: 0.5034
Batch 230, Loss: 0.4862
Batch 240, Loss: 0.4549
Batch 250, Loss: 0.4671
Batch 260, Loss: 0.4844
Batch 270, Loss: 0.5199
Batch 280, Loss: 0.4845
Batch 290, Loss: 0.4871
Batch 300, Loss: 0.5101
Batch 310, Loss: 0.5290
Batch 320, Loss: 0.4935
Batch 330, Loss: 0.5092
Batch 340, Loss: 0.5021
Batch 350, Loss: 0.4926
Batch 360, Loss: 0.4922
Batch 370, Loss: 0.5164
Batch 380, Loss: 0.5134
Batch 390, Loss: 0.4652
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.10717010498047 seconds
Epoch 75 accuracy: 86.58%
Batch 10, Loss: 0.5027
Batch 20, Loss: 0.4711
Batch 30, Loss: 0.5069
Batch 40, Loss: 0.5000
Batch 50, Loss: 0.4901
Batch 60, Loss: 0.5114
Batch 70, Loss: 0.4613
Batch 80, Loss: 0.4625
Batch 90, Loss: 0.4771
Batch 100, Loss: 0.4674
Batch 110, Loss: 0.4979
Batch 120, Loss: 0.4924
Batch 130, Loss: 0.4571
Batch 140, Loss: 0.4931
Batch 150, Loss: 0.5003
Batch 160, Loss: 0.4614
Batch 170, Loss: 0.5107
Batch 180, Loss: 0.4900
Batch 190, Loss: 0.5493
Batch 200, Loss: 0.5043
Batch 210, Loss: 0.4682
Batch 220, Loss: 0.5517
Batch 230, Loss: 0.4993
Batch 240, Loss: 0.4753
Batch 250, Loss: 0.4689
Batch 260, Loss: 0.4571
Batch 270, Loss: 0.4691
Batch 280, Loss: 0.4517
Batch 290, Loss: 0.4963
Batch 300, Loss: 0.4586
Batch 310, Loss: 0.4606
Batch 320, Loss: 0.4941
Batch 330, Loss: 0.5034
Batch 340, Loss: 0.4455
Batch 350, Loss: 0.4843
Batch 360, Loss: 0.4946
Batch 370, Loss: 0.4885
Batch 380, Loss: 0.4966
Batch 390, Loss: 0.5109
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.13256573677063 seconds
Epoch 76 accuracy: 86.22%
Batch 10, Loss: 0.4539
Batch 20, Loss: 0.4669
Batch 30, Loss: 0.4911
Batch 40, Loss: 0.5010
Batch 50, Loss: 0.4607
Batch 60, Loss: 0.4685
Batch 70, Loss: 0.4683
Batch 80, Loss: 0.5068
Batch 90, Loss: 0.4578
Batch 100, Loss: 0.5092
Batch 110, Loss: 0.5011
Batch 120, Loss: 0.5127
Batch 130, Loss: 0.4677
Batch 140, Loss: 0.4888
Batch 150, Loss: 0.4819
Batch 160, Loss: 0.5335
Batch 170, Loss: 0.4779
Batch 180, Loss: 0.4729
Batch 190, Loss: 0.4944
Batch 200, Loss: 0.5012
Batch 210, Loss: 0.5256
Batch 220, Loss: 0.5066
Batch 230, Loss: 0.4887
Batch 240, Loss: 0.4846
Batch 250, Loss: 0.4555
Batch 260, Loss: 0.4896
Batch 270, Loss: 0.4998
Batch 280, Loss: 0.4741
Batch 290, Loss: 0.5053
Batch 300, Loss: 0.5164
Batch 310, Loss: 0.4820
Batch 320, Loss: 0.4924
Batch 330, Loss: 0.4507
Batch 340, Loss: 0.4996
Batch 350, Loss: 0.4402
Batch 360, Loss: 0.5069
Batch 370, Loss: 0.4941
Batch 380, Loss: 0.5036
Batch 390, Loss: 0.4985
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.061359405517578 seconds
Epoch 77 accuracy: 84.8%
Batch 10, Loss: 0.4737
Batch 20, Loss: 0.5014
Batch 30, Loss: 0.5142
Batch 40, Loss: 0.5038
Batch 50, Loss: 0.4907
Batch 60, Loss: 0.4966
Batch 70, Loss: 0.4632
Batch 80, Loss: 0.4679
Batch 90, Loss: 0.5033
Batch 100, Loss: 0.4640
Batch 110, Loss: 0.4899
Batch 120, Loss: 0.4369
Batch 130, Loss: 0.4935
Batch 140, Loss: 0.5039
Batch 150, Loss: 0.4889
Batch 160, Loss: 0.5014
Batch 170, Loss: 0.4911
Batch 180, Loss: 0.5235
Batch 190, Loss: 0.4526
Batch 200, Loss: 0.5110
Batch 210, Loss: 0.5013
Batch 220, Loss: 0.4813
Batch 230, Loss: 0.4939
Batch 240, Loss: 0.5165
Batch 250, Loss: 0.4513
Batch 260, Loss: 0.4832
Batch 270, Loss: 0.4908
Batch 280, Loss: 0.4801
Batch 290, Loss: 0.5043
Batch 300, Loss: 0.4926
Batch 310, Loss: 0.5227
Batch 320, Loss: 0.4995
Batch 330, Loss: 0.4773
Batch 340, Loss: 0.4632
Batch 350, Loss: 0.4778
Batch 360, Loss: 0.5282
Batch 370, Loss: 0.4624
Batch 380, Loss: 0.5092
Batch 390, Loss: 0.4546
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.12298822402954 seconds
Epoch 78 accuracy: 85.02%
Batch 10, Loss: 0.5024
Batch 20, Loss: 0.5053
Batch 30, Loss: 0.4802
Batch 40, Loss: 0.5067
Batch 50, Loss: 0.4852
Batch 60, Loss: 0.4472
Batch 70, Loss: 0.5276
Batch 80, Loss: 0.5333
Batch 90, Loss: 0.5063
Batch 100, Loss: 0.4576
Batch 110, Loss: 0.4697
Batch 120, Loss: 0.4940
Batch 130, Loss: 0.4397
Batch 140, Loss: 0.4743
Batch 150, Loss: 0.4953
Batch 160, Loss: 0.5002
Batch 170, Loss: 0.4983
Batch 180, Loss: 0.5153
Batch 190, Loss: 0.4696
Batch 200, Loss: 0.4835
Batch 210, Loss: 0.4731
Batch 220, Loss: 0.4757
Batch 230, Loss: 0.4572
Batch 240, Loss: 0.5339
Batch 250, Loss: 0.4547
Batch 260, Loss: 0.5094
Batch 270, Loss: 0.4992
Batch 280, Loss: 0.4793
Batch 290, Loss: 0.4409
Batch 300, Loss: 0.5118
Batch 310, Loss: 0.5164
Batch 320, Loss: 0.5088
Batch 330, Loss: 0.4862
Batch 340, Loss: 0.4839
Batch 350, Loss: 0.5038
Batch 360, Loss: 0.4435
Batch 370, Loss: 0.5111
Batch 380, Loss: 0.4740
Batch 390, Loss: 0.4585
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.21859121322632 seconds
Epoch 79 accuracy: 84.84%
Batch 10, Loss: 0.4667
Batch 20, Loss: 0.4913
Batch 30, Loss: 0.4824
Batch 40, Loss: 0.4573
Batch 50, Loss: 0.4820
Batch 60, Loss: 0.4485
Batch 70, Loss: 0.4708
Batch 80, Loss: 0.4975
Batch 90, Loss: 0.4772
Batch 100, Loss: 0.4707
Batch 110, Loss: 0.4649
Batch 120, Loss: 0.4548
Batch 130, Loss: 0.4901
Batch 140, Loss: 0.5269
Batch 150, Loss: 0.4898
Batch 160, Loss: 0.4728
Batch 170, Loss: 0.4693
Batch 180, Loss: 0.4662
Batch 190, Loss: 0.4763
Batch 200, Loss: 0.4395
Batch 210, Loss: 0.5173
Batch 220, Loss: 0.4668
Batch 230, Loss: 0.4716
Batch 240, Loss: 0.5012
Batch 250, Loss: 0.5000
Batch 260, Loss: 0.4974
Batch 270, Loss: 0.4927
Batch 280, Loss: 0.4918
Batch 290, Loss: 0.4873
Batch 300, Loss: 0.5110
Batch 310, Loss: 0.5233
Batch 320, Loss: 0.4835
Batch 330, Loss: 0.4759
Batch 340, Loss: 0.4780
Batch 350, Loss: 0.4787
Batch 360, Loss: 0.4557
Batch 370, Loss: 0.4710
Batch 380, Loss: 0.4529
Batch 390, Loss: 0.4494
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.06019425392151 seconds
Epoch 80 accuracy: 88.21%
Batch 10, Loss: 0.4897
Batch 20, Loss: 0.5176
Batch 30, Loss: 0.4798
Batch 40, Loss: 0.4942
Batch 50, Loss: 0.4876
Batch 60, Loss: 0.4903
Batch 70, Loss: 0.4900
Batch 80, Loss: 0.4700
Batch 90, Loss: 0.4808
Batch 100, Loss: 0.4817
Batch 110, Loss: 0.4858
Batch 120, Loss: 0.5104
Batch 130, Loss: 0.4795
Batch 140, Loss: 0.4625
Batch 150, Loss: 0.4595
Batch 160, Loss: 0.4474
Batch 170, Loss: 0.4846
Batch 180, Loss: 0.4716
Batch 190, Loss: 0.4742
Batch 200, Loss: 0.5245
Batch 210, Loss: 0.4871
Batch 220, Loss: 0.4836
Batch 230, Loss: 0.4788
Batch 240, Loss: 0.4840
Batch 250, Loss: 0.4857
Batch 260, Loss: 0.4754
Batch 270, Loss: 0.5037
Batch 280, Loss: 0.5097
Batch 290, Loss: 0.5202
Batch 300, Loss: 0.4830
Batch 310, Loss: 0.4857
Batch 320, Loss: 0.4275
Batch 330, Loss: 0.4342
Batch 340, Loss: 0.4914
Batch 350, Loss: 0.4696
Batch 360, Loss: 0.4834
Batch 370, Loss: 0.5048
Batch 380, Loss: 0.4447
Batch 390, Loss: 0.5145
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.12501096725464 seconds
Epoch 81 accuracy: 86.4%
Batch 10, Loss: 0.4762
Batch 20, Loss: 0.4694
Batch 30, Loss: 0.4313
Batch 40, Loss: 0.4720
Batch 50, Loss: 0.4560
Batch 60, Loss: 0.4588
Batch 70, Loss: 0.4637
Batch 80, Loss: 0.4431
Batch 90, Loss: 0.4635
Batch 100, Loss: 0.4965
Batch 110, Loss: 0.4893
Batch 120, Loss: 0.5031
Batch 130, Loss: 0.4747
Batch 140, Loss: 0.4665
Batch 150, Loss: 0.4698
Batch 160, Loss: 0.4392
Batch 170, Loss: 0.5019
Batch 180, Loss: 0.5107
Batch 190, Loss: 0.4938
Batch 200, Loss: 0.4521
Batch 210, Loss: 0.4632
Batch 220, Loss: 0.4692
Batch 230, Loss: 0.4877
Batch 240, Loss: 0.4822
Batch 250, Loss: 0.4898
Batch 260, Loss: 0.4798
Batch 270, Loss: 0.4801
Batch 280, Loss: 0.4841
Batch 290, Loss: 0.5062
Batch 300, Loss: 0.4775
Batch 310, Loss: 0.4771
Batch 320, Loss: 0.4872
Batch 330, Loss: 0.4614
Batch 340, Loss: 0.4773
Batch 350, Loss: 0.5011
Batch 360, Loss: 0.4813
Batch 370, Loss: 0.4708
Batch 380, Loss: 0.4598
Batch 390, Loss: 0.4931
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.065924882888794 seconds
Epoch 82 accuracy: 88.05%
Batch 10, Loss: 0.4908
Batch 20, Loss: 0.5089
Batch 30, Loss: 0.4835
Batch 40, Loss: 0.4493
Batch 50, Loss: 0.4251
Batch 60, Loss: 0.4533
Batch 70, Loss: 0.4316
Batch 80, Loss: 0.4430
Batch 90, Loss: 0.4090
Batch 100, Loss: 0.4685
Batch 110, Loss: 0.5023
Batch 120, Loss: 0.4384
Batch 130, Loss: 0.4709
Batch 140, Loss: 0.4627
Batch 150, Loss: 0.4581
Batch 160, Loss: 0.4485
Batch 170, Loss: 0.4802
Batch 180, Loss: 0.4915
Batch 190, Loss: 0.4936
Batch 200, Loss: 0.4137
Batch 210, Loss: 0.5010
Batch 220, Loss: 0.4982
Batch 230, Loss: 0.5068
Batch 240, Loss: 0.5169
Batch 250, Loss: 0.4533
Batch 260, Loss: 0.4734
Batch 270, Loss: 0.4398
Batch 280, Loss: 0.4891
Batch 290, Loss: 0.4712
Batch 300, Loss: 0.4426
Batch 310, Loss: 0.4628
Batch 320, Loss: 0.4634
Batch 330, Loss: 0.4728
Batch 340, Loss: 0.4823
Batch 350, Loss: 0.5046
Batch 360, Loss: 0.4682
Batch 370, Loss: 0.4882
Batch 380, Loss: 0.4573
Batch 390, Loss: 0.4633
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.065419912338257 seconds
Epoch 83 accuracy: 84.66%
Batch 10, Loss: 0.4195
Batch 20, Loss: 0.4769
Batch 30, Loss: 0.4724
Batch 40, Loss: 0.4867
Batch 50, Loss: 0.4470
Batch 60, Loss: 0.4804
Batch 70, Loss: 0.4665
Batch 80, Loss: 0.4926
Batch 90, Loss: 0.4831
Batch 100, Loss: 0.4527
Batch 110, Loss: 0.5000
Batch 120, Loss: 0.4560
Batch 130, Loss: 0.4561
Batch 140, Loss: 0.4755
Batch 150, Loss: 0.5001
Batch 160, Loss: 0.5040
Batch 170, Loss: 0.4969
Batch 180, Loss: 0.4616
Batch 190, Loss: 0.5080
Batch 200, Loss: 0.4853
Batch 210, Loss: 0.4383
Batch 220, Loss: 0.4768
Batch 230, Loss: 0.4526
Batch 240, Loss: 0.4898
Batch 250, Loss: 0.4736
Batch 260, Loss: 0.4425
Batch 270, Loss: 0.4614
Batch 280, Loss: 0.4630
Batch 290, Loss: 0.4464
Batch 300, Loss: 0.4705
Batch 310, Loss: 0.4766
Batch 320, Loss: 0.4844
Batch 330, Loss: 0.4903
Batch 340, Loss: 0.4630
Batch 350, Loss: 0.5013
Batch 360, Loss: 0.5042
Batch 370, Loss: 0.4857
Batch 380, Loss: 0.4976
Batch 390, Loss: 0.4841
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.06791639328003 seconds
Epoch 84 accuracy: 85.21%
Batch 10, Loss: 0.4721
Batch 20, Loss: 0.4740
Batch 30, Loss: 0.4951
Batch 40, Loss: 0.4373
Batch 50, Loss: 0.4710
Batch 60, Loss: 0.4730
Batch 70, Loss: 0.4962
Batch 80, Loss: 0.4452
Batch 90, Loss: 0.4515
Batch 100, Loss: 0.4910
Batch 110, Loss: 0.4618
Batch 120, Loss: 0.4377
Batch 130, Loss: 0.4813
Batch 140, Loss: 0.4880
Batch 150, Loss: 0.4541
Batch 160, Loss: 0.4553
Batch 170, Loss: 0.4459
Batch 180, Loss: 0.4402
Batch 190, Loss: 0.4833
Batch 200, Loss: 0.4879
Batch 210, Loss: 0.4854
Batch 220, Loss: 0.4824
Batch 230, Loss: 0.4548
Batch 240, Loss: 0.4404
Batch 250, Loss: 0.4810
Batch 260, Loss: 0.4670
Batch 270, Loss: 0.4682
Batch 280, Loss: 0.4889
Batch 290, Loss: 0.5072
Batch 300, Loss: 0.4874
Batch 310, Loss: 0.5039
Batch 320, Loss: 0.4773
Batch 330, Loss: 0.4697
Batch 340, Loss: 0.4677
Batch 350, Loss: 0.4228
Batch 360, Loss: 0.4531
Batch 370, Loss: 0.4510
Batch 380, Loss: 0.4989
Batch 390, Loss: 0.4866
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.19840168952942 seconds
Epoch 85 accuracy: 86.93%
Batch 10, Loss: 0.4203
Batch 20, Loss: 0.4123
Batch 30, Loss: 0.4418
Batch 40, Loss: 0.4431
Batch 50, Loss: 0.4683
Batch 60, Loss: 0.4491
Batch 70, Loss: 0.4358
Batch 80, Loss: 0.4225
Batch 90, Loss: 0.4401
Batch 100, Loss: 0.4786
Batch 110, Loss: 0.4610
Batch 120, Loss: 0.4615
Batch 130, Loss: 0.5080
Batch 140, Loss: 0.4677
Batch 150, Loss: 0.4581
Batch 160, Loss: 0.4640
Batch 170, Loss: 0.4769
Batch 180, Loss: 0.4920
Batch 190, Loss: 0.4587
Batch 200, Loss: 0.4741
Batch 210, Loss: 0.4814
Batch 220, Loss: 0.5069
Batch 230, Loss: 0.4990
Batch 240, Loss: 0.4624
Batch 250, Loss: 0.4897
Batch 260, Loss: 0.4241
Batch 270, Loss: 0.4317
Batch 280, Loss: 0.4743
Batch 290, Loss: 0.4534
Batch 300, Loss: 0.4812
Batch 310, Loss: 0.4760
Batch 320, Loss: 0.4725
Batch 330, Loss: 0.4736
Batch 340, Loss: 0.4829
Batch 350, Loss: 0.4456
Batch 360, Loss: 0.4947
Batch 370, Loss: 0.4712
Batch 380, Loss: 0.5089
Batch 390, Loss: 0.4987
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.15211296081543 seconds
Epoch 86 accuracy: 85.9%
Batch 10, Loss: 0.4596
Batch 20, Loss: 0.4424
Batch 30, Loss: 0.4748
Batch 40, Loss: 0.4765
Batch 50, Loss: 0.4896
Batch 60, Loss: 0.4676
Batch 70, Loss: 0.4463
Batch 80, Loss: 0.4915
Batch 90, Loss: 0.4383
Batch 100, Loss: 0.4671
Batch 110, Loss: 0.4320
Batch 120, Loss: 0.4365
Batch 130, Loss: 0.4524
Batch 140, Loss: 0.4739
Batch 150, Loss: 0.4482
Batch 160, Loss: 0.4498
Batch 170, Loss: 0.4564
Batch 180, Loss: 0.4549
Batch 190, Loss: 0.4513
Batch 200, Loss: 0.4563
Batch 210, Loss: 0.4599
Batch 220, Loss: 0.4497
Batch 230, Loss: 0.4686
Batch 240, Loss: 0.4921
Batch 250, Loss: 0.4757
Batch 260, Loss: 0.4715
Batch 270, Loss: 0.4391
Batch 280, Loss: 0.4154
Batch 290, Loss: 0.4878
Batch 300, Loss: 0.4850
Batch 310, Loss: 0.4562
Batch 320, Loss: 0.4613
Batch 330, Loss: 0.5152
Batch 340, Loss: 0.4752
Batch 350, Loss: 0.5350
Batch 360, Loss: 0.4795
Batch 370, Loss: 0.4647
Batch 380, Loss: 0.4752
Batch 390, Loss: 0.4744
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.210289239883423 seconds
Epoch 87 accuracy: 88.6%
Batch 10, Loss: 0.4289
Batch 20, Loss: 0.4632
Batch 30, Loss: 0.4774
Batch 40, Loss: 0.4745
Batch 50, Loss: 0.4555
Batch 60, Loss: 0.4655
Batch 70, Loss: 0.4590
Batch 80, Loss: 0.4453
Batch 90, Loss: 0.4425
Batch 100, Loss: 0.4519
Batch 110, Loss: 0.4587
Batch 120, Loss: 0.4482
Batch 130, Loss: 0.4745
Batch 140, Loss: 0.4600
Batch 150, Loss: 0.4708
Batch 160, Loss: 0.4557
Batch 170, Loss: 0.4820
Batch 180, Loss: 0.4323
Batch 190, Loss: 0.4484
Batch 200, Loss: 0.4435
Batch 210, Loss: 0.4343
Batch 220, Loss: 0.4939
Batch 230, Loss: 0.4449
Batch 240, Loss: 0.4200
Batch 250, Loss: 0.4573
Batch 260, Loss: 0.4864
Batch 270, Loss: 0.5353
Batch 280, Loss: 0.5044
Batch 290, Loss: 0.4640
Batch 300, Loss: 0.4490
Batch 310, Loss: 0.4725
Batch 320, Loss: 0.4358
Batch 330, Loss: 0.4610
Batch 340, Loss: 0.4466
Batch 350, Loss: 0.4339
Batch 360, Loss: 0.4581
Batch 370, Loss: 0.4987
Batch 380, Loss: 0.4533
Batch 390, Loss: 0.4669
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.206140518188477 seconds
Epoch 88 accuracy: 82.74%
Batch 10, Loss: 0.4542
Batch 20, Loss: 0.4180
Batch 30, Loss: 0.4576
Batch 40, Loss: 0.4118
Batch 50, Loss: 0.4691
Batch 60, Loss: 0.4293
Batch 70, Loss: 0.4826
Batch 80, Loss: 0.4606
Batch 90, Loss: 0.4783
Batch 100, Loss: 0.4795
Batch 110, Loss: 0.4249
Batch 120, Loss: 0.4521
Batch 130, Loss: 0.4412
Batch 140, Loss: 0.4538
Batch 150, Loss: 0.4452
Batch 160, Loss: 0.4555
Batch 170, Loss: 0.4495
Batch 180, Loss: 0.4512
Batch 190, Loss: 0.4814
Batch 200, Loss: 0.4836
Batch 210, Loss: 0.4548
Batch 220, Loss: 0.4912
Batch 230, Loss: 0.4585
Batch 240, Loss: 0.4715
Batch 250, Loss: 0.4486
Batch 260, Loss: 0.4811
Batch 270, Loss: 0.4657
Batch 280, Loss: 0.4901
Batch 290, Loss: 0.4497
Batch 300, Loss: 0.4386
Batch 310, Loss: 0.4569
Batch 320, Loss: 0.4953
Batch 330, Loss: 0.4769
Batch 340, Loss: 0.4563
Batch 350, Loss: 0.4850
Batch 360, Loss: 0.4605
Batch 370, Loss: 0.4506
Batch 380, Loss: 0.4603
Batch 390, Loss: 0.5065
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.111913204193115 seconds
Epoch 89 accuracy: 86.69%
Batch 10, Loss: 0.4700
Batch 20, Loss: 0.4560
Batch 30, Loss: 0.4665
Batch 40, Loss: 0.4419
Batch 50, Loss: 0.4430
Batch 60, Loss: 0.4622
Batch 70, Loss: 0.4108
Batch 80, Loss: 0.4245
Batch 90, Loss: 0.4357
Batch 100, Loss: 0.4566
Batch 110, Loss: 0.4818
Batch 120, Loss: 0.4568
Batch 130, Loss: 0.4564
Batch 140, Loss: 0.4601
Batch 150, Loss: 0.4413
Batch 160, Loss: 0.4717
Batch 170, Loss: 0.4919
Batch 180, Loss: 0.4969
Batch 190, Loss: 0.4453
Batch 200, Loss: 0.4426
Batch 210, Loss: 0.4705
Batch 220, Loss: 0.4551
Batch 230, Loss: 0.4040
Batch 240, Loss: 0.4606
Batch 250, Loss: 0.4827
Batch 260, Loss: 0.4347
Batch 270, Loss: 0.4458
Batch 280, Loss: 0.4885
Batch 290, Loss: 0.4435
Batch 300, Loss: 0.4853
Batch 310, Loss: 0.4669
Batch 320, Loss: 0.4308
Batch 330, Loss: 0.4440
Batch 340, Loss: 0.4316
Batch 350, Loss: 0.4474
Batch 360, Loss: 0.4718
Batch 370, Loss: 0.4741
Batch 380, Loss: 0.4506
Batch 390, Loss: 0.4694
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.158909559249878 seconds
Epoch 90 accuracy: 87.62%
Batch 10, Loss: 0.4571
Batch 20, Loss: 0.4151
Batch 30, Loss: 0.4660
Batch 40, Loss: 0.4157
Batch 50, Loss: 0.4663
Batch 60, Loss: 0.4694
Batch 70, Loss: 0.4535
Batch 80, Loss: 0.4407
Batch 90, Loss: 0.4531
Batch 100, Loss: 0.4423
Batch 110, Loss: 0.4103
Batch 120, Loss: 0.4860
Batch 130, Loss: 0.4947
Batch 140, Loss: 0.4755
Batch 150, Loss: 0.4410
Batch 160, Loss: 0.4592
Batch 170, Loss: 0.4707
Batch 180, Loss: 0.4553
Batch 190, Loss: 0.4525
Batch 200, Loss: 0.4397
Batch 210, Loss: 0.4584
Batch 220, Loss: 0.4398
Batch 230, Loss: 0.4629
Batch 240, Loss: 0.4904
Batch 250, Loss: 0.4360
Batch 260, Loss: 0.4514
Batch 270, Loss: 0.4464
Batch 280, Loss: 0.4794
Batch 290, Loss: 0.4690
Batch 300, Loss: 0.4468
Batch 310, Loss: 0.4481
Batch 320, Loss: 0.4471
Batch 330, Loss: 0.4353
Batch 340, Loss: 0.4732
Batch 350, Loss: 0.4556
Batch 360, Loss: 0.4567
Batch 370, Loss: 0.4800
Batch 380, Loss: 0.4331
Batch 390, Loss: 0.4631
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.05602717399597 seconds
Epoch 91 accuracy: 85.9%
Batch 10, Loss: 0.4490
Batch 20, Loss: 0.4534
Batch 30, Loss: 0.4624
Batch 40, Loss: 0.4753
Batch 50, Loss: 0.4679
Batch 60, Loss: 0.4579
Batch 70, Loss: 0.4267
Batch 80, Loss: 0.4180
Batch 90, Loss: 0.4303
Batch 100, Loss: 0.4191
Batch 110, Loss: 0.4614
Batch 120, Loss: 0.4606
Batch 130, Loss: 0.4344
Batch 140, Loss: 0.4669
Batch 150, Loss: 0.4751
Batch 160, Loss: 0.4188
Batch 170, Loss: 0.4804
Batch 180, Loss: 0.4644
Batch 190, Loss: 0.4327
Batch 200, Loss: 0.4284
Batch 210, Loss: 0.4180
Batch 220, Loss: 0.4239
Batch 230, Loss: 0.4437
Batch 240, Loss: 0.4725
Batch 250, Loss: 0.4883
Batch 260, Loss: 0.4726
Batch 270, Loss: 0.4388
Batch 280, Loss: 0.4383
Batch 290, Loss: 0.4404
Batch 300, Loss: 0.4683
Batch 310, Loss: 0.4540
Batch 320, Loss: 0.4624
Batch 330, Loss: 0.4335
Batch 340, Loss: 0.4531
Batch 350, Loss: 0.4757
Batch 360, Loss: 0.4810
Batch 370, Loss: 0.4870
Batch 380, Loss: 0.4650
Batch 390, Loss: 0.4518
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.03247046470642 seconds
Epoch 92 accuracy: 87.73%
Batch 10, Loss: 0.4626
Batch 20, Loss: 0.4334
Batch 30, Loss: 0.4385
Batch 40, Loss: 0.4473
Batch 50, Loss: 0.4602
Batch 60, Loss: 0.4910
Batch 70, Loss: 0.4274
Batch 80, Loss: 0.4284
Batch 90, Loss: 0.4287
Batch 100, Loss: 0.4221
Batch 110, Loss: 0.4889
Batch 120, Loss: 0.4762
Batch 130, Loss: 0.5124
Batch 140, Loss: 0.4604
Batch 150, Loss: 0.4535
Batch 160, Loss: 0.4561
Batch 170, Loss: 0.4197
Batch 180, Loss: 0.4766
Batch 190, Loss: 0.4819
Batch 200, Loss: 0.4727
Batch 210, Loss: 0.4255
Batch 220, Loss: 0.4312
Batch 230, Loss: 0.4327
Batch 240, Loss: 0.4518
Batch 250, Loss: 0.4569
Batch 260, Loss: 0.4426
Batch 270, Loss: 0.4625
Batch 280, Loss: 0.4894
Batch 290, Loss: 0.4605
Batch 300, Loss: 0.4236
Batch 310, Loss: 0.4746
Batch 320, Loss: 0.4334
Batch 330, Loss: 0.4948
Batch 340, Loss: 0.4511
Batch 350, Loss: 0.5017
Batch 360, Loss: 0.4372
Batch 370, Loss: 0.4601
Batch 380, Loss: 0.4518
Batch 390, Loss: 0.5062
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.108586072921753 seconds
Epoch 93 accuracy: 82.51%
Batch 10, Loss: 0.4837
Batch 20, Loss: 0.4240
Batch 30, Loss: 0.4087
Batch 40, Loss: 0.4382
Batch 50, Loss: 0.4524
Batch 60, Loss: 0.4305
Batch 70, Loss: 0.4501
Batch 80, Loss: 0.4332
Batch 90, Loss: 0.4361
Batch 100, Loss: 0.4802
Batch 110, Loss: 0.4411
Batch 120, Loss: 0.4646
Batch 130, Loss: 0.4256
Batch 140, Loss: 0.4614
Batch 150, Loss: 0.4520
Batch 160, Loss: 0.4544
Batch 170, Loss: 0.4842
Batch 180, Loss: 0.4499
Batch 190, Loss: 0.4342
Batch 200, Loss: 0.4555
Batch 210, Loss: 0.4515
Batch 220, Loss: 0.4366
Batch 230, Loss: 0.4456
Batch 240, Loss: 0.5094
Batch 250, Loss: 0.4959
Batch 260, Loss: 0.4711
Batch 270, Loss: 0.4425
Batch 280, Loss: 0.4441
Batch 290, Loss: 0.4633
Batch 300, Loss: 0.5102
Batch 310, Loss: 0.4533
Batch 320, Loss: 0.4580
Batch 330, Loss: 0.4223
Batch 340, Loss: 0.4425
Batch 350, Loss: 0.4595
Batch 360, Loss: 0.4758
Batch 370, Loss: 0.4634
Batch 380, Loss: 0.4259
Batch 390, Loss: 0.4451
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.04767656326294 seconds
Epoch 94 accuracy: 83.77%
Batch 10, Loss: 0.4318
Batch 20, Loss: 0.4356
Batch 30, Loss: 0.4503
Batch 40, Loss: 0.4527
Batch 50, Loss: 0.4384
Batch 60, Loss: 0.3975
Batch 70, Loss: 0.4240
Batch 80, Loss: 0.4446
Batch 90, Loss: 0.4358
Batch 100, Loss: 0.4481
Batch 110, Loss: 0.4205
Batch 120, Loss: 0.4341
Batch 130, Loss: 0.4519
Batch 140, Loss: 0.4333
Batch 150, Loss: 0.4311
Batch 160, Loss: 0.4647
Batch 170, Loss: 0.4646
Batch 180, Loss: 0.4366
Batch 190, Loss: 0.4468
Batch 200, Loss: 0.4090
Batch 210, Loss: 0.4403
Batch 220, Loss: 0.4240
Batch 230, Loss: 0.4434
Batch 240, Loss: 0.4644
Batch 250, Loss: 0.4577
Batch 260, Loss: 0.4227
Batch 270, Loss: 0.4341
Batch 280, Loss: 0.4696
Batch 290, Loss: 0.4493
Batch 300, Loss: 0.4513
Batch 310, Loss: 0.4416
Batch 320, Loss: 0.4634
Batch 330, Loss: 0.4906
Batch 340, Loss: 0.4471
Batch 350, Loss: 0.5035
Batch 360, Loss: 0.4122
Batch 370, Loss: 0.5069
Batch 380, Loss: 0.4539
Batch 390, Loss: 0.4310
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.061819314956665 seconds
Epoch 95 accuracy: 86.2%
Batch 10, Loss: 0.4112
Batch 20, Loss: 0.4163
Batch 30, Loss: 0.4467
Batch 40, Loss: 0.4428
Batch 50, Loss: 0.4507
Batch 60, Loss: 0.4067
Batch 70, Loss: 0.4260
Batch 80, Loss: 0.4342
Batch 90, Loss: 0.4423
Batch 100, Loss: 0.4264
Batch 110, Loss: 0.4612
Batch 120, Loss: 0.4417
Batch 130, Loss: 0.4480
Batch 140, Loss: 0.4013
Batch 150, Loss: 0.4375
Batch 160, Loss: 0.4382
Batch 170, Loss: 0.4269
Batch 180, Loss: 0.4197
Batch 190, Loss: 0.4461
Batch 200, Loss: 0.4665
Batch 210, Loss: 0.4606
Batch 220, Loss: 0.4588
Batch 230, Loss: 0.4677
Batch 240, Loss: 0.4428
Batch 250, Loss: 0.4578
Batch 260, Loss: 0.4881
Batch 270, Loss: 0.4622
Batch 280, Loss: 0.4694
Batch 290, Loss: 0.4061
Batch 300, Loss: 0.4336
Batch 310, Loss: 0.4724
Batch 320, Loss: 0.4793
Batch 330, Loss: 0.4409
Batch 340, Loss: 0.4698
Batch 350, Loss: 0.4716
Batch 360, Loss: 0.4700
Batch 370, Loss: 0.4460
Batch 380, Loss: 0.4697
Batch 390, Loss: 0.4447
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.33007025718689 seconds
Epoch 96 accuracy: 87.15%
Batch 10, Loss: 0.4457
Batch 20, Loss: 0.4336
Batch 30, Loss: 0.4057
Batch 40, Loss: 0.4176
Batch 50, Loss: 0.4158
Batch 60, Loss: 0.4315
Batch 70, Loss: 0.4842
Batch 80, Loss: 0.4462
Batch 90, Loss: 0.4100
Batch 100, Loss: 0.4392
Batch 110, Loss: 0.4633
Batch 120, Loss: 0.4501
Batch 130, Loss: 0.4201
Batch 140, Loss: 0.4259
Batch 150, Loss: 0.4561
Batch 160, Loss: 0.4099
Batch 170, Loss: 0.4334
Batch 180, Loss: 0.4118
Batch 190, Loss: 0.4264
Batch 200, Loss: 0.4591
Batch 210, Loss: 0.3772
Batch 220, Loss: 0.4203
Batch 230, Loss: 0.4548
Batch 240, Loss: 0.4587
Batch 250, Loss: 0.4356
Batch 260, Loss: 0.4563
Batch 270, Loss: 0.4229
Batch 280, Loss: 0.4512
Batch 290, Loss: 0.4346
Batch 300, Loss: 0.4352
Batch 310, Loss: 0.4420
Batch 320, Loss: 0.4381
Batch 330, Loss: 0.4337
Batch 340, Loss: 0.4646
Batch 350, Loss: 0.4662
Batch 360, Loss: 0.4530
Batch 370, Loss: 0.4498
Batch 380, Loss: 0.4156
Batch 390, Loss: 0.4503
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.1232750415802 seconds
Epoch 97 accuracy: 88.56%
Batch 10, Loss: 0.4265
Batch 20, Loss: 0.4706
Batch 30, Loss: 0.4692
Batch 40, Loss: 0.4804
Batch 50, Loss: 0.3931
Batch 60, Loss: 0.4448
Batch 70, Loss: 0.4182
Batch 80, Loss: 0.4350
Batch 90, Loss: 0.4289
Batch 100, Loss: 0.4321
Batch 110, Loss: 0.4492
Batch 120, Loss: 0.4467
Batch 130, Loss: 0.4519
Batch 140, Loss: 0.4295
Batch 150, Loss: 0.4295
Batch 160, Loss: 0.4490
Batch 170, Loss: 0.4027
Batch 180, Loss: 0.4268
Batch 190, Loss: 0.4392
Batch 200, Loss: 0.4878
Batch 210, Loss: 0.4637
Batch 220, Loss: 0.4389
Batch 230, Loss: 0.4325
Batch 240, Loss: 0.4423
Batch 250, Loss: 0.4283
Batch 260, Loss: 0.4527
Batch 270, Loss: 0.4418
Batch 280, Loss: 0.4227
Batch 290, Loss: 0.4380
Batch 300, Loss: 0.4356
Batch 310, Loss: 0.4377
Batch 320, Loss: 0.4270
Batch 330, Loss: 0.4593
Batch 340, Loss: 0.4740
Batch 350, Loss: 0.4282
Batch 360, Loss: 0.4418
Batch 370, Loss: 0.4279
Batch 380, Loss: 0.4500
Batch 390, Loss: 0.4324
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.381117582321167 seconds
Epoch 98 accuracy: 86.59%
Batch 10, Loss: 0.4128
Batch 20, Loss: 0.3969
Batch 30, Loss: 0.3998
Batch 40, Loss: 0.4420
Batch 50, Loss: 0.4050
Batch 60, Loss: 0.4294
Batch 70, Loss: 0.4551
Batch 80, Loss: 0.4302
Batch 90, Loss: 0.4470
Batch 100, Loss: 0.3902
Batch 110, Loss: 0.3964
Batch 120, Loss: 0.4211
Batch 130, Loss: 0.4318
Batch 140, Loss: 0.4314
Batch 150, Loss: 0.4120
Batch 160, Loss: 0.4143
Batch 170, Loss: 0.4658
Batch 180, Loss: 0.4401
Batch 190, Loss: 0.4632
Batch 200, Loss: 0.4273
Batch 210, Loss: 0.4570
Batch 220, Loss: 0.3819
Batch 230, Loss: 0.4091
Batch 240, Loss: 0.4387
Batch 250, Loss: 0.4329
Batch 260, Loss: 0.4729
Batch 270, Loss: 0.4748
Batch 280, Loss: 0.4234
Batch 290, Loss: 0.4360
Batch 300, Loss: 0.4709
Batch 310, Loss: 0.4635
Batch 320, Loss: 0.4401
Batch 330, Loss: 0.4368
Batch 340, Loss: 0.4284
Batch 350, Loss: 0.4720
Batch 360, Loss: 0.4491
Batch 370, Loss: 0.4394
Batch 380, Loss: 0.4225
Batch 390, Loss: 0.4447
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.23416519165039 seconds
Epoch 99 accuracy: 88.91%
Batch 10, Loss: 0.4453
Batch 20, Loss: 0.4401
Batch 30, Loss: 0.4419
Batch 40, Loss: 0.4449
Batch 50, Loss: 0.4139
Batch 60, Loss: 0.4426
Batch 70, Loss: 0.4182
Batch 80, Loss: 0.4051
Batch 90, Loss: 0.4163
Batch 100, Loss: 0.3889
Batch 110, Loss: 0.4102
Batch 120, Loss: 0.4210
Batch 130, Loss: 0.4509
Batch 140, Loss: 0.4399
Batch 150, Loss: 0.4509
Batch 160, Loss: 0.4778
Batch 170, Loss: 0.4518
Batch 180, Loss: 0.4613
Batch 190, Loss: 0.4468
Batch 200, Loss: 0.4653
Batch 210, Loss: 0.4544
Batch 220, Loss: 0.4164
Batch 230, Loss: 0.4217
Batch 240, Loss: 0.3786
Batch 250, Loss: 0.4247
Batch 260, Loss: 0.4341
Batch 270, Loss: 0.4237
Batch 280, Loss: 0.4734
Batch 290, Loss: 0.4094
Batch 300, Loss: 0.3919
Batch 310, Loss: 0.4304
Batch 320, Loss: 0.4382
Batch 330, Loss: 0.4647
Batch 340, Loss: 0.4553
Batch 350, Loss: 0.4011
Batch 360, Loss: 0.4593
Batch 370, Loss: 0.4319
Batch 380, Loss: 0.4064
Batch 390, Loss: 0.4166
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.11417555809021 seconds
Epoch 100 accuracy: 88.18%
Batch 10, Loss: 0.4162
Batch 20, Loss: 0.4543
Batch 30, Loss: 0.4481
Batch 40, Loss: 0.4412
Batch 50, Loss: 0.4332
Batch 60, Loss: 0.4259
Batch 70, Loss: 0.4524
Batch 80, Loss: 0.4074
Batch 90, Loss: 0.4508
Batch 100, Loss: 0.4039
Batch 110, Loss: 0.4401
Batch 120, Loss: 0.4262
Batch 130, Loss: 0.4506
Batch 140, Loss: 0.3843
Batch 150, Loss: 0.4550
Batch 160, Loss: 0.4165
Batch 170, Loss: 0.4391
Batch 180, Loss: 0.4436
Batch 190, Loss: 0.4513
Batch 200, Loss: 0.4899
Batch 210, Loss: 0.4466
Batch 220, Loss: 0.4282
Batch 230, Loss: 0.4555
Batch 240, Loss: 0.4092
Batch 250, Loss: 0.4394
Batch 260, Loss: 0.4351
Batch 270, Loss: 0.4473
Batch 280, Loss: 0.4122
Batch 290, Loss: 0.4054
Batch 300, Loss: 0.4454
Batch 310, Loss: 0.4230
Batch 320, Loss: 0.4545
Batch 330, Loss: 0.4208
Batch 340, Loss: 0.4127
Batch 350, Loss: 0.4138
Batch 360, Loss: 0.4780
Batch 370, Loss: 0.4544
Batch 380, Loss: 0.4110
Batch 390, Loss: 0.4614
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.244463205337524 seconds
Epoch 101 accuracy: 88.05%
Batch 10, Loss: 0.4246
Batch 20, Loss: 0.4375
Batch 30, Loss: 0.4201
Batch 40, Loss: 0.4467
Batch 50, Loss: 0.3947
Batch 60, Loss: 0.3799
Batch 70, Loss: 0.4279
Batch 80, Loss: 0.4403
Batch 90, Loss: 0.4169
Batch 100, Loss: 0.3941
Batch 110, Loss: 0.4311
Batch 120, Loss: 0.4476
Batch 130, Loss: 0.4281
Batch 140, Loss: 0.4553
Batch 150, Loss: 0.4183
Batch 160, Loss: 0.4303
Batch 170, Loss: 0.4262
Batch 180, Loss: 0.4371
Batch 190, Loss: 0.4224
Batch 200, Loss: 0.4562
Batch 210, Loss: 0.4473
Batch 220, Loss: 0.4401
Batch 230, Loss: 0.4381
Batch 240, Loss: 0.4198
Batch 250, Loss: 0.4151
Batch 260, Loss: 0.4280
Batch 270, Loss: 0.4547
Batch 280, Loss: 0.3897
Batch 290, Loss: 0.4181
Batch 300, Loss: 0.4217
Batch 310, Loss: 0.4289
Batch 320, Loss: 0.4355
Batch 330, Loss: 0.4440
Batch 340, Loss: 0.4045
Batch 350, Loss: 0.4451
Batch 360, Loss: 0.4327
Batch 370, Loss: 0.4126
Batch 380, Loss: 0.3991
Batch 390, Loss: 0.4675
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.070220708847046 seconds
Epoch 102 accuracy: 89.12%
Batch 10, Loss: 0.4080
Batch 20, Loss: 0.4462
Batch 30, Loss: 0.4040
Batch 40, Loss: 0.4159
Batch 50, Loss: 0.3743
Batch 60, Loss: 0.4382
Batch 70, Loss: 0.4542
Batch 80, Loss: 0.4151
Batch 90, Loss: 0.3971
Batch 100, Loss: 0.4236
Batch 110, Loss: 0.3817
Batch 120, Loss: 0.4412
Batch 130, Loss: 0.4380
Batch 140, Loss: 0.4406
Batch 150, Loss: 0.4083
Batch 160, Loss: 0.4151
Batch 170, Loss: 0.4111
Batch 180, Loss: 0.4248
Batch 190, Loss: 0.4257
Batch 200, Loss: 0.4231
Batch 210, Loss: 0.4536
Batch 220, Loss: 0.4340
Batch 230, Loss: 0.4213
Batch 240, Loss: 0.4005
Batch 250, Loss: 0.4466
Batch 260, Loss: 0.4087
Batch 270, Loss: 0.3974
Batch 280, Loss: 0.4280
Batch 290, Loss: 0.4296
Batch 300, Loss: 0.4473
Batch 310, Loss: 0.4520
Batch 320, Loss: 0.4634
Batch 330, Loss: 0.4659
Batch 340, Loss: 0.4519
Batch 350, Loss: 0.4295
Batch 360, Loss: 0.4619
Batch 370, Loss: 0.4056
Batch 380, Loss: 0.4107
Batch 390, Loss: 0.4256
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.037752389907837 seconds
Epoch 103 accuracy: 86.98%
Batch 10, Loss: 0.3664
Batch 20, Loss: 0.4177
Batch 30, Loss: 0.3810
Batch 40, Loss: 0.4303
Batch 50, Loss: 0.3661
Batch 60, Loss: 0.4316
Batch 70, Loss: 0.4361
Batch 80, Loss: 0.4367
Batch 90, Loss: 0.4956
Batch 100, Loss: 0.4511
Batch 110, Loss: 0.4398
Batch 120, Loss: 0.4516
Batch 130, Loss: 0.4369
Batch 140, Loss: 0.4723
Batch 150, Loss: 0.3843
Batch 160, Loss: 0.4169
Batch 170, Loss: 0.4431
Batch 180, Loss: 0.4508
Batch 190, Loss: 0.4108
Batch 200, Loss: 0.4220
Batch 210, Loss: 0.4135
Batch 220, Loss: 0.4223
Batch 230, Loss: 0.4017
Batch 240, Loss: 0.4199
Batch 250, Loss: 0.4202
Batch 260, Loss: 0.4267
Batch 270, Loss: 0.4429
Batch 280, Loss: 0.4438
Batch 290, Loss: 0.4128
Batch 300, Loss: 0.3989
Batch 310, Loss: 0.4248
Batch 320, Loss: 0.4403
Batch 330, Loss: 0.4389
Batch 340, Loss: 0.3962
Batch 350, Loss: 0.4026
Batch 360, Loss: 0.4148
Batch 370, Loss: 0.3866
Batch 380, Loss: 0.4203
Batch 390, Loss: 0.4232
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.089873790740967 seconds
Epoch 104 accuracy: 89.92%
Batch 10, Loss: 0.4099
Batch 20, Loss: 0.3997
Batch 30, Loss: 0.4446
Batch 40, Loss: 0.4344
Batch 50, Loss: 0.4218
Batch 60, Loss: 0.4211
Batch 70, Loss: 0.4214
Batch 80, Loss: 0.4312
Batch 90, Loss: 0.4065
Batch 100, Loss: 0.4276
Batch 110, Loss: 0.3959
Batch 120, Loss: 0.4229
Batch 130, Loss: 0.4099
Batch 140, Loss: 0.4242
Batch 150, Loss: 0.4537
Batch 160, Loss: 0.4233
Batch 170, Loss: 0.3878
Batch 180, Loss: 0.4468
Batch 190, Loss: 0.4292
Batch 200, Loss: 0.4190
Batch 210, Loss: 0.4114
Batch 220, Loss: 0.4258
Batch 230, Loss: 0.4519
Batch 240, Loss: 0.4246
Batch 250, Loss: 0.4199
Batch 260, Loss: 0.4291
Batch 270, Loss: 0.4212
Batch 280, Loss: 0.4501
Batch 290, Loss: 0.4804
Batch 300, Loss: 0.4393
Batch 310, Loss: 0.4013
Batch 320, Loss: 0.4028
Batch 330, Loss: 0.4031
Batch 340, Loss: 0.4063
Batch 350, Loss: 0.3840
Batch 360, Loss: 0.4087
Batch 370, Loss: 0.4289
Batch 380, Loss: 0.4414
Batch 390, Loss: 0.4642
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.245972633361816 seconds
Epoch 105 accuracy: 88.89%
Batch 10, Loss: 0.4165
Batch 20, Loss: 0.3965
Batch 30, Loss: 0.3959
Batch 40, Loss: 0.4083
Batch 50, Loss: 0.4174
Batch 60, Loss: 0.4204
Batch 70, Loss: 0.3686
Batch 80, Loss: 0.4347
Batch 90, Loss: 0.4334
Batch 100, Loss: 0.3732
Batch 110, Loss: 0.4145
Batch 120, Loss: 0.3989
Batch 130, Loss: 0.4028
Batch 140, Loss: 0.4321
Batch 150, Loss: 0.4405
Batch 160, Loss: 0.4222
Batch 170, Loss: 0.4162
Batch 180, Loss: 0.4174
Batch 190, Loss: 0.4081
Batch 200, Loss: 0.4545
Batch 210, Loss: 0.4262
Batch 220, Loss: 0.4324
Batch 230, Loss: 0.3919
Batch 240, Loss: 0.4251
Batch 250, Loss: 0.4217
Batch 260, Loss: 0.3665
Batch 270, Loss: 0.4226
Batch 280, Loss: 0.4427
Batch 290, Loss: 0.3801
Batch 300, Loss: 0.4103
Batch 310, Loss: 0.3883
Batch 320, Loss: 0.4196
Batch 330, Loss: 0.4305
Batch 340, Loss: 0.3993
Batch 350, Loss: 0.4221
Batch 360, Loss: 0.4166
Batch 370, Loss: 0.4341
Batch 380, Loss: 0.4308
Batch 390, Loss: 0.4238
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.304954051971436 seconds
Epoch 106 accuracy: 86.7%
Batch 10, Loss: 0.4090
Batch 20, Loss: 0.4295
Batch 30, Loss: 0.4027
Batch 40, Loss: 0.4402
Batch 50, Loss: 0.3843
Batch 60, Loss: 0.4028
Batch 70, Loss: 0.4282
Batch 80, Loss: 0.4311
Batch 90, Loss: 0.4534
Batch 100, Loss: 0.4353
Batch 110, Loss: 0.4275
Batch 120, Loss: 0.4000
Batch 130, Loss: 0.4217
Batch 140, Loss: 0.3853
Batch 150, Loss: 0.3992
Batch 160, Loss: 0.3904
Batch 170, Loss: 0.4072
Batch 180, Loss: 0.4386
Batch 190, Loss: 0.4324
Batch 200, Loss: 0.4322
Batch 210, Loss: 0.4243
Batch 220, Loss: 0.4201
Batch 230, Loss: 0.4014
Batch 240, Loss: 0.4148
Batch 250, Loss: 0.4148
Batch 260, Loss: 0.4122
Batch 270, Loss: 0.4013
Batch 280, Loss: 0.4283
Batch 290, Loss: 0.4358
Batch 300, Loss: 0.4299
Batch 310, Loss: 0.4329
Batch 320, Loss: 0.4388
Batch 330, Loss: 0.3922
Batch 340, Loss: 0.3783
Batch 350, Loss: 0.4040
Batch 360, Loss: 0.3984
Batch 370, Loss: 0.4208
Batch 380, Loss: 0.4480
Batch 390, Loss: 0.4293
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.095871210098267 seconds
Epoch 107 accuracy: 89.54%
Batch 10, Loss: 0.4386
Batch 20, Loss: 0.4146
Batch 30, Loss: 0.4105
Batch 40, Loss: 0.4085
Batch 50, Loss: 0.3943
Batch 60, Loss: 0.4178
Batch 70, Loss: 0.4309
Batch 80, Loss: 0.3787
Batch 90, Loss: 0.4084
Batch 100, Loss: 0.4246
Batch 110, Loss: 0.3978
Batch 120, Loss: 0.4114
Batch 130, Loss: 0.4179
Batch 140, Loss: 0.4156
Batch 150, Loss: 0.4037
Batch 160, Loss: 0.4121
Batch 170, Loss: 0.4224
Batch 180, Loss: 0.4346
Batch 190, Loss: 0.4362
Batch 200, Loss: 0.3945
Batch 210, Loss: 0.4558
Batch 220, Loss: 0.3853
Batch 230, Loss: 0.4028
Batch 240, Loss: 0.4360
Batch 250, Loss: 0.4066
Batch 260, Loss: 0.4410
Batch 270, Loss: 0.3901
Batch 280, Loss: 0.4446
Batch 290, Loss: 0.3981
Batch 300, Loss: 0.4133
Batch 310, Loss: 0.3998
Batch 320, Loss: 0.4340
Batch 330, Loss: 0.3907
Batch 340, Loss: 0.4047
Batch 350, Loss: 0.3806
Batch 360, Loss: 0.4145
Batch 370, Loss: 0.3954
Batch 380, Loss: 0.4419
Batch 390, Loss: 0.4231
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.260222911834717 seconds
Epoch 108 accuracy: 88.86%
Batch 10, Loss: 0.4164
Batch 20, Loss: 0.4161
Batch 30, Loss: 0.3732
Batch 40, Loss: 0.3929
Batch 50, Loss: 0.3938
Batch 60, Loss: 0.3727
Batch 70, Loss: 0.4439
Batch 80, Loss: 0.4269
Batch 90, Loss: 0.4507
Batch 100, Loss: 0.4464
Batch 110, Loss: 0.3921
Batch 120, Loss: 0.4160
Batch 130, Loss: 0.3808
Batch 140, Loss: 0.3997
Batch 150, Loss: 0.3999
Batch 160, Loss: 0.4489
Batch 170, Loss: 0.4326
Batch 180, Loss: 0.4231
Batch 190, Loss: 0.4054
Batch 200, Loss: 0.3878
Batch 210, Loss: 0.3792
Batch 220, Loss: 0.4011
Batch 230, Loss: 0.4145
Batch 240, Loss: 0.3756
Batch 250, Loss: 0.3790
Batch 260, Loss: 0.4110
Batch 270, Loss: 0.3974
Batch 280, Loss: 0.4198
Batch 290, Loss: 0.4637
Batch 300, Loss: 0.4326
Batch 310, Loss: 0.4233
Batch 320, Loss: 0.4195
Batch 330, Loss: 0.4447
Batch 340, Loss: 0.4009
Batch 350, Loss: 0.4052
Batch 360, Loss: 0.4706
Batch 370, Loss: 0.4179
Batch 380, Loss: 0.4137
Batch 390, Loss: 0.3931
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.02215552330017 seconds
Epoch 109 accuracy: 90.5%
Batch 10, Loss: 0.4103
Batch 20, Loss: 0.3994
Batch 30, Loss: 0.4225
Batch 40, Loss: 0.4105
Batch 50, Loss: 0.3854
Batch 60, Loss: 0.3952
Batch 70, Loss: 0.4047
Batch 80, Loss: 0.4169
Batch 90, Loss: 0.3939
Batch 100, Loss: 0.4118
Batch 110, Loss: 0.3972
Batch 120, Loss: 0.4400
Batch 130, Loss: 0.3977
Batch 140, Loss: 0.3832
Batch 150, Loss: 0.4112
Batch 160, Loss: 0.4099
Batch 170, Loss: 0.4197
Batch 180, Loss: 0.4046
Batch 190, Loss: 0.4140
Batch 200, Loss: 0.3988
Batch 210, Loss: 0.3907
Batch 220, Loss: 0.4081
Batch 230, Loss: 0.4328
Batch 240, Loss: 0.4171
Batch 250, Loss: 0.3876
Batch 260, Loss: 0.4254
Batch 270, Loss: 0.3796
Batch 280, Loss: 0.4171
Batch 290, Loss: 0.3791
Batch 300, Loss: 0.4013
Batch 310, Loss: 0.4372
Batch 320, Loss: 0.4093
Batch 330, Loss: 0.3978
Batch 340, Loss: 0.4397
Batch 350, Loss: 0.3937
Batch 360, Loss: 0.3776
Batch 370, Loss: 0.3973
Batch 380, Loss: 0.3900
Batch 390, Loss: 0.3934
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.20917320251465 seconds
Epoch 110 accuracy: 89.69%
Batch 10, Loss: 0.4054
Batch 20, Loss: 0.4173
Batch 30, Loss: 0.3861
Batch 40, Loss: 0.4276
Batch 50, Loss: 0.3790
Batch 60, Loss: 0.4151
Batch 70, Loss: 0.4011
Batch 80, Loss: 0.4115
Batch 90, Loss: 0.3920
Batch 100, Loss: 0.3795
Batch 110, Loss: 0.4227
Batch 120, Loss: 0.4164
Batch 130, Loss: 0.3894
Batch 140, Loss: 0.3917
Batch 150, Loss: 0.3895
Batch 160, Loss: 0.4318
Batch 170, Loss: 0.3982
Batch 180, Loss: 0.4187
Batch 190, Loss: 0.4366
Batch 200, Loss: 0.3796
Batch 210, Loss: 0.3943
Batch 220, Loss: 0.4100
Batch 230, Loss: 0.3758
Batch 240, Loss: 0.4274
Batch 250, Loss: 0.3864
Batch 260, Loss: 0.4638
Batch 270, Loss: 0.4321
Batch 280, Loss: 0.4199
Batch 290, Loss: 0.3829
Batch 300, Loss: 0.4652
Batch 310, Loss: 0.4130
Batch 320, Loss: 0.4158
Batch 330, Loss: 0.3868
Batch 340, Loss: 0.4051
Batch 350, Loss: 0.3931
Batch 360, Loss: 0.3939
Batch 370, Loss: 0.3811
Batch 380, Loss: 0.3832
Batch 390, Loss: 0.4209
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.27507781982422 seconds
Epoch 111 accuracy: 88.28%
Batch 10, Loss: 0.3980
Batch 20, Loss: 0.4274
Batch 30, Loss: 0.3818
Batch 40, Loss: 0.4223
Batch 50, Loss: 0.3739
Batch 60, Loss: 0.4006
Batch 70, Loss: 0.4300
Batch 80, Loss: 0.3802
Batch 90, Loss: 0.4025
Batch 100, Loss: 0.3926
Batch 110, Loss: 0.4061
Batch 120, Loss: 0.3775
Batch 130, Loss: 0.4060
Batch 140, Loss: 0.4045
Batch 150, Loss: 0.3954
Batch 160, Loss: 0.3814
Batch 170, Loss: 0.3816
Batch 180, Loss: 0.3534
Batch 190, Loss: 0.4457
Batch 200, Loss: 0.4215
Batch 210, Loss: 0.3942
Batch 220, Loss: 0.3935
Batch 230, Loss: 0.3894
Batch 240, Loss: 0.4089
Batch 250, Loss: 0.4213
Batch 260, Loss: 0.3908
Batch 270, Loss: 0.3809
Batch 280, Loss: 0.4150
Batch 290, Loss: 0.4032
Batch 300, Loss: 0.3786
Batch 310, Loss: 0.3958
Batch 320, Loss: 0.4169
Batch 330, Loss: 0.4183
Batch 340, Loss: 0.4027
Batch 350, Loss: 0.4074
Batch 360, Loss: 0.4088
Batch 370, Loss: 0.3964
Batch 380, Loss: 0.3685
Batch 390, Loss: 0.3814
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.14401149749756 seconds
Epoch 112 accuracy: 89.62%
Batch 10, Loss: 0.3673
Batch 20, Loss: 0.3940
Batch 30, Loss: 0.4215
Batch 40, Loss: 0.4136
Batch 50, Loss: 0.4244
Batch 60, Loss: 0.4103
Batch 70, Loss: 0.3697
Batch 80, Loss: 0.4007
Batch 90, Loss: 0.4016
Batch 100, Loss: 0.4460
Batch 110, Loss: 0.4101
Batch 120, Loss: 0.4542
Batch 130, Loss: 0.4147
Batch 140, Loss: 0.4063
Batch 150, Loss: 0.3869
Batch 160, Loss: 0.3848
Batch 170, Loss: 0.3682
Batch 180, Loss: 0.4010
Batch 190, Loss: 0.3871
Batch 200, Loss: 0.4004
Batch 210, Loss: 0.3896
Batch 220, Loss: 0.4400
Batch 230, Loss: 0.4341
Batch 240, Loss: 0.3808
Batch 250, Loss: 0.3841
Batch 260, Loss: 0.3951
Batch 270, Loss: 0.3775
Batch 280, Loss: 0.3995
Batch 290, Loss: 0.3847
Batch 300, Loss: 0.4327
Batch 310, Loss: 0.4733
Batch 320, Loss: 0.3726
Batch 330, Loss: 0.3676
Batch 340, Loss: 0.4096
Batch 350, Loss: 0.3999
Batch 360, Loss: 0.4459
Batch 370, Loss: 0.3906
Batch 380, Loss: 0.3763
Batch 390, Loss: 0.4195
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.080713987350464 seconds
Epoch 113 accuracy: 88.26%
Batch 10, Loss: 0.3854
Batch 20, Loss: 0.3825
Batch 30, Loss: 0.3937
Batch 40, Loss: 0.3855
Batch 50, Loss: 0.3564
Batch 60, Loss: 0.3825
Batch 70, Loss: 0.4188
Batch 80, Loss: 0.3879
Batch 90, Loss: 0.4094
Batch 100, Loss: 0.3893
Batch 110, Loss: 0.3957
Batch 120, Loss: 0.4182
Batch 130, Loss: 0.4426
Batch 140, Loss: 0.4062
Batch 150, Loss: 0.3923
Batch 160, Loss: 0.4153
Batch 170, Loss: 0.3699
Batch 180, Loss: 0.3877
Batch 190, Loss: 0.4073
Batch 200, Loss: 0.3808
Batch 210, Loss: 0.4069
Batch 220, Loss: 0.3906
Batch 230, Loss: 0.4060
Batch 240, Loss: 0.3969
Batch 250, Loss: 0.3834
Batch 260, Loss: 0.3849
Batch 270, Loss: 0.4345
Batch 280, Loss: 0.4351
Batch 290, Loss: 0.4111
Batch 300, Loss: 0.4021
Batch 310, Loss: 0.3905
Batch 320, Loss: 0.3908
Batch 330, Loss: 0.3780
Batch 340, Loss: 0.4074
Batch 350, Loss: 0.3890
Batch 360, Loss: 0.3621
Batch 370, Loss: 0.4291
Batch 380, Loss: 0.3985
Batch 390, Loss: 0.3925
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.22567129135132 seconds
Epoch 114 accuracy: 88.39%
Batch 10, Loss: 0.3901
Batch 20, Loss: 0.3736
Batch 30, Loss: 0.3772
Batch 40, Loss: 0.3720
Batch 50, Loss: 0.3724
Batch 60, Loss: 0.4277
Batch 70, Loss: 0.4069
Batch 80, Loss: 0.3941
Batch 90, Loss: 0.3997
Batch 100, Loss: 0.3727
Batch 110, Loss: 0.4215
Batch 120, Loss: 0.4138
Batch 130, Loss: 0.4051
Batch 140, Loss: 0.4061
Batch 150, Loss: 0.4134
Batch 160, Loss: 0.4004
Batch 170, Loss: 0.3753
Batch 180, Loss: 0.3989
Batch 190, Loss: 0.4030
Batch 200, Loss: 0.3906
Batch 210, Loss: 0.3894
Batch 220, Loss: 0.4225
Batch 230, Loss: 0.3890
Batch 240, Loss: 0.4213
Batch 250, Loss: 0.3726
Batch 260, Loss: 0.4198
Batch 270, Loss: 0.3925
Batch 280, Loss: 0.4171
Batch 290, Loss: 0.4145
Batch 300, Loss: 0.4176
Batch 310, Loss: 0.3741
Batch 320, Loss: 0.3741
Batch 330, Loss: 0.3998
Batch 340, Loss: 0.3848
Batch 350, Loss: 0.4237
Batch 360, Loss: 0.4170
Batch 370, Loss: 0.4034
Batch 380, Loss: 0.3969
Batch 390, Loss: 0.3733
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.270289421081543 seconds
Epoch 115 accuracy: 91.04%
Batch 10, Loss: 0.3728
Batch 20, Loss: 0.3932
Batch 30, Loss: 0.3725
Batch 40, Loss: 0.3593
Batch 50, Loss: 0.3840
Batch 60, Loss: 0.4160
Batch 70, Loss: 0.3901
Batch 80, Loss: 0.4161
Batch 90, Loss: 0.3930
Batch 100, Loss: 0.4251
Batch 110, Loss: 0.4003
Batch 120, Loss: 0.3441
Batch 130, Loss: 0.4214
Batch 140, Loss: 0.4120
Batch 150, Loss: 0.3494
Batch 160, Loss: 0.3760
Batch 170, Loss: 0.3780
Batch 180, Loss: 0.3898
Batch 190, Loss: 0.3927
Batch 200, Loss: 0.4044
Batch 210, Loss: 0.3997
Batch 220, Loss: 0.3903
Batch 230, Loss: 0.3856
Batch 240, Loss: 0.4030
Batch 250, Loss: 0.3857
Batch 260, Loss: 0.3867
Batch 270, Loss: 0.4339
Batch 280, Loss: 0.4230
Batch 290, Loss: 0.4051
Batch 300, Loss: 0.4092
Batch 310, Loss: 0.3734
Batch 320, Loss: 0.3803
Batch 330, Loss: 0.4011
Batch 340, Loss: 0.3962
Batch 350, Loss: 0.4015
Batch 360, Loss: 0.3956
Batch 370, Loss: 0.3731
Batch 380, Loss: 0.4135
Batch 390, Loss: 0.4005
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.19466257095337 seconds
Epoch 116 accuracy: 90.07%
Batch 10, Loss: 0.3559
Batch 20, Loss: 0.4190
Batch 30, Loss: 0.3797
Batch 40, Loss: 0.4071
Batch 50, Loss: 0.3917
Batch 60, Loss: 0.3962
Batch 70, Loss: 0.3669
Batch 80, Loss: 0.3757
Batch 90, Loss: 0.3739
Batch 100, Loss: 0.4383
Batch 110, Loss: 0.3948
Batch 120, Loss: 0.3934
Batch 130, Loss: 0.3736
Batch 140, Loss: 0.3829
Batch 150, Loss: 0.3441
Batch 160, Loss: 0.4203
Batch 170, Loss: 0.4033
Batch 180, Loss: 0.4022
Batch 190, Loss: 0.3755
Batch 200, Loss: 0.4046
Batch 210, Loss: 0.3685
Batch 220, Loss: 0.3821
Batch 230, Loss: 0.3666
Batch 240, Loss: 0.3793
Batch 250, Loss: 0.3561
Batch 260, Loss: 0.3935
Batch 270, Loss: 0.3843
Batch 280, Loss: 0.4138
Batch 290, Loss: 0.3824
Batch 300, Loss: 0.4065
Batch 310, Loss: 0.4291
Batch 320, Loss: 0.3568
Batch 330, Loss: 0.3980
Batch 340, Loss: 0.3818
Batch 350, Loss: 0.4006
Batch 360, Loss: 0.4150
Batch 370, Loss: 0.3762
Batch 380, Loss: 0.4165
Batch 390, Loss: 0.4048
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.23353624343872 seconds
Epoch 117 accuracy: 90.9%
Batch 10, Loss: 0.3884
Batch 20, Loss: 0.4114
Batch 30, Loss: 0.3800
Batch 40, Loss: 0.3803
Batch 50, Loss: 0.3762
Batch 60, Loss: 0.3840
Batch 70, Loss: 0.3471
Batch 80, Loss: 0.3874
Batch 90, Loss: 0.3691
Batch 100, Loss: 0.3617
Batch 110, Loss: 0.3661
Batch 120, Loss: 0.4048
Batch 130, Loss: 0.4024
Batch 140, Loss: 0.3638
Batch 150, Loss: 0.3702
Batch 160, Loss: 0.3859
Batch 170, Loss: 0.3643
Batch 180, Loss: 0.3904
Batch 190, Loss: 0.3865
Batch 200, Loss: 0.3862
Batch 210, Loss: 0.4089
Batch 220, Loss: 0.3966
Batch 230, Loss: 0.3807
Batch 240, Loss: 0.4187
Batch 250, Loss: 0.4136
Batch 260, Loss: 0.3556
Batch 270, Loss: 0.3889
Batch 280, Loss: 0.3949
Batch 290, Loss: 0.4145
Batch 300, Loss: 0.3739
Batch 310, Loss: 0.3524
Batch 320, Loss: 0.4301
Batch 330, Loss: 0.4318
Batch 340, Loss: 0.4311
Batch 350, Loss: 0.4109
Batch 360, Loss: 0.3676
Batch 370, Loss: 0.4206
Batch 380, Loss: 0.3896
Batch 390, Loss: 0.3672
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.196656227111816 seconds
Epoch 118 accuracy: 90.58%
Batch 10, Loss: 0.3865
Batch 20, Loss: 0.3701
Batch 30, Loss: 0.4062
Batch 40, Loss: 0.3818
Batch 50, Loss: 0.3874
Batch 60, Loss: 0.3672
Batch 70, Loss: 0.3720
Batch 80, Loss: 0.3801
Batch 90, Loss: 0.4083
Batch 100, Loss: 0.3871
Batch 110, Loss: 0.3547
Batch 120, Loss: 0.3910
Batch 130, Loss: 0.3973
Batch 140, Loss: 0.3781
Batch 150, Loss: 0.3636
Batch 160, Loss: 0.3517
Batch 170, Loss: 0.3965
Batch 180, Loss: 0.3713
Batch 190, Loss: 0.3949
Batch 200, Loss: 0.4023
Batch 210, Loss: 0.4002
Batch 220, Loss: 0.3463
Batch 230, Loss: 0.3842
Batch 240, Loss: 0.4101
Batch 250, Loss: 0.3722
Batch 260, Loss: 0.3986
Batch 270, Loss: 0.3823
Batch 280, Loss: 0.3814
Batch 290, Loss: 0.3989
Batch 300, Loss: 0.4056
Batch 310, Loss: 0.3594
Batch 320, Loss: 0.3582
Batch 330, Loss: 0.4191
Batch 340, Loss: 0.4008
Batch 350, Loss: 0.3591
Batch 360, Loss: 0.3448
Batch 370, Loss: 0.3836
Batch 380, Loss: 0.4230
Batch 390, Loss: 0.3656
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.27969717979431 seconds
Epoch 119 accuracy: 90.29%
Batch 10, Loss: 0.3642
Batch 20, Loss: 0.3914
Batch 30, Loss: 0.3505
Batch 40, Loss: 0.3653
Batch 50, Loss: 0.3843
Batch 60, Loss: 0.3758
Batch 70, Loss: 0.3846
Batch 80, Loss: 0.3969
Batch 90, Loss: 0.3549
Batch 100, Loss: 0.4047
Batch 110, Loss: 0.3926
Batch 120, Loss: 0.4054
Batch 130, Loss: 0.3785
Batch 140, Loss: 0.3958
Batch 150, Loss: 0.3893
Batch 160, Loss: 0.4268
Batch 170, Loss: 0.3635
Batch 180, Loss: 0.3597
Batch 190, Loss: 0.4137
Batch 200, Loss: 0.3378
Batch 210, Loss: 0.3877
Batch 220, Loss: 0.4170
Batch 230, Loss: 0.3818
Batch 240, Loss: 0.3839
Batch 250, Loss: 0.3941
Batch 260, Loss: 0.4230
Batch 270, Loss: 0.3603
Batch 280, Loss: 0.3632
Batch 290, Loss: 0.4001
Batch 300, Loss: 0.3760
Batch 310, Loss: 0.3896
Batch 320, Loss: 0.4233
Batch 330, Loss: 0.3842
Batch 340, Loss: 0.3666
Batch 350, Loss: 0.3780
Batch 360, Loss: 0.3709
Batch 370, Loss: 0.3693
Batch 380, Loss: 0.3729
Batch 390, Loss: 0.3751
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.356627702713013 seconds
Epoch 120 accuracy: 89.76%
Batch 10, Loss: 0.4018
Batch 20, Loss: 0.3763
Batch 30, Loss: 0.3588
Batch 40, Loss: 0.3611
Batch 50, Loss: 0.3893
Batch 60, Loss: 0.3435
Batch 70, Loss: 0.3850
Batch 80, Loss: 0.3722
Batch 90, Loss: 0.3929
Batch 100, Loss: 0.3504
Batch 110, Loss: 0.3714
Batch 120, Loss: 0.3866
Batch 130, Loss: 0.3840
Batch 140, Loss: 0.3592
Batch 150, Loss: 0.3706
Batch 160, Loss: 0.3671
Batch 170, Loss: 0.3629
Batch 180, Loss: 0.3923
Batch 190, Loss: 0.3935
Batch 200, Loss: 0.3960
Batch 210, Loss: 0.3907
Batch 220, Loss: 0.4002
Batch 230, Loss: 0.3728
Batch 240, Loss: 0.3794
Batch 250, Loss: 0.3970
Batch 260, Loss: 0.3974
Batch 270, Loss: 0.3774
Batch 280, Loss: 0.3868
Batch 290, Loss: 0.3906
Batch 300, Loss: 0.3930
Batch 310, Loss: 0.3626
Batch 320, Loss: 0.3876
Batch 330, Loss: 0.3857
Batch 340, Loss: 0.3797
Batch 350, Loss: 0.3717
Batch 360, Loss: 0.3763
Batch 370, Loss: 0.4020
Batch 380, Loss: 0.3738
Batch 390, Loss: 0.3847
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.057962894439697 seconds
Epoch 121 accuracy: 90.23%
Batch 10, Loss: 0.3470
Batch 20, Loss: 0.3611
Batch 30, Loss: 0.3368
Batch 40, Loss: 0.3993
Batch 50, Loss: 0.3464
Batch 60, Loss: 0.3604
Batch 70, Loss: 0.3874
Batch 80, Loss: 0.3546
Batch 90, Loss: 0.3562
Batch 100, Loss: 0.3931
Batch 110, Loss: 0.3917
Batch 120, Loss: 0.3881
Batch 130, Loss: 0.3636
Batch 140, Loss: 0.3760
Batch 150, Loss: 0.3643
Batch 160, Loss: 0.3653
Batch 170, Loss: 0.3347
Batch 180, Loss: 0.3702
Batch 190, Loss: 0.3434
Batch 200, Loss: 0.3828
Batch 210, Loss: 0.3765
Batch 220, Loss: 0.3749
Batch 230, Loss: 0.3849
Batch 240, Loss: 0.4095
Batch 250, Loss: 0.3776
Batch 260, Loss: 0.3759
Batch 270, Loss: 0.3420
Batch 280, Loss: 0.4137
Batch 290, Loss: 0.3998
Batch 300, Loss: 0.4151
Batch 310, Loss: 0.3478
Batch 320, Loss: 0.3416
Batch 330, Loss: 0.4061
Batch 340, Loss: 0.3917
Batch 350, Loss: 0.3587
Batch 360, Loss: 0.3959
Batch 370, Loss: 0.3599
Batch 380, Loss: 0.3554
Batch 390, Loss: 0.3648
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.067818641662598 seconds
Epoch 122 accuracy: 90.44%
Batch 10, Loss: 0.3829
Batch 20, Loss: 0.3497
Batch 30, Loss: 0.3629
Batch 40, Loss: 0.3764
Batch 50, Loss: 0.3200
Batch 60, Loss: 0.3646
Batch 70, Loss: 0.3516
Batch 80, Loss: 0.3588
Batch 90, Loss: 0.3595
Batch 100, Loss: 0.3739
Batch 110, Loss: 0.3663
Batch 120, Loss: 0.3657
Batch 130, Loss: 0.3833
Batch 140, Loss: 0.3641
Batch 150, Loss: 0.3649
Batch 160, Loss: 0.3886
Batch 170, Loss: 0.3884
Batch 180, Loss: 0.3864
Batch 190, Loss: 0.4006
Batch 200, Loss: 0.3569
Batch 210, Loss: 0.3450
Batch 220, Loss: 0.4001
Batch 230, Loss: 0.3704
Batch 240, Loss: 0.3928
Batch 250, Loss: 0.4185
Batch 260, Loss: 0.3702
Batch 270, Loss: 0.3440
Batch 280, Loss: 0.4057
Batch 290, Loss: 0.4176
Batch 300, Loss: 0.3566
Batch 310, Loss: 0.3548
Batch 320, Loss: 0.3815
Batch 330, Loss: 0.3992
Batch 340, Loss: 0.3738
Batch 350, Loss: 0.3362
Batch 360, Loss: 0.3483
Batch 370, Loss: 0.3474
Batch 380, Loss: 0.3796
Batch 390, Loss: 0.3722
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.153100967407227 seconds
Epoch 123 accuracy: 90.32%
Batch 10, Loss: 0.3928
Batch 20, Loss: 0.3404
Batch 30, Loss: 0.3516
Batch 40, Loss: 0.3992
Batch 50, Loss: 0.3939
Batch 60, Loss: 0.3724
Batch 70, Loss: 0.3823
Batch 80, Loss: 0.3356
Batch 90, Loss: 0.3494
Batch 100, Loss: 0.3748
Batch 110, Loss: 0.3856
Batch 120, Loss: 0.3487
Batch 130, Loss: 0.3387
Batch 140, Loss: 0.3414
Batch 150, Loss: 0.3712
Batch 160, Loss: 0.3655
Batch 170, Loss: 0.3705
Batch 180, Loss: 0.3689
Batch 190, Loss: 0.3898
Batch 200, Loss: 0.3662
Batch 210, Loss: 0.4106
Batch 220, Loss: 0.3534
Batch 230, Loss: 0.4371
Batch 240, Loss: 0.3909
Batch 250, Loss: 0.3966
Batch 260, Loss: 0.3411
Batch 270, Loss: 0.3503
Batch 280, Loss: 0.3688
Batch 290, Loss: 0.3896
Batch 300, Loss: 0.3414
Batch 310, Loss: 0.3745
Batch 320, Loss: 0.3936
Batch 330, Loss: 0.3960
Batch 340, Loss: 0.3720
Batch 350, Loss: 0.3655
Batch 360, Loss: 0.3428
Batch 370, Loss: 0.3755
Batch 380, Loss: 0.3719
Batch 390, Loss: 0.3765
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.088749170303345 seconds
Epoch 124 accuracy: 89.13%
Batch 10, Loss: 0.3734
Batch 20, Loss: 0.3676
Batch 30, Loss: 0.3438
Batch 40, Loss: 0.3666
Batch 50, Loss: 0.3298
Batch 60, Loss: 0.3500
Batch 70, Loss: 0.3465
Batch 80, Loss: 0.3620
Batch 90, Loss: 0.3535
Batch 100, Loss: 0.3545
Batch 110, Loss: 0.3741
Batch 120, Loss: 0.3543
Batch 130, Loss: 0.3752
Batch 140, Loss: 0.3662
Batch 150, Loss: 0.3611
Batch 160, Loss: 0.3453
Batch 170, Loss: 0.3764
Batch 180, Loss: 0.3418
Batch 190, Loss: 0.3475
Batch 200, Loss: 0.3672
Batch 210, Loss: 0.3890
Batch 220, Loss: 0.3665
Batch 230, Loss: 0.3847
Batch 240, Loss: 0.3309
Batch 250, Loss: 0.3714
Batch 260, Loss: 0.3914
Batch 270, Loss: 0.3687
Batch 280, Loss: 0.3877
Batch 290, Loss: 0.3647
Batch 300, Loss: 0.3390
Batch 310, Loss: 0.3748
Batch 320, Loss: 0.3641
Batch 330, Loss: 0.3860
Batch 340, Loss: 0.3706
Batch 350, Loss: 0.3796
Batch 360, Loss: 0.3592
Batch 370, Loss: 0.3847
Batch 380, Loss: 0.3692
Batch 390, Loss: 0.3689
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.204671621322632 seconds
Epoch 125 accuracy: 91.02%
Batch 10, Loss: 0.3623
Batch 20, Loss: 0.3430
Batch 30, Loss: 0.3816
Batch 40, Loss: 0.3805
Batch 50, Loss: 0.3593
Batch 60, Loss: 0.3663
Batch 70, Loss: 0.3473
Batch 80, Loss: 0.3666
Batch 90, Loss: 0.3679
Batch 100, Loss: 0.3602
Batch 110, Loss: 0.3295
Batch 120, Loss: 0.3854
Batch 130, Loss: 0.3483
Batch 140, Loss: 0.3657
Batch 150, Loss: 0.3638
Batch 160, Loss: 0.3460
Batch 170, Loss: 0.3232
Batch 180, Loss: 0.3418
Batch 190, Loss: 0.3728
Batch 200, Loss: 0.3334
Batch 210, Loss: 0.3802
Batch 220, Loss: 0.3396
Batch 230, Loss: 0.3530
Batch 240, Loss: 0.3411
Batch 250, Loss: 0.3266
Batch 260, Loss: 0.3605
Batch 270, Loss: 0.3692
Batch 280, Loss: 0.3500
Batch 290, Loss: 0.3431
Batch 300, Loss: 0.3244
Batch 310, Loss: 0.3706
Batch 320, Loss: 0.3988
Batch 330, Loss: 0.3680
Batch 340, Loss: 0.3949
Batch 350, Loss: 0.3527
Batch 360, Loss: 0.3787
Batch 370, Loss: 0.3599
Batch 380, Loss: 0.3562
Batch 390, Loss: 0.3457
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.196989059448242 seconds
Epoch 126 accuracy: 89.95%
Batch 10, Loss: 0.3446
Batch 20, Loss: 0.3604
Batch 30, Loss: 0.3939
Batch 40, Loss: 0.3588
Batch 50, Loss: 0.3517
Batch 60, Loss: 0.3515
Batch 70, Loss: 0.3338
Batch 80, Loss: 0.3643
Batch 90, Loss: 0.3238
Batch 100, Loss: 0.3291
Batch 110, Loss: 0.3342
Batch 120, Loss: 0.3339
Batch 130, Loss: 0.3590
Batch 140, Loss: 0.3731
Batch 150, Loss: 0.3786
Batch 160, Loss: 0.3487
Batch 170, Loss: 0.3764
Batch 180, Loss: 0.3531
Batch 190, Loss: 0.3906
Batch 200, Loss: 0.3412
Batch 210, Loss: 0.3564
Batch 220, Loss: 0.3817
Batch 230, Loss: 0.3701
Batch 240, Loss: 0.3942
Batch 250, Loss: 0.3405
Batch 260, Loss: 0.3518
Batch 270, Loss: 0.3509
Batch 280, Loss: 0.3905
Batch 290, Loss: 0.3518
Batch 300, Loss: 0.3545
Batch 310, Loss: 0.3962
Batch 320, Loss: 0.3628
Batch 330, Loss: 0.3640
Batch 340, Loss: 0.3209
Batch 350, Loss: 0.3758
Batch 360, Loss: 0.3515
Batch 370, Loss: 0.3907
Batch 380, Loss: 0.3603
Batch 390, Loss: 0.3372
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.099307537078857 seconds
Epoch 127 accuracy: 89.92%
Batch 10, Loss: 0.3560
Batch 20, Loss: 0.3334
Batch 30, Loss: 0.3412
Batch 40, Loss: 0.3510
Batch 50, Loss: 0.3422
Batch 60, Loss: 0.3588
Batch 70, Loss: 0.3729
Batch 80, Loss: 0.3759
Batch 90, Loss: 0.3548
Batch 100, Loss: 0.3441
Batch 110, Loss: 0.3552
Batch 120, Loss: 0.3364
Batch 130, Loss: 0.3519
Batch 140, Loss: 0.3740
Batch 150, Loss: 0.3509
Batch 160, Loss: 0.3889
Batch 170, Loss: 0.3507
Batch 180, Loss: 0.3458
Batch 190, Loss: 0.3812
Batch 200, Loss: 0.3491
Batch 210, Loss: 0.3622
Batch 220, Loss: 0.3540
Batch 230, Loss: 0.3506
Batch 240, Loss: 0.3527
Batch 250, Loss: 0.3468
Batch 260, Loss: 0.3458
Batch 270, Loss: 0.3380
Batch 280, Loss: 0.3847
Batch 290, Loss: 0.3812
Batch 300, Loss: 0.3468
Batch 310, Loss: 0.3760
Batch 320, Loss: 0.3676
Batch 330, Loss: 0.3548
Batch 340, Loss: 0.3544
Batch 350, Loss: 0.3399
Batch 360, Loss: 0.3442
Batch 370, Loss: 0.3679
Batch 380, Loss: 0.3685
Batch 390, Loss: 0.3680
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.10199761390686 seconds
Epoch 128 accuracy: 90.43%
Batch 10, Loss: 0.3599
Batch 20, Loss: 0.3484
Batch 30, Loss: 0.3204
Batch 40, Loss: 0.3585
Batch 50, Loss: 0.3154
Batch 60, Loss: 0.3533
Batch 70, Loss: 0.3252
Batch 80, Loss: 0.3621
Batch 90, Loss: 0.3474
Batch 100, Loss: 0.3522
Batch 110, Loss: 0.3562
Batch 120, Loss: 0.3951
Batch 130, Loss: 0.3594
Batch 140, Loss: 0.3529
Batch 150, Loss: 0.3557
Batch 160, Loss: 0.3577
Batch 170, Loss: 0.3343
Batch 180, Loss: 0.3355
Batch 190, Loss: 0.3366
Batch 200, Loss: 0.3205
Batch 210, Loss: 0.3770
Batch 220, Loss: 0.3449
Batch 230, Loss: 0.3313
Batch 240, Loss: 0.3589
Batch 250, Loss: 0.3779
Batch 260, Loss: 0.3677
Batch 270, Loss: 0.3646
Batch 280, Loss: 0.3487
Batch 290, Loss: 0.3337
Batch 300, Loss: 0.3613
Batch 310, Loss: 0.3263
Batch 320, Loss: 0.3560
Batch 330, Loss: 0.3416
Batch 340, Loss: 0.3480
Batch 350, Loss: 0.3805
Batch 360, Loss: 0.3507
Batch 370, Loss: 0.3589
Batch 380, Loss: 0.3336
Batch 390, Loss: 0.3509
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.121424674987793 seconds
Epoch 129 accuracy: 89.26%
Batch 10, Loss: 0.3666
Batch 20, Loss: 0.3420
Batch 30, Loss: 0.3339
Batch 40, Loss: 0.3409
Batch 50, Loss: 0.3375
Batch 60, Loss: 0.3477
Batch 70, Loss: 0.3327
Batch 80, Loss: 0.3136
Batch 90, Loss: 0.3625
Batch 100, Loss: 0.3723
Batch 110, Loss: 0.3601
Batch 120, Loss: 0.3283
Batch 130, Loss: 0.3433
Batch 140, Loss: 0.3443
Batch 150, Loss: 0.3383
Batch 160, Loss: 0.3554
Batch 170, Loss: 0.3514
Batch 180, Loss: 0.3539
Batch 190, Loss: 0.3382
Batch 200, Loss: 0.3588
Batch 210, Loss: 0.3639
Batch 220, Loss: 0.3985
Batch 230, Loss: 0.3359
Batch 240, Loss: 0.3416
Batch 250, Loss: 0.3267
Batch 260, Loss: 0.3680
Batch 270, Loss: 0.3443
Batch 280, Loss: 0.3600
Batch 290, Loss: 0.3399
Batch 300, Loss: 0.3683
Batch 310, Loss: 0.3717
Batch 320, Loss: 0.3512
Batch 330, Loss: 0.3356
Batch 340, Loss: 0.3280
Batch 350, Loss: 0.3402
Batch 360, Loss: 0.3570
Batch 370, Loss: 0.3325
Batch 380, Loss: 0.3526
Batch 390, Loss: 0.3503
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.04644012451172 seconds
Epoch 130 accuracy: 91.07%
Batch 10, Loss: 0.3520
Batch 20, Loss: 0.3764
Batch 30, Loss: 0.3306
Batch 40, Loss: 0.3450
Batch 50, Loss: 0.3367
Batch 60, Loss: 0.3643
Batch 70, Loss: 0.3440
Batch 80, Loss: 0.3113
Batch 90, Loss: 0.3372
Batch 100, Loss: 0.3341
Batch 110, Loss: 0.3215
Batch 120, Loss: 0.3289
Batch 130, Loss: 0.3427
Batch 140, Loss: 0.3396
Batch 150, Loss: 0.3706
Batch 160, Loss: 0.3499
Batch 170, Loss: 0.3441
Batch 180, Loss: 0.3523
Batch 190, Loss: 0.3185
Batch 200, Loss: 0.3047
Batch 210, Loss: 0.4069
Batch 220, Loss: 0.3479
Batch 230, Loss: 0.3482
Batch 240, Loss: 0.3401
Batch 250, Loss: 0.3580
Batch 260, Loss: 0.3275
Batch 270, Loss: 0.3579
Batch 280, Loss: 0.3503
Batch 290, Loss: 0.3773
Batch 300, Loss: 0.3495
Batch 310, Loss: 0.3572
Batch 320, Loss: 0.3389
Batch 330, Loss: 0.3213
Batch 340, Loss: 0.3447
Batch 350, Loss: 0.3918
Batch 360, Loss: 0.3623
Batch 370, Loss: 0.3576
Batch 380, Loss: 0.3345
Batch 390, Loss: 0.3602
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.04090452194214 seconds
Epoch 131 accuracy: 91.76%
Batch 10, Loss: 0.3556
Batch 20, Loss: 0.2941
Batch 30, Loss: 0.3600
Batch 40, Loss: 0.3985
Batch 50, Loss: 0.3383
Batch 60, Loss: 0.3397
Batch 70, Loss: 0.3373
Batch 80, Loss: 0.3163
Batch 90, Loss: 0.3483
Batch 100, Loss: 0.3181
Batch 110, Loss: 0.3143
Batch 120, Loss: 0.3768
Batch 130, Loss: 0.3639
Batch 140, Loss: 0.3316
Batch 150, Loss: 0.3731
Batch 160, Loss: 0.3441
Batch 170, Loss: 0.3351
Batch 180, Loss: 0.3499
Batch 190, Loss: 0.3762
Batch 200, Loss: 0.3316
Batch 210, Loss: 0.3704
Batch 220, Loss: 0.3361
Batch 230, Loss: 0.3424
Batch 240, Loss: 0.3429
Batch 250, Loss: 0.3460
Batch 260, Loss: 0.3574
Batch 270, Loss: 0.3249
Batch 280, Loss: 0.3731
Batch 290, Loss: 0.3669
Batch 300, Loss: 0.3320
Batch 310, Loss: 0.3338
Batch 320, Loss: 0.3438
Batch 330, Loss: 0.3292
Batch 340, Loss: 0.3445
Batch 350, Loss: 0.3583
Batch 360, Loss: 0.2953
Batch 370, Loss: 0.3381
Batch 380, Loss: 0.3364
Batch 390, Loss: 0.3408
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.07630491256714 seconds
Epoch 132 accuracy: 91.34%
Batch 10, Loss: 0.3296
Batch 20, Loss: 0.3597
Batch 30, Loss: 0.3583
Batch 40, Loss: 0.3606
Batch 50, Loss: 0.3472
Batch 60, Loss: 0.3078
Batch 70, Loss: 0.3291
Batch 80, Loss: 0.3656
Batch 90, Loss: 0.3534
Batch 100, Loss: 0.3510
Batch 110, Loss: 0.3186
Batch 120, Loss: 0.3516
Batch 130, Loss: 0.3151
Batch 140, Loss: 0.3359
Batch 150, Loss: 0.3833
Batch 160, Loss: 0.3193
Batch 170, Loss: 0.3128
Batch 180, Loss: 0.2888
Batch 190, Loss: 0.3392
Batch 200, Loss: 0.3448
Batch 210, Loss: 0.3441
Batch 220, Loss: 0.3614
Batch 230, Loss: 0.3402
Batch 240, Loss: 0.3669
Batch 250, Loss: 0.3417
Batch 260, Loss: 0.3607
Batch 270, Loss: 0.2959
Batch 280, Loss: 0.3390
Batch 290, Loss: 0.3302
Batch 300, Loss: 0.3465
Batch 310, Loss: 0.3271
Batch 320, Loss: 0.3538
Batch 330, Loss: 0.3241
Batch 340, Loss: 0.3403
Batch 350, Loss: 0.3435
Batch 360, Loss: 0.3269
Batch 370, Loss: 0.3506
Batch 380, Loss: 0.3551
Batch 390, Loss: 0.3520
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.17445993423462 seconds
Epoch 133 accuracy: 91.45%
Batch 10, Loss: 0.3229
Batch 20, Loss: 0.3500
Batch 30, Loss: 0.3357
Batch 40, Loss: 0.3418
Batch 50, Loss: 0.3418
Batch 60, Loss: 0.3518
Batch 70, Loss: 0.3381
Batch 80, Loss: 0.3172
Batch 90, Loss: 0.3602
Batch 100, Loss: 0.3400
Batch 110, Loss: 0.3419
Batch 120, Loss: 0.3670
Batch 130, Loss: 0.3169
Batch 140, Loss: 0.3564
Batch 150, Loss: 0.3473
Batch 160, Loss: 0.3510
Batch 170, Loss: 0.3533
Batch 180, Loss: 0.3141
Batch 190, Loss: 0.3239
Batch 200, Loss: 0.3288
Batch 210, Loss: 0.3373
Batch 220, Loss: 0.3015
Batch 230, Loss: 0.3166
Batch 240, Loss: 0.3536
Batch 250, Loss: 0.3295
Batch 260, Loss: 0.3134
Batch 270, Loss: 0.3369
Batch 280, Loss: 0.3466
Batch 290, Loss: 0.3447
Batch 300, Loss: 0.3845
Batch 310, Loss: 0.3111
Batch 320, Loss: 0.3655
Batch 330, Loss: 0.3311
Batch 340, Loss: 0.3479
Batch 350, Loss: 0.3569
Batch 360, Loss: 0.3760
Batch 370, Loss: 0.3598
Batch 380, Loss: 0.3335
Batch 390, Loss: 0.3280
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.084564447402954 seconds
Epoch 134 accuracy: 91.4%
Batch 10, Loss: 0.3407
Batch 20, Loss: 0.3186
Batch 30, Loss: 0.3153
Batch 40, Loss: 0.3310
Batch 50, Loss: 0.3333
Batch 60, Loss: 0.3465
Batch 70, Loss: 0.3481
Batch 80, Loss: 0.3327
Batch 90, Loss: 0.3048
Batch 100, Loss: 0.3419
Batch 110, Loss: 0.3435
Batch 120, Loss: 0.3283
Batch 130, Loss: 0.3169
Batch 140, Loss: 0.3052
Batch 150, Loss: 0.3233
Batch 160, Loss: 0.3761
Batch 170, Loss: 0.3348
Batch 180, Loss: 0.3499
Batch 190, Loss: 0.3483
Batch 200, Loss: 0.3056
Batch 210, Loss: 0.3477
Batch 220, Loss: 0.3165
Batch 230, Loss: 0.3486
Batch 240, Loss: 0.3532
Batch 250, Loss: 0.3392
Batch 260, Loss: 0.3103
Batch 270, Loss: 0.3300
Batch 280, Loss: 0.3219
Batch 290, Loss: 0.3658
Batch 300, Loss: 0.3387
Batch 310, Loss: 0.3250
Batch 320, Loss: 0.2968
Batch 330, Loss: 0.3636
Batch 340, Loss: 0.3416
Batch 350, Loss: 0.3283
Batch 360, Loss: 0.3401
Batch 370, Loss: 0.3157
Batch 380, Loss: 0.3277
Batch 390, Loss: 0.3414
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.171704292297363 seconds
Epoch 135 accuracy: 91.48%
Batch 10, Loss: 0.3587
Batch 20, Loss: 0.3738
Batch 30, Loss: 0.3381
Batch 40, Loss: 0.3509
Batch 50, Loss: 0.3340
Batch 60, Loss: 0.3228
Batch 70, Loss: 0.2950
Batch 80, Loss: 0.3452
Batch 90, Loss: 0.3391
Batch 100, Loss: 0.3572
Batch 110, Loss: 0.3281
Batch 120, Loss: 0.3497
Batch 130, Loss: 0.3428
Batch 140, Loss: 0.3146
Batch 150, Loss: 0.3011
Batch 160, Loss: 0.3459
Batch 170, Loss: 0.3227
Batch 180, Loss: 0.3409
Batch 190, Loss: 0.3184
Batch 200, Loss: 0.3213
Batch 210, Loss: 0.3148
Batch 220, Loss: 0.3008
Batch 230, Loss: 0.3337
Batch 240, Loss: 0.2928
Batch 250, Loss: 0.3099
Batch 260, Loss: 0.3291
Batch 270, Loss: 0.3185
Batch 280, Loss: 0.3430
Batch 290, Loss: 0.3397
Batch 300, Loss: 0.3202
Batch 310, Loss: 0.3227
Batch 320, Loss: 0.3308
Batch 330, Loss: 0.3391
Batch 340, Loss: 0.3319
Batch 350, Loss: 0.3320
Batch 360, Loss: 0.3408
Batch 370, Loss: 0.3573
Batch 380, Loss: 0.3229
Batch 390, Loss: 0.3320
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.25336265563965 seconds
Epoch 136 accuracy: 92.57%
Batch 10, Loss: 0.3095
Batch 20, Loss: 0.3234
Batch 30, Loss: 0.3247
Batch 40, Loss: 0.3092
Batch 50, Loss: 0.3159
Batch 60, Loss: 0.2616
Batch 70, Loss: 0.3093
Batch 80, Loss: 0.3497
Batch 90, Loss: 0.3327
Batch 100, Loss: 0.3238
Batch 110, Loss: 0.3580
Batch 120, Loss: 0.3134
Batch 130, Loss: 0.3313
Batch 140, Loss: 0.3345
Batch 150, Loss: 0.3101
Batch 160, Loss: 0.3230
Batch 170, Loss: 0.3376
Batch 180, Loss: 0.3370
Batch 190, Loss: 0.2942
Batch 200, Loss: 0.3112
Batch 210, Loss: 0.3395
Batch 220, Loss: 0.3277
Batch 230, Loss: 0.3194
Batch 240, Loss: 0.3287
Batch 250, Loss: 0.3235
Batch 260, Loss: 0.3345
Batch 270, Loss: 0.3477
Batch 280, Loss: 0.3290
Batch 290, Loss: 0.3322
Batch 300, Loss: 0.3201
Batch 310, Loss: 0.3434
Batch 320, Loss: 0.3035
Batch 330, Loss: 0.3308
Batch 340, Loss: 0.3612
Batch 350, Loss: 0.3464
Batch 360, Loss: 0.3495
Batch 370, Loss: 0.3636
Batch 380, Loss: 0.3416
Batch 390, Loss: 0.3452
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.065056085586548 seconds
Epoch 137 accuracy: 91.58%
Batch 10, Loss: 0.3380
Batch 20, Loss: 0.3647
Batch 30, Loss: 0.3142
Batch 40, Loss: 0.3062
Batch 50, Loss: 0.3253
Batch 60, Loss: 0.3111
Batch 70, Loss: 0.3283
Batch 80, Loss: 0.2900
Batch 90, Loss: 0.2777
Batch 100, Loss: 0.3176
Batch 110, Loss: 0.3251
Batch 120, Loss: 0.3038
Batch 130, Loss: 0.3140
Batch 140, Loss: 0.3277
Batch 150, Loss: 0.3470
Batch 160, Loss: 0.3009
Batch 170, Loss: 0.3139
Batch 180, Loss: 0.2959
Batch 190, Loss: 0.3005
Batch 200, Loss: 0.3139
Batch 210, Loss: 0.3344
Batch 220, Loss: 0.3437
Batch 230, Loss: 0.3364
Batch 240, Loss: 0.3052
Batch 250, Loss: 0.3563
Batch 260, Loss: 0.3319
Batch 270, Loss: 0.3352
Batch 280, Loss: 0.3103
Batch 290, Loss: 0.3314
Batch 300, Loss: 0.3172
Batch 310, Loss: 0.3093
Batch 320, Loss: 0.3210
Batch 330, Loss: 0.3041
Batch 340, Loss: 0.3105
Batch 350, Loss: 0.3402
Batch 360, Loss: 0.3382
Batch 370, Loss: 0.3693
Batch 380, Loss: 0.2981
Batch 390, Loss: 0.3380
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.148860692977905 seconds
Epoch 138 accuracy: 92.43%
Batch 10, Loss: 0.3575
Batch 20, Loss: 0.3483
Batch 30, Loss: 0.3210
Batch 40, Loss: 0.3009
Batch 50, Loss: 0.2989
Batch 60, Loss: 0.2954
Batch 70, Loss: 0.3247
Batch 80, Loss: 0.3169
Batch 90, Loss: 0.3247
Batch 100, Loss: 0.2859
Batch 110, Loss: 0.3105
Batch 120, Loss: 0.3156
Batch 130, Loss: 0.3418
Batch 140, Loss: 0.3090
Batch 150, Loss: 0.2958
Batch 160, Loss: 0.3206
Batch 170, Loss: 0.3274
Batch 180, Loss: 0.3188
Batch 190, Loss: 0.3312
Batch 200, Loss: 0.3142
Batch 210, Loss: 0.3079
Batch 220, Loss: 0.2986
Batch 230, Loss: 0.3567
Batch 240, Loss: 0.3146
Batch 250, Loss: 0.2868
Batch 260, Loss: 0.3165
Batch 270, Loss: 0.3311
Batch 280, Loss: 0.3027
Batch 290, Loss: 0.3164
Batch 300, Loss: 0.3212
Batch 310, Loss: 0.3211
Batch 320, Loss: 0.3324
Batch 330, Loss: 0.3617
Batch 340, Loss: 0.3269
Batch 350, Loss: 0.3388
Batch 360, Loss: 0.3554
Batch 370, Loss: 0.3308
Batch 380, Loss: 0.3054
Batch 390, Loss: 0.3470
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.10626459121704 seconds
Epoch 139 accuracy: 92.8%
Batch 10, Loss: 0.3166
Batch 20, Loss: 0.2951
Batch 30, Loss: 0.2844
Batch 40, Loss: 0.2765
Batch 50, Loss: 0.3000
Batch 60, Loss: 0.3219
Batch 70, Loss: 0.3025
Batch 80, Loss: 0.3212
Batch 90, Loss: 0.3539
Batch 100, Loss: 0.3024
Batch 110, Loss: 0.3262
Batch 120, Loss: 0.3140
Batch 130, Loss: 0.3020
Batch 140, Loss: 0.2770
Batch 150, Loss: 0.3298
Batch 160, Loss: 0.3017
Batch 170, Loss: 0.3311
Batch 180, Loss: 0.3226
Batch 190, Loss: 0.3232
Batch 200, Loss: 0.3199
Batch 210, Loss: 0.3083
Batch 220, Loss: 0.3041
Batch 230, Loss: 0.3263
Batch 240, Loss: 0.3201
Batch 250, Loss: 0.3495
Batch 260, Loss: 0.3279
Batch 270, Loss: 0.3054
Batch 280, Loss: 0.3656
Batch 290, Loss: 0.3267
Batch 300, Loss: 0.3264
Batch 310, Loss: 0.3447
Batch 320, Loss: 0.3097
Batch 330, Loss: 0.3150
Batch 340, Loss: 0.3403
Batch 350, Loss: 0.3096
Batch 360, Loss: 0.2998
Batch 370, Loss: 0.2881
Batch 380, Loss: 0.3040
Batch 390, Loss: 0.3045
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.137049913406372 seconds
Epoch 140 accuracy: 92.52%
Batch 10, Loss: 0.3013
Batch 20, Loss: 0.3209
Batch 30, Loss: 0.3247
Batch 40, Loss: 0.2949
Batch 50, Loss: 0.3213
Batch 60, Loss: 0.3445
Batch 70, Loss: 0.2620
Batch 80, Loss: 0.3073
Batch 90, Loss: 0.3262
Batch 100, Loss: 0.2818
Batch 110, Loss: 0.2997
Batch 120, Loss: 0.2905
Batch 130, Loss: 0.3057
Batch 140, Loss: 0.3265
Batch 150, Loss: 0.3211
Batch 160, Loss: 0.2825
Batch 170, Loss: 0.3217
Batch 180, Loss: 0.3046
Batch 190, Loss: 0.3393
Batch 200, Loss: 0.3275
Batch 210, Loss: 0.2999
Batch 220, Loss: 0.2789
Batch 230, Loss: 0.3250
Batch 240, Loss: 0.3206
Batch 250, Loss: 0.2749
Batch 260, Loss: 0.3144
Batch 270, Loss: 0.2897
Batch 280, Loss: 0.3221
Batch 290, Loss: 0.3362
Batch 300, Loss: 0.3365
Batch 310, Loss: 0.2932
Batch 320, Loss: 0.3097
Batch 330, Loss: 0.2996
Batch 340, Loss: 0.3141
Batch 350, Loss: 0.3162
Batch 360, Loss: 0.3430
Batch 370, Loss: 0.3459
Batch 380, Loss: 0.3141
Batch 390, Loss: 0.3098
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.155458688735962 seconds
Epoch 141 accuracy: 92.54%
Batch 10, Loss: 0.2834
Batch 20, Loss: 0.3172
Batch 30, Loss: 0.2573
Batch 40, Loss: 0.3039
Batch 50, Loss: 0.3064
Batch 60, Loss: 0.2695
Batch 70, Loss: 0.3173
Batch 80, Loss: 0.2934
Batch 90, Loss: 0.3356
Batch 100, Loss: 0.3416
Batch 110, Loss: 0.3075
Batch 120, Loss: 0.2961
Batch 130, Loss: 0.2899
Batch 140, Loss: 0.3089
Batch 150, Loss: 0.2588
Batch 160, Loss: 0.3327
Batch 170, Loss: 0.3069
Batch 180, Loss: 0.3274
Batch 190, Loss: 0.3159
Batch 200, Loss: 0.3091
Batch 210, Loss: 0.3188
Batch 220, Loss: 0.2935
Batch 230, Loss: 0.2911
Batch 240, Loss: 0.3197
Batch 250, Loss: 0.2870
Batch 260, Loss: 0.3371
Batch 270, Loss: 0.3064
Batch 280, Loss: 0.3221
Batch 290, Loss: 0.2855
Batch 300, Loss: 0.3102
Batch 310, Loss: 0.3255
Batch 320, Loss: 0.3285
Batch 330, Loss: 0.3024
Batch 340, Loss: 0.3143
Batch 350, Loss: 0.3196
Batch 360, Loss: 0.3028
Batch 370, Loss: 0.3000
Batch 380, Loss: 0.3191
Batch 390, Loss: 0.2988
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.075587272644043 seconds
Epoch 142 accuracy: 92.22%
Batch 10, Loss: 0.3442
Batch 20, Loss: 0.2878
Batch 30, Loss: 0.3017
Batch 40, Loss: 0.2823
Batch 50, Loss: 0.3236
Batch 60, Loss: 0.2732
Batch 70, Loss: 0.3320
Batch 80, Loss: 0.2777
Batch 90, Loss: 0.3114
Batch 100, Loss: 0.2693
Batch 110, Loss: 0.3178
Batch 120, Loss: 0.3012
Batch 130, Loss: 0.3201
Batch 140, Loss: 0.3043
Batch 150, Loss: 0.2923
Batch 160, Loss: 0.3226
Batch 170, Loss: 0.2886
Batch 180, Loss: 0.3321
Batch 190, Loss: 0.3148
Batch 200, Loss: 0.3285
Batch 210, Loss: 0.2907
Batch 220, Loss: 0.3127
Batch 230, Loss: 0.3323
Batch 240, Loss: 0.3126
Batch 250, Loss: 0.3070
Batch 260, Loss: 0.3158
Batch 270, Loss: 0.3116
Batch 280, Loss: 0.3100
Batch 290, Loss: 0.3225
Batch 300, Loss: 0.2997
Batch 310, Loss: 0.3038
Batch 320, Loss: 0.3001
Batch 330, Loss: 0.3284
Batch 340, Loss: 0.2804
Batch 350, Loss: 0.2770
Batch 360, Loss: 0.3322
Batch 370, Loss: 0.2932
Batch 380, Loss: 0.2958
Batch 390, Loss: 0.3211
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.09332299232483 seconds
Epoch 143 accuracy: 92.6%
Batch 10, Loss: 0.3126
Batch 20, Loss: 0.2916
Batch 30, Loss: 0.2838
Batch 40, Loss: 0.2895
Batch 50, Loss: 0.3046
Batch 60, Loss: 0.3011
Batch 70, Loss: 0.2838
Batch 80, Loss: 0.2979
Batch 90, Loss: 0.2881
Batch 100, Loss: 0.2869
Batch 110, Loss: 0.2753
Batch 120, Loss: 0.2959
Batch 130, Loss: 0.2871
Batch 140, Loss: 0.3023
Batch 150, Loss: 0.3074
Batch 160, Loss: 0.2992
Batch 170, Loss: 0.3118
Batch 180, Loss: 0.2944
Batch 190, Loss: 0.2954
Batch 200, Loss: 0.2975
Batch 210, Loss: 0.3209
Batch 220, Loss: 0.3370
Batch 230, Loss: 0.2815
Batch 240, Loss: 0.2727
Batch 250, Loss: 0.3140
Batch 260, Loss: 0.2958
Batch 270, Loss: 0.3041
Batch 280, Loss: 0.2965
Batch 290, Loss: 0.3182
Batch 300, Loss: 0.2951
Batch 310, Loss: 0.2933
Batch 320, Loss: 0.3198
Batch 330, Loss: 0.3093
Batch 340, Loss: 0.3204
Batch 350, Loss: 0.3297
Batch 360, Loss: 0.2937
Batch 370, Loss: 0.3103
Batch 380, Loss: 0.3323
Batch 390, Loss: 0.3033
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.01355481147766 seconds
Epoch 144 accuracy: 92.49%
Batch 10, Loss: 0.3521
Batch 20, Loss: 0.3105
Batch 30, Loss: 0.3093
Batch 40, Loss: 0.2827
Batch 50, Loss: 0.2750
Batch 60, Loss: 0.2989
Batch 70, Loss: 0.3136
Batch 80, Loss: 0.2843
Batch 90, Loss: 0.2938
Batch 100, Loss: 0.3059
Batch 110, Loss: 0.3375
Batch 120, Loss: 0.2834
Batch 130, Loss: 0.2771
Batch 140, Loss: 0.2724
Batch 150, Loss: 0.2724
Batch 160, Loss: 0.2843
Batch 170, Loss: 0.2927
Batch 180, Loss: 0.2744
Batch 190, Loss: 0.2794
Batch 200, Loss: 0.3178
Batch 210, Loss: 0.3026
Batch 220, Loss: 0.2972
Batch 230, Loss: 0.3007
Batch 240, Loss: 0.3095
Batch 250, Loss: 0.3054
Batch 260, Loss: 0.3061
Batch 270, Loss: 0.3057
Batch 280, Loss: 0.3323
Batch 290, Loss: 0.2805
Batch 300, Loss: 0.3166
Batch 310, Loss: 0.2693
Batch 320, Loss: 0.2890
Batch 330, Loss: 0.2985
Batch 340, Loss: 0.3126
Batch 350, Loss: 0.3079
Batch 360, Loss: 0.2981
Batch 370, Loss: 0.3500
Batch 380, Loss: 0.2866
Batch 390, Loss: 0.2887
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.111835956573486 seconds
Epoch 145 accuracy: 92.62%
Batch 10, Loss: 0.3236
Batch 20, Loss: 0.3032
Batch 30, Loss: 0.3012
Batch 40, Loss: 0.2838
Batch 50, Loss: 0.2941
Batch 60, Loss: 0.2575
Batch 70, Loss: 0.2799
Batch 80, Loss: 0.3074
Batch 90, Loss: 0.2811
Batch 100, Loss: 0.3060
Batch 110, Loss: 0.3100
Batch 120, Loss: 0.3161
Batch 130, Loss: 0.2799
Batch 140, Loss: 0.2879
Batch 150, Loss: 0.2995
Batch 160, Loss: 0.2907
Batch 170, Loss: 0.3082
Batch 180, Loss: 0.3050
Batch 190, Loss: 0.2925
Batch 200, Loss: 0.2937
Batch 210, Loss: 0.2842
Batch 220, Loss: 0.2855
Batch 230, Loss: 0.3043
Batch 240, Loss: 0.2720
Batch 250, Loss: 0.2967
Batch 260, Loss: 0.2680
Batch 270, Loss: 0.2584
Batch 280, Loss: 0.2700
Batch 290, Loss: 0.3075
Batch 300, Loss: 0.2986
Batch 310, Loss: 0.3187
Batch 320, Loss: 0.3041
Batch 330, Loss: 0.2884
Batch 340, Loss: 0.2856
Batch 350, Loss: 0.3249
Batch 360, Loss: 0.2917
Batch 370, Loss: 0.3068
Batch 380, Loss: 0.2832
Batch 390, Loss: 0.3145
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.22461771965027 seconds
Epoch 146 accuracy: 92.38%
Batch 10, Loss: 0.3154
Batch 20, Loss: 0.2934
Batch 30, Loss: 0.2932
Batch 40, Loss: 0.3147
Batch 50, Loss: 0.2566
Batch 60, Loss: 0.2963
Batch 70, Loss: 0.2703
Batch 80, Loss: 0.2888
Batch 90, Loss: 0.2713
Batch 100, Loss: 0.2864
Batch 110, Loss: 0.2777
Batch 120, Loss: 0.2426
Batch 130, Loss: 0.2854
Batch 140, Loss: 0.2827
Batch 150, Loss: 0.2922
Batch 160, Loss: 0.2870
Batch 170, Loss: 0.2992
Batch 180, Loss: 0.2826
Batch 190, Loss: 0.2756
Batch 200, Loss: 0.2699
Batch 210, Loss: 0.2993
Batch 220, Loss: 0.2889
Batch 230, Loss: 0.2872
Batch 240, Loss: 0.2876
Batch 250, Loss: 0.2910
Batch 260, Loss: 0.2905
Batch 270, Loss: 0.2647
Batch 280, Loss: 0.2965
Batch 290, Loss: 0.2790
Batch 300, Loss: 0.2788
Batch 310, Loss: 0.2896
Batch 320, Loss: 0.2891
Batch 330, Loss: 0.2950
Batch 340, Loss: 0.3014
Batch 350, Loss: 0.2821
Batch 360, Loss: 0.2847
Batch 370, Loss: 0.3139
Batch 380, Loss: 0.2691
Batch 390, Loss: 0.2993
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.218976736068726 seconds
Epoch 147 accuracy: 93.26%
Batch 10, Loss: 0.2754
Batch 20, Loss: 0.2928
Batch 30, Loss: 0.2685
Batch 40, Loss: 0.3081
Batch 50, Loss: 0.2606
Batch 60, Loss: 0.2651
Batch 70, Loss: 0.2732
Batch 80, Loss: 0.3202
Batch 90, Loss: 0.2699
Batch 100, Loss: 0.3066
Batch 110, Loss: 0.2769
Batch 120, Loss: 0.2946
Batch 130, Loss: 0.2929
Batch 140, Loss: 0.2753
Batch 150, Loss: 0.2611
Batch 160, Loss: 0.2876
Batch 170, Loss: 0.3007
Batch 180, Loss: 0.3058
Batch 190, Loss: 0.2264
Batch 200, Loss: 0.2952
Batch 210, Loss: 0.2532
Batch 220, Loss: 0.2960
Batch 230, Loss: 0.2572
Batch 240, Loss: 0.2980
Batch 250, Loss: 0.2827
Batch 260, Loss: 0.2302
Batch 270, Loss: 0.2712
Batch 280, Loss: 0.2770
Batch 290, Loss: 0.2670
Batch 300, Loss: 0.2605
Batch 310, Loss: 0.2934
Batch 320, Loss: 0.2994
Batch 330, Loss: 0.3264
Batch 340, Loss: 0.2893
Batch 350, Loss: 0.2630
Batch 360, Loss: 0.2908
Batch 370, Loss: 0.2916
Batch 380, Loss: 0.2950
Batch 390, Loss: 0.2894
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.19004464149475 seconds
Epoch 148 accuracy: 93.17%
Batch 10, Loss: 0.2661
Batch 20, Loss: 0.2958
Batch 30, Loss: 0.3010
Batch 40, Loss: 0.2838
Batch 50, Loss: 0.2820
Batch 60, Loss: 0.2521
Batch 70, Loss: 0.2618
Batch 80, Loss: 0.2963
Batch 90, Loss: 0.2827
Batch 100, Loss: 0.2685
Batch 110, Loss: 0.2998
Batch 120, Loss: 0.2875
Batch 130, Loss: 0.2864
Batch 140, Loss: 0.3004
Batch 150, Loss: 0.3000
Batch 160, Loss: 0.3028
Batch 170, Loss: 0.2475
Batch 180, Loss: 0.2717
Batch 190, Loss: 0.2820
Batch 200, Loss: 0.2692
Batch 210, Loss: 0.2629
Batch 220, Loss: 0.2853
Batch 230, Loss: 0.2693
Batch 240, Loss: 0.2833
Batch 250, Loss: 0.2781
Batch 260, Loss: 0.2698
Batch 270, Loss: 0.2864
Batch 280, Loss: 0.2814
Batch 290, Loss: 0.3005
Batch 300, Loss: 0.2814
Batch 310, Loss: 0.2710
Batch 320, Loss: 0.2776
Batch 330, Loss: 0.2933
Batch 340, Loss: 0.3036
Batch 350, Loss: 0.3030
Batch 360, Loss: 0.2892
Batch 370, Loss: 0.2977
Batch 380, Loss: 0.2597
Batch 390, Loss: 0.2496
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.14786958694458 seconds
Epoch 149 accuracy: 93.24%
Batch 10, Loss: 0.2843
Batch 20, Loss: 0.2690
Batch 30, Loss: 0.2946
Batch 40, Loss: 0.2865
Batch 50, Loss: 0.2727
Batch 60, Loss: 0.2573
Batch 70, Loss: 0.2547
Batch 80, Loss: 0.2669
Batch 90, Loss: 0.2536
Batch 100, Loss: 0.3209
Batch 110, Loss: 0.2767
Batch 120, Loss: 0.2737
Batch 130, Loss: 0.3281
Batch 140, Loss: 0.2513
Batch 150, Loss: 0.2982
Batch 160, Loss: 0.3048
Batch 170, Loss: 0.2864
Batch 180, Loss: 0.2976
Batch 190, Loss: 0.2569
Batch 200, Loss: 0.2661
Batch 210, Loss: 0.2826
Batch 220, Loss: 0.2912
Batch 230, Loss: 0.2749
Batch 240, Loss: 0.2778
Batch 250, Loss: 0.2637
Batch 260, Loss: 0.2771
Batch 270, Loss: 0.3200
Batch 280, Loss: 0.2697
Batch 290, Loss: 0.2602
Batch 300, Loss: 0.2723
Batch 310, Loss: 0.2725
Batch 320, Loss: 0.2977
Batch 330, Loss: 0.3009
Batch 340, Loss: 0.2824
Batch 350, Loss: 0.2757
Batch 360, Loss: 0.2964
Batch 370, Loss: 0.2912
Batch 380, Loss: 0.2429
Batch 390, Loss: 0.2597
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.15307593345642 seconds
Epoch 150 accuracy: 93.73%
Batch 10, Loss: 0.2981
Batch 20, Loss: 0.2718
Batch 30, Loss: 0.2672
Batch 40, Loss: 0.2568
Batch 50, Loss: 0.2760
Batch 60, Loss: 0.2532
Batch 70, Loss: 0.2706
Batch 80, Loss: 0.2922
Batch 90, Loss: 0.2734
Batch 100, Loss: 0.2920
Batch 110, Loss: 0.2878
Batch 120, Loss: 0.2981
Batch 130, Loss: 0.2860
Batch 140, Loss: 0.2696
Batch 150, Loss: 0.2717
Batch 160, Loss: 0.2844
Batch 170, Loss: 0.2804
Batch 180, Loss: 0.2742
Batch 190, Loss: 0.2847
Batch 200, Loss: 0.2751
Batch 210, Loss: 0.2834
Batch 220, Loss: 0.2830
Batch 230, Loss: 0.3098
Batch 240, Loss: 0.2876
Batch 250, Loss: 0.2620
Batch 260, Loss: 0.2779
Batch 270, Loss: 0.2724
Batch 280, Loss: 0.2893
Batch 290, Loss: 0.2725
Batch 300, Loss: 0.2457
Batch 310, Loss: 0.2689
Batch 320, Loss: 0.2424
Batch 330, Loss: 0.2935
Batch 340, Loss: 0.2650
Batch 350, Loss: 0.2751
Batch 360, Loss: 0.2998
Batch 370, Loss: 0.2934
Batch 380, Loss: 0.2759
Batch 390, Loss: 0.2882
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.060227394104004 seconds
Epoch 151 accuracy: 93.67%
Batch 10, Loss: 0.2891
Batch 20, Loss: 0.2602
Batch 30, Loss: 0.2486
Batch 40, Loss: 0.2532
Batch 50, Loss: 0.2559
Batch 60, Loss: 0.2809
Batch 70, Loss: 0.2587
Batch 80, Loss: 0.2534
Batch 90, Loss: 0.2652
Batch 100, Loss: 0.2809
Batch 110, Loss: 0.2801
Batch 120, Loss: 0.2462
Batch 130, Loss: 0.2514
Batch 140, Loss: 0.2781
Batch 150, Loss: 0.2864
Batch 160, Loss: 0.2686
Batch 170, Loss: 0.2698
Batch 180, Loss: 0.2784
Batch 190, Loss: 0.2797
Batch 200, Loss: 0.2597
Batch 210, Loss: 0.2599
Batch 220, Loss: 0.2793
Batch 230, Loss: 0.2833
Batch 240, Loss: 0.2904
Batch 250, Loss: 0.2971
Batch 260, Loss: 0.2813
Batch 270, Loss: 0.2927
Batch 280, Loss: 0.2445
Batch 290, Loss: 0.2665
Batch 300, Loss: 0.2785
Batch 310, Loss: 0.2565
Batch 320, Loss: 0.2711
Batch 330, Loss: 0.2921
Batch 340, Loss: 0.2770
Batch 350, Loss: 0.3094
Batch 360, Loss: 0.2895
Batch 370, Loss: 0.2734
Batch 380, Loss: 0.2631
Batch 390, Loss: 0.2690
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.153984308242798 seconds
Epoch 152 accuracy: 93.96%
Batch 10, Loss: 0.2673
Batch 20, Loss: 0.2635
Batch 30, Loss: 0.2862
Batch 40, Loss: 0.2735
Batch 50, Loss: 0.2778
Batch 60, Loss: 0.2385
Batch 70, Loss: 0.2700
Batch 80, Loss: 0.2884
Batch 90, Loss: 0.2614
Batch 100, Loss: 0.2639
Batch 110, Loss: 0.2416
Batch 120, Loss: 0.2756
Batch 130, Loss: 0.2814
Batch 140, Loss: 0.2424
Batch 150, Loss: 0.2540
Batch 160, Loss: 0.2774
Batch 170, Loss: 0.2507
Batch 180, Loss: 0.2312
Batch 190, Loss: 0.2665
Batch 200, Loss: 0.2680
Batch 210, Loss: 0.2504
Batch 220, Loss: 0.2485
Batch 230, Loss: 0.2719
Batch 240, Loss: 0.2894
Batch 250, Loss: 0.2736
Batch 260, Loss: 0.2833
Batch 270, Loss: 0.2878
Batch 280, Loss: 0.2613
Batch 290, Loss: 0.2655
Batch 300, Loss: 0.2445
Batch 310, Loss: 0.2680
Batch 320, Loss: 0.2590
Batch 330, Loss: 0.3062
Batch 340, Loss: 0.2717
Batch 350, Loss: 0.2939
Batch 360, Loss: 0.2747
Batch 370, Loss: 0.2902
Batch 380, Loss: 0.2770
Batch 390, Loss: 0.2825
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.168891429901123 seconds
Epoch 153 accuracy: 93.32%
Batch 10, Loss: 0.2337
Batch 20, Loss: 0.2489
Batch 30, Loss: 0.2496
Batch 40, Loss: 0.2573
Batch 50, Loss: 0.2779
Batch 60, Loss: 0.2669
Batch 70, Loss: 0.2478
Batch 80, Loss: 0.2473
Batch 90, Loss: 0.2574
Batch 100, Loss: 0.2713
Batch 110, Loss: 0.2729
Batch 120, Loss: 0.2519
Batch 130, Loss: 0.2474
Batch 140, Loss: 0.2783
Batch 150, Loss: 0.2786
Batch 160, Loss: 0.2689
Batch 170, Loss: 0.2759
Batch 180, Loss: 0.2634
Batch 190, Loss: 0.2406
Batch 200, Loss: 0.2681
Batch 210, Loss: 0.2905
Batch 220, Loss: 0.2730
Batch 230, Loss: 0.2477
Batch 240, Loss: 0.2641
Batch 250, Loss: 0.2535
Batch 260, Loss: 0.2815
Batch 270, Loss: 0.2816
Batch 280, Loss: 0.2560
Batch 290, Loss: 0.2657
Batch 300, Loss: 0.2840
Batch 310, Loss: 0.2803
Batch 320, Loss: 0.2667
Batch 330, Loss: 0.2593
Batch 340, Loss: 0.2447
Batch 350, Loss: 0.2591
Batch 360, Loss: 0.2557
Batch 370, Loss: 0.2451
Batch 380, Loss: 0.2541
Batch 390, Loss: 0.3046
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.09426236152649 seconds
Epoch 154 accuracy: 93.97%
Batch 10, Loss: 0.2633
Batch 20, Loss: 0.2601
Batch 30, Loss: 0.2542
Batch 40, Loss: 0.2699
Batch 50, Loss: 0.2531
Batch 60, Loss: 0.2665
Batch 70, Loss: 0.2745
Batch 80, Loss: 0.2417
Batch 90, Loss: 0.2702
Batch 100, Loss: 0.2623
Batch 110, Loss: 0.2809
Batch 120, Loss: 0.2767
Batch 130, Loss: 0.2211
Batch 140, Loss: 0.2535
Batch 150, Loss: 0.2564
Batch 160, Loss: 0.2488
Batch 170, Loss: 0.2563
Batch 180, Loss: 0.2720
Batch 190, Loss: 0.2471
Batch 200, Loss: 0.2724
Batch 210, Loss: 0.2750
Batch 220, Loss: 0.2665
Batch 230, Loss: 0.2577
Batch 240, Loss: 0.2884
Batch 250, Loss: 0.2496
Batch 260, Loss: 0.2328
Batch 270, Loss: 0.2582
Batch 280, Loss: 0.2953
Batch 290, Loss: 0.2780
Batch 300, Loss: 0.2732
Batch 310, Loss: 0.2581
Batch 320, Loss: 0.2579
Batch 330, Loss: 0.2898
Batch 340, Loss: 0.2457
Batch 350, Loss: 0.2653
Batch 360, Loss: 0.2645
Batch 370, Loss: 0.2907
Batch 380, Loss: 0.2519
Batch 390, Loss: 0.2385
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.156007289886475 seconds
Epoch 155 accuracy: 94.11%
Batch 10, Loss: 0.2518
Batch 20, Loss: 0.2472
Batch 30, Loss: 0.2373
Batch 40, Loss: 0.2425
Batch 50, Loss: 0.2805
Batch 60, Loss: 0.2480
Batch 70, Loss: 0.2583
Batch 80, Loss: 0.2553
Batch 90, Loss: 0.2911
Batch 100, Loss: 0.2539
Batch 110, Loss: 0.2682
Batch 120, Loss: 0.2481
Batch 130, Loss: 0.2322
Batch 140, Loss: 0.2326
Batch 150, Loss: 0.2430
Batch 160, Loss: 0.2569
Batch 170, Loss: 0.2837
Batch 180, Loss: 0.2784
Batch 190, Loss: 0.2480
Batch 200, Loss: 0.2518
Batch 210, Loss: 0.2493
Batch 220, Loss: 0.2219
Batch 230, Loss: 0.2368
Batch 240, Loss: 0.2369
Batch 250, Loss: 0.2567
Batch 260, Loss: 0.2290
Batch 270, Loss: 0.2430
Batch 280, Loss: 0.2546
Batch 290, Loss: 0.2417
Batch 300, Loss: 0.2247
Batch 310, Loss: 0.2570
Batch 320, Loss: 0.2491
Batch 330, Loss: 0.2538
Batch 340, Loss: 0.2553
Batch 350, Loss: 0.2624
Batch 360, Loss: 0.2650
Batch 370, Loss: 0.2911
Batch 380, Loss: 0.2579
Batch 390, Loss: 0.2753
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.316633224487305 seconds
Epoch 156 accuracy: 94.21%
Batch 10, Loss: 0.2578
Batch 20, Loss: 0.2106
Batch 30, Loss: 0.2805
Batch 40, Loss: 0.2227
Batch 50, Loss: 0.2295
Batch 60, Loss: 0.2329
Batch 70, Loss: 0.2439
Batch 80, Loss: 0.2637
Batch 90, Loss: 0.2208
Batch 100, Loss: 0.2240
Batch 110, Loss: 0.2517
Batch 120, Loss: 0.2251
Batch 130, Loss: 0.2691
Batch 140, Loss: 0.2747
Batch 150, Loss: 0.2446
Batch 160, Loss: 0.2412
Batch 170, Loss: 0.2549
Batch 180, Loss: 0.2445
Batch 190, Loss: 0.2580
Batch 200, Loss: 0.2314
Batch 210, Loss: 0.2388
Batch 220, Loss: 0.2510
Batch 230, Loss: 0.2511
Batch 240, Loss: 0.2670
Batch 250, Loss: 0.2400
Batch 260, Loss: 0.2636
Batch 270, Loss: 0.2308
Batch 280, Loss: 0.2459
Batch 290, Loss: 0.2542
Batch 300, Loss: 0.2568
Batch 310, Loss: 0.2629
Batch 320, Loss: 0.2644
Batch 330, Loss: 0.2434
Batch 340, Loss: 0.2480
Batch 350, Loss: 0.2464
Batch 360, Loss: 0.2596
Batch 370, Loss: 0.2702
Batch 380, Loss: 0.2753
Batch 390, Loss: 0.2499
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.207573175430298 seconds
Epoch 157 accuracy: 93.89%
Batch 10, Loss: 0.2302
Batch 20, Loss: 0.2417
Batch 30, Loss: 0.2711
Batch 40, Loss: 0.2514
Batch 50, Loss: 0.2457
Batch 60, Loss: 0.2258
Batch 70, Loss: 0.2292
Batch 80, Loss: 0.2451
Batch 90, Loss: 0.2642
Batch 100, Loss: 0.2644
Batch 110, Loss: 0.2294
Batch 120, Loss: 0.2563
Batch 130, Loss: 0.2665
Batch 140, Loss: 0.2397
Batch 150, Loss: 0.2409
Batch 160, Loss: 0.2275
Batch 170, Loss: 0.2114
Batch 180, Loss: 0.2439
Batch 190, Loss: 0.2354
Batch 200, Loss: 0.2323
Batch 210, Loss: 0.2518
Batch 220, Loss: 0.2076
Batch 230, Loss: 0.2531
Batch 240, Loss: 0.2411
Batch 250, Loss: 0.2624
Batch 260, Loss: 0.2716
Batch 270, Loss: 0.2462
Batch 280, Loss: 0.2645
Batch 290, Loss: 0.2363
Batch 300, Loss: 0.2730
Batch 310, Loss: 0.2657
Batch 320, Loss: 0.2742
Batch 330, Loss: 0.2284
Batch 340, Loss: 0.2577
Batch 350, Loss: 0.2201
Batch 360, Loss: 0.2364
Batch 370, Loss: 0.2806
Batch 380, Loss: 0.2388
Batch 390, Loss: 0.2447
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.118561029434204 seconds
Epoch 158 accuracy: 93.78%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2562
Batch 30, Loss: 0.2268
Batch 40, Loss: 0.2210
Batch 50, Loss: 0.2476
Batch 60, Loss: 0.2275
Batch 70, Loss: 0.2315
Batch 80, Loss: 0.2406
Batch 90, Loss: 0.2640
Batch 100, Loss: 0.2478
Batch 110, Loss: 0.2483
Batch 120, Loss: 0.2272
Batch 130, Loss: 0.2356
Batch 140, Loss: 0.2714
Batch 150, Loss: 0.2260
Batch 160, Loss: 0.2229
Batch 170, Loss: 0.2277
Batch 180, Loss: 0.2717
Batch 190, Loss: 0.2637
Batch 200, Loss: 0.2544
Batch 210, Loss: 0.2500
Batch 220, Loss: 0.2407
Batch 230, Loss: 0.2230
Batch 240, Loss: 0.2604
Batch 250, Loss: 0.2368
Batch 260, Loss: 0.2090
Batch 270, Loss: 0.2499
Batch 280, Loss: 0.2675
Batch 290, Loss: 0.2474
Batch 300, Loss: 0.2471
Batch 310, Loss: 0.2487
Batch 320, Loss: 0.2154
Batch 330, Loss: 0.2360
Batch 340, Loss: 0.2360
Batch 350, Loss: 0.2628
Batch 360, Loss: 0.2202
Batch 370, Loss: 0.2667
Batch 380, Loss: 0.2419
Batch 390, Loss: 0.2617
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.28154945373535 seconds
Epoch 159 accuracy: 94.05%
Batch 10, Loss: 0.2293
Batch 20, Loss: 0.2701
Batch 30, Loss: 0.2563
Batch 40, Loss: 0.2427
Batch 50, Loss: 0.2552
Batch 60, Loss: 0.2533
Batch 70, Loss: 0.2087
Batch 80, Loss: 0.2231
Batch 90, Loss: 0.2268
Batch 100, Loss: 0.2498
Batch 110, Loss: 0.2763
Batch 120, Loss: 0.2420
Batch 130, Loss: 0.2390
Batch 140, Loss: 0.2442
Batch 150, Loss: 0.2162
Batch 160, Loss: 0.2142
Batch 170, Loss: 0.2575
Batch 180, Loss: 0.2370
Batch 190, Loss: 0.2496
Batch 200, Loss: 0.2371
Batch 210, Loss: 0.2186
Batch 220, Loss: 0.2727
Batch 230, Loss: 0.2337
Batch 240, Loss: 0.2138
Batch 250, Loss: 0.2431
Batch 260, Loss: 0.2430
Batch 270, Loss: 0.2108
Batch 280, Loss: 0.2702
Batch 290, Loss: 0.2422
Batch 300, Loss: 0.2155
Batch 310, Loss: 0.2513
Batch 320, Loss: 0.2397
Batch 330, Loss: 0.2214
Batch 340, Loss: 0.2388
Batch 350, Loss: 0.2250
Batch 360, Loss: 0.2547
Batch 370, Loss: 0.2209
Batch 380, Loss: 0.2519
Batch 390, Loss: 0.2232
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.04833197593689 seconds
Epoch 160 accuracy: 94.23%
Batch 10, Loss: 0.2655
Batch 20, Loss: 0.2478
Batch 30, Loss: 0.2032
Batch 40, Loss: 0.2053
Batch 50, Loss: 0.2173
Batch 60, Loss: 0.2280
Batch 70, Loss: 0.2024
Batch 80, Loss: 0.2458
Batch 90, Loss: 0.2229
Batch 100, Loss: 0.1995
Batch 110, Loss: 0.2273
Batch 120, Loss: 0.2404
Batch 130, Loss: 0.2355
Batch 140, Loss: 0.2407
Batch 150, Loss: 0.2438
Batch 160, Loss: 0.2433
Batch 170, Loss: 0.2575
Batch 180, Loss: 0.2302
Batch 190, Loss: 0.2140
Batch 200, Loss: 0.2400
Batch 210, Loss: 0.2206
Batch 220, Loss: 0.2521
Batch 230, Loss: 0.2372
Batch 240, Loss: 0.2111
Batch 250, Loss: 0.2356
Batch 260, Loss: 0.2287
Batch 270, Loss: 0.2400
Batch 280, Loss: 0.2462
Batch 290, Loss: 0.2555
Batch 300, Loss: 0.2410
Batch 310, Loss: 0.2440
Batch 320, Loss: 0.2509
Batch 330, Loss: 0.2329
Batch 340, Loss: 0.2724
Batch 350, Loss: 0.2412
Batch 360, Loss: 0.2275
Batch 370, Loss: 0.2246
Batch 380, Loss: 0.2552
Batch 390, Loss: 0.2059
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.344042539596558 seconds
Epoch 161 accuracy: 94.02%
Batch 10, Loss: 0.2426
Batch 20, Loss: 0.2300
Batch 30, Loss: 0.2285
Batch 40, Loss: 0.2125
Batch 50, Loss: 0.2193
Batch 60, Loss: 0.2285
Batch 70, Loss: 0.2404
Batch 80, Loss: 0.2365
Batch 90, Loss: 0.2451
Batch 100, Loss: 0.2478
Batch 110, Loss: 0.2287
Batch 120, Loss: 0.2383
Batch 130, Loss: 0.2443
Batch 140, Loss: 0.2370
Batch 150, Loss: 0.2306
Batch 160, Loss: 0.2438
Batch 170, Loss: 0.2267
Batch 180, Loss: 0.2480
Batch 190, Loss: 0.2432
Batch 200, Loss: 0.2481
Batch 210, Loss: 0.2340
Batch 220, Loss: 0.2262
Batch 230, Loss: 0.2254
Batch 240, Loss: 0.2143
Batch 250, Loss: 0.2230
Batch 260, Loss: 0.2378
Batch 270, Loss: 0.2255
Batch 280, Loss: 0.2384
Batch 290, Loss: 0.2430
Batch 300, Loss: 0.2180
Batch 310, Loss: 0.2388
Batch 320, Loss: 0.2529
Batch 330, Loss: 0.2406
Batch 340, Loss: 0.2204
Batch 350, Loss: 0.2687
Batch 360, Loss: 0.2157
Batch 370, Loss: 0.2290
Batch 380, Loss: 0.2136
Batch 390, Loss: 0.2317
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.069334983825684 seconds
Epoch 162 accuracy: 94.52%
Batch 10, Loss: 0.2141
Batch 20, Loss: 0.2300
Batch 30, Loss: 0.2386
Batch 40, Loss: 0.2029
Batch 50, Loss: 0.2556
Batch 60, Loss: 0.2314
Batch 70, Loss: 0.1864
Batch 80, Loss: 0.2457
Batch 90, Loss: 0.2493
Batch 100, Loss: 0.2363
Batch 110, Loss: 0.2054
Batch 120, Loss: 0.2267
Batch 130, Loss: 0.2172
Batch 140, Loss: 0.2372
Batch 150, Loss: 0.2083
Batch 160, Loss: 0.2159
Batch 170, Loss: 0.2250
Batch 180, Loss: 0.2307
Batch 190, Loss: 0.2030
Batch 200, Loss: 0.2278
Batch 210, Loss: 0.2515
Batch 220, Loss: 0.2473
Batch 230, Loss: 0.2260
Batch 240, Loss: 0.2377
Batch 250, Loss: 0.2250
Batch 260, Loss: 0.2396
Batch 270, Loss: 0.2107
Batch 280, Loss: 0.2328
Batch 290, Loss: 0.2266
Batch 300, Loss: 0.2107
Batch 310, Loss: 0.2366
Batch 320, Loss: 0.2275
Batch 330, Loss: 0.2472
Batch 340, Loss: 0.2189
Batch 350, Loss: 0.2058
Batch 360, Loss: 0.2377
Batch 370, Loss: 0.2204
Batch 380, Loss: 0.2154
Batch 390, Loss: 0.2183
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.09495520591736 seconds
Epoch 163 accuracy: 94.6%
Batch 10, Loss: 0.2169
Batch 20, Loss: 0.2084
Batch 30, Loss: 0.2404
Batch 40, Loss: 0.2117
Batch 50, Loss: 0.2264
Batch 60, Loss: 0.2203
Batch 70, Loss: 0.2446
Batch 80, Loss: 0.2132
Batch 90, Loss: 0.2204
Batch 100, Loss: 0.2089
Batch 110, Loss: 0.1884
Batch 120, Loss: 0.2248
Batch 130, Loss: 0.2178
Batch 140, Loss: 0.2131
Batch 150, Loss: 0.2088
Batch 160, Loss: 0.2148
Batch 170, Loss: 0.2310
Batch 180, Loss: 0.2357
Batch 190, Loss: 0.1998
Batch 200, Loss: 0.2367
Batch 210, Loss: 0.2656
Batch 220, Loss: 0.2180
Batch 230, Loss: 0.2051
Batch 240, Loss: 0.2305
Batch 250, Loss: 0.2179
Batch 260, Loss: 0.2537
Batch 270, Loss: 0.2404
Batch 280, Loss: 0.2028
Batch 290, Loss: 0.2226
Batch 300, Loss: 0.2433
Batch 310, Loss: 0.2394
Batch 320, Loss: 0.2268
Batch 330, Loss: 0.2291
Batch 340, Loss: 0.2186
Batch 350, Loss: 0.2301
Batch 360, Loss: 0.2209
Batch 370, Loss: 0.2354
Batch 380, Loss: 0.2166
Batch 390, Loss: 0.2402
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.1750431060791 seconds
Epoch 164 accuracy: 94.54%
Batch 10, Loss: 0.2353
Batch 20, Loss: 0.2086
Batch 30, Loss: 0.2262
Batch 40, Loss: 0.2513
Batch 50, Loss: 0.2180
Batch 60, Loss: 0.2270
Batch 70, Loss: 0.2360
Batch 80, Loss: 0.2139
Batch 90, Loss: 0.2377
Batch 100, Loss: 0.2243
Batch 110, Loss: 0.2078
Batch 120, Loss: 0.2146
Batch 130, Loss: 0.2280
Batch 140, Loss: 0.1858
Batch 150, Loss: 0.2185
Batch 160, Loss: 0.2002
Batch 170, Loss: 0.2306
Batch 180, Loss: 0.2099
Batch 190, Loss: 0.1958
Batch 200, Loss: 0.2360
Batch 210, Loss: 0.2194
Batch 220, Loss: 0.2038
Batch 230, Loss: 0.2154
Batch 240, Loss: 0.1986
Batch 250, Loss: 0.2044
Batch 260, Loss: 0.2057
Batch 270, Loss: 0.2386
Batch 280, Loss: 0.2090
Batch 290, Loss: 0.2348
Batch 300, Loss: 0.2054
Batch 310, Loss: 0.2157
Batch 320, Loss: 0.2398
Batch 330, Loss: 0.2391
Batch 340, Loss: 0.2021
Batch 350, Loss: 0.1925
Batch 360, Loss: 0.2400
Batch 370, Loss: 0.2217
Batch 380, Loss: 0.2128
Batch 390, Loss: 0.2185
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.108318328857422 seconds
Epoch 165 accuracy: 95.05%
Batch 10, Loss: 0.2257
Batch 20, Loss: 0.2243
Batch 30, Loss: 0.2044
Batch 40, Loss: 0.2343
Batch 50, Loss: 0.2101
Batch 60, Loss: 0.1968
Batch 70, Loss: 0.2268
Batch 80, Loss: 0.2206
Batch 90, Loss: 0.2300
Batch 100, Loss: 0.2294
Batch 110, Loss: 0.2134
Batch 120, Loss: 0.2365
Batch 130, Loss: 0.2508
Batch 140, Loss: 0.2259
Batch 150, Loss: 0.2099
Batch 160, Loss: 0.1886
Batch 170, Loss: 0.2075
Batch 180, Loss: 0.2369
Batch 190, Loss: 0.2107
Batch 200, Loss: 0.1977
Batch 210, Loss: 0.1991
Batch 220, Loss: 0.2208
Batch 230, Loss: 0.2284
Batch 240, Loss: 0.2421
Batch 250, Loss: 0.1864
Batch 260, Loss: 0.2278
Batch 270, Loss: 0.2034
Batch 280, Loss: 0.2218
Batch 290, Loss: 0.2115
Batch 300, Loss: 0.2350
Batch 310, Loss: 0.2195
Batch 320, Loss: 0.2274
Batch 330, Loss: 0.2317
Batch 340, Loss: 0.1913
Batch 350, Loss: 0.2159
Batch 360, Loss: 0.2038
Batch 370, Loss: 0.1983
Batch 380, Loss: 0.1962
Batch 390, Loss: 0.2103
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.034361124038696 seconds
Epoch 166 accuracy: 95.29%
Batch 10, Loss: 0.1870
Batch 20, Loss: 0.1893
Batch 30, Loss: 0.2109
Batch 40, Loss: 0.1807
Batch 50, Loss: 0.1879
Batch 60, Loss: 0.1975
Batch 70, Loss: 0.1874
Batch 80, Loss: 0.2048
Batch 90, Loss: 0.2153
Batch 100, Loss: 0.2144
Batch 110, Loss: 0.1971
Batch 120, Loss: 0.2268
Batch 130, Loss: 0.2144
Batch 140, Loss: 0.2305
Batch 150, Loss: 0.1959
Batch 160, Loss: 0.2083
Batch 170, Loss: 0.2126
Batch 180, Loss: 0.2181
Batch 190, Loss: 0.2074
Batch 200, Loss: 0.2172
Batch 210, Loss: 0.2208
Batch 220, Loss: 0.2134
Batch 230, Loss: 0.2065
Batch 240, Loss: 0.1998
Batch 250, Loss: 0.2048
Batch 260, Loss: 0.2210
Batch 270, Loss: 0.2200
Batch 280, Loss: 0.2091
Batch 290, Loss: 0.2292
Batch 300, Loss: 0.1923
Batch 310, Loss: 0.2104
Batch 320, Loss: 0.2246
Batch 330, Loss: 0.2009
Batch 340, Loss: 0.2048
Batch 350, Loss: 0.2147
Batch 360, Loss: 0.2278
Batch 370, Loss: 0.1838
Batch 380, Loss: 0.1783
Batch 390, Loss: 0.2103
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.358845949172974 seconds
Epoch 167 accuracy: 95.28%
Batch 10, Loss: 0.2170
Batch 20, Loss: 0.2155
Batch 30, Loss: 0.1732
Batch 40, Loss: 0.1902
Batch 50, Loss: 0.1946
Batch 60, Loss: 0.1868
Batch 70, Loss: 0.2095
Batch 80, Loss: 0.2099
Batch 90, Loss: 0.2296
Batch 100, Loss: 0.2248
Batch 110, Loss: 0.2007
Batch 120, Loss: 0.2255
Batch 130, Loss: 0.1958
Batch 140, Loss: 0.2376
Batch 150, Loss: 0.1884
Batch 160, Loss: 0.1920
Batch 170, Loss: 0.1885
Batch 180, Loss: 0.2455
Batch 190, Loss: 0.2189
Batch 200, Loss: 0.2100
Batch 210, Loss: 0.2194
Batch 220, Loss: 0.2266
Batch 230, Loss: 0.2022
Batch 240, Loss: 0.1986
Batch 250, Loss: 0.2264
Batch 260, Loss: 0.2007
Batch 270, Loss: 0.2210
Batch 280, Loss: 0.2277
Batch 290, Loss: 0.1981
Batch 300, Loss: 0.1924
Batch 310, Loss: 0.2054
Batch 320, Loss: 0.2102
Batch 330, Loss: 0.2256
Batch 340, Loss: 0.2261
Batch 350, Loss: 0.1888
Batch 360, Loss: 0.1937
Batch 370, Loss: 0.2407
Batch 380, Loss: 0.2091
Batch 390, Loss: 0.2227
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.247618198394775 seconds
Epoch 168 accuracy: 94.81%
Batch 10, Loss: 0.1954
Batch 20, Loss: 0.1792
Batch 30, Loss: 0.2050
Batch 40, Loss: 0.1767
Batch 50, Loss: 0.2068
Batch 60, Loss: 0.2112
Batch 70, Loss: 0.1861
Batch 80, Loss: 0.1849
Batch 90, Loss: 0.2002
Batch 100, Loss: 0.2026
Batch 110, Loss: 0.1953
Batch 120, Loss: 0.2052
Batch 130, Loss: 0.1880
Batch 140, Loss: 0.2041
Batch 150, Loss: 0.2026
Batch 160, Loss: 0.2105
Batch 170, Loss: 0.2078
Batch 180, Loss: 0.2304
Batch 190, Loss: 0.2076
Batch 200, Loss: 0.1915
Batch 210, Loss: 0.1987
Batch 220, Loss: 0.2088
Batch 230, Loss: 0.2034
Batch 240, Loss: 0.1748
Batch 250, Loss: 0.1995
Batch 260, Loss: 0.2118
Batch 270, Loss: 0.2206
Batch 280, Loss: 0.1919
Batch 290, Loss: 0.1908
Batch 300, Loss: 0.1941
Batch 310, Loss: 0.2106
Batch 320, Loss: 0.1943
Batch 330, Loss: 0.2238
Batch 340, Loss: 0.2350
Batch 350, Loss: 0.1850
Batch 360, Loss: 0.2016
Batch 370, Loss: 0.2155
Batch 380, Loss: 0.2400
Batch 390, Loss: 0.2180
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.246155977249146 seconds
Epoch 169 accuracy: 95.36%
Batch 10, Loss: 0.1845
Batch 20, Loss: 0.1938
Batch 30, Loss: 0.2038
Batch 40, Loss: 0.2207
Batch 50, Loss: 0.2067
Batch 60, Loss: 0.2070
Batch 70, Loss: 0.1976
Batch 80, Loss: 0.1995
Batch 90, Loss: 0.1852
Batch 100, Loss: 0.2090
Batch 110, Loss: 0.2112
Batch 120, Loss: 0.1831
Batch 130, Loss: 0.1790
Batch 140, Loss: 0.2012
Batch 150, Loss: 0.1560
Batch 160, Loss: 0.1827
Batch 170, Loss: 0.2045
Batch 180, Loss: 0.1899
Batch 190, Loss: 0.2063
Batch 200, Loss: 0.1627
Batch 210, Loss: 0.1833
Batch 220, Loss: 0.1947
Batch 230, Loss: 0.2039
Batch 240, Loss: 0.2066
Batch 250, Loss: 0.1952
Batch 260, Loss: 0.2219
Batch 270, Loss: 0.1888
Batch 280, Loss: 0.2123
Batch 290, Loss: 0.2043
Batch 300, Loss: 0.2095
Batch 310, Loss: 0.2139
Batch 320, Loss: 0.1841
Batch 330, Loss: 0.2385
Batch 340, Loss: 0.1835
Batch 350, Loss: 0.2004
Batch 360, Loss: 0.2123
Batch 370, Loss: 0.1970
Batch 380, Loss: 0.1953
Batch 390, Loss: 0.2158
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.187177181243896 seconds
Epoch 170 accuracy: 95.36%
Batch 10, Loss: 0.2022
Batch 20, Loss: 0.1802
Batch 30, Loss: 0.1852
Batch 40, Loss: 0.1805
Batch 50, Loss: 0.2001
Batch 60, Loss: 0.1638
Batch 70, Loss: 0.2441
Batch 80, Loss: 0.1984
Batch 90, Loss: 0.1976
Batch 100, Loss: 0.1843
Batch 110, Loss: 0.1946
Batch 120, Loss: 0.1942
Batch 130, Loss: 0.1727
Batch 140, Loss: 0.1940
Batch 150, Loss: 0.1777
Batch 160, Loss: 0.2011
Batch 170, Loss: 0.2022
Batch 180, Loss: 0.2236
Batch 190, Loss: 0.1748
Batch 200, Loss: 0.1957
Batch 210, Loss: 0.1912
Batch 220, Loss: 0.2137
Batch 230, Loss: 0.1634
Batch 240, Loss: 0.1963
Batch 250, Loss: 0.2114
Batch 260, Loss: 0.2089
Batch 270, Loss: 0.2076
Batch 280, Loss: 0.1859
Batch 290, Loss: 0.1826
Batch 300, Loss: 0.2085
Batch 310, Loss: 0.1924
Batch 320, Loss: 0.1904
Batch 330, Loss: 0.2027
Batch 340, Loss: 0.2260
Batch 350, Loss: 0.1901
Batch 360, Loss: 0.1799
Batch 370, Loss: 0.2049
Batch 380, Loss: 0.1919
Batch 390, Loss: 0.2045
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.270047187805176 seconds
Epoch 171 accuracy: 95.68%
Batch 10, Loss: 0.1780
Batch 20, Loss: 0.1641
Batch 30, Loss: 0.2017
Batch 40, Loss: 0.1861
Batch 50, Loss: 0.1649
Batch 60, Loss: 0.1775
Batch 70, Loss: 0.1962
Batch 80, Loss: 0.1774
Batch 90, Loss: 0.2023
Batch 100, Loss: 0.2025
Batch 110, Loss: 0.1939
Batch 120, Loss: 0.2036
Batch 130, Loss: 0.2154
Batch 140, Loss: 0.2071
Batch 150, Loss: 0.1966
Batch 160, Loss: 0.1810
Batch 170, Loss: 0.1869
Batch 180, Loss: 0.1923
Batch 190, Loss: 0.1958
Batch 200, Loss: 0.1972
Batch 210, Loss: 0.2058
Batch 220, Loss: 0.2003
Batch 230, Loss: 0.1996
Batch 240, Loss: 0.2054
Batch 250, Loss: 0.1918
Batch 260, Loss: 0.2037
Batch 270, Loss: 0.1859
Batch 280, Loss: 0.1943
Batch 290, Loss: 0.1935
Batch 300, Loss: 0.2116
Batch 310, Loss: 0.1768
Batch 320, Loss: 0.2009
Batch 330, Loss: 0.1866
Batch 340, Loss: 0.1820
Batch 350, Loss: 0.1547
Batch 360, Loss: 0.1965
Batch 370, Loss: 0.2001
Batch 380, Loss: 0.1799
Batch 390, Loss: 0.2017
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.147209644317627 seconds
Epoch 172 accuracy: 95.63%
Batch 10, Loss: 0.1723
Batch 20, Loss: 0.1534
Batch 30, Loss: 0.1996
Batch 40, Loss: 0.1854
Batch 50, Loss: 0.2009
Batch 60, Loss: 0.1815
Batch 70, Loss: 0.1800
Batch 80, Loss: 0.2057
Batch 90, Loss: 0.1840
Batch 100, Loss: 0.1698
Batch 110, Loss: 0.2035
Batch 120, Loss: 0.1789
Batch 130, Loss: 0.1961
Batch 140, Loss: 0.1867
Batch 150, Loss: 0.1887
Batch 160, Loss: 0.1650
Batch 170, Loss: 0.1855
Batch 180, Loss: 0.1800
Batch 190, Loss: 0.2043
Batch 200, Loss: 0.1936
Batch 210, Loss: 0.1714
Batch 220, Loss: 0.1822
Batch 230, Loss: 0.1970
Batch 240, Loss: 0.1730
Batch 250, Loss: 0.1915
Batch 260, Loss: 0.1962
Batch 270, Loss: 0.1903
Batch 280, Loss: 0.1825
Batch 290, Loss: 0.1589
Batch 300, Loss: 0.1782
Batch 310, Loss: 0.1836
Batch 320, Loss: 0.1737
Batch 330, Loss: 0.1751
Batch 340, Loss: 0.1713
Batch 350, Loss: 0.1737
Batch 360, Loss: 0.1907
Batch 370, Loss: 0.1869
Batch 380, Loss: 0.2005
Batch 390, Loss: 0.2057
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.206459760665894 seconds
Epoch 173 accuracy: 95.78%
Batch 10, Loss: 0.1936
Batch 20, Loss: 0.2331
Batch 30, Loss: 0.2002
Batch 40, Loss: 0.1479
Batch 50, Loss: 0.1706
Batch 60, Loss: 0.1728
Batch 70, Loss: 0.1697
Batch 80, Loss: 0.1775
Batch 90, Loss: 0.2001
Batch 100, Loss: 0.1967
Batch 110, Loss: 0.1692
Batch 120, Loss: 0.1750
Batch 130, Loss: 0.2012
Batch 140, Loss: 0.1623
Batch 150, Loss: 0.1959
Batch 160, Loss: 0.1660
Batch 170, Loss: 0.1685
Batch 180, Loss: 0.1881
Batch 190, Loss: 0.1941
Batch 200, Loss: 0.1807
Batch 210, Loss: 0.1966
Batch 220, Loss: 0.1648
Batch 230, Loss: 0.1966
Batch 240, Loss: 0.1887
Batch 250, Loss: 0.1909
Batch 260, Loss: 0.1643
Batch 270, Loss: 0.1979
Batch 280, Loss: 0.1818
Batch 290, Loss: 0.1947
Batch 300, Loss: 0.1779
Batch 310, Loss: 0.1773
Batch 320, Loss: 0.1798
Batch 330, Loss: 0.1848
Batch 340, Loss: 0.2015
Batch 350, Loss: 0.1610
Batch 360, Loss: 0.1631
Batch 370, Loss: 0.1671
Batch 380, Loss: 0.1649
Batch 390, Loss: 0.1758
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.059812545776367 seconds
Epoch 174 accuracy: 95.94%
Batch 10, Loss: 0.1991
Batch 20, Loss: 0.1520
Batch 30, Loss: 0.1653
Batch 40, Loss: 0.1590
Batch 50, Loss: 0.1940
Batch 60, Loss: 0.1643
Batch 70, Loss: 0.1816
Batch 80, Loss: 0.1779
Batch 90, Loss: 0.1845
Batch 100, Loss: 0.1813
Batch 110, Loss: 0.1601
Batch 120, Loss: 0.1543
Batch 130, Loss: 0.1701
Batch 140, Loss: 0.2026
Batch 150, Loss: 0.1553
Batch 160, Loss: 0.1780
Batch 170, Loss: 0.1953
Batch 180, Loss: 0.1648
Batch 190, Loss: 0.1764
Batch 200, Loss: 0.1883
Batch 210, Loss: 0.1724
Batch 220, Loss: 0.2155
Batch 230, Loss: 0.1887
Batch 240, Loss: 0.1935
Batch 250, Loss: 0.1687
Batch 260, Loss: 0.1620
Batch 270, Loss: 0.1869
Batch 280, Loss: 0.1718
Batch 290, Loss: 0.1966
Batch 300, Loss: 0.1654
Batch 310, Loss: 0.1827
Batch 320, Loss: 0.1673
Batch 330, Loss: 0.1818
Batch 340, Loss: 0.1646
Batch 350, Loss: 0.1771
Batch 360, Loss: 0.1594
Batch 370, Loss: 0.1728
Batch 380, Loss: 0.1614
Batch 390, Loss: 0.1919
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.146984100341797 seconds
Epoch 175 accuracy: 96.03%
Batch 10, Loss: 0.1776
Batch 20, Loss: 0.1698
Batch 30, Loss: 0.1812
Batch 40, Loss: 0.1599
Batch 50, Loss: 0.1755
Batch 60, Loss: 0.1763
Batch 70, Loss: 0.1908
Batch 80, Loss: 0.2022
Batch 90, Loss: 0.1586
Batch 100, Loss: 0.1964
Batch 110, Loss: 0.1560
Batch 120, Loss: 0.1820
Batch 130, Loss: 0.1702
Batch 140, Loss: 0.1698
Batch 150, Loss: 0.1546
Batch 160, Loss: 0.1894
Batch 170, Loss: 0.1586
Batch 180, Loss: 0.1699
Batch 190, Loss: 0.1470
Batch 200, Loss: 0.1535
Batch 210, Loss: 0.1463
Batch 220, Loss: 0.1807
Batch 230, Loss: 0.1911
Batch 240, Loss: 0.1728
Batch 250, Loss: 0.1474
Batch 260, Loss: 0.1638
Batch 270, Loss: 0.1639
Batch 280, Loss: 0.1634
Batch 290, Loss: 0.1609
Batch 300, Loss: 0.1684
Batch 310, Loss: 0.1794
Batch 320, Loss: 0.1675
Batch 330, Loss: 0.1881
Batch 340, Loss: 0.1934
Batch 350, Loss: 0.1631
Batch 360, Loss: 0.1738
Batch 370, Loss: 0.1859
Batch 380, Loss: 0.1714
Batch 390, Loss: 0.1585
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.32470965385437 seconds
Epoch 176 accuracy: 95.89%
Batch 10, Loss: 0.1671
Batch 20, Loss: 0.1574
Batch 30, Loss: 0.1709
Batch 40, Loss: 0.1667
Batch 50, Loss: 0.1805
Batch 60, Loss: 0.1423
Batch 70, Loss: 0.1542
Batch 80, Loss: 0.1475
Batch 90, Loss: 0.1416
Batch 100, Loss: 0.1642
Batch 110, Loss: 0.1769
Batch 120, Loss: 0.1558
Batch 130, Loss: 0.1626
Batch 140, Loss: 0.1539
Batch 150, Loss: 0.1617
Batch 160, Loss: 0.2034
Batch 170, Loss: 0.1599
Batch 180, Loss: 0.1734
Batch 190, Loss: 0.1869
Batch 200, Loss: 0.1638
Batch 210, Loss: 0.1887
Batch 220, Loss: 0.1612
Batch 230, Loss: 0.1834
Batch 240, Loss: 0.1722
Batch 250, Loss: 0.1968
Batch 260, Loss: 0.1756
Batch 270, Loss: 0.1648
Batch 280, Loss: 0.1775
Batch 290, Loss: 0.1836
Batch 300, Loss: 0.1754
Batch 310, Loss: 0.1666
Batch 320, Loss: 0.2084
Batch 330, Loss: 0.1806
Batch 340, Loss: 0.1788
Batch 350, Loss: 0.1847
Batch 360, Loss: 0.1729
Batch 370, Loss: 0.1832
Batch 380, Loss: 0.1616
Batch 390, Loss: 0.1665
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.148067951202393 seconds
Epoch 177 accuracy: 96.16%
Batch 10, Loss: 0.1671
Batch 20, Loss: 0.1828
Batch 30, Loss: 0.1593
Batch 40, Loss: 0.1378
Batch 50, Loss: 0.1667
Batch 60, Loss: 0.1743
Batch 70, Loss: 0.1528
Batch 80, Loss: 0.1328
Batch 90, Loss: 0.1610
Batch 100, Loss: 0.1680
Batch 110, Loss: 0.1390
Batch 120, Loss: 0.1582
Batch 130, Loss: 0.1650
Batch 140, Loss: 0.1708
Batch 150, Loss: 0.1560
Batch 160, Loss: 0.1565
Batch 170, Loss: 0.1493
Batch 180, Loss: 0.1776
Batch 190, Loss: 0.1746
Batch 200, Loss: 0.1795
Batch 210, Loss: 0.1564
Batch 220, Loss: 0.1874
Batch 230, Loss: 0.1867
Batch 240, Loss: 0.1641
Batch 250, Loss: 0.1528
Batch 260, Loss: 0.1773
Batch 270, Loss: 0.1816
Batch 280, Loss: 0.1705
Batch 290, Loss: 0.1773
Batch 300, Loss: 0.1701
Batch 310, Loss: 0.1638
Batch 320, Loss: 0.1547
Batch 330, Loss: 0.1463
Batch 340, Loss: 0.1667
Batch 350, Loss: 0.1702
Batch 360, Loss: 0.1565
Batch 370, Loss: 0.1696
Batch 380, Loss: 0.1440
Batch 390, Loss: 0.1582
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.087172985076904 seconds
Epoch 178 accuracy: 96.12%
Batch 10, Loss: 0.1735
Batch 20, Loss: 0.1710
Batch 30, Loss: 0.1707
Batch 40, Loss: 0.1606
Batch 50, Loss: 0.1563
Batch 60, Loss: 0.1683
Batch 70, Loss: 0.1508
Batch 80, Loss: 0.1443
Batch 90, Loss: 0.1619
Batch 100, Loss: 0.1901
Batch 110, Loss: 0.1441
Batch 120, Loss: 0.1449
Batch 130, Loss: 0.1579
Batch 140, Loss: 0.1837
Batch 150, Loss: 0.1953
Batch 160, Loss: 0.1567
Batch 170, Loss: 0.1446
Batch 180, Loss: 0.1758
Batch 190, Loss: 0.1702
Batch 200, Loss: 0.1548
Batch 210, Loss: 0.1815
Batch 220, Loss: 0.1545
Batch 230, Loss: 0.1936
Batch 240, Loss: 0.1756
Batch 250, Loss: 0.1689
Batch 260, Loss: 0.1558
Batch 270, Loss: 0.1801
Batch 280, Loss: 0.1631
Batch 290, Loss: 0.1662
Batch 300, Loss: 0.1501
Batch 310, Loss: 0.1559
Batch 320, Loss: 0.1591
Batch 330, Loss: 0.1482
Batch 340, Loss: 0.1509
Batch 350, Loss: 0.1556
Batch 360, Loss: 0.1618
Batch 370, Loss: 0.1775
Batch 380, Loss: 0.1701
Batch 390, Loss: 0.1829
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.266385316848755 seconds
Epoch 179 accuracy: 95.9%
Batch 10, Loss: 0.1552
Batch 20, Loss: 0.1369
Batch 30, Loss: 0.1667
Batch 40, Loss: 0.1769
Batch 50, Loss: 0.1661
Batch 60, Loss: 0.1763
Batch 70, Loss: 0.1527
Batch 80, Loss: 0.1564
Batch 90, Loss: 0.1767
Batch 100, Loss: 0.1669
Batch 110, Loss: 0.1475
Batch 120, Loss: 0.1408
Batch 130, Loss: 0.1739
Batch 140, Loss: 0.1457
Batch 150, Loss: 0.1609
Batch 160, Loss: 0.1574
Batch 170, Loss: 0.1539
Batch 180, Loss: 0.1802
Batch 190, Loss: 0.1765
Batch 200, Loss: 0.1619
Batch 210, Loss: 0.1754
Batch 220, Loss: 0.1434
Batch 230, Loss: 0.1535
Batch 240, Loss: 0.1643
Batch 250, Loss: 0.1842
Batch 260, Loss: 0.1577
Batch 270, Loss: 0.1504
Batch 280, Loss: 0.1435
Batch 290, Loss: 0.1500
Batch 300, Loss: 0.1648
Batch 310, Loss: 0.1467
Batch 320, Loss: 0.1678
Batch 330, Loss: 0.1413
Batch 340, Loss: 0.1518
Batch 350, Loss: 0.1620
Batch 360, Loss: 0.1576
Batch 370, Loss: 0.1587
Batch 380, Loss: 0.1763
Batch 390, Loss: 0.1462
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.196934700012207 seconds
Epoch 180 accuracy: 95.95%
Batch 10, Loss: 0.1555
Batch 20, Loss: 0.1493
Batch 30, Loss: 0.1910
Batch 40, Loss: 0.1675
Batch 50, Loss: 0.1508
Batch 60, Loss: 0.1438
Batch 70, Loss: 0.1418
Batch 80, Loss: 0.1477
Batch 90, Loss: 0.1448
Batch 100, Loss: 0.1587
Batch 110, Loss: 0.1715
Batch 120, Loss: 0.1762
Batch 130, Loss: 0.1741
Batch 140, Loss: 0.1470
Batch 150, Loss: 0.1565
Batch 160, Loss: 0.1643
Batch 170, Loss: 0.1525
Batch 180, Loss: 0.1428
Batch 190, Loss: 0.1528
Batch 200, Loss: 0.1668
Batch 210, Loss: 0.1477
Batch 220, Loss: 0.1538
Batch 230, Loss: 0.1600
Batch 240, Loss: 0.1387
Batch 250, Loss: 0.1420
Batch 260, Loss: 0.1558
Batch 270, Loss: 0.1475
Batch 280, Loss: 0.1374
Batch 290, Loss: 0.1663
Batch 300, Loss: 0.1502
Batch 310, Loss: 0.1726
Batch 320, Loss: 0.1554
Batch 330, Loss: 0.1877
Batch 340, Loss: 0.1523
Batch 350, Loss: 0.1639
Batch 360, Loss: 0.1661
Batch 370, Loss: 0.1586
Batch 380, Loss: 0.1459
Batch 390, Loss: 0.1449
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.01407814025879 seconds
Epoch 181 accuracy: 96.16%
Batch 10, Loss: 0.1474
Batch 20, Loss: 0.1354
Batch 30, Loss: 0.1679
Batch 40, Loss: 0.1600
Batch 50, Loss: 0.1424
Batch 60, Loss: 0.1522
Batch 70, Loss: 0.1660
Batch 80, Loss: 0.1500
Batch 90, Loss: 0.1399
Batch 100, Loss: 0.1557
Batch 110, Loss: 0.1726
Batch 120, Loss: 0.1479
Batch 130, Loss: 0.1624
Batch 140, Loss: 0.1595
Batch 150, Loss: 0.1387
Batch 160, Loss: 0.1428
Batch 170, Loss: 0.1525
Batch 180, Loss: 0.1499
Batch 190, Loss: 0.1633
Batch 200, Loss: 0.1451
Batch 210, Loss: 0.1581
Batch 220, Loss: 0.1561
Batch 230, Loss: 0.1914
Batch 240, Loss: 0.1659
Batch 250, Loss: 0.1564
Batch 260, Loss: 0.1366
Batch 270, Loss: 0.1493
Batch 280, Loss: 0.1478
Batch 290, Loss: 0.1477
Batch 300, Loss: 0.1758
Batch 310, Loss: 0.1518
Batch 320, Loss: 0.1289
Batch 330, Loss: 0.1407
Batch 340, Loss: 0.1630
Batch 350, Loss: 0.1521
Batch 360, Loss: 0.1585
Batch 370, Loss: 0.1636
Batch 380, Loss: 0.1429
Batch 390, Loss: 0.1593
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.035547494888306 seconds
Epoch 182 accuracy: 96.08%
Batch 10, Loss: 0.1234
Batch 20, Loss: 0.1680
Batch 30, Loss: 0.1673
Batch 40, Loss: 0.1497
Batch 50, Loss: 0.1514
Batch 60, Loss: 0.1664
Batch 70, Loss: 0.1534
Batch 80, Loss: 0.1523
Batch 90, Loss: 0.1634
Batch 100, Loss: 0.1520
Batch 110, Loss: 0.1361
Batch 120, Loss: 0.1192
Batch 130, Loss: 0.1975
Batch 140, Loss: 0.1330
Batch 150, Loss: 0.1454
Batch 160, Loss: 0.1533
Batch 170, Loss: 0.1420
Batch 180, Loss: 0.1503
Batch 190, Loss: 0.1390
Batch 200, Loss: 0.1591
Batch 210, Loss: 0.1657
Batch 220, Loss: 0.1451
Batch 230, Loss: 0.1509
Batch 240, Loss: 0.1638
Batch 250, Loss: 0.1495
Batch 260, Loss: 0.1340
Batch 270, Loss: 0.1318
Batch 280, Loss: 0.1547
Batch 290, Loss: 0.1487
Batch 300, Loss: 0.1550
Batch 310, Loss: 0.1633
Batch 320, Loss: 0.1556
Batch 330, Loss: 0.1448
Batch 340, Loss: 0.1309
Batch 350, Loss: 0.1520
Batch 360, Loss: 0.1657
Batch 370, Loss: 0.1303
Batch 380, Loss: 0.1555
Batch 390, Loss: 0.1590
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.376509189605713 seconds
Epoch 183 accuracy: 95.96%
Batch 10, Loss: 0.1506
Batch 20, Loss: 0.1538
Batch 30, Loss: 0.1647
Batch 40, Loss: 0.1521
Batch 50, Loss: 0.1376
Batch 60, Loss: 0.1492
Batch 70, Loss: 0.1469
Batch 80, Loss: 0.1315
Batch 90, Loss: 0.1807
Batch 100, Loss: 0.1395
Batch 110, Loss: 0.1521
Batch 120, Loss: 0.1492
Batch 130, Loss: 0.1474
Batch 140, Loss: 0.1557
Batch 150, Loss: 0.1311
Batch 160, Loss: 0.1676
Batch 170, Loss: 0.1606
Batch 180, Loss: 0.1303
Batch 190, Loss: 0.1342
Batch 200, Loss: 0.1324
Batch 210, Loss: 0.1485
Batch 220, Loss: 0.1420
Batch 230, Loss: 0.1375
Batch 240, Loss: 0.1389
Batch 250, Loss: 0.1303
Batch 260, Loss: 0.1335
Batch 270, Loss: 0.1584
Batch 280, Loss: 0.1551
Batch 290, Loss: 0.1419
Batch 300, Loss: 0.1502
Batch 310, Loss: 0.1524
Batch 320, Loss: 0.1444
Batch 330, Loss: 0.1713
Batch 340, Loss: 0.1506
Batch 350, Loss: 0.1313
Batch 360, Loss: 0.1447
Batch 370, Loss: 0.1424
Batch 380, Loss: 0.1389
Batch 390, Loss: 0.1514
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.17790699005127 seconds
Epoch 184 accuracy: 96.19%
Batch 10, Loss: 0.1372
Batch 20, Loss: 0.1304
Batch 30, Loss: 0.1352
Batch 40, Loss: 0.1374
Batch 50, Loss: 0.1373
Batch 60, Loss: 0.1473
Batch 70, Loss: 0.1377
Batch 80, Loss: 0.1427
Batch 90, Loss: 0.1307
Batch 100, Loss: 0.1488
Batch 110, Loss: 0.1440
Batch 120, Loss: 0.1319
Batch 130, Loss: 0.1523
Batch 140, Loss: 0.1635
Batch 150, Loss: 0.1042
Batch 160, Loss: 0.1680
Batch 170, Loss: 0.1456
Batch 180, Loss: 0.1569
Batch 190, Loss: 0.1373
Batch 200, Loss: 0.1526
Batch 210, Loss: 0.1502
Batch 220, Loss: 0.1491
Batch 230, Loss: 0.1305
Batch 240, Loss: 0.1295
Batch 250, Loss: 0.1248
Batch 260, Loss: 0.1370
Batch 270, Loss: 0.1351
Batch 280, Loss: 0.1655
Batch 290, Loss: 0.1453
Batch 300, Loss: 0.1552
Batch 310, Loss: 0.1454
Batch 320, Loss: 0.1251
Batch 330, Loss: 0.1455
Batch 340, Loss: 0.1398
Batch 350, Loss: 0.1367
Batch 360, Loss: 0.1468
Batch 370, Loss: 0.1410
Batch 380, Loss: 0.1346
Batch 390, Loss: 0.1442
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.095725774765015 seconds
Epoch 185 accuracy: 96.31%
Batch 10, Loss: 0.1282
Batch 20, Loss: 0.1305
Batch 30, Loss: 0.1340
Batch 40, Loss: 0.1490
Batch 50, Loss: 0.1452
Batch 60, Loss: 0.1715
Batch 70, Loss: 0.1307
Batch 80, Loss: 0.1246
Batch 90, Loss: 0.1305
Batch 100, Loss: 0.1587
Batch 110, Loss: 0.1481
Batch 120, Loss: 0.1445
Batch 130, Loss: 0.1483
Batch 140, Loss: 0.1317
Batch 150, Loss: 0.1361
Batch 160, Loss: 0.1353
Batch 170, Loss: 0.1470
Batch 180, Loss: 0.1481
Batch 190, Loss: 0.1429
Batch 200, Loss: 0.1363
Batch 210, Loss: 0.1514
Batch 220, Loss: 0.1323
Batch 230, Loss: 0.1090
Batch 240, Loss: 0.1399
Batch 250, Loss: 0.1601
Batch 260, Loss: 0.1242
Batch 270, Loss: 0.1641
Batch 280, Loss: 0.1361
Batch 290, Loss: 0.1294
Batch 300, Loss: 0.1275
Batch 310, Loss: 0.1345
Batch 320, Loss: 0.1383
Batch 330, Loss: 0.1451
Batch 340, Loss: 0.1502
Batch 350, Loss: 0.1386
Batch 360, Loss: 0.1494
Batch 370, Loss: 0.1421
Batch 380, Loss: 0.1295
Batch 390, Loss: 0.1430
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.088160037994385 seconds
Epoch 186 accuracy: 96.35%
Batch 10, Loss: 0.1571
Batch 20, Loss: 0.1416
Batch 30, Loss: 0.1157
Batch 40, Loss: 0.1167
Batch 50, Loss: 0.1361
Batch 60, Loss: 0.1336
Batch 70, Loss: 0.1420
Batch 80, Loss: 0.1452
Batch 90, Loss: 0.1455
Batch 100, Loss: 0.1355
Batch 110, Loss: 0.1362
Batch 120, Loss: 0.1375
Batch 130, Loss: 0.1258
Batch 140, Loss: 0.1315
Batch 150, Loss: 0.1677
Batch 160, Loss: 0.1444
Batch 170, Loss: 0.1270
Batch 180, Loss: 0.1239
Batch 190, Loss: 0.1336
Batch 200, Loss: 0.1371
Batch 210, Loss: 0.1281
Batch 220, Loss: 0.1448
Batch 230, Loss: 0.1736
Batch 240, Loss: 0.1340
Batch 250, Loss: 0.1477
Batch 260, Loss: 0.1547
Batch 270, Loss: 0.1458
Batch 280, Loss: 0.1269
Batch 290, Loss: 0.1337
Batch 300, Loss: 0.1492
Batch 310, Loss: 0.1534
Batch 320, Loss: 0.1332
Batch 330, Loss: 0.1459
Batch 340, Loss: 0.1355
Batch 350, Loss: 0.1422
Batch 360, Loss: 0.1647
Batch 370, Loss: 0.1590
Batch 380, Loss: 0.1428
Batch 390, Loss: 0.1431
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.101356267929077 seconds
Epoch 187 accuracy: 96.37%
Batch 10, Loss: 0.1600
Batch 20, Loss: 0.1225
Batch 30, Loss: 0.1313
Batch 40, Loss: 0.1332
Batch 50, Loss: 0.1407
Batch 60, Loss: 0.1229
Batch 70, Loss: 0.1401
Batch 80, Loss: 0.1436
Batch 90, Loss: 0.1272
Batch 100, Loss: 0.1394
Batch 110, Loss: 0.1737
Batch 120, Loss: 0.1195
Batch 130, Loss: 0.1189
Batch 140, Loss: 0.1301
Batch 150, Loss: 0.1320
Batch 160, Loss: 0.1579
Batch 170, Loss: 0.1383
Batch 180, Loss: 0.1251
Batch 190, Loss: 0.1242
Batch 200, Loss: 0.1573
Batch 210, Loss: 0.1517
Batch 220, Loss: 0.1410
Batch 230, Loss: 0.1339
Batch 240, Loss: 0.1356
Batch 250, Loss: 0.1275
Batch 260, Loss: 0.1232
Batch 270, Loss: 0.1270
Batch 280, Loss: 0.1515
Batch 290, Loss: 0.1319
Batch 300, Loss: 0.1117
Batch 310, Loss: 0.1320
Batch 320, Loss: 0.1408
Batch 330, Loss: 0.1554
Batch 340, Loss: 0.1481
Batch 350, Loss: 0.1398
Batch 360, Loss: 0.1278
Batch 370, Loss: 0.1377
Batch 380, Loss: 0.1166
Batch 390, Loss: 0.1392
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.05139970779419 seconds
Epoch 188 accuracy: 96.33%
Batch 10, Loss: 0.1145
Batch 20, Loss: 0.1330
Batch 30, Loss: 0.1165
Batch 40, Loss: 0.1205
Batch 50, Loss: 0.1374
Batch 60, Loss: 0.1393
Batch 70, Loss: 0.1510
Batch 80, Loss: 0.1408
Batch 90, Loss: 0.1246
Batch 100, Loss: 0.1413
Batch 110, Loss: 0.1267
Batch 120, Loss: 0.1289
Batch 130, Loss: 0.1131
Batch 140, Loss: 0.1326
Batch 150, Loss: 0.1369
Batch 160, Loss: 0.1372
Batch 170, Loss: 0.1454
Batch 180, Loss: 0.1261
Batch 190, Loss: 0.1253
Batch 200, Loss: 0.1265
Batch 210, Loss: 0.1195
Batch 220, Loss: 0.1362
Batch 230, Loss: 0.1305
Batch 240, Loss: 0.1410
Batch 250, Loss: 0.0993
Batch 260, Loss: 0.1406
Batch 270, Loss: 0.1379
Batch 280, Loss: 0.1154
Batch 290, Loss: 0.1410
Batch 300, Loss: 0.1546
Batch 310, Loss: 0.1236
Batch 320, Loss: 0.1506
Batch 330, Loss: 0.1462
Batch 340, Loss: 0.1380
Batch 350, Loss: 0.1335
Batch 360, Loss: 0.1475
Batch 370, Loss: 0.1338
Batch 380, Loss: 0.1168
Batch 390, Loss: 0.1535
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.140777111053467 seconds
Epoch 189 accuracy: 96.49%
Batch 10, Loss: 0.1483
Batch 20, Loss: 0.1333
Batch 30, Loss: 0.1625
Batch 40, Loss: 0.1366
Batch 50, Loss: 0.1399
Batch 60, Loss: 0.1351
Batch 70, Loss: 0.1390
Batch 80, Loss: 0.1167
Batch 90, Loss: 0.1443
Batch 100, Loss: 0.1345
Batch 110, Loss: 0.1405
Batch 120, Loss: 0.1304
Batch 130, Loss: 0.1504
Batch 140, Loss: 0.1146
Batch 150, Loss: 0.1398
Batch 160, Loss: 0.1154
Batch 170, Loss: 0.1292
Batch 180, Loss: 0.1464
Batch 190, Loss: 0.1205
Batch 200, Loss: 0.1497
Batch 210, Loss: 0.1294
Batch 220, Loss: 0.1194
Batch 230, Loss: 0.1244
Batch 240, Loss: 0.1283
Batch 250, Loss: 0.1346
Batch 260, Loss: 0.1299
Batch 270, Loss: 0.1328
Batch 280, Loss: 0.1428
Batch 290, Loss: 0.1489
Batch 300, Loss: 0.1437
Batch 310, Loss: 0.1197
Batch 320, Loss: 0.1123
Batch 330, Loss: 0.1429
Batch 340, Loss: 0.1349
Batch 350, Loss: 0.1320
Batch 360, Loss: 0.1540
Batch 370, Loss: 0.1289
Batch 380, Loss: 0.1398
Batch 390, Loss: 0.1086
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.21482539176941 seconds
Epoch 190 accuracy: 96.49%
Batch 10, Loss: 0.1436
Batch 20, Loss: 0.1212
Batch 30, Loss: 0.1366
Batch 40, Loss: 0.1573
Batch 50, Loss: 0.1281
Batch 60, Loss: 0.1596
Batch 70, Loss: 0.1332
Batch 80, Loss: 0.1363
Batch 90, Loss: 0.1430
Batch 100, Loss: 0.1362
Batch 110, Loss: 0.1404
Batch 120, Loss: 0.1269
Batch 130, Loss: 0.1196
Batch 140, Loss: 0.1369
Batch 150, Loss: 0.1224
Batch 160, Loss: 0.1341
Batch 170, Loss: 0.1350
Batch 180, Loss: 0.1109
Batch 190, Loss: 0.1484
Batch 200, Loss: 0.1425
Batch 210, Loss: 0.1205
Batch 220, Loss: 0.1335
Batch 230, Loss: 0.1460
Batch 240, Loss: 0.1433
Batch 250, Loss: 0.1341
Batch 260, Loss: 0.1239
Batch 270, Loss: 0.1227
Batch 280, Loss: 0.1203
Batch 290, Loss: 0.1159
Batch 300, Loss: 0.1185
Batch 310, Loss: 0.1348
Batch 320, Loss: 0.1661
Batch 330, Loss: 0.1448
Batch 340, Loss: 0.1427
Batch 350, Loss: 0.1264
Batch 360, Loss: 0.1285
Batch 370, Loss: 0.1268
Batch 380, Loss: 0.1354
Batch 390, Loss: 0.1278
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.187411308288574 seconds
Epoch 191 accuracy: 96.36%
Batch 10, Loss: 0.1125
Batch 20, Loss: 0.1391
Batch 30, Loss: 0.1368
Batch 40, Loss: 0.1234
Batch 50, Loss: 0.1183
Batch 60, Loss: 0.1342
Batch 70, Loss: 0.1276
Batch 80, Loss: 0.1348
Batch 90, Loss: 0.1239
Batch 100, Loss: 0.1275
Batch 110, Loss: 0.1242
Batch 120, Loss: 0.1268
Batch 130, Loss: 0.1485
Batch 140, Loss: 0.1348
Batch 150, Loss: 0.1219
Batch 160, Loss: 0.1424
Batch 170, Loss: 0.1151
Batch 180, Loss: 0.1354
Batch 190, Loss: 0.1221
Batch 200, Loss: 0.1211
Batch 210, Loss: 0.1412
Batch 220, Loss: 0.1442
Batch 230, Loss: 0.1424
Batch 240, Loss: 0.1368
Batch 250, Loss: 0.1391
Batch 260, Loss: 0.1321
Batch 270, Loss: 0.1217
Batch 280, Loss: 0.1434
Batch 290, Loss: 0.1361
Batch 300, Loss: 0.1130
Batch 310, Loss: 0.1467
Batch 320, Loss: 0.1288
Batch 330, Loss: 0.1407
Batch 340, Loss: 0.1252
Batch 350, Loss: 0.1240
Batch 360, Loss: 0.1169
Batch 370, Loss: 0.1290
Batch 380, Loss: 0.1206
Batch 390, Loss: 0.1269
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.357715368270874 seconds
Epoch 192 accuracy: 96.44%
Batch 10, Loss: 0.1359
Batch 20, Loss: 0.1205
Batch 30, Loss: 0.1243
Batch 40, Loss: 0.1256
Batch 50, Loss: 0.1122
Batch 60, Loss: 0.1313
Batch 70, Loss: 0.1549
Batch 80, Loss: 0.1265
Batch 90, Loss: 0.1283
Batch 100, Loss: 0.1118
Batch 110, Loss: 0.1515
Batch 120, Loss: 0.1460
Batch 130, Loss: 0.1477
Batch 140, Loss: 0.1285
Batch 150, Loss: 0.1205
Batch 160, Loss: 0.1086
Batch 170, Loss: 0.1263
Batch 180, Loss: 0.1196
Batch 190, Loss: 0.1154
Batch 200, Loss: 0.1368
Batch 210, Loss: 0.1445
Batch 220, Loss: 0.1384
Batch 230, Loss: 0.1343
Batch 240, Loss: 0.1254
Batch 250, Loss: 0.1301
Batch 260, Loss: 0.1317
Batch 270, Loss: 0.1448
Batch 280, Loss: 0.1364
Batch 290, Loss: 0.1315
Batch 300, Loss: 0.1267
Batch 310, Loss: 0.1431
Batch 320, Loss: 0.1368
Batch 330, Loss: 0.1337
Batch 340, Loss: 0.1394
Batch 350, Loss: 0.1278
Batch 360, Loss: 0.1284
Batch 370, Loss: 0.1355
Batch 380, Loss: 0.1308
Batch 390, Loss: 0.1113
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.10101342201233 seconds
Epoch 193 accuracy: 96.61%
Batch 10, Loss: 0.1331
Batch 20, Loss: 0.1165
Batch 30, Loss: 0.1312
Batch 40, Loss: 0.1104
Batch 50, Loss: 0.1362
Batch 60, Loss: 0.1232
Batch 70, Loss: 0.1358
Batch 80, Loss: 0.1290
Batch 90, Loss: 0.1163
Batch 100, Loss: 0.1222
Batch 110, Loss: 0.1296
Batch 120, Loss: 0.1375
Batch 130, Loss: 0.1282
Batch 140, Loss: 0.1403
Batch 150, Loss: 0.1327
Batch 160, Loss: 0.1294
Batch 170, Loss: 0.1400
Batch 180, Loss: 0.1336
Batch 190, Loss: 0.1159
Batch 200, Loss: 0.1418
Batch 210, Loss: 0.1341
Batch 220, Loss: 0.1114
Batch 230, Loss: 0.1250
Batch 240, Loss: 0.1394
Batch 250, Loss: 0.1293
Batch 260, Loss: 0.1113
Batch 270, Loss: 0.1214
Batch 280, Loss: 0.1412
Batch 290, Loss: 0.1346
Batch 300, Loss: 0.1211
Batch 310, Loss: 0.1452
Batch 320, Loss: 0.1388
Batch 330, Loss: 0.1219
Batch 340, Loss: 0.0935
Batch 350, Loss: 0.1368
Batch 360, Loss: 0.1213
Batch 370, Loss: 0.1382
Batch 380, Loss: 0.1244
Batch 390, Loss: 0.1295
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.077138662338257 seconds
Epoch 194 accuracy: 96.46%
Batch 10, Loss: 0.1297
Batch 20, Loss: 0.1334
Batch 30, Loss: 0.1098
Batch 40, Loss: 0.1046
Batch 50, Loss: 0.1341
Batch 60, Loss: 0.1243
Batch 70, Loss: 0.1084
Batch 80, Loss: 0.1276
Batch 90, Loss: 0.1429
Batch 100, Loss: 0.1190
Batch 110, Loss: 0.1180
Batch 120, Loss: 0.1381
Batch 130, Loss: 0.1320
Batch 140, Loss: 0.1397
Batch 150, Loss: 0.1090
Batch 160, Loss: 0.1287
Batch 170, Loss: 0.1556
Batch 180, Loss: 0.1311
Batch 190, Loss: 0.1115
Batch 200, Loss: 0.1366
Batch 210, Loss: 0.1157
Batch 220, Loss: 0.1437
Batch 230, Loss: 0.1234
Batch 240, Loss: 0.1090
Batch 250, Loss: 0.1199
Batch 260, Loss: 0.1361
Batch 270, Loss: 0.1329
Batch 280, Loss: 0.1301
Batch 290, Loss: 0.1159
Batch 300, Loss: 0.1251
Batch 310, Loss: 0.1142
Batch 320, Loss: 0.1308
Batch 330, Loss: 0.1266
Batch 340, Loss: 0.1330
Batch 350, Loss: 0.1446
Batch 360, Loss: 0.1441
Batch 370, Loss: 0.1313
Batch 380, Loss: 0.1195
Batch 390, Loss: 0.1241
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.228630781173706 seconds
Epoch 195 accuracy: 96.5%
Batch 10, Loss: 0.1251
Batch 20, Loss: 0.1090
Batch 30, Loss: 0.1193
Batch 40, Loss: 0.1213
Batch 50, Loss: 0.1340
Batch 60, Loss: 0.1027
Batch 70, Loss: 0.1305
Batch 80, Loss: 0.1232
Batch 90, Loss: 0.1271
Batch 100, Loss: 0.1320
Batch 110, Loss: 0.1380
Batch 120, Loss: 0.1272
Batch 130, Loss: 0.1115
Batch 140, Loss: 0.1273
Batch 150, Loss: 0.1107
Batch 160, Loss: 0.1327
Batch 170, Loss: 0.1167
Batch 180, Loss: 0.1169
Batch 190, Loss: 0.1182
Batch 200, Loss: 0.1181
Batch 210, Loss: 0.1435
Batch 220, Loss: 0.1058
Batch 230, Loss: 0.1218
Batch 240, Loss: 0.1248
Batch 250, Loss: 0.1196
Batch 260, Loss: 0.1195
Batch 270, Loss: 0.1379
Batch 280, Loss: 0.1275
Batch 290, Loss: 0.1278
Batch 300, Loss: 0.1282
Batch 310, Loss: 0.0997
Batch 320, Loss: 0.1237
Batch 330, Loss: 0.1295
Batch 340, Loss: 0.1312
Batch 350, Loss: 0.1144
Batch 360, Loss: 0.1288
Batch 370, Loss: 0.1204
Batch 380, Loss: 0.1521
Batch 390, Loss: 0.1258
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.11303162574768 seconds
Epoch 196 accuracy: 96.53%
Batch 10, Loss: 0.1164
Batch 20, Loss: 0.1259
Batch 30, Loss: 0.1269
Batch 40, Loss: 0.1435
Batch 50, Loss: 0.1237
Batch 60, Loss: 0.1414
Batch 70, Loss: 0.1097
Batch 80, Loss: 0.1324
Batch 90, Loss: 0.1500
Batch 100, Loss: 0.1208
Batch 110, Loss: 0.1184
Batch 120, Loss: 0.1314
Batch 130, Loss: 0.1346
Batch 140, Loss: 0.1410
Batch 150, Loss: 0.1258
Batch 160, Loss: 0.1460
Batch 170, Loss: 0.1160
Batch 180, Loss: 0.1389
Batch 190, Loss: 0.1532
Batch 200, Loss: 0.1226
Batch 210, Loss: 0.1420
Batch 220, Loss: 0.1188
Batch 230, Loss: 0.1209
Batch 240, Loss: 0.1198
Batch 250, Loss: 0.1253
Batch 260, Loss: 0.1193
Batch 270, Loss: 0.1260
Batch 280, Loss: 0.1122
Batch 290, Loss: 0.1324
Batch 300, Loss: 0.1053
Batch 310, Loss: 0.1149
Batch 320, Loss: 0.1178
Batch 330, Loss: 0.1249
Batch 340, Loss: 0.1288
Batch 350, Loss: 0.1244
Batch 360, Loss: 0.1233
Batch 370, Loss: 0.1406
Batch 380, Loss: 0.1279
Batch 390, Loss: 0.1292
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.171881198883057 seconds
Epoch 197 accuracy: 96.6%
Batch 10, Loss: 0.1145
Batch 20, Loss: 0.1415
Batch 30, Loss: 0.1004
Batch 40, Loss: 0.1219
Batch 50, Loss: 0.1237
Batch 60, Loss: 0.1317
Batch 70, Loss: 0.1397
Batch 80, Loss: 0.1283
Batch 90, Loss: 0.1173
Batch 100, Loss: 0.1187
Batch 110, Loss: 0.1010
Batch 120, Loss: 0.1387
Batch 130, Loss: 0.1321
Batch 140, Loss: 0.1309
Batch 150, Loss: 0.1253
Batch 160, Loss: 0.1134
Batch 170, Loss: 0.1288
Batch 180, Loss: 0.1223
Batch 190, Loss: 0.1250
Batch 200, Loss: 0.1257
Batch 210, Loss: 0.1002
Batch 220, Loss: 0.1319
Batch 230, Loss: 0.1217
Batch 240, Loss: 0.1227
Batch 250, Loss: 0.1288
Batch 260, Loss: 0.1387
Batch 270, Loss: 0.1242
Batch 280, Loss: 0.1169
Batch 290, Loss: 0.1319
Batch 300, Loss: 0.1246
Batch 310, Loss: 0.1092
Batch 320, Loss: 0.1304
Batch 330, Loss: 0.1125
Batch 340, Loss: 0.1017
Batch 350, Loss: 0.1191
Batch 360, Loss: 0.1067
Batch 370, Loss: 0.1131
Batch 380, Loss: 0.1240
Batch 390, Loss: 0.1461
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.233302354812622 seconds
Epoch 198 accuracy: 96.55%
Batch 10, Loss: 0.1191
Batch 20, Loss: 0.1178
Batch 30, Loss: 0.1398
Batch 40, Loss: 0.1295
Batch 50, Loss: 0.1136
Batch 60, Loss: 0.1259
Batch 70, Loss: 0.1283
Batch 80, Loss: 0.1259
Batch 90, Loss: 0.1230
Batch 100, Loss: 0.1045
Batch 110, Loss: 0.1330
Batch 120, Loss: 0.1377
Batch 130, Loss: 0.1250
Batch 140, Loss: 0.1285
Batch 150, Loss: 0.1199
Batch 160, Loss: 0.1188
Batch 170, Loss: 0.1248
Batch 180, Loss: 0.1041
Batch 190, Loss: 0.1103
Batch 200, Loss: 0.1183
Batch 210, Loss: 0.1455
Batch 220, Loss: 0.1249
Batch 230, Loss: 0.1226
Batch 240, Loss: 0.1328
Batch 250, Loss: 0.1282
Batch 260, Loss: 0.1324
Batch 270, Loss: 0.1063
Batch 280, Loss: 0.1327
Batch 290, Loss: 0.1197
Batch 300, Loss: 0.0904
Batch 310, Loss: 0.1069
Batch 320, Loss: 0.1315
Batch 330, Loss: 0.1305
Batch 340, Loss: 0.1234
Batch 350, Loss: 0.1321
Batch 360, Loss: 0.1389
Batch 370, Loss: 0.1151
Batch 380, Loss: 0.0999
Batch 390, Loss: 0.1113
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.074644804000854 seconds
Epoch 199 accuracy: 96.6%
Batch 10, Loss: 0.1389
Batch 20, Loss: 0.1280
Batch 30, Loss: 0.1256
Batch 40, Loss: 0.1152
Batch 50, Loss: 0.1409
Batch 60, Loss: 0.1238
Batch 70, Loss: 0.1371
Batch 80, Loss: 0.1151
Batch 90, Loss: 0.1099
Batch 100, Loss: 0.1259
Batch 110, Loss: 0.1141
Batch 120, Loss: 0.1322
Batch 130, Loss: 0.1269
Batch 140, Loss: 0.1214
Batch 150, Loss: 0.1182
Batch 160, Loss: 0.1196
Batch 170, Loss: 0.1193
Batch 180, Loss: 0.1026
Batch 190, Loss: 0.1228
Batch 200, Loss: 0.1329
Batch 210, Loss: 0.1396
Batch 220, Loss: 0.1432
Batch 230, Loss: 0.1256
Batch 240, Loss: 0.1145
Batch 250, Loss: 0.1246
Batch 260, Loss: 0.1203
Batch 270, Loss: 0.1471
Batch 280, Loss: 0.1167
Batch 290, Loss: 0.1086
Batch 300, Loss: 0.1343
Batch 310, Loss: 0.1348
Batch 320, Loss: 0.1297
Batch 330, Loss: 0.1141
Batch 340, Loss: 0.1136
Batch 350, Loss: 0.1166
Batch 360, Loss: 0.1279
Batch 370, Loss: 0.1265
Batch 380, Loss: 0.1258
Batch 390, Loss: 0.1200
Epoch 200 learning rate: 0.0
Epoch 200 time: 24.948920965194702 seconds
Epoch 200 accuracy: 96.55%
Total training time: 5037.970349788666 seconds
