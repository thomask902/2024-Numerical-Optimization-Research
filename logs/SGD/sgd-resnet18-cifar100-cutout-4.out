The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.0807
Batch 20, Loss: 4.1698
Batch 30, Loss: 3.9806
Batch 40, Loss: 3.7839
Batch 50, Loss: 3.6270
Batch 60, Loss: 3.5705
Batch 70, Loss: 3.5149
Batch 80, Loss: 3.4367
Batch 90, Loss: 3.4073
Batch 100, Loss: 3.3916
Batch 110, Loss: 3.3640
Batch 120, Loss: 3.3608
Batch 130, Loss: 3.3537
Batch 140, Loss: 3.3084
Batch 150, Loss: 3.2816
Batch 160, Loss: 3.2968
Batch 170, Loss: 3.2800
Batch 180, Loss: 3.2560
Batch 190, Loss: 3.2215
Batch 200, Loss: 3.2064
Batch 210, Loss: 3.2669
Batch 220, Loss: 3.1968
Batch 230, Loss: 3.2096
Batch 240, Loss: 3.1693
Batch 250, Loss: 3.1953
Batch 260, Loss: 3.1198
Batch 270, Loss: 3.1449
Batch 280, Loss: 3.1576
Batch 290, Loss: 3.1905
Batch 300, Loss: 3.1210
Batch 310, Loss: 3.1236
Batch 320, Loss: 3.1035
Batch 330, Loss: 3.1271
Batch 340, Loss: 3.0682
Batch 350, Loss: 3.0598
Batch 360, Loss: 3.0460
Batch 370, Loss: 3.1139
Batch 380, Loss: 3.0733
Batch 390, Loss: 3.0404
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.508148193359375 seconds
Epoch 1 accuracy: 14.08%
Batch 10, Loss: 3.0039
Batch 20, Loss: 3.0044
Batch 30, Loss: 2.9875
Batch 40, Loss: 2.9792
Batch 50, Loss: 3.0309
Batch 60, Loss: 2.9808
Batch 70, Loss: 2.9080
Batch 80, Loss: 2.9486
Batch 90, Loss: 2.9707
Batch 100, Loss: 2.9766
Batch 110, Loss: 2.9609
Batch 120, Loss: 2.8828
Batch 130, Loss: 2.9254
Batch 140, Loss: 2.9599
Batch 150, Loss: 2.9633
Batch 160, Loss: 2.8640
Batch 170, Loss: 2.8756
Batch 180, Loss: 2.9036
Batch 190, Loss: 2.8496
Batch 200, Loss: 2.8294
Batch 210, Loss: 2.8694
Batch 220, Loss: 2.8634
Batch 230, Loss: 2.8638
Batch 240, Loss: 2.7651
Batch 250, Loss: 2.8268
Batch 260, Loss: 2.8237
Batch 270, Loss: 2.7905
Batch 280, Loss: 2.7879
Batch 290, Loss: 2.7721
Batch 300, Loss: 2.7852
Batch 310, Loss: 2.7663
Batch 320, Loss: 2.7735
Batch 330, Loss: 2.7327
Batch 340, Loss: 2.7386
Batch 350, Loss: 2.6997
Batch 360, Loss: 2.7420
Batch 370, Loss: 2.7237
Batch 380, Loss: 2.7294
Batch 390, Loss: 2.7118
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.18040919303894 seconds
Epoch 2 accuracy: 21.43%
Batch 10, Loss: 2.6497
Batch 20, Loss: 2.6372
Batch 30, Loss: 2.6261
Batch 40, Loss: 2.6304
Batch 50, Loss: 2.5925
Batch 60, Loss: 2.6202
Batch 70, Loss: 2.5434
Batch 80, Loss: 2.6288
Batch 90, Loss: 2.6110
Batch 100, Loss: 2.6331
Batch 110, Loss: 2.6129
Batch 120, Loss: 2.5527
Batch 130, Loss: 2.5494
Batch 140, Loss: 2.5919
Batch 150, Loss: 2.5300
Batch 160, Loss: 2.5294
Batch 170, Loss: 2.5215
Batch 180, Loss: 2.5210
Batch 190, Loss: 2.5259
Batch 200, Loss: 2.5192
Batch 210, Loss: 2.5379
Batch 220, Loss: 2.4562
Batch 230, Loss: 2.4468
Batch 240, Loss: 2.5303
Batch 250, Loss: 2.4963
Batch 260, Loss: 2.4321
Batch 270, Loss: 2.4297
Batch 280, Loss: 2.5203
Batch 290, Loss: 2.4895
Batch 300, Loss: 2.4105
Batch 310, Loss: 2.3966
Batch 320, Loss: 2.4363
Batch 330, Loss: 2.3922
Batch 340, Loss: 2.4472
Batch 350, Loss: 2.4057
Batch 360, Loss: 2.4363
Batch 370, Loss: 2.4076
Batch 380, Loss: 2.4243
Batch 390, Loss: 2.4460
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.11094570159912 seconds
Epoch 3 accuracy: 28.14%
Batch 10, Loss: 2.3551
Batch 20, Loss: 2.3662
Batch 30, Loss: 2.3468
Batch 40, Loss: 2.3207
Batch 50, Loss: 2.3778
Batch 60, Loss: 2.2944
Batch 70, Loss: 2.3535
Batch 80, Loss: 2.3286
Batch 90, Loss: 2.2854
Batch 100, Loss: 2.2664
Batch 110, Loss: 2.2113
Batch 120, Loss: 2.2769
Batch 130, Loss: 2.2511
Batch 140, Loss: 2.2517
Batch 150, Loss: 2.2494
Batch 160, Loss: 2.2437
Batch 170, Loss: 2.2160
Batch 180, Loss: 2.2066
Batch 190, Loss: 2.2361
Batch 200, Loss: 2.2144
Batch 210, Loss: 2.2358
Batch 220, Loss: 2.2374
Batch 230, Loss: 2.1498
Batch 240, Loss: 2.1843
Batch 250, Loss: 2.1721
Batch 260, Loss: 2.1165
Batch 270, Loss: 2.1411
Batch 280, Loss: 2.0934
Batch 290, Loss: 2.1650
Batch 300, Loss: 2.1502
Batch 310, Loss: 2.1509
Batch 320, Loss: 2.1370
Batch 330, Loss: 2.0296
Batch 340, Loss: 2.0803
Batch 350, Loss: 2.0921
Batch 360, Loss: 2.1007
Batch 370, Loss: 2.0750
Batch 380, Loss: 2.1457
Batch 390, Loss: 2.1112
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.227432012557983 seconds
Epoch 4 accuracy: 31.47%
Batch 10, Loss: 2.0374
Batch 20, Loss: 2.0403
Batch 30, Loss: 1.9792
Batch 40, Loss: 1.9958
Batch 50, Loss: 1.9625
Batch 60, Loss: 1.9450
Batch 70, Loss: 2.0142
Batch 80, Loss: 1.9855
Batch 90, Loss: 2.0194
Batch 100, Loss: 2.0247
Batch 110, Loss: 1.9953
Batch 120, Loss: 1.8526
Batch 130, Loss: 1.9026
Batch 140, Loss: 1.9761
Batch 150, Loss: 1.9223
Batch 160, Loss: 1.9751
Batch 170, Loss: 1.9224
Batch 180, Loss: 1.9924
Batch 190, Loss: 1.9510
Batch 200, Loss: 1.9471
Batch 210, Loss: 1.8549
Batch 220, Loss: 1.9523
Batch 230, Loss: 1.8978
Batch 240, Loss: 1.9099
Batch 250, Loss: 1.8781
Batch 260, Loss: 1.9538
Batch 270, Loss: 1.8852
Batch 280, Loss: 1.8831
Batch 290, Loss: 1.8989
Batch 300, Loss: 1.9202
Batch 310, Loss: 1.9521
Batch 320, Loss: 1.8689
Batch 330, Loss: 1.8881
Batch 340, Loss: 1.8118
Batch 350, Loss: 1.8718
Batch 360, Loss: 1.8379
Batch 370, Loss: 1.8227
Batch 380, Loss: 1.8641
Batch 390, Loss: 1.8413
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.12218141555786 seconds
Epoch 5 accuracy: 42.41%
Batch 10, Loss: 1.8747
Batch 20, Loss: 1.7763
Batch 30, Loss: 1.7224
Batch 40, Loss: 1.7635
Batch 50, Loss: 1.7534
Batch 60, Loss: 1.8050
Batch 70, Loss: 1.8017
Batch 80, Loss: 1.7612
Batch 90, Loss: 1.7958
Batch 100, Loss: 1.7249
Batch 110, Loss: 1.7838
Batch 120, Loss: 1.7390
Batch 130, Loss: 1.7769
Batch 140, Loss: 1.8235
Batch 150, Loss: 1.7295
Batch 160, Loss: 1.7115
Batch 170, Loss: 1.7754
Batch 180, Loss: 1.7175
Batch 190, Loss: 1.7327
Batch 200, Loss: 1.7825
Batch 210, Loss: 1.7594
Batch 220, Loss: 1.6948
Batch 230, Loss: 1.7534
Batch 240, Loss: 1.7434
Batch 250, Loss: 1.7692
Batch 260, Loss: 1.7141
Batch 270, Loss: 1.6807
Batch 280, Loss: 1.7123
Batch 290, Loss: 1.7219
Batch 300, Loss: 1.6922
Batch 310, Loss: 1.7504
Batch 320, Loss: 1.6634
Batch 330, Loss: 1.6929
Batch 340, Loss: 1.7088
Batch 350, Loss: 1.7579
Batch 360, Loss: 1.7213
Batch 370, Loss: 1.7432
Batch 380, Loss: 1.6800
Batch 390, Loss: 1.6471
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.145602464675903 seconds
Epoch 6 accuracy: 40.33%
Batch 10, Loss: 1.6315
Batch 20, Loss: 1.6400
Batch 30, Loss: 1.5648
Batch 40, Loss: 1.6285
Batch 50, Loss: 1.6213
Batch 60, Loss: 1.6545
Batch 70, Loss: 1.6617
Batch 80, Loss: 1.6148
Batch 90, Loss: 1.5941
Batch 100, Loss: 1.5594
Batch 110, Loss: 1.5842
Batch 120, Loss: 1.6039
Batch 130, Loss: 1.6231
Batch 140, Loss: 1.5661
Batch 150, Loss: 1.5855
Batch 160, Loss: 1.5454
Batch 170, Loss: 1.6328
Batch 180, Loss: 1.6700
Batch 190, Loss: 1.5974
Batch 200, Loss: 1.6131
Batch 210, Loss: 1.5933
Batch 220, Loss: 1.6025
Batch 230, Loss: 1.6340
Batch 240, Loss: 1.6264
Batch 250, Loss: 1.6220
Batch 260, Loss: 1.5960
Batch 270, Loss: 1.6464
Batch 280, Loss: 1.6205
Batch 290, Loss: 1.6465
Batch 300, Loss: 1.6032
Batch 310, Loss: 1.6778
Batch 320, Loss: 1.5923
Batch 330, Loss: 1.5850
Batch 340, Loss: 1.6466
Batch 350, Loss: 1.5956
Batch 360, Loss: 1.5510
Batch 370, Loss: 1.5801
Batch 380, Loss: 1.5787
Batch 390, Loss: 1.6118
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.25407075881958 seconds
Epoch 7 accuracy: 45.94%
Batch 10, Loss: 1.5243
Batch 20, Loss: 1.5011
Batch 30, Loss: 1.5386
Batch 40, Loss: 1.4844
Batch 50, Loss: 1.4593
Batch 60, Loss: 1.5687
Batch 70, Loss: 1.4942
Batch 80, Loss: 1.5271
Batch 90, Loss: 1.5594
Batch 100, Loss: 1.5364
Batch 110, Loss: 1.5076
Batch 120, Loss: 1.5017
Batch 130, Loss: 1.4648
Batch 140, Loss: 1.5448
Batch 150, Loss: 1.5660
Batch 160, Loss: 1.5453
Batch 170, Loss: 1.5442
Batch 180, Loss: 1.5178
Batch 190, Loss: 1.5432
Batch 200, Loss: 1.5271
Batch 210, Loss: 1.5584
Batch 220, Loss: 1.4780
Batch 230, Loss: 1.4562
Batch 240, Loss: 1.4804
Batch 250, Loss: 1.5774
Batch 260, Loss: 1.5525
Batch 270, Loss: 1.5514
Batch 280, Loss: 1.5373
Batch 290, Loss: 1.5480
Batch 300, Loss: 1.5304
Batch 310, Loss: 1.5452
Batch 320, Loss: 1.5443
Batch 330, Loss: 1.5355
Batch 340, Loss: 1.5185
Batch 350, Loss: 1.4327
Batch 360, Loss: 1.5025
Batch 370, Loss: 1.5115
Batch 380, Loss: 1.3995
Batch 390, Loss: 1.4843
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.361663818359375 seconds
Epoch 8 accuracy: 49.57%
Batch 10, Loss: 1.3619
Batch 20, Loss: 1.4653
Batch 30, Loss: 1.4517
Batch 40, Loss: 1.4481
Batch 50, Loss: 1.4049
Batch 60, Loss: 1.3681
Batch 70, Loss: 1.4700
Batch 80, Loss: 1.4319
Batch 90, Loss: 1.3891
Batch 100, Loss: 1.3872
Batch 110, Loss: 1.3636
Batch 120, Loss: 1.4965
Batch 130, Loss: 1.5361
Batch 140, Loss: 1.3998
Batch 150, Loss: 1.4385
Batch 160, Loss: 1.4940
Batch 170, Loss: 1.4600
Batch 180, Loss: 1.5069
Batch 190, Loss: 1.4519
Batch 200, Loss: 1.5022
Batch 210, Loss: 1.4125
Batch 220, Loss: 1.4436
Batch 230, Loss: 1.4624
Batch 240, Loss: 1.4403
Batch 250, Loss: 1.4872
Batch 260, Loss: 1.4470
Batch 270, Loss: 1.4025
Batch 280, Loss: 1.4239
Batch 290, Loss: 1.4675
Batch 300, Loss: 1.4389
Batch 310, Loss: 1.3989
Batch 320, Loss: 1.4120
Batch 330, Loss: 1.4546
Batch 340, Loss: 1.4647
Batch 350, Loss: 1.4748
Batch 360, Loss: 1.4988
Batch 370, Loss: 1.4264
Batch 380, Loss: 1.4173
Batch 390, Loss: 1.4434
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.223695516586304 seconds
Epoch 9 accuracy: 48.99%
Batch 10, Loss: 1.3771
Batch 20, Loss: 1.4219
Batch 30, Loss: 1.4236
Batch 40, Loss: 1.3576
Batch 50, Loss: 1.3499
Batch 60, Loss: 1.3552
Batch 70, Loss: 1.3519
Batch 80, Loss: 1.3899
Batch 90, Loss: 1.4140
Batch 100, Loss: 1.3893
Batch 110, Loss: 1.4323
Batch 120, Loss: 1.4437
Batch 130, Loss: 1.3618
Batch 140, Loss: 1.3258
Batch 150, Loss: 1.4186
Batch 160, Loss: 1.3434
Batch 170, Loss: 1.3711
Batch 180, Loss: 1.3747
Batch 190, Loss: 1.3813
Batch 200, Loss: 1.3830
Batch 210, Loss: 1.4123
Batch 220, Loss: 1.4418
Batch 230, Loss: 1.4205
Batch 240, Loss: 1.3687
Batch 250, Loss: 1.3473
Batch 260, Loss: 1.3943
Batch 270, Loss: 1.4289
Batch 280, Loss: 1.4424
Batch 290, Loss: 1.4280
Batch 300, Loss: 1.3990
Batch 310, Loss: 1.4036
Batch 320, Loss: 1.4162
Batch 330, Loss: 1.3372
Batch 340, Loss: 1.2890
Batch 350, Loss: 1.3926
Batch 360, Loss: 1.4287
Batch 370, Loss: 1.4326
Batch 380, Loss: 1.3757
Batch 390, Loss: 1.4247
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.2723286151886 seconds
Epoch 10 accuracy: 45.08%
Batch 10, Loss: 1.3383
Batch 20, Loss: 1.3179
Batch 30, Loss: 1.2747
Batch 40, Loss: 1.3175
Batch 50, Loss: 1.3758
Batch 60, Loss: 1.3455
Batch 70, Loss: 1.3914
Batch 80, Loss: 1.3259
Batch 90, Loss: 1.3001
Batch 100, Loss: 1.3640
Batch 110, Loss: 1.3754
Batch 120, Loss: 1.3437
Batch 130, Loss: 1.3349
Batch 140, Loss: 1.3695
Batch 150, Loss: 1.3213
Batch 160, Loss: 1.3812
Batch 170, Loss: 1.3565
Batch 180, Loss: 1.3556
Batch 190, Loss: 1.3274
Batch 200, Loss: 1.3907
Batch 210, Loss: 1.4142
Batch 220, Loss: 1.3788
Batch 230, Loss: 1.3412
Batch 240, Loss: 1.3369
Batch 250, Loss: 1.3808
Batch 260, Loss: 1.3059
Batch 270, Loss: 1.3504
Batch 280, Loss: 1.3440
Batch 290, Loss: 1.3454
Batch 300, Loss: 1.3729
Batch 310, Loss: 1.2809
Batch 320, Loss: 1.3342
Batch 330, Loss: 1.3056
Batch 340, Loss: 1.3247
Batch 350, Loss: 1.3215
Batch 360, Loss: 1.3752
Batch 370, Loss: 1.4101
Batch 380, Loss: 1.3107
Batch 390, Loss: 1.3659
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.335058212280273 seconds
Epoch 11 accuracy: 48.23%
Batch 10, Loss: 1.2563
Batch 20, Loss: 1.2336
Batch 30, Loss: 1.2527
Batch 40, Loss: 1.2498
Batch 50, Loss: 1.2551
Batch 60, Loss: 1.2669
Batch 70, Loss: 1.2675
Batch 80, Loss: 1.3139
Batch 90, Loss: 1.2990
Batch 100, Loss: 1.2721
Batch 110, Loss: 1.3988
Batch 120, Loss: 1.2855
Batch 130, Loss: 1.3076
Batch 140, Loss: 1.3068
Batch 150, Loss: 1.2841
Batch 160, Loss: 1.3254
Batch 170, Loss: 1.3294
Batch 180, Loss: 1.3093
Batch 190, Loss: 1.3255
Batch 200, Loss: 1.3181
Batch 210, Loss: 1.3614
Batch 220, Loss: 1.2253
Batch 230, Loss: 1.2488
Batch 240, Loss: 1.3391
Batch 250, Loss: 1.2817
Batch 260, Loss: 1.2345
Batch 270, Loss: 1.3474
Batch 280, Loss: 1.3090
Batch 290, Loss: 1.2526
Batch 300, Loss: 1.3671
Batch 310, Loss: 1.3402
Batch 320, Loss: 1.3492
Batch 330, Loss: 1.2119
Batch 340, Loss: 1.3035
Batch 350, Loss: 1.3125
Batch 360, Loss: 1.3617
Batch 370, Loss: 1.3184
Batch 380, Loss: 1.3098
Batch 390, Loss: 1.3493
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.283697605133057 seconds
Epoch 12 accuracy: 51.77%
Batch 10, Loss: 1.2553
Batch 20, Loss: 1.2361
Batch 30, Loss: 1.2191
Batch 40, Loss: 1.2469
Batch 50, Loss: 1.2628
Batch 60, Loss: 1.2202
Batch 70, Loss: 1.3083
Batch 80, Loss: 1.2963
Batch 90, Loss: 1.2767
Batch 100, Loss: 1.2376
Batch 110, Loss: 1.2970
Batch 120, Loss: 1.2513
Batch 130, Loss: 1.2048
Batch 140, Loss: 1.2592
Batch 150, Loss: 1.2835
Batch 160, Loss: 1.3139
Batch 170, Loss: 1.2355
Batch 180, Loss: 1.2348
Batch 190, Loss: 1.3019
Batch 200, Loss: 1.2974
Batch 210, Loss: 1.2920
Batch 220, Loss: 1.2881
Batch 230, Loss: 1.2751
Batch 240, Loss: 1.2322
Batch 250, Loss: 1.2086
Batch 260, Loss: 1.2025
Batch 270, Loss: 1.2991
Batch 280, Loss: 1.3006
Batch 290, Loss: 1.3339
Batch 300, Loss: 1.3412
Batch 310, Loss: 1.3378
Batch 320, Loss: 1.2830
Batch 330, Loss: 1.2723
Batch 340, Loss: 1.3083
Batch 350, Loss: 1.3248
Batch 360, Loss: 1.2605
Batch 370, Loss: 1.2631
Batch 380, Loss: 1.3270
Batch 390, Loss: 1.2698
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.31508469581604 seconds
Epoch 13 accuracy: 53.8%
Batch 10, Loss: 1.1583
Batch 20, Loss: 1.2076
Batch 30, Loss: 1.1613
Batch 40, Loss: 1.1774
Batch 50, Loss: 1.2368
Batch 60, Loss: 1.2332
Batch 70, Loss: 1.2458
Batch 80, Loss: 1.2002
Batch 90, Loss: 1.1901
Batch 100, Loss: 1.2350
Batch 110, Loss: 1.2280
Batch 120, Loss: 1.2781
Batch 130, Loss: 1.2628
Batch 140, Loss: 1.2332
Batch 150, Loss: 1.2533
Batch 160, Loss: 1.2461
Batch 170, Loss: 1.2440
Batch 180, Loss: 1.2566
Batch 190, Loss: 1.1938
Batch 200, Loss: 1.2104
Batch 210, Loss: 1.2705
Batch 220, Loss: 1.1993
Batch 230, Loss: 1.2209
Batch 240, Loss: 1.2599
Batch 250, Loss: 1.2329
Batch 260, Loss: 1.2924
Batch 270, Loss: 1.2858
Batch 280, Loss: 1.3113
Batch 290, Loss: 1.2170
Batch 300, Loss: 1.2639
Batch 310, Loss: 1.2500
Batch 320, Loss: 1.2593
Batch 330, Loss: 1.2841
Batch 340, Loss: 1.2755
Batch 350, Loss: 1.2868
Batch 360, Loss: 1.2783
Batch 370, Loss: 1.2903
Batch 380, Loss: 1.3126
Batch 390, Loss: 1.2554
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.177218198776245 seconds
Epoch 14 accuracy: 50.16%
Batch 10, Loss: 1.1137
Batch 20, Loss: 1.1022
Batch 30, Loss: 1.1679
Batch 40, Loss: 1.1485
Batch 50, Loss: 1.1667
Batch 60, Loss: 1.2107
Batch 70, Loss: 1.1699
Batch 80, Loss: 1.2323
Batch 90, Loss: 1.2238
Batch 100, Loss: 1.1985
Batch 110, Loss: 1.2395
Batch 120, Loss: 1.2111
Batch 130, Loss: 1.1950
Batch 140, Loss: 1.1849
Batch 150, Loss: 1.1855
Batch 160, Loss: 1.2169
Batch 170, Loss: 1.2171
Batch 180, Loss: 1.2143
Batch 190, Loss: 1.2412
Batch 200, Loss: 1.2263
Batch 210, Loss: 1.2536
Batch 220, Loss: 1.2066
Batch 230, Loss: 1.1946
Batch 240, Loss: 1.2012
Batch 250, Loss: 1.2460
Batch 260, Loss: 1.2081
Batch 270, Loss: 1.2317
Batch 280, Loss: 1.2317
Batch 290, Loss: 1.1996
Batch 300, Loss: 1.2289
Batch 310, Loss: 1.1736
Batch 320, Loss: 1.2562
Batch 330, Loss: 1.1779
Batch 340, Loss: 1.1801
Batch 350, Loss: 1.2271
Batch 360, Loss: 1.2405
Batch 370, Loss: 1.2343
Batch 380, Loss: 1.2416
Batch 390, Loss: 1.2591
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.1911301612854 seconds
Epoch 15 accuracy: 55.09%
Batch 10, Loss: 1.1343
Batch 20, Loss: 1.1473
Batch 30, Loss: 1.1712
Batch 40, Loss: 1.1261
Batch 50, Loss: 1.2131
Batch 60, Loss: 1.1594
Batch 70, Loss: 1.1610
Batch 80, Loss: 1.2042
Batch 90, Loss: 1.1025
Batch 100, Loss: 1.1431
Batch 110, Loss: 1.1290
Batch 120, Loss: 1.1330
Batch 130, Loss: 1.2787
Batch 140, Loss: 1.1935
Batch 150, Loss: 1.1903
Batch 160, Loss: 1.1624
Batch 170, Loss: 1.1924
Batch 180, Loss: 1.1605
Batch 190, Loss: 1.2483
Batch 200, Loss: 1.2023
Batch 210, Loss: 1.2282
Batch 220, Loss: 1.1756
Batch 230, Loss: 1.1847
Batch 240, Loss: 1.1407
Batch 250, Loss: 1.2222
Batch 260, Loss: 1.1949
Batch 270, Loss: 1.2802
Batch 280, Loss: 1.2196
Batch 290, Loss: 1.2561
Batch 300, Loss: 1.2509
Batch 310, Loss: 1.2126
Batch 320, Loss: 1.1784
Batch 330, Loss: 1.2075
Batch 340, Loss: 1.2028
Batch 350, Loss: 1.2365
Batch 360, Loss: 1.1551
Batch 370, Loss: 1.1974
Batch 380, Loss: 1.1972
Batch 390, Loss: 1.2429
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.181469202041626 seconds
Epoch 16 accuracy: 53.61%
Batch 10, Loss: 1.1872
Batch 20, Loss: 1.1714
Batch 30, Loss: 1.1162
Batch 40, Loss: 1.1722
Batch 50, Loss: 1.0813
Batch 60, Loss: 1.1442
Batch 70, Loss: 1.1834
Batch 80, Loss: 1.1728
Batch 90, Loss: 1.1131
Batch 100, Loss: 1.1421
Batch 110, Loss: 1.2009
Batch 120, Loss: 1.1490
Batch 130, Loss: 1.1215
Batch 140, Loss: 1.1795
Batch 150, Loss: 1.1905
Batch 160, Loss: 1.1295
Batch 170, Loss: 1.1316
Batch 180, Loss: 1.1393
Batch 190, Loss: 1.2225
Batch 200, Loss: 1.1399
Batch 210, Loss: 1.2354
Batch 220, Loss: 1.1794
Batch 230, Loss: 1.1633
Batch 240, Loss: 1.1713
Batch 250, Loss: 1.1833
Batch 260, Loss: 1.2144
Batch 270, Loss: 1.2295
Batch 280, Loss: 1.1888
Batch 290, Loss: 1.1965
Batch 300, Loss: 1.1564
Batch 310, Loss: 1.2205
Batch 320, Loss: 1.2172
Batch 330, Loss: 1.1502
Batch 340, Loss: 1.1642
Batch 350, Loss: 1.1874
Batch 360, Loss: 1.1773
Batch 370, Loss: 1.2248
Batch 380, Loss: 1.1936
Batch 390, Loss: 1.2738
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.21794366836548 seconds
Epoch 17 accuracy: 53.78%
Batch 10, Loss: 1.1007
Batch 20, Loss: 1.1383
Batch 30, Loss: 1.1310
Batch 40, Loss: 1.1538
Batch 50, Loss: 1.0642
Batch 60, Loss: 1.1846
Batch 70, Loss: 1.1305
Batch 80, Loss: 1.1646
Batch 90, Loss: 1.1373
Batch 100, Loss: 1.1502
Batch 110, Loss: 1.1905
Batch 120, Loss: 1.0992
Batch 130, Loss: 1.1387
Batch 140, Loss: 1.2099
Batch 150, Loss: 1.1639
Batch 160, Loss: 1.1230
Batch 170, Loss: 1.1487
Batch 180, Loss: 1.0836
Batch 190, Loss: 1.1495
Batch 200, Loss: 1.1786
Batch 210, Loss: 1.1441
Batch 220, Loss: 1.1496
Batch 230, Loss: 1.1367
Batch 240, Loss: 1.0705
Batch 250, Loss: 1.1478
Batch 260, Loss: 1.2120
Batch 270, Loss: 1.1927
Batch 280, Loss: 1.2537
Batch 290, Loss: 1.2010
Batch 300, Loss: 1.2032
Batch 310, Loss: 1.1641
Batch 320, Loss: 1.1733
Batch 330, Loss: 1.1852
Batch 340, Loss: 1.1790
Batch 350, Loss: 1.1890
Batch 360, Loss: 1.1828
Batch 370, Loss: 1.2323
Batch 380, Loss: 1.1787
Batch 390, Loss: 1.1910
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.171787977218628 seconds
Epoch 18 accuracy: 53.68%
Batch 10, Loss: 1.1467
Batch 20, Loss: 1.1651
Batch 30, Loss: 1.1373
Batch 40, Loss: 1.0896
Batch 50, Loss: 1.0667
Batch 60, Loss: 1.1236
Batch 70, Loss: 1.1582
Batch 80, Loss: 1.1150
Batch 90, Loss: 1.1272
Batch 100, Loss: 1.1072
Batch 110, Loss: 1.0723
Batch 120, Loss: 1.1258
Batch 130, Loss: 1.1815
Batch 140, Loss: 1.0994
Batch 150, Loss: 1.1237
Batch 160, Loss: 1.1344
Batch 170, Loss: 1.1562
Batch 180, Loss: 1.1068
Batch 190, Loss: 1.1552
Batch 200, Loss: 1.1717
Batch 210, Loss: 1.1418
Batch 220, Loss: 1.1265
Batch 230, Loss: 1.2221
Batch 240, Loss: 1.1356
Batch 250, Loss: 1.1835
Batch 260, Loss: 1.1424
Batch 270, Loss: 1.1770
Batch 280, Loss: 1.1296
Batch 290, Loss: 1.1657
Batch 300, Loss: 1.1555
Batch 310, Loss: 1.0832
Batch 320, Loss: 1.1232
Batch 330, Loss: 1.1447
Batch 340, Loss: 1.2393
Batch 350, Loss: 1.1834
Batch 360, Loss: 1.1548
Batch 370, Loss: 1.2110
Batch 380, Loss: 1.2215
Batch 390, Loss: 1.1503
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.169200897216797 seconds
Epoch 19 accuracy: 55.53%
Batch 10, Loss: 1.0750
Batch 20, Loss: 1.1021
Batch 30, Loss: 1.0338
Batch 40, Loss: 1.0690
Batch 50, Loss: 1.0697
Batch 60, Loss: 1.1175
Batch 70, Loss: 1.0682
Batch 80, Loss: 1.0927
Batch 90, Loss: 1.0742
Batch 100, Loss: 1.0656
Batch 110, Loss: 1.1513
Batch 120, Loss: 1.1107
Batch 130, Loss: 1.0409
Batch 140, Loss: 1.0825
Batch 150, Loss: 1.0729
Batch 160, Loss: 1.0661
Batch 170, Loss: 1.1178
Batch 180, Loss: 1.1650
Batch 190, Loss: 1.1942
Batch 200, Loss: 1.1312
Batch 210, Loss: 1.1155
Batch 220, Loss: 1.0985
Batch 230, Loss: 1.1522
Batch 240, Loss: 1.1022
Batch 250, Loss: 1.1360
Batch 260, Loss: 1.1353
Batch 270, Loss: 1.1579
Batch 280, Loss: 1.1397
Batch 290, Loss: 1.1801
Batch 300, Loss: 1.1857
Batch 310, Loss: 1.2232
Batch 320, Loss: 1.2094
Batch 330, Loss: 1.1893
Batch 340, Loss: 1.1170
Batch 350, Loss: 1.1446
Batch 360, Loss: 1.1818
Batch 370, Loss: 1.1027
Batch 380, Loss: 1.1709
Batch 390, Loss: 1.1945
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.173575162887573 seconds
Epoch 20 accuracy: 55.91%
Batch 10, Loss: 1.0630
Batch 20, Loss: 1.0883
Batch 30, Loss: 1.0861
Batch 40, Loss: 1.0602
Batch 50, Loss: 1.0029
Batch 60, Loss: 1.0512
Batch 70, Loss: 1.1087
Batch 80, Loss: 1.0514
Batch 90, Loss: 1.1099
Batch 100, Loss: 1.0644
Batch 110, Loss: 1.0706
Batch 120, Loss: 1.0858
Batch 130, Loss: 1.0954
Batch 140, Loss: 1.1109
Batch 150, Loss: 1.0996
Batch 160, Loss: 1.1519
Batch 170, Loss: 1.1014
Batch 180, Loss: 1.0928
Batch 190, Loss: 1.1323
Batch 200, Loss: 1.1609
Batch 210, Loss: 1.1452
Batch 220, Loss: 1.0898
Batch 230, Loss: 1.1294
Batch 240, Loss: 1.1332
Batch 250, Loss: 1.0789
Batch 260, Loss: 1.2015
Batch 270, Loss: 1.0960
Batch 280, Loss: 1.0744
Batch 290, Loss: 1.0962
Batch 300, Loss: 1.1293
Batch 310, Loss: 1.0990
Batch 320, Loss: 1.0923
Batch 330, Loss: 1.1380
Batch 340, Loss: 1.2146
Batch 350, Loss: 1.1376
Batch 360, Loss: 1.1859
Batch 370, Loss: 1.2291
Batch 380, Loss: 1.1808
Batch 390, Loss: 1.1360
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.211273431777954 seconds
Epoch 21 accuracy: 53.8%
Batch 10, Loss: 1.0427
Batch 20, Loss: 1.0187
Batch 30, Loss: 0.9921
Batch 40, Loss: 1.0819
Batch 50, Loss: 1.0156
Batch 60, Loss: 1.0388
Batch 70, Loss: 1.0957
Batch 80, Loss: 1.0471
Batch 90, Loss: 1.0139
Batch 100, Loss: 1.0089
Batch 110, Loss: 1.1238
Batch 120, Loss: 1.1141
Batch 130, Loss: 1.0421
Batch 140, Loss: 1.1256
Batch 150, Loss: 1.0612
Batch 160, Loss: 1.1017
Batch 170, Loss: 1.1127
Batch 180, Loss: 1.0538
Batch 190, Loss: 1.1073
Batch 200, Loss: 1.1591
Batch 210, Loss: 1.1009
Batch 220, Loss: 1.1801
Batch 230, Loss: 1.1233
Batch 240, Loss: 1.1191
Batch 250, Loss: 1.0790
Batch 260, Loss: 1.1451
Batch 270, Loss: 1.1408
Batch 280, Loss: 1.1594
Batch 290, Loss: 1.1235
Batch 300, Loss: 1.1355
Batch 310, Loss: 1.1347
Batch 320, Loss: 1.1522
Batch 330, Loss: 1.1221
Batch 340, Loss: 1.1364
Batch 350, Loss: 1.0939
Batch 360, Loss: 1.0514
Batch 370, Loss: 1.1688
Batch 380, Loss: 1.1751
Batch 390, Loss: 1.0579
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.22719669342041 seconds
Epoch 22 accuracy: 56.91%
Batch 10, Loss: 0.9905
Batch 20, Loss: 0.9859
Batch 30, Loss: 0.9812
Batch 40, Loss: 1.0068
Batch 50, Loss: 1.0305
Batch 60, Loss: 1.0951
Batch 70, Loss: 1.0380
Batch 80, Loss: 1.0756
Batch 90, Loss: 1.0812
Batch 100, Loss: 1.0766
Batch 110, Loss: 1.1223
Batch 120, Loss: 1.0871
Batch 130, Loss: 1.0204
Batch 140, Loss: 1.0899
Batch 150, Loss: 1.0692
Batch 160, Loss: 1.1018
Batch 170, Loss: 1.0879
Batch 180, Loss: 1.1306
Batch 190, Loss: 1.0935
Batch 200, Loss: 1.0940
Batch 210, Loss: 1.0684
Batch 220, Loss: 1.0859
Batch 230, Loss: 1.0694
Batch 240, Loss: 1.1095
Batch 250, Loss: 1.1667
Batch 260, Loss: 1.1156
Batch 270, Loss: 1.0821
Batch 280, Loss: 1.1536
Batch 290, Loss: 1.0515
Batch 300, Loss: 1.0776
Batch 310, Loss: 1.1505
Batch 320, Loss: 1.1050
Batch 330, Loss: 1.1222
Batch 340, Loss: 1.1066
Batch 350, Loss: 1.1427
Batch 360, Loss: 1.1084
Batch 370, Loss: 1.1495
Batch 380, Loss: 1.1299
Batch 390, Loss: 1.1437
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.268202304840088 seconds
Epoch 23 accuracy: 57.26%
Batch 10, Loss: 1.0288
Batch 20, Loss: 1.0219
Batch 30, Loss: 1.0004
Batch 40, Loss: 1.0245
Batch 50, Loss: 1.0197
Batch 60, Loss: 1.0652
Batch 70, Loss: 1.0484
Batch 80, Loss: 1.0334
Batch 90, Loss: 1.0140
Batch 100, Loss: 1.0742
Batch 110, Loss: 1.0650
Batch 120, Loss: 1.0480
Batch 130, Loss: 1.1074
Batch 140, Loss: 1.1066
Batch 150, Loss: 1.0734
Batch 160, Loss: 1.1088
Batch 170, Loss: 1.0965
Batch 180, Loss: 1.1150
Batch 190, Loss: 1.0981
Batch 200, Loss: 1.0730
Batch 210, Loss: 1.0930
Batch 220, Loss: 1.0519
Batch 230, Loss: 1.0702
Batch 240, Loss: 1.0704
Batch 250, Loss: 1.0615
Batch 260, Loss: 1.0951
Batch 270, Loss: 1.0888
Batch 280, Loss: 1.0827
Batch 290, Loss: 1.1416
Batch 300, Loss: 1.0255
Batch 310, Loss: 1.1141
Batch 320, Loss: 1.1293
Batch 330, Loss: 1.0866
Batch 340, Loss: 1.0938
Batch 350, Loss: 1.0932
Batch 360, Loss: 1.1160
Batch 370, Loss: 1.1347
Batch 380, Loss: 1.1205
Batch 390, Loss: 1.0728
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.16125988960266 seconds
Epoch 24 accuracy: 58.03%
Batch 10, Loss: 0.9956
Batch 20, Loss: 1.0034
Batch 30, Loss: 1.0140
Batch 40, Loss: 1.0266
Batch 50, Loss: 1.0216
Batch 60, Loss: 1.0489
Batch 70, Loss: 1.0847
Batch 80, Loss: 1.0884
Batch 90, Loss: 1.0578
Batch 100, Loss: 1.0220
Batch 110, Loss: 1.0163
Batch 120, Loss: 1.0161
Batch 130, Loss: 1.0349
Batch 140, Loss: 1.0183
Batch 150, Loss: 1.0835
Batch 160, Loss: 1.0177
Batch 170, Loss: 1.0521
Batch 180, Loss: 1.0251
Batch 190, Loss: 1.1084
Batch 200, Loss: 1.1585
Batch 210, Loss: 1.0549
Batch 220, Loss: 1.0726
Batch 230, Loss: 1.0571
Batch 240, Loss: 1.0960
Batch 250, Loss: 1.0985
Batch 260, Loss: 1.1276
Batch 270, Loss: 1.1395
Batch 280, Loss: 1.0647
Batch 290, Loss: 1.0873
Batch 300, Loss: 1.0806
Batch 310, Loss: 1.0927
Batch 320, Loss: 1.0523
Batch 330, Loss: 1.0789
Batch 340, Loss: 1.0871
Batch 350, Loss: 1.0841
Batch 360, Loss: 1.0643
Batch 370, Loss: 1.0926
Batch 380, Loss: 1.0109
Batch 390, Loss: 1.0859
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.196661472320557 seconds
Epoch 25 accuracy: 58.64%
Batch 10, Loss: 1.0015
Batch 20, Loss: 1.0565
Batch 30, Loss: 1.0066
Batch 40, Loss: 0.9923
Batch 50, Loss: 1.0070
Batch 60, Loss: 1.0246
Batch 70, Loss: 1.0074
Batch 80, Loss: 1.0339
Batch 90, Loss: 0.9945
Batch 100, Loss: 1.0729
Batch 110, Loss: 1.0204
Batch 120, Loss: 1.0501
Batch 130, Loss: 1.0249
Batch 140, Loss: 1.0182
Batch 150, Loss: 1.0718
Batch 160, Loss: 1.0354
Batch 170, Loss: 1.0253
Batch 180, Loss: 1.0819
Batch 190, Loss: 1.0858
Batch 200, Loss: 1.0398
Batch 210, Loss: 1.0451
Batch 220, Loss: 1.0288
Batch 230, Loss: 1.0734
Batch 240, Loss: 1.0823
Batch 250, Loss: 1.0774
Batch 260, Loss: 1.0663
Batch 270, Loss: 1.1148
Batch 280, Loss: 1.0611
Batch 290, Loss: 1.0460
Batch 300, Loss: 1.1336
Batch 310, Loss: 1.0743
Batch 320, Loss: 1.0404
Batch 330, Loss: 1.0813
Batch 340, Loss: 1.0514
Batch 350, Loss: 1.0368
Batch 360, Loss: 1.0697
Batch 370, Loss: 1.1095
Batch 380, Loss: 1.1241
Batch 390, Loss: 1.0744
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.16358256340027 seconds
Epoch 26 accuracy: 59.15%
Batch 10, Loss: 1.0091
Batch 20, Loss: 0.9158
Batch 30, Loss: 0.9748
Batch 40, Loss: 1.0267
Batch 50, Loss: 0.9796
Batch 60, Loss: 1.0222
Batch 70, Loss: 1.0357
Batch 80, Loss: 0.9642
Batch 90, Loss: 1.0090
Batch 100, Loss: 0.9965
Batch 110, Loss: 0.9757
Batch 120, Loss: 1.0117
Batch 130, Loss: 1.0081
Batch 140, Loss: 1.0923
Batch 150, Loss: 1.0108
Batch 160, Loss: 1.0360
Batch 170, Loss: 1.0242
Batch 180, Loss: 1.0796
Batch 190, Loss: 1.0714
Batch 200, Loss: 1.1281
Batch 210, Loss: 1.0874
Batch 220, Loss: 1.0687
Batch 230, Loss: 1.0635
Batch 240, Loss: 1.0753
Batch 250, Loss: 1.0124
Batch 260, Loss: 1.0285
Batch 270, Loss: 1.0670
Batch 280, Loss: 1.1093
Batch 290, Loss: 1.0803
Batch 300, Loss: 1.0942
Batch 310, Loss: 1.0836
Batch 320, Loss: 1.1216
Batch 330, Loss: 1.0663
Batch 340, Loss: 1.0537
Batch 350, Loss: 1.0561
Batch 360, Loss: 1.1188
Batch 370, Loss: 1.0698
Batch 380, Loss: 1.0798
Batch 390, Loss: 1.0941
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.014590740203857 seconds
Epoch 27 accuracy: 56.41%
Batch 10, Loss: 0.9664
Batch 20, Loss: 0.9852
Batch 30, Loss: 0.9701
Batch 40, Loss: 0.8951
Batch 50, Loss: 1.0360
Batch 60, Loss: 1.0530
Batch 70, Loss: 0.9281
Batch 80, Loss: 1.0068
Batch 90, Loss: 0.9460
Batch 100, Loss: 0.9950
Batch 110, Loss: 0.9864
Batch 120, Loss: 0.9950
Batch 130, Loss: 0.9914
Batch 140, Loss: 1.0534
Batch 150, Loss: 1.0693
Batch 160, Loss: 1.0431
Batch 170, Loss: 1.0517
Batch 180, Loss: 1.0411
Batch 190, Loss: 1.0197
Batch 200, Loss: 1.0379
Batch 210, Loss: 1.0619
Batch 220, Loss: 1.0676
Batch 230, Loss: 1.0741
Batch 240, Loss: 1.0063
Batch 250, Loss: 1.0199
Batch 260, Loss: 1.0466
Batch 270, Loss: 1.0785
Batch 280, Loss: 1.0779
Batch 290, Loss: 1.0589
Batch 300, Loss: 1.0443
Batch 310, Loss: 1.0682
Batch 320, Loss: 1.0745
Batch 330, Loss: 1.0449
Batch 340, Loss: 1.0127
Batch 350, Loss: 1.0790
Batch 360, Loss: 1.1134
Batch 370, Loss: 1.1096
Batch 380, Loss: 1.1091
Batch 390, Loss: 1.0489
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.20303177833557 seconds
Epoch 28 accuracy: 54.29%
Batch 10, Loss: 0.9541
Batch 20, Loss: 0.9385
Batch 30, Loss: 0.9212
Batch 40, Loss: 0.9476
Batch 50, Loss: 0.9991
Batch 60, Loss: 0.9976
Batch 70, Loss: 0.9854
Batch 80, Loss: 1.0037
Batch 90, Loss: 0.9808
Batch 100, Loss: 0.9818
Batch 110, Loss: 1.0063
Batch 120, Loss: 1.0364
Batch 130, Loss: 0.9685
Batch 140, Loss: 1.1024
Batch 150, Loss: 1.0619
Batch 160, Loss: 1.0017
Batch 170, Loss: 1.0534
Batch 180, Loss: 1.0503
Batch 190, Loss: 1.0247
Batch 200, Loss: 1.0880
Batch 210, Loss: 1.0268
Batch 220, Loss: 1.0381
Batch 230, Loss: 1.0303
Batch 240, Loss: 1.0289
Batch 250, Loss: 1.0783
Batch 260, Loss: 1.0131
Batch 270, Loss: 0.9880
Batch 280, Loss: 1.0367
Batch 290, Loss: 0.9971
Batch 300, Loss: 1.0562
Batch 310, Loss: 0.9933
Batch 320, Loss: 1.0537
Batch 330, Loss: 1.0975
Batch 340, Loss: 1.0650
Batch 350, Loss: 1.0188
Batch 360, Loss: 1.1318
Batch 370, Loss: 1.0614
Batch 380, Loss: 1.1185
Batch 390, Loss: 1.0266
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.24303436279297 seconds
Epoch 29 accuracy: 59.47%
Batch 10, Loss: 0.9555
Batch 20, Loss: 0.9432
Batch 30, Loss: 1.0073
Batch 40, Loss: 0.9491
Batch 50, Loss: 0.9784
Batch 60, Loss: 0.9316
Batch 70, Loss: 1.0114
Batch 80, Loss: 0.9881
Batch 90, Loss: 1.0028
Batch 100, Loss: 0.9832
Batch 110, Loss: 0.9922
Batch 120, Loss: 0.9670
Batch 130, Loss: 1.0488
Batch 140, Loss: 0.9982
Batch 150, Loss: 1.0444
Batch 160, Loss: 1.0294
Batch 170, Loss: 1.0048
Batch 180, Loss: 1.0404
Batch 190, Loss: 1.0121
Batch 200, Loss: 1.0387
Batch 210, Loss: 1.0291
Batch 220, Loss: 1.0192
Batch 230, Loss: 1.0590
Batch 240, Loss: 0.9789
Batch 250, Loss: 1.0491
Batch 260, Loss: 1.0105
Batch 270, Loss: 1.0620
Batch 280, Loss: 1.0157
Batch 290, Loss: 1.0692
Batch 300, Loss: 1.0146
Batch 310, Loss: 1.0045
Batch 320, Loss: 1.0400
Batch 330, Loss: 1.0558
Batch 340, Loss: 1.0773
Batch 350, Loss: 1.0284
Batch 360, Loss: 1.0327
Batch 370, Loss: 1.0732
Batch 380, Loss: 1.0530
Batch 390, Loss: 1.0625
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.263242721557617 seconds
Epoch 30 accuracy: 58.07%
Batch 10, Loss: 0.9835
Batch 20, Loss: 0.9401
Batch 30, Loss: 0.9077
Batch 40, Loss: 0.9503
Batch 50, Loss: 0.9612
Batch 60, Loss: 0.9598
Batch 70, Loss: 0.9636
Batch 80, Loss: 0.9962
Batch 90, Loss: 0.9653
Batch 100, Loss: 0.9574
Batch 110, Loss: 0.9836
Batch 120, Loss: 0.9908
Batch 130, Loss: 0.9796
Batch 140, Loss: 1.0020
Batch 150, Loss: 1.0905
Batch 160, Loss: 0.9985
Batch 170, Loss: 1.0786
Batch 180, Loss: 1.0132
Batch 190, Loss: 1.0624
Batch 200, Loss: 1.0189
Batch 210, Loss: 0.9934
Batch 220, Loss: 1.0054
Batch 230, Loss: 1.0098
Batch 240, Loss: 1.0087
Batch 250, Loss: 1.1026
Batch 260, Loss: 1.0252
Batch 270, Loss: 1.0975
Batch 280, Loss: 1.0265
Batch 290, Loss: 1.0169
Batch 300, Loss: 0.9869
Batch 310, Loss: 1.0946
Batch 320, Loss: 1.0225
Batch 330, Loss: 1.0743
Batch 340, Loss: 1.0587
Batch 350, Loss: 1.0983
Batch 360, Loss: 1.0580
Batch 370, Loss: 1.0580
Batch 380, Loss: 1.0111
Batch 390, Loss: 1.0412
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.19843029975891 seconds
Epoch 31 accuracy: 58.67%
Batch 10, Loss: 0.9188
Batch 20, Loss: 0.9625
Batch 30, Loss: 0.9648
Batch 40, Loss: 0.9664
Batch 50, Loss: 0.9109
Batch 60, Loss: 0.9315
Batch 70, Loss: 0.9939
Batch 80, Loss: 0.9395
Batch 90, Loss: 0.9265
Batch 100, Loss: 0.9255
Batch 110, Loss: 1.0034
Batch 120, Loss: 0.9563
Batch 130, Loss: 1.0005
Batch 140, Loss: 0.9705
Batch 150, Loss: 0.9899
Batch 160, Loss: 1.0248
Batch 170, Loss: 0.9852
Batch 180, Loss: 1.0307
Batch 190, Loss: 1.0200
Batch 200, Loss: 1.0492
Batch 210, Loss: 1.0342
Batch 220, Loss: 1.0765
Batch 230, Loss: 0.9997
Batch 240, Loss: 1.0085
Batch 250, Loss: 1.0394
Batch 260, Loss: 1.0277
Batch 270, Loss: 1.0383
Batch 280, Loss: 1.0429
Batch 290, Loss: 1.0402
Batch 300, Loss: 1.0243
Batch 310, Loss: 1.0494
Batch 320, Loss: 1.0425
Batch 330, Loss: 1.0571
Batch 340, Loss: 1.0320
Batch 350, Loss: 1.0172
Batch 360, Loss: 1.0426
Batch 370, Loss: 1.0067
Batch 380, Loss: 1.0160
Batch 390, Loss: 1.0974
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.271907329559326 seconds
Epoch 32 accuracy: 59.72%
Batch 10, Loss: 0.9883
Batch 20, Loss: 0.9457
Batch 30, Loss: 1.0016
Batch 40, Loss: 0.9021
Batch 50, Loss: 0.9668
Batch 60, Loss: 0.9123
Batch 70, Loss: 0.9145
Batch 80, Loss: 0.9699
Batch 90, Loss: 0.9396
Batch 100, Loss: 0.9749
Batch 110, Loss: 0.9971
Batch 120, Loss: 0.9831
Batch 130, Loss: 1.0263
Batch 140, Loss: 0.9604
Batch 150, Loss: 1.0137
Batch 160, Loss: 1.0252
Batch 170, Loss: 1.0282
Batch 180, Loss: 0.9543
Batch 190, Loss: 0.9681
Batch 200, Loss: 1.0244
Batch 210, Loss: 0.9687
Batch 220, Loss: 0.9812
Batch 230, Loss: 1.0465
Batch 240, Loss: 1.0086
Batch 250, Loss: 1.0011
Batch 260, Loss: 1.0238
Batch 270, Loss: 1.0736
Batch 280, Loss: 1.0493
Batch 290, Loss: 1.0598
Batch 300, Loss: 1.0098
Batch 310, Loss: 0.9780
Batch 320, Loss: 1.0014
Batch 330, Loss: 1.0310
Batch 340, Loss: 1.0082
Batch 350, Loss: 1.0076
Batch 360, Loss: 1.0438
Batch 370, Loss: 1.0581
Batch 380, Loss: 1.0606
Batch 390, Loss: 1.0595
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.265262603759766 seconds
Epoch 33 accuracy: 57.68%
Batch 10, Loss: 0.9700
Batch 20, Loss: 0.8888
Batch 30, Loss: 0.8963
Batch 40, Loss: 0.9401
Batch 50, Loss: 0.9756
Batch 60, Loss: 0.9347
Batch 70, Loss: 0.9029
Batch 80, Loss: 0.9396
Batch 90, Loss: 0.9390
Batch 100, Loss: 0.8870
Batch 110, Loss: 0.9384
Batch 120, Loss: 0.9716
Batch 130, Loss: 0.9934
Batch 140, Loss: 0.9552
Batch 150, Loss: 0.9995
Batch 160, Loss: 0.9565
Batch 170, Loss: 0.9822
Batch 180, Loss: 0.9042
Batch 190, Loss: 1.0061
Batch 200, Loss: 0.9802
Batch 210, Loss: 1.0391
Batch 220, Loss: 1.0328
Batch 230, Loss: 1.0332
Batch 240, Loss: 1.0780
Batch 250, Loss: 1.0105
Batch 260, Loss: 1.0132
Batch 270, Loss: 0.9953
Batch 280, Loss: 1.0250
Batch 290, Loss: 1.0231
Batch 300, Loss: 1.0743
Batch 310, Loss: 1.0165
Batch 320, Loss: 1.0722
Batch 330, Loss: 1.0484
Batch 340, Loss: 0.9983
Batch 350, Loss: 0.9610
Batch 360, Loss: 0.9735
Batch 370, Loss: 1.0124
Batch 380, Loss: 1.0121
Batch 390, Loss: 1.0447
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.25928497314453 seconds
Epoch 34 accuracy: 60.07%
Batch 10, Loss: 0.9226
Batch 20, Loss: 0.9337
Batch 30, Loss: 0.9170
Batch 40, Loss: 0.8467
Batch 50, Loss: 0.8931
Batch 60, Loss: 0.9405
Batch 70, Loss: 0.9118
Batch 80, Loss: 0.9502
Batch 90, Loss: 0.9424
Batch 100, Loss: 0.9999
Batch 110, Loss: 0.9530
Batch 120, Loss: 0.9257
Batch 130, Loss: 0.9938
Batch 140, Loss: 1.0256
Batch 150, Loss: 0.9983
Batch 160, Loss: 0.9562
Batch 170, Loss: 0.9527
Batch 180, Loss: 0.9702
Batch 190, Loss: 1.0434
Batch 200, Loss: 0.9955
Batch 210, Loss: 0.9960
Batch 220, Loss: 0.9706
Batch 230, Loss: 1.0134
Batch 240, Loss: 1.0471
Batch 250, Loss: 1.0232
Batch 260, Loss: 1.0292
Batch 270, Loss: 1.0375
Batch 280, Loss: 0.9618
Batch 290, Loss: 1.0481
Batch 300, Loss: 0.9764
Batch 310, Loss: 1.0298
Batch 320, Loss: 1.0294
Batch 330, Loss: 1.1100
Batch 340, Loss: 1.0731
Batch 350, Loss: 1.0838
Batch 360, Loss: 1.0292
Batch 370, Loss: 1.1212
Batch 380, Loss: 0.9848
Batch 390, Loss: 0.9561
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.351451873779297 seconds
Epoch 35 accuracy: 58.43%
Batch 10, Loss: 0.9063
Batch 20, Loss: 0.8823
Batch 30, Loss: 0.9098
Batch 40, Loss: 0.8950
Batch 50, Loss: 0.9182
Batch 60, Loss: 0.9771
Batch 70, Loss: 0.9053
Batch 80, Loss: 0.9227
Batch 90, Loss: 0.9723
Batch 100, Loss: 0.9615
Batch 110, Loss: 0.9342
Batch 120, Loss: 0.9654
Batch 130, Loss: 0.9643
Batch 140, Loss: 0.9667
Batch 150, Loss: 0.9594
Batch 160, Loss: 0.9567
Batch 170, Loss: 0.9922
Batch 180, Loss: 0.9883
Batch 190, Loss: 1.0201
Batch 200, Loss: 1.0450
Batch 210, Loss: 0.9796
Batch 220, Loss: 0.9726
Batch 230, Loss: 1.0224
Batch 240, Loss: 1.0017
Batch 250, Loss: 0.9964
Batch 260, Loss: 0.9767
Batch 270, Loss: 0.9612
Batch 280, Loss: 0.9951
Batch 290, Loss: 0.9771
Batch 300, Loss: 0.9607
Batch 310, Loss: 0.9561
Batch 320, Loss: 0.9853
Batch 330, Loss: 0.9544
Batch 340, Loss: 1.0204
Batch 350, Loss: 1.0220
Batch 360, Loss: 1.0090
Batch 370, Loss: 1.0692
Batch 380, Loss: 0.9645
Batch 390, Loss: 1.0225
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.38380002975464 seconds
Epoch 36 accuracy: 58.07%
Batch 10, Loss: 0.9238
Batch 20, Loss: 0.8965
Batch 30, Loss: 0.9682
Batch 40, Loss: 0.8892
Batch 50, Loss: 0.9132
Batch 60, Loss: 0.8911
Batch 70, Loss: 0.9008
Batch 80, Loss: 1.0054
Batch 90, Loss: 0.8864
Batch 100, Loss: 0.9222
Batch 110, Loss: 0.9444
Batch 120, Loss: 0.9569
Batch 130, Loss: 0.9150
Batch 140, Loss: 0.9633
Batch 150, Loss: 0.9900
Batch 160, Loss: 0.9466
Batch 170, Loss: 0.9776
Batch 180, Loss: 0.9330
Batch 190, Loss: 0.9749
Batch 200, Loss: 0.9555
Batch 210, Loss: 0.9393
Batch 220, Loss: 0.9972
Batch 230, Loss: 1.0097
Batch 240, Loss: 0.9754
Batch 250, Loss: 1.0496
Batch 260, Loss: 0.9801
Batch 270, Loss: 0.9989
Batch 280, Loss: 1.0299
Batch 290, Loss: 0.9776
Batch 300, Loss: 0.9625
Batch 310, Loss: 1.0455
Batch 320, Loss: 0.9711
Batch 330, Loss: 1.0126
Batch 340, Loss: 0.9690
Batch 350, Loss: 1.0063
Batch 360, Loss: 0.9974
Batch 370, Loss: 1.0613
Batch 380, Loss: 1.0731
Batch 390, Loss: 1.0007
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.15051794052124 seconds
Epoch 37 accuracy: 58.34%
Batch 10, Loss: 0.8896
Batch 20, Loss: 0.8793
Batch 30, Loss: 0.9369
Batch 40, Loss: 0.9212
Batch 50, Loss: 0.8570
Batch 60, Loss: 0.9146
Batch 70, Loss: 0.9566
Batch 80, Loss: 0.9104
Batch 90, Loss: 0.9273
Batch 100, Loss: 0.9014
Batch 110, Loss: 0.9098
Batch 120, Loss: 0.8813
Batch 130, Loss: 0.9618
Batch 140, Loss: 0.9481
Batch 150, Loss: 0.9866
Batch 160, Loss: 0.9333
Batch 170, Loss: 0.9952
Batch 180, Loss: 0.9814
Batch 190, Loss: 0.9883
Batch 200, Loss: 0.9733
Batch 210, Loss: 1.0036
Batch 220, Loss: 0.9922
Batch 230, Loss: 1.0107
Batch 240, Loss: 0.9712
Batch 250, Loss: 0.9959
Batch 260, Loss: 0.9928
Batch 270, Loss: 0.9563
Batch 280, Loss: 0.9727
Batch 290, Loss: 1.0115
Batch 300, Loss: 1.0356
Batch 310, Loss: 0.9547
Batch 320, Loss: 1.0261
Batch 330, Loss: 1.0163
Batch 340, Loss: 0.9784
Batch 350, Loss: 1.0093
Batch 360, Loss: 0.9921
Batch 370, Loss: 0.9987
Batch 380, Loss: 1.0754
Batch 390, Loss: 1.0374
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.18123483657837 seconds
Epoch 38 accuracy: 56.88%
Batch 10, Loss: 0.9286
Batch 20, Loss: 0.9351
Batch 30, Loss: 0.9487
Batch 40, Loss: 0.9350
Batch 50, Loss: 0.8823
Batch 60, Loss: 0.8682
Batch 70, Loss: 0.9171
Batch 80, Loss: 0.9420
Batch 90, Loss: 0.8880
Batch 100, Loss: 0.9803
Batch 110, Loss: 0.9612
Batch 120, Loss: 0.9397
Batch 130, Loss: 0.9717
Batch 140, Loss: 1.0148
Batch 150, Loss: 0.9490
Batch 160, Loss: 0.9702
Batch 170, Loss: 0.9380
Batch 180, Loss: 0.9046
Batch 190, Loss: 0.9711
Batch 200, Loss: 0.9385
Batch 210, Loss: 0.9579
Batch 220, Loss: 0.9120
Batch 230, Loss: 0.9541
Batch 240, Loss: 0.9677
Batch 250, Loss: 1.0070
Batch 260, Loss: 0.9516
Batch 270, Loss: 0.9456
Batch 280, Loss: 0.9547
Batch 290, Loss: 0.9832
Batch 300, Loss: 0.9725
Batch 310, Loss: 0.9708
Batch 320, Loss: 1.0645
Batch 330, Loss: 1.0047
Batch 340, Loss: 0.9768
Batch 350, Loss: 1.0450
Batch 360, Loss: 1.0000
Batch 370, Loss: 1.0071
Batch 380, Loss: 1.0248
Batch 390, Loss: 1.0287
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.24938440322876 seconds
Epoch 39 accuracy: 57.69%
Batch 10, Loss: 0.9835
Batch 20, Loss: 0.8722
Batch 30, Loss: 0.9276
Batch 40, Loss: 0.8492
Batch 50, Loss: 0.8670
Batch 60, Loss: 0.9162
Batch 70, Loss: 0.9308
Batch 80, Loss: 0.9620
Batch 90, Loss: 0.8666
Batch 100, Loss: 0.9738
Batch 110, Loss: 0.9384
Batch 120, Loss: 0.9305
Batch 130, Loss: 0.9204
Batch 140, Loss: 0.9176
Batch 150, Loss: 0.9493
Batch 160, Loss: 0.9201
Batch 170, Loss: 0.9920
Batch 180, Loss: 0.9132
Batch 190, Loss: 0.9434
Batch 200, Loss: 0.9442
Batch 210, Loss: 0.9590
Batch 220, Loss: 0.9308
Batch 230, Loss: 0.9753
Batch 240, Loss: 0.9882
Batch 250, Loss: 0.9940
Batch 260, Loss: 0.9444
Batch 270, Loss: 0.9549
Batch 280, Loss: 0.9652
Batch 290, Loss: 0.9738
Batch 300, Loss: 0.9920
Batch 310, Loss: 1.0372
Batch 320, Loss: 1.0148
Batch 330, Loss: 0.9952
Batch 340, Loss: 0.9940
Batch 350, Loss: 1.0019
Batch 360, Loss: 0.9794
Batch 370, Loss: 0.9651
Batch 380, Loss: 0.9743
Batch 390, Loss: 0.9670
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.181875228881836 seconds
Epoch 40 accuracy: 57.24%
Batch 10, Loss: 0.8914
Batch 20, Loss: 0.9121
Batch 30, Loss: 0.8930
Batch 40, Loss: 0.9021
Batch 50, Loss: 0.8665
Batch 60, Loss: 0.8518
Batch 70, Loss: 0.9348
Batch 80, Loss: 0.8530
Batch 90, Loss: 0.8811
Batch 100, Loss: 0.8642
Batch 110, Loss: 0.9135
Batch 120, Loss: 1.0105
Batch 130, Loss: 0.9211
Batch 140, Loss: 0.9217
Batch 150, Loss: 0.9310
Batch 160, Loss: 0.9486
Batch 170, Loss: 0.9554
Batch 180, Loss: 0.9365
Batch 190, Loss: 0.9421
Batch 200, Loss: 0.9144
Batch 210, Loss: 0.9531
Batch 220, Loss: 0.9971
Batch 230, Loss: 0.9934
Batch 240, Loss: 0.9713
Batch 250, Loss: 1.0228
Batch 260, Loss: 0.9968
Batch 270, Loss: 0.9523
Batch 280, Loss: 1.0153
Batch 290, Loss: 0.9416
Batch 300, Loss: 0.9883
Batch 310, Loss: 0.9727
Batch 320, Loss: 1.0529
Batch 330, Loss: 0.9991
Batch 340, Loss: 1.0195
Batch 350, Loss: 1.0178
Batch 360, Loss: 0.9924
Batch 370, Loss: 1.0324
Batch 380, Loss: 1.0089
Batch 390, Loss: 0.9518
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.21201491355896 seconds
Epoch 41 accuracy: 59.55%
Batch 10, Loss: 0.8827
Batch 20, Loss: 0.8984
Batch 30, Loss: 0.8999
Batch 40, Loss: 0.8917
Batch 50, Loss: 0.8651
Batch 60, Loss: 0.9173
Batch 70, Loss: 0.8383
Batch 80, Loss: 0.8855
Batch 90, Loss: 0.8747
Batch 100, Loss: 0.9086
Batch 110, Loss: 0.8960
Batch 120, Loss: 0.9318
Batch 130, Loss: 0.8942
Batch 140, Loss: 0.9441
Batch 150, Loss: 0.9492
Batch 160, Loss: 0.9927
Batch 170, Loss: 0.9503
Batch 180, Loss: 0.9414
Batch 190, Loss: 0.9650
Batch 200, Loss: 0.9089
Batch 210, Loss: 0.9105
Batch 220, Loss: 1.0037
Batch 230, Loss: 0.9942
Batch 240, Loss: 1.0097
Batch 250, Loss: 0.9402
Batch 260, Loss: 0.9195
Batch 270, Loss: 0.9773
Batch 280, Loss: 0.9611
Batch 290, Loss: 0.9993
Batch 300, Loss: 0.9789
Batch 310, Loss: 0.9487
Batch 320, Loss: 0.9613
Batch 330, Loss: 0.9673
Batch 340, Loss: 0.9341
Batch 350, Loss: 0.9762
Batch 360, Loss: 0.9735
Batch 370, Loss: 0.9794
Batch 380, Loss: 0.9958
Batch 390, Loss: 0.9825
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.24513530731201 seconds
Epoch 42 accuracy: 59.89%
Batch 10, Loss: 0.8772
Batch 20, Loss: 0.8505
Batch 30, Loss: 0.8120
Batch 40, Loss: 0.8520
Batch 50, Loss: 0.8652
Batch 60, Loss: 0.8505
Batch 70, Loss: 0.8763
Batch 80, Loss: 0.8873
Batch 90, Loss: 0.9503
Batch 100, Loss: 0.9359
Batch 110, Loss: 0.9636
Batch 120, Loss: 0.8899
Batch 130, Loss: 0.9602
Batch 140, Loss: 0.9756
Batch 150, Loss: 0.9469
Batch 160, Loss: 0.9870
Batch 170, Loss: 0.9203
Batch 180, Loss: 0.9004
Batch 190, Loss: 0.9195
Batch 200, Loss: 0.9111
Batch 210, Loss: 0.9728
Batch 220, Loss: 1.0208
Batch 230, Loss: 0.9498
Batch 240, Loss: 0.9038
Batch 250, Loss: 0.9077
Batch 260, Loss: 0.9055
Batch 270, Loss: 0.9719
Batch 280, Loss: 0.9491
Batch 290, Loss: 0.9602
Batch 300, Loss: 0.9395
Batch 310, Loss: 0.9644
Batch 320, Loss: 0.9686
Batch 330, Loss: 0.9545
Batch 340, Loss: 0.9775
Batch 350, Loss: 1.0172
Batch 360, Loss: 0.9686
Batch 370, Loss: 0.9606
Batch 380, Loss: 1.0102
Batch 390, Loss: 0.9542
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.257140159606934 seconds
Epoch 43 accuracy: 57.98%
Batch 10, Loss: 0.8935
Batch 20, Loss: 0.8183
Batch 30, Loss: 0.8516
Batch 40, Loss: 0.9081
Batch 50, Loss: 0.9575
Batch 60, Loss: 0.8859
Batch 70, Loss: 0.8471
Batch 80, Loss: 0.8667
Batch 90, Loss: 0.8621
Batch 100, Loss: 0.9519
Batch 110, Loss: 0.8684
Batch 120, Loss: 0.8925
Batch 130, Loss: 0.9041
Batch 140, Loss: 0.9148
Batch 150, Loss: 0.9377
Batch 160, Loss: 0.9087
Batch 170, Loss: 0.9168
Batch 180, Loss: 0.9351
Batch 190, Loss: 0.8648
Batch 200, Loss: 1.0252
Batch 210, Loss: 0.9182
Batch 220, Loss: 0.9062
Batch 230, Loss: 1.0023
Batch 240, Loss: 1.0054
Batch 250, Loss: 0.9786
Batch 260, Loss: 0.9669
Batch 270, Loss: 0.9338
Batch 280, Loss: 0.9899
Batch 290, Loss: 0.9705
Batch 300, Loss: 0.9548
Batch 310, Loss: 0.9543
Batch 320, Loss: 0.9729
Batch 330, Loss: 0.8846
Batch 340, Loss: 0.9719
Batch 350, Loss: 0.9195
Batch 360, Loss: 0.9765
Batch 370, Loss: 0.9107
Batch 380, Loss: 0.9488
Batch 390, Loss: 1.0235
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.304264307022095 seconds
Epoch 44 accuracy: 60.86%
Batch 10, Loss: 0.9325
Batch 20, Loss: 0.8544
Batch 30, Loss: 0.8340
Batch 40, Loss: 0.8498
Batch 50, Loss: 0.8681
Batch 60, Loss: 0.8702
Batch 70, Loss: 0.8677
Batch 80, Loss: 0.8680
Batch 90, Loss: 0.8904
Batch 100, Loss: 0.9641
Batch 110, Loss: 0.8725
Batch 120, Loss: 0.8676
Batch 130, Loss: 0.9080
Batch 140, Loss: 0.8708
Batch 150, Loss: 0.9142
Batch 160, Loss: 0.8987
Batch 170, Loss: 0.8924
Batch 180, Loss: 0.8877
Batch 190, Loss: 0.8801
Batch 200, Loss: 0.9273
Batch 210, Loss: 0.9388
Batch 220, Loss: 0.9345
Batch 230, Loss: 0.9936
Batch 240, Loss: 0.9690
Batch 250, Loss: 0.9450
Batch 260, Loss: 0.9924
Batch 270, Loss: 0.9906
Batch 280, Loss: 0.9557
Batch 290, Loss: 0.9678
Batch 300, Loss: 0.9472
Batch 310, Loss: 0.9229
Batch 320, Loss: 0.9302
Batch 330, Loss: 0.9445
Batch 340, Loss: 0.9345
Batch 350, Loss: 0.9451
Batch 360, Loss: 0.9658
Batch 370, Loss: 0.9212
Batch 380, Loss: 0.9926
Batch 390, Loss: 0.9519
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.23439335823059 seconds
Epoch 45 accuracy: 59.58%
Batch 10, Loss: 0.8976
Batch 20, Loss: 0.8649
Batch 30, Loss: 0.8217
Batch 40, Loss: 0.8313
Batch 50, Loss: 0.8665
Batch 60, Loss: 0.8911
Batch 70, Loss: 0.8394
Batch 80, Loss: 0.8537
Batch 90, Loss: 0.9301
Batch 100, Loss: 0.9294
Batch 110, Loss: 0.8825
Batch 120, Loss: 0.9026
Batch 130, Loss: 0.9131
Batch 140, Loss: 0.9301
Batch 150, Loss: 0.9036
Batch 160, Loss: 0.9358
Batch 170, Loss: 0.9066
Batch 180, Loss: 0.9320
Batch 190, Loss: 0.9237
Batch 200, Loss: 0.8896
Batch 210, Loss: 0.8841
Batch 220, Loss: 0.9518
Batch 230, Loss: 0.9379
Batch 240, Loss: 0.9313
Batch 250, Loss: 0.8850
Batch 260, Loss: 0.9283
Batch 270, Loss: 0.9093
Batch 280, Loss: 0.9118
Batch 290, Loss: 0.9094
Batch 300, Loss: 0.8849
Batch 310, Loss: 0.9551
Batch 320, Loss: 0.9336
Batch 330, Loss: 0.9214
Batch 340, Loss: 0.9638
Batch 350, Loss: 0.9406
Batch 360, Loss: 1.0029
Batch 370, Loss: 0.9928
Batch 380, Loss: 0.9858
Batch 390, Loss: 0.9836
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.185022830963135 seconds
Epoch 46 accuracy: 58.91%
Batch 10, Loss: 0.8605
Batch 20, Loss: 0.8450
Batch 30, Loss: 0.8666
Batch 40, Loss: 0.8379
Batch 50, Loss: 0.8576
Batch 60, Loss: 0.8753
Batch 70, Loss: 0.8754
Batch 80, Loss: 0.8426
Batch 90, Loss: 0.8734
Batch 100, Loss: 0.8656
Batch 110, Loss: 0.9015
Batch 120, Loss: 0.8641
Batch 130, Loss: 0.9070
Batch 140, Loss: 0.9150
Batch 150, Loss: 0.8654
Batch 160, Loss: 0.9374
Batch 170, Loss: 0.9277
Batch 180, Loss: 0.9037
Batch 190, Loss: 0.9145
Batch 200, Loss: 0.9189
Batch 210, Loss: 0.9280
Batch 220, Loss: 0.9848
Batch 230, Loss: 0.9949
Batch 240, Loss: 0.9547
Batch 250, Loss: 0.9500
Batch 260, Loss: 0.9577
Batch 270, Loss: 0.9130
Batch 280, Loss: 0.9319
Batch 290, Loss: 0.9769
Batch 300, Loss: 0.9402
Batch 310, Loss: 0.9723
Batch 320, Loss: 0.9846
Batch 330, Loss: 0.9116
Batch 340, Loss: 0.9486
Batch 350, Loss: 0.9904
Batch 360, Loss: 0.9931
Batch 370, Loss: 0.9786
Batch 380, Loss: 1.0069
Batch 390, Loss: 0.9364
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.277852058410645 seconds
Epoch 47 accuracy: 58.44%
Batch 10, Loss: 0.8285
Batch 20, Loss: 0.8163
Batch 30, Loss: 0.8597
Batch 40, Loss: 0.8261
Batch 50, Loss: 0.8382
Batch 60, Loss: 0.8405
Batch 70, Loss: 0.8503
Batch 80, Loss: 0.8532
Batch 90, Loss: 0.8520
Batch 100, Loss: 0.8222
Batch 110, Loss: 0.8816
Batch 120, Loss: 0.8869
Batch 130, Loss: 0.9058
Batch 140, Loss: 0.8811
Batch 150, Loss: 0.9473
Batch 160, Loss: 0.9085
Batch 170, Loss: 0.9117
Batch 180, Loss: 0.8832
Batch 190, Loss: 0.8828
Batch 200, Loss: 0.8980
Batch 210, Loss: 0.9333
Batch 220, Loss: 0.9123
Batch 230, Loss: 0.9214
Batch 240, Loss: 0.9780
Batch 250, Loss: 0.8908
Batch 260, Loss: 0.9233
Batch 270, Loss: 0.9088
Batch 280, Loss: 0.9823
Batch 290, Loss: 0.9779
Batch 300, Loss: 0.9503
Batch 310, Loss: 0.9403
Batch 320, Loss: 0.9514
Batch 330, Loss: 0.9284
Batch 340, Loss: 0.9142
Batch 350, Loss: 0.9267
Batch 360, Loss: 0.9570
Batch 370, Loss: 0.9498
Batch 380, Loss: 0.9954
Batch 390, Loss: 0.9396
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.203137159347534 seconds
Epoch 48 accuracy: 60.93%
Batch 10, Loss: 0.8521
Batch 20, Loss: 0.7937
Batch 30, Loss: 0.8203
Batch 40, Loss: 0.8366
Batch 50, Loss: 0.8535
Batch 60, Loss: 0.8302
Batch 70, Loss: 0.8278
Batch 80, Loss: 0.8267
Batch 90, Loss: 0.8894
Batch 100, Loss: 0.8470
Batch 110, Loss: 0.8924
Batch 120, Loss: 0.8595
Batch 130, Loss: 0.9280
Batch 140, Loss: 0.9337
Batch 150, Loss: 0.8939
Batch 160, Loss: 0.8310
Batch 170, Loss: 0.8661
Batch 180, Loss: 0.9087
Batch 190, Loss: 0.9259
Batch 200, Loss: 0.8949
Batch 210, Loss: 0.9510
Batch 220, Loss: 0.8941
Batch 230, Loss: 0.9197
Batch 240, Loss: 0.9176
Batch 250, Loss: 0.9116
Batch 260, Loss: 0.9612
Batch 270, Loss: 0.9977
Batch 280, Loss: 0.9339
Batch 290, Loss: 0.8916
Batch 300, Loss: 0.9242
Batch 310, Loss: 0.9359
Batch 320, Loss: 0.9511
Batch 330, Loss: 0.9774
Batch 340, Loss: 0.9892
Batch 350, Loss: 0.9107
Batch 360, Loss: 0.9678
Batch 370, Loss: 0.9136
Batch 380, Loss: 0.9802
Batch 390, Loss: 0.9498
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.25162148475647 seconds
Epoch 49 accuracy: 57.69%
Batch 10, Loss: 0.8667
Batch 20, Loss: 0.8364
Batch 30, Loss: 0.8254
Batch 40, Loss: 0.8439
Batch 50, Loss: 0.8605
Batch 60, Loss: 0.8543
Batch 70, Loss: 0.8149
Batch 80, Loss: 0.8260
Batch 90, Loss: 0.8276
Batch 100, Loss: 0.8537
Batch 110, Loss: 0.8476
Batch 120, Loss: 0.8664
Batch 130, Loss: 0.8947
Batch 140, Loss: 0.8533
Batch 150, Loss: 0.8864
Batch 160, Loss: 0.9093
Batch 170, Loss: 0.9528
Batch 180, Loss: 0.8920
Batch 190, Loss: 0.8866
Batch 200, Loss: 0.9167
Batch 210, Loss: 0.9539
Batch 220, Loss: 0.9188
Batch 230, Loss: 0.8935
Batch 240, Loss: 0.8577
Batch 250, Loss: 0.8856
Batch 260, Loss: 0.9176
Batch 270, Loss: 0.9391
Batch 280, Loss: 0.9258
Batch 290, Loss: 1.0158
Batch 300, Loss: 0.9729
Batch 310, Loss: 0.9193
Batch 320, Loss: 0.9146
Batch 330, Loss: 0.9233
Batch 340, Loss: 0.9972
Batch 350, Loss: 0.9525
Batch 360, Loss: 0.9258
Batch 370, Loss: 0.9396
Batch 380, Loss: 0.9488
Batch 390, Loss: 0.9737
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.24861717224121 seconds
Epoch 50 accuracy: 59.55%
Batch 10, Loss: 0.8169
Batch 20, Loss: 0.8539
Batch 30, Loss: 0.8508
Batch 40, Loss: 0.8279
Batch 50, Loss: 0.8502
Batch 60, Loss: 0.8433
Batch 70, Loss: 0.8514
Batch 80, Loss: 0.8224
Batch 90, Loss: 0.8565
Batch 100, Loss: 0.8540
Batch 110, Loss: 0.8540
Batch 120, Loss: 0.8443
Batch 130, Loss: 0.8683
Batch 140, Loss: 0.8950
Batch 150, Loss: 0.9171
Batch 160, Loss: 0.8657
Batch 170, Loss: 0.8596
Batch 180, Loss: 0.9385
Batch 190, Loss: 0.8552
Batch 200, Loss: 0.9397
Batch 210, Loss: 0.9844
Batch 220, Loss: 0.9046
Batch 230, Loss: 0.9276
Batch 240, Loss: 0.9343
Batch 250, Loss: 0.9453
Batch 260, Loss: 0.8821
Batch 270, Loss: 0.8655
Batch 280, Loss: 0.9190
Batch 290, Loss: 0.9139
Batch 300, Loss: 0.9555
Batch 310, Loss: 0.9357
Batch 320, Loss: 0.9268
Batch 330, Loss: 0.9610
Batch 340, Loss: 0.9331
Batch 350, Loss: 0.9720
Batch 360, Loss: 0.9596
Batch 370, Loss: 0.9359
Batch 380, Loss: 0.9223
Batch 390, Loss: 0.8770
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.215383291244507 seconds
Epoch 51 accuracy: 62.86%
Batch 10, Loss: 0.8503
Batch 20, Loss: 0.7917
Batch 30, Loss: 0.7888
Batch 40, Loss: 0.8456
Batch 50, Loss: 0.8158
Batch 60, Loss: 0.8646
Batch 70, Loss: 0.8585
Batch 80, Loss: 0.8007
Batch 90, Loss: 0.8264
Batch 100, Loss: 0.8559
Batch 110, Loss: 0.8680
Batch 120, Loss: 0.8712
Batch 130, Loss: 0.8764
Batch 140, Loss: 0.8568
Batch 150, Loss: 0.8692
Batch 160, Loss: 0.8796
Batch 170, Loss: 0.8352
Batch 180, Loss: 0.8376
Batch 190, Loss: 0.8669
Batch 200, Loss: 0.8267
Batch 210, Loss: 0.8330
Batch 220, Loss: 0.9296
Batch 230, Loss: 0.9173
Batch 240, Loss: 0.9333
Batch 250, Loss: 0.9231
Batch 260, Loss: 0.9079
Batch 270, Loss: 0.8924
Batch 280, Loss: 0.9283
Batch 290, Loss: 0.9314
Batch 300, Loss: 0.9684
Batch 310, Loss: 0.9501
Batch 320, Loss: 0.9203
Batch 330, Loss: 0.9104
Batch 340, Loss: 0.9336
Batch 350, Loss: 0.9568
Batch 360, Loss: 0.8318
Batch 370, Loss: 0.8951
Batch 380, Loss: 0.9252
Batch 390, Loss: 0.9091
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.154268980026245 seconds
Epoch 52 accuracy: 56.48%
Batch 10, Loss: 0.8597
Batch 20, Loss: 0.8167
Batch 30, Loss: 0.8181
Batch 40, Loss: 0.8504
Batch 50, Loss: 0.8335
Batch 60, Loss: 0.8063
Batch 70, Loss: 0.8504
Batch 80, Loss: 0.8048
Batch 90, Loss: 0.8770
Batch 100, Loss: 0.8435
Batch 110, Loss: 0.8721
Batch 120, Loss: 0.8241
Batch 130, Loss: 0.8848
Batch 140, Loss: 0.8286
Batch 150, Loss: 0.9086
Batch 160, Loss: 0.8505
Batch 170, Loss: 0.8595
Batch 180, Loss: 0.8778
Batch 190, Loss: 0.8873
Batch 200, Loss: 0.9215
Batch 210, Loss: 0.9080
Batch 220, Loss: 0.9195
Batch 230, Loss: 0.8648
Batch 240, Loss: 0.9001
Batch 250, Loss: 0.8398
Batch 260, Loss: 0.8574
Batch 270, Loss: 0.9045
Batch 280, Loss: 0.9499
Batch 290, Loss: 0.8847
Batch 300, Loss: 0.9227
Batch 310, Loss: 0.9130
Batch 320, Loss: 0.9049
Batch 330, Loss: 0.9058
Batch 340, Loss: 0.9486
Batch 350, Loss: 0.9140
Batch 360, Loss: 0.8670
Batch 370, Loss: 0.9429
Batch 380, Loss: 0.8911
Batch 390, Loss: 0.9278
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.07515001296997 seconds
Epoch 53 accuracy: 60.15%
Batch 10, Loss: 0.8125
Batch 20, Loss: 0.8127
Batch 30, Loss: 0.8342
Batch 40, Loss: 0.8016
Batch 50, Loss: 0.8112
Batch 60, Loss: 0.8551
Batch 70, Loss: 0.8266
Batch 80, Loss: 0.8223
Batch 90, Loss: 0.8135
Batch 100, Loss: 0.8427
Batch 110, Loss: 0.8450
Batch 120, Loss: 0.8245
Batch 130, Loss: 0.8641
Batch 140, Loss: 0.8643
Batch 150, Loss: 0.8969
Batch 160, Loss: 0.8857
Batch 170, Loss: 0.9066
Batch 180, Loss: 0.9291
Batch 190, Loss: 0.9004
Batch 200, Loss: 0.8745
Batch 210, Loss: 0.8774
Batch 220, Loss: 0.9014
Batch 230, Loss: 0.8644
Batch 240, Loss: 0.8769
Batch 250, Loss: 0.8701
Batch 260, Loss: 0.8794
Batch 270, Loss: 0.8597
Batch 280, Loss: 0.9135
Batch 290, Loss: 0.8709
Batch 300, Loss: 0.9771
Batch 310, Loss: 0.9312
Batch 320, Loss: 0.9569
Batch 330, Loss: 0.9734
Batch 340, Loss: 0.8859
Batch 350, Loss: 0.8908
Batch 360, Loss: 0.9473
Batch 370, Loss: 0.8956
Batch 380, Loss: 0.9240
Batch 390, Loss: 0.8990
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.158822059631348 seconds
Epoch 54 accuracy: 61.51%
Batch 10, Loss: 0.8172
Batch 20, Loss: 0.7602
Batch 30, Loss: 0.8009
Batch 40, Loss: 0.8055
Batch 50, Loss: 0.7864
Batch 60, Loss: 0.8196
Batch 70, Loss: 0.7599
Batch 80, Loss: 0.7808
Batch 90, Loss: 0.8248
Batch 100, Loss: 0.8297
Batch 110, Loss: 0.8779
Batch 120, Loss: 0.8450
Batch 130, Loss: 0.8227
Batch 140, Loss: 0.7808
Batch 150, Loss: 0.8750
Batch 160, Loss: 0.8427
Batch 170, Loss: 0.8700
Batch 180, Loss: 0.8668
Batch 190, Loss: 0.8597
Batch 200, Loss: 0.8644
Batch 210, Loss: 0.8860
Batch 220, Loss: 0.8547
Batch 230, Loss: 0.8530
Batch 240, Loss: 0.8841
Batch 250, Loss: 0.9674
Batch 260, Loss: 0.8993
Batch 270, Loss: 0.9615
Batch 280, Loss: 0.9323
Batch 290, Loss: 0.9411
Batch 300, Loss: 0.9502
Batch 310, Loss: 0.9081
Batch 320, Loss: 0.8740
Batch 330, Loss: 0.9339
Batch 340, Loss: 0.9180
Batch 350, Loss: 0.8995
Batch 360, Loss: 0.9001
Batch 370, Loss: 0.9686
Batch 380, Loss: 0.8920
Batch 390, Loss: 0.8852
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.167025566101074 seconds
Epoch 55 accuracy: 64.34%
Batch 10, Loss: 0.8289
Batch 20, Loss: 0.8043
Batch 30, Loss: 0.7993
Batch 40, Loss: 0.8385
Batch 50, Loss: 0.8232
Batch 60, Loss: 0.8456
Batch 70, Loss: 0.8508
Batch 80, Loss: 0.8029
Batch 90, Loss: 0.8461
Batch 100, Loss: 0.8415
Batch 110, Loss: 0.8171
Batch 120, Loss: 0.8223
Batch 130, Loss: 0.8849
Batch 140, Loss: 0.8148
Batch 150, Loss: 0.9336
Batch 160, Loss: 0.8920
Batch 170, Loss: 0.8786
Batch 180, Loss: 0.8593
Batch 190, Loss: 0.7894
Batch 200, Loss: 0.8443
Batch 210, Loss: 0.8495
Batch 220, Loss: 0.8774
Batch 230, Loss: 0.9170
Batch 240, Loss: 0.8846
Batch 250, Loss: 0.8892
Batch 260, Loss: 0.8698
Batch 270, Loss: 0.8499
Batch 280, Loss: 0.9214
Batch 290, Loss: 0.9112
Batch 300, Loss: 0.8985
Batch 310, Loss: 0.9175
Batch 320, Loss: 0.8935
Batch 330, Loss: 0.9095
Batch 340, Loss: 0.9039
Batch 350, Loss: 0.9015
Batch 360, Loss: 0.9277
Batch 370, Loss: 0.9280
Batch 380, Loss: 0.9508
Batch 390, Loss: 0.8757
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.133397340774536 seconds
Epoch 56 accuracy: 62.13%
Batch 10, Loss: 0.8012
Batch 20, Loss: 0.7748
Batch 30, Loss: 0.7828
Batch 40, Loss: 0.7669
Batch 50, Loss: 0.7704
Batch 60, Loss: 0.7688
Batch 70, Loss: 0.8501
Batch 80, Loss: 0.8459
Batch 90, Loss: 0.8003
Batch 100, Loss: 0.7968
Batch 110, Loss: 0.8196
Batch 120, Loss: 0.8334
Batch 130, Loss: 0.8198
Batch 140, Loss: 0.8305
Batch 150, Loss: 0.8517
Batch 160, Loss: 0.8654
Batch 170, Loss: 0.9152
Batch 180, Loss: 0.8416
Batch 190, Loss: 0.9235
Batch 200, Loss: 0.8365
Batch 210, Loss: 0.8044
Batch 220, Loss: 0.8599
Batch 230, Loss: 0.9113
Batch 240, Loss: 0.9275
Batch 250, Loss: 0.8481
Batch 260, Loss: 0.8900
Batch 270, Loss: 0.9668
Batch 280, Loss: 0.9121
Batch 290, Loss: 0.9072
Batch 300, Loss: 0.9225
Batch 310, Loss: 0.8598
Batch 320, Loss: 0.9179
Batch 330, Loss: 0.8685
Batch 340, Loss: 0.8448
Batch 350, Loss: 0.8999
Batch 360, Loss: 0.8931
Batch 370, Loss: 0.9145
Batch 380, Loss: 0.9100
Batch 390, Loss: 0.9213
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.186878442764282 seconds
Epoch 57 accuracy: 60.98%
Batch 10, Loss: 0.7876
Batch 20, Loss: 0.8145
Batch 30, Loss: 0.8209
Batch 40, Loss: 0.7898
Batch 50, Loss: 0.7787
Batch 60, Loss: 0.8286
Batch 70, Loss: 0.7626
Batch 80, Loss: 0.7690
Batch 90, Loss: 0.7882
Batch 100, Loss: 0.8115
Batch 110, Loss: 0.8411
Batch 120, Loss: 0.7909
Batch 130, Loss: 0.8032
Batch 140, Loss: 0.7744
Batch 150, Loss: 0.8311
Batch 160, Loss: 0.8265
Batch 170, Loss: 0.8431
Batch 180, Loss: 0.8720
Batch 190, Loss: 0.8738
Batch 200, Loss: 0.8314
Batch 210, Loss: 0.8699
Batch 220, Loss: 0.8645
Batch 230, Loss: 0.8907
Batch 240, Loss: 0.8924
Batch 250, Loss: 0.8943
Batch 260, Loss: 0.8665
Batch 270, Loss: 0.8730
Batch 280, Loss: 0.8656
Batch 290, Loss: 0.8571
Batch 300, Loss: 0.9243
Batch 310, Loss: 0.8874
Batch 320, Loss: 0.9035
Batch 330, Loss: 0.8545
Batch 340, Loss: 0.8580
Batch 350, Loss: 0.8967
Batch 360, Loss: 0.8942
Batch 370, Loss: 0.9587
Batch 380, Loss: 0.9310
Batch 390, Loss: 0.8692
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.222798347473145 seconds
Epoch 58 accuracy: 59.62%
Batch 10, Loss: 0.7913
Batch 20, Loss: 0.7700
Batch 30, Loss: 0.8118
Batch 40, Loss: 0.7771
Batch 50, Loss: 0.7743
Batch 60, Loss: 0.7602
Batch 70, Loss: 0.7882
Batch 80, Loss: 0.8156
Batch 90, Loss: 0.8458
Batch 100, Loss: 0.8606
Batch 110, Loss: 0.8223
Batch 120, Loss: 0.7586
Batch 130, Loss: 0.7832
Batch 140, Loss: 0.8632
Batch 150, Loss: 0.7874
Batch 160, Loss: 0.8409
Batch 170, Loss: 0.8039
Batch 180, Loss: 0.8234
Batch 190, Loss: 0.8691
Batch 200, Loss: 0.7974
Batch 210, Loss: 0.8228
Batch 220, Loss: 0.8742
Batch 230, Loss: 0.8203
Batch 240, Loss: 0.8837
Batch 250, Loss: 0.8193
Batch 260, Loss: 0.8930
Batch 270, Loss: 0.9090
Batch 280, Loss: 0.9264
Batch 290, Loss: 0.8926
Batch 300, Loss: 0.8521
Batch 310, Loss: 0.8805
Batch 320, Loss: 0.8685
Batch 330, Loss: 0.9080
Batch 340, Loss: 0.9125
Batch 350, Loss: 0.9452
Batch 360, Loss: 0.8895
Batch 370, Loss: 0.8948
Batch 380, Loss: 0.8614
Batch 390, Loss: 0.8592
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.27702045440674 seconds
Epoch 59 accuracy: 58.15%
Batch 10, Loss: 0.7397
Batch 20, Loss: 0.7696
Batch 30, Loss: 0.7963
Batch 40, Loss: 0.7562
Batch 50, Loss: 0.7405
Batch 60, Loss: 0.7854
Batch 70, Loss: 0.8005
Batch 80, Loss: 0.8266
Batch 90, Loss: 0.8234
Batch 100, Loss: 0.7868
Batch 110, Loss: 0.8340
Batch 120, Loss: 0.7825
Batch 130, Loss: 0.8798
Batch 140, Loss: 0.8401
Batch 150, Loss: 0.8236
Batch 160, Loss: 0.8392
Batch 170, Loss: 0.8394
Batch 180, Loss: 0.8298
Batch 190, Loss: 0.8436
Batch 200, Loss: 0.9206
Batch 210, Loss: 0.8021
Batch 220, Loss: 0.8222
Batch 230, Loss: 0.8547
Batch 240, Loss: 0.8790
Batch 250, Loss: 0.8752
Batch 260, Loss: 0.8382
Batch 270, Loss: 0.8272
Batch 280, Loss: 0.9097
Batch 290, Loss: 0.8689
Batch 300, Loss: 0.8741
Batch 310, Loss: 0.8380
Batch 320, Loss: 0.8585
Batch 330, Loss: 0.8374
Batch 340, Loss: 0.8607
Batch 350, Loss: 0.8297
Batch 360, Loss: 0.8968
Batch 370, Loss: 0.9295
Batch 380, Loss: 0.8715
Batch 390, Loss: 0.9188
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.249924898147583 seconds
Epoch 60 accuracy: 61.25%
Batch 10, Loss: 0.7994
Batch 20, Loss: 0.7264
Batch 30, Loss: 0.7833
Batch 40, Loss: 0.7829
Batch 50, Loss: 0.7707
Batch 60, Loss: 0.7433
Batch 70, Loss: 0.7704
Batch 80, Loss: 0.7683
Batch 90, Loss: 0.7598
Batch 100, Loss: 0.7954
Batch 110, Loss: 0.8195
Batch 120, Loss: 0.8537
Batch 130, Loss: 0.7217
Batch 140, Loss: 0.7797
Batch 150, Loss: 0.7918
Batch 160, Loss: 0.8176
Batch 170, Loss: 0.8350
Batch 180, Loss: 0.8765
Batch 190, Loss: 0.8703
Batch 200, Loss: 0.8181
Batch 210, Loss: 0.8246
Batch 220, Loss: 0.8575
Batch 230, Loss: 0.8096
Batch 240, Loss: 0.8595
Batch 250, Loss: 0.8836
Batch 260, Loss: 0.8380
Batch 270, Loss: 0.8322
Batch 280, Loss: 0.9355
Batch 290, Loss: 0.8222
Batch 300, Loss: 0.8926
Batch 310, Loss: 0.8822
Batch 320, Loss: 0.8740
Batch 330, Loss: 0.9130
Batch 340, Loss: 0.8513
Batch 350, Loss: 0.8918
Batch 360, Loss: 0.8843
Batch 370, Loss: 0.8762
Batch 380, Loss: 0.9376
Batch 390, Loss: 0.8447
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.250819444656372 seconds
Epoch 61 accuracy: 60.99%
Batch 10, Loss: 0.7846
Batch 20, Loss: 0.8073
Batch 30, Loss: 0.7678
Batch 40, Loss: 0.7661
Batch 50, Loss: 0.7902
Batch 60, Loss: 0.7638
Batch 70, Loss: 0.7909
Batch 80, Loss: 0.8109
Batch 90, Loss: 0.8338
Batch 100, Loss: 0.8032
Batch 110, Loss: 0.8270
Batch 120, Loss: 0.8657
Batch 130, Loss: 0.8266
Batch 140, Loss: 0.7670
Batch 150, Loss: 0.7851
Batch 160, Loss: 0.8607
Batch 170, Loss: 0.7533
Batch 180, Loss: 0.8141
Batch 190, Loss: 0.8158
Batch 200, Loss: 0.8453
Batch 210, Loss: 0.8259
Batch 220, Loss: 0.8301
Batch 230, Loss: 0.8939
Batch 240, Loss: 0.8798
Batch 250, Loss: 0.8587
Batch 260, Loss: 0.8896
Batch 270, Loss: 0.8647
Batch 280, Loss: 0.8429
Batch 290, Loss: 0.8513
Batch 300, Loss: 0.8757
Batch 310, Loss: 0.8861
Batch 320, Loss: 0.8412
Batch 330, Loss: 0.8463
Batch 340, Loss: 0.8576
Batch 350, Loss: 0.8594
Batch 360, Loss: 0.8438
Batch 370, Loss: 0.8829
Batch 380, Loss: 0.9034
Batch 390, Loss: 0.8630
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.251900911331177 seconds
Epoch 62 accuracy: 62.82%
Batch 10, Loss: 0.7953
Batch 20, Loss: 0.7608
Batch 30, Loss: 0.7017
Batch 40, Loss: 0.7702
Batch 50, Loss: 0.7093
Batch 60, Loss: 0.7698
Batch 70, Loss: 0.7776
Batch 80, Loss: 0.7376
Batch 90, Loss: 0.8096
Batch 100, Loss: 0.7577
Batch 110, Loss: 0.7841
Batch 120, Loss: 0.8005
Batch 130, Loss: 0.8220
Batch 140, Loss: 0.8267
Batch 150, Loss: 0.8274
Batch 160, Loss: 0.8196
Batch 170, Loss: 0.8406
Batch 180, Loss: 0.8870
Batch 190, Loss: 0.8299
Batch 200, Loss: 0.8097
Batch 210, Loss: 0.7956
Batch 220, Loss: 0.8201
Batch 230, Loss: 0.8795
Batch 240, Loss: 0.8550
Batch 250, Loss: 0.8512
Batch 260, Loss: 0.8262
Batch 270, Loss: 0.8351
Batch 280, Loss: 0.8200
Batch 290, Loss: 0.8678
Batch 300, Loss: 0.9029
Batch 310, Loss: 0.8571
Batch 320, Loss: 0.8209
Batch 330, Loss: 0.8084
Batch 340, Loss: 0.9100
Batch 350, Loss: 0.8904
Batch 360, Loss: 0.8558
Batch 370, Loss: 0.8378
Batch 380, Loss: 0.8443
Batch 390, Loss: 0.8683
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.178556203842163 seconds
Epoch 63 accuracy: 55.94%
Batch 10, Loss: 0.7075
Batch 20, Loss: 0.7549
Batch 30, Loss: 0.7700
Batch 40, Loss: 0.7225
Batch 50, Loss: 0.7441
Batch 60, Loss: 0.7851
Batch 70, Loss: 0.7697
Batch 80, Loss: 0.8073
Batch 90, Loss: 0.8343
Batch 100, Loss: 0.8634
Batch 110, Loss: 0.7785
Batch 120, Loss: 0.8339
Batch 130, Loss: 0.7780
Batch 140, Loss: 0.7896
Batch 150, Loss: 0.7800
Batch 160, Loss: 0.8349
Batch 170, Loss: 0.7619
Batch 180, Loss: 0.8268
Batch 190, Loss: 0.7950
Batch 200, Loss: 0.8198
Batch 210, Loss: 0.8321
Batch 220, Loss: 0.8402
Batch 230, Loss: 0.8083
Batch 240, Loss: 0.8286
Batch 250, Loss: 0.7760
Batch 260, Loss: 0.8291
Batch 270, Loss: 0.8167
Batch 280, Loss: 0.9025
Batch 290, Loss: 0.8533
Batch 300, Loss: 0.8932
Batch 310, Loss: 0.8529
Batch 320, Loss: 0.8361
Batch 330, Loss: 0.8730
Batch 340, Loss: 0.8499
Batch 350, Loss: 0.8489
Batch 360, Loss: 0.8637
Batch 370, Loss: 0.8613
Batch 380, Loss: 0.9075
Batch 390, Loss: 0.7550
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.097652673721313 seconds
Epoch 64 accuracy: 65.64%
Batch 10, Loss: 0.7309
Batch 20, Loss: 0.7630
Batch 30, Loss: 0.7325
Batch 40, Loss: 0.6901
Batch 50, Loss: 0.7789
Batch 60, Loss: 0.7558
Batch 70, Loss: 0.7592
Batch 80, Loss: 0.7558
Batch 90, Loss: 0.7323
Batch 100, Loss: 0.7327
Batch 110, Loss: 0.7494
Batch 120, Loss: 0.8144
Batch 130, Loss: 0.7595
Batch 140, Loss: 0.8254
Batch 150, Loss: 0.7879
Batch 160, Loss: 0.8273
Batch 170, Loss: 0.8337
Batch 180, Loss: 0.7867
Batch 190, Loss: 0.7836
Batch 200, Loss: 0.8263
Batch 210, Loss: 0.8367
Batch 220, Loss: 0.8287
Batch 230, Loss: 0.8413
Batch 240, Loss: 0.8810
Batch 250, Loss: 0.9371
Batch 260, Loss: 0.8394
Batch 270, Loss: 0.8061
Batch 280, Loss: 0.8347
Batch 290, Loss: 0.8135
Batch 300, Loss: 0.8542
Batch 310, Loss: 0.8154
Batch 320, Loss: 0.8623
Batch 330, Loss: 0.8590
Batch 340, Loss: 0.8192
Batch 350, Loss: 0.7967
Batch 360, Loss: 0.8424
Batch 370, Loss: 0.8353
Batch 380, Loss: 0.9127
Batch 390, Loss: 0.8250
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.275306463241577 seconds
Epoch 65 accuracy: 59.91%
Batch 10, Loss: 0.7540
Batch 20, Loss: 0.7174
Batch 30, Loss: 0.7261
Batch 40, Loss: 0.7726
Batch 50, Loss: 0.7573
Batch 60, Loss: 0.7432
Batch 70, Loss: 0.8091
Batch 80, Loss: 0.7407
Batch 90, Loss: 0.7280
Batch 100, Loss: 0.7813
Batch 110, Loss: 0.7445
Batch 120, Loss: 0.7783
Batch 130, Loss: 0.7660
Batch 140, Loss: 0.7899
Batch 150, Loss: 0.7955
Batch 160, Loss: 0.7898
Batch 170, Loss: 0.7983
Batch 180, Loss: 0.7876
Batch 190, Loss: 0.8131
Batch 200, Loss: 0.8273
Batch 210, Loss: 0.8481
Batch 220, Loss: 0.8617
Batch 230, Loss: 0.8513
Batch 240, Loss: 0.8564
Batch 250, Loss: 0.8914
Batch 260, Loss: 0.8379
Batch 270, Loss: 0.8677
Batch 280, Loss: 0.8071
Batch 290, Loss: 0.8349
Batch 300, Loss: 0.8470
Batch 310, Loss: 0.8554
Batch 320, Loss: 0.8588
Batch 330, Loss: 0.8764
Batch 340, Loss: 0.8822
Batch 350, Loss: 0.8777
Batch 360, Loss: 0.8468
Batch 370, Loss: 0.8412
Batch 380, Loss: 0.8385
Batch 390, Loss: 0.9240
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.183485746383667 seconds
Epoch 66 accuracy: 62.23%
Batch 10, Loss: 0.7590
Batch 20, Loss: 0.7067
Batch 30, Loss: 0.7107
Batch 40, Loss: 0.7115
Batch 50, Loss: 0.7420
Batch 60, Loss: 0.7488
Batch 70, Loss: 0.6999
Batch 80, Loss: 0.7636
Batch 90, Loss: 0.7832
Batch 100, Loss: 0.7616
Batch 110, Loss: 0.7788
Batch 120, Loss: 0.7987
Batch 130, Loss: 0.8207
Batch 140, Loss: 0.7717
Batch 150, Loss: 0.8282
Batch 160, Loss: 0.7849
Batch 170, Loss: 0.7788
Batch 180, Loss: 0.7531
Batch 190, Loss: 0.8383
Batch 200, Loss: 0.8474
Batch 210, Loss: 0.8280
Batch 220, Loss: 0.8270
Batch 230, Loss: 0.8100
Batch 240, Loss: 0.8099
Batch 250, Loss: 0.7788
Batch 260, Loss: 0.7942
Batch 270, Loss: 0.8351
Batch 280, Loss: 0.8405
Batch 290, Loss: 0.7912
Batch 300, Loss: 0.7753
Batch 310, Loss: 0.8045
Batch 320, Loss: 0.8306
Batch 330, Loss: 0.8308
Batch 340, Loss: 0.8605
Batch 350, Loss: 0.8163
Batch 360, Loss: 0.8642
Batch 370, Loss: 0.8668
Batch 380, Loss: 0.8543
Batch 390, Loss: 0.8342
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.792913913726807 seconds
Epoch 67 accuracy: 62.2%
Batch 10, Loss: 0.7461
Batch 20, Loss: 0.6936
Batch 30, Loss: 0.7680
Batch 40, Loss: 0.7022
Batch 50, Loss: 0.7265
Batch 60, Loss: 0.7194
Batch 70, Loss: 0.7472
Batch 80, Loss: 0.7351
Batch 90, Loss: 0.7564
Batch 100, Loss: 0.7750
Batch 110, Loss: 0.7534
Batch 120, Loss: 0.7416
Batch 130, Loss: 0.7573
Batch 140, Loss: 0.7786
Batch 150, Loss: 0.7789
Batch 160, Loss: 0.8093
Batch 170, Loss: 0.7894
Batch 180, Loss: 0.7695
Batch 190, Loss: 0.8342
Batch 200, Loss: 0.7716
Batch 210, Loss: 0.8326
Batch 220, Loss: 0.7648
Batch 230, Loss: 0.7803
Batch 240, Loss: 0.8110
Batch 250, Loss: 0.8179
Batch 260, Loss: 0.7953
Batch 270, Loss: 0.7830
Batch 280, Loss: 0.8363
Batch 290, Loss: 0.8551
Batch 300, Loss: 0.8376
Batch 310, Loss: 0.8339
Batch 320, Loss: 0.8671
Batch 330, Loss: 0.7915
Batch 340, Loss: 0.8295
Batch 350, Loss: 0.8298
Batch 360, Loss: 0.8660
Batch 370, Loss: 0.7855
Batch 380, Loss: 0.8151
Batch 390, Loss: 0.8873
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.149261236190796 seconds
Epoch 68 accuracy: 59.78%
Batch 10, Loss: 0.7552
Batch 20, Loss: 0.7191
Batch 30, Loss: 0.7313
Batch 40, Loss: 0.6970
Batch 50, Loss: 0.7192
Batch 60, Loss: 0.7260
Batch 70, Loss: 0.7336
Batch 80, Loss: 0.6880
Batch 90, Loss: 0.7603
Batch 100, Loss: 0.7514
Batch 110, Loss: 0.7775
Batch 120, Loss: 0.7316
Batch 130, Loss: 0.7661
Batch 140, Loss: 0.7768
Batch 150, Loss: 0.8189
Batch 160, Loss: 0.7647
Batch 170, Loss: 0.7528
Batch 180, Loss: 0.7831
Batch 190, Loss: 0.7484
Batch 200, Loss: 0.7527
Batch 210, Loss: 0.8153
Batch 220, Loss: 0.8154
Batch 230, Loss: 0.7852
Batch 240, Loss: 0.7865
Batch 250, Loss: 0.7973
Batch 260, Loss: 0.7831
Batch 270, Loss: 0.8135
Batch 280, Loss: 0.7575
Batch 290, Loss: 0.8034
Batch 300, Loss: 0.7837
Batch 310, Loss: 0.8044
Batch 320, Loss: 0.8280
Batch 330, Loss: 0.8454
Batch 340, Loss: 0.8312
Batch 350, Loss: 0.8956
Batch 360, Loss: 0.8521
Batch 370, Loss: 0.8742
Batch 380, Loss: 0.8629
Batch 390, Loss: 0.9014
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.335544109344482 seconds
Epoch 69 accuracy: 62.24%
Batch 10, Loss: 0.7265
Batch 20, Loss: 0.7320
Batch 30, Loss: 0.6836
Batch 40, Loss: 0.6794
Batch 50, Loss: 0.6793
Batch 60, Loss: 0.6701
Batch 70, Loss: 0.7394
Batch 80, Loss: 0.7486
Batch 90, Loss: 0.7516
Batch 100, Loss: 0.7400
Batch 110, Loss: 0.7525
Batch 120, Loss: 0.7921
Batch 130, Loss: 0.7674
Batch 140, Loss: 0.7478
Batch 150, Loss: 0.7853
Batch 160, Loss: 0.8175
Batch 170, Loss: 0.8080
Batch 180, Loss: 0.7422
Batch 190, Loss: 0.7264
Batch 200, Loss: 0.7741
Batch 210, Loss: 0.7876
Batch 220, Loss: 0.7896
Batch 230, Loss: 0.8155
Batch 240, Loss: 0.8200
Batch 250, Loss: 0.8219
Batch 260, Loss: 0.8299
Batch 270, Loss: 0.8062
Batch 280, Loss: 0.8652
Batch 290, Loss: 0.7680
Batch 300, Loss: 0.8105
Batch 310, Loss: 0.8271
Batch 320, Loss: 0.8243
Batch 330, Loss: 0.8444
Batch 340, Loss: 0.8032
Batch 350, Loss: 0.7956
Batch 360, Loss: 0.7939
Batch 370, Loss: 0.8652
Batch 380, Loss: 0.8272
Batch 390, Loss: 0.8343
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.108038425445557 seconds
Epoch 70 accuracy: 61.54%
Batch 10, Loss: 0.6977
Batch 20, Loss: 0.7273
Batch 30, Loss: 0.7115
Batch 40, Loss: 0.7306
Batch 50, Loss: 0.7064
Batch 60, Loss: 0.7121
Batch 70, Loss: 0.7124
Batch 80, Loss: 0.7576
Batch 90, Loss: 0.7821
Batch 100, Loss: 0.7093
Batch 110, Loss: 0.7710
Batch 120, Loss: 0.7403
Batch 130, Loss: 0.7656
Batch 140, Loss: 0.7551
Batch 150, Loss: 0.7619
Batch 160, Loss: 0.7944
Batch 170, Loss: 0.7681
Batch 180, Loss: 0.7849
Batch 190, Loss: 0.7835
Batch 200, Loss: 0.7862
Batch 210, Loss: 0.7421
Batch 220, Loss: 0.7814
Batch 230, Loss: 0.7760
Batch 240, Loss: 0.8188
Batch 250, Loss: 0.7653
Batch 260, Loss: 0.7936
Batch 270, Loss: 0.8221
Batch 280, Loss: 0.7694
Batch 290, Loss: 0.7803
Batch 300, Loss: 0.8072
Batch 310, Loss: 0.7868
Batch 320, Loss: 0.7832
Batch 330, Loss: 0.8170
Batch 340, Loss: 0.8215
Batch 350, Loss: 0.8187
Batch 360, Loss: 0.8253
Batch 370, Loss: 0.8052
Batch 380, Loss: 0.7973
Batch 390, Loss: 0.7647
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.069827795028687 seconds
Epoch 71 accuracy: 64.38%
Batch 10, Loss: 0.7038
Batch 20, Loss: 0.6760
Batch 30, Loss: 0.6935
Batch 40, Loss: 0.7006
Batch 50, Loss: 0.7470
Batch 60, Loss: 0.6889
Batch 70, Loss: 0.7142
Batch 80, Loss: 0.7275
Batch 90, Loss: 0.7387
Batch 100, Loss: 0.8012
Batch 110, Loss: 0.7260
Batch 120, Loss: 0.7382
Batch 130, Loss: 0.7036
Batch 140, Loss: 0.7617
Batch 150, Loss: 0.7198
Batch 160, Loss: 0.7126
Batch 170, Loss: 0.7834
Batch 180, Loss: 0.7787
Batch 190, Loss: 0.7983
Batch 200, Loss: 0.8314
Batch 210, Loss: 0.7565
Batch 220, Loss: 0.7418
Batch 230, Loss: 0.7602
Batch 240, Loss: 0.7667
Batch 250, Loss: 0.7756
Batch 260, Loss: 0.7543
Batch 270, Loss: 0.8332
Batch 280, Loss: 0.7631
Batch 290, Loss: 0.7676
Batch 300, Loss: 0.7623
Batch 310, Loss: 0.8307
Batch 320, Loss: 0.8536
Batch 330, Loss: 0.8292
Batch 340, Loss: 0.8073
Batch 350, Loss: 0.7714
Batch 360, Loss: 0.7971
Batch 370, Loss: 0.8181
Batch 380, Loss: 0.8324
Batch 390, Loss: 0.7634
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.1535222530365 seconds
Epoch 72 accuracy: 65.02%
Batch 10, Loss: 0.6716
Batch 20, Loss: 0.6836
Batch 30, Loss: 0.6904
Batch 40, Loss: 0.7019
Batch 50, Loss: 0.6212
Batch 60, Loss: 0.6753
Batch 70, Loss: 0.6994
Batch 80, Loss: 0.7298
Batch 90, Loss: 0.7513
Batch 100, Loss: 0.7173
Batch 110, Loss: 0.7093
Batch 120, Loss: 0.6909
Batch 130, Loss: 0.6936
Batch 140, Loss: 0.7483
Batch 150, Loss: 0.7288
Batch 160, Loss: 0.7505
Batch 170, Loss: 0.7841
Batch 180, Loss: 0.7407
Batch 190, Loss: 0.8077
Batch 200, Loss: 0.7929
Batch 210, Loss: 0.7469
Batch 220, Loss: 0.7684
Batch 230, Loss: 0.7987
Batch 240, Loss: 0.8028
Batch 250, Loss: 0.8402
Batch 260, Loss: 0.7702
Batch 270, Loss: 0.7909
Batch 280, Loss: 0.8062
Batch 290, Loss: 0.7607
Batch 300, Loss: 0.8131
Batch 310, Loss: 0.8191
Batch 320, Loss: 0.8213
Batch 330, Loss: 0.7994
Batch 340, Loss: 0.7716
Batch 350, Loss: 0.7789
Batch 360, Loss: 0.8093
Batch 370, Loss: 0.8319
Batch 380, Loss: 0.8294
Batch 390, Loss: 0.7872
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.0930073261261 seconds
Epoch 73 accuracy: 62.58%
Batch 10, Loss: 0.6838
Batch 20, Loss: 0.7159
Batch 30, Loss: 0.6719
Batch 40, Loss: 0.6625
Batch 50, Loss: 0.6626
Batch 60, Loss: 0.6888
Batch 70, Loss: 0.6874
Batch 80, Loss: 0.6821
Batch 90, Loss: 0.6701
Batch 100, Loss: 0.7161
Batch 110, Loss: 0.7740
Batch 120, Loss: 0.7221
Batch 130, Loss: 0.7059
Batch 140, Loss: 0.7405
Batch 150, Loss: 0.8028
Batch 160, Loss: 0.7953
Batch 170, Loss: 0.7058
Batch 180, Loss: 0.7724
Batch 190, Loss: 0.7951
Batch 200, Loss: 0.7897
Batch 210, Loss: 0.7767
Batch 220, Loss: 0.7699
Batch 230, Loss: 0.7921
Batch 240, Loss: 0.7652
Batch 250, Loss: 0.6982
Batch 260, Loss: 0.7830
Batch 270, Loss: 0.7646
Batch 280, Loss: 0.7636
Batch 290, Loss: 0.7545
Batch 300, Loss: 0.7630
Batch 310, Loss: 0.7542
Batch 320, Loss: 0.7263
Batch 330, Loss: 0.7729
Batch 340, Loss: 0.8322
Batch 350, Loss: 0.8025
Batch 360, Loss: 0.8233
Batch 370, Loss: 0.8224
Batch 380, Loss: 0.7930
Batch 390, Loss: 0.7579
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.09000587463379 seconds
Epoch 74 accuracy: 62.01%
Batch 10, Loss: 0.6813
Batch 20, Loss: 0.6934
Batch 30, Loss: 0.7113
Batch 40, Loss: 0.6634
Batch 50, Loss: 0.6976
Batch 60, Loss: 0.6109
Batch 70, Loss: 0.6939
Batch 80, Loss: 0.7042
Batch 90, Loss: 0.7006
Batch 100, Loss: 0.7259
Batch 110, Loss: 0.6926
Batch 120, Loss: 0.7785
Batch 130, Loss: 0.7344
Batch 140, Loss: 0.7115
Batch 150, Loss: 0.7145
Batch 160, Loss: 0.7596
Batch 170, Loss: 0.7240
Batch 180, Loss: 0.7464
Batch 190, Loss: 0.7263
Batch 200, Loss: 0.7808
Batch 210, Loss: 0.7833
Batch 220, Loss: 0.7712
Batch 230, Loss: 0.7478
Batch 240, Loss: 0.7428
Batch 250, Loss: 0.7339
Batch 260, Loss: 0.7823
Batch 270, Loss: 0.8249
Batch 280, Loss: 0.7747
Batch 290, Loss: 0.7906
Batch 300, Loss: 0.8393
Batch 310, Loss: 0.8093
Batch 320, Loss: 0.7491
Batch 330, Loss: 0.7778
Batch 340, Loss: 0.8342
Batch 350, Loss: 0.7989
Batch 360, Loss: 0.8145
Batch 370, Loss: 0.8572
Batch 380, Loss: 0.7725
Batch 390, Loss: 0.7817
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.044265031814575 seconds
Epoch 75 accuracy: 62.08%
Batch 10, Loss: 0.7231
Batch 20, Loss: 0.6450
Batch 30, Loss: 0.6344
Batch 40, Loss: 0.6805
Batch 50, Loss: 0.7359
Batch 60, Loss: 0.6369
Batch 70, Loss: 0.6777
Batch 80, Loss: 0.7036
Batch 90, Loss: 0.6769
Batch 100, Loss: 0.6916
Batch 110, Loss: 0.6555
Batch 120, Loss: 0.7690
Batch 130, Loss: 0.6905
Batch 140, Loss: 0.7535
Batch 150, Loss: 0.7405
Batch 160, Loss: 0.6970
Batch 170, Loss: 0.6924
Batch 180, Loss: 0.7628
Batch 190, Loss: 0.7297
Batch 200, Loss: 0.7557
Batch 210, Loss: 0.7561
Batch 220, Loss: 0.7996
Batch 230, Loss: 0.7706
Batch 240, Loss: 0.7976
Batch 250, Loss: 0.7671
Batch 260, Loss: 0.7649
Batch 270, Loss: 0.7707
Batch 280, Loss: 0.7651
Batch 290, Loss: 0.7903
Batch 300, Loss: 0.7126
Batch 310, Loss: 0.7555
Batch 320, Loss: 0.7543
Batch 330, Loss: 0.7854
Batch 340, Loss: 0.7702
Batch 350, Loss: 0.8017
Batch 360, Loss: 0.7731
Batch 370, Loss: 0.7595
Batch 380, Loss: 0.8173
Batch 390, Loss: 0.8059
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.13667321205139 seconds
Epoch 76 accuracy: 64.92%
Batch 10, Loss: 0.6491
Batch 20, Loss: 0.6403
Batch 30, Loss: 0.6490
Batch 40, Loss: 0.6486
Batch 50, Loss: 0.6518
Batch 60, Loss: 0.6667
Batch 70, Loss: 0.6619
Batch 80, Loss: 0.7063
Batch 90, Loss: 0.6633
Batch 100, Loss: 0.7115
Batch 110, Loss: 0.7254
Batch 120, Loss: 0.7337
Batch 130, Loss: 0.6857
Batch 140, Loss: 0.7497
Batch 150, Loss: 0.7506
Batch 160, Loss: 0.7324
Batch 170, Loss: 0.7422
Batch 180, Loss: 0.7451
Batch 190, Loss: 0.7374
Batch 200, Loss: 0.7772
Batch 210, Loss: 0.7039
Batch 220, Loss: 0.7809
Batch 230, Loss: 0.7439
Batch 240, Loss: 0.7425
Batch 250, Loss: 0.7479
Batch 260, Loss: 0.7696
Batch 270, Loss: 0.7777
Batch 280, Loss: 0.7840
Batch 290, Loss: 0.7819
Batch 300, Loss: 0.7696
Batch 310, Loss: 0.7780
Batch 320, Loss: 0.7777
Batch 330, Loss: 0.7517
Batch 340, Loss: 0.7647
Batch 350, Loss: 0.8053
Batch 360, Loss: 0.7072
Batch 370, Loss: 0.7938
Batch 380, Loss: 0.7924
Batch 390, Loss: 0.8058
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.176029682159424 seconds
Epoch 77 accuracy: 62.94%
Batch 10, Loss: 0.6821
Batch 20, Loss: 0.7070
Batch 30, Loss: 0.6461
Batch 40, Loss: 0.6535
Batch 50, Loss: 0.6505
Batch 60, Loss: 0.6915
Batch 70, Loss: 0.7435
Batch 80, Loss: 0.6974
Batch 90, Loss: 0.6884
Batch 100, Loss: 0.6570
Batch 110, Loss: 0.6927
Batch 120, Loss: 0.6609
Batch 130, Loss: 0.7100
Batch 140, Loss: 0.7045
Batch 150, Loss: 0.7160
Batch 160, Loss: 0.7353
Batch 170, Loss: 0.7217
Batch 180, Loss: 0.7603
Batch 190, Loss: 0.7727
Batch 200, Loss: 0.7592
Batch 210, Loss: 0.6966
Batch 220, Loss: 0.7126
Batch 230, Loss: 0.7679
Batch 240, Loss: 0.7210
Batch 250, Loss: 0.7659
Batch 260, Loss: 0.7405
Batch 270, Loss: 0.7736
Batch 280, Loss: 0.7316
Batch 290, Loss: 0.7668
Batch 300, Loss: 0.7560
Batch 310, Loss: 0.7370
Batch 320, Loss: 0.7654
Batch 330, Loss: 0.7638
Batch 340, Loss: 0.8027
Batch 350, Loss: 0.7628
Batch 360, Loss: 0.7270
Batch 370, Loss: 0.8061
Batch 380, Loss: 0.7734
Batch 390, Loss: 0.7538
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.187482118606567 seconds
Epoch 78 accuracy: 64.32%
Batch 10, Loss: 0.6867
Batch 20, Loss: 0.6119
Batch 30, Loss: 0.6255
Batch 40, Loss: 0.6738
Batch 50, Loss: 0.6440
Batch 60, Loss: 0.6542
Batch 70, Loss: 0.6538
Batch 80, Loss: 0.6898
Batch 90, Loss: 0.7092
Batch 100, Loss: 0.6856
Batch 110, Loss: 0.6654
Batch 120, Loss: 0.7206
Batch 130, Loss: 0.6962
Batch 140, Loss: 0.6615
Batch 150, Loss: 0.6977
Batch 160, Loss: 0.7498
Batch 170, Loss: 0.7275
Batch 180, Loss: 0.7376
Batch 190, Loss: 0.6949
Batch 200, Loss: 0.7705
Batch 210, Loss: 0.6968
Batch 220, Loss: 0.7078
Batch 230, Loss: 0.7436
Batch 240, Loss: 0.6964
Batch 250, Loss: 0.7245
Batch 260, Loss: 0.7067
Batch 270, Loss: 0.7250
Batch 280, Loss: 0.7221
Batch 290, Loss: 0.7927
Batch 300, Loss: 0.7810
Batch 310, Loss: 0.7665
Batch 320, Loss: 0.7636
Batch 330, Loss: 0.7799
Batch 340, Loss: 0.7876
Batch 350, Loss: 0.7957
Batch 360, Loss: 0.8243
Batch 370, Loss: 0.8172
Batch 380, Loss: 0.8156
Batch 390, Loss: 0.8736
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.2667875289917 seconds
Epoch 79 accuracy: 62.45%
Batch 10, Loss: 0.6811
Batch 20, Loss: 0.6573
Batch 30, Loss: 0.6580
Batch 40, Loss: 0.6558
Batch 50, Loss: 0.6813
Batch 60, Loss: 0.6775
Batch 70, Loss: 0.6450
Batch 80, Loss: 0.6414
Batch 90, Loss: 0.7097
Batch 100, Loss: 0.6655
Batch 110, Loss: 0.6833
Batch 120, Loss: 0.6763
Batch 130, Loss: 0.6871
Batch 140, Loss: 0.6960
Batch 150, Loss: 0.6277
Batch 160, Loss: 0.7127
Batch 170, Loss: 0.6760
Batch 180, Loss: 0.6946
Batch 190, Loss: 0.6937
Batch 200, Loss: 0.6990
Batch 210, Loss: 0.6893
Batch 220, Loss: 0.7241
Batch 230, Loss: 0.7105
Batch 240, Loss: 0.7196
Batch 250, Loss: 0.7214
Batch 260, Loss: 0.7313
Batch 270, Loss: 0.6734
Batch 280, Loss: 0.7363
Batch 290, Loss: 0.7629
Batch 300, Loss: 0.7058
Batch 310, Loss: 0.7341
Batch 320, Loss: 0.7536
Batch 330, Loss: 0.7878
Batch 340, Loss: 0.7588
Batch 350, Loss: 0.7269
Batch 360, Loss: 0.7981
Batch 370, Loss: 0.8071
Batch 380, Loss: 0.8405
Batch 390, Loss: 0.7948
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.220502376556396 seconds
Epoch 80 accuracy: 61.63%
Batch 10, Loss: 0.6711
Batch 20, Loss: 0.6490
Batch 30, Loss: 0.6386
Batch 40, Loss: 0.6305
Batch 50, Loss: 0.6041
Batch 60, Loss: 0.6396
Batch 70, Loss: 0.6438
Batch 80, Loss: 0.6787
Batch 90, Loss: 0.6532
Batch 100, Loss: 0.6551
Batch 110, Loss: 0.7096
Batch 120, Loss: 0.6964
Batch 130, Loss: 0.6897
Batch 140, Loss: 0.6839
Batch 150, Loss: 0.7140
Batch 160, Loss: 0.7300
Batch 170, Loss: 0.7097
Batch 180, Loss: 0.6913
Batch 190, Loss: 0.7182
Batch 200, Loss: 0.7600
Batch 210, Loss: 0.7002
Batch 220, Loss: 0.7313
Batch 230, Loss: 0.7144
Batch 240, Loss: 0.7203
Batch 250, Loss: 0.7381
Batch 260, Loss: 0.7370
Batch 270, Loss: 0.7224
Batch 280, Loss: 0.7272
Batch 290, Loss: 0.7160
Batch 300, Loss: 0.7376
Batch 310, Loss: 0.7494
Batch 320, Loss: 0.7331
Batch 330, Loss: 0.7677
Batch 340, Loss: 0.7658
Batch 350, Loss: 0.7880
Batch 360, Loss: 0.7688
Batch 370, Loss: 0.7626
Batch 380, Loss: 0.7609
Batch 390, Loss: 0.7878
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.23342776298523 seconds
Epoch 81 accuracy: 61.24%
Batch 10, Loss: 0.6569
Batch 20, Loss: 0.5865
Batch 30, Loss: 0.6593
Batch 40, Loss: 0.6379
Batch 50, Loss: 0.6204
Batch 60, Loss: 0.6659
Batch 70, Loss: 0.6716
Batch 80, Loss: 0.6939
Batch 90, Loss: 0.6607
Batch 100, Loss: 0.6758
Batch 110, Loss: 0.6720
Batch 120, Loss: 0.6346
Batch 130, Loss: 0.6506
Batch 140, Loss: 0.6779
Batch 150, Loss: 0.6935
Batch 160, Loss: 0.6699
Batch 170, Loss: 0.6881
Batch 180, Loss: 0.6989
Batch 190, Loss: 0.6932
Batch 200, Loss: 0.7353
Batch 210, Loss: 0.7352
Batch 220, Loss: 0.6516
Batch 230, Loss: 0.6533
Batch 240, Loss: 0.6890
Batch 250, Loss: 0.7142
Batch 260, Loss: 0.6972
Batch 270, Loss: 0.7208
Batch 280, Loss: 0.7626
Batch 290, Loss: 0.7277
Batch 300, Loss: 0.7097
Batch 310, Loss: 0.7523
Batch 320, Loss: 0.6953
Batch 330, Loss: 0.7417
Batch 340, Loss: 0.7596
Batch 350, Loss: 0.7339
Batch 360, Loss: 0.7177
Batch 370, Loss: 0.7613
Batch 380, Loss: 0.7836
Batch 390, Loss: 0.7635
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.21304416656494 seconds
Epoch 82 accuracy: 64.61%
Batch 10, Loss: 0.6436
Batch 20, Loss: 0.6550
Batch 30, Loss: 0.6174
Batch 40, Loss: 0.6238
Batch 50, Loss: 0.6374
Batch 60, Loss: 0.6237
Batch 70, Loss: 0.6762
Batch 80, Loss: 0.6700
Batch 90, Loss: 0.6776
Batch 100, Loss: 0.6641
Batch 110, Loss: 0.6192
Batch 120, Loss: 0.6384
Batch 130, Loss: 0.6474
Batch 140, Loss: 0.6942
Batch 150, Loss: 0.6775
Batch 160, Loss: 0.6719
Batch 170, Loss: 0.6636
Batch 180, Loss: 0.6957
Batch 190, Loss: 0.6369
Batch 200, Loss: 0.6807
Batch 210, Loss: 0.7017
Batch 220, Loss: 0.7104
Batch 230, Loss: 0.6613
Batch 240, Loss: 0.7012
Batch 250, Loss: 0.7083
Batch 260, Loss: 0.7216
Batch 270, Loss: 0.7325
Batch 280, Loss: 0.7162
Batch 290, Loss: 0.7356
Batch 300, Loss: 0.7675
Batch 310, Loss: 0.7450
Batch 320, Loss: 0.7824
Batch 330, Loss: 0.7348
Batch 340, Loss: 0.7064
Batch 350, Loss: 0.7072
Batch 360, Loss: 0.7583
Batch 370, Loss: 0.7475
Batch 380, Loss: 0.7871
Batch 390, Loss: 0.6962
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.213703870773315 seconds
Epoch 83 accuracy: 64.17%
Batch 10, Loss: 0.6538
Batch 20, Loss: 0.6322
Batch 30, Loss: 0.6329
Batch 40, Loss: 0.5911
Batch 50, Loss: 0.6518
Batch 60, Loss: 0.6522
Batch 70, Loss: 0.6523
Batch 80, Loss: 0.6472
Batch 90, Loss: 0.6336
Batch 100, Loss: 0.5992
Batch 110, Loss: 0.7082
Batch 120, Loss: 0.6336
Batch 130, Loss: 0.7054
Batch 140, Loss: 0.6273
Batch 150, Loss: 0.6706
Batch 160, Loss: 0.6802
Batch 170, Loss: 0.7060
Batch 180, Loss: 0.6656
Batch 190, Loss: 0.7296
Batch 200, Loss: 0.7258
Batch 210, Loss: 0.6737
Batch 220, Loss: 0.6876
Batch 230, Loss: 0.6635
Batch 240, Loss: 0.7012
Batch 250, Loss: 0.7019
Batch 260, Loss: 0.7528
Batch 270, Loss: 0.7363
Batch 280, Loss: 0.7090
Batch 290, Loss: 0.7359
Batch 300, Loss: 0.7311
Batch 310, Loss: 0.7175
Batch 320, Loss: 0.7018
Batch 330, Loss: 0.7347
Batch 340, Loss: 0.7830
Batch 350, Loss: 0.7278
Batch 360, Loss: 0.7391
Batch 370, Loss: 0.7222
Batch 380, Loss: 0.7327
Batch 390, Loss: 0.7559
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.154927253723145 seconds
Epoch 84 accuracy: 65.55%
Batch 10, Loss: 0.6184
Batch 20, Loss: 0.6152
Batch 30, Loss: 0.6022
Batch 40, Loss: 0.5765
Batch 50, Loss: 0.6270
Batch 60, Loss: 0.6312
Batch 70, Loss: 0.6169
Batch 80, Loss: 0.6291
Batch 90, Loss: 0.6545
Batch 100, Loss: 0.6444
Batch 110, Loss: 0.6144
Batch 120, Loss: 0.6216
Batch 130, Loss: 0.6187
Batch 140, Loss: 0.6323
Batch 150, Loss: 0.6530
Batch 160, Loss: 0.6535
Batch 170, Loss: 0.6491
Batch 180, Loss: 0.6750
Batch 190, Loss: 0.6790
Batch 200, Loss: 0.7127
Batch 210, Loss: 0.6656
Batch 220, Loss: 0.6976
Batch 230, Loss: 0.6876
Batch 240, Loss: 0.6906
Batch 250, Loss: 0.7587
Batch 260, Loss: 0.7334
Batch 270, Loss: 0.6737
Batch 280, Loss: 0.6703
Batch 290, Loss: 0.6651
Batch 300, Loss: 0.7010
Batch 310, Loss: 0.7077
Batch 320, Loss: 0.7150
Batch 330, Loss: 0.7387
Batch 340, Loss: 0.6994
Batch 350, Loss: 0.7518
Batch 360, Loss: 0.7250
Batch 370, Loss: 0.7504
Batch 380, Loss: 0.7544
Batch 390, Loss: 0.7235
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.202509880065918 seconds
Epoch 85 accuracy: 64.41%
Batch 10, Loss: 0.5815
Batch 20, Loss: 0.6241
Batch 30, Loss: 0.6540
Batch 40, Loss: 0.6083
Batch 50, Loss: 0.5990
Batch 60, Loss: 0.5698
Batch 70, Loss: 0.5852
Batch 80, Loss: 0.6182
Batch 90, Loss: 0.6120
Batch 100, Loss: 0.5920
Batch 110, Loss: 0.5691
Batch 120, Loss: 0.6328
Batch 130, Loss: 0.6429
Batch 140, Loss: 0.6196
Batch 150, Loss: 0.6298
Batch 160, Loss: 0.6227
Batch 170, Loss: 0.6845
Batch 180, Loss: 0.6207
Batch 190, Loss: 0.6745
Batch 200, Loss: 0.6868
Batch 210, Loss: 0.6683
Batch 220, Loss: 0.7063
Batch 230, Loss: 0.7120
Batch 240, Loss: 0.6980
Batch 250, Loss: 0.7270
Batch 260, Loss: 0.7190
Batch 270, Loss: 0.6887
Batch 280, Loss: 0.7021
Batch 290, Loss: 0.7250
Batch 300, Loss: 0.7249
Batch 310, Loss: 0.7133
Batch 320, Loss: 0.7110
Batch 330, Loss: 0.7513
Batch 340, Loss: 0.7022
Batch 350, Loss: 0.6999
Batch 360, Loss: 0.7089
Batch 370, Loss: 0.6754
Batch 380, Loss: 0.7185
Batch 390, Loss: 0.6798
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.240405797958374 seconds
Epoch 86 accuracy: 64.96%
Batch 10, Loss: 0.6157
Batch 20, Loss: 0.6398
Batch 30, Loss: 0.5915
Batch 40, Loss: 0.5828
Batch 50, Loss: 0.6219
Batch 60, Loss: 0.6178
Batch 70, Loss: 0.5987
Batch 80, Loss: 0.6519
Batch 90, Loss: 0.6100
Batch 100, Loss: 0.6333
Batch 110, Loss: 0.6481
Batch 120, Loss: 0.6169
Batch 130, Loss: 0.6403
Batch 140, Loss: 0.6393
Batch 150, Loss: 0.6683
Batch 160, Loss: 0.6700
Batch 170, Loss: 0.6821
Batch 180, Loss: 0.6256
Batch 190, Loss: 0.6940
Batch 200, Loss: 0.6931
Batch 210, Loss: 0.6476
Batch 220, Loss: 0.6612
Batch 230, Loss: 0.6792
Batch 240, Loss: 0.6836
Batch 250, Loss: 0.6895
Batch 260, Loss: 0.6867
Batch 270, Loss: 0.6764
Batch 280, Loss: 0.7117
Batch 290, Loss: 0.6977
Batch 300, Loss: 0.6887
Batch 310, Loss: 0.6936
Batch 320, Loss: 0.6625
Batch 330, Loss: 0.7327
Batch 340, Loss: 0.6900
Batch 350, Loss: 0.6779
Batch 360, Loss: 0.6582
Batch 370, Loss: 0.6784
Batch 380, Loss: 0.6613
Batch 390, Loss: 0.6670
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.334653615951538 seconds
Epoch 87 accuracy: 65.56%
Batch 10, Loss: 0.6252
Batch 20, Loss: 0.6453
Batch 30, Loss: 0.5718
Batch 40, Loss: 0.6286
Batch 50, Loss: 0.6002
Batch 60, Loss: 0.5803
Batch 70, Loss: 0.5925
Batch 80, Loss: 0.5760
Batch 90, Loss: 0.6226
Batch 100, Loss: 0.5858
Batch 110, Loss: 0.6229
Batch 120, Loss: 0.6015
Batch 130, Loss: 0.7070
Batch 140, Loss: 0.6240
Batch 150, Loss: 0.6416
Batch 160, Loss: 0.6771
Batch 170, Loss: 0.6519
Batch 180, Loss: 0.6485
Batch 190, Loss: 0.6614
Batch 200, Loss: 0.6935
Batch 210, Loss: 0.6562
Batch 220, Loss: 0.6387
Batch 230, Loss: 0.6488
Batch 240, Loss: 0.6575
Batch 250, Loss: 0.6993
Batch 260, Loss: 0.6947
Batch 270, Loss: 0.6342
Batch 280, Loss: 0.7043
Batch 290, Loss: 0.6729
Batch 300, Loss: 0.7032
Batch 310, Loss: 0.6674
Batch 320, Loss: 0.7239
Batch 330, Loss: 0.6823
Batch 340, Loss: 0.6510
Batch 350, Loss: 0.7020
Batch 360, Loss: 0.7862
Batch 370, Loss: 0.7234
Batch 380, Loss: 0.6935
Batch 390, Loss: 0.7505
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.321744441986084 seconds
Epoch 88 accuracy: 63.47%
Batch 10, Loss: 0.6325
Batch 20, Loss: 0.5872
Batch 30, Loss: 0.6086
Batch 40, Loss: 0.5964
Batch 50, Loss: 0.5597
Batch 60, Loss: 0.5862
Batch 70, Loss: 0.6123
Batch 80, Loss: 0.5795
Batch 90, Loss: 0.6231
Batch 100, Loss: 0.6151
Batch 110, Loss: 0.6222
Batch 120, Loss: 0.6049
Batch 130, Loss: 0.6151
Batch 140, Loss: 0.6025
Batch 150, Loss: 0.6378
Batch 160, Loss: 0.6466
Batch 170, Loss: 0.6158
Batch 180, Loss: 0.6444
Batch 190, Loss: 0.6717
Batch 200, Loss: 0.6552
Batch 210, Loss: 0.6133
Batch 220, Loss: 0.6192
Batch 230, Loss: 0.6656
Batch 240, Loss: 0.6980
Batch 250, Loss: 0.7142
Batch 260, Loss: 0.6753
Batch 270, Loss: 0.7023
Batch 280, Loss: 0.6782
Batch 290, Loss: 0.6549
Batch 300, Loss: 0.6990
Batch 310, Loss: 0.7058
Batch 320, Loss: 0.6997
Batch 330, Loss: 0.6729
Batch 340, Loss: 0.6656
Batch 350, Loss: 0.6975
Batch 360, Loss: 0.7014
Batch 370, Loss: 0.7111
Batch 380, Loss: 0.7283
Batch 390, Loss: 0.7172
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.134662866592407 seconds
Epoch 89 accuracy: 64.99%
Batch 10, Loss: 0.5863
Batch 20, Loss: 0.5796
Batch 30, Loss: 0.5878
Batch 40, Loss: 0.5741
Batch 50, Loss: 0.5887
Batch 60, Loss: 0.5810
Batch 70, Loss: 0.5779
Batch 80, Loss: 0.6024
Batch 90, Loss: 0.5982
Batch 100, Loss: 0.5923
Batch 110, Loss: 0.5845
Batch 120, Loss: 0.5878
Batch 130, Loss: 0.6217
Batch 140, Loss: 0.5863
Batch 150, Loss: 0.6470
Batch 160, Loss: 0.6200
Batch 170, Loss: 0.6565
Batch 180, Loss: 0.6709
Batch 190, Loss: 0.7137
Batch 200, Loss: 0.6131
Batch 210, Loss: 0.6184
Batch 220, Loss: 0.6891
Batch 230, Loss: 0.6505
Batch 240, Loss: 0.6687
Batch 250, Loss: 0.6390
Batch 260, Loss: 0.6507
Batch 270, Loss: 0.6980
Batch 280, Loss: 0.6700
Batch 290, Loss: 0.6364
Batch 300, Loss: 0.6734
Batch 310, Loss: 0.6912
Batch 320, Loss: 0.6741
Batch 330, Loss: 0.7125
Batch 340, Loss: 0.6720
Batch 350, Loss: 0.6957
Batch 360, Loss: 0.6734
Batch 370, Loss: 0.6917
Batch 380, Loss: 0.7262
Batch 390, Loss: 0.7011
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.22667694091797 seconds
Epoch 90 accuracy: 67.13%
Batch 10, Loss: 0.5775
Batch 20, Loss: 0.5805
Batch 30, Loss: 0.5459
Batch 40, Loss: 0.5973
Batch 50, Loss: 0.5667
Batch 60, Loss: 0.5634
Batch 70, Loss: 0.6123
Batch 80, Loss: 0.5785
Batch 90, Loss: 0.5975
Batch 100, Loss: 0.5965
Batch 110, Loss: 0.5876
Batch 120, Loss: 0.5661
Batch 130, Loss: 0.6134
Batch 140, Loss: 0.6038
Batch 150, Loss: 0.6177
Batch 160, Loss: 0.6617
Batch 170, Loss: 0.6478
Batch 180, Loss: 0.6312
Batch 190, Loss: 0.6608
Batch 200, Loss: 0.6600
Batch 210, Loss: 0.6245
Batch 220, Loss: 0.6111
Batch 230, Loss: 0.6331
Batch 240, Loss: 0.6846
Batch 250, Loss: 0.6275
Batch 260, Loss: 0.6701
Batch 270, Loss: 0.6275
Batch 280, Loss: 0.6568
Batch 290, Loss: 0.6799
Batch 300, Loss: 0.6274
Batch 310, Loss: 0.6900
Batch 320, Loss: 0.6495
Batch 330, Loss: 0.6782
Batch 340, Loss: 0.7125
Batch 350, Loss: 0.6353
Batch 360, Loss: 0.6909
Batch 370, Loss: 0.7109
Batch 380, Loss: 0.6507
Batch 390, Loss: 0.6464
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.081414222717285 seconds
Epoch 91 accuracy: 65.56%
Batch 10, Loss: 0.5305
Batch 20, Loss: 0.5586
Batch 30, Loss: 0.5476
Batch 40, Loss: 0.5339
Batch 50, Loss: 0.5454
Batch 60, Loss: 0.5985
Batch 70, Loss: 0.5281
Batch 80, Loss: 0.5872
Batch 90, Loss: 0.5571
Batch 100, Loss: 0.6009
Batch 110, Loss: 0.5713
Batch 120, Loss: 0.6356
Batch 130, Loss: 0.6075
Batch 140, Loss: 0.5622
Batch 150, Loss: 0.6069
Batch 160, Loss: 0.5992
Batch 170, Loss: 0.5975
Batch 180, Loss: 0.6398
Batch 190, Loss: 0.6734
Batch 200, Loss: 0.6342
Batch 210, Loss: 0.6445
Batch 220, Loss: 0.6216
Batch 230, Loss: 0.6305
Batch 240, Loss: 0.6053
Batch 250, Loss: 0.6405
Batch 260, Loss: 0.6119
Batch 270, Loss: 0.6321
Batch 280, Loss: 0.6573
Batch 290, Loss: 0.6345
Batch 300, Loss: 0.6455
Batch 310, Loss: 0.7275
Batch 320, Loss: 0.6818
Batch 330, Loss: 0.6667
Batch 340, Loss: 0.6941
Batch 350, Loss: 0.6674
Batch 360, Loss: 0.7134
Batch 370, Loss: 0.6494
Batch 380, Loss: 0.6581
Batch 390, Loss: 0.6864
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.062222957611084 seconds
Epoch 92 accuracy: 63.93%
Batch 10, Loss: 0.6340
Batch 20, Loss: 0.5966
Batch 30, Loss: 0.5519
Batch 40, Loss: 0.5770
Batch 50, Loss: 0.5678
Batch 60, Loss: 0.5839
Batch 70, Loss: 0.5020
Batch 80, Loss: 0.5675
Batch 90, Loss: 0.5407
Batch 100, Loss: 0.5461
Batch 110, Loss: 0.5677
Batch 120, Loss: 0.5273
Batch 130, Loss: 0.5826
Batch 140, Loss: 0.5914
Batch 150, Loss: 0.6380
Batch 160, Loss: 0.5426
Batch 170, Loss: 0.5853
Batch 180, Loss: 0.5877
Batch 190, Loss: 0.6210
Batch 200, Loss: 0.6168
Batch 210, Loss: 0.6167
Batch 220, Loss: 0.6179
Batch 230, Loss: 0.6286
Batch 240, Loss: 0.5974
Batch 250, Loss: 0.5956
Batch 260, Loss: 0.6170
Batch 270, Loss: 0.6444
Batch 280, Loss: 0.6531
Batch 290, Loss: 0.6704
Batch 300, Loss: 0.6994
Batch 310, Loss: 0.6615
Batch 320, Loss: 0.7260
Batch 330, Loss: 0.6990
Batch 340, Loss: 0.6456
Batch 350, Loss: 0.6489
Batch 360, Loss: 0.6967
Batch 370, Loss: 0.6754
Batch 380, Loss: 0.6798
Batch 390, Loss: 0.7025
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.162225484848022 seconds
Epoch 93 accuracy: 65.71%
Batch 10, Loss: 0.5783
Batch 20, Loss: 0.5518
Batch 30, Loss: 0.5476
Batch 40, Loss: 0.5267
Batch 50, Loss: 0.5308
Batch 60, Loss: 0.5660
Batch 70, Loss: 0.5460
Batch 80, Loss: 0.5427
Batch 90, Loss: 0.5394
Batch 100, Loss: 0.5252
Batch 110, Loss: 0.6029
Batch 120, Loss: 0.5537
Batch 130, Loss: 0.5901
Batch 140, Loss: 0.5925
Batch 150, Loss: 0.6354
Batch 160, Loss: 0.6085
Batch 170, Loss: 0.6339
Batch 180, Loss: 0.6401
Batch 190, Loss: 0.6169
Batch 200, Loss: 0.6057
Batch 210, Loss: 0.6289
Batch 220, Loss: 0.6084
Batch 230, Loss: 0.6349
Batch 240, Loss: 0.6113
Batch 250, Loss: 0.6437
Batch 260, Loss: 0.6111
Batch 270, Loss: 0.6247
Batch 280, Loss: 0.6376
Batch 290, Loss: 0.6229
Batch 300, Loss: 0.6613
Batch 310, Loss: 0.6503
Batch 320, Loss: 0.6427
Batch 330, Loss: 0.6545
Batch 340, Loss: 0.6475
Batch 350, Loss: 0.6612
Batch 360, Loss: 0.6320
Batch 370, Loss: 0.6664
Batch 380, Loss: 0.6713
Batch 390, Loss: 0.6536
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.148188829421997 seconds
Epoch 94 accuracy: 66.17%
Batch 10, Loss: 0.5548
Batch 20, Loss: 0.5946
Batch 30, Loss: 0.5475
Batch 40, Loss: 0.5656
Batch 50, Loss: 0.5746
Batch 60, Loss: 0.4901
Batch 70, Loss: 0.5573
Batch 80, Loss: 0.5770
Batch 90, Loss: 0.5600
Batch 100, Loss: 0.5475
Batch 110, Loss: 0.5657
Batch 120, Loss: 0.5567
Batch 130, Loss: 0.6026
Batch 140, Loss: 0.5792
Batch 150, Loss: 0.6015
Batch 160, Loss: 0.5609
Batch 170, Loss: 0.5559
Batch 180, Loss: 0.5671
Batch 190, Loss: 0.5926
Batch 200, Loss: 0.6160
Batch 210, Loss: 0.5892
Batch 220, Loss: 0.6116
Batch 230, Loss: 0.6206
Batch 240, Loss: 0.5970
Batch 250, Loss: 0.6192
Batch 260, Loss: 0.6245
Batch 270, Loss: 0.6350
Batch 280, Loss: 0.6677
Batch 290, Loss: 0.6232
Batch 300, Loss: 0.6483
Batch 310, Loss: 0.6828
Batch 320, Loss: 0.6420
Batch 330, Loss: 0.6497
Batch 340, Loss: 0.6341
Batch 350, Loss: 0.6693
Batch 360, Loss: 0.6684
Batch 370, Loss: 0.6677
Batch 380, Loss: 0.6750
Batch 390, Loss: 0.6222
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.102620601654053 seconds
Epoch 95 accuracy: 62.73%
Batch 10, Loss: 0.5676
Batch 20, Loss: 0.5663
Batch 30, Loss: 0.5210
Batch 40, Loss: 0.5236
Batch 50, Loss: 0.5663
Batch 60, Loss: 0.5157
Batch 70, Loss: 0.5815
Batch 80, Loss: 0.5739
Batch 90, Loss: 0.5422
Batch 100, Loss: 0.5732
Batch 110, Loss: 0.5913
Batch 120, Loss: 0.6018
Batch 130, Loss: 0.5407
Batch 140, Loss: 0.5738
Batch 150, Loss: 0.5638
Batch 160, Loss: 0.5509
Batch 170, Loss: 0.5190
Batch 180, Loss: 0.5792
Batch 190, Loss: 0.5567
Batch 200, Loss: 0.5771
Batch 210, Loss: 0.6016
Batch 220, Loss: 0.5774
Batch 230, Loss: 0.5934
Batch 240, Loss: 0.5929
Batch 250, Loss: 0.6216
Batch 260, Loss: 0.5899
Batch 270, Loss: 0.6255
Batch 280, Loss: 0.5558
Batch 290, Loss: 0.6246
Batch 300, Loss: 0.6230
Batch 310, Loss: 0.6424
Batch 320, Loss: 0.6159
Batch 330, Loss: 0.6499
Batch 340, Loss: 0.6198
Batch 350, Loss: 0.6386
Batch 360, Loss: 0.6800
Batch 370, Loss: 0.6362
Batch 380, Loss: 0.6922
Batch 390, Loss: 0.6348
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.16671085357666 seconds
Epoch 96 accuracy: 62.55%
Batch 10, Loss: 0.5717
Batch 20, Loss: 0.5415
Batch 30, Loss: 0.5342
Batch 40, Loss: 0.5039
Batch 50, Loss: 0.5203
Batch 60, Loss: 0.5061
Batch 70, Loss: 0.5100
Batch 80, Loss: 0.5442
Batch 90, Loss: 0.5351
Batch 100, Loss: 0.5315
Batch 110, Loss: 0.5146
Batch 120, Loss: 0.5365
Batch 130, Loss: 0.5521
Batch 140, Loss: 0.5786
Batch 150, Loss: 0.5610
Batch 160, Loss: 0.6257
Batch 170, Loss: 0.6369
Batch 180, Loss: 0.5841
Batch 190, Loss: 0.5670
Batch 200, Loss: 0.5339
Batch 210, Loss: 0.5568
Batch 220, Loss: 0.5816
Batch 230, Loss: 0.5679
Batch 240, Loss: 0.5603
Batch 250, Loss: 0.5724
Batch 260, Loss: 0.5936
Batch 270, Loss: 0.5955
Batch 280, Loss: 0.5959
Batch 290, Loss: 0.6330
Batch 300, Loss: 0.6644
Batch 310, Loss: 0.6118
Batch 320, Loss: 0.6150
Batch 330, Loss: 0.6464
Batch 340, Loss: 0.6491
Batch 350, Loss: 0.6399
Batch 360, Loss: 0.6231
Batch 370, Loss: 0.6545
Batch 380, Loss: 0.6499
Batch 390, Loss: 0.7029
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.283127069473267 seconds
Epoch 97 accuracy: 64.36%
Batch 10, Loss: 0.5391
Batch 20, Loss: 0.5432
Batch 30, Loss: 0.5019
Batch 40, Loss: 0.5120
Batch 50, Loss: 0.5214
Batch 60, Loss: 0.5070
Batch 70, Loss: 0.5388
Batch 80, Loss: 0.5608
Batch 90, Loss: 0.5603
Batch 100, Loss: 0.5617
Batch 110, Loss: 0.5454
Batch 120, Loss: 0.5756
Batch 130, Loss: 0.5430
Batch 140, Loss: 0.5592
Batch 150, Loss: 0.5525
Batch 160, Loss: 0.5593
Batch 170, Loss: 0.5513
Batch 180, Loss: 0.5973
Batch 190, Loss: 0.6126
Batch 200, Loss: 0.5772
Batch 210, Loss: 0.5978
Batch 220, Loss: 0.5779
Batch 230, Loss: 0.5918
Batch 240, Loss: 0.6098
Batch 250, Loss: 0.5812
Batch 260, Loss: 0.5816
Batch 270, Loss: 0.5516
Batch 280, Loss: 0.6242
Batch 290, Loss: 0.5841
Batch 300, Loss: 0.6417
Batch 310, Loss: 0.5987
Batch 320, Loss: 0.5878
Batch 330, Loss: 0.6193
Batch 340, Loss: 0.6149
Batch 350, Loss: 0.6489
Batch 360, Loss: 0.6436
Batch 370, Loss: 0.6597
Batch 380, Loss: 0.6083
Batch 390, Loss: 0.6146
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.239710330963135 seconds
Epoch 98 accuracy: 67.38%
Batch 10, Loss: 0.5292
Batch 20, Loss: 0.5083
Batch 30, Loss: 0.4850
Batch 40, Loss: 0.4717
Batch 50, Loss: 0.5329
Batch 60, Loss: 0.5040
Batch 70, Loss: 0.5114
Batch 80, Loss: 0.5377
Batch 90, Loss: 0.5716
Batch 100, Loss: 0.5113
Batch 110, Loss: 0.5312
Batch 120, Loss: 0.5335
Batch 130, Loss: 0.5628
Batch 140, Loss: 0.5713
Batch 150, Loss: 0.5773
Batch 160, Loss: 0.5450
Batch 170, Loss: 0.5474
Batch 180, Loss: 0.5720
Batch 190, Loss: 0.5529
Batch 200, Loss: 0.5763
Batch 210, Loss: 0.5727
Batch 220, Loss: 0.6193
Batch 230, Loss: 0.5596
Batch 240, Loss: 0.6071
Batch 250, Loss: 0.6323
Batch 260, Loss: 0.6039
Batch 270, Loss: 0.6308
Batch 280, Loss: 0.6171
Batch 290, Loss: 0.5915
Batch 300, Loss: 0.6005
Batch 310, Loss: 0.5812
Batch 320, Loss: 0.6200
Batch 330, Loss: 0.6107
Batch 340, Loss: 0.6112
Batch 350, Loss: 0.6169
Batch 360, Loss: 0.6024
Batch 370, Loss: 0.6225
Batch 380, Loss: 0.6151
Batch 390, Loss: 0.6462
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.3983211517334 seconds
Epoch 99 accuracy: 66.41%
Batch 10, Loss: 0.5129
Batch 20, Loss: 0.5516
Batch 30, Loss: 0.5158
Batch 40, Loss: 0.4820
Batch 50, Loss: 0.4870
Batch 60, Loss: 0.4665
Batch 70, Loss: 0.5011
Batch 80, Loss: 0.4636
Batch 90, Loss: 0.5251
Batch 100, Loss: 0.5158
Batch 110, Loss: 0.4902
Batch 120, Loss: 0.4672
Batch 130, Loss: 0.5140
Batch 140, Loss: 0.4862
Batch 150, Loss: 0.5240
Batch 160, Loss: 0.5633
Batch 170, Loss: 0.5437
Batch 180, Loss: 0.5350
Batch 190, Loss: 0.5246
Batch 200, Loss: 0.5345
Batch 210, Loss: 0.5696
Batch 220, Loss: 0.5595
Batch 230, Loss: 0.6168
Batch 240, Loss: 0.6143
Batch 250, Loss: 0.5754
Batch 260, Loss: 0.5550
Batch 270, Loss: 0.5630
Batch 280, Loss: 0.6012
Batch 290, Loss: 0.6082
Batch 300, Loss: 0.5940
Batch 310, Loss: 0.5800
Batch 320, Loss: 0.6119
Batch 330, Loss: 0.6188
Batch 340, Loss: 0.6306
Batch 350, Loss: 0.5950
Batch 360, Loss: 0.5830
Batch 370, Loss: 0.6176
Batch 380, Loss: 0.6582
Batch 390, Loss: 0.6339
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.317545652389526 seconds
Epoch 100 accuracy: 63.71%
Batch 10, Loss: 0.5352
Batch 20, Loss: 0.5264
Batch 30, Loss: 0.5142
Batch 40, Loss: 0.4695
Batch 50, Loss: 0.5163
Batch 60, Loss: 0.4866
Batch 70, Loss: 0.5028
Batch 80, Loss: 0.5047
Batch 90, Loss: 0.5215
Batch 100, Loss: 0.5153
Batch 110, Loss: 0.5044
Batch 120, Loss: 0.5416
Batch 130, Loss: 0.5388
Batch 140, Loss: 0.5248
Batch 150, Loss: 0.5719
Batch 160, Loss: 0.5183
Batch 170, Loss: 0.4991
Batch 180, Loss: 0.5109
Batch 190, Loss: 0.5271
Batch 200, Loss: 0.5068
Batch 210, Loss: 0.5640
Batch 220, Loss: 0.5329
Batch 230, Loss: 0.5293
Batch 240, Loss: 0.5617
Batch 250, Loss: 0.5912
Batch 260, Loss: 0.5983
Batch 270, Loss: 0.5984
Batch 280, Loss: 0.5948
Batch 290, Loss: 0.5840
Batch 300, Loss: 0.6037
Batch 310, Loss: 0.5688
Batch 320, Loss: 0.5670
Batch 330, Loss: 0.5800
Batch 340, Loss: 0.5987
Batch 350, Loss: 0.6476
Batch 360, Loss: 0.6183
Batch 370, Loss: 0.6009
Batch 380, Loss: 0.6257
Batch 390, Loss: 0.6274
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.25085711479187 seconds
Epoch 101 accuracy: 64.04%
Batch 10, Loss: 0.5570
Batch 20, Loss: 0.5106
Batch 30, Loss: 0.4916
Batch 40, Loss: 0.5067
Batch 50, Loss: 0.4865
Batch 60, Loss: 0.4904
Batch 70, Loss: 0.4687
Batch 80, Loss: 0.4810
Batch 90, Loss: 0.4960
Batch 100, Loss: 0.4981
Batch 110, Loss: 0.5269
Batch 120, Loss: 0.5224
Batch 130, Loss: 0.5162
Batch 140, Loss: 0.5409
Batch 150, Loss: 0.5217
Batch 160, Loss: 0.5089
Batch 170, Loss: 0.5089
Batch 180, Loss: 0.5276
Batch 190, Loss: 0.5205
Batch 200, Loss: 0.4733
Batch 210, Loss: 0.5511
Batch 220, Loss: 0.5670
Batch 230, Loss: 0.5268
Batch 240, Loss: 0.5067
Batch 250, Loss: 0.5748
Batch 260, Loss: 0.5582
Batch 270, Loss: 0.5639
Batch 280, Loss: 0.5687
Batch 290, Loss: 0.5498
Batch 300, Loss: 0.5864
Batch 310, Loss: 0.5549
Batch 320, Loss: 0.5542
Batch 330, Loss: 0.5715
Batch 340, Loss: 0.5392
Batch 350, Loss: 0.5681
Batch 360, Loss: 0.5870
Batch 370, Loss: 0.6306
Batch 380, Loss: 0.5953
Batch 390, Loss: 0.5966
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.307415008544922 seconds
Epoch 102 accuracy: 66.77%
Batch 10, Loss: 0.5118
Batch 20, Loss: 0.4792
Batch 30, Loss: 0.4710
Batch 40, Loss: 0.4521
Batch 50, Loss: 0.4995
Batch 60, Loss: 0.5040
Batch 70, Loss: 0.4696
Batch 80, Loss: 0.4758
Batch 90, Loss: 0.4757
Batch 100, Loss: 0.4354
Batch 110, Loss: 0.4831
Batch 120, Loss: 0.4936
Batch 130, Loss: 0.4911
Batch 140, Loss: 0.5365
Batch 150, Loss: 0.5301
Batch 160, Loss: 0.5361
Batch 170, Loss: 0.5553
Batch 180, Loss: 0.5564
Batch 190, Loss: 0.5470
Batch 200, Loss: 0.5625
Batch 210, Loss: 0.5290
Batch 220, Loss: 0.5425
Batch 230, Loss: 0.5457
Batch 240, Loss: 0.5422
Batch 250, Loss: 0.5553
Batch 260, Loss: 0.5814
Batch 270, Loss: 0.6186
Batch 280, Loss: 0.5449
Batch 290, Loss: 0.5706
Batch 300, Loss: 0.5749
Batch 310, Loss: 0.5733
Batch 320, Loss: 0.5570
Batch 330, Loss: 0.5633
Batch 340, Loss: 0.5844
Batch 350, Loss: 0.5855
Batch 360, Loss: 0.5623
Batch 370, Loss: 0.6140
Batch 380, Loss: 0.6208
Batch 390, Loss: 0.5931
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.372374534606934 seconds
Epoch 103 accuracy: 66.34%
Batch 10, Loss: 0.4865
Batch 20, Loss: 0.4825
Batch 30, Loss: 0.4673
Batch 40, Loss: 0.4975
Batch 50, Loss: 0.4570
Batch 60, Loss: 0.4393
Batch 70, Loss: 0.4781
Batch 80, Loss: 0.4866
Batch 90, Loss: 0.4960
Batch 100, Loss: 0.4700
Batch 110, Loss: 0.4671
Batch 120, Loss: 0.5118
Batch 130, Loss: 0.4867
Batch 140, Loss: 0.4766
Batch 150, Loss: 0.4862
Batch 160, Loss: 0.4919
Batch 170, Loss: 0.4917
Batch 180, Loss: 0.4952
Batch 190, Loss: 0.5059
Batch 200, Loss: 0.5239
Batch 210, Loss: 0.5155
Batch 220, Loss: 0.5115
Batch 230, Loss: 0.5200
Batch 240, Loss: 0.5484
Batch 250, Loss: 0.5538
Batch 260, Loss: 0.5174
Batch 270, Loss: 0.5522
Batch 280, Loss: 0.5536
Batch 290, Loss: 0.5652
Batch 300, Loss: 0.5696
Batch 310, Loss: 0.5647
Batch 320, Loss: 0.5713
Batch 330, Loss: 0.5880
Batch 340, Loss: 0.5262
Batch 350, Loss: 0.5743
Batch 360, Loss: 0.5682
Batch 370, Loss: 0.5498
Batch 380, Loss: 0.5455
Batch 390, Loss: 0.5484
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.26428723335266 seconds
Epoch 104 accuracy: 65.98%
Batch 10, Loss: 0.4849
Batch 20, Loss: 0.4682
Batch 30, Loss: 0.4350
Batch 40, Loss: 0.4577
Batch 50, Loss: 0.4535
Batch 60, Loss: 0.4286
Batch 70, Loss: 0.4870
Batch 80, Loss: 0.4287
Batch 90, Loss: 0.4684
Batch 100, Loss: 0.4663
Batch 110, Loss: 0.4915
Batch 120, Loss: 0.4628
Batch 130, Loss: 0.4949
Batch 140, Loss: 0.4933
Batch 150, Loss: 0.4837
Batch 160, Loss: 0.5128
Batch 170, Loss: 0.5142
Batch 180, Loss: 0.5214
Batch 190, Loss: 0.5356
Batch 200, Loss: 0.5281
Batch 210, Loss: 0.5173
Batch 220, Loss: 0.5144
Batch 230, Loss: 0.5631
Batch 240, Loss: 0.5134
Batch 250, Loss: 0.5357
Batch 260, Loss: 0.5235
Batch 270, Loss: 0.5679
Batch 280, Loss: 0.5679
Batch 290, Loss: 0.5259
Batch 300, Loss: 0.5817
Batch 310, Loss: 0.5309
Batch 320, Loss: 0.4939
Batch 330, Loss: 0.5740
Batch 340, Loss: 0.5887
Batch 350, Loss: 0.5602
Batch 360, Loss: 0.5842
Batch 370, Loss: 0.6106
Batch 380, Loss: 0.6252
Batch 390, Loss: 0.5915
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.244056463241577 seconds
Epoch 105 accuracy: 65.81%
Batch 10, Loss: 0.4496
Batch 20, Loss: 0.4672
Batch 30, Loss: 0.4348
Batch 40, Loss: 0.4408
Batch 50, Loss: 0.4490
Batch 60, Loss: 0.4318
Batch 70, Loss: 0.4768
Batch 80, Loss: 0.4787
Batch 90, Loss: 0.4654
Batch 100, Loss: 0.4658
Batch 110, Loss: 0.5221
Batch 120, Loss: 0.4671
Batch 130, Loss: 0.4558
Batch 140, Loss: 0.4833
Batch 150, Loss: 0.5075
Batch 160, Loss: 0.4922
Batch 170, Loss: 0.5068
Batch 180, Loss: 0.5329
Batch 190, Loss: 0.4944
Batch 200, Loss: 0.4973
Batch 210, Loss: 0.5391
Batch 220, Loss: 0.5297
Batch 230, Loss: 0.4820
Batch 240, Loss: 0.5130
Batch 250, Loss: 0.4980
Batch 260, Loss: 0.4698
Batch 270, Loss: 0.4899
Batch 280, Loss: 0.5114
Batch 290, Loss: 0.5625
Batch 300, Loss: 0.5398
Batch 310, Loss: 0.5548
Batch 320, Loss: 0.5389
Batch 330, Loss: 0.5868
Batch 340, Loss: 0.5772
Batch 350, Loss: 0.5474
Batch 360, Loss: 0.4991
Batch 370, Loss: 0.5538
Batch 380, Loss: 0.5384
Batch 390, Loss: 0.5794
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.185012340545654 seconds
Epoch 106 accuracy: 65.09%
Batch 10, Loss: 0.4999
Batch 20, Loss: 0.4455
Batch 30, Loss: 0.4574
Batch 40, Loss: 0.4180
Batch 50, Loss: 0.4554
Batch 60, Loss: 0.4365
Batch 70, Loss: 0.4622
Batch 80, Loss: 0.4645
Batch 90, Loss: 0.4549
Batch 100, Loss: 0.4300
Batch 110, Loss: 0.4379
Batch 120, Loss: 0.5014
Batch 130, Loss: 0.4580
Batch 140, Loss: 0.4678
Batch 150, Loss: 0.4797
Batch 160, Loss: 0.4974
Batch 170, Loss: 0.4687
Batch 180, Loss: 0.4794
Batch 190, Loss: 0.5031
Batch 200, Loss: 0.5192
Batch 210, Loss: 0.5214
Batch 220, Loss: 0.5570
Batch 230, Loss: 0.5121
Batch 240, Loss: 0.5259
Batch 250, Loss: 0.5302
Batch 260, Loss: 0.4949
Batch 270, Loss: 0.5073
Batch 280, Loss: 0.5194
Batch 290, Loss: 0.5256
Batch 300, Loss: 0.5282
Batch 310, Loss: 0.5704
Batch 320, Loss: 0.5183
Batch 330, Loss: 0.5410
Batch 340, Loss: 0.5114
Batch 350, Loss: 0.4945
Batch 360, Loss: 0.5453
Batch 370, Loss: 0.5398
Batch 380, Loss: 0.5945
Batch 390, Loss: 0.5392
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.269380807876587 seconds
Epoch 107 accuracy: 66.21%
Batch 10, Loss: 0.4770
Batch 20, Loss: 0.4305
Batch 30, Loss: 0.4495
Batch 40, Loss: 0.3935
Batch 50, Loss: 0.4286
Batch 60, Loss: 0.4518
Batch 70, Loss: 0.4241
Batch 80, Loss: 0.4423
Batch 90, Loss: 0.4378
Batch 100, Loss: 0.4348
Batch 110, Loss: 0.4323
Batch 120, Loss: 0.5006
Batch 130, Loss: 0.4787
Batch 140, Loss: 0.4974
Batch 150, Loss: 0.4552
Batch 160, Loss: 0.5073
Batch 170, Loss: 0.4736
Batch 180, Loss: 0.5242
Batch 190, Loss: 0.4719
Batch 200, Loss: 0.4887
Batch 210, Loss: 0.5008
Batch 220, Loss: 0.4864
Batch 230, Loss: 0.4946
Batch 240, Loss: 0.5178
Batch 250, Loss: 0.5367
Batch 260, Loss: 0.5234
Batch 270, Loss: 0.5641
Batch 280, Loss: 0.5450
Batch 290, Loss: 0.4947
Batch 300, Loss: 0.5178
Batch 310, Loss: 0.5210
Batch 320, Loss: 0.5267
Batch 330, Loss: 0.5071
Batch 340, Loss: 0.5177
Batch 350, Loss: 0.5119
Batch 360, Loss: 0.5665
Batch 370, Loss: 0.5741
Batch 380, Loss: 0.5230
Batch 390, Loss: 0.5864
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.29947018623352 seconds
Epoch 108 accuracy: 68.69%
Batch 10, Loss: 0.4457
Batch 20, Loss: 0.4845
Batch 30, Loss: 0.4598
Batch 40, Loss: 0.4784
Batch 50, Loss: 0.4346
Batch 60, Loss: 0.4427
Batch 70, Loss: 0.4335
Batch 80, Loss: 0.4275
Batch 90, Loss: 0.4749
Batch 100, Loss: 0.4331
Batch 110, Loss: 0.4295
Batch 120, Loss: 0.4585
Batch 130, Loss: 0.4350
Batch 140, Loss: 0.4548
Batch 150, Loss: 0.4334
Batch 160, Loss: 0.4241
Batch 170, Loss: 0.4470
Batch 180, Loss: 0.4865
Batch 190, Loss: 0.4712
Batch 200, Loss: 0.4536
Batch 210, Loss: 0.4594
Batch 220, Loss: 0.4688
Batch 230, Loss: 0.4688
Batch 240, Loss: 0.5255
Batch 250, Loss: 0.4462
Batch 260, Loss: 0.5088
Batch 270, Loss: 0.5339
Batch 280, Loss: 0.4836
Batch 290, Loss: 0.5275
Batch 300, Loss: 0.5609
Batch 310, Loss: 0.5257
Batch 320, Loss: 0.5380
Batch 330, Loss: 0.4973
Batch 340, Loss: 0.5397
Batch 350, Loss: 0.5390
Batch 360, Loss: 0.5117
Batch 370, Loss: 0.5489
Batch 380, Loss: 0.5667
Batch 390, Loss: 0.5705
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.242062091827393 seconds
Epoch 109 accuracy: 65.07%
Batch 10, Loss: 0.4240
Batch 20, Loss: 0.4441
Batch 30, Loss: 0.4508
Batch 40, Loss: 0.4419
Batch 50, Loss: 0.4468
Batch 60, Loss: 0.4096
Batch 70, Loss: 0.4580
Batch 80, Loss: 0.4581
Batch 90, Loss: 0.4427
Batch 100, Loss: 0.4794
Batch 110, Loss: 0.4480
Batch 120, Loss: 0.4326
Batch 130, Loss: 0.4151
Batch 140, Loss: 0.4206
Batch 150, Loss: 0.4665
Batch 160, Loss: 0.4218
Batch 170, Loss: 0.4610
Batch 180, Loss: 0.4778
Batch 190, Loss: 0.4680
Batch 200, Loss: 0.4624
Batch 210, Loss: 0.4954
Batch 220, Loss: 0.4784
Batch 230, Loss: 0.5451
Batch 240, Loss: 0.4766
Batch 250, Loss: 0.5111
Batch 260, Loss: 0.4643
Batch 270, Loss: 0.4882
Batch 280, Loss: 0.4961
Batch 290, Loss: 0.4905
Batch 300, Loss: 0.4905
Batch 310, Loss: 0.5387
Batch 320, Loss: 0.5307
Batch 330, Loss: 0.5724
Batch 340, Loss: 0.5281
Batch 350, Loss: 0.5438
Batch 360, Loss: 0.4970
Batch 370, Loss: 0.5133
Batch 380, Loss: 0.4833
Batch 390, Loss: 0.4844
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.238977193832397 seconds
Epoch 110 accuracy: 67.0%
Batch 10, Loss: 0.4121
Batch 20, Loss: 0.3899
Batch 30, Loss: 0.4172
Batch 40, Loss: 0.4038
Batch 50, Loss: 0.4016
Batch 60, Loss: 0.4018
Batch 70, Loss: 0.4155
Batch 80, Loss: 0.4407
Batch 90, Loss: 0.3958
Batch 100, Loss: 0.4370
Batch 110, Loss: 0.4192
Batch 120, Loss: 0.4288
Batch 130, Loss: 0.4475
Batch 140, Loss: 0.4478
Batch 150, Loss: 0.4315
Batch 160, Loss: 0.4880
Batch 170, Loss: 0.4207
Batch 180, Loss: 0.4603
Batch 190, Loss: 0.4420
Batch 200, Loss: 0.4588
Batch 210, Loss: 0.4332
Batch 220, Loss: 0.4927
Batch 230, Loss: 0.5138
Batch 240, Loss: 0.4890
Batch 250, Loss: 0.4928
Batch 260, Loss: 0.5099
Batch 270, Loss: 0.5218
Batch 280, Loss: 0.4766
Batch 290, Loss: 0.5038
Batch 300, Loss: 0.4649
Batch 310, Loss: 0.5207
Batch 320, Loss: 0.4994
Batch 330, Loss: 0.5123
Batch 340, Loss: 0.4725
Batch 350, Loss: 0.4982
Batch 360, Loss: 0.5599
Batch 370, Loss: 0.4810
Batch 380, Loss: 0.5428
Batch 390, Loss: 0.5037
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.234527349472046 seconds
Epoch 111 accuracy: 66.88%
Batch 10, Loss: 0.4214
Batch 20, Loss: 0.3969
Batch 30, Loss: 0.4340
Batch 40, Loss: 0.4268
Batch 50, Loss: 0.3984
Batch 60, Loss: 0.4119
Batch 70, Loss: 0.4180
Batch 80, Loss: 0.4003
Batch 90, Loss: 0.4487
Batch 100, Loss: 0.3968
Batch 110, Loss: 0.3967
Batch 120, Loss: 0.4217
Batch 130, Loss: 0.4343
Batch 140, Loss: 0.4004
Batch 150, Loss: 0.4282
Batch 160, Loss: 0.4534
Batch 170, Loss: 0.4267
Batch 180, Loss: 0.4233
Batch 190, Loss: 0.4118
Batch 200, Loss: 0.4501
Batch 210, Loss: 0.4747
Batch 220, Loss: 0.4325
Batch 230, Loss: 0.4686
Batch 240, Loss: 0.4488
Batch 250, Loss: 0.4657
Batch 260, Loss: 0.4979
Batch 270, Loss: 0.4892
Batch 280, Loss: 0.4980
Batch 290, Loss: 0.4655
Batch 300, Loss: 0.4988
Batch 310, Loss: 0.4780
Batch 320, Loss: 0.4791
Batch 330, Loss: 0.4733
Batch 340, Loss: 0.4904
Batch 350, Loss: 0.5333
Batch 360, Loss: 0.5321
Batch 370, Loss: 0.5422
Batch 380, Loss: 0.4982
Batch 390, Loss: 0.4796
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.273969888687134 seconds
Epoch 112 accuracy: 67.87%
Batch 10, Loss: 0.4250
Batch 20, Loss: 0.4104
Batch 30, Loss: 0.4313
Batch 40, Loss: 0.4279
Batch 50, Loss: 0.4041
Batch 60, Loss: 0.4104
Batch 70, Loss: 0.4239
Batch 80, Loss: 0.3941
Batch 90, Loss: 0.4290
Batch 100, Loss: 0.4207
Batch 110, Loss: 0.4358
Batch 120, Loss: 0.4141
Batch 130, Loss: 0.4113
Batch 140, Loss: 0.3964
Batch 150, Loss: 0.4205
Batch 160, Loss: 0.4191
Batch 170, Loss: 0.4403
Batch 180, Loss: 0.4082
Batch 190, Loss: 0.4414
Batch 200, Loss: 0.4413
Batch 210, Loss: 0.4435
Batch 220, Loss: 0.4435
Batch 230, Loss: 0.4413
Batch 240, Loss: 0.4500
Batch 250, Loss: 0.4308
Batch 260, Loss: 0.4344
Batch 270, Loss: 0.4184
Batch 280, Loss: 0.4834
Batch 290, Loss: 0.4611
Batch 300, Loss: 0.4259
Batch 310, Loss: 0.5059
Batch 320, Loss: 0.4906
Batch 330, Loss: 0.4783
Batch 340, Loss: 0.4760
Batch 350, Loss: 0.5050
Batch 360, Loss: 0.4238
Batch 370, Loss: 0.4571
Batch 380, Loss: 0.4741
Batch 390, Loss: 0.4769
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.330510139465332 seconds
Epoch 113 accuracy: 67.82%
Batch 10, Loss: 0.4025
Batch 20, Loss: 0.3873
Batch 30, Loss: 0.3964
Batch 40, Loss: 0.3965
Batch 50, Loss: 0.3754
Batch 60, Loss: 0.3887
Batch 70, Loss: 0.3745
Batch 80, Loss: 0.3844
Batch 90, Loss: 0.3745
Batch 100, Loss: 0.4099
Batch 110, Loss: 0.4244
Batch 120, Loss: 0.4092
Batch 130, Loss: 0.3920
Batch 140, Loss: 0.4041
Batch 150, Loss: 0.3849
Batch 160, Loss: 0.4033
Batch 170, Loss: 0.3924
Batch 180, Loss: 0.4226
Batch 190, Loss: 0.4402
Batch 200, Loss: 0.4307
Batch 210, Loss: 0.4435
Batch 220, Loss: 0.4214
Batch 230, Loss: 0.4378
Batch 240, Loss: 0.4327
Batch 250, Loss: 0.4340
Batch 260, Loss: 0.4265
Batch 270, Loss: 0.4808
Batch 280, Loss: 0.4731
Batch 290, Loss: 0.4401
Batch 300, Loss: 0.4929
Batch 310, Loss: 0.4852
Batch 320, Loss: 0.4777
Batch 330, Loss: 0.5008
Batch 340, Loss: 0.4953
Batch 350, Loss: 0.5299
Batch 360, Loss: 0.4877
Batch 370, Loss: 0.4887
Batch 380, Loss: 0.4893
Batch 390, Loss: 0.5217
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.341437101364136 seconds
Epoch 114 accuracy: 67.65%
Batch 10, Loss: 0.4276
Batch 20, Loss: 0.4196
Batch 30, Loss: 0.3926
Batch 40, Loss: 0.3810
Batch 50, Loss: 0.3620
Batch 60, Loss: 0.3649
Batch 70, Loss: 0.4051
Batch 80, Loss: 0.3841
Batch 90, Loss: 0.3974
Batch 100, Loss: 0.4168
Batch 110, Loss: 0.3931
Batch 120, Loss: 0.3865
Batch 130, Loss: 0.4128
Batch 140, Loss: 0.4215
Batch 150, Loss: 0.3864
Batch 160, Loss: 0.4385
Batch 170, Loss: 0.3972
Batch 180, Loss: 0.4258
Batch 190, Loss: 0.4060
Batch 200, Loss: 0.4237
Batch 210, Loss: 0.4240
Batch 220, Loss: 0.4138
Batch 230, Loss: 0.4282
Batch 240, Loss: 0.4532
Batch 250, Loss: 0.4227
Batch 260, Loss: 0.4134
Batch 270, Loss: 0.4256
Batch 280, Loss: 0.4498
Batch 290, Loss: 0.4548
Batch 300, Loss: 0.4705
Batch 310, Loss: 0.4400
Batch 320, Loss: 0.4373
Batch 330, Loss: 0.4546
Batch 340, Loss: 0.4428
Batch 350, Loss: 0.4287
Batch 360, Loss: 0.4578
Batch 370, Loss: 0.4690
Batch 380, Loss: 0.4967
Batch 390, Loss: 0.4498
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.201767683029175 seconds
Epoch 115 accuracy: 67.73%
Batch 10, Loss: 0.3992
Batch 20, Loss: 0.4203
Batch 30, Loss: 0.3603
Batch 40, Loss: 0.3765
Batch 50, Loss: 0.3694
Batch 60, Loss: 0.3688
Batch 70, Loss: 0.3570
Batch 80, Loss: 0.3760
Batch 90, Loss: 0.3506
Batch 100, Loss: 0.3693
Batch 110, Loss: 0.3882
Batch 120, Loss: 0.3575
Batch 130, Loss: 0.3961
Batch 140, Loss: 0.3892
Batch 150, Loss: 0.4160
Batch 160, Loss: 0.3701
Batch 170, Loss: 0.4231
Batch 180, Loss: 0.4301
Batch 190, Loss: 0.4043
Batch 200, Loss: 0.4221
Batch 210, Loss: 0.4134
Batch 220, Loss: 0.4249
Batch 230, Loss: 0.4430
Batch 240, Loss: 0.4190
Batch 250, Loss: 0.3958
Batch 260, Loss: 0.4707
Batch 270, Loss: 0.4530
Batch 280, Loss: 0.4154
Batch 290, Loss: 0.4082
Batch 300, Loss: 0.4458
Batch 310, Loss: 0.4262
Batch 320, Loss: 0.4524
Batch 330, Loss: 0.4408
Batch 340, Loss: 0.4630
Batch 350, Loss: 0.4758
Batch 360, Loss: 0.4867
Batch 370, Loss: 0.4658
Batch 380, Loss: 0.4468
Batch 390, Loss: 0.4744
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.30264186859131 seconds
Epoch 116 accuracy: 69.43%
Batch 10, Loss: 0.3765
Batch 20, Loss: 0.3858
Batch 30, Loss: 0.3749
Batch 40, Loss: 0.3846
Batch 50, Loss: 0.3655
Batch 60, Loss: 0.3864
Batch 70, Loss: 0.3481
Batch 80, Loss: 0.3488
Batch 90, Loss: 0.3791
Batch 100, Loss: 0.3678
Batch 110, Loss: 0.3970
Batch 120, Loss: 0.3930
Batch 130, Loss: 0.3781
Batch 140, Loss: 0.4060
Batch 150, Loss: 0.4069
Batch 160, Loss: 0.3715
Batch 170, Loss: 0.3800
Batch 180, Loss: 0.4043
Batch 190, Loss: 0.4290
Batch 200, Loss: 0.3901
Batch 210, Loss: 0.4024
Batch 220, Loss: 0.4123
Batch 230, Loss: 0.4210
Batch 240, Loss: 0.4232
Batch 250, Loss: 0.3782
Batch 260, Loss: 0.4362
Batch 270, Loss: 0.4313
Batch 280, Loss: 0.4442
Batch 290, Loss: 0.4419
Batch 300, Loss: 0.4317
Batch 310, Loss: 0.4567
Batch 320, Loss: 0.4980
Batch 330, Loss: 0.4852
Batch 340, Loss: 0.4550
Batch 350, Loss: 0.4517
Batch 360, Loss: 0.4206
Batch 370, Loss: 0.4555
Batch 380, Loss: 0.4648
Batch 390, Loss: 0.4543
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.14690351486206 seconds
Epoch 117 accuracy: 67.31%
Batch 10, Loss: 0.4461
Batch 20, Loss: 0.4139
Batch 30, Loss: 0.3753
Batch 40, Loss: 0.3613
Batch 50, Loss: 0.3363
Batch 60, Loss: 0.3263
Batch 70, Loss: 0.3818
Batch 80, Loss: 0.3342
Batch 90, Loss: 0.3932
Batch 100, Loss: 0.3606
Batch 110, Loss: 0.3658
Batch 120, Loss: 0.3586
Batch 130, Loss: 0.3765
Batch 140, Loss: 0.3672
Batch 150, Loss: 0.3975
Batch 160, Loss: 0.3476
Batch 170, Loss: 0.3875
Batch 180, Loss: 0.3965
Batch 190, Loss: 0.3843
Batch 200, Loss: 0.3860
Batch 210, Loss: 0.4044
Batch 220, Loss: 0.4202
Batch 230, Loss: 0.4269
Batch 240, Loss: 0.3951
Batch 250, Loss: 0.4292
Batch 260, Loss: 0.4157
Batch 270, Loss: 0.3858
Batch 280, Loss: 0.4350
Batch 290, Loss: 0.4098
Batch 300, Loss: 0.4381
Batch 310, Loss: 0.4007
Batch 320, Loss: 0.4287
Batch 330, Loss: 0.4300
Batch 340, Loss: 0.4168
Batch 350, Loss: 0.4747
Batch 360, Loss: 0.4450
Batch 370, Loss: 0.4587
Batch 380, Loss: 0.4640
Batch 390, Loss: 0.4459
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.249420166015625 seconds
Epoch 118 accuracy: 68.83%
Batch 10, Loss: 0.3495
Batch 20, Loss: 0.3560
Batch 30, Loss: 0.3486
Batch 40, Loss: 0.3783
Batch 50, Loss: 0.3447
Batch 60, Loss: 0.3360
Batch 70, Loss: 0.3663
Batch 80, Loss: 0.3493
Batch 90, Loss: 0.3679
Batch 100, Loss: 0.3818
Batch 110, Loss: 0.3626
Batch 120, Loss: 0.4014
Batch 130, Loss: 0.3649
Batch 140, Loss: 0.3827
Batch 150, Loss: 0.3545
Batch 160, Loss: 0.3790
Batch 170, Loss: 0.4074
Batch 180, Loss: 0.3650
Batch 190, Loss: 0.3720
Batch 200, Loss: 0.3340
Batch 210, Loss: 0.3847
Batch 220, Loss: 0.3843
Batch 230, Loss: 0.3648
Batch 240, Loss: 0.3710
Batch 250, Loss: 0.4031
Batch 260, Loss: 0.3889
Batch 270, Loss: 0.4210
Batch 280, Loss: 0.3727
Batch 290, Loss: 0.4098
Batch 300, Loss: 0.3957
Batch 310, Loss: 0.4461
Batch 320, Loss: 0.4096
Batch 330, Loss: 0.4310
Batch 340, Loss: 0.4412
Batch 350, Loss: 0.4325
Batch 360, Loss: 0.4281
Batch 370, Loss: 0.3979
Batch 380, Loss: 0.4401
Batch 390, Loss: 0.4370
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.349267721176147 seconds
Epoch 119 accuracy: 68.83%
Batch 10, Loss: 0.3475
Batch 20, Loss: 0.3858
Batch 30, Loss: 0.3431
Batch 40, Loss: 0.3345
Batch 50, Loss: 0.3423
Batch 60, Loss: 0.3247
Batch 70, Loss: 0.3250
Batch 80, Loss: 0.3337
Batch 90, Loss: 0.3405
Batch 100, Loss: 0.3351
Batch 110, Loss: 0.3520
Batch 120, Loss: 0.3443
Batch 130, Loss: 0.3403
Batch 140, Loss: 0.3548
Batch 150, Loss: 0.3292
Batch 160, Loss: 0.3685
Batch 170, Loss: 0.3675
Batch 180, Loss: 0.3458
Batch 190, Loss: 0.3614
Batch 200, Loss: 0.3882
Batch 210, Loss: 0.3950
Batch 220, Loss: 0.4251
Batch 230, Loss: 0.3657
Batch 240, Loss: 0.3794
Batch 250, Loss: 0.3937
Batch 260, Loss: 0.4062
Batch 270, Loss: 0.3713
Batch 280, Loss: 0.4304
Batch 290, Loss: 0.4516
Batch 300, Loss: 0.4357
Batch 310, Loss: 0.4022
Batch 320, Loss: 0.3978
Batch 330, Loss: 0.3877
Batch 340, Loss: 0.4238
Batch 350, Loss: 0.4133
Batch 360, Loss: 0.4063
Batch 370, Loss: 0.4614
Batch 380, Loss: 0.4352
Batch 390, Loss: 0.4573
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.16744375228882 seconds
Epoch 120 accuracy: 67.26%
Batch 10, Loss: 0.3772
Batch 20, Loss: 0.3504
Batch 30, Loss: 0.3495
Batch 40, Loss: 0.3646
Batch 50, Loss: 0.3433
Batch 60, Loss: 0.3111
Batch 70, Loss: 0.3465
Batch 80, Loss: 0.3214
Batch 90, Loss: 0.3044
Batch 100, Loss: 0.3396
Batch 110, Loss: 0.3395
Batch 120, Loss: 0.3257
Batch 130, Loss: 0.3351
Batch 140, Loss: 0.3779
Batch 150, Loss: 0.3465
Batch 160, Loss: 0.3358
Batch 170, Loss: 0.3477
Batch 180, Loss: 0.3626
Batch 190, Loss: 0.3692
Batch 200, Loss: 0.3928
Batch 210, Loss: 0.3738
Batch 220, Loss: 0.3898
Batch 230, Loss: 0.3829
Batch 240, Loss: 0.4105
Batch 250, Loss: 0.4073
Batch 260, Loss: 0.3522
Batch 270, Loss: 0.3875
Batch 280, Loss: 0.4230
Batch 290, Loss: 0.4080
Batch 300, Loss: 0.4004
Batch 310, Loss: 0.4141
Batch 320, Loss: 0.3987
Batch 330, Loss: 0.4156
Batch 340, Loss: 0.3746
Batch 350, Loss: 0.4139
Batch 360, Loss: 0.3806
Batch 370, Loss: 0.3583
Batch 380, Loss: 0.4095
Batch 390, Loss: 0.4051
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.26310658454895 seconds
Epoch 121 accuracy: 67.92%
Batch 10, Loss: 0.3191
Batch 20, Loss: 0.3333
Batch 30, Loss: 0.3225
Batch 40, Loss: 0.3197
Batch 50, Loss: 0.3493
Batch 60, Loss: 0.2986
Batch 70, Loss: 0.3764
Batch 80, Loss: 0.3093
Batch 90, Loss: 0.3158
Batch 100, Loss: 0.3419
Batch 110, Loss: 0.3209
Batch 120, Loss: 0.3393
Batch 130, Loss: 0.3505
Batch 140, Loss: 0.3268
Batch 150, Loss: 0.3377
Batch 160, Loss: 0.3578
Batch 170, Loss: 0.3667
Batch 180, Loss: 0.3350
Batch 190, Loss: 0.3820
Batch 200, Loss: 0.3732
Batch 210, Loss: 0.3803
Batch 220, Loss: 0.3911
Batch 230, Loss: 0.3596
Batch 240, Loss: 0.3514
Batch 250, Loss: 0.3699
Batch 260, Loss: 0.3515
Batch 270, Loss: 0.3769
Batch 280, Loss: 0.3992
Batch 290, Loss: 0.3982
Batch 300, Loss: 0.4249
Batch 310, Loss: 0.4061
Batch 320, Loss: 0.4012
Batch 330, Loss: 0.3996
Batch 340, Loss: 0.4203
Batch 350, Loss: 0.4083
Batch 360, Loss: 0.4210
Batch 370, Loss: 0.3762
Batch 380, Loss: 0.4266
Batch 390, Loss: 0.4000
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.15828251838684 seconds
Epoch 122 accuracy: 68.2%
Batch 10, Loss: 0.3427
Batch 20, Loss: 0.3163
Batch 30, Loss: 0.3120
Batch 40, Loss: 0.3377
Batch 50, Loss: 0.3097
Batch 60, Loss: 0.2950
Batch 70, Loss: 0.3350
Batch 80, Loss: 0.3132
Batch 90, Loss: 0.3242
Batch 100, Loss: 0.3374
Batch 110, Loss: 0.3265
Batch 120, Loss: 0.3395
Batch 130, Loss: 0.3557
Batch 140, Loss: 0.3340
Batch 150, Loss: 0.3647
Batch 160, Loss: 0.3133
Batch 170, Loss: 0.3229
Batch 180, Loss: 0.3187
Batch 190, Loss: 0.3111
Batch 200, Loss: 0.3598
Batch 210, Loss: 0.3574
Batch 220, Loss: 0.3344
Batch 230, Loss: 0.3622
Batch 240, Loss: 0.3409
Batch 250, Loss: 0.3414
Batch 260, Loss: 0.3396
Batch 270, Loss: 0.3779
Batch 280, Loss: 0.3667
Batch 290, Loss: 0.3899
Batch 300, Loss: 0.3805
Batch 310, Loss: 0.4046
Batch 320, Loss: 0.3901
Batch 330, Loss: 0.4146
Batch 340, Loss: 0.3843
Batch 350, Loss: 0.4036
Batch 360, Loss: 0.3832
Batch 370, Loss: 0.4104
Batch 380, Loss: 0.3864
Batch 390, Loss: 0.4236
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.29168128967285 seconds
Epoch 123 accuracy: 67.81%
Batch 10, Loss: 0.3302
Batch 20, Loss: 0.3213
Batch 30, Loss: 0.2818
Batch 40, Loss: 0.3131
Batch 50, Loss: 0.2989
Batch 60, Loss: 0.3546
Batch 70, Loss: 0.3308
Batch 80, Loss: 0.3386
Batch 90, Loss: 0.3426
Batch 100, Loss: 0.3203
Batch 110, Loss: 0.3449
Batch 120, Loss: 0.3400
Batch 130, Loss: 0.3276
Batch 140, Loss: 0.2894
Batch 150, Loss: 0.2858
Batch 160, Loss: 0.3215
Batch 170, Loss: 0.3184
Batch 180, Loss: 0.3394
Batch 190, Loss: 0.3192
Batch 200, Loss: 0.3178
Batch 210, Loss: 0.3561
Batch 220, Loss: 0.3091
Batch 230, Loss: 0.3332
Batch 240, Loss: 0.3472
Batch 250, Loss: 0.3396
Batch 260, Loss: 0.3153
Batch 270, Loss: 0.3243
Batch 280, Loss: 0.3388
Batch 290, Loss: 0.3662
Batch 300, Loss: 0.3653
Batch 310, Loss: 0.3476
Batch 320, Loss: 0.3728
Batch 330, Loss: 0.3837
Batch 340, Loss: 0.3834
Batch 350, Loss: 0.3733
Batch 360, Loss: 0.3829
Batch 370, Loss: 0.4144
Batch 380, Loss: 0.4207
Batch 390, Loss: 0.4223
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.26510000228882 seconds
Epoch 124 accuracy: 67.32%
Batch 10, Loss: 0.3435
Batch 20, Loss: 0.3158
Batch 30, Loss: 0.3134
Batch 40, Loss: 0.3075
Batch 50, Loss: 0.3081
Batch 60, Loss: 0.2800
Batch 70, Loss: 0.3041
Batch 80, Loss: 0.3043
Batch 90, Loss: 0.3151
Batch 100, Loss: 0.2942
Batch 110, Loss: 0.2681
Batch 120, Loss: 0.3024
Batch 130, Loss: 0.3206
Batch 140, Loss: 0.3359
Batch 150, Loss: 0.3144
Batch 160, Loss: 0.3196
Batch 170, Loss: 0.3174
Batch 180, Loss: 0.3223
Batch 190, Loss: 0.3136
Batch 200, Loss: 0.3304
Batch 210, Loss: 0.3601
Batch 220, Loss: 0.3293
Batch 230, Loss: 0.3386
Batch 240, Loss: 0.3450
Batch 250, Loss: 0.3298
Batch 260, Loss: 0.3624
Batch 270, Loss: 0.3759
Batch 280, Loss: 0.3698
Batch 290, Loss: 0.3888
Batch 300, Loss: 0.3777
Batch 310, Loss: 0.3825
Batch 320, Loss: 0.3924
Batch 330, Loss: 0.3715
Batch 340, Loss: 0.3830
Batch 350, Loss: 0.3628
Batch 360, Loss: 0.3767
Batch 370, Loss: 0.3747
Batch 380, Loss: 0.3659
Batch 390, Loss: 0.3620
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.37249779701233 seconds
Epoch 125 accuracy: 69.05%
Batch 10, Loss: 0.2984
Batch 20, Loss: 0.3174
Batch 30, Loss: 0.3413
Batch 40, Loss: 0.2856
Batch 50, Loss: 0.3009
Batch 60, Loss: 0.3018
Batch 70, Loss: 0.2893
Batch 80, Loss: 0.3037
Batch 90, Loss: 0.2982
Batch 100, Loss: 0.2946
Batch 110, Loss: 0.2998
Batch 120, Loss: 0.2841
Batch 130, Loss: 0.3168
Batch 140, Loss: 0.3046
Batch 150, Loss: 0.3181
Batch 160, Loss: 0.3526
Batch 170, Loss: 0.3336
Batch 180, Loss: 0.3165
Batch 190, Loss: 0.3137
Batch 200, Loss: 0.3018
Batch 210, Loss: 0.3326
Batch 220, Loss: 0.3404
Batch 230, Loss: 0.3233
Batch 240, Loss: 0.3523
Batch 250, Loss: 0.3770
Batch 260, Loss: 0.3229
Batch 270, Loss: 0.3275
Batch 280, Loss: 0.3014
Batch 290, Loss: 0.3245
Batch 300, Loss: 0.3331
Batch 310, Loss: 0.3620
Batch 320, Loss: 0.3861
Batch 330, Loss: 0.3626
Batch 340, Loss: 0.3978
Batch 350, Loss: 0.3576
Batch 360, Loss: 0.3721
Batch 370, Loss: 0.3713
Batch 380, Loss: 0.4012
Batch 390, Loss: 0.3814
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.267030715942383 seconds
Epoch 126 accuracy: 69.08%
Batch 10, Loss: 0.3215
Batch 20, Loss: 0.3325
Batch 30, Loss: 0.2913
Batch 40, Loss: 0.2878
Batch 50, Loss: 0.3022
Batch 60, Loss: 0.2806
Batch 70, Loss: 0.2876
Batch 80, Loss: 0.3362
Batch 90, Loss: 0.3106
Batch 100, Loss: 0.2911
Batch 110, Loss: 0.3025
Batch 120, Loss: 0.3145
Batch 130, Loss: 0.2826
Batch 140, Loss: 0.2905
Batch 150, Loss: 0.3104
Batch 160, Loss: 0.2940
Batch 170, Loss: 0.3153
Batch 180, Loss: 0.3205
Batch 190, Loss: 0.3246
Batch 200, Loss: 0.3103
Batch 210, Loss: 0.3417
Batch 220, Loss: 0.3354
Batch 230, Loss: 0.3302
Batch 240, Loss: 0.3105
Batch 250, Loss: 0.3411
Batch 260, Loss: 0.3303
Batch 270, Loss: 0.3205
Batch 280, Loss: 0.3119
Batch 290, Loss: 0.3461
Batch 300, Loss: 0.3624
Batch 310, Loss: 0.3485
Batch 320, Loss: 0.3221
Batch 330, Loss: 0.3300
Batch 340, Loss: 0.3560
Batch 350, Loss: 0.3286
Batch 360, Loss: 0.3737
Batch 370, Loss: 0.3595
Batch 380, Loss: 0.3705
Batch 390, Loss: 0.3484
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.29199981689453 seconds
Epoch 127 accuracy: 67.27%
Batch 10, Loss: 0.2995
Batch 20, Loss: 0.2856
Batch 30, Loss: 0.2864
Batch 40, Loss: 0.2631
Batch 50, Loss: 0.2811
Batch 60, Loss: 0.2762
Batch 70, Loss: 0.2747
Batch 80, Loss: 0.2963
Batch 90, Loss: 0.2954
Batch 100, Loss: 0.2758
Batch 110, Loss: 0.2710
Batch 120, Loss: 0.2963
Batch 130, Loss: 0.2694
Batch 140, Loss: 0.2636
Batch 150, Loss: 0.2746
Batch 160, Loss: 0.2971
Batch 170, Loss: 0.2902
Batch 180, Loss: 0.2850
Batch 190, Loss: 0.2875
Batch 200, Loss: 0.3035
Batch 210, Loss: 0.2916
Batch 220, Loss: 0.3113
Batch 230, Loss: 0.3033
Batch 240, Loss: 0.3014
Batch 250, Loss: 0.2950
Batch 260, Loss: 0.3041
Batch 270, Loss: 0.3417
Batch 280, Loss: 0.3079
Batch 290, Loss: 0.3158
Batch 300, Loss: 0.2976
Batch 310, Loss: 0.2926
Batch 320, Loss: 0.3239
Batch 330, Loss: 0.3457
Batch 340, Loss: 0.3378
Batch 350, Loss: 0.3790
Batch 360, Loss: 0.3480
Batch 370, Loss: 0.3604
Batch 380, Loss: 0.3530
Batch 390, Loss: 0.3445
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.22101926803589 seconds
Epoch 128 accuracy: 69.42%
Batch 10, Loss: 0.2852
Batch 20, Loss: 0.2644
Batch 30, Loss: 0.2885
Batch 40, Loss: 0.2697
Batch 50, Loss: 0.2588
Batch 60, Loss: 0.2859
Batch 70, Loss: 0.2706
Batch 80, Loss: 0.2696
Batch 90, Loss: 0.2635
Batch 100, Loss: 0.2808
Batch 110, Loss: 0.2808
Batch 120, Loss: 0.2861
Batch 130, Loss: 0.2960
Batch 140, Loss: 0.3098
Batch 150, Loss: 0.2749
Batch 160, Loss: 0.2921
Batch 170, Loss: 0.2861
Batch 180, Loss: 0.2826
Batch 190, Loss: 0.2944
Batch 200, Loss: 0.3113
Batch 210, Loss: 0.3073
Batch 220, Loss: 0.3189
Batch 230, Loss: 0.2914
Batch 240, Loss: 0.2806
Batch 250, Loss: 0.2932
Batch 260, Loss: 0.3142
Batch 270, Loss: 0.2862
Batch 280, Loss: 0.2868
Batch 290, Loss: 0.3205
Batch 300, Loss: 0.3298
Batch 310, Loss: 0.3133
Batch 320, Loss: 0.3089
Batch 330, Loss: 0.3054
Batch 340, Loss: 0.3120
Batch 350, Loss: 0.3329
Batch 360, Loss: 0.3028
Batch 370, Loss: 0.3347
Batch 380, Loss: 0.3160
Batch 390, Loss: 0.3439
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.278989553451538 seconds
Epoch 129 accuracy: 69.37%
Batch 10, Loss: 0.2744
Batch 20, Loss: 0.2815
Batch 30, Loss: 0.2684
Batch 40, Loss: 0.2531
Batch 50, Loss: 0.2458
Batch 60, Loss: 0.2843
Batch 70, Loss: 0.2652
Batch 80, Loss: 0.2773
Batch 90, Loss: 0.2975
Batch 100, Loss: 0.2578
Batch 110, Loss: 0.2768
Batch 120, Loss: 0.2616
Batch 130, Loss: 0.2829
Batch 140, Loss: 0.2925
Batch 150, Loss: 0.2721
Batch 160, Loss: 0.2626
Batch 170, Loss: 0.2971
Batch 180, Loss: 0.2730
Batch 190, Loss: 0.2798
Batch 200, Loss: 0.2806
Batch 210, Loss: 0.2857
Batch 220, Loss: 0.2934
Batch 230, Loss: 0.3132
Batch 240, Loss: 0.3029
Batch 250, Loss: 0.3013
Batch 260, Loss: 0.3119
Batch 270, Loss: 0.3060
Batch 280, Loss: 0.3067
Batch 290, Loss: 0.2837
Batch 300, Loss: 0.3193
Batch 310, Loss: 0.3257
Batch 320, Loss: 0.3095
Batch 330, Loss: 0.3285
Batch 340, Loss: 0.3548
Batch 350, Loss: 0.3385
Batch 360, Loss: 0.3144
Batch 370, Loss: 0.3422
Batch 380, Loss: 0.3253
Batch 390, Loss: 0.3404
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.223196983337402 seconds
Epoch 130 accuracy: 68.88%
Batch 10, Loss: 0.3077
Batch 20, Loss: 0.2765
Batch 30, Loss: 0.2832
Batch 40, Loss: 0.2676
Batch 50, Loss: 0.2825
Batch 60, Loss: 0.2757
Batch 70, Loss: 0.2938
Batch 80, Loss: 0.2806
Batch 90, Loss: 0.2804
Batch 100, Loss: 0.2723
Batch 110, Loss: 0.2855
Batch 120, Loss: 0.2518
Batch 130, Loss: 0.2498
Batch 140, Loss: 0.2635
Batch 150, Loss: 0.2544
Batch 160, Loss: 0.2709
Batch 170, Loss: 0.2688
Batch 180, Loss: 0.2797
Batch 190, Loss: 0.2732
Batch 200, Loss: 0.2879
Batch 210, Loss: 0.2918
Batch 220, Loss: 0.2570
Batch 230, Loss: 0.2829
Batch 240, Loss: 0.2950
Batch 250, Loss: 0.2711
Batch 260, Loss: 0.3024
Batch 270, Loss: 0.2792
Batch 280, Loss: 0.2942
Batch 290, Loss: 0.2790
Batch 300, Loss: 0.3097
Batch 310, Loss: 0.3033
Batch 320, Loss: 0.2965
Batch 330, Loss: 0.2943
Batch 340, Loss: 0.3002
Batch 350, Loss: 0.3137
Batch 360, Loss: 0.3135
Batch 370, Loss: 0.3104
Batch 380, Loss: 0.3285
Batch 390, Loss: 0.3231
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.30116605758667 seconds
Epoch 131 accuracy: 70.45%
Batch 10, Loss: 0.2604
Batch 20, Loss: 0.2571
Batch 30, Loss: 0.3020
Batch 40, Loss: 0.2577
Batch 50, Loss: 0.2466
Batch 60, Loss: 0.2603
Batch 70, Loss: 0.2755
Batch 80, Loss: 0.2448
Batch 90, Loss: 0.2722
Batch 100, Loss: 0.2637
Batch 110, Loss: 0.2905
Batch 120, Loss: 0.2641
Batch 130, Loss: 0.2579
Batch 140, Loss: 0.2574
Batch 150, Loss: 0.2515
Batch 160, Loss: 0.2711
Batch 170, Loss: 0.2453
Batch 180, Loss: 0.2854
Batch 190, Loss: 0.2779
Batch 200, Loss: 0.2808
Batch 210, Loss: 0.2620
Batch 220, Loss: 0.2967
Batch 230, Loss: 0.2920
Batch 240, Loss: 0.2963
Batch 250, Loss: 0.2686
Batch 260, Loss: 0.2585
Batch 270, Loss: 0.2847
Batch 280, Loss: 0.2832
Batch 290, Loss: 0.2979
Batch 300, Loss: 0.2795
Batch 310, Loss: 0.3048
Batch 320, Loss: 0.2573
Batch 330, Loss: 0.2960
Batch 340, Loss: 0.2913
Batch 350, Loss: 0.2828
Batch 360, Loss: 0.2902
Batch 370, Loss: 0.3076
Batch 380, Loss: 0.3076
Batch 390, Loss: 0.2978
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.339807987213135 seconds
Epoch 132 accuracy: 70.07%
Batch 10, Loss: 0.2738
Batch 20, Loss: 0.2670
Batch 30, Loss: 0.2327
Batch 40, Loss: 0.2548
Batch 50, Loss: 0.2372
Batch 60, Loss: 0.2383
Batch 70, Loss: 0.2319
Batch 80, Loss: 0.2549
Batch 90, Loss: 0.2540
Batch 100, Loss: 0.2381
Batch 110, Loss: 0.2320
Batch 120, Loss: 0.2601
Batch 130, Loss: 0.2346
Batch 140, Loss: 0.2355
Batch 150, Loss: 0.2563
Batch 160, Loss: 0.2540
Batch 170, Loss: 0.2701
Batch 180, Loss: 0.2507
Batch 190, Loss: 0.2563
Batch 200, Loss: 0.2659
Batch 210, Loss: 0.2654
Batch 220, Loss: 0.2656
Batch 230, Loss: 0.2677
Batch 240, Loss: 0.2665
Batch 250, Loss: 0.2391
Batch 260, Loss: 0.2774
Batch 270, Loss: 0.2685
Batch 280, Loss: 0.2759
Batch 290, Loss: 0.2751
Batch 300, Loss: 0.2825
Batch 310, Loss: 0.3140
Batch 320, Loss: 0.2888
Batch 330, Loss: 0.2899
Batch 340, Loss: 0.2868
Batch 350, Loss: 0.2902
Batch 360, Loss: 0.3065
Batch 370, Loss: 0.2848
Batch 380, Loss: 0.2865
Batch 390, Loss: 0.3072
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.22904396057129 seconds
Epoch 133 accuracy: 69.63%
Batch 10, Loss: 0.2399
Batch 20, Loss: 0.2602
Batch 30, Loss: 0.2201
Batch 40, Loss: 0.2247
Batch 50, Loss: 0.2387
Batch 60, Loss: 0.2306
Batch 70, Loss: 0.2443
Batch 80, Loss: 0.2317
Batch 90, Loss: 0.2414
Batch 100, Loss: 0.2144
Batch 110, Loss: 0.2252
Batch 120, Loss: 0.2482
Batch 130, Loss: 0.2575
Batch 140, Loss: 0.2385
Batch 150, Loss: 0.2357
Batch 160, Loss: 0.2429
Batch 170, Loss: 0.2363
Batch 180, Loss: 0.2417
Batch 190, Loss: 0.2419
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2537
Batch 220, Loss: 0.2654
Batch 230, Loss: 0.2453
Batch 240, Loss: 0.2609
Batch 250, Loss: 0.2710
Batch 260, Loss: 0.2514
Batch 270, Loss: 0.2768
Batch 280, Loss: 0.2493
Batch 290, Loss: 0.2740
Batch 300, Loss: 0.2647
Batch 310, Loss: 0.2622
Batch 320, Loss: 0.2564
Batch 330, Loss: 0.2723
Batch 340, Loss: 0.2729
Batch 350, Loss: 0.2815
Batch 360, Loss: 0.2744
Batch 370, Loss: 0.2923
Batch 380, Loss: 0.2653
Batch 390, Loss: 0.2584
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.19562530517578 seconds
Epoch 134 accuracy: 70.63%
Batch 10, Loss: 0.2271
Batch 20, Loss: 0.2404
Batch 30, Loss: 0.2298
Batch 40, Loss: 0.2269
Batch 50, Loss: 0.2123
Batch 60, Loss: 0.2248
Batch 70, Loss: 0.2171
Batch 80, Loss: 0.2175
Batch 90, Loss: 0.2209
Batch 100, Loss: 0.2008
Batch 110, Loss: 0.2176
Batch 120, Loss: 0.2322
Batch 130, Loss: 0.2398
Batch 140, Loss: 0.2488
Batch 150, Loss: 0.2329
Batch 160, Loss: 0.2142
Batch 170, Loss: 0.2564
Batch 180, Loss: 0.2249
Batch 190, Loss: 0.2316
Batch 200, Loss: 0.2570
Batch 210, Loss: 0.2506
Batch 220, Loss: 0.2494
Batch 230, Loss: 0.2342
Batch 240, Loss: 0.2318
Batch 250, Loss: 0.2365
Batch 260, Loss: 0.2338
Batch 270, Loss: 0.2474
Batch 280, Loss: 0.2333
Batch 290, Loss: 0.2551
Batch 300, Loss: 0.2747
Batch 310, Loss: 0.2815
Batch 320, Loss: 0.2660
Batch 330, Loss: 0.2829
Batch 340, Loss: 0.2662
Batch 350, Loss: 0.2791
Batch 360, Loss: 0.2707
Batch 370, Loss: 0.2925
Batch 380, Loss: 0.2561
Batch 390, Loss: 0.2949
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.19163179397583 seconds
Epoch 135 accuracy: 71.28%
Batch 10, Loss: 0.2141
Batch 20, Loss: 0.2239
Batch 30, Loss: 0.2063
Batch 40, Loss: 0.2266
Batch 50, Loss: 0.2430
Batch 60, Loss: 0.2073
Batch 70, Loss: 0.2186
Batch 80, Loss: 0.2286
Batch 90, Loss: 0.2262
Batch 100, Loss: 0.2068
Batch 110, Loss: 0.2287
Batch 120, Loss: 0.2210
Batch 130, Loss: 0.2182
Batch 140, Loss: 0.2308
Batch 150, Loss: 0.2204
Batch 160, Loss: 0.2288
Batch 170, Loss: 0.2107
Batch 180, Loss: 0.2071
Batch 190, Loss: 0.2498
Batch 200, Loss: 0.2236
Batch 210, Loss: 0.2485
Batch 220, Loss: 0.2501
Batch 230, Loss: 0.2480
Batch 240, Loss: 0.2569
Batch 250, Loss: 0.2315
Batch 260, Loss: 0.2532
Batch 270, Loss: 0.2469
Batch 280, Loss: 0.2610
Batch 290, Loss: 0.2297
Batch 300, Loss: 0.2226
Batch 310, Loss: 0.2326
Batch 320, Loss: 0.2503
Batch 330, Loss: 0.2680
Batch 340, Loss: 0.2541
Batch 350, Loss: 0.2290
Batch 360, Loss: 0.2342
Batch 370, Loss: 0.2373
Batch 380, Loss: 0.2601
Batch 390, Loss: 0.2798
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.27495288848877 seconds
Epoch 136 accuracy: 71.26%
Batch 10, Loss: 0.2364
Batch 20, Loss: 0.2207
Batch 30, Loss: 0.2224
Batch 40, Loss: 0.2092
Batch 50, Loss: 0.1999
Batch 60, Loss: 0.2201
Batch 70, Loss: 0.2170
Batch 80, Loss: 0.2145
Batch 90, Loss: 0.2100
Batch 100, Loss: 0.2281
Batch 110, Loss: 0.2260
Batch 120, Loss: 0.2347
Batch 130, Loss: 0.2379
Batch 140, Loss: 0.2358
Batch 150, Loss: 0.2219
Batch 160, Loss: 0.2225
Batch 170, Loss: 0.2437
Batch 180, Loss: 0.2376
Batch 190, Loss: 0.2324
Batch 200, Loss: 0.2260
Batch 210, Loss: 0.2331
Batch 220, Loss: 0.2353
Batch 230, Loss: 0.2241
Batch 240, Loss: 0.2364
Batch 250, Loss: 0.2676
Batch 260, Loss: 0.2517
Batch 270, Loss: 0.2494
Batch 280, Loss: 0.2348
Batch 290, Loss: 0.2436
Batch 300, Loss: 0.2472
Batch 310, Loss: 0.2385
Batch 320, Loss: 0.2424
Batch 330, Loss: 0.2465
Batch 340, Loss: 0.2550
Batch 350, Loss: 0.2361
Batch 360, Loss: 0.2460
Batch 370, Loss: 0.2371
Batch 380, Loss: 0.2800
Batch 390, Loss: 0.2586
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.18378520011902 seconds
Epoch 137 accuracy: 70.93%
Batch 10, Loss: 0.2067
Batch 20, Loss: 0.2166
Batch 30, Loss: 0.2158
Batch 40, Loss: 0.2011
Batch 50, Loss: 0.1826
Batch 60, Loss: 0.1971
Batch 70, Loss: 0.2076
Batch 80, Loss: 0.2046
Batch 90, Loss: 0.1952
Batch 100, Loss: 0.1935
Batch 110, Loss: 0.2063
Batch 120, Loss: 0.2162
Batch 130, Loss: 0.2208
Batch 140, Loss: 0.2158
Batch 150, Loss: 0.2036
Batch 160, Loss: 0.2139
Batch 170, Loss: 0.2061
Batch 180, Loss: 0.2164
Batch 190, Loss: 0.2232
Batch 200, Loss: 0.2178
Batch 210, Loss: 0.2191
Batch 220, Loss: 0.2069
Batch 230, Loss: 0.2154
Batch 240, Loss: 0.2007
Batch 250, Loss: 0.2148
Batch 260, Loss: 0.2113
Batch 270, Loss: 0.2165
Batch 280, Loss: 0.2139
Batch 290, Loss: 0.2242
Batch 300, Loss: 0.2152
Batch 310, Loss: 0.2252
Batch 320, Loss: 0.2240
Batch 330, Loss: 0.2203
Batch 340, Loss: 0.2441
Batch 350, Loss: 0.2303
Batch 360, Loss: 0.2248
Batch 370, Loss: 0.2357
Batch 380, Loss: 0.2293
Batch 390, Loss: 0.2127
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.2940833568573 seconds
Epoch 138 accuracy: 72.18%
Batch 10, Loss: 0.2063
Batch 20, Loss: 0.1838
Batch 30, Loss: 0.1841
Batch 40, Loss: 0.1715
Batch 50, Loss: 0.1881
Batch 60, Loss: 0.1935
Batch 70, Loss: 0.2013
Batch 80, Loss: 0.1761
Batch 90, Loss: 0.1985
Batch 100, Loss: 0.2029
Batch 110, Loss: 0.1939
Batch 120, Loss: 0.1847
Batch 130, Loss: 0.1850
Batch 140, Loss: 0.1743
Batch 150, Loss: 0.1884
Batch 160, Loss: 0.2101
Batch 170, Loss: 0.1996
Batch 180, Loss: 0.1993
Batch 190, Loss: 0.2090
Batch 200, Loss: 0.2033
Batch 210, Loss: 0.1981
Batch 220, Loss: 0.2115
Batch 230, Loss: 0.1997
Batch 240, Loss: 0.1992
Batch 250, Loss: 0.2086
Batch 260, Loss: 0.2313
Batch 270, Loss: 0.1977
Batch 280, Loss: 0.2111
Batch 290, Loss: 0.2183
Batch 300, Loss: 0.2264
Batch 310, Loss: 0.2204
Batch 320, Loss: 0.2419
Batch 330, Loss: 0.2222
Batch 340, Loss: 0.2244
Batch 350, Loss: 0.2347
Batch 360, Loss: 0.2313
Batch 370, Loss: 0.2565
Batch 380, Loss: 0.2551
Batch 390, Loss: 0.2478
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.260443210601807 seconds
Epoch 139 accuracy: 71.45%
Batch 10, Loss: 0.2244
Batch 20, Loss: 0.2269
Batch 30, Loss: 0.2043
Batch 40, Loss: 0.2005
Batch 50, Loss: 0.2105
Batch 60, Loss: 0.1759
Batch 70, Loss: 0.1906
Batch 80, Loss: 0.1977
Batch 90, Loss: 0.1992
Batch 100, Loss: 0.2133
Batch 110, Loss: 0.2054
Batch 120, Loss: 0.1942
Batch 130, Loss: 0.1935
Batch 140, Loss: 0.1943
Batch 150, Loss: 0.1903
Batch 160, Loss: 0.2117
Batch 170, Loss: 0.2027
Batch 180, Loss: 0.2180
Batch 190, Loss: 0.2140
Batch 200, Loss: 0.2066
Batch 210, Loss: 0.2218
Batch 220, Loss: 0.2142
Batch 230, Loss: 0.2066
Batch 240, Loss: 0.2276
Batch 250, Loss: 0.2092
Batch 260, Loss: 0.2140
Batch 270, Loss: 0.1911
Batch 280, Loss: 0.2041
Batch 290, Loss: 0.2082
Batch 300, Loss: 0.2334
Batch 310, Loss: 0.2106
Batch 320, Loss: 0.2492
Batch 330, Loss: 0.2369
Batch 340, Loss: 0.2306
Batch 350, Loss: 0.2221
Batch 360, Loss: 0.2091
Batch 370, Loss: 0.2173
Batch 380, Loss: 0.2299
Batch 390, Loss: 0.2212
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.241464614868164 seconds
Epoch 140 accuracy: 73.27%
Batch 10, Loss: 0.1886
Batch 20, Loss: 0.1808
Batch 30, Loss: 0.1820
Batch 40, Loss: 0.1883
Batch 50, Loss: 0.1732
Batch 60, Loss: 0.1898
Batch 70, Loss: 0.1807
Batch 80, Loss: 0.1872
Batch 90, Loss: 0.1798
Batch 100, Loss: 0.1976
Batch 110, Loss: 0.1949
Batch 120, Loss: 0.2062
Batch 130, Loss: 0.1959
Batch 140, Loss: 0.1981
Batch 150, Loss: 0.2025
Batch 160, Loss: 0.1970
Batch 170, Loss: 0.1881
Batch 180, Loss: 0.1916
Batch 190, Loss: 0.1835
Batch 200, Loss: 0.2007
Batch 210, Loss: 0.1996
Batch 220, Loss: 0.1947
Batch 230, Loss: 0.1871
Batch 240, Loss: 0.1897
Batch 250, Loss: 0.2017
Batch 260, Loss: 0.2042
Batch 270, Loss: 0.1960
Batch 280, Loss: 0.1904
Batch 290, Loss: 0.2126
Batch 300, Loss: 0.1878
Batch 310, Loss: 0.2037
Batch 320, Loss: 0.2112
Batch 330, Loss: 0.2014
Batch 340, Loss: 0.2027
Batch 350, Loss: 0.2248
Batch 360, Loss: 0.2021
Batch 370, Loss: 0.2036
Batch 380, Loss: 0.2300
Batch 390, Loss: 0.2277
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.385560274124146 seconds
Epoch 141 accuracy: 72.03%
Batch 10, Loss: 0.1985
Batch 20, Loss: 0.1799
Batch 30, Loss: 0.1873
Batch 40, Loss: 0.1756
Batch 50, Loss: 0.1728
Batch 60, Loss: 0.1770
Batch 70, Loss: 0.1955
Batch 80, Loss: 0.1946
Batch 90, Loss: 0.1831
Batch 100, Loss: 0.1718
Batch 110, Loss: 0.1718
Batch 120, Loss: 0.1912
Batch 130, Loss: 0.1641
Batch 140, Loss: 0.1636
Batch 150, Loss: 0.1827
Batch 160, Loss: 0.1780
Batch 170, Loss: 0.1911
Batch 180, Loss: 0.1935
Batch 190, Loss: 0.1841
Batch 200, Loss: 0.1936
Batch 210, Loss: 0.1794
Batch 220, Loss: 0.1721
Batch 230, Loss: 0.1867
Batch 240, Loss: 0.1834
Batch 250, Loss: 0.1729
Batch 260, Loss: 0.1847
Batch 270, Loss: 0.1856
Batch 280, Loss: 0.2196
Batch 290, Loss: 0.1942
Batch 300, Loss: 0.2173
Batch 310, Loss: 0.2014
Batch 320, Loss: 0.2184
Batch 330, Loss: 0.2161
Batch 340, Loss: 0.2047
Batch 350, Loss: 0.2281
Batch 360, Loss: 0.2285
Batch 370, Loss: 0.2029
Batch 380, Loss: 0.2016
Batch 390, Loss: 0.2123
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.250117301940918 seconds
Epoch 142 accuracy: 72.9%
Batch 10, Loss: 0.1997
Batch 20, Loss: 0.1858
Batch 30, Loss: 0.1911
Batch 40, Loss: 0.1758
Batch 50, Loss: 0.1810
Batch 60, Loss: 0.1762
Batch 70, Loss: 0.1752
Batch 80, Loss: 0.1675
Batch 90, Loss: 0.1775
Batch 100, Loss: 0.1535
Batch 110, Loss: 0.1747
Batch 120, Loss: 0.1581
Batch 130, Loss: 0.1723
Batch 140, Loss: 0.1787
Batch 150, Loss: 0.1766
Batch 160, Loss: 0.1765
Batch 170, Loss: 0.1852
Batch 180, Loss: 0.1632
Batch 190, Loss: 0.1714
Batch 200, Loss: 0.1473
Batch 210, Loss: 0.1770
Batch 220, Loss: 0.1658
Batch 230, Loss: 0.1826
Batch 240, Loss: 0.1595
Batch 250, Loss: 0.1673
Batch 260, Loss: 0.1755
Batch 270, Loss: 0.1942
Batch 280, Loss: 0.1850
Batch 290, Loss: 0.1848
Batch 300, Loss: 0.1893
Batch 310, Loss: 0.2137
Batch 320, Loss: 0.1727
Batch 330, Loss: 0.2073
Batch 340, Loss: 0.1913
Batch 350, Loss: 0.1988
Batch 360, Loss: 0.1995
Batch 370, Loss: 0.1962
Batch 380, Loss: 0.1830
Batch 390, Loss: 0.1945
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.172155141830444 seconds
Epoch 143 accuracy: 72.23%
Batch 10, Loss: 0.1788
Batch 20, Loss: 0.1733
Batch 30, Loss: 0.1684
Batch 40, Loss: 0.1636
Batch 50, Loss: 0.1675
Batch 60, Loss: 0.1624
Batch 70, Loss: 0.1559
Batch 80, Loss: 0.1602
Batch 90, Loss: 0.1666
Batch 100, Loss: 0.1563
Batch 110, Loss: 0.1590
Batch 120, Loss: 0.1769
Batch 130, Loss: 0.1711
Batch 140, Loss: 0.1580
Batch 150, Loss: 0.1587
Batch 160, Loss: 0.1614
Batch 170, Loss: 0.1829
Batch 180, Loss: 0.1701
Batch 190, Loss: 0.1771
Batch 200, Loss: 0.1853
Batch 210, Loss: 0.1919
Batch 220, Loss: 0.1885
Batch 230, Loss: 0.1820
Batch 240, Loss: 0.1721
Batch 250, Loss: 0.1663
Batch 260, Loss: 0.1896
Batch 270, Loss: 0.1802
Batch 280, Loss: 0.1827
Batch 290, Loss: 0.1795
Batch 300, Loss: 0.1944
Batch 310, Loss: 0.1900
Batch 320, Loss: 0.1997
Batch 330, Loss: 0.1862
Batch 340, Loss: 0.1795
Batch 350, Loss: 0.1773
Batch 360, Loss: 0.1966
Batch 370, Loss: 0.1779
Batch 380, Loss: 0.1901
Batch 390, Loss: 0.1916
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.10066866874695 seconds
Epoch 144 accuracy: 70.09%
Batch 10, Loss: 0.1570
Batch 20, Loss: 0.1568
Batch 30, Loss: 0.1702
Batch 40, Loss: 0.1730
Batch 50, Loss: 0.1630
Batch 60, Loss: 0.1693
Batch 70, Loss: 0.1909
Batch 80, Loss: 0.1626
Batch 90, Loss: 0.1613
Batch 100, Loss: 0.1581
Batch 110, Loss: 0.1572
Batch 120, Loss: 0.1616
Batch 130, Loss: 0.1555
Batch 140, Loss: 0.1581
Batch 150, Loss: 0.1553
Batch 160, Loss: 0.1562
Batch 170, Loss: 0.1545
Batch 180, Loss: 0.1727
Batch 190, Loss: 0.1679
Batch 200, Loss: 0.1580
Batch 210, Loss: 0.1681
Batch 220, Loss: 0.1647
Batch 230, Loss: 0.1807
Batch 240, Loss: 0.1716
Batch 250, Loss: 0.1609
Batch 260, Loss: 0.1831
Batch 270, Loss: 0.1982
Batch 280, Loss: 0.1689
Batch 290, Loss: 0.1647
Batch 300, Loss: 0.1648
Batch 310, Loss: 0.1833
Batch 320, Loss: 0.1774
Batch 330, Loss: 0.1757
Batch 340, Loss: 0.1735
Batch 350, Loss: 0.1599
Batch 360, Loss: 0.1632
Batch 370, Loss: 0.1947
Batch 380, Loss: 0.1812
Batch 390, Loss: 0.2108
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.06341552734375 seconds
Epoch 145 accuracy: 72.41%
Batch 10, Loss: 0.1560
Batch 20, Loss: 0.1606
Batch 30, Loss: 0.1591
Batch 40, Loss: 0.1558
Batch 50, Loss: 0.1528
Batch 60, Loss: 0.1438
Batch 70, Loss: 0.1500
Batch 80, Loss: 0.1516
Batch 90, Loss: 0.1488
Batch 100, Loss: 0.1412
Batch 110, Loss: 0.1472
Batch 120, Loss: 0.1547
Batch 130, Loss: 0.1615
Batch 140, Loss: 0.1553
Batch 150, Loss: 0.1578
Batch 160, Loss: 0.1676
Batch 170, Loss: 0.1501
Batch 180, Loss: 0.1496
Batch 190, Loss: 0.1395
Batch 200, Loss: 0.1603
Batch 210, Loss: 0.1462
Batch 220, Loss: 0.1545
Batch 230, Loss: 0.1385
Batch 240, Loss: 0.1496
Batch 250, Loss: 0.1515
Batch 260, Loss: 0.1532
Batch 270, Loss: 0.1661
Batch 280, Loss: 0.1731
Batch 290, Loss: 0.1583
Batch 300, Loss: 0.1826
Batch 310, Loss: 0.1550
Batch 320, Loss: 0.1558
Batch 330, Loss: 0.1597
Batch 340, Loss: 0.1700
Batch 350, Loss: 0.1715
Batch 360, Loss: 0.1725
Batch 370, Loss: 0.1639
Batch 380, Loss: 0.1672
Batch 390, Loss: 0.1771
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.03405499458313 seconds
Epoch 146 accuracy: 73.19%
Batch 10, Loss: 0.1549
Batch 20, Loss: 0.1525
Batch 30, Loss: 0.1317
Batch 40, Loss: 0.1460
Batch 50, Loss: 0.1376
Batch 60, Loss: 0.1518
Batch 70, Loss: 0.1401
Batch 80, Loss: 0.1347
Batch 90, Loss: 0.1450
Batch 100, Loss: 0.1354
Batch 110, Loss: 0.1443
Batch 120, Loss: 0.1434
Batch 130, Loss: 0.1439
Batch 140, Loss: 0.1437
Batch 150, Loss: 0.1451
Batch 160, Loss: 0.1385
Batch 170, Loss: 0.1435
Batch 180, Loss: 0.1366
Batch 190, Loss: 0.1588
Batch 200, Loss: 0.1527
Batch 210, Loss: 0.1584
Batch 220, Loss: 0.1488
Batch 230, Loss: 0.1546
Batch 240, Loss: 0.1501
Batch 250, Loss: 0.1491
Batch 260, Loss: 0.1431
Batch 270, Loss: 0.1476
Batch 280, Loss: 0.1347
Batch 290, Loss: 0.1496
Batch 300, Loss: 0.1519
Batch 310, Loss: 0.1596
Batch 320, Loss: 0.1724
Batch 330, Loss: 0.1578
Batch 340, Loss: 0.1747
Batch 350, Loss: 0.1594
Batch 360, Loss: 0.1734
Batch 370, Loss: 0.1634
Batch 380, Loss: 0.1701
Batch 390, Loss: 0.1742
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.08957529067993 seconds
Epoch 147 accuracy: 73.14%
Batch 10, Loss: 0.1562
Batch 20, Loss: 0.1406
Batch 30, Loss: 0.1365
Batch 40, Loss: 0.1375
Batch 50, Loss: 0.1443
Batch 60, Loss: 0.1421
Batch 70, Loss: 0.1294
Batch 80, Loss: 0.1536
Batch 90, Loss: 0.1324
Batch 100, Loss: 0.1520
Batch 110, Loss: 0.1386
Batch 120, Loss: 0.1356
Batch 130, Loss: 0.1437
Batch 140, Loss: 0.1422
Batch 150, Loss: 0.1315
Batch 160, Loss: 0.1431
Batch 170, Loss: 0.1470
Batch 180, Loss: 0.1316
Batch 190, Loss: 0.1418
Batch 200, Loss: 0.1406
Batch 210, Loss: 0.1483
Batch 220, Loss: 0.1550
Batch 230, Loss: 0.1532
Batch 240, Loss: 0.1419
Batch 250, Loss: 0.1620
Batch 260, Loss: 0.1557
Batch 270, Loss: 0.1486
Batch 280, Loss: 0.1465
Batch 290, Loss: 0.1425
Batch 300, Loss: 0.1551
Batch 310, Loss: 0.1687
Batch 320, Loss: 0.1556
Batch 330, Loss: 0.1645
Batch 340, Loss: 0.1686
Batch 350, Loss: 0.1649
Batch 360, Loss: 0.1642
Batch 370, Loss: 0.1500
Batch 380, Loss: 0.1531
Batch 390, Loss: 0.1626
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.06928014755249 seconds
Epoch 148 accuracy: 73.87%
Batch 10, Loss: 0.1421
Batch 20, Loss: 0.1358
Batch 30, Loss: 0.1310
Batch 40, Loss: 0.1272
Batch 50, Loss: 0.1357
Batch 60, Loss: 0.1221
Batch 70, Loss: 0.1279
Batch 80, Loss: 0.1357
Batch 90, Loss: 0.1368
Batch 100, Loss: 0.1421
Batch 110, Loss: 0.1380
Batch 120, Loss: 0.1550
Batch 130, Loss: 0.1376
Batch 140, Loss: 0.1579
Batch 150, Loss: 0.1286
Batch 160, Loss: 0.1374
Batch 170, Loss: 0.1456
Batch 180, Loss: 0.1507
Batch 190, Loss: 0.1316
Batch 200, Loss: 0.1358
Batch 210, Loss: 0.1462
Batch 220, Loss: 0.1353
Batch 230, Loss: 0.1283
Batch 240, Loss: 0.1435
Batch 250, Loss: 0.1360
Batch 260, Loss: 0.1204
Batch 270, Loss: 0.1398
Batch 280, Loss: 0.1260
Batch 290, Loss: 0.1416
Batch 300, Loss: 0.1487
Batch 310, Loss: 0.1397
Batch 320, Loss: 0.1459
Batch 330, Loss: 0.1454
Batch 340, Loss: 0.1449
Batch 350, Loss: 0.1460
Batch 360, Loss: 0.1374
Batch 370, Loss: 0.1389
Batch 380, Loss: 0.1567
Batch 390, Loss: 0.1593
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.199402332305908 seconds
Epoch 149 accuracy: 74.09%
Batch 10, Loss: 0.1299
Batch 20, Loss: 0.1320
Batch 30, Loss: 0.1215
Batch 40, Loss: 0.1283
Batch 50, Loss: 0.1199
Batch 60, Loss: 0.1097
Batch 70, Loss: 0.1195
Batch 80, Loss: 0.1171
Batch 90, Loss: 0.1248
Batch 100, Loss: 0.1284
Batch 110, Loss: 0.1282
Batch 120, Loss: 0.1345
Batch 130, Loss: 0.1113
Batch 140, Loss: 0.1353
Batch 150, Loss: 0.1284
Batch 160, Loss: 0.1143
Batch 170, Loss: 0.1329
Batch 180, Loss: 0.1259
Batch 190, Loss: 0.1335
Batch 200, Loss: 0.1166
Batch 210, Loss: 0.1255
Batch 220, Loss: 0.1299
Batch 230, Loss: 0.1308
Batch 240, Loss: 0.1429
Batch 250, Loss: 0.1376
Batch 260, Loss: 0.1398
Batch 270, Loss: 0.1354
Batch 280, Loss: 0.1491
Batch 290, Loss: 0.1377
Batch 300, Loss: 0.1389
Batch 310, Loss: 0.1437
Batch 320, Loss: 0.1356
Batch 330, Loss: 0.1354
Batch 340, Loss: 0.1419
Batch 350, Loss: 0.1577
Batch 360, Loss: 0.1520
Batch 370, Loss: 0.1472
Batch 380, Loss: 0.1444
Batch 390, Loss: 0.1392
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.221027612686157 seconds
Epoch 150 accuracy: 74.03%
Batch 10, Loss: 0.1311
Batch 20, Loss: 0.1152
Batch 30, Loss: 0.1195
Batch 40, Loss: 0.1328
Batch 50, Loss: 0.1322
Batch 60, Loss: 0.1348
Batch 70, Loss: 0.1227
Batch 80, Loss: 0.1102
Batch 90, Loss: 0.1121
Batch 100, Loss: 0.1286
Batch 110, Loss: 0.1178
Batch 120, Loss: 0.1232
Batch 130, Loss: 0.1236
Batch 140, Loss: 0.1330
Batch 150, Loss: 0.1267
Batch 160, Loss: 0.1135
Batch 170, Loss: 0.1235
Batch 180, Loss: 0.1101
Batch 190, Loss: 0.1172
Batch 200, Loss: 0.1257
Batch 210, Loss: 0.1230
Batch 220, Loss: 0.1199
Batch 230, Loss: 0.1239
Batch 240, Loss: 0.1343
Batch 250, Loss: 0.1257
Batch 260, Loss: 0.1251
Batch 270, Loss: 0.1420
Batch 280, Loss: 0.1174
Batch 290, Loss: 0.1386
Batch 300, Loss: 0.1246
Batch 310, Loss: 0.1189
Batch 320, Loss: 0.1301
Batch 330, Loss: 0.1356
Batch 340, Loss: 0.1281
Batch 350, Loss: 0.1351
Batch 360, Loss: 0.1437
Batch 370, Loss: 0.1325
Batch 380, Loss: 0.1522
Batch 390, Loss: 0.1358
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.11405086517334 seconds
Epoch 151 accuracy: 74.44%
Batch 10, Loss: 0.1209
Batch 20, Loss: 0.1250
Batch 30, Loss: 0.1134
Batch 40, Loss: 0.1161
Batch 50, Loss: 0.1067
Batch 60, Loss: 0.1185
Batch 70, Loss: 0.1103
Batch 80, Loss: 0.1060
Batch 90, Loss: 0.1218
Batch 100, Loss: 0.1117
Batch 110, Loss: 0.1199
Batch 120, Loss: 0.1190
Batch 130, Loss: 0.1211
Batch 140, Loss: 0.1225
Batch 150, Loss: 0.1147
Batch 160, Loss: 0.1245
Batch 170, Loss: 0.1159
Batch 180, Loss: 0.1153
Batch 190, Loss: 0.1241
Batch 200, Loss: 0.1192
Batch 210, Loss: 0.1150
Batch 220, Loss: 0.1172
Batch 230, Loss: 0.1147
Batch 240, Loss: 0.1120
Batch 250, Loss: 0.1133
Batch 260, Loss: 0.1161
Batch 270, Loss: 0.1389
Batch 280, Loss: 0.1170
Batch 290, Loss: 0.1230
Batch 300, Loss: 0.1120
Batch 310, Loss: 0.1148
Batch 320, Loss: 0.1282
Batch 330, Loss: 0.1092
Batch 340, Loss: 0.1235
Batch 350, Loss: 0.1250
Batch 360, Loss: 0.1285
Batch 370, Loss: 0.1324
Batch 380, Loss: 0.1282
Batch 390, Loss: 0.1248
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.25448751449585 seconds
Epoch 152 accuracy: 73.78%
Batch 10, Loss: 0.1227
Batch 20, Loss: 0.1208
Batch 30, Loss: 0.1175
Batch 40, Loss: 0.1096
Batch 50, Loss: 0.1060
Batch 60, Loss: 0.1073
Batch 70, Loss: 0.1063
Batch 80, Loss: 0.1171
Batch 90, Loss: 0.1038
Batch 100, Loss: 0.1085
Batch 110, Loss: 0.1069
Batch 120, Loss: 0.1030
Batch 130, Loss: 0.1044
Batch 140, Loss: 0.1250
Batch 150, Loss: 0.1143
Batch 160, Loss: 0.0959
Batch 170, Loss: 0.0930
Batch 180, Loss: 0.1077
Batch 190, Loss: 0.1043
Batch 200, Loss: 0.1075
Batch 210, Loss: 0.0996
Batch 220, Loss: 0.1058
Batch 230, Loss: 0.1116
Batch 240, Loss: 0.1129
Batch 250, Loss: 0.1090
Batch 260, Loss: 0.1119
Batch 270, Loss: 0.1154
Batch 280, Loss: 0.1135
Batch 290, Loss: 0.1129
Batch 300, Loss: 0.1160
Batch 310, Loss: 0.1155
Batch 320, Loss: 0.1076
Batch 330, Loss: 0.1123
Batch 340, Loss: 0.1164
Batch 350, Loss: 0.1291
Batch 360, Loss: 0.1197
Batch 370, Loss: 0.1053
Batch 380, Loss: 0.1098
Batch 390, Loss: 0.1247
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.213330507278442 seconds
Epoch 153 accuracy: 74.76%
Batch 10, Loss: 0.1118
Batch 20, Loss: 0.1069
Batch 30, Loss: 0.1070
Batch 40, Loss: 0.1013
Batch 50, Loss: 0.1019
Batch 60, Loss: 0.1009
Batch 70, Loss: 0.1022
Batch 80, Loss: 0.0947
Batch 90, Loss: 0.1067
Batch 100, Loss: 0.1093
Batch 110, Loss: 0.0980
Batch 120, Loss: 0.1041
Batch 130, Loss: 0.0980
Batch 140, Loss: 0.1064
Batch 150, Loss: 0.0997
Batch 160, Loss: 0.1000
Batch 170, Loss: 0.1030
Batch 180, Loss: 0.1026
Batch 190, Loss: 0.1098
Batch 200, Loss: 0.1240
Batch 210, Loss: 0.1057
Batch 220, Loss: 0.1051
Batch 230, Loss: 0.1157
Batch 240, Loss: 0.1122
Batch 250, Loss: 0.1129
Batch 260, Loss: 0.1059
Batch 270, Loss: 0.1060
Batch 280, Loss: 0.0996
Batch 290, Loss: 0.1085
Batch 300, Loss: 0.1170
Batch 310, Loss: 0.1073
Batch 320, Loss: 0.1170
Batch 330, Loss: 0.1124
Batch 340, Loss: 0.1197
Batch 350, Loss: 0.1203
Batch 360, Loss: 0.1027
Batch 370, Loss: 0.1039
Batch 380, Loss: 0.1041
Batch 390, Loss: 0.1232
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.234214544296265 seconds
Epoch 154 accuracy: 75.42%
Batch 10, Loss: 0.1092
Batch 20, Loss: 0.1002
Batch 30, Loss: 0.0956
Batch 40, Loss: 0.0963
Batch 50, Loss: 0.0982
Batch 60, Loss: 0.0996
Batch 70, Loss: 0.1076
Batch 80, Loss: 0.1039
Batch 90, Loss: 0.1049
Batch 100, Loss: 0.1013
Batch 110, Loss: 0.0939
Batch 120, Loss: 0.1063
Batch 130, Loss: 0.0964
Batch 140, Loss: 0.0961
Batch 150, Loss: 0.0949
Batch 160, Loss: 0.1038
Batch 170, Loss: 0.0987
Batch 180, Loss: 0.1029
Batch 190, Loss: 0.1171
Batch 200, Loss: 0.1047
Batch 210, Loss: 0.0961
Batch 220, Loss: 0.0991
Batch 230, Loss: 0.0964
Batch 240, Loss: 0.0941
Batch 250, Loss: 0.1048
Batch 260, Loss: 0.0966
Batch 270, Loss: 0.0897
Batch 280, Loss: 0.0958
Batch 290, Loss: 0.0972
Batch 300, Loss: 0.0998
Batch 310, Loss: 0.1075
Batch 320, Loss: 0.1093
Batch 330, Loss: 0.1001
Batch 340, Loss: 0.0995
Batch 350, Loss: 0.1065
Batch 360, Loss: 0.0959
Batch 370, Loss: 0.0940
Batch 380, Loss: 0.1042
Batch 390, Loss: 0.1068
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.204943656921387 seconds
Epoch 155 accuracy: 75.4%
Batch 10, Loss: 0.0959
Batch 20, Loss: 0.0971
Batch 30, Loss: 0.0921
Batch 40, Loss: 0.0854
Batch 50, Loss: 0.0886
Batch 60, Loss: 0.0835
Batch 70, Loss: 0.1038
Batch 80, Loss: 0.0886
Batch 90, Loss: 0.0930
Batch 100, Loss: 0.0893
Batch 110, Loss: 0.0805
Batch 120, Loss: 0.0935
Batch 130, Loss: 0.0929
Batch 140, Loss: 0.0874
Batch 150, Loss: 0.0999
Batch 160, Loss: 0.0969
Batch 170, Loss: 0.1045
Batch 180, Loss: 0.0955
Batch 190, Loss: 0.1006
Batch 200, Loss: 0.0963
Batch 210, Loss: 0.0948
Batch 220, Loss: 0.0998
Batch 230, Loss: 0.0939
Batch 240, Loss: 0.0973
Batch 250, Loss: 0.0888
Batch 260, Loss: 0.0946
Batch 270, Loss: 0.0903
Batch 280, Loss: 0.0949
Batch 290, Loss: 0.1022
Batch 300, Loss: 0.1055
Batch 310, Loss: 0.1038
Batch 320, Loss: 0.1055
Batch 330, Loss: 0.1044
Batch 340, Loss: 0.0914
Batch 350, Loss: 0.0963
Batch 360, Loss: 0.1068
Batch 370, Loss: 0.1000
Batch 380, Loss: 0.1073
Batch 390, Loss: 0.1050
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.278563022613525 seconds
Epoch 156 accuracy: 75.59%
Batch 10, Loss: 0.0921
Batch 20, Loss: 0.0952
Batch 30, Loss: 0.0859
Batch 40, Loss: 0.0906
Batch 50, Loss: 0.0868
Batch 60, Loss: 0.0834
Batch 70, Loss: 0.0811
Batch 80, Loss: 0.0883
Batch 90, Loss: 0.0879
Batch 100, Loss: 0.0924
Batch 110, Loss: 0.0897
Batch 120, Loss: 0.0931
Batch 130, Loss: 0.1017
Batch 140, Loss: 0.0876
Batch 150, Loss: 0.0922
Batch 160, Loss: 0.0990
Batch 170, Loss: 0.0987
Batch 180, Loss: 0.0888
Batch 190, Loss: 0.0977
Batch 200, Loss: 0.0912
Batch 210, Loss: 0.0921
Batch 220, Loss: 0.0944
Batch 230, Loss: 0.0922
Batch 240, Loss: 0.0840
Batch 250, Loss: 0.0957
Batch 260, Loss: 0.0926
Batch 270, Loss: 0.0945
Batch 280, Loss: 0.0862
Batch 290, Loss: 0.1000
Batch 300, Loss: 0.0808
Batch 310, Loss: 0.0886
Batch 320, Loss: 0.0970
Batch 330, Loss: 0.0898
Batch 340, Loss: 0.0945
Batch 350, Loss: 0.1010
Batch 360, Loss: 0.0903
Batch 370, Loss: 0.0958
Batch 380, Loss: 0.0880
Batch 390, Loss: 0.0905
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.218440055847168 seconds
Epoch 157 accuracy: 75.72%
Batch 10, Loss: 0.0915
Batch 20, Loss: 0.0854
Batch 30, Loss: 0.0773
Batch 40, Loss: 0.0809
Batch 50, Loss: 0.0770
Batch 60, Loss: 0.0818
Batch 70, Loss: 0.0841
Batch 80, Loss: 0.0851
Batch 90, Loss: 0.0847
Batch 100, Loss: 0.0840
Batch 110, Loss: 0.0819
Batch 120, Loss: 0.0910
Batch 130, Loss: 0.0761
Batch 140, Loss: 0.0852
Batch 150, Loss: 0.0700
Batch 160, Loss: 0.0784
Batch 170, Loss: 0.0941
Batch 180, Loss: 0.0847
Batch 190, Loss: 0.0843
Batch 200, Loss: 0.0870
Batch 210, Loss: 0.0824
Batch 220, Loss: 0.0903
Batch 230, Loss: 0.0888
Batch 240, Loss: 0.0834
Batch 250, Loss: 0.0910
Batch 260, Loss: 0.0833
Batch 270, Loss: 0.0900
Batch 280, Loss: 0.0855
Batch 290, Loss: 0.0805
Batch 300, Loss: 0.0881
Batch 310, Loss: 0.0775
Batch 320, Loss: 0.0802
Batch 330, Loss: 0.0864
Batch 340, Loss: 0.0864
Batch 350, Loss: 0.0861
Batch 360, Loss: 0.0935
Batch 370, Loss: 0.0783
Batch 380, Loss: 0.0866
Batch 390, Loss: 0.0879
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.225898265838623 seconds
Epoch 158 accuracy: 75.57%
Batch 10, Loss: 0.0771
Batch 20, Loss: 0.0789
Batch 30, Loss: 0.0704
Batch 40, Loss: 0.0806
Batch 50, Loss: 0.0761
Batch 60, Loss: 0.0781
Batch 70, Loss: 0.0713
Batch 80, Loss: 0.0838
Batch 90, Loss: 0.0784
Batch 100, Loss: 0.0766
Batch 110, Loss: 0.0768
Batch 120, Loss: 0.0796
Batch 130, Loss: 0.0795
Batch 140, Loss: 0.0779
Batch 150, Loss: 0.0837
Batch 160, Loss: 0.0764
Batch 170, Loss: 0.0721
Batch 180, Loss: 0.0801
Batch 190, Loss: 0.0747
Batch 200, Loss: 0.0686
Batch 210, Loss: 0.0778
Batch 220, Loss: 0.0821
Batch 230, Loss: 0.0758
Batch 240, Loss: 0.0790
Batch 250, Loss: 0.0819
Batch 260, Loss: 0.0722
Batch 270, Loss: 0.0881
Batch 280, Loss: 0.0752
Batch 290, Loss: 0.0694
Batch 300, Loss: 0.0759
Batch 310, Loss: 0.0818
Batch 320, Loss: 0.0750
Batch 330, Loss: 0.0790
Batch 340, Loss: 0.0786
Batch 350, Loss: 0.0882
Batch 360, Loss: 0.0788
Batch 370, Loss: 0.0908
Batch 380, Loss: 0.0801
Batch 390, Loss: 0.0794
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.234362602233887 seconds
Epoch 159 accuracy: 76.43%
Batch 10, Loss: 0.0757
Batch 20, Loss: 0.0772
Batch 30, Loss: 0.0701
Batch 40, Loss: 0.0723
Batch 50, Loss: 0.0664
Batch 60, Loss: 0.0674
Batch 70, Loss: 0.0799
Batch 80, Loss: 0.0771
Batch 90, Loss: 0.0772
Batch 100, Loss: 0.0697
Batch 110, Loss: 0.0667
Batch 120, Loss: 0.0658
Batch 130, Loss: 0.0708
Batch 140, Loss: 0.0641
Batch 150, Loss: 0.0748
Batch 160, Loss: 0.0785
Batch 170, Loss: 0.0715
Batch 180, Loss: 0.0836
Batch 190, Loss: 0.0743
Batch 200, Loss: 0.0760
Batch 210, Loss: 0.0783
Batch 220, Loss: 0.0701
Batch 230, Loss: 0.0793
Batch 240, Loss: 0.0764
Batch 250, Loss: 0.0766
Batch 260, Loss: 0.0857
Batch 270, Loss: 0.0720
Batch 280, Loss: 0.0778
Batch 290, Loss: 0.0743
Batch 300, Loss: 0.0785
Batch 310, Loss: 0.0773
Batch 320, Loss: 0.0850
Batch 330, Loss: 0.0786
Batch 340, Loss: 0.0721
Batch 350, Loss: 0.0749
Batch 360, Loss: 0.0779
Batch 370, Loss: 0.0784
Batch 380, Loss: 0.0725
Batch 390, Loss: 0.0772
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.152338981628418 seconds
Epoch 160 accuracy: 75.95%
Batch 10, Loss: 0.0657
Batch 20, Loss: 0.0738
Batch 30, Loss: 0.0664
Batch 40, Loss: 0.0768
Batch 50, Loss: 0.0655
Batch 60, Loss: 0.0629
Batch 70, Loss: 0.0739
Batch 80, Loss: 0.0650
Batch 90, Loss: 0.0704
Batch 100, Loss: 0.0677
Batch 110, Loss: 0.0727
Batch 120, Loss: 0.0708
Batch 130, Loss: 0.0661
Batch 140, Loss: 0.0653
Batch 150, Loss: 0.0752
Batch 160, Loss: 0.0752
Batch 170, Loss: 0.0637
Batch 180, Loss: 0.0696
Batch 190, Loss: 0.0766
Batch 200, Loss: 0.0674
Batch 210, Loss: 0.0754
Batch 220, Loss: 0.0772
Batch 230, Loss: 0.0864
Batch 240, Loss: 0.0731
Batch 250, Loss: 0.0661
Batch 260, Loss: 0.0725
Batch 270, Loss: 0.0713
Batch 280, Loss: 0.0755
Batch 290, Loss: 0.0710
Batch 300, Loss: 0.0750
Batch 310, Loss: 0.0726
Batch 320, Loss: 0.0759
Batch 330, Loss: 0.0716
Batch 340, Loss: 0.0724
Batch 350, Loss: 0.0636
Batch 360, Loss: 0.0673
Batch 370, Loss: 0.0731
Batch 380, Loss: 0.0814
Batch 390, Loss: 0.0826
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.171675443649292 seconds
Epoch 161 accuracy: 76.76%
Batch 10, Loss: 0.0662
Batch 20, Loss: 0.0611
Batch 30, Loss: 0.0648
Batch 40, Loss: 0.0664
Batch 50, Loss: 0.0669
Batch 60, Loss: 0.0639
Batch 70, Loss: 0.0636
Batch 80, Loss: 0.0697
Batch 90, Loss: 0.0683
Batch 100, Loss: 0.0644
Batch 110, Loss: 0.0660
Batch 120, Loss: 0.0646
Batch 130, Loss: 0.0739
Batch 140, Loss: 0.0663
Batch 150, Loss: 0.0671
Batch 160, Loss: 0.0733
Batch 170, Loss: 0.0655
Batch 180, Loss: 0.0585
Batch 190, Loss: 0.0745
Batch 200, Loss: 0.0654
Batch 210, Loss: 0.0591
Batch 220, Loss: 0.0715
Batch 230, Loss: 0.0630
Batch 240, Loss: 0.0738
Batch 250, Loss: 0.0675
Batch 260, Loss: 0.0663
Batch 270, Loss: 0.0648
Batch 280, Loss: 0.0656
Batch 290, Loss: 0.0650
Batch 300, Loss: 0.0697
Batch 310, Loss: 0.0697
Batch 320, Loss: 0.0641
Batch 330, Loss: 0.0666
Batch 340, Loss: 0.0696
Batch 350, Loss: 0.0624
Batch 360, Loss: 0.0720
Batch 370, Loss: 0.0661
Batch 380, Loss: 0.0622
Batch 390, Loss: 0.0743
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.217109441757202 seconds
Epoch 162 accuracy: 76.34%
Batch 10, Loss: 0.0607
Batch 20, Loss: 0.0701
Batch 30, Loss: 0.0607
Batch 40, Loss: 0.0641
Batch 50, Loss: 0.0614
Batch 60, Loss: 0.0621
Batch 70, Loss: 0.0566
Batch 80, Loss: 0.0598
Batch 90, Loss: 0.0596
Batch 100, Loss: 0.0598
Batch 110, Loss: 0.0617
Batch 120, Loss: 0.0637
Batch 130, Loss: 0.0573
Batch 140, Loss: 0.0583
Batch 150, Loss: 0.0547
Batch 160, Loss: 0.0562
Batch 170, Loss: 0.0633
Batch 180, Loss: 0.0604
Batch 190, Loss: 0.0676
Batch 200, Loss: 0.0589
Batch 210, Loss: 0.0622
Batch 220, Loss: 0.0544
Batch 230, Loss: 0.0571
Batch 240, Loss: 0.0647
Batch 250, Loss: 0.0577
Batch 260, Loss: 0.0691
Batch 270, Loss: 0.0653
Batch 280, Loss: 0.0591
Batch 290, Loss: 0.0673
Batch 300, Loss: 0.0618
Batch 310, Loss: 0.0614
Batch 320, Loss: 0.0629
Batch 330, Loss: 0.0699
Batch 340, Loss: 0.0589
Batch 350, Loss: 0.0674
Batch 360, Loss: 0.0617
Batch 370, Loss: 0.0650
Batch 380, Loss: 0.0642
Batch 390, Loss: 0.0688
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.12013077735901 seconds
Epoch 163 accuracy: 77.04%
Batch 10, Loss: 0.0577
Batch 20, Loss: 0.0627
Batch 30, Loss: 0.0556
Batch 40, Loss: 0.0560
Batch 50, Loss: 0.0547
Batch 60, Loss: 0.0602
Batch 70, Loss: 0.0509
Batch 80, Loss: 0.0498
Batch 90, Loss: 0.0606
Batch 100, Loss: 0.0570
Batch 110, Loss: 0.0575
Batch 120, Loss: 0.0603
Batch 130, Loss: 0.0528
Batch 140, Loss: 0.0542
Batch 150, Loss: 0.0544
Batch 160, Loss: 0.0624
Batch 170, Loss: 0.0518
Batch 180, Loss: 0.0575
Batch 190, Loss: 0.0575
Batch 200, Loss: 0.0617
Batch 210, Loss: 0.0630
Batch 220, Loss: 0.0570
Batch 230, Loss: 0.0553
Batch 240, Loss: 0.0605
Batch 250, Loss: 0.0579
Batch 260, Loss: 0.0594
Batch 270, Loss: 0.0610
Batch 280, Loss: 0.0569
Batch 290, Loss: 0.0582
Batch 300, Loss: 0.0631
Batch 310, Loss: 0.0755
Batch 320, Loss: 0.0611
Batch 330, Loss: 0.0655
Batch 340, Loss: 0.0629
Batch 350, Loss: 0.0584
Batch 360, Loss: 0.0620
Batch 370, Loss: 0.0552
Batch 380, Loss: 0.0609
Batch 390, Loss: 0.0592
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.06735134124756 seconds
Epoch 164 accuracy: 77.04%
Batch 10, Loss: 0.0545
Batch 20, Loss: 0.0565
Batch 30, Loss: 0.0650
Batch 40, Loss: 0.0553
Batch 50, Loss: 0.0556
Batch 60, Loss: 0.0544
Batch 70, Loss: 0.0497
Batch 80, Loss: 0.0553
Batch 90, Loss: 0.0608
Batch 100, Loss: 0.0526
Batch 110, Loss: 0.0612
Batch 120, Loss: 0.0575
Batch 130, Loss: 0.0595
Batch 140, Loss: 0.0591
Batch 150, Loss: 0.0543
Batch 160, Loss: 0.0581
Batch 170, Loss: 0.0553
Batch 180, Loss: 0.0599
Batch 190, Loss: 0.0522
Batch 200, Loss: 0.0605
Batch 210, Loss: 0.0500
Batch 220, Loss: 0.0503
Batch 230, Loss: 0.0594
Batch 240, Loss: 0.0562
Batch 250, Loss: 0.0573
Batch 260, Loss: 0.0585
Batch 270, Loss: 0.0528
Batch 280, Loss: 0.0536
Batch 290, Loss: 0.0554
Batch 300, Loss: 0.0522
Batch 310, Loss: 0.0531
Batch 320, Loss: 0.0515
Batch 330, Loss: 0.0466
Batch 340, Loss: 0.0587
Batch 350, Loss: 0.0576
Batch 360, Loss: 0.0561
Batch 370, Loss: 0.0549
Batch 380, Loss: 0.0531
Batch 390, Loss: 0.0565
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.05316162109375 seconds
Epoch 165 accuracy: 77.49%
Batch 10, Loss: 0.0468
Batch 20, Loss: 0.0472
Batch 30, Loss: 0.0483
Batch 40, Loss: 0.0461
Batch 50, Loss: 0.0495
Batch 60, Loss: 0.0476
Batch 70, Loss: 0.0481
Batch 80, Loss: 0.0499
Batch 90, Loss: 0.0464
Batch 100, Loss: 0.0458
Batch 110, Loss: 0.0563
Batch 120, Loss: 0.0484
Batch 130, Loss: 0.0474
Batch 140, Loss: 0.0523
Batch 150, Loss: 0.0531
Batch 160, Loss: 0.0566
Batch 170, Loss: 0.0555
Batch 180, Loss: 0.0574
Batch 190, Loss: 0.0506
Batch 200, Loss: 0.0522
Batch 210, Loss: 0.0483
Batch 220, Loss: 0.0588
Batch 230, Loss: 0.0586
Batch 240, Loss: 0.0582
Batch 250, Loss: 0.0522
Batch 260, Loss: 0.0465
Batch 270, Loss: 0.0504
Batch 280, Loss: 0.0574
Batch 290, Loss: 0.0591
Batch 300, Loss: 0.0528
Batch 310, Loss: 0.0547
Batch 320, Loss: 0.0515
Batch 330, Loss: 0.0510
Batch 340, Loss: 0.0497
Batch 350, Loss: 0.0530
Batch 360, Loss: 0.0534
Batch 370, Loss: 0.0546
Batch 380, Loss: 0.0532
Batch 390, Loss: 0.0552
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.12688708305359 seconds
Epoch 166 accuracy: 77.84%
Batch 10, Loss: 0.0465
Batch 20, Loss: 0.0520
Batch 30, Loss: 0.0462
Batch 40, Loss: 0.0491
Batch 50, Loss: 0.0499
Batch 60, Loss: 0.0481
Batch 70, Loss: 0.0457
Batch 80, Loss: 0.0506
Batch 90, Loss: 0.0518
Batch 100, Loss: 0.0479
Batch 110, Loss: 0.0450
Batch 120, Loss: 0.0514
Batch 130, Loss: 0.0477
Batch 140, Loss: 0.0444
Batch 150, Loss: 0.0480
Batch 160, Loss: 0.0465
Batch 170, Loss: 0.0521
Batch 180, Loss: 0.0462
Batch 190, Loss: 0.0541
Batch 200, Loss: 0.0434
Batch 210, Loss: 0.0563
Batch 220, Loss: 0.0511
Batch 230, Loss: 0.0531
Batch 240, Loss: 0.0469
Batch 250, Loss: 0.0609
Batch 260, Loss: 0.0485
Batch 270, Loss: 0.0520
Batch 280, Loss: 0.0444
Batch 290, Loss: 0.0490
Batch 300, Loss: 0.0459
Batch 310, Loss: 0.0515
Batch 320, Loss: 0.0496
Batch 330, Loss: 0.0517
Batch 340, Loss: 0.0572
Batch 350, Loss: 0.0543
Batch 360, Loss: 0.0521
Batch 370, Loss: 0.0460
Batch 380, Loss: 0.0447
Batch 390, Loss: 0.0508
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.118266344070435 seconds
Epoch 167 accuracy: 78.11%
Batch 10, Loss: 0.0466
Batch 20, Loss: 0.0447
Batch 30, Loss: 0.0491
Batch 40, Loss: 0.0448
Batch 50, Loss: 0.0439
Batch 60, Loss: 0.0446
Batch 70, Loss: 0.0459
Batch 80, Loss: 0.0459
Batch 90, Loss: 0.0474
Batch 100, Loss: 0.0510
Batch 110, Loss: 0.0507
Batch 120, Loss: 0.0480
Batch 130, Loss: 0.0446
Batch 140, Loss: 0.0452
Batch 150, Loss: 0.0465
Batch 160, Loss: 0.0480
Batch 170, Loss: 0.0497
Batch 180, Loss: 0.0504
Batch 190, Loss: 0.0483
Batch 200, Loss: 0.0506
Batch 210, Loss: 0.0477
Batch 220, Loss: 0.0488
Batch 230, Loss: 0.0477
Batch 240, Loss: 0.0540
Batch 250, Loss: 0.0450
Batch 260, Loss: 0.0443
Batch 270, Loss: 0.0422
Batch 280, Loss: 0.0518
Batch 290, Loss: 0.0418
Batch 300, Loss: 0.0502
Batch 310, Loss: 0.0473
Batch 320, Loss: 0.0496
Batch 330, Loss: 0.0491
Batch 340, Loss: 0.0459
Batch 350, Loss: 0.0474
Batch 360, Loss: 0.0472
Batch 370, Loss: 0.0482
Batch 380, Loss: 0.0437
Batch 390, Loss: 0.0504
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.13443922996521 seconds
Epoch 168 accuracy: 78.01%
Batch 10, Loss: 0.0429
Batch 20, Loss: 0.0453
Batch 30, Loss: 0.0455
Batch 40, Loss: 0.0457
Batch 50, Loss: 0.0432
Batch 60, Loss: 0.0481
Batch 70, Loss: 0.0451
Batch 80, Loss: 0.0425
Batch 90, Loss: 0.0435
Batch 100, Loss: 0.0470
Batch 110, Loss: 0.0474
Batch 120, Loss: 0.0486
Batch 130, Loss: 0.0439
Batch 140, Loss: 0.0424
Batch 150, Loss: 0.0400
Batch 160, Loss: 0.0427
Batch 170, Loss: 0.0443
Batch 180, Loss: 0.0401
Batch 190, Loss: 0.0468
Batch 200, Loss: 0.0456
Batch 210, Loss: 0.0453
Batch 220, Loss: 0.0456
Batch 230, Loss: 0.0431
Batch 240, Loss: 0.0468
Batch 250, Loss: 0.0454
Batch 260, Loss: 0.0440
Batch 270, Loss: 0.0458
Batch 280, Loss: 0.0419
Batch 290, Loss: 0.0405
Batch 300, Loss: 0.0427
Batch 310, Loss: 0.0399
Batch 320, Loss: 0.0430
Batch 330, Loss: 0.0445
Batch 340, Loss: 0.0430
Batch 350, Loss: 0.0446
Batch 360, Loss: 0.0490
Batch 370, Loss: 0.0411
Batch 380, Loss: 0.0460
Batch 390, Loss: 0.0469
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.03272843360901 seconds
Epoch 169 accuracy: 78.13%
Batch 10, Loss: 0.0425
Batch 20, Loss: 0.0444
Batch 30, Loss: 0.0454
Batch 40, Loss: 0.0384
Batch 50, Loss: 0.0403
Batch 60, Loss: 0.0482
Batch 70, Loss: 0.0448
Batch 80, Loss: 0.0409
Batch 90, Loss: 0.0425
Batch 100, Loss: 0.0389
Batch 110, Loss: 0.0412
Batch 120, Loss: 0.0386
Batch 130, Loss: 0.0412
Batch 140, Loss: 0.0440
Batch 150, Loss: 0.0417
Batch 160, Loss: 0.0398
Batch 170, Loss: 0.0366
Batch 180, Loss: 0.0448
Batch 190, Loss: 0.0383
Batch 200, Loss: 0.0398
Batch 210, Loss: 0.0396
Batch 220, Loss: 0.0423
Batch 230, Loss: 0.0466
Batch 240, Loss: 0.0381
Batch 250, Loss: 0.0489
Batch 260, Loss: 0.0497
Batch 270, Loss: 0.0419
Batch 280, Loss: 0.0447
Batch 290, Loss: 0.0429
Batch 300, Loss: 0.0410
Batch 310, Loss: 0.0475
Batch 320, Loss: 0.0445
Batch 330, Loss: 0.0426
Batch 340, Loss: 0.0470
Batch 350, Loss: 0.0458
Batch 360, Loss: 0.0397
Batch 370, Loss: 0.0465
Batch 380, Loss: 0.0408
Batch 390, Loss: 0.0506
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.087132930755615 seconds
Epoch 170 accuracy: 78.17%
Batch 10, Loss: 0.0373
Batch 20, Loss: 0.0409
Batch 30, Loss: 0.0491
Batch 40, Loss: 0.0412
Batch 50, Loss: 0.0433
Batch 60, Loss: 0.0406
Batch 70, Loss: 0.0401
Batch 80, Loss: 0.0402
Batch 90, Loss: 0.0432
Batch 100, Loss: 0.0405
Batch 110, Loss: 0.0389
Batch 120, Loss: 0.0403
Batch 130, Loss: 0.0395
Batch 140, Loss: 0.0406
Batch 150, Loss: 0.0420
Batch 160, Loss: 0.0382
Batch 170, Loss: 0.0374
Batch 180, Loss: 0.0425
Batch 190, Loss: 0.0416
Batch 200, Loss: 0.0425
Batch 210, Loss: 0.0373
Batch 220, Loss: 0.0377
Batch 230, Loss: 0.0348
Batch 240, Loss: 0.0394
Batch 250, Loss: 0.0406
Batch 260, Loss: 0.0419
Batch 270, Loss: 0.0381
Batch 280, Loss: 0.0407
Batch 290, Loss: 0.0385
Batch 300, Loss: 0.0370
Batch 310, Loss: 0.0412
Batch 320, Loss: 0.0446
Batch 330, Loss: 0.0512
Batch 340, Loss: 0.0427
Batch 350, Loss: 0.0351
Batch 360, Loss: 0.0415
Batch 370, Loss: 0.0398
Batch 380, Loss: 0.0448
Batch 390, Loss: 0.0406
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.059568881988525 seconds
Epoch 171 accuracy: 78.08%
Batch 10, Loss: 0.0427
Batch 20, Loss: 0.0363
Batch 30, Loss: 0.0362
Batch 40, Loss: 0.0375
Batch 50, Loss: 0.0373
Batch 60, Loss: 0.0372
Batch 70, Loss: 0.0368
Batch 80, Loss: 0.0406
Batch 90, Loss: 0.0364
Batch 100, Loss: 0.0395
Batch 110, Loss: 0.0392
Batch 120, Loss: 0.0430
Batch 130, Loss: 0.0403
Batch 140, Loss: 0.0412
Batch 150, Loss: 0.0389
Batch 160, Loss: 0.0385
Batch 170, Loss: 0.0413
Batch 180, Loss: 0.0418
Batch 190, Loss: 0.0355
Batch 200, Loss: 0.0420
Batch 210, Loss: 0.0419
Batch 220, Loss: 0.0366
Batch 230, Loss: 0.0406
Batch 240, Loss: 0.0371
Batch 250, Loss: 0.0355
Batch 260, Loss: 0.0328
Batch 270, Loss: 0.0374
Batch 280, Loss: 0.0381
Batch 290, Loss: 0.0421
Batch 300, Loss: 0.0395
Batch 310, Loss: 0.0397
Batch 320, Loss: 0.0374
Batch 330, Loss: 0.0431
Batch 340, Loss: 0.0371
Batch 350, Loss: 0.0388
Batch 360, Loss: 0.0366
Batch 370, Loss: 0.0372
Batch 380, Loss: 0.0392
Batch 390, Loss: 0.0395
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.0632746219635 seconds
Epoch 172 accuracy: 78.4%
Batch 10, Loss: 0.0370
Batch 20, Loss: 0.0344
Batch 30, Loss: 0.0362
Batch 40, Loss: 0.0338
Batch 50, Loss: 0.0342
Batch 60, Loss: 0.0356
Batch 70, Loss: 0.0342
Batch 80, Loss: 0.0337
Batch 90, Loss: 0.0390
Batch 100, Loss: 0.0373
Batch 110, Loss: 0.0362
Batch 120, Loss: 0.0391
Batch 130, Loss: 0.0363
Batch 140, Loss: 0.0383
Batch 150, Loss: 0.0369
Batch 160, Loss: 0.0341
Batch 170, Loss: 0.0333
Batch 180, Loss: 0.0384
Batch 190, Loss: 0.0336
Batch 200, Loss: 0.0399
Batch 210, Loss: 0.0373
Batch 220, Loss: 0.0329
Batch 230, Loss: 0.0405
Batch 240, Loss: 0.0367
Batch 250, Loss: 0.0373
Batch 260, Loss: 0.0395
Batch 270, Loss: 0.0352
Batch 280, Loss: 0.0370
Batch 290, Loss: 0.0370
Batch 300, Loss: 0.0376
Batch 310, Loss: 0.0372
Batch 320, Loss: 0.0395
Batch 330, Loss: 0.0414
Batch 340, Loss: 0.0378
Batch 350, Loss: 0.0355
Batch 360, Loss: 0.0394
Batch 370, Loss: 0.0352
Batch 380, Loss: 0.0383
Batch 390, Loss: 0.0372
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.084853410720825 seconds
Epoch 173 accuracy: 78.46%
Batch 10, Loss: 0.0386
Batch 20, Loss: 0.0345
Batch 30, Loss: 0.0310
Batch 40, Loss: 0.0303
Batch 50, Loss: 0.0355
Batch 60, Loss: 0.0345
Batch 70, Loss: 0.0345
Batch 80, Loss: 0.0333
Batch 90, Loss: 0.0380
Batch 100, Loss: 0.0344
Batch 110, Loss: 0.0326
Batch 120, Loss: 0.0338
Batch 130, Loss: 0.0364
Batch 140, Loss: 0.0329
Batch 150, Loss: 0.0373
Batch 160, Loss: 0.0369
Batch 170, Loss: 0.0337
Batch 180, Loss: 0.0374
Batch 190, Loss: 0.0352
Batch 200, Loss: 0.0318
Batch 210, Loss: 0.0343
Batch 220, Loss: 0.0316
Batch 230, Loss: 0.0387
Batch 240, Loss: 0.0353
Batch 250, Loss: 0.0371
Batch 260, Loss: 0.0342
Batch 270, Loss: 0.0382
Batch 280, Loss: 0.0369
Batch 290, Loss: 0.0355
Batch 300, Loss: 0.0353
Batch 310, Loss: 0.0339
Batch 320, Loss: 0.0352
Batch 330, Loss: 0.0359
Batch 340, Loss: 0.0368
Batch 350, Loss: 0.0326
Batch 360, Loss: 0.0357
Batch 370, Loss: 0.0338
Batch 380, Loss: 0.0369
Batch 390, Loss: 0.0335
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.074397087097168 seconds
Epoch 174 accuracy: 78.46%
Batch 10, Loss: 0.0355
Batch 20, Loss: 0.0323
Batch 30, Loss: 0.0360
Batch 40, Loss: 0.0329
Batch 50, Loss: 0.0335
Batch 60, Loss: 0.0322
Batch 70, Loss: 0.0347
Batch 80, Loss: 0.0331
Batch 90, Loss: 0.0360
Batch 100, Loss: 0.0333
Batch 110, Loss: 0.0336
Batch 120, Loss: 0.0312
Batch 130, Loss: 0.0323
Batch 140, Loss: 0.0314
Batch 150, Loss: 0.0341
Batch 160, Loss: 0.0343
Batch 170, Loss: 0.0331
Batch 180, Loss: 0.0345
Batch 190, Loss: 0.0375
Batch 200, Loss: 0.0359
Batch 210, Loss: 0.0408
Batch 220, Loss: 0.0357
Batch 230, Loss: 0.0328
Batch 240, Loss: 0.0350
Batch 250, Loss: 0.0364
Batch 260, Loss: 0.0351
Batch 270, Loss: 0.0334
Batch 280, Loss: 0.0324
Batch 290, Loss: 0.0330
Batch 300, Loss: 0.0313
Batch 310, Loss: 0.0340
Batch 320, Loss: 0.0324
Batch 330, Loss: 0.0326
Batch 340, Loss: 0.0342
Batch 350, Loss: 0.0342
Batch 360, Loss: 0.0284
Batch 370, Loss: 0.0343
Batch 380, Loss: 0.0339
Batch 390, Loss: 0.0376
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.117077827453613 seconds
Epoch 175 accuracy: 78.48%
Batch 10, Loss: 0.0305
Batch 20, Loss: 0.0346
Batch 30, Loss: 0.0320
Batch 40, Loss: 0.0301
Batch 50, Loss: 0.0305
Batch 60, Loss: 0.0349
Batch 70, Loss: 0.0321
Batch 80, Loss: 0.0325
Batch 90, Loss: 0.0323
Batch 100, Loss: 0.0326
Batch 110, Loss: 0.0338
Batch 120, Loss: 0.0317
Batch 130, Loss: 0.0317
Batch 140, Loss: 0.0344
Batch 150, Loss: 0.0305
Batch 160, Loss: 0.0335
Batch 170, Loss: 0.0313
Batch 180, Loss: 0.0328
Batch 190, Loss: 0.0357
Batch 200, Loss: 0.0324
Batch 210, Loss: 0.0336
Batch 220, Loss: 0.0326
Batch 230, Loss: 0.0333
Batch 240, Loss: 0.0327
Batch 250, Loss: 0.0331
Batch 260, Loss: 0.0323
Batch 270, Loss: 0.0334
Batch 280, Loss: 0.0306
Batch 290, Loss: 0.0328
Batch 300, Loss: 0.0325
Batch 310, Loss: 0.0322
Batch 320, Loss: 0.0360
Batch 330, Loss: 0.0310
Batch 340, Loss: 0.0316
Batch 350, Loss: 0.0296
Batch 360, Loss: 0.0357
Batch 370, Loss: 0.0316
Batch 380, Loss: 0.0304
Batch 390, Loss: 0.0334
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.084787368774414 seconds
Epoch 176 accuracy: 78.59%
Batch 10, Loss: 0.0267
Batch 20, Loss: 0.0282
Batch 30, Loss: 0.0323
Batch 40, Loss: 0.0316
Batch 50, Loss: 0.0327
Batch 60, Loss: 0.0298
Batch 70, Loss: 0.0328
Batch 80, Loss: 0.0305
Batch 90, Loss: 0.0288
Batch 100, Loss: 0.0313
Batch 110, Loss: 0.0332
Batch 120, Loss: 0.0279
Batch 130, Loss: 0.0320
Batch 140, Loss: 0.0336
Batch 150, Loss: 0.0288
Batch 160, Loss: 0.0314
Batch 170, Loss: 0.0288
Batch 180, Loss: 0.0317
Batch 190, Loss: 0.0337
Batch 200, Loss: 0.0319
Batch 210, Loss: 0.0321
Batch 220, Loss: 0.0304
Batch 230, Loss: 0.0291
Batch 240, Loss: 0.0313
Batch 250, Loss: 0.0313
Batch 260, Loss: 0.0308
Batch 270, Loss: 0.0285
Batch 280, Loss: 0.0357
Batch 290, Loss: 0.0330
Batch 300, Loss: 0.0326
Batch 310, Loss: 0.0372
Batch 320, Loss: 0.0344
Batch 330, Loss: 0.0319
Batch 340, Loss: 0.0305
Batch 350, Loss: 0.0338
Batch 360, Loss: 0.0311
Batch 370, Loss: 0.0353
Batch 380, Loss: 0.0303
Batch 390, Loss: 0.0326
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.079694509506226 seconds
Epoch 177 accuracy: 79.01%
Batch 10, Loss: 0.0285
Batch 20, Loss: 0.0292
Batch 30, Loss: 0.0299
Batch 40, Loss: 0.0303
Batch 50, Loss: 0.0288
Batch 60, Loss: 0.0310
Batch 70, Loss: 0.0288
Batch 80, Loss: 0.0320
Batch 90, Loss: 0.0315
Batch 100, Loss: 0.0348
Batch 110, Loss: 0.0296
Batch 120, Loss: 0.0327
Batch 130, Loss: 0.0293
Batch 140, Loss: 0.0332
Batch 150, Loss: 0.0308
Batch 160, Loss: 0.0319
Batch 170, Loss: 0.0304
Batch 180, Loss: 0.0301
Batch 190, Loss: 0.0281
Batch 200, Loss: 0.0305
Batch 210, Loss: 0.0309
Batch 220, Loss: 0.0338
Batch 230, Loss: 0.0308
Batch 240, Loss: 0.0283
Batch 250, Loss: 0.0317
Batch 260, Loss: 0.0311
Batch 270, Loss: 0.0325
Batch 280, Loss: 0.0340
Batch 290, Loss: 0.0293
Batch 300, Loss: 0.0331
Batch 310, Loss: 0.0319
Batch 320, Loss: 0.0285
Batch 330, Loss: 0.0329
Batch 340, Loss: 0.0289
Batch 350, Loss: 0.0285
Batch 360, Loss: 0.0317
Batch 370, Loss: 0.0328
Batch 380, Loss: 0.0312
Batch 390, Loss: 0.0309
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.147916078567505 seconds
Epoch 178 accuracy: 78.81%
Batch 10, Loss: 0.0308
Batch 20, Loss: 0.0312
Batch 30, Loss: 0.0288
Batch 40, Loss: 0.0303
Batch 50, Loss: 0.0261
Batch 60, Loss: 0.0299
Batch 70, Loss: 0.0267
Batch 80, Loss: 0.0305
Batch 90, Loss: 0.0332
Batch 100, Loss: 0.0301
Batch 110, Loss: 0.0338
Batch 120, Loss: 0.0308
Batch 130, Loss: 0.0322
Batch 140, Loss: 0.0295
Batch 150, Loss: 0.0260
Batch 160, Loss: 0.0265
Batch 170, Loss: 0.0331
Batch 180, Loss: 0.0317
Batch 190, Loss: 0.0266
Batch 200, Loss: 0.0321
Batch 210, Loss: 0.0266
Batch 220, Loss: 0.0339
Batch 230, Loss: 0.0314
Batch 240, Loss: 0.0277
Batch 250, Loss: 0.0320
Batch 260, Loss: 0.0284
Batch 270, Loss: 0.0334
Batch 280, Loss: 0.0288
Batch 290, Loss: 0.0316
Batch 300, Loss: 0.0307
Batch 310, Loss: 0.0310
Batch 320, Loss: 0.0274
Batch 330, Loss: 0.0293
Batch 340, Loss: 0.0276
Batch 350, Loss: 0.0283
Batch 360, Loss: 0.0285
Batch 370, Loss: 0.0293
Batch 380, Loss: 0.0357
Batch 390, Loss: 0.0311
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.12939167022705 seconds
Epoch 179 accuracy: 79.15%
Batch 10, Loss: 0.0278
Batch 20, Loss: 0.0299
Batch 30, Loss: 0.0285
Batch 40, Loss: 0.0310
Batch 50, Loss: 0.0283
Batch 60, Loss: 0.0260
Batch 70, Loss: 0.0289
Batch 80, Loss: 0.0286
Batch 90, Loss: 0.0284
Batch 100, Loss: 0.0282
Batch 110, Loss: 0.0251
Batch 120, Loss: 0.0274
Batch 130, Loss: 0.0271
Batch 140, Loss: 0.0259
Batch 150, Loss: 0.0296
Batch 160, Loss: 0.0298
Batch 170, Loss: 0.0303
Batch 180, Loss: 0.0321
Batch 190, Loss: 0.0262
Batch 200, Loss: 0.0269
Batch 210, Loss: 0.0297
Batch 220, Loss: 0.0305
Batch 230, Loss: 0.0287
Batch 240, Loss: 0.0310
Batch 250, Loss: 0.0312
Batch 260, Loss: 0.0287
Batch 270, Loss: 0.0280
Batch 280, Loss: 0.0302
Batch 290, Loss: 0.0282
Batch 300, Loss: 0.0294
Batch 310, Loss: 0.0289
Batch 320, Loss: 0.0283
Batch 330, Loss: 0.0257
Batch 340, Loss: 0.0296
Batch 350, Loss: 0.0286
Batch 360, Loss: 0.0333
Batch 370, Loss: 0.0268
Batch 380, Loss: 0.0282
Batch 390, Loss: 0.0291
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.109565258026123 seconds
Epoch 180 accuracy: 79.11%
Batch 10, Loss: 0.0296
Batch 20, Loss: 0.0258
Batch 30, Loss: 0.0241
Batch 40, Loss: 0.0281
Batch 50, Loss: 0.0266
Batch 60, Loss: 0.0302
Batch 70, Loss: 0.0272
Batch 80, Loss: 0.0266
Batch 90, Loss: 0.0260
Batch 100, Loss: 0.0258
Batch 110, Loss: 0.0299
Batch 120, Loss: 0.0280
Batch 130, Loss: 0.0281
Batch 140, Loss: 0.0285
Batch 150, Loss: 0.0246
Batch 160, Loss: 0.0297
Batch 170, Loss: 0.0280
Batch 180, Loss: 0.0285
Batch 190, Loss: 0.0324
Batch 200, Loss: 0.0291
Batch 210, Loss: 0.0273
Batch 220, Loss: 0.0289
Batch 230, Loss: 0.0252
Batch 240, Loss: 0.0301
Batch 250, Loss: 0.0269
Batch 260, Loss: 0.0280
Batch 270, Loss: 0.0294
Batch 280, Loss: 0.0292
Batch 290, Loss: 0.0321
Batch 300, Loss: 0.0295
Batch 310, Loss: 0.0332
Batch 320, Loss: 0.0275
Batch 330, Loss: 0.0288
Batch 340, Loss: 0.0280
Batch 350, Loss: 0.0281
Batch 360, Loss: 0.0279
Batch 370, Loss: 0.0295
Batch 380, Loss: 0.0292
Batch 390, Loss: 0.0324
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.058236598968506 seconds
Epoch 181 accuracy: 79.24%
Batch 10, Loss: 0.0298
Batch 20, Loss: 0.0267
Batch 30, Loss: 0.0251
Batch 40, Loss: 0.0238
Batch 50, Loss: 0.0305
Batch 60, Loss: 0.0243
Batch 70, Loss: 0.0310
Batch 80, Loss: 0.0291
Batch 90, Loss: 0.0254
Batch 100, Loss: 0.0291
Batch 110, Loss: 0.0301
Batch 120, Loss: 0.0258
Batch 130, Loss: 0.0268
Batch 140, Loss: 0.0295
Batch 150, Loss: 0.0277
Batch 160, Loss: 0.0276
Batch 170, Loss: 0.0282
Batch 180, Loss: 0.0238
Batch 190, Loss: 0.0297
Batch 200, Loss: 0.0294
Batch 210, Loss: 0.0246
Batch 220, Loss: 0.0270
Batch 230, Loss: 0.0294
Batch 240, Loss: 0.0265
Batch 250, Loss: 0.0293
Batch 260, Loss: 0.0267
Batch 270, Loss: 0.0273
Batch 280, Loss: 0.0262
Batch 290, Loss: 0.0268
Batch 300, Loss: 0.0261
Batch 310, Loss: 0.0273
Batch 320, Loss: 0.0298
Batch 330, Loss: 0.0242
Batch 340, Loss: 0.0244
Batch 350, Loss: 0.0245
Batch 360, Loss: 0.0244
Batch 370, Loss: 0.0293
Batch 380, Loss: 0.0279
Batch 390, Loss: 0.0262
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.053405284881592 seconds
Epoch 182 accuracy: 79.18%
Batch 10, Loss: 0.0260
Batch 20, Loss: 0.0286
Batch 30, Loss: 0.0246
Batch 40, Loss: 0.0252
Batch 50, Loss: 0.0240
Batch 60, Loss: 0.0254
Batch 70, Loss: 0.0280
Batch 80, Loss: 0.0276
Batch 90, Loss: 0.0260
Batch 100, Loss: 0.0243
Batch 110, Loss: 0.0268
Batch 120, Loss: 0.0281
Batch 130, Loss: 0.0260
Batch 140, Loss: 0.0301
Batch 150, Loss: 0.0265
Batch 160, Loss: 0.0298
Batch 170, Loss: 0.0259
Batch 180, Loss: 0.0246
Batch 190, Loss: 0.0324
Batch 200, Loss: 0.0246
Batch 210, Loss: 0.0265
Batch 220, Loss: 0.0276
Batch 230, Loss: 0.0277
Batch 240, Loss: 0.0286
Batch 250, Loss: 0.0282
Batch 260, Loss: 0.0261
Batch 270, Loss: 0.0261
Batch 280, Loss: 0.0251
Batch 290, Loss: 0.0238
Batch 300, Loss: 0.0255
Batch 310, Loss: 0.0272
Batch 320, Loss: 0.0261
Batch 330, Loss: 0.0262
Batch 340, Loss: 0.0284
Batch 350, Loss: 0.0261
Batch 360, Loss: 0.0277
Batch 370, Loss: 0.0267
Batch 380, Loss: 0.0275
Batch 390, Loss: 0.0302
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.102630376815796 seconds
Epoch 183 accuracy: 79.09%
Batch 10, Loss: 0.0279
Batch 20, Loss: 0.0254
Batch 30, Loss: 0.0274
Batch 40, Loss: 0.0232
Batch 50, Loss: 0.0261
Batch 60, Loss: 0.0251
Batch 70, Loss: 0.0299
Batch 80, Loss: 0.0247
Batch 90, Loss: 0.0260
Batch 100, Loss: 0.0284
Batch 110, Loss: 0.0247
Batch 120, Loss: 0.0248
Batch 130, Loss: 0.0257
Batch 140, Loss: 0.0255
Batch 150, Loss: 0.0306
Batch 160, Loss: 0.0276
Batch 170, Loss: 0.0263
Batch 180, Loss: 0.0253
Batch 190, Loss: 0.0285
Batch 200, Loss: 0.0300
Batch 210, Loss: 0.0265
Batch 220, Loss: 0.0278
Batch 230, Loss: 0.0250
Batch 240, Loss: 0.0258
Batch 250, Loss: 0.0262
Batch 260, Loss: 0.0284
Batch 270, Loss: 0.0246
Batch 280, Loss: 0.0286
Batch 290, Loss: 0.0272
Batch 300, Loss: 0.0279
Batch 310, Loss: 0.0236
Batch 320, Loss: 0.0253
Batch 330, Loss: 0.0248
Batch 340, Loss: 0.0266
Batch 350, Loss: 0.0274
Batch 360, Loss: 0.0248
Batch 370, Loss: 0.0262
Batch 380, Loss: 0.0251
Batch 390, Loss: 0.0253
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.124892234802246 seconds
Epoch 184 accuracy: 79.28%
Batch 10, Loss: 0.0266
Batch 20, Loss: 0.0266
Batch 30, Loss: 0.0246
Batch 40, Loss: 0.0244
Batch 50, Loss: 0.0264
Batch 60, Loss: 0.0247
Batch 70, Loss: 0.0236
Batch 80, Loss: 0.0272
Batch 90, Loss: 0.0250
Batch 100, Loss: 0.0250
Batch 110, Loss: 0.0257
Batch 120, Loss: 0.0283
Batch 130, Loss: 0.0253
Batch 140, Loss: 0.0297
Batch 150, Loss: 0.0252
Batch 160, Loss: 0.0250
Batch 170, Loss: 0.0275
Batch 180, Loss: 0.0279
Batch 190, Loss: 0.0264
Batch 200, Loss: 0.0297
Batch 210, Loss: 0.0267
Batch 220, Loss: 0.0250
Batch 230, Loss: 0.0249
Batch 240, Loss: 0.0254
Batch 250, Loss: 0.0279
Batch 260, Loss: 0.0246
Batch 270, Loss: 0.0262
Batch 280, Loss: 0.0256
Batch 290, Loss: 0.0258
Batch 300, Loss: 0.0280
Batch 310, Loss: 0.0263
Batch 320, Loss: 0.0246
Batch 330, Loss: 0.0300
Batch 340, Loss: 0.0225
Batch 350, Loss: 0.0239
Batch 360, Loss: 0.0273
Batch 370, Loss: 0.0257
Batch 380, Loss: 0.0236
Batch 390, Loss: 0.0260
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.11430549621582 seconds
Epoch 185 accuracy: 79.28%
Batch 10, Loss: 0.0236
Batch 20, Loss: 0.0265
Batch 30, Loss: 0.0290
Batch 40, Loss: 0.0241
Batch 50, Loss: 0.0216
Batch 60, Loss: 0.0216
Batch 70, Loss: 0.0252
Batch 80, Loss: 0.0258
Batch 90, Loss: 0.0275
Batch 100, Loss: 0.0250
Batch 110, Loss: 0.0289
Batch 120, Loss: 0.0252
Batch 130, Loss: 0.0245
Batch 140, Loss: 0.0252
Batch 150, Loss: 0.0233
Batch 160, Loss: 0.0266
Batch 170, Loss: 0.0237
Batch 180, Loss: 0.0254
Batch 190, Loss: 0.0232
Batch 200, Loss: 0.0270
Batch 210, Loss: 0.0237
Batch 220, Loss: 0.0231
Batch 230, Loss: 0.0273
Batch 240, Loss: 0.0265
Batch 250, Loss: 0.0236
Batch 260, Loss: 0.0282
Batch 270, Loss: 0.0253
Batch 280, Loss: 0.0251
Batch 290, Loss: 0.0268
Batch 300, Loss: 0.0230
Batch 310, Loss: 0.0247
Batch 320, Loss: 0.0244
Batch 330, Loss: 0.0264
Batch 340, Loss: 0.0229
Batch 350, Loss: 0.0226
Batch 360, Loss: 0.0289
Batch 370, Loss: 0.0232
Batch 380, Loss: 0.0280
Batch 390, Loss: 0.0227
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.097310543060303 seconds
Epoch 186 accuracy: 79.17%
Batch 10, Loss: 0.0245
Batch 20, Loss: 0.0240
Batch 30, Loss: 0.0231
Batch 40, Loss: 0.0222
Batch 50, Loss: 0.0205
Batch 60, Loss: 0.0256
Batch 70, Loss: 0.0230
Batch 80, Loss: 0.0304
Batch 90, Loss: 0.0257
Batch 100, Loss: 0.0249
Batch 110, Loss: 0.0227
Batch 120, Loss: 0.0216
Batch 130, Loss: 0.0252
Batch 140, Loss: 0.0261
Batch 150, Loss: 0.0293
Batch 160, Loss: 0.0244
Batch 170, Loss: 0.0276
Batch 180, Loss: 0.0242
Batch 190, Loss: 0.0249
Batch 200, Loss: 0.0228
Batch 210, Loss: 0.0255
Batch 220, Loss: 0.0254
Batch 230, Loss: 0.0222
Batch 240, Loss: 0.0255
Batch 250, Loss: 0.0263
Batch 260, Loss: 0.0263
Batch 270, Loss: 0.0258
Batch 280, Loss: 0.0253
Batch 290, Loss: 0.0278
Batch 300, Loss: 0.0243
Batch 310, Loss: 0.0255
Batch 320, Loss: 0.0253
Batch 330, Loss: 0.0224
Batch 340, Loss: 0.0280
Batch 350, Loss: 0.0229
Batch 360, Loss: 0.0240
Batch 370, Loss: 0.0228
Batch 380, Loss: 0.0228
Batch 390, Loss: 0.0261
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.14690351486206 seconds
Epoch 187 accuracy: 78.98%
Batch 10, Loss: 0.0260
Batch 20, Loss: 0.0237
Batch 30, Loss: 0.0254
Batch 40, Loss: 0.0245
Batch 50, Loss: 0.0243
Batch 60, Loss: 0.0240
Batch 70, Loss: 0.0252
Batch 80, Loss: 0.0241
Batch 90, Loss: 0.0252
Batch 100, Loss: 0.0237
Batch 110, Loss: 0.0261
Batch 120, Loss: 0.0238
Batch 130, Loss: 0.0276
Batch 140, Loss: 0.0248
Batch 150, Loss: 0.0235
Batch 160, Loss: 0.0254
Batch 170, Loss: 0.0253
Batch 180, Loss: 0.0254
Batch 190, Loss: 0.0257
Batch 200, Loss: 0.0233
Batch 210, Loss: 0.0244
Batch 220, Loss: 0.0245
Batch 230, Loss: 0.0231
Batch 240, Loss: 0.0249
Batch 250, Loss: 0.0248
Batch 260, Loss: 0.0295
Batch 270, Loss: 0.0220
Batch 280, Loss: 0.0241
Batch 290, Loss: 0.0262
Batch 300, Loss: 0.0272
Batch 310, Loss: 0.0229
Batch 320, Loss: 0.0246
Batch 330, Loss: 0.0246
Batch 340, Loss: 0.0248
Batch 350, Loss: 0.0258
Batch 360, Loss: 0.0236
Batch 370, Loss: 0.0256
Batch 380, Loss: 0.0234
Batch 390, Loss: 0.0251
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.07937502861023 seconds
Epoch 188 accuracy: 79.23%
Batch 10, Loss: 0.0272
Batch 20, Loss: 0.0238
Batch 30, Loss: 0.0241
Batch 40, Loss: 0.0249
Batch 50, Loss: 0.0234
Batch 60, Loss: 0.0270
Batch 70, Loss: 0.0232
Batch 80, Loss: 0.0241
Batch 90, Loss: 0.0244
Batch 100, Loss: 0.0206
Batch 110, Loss: 0.0225
Batch 120, Loss: 0.0224
Batch 130, Loss: 0.0270
Batch 140, Loss: 0.0246
Batch 150, Loss: 0.0217
Batch 160, Loss: 0.0235
Batch 170, Loss: 0.0222
Batch 180, Loss: 0.0216
Batch 190, Loss: 0.0229
Batch 200, Loss: 0.0242
Batch 210, Loss: 0.0264
Batch 220, Loss: 0.0239
Batch 230, Loss: 0.0237
Batch 240, Loss: 0.0218
Batch 250, Loss: 0.0253
Batch 260, Loss: 0.0248
Batch 270, Loss: 0.0228
Batch 280, Loss: 0.0247
Batch 290, Loss: 0.0238
Batch 300, Loss: 0.0248
Batch 310, Loss: 0.0233
Batch 320, Loss: 0.0237
Batch 330, Loss: 0.0262
Batch 340, Loss: 0.0256
Batch 350, Loss: 0.0231
Batch 360, Loss: 0.0229
Batch 370, Loss: 0.0250
Batch 380, Loss: 0.0250
Batch 390, Loss: 0.0231
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.07547354698181 seconds
Epoch 189 accuracy: 79.18%
Batch 10, Loss: 0.0250
Batch 20, Loss: 0.0222
Batch 30, Loss: 0.0200
Batch 40, Loss: 0.0216
Batch 50, Loss: 0.0245
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0231
Batch 80, Loss: 0.0226
Batch 90, Loss: 0.0229
Batch 100, Loss: 0.0263
Batch 110, Loss: 0.0243
Batch 120, Loss: 0.0218
Batch 130, Loss: 0.0221
Batch 140, Loss: 0.0238
Batch 150, Loss: 0.0228
Batch 160, Loss: 0.0207
Batch 170, Loss: 0.0240
Batch 180, Loss: 0.0258
Batch 190, Loss: 0.0249
Batch 200, Loss: 0.0258
Batch 210, Loss: 0.0236
Batch 220, Loss: 0.0253
Batch 230, Loss: 0.0245
Batch 240, Loss: 0.0240
Batch 250, Loss: 0.0231
Batch 260, Loss: 0.0204
Batch 270, Loss: 0.0241
Batch 280, Loss: 0.0224
Batch 290, Loss: 0.0234
Batch 300, Loss: 0.0223
Batch 310, Loss: 0.0236
Batch 320, Loss: 0.0231
Batch 330, Loss: 0.0207
Batch 340, Loss: 0.0254
Batch 350, Loss: 0.0226
Batch 360, Loss: 0.0242
Batch 370, Loss: 0.0243
Batch 380, Loss: 0.0215
Batch 390, Loss: 0.0237
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.17211604118347 seconds
Epoch 190 accuracy: 79.39%
Batch 10, Loss: 0.0222
Batch 20, Loss: 0.0262
Batch 30, Loss: 0.0259
Batch 40, Loss: 0.0236
Batch 50, Loss: 0.0246
Batch 60, Loss: 0.0229
Batch 70, Loss: 0.0235
Batch 80, Loss: 0.0241
Batch 90, Loss: 0.0231
Batch 100, Loss: 0.0241
Batch 110, Loss: 0.0211
Batch 120, Loss: 0.0256
Batch 130, Loss: 0.0213
Batch 140, Loss: 0.0226
Batch 150, Loss: 0.0222
Batch 160, Loss: 0.0227
Batch 170, Loss: 0.0241
Batch 180, Loss: 0.0226
Batch 190, Loss: 0.0213
Batch 200, Loss: 0.0216
Batch 210, Loss: 0.0237
Batch 220, Loss: 0.0237
Batch 230, Loss: 0.0253
Batch 240, Loss: 0.0248
Batch 250, Loss: 0.0217
Batch 260, Loss: 0.0250
Batch 270, Loss: 0.0209
Batch 280, Loss: 0.0230
Batch 290, Loss: 0.0226
Batch 300, Loss: 0.0235
Batch 310, Loss: 0.0233
Batch 320, Loss: 0.0235
Batch 330, Loss: 0.0220
Batch 340, Loss: 0.0223
Batch 350, Loss: 0.0246
Batch 360, Loss: 0.0246
Batch 370, Loss: 0.0223
Batch 380, Loss: 0.0211
Batch 390, Loss: 0.0215
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.07060933113098 seconds
Epoch 191 accuracy: 79.28%
Batch 10, Loss: 0.0258
Batch 20, Loss: 0.0215
Batch 30, Loss: 0.0229
Batch 40, Loss: 0.0251
Batch 50, Loss: 0.0252
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0206
Batch 80, Loss: 0.0258
Batch 90, Loss: 0.0223
Batch 100, Loss: 0.0218
Batch 110, Loss: 0.0261
Batch 120, Loss: 0.0235
Batch 130, Loss: 0.0216
Batch 140, Loss: 0.0219
Batch 150, Loss: 0.0213
Batch 160, Loss: 0.0239
Batch 170, Loss: 0.0241
Batch 180, Loss: 0.0240
Batch 190, Loss: 0.0228
Batch 200, Loss: 0.0232
Batch 210, Loss: 0.0217
Batch 220, Loss: 0.0237
Batch 230, Loss: 0.0267
Batch 240, Loss: 0.0228
Batch 250, Loss: 0.0263
Batch 260, Loss: 0.0204
Batch 270, Loss: 0.0223
Batch 280, Loss: 0.0238
Batch 290, Loss: 0.0243
Batch 300, Loss: 0.0206
Batch 310, Loss: 0.0230
Batch 320, Loss: 0.0223
Batch 330, Loss: 0.0249
Batch 340, Loss: 0.0229
Batch 350, Loss: 0.0279
Batch 360, Loss: 0.0235
Batch 370, Loss: 0.0224
Batch 380, Loss: 0.0228
Batch 390, Loss: 0.0223
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.119273900985718 seconds
Epoch 192 accuracy: 79.4%
Batch 10, Loss: 0.0242
Batch 20, Loss: 0.0223
Batch 30, Loss: 0.0214
Batch 40, Loss: 0.0214
Batch 50, Loss: 0.0229
Batch 60, Loss: 0.0222
Batch 70, Loss: 0.0219
Batch 80, Loss: 0.0215
Batch 90, Loss: 0.0246
Batch 100, Loss: 0.0200
Batch 110, Loss: 0.0250
Batch 120, Loss: 0.0255
Batch 130, Loss: 0.0208
Batch 140, Loss: 0.0213
Batch 150, Loss: 0.0223
Batch 160, Loss: 0.0244
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0222
Batch 190, Loss: 0.0261
Batch 200, Loss: 0.0241
Batch 210, Loss: 0.0254
Batch 220, Loss: 0.0236
Batch 230, Loss: 0.0227
Batch 240, Loss: 0.0239
Batch 250, Loss: 0.0241
Batch 260, Loss: 0.0254
Batch 270, Loss: 0.0227
Batch 280, Loss: 0.0220
Batch 290, Loss: 0.0224
Batch 300, Loss: 0.0252
Batch 310, Loss: 0.0223
Batch 320, Loss: 0.0227
Batch 330, Loss: 0.0280
Batch 340, Loss: 0.0221
Batch 350, Loss: 0.0218
Batch 360, Loss: 0.0224
Batch 370, Loss: 0.0227
Batch 380, Loss: 0.0221
Batch 390, Loss: 0.0222
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.130590677261353 seconds
Epoch 193 accuracy: 79.48%
Batch 10, Loss: 0.0210
Batch 20, Loss: 0.0236
Batch 30, Loss: 0.0216
Batch 40, Loss: 0.0241
Batch 50, Loss: 0.0225
Batch 60, Loss: 0.0219
Batch 70, Loss: 0.0209
Batch 80, Loss: 0.0229
Batch 90, Loss: 0.0228
Batch 100, Loss: 0.0226
Batch 110, Loss: 0.0215
Batch 120, Loss: 0.0232
Batch 130, Loss: 0.0224
Batch 140, Loss: 0.0233
Batch 150, Loss: 0.0237
Batch 160, Loss: 0.0247
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0211
Batch 190, Loss: 0.0236
Batch 200, Loss: 0.0255
Batch 210, Loss: 0.0250
Batch 220, Loss: 0.0242
Batch 230, Loss: 0.0241
Batch 240, Loss: 0.0237
Batch 250, Loss: 0.0239
Batch 260, Loss: 0.0236
Batch 270, Loss: 0.0244
Batch 280, Loss: 0.0235
Batch 290, Loss: 0.0205
Batch 300, Loss: 0.0219
Batch 310, Loss: 0.0227
Batch 320, Loss: 0.0224
Batch 330, Loss: 0.0223
Batch 340, Loss: 0.0218
Batch 350, Loss: 0.0226
Batch 360, Loss: 0.0221
Batch 370, Loss: 0.0222
Batch 380, Loss: 0.0235
Batch 390, Loss: 0.0245
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.132924556732178 seconds
Epoch 194 accuracy: 79.32%
Batch 10, Loss: 0.0209
Batch 20, Loss: 0.0205
Batch 30, Loss: 0.0229
Batch 40, Loss: 0.0240
Batch 50, Loss: 0.0222
Batch 60, Loss: 0.0240
Batch 70, Loss: 0.0223
Batch 80, Loss: 0.0207
Batch 90, Loss: 0.0239
Batch 100, Loss: 0.0227
Batch 110, Loss: 0.0231
Batch 120, Loss: 0.0265
Batch 130, Loss: 0.0229
Batch 140, Loss: 0.0249
Batch 150, Loss: 0.0239
Batch 160, Loss: 0.0229
Batch 170, Loss: 0.0240
Batch 180, Loss: 0.0235
Batch 190, Loss: 0.0251
Batch 200, Loss: 0.0229
Batch 210, Loss: 0.0232
Batch 220, Loss: 0.0240
Batch 230, Loss: 0.0239
Batch 240, Loss: 0.0195
Batch 250, Loss: 0.0197
Batch 260, Loss: 0.0229
Batch 270, Loss: 0.0256
Batch 280, Loss: 0.0207
Batch 290, Loss: 0.0215
Batch 300, Loss: 0.0246
Batch 310, Loss: 0.0238
Batch 320, Loss: 0.0214
Batch 330, Loss: 0.0216
Batch 340, Loss: 0.0207
Batch 350, Loss: 0.0235
Batch 360, Loss: 0.0216
Batch 370, Loss: 0.0225
Batch 380, Loss: 0.0220
Batch 390, Loss: 0.0245
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.042223691940308 seconds
Epoch 195 accuracy: 79.41%
Batch 10, Loss: 0.0221
Batch 20, Loss: 0.0219
Batch 30, Loss: 0.0240
Batch 40, Loss: 0.0256
Batch 50, Loss: 0.0218
Batch 60, Loss: 0.0228
Batch 70, Loss: 0.0213
Batch 80, Loss: 0.0249
Batch 90, Loss: 0.0213
Batch 100, Loss: 0.0209
Batch 110, Loss: 0.0239
Batch 120, Loss: 0.0255
Batch 130, Loss: 0.0210
Batch 140, Loss: 0.0233
Batch 150, Loss: 0.0231
Batch 160, Loss: 0.0218
Batch 170, Loss: 0.0239
Batch 180, Loss: 0.0231
Batch 190, Loss: 0.0209
Batch 200, Loss: 0.0212
Batch 210, Loss: 0.0225
Batch 220, Loss: 0.0232
Batch 230, Loss: 0.0214
Batch 240, Loss: 0.0237
Batch 250, Loss: 0.0208
Batch 260, Loss: 0.0235
Batch 270, Loss: 0.0246
Batch 280, Loss: 0.0221
Batch 290, Loss: 0.0218
Batch 300, Loss: 0.0203
Batch 310, Loss: 0.0241
Batch 320, Loss: 0.0190
Batch 330, Loss: 0.0213
Batch 340, Loss: 0.0260
Batch 350, Loss: 0.0215
Batch 360, Loss: 0.0214
Batch 370, Loss: 0.0240
Batch 380, Loss: 0.0227
Batch 390, Loss: 0.0197
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.004372596740723 seconds
Epoch 196 accuracy: 79.38%
Batch 10, Loss: 0.0210
Batch 20, Loss: 0.0204
Batch 30, Loss: 0.0212
Batch 40, Loss: 0.0231
Batch 50, Loss: 0.0243
Batch 60, Loss: 0.0230
Batch 70, Loss: 0.0248
Batch 80, Loss: 0.0236
Batch 90, Loss: 0.0235
Batch 100, Loss: 0.0234
Batch 110, Loss: 0.0236
Batch 120, Loss: 0.0239
Batch 130, Loss: 0.0236
Batch 140, Loss: 0.0224
Batch 150, Loss: 0.0227
Batch 160, Loss: 0.0220
Batch 170, Loss: 0.0223
Batch 180, Loss: 0.0203
Batch 190, Loss: 0.0239
Batch 200, Loss: 0.0215
Batch 210, Loss: 0.0266
Batch 220, Loss: 0.0223
Batch 230, Loss: 0.0220
Batch 240, Loss: 0.0255
Batch 250, Loss: 0.0272
Batch 260, Loss: 0.0233
Batch 270, Loss: 0.0234
Batch 280, Loss: 0.0215
Batch 290, Loss: 0.0222
Batch 300, Loss: 0.0243
Batch 310, Loss: 0.0231
Batch 320, Loss: 0.0217
Batch 330, Loss: 0.0213
Batch 340, Loss: 0.0215
Batch 350, Loss: 0.0225
Batch 360, Loss: 0.0210
Batch 370, Loss: 0.0237
Batch 380, Loss: 0.0209
Batch 390, Loss: 0.0212
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.057122945785522 seconds
Epoch 197 accuracy: 79.31%
Batch 10, Loss: 0.0227
Batch 20, Loss: 0.0221
Batch 30, Loss: 0.0200
Batch 40, Loss: 0.0224
Batch 50, Loss: 0.0216
Batch 60, Loss: 0.0257
Batch 70, Loss: 0.0231
Batch 80, Loss: 0.0245
Batch 90, Loss: 0.0214
Batch 100, Loss: 0.0229
Batch 110, Loss: 0.0266
Batch 120, Loss: 0.0213
Batch 130, Loss: 0.0238
Batch 140, Loss: 0.0234
Batch 150, Loss: 0.0225
Batch 160, Loss: 0.0215
Batch 170, Loss: 0.0224
Batch 180, Loss: 0.0223
Batch 190, Loss: 0.0225
Batch 200, Loss: 0.0246
Batch 210, Loss: 0.0210
Batch 220, Loss: 0.0242
Batch 230, Loss: 0.0229
Batch 240, Loss: 0.0244
Batch 250, Loss: 0.0225
Batch 260, Loss: 0.0220
Batch 270, Loss: 0.0224
Batch 280, Loss: 0.0223
Batch 290, Loss: 0.0257
Batch 300, Loss: 0.0196
Batch 310, Loss: 0.0217
Batch 320, Loss: 0.0208
Batch 330, Loss: 0.0229
Batch 340, Loss: 0.0232
Batch 350, Loss: 0.0240
Batch 360, Loss: 0.0230
Batch 370, Loss: 0.0211
Batch 380, Loss: 0.0226
Batch 390, Loss: 0.0246
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.07890224456787 seconds
Epoch 198 accuracy: 79.48%
Batch 10, Loss: 0.0254
Batch 20, Loss: 0.0233
Batch 30, Loss: 0.0220
Batch 40, Loss: 0.0235
Batch 50, Loss: 0.0197
Batch 60, Loss: 0.0213
Batch 70, Loss: 0.0212
Batch 80, Loss: 0.0224
Batch 90, Loss: 0.0211
Batch 100, Loss: 0.0229
Batch 110, Loss: 0.0215
Batch 120, Loss: 0.0248
Batch 130, Loss: 0.0202
Batch 140, Loss: 0.0235
Batch 150, Loss: 0.0223
Batch 160, Loss: 0.0231
Batch 170, Loss: 0.0211
Batch 180, Loss: 0.0251
Batch 190, Loss: 0.0221
Batch 200, Loss: 0.0241
Batch 210, Loss: 0.0238
Batch 220, Loss: 0.0225
Batch 230, Loss: 0.0221
Batch 240, Loss: 0.0213
Batch 250, Loss: 0.0205
Batch 260, Loss: 0.0224
Batch 270, Loss: 0.0234
Batch 280, Loss: 0.0224
Batch 290, Loss: 0.0230
Batch 300, Loss: 0.0220
Batch 310, Loss: 0.0208
Batch 320, Loss: 0.0232
Batch 330, Loss: 0.0215
Batch 340, Loss: 0.0199
Batch 350, Loss: 0.0213
Batch 360, Loss: 0.0235
Batch 370, Loss: 0.0250
Batch 380, Loss: 0.0221
Batch 390, Loss: 0.0202
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.08042311668396 seconds
Epoch 199 accuracy: 79.29%
Batch 10, Loss: 0.0240
Batch 20, Loss: 0.0194
Batch 30, Loss: 0.0212
Batch 40, Loss: 0.0217
Batch 50, Loss: 0.0225
Batch 60, Loss: 0.0216
Batch 70, Loss: 0.0219
Batch 80, Loss: 0.0235
Batch 90, Loss: 0.0208
Batch 100, Loss: 0.0221
Batch 110, Loss: 0.0209
Batch 120, Loss: 0.0248
Batch 130, Loss: 0.0211
Batch 140, Loss: 0.0235
Batch 150, Loss: 0.0229
Batch 160, Loss: 0.0227
Batch 170, Loss: 0.0208
Batch 180, Loss: 0.0220
Batch 190, Loss: 0.0212
Batch 200, Loss: 0.0207
Batch 210, Loss: 0.0218
Batch 220, Loss: 0.0217
Batch 230, Loss: 0.0222
Batch 240, Loss: 0.0214
Batch 250, Loss: 0.0214
Batch 260, Loss: 0.0248
Batch 270, Loss: 0.0196
Batch 280, Loss: 0.0211
Batch 290, Loss: 0.0230
Batch 300, Loss: 0.0243
Batch 310, Loss: 0.0219
Batch 320, Loss: 0.0198
Batch 330, Loss: 0.0219
Batch 340, Loss: 0.0226
Batch 350, Loss: 0.0222
Batch 360, Loss: 0.0215
Batch 370, Loss: 0.0201
Batch 380, Loss: 0.0239
Batch 390, Loss: 0.0235
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.03337335586548 seconds
Epoch 200 accuracy: 79.33%
Total training time: 5045.765716552734 seconds
