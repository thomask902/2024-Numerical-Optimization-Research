The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1258
Batch 20, Loss: 4.1370
Batch 30, Loss: 3.9780
Batch 40, Loss: 3.8606
Batch 50, Loss: 3.8071
Batch 60, Loss: 3.7501
Batch 70, Loss: 3.6903
Batch 80, Loss: 3.6925
Batch 90, Loss: 3.6862
Batch 100, Loss: 3.6233
Batch 110, Loss: 3.6200
Batch 120, Loss: 3.6125
Batch 130, Loss: 3.6163
Batch 140, Loss: 3.5836
Batch 150, Loss: 3.6066
Batch 160, Loss: 3.5868
Batch 170, Loss: 3.5526
Batch 180, Loss: 3.5665
Batch 190, Loss: 3.5562
Batch 200, Loss: 3.5585
Batch 210, Loss: 3.5444
Batch 220, Loss: 3.5250
Batch 230, Loss: 3.5357
Batch 240, Loss: 3.4867
Batch 250, Loss: 3.4971
Batch 260, Loss: 3.4935
Batch 270, Loss: 3.4717
Batch 280, Loss: 3.4628
Batch 290, Loss: 3.4391
Batch 300, Loss: 3.4615
Batch 310, Loss: 3.4997
Batch 320, Loss: 3.4188
Batch 330, Loss: 3.4664
Batch 340, Loss: 3.4599
Batch 350, Loss: 3.4522
Batch 360, Loss: 3.4386
Batch 370, Loss: 3.4606
Batch 380, Loss: 3.4154
Batch 390, Loss: 3.4358
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.601033926010132 seconds
Epoch 1 accuracy: 10.15%
Batch 10, Loss: 3.3702
Batch 20, Loss: 3.3614
Batch 30, Loss: 3.4223
Batch 40, Loss: 3.4016
Batch 50, Loss: 3.4025
Batch 60, Loss: 3.4103
Batch 70, Loss: 3.4010
Batch 80, Loss: 3.3560
Batch 90, Loss: 3.3398
Batch 100, Loss: 3.3491
Batch 110, Loss: 3.3737
Batch 120, Loss: 3.3409
Batch 130, Loss: 3.3633
Batch 140, Loss: 3.3453
Batch 150, Loss: 3.2962
Batch 160, Loss: 3.3331
Batch 170, Loss: 3.2306
Batch 180, Loss: 3.3035
Batch 190, Loss: 3.2986
Batch 200, Loss: 3.3030
Batch 210, Loss: 3.2877
Batch 220, Loss: 3.2848
Batch 230, Loss: 3.3113
Batch 240, Loss: 3.2905
Batch 250, Loss: 3.2796
Batch 260, Loss: 3.2171
Batch 270, Loss: 3.2621
Batch 280, Loss: 3.2872
Batch 290, Loss: 3.2305
Batch 300, Loss: 3.2302
Batch 310, Loss: 3.2155
Batch 320, Loss: 3.2159
Batch 330, Loss: 3.1749
Batch 340, Loss: 3.1932
Batch 350, Loss: 3.2091
Batch 360, Loss: 3.1918
Batch 370, Loss: 3.1774
Batch 380, Loss: 3.1575
Batch 390, Loss: 3.0579
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.51854634284973 seconds
Epoch 2 accuracy: 14.9%
Batch 10, Loss: 3.2073
Batch 20, Loss: 3.1444
Batch 30, Loss: 3.1390
Batch 40, Loss: 3.1476
Batch 50, Loss: 3.1061
Batch 60, Loss: 3.1239
Batch 70, Loss: 3.1069
Batch 80, Loss: 3.0687
Batch 90, Loss: 3.1163
Batch 100, Loss: 3.0752
Batch 110, Loss: 3.1007
Batch 120, Loss: 3.0945
Batch 130, Loss: 3.0730
Batch 140, Loss: 3.0221
Batch 150, Loss: 3.0228
Batch 160, Loss: 3.1016
Batch 170, Loss: 3.0114
Batch 180, Loss: 3.0218
Batch 190, Loss: 3.0390
Batch 200, Loss: 3.0262
Batch 210, Loss: 2.9311
Batch 220, Loss: 3.0281
Batch 230, Loss: 3.0274
Batch 240, Loss: 2.9279
Batch 250, Loss: 3.0209
Batch 260, Loss: 2.9588
Batch 270, Loss: 2.9786
Batch 280, Loss: 2.9376
Batch 290, Loss: 2.9556
Batch 300, Loss: 2.9898
Batch 310, Loss: 2.9785
Batch 320, Loss: 2.9250
Batch 330, Loss: 2.9011
Batch 340, Loss: 2.9170
Batch 350, Loss: 2.9513
Batch 360, Loss: 2.9349
Batch 370, Loss: 2.8920
Batch 380, Loss: 2.9305
Batch 390, Loss: 2.9561
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.50779414176941 seconds
Epoch 3 accuracy: 23.39%
Batch 10, Loss: 2.8650
Batch 20, Loss: 2.8469
Batch 30, Loss: 2.8910
Batch 40, Loss: 2.8098
Batch 50, Loss: 2.8687
Batch 60, Loss: 2.8170
Batch 70, Loss: 2.7925
Batch 80, Loss: 2.7701
Batch 90, Loss: 2.7919
Batch 100, Loss: 2.8192
Batch 110, Loss: 2.8038
Batch 120, Loss: 2.8061
Batch 130, Loss: 2.7951
Batch 140, Loss: 2.6937
Batch 150, Loss: 2.7351
Batch 160, Loss: 2.7835
Batch 170, Loss: 2.7191
Batch 180, Loss: 2.7699
Batch 190, Loss: 2.6879
Batch 200, Loss: 2.6559
Batch 210, Loss: 2.7152
Batch 220, Loss: 2.6819
Batch 230, Loss: 2.6740
Batch 240, Loss: 2.6934
Batch 250, Loss: 2.7371
Batch 260, Loss: 2.6362
Batch 270, Loss: 2.5842
Batch 280, Loss: 2.6547
Batch 290, Loss: 2.6302
Batch 300, Loss: 2.7010
Batch 310, Loss: 2.5878
Batch 320, Loss: 2.5951
Batch 330, Loss: 2.6425
Batch 340, Loss: 2.6650
Batch 350, Loss: 2.5833
Batch 360, Loss: 2.5968
Batch 370, Loss: 2.6194
Batch 380, Loss: 2.5878
Batch 390, Loss: 2.6615
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.440015077590942 seconds
Epoch 4 accuracy: 27.78%
Batch 10, Loss: 2.5469
Batch 20, Loss: 2.5162
Batch 30, Loss: 2.4721
Batch 40, Loss: 2.4750
Batch 50, Loss: 2.5728
Batch 60, Loss: 2.4795
Batch 70, Loss: 2.5204
Batch 80, Loss: 2.5028
Batch 90, Loss: 2.5668
Batch 100, Loss: 2.5274
Batch 110, Loss: 2.4959
Batch 120, Loss: 2.5777
Batch 130, Loss: 2.4508
Batch 140, Loss: 2.4940
Batch 150, Loss: 2.4887
Batch 160, Loss: 2.4366
Batch 170, Loss: 2.4485
Batch 180, Loss: 2.4223
Batch 190, Loss: 2.4973
Batch 200, Loss: 2.4481
Batch 210, Loss: 2.3991
Batch 220, Loss: 2.4481
Batch 230, Loss: 2.4385
Batch 240, Loss: 2.4033
Batch 250, Loss: 2.4590
Batch 260, Loss: 2.4254
Batch 270, Loss: 2.3999
Batch 280, Loss: 2.3883
Batch 290, Loss: 2.3748
Batch 300, Loss: 2.3209
Batch 310, Loss: 2.4070
Batch 320, Loss: 2.4213
Batch 330, Loss: 2.3572
Batch 340, Loss: 2.4059
Batch 350, Loss: 2.3726
Batch 360, Loss: 2.3803
Batch 370, Loss: 2.4124
Batch 380, Loss: 2.3383
Batch 390, Loss: 2.3771
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.48218607902527 seconds
Epoch 5 accuracy: 34.02%
Batch 10, Loss: 2.3980
Batch 20, Loss: 2.2890
Batch 30, Loss: 2.2766
Batch 40, Loss: 2.2747
Batch 50, Loss: 2.3099
Batch 60, Loss: 2.2625
Batch 70, Loss: 2.3340
Batch 80, Loss: 2.3041
Batch 90, Loss: 2.2901
Batch 100, Loss: 2.3512
Batch 110, Loss: 2.3642
Batch 120, Loss: 2.3819
Batch 130, Loss: 2.3416
Batch 140, Loss: 2.3533
Batch 150, Loss: 2.2733
Batch 160, Loss: 2.3071
Batch 170, Loss: 2.3022
Batch 180, Loss: 2.3239
Batch 190, Loss: 2.3069
Batch 200, Loss: 2.3029
Batch 210, Loss: 2.2587
Batch 220, Loss: 2.2542
Batch 230, Loss: 2.2589
Batch 240, Loss: 2.2018
Batch 250, Loss: 2.2299
Batch 260, Loss: 2.1942
Batch 270, Loss: 2.2341
Batch 280, Loss: 2.2376
Batch 290, Loss: 2.2437
Batch 300, Loss: 2.2213
Batch 310, Loss: 2.2552
Batch 320, Loss: 2.2416
Batch 330, Loss: 2.2820
Batch 340, Loss: 2.2111
Batch 350, Loss: 2.2672
Batch 360, Loss: 2.2487
Batch 370, Loss: 2.1586
Batch 380, Loss: 2.2164
Batch 390, Loss: 2.1844
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.416027069091797 seconds
Epoch 6 accuracy: 33.23%
Batch 10, Loss: 2.2570
Batch 20, Loss: 2.1614
Batch 30, Loss: 2.1321
Batch 40, Loss: 2.1961
Batch 50, Loss: 2.1621
Batch 60, Loss: 2.1465
Batch 70, Loss: 2.2572
Batch 80, Loss: 2.1402
Batch 90, Loss: 2.1890
Batch 100, Loss: 2.1871
Batch 110, Loss: 2.2245
Batch 120, Loss: 2.2310
Batch 130, Loss: 2.1638
Batch 140, Loss: 2.1238
Batch 150, Loss: 2.1434
Batch 160, Loss: 2.2431
Batch 170, Loss: 2.2174
Batch 180, Loss: 2.1858
Batch 190, Loss: 2.1303
Batch 200, Loss: 2.1192
Batch 210, Loss: 2.1300
Batch 220, Loss: 2.1602
Batch 230, Loss: 2.1462
Batch 240, Loss: 2.1699
Batch 250, Loss: 2.1716
Batch 260, Loss: 2.1007
Batch 270, Loss: 2.1055
Batch 280, Loss: 2.1202
Batch 290, Loss: 2.1231
Batch 300, Loss: 2.1623
Batch 310, Loss: 2.1473
Batch 320, Loss: 2.2134
Batch 330, Loss: 2.0598
Batch 340, Loss: 2.1399
Batch 350, Loss: 2.1062
Batch 360, Loss: 2.0954
Batch 370, Loss: 2.0854
Batch 380, Loss: 2.1078
Batch 390, Loss: 2.0411
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.404822826385498 seconds
Epoch 7 accuracy: 37.3%
Batch 10, Loss: 2.0818
Batch 20, Loss: 2.0737
Batch 30, Loss: 1.9778
Batch 40, Loss: 2.0101
Batch 50, Loss: 2.0421
Batch 60, Loss: 2.1065
Batch 70, Loss: 2.0649
Batch 80, Loss: 2.0917
Batch 90, Loss: 2.0115
Batch 100, Loss: 2.0122
Batch 110, Loss: 1.9700
Batch 120, Loss: 1.9595
Batch 130, Loss: 2.1029
Batch 140, Loss: 2.0356
Batch 150, Loss: 2.0665
Batch 160, Loss: 2.1108
Batch 170, Loss: 2.0291
Batch 180, Loss: 1.9820
Batch 190, Loss: 2.0855
Batch 200, Loss: 2.0181
Batch 210, Loss: 1.9802
Batch 220, Loss: 2.0411
Batch 230, Loss: 2.0272
Batch 240, Loss: 2.0225
Batch 250, Loss: 1.9438
Batch 260, Loss: 2.0086
Batch 270, Loss: 2.0284
Batch 280, Loss: 1.9774
Batch 290, Loss: 1.9733
Batch 300, Loss: 1.9858
Batch 310, Loss: 2.0564
Batch 320, Loss: 2.0194
Batch 330, Loss: 2.0208
Batch 340, Loss: 2.0254
Batch 350, Loss: 2.0306
Batch 360, Loss: 2.0150
Batch 370, Loss: 2.0629
Batch 380, Loss: 1.8989
Batch 390, Loss: 1.9553
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.414335250854492 seconds
Epoch 8 accuracy: 39.42%
Batch 10, Loss: 1.9654
Batch 20, Loss: 1.9176
Batch 30, Loss: 1.8808
Batch 40, Loss: 1.9859
Batch 50, Loss: 1.9523
Batch 60, Loss: 1.9792
Batch 70, Loss: 1.9640
Batch 80, Loss: 1.9450
Batch 90, Loss: 1.9422
Batch 100, Loss: 1.9366
Batch 110, Loss: 1.9855
Batch 120, Loss: 2.0014
Batch 130, Loss: 1.8929
Batch 140, Loss: 1.9067
Batch 150, Loss: 1.9683
Batch 160, Loss: 1.9835
Batch 170, Loss: 1.9747
Batch 180, Loss: 1.9756
Batch 190, Loss: 1.9647
Batch 200, Loss: 1.8380
Batch 210, Loss: 1.9266
Batch 220, Loss: 1.9666
Batch 230, Loss: 1.9477
Batch 240, Loss: 2.0100
Batch 250, Loss: 1.9717
Batch 260, Loss: 2.0504
Batch 270, Loss: 1.9132
Batch 280, Loss: 1.9412
Batch 290, Loss: 2.0371
Batch 300, Loss: 1.9977
Batch 310, Loss: 1.9659
Batch 320, Loss: 1.9775
Batch 330, Loss: 1.9668
Batch 340, Loss: 1.9175
Batch 350, Loss: 1.9716
Batch 360, Loss: 1.9171
Batch 370, Loss: 1.9032
Batch 380, Loss: 2.0308
Batch 390, Loss: 1.8629
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.54067635536194 seconds
Epoch 9 accuracy: 45.7%
Batch 10, Loss: 1.8045
Batch 20, Loss: 1.8758
Batch 30, Loss: 1.8909
Batch 40, Loss: 1.8776
Batch 50, Loss: 1.9425
Batch 60, Loss: 1.8718
Batch 70, Loss: 1.9088
Batch 80, Loss: 1.9055
Batch 90, Loss: 1.8712
Batch 100, Loss: 1.9217
Batch 110, Loss: 1.9028
Batch 120, Loss: 1.8631
Batch 130, Loss: 1.9055
Batch 140, Loss: 1.8659
Batch 150, Loss: 1.9294
Batch 160, Loss: 1.9820
Batch 170, Loss: 1.9319
Batch 180, Loss: 1.9026
Batch 190, Loss: 1.9284
Batch 200, Loss: 1.8848
Batch 210, Loss: 1.8470
Batch 220, Loss: 1.9324
Batch 230, Loss: 1.8821
Batch 240, Loss: 1.8728
Batch 250, Loss: 1.8696
Batch 260, Loss: 1.8724
Batch 270, Loss: 1.9567
Batch 280, Loss: 1.8635
Batch 290, Loss: 1.8774
Batch 300, Loss: 1.8615
Batch 310, Loss: 1.8530
Batch 320, Loss: 1.8547
Batch 330, Loss: 1.9343
Batch 340, Loss: 1.8831
Batch 350, Loss: 1.8694
Batch 360, Loss: 1.9052
Batch 370, Loss: 1.9000
Batch 380, Loss: 1.8298
Batch 390, Loss: 1.8734
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.46341896057129 seconds
Epoch 10 accuracy: 46.91%
Batch 10, Loss: 1.8180
Batch 20, Loss: 1.8745
Batch 30, Loss: 1.8683
Batch 40, Loss: 1.8152
Batch 50, Loss: 1.8221
Batch 60, Loss: 1.8841
Batch 70, Loss: 1.8251
Batch 80, Loss: 1.7966
Batch 90, Loss: 1.8935
Batch 100, Loss: 1.8865
Batch 110, Loss: 1.8404
Batch 120, Loss: 1.8206
Batch 130, Loss: 1.8285
Batch 140, Loss: 1.8000
Batch 150, Loss: 1.9675
Batch 160, Loss: 1.8192
Batch 170, Loss: 1.8492
Batch 180, Loss: 1.8285
Batch 190, Loss: 1.8164
Batch 200, Loss: 1.8948
Batch 210, Loss: 1.8730
Batch 220, Loss: 1.8043
Batch 230, Loss: 1.8271
Batch 240, Loss: 1.8447
Batch 250, Loss: 1.8665
Batch 260, Loss: 1.7752
Batch 270, Loss: 1.7581
Batch 280, Loss: 1.8122
Batch 290, Loss: 1.8124
Batch 300, Loss: 1.8167
Batch 310, Loss: 1.8805
Batch 320, Loss: 1.8550
Batch 330, Loss: 1.8370
Batch 340, Loss: 1.8101
Batch 350, Loss: 1.8382
Batch 360, Loss: 1.7757
Batch 370, Loss: 1.7812
Batch 380, Loss: 1.8905
Batch 390, Loss: 1.8342
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.41302251815796 seconds
Epoch 11 accuracy: 47.22%
Batch 10, Loss: 1.8543
Batch 20, Loss: 1.7639
Batch 30, Loss: 1.7440
Batch 40, Loss: 1.7827
Batch 50, Loss: 1.7317
Batch 60, Loss: 1.8403
Batch 70, Loss: 1.7412
Batch 80, Loss: 1.7219
Batch 90, Loss: 1.7187
Batch 100, Loss: 1.7949
Batch 110, Loss: 1.7733
Batch 120, Loss: 1.8273
Batch 130, Loss: 1.7614
Batch 140, Loss: 1.7614
Batch 150, Loss: 1.8279
Batch 160, Loss: 1.8445
Batch 170, Loss: 1.8227
Batch 180, Loss: 1.8363
Batch 190, Loss: 1.7914
Batch 200, Loss: 1.8841
Batch 210, Loss: 1.8652
Batch 220, Loss: 1.8095
Batch 230, Loss: 1.8240
Batch 240, Loss: 1.8136
Batch 250, Loss: 1.7385
Batch 260, Loss: 1.8191
Batch 270, Loss: 1.8118
Batch 280, Loss: 1.7993
Batch 290, Loss: 1.7909
Batch 300, Loss: 1.8141
Batch 310, Loss: 1.8046
Batch 320, Loss: 1.8124
Batch 330, Loss: 1.7624
Batch 340, Loss: 1.8486
Batch 350, Loss: 1.7878
Batch 360, Loss: 1.7708
Batch 370, Loss: 1.8152
Batch 380, Loss: 1.8921
Batch 390, Loss: 1.8848
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.450823068618774 seconds
Epoch 12 accuracy: 48.57%
Batch 10, Loss: 1.7323
Batch 20, Loss: 1.7142
Batch 30, Loss: 1.6609
Batch 40, Loss: 1.7939
Batch 50, Loss: 1.7692
Batch 60, Loss: 1.7646
Batch 70, Loss: 1.7342
Batch 80, Loss: 1.7342
Batch 90, Loss: 1.8320
Batch 100, Loss: 1.7639
Batch 110, Loss: 1.7067
Batch 120, Loss: 1.7404
Batch 130, Loss: 1.7331
Batch 140, Loss: 1.7306
Batch 150, Loss: 1.6962
Batch 160, Loss: 1.7494
Batch 170, Loss: 1.8032
Batch 180, Loss: 1.7394
Batch 190, Loss: 1.7878
Batch 200, Loss: 1.7163
Batch 210, Loss: 1.7791
Batch 220, Loss: 1.7560
Batch 230, Loss: 1.7630
Batch 240, Loss: 1.7130
Batch 250, Loss: 1.7679
Batch 260, Loss: 1.8338
Batch 270, Loss: 1.8037
Batch 280, Loss: 1.7639
Batch 290, Loss: 1.8002
Batch 300, Loss: 1.7569
Batch 310, Loss: 1.7430
Batch 320, Loss: 1.8077
Batch 330, Loss: 1.7236
Batch 340, Loss: 1.7365
Batch 350, Loss: 1.7720
Batch 360, Loss: 1.7056
Batch 370, Loss: 1.8123
Batch 380, Loss: 1.7426
Batch 390, Loss: 1.7704
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.391770839691162 seconds
Epoch 13 accuracy: 49.37%
Batch 10, Loss: 1.7283
Batch 20, Loss: 1.7234
Batch 30, Loss: 1.6822
Batch 40, Loss: 1.6999
Batch 50, Loss: 1.7051
Batch 60, Loss: 1.6278
Batch 70, Loss: 1.6977
Batch 80, Loss: 1.7016
Batch 90, Loss: 1.6948
Batch 100, Loss: 1.8295
Batch 110, Loss: 1.6916
Batch 120, Loss: 1.7426
Batch 130, Loss: 1.6663
Batch 140, Loss: 1.7048
Batch 150, Loss: 1.6762
Batch 160, Loss: 1.7427
Batch 170, Loss: 1.7157
Batch 180, Loss: 1.7028
Batch 190, Loss: 1.7427
Batch 200, Loss: 1.7284
Batch 210, Loss: 1.7582
Batch 220, Loss: 1.7548
Batch 230, Loss: 1.6728
Batch 240, Loss: 1.7099
Batch 250, Loss: 1.7202
Batch 260, Loss: 1.6631
Batch 270, Loss: 1.8315
Batch 280, Loss: 1.7473
Batch 290, Loss: 1.8329
Batch 300, Loss: 1.7042
Batch 310, Loss: 1.7118
Batch 320, Loss: 1.6896
Batch 330, Loss: 1.7954
Batch 340, Loss: 1.7333
Batch 350, Loss: 1.7343
Batch 360, Loss: 1.7570
Batch 370, Loss: 1.7907
Batch 380, Loss: 1.8043
Batch 390, Loss: 1.7615
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.392436504364014 seconds
Epoch 14 accuracy: 49.41%
Batch 10, Loss: 1.6857
Batch 20, Loss: 1.7194
Batch 30, Loss: 1.7309
Batch 40, Loss: 1.7310
Batch 50, Loss: 1.7394
Batch 60, Loss: 1.7203
Batch 70, Loss: 1.6861
Batch 80, Loss: 1.6876
Batch 90, Loss: 1.6811
Batch 100, Loss: 1.6873
Batch 110, Loss: 1.6533
Batch 120, Loss: 1.6744
Batch 130, Loss: 1.7097
Batch 140, Loss: 1.6910
Batch 150, Loss: 1.6662
Batch 160, Loss: 1.6574
Batch 170, Loss: 1.6474
Batch 180, Loss: 1.7622
Batch 190, Loss: 1.6976
Batch 200, Loss: 1.6860
Batch 210, Loss: 1.7136
Batch 220, Loss: 1.6540
Batch 230, Loss: 1.6740
Batch 240, Loss: 1.6828
Batch 250, Loss: 1.7182
Batch 260, Loss: 1.7262
Batch 270, Loss: 1.7031
Batch 280, Loss: 1.7054
Batch 290, Loss: 1.6900
Batch 300, Loss: 1.7604
Batch 310, Loss: 1.6483
Batch 320, Loss: 1.7456
Batch 330, Loss: 1.6702
Batch 340, Loss: 1.7624
Batch 350, Loss: 1.7445
Batch 360, Loss: 1.7004
Batch 370, Loss: 1.7510
Batch 380, Loss: 1.6359
Batch 390, Loss: 1.7215
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.494408130645752 seconds
Epoch 15 accuracy: 48.46%
Batch 10, Loss: 1.6793
Batch 20, Loss: 1.6582
Batch 30, Loss: 1.6634
Batch 40, Loss: 1.5940
Batch 50, Loss: 1.6566
Batch 60, Loss: 1.6946
Batch 70, Loss: 1.6684
Batch 80, Loss: 1.6225
Batch 90, Loss: 1.6574
Batch 100, Loss: 1.6451
Batch 110, Loss: 1.6612
Batch 120, Loss: 1.7325
Batch 130, Loss: 1.7431
Batch 140, Loss: 1.6810
Batch 150, Loss: 1.6565
Batch 160, Loss: 1.6935
Batch 170, Loss: 1.6795
Batch 180, Loss: 1.7150
Batch 190, Loss: 1.6709
Batch 200, Loss: 1.6262
Batch 210, Loss: 1.6831
Batch 220, Loss: 1.7003
Batch 230, Loss: 1.6776
Batch 240, Loss: 1.6487
Batch 250, Loss: 1.6960
Batch 260, Loss: 1.6531
Batch 270, Loss: 1.6907
Batch 280, Loss: 1.7517
Batch 290, Loss: 1.6839
Batch 300, Loss: 1.7186
Batch 310, Loss: 1.7093
Batch 320, Loss: 1.6982
Batch 330, Loss: 1.6999
Batch 340, Loss: 1.6981
Batch 350, Loss: 1.7433
Batch 360, Loss: 1.6718
Batch 370, Loss: 1.6262
Batch 380, Loss: 1.7138
Batch 390, Loss: 1.6367
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.55913257598877 seconds
Epoch 16 accuracy: 43.64%
Batch 10, Loss: 1.6212
Batch 20, Loss: 1.6259
Batch 30, Loss: 1.5840
Batch 40, Loss: 1.5628
Batch 50, Loss: 1.6318
Batch 60, Loss: 1.6977
Batch 70, Loss: 1.6608
Batch 80, Loss: 1.6473
Batch 90, Loss: 1.6722
Batch 100, Loss: 1.6961
Batch 110, Loss: 1.6882
Batch 120, Loss: 1.6230
Batch 130, Loss: 1.6697
Batch 140, Loss: 1.6986
Batch 150, Loss: 1.6948
Batch 160, Loss: 1.6191
Batch 170, Loss: 1.6849
Batch 180, Loss: 1.6674
Batch 190, Loss: 1.6281
Batch 200, Loss: 1.5794
Batch 210, Loss: 1.6981
Batch 220, Loss: 1.6373
Batch 230, Loss: 1.7284
Batch 240, Loss: 1.7708
Batch 250, Loss: 1.7129
Batch 260, Loss: 1.6399
Batch 270, Loss: 1.7112
Batch 280, Loss: 1.5985
Batch 290, Loss: 1.6811
Batch 300, Loss: 1.6344
Batch 310, Loss: 1.6934
Batch 320, Loss: 1.6799
Batch 330, Loss: 1.6617
Batch 340, Loss: 1.6108
Batch 350, Loss: 1.7160
Batch 360, Loss: 1.6745
Batch 370, Loss: 1.7026
Batch 380, Loss: 1.5656
Batch 390, Loss: 1.6265
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.34113335609436 seconds
Epoch 17 accuracy: 51.59%
Batch 10, Loss: 1.6273
Batch 20, Loss: 1.6028
Batch 30, Loss: 1.6206
Batch 40, Loss: 1.6935
Batch 50, Loss: 1.6053
Batch 60, Loss: 1.6291
Batch 70, Loss: 1.6384
Batch 80, Loss: 1.6438
Batch 90, Loss: 1.6984
Batch 100, Loss: 1.6064
Batch 110, Loss: 1.6126
Batch 120, Loss: 1.6301
Batch 130, Loss: 1.5753
Batch 140, Loss: 1.5780
Batch 150, Loss: 1.5811
Batch 160, Loss: 1.6819
Batch 170, Loss: 1.6627
Batch 180, Loss: 1.6334
Batch 190, Loss: 1.6706
Batch 200, Loss: 1.6536
Batch 210, Loss: 1.5898
Batch 220, Loss: 1.6746
Batch 230, Loss: 1.6599
Batch 240, Loss: 1.6368
Batch 250, Loss: 1.6679
Batch 260, Loss: 1.6513
Batch 270, Loss: 1.6185
Batch 280, Loss: 1.7042
Batch 290, Loss: 1.7046
Batch 300, Loss: 1.6872
Batch 310, Loss: 1.6684
Batch 320, Loss: 1.6615
Batch 330, Loss: 1.6513
Batch 340, Loss: 1.6648
Batch 350, Loss: 1.6654
Batch 360, Loss: 1.6266
Batch 370, Loss: 1.6203
Batch 380, Loss: 1.6687
Batch 390, Loss: 1.6076
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.46451497077942 seconds
Epoch 18 accuracy: 52.25%
Batch 10, Loss: 1.6664
Batch 20, Loss: 1.5665
Batch 30, Loss: 1.6322
Batch 40, Loss: 1.5996
Batch 50, Loss: 1.5820
Batch 60, Loss: 1.6395
Batch 70, Loss: 1.6119
Batch 80, Loss: 1.6794
Batch 90, Loss: 1.6559
Batch 100, Loss: 1.5979
Batch 110, Loss: 1.6697
Batch 120, Loss: 1.5627
Batch 130, Loss: 1.6861
Batch 140, Loss: 1.6100
Batch 150, Loss: 1.6132
Batch 160, Loss: 1.6042
Batch 170, Loss: 1.6175
Batch 180, Loss: 1.6354
Batch 190, Loss: 1.7310
Batch 200, Loss: 1.5892
Batch 210, Loss: 1.6186
Batch 220, Loss: 1.6135
Batch 230, Loss: 1.6703
Batch 240, Loss: 1.6012
Batch 250, Loss: 1.6941
Batch 260, Loss: 1.6246
Batch 270, Loss: 1.6798
Batch 280, Loss: 1.6399
Batch 290, Loss: 1.5976
Batch 300, Loss: 1.6204
Batch 310, Loss: 1.5868
Batch 320, Loss: 1.6276
Batch 330, Loss: 1.6055
Batch 340, Loss: 1.6695
Batch 350, Loss: 1.6378
Batch 360, Loss: 1.5528
Batch 370, Loss: 1.6275
Batch 380, Loss: 1.6488
Batch 390, Loss: 1.6627
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.390295028686523 seconds
Epoch 19 accuracy: 52.91%
Batch 10, Loss: 1.6028
Batch 20, Loss: 1.5755
Batch 30, Loss: 1.5361
Batch 40, Loss: 1.5775
Batch 50, Loss: 1.5245
Batch 60, Loss: 1.5991
Batch 70, Loss: 1.6437
Batch 80, Loss: 1.5867
Batch 90, Loss: 1.6333
Batch 100, Loss: 1.6015
Batch 110, Loss: 1.6283
Batch 120, Loss: 1.5302
Batch 130, Loss: 1.5547
Batch 140, Loss: 1.5258
Batch 150, Loss: 1.6014
Batch 160, Loss: 1.5825
Batch 170, Loss: 1.6417
Batch 180, Loss: 1.5446
Batch 190, Loss: 1.6069
Batch 200, Loss: 1.5986
Batch 210, Loss: 1.5881
Batch 220, Loss: 1.6942
Batch 230, Loss: 1.6093
Batch 240, Loss: 1.6320
Batch 250, Loss: 1.7013
Batch 260, Loss: 1.6773
Batch 270, Loss: 1.6265
Batch 280, Loss: 1.6534
Batch 290, Loss: 1.6458
Batch 300, Loss: 1.5994
Batch 310, Loss: 1.5736
Batch 320, Loss: 1.5964
Batch 330, Loss: 1.6447
Batch 340, Loss: 1.6693
Batch 350, Loss: 1.5852
Batch 360, Loss: 1.6380
Batch 370, Loss: 1.6580
Batch 380, Loss: 1.6495
Batch 390, Loss: 1.5584
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.57269048690796 seconds
Epoch 20 accuracy: 49.85%
Batch 10, Loss: 1.5623
Batch 20, Loss: 1.6176
Batch 30, Loss: 1.5380
Batch 40, Loss: 1.6110
Batch 50, Loss: 1.6251
Batch 60, Loss: 1.5548
Batch 70, Loss: 1.5343
Batch 80, Loss: 1.5200
Batch 90, Loss: 1.5795
Batch 100, Loss: 1.6223
Batch 110, Loss: 1.6399
Batch 120, Loss: 1.5335
Batch 130, Loss: 1.5693
Batch 140, Loss: 1.6054
Batch 150, Loss: 1.5137
Batch 160, Loss: 1.6406
Batch 170, Loss: 1.6184
Batch 180, Loss: 1.5877
Batch 190, Loss: 1.5997
Batch 200, Loss: 1.5936
Batch 210, Loss: 1.6101
Batch 220, Loss: 1.6042
Batch 230, Loss: 1.6172
Batch 240, Loss: 1.6849
Batch 250, Loss: 1.5221
Batch 260, Loss: 1.5990
Batch 270, Loss: 1.6551
Batch 280, Loss: 1.6268
Batch 290, Loss: 1.4814
Batch 300, Loss: 1.6392
Batch 310, Loss: 1.5838
Batch 320, Loss: 1.6014
Batch 330, Loss: 1.6456
Batch 340, Loss: 1.6123
Batch 350, Loss: 1.5773
Batch 360, Loss: 1.6176
Batch 370, Loss: 1.5769
Batch 380, Loss: 1.6245
Batch 390, Loss: 1.5906
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.498351573944092 seconds
Epoch 21 accuracy: 55.8%
Batch 10, Loss: 1.5586
Batch 20, Loss: 1.5146
Batch 30, Loss: 1.6259
Batch 40, Loss: 1.6317
Batch 50, Loss: 1.5718
Batch 60, Loss: 1.5671
Batch 70, Loss: 1.5523
Batch 80, Loss: 1.5221
Batch 90, Loss: 1.5229
Batch 100, Loss: 1.6283
Batch 110, Loss: 1.6303
Batch 120, Loss: 1.6103
Batch 130, Loss: 1.5451
Batch 140, Loss: 1.5290
Batch 150, Loss: 1.5040
Batch 160, Loss: 1.5595
Batch 170, Loss: 1.5988
Batch 180, Loss: 1.6410
Batch 190, Loss: 1.5876
Batch 200, Loss: 1.6034
Batch 210, Loss: 1.5643
Batch 220, Loss: 1.5121
Batch 230, Loss: 1.5481
Batch 240, Loss: 1.4865
Batch 250, Loss: 1.6692
Batch 260, Loss: 1.6291
Batch 270, Loss: 1.6096
Batch 280, Loss: 1.5304
Batch 290, Loss: 1.6464
Batch 300, Loss: 1.5399
Batch 310, Loss: 1.6029
Batch 320, Loss: 1.6072
Batch 330, Loss: 1.6620
Batch 340, Loss: 1.6370
Batch 350, Loss: 1.6289
Batch 360, Loss: 1.5312
Batch 370, Loss: 1.5876
Batch 380, Loss: 1.5104
Batch 390, Loss: 1.5646
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.451653242111206 seconds
Epoch 22 accuracy: 53.92%
Batch 10, Loss: 1.5360
Batch 20, Loss: 1.5410
Batch 30, Loss: 1.5692
Batch 40, Loss: 1.6255
Batch 50, Loss: 1.5640
Batch 60, Loss: 1.5781
Batch 70, Loss: 1.4820
Batch 80, Loss: 1.5716
Batch 90, Loss: 1.5373
Batch 100, Loss: 1.5184
Batch 110, Loss: 1.4817
Batch 120, Loss: 1.5480
Batch 130, Loss: 1.6170
Batch 140, Loss: 1.5453
Batch 150, Loss: 1.6281
Batch 160, Loss: 1.5712
Batch 170, Loss: 1.6391
Batch 180, Loss: 1.5873
Batch 190, Loss: 1.6068
Batch 200, Loss: 1.6019
Batch 210, Loss: 1.5466
Batch 220, Loss: 1.5880
Batch 230, Loss: 1.6236
Batch 240, Loss: 1.5858
Batch 250, Loss: 1.5519
Batch 260, Loss: 1.5186
Batch 270, Loss: 1.5551
Batch 280, Loss: 1.5995
Batch 290, Loss: 1.5888
Batch 300, Loss: 1.5746
Batch 310, Loss: 1.5944
Batch 320, Loss: 1.5277
Batch 330, Loss: 1.5671
Batch 340, Loss: 1.5666
Batch 350, Loss: 1.5366
Batch 360, Loss: 1.5464
Batch 370, Loss: 1.5219
Batch 380, Loss: 1.5767
Batch 390, Loss: 1.5866
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.472067832946777 seconds
Epoch 23 accuracy: 52.64%
Batch 10, Loss: 1.5099
Batch 20, Loss: 1.6375
Batch 30, Loss: 1.5509
Batch 40, Loss: 1.5309
Batch 50, Loss: 1.5893
Batch 60, Loss: 1.5897
Batch 70, Loss: 1.6079
Batch 80, Loss: 1.6175
Batch 90, Loss: 1.5625
Batch 100, Loss: 1.5562
Batch 110, Loss: 1.6407
Batch 120, Loss: 1.6134
Batch 130, Loss: 1.6067
Batch 140, Loss: 1.6161
Batch 150, Loss: 1.5187
Batch 160, Loss: 1.5260
Batch 170, Loss: 1.4750
Batch 180, Loss: 1.5170
Batch 190, Loss: 1.5490
Batch 200, Loss: 1.5700
Batch 210, Loss: 1.5249
Batch 220, Loss: 1.5417
Batch 230, Loss: 1.5347
Batch 240, Loss: 1.5926
Batch 250, Loss: 1.5779
Batch 260, Loss: 1.5608
Batch 270, Loss: 1.5858
Batch 280, Loss: 1.5714
Batch 290, Loss: 1.5930
Batch 300, Loss: 1.6271
Batch 310, Loss: 1.4879
Batch 320, Loss: 1.6459
Batch 330, Loss: 1.4975
Batch 340, Loss: 1.5509
Batch 350, Loss: 1.5344
Batch 360, Loss: 1.5314
Batch 370, Loss: 1.5943
Batch 380, Loss: 1.6112
Batch 390, Loss: 1.5765
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.429954528808594 seconds
Epoch 24 accuracy: 54.28%
Batch 10, Loss: 1.6417
Batch 20, Loss: 1.5446
Batch 30, Loss: 1.5431
Batch 40, Loss: 1.5623
Batch 50, Loss: 1.4951
Batch 60, Loss: 1.5124
Batch 70, Loss: 1.5357
Batch 80, Loss: 1.5655
Batch 90, Loss: 1.5628
Batch 100, Loss: 1.5344
Batch 110, Loss: 1.5076
Batch 120, Loss: 1.5264
Batch 130, Loss: 1.4756
Batch 140, Loss: 1.5576
Batch 150, Loss: 1.6280
Batch 160, Loss: 1.5751
Batch 170, Loss: 1.5526
Batch 180, Loss: 1.5860
Batch 190, Loss: 1.5207
Batch 200, Loss: 1.4850
Batch 210, Loss: 1.5173
Batch 220, Loss: 1.5753
Batch 230, Loss: 1.6293
Batch 240, Loss: 1.5533
Batch 250, Loss: 1.5921
Batch 260, Loss: 1.6060
Batch 270, Loss: 1.6297
Batch 280, Loss: 1.5378
Batch 290, Loss: 1.5330
Batch 300, Loss: 1.5210
Batch 310, Loss: 1.5441
Batch 320, Loss: 1.5257
Batch 330, Loss: 1.6041
Batch 340, Loss: 1.5042
Batch 350, Loss: 1.5416
Batch 360, Loss: 1.5279
Batch 370, Loss: 1.5748
Batch 380, Loss: 1.5509
Batch 390, Loss: 1.5919
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.34916377067566 seconds
Epoch 25 accuracy: 56.85%
Batch 10, Loss: 1.5679
Batch 20, Loss: 1.4875
Batch 30, Loss: 1.4820
Batch 40, Loss: 1.5650
Batch 50, Loss: 1.5508
Batch 60, Loss: 1.5583
Batch 70, Loss: 1.5212
Batch 80, Loss: 1.5706
Batch 90, Loss: 1.5343
Batch 100, Loss: 1.5051
Batch 110, Loss: 1.5212
Batch 120, Loss: 1.5748
Batch 130, Loss: 1.4656
Batch 140, Loss: 1.5474
Batch 150, Loss: 1.5301
Batch 160, Loss: 1.5217
Batch 170, Loss: 1.5236
Batch 180, Loss: 1.5271
Batch 190, Loss: 1.5486
Batch 200, Loss: 1.4646
Batch 210, Loss: 1.5667
Batch 220, Loss: 1.5555
Batch 230, Loss: 1.5696
Batch 240, Loss: 1.5084
Batch 250, Loss: 1.5816
Batch 260, Loss: 1.6028
Batch 270, Loss: 1.5873
Batch 280, Loss: 1.6052
Batch 290, Loss: 1.5513
Batch 300, Loss: 1.4794
Batch 310, Loss: 1.5139
Batch 320, Loss: 1.5518
Batch 330, Loss: 1.4825
Batch 340, Loss: 1.5967
Batch 350, Loss: 1.5390
Batch 360, Loss: 1.5396
Batch 370, Loss: 1.6248
Batch 380, Loss: 1.5688
Batch 390, Loss: 1.5280
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.426541328430176 seconds
Epoch 26 accuracy: 54.54%
Batch 10, Loss: 1.5190
Batch 20, Loss: 1.5385
Batch 30, Loss: 1.4887
Batch 40, Loss: 1.5366
Batch 50, Loss: 1.4823
Batch 60, Loss: 1.4968
Batch 70, Loss: 1.5140
Batch 80, Loss: 1.4597
Batch 90, Loss: 1.4661
Batch 100, Loss: 1.5737
Batch 110, Loss: 1.5698
Batch 120, Loss: 1.5038
Batch 130, Loss: 1.5512
Batch 140, Loss: 1.4854
Batch 150, Loss: 1.5772
Batch 160, Loss: 1.5589
Batch 170, Loss: 1.5685
Batch 180, Loss: 1.5535
Batch 190, Loss: 1.4888
Batch 200, Loss: 1.5230
Batch 210, Loss: 1.6049
Batch 220, Loss: 1.5323
Batch 230, Loss: 1.5344
Batch 240, Loss: 1.5499
Batch 250, Loss: 1.5546
Batch 260, Loss: 1.5360
Batch 270, Loss: 1.5193
Batch 280, Loss: 1.5425
Batch 290, Loss: 1.5868
Batch 300, Loss: 1.5494
Batch 310, Loss: 1.5823
Batch 320, Loss: 1.6078
Batch 330, Loss: 1.5900
Batch 340, Loss: 1.5013
Batch 350, Loss: 1.5505
Batch 360, Loss: 1.5570
Batch 370, Loss: 1.4782
Batch 380, Loss: 1.5912
Batch 390, Loss: 1.5203
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.47198486328125 seconds
Epoch 27 accuracy: 54.31%
Batch 10, Loss: 1.4947
Batch 20, Loss: 1.5099
Batch 30, Loss: 1.5256
Batch 40, Loss: 1.4845
Batch 50, Loss: 1.4441
Batch 60, Loss: 1.4710
Batch 70, Loss: 1.5076
Batch 80, Loss: 1.4934
Batch 90, Loss: 1.4862
Batch 100, Loss: 1.4913
Batch 110, Loss: 1.5179
Batch 120, Loss: 1.5219
Batch 130, Loss: 1.5670
Batch 140, Loss: 1.4930
Batch 150, Loss: 1.5421
Batch 160, Loss: 1.5341
Batch 170, Loss: 1.5613
Batch 180, Loss: 1.5187
Batch 190, Loss: 1.5766
Batch 200, Loss: 1.5325
Batch 210, Loss: 1.5415
Batch 220, Loss: 1.5123
Batch 230, Loss: 1.5655
Batch 240, Loss: 1.5293
Batch 250, Loss: 1.5485
Batch 260, Loss: 1.5914
Batch 270, Loss: 1.5207
Batch 280, Loss: 1.4229
Batch 290, Loss: 1.5748
Batch 300, Loss: 1.5116
Batch 310, Loss: 1.6113
Batch 320, Loss: 1.5145
Batch 330, Loss: 1.5253
Batch 340, Loss: 1.5774
Batch 350, Loss: 1.4851
Batch 360, Loss: 1.5450
Batch 370, Loss: 1.4560
Batch 380, Loss: 1.5407
Batch 390, Loss: 1.4976
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.430011987686157 seconds
Epoch 28 accuracy: 51.75%
Batch 10, Loss: 1.5751
Batch 20, Loss: 1.5364
Batch 30, Loss: 1.4594
Batch 40, Loss: 1.5372
Batch 50, Loss: 1.5169
Batch 60, Loss: 1.5006
Batch 70, Loss: 1.4656
Batch 80, Loss: 1.4654
Batch 90, Loss: 1.5836
Batch 100, Loss: 1.4890
Batch 110, Loss: 1.5153
Batch 120, Loss: 1.5482
Batch 130, Loss: 1.4664
Batch 140, Loss: 1.5056
Batch 150, Loss: 1.5398
Batch 160, Loss: 1.4629
Batch 170, Loss: 1.5697
Batch 180, Loss: 1.4411
Batch 190, Loss: 1.5494
Batch 200, Loss: 1.4887
Batch 210, Loss: 1.5129
Batch 220, Loss: 1.5157
Batch 230, Loss: 1.4408
Batch 240, Loss: 1.5559
Batch 250, Loss: 1.5009
Batch 260, Loss: 1.5383
Batch 270, Loss: 1.4815
Batch 280, Loss: 1.5067
Batch 290, Loss: 1.4599
Batch 300, Loss: 1.5811
Batch 310, Loss: 1.5328
Batch 320, Loss: 1.5035
Batch 330, Loss: 1.5303
Batch 340, Loss: 1.5722
Batch 350, Loss: 1.5447
Batch 360, Loss: 1.5159
Batch 370, Loss: 1.5210
Batch 380, Loss: 1.5290
Batch 390, Loss: 1.5704
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.438886642456055 seconds
Epoch 29 accuracy: 54.69%
Batch 10, Loss: 1.5084
Batch 20, Loss: 1.4520
Batch 30, Loss: 1.4581
Batch 40, Loss: 1.4461
Batch 50, Loss: 1.4899
Batch 60, Loss: 1.4381
Batch 70, Loss: 1.5520
Batch 80, Loss: 1.5650
Batch 90, Loss: 1.4906
Batch 100, Loss: 1.5441
Batch 110, Loss: 1.5275
Batch 120, Loss: 1.5252
Batch 130, Loss: 1.5197
Batch 140, Loss: 1.5553
Batch 150, Loss: 1.4671
Batch 160, Loss: 1.4617
Batch 170, Loss: 1.4756
Batch 180, Loss: 1.5028
Batch 190, Loss: 1.4955
Batch 200, Loss: 1.5310
Batch 210, Loss: 1.5350
Batch 220, Loss: 1.4918
Batch 230, Loss: 1.5710
Batch 240, Loss: 1.5631
Batch 250, Loss: 1.5486
Batch 260, Loss: 1.5450
Batch 270, Loss: 1.5435
Batch 280, Loss: 1.5327
Batch 290, Loss: 1.4952
Batch 300, Loss: 1.5148
Batch 310, Loss: 1.5933
Batch 320, Loss: 1.5771
Batch 330, Loss: 1.5116
Batch 340, Loss: 1.5504
Batch 350, Loss: 1.5483
Batch 360, Loss: 1.5120
Batch 370, Loss: 1.4782
Batch 380, Loss: 1.4812
Batch 390, Loss: 1.5166
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.54837989807129 seconds
Epoch 30 accuracy: 57.4%
Batch 10, Loss: 1.4972
Batch 20, Loss: 1.4080
Batch 30, Loss: 1.5142
Batch 40, Loss: 1.4341
Batch 50, Loss: 1.5986
Batch 60, Loss: 1.4761
Batch 70, Loss: 1.4368
Batch 80, Loss: 1.4915
Batch 90, Loss: 1.4150
Batch 100, Loss: 1.5744
Batch 110, Loss: 1.4700
Batch 120, Loss: 1.5319
Batch 130, Loss: 1.5813
Batch 140, Loss: 1.5109
Batch 150, Loss: 1.5039
Batch 160, Loss: 1.5399
Batch 170, Loss: 1.4666
Batch 180, Loss: 1.5238
Batch 190, Loss: 1.4882
Batch 200, Loss: 1.4531
Batch 210, Loss: 1.5571
Batch 220, Loss: 1.5196
Batch 230, Loss: 1.4720
Batch 240, Loss: 1.4842
Batch 250, Loss: 1.5509
Batch 260, Loss: 1.5164
Batch 270, Loss: 1.4896
Batch 280, Loss: 1.5006
Batch 290, Loss: 1.4747
Batch 300, Loss: 1.5276
Batch 310, Loss: 1.4724
Batch 320, Loss: 1.4866
Batch 330, Loss: 1.5119
Batch 340, Loss: 1.5114
Batch 350, Loss: 1.5549
Batch 360, Loss: 1.5262
Batch 370, Loss: 1.5211
Batch 380, Loss: 1.5133
Batch 390, Loss: 1.5358
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.42809820175171 seconds
Epoch 31 accuracy: 57.72%
Batch 10, Loss: 1.4288
Batch 20, Loss: 1.5107
Batch 30, Loss: 1.4532
Batch 40, Loss: 1.4497
Batch 50, Loss: 1.4988
Batch 60, Loss: 1.4703
Batch 70, Loss: 1.5137
Batch 80, Loss: 1.5333
Batch 90, Loss: 1.4837
Batch 100, Loss: 1.4484
Batch 110, Loss: 1.5363
Batch 120, Loss: 1.4631
Batch 130, Loss: 1.4999
Batch 140, Loss: 1.4900
Batch 150, Loss: 1.5425
Batch 160, Loss: 1.5385
Batch 170, Loss: 1.4654
Batch 180, Loss: 1.5645
Batch 190, Loss: 1.4728
Batch 200, Loss: 1.4716
Batch 210, Loss: 1.5248
Batch 220, Loss: 1.5097
Batch 230, Loss: 1.4838
Batch 240, Loss: 1.4907
Batch 250, Loss: 1.4739
Batch 260, Loss: 1.4642
Batch 270, Loss: 1.4250
Batch 280, Loss: 1.5217
Batch 290, Loss: 1.5356
Batch 300, Loss: 1.4987
Batch 310, Loss: 1.5305
Batch 320, Loss: 1.5938
Batch 330, Loss: 1.5424
Batch 340, Loss: 1.5460
Batch 350, Loss: 1.5006
Batch 360, Loss: 1.4794
Batch 370, Loss: 1.5942
Batch 380, Loss: 1.4828
Batch 390, Loss: 1.5220
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.425633430480957 seconds
Epoch 32 accuracy: 54.85%
Batch 10, Loss: 1.3913
Batch 20, Loss: 1.5181
Batch 30, Loss: 1.5048
Batch 40, Loss: 1.5071
Batch 50, Loss: 1.5268
Batch 60, Loss: 1.4403
Batch 70, Loss: 1.4700
Batch 80, Loss: 1.4816
Batch 90, Loss: 1.4773
Batch 100, Loss: 1.4738
Batch 110, Loss: 1.4486
Batch 120, Loss: 1.4221
Batch 130, Loss: 1.5088
Batch 140, Loss: 1.4642
Batch 150, Loss: 1.5436
Batch 160, Loss: 1.4733
Batch 170, Loss: 1.4474
Batch 180, Loss: 1.4822
Batch 190, Loss: 1.4977
Batch 200, Loss: 1.4981
Batch 210, Loss: 1.5134
Batch 220, Loss: 1.4787
Batch 230, Loss: 1.4601
Batch 240, Loss: 1.4674
Batch 250, Loss: 1.5241
Batch 260, Loss: 1.4860
Batch 270, Loss: 1.5084
Batch 280, Loss: 1.4233
Batch 290, Loss: 1.4856
Batch 300, Loss: 1.5047
Batch 310, Loss: 1.4927
Batch 320, Loss: 1.5650
Batch 330, Loss: 1.5408
Batch 340, Loss: 1.5130
Batch 350, Loss: 1.5474
Batch 360, Loss: 1.3974
Batch 370, Loss: 1.5332
Batch 380, Loss: 1.5639
Batch 390, Loss: 1.5312
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.40757703781128 seconds
Epoch 33 accuracy: 55.64%
Batch 10, Loss: 1.4870
Batch 20, Loss: 1.4635
Batch 30, Loss: 1.4522
Batch 40, Loss: 1.5601
Batch 50, Loss: 1.4596
Batch 60, Loss: 1.5044
Batch 70, Loss: 1.4666
Batch 80, Loss: 1.4471
Batch 90, Loss: 1.4011
Batch 100, Loss: 1.4631
Batch 110, Loss: 1.4644
Batch 120, Loss: 1.4994
Batch 130, Loss: 1.5171
Batch 140, Loss: 1.5037
Batch 150, Loss: 1.4028
Batch 160, Loss: 1.4695
Batch 170, Loss: 1.4786
Batch 180, Loss: 1.4366
Batch 190, Loss: 1.4573
Batch 200, Loss: 1.4841
Batch 210, Loss: 1.5026
Batch 220, Loss: 1.4639
Batch 230, Loss: 1.4671
Batch 240, Loss: 1.5038
Batch 250, Loss: 1.4419
Batch 260, Loss: 1.4758
Batch 270, Loss: 1.4658
Batch 280, Loss: 1.4357
Batch 290, Loss: 1.4516
Batch 300, Loss: 1.4514
Batch 310, Loss: 1.5062
Batch 320, Loss: 1.4915
Batch 330, Loss: 1.4731
Batch 340, Loss: 1.4941
Batch 350, Loss: 1.3865
Batch 360, Loss: 1.5331
Batch 370, Loss: 1.4931
Batch 380, Loss: 1.5440
Batch 390, Loss: 1.5673
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.506486892700195 seconds
Epoch 34 accuracy: 55.18%
Batch 10, Loss: 1.4480
Batch 20, Loss: 1.4189
Batch 30, Loss: 1.4081
Batch 40, Loss: 1.4754
Batch 50, Loss: 1.4180
Batch 60, Loss: 1.4011
Batch 70, Loss: 1.4348
Batch 80, Loss: 1.4398
Batch 90, Loss: 1.3948
Batch 100, Loss: 1.4242
Batch 110, Loss: 1.4571
Batch 120, Loss: 1.4707
Batch 130, Loss: 1.4253
Batch 140, Loss: 1.6091
Batch 150, Loss: 1.5129
Batch 160, Loss: 1.4775
Batch 170, Loss: 1.5025
Batch 180, Loss: 1.4745
Batch 190, Loss: 1.5295
Batch 200, Loss: 1.4705
Batch 210, Loss: 1.5472
Batch 220, Loss: 1.4973
Batch 230, Loss: 1.4734
Batch 240, Loss: 1.4708
Batch 250, Loss: 1.4864
Batch 260, Loss: 1.5034
Batch 270, Loss: 1.5940
Batch 280, Loss: 1.4813
Batch 290, Loss: 1.5076
Batch 300, Loss: 1.4998
Batch 310, Loss: 1.4751
Batch 320, Loss: 1.4515
Batch 330, Loss: 1.5019
Batch 340, Loss: 1.4576
Batch 350, Loss: 1.5065
Batch 360, Loss: 1.5016
Batch 370, Loss: 1.4762
Batch 380, Loss: 1.4911
Batch 390, Loss: 1.4095
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.470521450042725 seconds
Epoch 35 accuracy: 54.42%
Batch 10, Loss: 1.3650
Batch 20, Loss: 1.4904
Batch 30, Loss: 1.4502
Batch 40, Loss: 1.4527
Batch 50, Loss: 1.4878
Batch 60, Loss: 1.4074
Batch 70, Loss: 1.4896
Batch 80, Loss: 1.4057
Batch 90, Loss: 1.4239
Batch 100, Loss: 1.4615
Batch 110, Loss: 1.5340
Batch 120, Loss: 1.5026
Batch 130, Loss: 1.4384
Batch 140, Loss: 1.4266
Batch 150, Loss: 1.5104
Batch 160, Loss: 1.4893
Batch 170, Loss: 1.4295
Batch 180, Loss: 1.4407
Batch 190, Loss: 1.5170
Batch 200, Loss: 1.5027
Batch 210, Loss: 1.5488
Batch 220, Loss: 1.4799
Batch 230, Loss: 1.4243
Batch 240, Loss: 1.5867
Batch 250, Loss: 1.5193
Batch 260, Loss: 1.4551
Batch 270, Loss: 1.4592
Batch 280, Loss: 1.5714
Batch 290, Loss: 1.4843
Batch 300, Loss: 1.5072
Batch 310, Loss: 1.4537
Batch 320, Loss: 1.4554
Batch 330, Loss: 1.4135
Batch 340, Loss: 1.4925
Batch 350, Loss: 1.4770
Batch 360, Loss: 1.4454
Batch 370, Loss: 1.5529
Batch 380, Loss: 1.4945
Batch 390, Loss: 1.4949
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.539668321609497 seconds
Epoch 36 accuracy: 56.9%
Batch 10, Loss: 1.4280
Batch 20, Loss: 1.4957
Batch 30, Loss: 1.4274
Batch 40, Loss: 1.3864
Batch 50, Loss: 1.3969
Batch 60, Loss: 1.4629
Batch 70, Loss: 1.5172
Batch 80, Loss: 1.3982
Batch 90, Loss: 1.4353
Batch 100, Loss: 1.4379
Batch 110, Loss: 1.4648
Batch 120, Loss: 1.4271
Batch 130, Loss: 1.5005
Batch 140, Loss: 1.4611
Batch 150, Loss: 1.4953
Batch 160, Loss: 1.4812
Batch 170, Loss: 1.4705
Batch 180, Loss: 1.4716
Batch 190, Loss: 1.4660
Batch 200, Loss: 1.4905
Batch 210, Loss: 1.5228
Batch 220, Loss: 1.4798
Batch 230, Loss: 1.3688
Batch 240, Loss: 1.4823
Batch 250, Loss: 1.4668
Batch 260, Loss: 1.4538
Batch 270, Loss: 1.4924
Batch 280, Loss: 1.4412
Batch 290, Loss: 1.4968
Batch 300, Loss: 1.4978
Batch 310, Loss: 1.4424
Batch 320, Loss: 1.4804
Batch 330, Loss: 1.4764
Batch 340, Loss: 1.5411
Batch 350, Loss: 1.5219
Batch 360, Loss: 1.4799
Batch 370, Loss: 1.4853
Batch 380, Loss: 1.4343
Batch 390, Loss: 1.4713
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.39298391342163 seconds
Epoch 37 accuracy: 56.11%
Batch 10, Loss: 1.4397
Batch 20, Loss: 1.4275
Batch 30, Loss: 1.4604
Batch 40, Loss: 1.4394
Batch 50, Loss: 1.4706
Batch 60, Loss: 1.4463
Batch 70, Loss: 1.4307
Batch 80, Loss: 1.4447
Batch 90, Loss: 1.4282
Batch 100, Loss: 1.4280
Batch 110, Loss: 1.4317
Batch 120, Loss: 1.4315
Batch 130, Loss: 1.4260
Batch 140, Loss: 1.4589
Batch 150, Loss: 1.4614
Batch 160, Loss: 1.4864
Batch 170, Loss: 1.4277
Batch 180, Loss: 1.5793
Batch 190, Loss: 1.4588
Batch 200, Loss: 1.5095
Batch 210, Loss: 1.5192
Batch 220, Loss: 1.4282
Batch 230, Loss: 1.4472
Batch 240, Loss: 1.4443
Batch 250, Loss: 1.4596
Batch 260, Loss: 1.4514
Batch 270, Loss: 1.4502
Batch 280, Loss: 1.5094
Batch 290, Loss: 1.5141
Batch 300, Loss: 1.4309
Batch 310, Loss: 1.4509
Batch 320, Loss: 1.4402
Batch 330, Loss: 1.4429
Batch 340, Loss: 1.4609
Batch 350, Loss: 1.4512
Batch 360, Loss: 1.4838
Batch 370, Loss: 1.4548
Batch 380, Loss: 1.4662
Batch 390, Loss: 1.4761
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.431375980377197 seconds
Epoch 38 accuracy: 56.55%
Batch 10, Loss: 1.3659
Batch 20, Loss: 1.4888
Batch 30, Loss: 1.3899
Batch 40, Loss: 1.3777
Batch 50, Loss: 1.4750
Batch 60, Loss: 1.4395
Batch 70, Loss: 1.4631
Batch 80, Loss: 1.4196
Batch 90, Loss: 1.3971
Batch 100, Loss: 1.4601
Batch 110, Loss: 1.4474
Batch 120, Loss: 1.4230
Batch 130, Loss: 1.4169
Batch 140, Loss: 1.4768
Batch 150, Loss: 1.4444
Batch 160, Loss: 1.3696
Batch 170, Loss: 1.4098
Batch 180, Loss: 1.4527
Batch 190, Loss: 1.4927
Batch 200, Loss: 1.4194
Batch 210, Loss: 1.4872
Batch 220, Loss: 1.4432
Batch 230, Loss: 1.4915
Batch 240, Loss: 1.4960
Batch 250, Loss: 1.4721
Batch 260, Loss: 1.4814
Batch 270, Loss: 1.5332
Batch 280, Loss: 1.4009
Batch 290, Loss: 1.4910
Batch 300, Loss: 1.4941
Batch 310, Loss: 1.5147
Batch 320, Loss: 1.4380
Batch 330, Loss: 1.6080
Batch 340, Loss: 1.3894
Batch 350, Loss: 1.4622
Batch 360, Loss: 1.4296
Batch 370, Loss: 1.5192
Batch 380, Loss: 1.5309
Batch 390, Loss: 1.4572
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.37137246131897 seconds
Epoch 39 accuracy: 56.68%
Batch 10, Loss: 1.4271
Batch 20, Loss: 1.4103
Batch 30, Loss: 1.3654
Batch 40, Loss: 1.4271
Batch 50, Loss: 1.4191
Batch 60, Loss: 1.4463
Batch 70, Loss: 1.4448
Batch 80, Loss: 1.4334
Batch 90, Loss: 1.3981
Batch 100, Loss: 1.3889
Batch 110, Loss: 1.4398
Batch 120, Loss: 1.4017
Batch 130, Loss: 1.4375
Batch 140, Loss: 1.4353
Batch 150, Loss: 1.4422
Batch 160, Loss: 1.4943
Batch 170, Loss: 1.4579
Batch 180, Loss: 1.4465
Batch 190, Loss: 1.4726
Batch 200, Loss: 1.4371
Batch 210, Loss: 1.4220
Batch 220, Loss: 1.4210
Batch 230, Loss: 1.4412
Batch 240, Loss: 1.5292
Batch 250, Loss: 1.4527
Batch 260, Loss: 1.5883
Batch 270, Loss: 1.4783
Batch 280, Loss: 1.4194
Batch 290, Loss: 1.4199
Batch 300, Loss: 1.4488
Batch 310, Loss: 1.5135
Batch 320, Loss: 1.4796
Batch 330, Loss: 1.4856
Batch 340, Loss: 1.5035
Batch 350, Loss: 1.4611
Batch 360, Loss: 1.4981
Batch 370, Loss: 1.4728
Batch 380, Loss: 1.5170
Batch 390, Loss: 1.4859
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.40123724937439 seconds
Epoch 40 accuracy: 56.85%
Batch 10, Loss: 1.4107
Batch 20, Loss: 1.4036
Batch 30, Loss: 1.4414
Batch 40, Loss: 1.4508
Batch 50, Loss: 1.3960
Batch 60, Loss: 1.4189
Batch 70, Loss: 1.4405
Batch 80, Loss: 1.4697
Batch 90, Loss: 1.3883
Batch 100, Loss: 1.4521
Batch 110, Loss: 1.4220
Batch 120, Loss: 1.4059
Batch 130, Loss: 1.4236
Batch 140, Loss: 1.4496
Batch 150, Loss: 1.4419
Batch 160, Loss: 1.4167
Batch 170, Loss: 1.4043
Batch 180, Loss: 1.4519
Batch 190, Loss: 1.4522
Batch 200, Loss: 1.4278
Batch 210, Loss: 1.4596
Batch 220, Loss: 1.3926
Batch 230, Loss: 1.4456
Batch 240, Loss: 1.3983
Batch 250, Loss: 1.3853
Batch 260, Loss: 1.4439
Batch 270, Loss: 1.4773
Batch 280, Loss: 1.4449
Batch 290, Loss: 1.4401
Batch 300, Loss: 1.4528
Batch 310, Loss: 1.4576
Batch 320, Loss: 1.5024
Batch 330, Loss: 1.4319
Batch 340, Loss: 1.3935
Batch 350, Loss: 1.4044
Batch 360, Loss: 1.4571
Batch 370, Loss: 1.4673
Batch 380, Loss: 1.4516
Batch 390, Loss: 1.5283
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.493913650512695 seconds
Epoch 41 accuracy: 57.27%
Batch 10, Loss: 1.3951
Batch 20, Loss: 1.3755
Batch 30, Loss: 1.3315
Batch 40, Loss: 1.4217
Batch 50, Loss: 1.3678
Batch 60, Loss: 1.3814
Batch 70, Loss: 1.3874
Batch 80, Loss: 1.4543
Batch 90, Loss: 1.3671
Batch 100, Loss: 1.4583
Batch 110, Loss: 1.4319
Batch 120, Loss: 1.4484
Batch 130, Loss: 1.4034
Batch 140, Loss: 1.4630
Batch 150, Loss: 1.3671
Batch 160, Loss: 1.3551
Batch 170, Loss: 1.4352
Batch 180, Loss: 1.4588
Batch 190, Loss: 1.4846
Batch 200, Loss: 1.4619
Batch 210, Loss: 1.4614
Batch 220, Loss: 1.4445
Batch 230, Loss: 1.5425
Batch 240, Loss: 1.5260
Batch 250, Loss: 1.4332
Batch 260, Loss: 1.4055
Batch 270, Loss: 1.4868
Batch 280, Loss: 1.5414
Batch 290, Loss: 1.4318
Batch 300, Loss: 1.4780
Batch 310, Loss: 1.4668
Batch 320, Loss: 1.4299
Batch 330, Loss: 1.4569
Batch 340, Loss: 1.4398
Batch 350, Loss: 1.4486
Batch 360, Loss: 1.4621
Batch 370, Loss: 1.5203
Batch 380, Loss: 1.4076
Batch 390, Loss: 1.4824
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.56878972053528 seconds
Epoch 42 accuracy: 56.08%
Batch 10, Loss: 1.3555
Batch 20, Loss: 1.3690
Batch 30, Loss: 1.3529
Batch 40, Loss: 1.4319
Batch 50, Loss: 1.4420
Batch 60, Loss: 1.4780
Batch 70, Loss: 1.3766
Batch 80, Loss: 1.3968
Batch 90, Loss: 1.4612
Batch 100, Loss: 1.3194
Batch 110, Loss: 1.4021
Batch 120, Loss: 1.3960
Batch 130, Loss: 1.4183
Batch 140, Loss: 1.4480
Batch 150, Loss: 1.4684
Batch 160, Loss: 1.3806
Batch 170, Loss: 1.4360
Batch 180, Loss: 1.4472
Batch 190, Loss: 1.4232
Batch 200, Loss: 1.4454
Batch 210, Loss: 1.4494
Batch 220, Loss: 1.4737
Batch 230, Loss: 1.4718
Batch 240, Loss: 1.4966
Batch 250, Loss: 1.4953
Batch 260, Loss: 1.4693
Batch 270, Loss: 1.4085
Batch 280, Loss: 1.4800
Batch 290, Loss: 1.4432
Batch 300, Loss: 1.4054
Batch 310, Loss: 1.4157
Batch 320, Loss: 1.4368
Batch 330, Loss: 1.4176
Batch 340, Loss: 1.4811
Batch 350, Loss: 1.5034
Batch 360, Loss: 1.4075
Batch 370, Loss: 1.4626
Batch 380, Loss: 1.5373
Batch 390, Loss: 1.4230
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.505690813064575 seconds
Epoch 43 accuracy: 57.37%
Batch 10, Loss: 1.3933
Batch 20, Loss: 1.3907
Batch 30, Loss: 1.4213
Batch 40, Loss: 1.3760
Batch 50, Loss: 1.3833
Batch 60, Loss: 1.3887
Batch 70, Loss: 1.4052
Batch 80, Loss: 1.4503
Batch 90, Loss: 1.4680
Batch 100, Loss: 1.4558
Batch 110, Loss: 1.4010
Batch 120, Loss: 1.3739
Batch 130, Loss: 1.4277
Batch 140, Loss: 1.4500
Batch 150, Loss: 1.4199
Batch 160, Loss: 1.3911
Batch 170, Loss: 1.3785
Batch 180, Loss: 1.4086
Batch 190, Loss: 1.3926
Batch 200, Loss: 1.3729
Batch 210, Loss: 1.5115
Batch 220, Loss: 1.4571
Batch 230, Loss: 1.4525
Batch 240, Loss: 1.4570
Batch 250, Loss: 1.3979
Batch 260, Loss: 1.4881
Batch 270, Loss: 1.3922
Batch 280, Loss: 1.4781
Batch 290, Loss: 1.3985
Batch 300, Loss: 1.4426
Batch 310, Loss: 1.5011
Batch 320, Loss: 1.4138
Batch 330, Loss: 1.3930
Batch 340, Loss: 1.3948
Batch 350, Loss: 1.4121
Batch 360, Loss: 1.5141
Batch 370, Loss: 1.4242
Batch 380, Loss: 1.3767
Batch 390, Loss: 1.3744
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.410018920898438 seconds
Epoch 44 accuracy: 56.9%
Batch 10, Loss: 1.3772
Batch 20, Loss: 1.3887
Batch 30, Loss: 1.4067
Batch 40, Loss: 1.3673
Batch 50, Loss: 1.4188
Batch 60, Loss: 1.3883
Batch 70, Loss: 1.4284
Batch 80, Loss: 1.3999
Batch 90, Loss: 1.4039
Batch 100, Loss: 1.3610
Batch 110, Loss: 1.4229
Batch 120, Loss: 1.4019
Batch 130, Loss: 1.4191
Batch 140, Loss: 1.3928
Batch 150, Loss: 1.4541
Batch 160, Loss: 1.4048
Batch 170, Loss: 1.4622
Batch 180, Loss: 1.4121
Batch 190, Loss: 1.4858
Batch 200, Loss: 1.3857
Batch 210, Loss: 1.4293
Batch 220, Loss: 1.4313
Batch 230, Loss: 1.4582
Batch 240, Loss: 1.4337
Batch 250, Loss: 1.3898
Batch 260, Loss: 1.4185
Batch 270, Loss: 1.4825
Batch 280, Loss: 1.4821
Batch 290, Loss: 1.4867
Batch 300, Loss: 1.4797
Batch 310, Loss: 1.4754
Batch 320, Loss: 1.4886
Batch 330, Loss: 1.3919
Batch 340, Loss: 1.4009
Batch 350, Loss: 1.4279
Batch 360, Loss: 1.4897
Batch 370, Loss: 1.4174
Batch 380, Loss: 1.4012
Batch 390, Loss: 1.4528
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.377073764801025 seconds
Epoch 45 accuracy: 58.0%
Batch 10, Loss: 1.3591
Batch 20, Loss: 1.3388
Batch 30, Loss: 1.3979
Batch 40, Loss: 1.4099
Batch 50, Loss: 1.3878
Batch 60, Loss: 1.3610
Batch 70, Loss: 1.3416
Batch 80, Loss: 1.3912
Batch 90, Loss: 1.3705
Batch 100, Loss: 1.3621
Batch 110, Loss: 1.4662
Batch 120, Loss: 1.4123
Batch 130, Loss: 1.3445
Batch 140, Loss: 1.4112
Batch 150, Loss: 1.3776
Batch 160, Loss: 1.4403
Batch 170, Loss: 1.4465
Batch 180, Loss: 1.4031
Batch 190, Loss: 1.4077
Batch 200, Loss: 1.4395
Batch 210, Loss: 1.4193
Batch 220, Loss: 1.4444
Batch 230, Loss: 1.5011
Batch 240, Loss: 1.3802
Batch 250, Loss: 1.4592
Batch 260, Loss: 1.4480
Batch 270, Loss: 1.4382
Batch 280, Loss: 1.3209
Batch 290, Loss: 1.4545
Batch 300, Loss: 1.4109
Batch 310, Loss: 1.4917
Batch 320, Loss: 1.4505
Batch 330, Loss: 1.4008
Batch 340, Loss: 1.4707
Batch 350, Loss: 1.4181
Batch 360, Loss: 1.3843
Batch 370, Loss: 1.4389
Batch 380, Loss: 1.4933
Batch 390, Loss: 1.4515
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.343263864517212 seconds
Epoch 46 accuracy: 58.39%
Batch 10, Loss: 1.3957
Batch 20, Loss: 1.3672
Batch 30, Loss: 1.3497
Batch 40, Loss: 1.3495
Batch 50, Loss: 1.4064
Batch 60, Loss: 1.4113
Batch 70, Loss: 1.3828
Batch 80, Loss: 1.3815
Batch 90, Loss: 1.4432
Batch 100, Loss: 1.4433
Batch 110, Loss: 1.4089
Batch 120, Loss: 1.4068
Batch 130, Loss: 1.4357
Batch 140, Loss: 1.4738
Batch 150, Loss: 1.4199
Batch 160, Loss: 1.4121
Batch 170, Loss: 1.4530
Batch 180, Loss: 1.4597
Batch 190, Loss: 1.3608
Batch 200, Loss: 1.4193
Batch 210, Loss: 1.3972
Batch 220, Loss: 1.4200
Batch 230, Loss: 1.3977
Batch 240, Loss: 1.3740
Batch 250, Loss: 1.4094
Batch 260, Loss: 1.4529
Batch 270, Loss: 1.4036
Batch 280, Loss: 1.4414
Batch 290, Loss: 1.3449
Batch 300, Loss: 1.4584
Batch 310, Loss: 1.3297
Batch 320, Loss: 1.4108
Batch 330, Loss: 1.3950
Batch 340, Loss: 1.4586
Batch 350, Loss: 1.4183
Batch 360, Loss: 1.3536
Batch 370, Loss: 1.4487
Batch 380, Loss: 1.4891
Batch 390, Loss: 1.4386
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.4768168926239 seconds
Epoch 47 accuracy: 56.95%
Batch 10, Loss: 1.3343
Batch 20, Loss: 1.3521
Batch 30, Loss: 1.3210
Batch 40, Loss: 1.3662
Batch 50, Loss: 1.3841
Batch 60, Loss: 1.3552
Batch 70, Loss: 1.3793
Batch 80, Loss: 1.4186
Batch 90, Loss: 1.3600
Batch 100, Loss: 1.3892
Batch 110, Loss: 1.4228
Batch 120, Loss: 1.3727
Batch 130, Loss: 1.3927
Batch 140, Loss: 1.4034
Batch 150, Loss: 1.4348
Batch 160, Loss: 1.3751
Batch 170, Loss: 1.3890
Batch 180, Loss: 1.3661
Batch 190, Loss: 1.4074
Batch 200, Loss: 1.4177
Batch 210, Loss: 1.4459
Batch 220, Loss: 1.4486
Batch 230, Loss: 1.4444
Batch 240, Loss: 1.3599
Batch 250, Loss: 1.4281
Batch 260, Loss: 1.4673
Batch 270, Loss: 1.4217
Batch 280, Loss: 1.4535
Batch 290, Loss: 1.4970
Batch 300, Loss: 1.3653
Batch 310, Loss: 1.4516
Batch 320, Loss: 1.4181
Batch 330, Loss: 1.5383
Batch 340, Loss: 1.4961
Batch 350, Loss: 1.4375
Batch 360, Loss: 1.4144
Batch 370, Loss: 1.3867
Batch 380, Loss: 1.4221
Batch 390, Loss: 1.4243
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.32547640800476 seconds
Epoch 48 accuracy: 60.31%
Batch 10, Loss: 1.3890
Batch 20, Loss: 1.3473
Batch 30, Loss: 1.3633
Batch 40, Loss: 1.3649
Batch 50, Loss: 1.3628
Batch 60, Loss: 1.3871
Batch 70, Loss: 1.4006
Batch 80, Loss: 1.3905
Batch 90, Loss: 1.4172
Batch 100, Loss: 1.3176
Batch 110, Loss: 1.3942
Batch 120, Loss: 1.3961
Batch 130, Loss: 1.4568
Batch 140, Loss: 1.3607
Batch 150, Loss: 1.3533
Batch 160, Loss: 1.3354
Batch 170, Loss: 1.3841
Batch 180, Loss: 1.4722
Batch 190, Loss: 1.4979
Batch 200, Loss: 1.4501
Batch 210, Loss: 1.3876
Batch 220, Loss: 1.4014
Batch 230, Loss: 1.4619
Batch 240, Loss: 1.4240
Batch 250, Loss: 1.3436
Batch 260, Loss: 1.3885
Batch 270, Loss: 1.3541
Batch 280, Loss: 1.4572
Batch 290, Loss: 1.4261
Batch 300, Loss: 1.3924
Batch 310, Loss: 1.3666
Batch 320, Loss: 1.4509
Batch 330, Loss: 1.4217
Batch 340, Loss: 1.4118
Batch 350, Loss: 1.3925
Batch 360, Loss: 1.3764
Batch 370, Loss: 1.4736
Batch 380, Loss: 1.4044
Batch 390, Loss: 1.4517
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.349777936935425 seconds
Epoch 49 accuracy: 56.41%
Batch 10, Loss: 1.3356
Batch 20, Loss: 1.3621
Batch 30, Loss: 1.3441
Batch 40, Loss: 1.3231
Batch 50, Loss: 1.3996
Batch 60, Loss: 1.3823
Batch 70, Loss: 1.3869
Batch 80, Loss: 1.4262
Batch 90, Loss: 1.4037
Batch 100, Loss: 1.3936
Batch 110, Loss: 1.3983
Batch 120, Loss: 1.3692
Batch 130, Loss: 1.3914
Batch 140, Loss: 1.3299
Batch 150, Loss: 1.3794
Batch 160, Loss: 1.3942
Batch 170, Loss: 1.4050
Batch 180, Loss: 1.4008
Batch 190, Loss: 1.4289
Batch 200, Loss: 1.4000
Batch 210, Loss: 1.4748
Batch 220, Loss: 1.4493
Batch 230, Loss: 1.4286
Batch 240, Loss: 1.4375
Batch 250, Loss: 1.3976
Batch 260, Loss: 1.3798
Batch 270, Loss: 1.4307
Batch 280, Loss: 1.4017
Batch 290, Loss: 1.3971
Batch 300, Loss: 1.4253
Batch 310, Loss: 1.4051
Batch 320, Loss: 1.4298
Batch 330, Loss: 1.4250
Batch 340, Loss: 1.3992
Batch 350, Loss: 1.4450
Batch 360, Loss: 1.4053
Batch 370, Loss: 1.4420
Batch 380, Loss: 1.4109
Batch 390, Loss: 1.4158
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.51138997077942 seconds
Epoch 50 accuracy: 54.89%
Batch 10, Loss: 1.3384
Batch 20, Loss: 1.3901
Batch 30, Loss: 1.2932
Batch 40, Loss: 1.2916
Batch 50, Loss: 1.3143
Batch 60, Loss: 1.3220
Batch 70, Loss: 1.3370
Batch 80, Loss: 1.3860
Batch 90, Loss: 1.3909
Batch 100, Loss: 1.3308
Batch 110, Loss: 1.4034
Batch 120, Loss: 1.3501
Batch 130, Loss: 1.3582
Batch 140, Loss: 1.3055
Batch 150, Loss: 1.4379
Batch 160, Loss: 1.2777
Batch 170, Loss: 1.3673
Batch 180, Loss: 1.3921
Batch 190, Loss: 1.4075
Batch 200, Loss: 1.4305
Batch 210, Loss: 1.4001
Batch 220, Loss: 1.4622
Batch 230, Loss: 1.4217
Batch 240, Loss: 1.4497
Batch 250, Loss: 1.4647
Batch 260, Loss: 1.4316
Batch 270, Loss: 1.4001
Batch 280, Loss: 1.4029
Batch 290, Loss: 1.3657
Batch 300, Loss: 1.4628
Batch 310, Loss: 1.3684
Batch 320, Loss: 1.3785
Batch 330, Loss: 1.4621
Batch 340, Loss: 1.4227
Batch 350, Loss: 1.4492
Batch 360, Loss: 1.3895
Batch 370, Loss: 1.4387
Batch 380, Loss: 1.4073
Batch 390, Loss: 1.4141
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.258373022079468 seconds
Epoch 51 accuracy: 57.66%
Batch 10, Loss: 1.3704
Batch 20, Loss: 1.3684
Batch 30, Loss: 1.3720
Batch 40, Loss: 1.3362
Batch 50, Loss: 1.2740
Batch 60, Loss: 1.3547
Batch 70, Loss: 1.3561
Batch 80, Loss: 1.3751
Batch 90, Loss: 1.3991
Batch 100, Loss: 1.3461
Batch 110, Loss: 1.3354
Batch 120, Loss: 1.4044
Batch 130, Loss: 1.3699
Batch 140, Loss: 1.3596
Batch 150, Loss: 1.3139
Batch 160, Loss: 1.3658
Batch 170, Loss: 1.3464
Batch 180, Loss: 1.4262
Batch 190, Loss: 1.4182
Batch 200, Loss: 1.3600
Batch 210, Loss: 1.4236
Batch 220, Loss: 1.4529
Batch 230, Loss: 1.4245
Batch 240, Loss: 1.4229
Batch 250, Loss: 1.3595
Batch 260, Loss: 1.3490
Batch 270, Loss: 1.3612
Batch 280, Loss: 1.4013
Batch 290, Loss: 1.3790
Batch 300, Loss: 1.3263
Batch 310, Loss: 1.4047
Batch 320, Loss: 1.3933
Batch 330, Loss: 1.4493
Batch 340, Loss: 1.4349
Batch 350, Loss: 1.4290
Batch 360, Loss: 1.3153
Batch 370, Loss: 1.4116
Batch 380, Loss: 1.3494
Batch 390, Loss: 1.4152
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.388025045394897 seconds
Epoch 52 accuracy: 59.0%
Batch 10, Loss: 1.3225
Batch 20, Loss: 1.3213
Batch 30, Loss: 1.4176
Batch 40, Loss: 1.3356
Batch 50, Loss: 1.3088
Batch 60, Loss: 1.3647
Batch 70, Loss: 1.2848
Batch 80, Loss: 1.3358
Batch 90, Loss: 1.3658
Batch 100, Loss: 1.3711
Batch 110, Loss: 1.3744
Batch 120, Loss: 1.3705
Batch 130, Loss: 1.3513
Batch 140, Loss: 1.3913
Batch 150, Loss: 1.3975
Batch 160, Loss: 1.3502
Batch 170, Loss: 1.4073
Batch 180, Loss: 1.3908
Batch 190, Loss: 1.3790
Batch 200, Loss: 1.4593
Batch 210, Loss: 1.4369
Batch 220, Loss: 1.4254
Batch 230, Loss: 1.3563
Batch 240, Loss: 1.3417
Batch 250, Loss: 1.3763
Batch 260, Loss: 1.4069
Batch 270, Loss: 1.3255
Batch 280, Loss: 1.3917
Batch 290, Loss: 1.4522
Batch 300, Loss: 1.4026
Batch 310, Loss: 1.4658
Batch 320, Loss: 1.4466
Batch 330, Loss: 1.4537
Batch 340, Loss: 1.3681
Batch 350, Loss: 1.3824
Batch 360, Loss: 1.4086
Batch 370, Loss: 1.4371
Batch 380, Loss: 1.4289
Batch 390, Loss: 1.4121
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.342477798461914 seconds
Epoch 53 accuracy: 62.24%
Batch 10, Loss: 1.3559
Batch 20, Loss: 1.3397
Batch 30, Loss: 1.3734
Batch 40, Loss: 1.3888
Batch 50, Loss: 1.3352
Batch 60, Loss: 1.3519
Batch 70, Loss: 1.3032
Batch 80, Loss: 1.3541
Batch 90, Loss: 1.3279
Batch 100, Loss: 1.3196
Batch 110, Loss: 1.3999
Batch 120, Loss: 1.4121
Batch 130, Loss: 1.3844
Batch 140, Loss: 1.3279
Batch 150, Loss: 1.3861
Batch 160, Loss: 1.3196
Batch 170, Loss: 1.3738
Batch 180, Loss: 1.3877
Batch 190, Loss: 1.3511
Batch 200, Loss: 1.3744
Batch 210, Loss: 1.3903
Batch 220, Loss: 1.3448
Batch 230, Loss: 1.4413
Batch 240, Loss: 1.4038
Batch 250, Loss: 1.3846
Batch 260, Loss: 1.3262
Batch 270, Loss: 1.3544
Batch 280, Loss: 1.3477
Batch 290, Loss: 1.3836
Batch 300, Loss: 1.4333
Batch 310, Loss: 1.4109
Batch 320, Loss: 1.4045
Batch 330, Loss: 1.4104
Batch 340, Loss: 1.3531
Batch 350, Loss: 1.3840
Batch 360, Loss: 1.3996
Batch 370, Loss: 1.3896
Batch 380, Loss: 1.4047
Batch 390, Loss: 1.3716
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.323768615722656 seconds
Epoch 54 accuracy: 60.1%
Batch 10, Loss: 1.3083
Batch 20, Loss: 1.3323
Batch 30, Loss: 1.3370
Batch 40, Loss: 1.3514
Batch 50, Loss: 1.3710
Batch 60, Loss: 1.3382
Batch 70, Loss: 1.3475
Batch 80, Loss: 1.3377
Batch 90, Loss: 1.4578
Batch 100, Loss: 1.3945
Batch 110, Loss: 1.3450
Batch 120, Loss: 1.2790
Batch 130, Loss: 1.4125
Batch 140, Loss: 1.3494
Batch 150, Loss: 1.3789
Batch 160, Loss: 1.3569
Batch 170, Loss: 1.3493
Batch 180, Loss: 1.3571
Batch 190, Loss: 1.3585
Batch 200, Loss: 1.4202
Batch 210, Loss: 1.4125
Batch 220, Loss: 1.3742
Batch 230, Loss: 1.3813
Batch 240, Loss: 1.4712
Batch 250, Loss: 1.3274
Batch 260, Loss: 1.3967
Batch 270, Loss: 1.4040
Batch 280, Loss: 1.3390
Batch 290, Loss: 1.4302
Batch 300, Loss: 1.3563
Batch 310, Loss: 1.4279
Batch 320, Loss: 1.4768
Batch 330, Loss: 1.3623
Batch 340, Loss: 1.3445
Batch 350, Loss: 1.3662
Batch 360, Loss: 1.3446
Batch 370, Loss: 1.4221
Batch 380, Loss: 1.3290
Batch 390, Loss: 1.4132
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.3226101398468 seconds
Epoch 55 accuracy: 60.24%
Batch 10, Loss: 1.3675
Batch 20, Loss: 1.3119
Batch 30, Loss: 1.3067
Batch 40, Loss: 1.3811
Batch 50, Loss: 1.3183
Batch 60, Loss: 1.2948
Batch 70, Loss: 1.3291
Batch 80, Loss: 1.3194
Batch 90, Loss: 1.2981
Batch 100, Loss: 1.3322
Batch 110, Loss: 1.3235
Batch 120, Loss: 1.3848
Batch 130, Loss: 1.3602
Batch 140, Loss: 1.4264
Batch 150, Loss: 1.3503
Batch 160, Loss: 1.4204
Batch 170, Loss: 1.4277
Batch 180, Loss: 1.4209
Batch 190, Loss: 1.3451
Batch 200, Loss: 1.3243
Batch 210, Loss: 1.4017
Batch 220, Loss: 1.3665
Batch 230, Loss: 1.3529
Batch 240, Loss: 1.4315
Batch 250, Loss: 1.4170
Batch 260, Loss: 1.4279
Batch 270, Loss: 1.4718
Batch 280, Loss: 1.4175
Batch 290, Loss: 1.3524
Batch 300, Loss: 1.4025
Batch 310, Loss: 1.2829
Batch 320, Loss: 1.4149
Batch 330, Loss: 1.4121
Batch 340, Loss: 1.3755
Batch 350, Loss: 1.4270
Batch 360, Loss: 1.5031
Batch 370, Loss: 1.4534
Batch 380, Loss: 1.3812
Batch 390, Loss: 1.3676
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.303651809692383 seconds
Epoch 56 accuracy: 61.84%
Batch 10, Loss: 1.2602
Batch 20, Loss: 1.3790
Batch 30, Loss: 1.3465
Batch 40, Loss: 1.3757
Batch 50, Loss: 1.2830
Batch 60, Loss: 1.2680
Batch 70, Loss: 1.3402
Batch 80, Loss: 1.3353
Batch 90, Loss: 1.3208
Batch 100, Loss: 1.3593
Batch 110, Loss: 1.3275
Batch 120, Loss: 1.3686
Batch 130, Loss: 1.3170
Batch 140, Loss: 1.2932
Batch 150, Loss: 1.3308
Batch 160, Loss: 1.4011
Batch 170, Loss: 1.2954
Batch 180, Loss: 1.4229
Batch 190, Loss: 1.3528
Batch 200, Loss: 1.4027
Batch 210, Loss: 1.4271
Batch 220, Loss: 1.4621
Batch 230, Loss: 1.3882
Batch 240, Loss: 1.3814
Batch 250, Loss: 1.3775
Batch 260, Loss: 1.3718
Batch 270, Loss: 1.3708
Batch 280, Loss: 1.3948
Batch 290, Loss: 1.3518
Batch 300, Loss: 1.4072
Batch 310, Loss: 1.3714
Batch 320, Loss: 1.3714
Batch 330, Loss: 1.3645
Batch 340, Loss: 1.3461
Batch 350, Loss: 1.3772
Batch 360, Loss: 1.4139
Batch 370, Loss: 1.3662
Batch 380, Loss: 1.3757
Batch 390, Loss: 1.4172
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.343026161193848 seconds
Epoch 57 accuracy: 59.98%
Batch 10, Loss: 1.3825
Batch 20, Loss: 1.3402
Batch 30, Loss: 1.2801
Batch 40, Loss: 1.3353
Batch 50, Loss: 1.3415
Batch 60, Loss: 1.3524
Batch 70, Loss: 1.3341
Batch 80, Loss: 1.3370
Batch 90, Loss: 1.3122
Batch 100, Loss: 1.3583
Batch 110, Loss: 1.2421
Batch 120, Loss: 1.2661
Batch 130, Loss: 1.3747
Batch 140, Loss: 1.4026
Batch 150, Loss: 1.3229
Batch 160, Loss: 1.3990
Batch 170, Loss: 1.3497
Batch 180, Loss: 1.3462
Batch 190, Loss: 1.3679
Batch 200, Loss: 1.3868
Batch 210, Loss: 1.3511
Batch 220, Loss: 1.3464
Batch 230, Loss: 1.3443
Batch 240, Loss: 1.3197
Batch 250, Loss: 1.3282
Batch 260, Loss: 1.3923
Batch 270, Loss: 1.3610
Batch 280, Loss: 1.3527
Batch 290, Loss: 1.3651
Batch 300, Loss: 1.3574
Batch 310, Loss: 1.3219
Batch 320, Loss: 1.4174
Batch 330, Loss: 1.3684
Batch 340, Loss: 1.3299
Batch 350, Loss: 1.3684
Batch 360, Loss: 1.3238
Batch 370, Loss: 1.3990
Batch 380, Loss: 1.4407
Batch 390, Loss: 1.4057
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.352938413619995 seconds
Epoch 58 accuracy: 58.69%
Batch 10, Loss: 1.3864
Batch 20, Loss: 1.3006
Batch 30, Loss: 1.3000
Batch 40, Loss: 1.3294
Batch 50, Loss: 1.2903
Batch 60, Loss: 1.2781
Batch 70, Loss: 1.3406
Batch 80, Loss: 1.2979
Batch 90, Loss: 1.2879
Batch 100, Loss: 1.2903
Batch 110, Loss: 1.3159
Batch 120, Loss: 1.3340
Batch 130, Loss: 1.3284
Batch 140, Loss: 1.3309
Batch 150, Loss: 1.3649
Batch 160, Loss: 1.3558
Batch 170, Loss: 1.3536
Batch 180, Loss: 1.4150
Batch 190, Loss: 1.3558
Batch 200, Loss: 1.3754
Batch 210, Loss: 1.3572
Batch 220, Loss: 1.3590
Batch 230, Loss: 1.4014
Batch 240, Loss: 1.3542
Batch 250, Loss: 1.3877
Batch 260, Loss: 1.4266
Batch 270, Loss: 1.3163
Batch 280, Loss: 1.4518
Batch 290, Loss: 1.3692
Batch 300, Loss: 1.3446
Batch 310, Loss: 1.3535
Batch 320, Loss: 1.3383
Batch 330, Loss: 1.4052
Batch 340, Loss: 1.4013
Batch 350, Loss: 1.3782
Batch 360, Loss: 1.4416
Batch 370, Loss: 1.3568
Batch 380, Loss: 1.3725
Batch 390, Loss: 1.3387
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.354801416397095 seconds
Epoch 59 accuracy: 59.7%
Batch 10, Loss: 1.3241
Batch 20, Loss: 1.3411
Batch 30, Loss: 1.2781
Batch 40, Loss: 1.3264
Batch 50, Loss: 1.2717
Batch 60, Loss: 1.2664
Batch 70, Loss: 1.2898
Batch 80, Loss: 1.2710
Batch 90, Loss: 1.3137
Batch 100, Loss: 1.2791
Batch 110, Loss: 1.3401
Batch 120, Loss: 1.3900
Batch 130, Loss: 1.3824
Batch 140, Loss: 1.4237
Batch 150, Loss: 1.3305
Batch 160, Loss: 1.3582
Batch 170, Loss: 1.3268
Batch 180, Loss: 1.3219
Batch 190, Loss: 1.4122
Batch 200, Loss: 1.3284
Batch 210, Loss: 1.3527
Batch 220, Loss: 1.4118
Batch 230, Loss: 1.3462
Batch 240, Loss: 1.3513
Batch 250, Loss: 1.4047
Batch 260, Loss: 1.3558
Batch 270, Loss: 1.3780
Batch 280, Loss: 1.3514
Batch 290, Loss: 1.4185
Batch 300, Loss: 1.4007
Batch 310, Loss: 1.4238
Batch 320, Loss: 1.3798
Batch 330, Loss: 1.3668
Batch 340, Loss: 1.3490
Batch 350, Loss: 1.3819
Batch 360, Loss: 1.3940
Batch 370, Loss: 1.3866
Batch 380, Loss: 1.3375
Batch 390, Loss: 1.2800
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.403064966201782 seconds
Epoch 60 accuracy: 61.28%
Batch 10, Loss: 1.2727
Batch 20, Loss: 1.2830
Batch 30, Loss: 1.3008
Batch 40, Loss: 1.2520
Batch 50, Loss: 1.3063
Batch 60, Loss: 1.2865
Batch 70, Loss: 1.3163
Batch 80, Loss: 1.3458
Batch 90, Loss: 1.3151
Batch 100, Loss: 1.2476
Batch 110, Loss: 1.3158
Batch 120, Loss: 1.3638
Batch 130, Loss: 1.3309
Batch 140, Loss: 1.3209
Batch 150, Loss: 1.3613
Batch 160, Loss: 1.3258
Batch 170, Loss: 1.3460
Batch 180, Loss: 1.3502
Batch 190, Loss: 1.2990
Batch 200, Loss: 1.3222
Batch 210, Loss: 1.3297
Batch 220, Loss: 1.2947
Batch 230, Loss: 1.3938
Batch 240, Loss: 1.3928
Batch 250, Loss: 1.3630
Batch 260, Loss: 1.3658
Batch 270, Loss: 1.3784
Batch 280, Loss: 1.3682
Batch 290, Loss: 1.3068
Batch 300, Loss: 1.3444
Batch 310, Loss: 1.3280
Batch 320, Loss: 1.3887
Batch 330, Loss: 1.4487
Batch 340, Loss: 1.4113
Batch 350, Loss: 1.2865
Batch 360, Loss: 1.2999
Batch 370, Loss: 1.3141
Batch 380, Loss: 1.3512
Batch 390, Loss: 1.3303
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.372747898101807 seconds
Epoch 61 accuracy: 57.75%
Batch 10, Loss: 1.2188
Batch 20, Loss: 1.3437
Batch 30, Loss: 1.3514
Batch 40, Loss: 1.3029
Batch 50, Loss: 1.3206
Batch 60, Loss: 1.3589
Batch 70, Loss: 1.3750
Batch 80, Loss: 1.2899
Batch 90, Loss: 1.3354
Batch 100, Loss: 1.3108
Batch 110, Loss: 1.3704
Batch 120, Loss: 1.3352
Batch 130, Loss: 1.3486
Batch 140, Loss: 1.3489
Batch 150, Loss: 1.3801
Batch 160, Loss: 1.3207
Batch 170, Loss: 1.3190
Batch 180, Loss: 1.2421
Batch 190, Loss: 1.3062
Batch 200, Loss: 1.3214
Batch 210, Loss: 1.3565
Batch 220, Loss: 1.2692
Batch 230, Loss: 1.3725
Batch 240, Loss: 1.3892
Batch 250, Loss: 1.3343
Batch 260, Loss: 1.3389
Batch 270, Loss: 1.3479
Batch 280, Loss: 1.3535
Batch 290, Loss: 1.3415
Batch 300, Loss: 1.4040
Batch 310, Loss: 1.3206
Batch 320, Loss: 1.3977
Batch 330, Loss: 1.3117
Batch 340, Loss: 1.3130
Batch 350, Loss: 1.3515
Batch 360, Loss: 1.3696
Batch 370, Loss: 1.2997
Batch 380, Loss: 1.3427
Batch 390, Loss: 1.3528
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.479569673538208 seconds
Epoch 62 accuracy: 61.28%
Batch 10, Loss: 1.3266
Batch 20, Loss: 1.2507
Batch 30, Loss: 1.2983
Batch 40, Loss: 1.3287
Batch 50, Loss: 1.2840
Batch 60, Loss: 1.2710
Batch 70, Loss: 1.3284
Batch 80, Loss: 1.3329
Batch 90, Loss: 1.3147
Batch 100, Loss: 1.3473
Batch 110, Loss: 1.3040
Batch 120, Loss: 1.2933
Batch 130, Loss: 1.3160
Batch 140, Loss: 1.3127
Batch 150, Loss: 1.2725
Batch 160, Loss: 1.3893
Batch 170, Loss: 1.3523
Batch 180, Loss: 1.2691
Batch 190, Loss: 1.3120
Batch 200, Loss: 1.3258
Batch 210, Loss: 1.2559
Batch 220, Loss: 1.4048
Batch 230, Loss: 1.2706
Batch 240, Loss: 1.3245
Batch 250, Loss: 1.2874
Batch 260, Loss: 1.3414
Batch 270, Loss: 1.3024
Batch 280, Loss: 1.3469
Batch 290, Loss: 1.3610
Batch 300, Loss: 1.3779
Batch 310, Loss: 1.3629
Batch 320, Loss: 1.3541
Batch 330, Loss: 1.2840
Batch 340, Loss: 1.3021
Batch 350, Loss: 1.3633
Batch 360, Loss: 1.3285
Batch 370, Loss: 1.3583
Batch 380, Loss: 1.3658
Batch 390, Loss: 1.3211
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.398242712020874 seconds
Epoch 63 accuracy: 59.51%
Batch 10, Loss: 1.3000
Batch 20, Loss: 1.2799
Batch 30, Loss: 1.2672
Batch 40, Loss: 1.2652
Batch 50, Loss: 1.2844
Batch 60, Loss: 1.2900
Batch 70, Loss: 1.3332
Batch 80, Loss: 1.3122
Batch 90, Loss: 1.2787
Batch 100, Loss: 1.3816
Batch 110, Loss: 1.2900
Batch 120, Loss: 1.2858
Batch 130, Loss: 1.2770
Batch 140, Loss: 1.3056
Batch 150, Loss: 1.2942
Batch 160, Loss: 1.3107
Batch 170, Loss: 1.3852
Batch 180, Loss: 1.3679
Batch 190, Loss: 1.2375
Batch 200, Loss: 1.3320
Batch 210, Loss: 1.3074
Batch 220, Loss: 1.3048
Batch 230, Loss: 1.3467
Batch 240, Loss: 1.3745
Batch 250, Loss: 1.3390
Batch 260, Loss: 1.3657
Batch 270, Loss: 1.2843
Batch 280, Loss: 1.3209
Batch 290, Loss: 1.3482
Batch 300, Loss: 1.3608
Batch 310, Loss: 1.2845
Batch 320, Loss: 1.3727
Batch 330, Loss: 1.3402
Batch 340, Loss: 1.3764
Batch 350, Loss: 1.3214
Batch 360, Loss: 1.3036
Batch 370, Loss: 1.3168
Batch 380, Loss: 1.3275
Batch 390, Loss: 1.3886
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.483548879623413 seconds
Epoch 64 accuracy: 57.46%
Batch 10, Loss: 1.3027
Batch 20, Loss: 1.2617
Batch 30, Loss: 1.3601
Batch 40, Loss: 1.3518
Batch 50, Loss: 1.2619
Batch 60, Loss: 1.2667
Batch 70, Loss: 1.3201
Batch 80, Loss: 1.3070
Batch 90, Loss: 1.2780
Batch 100, Loss: 1.3014
Batch 110, Loss: 1.2961
Batch 120, Loss: 1.2245
Batch 130, Loss: 1.3315
Batch 140, Loss: 1.2596
Batch 150, Loss: 1.2779
Batch 160, Loss: 1.2973
Batch 170, Loss: 1.2948
Batch 180, Loss: 1.2724
Batch 190, Loss: 1.2872
Batch 200, Loss: 1.2906
Batch 210, Loss: 1.3430
Batch 220, Loss: 1.3077
Batch 230, Loss: 1.3118
Batch 240, Loss: 1.2891
Batch 250, Loss: 1.3657
Batch 260, Loss: 1.2301
Batch 270, Loss: 1.3426
Batch 280, Loss: 1.3295
Batch 290, Loss: 1.3582
Batch 300, Loss: 1.3358
Batch 310, Loss: 1.3228
Batch 320, Loss: 1.3104
Batch 330, Loss: 1.2992
Batch 340, Loss: 1.3067
Batch 350, Loss: 1.3310
Batch 360, Loss: 1.3841
Batch 370, Loss: 1.3100
Batch 380, Loss: 1.3373
Batch 390, Loss: 1.3463
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.460991144180298 seconds
Epoch 65 accuracy: 61.08%
Batch 10, Loss: 1.2155
Batch 20, Loss: 1.2731
Batch 30, Loss: 1.2152
Batch 40, Loss: 1.2715
Batch 50, Loss: 1.3056
Batch 60, Loss: 1.2380
Batch 70, Loss: 1.2435
Batch 80, Loss: 1.2778
Batch 90, Loss: 1.2638
Batch 100, Loss: 1.2502
Batch 110, Loss: 1.3612
Batch 120, Loss: 1.2730
Batch 130, Loss: 1.3467
Batch 140, Loss: 1.3225
Batch 150, Loss: 1.3979
Batch 160, Loss: 1.3576
Batch 170, Loss: 1.3465
Batch 180, Loss: 1.2808
Batch 190, Loss: 1.2533
Batch 200, Loss: 1.3048
Batch 210, Loss: 1.3121
Batch 220, Loss: 1.3739
Batch 230, Loss: 1.3444
Batch 240, Loss: 1.4028
Batch 250, Loss: 1.2500
Batch 260, Loss: 1.3736
Batch 270, Loss: 1.3272
Batch 280, Loss: 1.3178
Batch 290, Loss: 1.3643
Batch 300, Loss: 1.3082
Batch 310, Loss: 1.3365
Batch 320, Loss: 1.3096
Batch 330, Loss: 1.3965
Batch 340, Loss: 1.3292
Batch 350, Loss: 1.3536
Batch 360, Loss: 1.3557
Batch 370, Loss: 1.3061
Batch 380, Loss: 1.3685
Batch 390, Loss: 1.3655
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.44132423400879 seconds
Epoch 66 accuracy: 59.03%
Batch 10, Loss: 1.3088
Batch 20, Loss: 1.3078
Batch 30, Loss: 1.2293
Batch 40, Loss: 1.3051
Batch 50, Loss: 1.2692
Batch 60, Loss: 1.2824
Batch 70, Loss: 1.2493
Batch 80, Loss: 1.3176
Batch 90, Loss: 1.2892
Batch 100, Loss: 1.2588
Batch 110, Loss: 1.2550
Batch 120, Loss: 1.3393
Batch 130, Loss: 1.3088
Batch 140, Loss: 1.2933
Batch 150, Loss: 1.2910
Batch 160, Loss: 1.2775
Batch 170, Loss: 1.3547
Batch 180, Loss: 1.2599
Batch 190, Loss: 1.2431
Batch 200, Loss: 1.3674
Batch 210, Loss: 1.3515
Batch 220, Loss: 1.3394
Batch 230, Loss: 1.3490
Batch 240, Loss: 1.3260
Batch 250, Loss: 1.3721
Batch 260, Loss: 1.4008
Batch 270, Loss: 1.3654
Batch 280, Loss: 1.3578
Batch 290, Loss: 1.2938
Batch 300, Loss: 1.2677
Batch 310, Loss: 1.2269
Batch 320, Loss: 1.2523
Batch 330, Loss: 1.3019
Batch 340, Loss: 1.3649
Batch 350, Loss: 1.3101
Batch 360, Loss: 1.3864
Batch 370, Loss: 1.3623
Batch 380, Loss: 1.3729
Batch 390, Loss: 1.3624
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.481390953063965 seconds
Epoch 67 accuracy: 59.43%
Batch 10, Loss: 1.3124
Batch 20, Loss: 1.2947
Batch 30, Loss: 1.2249
Batch 40, Loss: 1.2409
Batch 50, Loss: 1.2316
Batch 60, Loss: 1.2870
Batch 70, Loss: 1.2713
Batch 80, Loss: 1.3077
Batch 90, Loss: 1.2615
Batch 100, Loss: 1.2449
Batch 110, Loss: 1.2741
Batch 120, Loss: 1.2554
Batch 130, Loss: 1.3114
Batch 140, Loss: 1.2588
Batch 150, Loss: 1.2995
Batch 160, Loss: 1.2891
Batch 170, Loss: 1.3457
Batch 180, Loss: 1.3032
Batch 190, Loss: 1.3475
Batch 200, Loss: 1.3159
Batch 210, Loss: 1.3325
Batch 220, Loss: 1.3289
Batch 230, Loss: 1.2829
Batch 240, Loss: 1.3380
Batch 250, Loss: 1.2872
Batch 260, Loss: 1.3195
Batch 270, Loss: 1.2858
Batch 280, Loss: 1.3346
Batch 290, Loss: 1.3180
Batch 300, Loss: 1.3333
Batch 310, Loss: 1.3313
Batch 320, Loss: 1.3061
Batch 330, Loss: 1.3036
Batch 340, Loss: 1.3541
Batch 350, Loss: 1.3273
Batch 360, Loss: 1.2546
Batch 370, Loss: 1.3010
Batch 380, Loss: 1.3092
Batch 390, Loss: 1.3578
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.762916326522827 seconds
Epoch 68 accuracy: 61.4%
Batch 10, Loss: 1.2603
Batch 20, Loss: 1.2560
Batch 30, Loss: 1.2177
Batch 40, Loss: 1.3059
Batch 50, Loss: 1.3050
Batch 60, Loss: 1.2272
Batch 70, Loss: 1.2110
Batch 80, Loss: 1.2544
Batch 90, Loss: 1.2471
Batch 100, Loss: 1.2534
Batch 110, Loss: 1.2990
Batch 120, Loss: 1.3292
Batch 130, Loss: 1.2710
Batch 140, Loss: 1.2855
Batch 150, Loss: 1.3031
Batch 160, Loss: 1.3094
Batch 170, Loss: 1.3068
Batch 180, Loss: 1.3001
Batch 190, Loss: 1.3198
Batch 200, Loss: 1.3264
Batch 210, Loss: 1.3311
Batch 220, Loss: 1.4020
Batch 230, Loss: 1.3500
Batch 240, Loss: 1.3720
Batch 250, Loss: 1.3402
Batch 260, Loss: 1.2682
Batch 270, Loss: 1.3809
Batch 280, Loss: 1.3270
Batch 290, Loss: 1.3079
Batch 300, Loss: 1.3197
Batch 310, Loss: 1.2222
Batch 320, Loss: 1.3000
Batch 330, Loss: 1.3458
Batch 340, Loss: 1.3199
Batch 350, Loss: 1.3647
Batch 360, Loss: 1.2914
Batch 370, Loss: 1.2726
Batch 380, Loss: 1.3004
Batch 390, Loss: 1.3631
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.3764328956604 seconds
Epoch 69 accuracy: 62.89%
Batch 10, Loss: 1.2808
Batch 20, Loss: 1.2613
Batch 30, Loss: 1.2307
Batch 40, Loss: 1.2248
Batch 50, Loss: 1.3166
Batch 60, Loss: 1.2554
Batch 70, Loss: 1.2547
Batch 80, Loss: 1.2866
Batch 90, Loss: 1.2795
Batch 100, Loss: 1.2953
Batch 110, Loss: 1.2986
Batch 120, Loss: 1.2723
Batch 130, Loss: 1.2388
Batch 140, Loss: 1.3131
Batch 150, Loss: 1.1984
Batch 160, Loss: 1.3258
Batch 170, Loss: 1.3143
Batch 180, Loss: 1.3105
Batch 190, Loss: 1.2936
Batch 200, Loss: 1.2517
Batch 210, Loss: 1.2870
Batch 220, Loss: 1.2250
Batch 230, Loss: 1.3708
Batch 240, Loss: 1.3868
Batch 250, Loss: 1.3127
Batch 260, Loss: 1.2985
Batch 270, Loss: 1.3602
Batch 280, Loss: 1.3459
Batch 290, Loss: 1.2797
Batch 300, Loss: 1.3096
Batch 310, Loss: 1.2978
Batch 320, Loss: 1.2799
Batch 330, Loss: 1.2670
Batch 340, Loss: 1.3538
Batch 350, Loss: 1.3738
Batch 360, Loss: 1.3438
Batch 370, Loss: 1.3315
Batch 380, Loss: 1.3268
Batch 390, Loss: 1.3458
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.41263246536255 seconds
Epoch 70 accuracy: 55.56%
Batch 10, Loss: 1.2538
Batch 20, Loss: 1.3733
Batch 30, Loss: 1.2742
Batch 40, Loss: 1.2674
Batch 50, Loss: 1.1659
Batch 60, Loss: 1.2547
Batch 70, Loss: 1.2374
Batch 80, Loss: 1.3144
Batch 90, Loss: 1.2772
Batch 100, Loss: 1.2301
Batch 110, Loss: 1.2658
Batch 120, Loss: 1.2466
Batch 130, Loss: 1.1794
Batch 140, Loss: 1.2426
Batch 150, Loss: 1.1831
Batch 160, Loss: 1.2426
Batch 170, Loss: 1.2670
Batch 180, Loss: 1.3202
Batch 190, Loss: 1.2613
Batch 200, Loss: 1.3116
Batch 210, Loss: 1.3196
Batch 220, Loss: 1.2751
Batch 230, Loss: 1.2851
Batch 240, Loss: 1.3348
Batch 250, Loss: 1.3046
Batch 260, Loss: 1.3390
Batch 270, Loss: 1.2836
Batch 280, Loss: 1.3128
Batch 290, Loss: 1.2994
Batch 300, Loss: 1.3867
Batch 310, Loss: 1.2549
Batch 320, Loss: 1.2716
Batch 330, Loss: 1.3018
Batch 340, Loss: 1.3190
Batch 350, Loss: 1.2904
Batch 360, Loss: 1.3369
Batch 370, Loss: 1.3245
Batch 380, Loss: 1.2001
Batch 390, Loss: 1.2838
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.37844705581665 seconds
Epoch 71 accuracy: 61.6%
Batch 10, Loss: 1.2535
Batch 20, Loss: 1.2569
Batch 30, Loss: 1.3042
Batch 40, Loss: 1.2039
Batch 50, Loss: 1.2440
Batch 60, Loss: 1.2429
Batch 70, Loss: 1.2740
Batch 80, Loss: 1.2401
Batch 90, Loss: 1.2768
Batch 100, Loss: 1.2628
Batch 110, Loss: 1.2178
Batch 120, Loss: 1.2894
Batch 130, Loss: 1.1922
Batch 140, Loss: 1.2210
Batch 150, Loss: 1.2736
Batch 160, Loss: 1.3049
Batch 170, Loss: 1.2914
Batch 180, Loss: 1.2752
Batch 190, Loss: 1.2474
Batch 200, Loss: 1.3258
Batch 210, Loss: 1.2805
Batch 220, Loss: 1.2612
Batch 230, Loss: 1.2535
Batch 240, Loss: 1.2926
Batch 250, Loss: 1.2802
Batch 260, Loss: 1.3093
Batch 270, Loss: 1.2460
Batch 280, Loss: 1.2992
Batch 290, Loss: 1.3126
Batch 300, Loss: 1.2770
Batch 310, Loss: 1.2516
Batch 320, Loss: 1.3463
Batch 330, Loss: 1.2980
Batch 340, Loss: 1.3511
Batch 350, Loss: 1.2848
Batch 360, Loss: 1.3074
Batch 370, Loss: 1.2368
Batch 380, Loss: 1.2912
Batch 390, Loss: 1.3348
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.403221607208252 seconds
Epoch 72 accuracy: 60.71%
Batch 10, Loss: 1.2060
Batch 20, Loss: 1.2318
Batch 30, Loss: 1.2807
Batch 40, Loss: 1.2711
Batch 50, Loss: 1.2175
Batch 60, Loss: 1.2485
Batch 70, Loss: 1.2970
Batch 80, Loss: 1.2315
Batch 90, Loss: 1.2225
Batch 100, Loss: 1.1980
Batch 110, Loss: 1.2338
Batch 120, Loss: 1.3245
Batch 130, Loss: 1.2407
Batch 140, Loss: 1.2864
Batch 150, Loss: 1.2477
Batch 160, Loss: 1.2928
Batch 170, Loss: 1.3079
Batch 180, Loss: 1.2928
Batch 190, Loss: 1.3671
Batch 200, Loss: 1.2589
Batch 210, Loss: 1.2552
Batch 220, Loss: 1.3352
Batch 230, Loss: 1.2944
Batch 240, Loss: 1.2705
Batch 250, Loss: 1.2788
Batch 260, Loss: 1.2941
Batch 270, Loss: 1.3169
Batch 280, Loss: 1.2421
Batch 290, Loss: 1.2358
Batch 300, Loss: 1.3175
Batch 310, Loss: 1.3052
Batch 320, Loss: 1.2050
Batch 330, Loss: 1.3256
Batch 340, Loss: 1.3890
Batch 350, Loss: 1.3078
Batch 360, Loss: 1.2934
Batch 370, Loss: 1.2941
Batch 380, Loss: 1.3822
Batch 390, Loss: 1.2870
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.550512552261353 seconds
Epoch 73 accuracy: 62.28%
Batch 10, Loss: 1.2485
Batch 20, Loss: 1.2529
Batch 30, Loss: 1.2548
Batch 40, Loss: 1.2070
Batch 50, Loss: 1.2198
Batch 60, Loss: 1.1646
Batch 70, Loss: 1.2033
Batch 80, Loss: 1.2601
Batch 90, Loss: 1.2275
Batch 100, Loss: 1.2257
Batch 110, Loss: 1.3039
Batch 120, Loss: 1.2883
Batch 130, Loss: 1.2630
Batch 140, Loss: 1.2781
Batch 150, Loss: 1.2768
Batch 160, Loss: 1.2877
Batch 170, Loss: 1.3056
Batch 180, Loss: 1.2437
Batch 190, Loss: 1.2333
Batch 200, Loss: 1.2670
Batch 210, Loss: 1.3061
Batch 220, Loss: 1.3080
Batch 230, Loss: 1.2614
Batch 240, Loss: 1.3033
Batch 250, Loss: 1.2588
Batch 260, Loss: 1.3164
Batch 270, Loss: 1.2636
Batch 280, Loss: 1.3113
Batch 290, Loss: 1.3111
Batch 300, Loss: 1.2737
Batch 310, Loss: 1.2875
Batch 320, Loss: 1.3117
Batch 330, Loss: 1.2561
Batch 340, Loss: 1.2953
Batch 350, Loss: 1.3156
Batch 360, Loss: 1.3033
Batch 370, Loss: 1.2686
Batch 380, Loss: 1.3227
Batch 390, Loss: 1.2505
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.41319751739502 seconds
Epoch 74 accuracy: 61.79%
Batch 10, Loss: 1.1825
Batch 20, Loss: 1.2047
Batch 30, Loss: 1.2272
Batch 40, Loss: 1.2271
Batch 50, Loss: 1.2472
Batch 60, Loss: 1.2539
Batch 70, Loss: 1.2412
Batch 80, Loss: 1.2261
Batch 90, Loss: 1.2777
Batch 100, Loss: 1.2603
Batch 110, Loss: 1.2501
Batch 120, Loss: 1.2560
Batch 130, Loss: 1.2290
Batch 140, Loss: 1.2169
Batch 150, Loss: 1.2716
Batch 160, Loss: 1.2332
Batch 170, Loss: 1.2171
Batch 180, Loss: 1.2824
Batch 190, Loss: 1.2532
Batch 200, Loss: 1.2607
Batch 210, Loss: 1.2630
Batch 220, Loss: 1.2474
Batch 230, Loss: 1.3131
Batch 240, Loss: 1.2365
Batch 250, Loss: 1.1911
Batch 260, Loss: 1.2913
Batch 270, Loss: 1.2375
Batch 280, Loss: 1.3196
Batch 290, Loss: 1.3114
Batch 300, Loss: 1.2753
Batch 310, Loss: 1.2929
Batch 320, Loss: 1.3253
Batch 330, Loss: 1.3438
Batch 340, Loss: 1.2602
Batch 350, Loss: 1.2389
Batch 360, Loss: 1.2928
Batch 370, Loss: 1.2685
Batch 380, Loss: 1.2977
Batch 390, Loss: 1.3385
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.39341139793396 seconds
Epoch 75 accuracy: 61.67%
Batch 10, Loss: 1.2522
Batch 20, Loss: 1.2907
Batch 30, Loss: 1.2722
Batch 40, Loss: 1.2215
Batch 50, Loss: 1.1983
Batch 60, Loss: 1.2432
Batch 70, Loss: 1.2430
Batch 80, Loss: 1.2753
Batch 90, Loss: 1.2543
Batch 100, Loss: 1.2380
Batch 110, Loss: 1.2553
Batch 120, Loss: 1.2483
Batch 130, Loss: 1.2396
Batch 140, Loss: 1.3282
Batch 150, Loss: 1.3165
Batch 160, Loss: 1.2960
Batch 170, Loss: 1.2852
Batch 180, Loss: 1.2635
Batch 190, Loss: 1.3088
Batch 200, Loss: 1.2514
Batch 210, Loss: 1.3088
Batch 220, Loss: 1.2899
Batch 230, Loss: 1.2415
Batch 240, Loss: 1.2871
Batch 250, Loss: 1.2561
Batch 260, Loss: 1.2647
Batch 270, Loss: 1.2334
Batch 280, Loss: 1.2794
Batch 290, Loss: 1.2375
Batch 300, Loss: 1.2588
Batch 310, Loss: 1.2974
Batch 320, Loss: 1.2753
Batch 330, Loss: 1.2775
Batch 340, Loss: 1.3111
Batch 350, Loss: 1.2561
Batch 360, Loss: 1.3050
Batch 370, Loss: 1.2406
Batch 380, Loss: 1.2148
Batch 390, Loss: 1.2696
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.41015934944153 seconds
Epoch 76 accuracy: 64.15%
Batch 10, Loss: 1.1647
Batch 20, Loss: 1.2385
Batch 30, Loss: 1.1604
Batch 40, Loss: 1.2216
Batch 50, Loss: 1.2031
Batch 60, Loss: 1.2214
Batch 70, Loss: 1.2156
Batch 80, Loss: 1.2520
Batch 90, Loss: 1.3014
Batch 100, Loss: 1.2710
Batch 110, Loss: 1.2912
Batch 120, Loss: 1.1710
Batch 130, Loss: 1.2336
Batch 140, Loss: 1.2147
Batch 150, Loss: 1.2325
Batch 160, Loss: 1.2122
Batch 170, Loss: 1.2314
Batch 180, Loss: 1.2265
Batch 190, Loss: 1.2101
Batch 200, Loss: 1.2338
Batch 210, Loss: 1.3090
Batch 220, Loss: 1.3541
Batch 230, Loss: 1.2771
Batch 240, Loss: 1.2101
Batch 250, Loss: 1.2370
Batch 260, Loss: 1.2685
Batch 270, Loss: 1.2578
Batch 280, Loss: 1.2624
Batch 290, Loss: 1.2715
Batch 300, Loss: 1.2841
Batch 310, Loss: 1.2360
Batch 320, Loss: 1.2002
Batch 330, Loss: 1.3487
Batch 340, Loss: 1.2704
Batch 350, Loss: 1.3035
Batch 360, Loss: 1.2729
Batch 370, Loss: 1.2532
Batch 380, Loss: 1.2413
Batch 390, Loss: 1.2831
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.462838649749756 seconds
Epoch 77 accuracy: 63.16%
Batch 10, Loss: 1.1821
Batch 20, Loss: 1.2499
Batch 30, Loss: 1.1611
Batch 40, Loss: 1.2390
Batch 50, Loss: 1.1936
Batch 60, Loss: 1.2207
Batch 70, Loss: 1.2407
Batch 80, Loss: 1.2245
Batch 90, Loss: 1.2191
Batch 100, Loss: 1.2409
Batch 110, Loss: 1.2038
Batch 120, Loss: 1.2662
Batch 130, Loss: 1.2374
Batch 140, Loss: 1.3196
Batch 150, Loss: 1.1950
Batch 160, Loss: 1.2151
Batch 170, Loss: 1.1974
Batch 180, Loss: 1.2409
Batch 190, Loss: 1.2441
Batch 200, Loss: 1.3318
Batch 210, Loss: 1.2462
Batch 220, Loss: 1.2064
Batch 230, Loss: 1.2666
Batch 240, Loss: 1.1941
Batch 250, Loss: 1.2609
Batch 260, Loss: 1.2898
Batch 270, Loss: 1.2573
Batch 280, Loss: 1.2248
Batch 290, Loss: 1.2551
Batch 300, Loss: 1.2577
Batch 310, Loss: 1.2067
Batch 320, Loss: 1.2330
Batch 330, Loss: 1.2047
Batch 340, Loss: 1.2746
Batch 350, Loss: 1.2212
Batch 360, Loss: 1.3053
Batch 370, Loss: 1.2747
Batch 380, Loss: 1.2662
Batch 390, Loss: 1.3433
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.439770221710205 seconds
Epoch 78 accuracy: 65.11%
Batch 10, Loss: 1.1314
Batch 20, Loss: 1.1827
Batch 30, Loss: 1.2006
Batch 40, Loss: 1.1851
Batch 50, Loss: 1.2149
Batch 60, Loss: 1.1992
Batch 70, Loss: 1.1373
Batch 80, Loss: 1.2257
Batch 90, Loss: 1.2629
Batch 100, Loss: 1.2923
Batch 110, Loss: 1.2514
Batch 120, Loss: 1.2482
Batch 130, Loss: 1.1987
Batch 140, Loss: 1.2447
Batch 150, Loss: 1.2607
Batch 160, Loss: 1.2037
Batch 170, Loss: 1.2236
Batch 180, Loss: 1.1601
Batch 190, Loss: 1.2854
Batch 200, Loss: 1.1859
Batch 210, Loss: 1.2198
Batch 220, Loss: 1.2330
Batch 230, Loss: 1.2277
Batch 240, Loss: 1.2337
Batch 250, Loss: 1.2686
Batch 260, Loss: 1.3173
Batch 270, Loss: 1.2342
Batch 280, Loss: 1.2771
Batch 290, Loss: 1.2312
Batch 300, Loss: 1.2788
Batch 310, Loss: 1.2888
Batch 320, Loss: 1.2965
Batch 330, Loss: 1.2399
Batch 340, Loss: 1.3294
Batch 350, Loss: 1.2846
Batch 360, Loss: 1.2103
Batch 370, Loss: 1.3339
Batch 380, Loss: 1.2567
Batch 390, Loss: 1.2650
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.399831771850586 seconds
Epoch 79 accuracy: 62.39%
Batch 10, Loss: 1.2406
Batch 20, Loss: 1.2149
Batch 30, Loss: 1.2061
Batch 40, Loss: 1.1968
Batch 50, Loss: 1.2191
Batch 60, Loss: 1.1836
Batch 70, Loss: 1.2401
Batch 80, Loss: 1.1792
Batch 90, Loss: 1.1434
Batch 100, Loss: 1.2162
Batch 110, Loss: 1.2424
Batch 120, Loss: 1.2142
Batch 130, Loss: 1.1692
Batch 140, Loss: 1.2688
Batch 150, Loss: 1.2120
Batch 160, Loss: 1.2060
Batch 170, Loss: 1.2737
Batch 180, Loss: 1.1764
Batch 190, Loss: 1.2337
Batch 200, Loss: 1.1949
Batch 210, Loss: 1.2458
Batch 220, Loss: 1.2433
Batch 230, Loss: 1.1906
Batch 240, Loss: 1.2099
Batch 250, Loss: 1.2261
Batch 260, Loss: 1.2674
Batch 270, Loss: 1.2808
Batch 280, Loss: 1.2909
Batch 290, Loss: 1.3032
Batch 300, Loss: 1.2638
Batch 310, Loss: 1.2478
Batch 320, Loss: 1.2549
Batch 330, Loss: 1.3071
Batch 340, Loss: 1.3619
Batch 350, Loss: 1.3072
Batch 360, Loss: 1.2519
Batch 370, Loss: 1.2914
Batch 380, Loss: 1.3023
Batch 390, Loss: 1.2457
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.371807098388672 seconds
Epoch 80 accuracy: 63.11%
Batch 10, Loss: 1.2315
Batch 20, Loss: 1.1657
Batch 30, Loss: 1.1776
Batch 40, Loss: 1.1909
Batch 50, Loss: 1.1135
Batch 60, Loss: 1.1854
Batch 70, Loss: 1.2511
Batch 80, Loss: 1.2555
Batch 90, Loss: 1.2616
Batch 100, Loss: 1.2287
Batch 110, Loss: 1.2233
Batch 120, Loss: 1.2127
Batch 130, Loss: 1.2088
Batch 140, Loss: 1.2360
Batch 150, Loss: 1.2296
Batch 160, Loss: 1.1885
Batch 170, Loss: 1.2015
Batch 180, Loss: 1.2014
Batch 190, Loss: 1.1612
Batch 200, Loss: 1.2646
Batch 210, Loss: 1.2468
Batch 220, Loss: 1.3022
Batch 230, Loss: 1.2388
Batch 240, Loss: 1.2501
Batch 250, Loss: 1.3057
Batch 260, Loss: 1.2035
Batch 270, Loss: 1.2942
Batch 280, Loss: 1.2433
Batch 290, Loss: 1.2029
Batch 300, Loss: 1.2621
Batch 310, Loss: 1.2246
Batch 320, Loss: 1.2504
Batch 330, Loss: 1.2953
Batch 340, Loss: 1.2271
Batch 350, Loss: 1.2198
Batch 360, Loss: 1.2945
Batch 370, Loss: 1.2413
Batch 380, Loss: 1.3007
Batch 390, Loss: 1.2889
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.36055636405945 seconds
Epoch 81 accuracy: 61.72%
Batch 10, Loss: 1.2461
Batch 20, Loss: 1.1549
Batch 30, Loss: 1.2256
Batch 40, Loss: 1.1727
Batch 50, Loss: 1.1430
Batch 60, Loss: 1.2369
Batch 70, Loss: 1.2398
Batch 80, Loss: 1.2325
Batch 90, Loss: 1.2314
Batch 100, Loss: 1.2742
Batch 110, Loss: 1.1742
Batch 120, Loss: 1.1585
Batch 130, Loss: 1.1919
Batch 140, Loss: 1.2294
Batch 150, Loss: 1.2269
Batch 160, Loss: 1.2143
Batch 170, Loss: 1.1827
Batch 180, Loss: 1.1859
Batch 190, Loss: 1.1725
Batch 200, Loss: 1.2216
Batch 210, Loss: 1.2329
Batch 220, Loss: 1.2736
Batch 230, Loss: 1.2430
Batch 240, Loss: 1.2953
Batch 250, Loss: 1.2436
Batch 260, Loss: 1.2468
Batch 270, Loss: 1.1935
Batch 280, Loss: 1.2560
Batch 290, Loss: 1.2297
Batch 300, Loss: 1.2741
Batch 310, Loss: 1.2243
Batch 320, Loss: 1.1901
Batch 330, Loss: 1.1578
Batch 340, Loss: 1.1761
Batch 350, Loss: 1.2625
Batch 360, Loss: 1.3012
Batch 370, Loss: 1.2315
Batch 380, Loss: 1.2677
Batch 390, Loss: 1.2362
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.51251220703125 seconds
Epoch 82 accuracy: 62.53%
Batch 10, Loss: 1.1237
Batch 20, Loss: 1.1888
Batch 30, Loss: 1.1770
Batch 40, Loss: 1.1594
Batch 50, Loss: 1.1438
Batch 60, Loss: 1.1059
Batch 70, Loss: 1.2059
Batch 80, Loss: 1.1315
Batch 90, Loss: 1.1637
Batch 100, Loss: 1.2222
Batch 110, Loss: 1.2018
Batch 120, Loss: 1.1618
Batch 130, Loss: 1.1496
Batch 140, Loss: 1.1995
Batch 150, Loss: 1.2182
Batch 160, Loss: 1.2713
Batch 170, Loss: 1.2023
Batch 180, Loss: 1.2047
Batch 190, Loss: 1.2707
Batch 200, Loss: 1.2223
Batch 210, Loss: 1.2538
Batch 220, Loss: 1.2531
Batch 230, Loss: 1.2387
Batch 240, Loss: 1.2654
Batch 250, Loss: 1.2495
Batch 260, Loss: 1.2365
Batch 270, Loss: 1.2007
Batch 280, Loss: 1.2490
Batch 290, Loss: 1.2440
Batch 300, Loss: 1.2027
Batch 310, Loss: 1.2156
Batch 320, Loss: 1.2075
Batch 330, Loss: 1.2208
Batch 340, Loss: 1.1882
Batch 350, Loss: 1.2560
Batch 360, Loss: 1.2476
Batch 370, Loss: 1.2644
Batch 380, Loss: 1.2408
Batch 390, Loss: 1.2547
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.472222566604614 seconds
Epoch 83 accuracy: 63.5%
Batch 10, Loss: 1.2368
Batch 20, Loss: 1.1199
Batch 30, Loss: 1.1274
Batch 40, Loss: 1.1139
Batch 50, Loss: 1.1433
Batch 60, Loss: 1.1605
Batch 70, Loss: 1.1333
Batch 80, Loss: 1.2100
Batch 90, Loss: 1.1363
Batch 100, Loss: 1.2248
Batch 110, Loss: 1.1872
Batch 120, Loss: 1.1858
Batch 130, Loss: 1.1697
Batch 140, Loss: 1.2532
Batch 150, Loss: 1.2369
Batch 160, Loss: 1.2322
Batch 170, Loss: 1.1909
Batch 180, Loss: 1.2228
Batch 190, Loss: 1.2473
Batch 200, Loss: 1.2412
Batch 210, Loss: 1.1834
Batch 220, Loss: 1.1674
Batch 230, Loss: 1.3042
Batch 240, Loss: 1.2850
Batch 250, Loss: 1.2282
Batch 260, Loss: 1.2337
Batch 270, Loss: 1.2522
Batch 280, Loss: 1.2257
Batch 290, Loss: 1.2072
Batch 300, Loss: 1.1884
Batch 310, Loss: 1.2503
Batch 320, Loss: 1.1961
Batch 330, Loss: 1.2267
Batch 340, Loss: 1.2259
Batch 350, Loss: 1.1848
Batch 360, Loss: 1.2416
Batch 370, Loss: 1.2142
Batch 380, Loss: 1.1986
Batch 390, Loss: 1.2135
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.431679010391235 seconds
Epoch 84 accuracy: 62.98%
Batch 10, Loss: 1.2089
Batch 20, Loss: 1.1494
Batch 30, Loss: 1.2235
Batch 40, Loss: 1.1514
Batch 50, Loss: 1.1665
Batch 60, Loss: 1.1435
Batch 70, Loss: 1.2067
Batch 80, Loss: 1.2481
Batch 90, Loss: 1.2154
Batch 100, Loss: 1.1830
Batch 110, Loss: 1.1534
Batch 120, Loss: 1.1465
Batch 130, Loss: 1.1854
Batch 140, Loss: 1.1795
Batch 150, Loss: 1.1726
Batch 160, Loss: 1.1364
Batch 170, Loss: 1.1984
Batch 180, Loss: 1.2363
Batch 190, Loss: 1.1479
Batch 200, Loss: 1.2456
Batch 210, Loss: 1.1904
Batch 220, Loss: 1.1894
Batch 230, Loss: 1.2121
Batch 240, Loss: 1.2324
Batch 250, Loss: 1.1725
Batch 260, Loss: 1.2308
Batch 270, Loss: 1.1722
Batch 280, Loss: 1.1848
Batch 290, Loss: 1.2479
Batch 300, Loss: 1.2297
Batch 310, Loss: 1.1988
Batch 320, Loss: 1.2448
Batch 330, Loss: 1.2430
Batch 340, Loss: 1.2629
Batch 350, Loss: 1.1710
Batch 360, Loss: 1.2178
Batch 370, Loss: 1.1589
Batch 380, Loss: 1.1681
Batch 390, Loss: 1.2242
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.41177463531494 seconds
Epoch 85 accuracy: 61.45%
Batch 10, Loss: 1.1193
Batch 20, Loss: 1.2430
Batch 30, Loss: 1.1427
Batch 40, Loss: 1.1521
Batch 50, Loss: 1.1567
Batch 60, Loss: 1.1613
Batch 70, Loss: 1.2278
Batch 80, Loss: 1.2375
Batch 90, Loss: 1.1270
Batch 100, Loss: 1.0886
Batch 110, Loss: 1.1547
Batch 120, Loss: 1.1742
Batch 130, Loss: 1.1410
Batch 140, Loss: 1.2256
Batch 150, Loss: 1.1473
Batch 160, Loss: 1.1730
Batch 170, Loss: 1.1745
Batch 180, Loss: 1.2467
Batch 190, Loss: 1.1950
Batch 200, Loss: 1.1671
Batch 210, Loss: 1.1782
Batch 220, Loss: 1.1342
Batch 230, Loss: 1.1574
Batch 240, Loss: 1.2341
Batch 250, Loss: 1.2267
Batch 260, Loss: 1.2111
Batch 270, Loss: 1.2673
Batch 280, Loss: 1.2071
Batch 290, Loss: 1.2216
Batch 300, Loss: 1.2486
Batch 310, Loss: 1.1947
Batch 320, Loss: 1.2555
Batch 330, Loss: 1.1838
Batch 340, Loss: 1.2388
Batch 350, Loss: 1.1984
Batch 360, Loss: 1.1937
Batch 370, Loss: 1.2455
Batch 380, Loss: 1.2070
Batch 390, Loss: 1.2453
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.435200929641724 seconds
Epoch 86 accuracy: 64.67%
Batch 10, Loss: 1.1995
Batch 20, Loss: 1.2240
Batch 30, Loss: 1.1917
Batch 40, Loss: 1.1174
Batch 50, Loss: 1.1250
Batch 60, Loss: 1.1721
Batch 70, Loss: 1.1858
Batch 80, Loss: 1.1540
Batch 90, Loss: 1.1635
Batch 100, Loss: 1.1592
Batch 110, Loss: 1.2030
Batch 120, Loss: 1.1642
Batch 130, Loss: 1.1922
Batch 140, Loss: 1.1558
Batch 150, Loss: 1.2697
Batch 160, Loss: 1.2166
Batch 170, Loss: 1.1748
Batch 180, Loss: 1.1057
Batch 190, Loss: 1.1583
Batch 200, Loss: 1.1845
Batch 210, Loss: 1.2253
Batch 220, Loss: 1.0987
Batch 230, Loss: 1.1811
Batch 240, Loss: 1.1610
Batch 250, Loss: 1.1370
Batch 260, Loss: 1.2631
Batch 270, Loss: 1.2508
Batch 280, Loss: 1.1490
Batch 290, Loss: 1.1959
Batch 300, Loss: 1.1317
Batch 310, Loss: 1.2040
Batch 320, Loss: 1.2704
Batch 330, Loss: 1.1230
Batch 340, Loss: 1.2617
Batch 350, Loss: 1.2754
Batch 360, Loss: 1.1697
Batch 370, Loss: 1.1708
Batch 380, Loss: 1.1495
Batch 390, Loss: 1.2272
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.437416791915894 seconds
Epoch 87 accuracy: 63.95%
Batch 10, Loss: 1.0902
Batch 20, Loss: 1.0799
Batch 30, Loss: 1.1988
Batch 40, Loss: 1.2104
Batch 50, Loss: 1.1114
Batch 60, Loss: 1.1453
Batch 70, Loss: 1.1559
Batch 80, Loss: 1.1525
Batch 90, Loss: 1.1385
Batch 100, Loss: 1.1923
Batch 110, Loss: 1.2017
Batch 120, Loss: 1.1573
Batch 130, Loss: 1.1543
Batch 140, Loss: 1.1510
Batch 150, Loss: 1.1517
Batch 160, Loss: 1.2322
Batch 170, Loss: 1.1790
Batch 180, Loss: 1.1796
Batch 190, Loss: 1.1775
Batch 200, Loss: 1.2351
Batch 210, Loss: 1.2187
Batch 220, Loss: 1.2209
Batch 230, Loss: 1.1801
Batch 240, Loss: 1.1440
Batch 250, Loss: 1.2420
Batch 260, Loss: 1.1960
Batch 270, Loss: 1.2042
Batch 280, Loss: 1.1928
Batch 290, Loss: 1.2111
Batch 300, Loss: 1.2586
Batch 310, Loss: 1.1916
Batch 320, Loss: 1.2011
Batch 330, Loss: 1.2138
Batch 340, Loss: 1.2147
Batch 350, Loss: 1.2016
Batch 360, Loss: 1.2408
Batch 370, Loss: 1.2214
Batch 380, Loss: 1.1959
Batch 390, Loss: 1.2086
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.477912664413452 seconds
Epoch 88 accuracy: 64.45%
Batch 10, Loss: 1.1376
Batch 20, Loss: 1.1266
Batch 30, Loss: 1.1891
Batch 40, Loss: 1.0764
Batch 50, Loss: 1.1900
Batch 60, Loss: 1.1338
Batch 70, Loss: 1.1820
Batch 80, Loss: 1.0992
Batch 90, Loss: 1.1708
Batch 100, Loss: 1.1425
Batch 110, Loss: 1.1517
Batch 120, Loss: 1.2180
Batch 130, Loss: 1.1780
Batch 140, Loss: 1.1576
Batch 150, Loss: 1.1622
Batch 160, Loss: 1.1240
Batch 170, Loss: 1.1490
Batch 180, Loss: 1.2014
Batch 190, Loss: 1.1307
Batch 200, Loss: 1.2239
Batch 210, Loss: 1.1552
Batch 220, Loss: 1.1492
Batch 230, Loss: 1.1885
Batch 240, Loss: 1.2201
Batch 250, Loss: 1.2073
Batch 260, Loss: 1.2076
Batch 270, Loss: 1.1650
Batch 280, Loss: 1.1820
Batch 290, Loss: 1.2211
Batch 300, Loss: 1.2316
Batch 310, Loss: 1.2195
Batch 320, Loss: 1.2074
Batch 330, Loss: 1.1588
Batch 340, Loss: 1.1577
Batch 350, Loss: 1.2008
Batch 360, Loss: 1.1569
Batch 370, Loss: 1.2488
Batch 380, Loss: 1.2016
Batch 390, Loss: 1.3147
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.414988040924072 seconds
Epoch 89 accuracy: 64.23%
Batch 10, Loss: 1.0983
Batch 20, Loss: 1.0954
Batch 30, Loss: 1.0990
Batch 40, Loss: 1.1277
Batch 50, Loss: 1.1580
Batch 60, Loss: 1.0958
Batch 70, Loss: 1.1771
Batch 80, Loss: 1.0705
Batch 90, Loss: 1.1751
Batch 100, Loss: 1.1692
Batch 110, Loss: 1.1855
Batch 120, Loss: 1.1361
Batch 130, Loss: 1.2361
Batch 140, Loss: 1.2060
Batch 150, Loss: 1.1827
Batch 160, Loss: 1.1801
Batch 170, Loss: 1.1372
Batch 180, Loss: 1.1854
Batch 190, Loss: 1.1448
Batch 200, Loss: 1.0900
Batch 210, Loss: 1.1605
Batch 220, Loss: 1.1620
Batch 230, Loss: 1.1671
Batch 240, Loss: 1.1771
Batch 250, Loss: 1.2081
Batch 260, Loss: 1.1498
Batch 270, Loss: 1.2651
Batch 280, Loss: 1.1711
Batch 290, Loss: 1.2532
Batch 300, Loss: 1.2186
Batch 310, Loss: 1.1579
Batch 320, Loss: 1.2047
Batch 330, Loss: 1.1459
Batch 340, Loss: 1.1740
Batch 350, Loss: 1.1749
Batch 360, Loss: 1.1613
Batch 370, Loss: 1.2360
Batch 380, Loss: 1.1715
Batch 390, Loss: 1.1790
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.423778295516968 seconds
Epoch 90 accuracy: 63.78%
Batch 10, Loss: 1.1703
Batch 20, Loss: 1.1335
Batch 30, Loss: 1.0646
Batch 40, Loss: 1.1073
Batch 50, Loss: 1.1825
Batch 60, Loss: 1.1334
Batch 70, Loss: 1.1340
Batch 80, Loss: 1.1538
Batch 90, Loss: 1.2268
Batch 100, Loss: 1.1252
Batch 110, Loss: 1.1458
Batch 120, Loss: 1.1206
Batch 130, Loss: 1.1664
Batch 140, Loss: 1.1788
Batch 150, Loss: 1.1899
Batch 160, Loss: 1.1595
Batch 170, Loss: 1.1646
Batch 180, Loss: 1.1476
Batch 190, Loss: 1.1820
Batch 200, Loss: 1.1514
Batch 210, Loss: 1.1864
Batch 220, Loss: 1.2257
Batch 230, Loss: 1.1038
Batch 240, Loss: 1.1456
Batch 250, Loss: 1.2174
Batch 260, Loss: 1.1569
Batch 270, Loss: 1.2149
Batch 280, Loss: 1.1741
Batch 290, Loss: 1.1798
Batch 300, Loss: 1.1659
Batch 310, Loss: 1.1691
Batch 320, Loss: 1.1537
Batch 330, Loss: 1.1439
Batch 340, Loss: 1.2355
Batch 350, Loss: 1.2005
Batch 360, Loss: 1.1718
Batch 370, Loss: 1.2355
Batch 380, Loss: 1.1808
Batch 390, Loss: 1.1952
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.416969060897827 seconds
Epoch 91 accuracy: 62.37%
Batch 10, Loss: 1.1547
Batch 20, Loss: 1.1082
Batch 30, Loss: 1.1574
Batch 40, Loss: 1.1121
Batch 50, Loss: 1.1104
Batch 60, Loss: 1.1626
Batch 70, Loss: 1.0755
Batch 80, Loss: 1.1510
Batch 90, Loss: 1.1260
Batch 100, Loss: 1.1631
Batch 110, Loss: 1.1200
Batch 120, Loss: 1.1112
Batch 130, Loss: 1.1394
Batch 140, Loss: 1.2124
Batch 150, Loss: 1.0525
Batch 160, Loss: 1.1180
Batch 170, Loss: 1.0998
Batch 180, Loss: 1.0680
Batch 190, Loss: 1.0810
Batch 200, Loss: 1.1528
Batch 210, Loss: 1.1232
Batch 220, Loss: 1.1195
Batch 230, Loss: 1.1748
Batch 240, Loss: 1.1655
Batch 250, Loss: 1.1395
Batch 260, Loss: 1.1389
Batch 270, Loss: 1.1248
Batch 280, Loss: 1.1412
Batch 290, Loss: 1.1924
Batch 300, Loss: 1.1900
Batch 310, Loss: 1.1845
Batch 320, Loss: 1.1590
Batch 330, Loss: 1.1806
Batch 340, Loss: 1.1918
Batch 350, Loss: 1.2209
Batch 360, Loss: 1.2195
Batch 370, Loss: 1.2253
Batch 380, Loss: 1.1882
Batch 390, Loss: 1.2470
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.47130036354065 seconds
Epoch 92 accuracy: 64.21%
Batch 10, Loss: 1.0824
Batch 20, Loss: 1.0728
Batch 30, Loss: 1.1033
Batch 40, Loss: 1.0703
Batch 50, Loss: 1.0468
Batch 60, Loss: 1.0793
Batch 70, Loss: 1.1117
Batch 80, Loss: 1.1896
Batch 90, Loss: 1.1276
Batch 100, Loss: 1.1208
Batch 110, Loss: 1.1615
Batch 120, Loss: 1.1961
Batch 130, Loss: 1.1750
Batch 140, Loss: 1.1707
Batch 150, Loss: 1.1146
Batch 160, Loss: 1.1396
Batch 170, Loss: 1.1439
Batch 180, Loss: 1.1425
Batch 190, Loss: 1.1823
Batch 200, Loss: 1.0854
Batch 210, Loss: 1.1307
Batch 220, Loss: 1.1124
Batch 230, Loss: 1.1661
Batch 240, Loss: 1.2294
Batch 250, Loss: 1.1944
Batch 260, Loss: 1.1328
Batch 270, Loss: 1.1891
Batch 280, Loss: 1.1813
Batch 290, Loss: 1.1662
Batch 300, Loss: 1.1829
Batch 310, Loss: 1.1586
Batch 320, Loss: 1.1642
Batch 330, Loss: 1.1938
Batch 340, Loss: 1.2059
Batch 350, Loss: 1.1765
Batch 360, Loss: 1.1345
Batch 370, Loss: 1.1463
Batch 380, Loss: 1.1600
Batch 390, Loss: 1.1995
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.394083499908447 seconds
Epoch 93 accuracy: 65.0%
Batch 10, Loss: 1.1113
Batch 20, Loss: 1.1288
Batch 30, Loss: 1.0323
Batch 40, Loss: 1.0907
Batch 50, Loss: 1.0529
Batch 60, Loss: 1.1179
Batch 70, Loss: 1.0648
Batch 80, Loss: 1.1210
Batch 90, Loss: 1.1228
Batch 100, Loss: 1.1143
Batch 110, Loss: 1.1156
Batch 120, Loss: 1.1952
Batch 130, Loss: 1.0994
Batch 140, Loss: 1.1675
Batch 150, Loss: 1.1748
Batch 160, Loss: 1.1051
Batch 170, Loss: 1.1159
Batch 180, Loss: 1.1082
Batch 190, Loss: 1.1241
Batch 200, Loss: 1.1642
Batch 210, Loss: 1.1512
Batch 220, Loss: 1.1312
Batch 230, Loss: 1.1240
Batch 240, Loss: 1.1087
Batch 250, Loss: 1.2484
Batch 260, Loss: 1.1446
Batch 270, Loss: 1.2024
Batch 280, Loss: 1.1729
Batch 290, Loss: 1.1787
Batch 300, Loss: 1.0868
Batch 310, Loss: 1.0761
Batch 320, Loss: 1.1581
Batch 330, Loss: 1.1016
Batch 340, Loss: 1.1305
Batch 350, Loss: 1.1374
Batch 360, Loss: 1.1252
Batch 370, Loss: 1.1844
Batch 380, Loss: 1.1375
Batch 390, Loss: 1.1886
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.40252161026001 seconds
Epoch 94 accuracy: 63.41%
Batch 10, Loss: 1.1149
Batch 20, Loss: 1.1458
Batch 30, Loss: 1.1028
Batch 40, Loss: 1.0753
Batch 50, Loss: 1.1582
Batch 60, Loss: 1.0932
Batch 70, Loss: 1.1035
Batch 80, Loss: 1.1381
Batch 90, Loss: 1.1538
Batch 100, Loss: 1.1265
Batch 110, Loss: 1.1138
Batch 120, Loss: 1.1703
Batch 130, Loss: 1.1318
Batch 140, Loss: 1.1284
Batch 150, Loss: 1.1575
Batch 160, Loss: 1.1320
Batch 170, Loss: 1.1950
Batch 180, Loss: 1.1078
Batch 190, Loss: 1.2022
Batch 200, Loss: 1.1379
Batch 210, Loss: 1.2050
Batch 220, Loss: 1.1348
Batch 230, Loss: 1.1836
Batch 240, Loss: 1.1472
Batch 250, Loss: 1.1559
Batch 260, Loss: 1.2342
Batch 270, Loss: 1.1942
Batch 280, Loss: 1.1882
Batch 290, Loss: 1.1642
Batch 300, Loss: 1.1689
Batch 310, Loss: 1.1215
Batch 320, Loss: 1.1181
Batch 330, Loss: 1.1235
Batch 340, Loss: 1.1707
Batch 350, Loss: 1.1065
Batch 360, Loss: 1.1681
Batch 370, Loss: 1.1642
Batch 380, Loss: 1.0978
Batch 390, Loss: 1.1376
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.516626358032227 seconds
Epoch 95 accuracy: 66.93%
Batch 10, Loss: 1.0565
Batch 20, Loss: 1.1422
Batch 30, Loss: 1.1071
Batch 40, Loss: 1.1091
Batch 50, Loss: 1.1528
Batch 60, Loss: 1.0790
Batch 70, Loss: 1.1088
Batch 80, Loss: 1.1107
Batch 90, Loss: 1.1133
Batch 100, Loss: 1.0962
Batch 110, Loss: 1.1050
Batch 120, Loss: 1.1166
Batch 130, Loss: 1.1274
Batch 140, Loss: 1.0812
Batch 150, Loss: 1.1119
Batch 160, Loss: 1.0394
Batch 170, Loss: 1.1130
Batch 180, Loss: 1.1147
Batch 190, Loss: 1.1197
Batch 200, Loss: 1.0976
Batch 210, Loss: 1.1539
Batch 220, Loss: 1.1688
Batch 230, Loss: 1.1714
Batch 240, Loss: 1.1117
Batch 250, Loss: 1.1732
Batch 260, Loss: 1.1580
Batch 270, Loss: 1.1196
Batch 280, Loss: 1.1066
Batch 290, Loss: 1.1280
Batch 300, Loss: 1.1881
Batch 310, Loss: 1.1212
Batch 320, Loss: 1.0828
Batch 330, Loss: 1.1390
Batch 340, Loss: 1.1022
Batch 350, Loss: 1.2236
Batch 360, Loss: 1.2041
Batch 370, Loss: 1.1755
Batch 380, Loss: 1.1652
Batch 390, Loss: 1.1220
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.40074372291565 seconds
Epoch 96 accuracy: 65.76%
Batch 10, Loss: 1.1268
Batch 20, Loss: 1.0450
Batch 30, Loss: 1.0878
Batch 40, Loss: 1.0162
Batch 50, Loss: 1.0870
Batch 60, Loss: 1.1652
Batch 70, Loss: 1.0892
Batch 80, Loss: 1.0908
Batch 90, Loss: 1.1292
Batch 100, Loss: 1.1003
Batch 110, Loss: 1.0931
Batch 120, Loss: 1.0695
Batch 130, Loss: 1.1129
Batch 140, Loss: 1.1355
Batch 150, Loss: 1.0831
Batch 160, Loss: 1.0679
Batch 170, Loss: 1.1852
Batch 180, Loss: 1.0903
Batch 190, Loss: 1.1435
Batch 200, Loss: 1.0444
Batch 210, Loss: 1.0823
Batch 220, Loss: 1.1065
Batch 230, Loss: 1.1500
Batch 240, Loss: 1.1095
Batch 250, Loss: 1.1319
Batch 260, Loss: 1.1607
Batch 270, Loss: 1.1218
Batch 280, Loss: 1.1115
Batch 290, Loss: 1.1333
Batch 300, Loss: 1.1857
Batch 310, Loss: 1.0786
Batch 320, Loss: 1.1491
Batch 330, Loss: 1.1263
Batch 340, Loss: 1.1441
Batch 350, Loss: 1.1764
Batch 360, Loss: 1.1377
Batch 370, Loss: 1.1351
Batch 380, Loss: 1.1137
Batch 390, Loss: 1.1373
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.45670437812805 seconds
Epoch 97 accuracy: 64.37%
Batch 10, Loss: 1.0263
Batch 20, Loss: 1.0147
Batch 30, Loss: 1.0718
Batch 40, Loss: 1.0804
Batch 50, Loss: 1.0643
Batch 60, Loss: 1.0816
Batch 70, Loss: 1.0584
Batch 80, Loss: 1.0462
Batch 90, Loss: 1.0095
Batch 100, Loss: 1.0193
Batch 110, Loss: 1.0412
Batch 120, Loss: 1.0678
Batch 130, Loss: 1.0790
Batch 140, Loss: 1.1588
Batch 150, Loss: 1.0727
Batch 160, Loss: 1.1296
Batch 170, Loss: 1.1652
Batch 180, Loss: 1.1448
Batch 190, Loss: 1.1768
Batch 200, Loss: 1.1508
Batch 210, Loss: 1.1234
Batch 220, Loss: 1.0822
Batch 230, Loss: 1.0920
Batch 240, Loss: 1.1223
Batch 250, Loss: 1.1101
Batch 260, Loss: 1.1065
Batch 270, Loss: 1.1483
Batch 280, Loss: 1.1519
Batch 290, Loss: 1.1657
Batch 300, Loss: 1.1267
Batch 310, Loss: 1.1579
Batch 320, Loss: 1.1213
Batch 330, Loss: 1.1468
Batch 340, Loss: 1.2263
Batch 350, Loss: 1.1621
Batch 360, Loss: 1.1535
Batch 370, Loss: 1.1070
Batch 380, Loss: 1.1615
Batch 390, Loss: 1.1236
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.546961784362793 seconds
Epoch 98 accuracy: 67.01%
Batch 10, Loss: 1.0514
Batch 20, Loss: 1.0467
Batch 30, Loss: 1.0568
Batch 40, Loss: 1.0455
Batch 50, Loss: 1.0652
Batch 60, Loss: 1.0242
Batch 70, Loss: 1.0388
Batch 80, Loss: 0.9646
Batch 90, Loss: 1.0741
Batch 100, Loss: 1.1100
Batch 110, Loss: 1.1033
Batch 120, Loss: 1.0763
Batch 130, Loss: 1.0630
Batch 140, Loss: 1.0744
Batch 150, Loss: 1.1074
Batch 160, Loss: 1.1388
Batch 170, Loss: 1.0958
Batch 180, Loss: 1.1643
Batch 190, Loss: 1.1185
Batch 200, Loss: 1.0739
Batch 210, Loss: 1.1182
Batch 220, Loss: 1.1078
Batch 230, Loss: 1.1413
Batch 240, Loss: 1.1694
Batch 250, Loss: 1.1470
Batch 260, Loss: 1.0769
Batch 270, Loss: 1.1104
Batch 280, Loss: 1.1450
Batch 290, Loss: 1.1536
Batch 300, Loss: 1.0797
Batch 310, Loss: 1.1397
Batch 320, Loss: 1.0823
Batch 330, Loss: 1.1142
Batch 340, Loss: 1.1760
Batch 350, Loss: 1.0813
Batch 360, Loss: 1.1735
Batch 370, Loss: 1.1275
Batch 380, Loss: 1.2099
Batch 390, Loss: 1.1807
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.472268104553223 seconds
Epoch 99 accuracy: 65.65%
Batch 10, Loss: 1.0633
Batch 20, Loss: 1.0276
Batch 30, Loss: 1.0717
Batch 40, Loss: 1.0457
Batch 50, Loss: 1.1722
Batch 60, Loss: 1.1202
Batch 70, Loss: 1.0839
Batch 80, Loss: 1.0391
Batch 90, Loss: 1.0970
Batch 100, Loss: 1.0577
Batch 110, Loss: 1.0329
Batch 120, Loss: 1.0559
Batch 130, Loss: 1.0901
Batch 140, Loss: 1.0526
Batch 150, Loss: 1.1016
Batch 160, Loss: 1.0892
Batch 170, Loss: 1.0190
Batch 180, Loss: 1.1136
Batch 190, Loss: 1.0359
Batch 200, Loss: 1.0863
Batch 210, Loss: 1.0987
Batch 220, Loss: 1.0714
Batch 230, Loss: 1.0968
Batch 240, Loss: 1.0371
Batch 250, Loss: 1.1234
Batch 260, Loss: 1.1130
Batch 270, Loss: 1.0973
Batch 280, Loss: 1.0895
Batch 290, Loss: 1.1177
Batch 300, Loss: 1.1057
Batch 310, Loss: 1.1514
Batch 320, Loss: 1.0559
Batch 330, Loss: 1.1582
Batch 340, Loss: 1.1509
Batch 350, Loss: 1.1129
Batch 360, Loss: 1.1376
Batch 370, Loss: 1.1383
Batch 380, Loss: 1.1417
Batch 390, Loss: 1.1343
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.36373734474182 seconds
Epoch 100 accuracy: 66.99%
Batch 10, Loss: 1.0651
Batch 20, Loss: 1.0268
Batch 30, Loss: 1.0650
Batch 40, Loss: 1.0683
Batch 50, Loss: 1.0392
Batch 60, Loss: 1.1046
Batch 70, Loss: 1.1433
Batch 80, Loss: 1.0835
Batch 90, Loss: 1.0463
Batch 100, Loss: 1.0366
Batch 110, Loss: 1.0467
Batch 120, Loss: 1.0390
Batch 130, Loss: 1.0661
Batch 140, Loss: 1.0217
Batch 150, Loss: 1.0883
Batch 160, Loss: 1.1400
Batch 170, Loss: 1.1181
Batch 180, Loss: 1.1007
Batch 190, Loss: 1.0754
Batch 200, Loss: 1.1028
Batch 210, Loss: 1.0750
Batch 220, Loss: 1.0596
Batch 230, Loss: 1.0389
Batch 240, Loss: 1.0852
Batch 250, Loss: 1.0663
Batch 260, Loss: 1.1374
Batch 270, Loss: 1.0966
Batch 280, Loss: 1.1247
Batch 290, Loss: 1.2004
Batch 300, Loss: 1.0991
Batch 310, Loss: 1.0813
Batch 320, Loss: 1.1175
Batch 330, Loss: 1.0354
Batch 340, Loss: 1.0479
Batch 350, Loss: 1.1371
Batch 360, Loss: 1.2028
Batch 370, Loss: 1.0866
Batch 380, Loss: 1.1376
Batch 390, Loss: 1.1276
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.400968074798584 seconds
Epoch 101 accuracy: 64.96%
Batch 10, Loss: 1.0291
Batch 20, Loss: 1.0481
Batch 30, Loss: 1.0541
Batch 40, Loss: 1.0633
Batch 50, Loss: 1.0897
Batch 60, Loss: 1.0637
Batch 70, Loss: 1.1065
Batch 80, Loss: 1.0852
Batch 90, Loss: 1.0585
Batch 100, Loss: 1.0559
Batch 110, Loss: 0.9948
Batch 120, Loss: 1.1119
Batch 130, Loss: 1.0711
Batch 140, Loss: 1.1084
Batch 150, Loss: 1.0718
Batch 160, Loss: 1.0932
Batch 170, Loss: 1.1158
Batch 180, Loss: 1.0453
Batch 190, Loss: 1.0646
Batch 200, Loss: 1.0489
Batch 210, Loss: 1.1060
Batch 220, Loss: 1.0674
Batch 230, Loss: 1.1350
Batch 240, Loss: 1.0811
Batch 250, Loss: 1.0663
Batch 260, Loss: 1.1065
Batch 270, Loss: 1.0336
Batch 280, Loss: 1.0965
Batch 290, Loss: 1.1251
Batch 300, Loss: 1.0433
Batch 310, Loss: 1.1451
Batch 320, Loss: 1.1359
Batch 330, Loss: 1.1402
Batch 340, Loss: 1.1316
Batch 350, Loss: 1.1295
Batch 360, Loss: 1.1136
Batch 370, Loss: 1.1078
Batch 380, Loss: 1.1268
Batch 390, Loss: 1.1125
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.46644616127014 seconds
Epoch 102 accuracy: 66.67%
Batch 10, Loss: 1.0671
Batch 20, Loss: 1.0254
Batch 30, Loss: 1.0100
Batch 40, Loss: 1.1095
Batch 50, Loss: 0.9497
Batch 60, Loss: 1.0283
Batch 70, Loss: 0.9385
Batch 80, Loss: 1.0552
Batch 90, Loss: 1.0857
Batch 100, Loss: 1.0964
Batch 110, Loss: 1.0125
Batch 120, Loss: 1.0570
Batch 130, Loss: 1.0195
Batch 140, Loss: 1.1224
Batch 150, Loss: 1.1037
Batch 160, Loss: 1.0763
Batch 170, Loss: 1.1334
Batch 180, Loss: 1.1132
Batch 190, Loss: 1.1225
Batch 200, Loss: 1.0780
Batch 210, Loss: 1.0859
Batch 220, Loss: 1.1193
Batch 230, Loss: 1.1111
Batch 240, Loss: 1.0961
Batch 250, Loss: 1.0840
Batch 260, Loss: 1.1039
Batch 270, Loss: 1.1366
Batch 280, Loss: 1.0743
Batch 290, Loss: 1.0692
Batch 300, Loss: 1.0823
Batch 310, Loss: 1.0656
Batch 320, Loss: 1.1320
Batch 330, Loss: 1.0840
Batch 340, Loss: 1.1440
Batch 350, Loss: 1.1314
Batch 360, Loss: 1.1228
Batch 370, Loss: 1.0750
Batch 380, Loss: 1.0569
Batch 390, Loss: 1.0422
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.37096381187439 seconds
Epoch 103 accuracy: 66.98%
Batch 10, Loss: 0.9611
Batch 20, Loss: 1.0304
Batch 30, Loss: 1.0310
Batch 40, Loss: 1.0045
Batch 50, Loss: 1.0347
Batch 60, Loss: 0.9969
Batch 70, Loss: 1.0769
Batch 80, Loss: 1.0627
Batch 90, Loss: 1.0028
Batch 100, Loss: 1.0733
Batch 110, Loss: 1.0407
Batch 120, Loss: 1.0865
Batch 130, Loss: 1.1336
Batch 140, Loss: 1.1651
Batch 150, Loss: 1.0576
Batch 160, Loss: 1.0294
Batch 170, Loss: 1.0582
Batch 180, Loss: 1.0184
Batch 190, Loss: 1.1317
Batch 200, Loss: 1.0738
Batch 210, Loss: 1.0403
Batch 220, Loss: 1.1008
Batch 230, Loss: 1.0530
Batch 240, Loss: 1.0833
Batch 250, Loss: 1.0695
Batch 260, Loss: 1.0291
Batch 270, Loss: 1.0558
Batch 280, Loss: 1.0408
Batch 290, Loss: 1.0761
Batch 300, Loss: 1.0743
Batch 310, Loss: 1.1081
Batch 320, Loss: 1.1335
Batch 330, Loss: 1.1128
Batch 340, Loss: 1.0680
Batch 350, Loss: 1.0595
Batch 360, Loss: 1.1090
Batch 370, Loss: 1.0411
Batch 380, Loss: 1.0846
Batch 390, Loss: 1.0882
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.36260724067688 seconds
Epoch 104 accuracy: 66.54%
Batch 10, Loss: 0.9863
Batch 20, Loss: 1.0708
Batch 30, Loss: 0.9867
Batch 40, Loss: 1.0284
Batch 50, Loss: 1.0168
Batch 60, Loss: 1.0153
Batch 70, Loss: 1.0518
Batch 80, Loss: 1.0393
Batch 90, Loss: 1.0238
Batch 100, Loss: 0.9846
Batch 110, Loss: 1.0906
Batch 120, Loss: 1.0962
Batch 130, Loss: 0.9786
Batch 140, Loss: 1.0457
Batch 150, Loss: 1.0102
Batch 160, Loss: 0.9691
Batch 170, Loss: 1.0436
Batch 180, Loss: 0.9628
Batch 190, Loss: 1.0333
Batch 200, Loss: 1.0455
Batch 210, Loss: 1.1104
Batch 220, Loss: 1.0089
Batch 230, Loss: 1.0814
Batch 240, Loss: 1.0451
Batch 250, Loss: 1.0217
Batch 260, Loss: 1.1037
Batch 270, Loss: 1.0638
Batch 280, Loss: 1.0699
Batch 290, Loss: 1.0612
Batch 300, Loss: 1.0645
Batch 310, Loss: 1.0624
Batch 320, Loss: 1.1034
Batch 330, Loss: 1.1329
Batch 340, Loss: 1.0881
Batch 350, Loss: 1.0990
Batch 360, Loss: 1.0690
Batch 370, Loss: 1.0796
Batch 380, Loss: 1.1701
Batch 390, Loss: 1.1217
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.42203998565674 seconds
Epoch 105 accuracy: 66.58%
Batch 10, Loss: 0.9969
Batch 20, Loss: 1.0533
Batch 30, Loss: 1.0614
Batch 40, Loss: 1.0645
Batch 50, Loss: 0.9716
Batch 60, Loss: 0.9945
Batch 70, Loss: 1.0466
Batch 80, Loss: 1.0061
Batch 90, Loss: 1.0495
Batch 100, Loss: 1.0250
Batch 110, Loss: 1.0437
Batch 120, Loss: 1.0837
Batch 130, Loss: 1.0339
Batch 140, Loss: 1.0047
Batch 150, Loss: 1.0248
Batch 160, Loss: 1.0373
Batch 170, Loss: 1.0657
Batch 180, Loss: 1.0895
Batch 190, Loss: 1.0995
Batch 200, Loss: 1.1123
Batch 210, Loss: 1.0750
Batch 220, Loss: 1.0397
Batch 230, Loss: 1.0256
Batch 240, Loss: 1.0720
Batch 250, Loss: 1.1388
Batch 260, Loss: 1.1330
Batch 270, Loss: 1.1052
Batch 280, Loss: 1.1082
Batch 290, Loss: 1.1113
Batch 300, Loss: 1.0730
Batch 310, Loss: 1.0845
Batch 320, Loss: 1.0522
Batch 330, Loss: 1.0241
Batch 340, Loss: 1.0586
Batch 350, Loss: 1.0820
Batch 360, Loss: 1.0543
Batch 370, Loss: 1.0935
Batch 380, Loss: 1.1058
Batch 390, Loss: 1.0732
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.477708101272583 seconds
Epoch 106 accuracy: 67.72%
Batch 10, Loss: 0.9449
Batch 20, Loss: 0.9984
Batch 30, Loss: 0.9671
Batch 40, Loss: 1.0646
Batch 50, Loss: 0.9796
Batch 60, Loss: 1.0323
Batch 70, Loss: 1.0416
Batch 80, Loss: 1.0120
Batch 90, Loss: 1.0143
Batch 100, Loss: 0.9460
Batch 110, Loss: 0.9791
Batch 120, Loss: 1.0338
Batch 130, Loss: 1.0497
Batch 140, Loss: 1.0595
Batch 150, Loss: 0.9870
Batch 160, Loss: 1.0661
Batch 170, Loss: 1.0485
Batch 180, Loss: 1.0688
Batch 190, Loss: 1.0696
Batch 200, Loss: 1.0793
Batch 210, Loss: 1.0025
Batch 220, Loss: 1.0649
Batch 230, Loss: 1.0857
Batch 240, Loss: 1.0737
Batch 250, Loss: 1.0608
Batch 260, Loss: 1.0948
Batch 270, Loss: 1.0825
Batch 280, Loss: 1.0648
Batch 290, Loss: 1.0859
Batch 300, Loss: 1.0180
Batch 310, Loss: 1.1217
Batch 320, Loss: 1.0281
Batch 330, Loss: 1.0576
Batch 340, Loss: 1.0727
Batch 350, Loss: 1.0174
Batch 360, Loss: 1.0876
Batch 370, Loss: 1.0981
Batch 380, Loss: 1.0804
Batch 390, Loss: 1.1107
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.393331050872803 seconds
Epoch 107 accuracy: 65.36%
Batch 10, Loss: 0.9661
Batch 20, Loss: 0.9743
Batch 30, Loss: 0.9654
Batch 40, Loss: 0.9780
Batch 50, Loss: 0.9384
Batch 60, Loss: 0.9794
Batch 70, Loss: 1.0229
Batch 80, Loss: 1.0724
Batch 90, Loss: 1.0377
Batch 100, Loss: 0.9824
Batch 110, Loss: 1.0190
Batch 120, Loss: 0.9732
Batch 130, Loss: 1.0415
Batch 140, Loss: 1.0469
Batch 150, Loss: 1.0274
Batch 160, Loss: 1.0604
Batch 170, Loss: 1.0436
Batch 180, Loss: 0.9982
Batch 190, Loss: 1.0766
Batch 200, Loss: 1.0399
Batch 210, Loss: 1.0502
Batch 220, Loss: 1.1018
Batch 230, Loss: 1.0326
Batch 240, Loss: 1.0512
Batch 250, Loss: 1.0711
Batch 260, Loss: 1.0365
Batch 270, Loss: 1.1060
Batch 280, Loss: 1.0064
Batch 290, Loss: 0.9755
Batch 300, Loss: 1.0363
Batch 310, Loss: 1.0342
Batch 320, Loss: 1.0749
Batch 330, Loss: 1.0422
Batch 340, Loss: 1.0889
Batch 350, Loss: 1.0743
Batch 360, Loss: 1.1414
Batch 370, Loss: 1.0933
Batch 380, Loss: 1.0985
Batch 390, Loss: 1.0706
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.32863712310791 seconds
Epoch 108 accuracy: 65.37%
Batch 10, Loss: 1.0003
Batch 20, Loss: 1.0271
Batch 30, Loss: 1.0180
Batch 40, Loss: 0.9569
Batch 50, Loss: 0.9395
Batch 60, Loss: 0.9714
Batch 70, Loss: 1.0110
Batch 80, Loss: 0.9985
Batch 90, Loss: 0.9624
Batch 100, Loss: 0.9827
Batch 110, Loss: 1.0104
Batch 120, Loss: 1.0264
Batch 130, Loss: 1.0478
Batch 140, Loss: 0.9737
Batch 150, Loss: 1.0902
Batch 160, Loss: 1.0205
Batch 170, Loss: 0.9903
Batch 180, Loss: 1.0567
Batch 190, Loss: 1.0626
Batch 200, Loss: 1.0645
Batch 210, Loss: 1.0097
Batch 220, Loss: 1.0647
Batch 230, Loss: 1.0027
Batch 240, Loss: 1.0053
Batch 250, Loss: 1.0445
Batch 260, Loss: 1.0133
Batch 270, Loss: 1.1370
Batch 280, Loss: 1.0203
Batch 290, Loss: 0.9548
Batch 300, Loss: 1.0056
Batch 310, Loss: 1.0329
Batch 320, Loss: 1.0239
Batch 330, Loss: 1.0441
Batch 340, Loss: 1.0382
Batch 350, Loss: 1.0452
Batch 360, Loss: 1.0755
Batch 370, Loss: 1.0472
Batch 380, Loss: 1.0637
Batch 390, Loss: 1.0187
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.38843870162964 seconds
Epoch 109 accuracy: 68.61%
Batch 10, Loss: 0.9923
Batch 20, Loss: 0.9705
Batch 30, Loss: 0.9609
Batch 40, Loss: 0.9429
Batch 50, Loss: 0.9737
Batch 60, Loss: 0.9949
Batch 70, Loss: 0.9834
Batch 80, Loss: 0.9741
Batch 90, Loss: 0.9873
Batch 100, Loss: 1.0081
Batch 110, Loss: 0.9873
Batch 120, Loss: 0.9976
Batch 130, Loss: 0.9947
Batch 140, Loss: 0.9759
Batch 150, Loss: 1.0193
Batch 160, Loss: 1.0089
Batch 170, Loss: 1.0302
Batch 180, Loss: 1.0022
Batch 190, Loss: 1.0378
Batch 200, Loss: 1.0456
Batch 210, Loss: 1.0070
Batch 220, Loss: 1.0127
Batch 230, Loss: 1.0988
Batch 240, Loss: 1.0305
Batch 250, Loss: 1.0293
Batch 260, Loss: 1.0142
Batch 270, Loss: 1.1040
Batch 280, Loss: 1.0862
Batch 290, Loss: 1.0624
Batch 300, Loss: 1.1208
Batch 310, Loss: 1.0788
Batch 320, Loss: 1.0954
Batch 330, Loss: 1.0351
Batch 340, Loss: 1.0103
Batch 350, Loss: 1.0454
Batch 360, Loss: 1.0641
Batch 370, Loss: 1.0686
Batch 380, Loss: 0.9965
Batch 390, Loss: 1.0348
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.39742684364319 seconds
Epoch 110 accuracy: 64.9%
Batch 10, Loss: 0.9912
Batch 20, Loss: 0.9776
Batch 30, Loss: 0.9369
Batch 40, Loss: 0.9262
Batch 50, Loss: 0.9496
Batch 60, Loss: 0.9578
Batch 70, Loss: 0.9156
Batch 80, Loss: 0.9687
Batch 90, Loss: 0.9429
Batch 100, Loss: 1.0104
Batch 110, Loss: 0.9362
Batch 120, Loss: 0.9608
Batch 130, Loss: 1.0784
Batch 140, Loss: 1.0241
Batch 150, Loss: 0.9880
Batch 160, Loss: 1.0051
Batch 170, Loss: 1.0364
Batch 180, Loss: 0.9984
Batch 190, Loss: 0.9877
Batch 200, Loss: 0.9983
Batch 210, Loss: 1.0137
Batch 220, Loss: 0.9764
Batch 230, Loss: 0.9479
Batch 240, Loss: 1.0792
Batch 250, Loss: 0.9675
Batch 260, Loss: 1.0642
Batch 270, Loss: 1.0029
Batch 280, Loss: 1.0459
Batch 290, Loss: 1.0587
Batch 300, Loss: 1.0740
Batch 310, Loss: 1.0152
Batch 320, Loss: 1.0077
Batch 330, Loss: 0.9796
Batch 340, Loss: 1.0455
Batch 350, Loss: 0.9891
Batch 360, Loss: 1.0187
Batch 370, Loss: 0.9673
Batch 380, Loss: 1.0387
Batch 390, Loss: 1.0161
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.407910346984863 seconds
Epoch 111 accuracy: 67.65%
Batch 10, Loss: 0.9543
Batch 20, Loss: 0.9382
Batch 30, Loss: 0.9094
Batch 40, Loss: 0.9133
Batch 50, Loss: 0.9909
Batch 60, Loss: 0.9779
Batch 70, Loss: 0.9960
Batch 80, Loss: 0.9770
Batch 90, Loss: 0.9290
Batch 100, Loss: 0.9582
Batch 110, Loss: 0.9384
Batch 120, Loss: 0.9786
Batch 130, Loss: 0.9494
Batch 140, Loss: 0.9748
Batch 150, Loss: 1.0639
Batch 160, Loss: 1.0362
Batch 170, Loss: 0.9643
Batch 180, Loss: 0.9812
Batch 190, Loss: 0.9868
Batch 200, Loss: 1.0080
Batch 210, Loss: 1.0128
Batch 220, Loss: 1.0518
Batch 230, Loss: 1.0074
Batch 240, Loss: 1.0203
Batch 250, Loss: 1.0184
Batch 260, Loss: 0.9707
Batch 270, Loss: 1.0257
Batch 280, Loss: 1.0145
Batch 290, Loss: 1.0523
Batch 300, Loss: 1.0297
Batch 310, Loss: 1.0123
Batch 320, Loss: 0.9886
Batch 330, Loss: 0.9942
Batch 340, Loss: 1.0319
Batch 350, Loss: 0.9892
Batch 360, Loss: 1.0000
Batch 370, Loss: 1.0094
Batch 380, Loss: 1.0735
Batch 390, Loss: 1.0290
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.47794008255005 seconds
Epoch 112 accuracy: 66.85%
Batch 10, Loss: 0.9848
Batch 20, Loss: 0.9803
Batch 30, Loss: 0.9292
Batch 40, Loss: 0.9231
Batch 50, Loss: 0.9600
Batch 60, Loss: 0.9358
Batch 70, Loss: 0.9775
Batch 80, Loss: 0.9593
Batch 90, Loss: 1.0072
Batch 100, Loss: 0.9578
Batch 110, Loss: 0.9838
Batch 120, Loss: 1.0413
Batch 130, Loss: 0.9738
Batch 140, Loss: 0.9670
Batch 150, Loss: 0.9255
Batch 160, Loss: 0.9786
Batch 170, Loss: 0.9668
Batch 180, Loss: 0.9450
Batch 190, Loss: 0.9417
Batch 200, Loss: 0.9615
Batch 210, Loss: 0.9847
Batch 220, Loss: 1.0342
Batch 230, Loss: 0.9660
Batch 240, Loss: 1.0627
Batch 250, Loss: 1.1100
Batch 260, Loss: 0.9991
Batch 270, Loss: 0.9630
Batch 280, Loss: 1.0180
Batch 290, Loss: 1.0237
Batch 300, Loss: 0.9896
Batch 310, Loss: 0.9986
Batch 320, Loss: 1.0011
Batch 330, Loss: 1.0698
Batch 340, Loss: 1.0981
Batch 350, Loss: 1.0576
Batch 360, Loss: 1.0289
Batch 370, Loss: 1.0249
Batch 380, Loss: 0.9966
Batch 390, Loss: 1.0172
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.518632888793945 seconds
Epoch 113 accuracy: 66.09%
Batch 10, Loss: 0.9641
Batch 20, Loss: 0.9698
Batch 30, Loss: 0.9626
Batch 40, Loss: 0.9324
Batch 50, Loss: 0.9477
Batch 60, Loss: 0.9129
Batch 70, Loss: 0.9389
Batch 80, Loss: 0.9350
Batch 90, Loss: 0.9652
Batch 100, Loss: 0.9389
Batch 110, Loss: 0.8741
Batch 120, Loss: 0.9301
Batch 130, Loss: 0.9824
Batch 140, Loss: 1.0421
Batch 150, Loss: 1.0724
Batch 160, Loss: 1.0061
Batch 170, Loss: 0.9784
Batch 180, Loss: 0.9674
Batch 190, Loss: 0.9544
Batch 200, Loss: 1.0687
Batch 210, Loss: 1.0031
Batch 220, Loss: 0.9788
Batch 230, Loss: 0.9750
Batch 240, Loss: 0.9207
Batch 250, Loss: 1.0022
Batch 260, Loss: 0.9579
Batch 270, Loss: 0.9220
Batch 280, Loss: 0.9477
Batch 290, Loss: 0.9905
Batch 300, Loss: 1.0170
Batch 310, Loss: 0.9919
Batch 320, Loss: 0.9587
Batch 330, Loss: 0.9743
Batch 340, Loss: 1.0116
Batch 350, Loss: 1.0166
Batch 360, Loss: 1.0690
Batch 370, Loss: 0.9734
Batch 380, Loss: 0.9800
Batch 390, Loss: 1.0518
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.317310571670532 seconds
Epoch 114 accuracy: 67.29%
Batch 10, Loss: 0.9698
Batch 20, Loss: 0.9769
Batch 30, Loss: 0.9323
Batch 40, Loss: 0.9755
Batch 50, Loss: 0.9374
Batch 60, Loss: 0.9835
Batch 70, Loss: 0.8772
Batch 80, Loss: 0.9803
Batch 90, Loss: 1.0053
Batch 100, Loss: 0.9111
Batch 110, Loss: 0.9856
Batch 120, Loss: 0.9684
Batch 130, Loss: 1.0274
Batch 140, Loss: 0.9624
Batch 150, Loss: 0.9752
Batch 160, Loss: 0.9611
Batch 170, Loss: 0.9531
Batch 180, Loss: 0.9713
Batch 190, Loss: 0.9660
Batch 200, Loss: 0.9765
Batch 210, Loss: 1.0531
Batch 220, Loss: 0.9615
Batch 230, Loss: 1.0135
Batch 240, Loss: 0.9336
Batch 250, Loss: 0.9702
Batch 260, Loss: 1.0214
Batch 270, Loss: 1.0004
Batch 280, Loss: 1.0153
Batch 290, Loss: 1.0053
Batch 300, Loss: 1.0273
Batch 310, Loss: 1.0224
Batch 320, Loss: 1.0467
Batch 330, Loss: 0.9761
Batch 340, Loss: 1.0193
Batch 350, Loss: 1.0181
Batch 360, Loss: 0.9742
Batch 370, Loss: 1.0297
Batch 380, Loss: 0.9988
Batch 390, Loss: 0.9709
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.369908809661865 seconds
Epoch 115 accuracy: 68.46%
Batch 10, Loss: 0.9212
Batch 20, Loss: 0.9123
Batch 30, Loss: 0.8927
Batch 40, Loss: 0.9429
Batch 50, Loss: 0.9214
Batch 60, Loss: 0.9144
Batch 70, Loss: 0.9306
Batch 80, Loss: 0.9775
Batch 90, Loss: 0.9035
Batch 100, Loss: 0.9202
Batch 110, Loss: 0.9628
Batch 120, Loss: 0.8873
Batch 130, Loss: 1.0206
Batch 140, Loss: 0.9648
Batch 150, Loss: 0.9162
Batch 160, Loss: 0.8946
Batch 170, Loss: 0.9860
Batch 180, Loss: 0.9195
Batch 190, Loss: 1.0395
Batch 200, Loss: 0.9651
Batch 210, Loss: 1.0059
Batch 220, Loss: 1.0103
Batch 230, Loss: 0.9717
Batch 240, Loss: 0.9840
Batch 250, Loss: 0.9300
Batch 260, Loss: 0.9409
Batch 270, Loss: 0.9622
Batch 280, Loss: 0.9758
Batch 290, Loss: 0.9725
Batch 300, Loss: 1.0163
Batch 310, Loss: 1.0462
Batch 320, Loss: 0.9474
Batch 330, Loss: 1.0149
Batch 340, Loss: 0.9561
Batch 350, Loss: 0.9718
Batch 360, Loss: 0.9528
Batch 370, Loss: 0.9535
Batch 380, Loss: 0.9475
Batch 390, Loss: 0.9933
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.304046392440796 seconds
Epoch 116 accuracy: 69.55%
Batch 10, Loss: 0.9206
Batch 20, Loss: 0.8625
Batch 30, Loss: 0.9411
Batch 40, Loss: 0.9880
Batch 50, Loss: 0.9122
Batch 60, Loss: 0.9229
Batch 70, Loss: 0.9465
Batch 80, Loss: 0.9906
Batch 90, Loss: 0.9398
Batch 100, Loss: 0.9073
Batch 110, Loss: 0.9042
Batch 120, Loss: 0.9589
Batch 130, Loss: 0.9037
Batch 140, Loss: 0.9184
Batch 150, Loss: 0.9131
Batch 160, Loss: 0.9447
Batch 170, Loss: 0.9283
Batch 180, Loss: 0.9461
Batch 190, Loss: 0.9414
Batch 200, Loss: 0.9242
Batch 210, Loss: 0.9172
Batch 220, Loss: 0.9712
Batch 230, Loss: 0.9709
Batch 240, Loss: 0.9649
Batch 250, Loss: 0.9570
Batch 260, Loss: 0.9738
Batch 270, Loss: 0.9802
Batch 280, Loss: 1.0225
Batch 290, Loss: 0.9853
Batch 300, Loss: 0.9567
Batch 310, Loss: 0.9703
Batch 320, Loss: 0.9710
Batch 330, Loss: 0.9912
Batch 340, Loss: 1.0059
Batch 350, Loss: 0.9864
Batch 360, Loss: 0.9319
Batch 370, Loss: 0.9807
Batch 380, Loss: 0.9658
Batch 390, Loss: 0.9763
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.518063068389893 seconds
Epoch 117 accuracy: 69.12%
Batch 10, Loss: 0.9545
Batch 20, Loss: 0.8651
Batch 30, Loss: 0.9136
Batch 40, Loss: 0.9338
Batch 50, Loss: 0.9056
Batch 60, Loss: 0.8650
Batch 70, Loss: 0.8988
Batch 80, Loss: 0.9413
Batch 90, Loss: 0.9655
Batch 100, Loss: 0.9596
Batch 110, Loss: 0.9383
Batch 120, Loss: 0.9106
Batch 130, Loss: 0.9495
Batch 140, Loss: 0.9398
Batch 150, Loss: 0.9255
Batch 160, Loss: 0.9267
Batch 170, Loss: 0.9311
Batch 180, Loss: 0.9381
Batch 190, Loss: 0.9434
Batch 200, Loss: 1.0059
Batch 210, Loss: 0.9053
Batch 220, Loss: 0.9556
Batch 230, Loss: 0.9366
Batch 240, Loss: 0.9445
Batch 250, Loss: 0.9362
Batch 260, Loss: 0.9221
Batch 270, Loss: 1.0015
Batch 280, Loss: 0.9982
Batch 290, Loss: 0.9173
Batch 300, Loss: 0.9428
Batch 310, Loss: 0.9536
Batch 320, Loss: 0.9301
Batch 330, Loss: 0.9744
Batch 340, Loss: 0.9945
Batch 350, Loss: 1.0108
Batch 360, Loss: 1.0089
Batch 370, Loss: 1.0077
Batch 380, Loss: 1.0397
Batch 390, Loss: 1.0393
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.433268308639526 seconds
Epoch 118 accuracy: 67.87%
Batch 10, Loss: 0.9384
Batch 20, Loss: 0.8513
Batch 30, Loss: 0.9176
Batch 40, Loss: 0.9389
Batch 50, Loss: 0.8612
Batch 60, Loss: 0.8597
Batch 70, Loss: 0.8924
Batch 80, Loss: 0.9815
Batch 90, Loss: 0.8967
Batch 100, Loss: 0.9253
Batch 110, Loss: 0.8740
Batch 120, Loss: 0.9072
Batch 130, Loss: 0.8837
Batch 140, Loss: 0.8574
Batch 150, Loss: 0.8479
Batch 160, Loss: 0.8730
Batch 170, Loss: 0.8937
Batch 180, Loss: 0.9547
Batch 190, Loss: 0.9140
Batch 200, Loss: 0.9199
Batch 210, Loss: 0.9733
Batch 220, Loss: 0.9718
Batch 230, Loss: 0.9400
Batch 240, Loss: 0.9405
Batch 250, Loss: 0.9517
Batch 260, Loss: 0.9516
Batch 270, Loss: 0.9809
Batch 280, Loss: 1.0157
Batch 290, Loss: 0.9409
Batch 300, Loss: 0.9436
Batch 310, Loss: 0.9511
Batch 320, Loss: 0.9238
Batch 330, Loss: 0.9138
Batch 340, Loss: 0.9906
Batch 350, Loss: 0.9223
Batch 360, Loss: 0.9719
Batch 370, Loss: 0.9833
Batch 380, Loss: 0.9622
Batch 390, Loss: 0.9692
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.34469246864319 seconds
Epoch 119 accuracy: 67.77%
Batch 10, Loss: 0.9123
Batch 20, Loss: 0.9196
Batch 30, Loss: 0.8970
Batch 40, Loss: 0.8391
Batch 50, Loss: 0.8828
Batch 60, Loss: 0.8825
Batch 70, Loss: 0.9096
Batch 80, Loss: 0.8797
Batch 90, Loss: 0.8897
Batch 100, Loss: 0.9379
Batch 110, Loss: 0.9058
Batch 120, Loss: 0.9352
Batch 130, Loss: 0.8308
Batch 140, Loss: 0.8916
Batch 150, Loss: 0.9109
Batch 160, Loss: 0.9127
Batch 170, Loss: 0.9365
Batch 180, Loss: 0.9358
Batch 190, Loss: 0.9756
Batch 200, Loss: 0.9168
Batch 210, Loss: 0.9565
Batch 220, Loss: 0.8834
Batch 230, Loss: 0.9417
Batch 240, Loss: 0.9181
Batch 250, Loss: 0.9377
Batch 260, Loss: 0.9432
Batch 270, Loss: 0.9758
Batch 280, Loss: 0.9265
Batch 290, Loss: 0.8714
Batch 300, Loss: 0.9328
Batch 310, Loss: 0.9611
Batch 320, Loss: 0.9702
Batch 330, Loss: 0.9812
Batch 340, Loss: 0.9302
Batch 350, Loss: 0.9675
Batch 360, Loss: 0.9743
Batch 370, Loss: 0.9500
Batch 380, Loss: 0.9651
Batch 390, Loss: 0.9629
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.313343048095703 seconds
Epoch 120 accuracy: 67.31%
Batch 10, Loss: 0.8816
Batch 20, Loss: 0.8979
Batch 30, Loss: 0.8926
Batch 40, Loss: 0.8849
Batch 50, Loss: 0.8800
Batch 60, Loss: 0.8538
Batch 70, Loss: 0.8780
Batch 80, Loss: 0.9093
Batch 90, Loss: 0.8391
Batch 100, Loss: 0.8848
Batch 110, Loss: 0.8826
Batch 120, Loss: 0.8789
Batch 130, Loss: 0.8858
Batch 140, Loss: 0.9209
Batch 150, Loss: 0.9205
Batch 160, Loss: 0.8561
Batch 170, Loss: 0.9260
Batch 180, Loss: 0.9414
Batch 190, Loss: 0.9641
Batch 200, Loss: 0.8975
Batch 210, Loss: 0.9395
Batch 220, Loss: 0.9322
Batch 230, Loss: 0.9574
Batch 240, Loss: 0.9649
Batch 250, Loss: 0.9316
Batch 260, Loss: 0.8925
Batch 270, Loss: 0.9605
Batch 280, Loss: 0.9311
Batch 290, Loss: 0.9710
Batch 300, Loss: 0.9663
Batch 310, Loss: 0.9745
Batch 320, Loss: 0.9335
Batch 330, Loss: 0.8947
Batch 340, Loss: 0.9275
Batch 350, Loss: 0.8993
Batch 360, Loss: 0.9694
Batch 370, Loss: 0.9137
Batch 380, Loss: 0.9794
Batch 390, Loss: 0.9662
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.273755311965942 seconds
Epoch 121 accuracy: 68.84%
Batch 10, Loss: 0.8468
Batch 20, Loss: 0.8247
Batch 30, Loss: 0.8725
Batch 40, Loss: 0.9180
Batch 50, Loss: 0.8450
Batch 60, Loss: 0.8684
Batch 70, Loss: 0.8467
Batch 80, Loss: 0.8339
Batch 90, Loss: 0.8380
Batch 100, Loss: 0.9059
Batch 110, Loss: 0.8833
Batch 120, Loss: 0.8794
Batch 130, Loss: 0.9425
Batch 140, Loss: 0.9105
Batch 150, Loss: 0.9193
Batch 160, Loss: 0.9308
Batch 170, Loss: 0.9016
Batch 180, Loss: 0.8870
Batch 190, Loss: 0.8731
Batch 200, Loss: 0.9054
Batch 210, Loss: 0.9681
Batch 220, Loss: 0.9649
Batch 230, Loss: 0.9413
Batch 240, Loss: 0.8943
Batch 250, Loss: 0.9266
Batch 260, Loss: 0.9165
Batch 270, Loss: 0.9638
Batch 280, Loss: 0.8693
Batch 290, Loss: 0.9102
Batch 300, Loss: 0.8710
Batch 310, Loss: 0.9001
Batch 320, Loss: 0.9954
Batch 330, Loss: 0.9115
Batch 340, Loss: 0.9023
Batch 350, Loss: 0.9726
Batch 360, Loss: 0.8957
Batch 370, Loss: 0.9276
Batch 380, Loss: 0.9392
Batch 390, Loss: 0.9037
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.463343143463135 seconds
Epoch 122 accuracy: 68.69%
Batch 10, Loss: 0.8528
Batch 20, Loss: 0.8683
Batch 30, Loss: 0.8922
Batch 40, Loss: 0.8452
Batch 50, Loss: 0.8597
Batch 60, Loss: 0.8767
Batch 70, Loss: 0.8880
Batch 80, Loss: 0.8668
Batch 90, Loss: 0.8837
Batch 100, Loss: 0.8950
Batch 110, Loss: 0.8627
Batch 120, Loss: 0.8859
Batch 130, Loss: 0.8404
Batch 140, Loss: 0.9032
Batch 150, Loss: 0.8757
Batch 160, Loss: 0.9332
Batch 170, Loss: 0.9068
Batch 180, Loss: 0.8822
Batch 190, Loss: 0.8849
Batch 200, Loss: 0.9510
Batch 210, Loss: 0.8831
Batch 220, Loss: 0.9356
Batch 230, Loss: 0.9027
Batch 240, Loss: 0.8894
Batch 250, Loss: 0.8842
Batch 260, Loss: 0.8901
Batch 270, Loss: 0.8104
Batch 280, Loss: 0.8350
Batch 290, Loss: 0.9121
Batch 300, Loss: 0.8734
Batch 310, Loss: 0.9054
Batch 320, Loss: 0.9340
Batch 330, Loss: 0.9374
Batch 340, Loss: 0.9115
Batch 350, Loss: 0.9117
Batch 360, Loss: 0.8501
Batch 370, Loss: 0.9452
Batch 380, Loss: 0.9736
Batch 390, Loss: 0.8861
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.36531972885132 seconds
Epoch 123 accuracy: 69.68%
Batch 10, Loss: 0.8760
Batch 20, Loss: 0.8452
Batch 30, Loss: 0.8007
Batch 40, Loss: 0.8667
Batch 50, Loss: 0.8904
Batch 60, Loss: 0.8314
Batch 70, Loss: 0.8152
Batch 80, Loss: 0.8246
Batch 90, Loss: 0.8265
Batch 100, Loss: 0.8594
Batch 110, Loss: 0.8807
Batch 120, Loss: 0.8708
Batch 130, Loss: 0.8541
Batch 140, Loss: 0.8592
Batch 150, Loss: 0.8773
Batch 160, Loss: 0.8796
Batch 170, Loss: 0.8452
Batch 180, Loss: 0.8564
Batch 190, Loss: 0.8606
Batch 200, Loss: 0.8827
Batch 210, Loss: 0.9360
Batch 220, Loss: 0.9128
Batch 230, Loss: 0.8914
Batch 240, Loss: 0.8983
Batch 250, Loss: 0.9014
Batch 260, Loss: 0.9129
Batch 270, Loss: 0.8762
Batch 280, Loss: 0.8728
Batch 290, Loss: 0.9286
Batch 300, Loss: 0.9143
Batch 310, Loss: 0.8928
Batch 320, Loss: 0.8989
Batch 330, Loss: 0.9206
Batch 340, Loss: 0.9571
Batch 350, Loss: 0.9516
Batch 360, Loss: 0.9628
Batch 370, Loss: 0.9065
Batch 380, Loss: 0.9679
Batch 390, Loss: 0.9162
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.440553426742554 seconds
Epoch 124 accuracy: 70.01%
Batch 10, Loss: 0.7977
Batch 20, Loss: 0.8574
Batch 30, Loss: 0.8574
Batch 40, Loss: 0.8064
Batch 50, Loss: 0.8692
Batch 60, Loss: 0.8652
Batch 70, Loss: 0.8872
Batch 80, Loss: 0.9035
Batch 90, Loss: 0.8826
Batch 100, Loss: 0.8728
Batch 110, Loss: 0.8960
Batch 120, Loss: 0.8764
Batch 130, Loss: 0.9397
Batch 140, Loss: 0.8577
Batch 150, Loss: 0.8486
Batch 160, Loss: 0.8220
Batch 170, Loss: 0.8365
Batch 180, Loss: 0.8413
Batch 190, Loss: 0.9247
Batch 200, Loss: 0.8707
Batch 210, Loss: 0.8900
Batch 220, Loss: 0.8704
Batch 230, Loss: 0.8168
Batch 240, Loss: 0.8940
Batch 250, Loss: 0.9233
Batch 260, Loss: 0.8741
Batch 270, Loss: 0.8953
Batch 280, Loss: 0.8860
Batch 290, Loss: 0.9345
Batch 300, Loss: 0.8916
Batch 310, Loss: 0.8561
Batch 320, Loss: 0.8418
Batch 330, Loss: 0.8952
Batch 340, Loss: 0.8929
Batch 350, Loss: 0.8757
Batch 360, Loss: 0.8821
Batch 370, Loss: 0.9177
Batch 380, Loss: 0.8639
Batch 390, Loss: 0.8929
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.403839588165283 seconds
Epoch 125 accuracy: 71.02%
Batch 10, Loss: 0.8696
Batch 20, Loss: 0.7984
Batch 30, Loss: 0.8298
Batch 40, Loss: 0.7892
Batch 50, Loss: 0.8297
Batch 60, Loss: 0.7939
Batch 70, Loss: 0.8129
Batch 80, Loss: 0.8173
Batch 90, Loss: 0.8561
Batch 100, Loss: 0.7906
Batch 110, Loss: 0.8499
Batch 120, Loss: 0.8495
Batch 130, Loss: 0.8270
Batch 140, Loss: 0.8260
Batch 150, Loss: 0.8246
Batch 160, Loss: 0.8396
Batch 170, Loss: 0.8580
Batch 180, Loss: 0.8331
Batch 190, Loss: 0.8718
Batch 200, Loss: 0.8681
Batch 210, Loss: 0.9347
Batch 220, Loss: 0.8899
Batch 230, Loss: 0.8673
Batch 240, Loss: 0.8761
Batch 250, Loss: 0.9328
Batch 260, Loss: 0.9028
Batch 270, Loss: 0.8855
Batch 280, Loss: 0.8599
Batch 290, Loss: 0.8553
Batch 300, Loss: 0.8960
Batch 310, Loss: 0.8853
Batch 320, Loss: 0.9767
Batch 330, Loss: 0.9023
Batch 340, Loss: 0.9033
Batch 350, Loss: 0.9004
Batch 360, Loss: 0.8879
Batch 370, Loss: 0.9250
Batch 380, Loss: 0.8794
Batch 390, Loss: 0.8408
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.430180549621582 seconds
Epoch 126 accuracy: 70.02%
Batch 10, Loss: 0.8169
Batch 20, Loss: 0.8125
Batch 30, Loss: 0.7948
Batch 40, Loss: 0.8106
Batch 50, Loss: 0.8228
Batch 60, Loss: 0.8082
Batch 70, Loss: 0.8158
Batch 80, Loss: 0.8477
Batch 90, Loss: 0.7973
Batch 100, Loss: 0.7666
Batch 110, Loss: 0.7997
Batch 120, Loss: 0.9030
Batch 130, Loss: 0.8568
Batch 140, Loss: 0.8375
Batch 150, Loss: 0.8130
Batch 160, Loss: 0.8647
Batch 170, Loss: 0.8658
Batch 180, Loss: 0.8896
Batch 190, Loss: 0.8818
Batch 200, Loss: 0.8849
Batch 210, Loss: 0.7775
Batch 220, Loss: 0.8419
Batch 230, Loss: 0.8480
Batch 240, Loss: 0.8684
Batch 250, Loss: 0.8758
Batch 260, Loss: 0.9387
Batch 270, Loss: 0.8442
Batch 280, Loss: 0.8434
Batch 290, Loss: 0.8851
Batch 300, Loss: 0.8979
Batch 310, Loss: 0.9008
Batch 320, Loss: 0.8587
Batch 330, Loss: 0.8811
Batch 340, Loss: 0.8941
Batch 350, Loss: 0.8990
Batch 360, Loss: 0.9050
Batch 370, Loss: 0.8899
Batch 380, Loss: 0.8363
Batch 390, Loss: 0.9140
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.36720871925354 seconds
Epoch 127 accuracy: 70.1%
Batch 10, Loss: 0.8207
Batch 20, Loss: 0.8400
Batch 30, Loss: 0.8178
Batch 40, Loss: 0.8002
Batch 50, Loss: 0.7981
Batch 60, Loss: 0.8137
Batch 70, Loss: 0.8176
Batch 80, Loss: 0.8296
Batch 90, Loss: 0.8185
Batch 100, Loss: 0.8807
Batch 110, Loss: 0.8216
Batch 120, Loss: 0.7995
Batch 130, Loss: 0.7847
Batch 140, Loss: 0.8371
Batch 150, Loss: 0.7798
Batch 160, Loss: 0.8073
Batch 170, Loss: 0.8398
Batch 180, Loss: 0.8845
Batch 190, Loss: 0.8647
Batch 200, Loss: 0.8002
Batch 210, Loss: 0.8727
Batch 220, Loss: 0.8519
Batch 230, Loss: 0.8527
Batch 240, Loss: 0.8594
Batch 250, Loss: 0.8493
Batch 260, Loss: 0.8455
Batch 270, Loss: 0.8487
Batch 280, Loss: 0.8461
Batch 290, Loss: 0.8442
Batch 300, Loss: 0.9489
Batch 310, Loss: 0.8505
Batch 320, Loss: 0.8967
Batch 330, Loss: 0.8264
Batch 340, Loss: 0.8662
Batch 350, Loss: 0.9093
Batch 360, Loss: 0.8372
Batch 370, Loss: 0.8269
Batch 380, Loss: 0.8721
Batch 390, Loss: 0.8802
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.357496976852417 seconds
Epoch 128 accuracy: 69.99%
Batch 10, Loss: 0.8198
Batch 20, Loss: 0.7966
Batch 30, Loss: 0.8004
Batch 40, Loss: 0.8239
Batch 50, Loss: 0.7581
Batch 60, Loss: 0.8255
Batch 70, Loss: 0.8540
Batch 80, Loss: 0.7707
Batch 90, Loss: 0.8782
Batch 100, Loss: 0.8147
Batch 110, Loss: 0.7645
Batch 120, Loss: 0.8146
Batch 130, Loss: 0.8716
Batch 140, Loss: 0.7443
Batch 150, Loss: 0.7902
Batch 160, Loss: 0.8274
Batch 170, Loss: 0.7957
Batch 180, Loss: 0.8013
Batch 190, Loss: 0.8094
Batch 200, Loss: 0.8334
Batch 210, Loss: 0.8496
Batch 220, Loss: 0.8117
Batch 230, Loss: 0.8477
Batch 240, Loss: 0.8174
Batch 250, Loss: 0.8758
Batch 260, Loss: 0.8624
Batch 270, Loss: 0.8302
Batch 280, Loss: 0.8818
Batch 290, Loss: 0.8603
Batch 300, Loss: 0.8888
Batch 310, Loss: 0.8272
Batch 320, Loss: 0.8303
Batch 330, Loss: 0.8522
Batch 340, Loss: 0.8531
Batch 350, Loss: 0.8615
Batch 360, Loss: 0.8753
Batch 370, Loss: 0.8624
Batch 380, Loss: 0.8899
Batch 390, Loss: 0.8511
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.305526733398438 seconds
Epoch 129 accuracy: 70.24%
Batch 10, Loss: 0.8044
Batch 20, Loss: 0.7640
Batch 30, Loss: 0.8239
Batch 40, Loss: 0.7919
Batch 50, Loss: 0.7687
Batch 60, Loss: 0.8178
Batch 70, Loss: 0.8195
Batch 80, Loss: 0.8420
Batch 90, Loss: 0.8566
Batch 100, Loss: 0.7469
Batch 110, Loss: 0.7894
Batch 120, Loss: 0.7943
Batch 130, Loss: 0.8109
Batch 140, Loss: 0.8257
Batch 150, Loss: 0.8109
Batch 160, Loss: 0.8194
Batch 170, Loss: 0.8119
Batch 180, Loss: 0.8220
Batch 190, Loss: 0.8187
Batch 200, Loss: 0.8250
Batch 210, Loss: 0.8197
Batch 220, Loss: 0.7804
Batch 230, Loss: 0.8318
Batch 240, Loss: 0.8054
Batch 250, Loss: 0.8513
Batch 260, Loss: 0.8766
Batch 270, Loss: 0.8407
Batch 280, Loss: 0.8160
Batch 290, Loss: 0.7800
Batch 300, Loss: 0.8959
Batch 310, Loss: 0.8662
Batch 320, Loss: 0.8197
Batch 330, Loss: 0.8056
Batch 340, Loss: 0.8135
Batch 350, Loss: 0.8385
Batch 360, Loss: 0.8688
Batch 370, Loss: 0.8720
Batch 380, Loss: 0.8034
Batch 390, Loss: 0.9131
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.47562026977539 seconds
Epoch 130 accuracy: 69.14%
Batch 10, Loss: 0.7394
Batch 20, Loss: 0.8310
Batch 30, Loss: 0.7963
Batch 40, Loss: 0.8075
Batch 50, Loss: 0.7820
Batch 60, Loss: 0.8105
Batch 70, Loss: 0.7552
Batch 80, Loss: 0.8035
Batch 90, Loss: 0.7936
Batch 100, Loss: 0.8051
Batch 110, Loss: 0.7808
Batch 120, Loss: 0.7956
Batch 130, Loss: 0.8299
Batch 140, Loss: 0.7727
Batch 150, Loss: 0.8207
Batch 160, Loss: 0.8228
Batch 170, Loss: 0.7776
Batch 180, Loss: 0.8328
Batch 190, Loss: 0.8446
Batch 200, Loss: 0.8074
Batch 210, Loss: 0.8398
Batch 220, Loss: 0.8026
Batch 230, Loss: 0.8344
Batch 240, Loss: 0.8521
Batch 250, Loss: 0.7839
Batch 260, Loss: 0.8736
Batch 270, Loss: 0.8558
Batch 280, Loss: 0.8257
Batch 290, Loss: 0.8093
Batch 300, Loss: 0.8478
Batch 310, Loss: 0.8483
Batch 320, Loss: 0.8569
Batch 330, Loss: 0.8489
Batch 340, Loss: 0.8363
Batch 350, Loss: 0.8574
Batch 360, Loss: 0.8180
Batch 370, Loss: 0.8181
Batch 380, Loss: 0.8434
Batch 390, Loss: 0.8430
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.39169716835022 seconds
Epoch 131 accuracy: 71.87%
Batch 10, Loss: 0.8171
Batch 20, Loss: 0.7431
Batch 30, Loss: 0.8147
Batch 40, Loss: 0.7608
Batch 50, Loss: 0.7368
Batch 60, Loss: 0.8097
Batch 70, Loss: 0.7440
Batch 80, Loss: 0.7715
Batch 90, Loss: 0.7868
Batch 100, Loss: 0.7837
Batch 110, Loss: 0.8128
Batch 120, Loss: 0.7771
Batch 130, Loss: 0.8136
Batch 140, Loss: 0.7700
Batch 150, Loss: 0.8235
Batch 160, Loss: 0.8256
Batch 170, Loss: 0.8122
Batch 180, Loss: 0.8059
Batch 190, Loss: 0.8125
Batch 200, Loss: 0.7636
Batch 210, Loss: 0.7406
Batch 220, Loss: 0.7713
Batch 230, Loss: 0.7868
Batch 240, Loss: 0.8137
Batch 250, Loss: 0.7773
Batch 260, Loss: 0.8396
Batch 270, Loss: 0.8651
Batch 280, Loss: 0.8037
Batch 290, Loss: 0.7887
Batch 300, Loss: 0.8173
Batch 310, Loss: 0.8153
Batch 320, Loss: 0.7736
Batch 330, Loss: 0.8176
Batch 340, Loss: 0.8068
Batch 350, Loss: 0.7589
Batch 360, Loss: 0.8189
Batch 370, Loss: 0.8200
Batch 380, Loss: 0.8158
Batch 390, Loss: 0.8324
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.41166067123413 seconds
Epoch 132 accuracy: 71.1%
Batch 10, Loss: 0.7512
Batch 20, Loss: 0.7438
Batch 30, Loss: 0.8001
Batch 40, Loss: 0.7715
Batch 50, Loss: 0.7785
Batch 60, Loss: 0.8451
Batch 70, Loss: 0.7693
Batch 80, Loss: 0.7902
Batch 90, Loss: 0.8128
Batch 100, Loss: 0.7209
Batch 110, Loss: 0.7766
Batch 120, Loss: 0.7643
Batch 130, Loss: 0.7372
Batch 140, Loss: 0.7638
Batch 150, Loss: 0.8101
Batch 160, Loss: 0.7893
Batch 170, Loss: 0.8226
Batch 180, Loss: 0.7601
Batch 190, Loss: 0.8228
Batch 200, Loss: 0.7539
Batch 210, Loss: 0.8139
Batch 220, Loss: 0.7993
Batch 230, Loss: 0.8075
Batch 240, Loss: 0.7766
Batch 250, Loss: 0.8187
Batch 260, Loss: 0.8271
Batch 270, Loss: 0.7885
Batch 280, Loss: 0.7908
Batch 290, Loss: 0.8563
Batch 300, Loss: 0.8837
Batch 310, Loss: 0.7486
Batch 320, Loss: 0.8352
Batch 330, Loss: 0.7700
Batch 340, Loss: 0.7568
Batch 350, Loss: 0.7662
Batch 360, Loss: 0.8462
Batch 370, Loss: 0.8049
Batch 380, Loss: 0.7452
Batch 390, Loss: 0.7865
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.329563856124878 seconds
Epoch 133 accuracy: 72.39%
Batch 10, Loss: 0.7419
Batch 20, Loss: 0.6901
Batch 30, Loss: 0.7246
Batch 40, Loss: 0.7371
Batch 50, Loss: 0.8176
Batch 60, Loss: 0.7850
Batch 70, Loss: 0.6853
Batch 80, Loss: 0.7531
Batch 90, Loss: 0.7193
Batch 100, Loss: 0.7372
Batch 110, Loss: 0.7475
Batch 120, Loss: 0.7411
Batch 130, Loss: 0.7624
Batch 140, Loss: 0.7485
Batch 150, Loss: 0.7207
Batch 160, Loss: 0.7524
Batch 170, Loss: 0.7547
Batch 180, Loss: 0.7541
Batch 190, Loss: 0.7951
Batch 200, Loss: 0.7956
Batch 210, Loss: 0.7729
Batch 220, Loss: 0.8114
Batch 230, Loss: 0.7776
Batch 240, Loss: 0.8114
Batch 250, Loss: 0.8219
Batch 260, Loss: 0.7636
Batch 270, Loss: 0.8036
Batch 280, Loss: 0.7716
Batch 290, Loss: 0.7945
Batch 300, Loss: 0.7918
Batch 310, Loss: 0.7897
Batch 320, Loss: 0.8239
Batch 330, Loss: 0.8416
Batch 340, Loss: 0.7940
Batch 350, Loss: 0.8421
Batch 360, Loss: 0.8364
Batch 370, Loss: 0.7595
Batch 380, Loss: 0.8170
Batch 390, Loss: 0.8026
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.358724355697632 seconds
Epoch 134 accuracy: 71.98%
Batch 10, Loss: 0.7924
Batch 20, Loss: 0.7630
Batch 30, Loss: 0.7293
Batch 40, Loss: 0.7143
Batch 50, Loss: 0.7484
Batch 60, Loss: 0.7555
Batch 70, Loss: 0.7441
Batch 80, Loss: 0.7469
Batch 90, Loss: 0.7768
Batch 100, Loss: 0.6992
Batch 110, Loss: 0.7727
Batch 120, Loss: 0.7834
Batch 130, Loss: 0.7503
Batch 140, Loss: 0.7527
Batch 150, Loss: 0.7421
Batch 160, Loss: 0.7714
Batch 170, Loss: 0.7723
Batch 180, Loss: 0.7760
Batch 190, Loss: 0.7794
Batch 200, Loss: 0.7591
Batch 210, Loss: 0.8241
Batch 220, Loss: 0.7849
Batch 230, Loss: 0.7870
Batch 240, Loss: 0.7603
Batch 250, Loss: 0.7859
Batch 260, Loss: 0.7759
Batch 270, Loss: 0.7603
Batch 280, Loss: 0.7991
Batch 290, Loss: 0.8010
Batch 300, Loss: 0.7817
Batch 310, Loss: 0.7869
Batch 320, Loss: 0.8122
Batch 330, Loss: 0.8014
Batch 340, Loss: 0.7999
Batch 350, Loss: 0.7930
Batch 360, Loss: 0.8361
Batch 370, Loss: 0.8180
Batch 380, Loss: 0.7630
Batch 390, Loss: 0.8086
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.47295641899109 seconds
Epoch 135 accuracy: 71.51%
Batch 10, Loss: 0.7409
Batch 20, Loss: 0.7644
Batch 30, Loss: 0.7518
Batch 40, Loss: 0.7374
Batch 50, Loss: 0.7283
Batch 60, Loss: 0.6802
Batch 70, Loss: 0.7559
Batch 80, Loss: 0.7119
Batch 90, Loss: 0.6748
Batch 100, Loss: 0.7486
Batch 110, Loss: 0.7426
Batch 120, Loss: 0.7129
Batch 130, Loss: 0.7322
Batch 140, Loss: 0.7438
Batch 150, Loss: 0.7366
Batch 160, Loss: 0.6881
Batch 170, Loss: 0.7581
Batch 180, Loss: 0.7120
Batch 190, Loss: 0.7543
Batch 200, Loss: 0.7198
Batch 210, Loss: 0.7692
Batch 220, Loss: 0.7909
Batch 230, Loss: 0.7204
Batch 240, Loss: 0.7569
Batch 250, Loss: 0.6856
Batch 260, Loss: 0.7325
Batch 270, Loss: 0.7368
Batch 280, Loss: 0.7903
Batch 290, Loss: 0.8177
Batch 300, Loss: 0.7957
Batch 310, Loss: 0.8121
Batch 320, Loss: 0.8516
Batch 330, Loss: 0.8528
Batch 340, Loss: 0.7591
Batch 350, Loss: 0.8050
Batch 360, Loss: 0.8323
Batch 370, Loss: 0.7512
Batch 380, Loss: 0.8126
Batch 390, Loss: 0.7940
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.31299090385437 seconds
Epoch 136 accuracy: 71.38%
Batch 10, Loss: 0.6931
Batch 20, Loss: 0.7397
Batch 30, Loss: 0.6882
Batch 40, Loss: 0.7738
Batch 50, Loss: 0.7386
Batch 60, Loss: 0.7098
Batch 70, Loss: 0.7735
Batch 80, Loss: 0.7322
Batch 90, Loss: 0.7523
Batch 100, Loss: 0.7856
Batch 110, Loss: 0.7353
Batch 120, Loss: 0.7351
Batch 130, Loss: 0.7428
Batch 140, Loss: 0.7379
Batch 150, Loss: 0.7466
Batch 160, Loss: 0.7667
Batch 170, Loss: 0.7439
Batch 180, Loss: 0.7068
Batch 190, Loss: 0.7972
Batch 200, Loss: 0.7299
Batch 210, Loss: 0.7745
Batch 220, Loss: 0.7275
Batch 230, Loss: 0.7370
Batch 240, Loss: 0.7457
Batch 250, Loss: 0.7814
Batch 260, Loss: 0.7386
Batch 270, Loss: 0.7718
Batch 280, Loss: 0.7789
Batch 290, Loss: 0.7813
Batch 300, Loss: 0.7491
Batch 310, Loss: 0.7380
Batch 320, Loss: 0.7446
Batch 330, Loss: 0.8164
Batch 340, Loss: 0.7572
Batch 350, Loss: 0.7764
Batch 360, Loss: 0.8058
Batch 370, Loss: 0.7840
Batch 380, Loss: 0.7472
Batch 390, Loss: 0.7904
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.344393730163574 seconds
Epoch 137 accuracy: 72.37%
Batch 10, Loss: 0.6938
Batch 20, Loss: 0.7000
Batch 30, Loss: 0.6962
Batch 40, Loss: 0.6937
Batch 50, Loss: 0.6917
Batch 60, Loss: 0.6768
Batch 70, Loss: 0.6766
Batch 80, Loss: 0.7078
Batch 90, Loss: 0.7227
Batch 100, Loss: 0.7293
Batch 110, Loss: 0.7191
Batch 120, Loss: 0.7037
Batch 130, Loss: 0.7452
Batch 140, Loss: 0.7189
Batch 150, Loss: 0.7695
Batch 160, Loss: 0.7483
Batch 170, Loss: 0.7110
Batch 180, Loss: 0.7388
Batch 190, Loss: 0.7374
Batch 200, Loss: 0.7789
Batch 210, Loss: 0.7151
Batch 220, Loss: 0.7513
Batch 230, Loss: 0.6865
Batch 240, Loss: 0.7205
Batch 250, Loss: 0.6977
Batch 260, Loss: 0.7375
Batch 270, Loss: 0.7065
Batch 280, Loss: 0.7777
Batch 290, Loss: 0.7143
Batch 300, Loss: 0.7456
Batch 310, Loss: 0.7274
Batch 320, Loss: 0.7629
Batch 330, Loss: 0.8071
Batch 340, Loss: 0.7885
Batch 350, Loss: 0.7535
Batch 360, Loss: 0.7572
Batch 370, Loss: 0.7881
Batch 380, Loss: 0.8122
Batch 390, Loss: 0.7416
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.367451190948486 seconds
Epoch 138 accuracy: 72.72%
Batch 10, Loss: 0.6936
Batch 20, Loss: 0.7093
Batch 30, Loss: 0.6995
Batch 40, Loss: 0.6360
Batch 50, Loss: 0.6972
Batch 60, Loss: 0.7177
Batch 70, Loss: 0.7497
Batch 80, Loss: 0.7117
Batch 90, Loss: 0.7415
Batch 100, Loss: 0.7404
Batch 110, Loss: 0.6984
Batch 120, Loss: 0.7358
Batch 130, Loss: 0.7026
Batch 140, Loss: 0.6889
Batch 150, Loss: 0.7353
Batch 160, Loss: 0.6517
Batch 170, Loss: 0.7185
Batch 180, Loss: 0.7207
Batch 190, Loss: 0.7063
Batch 200, Loss: 0.7224
Batch 210, Loss: 0.7343
Batch 220, Loss: 0.7572
Batch 230, Loss: 0.7782
Batch 240, Loss: 0.7046
Batch 250, Loss: 0.8194
Batch 260, Loss: 0.7964
Batch 270, Loss: 0.7536
Batch 280, Loss: 0.7279
Batch 290, Loss: 0.7360
Batch 300, Loss: 0.7935
Batch 310, Loss: 0.7478
Batch 320, Loss: 0.7950
Batch 330, Loss: 0.7427
Batch 340, Loss: 0.7447
Batch 350, Loss: 0.8230
Batch 360, Loss: 0.7609
Batch 370, Loss: 0.7814
Batch 380, Loss: 0.7289
Batch 390, Loss: 0.7157
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.337474822998047 seconds
Epoch 139 accuracy: 71.66%
Batch 10, Loss: 0.6513
Batch 20, Loss: 0.7288
Batch 30, Loss: 0.6713
Batch 40, Loss: 0.6867
Batch 50, Loss: 0.6688
Batch 60, Loss: 0.6714
Batch 70, Loss: 0.6901
Batch 80, Loss: 0.6944
Batch 90, Loss: 0.6925
Batch 100, Loss: 0.6942
Batch 110, Loss: 0.7271
Batch 120, Loss: 0.7138
Batch 130, Loss: 0.7238
Batch 140, Loss: 0.6724
Batch 150, Loss: 0.6858
Batch 160, Loss: 0.6974
Batch 170, Loss: 0.6816
Batch 180, Loss: 0.6817
Batch 190, Loss: 0.6843
Batch 200, Loss: 0.6949
Batch 210, Loss: 0.6667
Batch 220, Loss: 0.6981
Batch 230, Loss: 0.7625
Batch 240, Loss: 0.7528
Batch 250, Loss: 0.7520
Batch 260, Loss: 0.7421
Batch 270, Loss: 0.6925
Batch 280, Loss: 0.7305
Batch 290, Loss: 0.7579
Batch 300, Loss: 0.7155
Batch 310, Loss: 0.7843
Batch 320, Loss: 0.7215
Batch 330, Loss: 0.7250
Batch 340, Loss: 0.7570
Batch 350, Loss: 0.7538
Batch 360, Loss: 0.7812
Batch 370, Loss: 0.7254
Batch 380, Loss: 0.7522
Batch 390, Loss: 0.7035
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.33115839958191 seconds
Epoch 140 accuracy: 72.67%
Batch 10, Loss: 0.6670
Batch 20, Loss: 0.6557
Batch 30, Loss: 0.6792
Batch 40, Loss: 0.6659
Batch 50, Loss: 0.6491
Batch 60, Loss: 0.6782
Batch 70, Loss: 0.6901
Batch 80, Loss: 0.6804
Batch 90, Loss: 0.6727
Batch 100, Loss: 0.6073
Batch 110, Loss: 0.6877
Batch 120, Loss: 0.7067
Batch 130, Loss: 0.7055
Batch 140, Loss: 0.6551
Batch 150, Loss: 0.6840
Batch 160, Loss: 0.7266
Batch 170, Loss: 0.6808
Batch 180, Loss: 0.6808
Batch 190, Loss: 0.6718
Batch 200, Loss: 0.6963
Batch 210, Loss: 0.7420
Batch 220, Loss: 0.7196
Batch 230, Loss: 0.7204
Batch 240, Loss: 0.7377
Batch 250, Loss: 0.7407
Batch 260, Loss: 0.7102
Batch 270, Loss: 0.6699
Batch 280, Loss: 0.6831
Batch 290, Loss: 0.7458
Batch 300, Loss: 0.7184
Batch 310, Loss: 0.7086
Batch 320, Loss: 0.7020
Batch 330, Loss: 0.7112
Batch 340, Loss: 0.7695
Batch 350, Loss: 0.7236
Batch 360, Loss: 0.7194
Batch 370, Loss: 0.7167
Batch 380, Loss: 0.7108
Batch 390, Loss: 0.7057
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.387863397598267 seconds
Epoch 141 accuracy: 72.48%
Batch 10, Loss: 0.6809
Batch 20, Loss: 0.6480
Batch 30, Loss: 0.6543
Batch 40, Loss: 0.6320
Batch 50, Loss: 0.6802
Batch 60, Loss: 0.6783
Batch 70, Loss: 0.6928
Batch 80, Loss: 0.6199
Batch 90, Loss: 0.7231
Batch 100, Loss: 0.6505
Batch 110, Loss: 0.6583
Batch 120, Loss: 0.6708
Batch 130, Loss: 0.6904
Batch 140, Loss: 0.7042
Batch 150, Loss: 0.6975
Batch 160, Loss: 0.6707
Batch 170, Loss: 0.7027
Batch 180, Loss: 0.6761
Batch 190, Loss: 0.6463
Batch 200, Loss: 0.6825
Batch 210, Loss: 0.7401
Batch 220, Loss: 0.6782
Batch 230, Loss: 0.6827
Batch 240, Loss: 0.7352
Batch 250, Loss: 0.6740
Batch 260, Loss: 0.6988
Batch 270, Loss: 0.6340
Batch 280, Loss: 0.7280
Batch 290, Loss: 0.6907
Batch 300, Loss: 0.7725
Batch 310, Loss: 0.6941
Batch 320, Loss: 0.6599
Batch 330, Loss: 0.6985
Batch 340, Loss: 0.6916
Batch 350, Loss: 0.6925
Batch 360, Loss: 0.6742
Batch 370, Loss: 0.7311
Batch 380, Loss: 0.7616
Batch 390, Loss: 0.7097
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.28873896598816 seconds
Epoch 142 accuracy: 71.75%
Batch 10, Loss: 0.6539
Batch 20, Loss: 0.6532
Batch 30, Loss: 0.6605
Batch 40, Loss: 0.6499
Batch 50, Loss: 0.6883
Batch 60, Loss: 0.6973
Batch 70, Loss: 0.6132
Batch 80, Loss: 0.6398
Batch 90, Loss: 0.6775
Batch 100, Loss: 0.6610
Batch 110, Loss: 0.6855
Batch 120, Loss: 0.7024
Batch 130, Loss: 0.6690
Batch 140, Loss: 0.6539
Batch 150, Loss: 0.6953
Batch 160, Loss: 0.6711
Batch 170, Loss: 0.6310
Batch 180, Loss: 0.6407
Batch 190, Loss: 0.7076
Batch 200, Loss: 0.6621
Batch 210, Loss: 0.6672
Batch 220, Loss: 0.6845
Batch 230, Loss: 0.6753
Batch 240, Loss: 0.6562
Batch 250, Loss: 0.6758
Batch 260, Loss: 0.7139
Batch 270, Loss: 0.6974
Batch 280, Loss: 0.7209
Batch 290, Loss: 0.6997
Batch 300, Loss: 0.7051
Batch 310, Loss: 0.7421
Batch 320, Loss: 0.6503
Batch 330, Loss: 0.7121
Batch 340, Loss: 0.7343
Batch 350, Loss: 0.7092
Batch 360, Loss: 0.7242
Batch 370, Loss: 0.7219
Batch 380, Loss: 0.7256
Batch 390, Loss: 0.6822
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.313008785247803 seconds
Epoch 143 accuracy: 72.43%
Batch 10, Loss: 0.5945
Batch 20, Loss: 0.6152
Batch 30, Loss: 0.6223
Batch 40, Loss: 0.6297
Batch 50, Loss: 0.6261
Batch 60, Loss: 0.6534
Batch 70, Loss: 0.6589
Batch 80, Loss: 0.5982
Batch 90, Loss: 0.5866
Batch 100, Loss: 0.6523
Batch 110, Loss: 0.6228
Batch 120, Loss: 0.6927
Batch 130, Loss: 0.6261
Batch 140, Loss: 0.6363
Batch 150, Loss: 0.6375
Batch 160, Loss: 0.6691
Batch 170, Loss: 0.6024
Batch 180, Loss: 0.6108
Batch 190, Loss: 0.7121
Batch 200, Loss: 0.7046
Batch 210, Loss: 0.6740
Batch 220, Loss: 0.6770
Batch 230, Loss: 0.6931
Batch 240, Loss: 0.6880
Batch 250, Loss: 0.6703
Batch 260, Loss: 0.6884
Batch 270, Loss: 0.6637
Batch 280, Loss: 0.7113
Batch 290, Loss: 0.6531
Batch 300, Loss: 0.6602
Batch 310, Loss: 0.7286
Batch 320, Loss: 0.6638
Batch 330, Loss: 0.6675
Batch 340, Loss: 0.6457
Batch 350, Loss: 0.6882
Batch 360, Loss: 0.6919
Batch 370, Loss: 0.6822
Batch 380, Loss: 0.7214
Batch 390, Loss: 0.7239
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.417147159576416 seconds
Epoch 144 accuracy: 71.44%
Batch 10, Loss: 0.6083
Batch 20, Loss: 0.6540
Batch 30, Loss: 0.5848
Batch 40, Loss: 0.6592
Batch 50, Loss: 0.6806
Batch 60, Loss: 0.6277
Batch 70, Loss: 0.6049
Batch 80, Loss: 0.6680
Batch 90, Loss: 0.6553
Batch 100, Loss: 0.6248
Batch 110, Loss: 0.6398
Batch 120, Loss: 0.6127
Batch 130, Loss: 0.6604
Batch 140, Loss: 0.6421
Batch 150, Loss: 0.6419
Batch 160, Loss: 0.6479
Batch 170, Loss: 0.6797
Batch 180, Loss: 0.6516
Batch 190, Loss: 0.6507
Batch 200, Loss: 0.6872
Batch 210, Loss: 0.6411
Batch 220, Loss: 0.6336
Batch 230, Loss: 0.6507
Batch 240, Loss: 0.6333
Batch 250, Loss: 0.6821
Batch 260, Loss: 0.6470
Batch 270, Loss: 0.6490
Batch 280, Loss: 0.6775
Batch 290, Loss: 0.6204
Batch 300, Loss: 0.6351
Batch 310, Loss: 0.6675
Batch 320, Loss: 0.6566
Batch 330, Loss: 0.6825
Batch 340, Loss: 0.6682
Batch 350, Loss: 0.7282
Batch 360, Loss: 0.6324
Batch 370, Loss: 0.7077
Batch 380, Loss: 0.6699
Batch 390, Loss: 0.6981
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.361114025115967 seconds
Epoch 145 accuracy: 72.96%
Batch 10, Loss: 0.6342
Batch 20, Loss: 0.6420
Batch 30, Loss: 0.5914
Batch 40, Loss: 0.6777
Batch 50, Loss: 0.6166
Batch 60, Loss: 0.6181
Batch 70, Loss: 0.6106
Batch 80, Loss: 0.6284
Batch 90, Loss: 0.6372
Batch 100, Loss: 0.6195
Batch 110, Loss: 0.6135
Batch 120, Loss: 0.5853
Batch 130, Loss: 0.6322
Batch 140, Loss: 0.6199
Batch 150, Loss: 0.6737
Batch 160, Loss: 0.6361
Batch 170, Loss: 0.6712
Batch 180, Loss: 0.6275
Batch 190, Loss: 0.6161
Batch 200, Loss: 0.6156
Batch 210, Loss: 0.6589
Batch 220, Loss: 0.6664
Batch 230, Loss: 0.6575
Batch 240, Loss: 0.6042
Batch 250, Loss: 0.6487
Batch 260, Loss: 0.6641
Batch 270, Loss: 0.5665
Batch 280, Loss: 0.6358
Batch 290, Loss: 0.6407
Batch 300, Loss: 0.6225
Batch 310, Loss: 0.6664
Batch 320, Loss: 0.6534
Batch 330, Loss: 0.6454
Batch 340, Loss: 0.6414
Batch 350, Loss: 0.6053
Batch 360, Loss: 0.6392
Batch 370, Loss: 0.6442
Batch 380, Loss: 0.6588
Batch 390, Loss: 0.6614
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.351946115493774 seconds
Epoch 146 accuracy: 72.86%
Batch 10, Loss: 0.5738
Batch 20, Loss: 0.6543
Batch 30, Loss: 0.5957
Batch 40, Loss: 0.6177
Batch 50, Loss: 0.6090
Batch 60, Loss: 0.5916
Batch 70, Loss: 0.6098
Batch 80, Loss: 0.5961
Batch 90, Loss: 0.5980
Batch 100, Loss: 0.6268
Batch 110, Loss: 0.6202
Batch 120, Loss: 0.5672
Batch 130, Loss: 0.6252
Batch 140, Loss: 0.6439
Batch 150, Loss: 0.5982
Batch 160, Loss: 0.5956
Batch 170, Loss: 0.5759
Batch 180, Loss: 0.6062
Batch 190, Loss: 0.6092
Batch 200, Loss: 0.5950
Batch 210, Loss: 0.6019
Batch 220, Loss: 0.6462
Batch 230, Loss: 0.6314
Batch 240, Loss: 0.6595
Batch 250, Loss: 0.6308
Batch 260, Loss: 0.5943
Batch 270, Loss: 0.6265
Batch 280, Loss: 0.6540
Batch 290, Loss: 0.6170
Batch 300, Loss: 0.6778
Batch 310, Loss: 0.6654
Batch 320, Loss: 0.6679
Batch 330, Loss: 0.5806
Batch 340, Loss: 0.6541
Batch 350, Loss: 0.6601
Batch 360, Loss: 0.6581
Batch 370, Loss: 0.6288
Batch 380, Loss: 0.6667
Batch 390, Loss: 0.6377
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.376837253570557 seconds
Epoch 147 accuracy: 73.29%
Batch 10, Loss: 0.6045
Batch 20, Loss: 0.6123
Batch 30, Loss: 0.5674
Batch 40, Loss: 0.6077
Batch 50, Loss: 0.5972
Batch 60, Loss: 0.5799
Batch 70, Loss: 0.5850
Batch 80, Loss: 0.5634
Batch 90, Loss: 0.5725
Batch 100, Loss: 0.6059
Batch 110, Loss: 0.5765
Batch 120, Loss: 0.6121
Batch 130, Loss: 0.6174
Batch 140, Loss: 0.6277
Batch 150, Loss: 0.6212
Batch 160, Loss: 0.5982
Batch 170, Loss: 0.6219
Batch 180, Loss: 0.5857
Batch 190, Loss: 0.5721
Batch 200, Loss: 0.6305
Batch 210, Loss: 0.5698
Batch 220, Loss: 0.6136
Batch 230, Loss: 0.6128
Batch 240, Loss: 0.5985
Batch 250, Loss: 0.5865
Batch 260, Loss: 0.5748
Batch 270, Loss: 0.6538
Batch 280, Loss: 0.6205
Batch 290, Loss: 0.6594
Batch 300, Loss: 0.6617
Batch 310, Loss: 0.5899
Batch 320, Loss: 0.6756
Batch 330, Loss: 0.6874
Batch 340, Loss: 0.6118
Batch 350, Loss: 0.6517
Batch 360, Loss: 0.6295
Batch 370, Loss: 0.6351
Batch 380, Loss: 0.6530
Batch 390, Loss: 0.6151
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.410429000854492 seconds
Epoch 148 accuracy: 73.12%
Batch 10, Loss: 0.5800
Batch 20, Loss: 0.6339
Batch 30, Loss: 0.5848
Batch 40, Loss: 0.5977
Batch 50, Loss: 0.5623
Batch 60, Loss: 0.6155
Batch 70, Loss: 0.5908
Batch 80, Loss: 0.5717
Batch 90, Loss: 0.5750
Batch 100, Loss: 0.6132
Batch 110, Loss: 0.5793
Batch 120, Loss: 0.5609
Batch 130, Loss: 0.5670
Batch 140, Loss: 0.6181
Batch 150, Loss: 0.6107
Batch 160, Loss: 0.5908
Batch 170, Loss: 0.6252
Batch 180, Loss: 0.6216
Batch 190, Loss: 0.6282
Batch 200, Loss: 0.6742
Batch 210, Loss: 0.6002
Batch 220, Loss: 0.6367
Batch 230, Loss: 0.6073
Batch 240, Loss: 0.6412
Batch 250, Loss: 0.5982
Batch 260, Loss: 0.5929
Batch 270, Loss: 0.6216
Batch 280, Loss: 0.6298
Batch 290, Loss: 0.6534
Batch 300, Loss: 0.5975
Batch 310, Loss: 0.5911
Batch 320, Loss: 0.5971
Batch 330, Loss: 0.6087
Batch 340, Loss: 0.6448
Batch 350, Loss: 0.6714
Batch 360, Loss: 0.6430
Batch 370, Loss: 0.6109
Batch 380, Loss: 0.6445
Batch 390, Loss: 0.6235
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.48455834388733 seconds
Epoch 149 accuracy: 73.63%
Batch 10, Loss: 0.5884
Batch 20, Loss: 0.5581
Batch 30, Loss: 0.5787
Batch 40, Loss: 0.6161
Batch 50, Loss: 0.5797
Batch 60, Loss: 0.6074
Batch 70, Loss: 0.5938
Batch 80, Loss: 0.5579
Batch 90, Loss: 0.5477
Batch 100, Loss: 0.5358
Batch 110, Loss: 0.5508
Batch 120, Loss: 0.6245
Batch 130, Loss: 0.5964
Batch 140, Loss: 0.6283
Batch 150, Loss: 0.5607
Batch 160, Loss: 0.5752
Batch 170, Loss: 0.5781
Batch 180, Loss: 0.5656
Batch 190, Loss: 0.6321
Batch 200, Loss: 0.6454
Batch 210, Loss: 0.5991
Batch 220, Loss: 0.6051
Batch 230, Loss: 0.6108
Batch 240, Loss: 0.5903
Batch 250, Loss: 0.5548
Batch 260, Loss: 0.6050
Batch 270, Loss: 0.5877
Batch 280, Loss: 0.6472
Batch 290, Loss: 0.5924
Batch 300, Loss: 0.5861
Batch 310, Loss: 0.6304
Batch 320, Loss: 0.6315
Batch 330, Loss: 0.5754
Batch 340, Loss: 0.5935
Batch 350, Loss: 0.6182
Batch 360, Loss: 0.6268
Batch 370, Loss: 0.6126
Batch 380, Loss: 0.5893
Batch 390, Loss: 0.6231
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.467233419418335 seconds
Epoch 150 accuracy: 74.37%
Batch 10, Loss: 0.5703
Batch 20, Loss: 0.5859
Batch 30, Loss: 0.5788
Batch 40, Loss: 0.5266
Batch 50, Loss: 0.5859
Batch 60, Loss: 0.5953
Batch 70, Loss: 0.5645
Batch 80, Loss: 0.5167
Batch 90, Loss: 0.5253
Batch 100, Loss: 0.5836
Batch 110, Loss: 0.5623
Batch 120, Loss: 0.5814
Batch 130, Loss: 0.5786
Batch 140, Loss: 0.5800
Batch 150, Loss: 0.5359
Batch 160, Loss: 0.6167
Batch 170, Loss: 0.5456
Batch 180, Loss: 0.6130
Batch 190, Loss: 0.5326
Batch 200, Loss: 0.5671
Batch 210, Loss: 0.5346
Batch 220, Loss: 0.5802
Batch 230, Loss: 0.5590
Batch 240, Loss: 0.6222
Batch 250, Loss: 0.5737
Batch 260, Loss: 0.5627
Batch 270, Loss: 0.5333
Batch 280, Loss: 0.6392
Batch 290, Loss: 0.5942
Batch 300, Loss: 0.5917
Batch 310, Loss: 0.5962
Batch 320, Loss: 0.6072
Batch 330, Loss: 0.6152
Batch 340, Loss: 0.5942
Batch 350, Loss: 0.5719
Batch 360, Loss: 0.5833
Batch 370, Loss: 0.5911
Batch 380, Loss: 0.5933
Batch 390, Loss: 0.6235
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.419787645339966 seconds
Epoch 151 accuracy: 74.37%
Batch 10, Loss: 0.5526
Batch 20, Loss: 0.4940
Batch 30, Loss: 0.5247
Batch 40, Loss: 0.5342
Batch 50, Loss: 0.5394
Batch 60, Loss: 0.5225
Batch 70, Loss: 0.5603
Batch 80, Loss: 0.5373
Batch 90, Loss: 0.5320
Batch 100, Loss: 0.5671
Batch 110, Loss: 0.5322
Batch 120, Loss: 0.5555
Batch 130, Loss: 0.5311
Batch 140, Loss: 0.5932
Batch 150, Loss: 0.5476
Batch 160, Loss: 0.5705
Batch 170, Loss: 0.5545
Batch 180, Loss: 0.5551
Batch 190, Loss: 0.5787
Batch 200, Loss: 0.6004
Batch 210, Loss: 0.5764
Batch 220, Loss: 0.6075
Batch 230, Loss: 0.5744
Batch 240, Loss: 0.5720
Batch 250, Loss: 0.6073
Batch 260, Loss: 0.5815
Batch 270, Loss: 0.5510
Batch 280, Loss: 0.6017
Batch 290, Loss: 0.5532
Batch 300, Loss: 0.5824
Batch 310, Loss: 0.5840
Batch 320, Loss: 0.5714
Batch 330, Loss: 0.5775
Batch 340, Loss: 0.5743
Batch 350, Loss: 0.5788
Batch 360, Loss: 0.5701
Batch 370, Loss: 0.5942
Batch 380, Loss: 0.6435
Batch 390, Loss: 0.6053
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.377864122390747 seconds
Epoch 152 accuracy: 73.88%
Batch 10, Loss: 0.5557
Batch 20, Loss: 0.5345
Batch 30, Loss: 0.5253
Batch 40, Loss: 0.5687
Batch 50, Loss: 0.5606
Batch 60, Loss: 0.5430
Batch 70, Loss: 0.5366
Batch 80, Loss: 0.5422
Batch 90, Loss: 0.4977
Batch 100, Loss: 0.4985
Batch 110, Loss: 0.5265
Batch 120, Loss: 0.5533
Batch 130, Loss: 0.5503
Batch 140, Loss: 0.5879
Batch 150, Loss: 0.5373
Batch 160, Loss: 0.5670
Batch 170, Loss: 0.5485
Batch 180, Loss: 0.5608
Batch 190, Loss: 0.5806
Batch 200, Loss: 0.5724
Batch 210, Loss: 0.5467
Batch 220, Loss: 0.5621
Batch 230, Loss: 0.5734
Batch 240, Loss: 0.5846
Batch 250, Loss: 0.5841
Batch 260, Loss: 0.5379
Batch 270, Loss: 0.5284
Batch 280, Loss: 0.5991
Batch 290, Loss: 0.5860
Batch 300, Loss: 0.5582
Batch 310, Loss: 0.5444
Batch 320, Loss: 0.6031
Batch 330, Loss: 0.5714
Batch 340, Loss: 0.5811
Batch 350, Loss: 0.5563
Batch 360, Loss: 0.5360
Batch 370, Loss: 0.5655
Batch 380, Loss: 0.6082
Batch 390, Loss: 0.5999
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.43858766555786 seconds
Epoch 153 accuracy: 74.17%
Batch 10, Loss: 0.5478
Batch 20, Loss: 0.5376
Batch 30, Loss: 0.5356
Batch 40, Loss: 0.5396
Batch 50, Loss: 0.5343
Batch 60, Loss: 0.5370
Batch 70, Loss: 0.5157
Batch 80, Loss: 0.5478
Batch 90, Loss: 0.5054
Batch 100, Loss: 0.5118
Batch 110, Loss: 0.5385
Batch 120, Loss: 0.5511
Batch 130, Loss: 0.5050
Batch 140, Loss: 0.5584
Batch 150, Loss: 0.5556
Batch 160, Loss: 0.5660
Batch 170, Loss: 0.5259
Batch 180, Loss: 0.6043
Batch 190, Loss: 0.5288
Batch 200, Loss: 0.5747
Batch 210, Loss: 0.4964
Batch 220, Loss: 0.5303
Batch 230, Loss: 0.5494
Batch 240, Loss: 0.5496
Batch 250, Loss: 0.5231
Batch 260, Loss: 0.5565
Batch 270, Loss: 0.5633
Batch 280, Loss: 0.5588
Batch 290, Loss: 0.5453
Batch 300, Loss: 0.5518
Batch 310, Loss: 0.5764
Batch 320, Loss: 0.5999
Batch 330, Loss: 0.5440
Batch 340, Loss: 0.5585
Batch 350, Loss: 0.5499
Batch 360, Loss: 0.5909
Batch 370, Loss: 0.5891
Batch 380, Loss: 0.5590
Batch 390, Loss: 0.5102
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.503434896469116 seconds
Epoch 154 accuracy: 74.73%
Batch 10, Loss: 0.5306
Batch 20, Loss: 0.5400
Batch 30, Loss: 0.5368
Batch 40, Loss: 0.5336
Batch 50, Loss: 0.5177
Batch 60, Loss: 0.5799
Batch 70, Loss: 0.4803
Batch 80, Loss: 0.5158
Batch 90, Loss: 0.5159
Batch 100, Loss: 0.5404
Batch 110, Loss: 0.5199
Batch 120, Loss: 0.5380
Batch 130, Loss: 0.4919
Batch 140, Loss: 0.5036
Batch 150, Loss: 0.5038
Batch 160, Loss: 0.5445
Batch 170, Loss: 0.4875
Batch 180, Loss: 0.5410
Batch 190, Loss: 0.5496
Batch 200, Loss: 0.4868
Batch 210, Loss: 0.5094
Batch 220, Loss: 0.5288
Batch 230, Loss: 0.5416
Batch 240, Loss: 0.5680
Batch 250, Loss: 0.5481
Batch 260, Loss: 0.5519
Batch 270, Loss: 0.5095
Batch 280, Loss: 0.5876
Batch 290, Loss: 0.5384
Batch 300, Loss: 0.5072
Batch 310, Loss: 0.5289
Batch 320, Loss: 0.5408
Batch 330, Loss: 0.5486
Batch 340, Loss: 0.5421
Batch 350, Loss: 0.5904
Batch 360, Loss: 0.5791
Batch 370, Loss: 0.5532
Batch 380, Loss: 0.5267
Batch 390, Loss: 0.5788
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.33490014076233 seconds
Epoch 155 accuracy: 75.31%
Batch 10, Loss: 0.5180
Batch 20, Loss: 0.5133
Batch 30, Loss: 0.4976
Batch 40, Loss: 0.4881
Batch 50, Loss: 0.5272
Batch 60, Loss: 0.5648
Batch 70, Loss: 0.5163
Batch 80, Loss: 0.4863
Batch 90, Loss: 0.5101
Batch 100, Loss: 0.5073
Batch 110, Loss: 0.5092
Batch 120, Loss: 0.5147
Batch 130, Loss: 0.5282
Batch 140, Loss: 0.5479
Batch 150, Loss: 0.4960
Batch 160, Loss: 0.5137
Batch 170, Loss: 0.4888
Batch 180, Loss: 0.5206
Batch 190, Loss: 0.5635
Batch 200, Loss: 0.5377
Batch 210, Loss: 0.5417
Batch 220, Loss: 0.5017
Batch 230, Loss: 0.5531
Batch 240, Loss: 0.5347
Batch 250, Loss: 0.5284
Batch 260, Loss: 0.5581
Batch 270, Loss: 0.5225
Batch 280, Loss: 0.4765
Batch 290, Loss: 0.5152
Batch 300, Loss: 0.5527
Batch 310, Loss: 0.5256
Batch 320, Loss: 0.5351
Batch 330, Loss: 0.5342
Batch 340, Loss: 0.5236
Batch 350, Loss: 0.5604
Batch 360, Loss: 0.4946
Batch 370, Loss: 0.5304
Batch 380, Loss: 0.5394
Batch 390, Loss: 0.5924
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.386157035827637 seconds
Epoch 156 accuracy: 74.61%
Batch 10, Loss: 0.4917
Batch 20, Loss: 0.5251
Batch 30, Loss: 0.5015
Batch 40, Loss: 0.4802
Batch 50, Loss: 0.4921
Batch 60, Loss: 0.5065
Batch 70, Loss: 0.5047
Batch 80, Loss: 0.4945
Batch 90, Loss: 0.5001
Batch 100, Loss: 0.4793
Batch 110, Loss: 0.5057
Batch 120, Loss: 0.4839
Batch 130, Loss: 0.4876
Batch 140, Loss: 0.5134
Batch 150, Loss: 0.5328
Batch 160, Loss: 0.4489
Batch 170, Loss: 0.4775
Batch 180, Loss: 0.5235
Batch 190, Loss: 0.5038
Batch 200, Loss: 0.5580
Batch 210, Loss: 0.5022
Batch 220, Loss: 0.5112
Batch 230, Loss: 0.5122
Batch 240, Loss: 0.4935
Batch 250, Loss: 0.4978
Batch 260, Loss: 0.4796
Batch 270, Loss: 0.5366
Batch 280, Loss: 0.4842
Batch 290, Loss: 0.5295
Batch 300, Loss: 0.5231
Batch 310, Loss: 0.5130
Batch 320, Loss: 0.5269
Batch 330, Loss: 0.5169
Batch 340, Loss: 0.4884
Batch 350, Loss: 0.5406
Batch 360, Loss: 0.5621
Batch 370, Loss: 0.5577
Batch 380, Loss: 0.5051
Batch 390, Loss: 0.5474
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.293195962905884 seconds
Epoch 157 accuracy: 74.97%
Batch 10, Loss: 0.4771
Batch 20, Loss: 0.4936
Batch 30, Loss: 0.4762
Batch 40, Loss: 0.4909
Batch 50, Loss: 0.4394
Batch 60, Loss: 0.5142
Batch 70, Loss: 0.4617
Batch 80, Loss: 0.5388
Batch 90, Loss: 0.4306
Batch 100, Loss: 0.4815
Batch 110, Loss: 0.4762
Batch 120, Loss: 0.4747
Batch 130, Loss: 0.5075
Batch 140, Loss: 0.4565
Batch 150, Loss: 0.4859
Batch 160, Loss: 0.4777
Batch 170, Loss: 0.4971
Batch 180, Loss: 0.5091
Batch 190, Loss: 0.4727
Batch 200, Loss: 0.4826
Batch 210, Loss: 0.5317
Batch 220, Loss: 0.5084
Batch 230, Loss: 0.5327
Batch 240, Loss: 0.5101
Batch 250, Loss: 0.5150
Batch 260, Loss: 0.4653
Batch 270, Loss: 0.4912
Batch 280, Loss: 0.5206
Batch 290, Loss: 0.5110
Batch 300, Loss: 0.4993
Batch 310, Loss: 0.4976
Batch 320, Loss: 0.5104
Batch 330, Loss: 0.5441
Batch 340, Loss: 0.5397
Batch 350, Loss: 0.5039
Batch 360, Loss: 0.5058
Batch 370, Loss: 0.5029
Batch 380, Loss: 0.5053
Batch 390, Loss: 0.5142
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.30789875984192 seconds
Epoch 158 accuracy: 75.12%
Batch 10, Loss: 0.4785
Batch 20, Loss: 0.4545
Batch 30, Loss: 0.5075
Batch 40, Loss: 0.5037
Batch 50, Loss: 0.4580
Batch 60, Loss: 0.4905
Batch 70, Loss: 0.4584
Batch 80, Loss: 0.4875
Batch 90, Loss: 0.4618
Batch 100, Loss: 0.4801
Batch 110, Loss: 0.4728
Batch 120, Loss: 0.4788
Batch 130, Loss: 0.4562
Batch 140, Loss: 0.4831
Batch 150, Loss: 0.4576
Batch 160, Loss: 0.4846
Batch 170, Loss: 0.4552
Batch 180, Loss: 0.4470
Batch 190, Loss: 0.4639
Batch 200, Loss: 0.4702
Batch 210, Loss: 0.4663
Batch 220, Loss: 0.4535
Batch 230, Loss: 0.5140
Batch 240, Loss: 0.4866
Batch 250, Loss: 0.4700
Batch 260, Loss: 0.5120
Batch 270, Loss: 0.5079
Batch 280, Loss: 0.4755
Batch 290, Loss: 0.4689
Batch 300, Loss: 0.5298
Batch 310, Loss: 0.5147
Batch 320, Loss: 0.5216
Batch 330, Loss: 0.5617
Batch 340, Loss: 0.4754
Batch 350, Loss: 0.4730
Batch 360, Loss: 0.4681
Batch 370, Loss: 0.4728
Batch 380, Loss: 0.5330
Batch 390, Loss: 0.5045
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.464893579483032 seconds
Epoch 159 accuracy: 75.08%
Batch 10, Loss: 0.4233
Batch 20, Loss: 0.5150
Batch 30, Loss: 0.4315
Batch 40, Loss: 0.4636
Batch 50, Loss: 0.4615
Batch 60, Loss: 0.4778
Batch 70, Loss: 0.4378
Batch 80, Loss: 0.5003
Batch 90, Loss: 0.4575
Batch 100, Loss: 0.4231
Batch 110, Loss: 0.4822
Batch 120, Loss: 0.4263
Batch 130, Loss: 0.4747
Batch 140, Loss: 0.4345
Batch 150, Loss: 0.5102
Batch 160, Loss: 0.4818
Batch 170, Loss: 0.4946
Batch 180, Loss: 0.4385
Batch 190, Loss: 0.4778
Batch 200, Loss: 0.4467
Batch 210, Loss: 0.4554
Batch 220, Loss: 0.5142
Batch 230, Loss: 0.4699
Batch 240, Loss: 0.5229
Batch 250, Loss: 0.4938
Batch 260, Loss: 0.5428
Batch 270, Loss: 0.4613
Batch 280, Loss: 0.4438
Batch 290, Loss: 0.4891
Batch 300, Loss: 0.5059
Batch 310, Loss: 0.5180
Batch 320, Loss: 0.4935
Batch 330, Loss: 0.5063
Batch 340, Loss: 0.4668
Batch 350, Loss: 0.4693
Batch 360, Loss: 0.4410
Batch 370, Loss: 0.4738
Batch 380, Loss: 0.4929
Batch 390, Loss: 0.4762
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.321388006210327 seconds
Epoch 160 accuracy: 76.07%
Batch 10, Loss: 0.4337
Batch 20, Loss: 0.4665
Batch 30, Loss: 0.4563
Batch 40, Loss: 0.4722
Batch 50, Loss: 0.4234
Batch 60, Loss: 0.4422
Batch 70, Loss: 0.4517
Batch 80, Loss: 0.4430
Batch 90, Loss: 0.4271
Batch 100, Loss: 0.4395
Batch 110, Loss: 0.4466
Batch 120, Loss: 0.4727
Batch 130, Loss: 0.4839
Batch 140, Loss: 0.4503
Batch 150, Loss: 0.4820
Batch 160, Loss: 0.4823
Batch 170, Loss: 0.4529
Batch 180, Loss: 0.4560
Batch 190, Loss: 0.4317
Batch 200, Loss: 0.4420
Batch 210, Loss: 0.4531
Batch 220, Loss: 0.4524
Batch 230, Loss: 0.4833
Batch 240, Loss: 0.4495
Batch 250, Loss: 0.4557
Batch 260, Loss: 0.4839
Batch 270, Loss: 0.4741
Batch 280, Loss: 0.4484
Batch 290, Loss: 0.4846
Batch 300, Loss: 0.4796
Batch 310, Loss: 0.4876
Batch 320, Loss: 0.4881
Batch 330, Loss: 0.4670
Batch 340, Loss: 0.4682
Batch 350, Loss: 0.4663
Batch 360, Loss: 0.5127
Batch 370, Loss: 0.4402
Batch 380, Loss: 0.4858
Batch 390, Loss: 0.4278
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.50982141494751 seconds
Epoch 161 accuracy: 75.58%
Batch 10, Loss: 0.4303
Batch 20, Loss: 0.4259
Batch 30, Loss: 0.4442
Batch 40, Loss: 0.4230
Batch 50, Loss: 0.4663
Batch 60, Loss: 0.4682
Batch 70, Loss: 0.4491
Batch 80, Loss: 0.4073
Batch 90, Loss: 0.4752
Batch 100, Loss: 0.4904
Batch 110, Loss: 0.4333
Batch 120, Loss: 0.4203
Batch 130, Loss: 0.4866
Batch 140, Loss: 0.4565
Batch 150, Loss: 0.4202
Batch 160, Loss: 0.4385
Batch 170, Loss: 0.4274
Batch 180, Loss: 0.4917
Batch 190, Loss: 0.4426
Batch 200, Loss: 0.4686
Batch 210, Loss: 0.4730
Batch 220, Loss: 0.4272
Batch 230, Loss: 0.4529
Batch 240, Loss: 0.4545
Batch 250, Loss: 0.4505
Batch 260, Loss: 0.4435
Batch 270, Loss: 0.4870
Batch 280, Loss: 0.4409
Batch 290, Loss: 0.4322
Batch 300, Loss: 0.5098
Batch 310, Loss: 0.4799
Batch 320, Loss: 0.4651
Batch 330, Loss: 0.4947
Batch 340, Loss: 0.4663
Batch 350, Loss: 0.4912
Batch 360, Loss: 0.4763
Batch 370, Loss: 0.4449
Batch 380, Loss: 0.4442
Batch 390, Loss: 0.4542
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.377869606018066 seconds
Epoch 162 accuracy: 76.37%
Batch 10, Loss: 0.4176
Batch 20, Loss: 0.4225
Batch 30, Loss: 0.4421
Batch 40, Loss: 0.4268
Batch 50, Loss: 0.3807
Batch 60, Loss: 0.4199
Batch 70, Loss: 0.4484
Batch 80, Loss: 0.4254
Batch 90, Loss: 0.4362
Batch 100, Loss: 0.4452
Batch 110, Loss: 0.4213
Batch 120, Loss: 0.4303
Batch 130, Loss: 0.4689
Batch 140, Loss: 0.4295
Batch 150, Loss: 0.4161
Batch 160, Loss: 0.4516
Batch 170, Loss: 0.4362
Batch 180, Loss: 0.4418
Batch 190, Loss: 0.4273
Batch 200, Loss: 0.4508
Batch 210, Loss: 0.4231
Batch 220, Loss: 0.4446
Batch 230, Loss: 0.4481
Batch 240, Loss: 0.4342
Batch 250, Loss: 0.4451
Batch 260, Loss: 0.4638
Batch 270, Loss: 0.4727
Batch 280, Loss: 0.4199
Batch 290, Loss: 0.4384
Batch 300, Loss: 0.4531
Batch 310, Loss: 0.4398
Batch 320, Loss: 0.4164
Batch 330, Loss: 0.4539
Batch 340, Loss: 0.4483
Batch 350, Loss: 0.4668
Batch 360, Loss: 0.3949
Batch 370, Loss: 0.4559
Batch 380, Loss: 0.4574
Batch 390, Loss: 0.4272
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.32241988182068 seconds
Epoch 163 accuracy: 76.55%
Batch 10, Loss: 0.4406
Batch 20, Loss: 0.4145
Batch 30, Loss: 0.4027
Batch 40, Loss: 0.3779
Batch 50, Loss: 0.3984
Batch 60, Loss: 0.3691
Batch 70, Loss: 0.4329
Batch 80, Loss: 0.4228
Batch 90, Loss: 0.4289
Batch 100, Loss: 0.3850
Batch 110, Loss: 0.4447
Batch 120, Loss: 0.4449
Batch 130, Loss: 0.4405
Batch 140, Loss: 0.4360
Batch 150, Loss: 0.4332
Batch 160, Loss: 0.4111
Batch 170, Loss: 0.4756
Batch 180, Loss: 0.4290
Batch 190, Loss: 0.3892
Batch 200, Loss: 0.4311
Batch 210, Loss: 0.4254
Batch 220, Loss: 0.4386
Batch 230, Loss: 0.4791
Batch 240, Loss: 0.4300
Batch 250, Loss: 0.4175
Batch 260, Loss: 0.4329
Batch 270, Loss: 0.4789
Batch 280, Loss: 0.4612
Batch 290, Loss: 0.4156
Batch 300, Loss: 0.4179
Batch 310, Loss: 0.4447
Batch 320, Loss: 0.4259
Batch 330, Loss: 0.4132
Batch 340, Loss: 0.4223
Batch 350, Loss: 0.4242
Batch 360, Loss: 0.4582
Batch 370, Loss: 0.4583
Batch 380, Loss: 0.4294
Batch 390, Loss: 0.4449
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.462892055511475 seconds
Epoch 164 accuracy: 76.57%
Batch 10, Loss: 0.3891
Batch 20, Loss: 0.3762
Batch 30, Loss: 0.4238
Batch 40, Loss: 0.4017
Batch 50, Loss: 0.3942
Batch 60, Loss: 0.4274
Batch 70, Loss: 0.3911
Batch 80, Loss: 0.4388
Batch 90, Loss: 0.4142
Batch 100, Loss: 0.4376
Batch 110, Loss: 0.4170
Batch 120, Loss: 0.3796
Batch 130, Loss: 0.3990
Batch 140, Loss: 0.4305
Batch 150, Loss: 0.3840
Batch 160, Loss: 0.4064
Batch 170, Loss: 0.3799
Batch 180, Loss: 0.4020
Batch 190, Loss: 0.4215
Batch 200, Loss: 0.4210
Batch 210, Loss: 0.4266
Batch 220, Loss: 0.3988
Batch 230, Loss: 0.4283
Batch 240, Loss: 0.4203
Batch 250, Loss: 0.3999
Batch 260, Loss: 0.4346
Batch 270, Loss: 0.3984
Batch 280, Loss: 0.4275
Batch 290, Loss: 0.4456
Batch 300, Loss: 0.4235
Batch 310, Loss: 0.4308
Batch 320, Loss: 0.4062
Batch 330, Loss: 0.4251
Batch 340, Loss: 0.3980
Batch 350, Loss: 0.4344
Batch 360, Loss: 0.3899
Batch 370, Loss: 0.4520
Batch 380, Loss: 0.4150
Batch 390, Loss: 0.4257
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.418121576309204 seconds
Epoch 165 accuracy: 77.2%
Batch 10, Loss: 0.4387
Batch 20, Loss: 0.4125
Batch 30, Loss: 0.4084
Batch 40, Loss: 0.3842
Batch 50, Loss: 0.3952
Batch 60, Loss: 0.3929
Batch 70, Loss: 0.4100
Batch 80, Loss: 0.3858
Batch 90, Loss: 0.4374
Batch 100, Loss: 0.4498
Batch 110, Loss: 0.3685
Batch 120, Loss: 0.3955
Batch 130, Loss: 0.3842
Batch 140, Loss: 0.4295
Batch 150, Loss: 0.3877
Batch 160, Loss: 0.4109
Batch 170, Loss: 0.4038
Batch 180, Loss: 0.4012
Batch 190, Loss: 0.3768
Batch 200, Loss: 0.4254
Batch 210, Loss: 0.4321
Batch 220, Loss: 0.4191
Batch 230, Loss: 0.4230
Batch 240, Loss: 0.4028
Batch 250, Loss: 0.4211
Batch 260, Loss: 0.4214
Batch 270, Loss: 0.3933
Batch 280, Loss: 0.4027
Batch 290, Loss: 0.4075
Batch 300, Loss: 0.4229
Batch 310, Loss: 0.4165
Batch 320, Loss: 0.3861
Batch 330, Loss: 0.4273
Batch 340, Loss: 0.4037
Batch 350, Loss: 0.3627
Batch 360, Loss: 0.4103
Batch 370, Loss: 0.4222
Batch 380, Loss: 0.4146
Batch 390, Loss: 0.3939
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.483438730239868 seconds
Epoch 166 accuracy: 77.2%
Batch 10, Loss: 0.3878
Batch 20, Loss: 0.4065
Batch 30, Loss: 0.4101
Batch 40, Loss: 0.3742
Batch 50, Loss: 0.3771
Batch 60, Loss: 0.3661
Batch 70, Loss: 0.3741
Batch 80, Loss: 0.3980
Batch 90, Loss: 0.3820
Batch 100, Loss: 0.3969
Batch 110, Loss: 0.3776
Batch 120, Loss: 0.4007
Batch 130, Loss: 0.3853
Batch 140, Loss: 0.4021
Batch 150, Loss: 0.4028
Batch 160, Loss: 0.4046
Batch 170, Loss: 0.3909
Batch 180, Loss: 0.4043
Batch 190, Loss: 0.3985
Batch 200, Loss: 0.3730
Batch 210, Loss: 0.3654
Batch 220, Loss: 0.4305
Batch 230, Loss: 0.3794
Batch 240, Loss: 0.4192
Batch 250, Loss: 0.4612
Batch 260, Loss: 0.4504
Batch 270, Loss: 0.4402
Batch 280, Loss: 0.4046
Batch 290, Loss: 0.4096
Batch 300, Loss: 0.3699
Batch 310, Loss: 0.4142
Batch 320, Loss: 0.4013
Batch 330, Loss: 0.3955
Batch 340, Loss: 0.3892
Batch 350, Loss: 0.3981
Batch 360, Loss: 0.3895
Batch 370, Loss: 0.4147
Batch 380, Loss: 0.4100
Batch 390, Loss: 0.3923
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.5004620552063 seconds
Epoch 167 accuracy: 76.82%
Batch 10, Loss: 0.3938
Batch 20, Loss: 0.3541
Batch 30, Loss: 0.4061
Batch 40, Loss: 0.3789
Batch 50, Loss: 0.4090
Batch 60, Loss: 0.3898
Batch 70, Loss: 0.3901
Batch 80, Loss: 0.3934
Batch 90, Loss: 0.4114
Batch 100, Loss: 0.3464
Batch 110, Loss: 0.3729
Batch 120, Loss: 0.3751
Batch 130, Loss: 0.3842
Batch 140, Loss: 0.3879
Batch 150, Loss: 0.3996
Batch 160, Loss: 0.4026
Batch 170, Loss: 0.3911
Batch 180, Loss: 0.3913
Batch 190, Loss: 0.3711
Batch 200, Loss: 0.4048
Batch 210, Loss: 0.3962
Batch 220, Loss: 0.3733
Batch 230, Loss: 0.3755
Batch 240, Loss: 0.3717
Batch 250, Loss: 0.3812
Batch 260, Loss: 0.3811
Batch 270, Loss: 0.3764
Batch 280, Loss: 0.3816
Batch 290, Loss: 0.3724
Batch 300, Loss: 0.3715
Batch 310, Loss: 0.3667
Batch 320, Loss: 0.3658
Batch 330, Loss: 0.3782
Batch 340, Loss: 0.4031
Batch 350, Loss: 0.3630
Batch 360, Loss: 0.4047
Batch 370, Loss: 0.4066
Batch 380, Loss: 0.3861
Batch 390, Loss: 0.3800
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.38704538345337 seconds
Epoch 168 accuracy: 76.71%
Batch 10, Loss: 0.3334
Batch 20, Loss: 0.3850
Batch 30, Loss: 0.3765
Batch 40, Loss: 0.3532
Batch 50, Loss: 0.3571
Batch 60, Loss: 0.3544
Batch 70, Loss: 0.3550
Batch 80, Loss: 0.3426
Batch 90, Loss: 0.3975
Batch 100, Loss: 0.3757
Batch 110, Loss: 0.3800
Batch 120, Loss: 0.4126
Batch 130, Loss: 0.3908
Batch 140, Loss: 0.3923
Batch 150, Loss: 0.3846
Batch 160, Loss: 0.3981
Batch 170, Loss: 0.3837
Batch 180, Loss: 0.3597
Batch 190, Loss: 0.3564
Batch 200, Loss: 0.3567
Batch 210, Loss: 0.3751
Batch 220, Loss: 0.3890
Batch 230, Loss: 0.3690
Batch 240, Loss: 0.3595
Batch 250, Loss: 0.3675
Batch 260, Loss: 0.3872
Batch 270, Loss: 0.4087
Batch 280, Loss: 0.3937
Batch 290, Loss: 0.3916
Batch 300, Loss: 0.3906
Batch 310, Loss: 0.3399
Batch 320, Loss: 0.3652
Batch 330, Loss: 0.3711
Batch 340, Loss: 0.3787
Batch 350, Loss: 0.3705
Batch 360, Loss: 0.4207
Batch 370, Loss: 0.3718
Batch 380, Loss: 0.3598
Batch 390, Loss: 0.3657
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.347218990325928 seconds
Epoch 169 accuracy: 77.26%
Batch 10, Loss: 0.3485
Batch 20, Loss: 0.3752
Batch 30, Loss: 0.3898
Batch 40, Loss: 0.3502
Batch 50, Loss: 0.3698
Batch 60, Loss: 0.3645
Batch 70, Loss: 0.3719
Batch 80, Loss: 0.3437
Batch 90, Loss: 0.3559
Batch 100, Loss: 0.3453
Batch 110, Loss: 0.4061
Batch 120, Loss: 0.3592
Batch 130, Loss: 0.3218
Batch 140, Loss: 0.3460
Batch 150, Loss: 0.3611
Batch 160, Loss: 0.3686
Batch 170, Loss: 0.3648
Batch 180, Loss: 0.3435
Batch 190, Loss: 0.3674
Batch 200, Loss: 0.3565
Batch 210, Loss: 0.3879
Batch 220, Loss: 0.3618
Batch 230, Loss: 0.3758
Batch 240, Loss: 0.3903
Batch 250, Loss: 0.3662
Batch 260, Loss: 0.3873
Batch 270, Loss: 0.3583
Batch 280, Loss: 0.3940
Batch 290, Loss: 0.3758
Batch 300, Loss: 0.3448
Batch 310, Loss: 0.3786
Batch 320, Loss: 0.3615
Batch 330, Loss: 0.3669
Batch 340, Loss: 0.3851
Batch 350, Loss: 0.4005
Batch 360, Loss: 0.3585
Batch 370, Loss: 0.3945
Batch 380, Loss: 0.3670
Batch 390, Loss: 0.3956
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.50494909286499 seconds
Epoch 170 accuracy: 77.64%
Batch 10, Loss: 0.3427
Batch 20, Loss: 0.3352
Batch 30, Loss: 0.3610
Batch 40, Loss: 0.4064
Batch 50, Loss: 0.3760
Batch 60, Loss: 0.4040
Batch 70, Loss: 0.3586
Batch 80, Loss: 0.3482
Batch 90, Loss: 0.3262
Batch 100, Loss: 0.3445
Batch 110, Loss: 0.3661
Batch 120, Loss: 0.3735
Batch 130, Loss: 0.3665
Batch 140, Loss: 0.3570
Batch 150, Loss: 0.3578
Batch 160, Loss: 0.3875
Batch 170, Loss: 0.3814
Batch 180, Loss: 0.3556
Batch 190, Loss: 0.3646
Batch 200, Loss: 0.3576
Batch 210, Loss: 0.3765
Batch 220, Loss: 0.3478
Batch 230, Loss: 0.3628
Batch 240, Loss: 0.3502
Batch 250, Loss: 0.3840
Batch 260, Loss: 0.3876
Batch 270, Loss: 0.3658
Batch 280, Loss: 0.3496
Batch 290, Loss: 0.3811
Batch 300, Loss: 0.3833
Batch 310, Loss: 0.3792
Batch 320, Loss: 0.3539
Batch 330, Loss: 0.3802
Batch 340, Loss: 0.3475
Batch 350, Loss: 0.4009
Batch 360, Loss: 0.3555
Batch 370, Loss: 0.3722
Batch 380, Loss: 0.3509
Batch 390, Loss: 0.3771
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.343132972717285 seconds
Epoch 171 accuracy: 77.58%
Batch 10, Loss: 0.3238
Batch 20, Loss: 0.3983
Batch 30, Loss: 0.3444
Batch 40, Loss: 0.3425
Batch 50, Loss: 0.3736
Batch 60, Loss: 0.3427
Batch 70, Loss: 0.3496
Batch 80, Loss: 0.3183
Batch 90, Loss: 0.3475
Batch 100, Loss: 0.3334
Batch 110, Loss: 0.3964
Batch 120, Loss: 0.3282
Batch 130, Loss: 0.3238
Batch 140, Loss: 0.3306
Batch 150, Loss: 0.2984
Batch 160, Loss: 0.3303
Batch 170, Loss: 0.3680
Batch 180, Loss: 0.3273
Batch 190, Loss: 0.3156
Batch 200, Loss: 0.3317
Batch 210, Loss: 0.3199
Batch 220, Loss: 0.3923
Batch 230, Loss: 0.3383
Batch 240, Loss: 0.3522
Batch 250, Loss: 0.3354
Batch 260, Loss: 0.3314
Batch 270, Loss: 0.3585
Batch 280, Loss: 0.3298
Batch 290, Loss: 0.3671
Batch 300, Loss: 0.3652
Batch 310, Loss: 0.3728
Batch 320, Loss: 0.3271
Batch 330, Loss: 0.3879
Batch 340, Loss: 0.3925
Batch 350, Loss: 0.3277
Batch 360, Loss: 0.3495
Batch 370, Loss: 0.3737
Batch 380, Loss: 0.3829
Batch 390, Loss: 0.3627
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.412543773651123 seconds
Epoch 172 accuracy: 77.96%
Batch 10, Loss: 0.3359
Batch 20, Loss: 0.3563
Batch 30, Loss: 0.3268
Batch 40, Loss: 0.3725
Batch 50, Loss: 0.3330
Batch 60, Loss: 0.3511
Batch 70, Loss: 0.3182
Batch 80, Loss: 0.3367
Batch 90, Loss: 0.3190
Batch 100, Loss: 0.3522
Batch 110, Loss: 0.3176
Batch 120, Loss: 0.3825
Batch 130, Loss: 0.3340
Batch 140, Loss: 0.3305
Batch 150, Loss: 0.3354
Batch 160, Loss: 0.2759
Batch 170, Loss: 0.3409
Batch 180, Loss: 0.3578
Batch 190, Loss: 0.3263
Batch 200, Loss: 0.3208
Batch 210, Loss: 0.3376
Batch 220, Loss: 0.3254
Batch 230, Loss: 0.3337
Batch 240, Loss: 0.3193
Batch 250, Loss: 0.3509
Batch 260, Loss: 0.3503
Batch 270, Loss: 0.3350
Batch 280, Loss: 0.3438
Batch 290, Loss: 0.3585
Batch 300, Loss: 0.3635
Batch 310, Loss: 0.3774
Batch 320, Loss: 0.3565
Batch 330, Loss: 0.3341
Batch 340, Loss: 0.3277
Batch 350, Loss: 0.3429
Batch 360, Loss: 0.3076
Batch 370, Loss: 0.3200
Batch 380, Loss: 0.3532
Batch 390, Loss: 0.3488
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.469260692596436 seconds
Epoch 173 accuracy: 78.51%
Batch 10, Loss: 0.3174
Batch 20, Loss: 0.3405
Batch 30, Loss: 0.3250
Batch 40, Loss: 0.3389
Batch 50, Loss: 0.3207
Batch 60, Loss: 0.3530
Batch 70, Loss: 0.3339
Batch 80, Loss: 0.3353
Batch 90, Loss: 0.3645
Batch 100, Loss: 0.3269
Batch 110, Loss: 0.3195
Batch 120, Loss: 0.3231
Batch 130, Loss: 0.3494
Batch 140, Loss: 0.4108
Batch 150, Loss: 0.3086
Batch 160, Loss: 0.3106
Batch 170, Loss: 0.3310
Batch 180, Loss: 0.3402
Batch 190, Loss: 0.3410
Batch 200, Loss: 0.3415
Batch 210, Loss: 0.3475
Batch 220, Loss: 0.3063
Batch 230, Loss: 0.3242
Batch 240, Loss: 0.3354
Batch 250, Loss: 0.3245
Batch 260, Loss: 0.3482
Batch 270, Loss: 0.3603
Batch 280, Loss: 0.3727
Batch 290, Loss: 0.3192
Batch 300, Loss: 0.3362
Batch 310, Loss: 0.3322
Batch 320, Loss: 0.3234
Batch 330, Loss: 0.3416
Batch 340, Loss: 0.3645
Batch 350, Loss: 0.3466
Batch 360, Loss: 0.3493
Batch 370, Loss: 0.3504
Batch 380, Loss: 0.3426
Batch 390, Loss: 0.3393
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.38828992843628 seconds
Epoch 174 accuracy: 78.18%
Batch 10, Loss: 0.3391
Batch 20, Loss: 0.3276
Batch 30, Loss: 0.3105
Batch 40, Loss: 0.2882
Batch 50, Loss: 0.3497
Batch 60, Loss: 0.3027
Batch 70, Loss: 0.3276
Batch 80, Loss: 0.2956
Batch 90, Loss: 0.3474
Batch 100, Loss: 0.3194
Batch 110, Loss: 0.3848
Batch 120, Loss: 0.3651
Batch 130, Loss: 0.3381
Batch 140, Loss: 0.3370
Batch 150, Loss: 0.3320
Batch 160, Loss: 0.3183
Batch 170, Loss: 0.3104
Batch 180, Loss: 0.3390
Batch 190, Loss: 0.3376
Batch 200, Loss: 0.2957
Batch 210, Loss: 0.3435
Batch 220, Loss: 0.2889
Batch 230, Loss: 0.3215
Batch 240, Loss: 0.3173
Batch 250, Loss: 0.3020
Batch 260, Loss: 0.3315
Batch 270, Loss: 0.3175
Batch 280, Loss: 0.3649
Batch 290, Loss: 0.3328
Batch 300, Loss: 0.3153
Batch 310, Loss: 0.3496
Batch 320, Loss: 0.3247
Batch 330, Loss: 0.3222
Batch 340, Loss: 0.3318
Batch 350, Loss: 0.3614
Batch 360, Loss: 0.3107
Batch 370, Loss: 0.3269
Batch 380, Loss: 0.3484
Batch 390, Loss: 0.3079
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.48461890220642 seconds
Epoch 175 accuracy: 78.18%
Batch 10, Loss: 0.3209
Batch 20, Loss: 0.3379
Batch 30, Loss: 0.3009
Batch 40, Loss: 0.3274
Batch 50, Loss: 0.3558
Batch 60, Loss: 0.2923
Batch 70, Loss: 0.2970
Batch 80, Loss: 0.3087
Batch 90, Loss: 0.3108
Batch 100, Loss: 0.3304
Batch 110, Loss: 0.3209
Batch 120, Loss: 0.3214
Batch 130, Loss: 0.3219
Batch 140, Loss: 0.3200
Batch 150, Loss: 0.3509
Batch 160, Loss: 0.3192
Batch 170, Loss: 0.3244
Batch 180, Loss: 0.2911
Batch 190, Loss: 0.3469
Batch 200, Loss: 0.2822
Batch 210, Loss: 0.2926
Batch 220, Loss: 0.2979
Batch 230, Loss: 0.2993
Batch 240, Loss: 0.3162
Batch 250, Loss: 0.3281
Batch 260, Loss: 0.2847
Batch 270, Loss: 0.3067
Batch 280, Loss: 0.3412
Batch 290, Loss: 0.3534
Batch 300, Loss: 0.3169
Batch 310, Loss: 0.3194
Batch 320, Loss: 0.2836
Batch 330, Loss: 0.3142
Batch 340, Loss: 0.3219
Batch 350, Loss: 0.2910
Batch 360, Loss: 0.3218
Batch 370, Loss: 0.3178
Batch 380, Loss: 0.2922
Batch 390, Loss: 0.3151
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.470837593078613 seconds
Epoch 176 accuracy: 78.84%
Batch 10, Loss: 0.3067
Batch 20, Loss: 0.3572
Batch 30, Loss: 0.2859
Batch 40, Loss: 0.3185
Batch 50, Loss: 0.3225
Batch 60, Loss: 0.3200
Batch 70, Loss: 0.2985
Batch 80, Loss: 0.3016
Batch 90, Loss: 0.3130
Batch 100, Loss: 0.2981
Batch 110, Loss: 0.3038
Batch 120, Loss: 0.2952
Batch 130, Loss: 0.2776
Batch 140, Loss: 0.3221
Batch 150, Loss: 0.2903
Batch 160, Loss: 0.2866
Batch 170, Loss: 0.2909
Batch 180, Loss: 0.3074
Batch 190, Loss: 0.3037
Batch 200, Loss: 0.3343
Batch 210, Loss: 0.2797
Batch 220, Loss: 0.3129
Batch 230, Loss: 0.3064
Batch 240, Loss: 0.2988
Batch 250, Loss: 0.3430
Batch 260, Loss: 0.3223
Batch 270, Loss: 0.2749
Batch 280, Loss: 0.2718
Batch 290, Loss: 0.2842
Batch 300, Loss: 0.3052
Batch 310, Loss: 0.3347
Batch 320, Loss: 0.3017
Batch 330, Loss: 0.2820
Batch 340, Loss: 0.3135
Batch 350, Loss: 0.2966
Batch 360, Loss: 0.3353
Batch 370, Loss: 0.2950
Batch 380, Loss: 0.2860
Batch 390, Loss: 0.3285
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.363577604293823 seconds
Epoch 177 accuracy: 78.74%
Batch 10, Loss: 0.2968
Batch 20, Loss: 0.2973
Batch 30, Loss: 0.3179
Batch 40, Loss: 0.2772
Batch 50, Loss: 0.3317
Batch 60, Loss: 0.2815
Batch 70, Loss: 0.2881
Batch 80, Loss: 0.3142
Batch 90, Loss: 0.2629
Batch 100, Loss: 0.3321
Batch 110, Loss: 0.3297
Batch 120, Loss: 0.2819
Batch 130, Loss: 0.3067
Batch 140, Loss: 0.2708
Batch 150, Loss: 0.2993
Batch 160, Loss: 0.2840
Batch 170, Loss: 0.3353
Batch 180, Loss: 0.2941
Batch 190, Loss: 0.3179
Batch 200, Loss: 0.3196
Batch 210, Loss: 0.2824
Batch 220, Loss: 0.3047
Batch 230, Loss: 0.3120
Batch 240, Loss: 0.2833
Batch 250, Loss: 0.3226
Batch 260, Loss: 0.2729
Batch 270, Loss: 0.3227
Batch 280, Loss: 0.2960
Batch 290, Loss: 0.3216
Batch 300, Loss: 0.3184
Batch 310, Loss: 0.3231
Batch 320, Loss: 0.3204
Batch 330, Loss: 0.3193
Batch 340, Loss: 0.3166
Batch 350, Loss: 0.3033
Batch 360, Loss: 0.3056
Batch 370, Loss: 0.3190
Batch 380, Loss: 0.3040
Batch 390, Loss: 0.2801
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.4118754863739 seconds
Epoch 178 accuracy: 78.87%
Batch 10, Loss: 0.3178
Batch 20, Loss: 0.3056
Batch 30, Loss: 0.2854
Batch 40, Loss: 0.3092
Batch 50, Loss: 0.3218
Batch 60, Loss: 0.2876
Batch 70, Loss: 0.2773
Batch 80, Loss: 0.2724
Batch 90, Loss: 0.2918
Batch 100, Loss: 0.2825
Batch 110, Loss: 0.3092
Batch 120, Loss: 0.2905
Batch 130, Loss: 0.2987
Batch 140, Loss: 0.2983
Batch 150, Loss: 0.3032
Batch 160, Loss: 0.2909
Batch 170, Loss: 0.2977
Batch 180, Loss: 0.3055
Batch 190, Loss: 0.3182
Batch 200, Loss: 0.3097
Batch 210, Loss: 0.2898
Batch 220, Loss: 0.2915
Batch 230, Loss: 0.2979
Batch 240, Loss: 0.2762
Batch 250, Loss: 0.2989
Batch 260, Loss: 0.2760
Batch 270, Loss: 0.3176
Batch 280, Loss: 0.2845
Batch 290, Loss: 0.2774
Batch 300, Loss: 0.3281
Batch 310, Loss: 0.3193
Batch 320, Loss: 0.3140
Batch 330, Loss: 0.3059
Batch 340, Loss: 0.3017
Batch 350, Loss: 0.2958
Batch 360, Loss: 0.2979
Batch 370, Loss: 0.2753
Batch 380, Loss: 0.3224
Batch 390, Loss: 0.2844
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.36722159385681 seconds
Epoch 179 accuracy: 78.95%
Batch 10, Loss: 0.3307
Batch 20, Loss: 0.2694
Batch 30, Loss: 0.2695
Batch 40, Loss: 0.2828
Batch 50, Loss: 0.2841
Batch 60, Loss: 0.3184
Batch 70, Loss: 0.3041
Batch 80, Loss: 0.3021
Batch 90, Loss: 0.3279
Batch 100, Loss: 0.2969
Batch 110, Loss: 0.2920
Batch 120, Loss: 0.2868
Batch 130, Loss: 0.2868
Batch 140, Loss: 0.2670
Batch 150, Loss: 0.2621
Batch 160, Loss: 0.3255
Batch 170, Loss: 0.3147
Batch 180, Loss: 0.3407
Batch 190, Loss: 0.2827
Batch 200, Loss: 0.2818
Batch 210, Loss: 0.2505
Batch 220, Loss: 0.2783
Batch 230, Loss: 0.3002
Batch 240, Loss: 0.2969
Batch 250, Loss: 0.3031
Batch 260, Loss: 0.2901
Batch 270, Loss: 0.2715
Batch 280, Loss: 0.2867
Batch 290, Loss: 0.2796
Batch 300, Loss: 0.2737
Batch 310, Loss: 0.2996
Batch 320, Loss: 0.3104
Batch 330, Loss: 0.3103
Batch 340, Loss: 0.3305
Batch 350, Loss: 0.3040
Batch 360, Loss: 0.2905
Batch 370, Loss: 0.2921
Batch 380, Loss: 0.2888
Batch 390, Loss: 0.2592
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.47097420692444 seconds
Epoch 180 accuracy: 78.91%
Batch 10, Loss: 0.2646
Batch 20, Loss: 0.2815
Batch 30, Loss: 0.2791
Batch 40, Loss: 0.2964
Batch 50, Loss: 0.2934
Batch 60, Loss: 0.2481
Batch 70, Loss: 0.2754
Batch 80, Loss: 0.3223
Batch 90, Loss: 0.3010
Batch 100, Loss: 0.3112
Batch 110, Loss: 0.2953
Batch 120, Loss: 0.2878
Batch 130, Loss: 0.2903
Batch 140, Loss: 0.2558
Batch 150, Loss: 0.2601
Batch 160, Loss: 0.2918
Batch 170, Loss: 0.2721
Batch 180, Loss: 0.2941
Batch 190, Loss: 0.2544
Batch 200, Loss: 0.2840
Batch 210, Loss: 0.3055
Batch 220, Loss: 0.2840
Batch 230, Loss: 0.2690
Batch 240, Loss: 0.2803
Batch 250, Loss: 0.2917
Batch 260, Loss: 0.2770
Batch 270, Loss: 0.2784
Batch 280, Loss: 0.2904
Batch 290, Loss: 0.2497
Batch 300, Loss: 0.2993
Batch 310, Loss: 0.2726
Batch 320, Loss: 0.2527
Batch 330, Loss: 0.2626
Batch 340, Loss: 0.2939
Batch 350, Loss: 0.2675
Batch 360, Loss: 0.2822
Batch 370, Loss: 0.2601
Batch 380, Loss: 0.2717
Batch 390, Loss: 0.2888
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.393424034118652 seconds
Epoch 181 accuracy: 78.79%
Batch 10, Loss: 0.2605
Batch 20, Loss: 0.2753
Batch 30, Loss: 0.2693
Batch 40, Loss: 0.2499
Batch 50, Loss: 0.2678
Batch 60, Loss: 0.2967
Batch 70, Loss: 0.2464
Batch 80, Loss: 0.2748
Batch 90, Loss: 0.2951
Batch 100, Loss: 0.2548
Batch 110, Loss: 0.3267
Batch 120, Loss: 0.3237
Batch 130, Loss: 0.3051
Batch 140, Loss: 0.2759
Batch 150, Loss: 0.2335
Batch 160, Loss: 0.2803
Batch 170, Loss: 0.2480
Batch 180, Loss: 0.2589
Batch 190, Loss: 0.2660
Batch 200, Loss: 0.2386
Batch 210, Loss: 0.2918
Batch 220, Loss: 0.2691
Batch 230, Loss: 0.3022
Batch 240, Loss: 0.2971
Batch 250, Loss: 0.2759
Batch 260, Loss: 0.2786
Batch 270, Loss: 0.2677
Batch 280, Loss: 0.2955
Batch 290, Loss: 0.2578
Batch 300, Loss: 0.2981
Batch 310, Loss: 0.2849
Batch 320, Loss: 0.3291
Batch 330, Loss: 0.2782
Batch 340, Loss: 0.2654
Batch 350, Loss: 0.2980
Batch 360, Loss: 0.2572
Batch 370, Loss: 0.2926
Batch 380, Loss: 0.2654
Batch 390, Loss: 0.2827
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.39502215385437 seconds
Epoch 182 accuracy: 79.05%
Batch 10, Loss: 0.2460
Batch 20, Loss: 0.2693
Batch 30, Loss: 0.2618
Batch 40, Loss: 0.2692
Batch 50, Loss: 0.2912
Batch 60, Loss: 0.2826
Batch 70, Loss: 0.2917
Batch 80, Loss: 0.2781
Batch 90, Loss: 0.2777
Batch 100, Loss: 0.2649
Batch 110, Loss: 0.2688
Batch 120, Loss: 0.2747
Batch 130, Loss: 0.2574
Batch 140, Loss: 0.2560
Batch 150, Loss: 0.2665
Batch 160, Loss: 0.2738
Batch 170, Loss: 0.2881
Batch 180, Loss: 0.2687
Batch 190, Loss: 0.2718
Batch 200, Loss: 0.2724
Batch 210, Loss: 0.2850
Batch 220, Loss: 0.2963
Batch 230, Loss: 0.2807
Batch 240, Loss: 0.2581
Batch 250, Loss: 0.2720
Batch 260, Loss: 0.2541
Batch 270, Loss: 0.2565
Batch 280, Loss: 0.2683
Batch 290, Loss: 0.2556
Batch 300, Loss: 0.2828
Batch 310, Loss: 0.2897
Batch 320, Loss: 0.2889
Batch 330, Loss: 0.2589
Batch 340, Loss: 0.2898
Batch 350, Loss: 0.2900
Batch 360, Loss: 0.2767
Batch 370, Loss: 0.2576
Batch 380, Loss: 0.2781
Batch 390, Loss: 0.2530
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.2353835105896 seconds
Epoch 183 accuracy: 79.22%
Batch 10, Loss: 0.2775
Batch 20, Loss: 0.2662
Batch 30, Loss: 0.2872
Batch 40, Loss: 0.2945
Batch 50, Loss: 0.2657
Batch 60, Loss: 0.2651
Batch 70, Loss: 0.2934
Batch 80, Loss: 0.2628
Batch 90, Loss: 0.2689
Batch 100, Loss: 0.2529
Batch 110, Loss: 0.2839
Batch 120, Loss: 0.2865
Batch 130, Loss: 0.2731
Batch 140, Loss: 0.2731
Batch 150, Loss: 0.3043
Batch 160, Loss: 0.2518
Batch 170, Loss: 0.2616
Batch 180, Loss: 0.2725
Batch 190, Loss: 0.2776
Batch 200, Loss: 0.2823
Batch 210, Loss: 0.2774
Batch 220, Loss: 0.2912
Batch 230, Loss: 0.2654
Batch 240, Loss: 0.2781
Batch 250, Loss: 0.2785
Batch 260, Loss: 0.2777
Batch 270, Loss: 0.2466
Batch 280, Loss: 0.2642
Batch 290, Loss: 0.2935
Batch 300, Loss: 0.2670
Batch 310, Loss: 0.2485
Batch 320, Loss: 0.2605
Batch 330, Loss: 0.2581
Batch 340, Loss: 0.2671
Batch 350, Loss: 0.2583
Batch 360, Loss: 0.2691
Batch 370, Loss: 0.2743
Batch 380, Loss: 0.2871
Batch 390, Loss: 0.2572
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.359004020690918 seconds
Epoch 184 accuracy: 79.27%
Batch 10, Loss: 0.2641
Batch 20, Loss: 0.2662
Batch 30, Loss: 0.2666
Batch 40, Loss: 0.2527
Batch 50, Loss: 0.2915
Batch 60, Loss: 0.2734
Batch 70, Loss: 0.2760
Batch 80, Loss: 0.2607
Batch 90, Loss: 0.2638
Batch 100, Loss: 0.2675
Batch 110, Loss: 0.2477
Batch 120, Loss: 0.2792
Batch 130, Loss: 0.2511
Batch 140, Loss: 0.3051
Batch 150, Loss: 0.2594
Batch 160, Loss: 0.2991
Batch 170, Loss: 0.2669
Batch 180, Loss: 0.2597
Batch 190, Loss: 0.2372
Batch 200, Loss: 0.2396
Batch 210, Loss: 0.2718
Batch 220, Loss: 0.2576
Batch 230, Loss: 0.2836
Batch 240, Loss: 0.2801
Batch 250, Loss: 0.2656
Batch 260, Loss: 0.2662
Batch 270, Loss: 0.2784
Batch 280, Loss: 0.2566
Batch 290, Loss: 0.2854
Batch 300, Loss: 0.3057
Batch 310, Loss: 0.3121
Batch 320, Loss: 0.2404
Batch 330, Loss: 0.2442
Batch 340, Loss: 0.2700
Batch 350, Loss: 0.2838
Batch 360, Loss: 0.2965
Batch 370, Loss: 0.2723
Batch 380, Loss: 0.2773
Batch 390, Loss: 0.2650
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.34497094154358 seconds
Epoch 185 accuracy: 79.51%
Batch 10, Loss: 0.2583
Batch 20, Loss: 0.2480
Batch 30, Loss: 0.2868
Batch 40, Loss: 0.2393
Batch 50, Loss: 0.2593
Batch 60, Loss: 0.2647
Batch 70, Loss: 0.2370
Batch 80, Loss: 0.2934
Batch 90, Loss: 0.2675
Batch 100, Loss: 0.2813
Batch 110, Loss: 0.2759
Batch 120, Loss: 0.2647
Batch 130, Loss: 0.2668
Batch 140, Loss: 0.2613
Batch 150, Loss: 0.2623
Batch 160, Loss: 0.2480
Batch 170, Loss: 0.2847
Batch 180, Loss: 0.2424
Batch 190, Loss: 0.2635
Batch 200, Loss: 0.2685
Batch 210, Loss: 0.2551
Batch 220, Loss: 0.2624
Batch 230, Loss: 0.2825
Batch 240, Loss: 0.2291
Batch 250, Loss: 0.2817
Batch 260, Loss: 0.2529
Batch 270, Loss: 0.2281
Batch 280, Loss: 0.2627
Batch 290, Loss: 0.2494
Batch 300, Loss: 0.2730
Batch 310, Loss: 0.2732
Batch 320, Loss: 0.2450
Batch 330, Loss: 0.2828
Batch 340, Loss: 0.2698
Batch 350, Loss: 0.2906
Batch 360, Loss: 0.2640
Batch 370, Loss: 0.2454
Batch 380, Loss: 0.2709
Batch 390, Loss: 0.2676
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.315678358078003 seconds
Epoch 186 accuracy: 79.52%
Batch 10, Loss: 0.2605
Batch 20, Loss: 0.2433
Batch 30, Loss: 0.2391
Batch 40, Loss: 0.2343
Batch 50, Loss: 0.2763
Batch 60, Loss: 0.2318
Batch 70, Loss: 0.2606
Batch 80, Loss: 0.2519
Batch 90, Loss: 0.2621
Batch 100, Loss: 0.2360
Batch 110, Loss: 0.2742
Batch 120, Loss: 0.2890
Batch 130, Loss: 0.2762
Batch 140, Loss: 0.2620
Batch 150, Loss: 0.2370
Batch 160, Loss: 0.2572
Batch 170, Loss: 0.2417
Batch 180, Loss: 0.2174
Batch 190, Loss: 0.2654
Batch 200, Loss: 0.2136
Batch 210, Loss: 0.2624
Batch 220, Loss: 0.2175
Batch 230, Loss: 0.2500
Batch 240, Loss: 0.2298
Batch 250, Loss: 0.2570
Batch 260, Loss: 0.2418
Batch 270, Loss: 0.2568
Batch 280, Loss: 0.2697
Batch 290, Loss: 0.2452
Batch 300, Loss: 0.2487
Batch 310, Loss: 0.2702
Batch 320, Loss: 0.2500
Batch 330, Loss: 0.3017
Batch 340, Loss: 0.2644
Batch 350, Loss: 0.2654
Batch 360, Loss: 0.2659
Batch 370, Loss: 0.2934
Batch 380, Loss: 0.2327
Batch 390, Loss: 0.2737
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.36329174041748 seconds
Epoch 187 accuracy: 79.6%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2449
Batch 30, Loss: 0.2598
Batch 40, Loss: 0.2635
Batch 50, Loss: 0.2432
Batch 60, Loss: 0.2564
Batch 70, Loss: 0.2185
Batch 80, Loss: 0.2723
Batch 90, Loss: 0.2536
Batch 100, Loss: 0.2452
Batch 110, Loss: 0.2435
Batch 120, Loss: 0.2471
Batch 130, Loss: 0.2474
Batch 140, Loss: 0.2356
Batch 150, Loss: 0.2419
Batch 160, Loss: 0.2604
Batch 170, Loss: 0.2452
Batch 180, Loss: 0.2373
Batch 190, Loss: 0.2456
Batch 200, Loss: 0.2622
Batch 210, Loss: 0.2694
Batch 220, Loss: 0.2505
Batch 230, Loss: 0.2534
Batch 240, Loss: 0.2454
Batch 250, Loss: 0.2492
Batch 260, Loss: 0.2736
Batch 270, Loss: 0.2589
Batch 280, Loss: 0.2237
Batch 290, Loss: 0.2337
Batch 300, Loss: 0.2670
Batch 310, Loss: 0.2438
Batch 320, Loss: 0.2327
Batch 330, Loss: 0.2755
Batch 340, Loss: 0.2556
Batch 350, Loss: 0.2492
Batch 360, Loss: 0.2449
Batch 370, Loss: 0.2876
Batch 380, Loss: 0.2390
Batch 390, Loss: 0.2270
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.50153875350952 seconds
Epoch 188 accuracy: 79.85%
Batch 10, Loss: 0.2694
Batch 20, Loss: 0.2316
Batch 30, Loss: 0.2597
Batch 40, Loss: 0.2651
Batch 50, Loss: 0.2419
Batch 60, Loss: 0.2501
Batch 70, Loss: 0.2510
Batch 80, Loss: 0.2124
Batch 90, Loss: 0.2608
Batch 100, Loss: 0.2177
Batch 110, Loss: 0.2553
Batch 120, Loss: 0.2314
Batch 130, Loss: 0.2582
Batch 140, Loss: 0.2738
Batch 150, Loss: 0.2324
Batch 160, Loss: 0.2584
Batch 170, Loss: 0.2666
Batch 180, Loss: 0.2688
Batch 190, Loss: 0.2587
Batch 200, Loss: 0.2597
Batch 210, Loss: 0.2010
Batch 220, Loss: 0.2641
Batch 230, Loss: 0.2975
Batch 240, Loss: 0.2179
Batch 250, Loss: 0.2800
Batch 260, Loss: 0.2214
Batch 270, Loss: 0.2723
Batch 280, Loss: 0.2368
Batch 290, Loss: 0.2377
Batch 300, Loss: 0.2407
Batch 310, Loss: 0.2514
Batch 320, Loss: 0.2513
Batch 330, Loss: 0.2797
Batch 340, Loss: 0.2223
Batch 350, Loss: 0.2637
Batch 360, Loss: 0.2618
Batch 370, Loss: 0.2760
Batch 380, Loss: 0.2540
Batch 390, Loss: 0.2354
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.458141565322876 seconds
Epoch 189 accuracy: 79.65%
Batch 10, Loss: 0.2213
Batch 20, Loss: 0.2385
Batch 30, Loss: 0.2418
Batch 40, Loss: 0.2738
Batch 50, Loss: 0.2456
Batch 60, Loss: 0.2279
Batch 70, Loss: 0.2496
Batch 80, Loss: 0.2405
Batch 90, Loss: 0.2564
Batch 100, Loss: 0.2478
Batch 110, Loss: 0.2795
Batch 120, Loss: 0.2414
Batch 130, Loss: 0.2559
Batch 140, Loss: 0.2157
Batch 150, Loss: 0.2119
Batch 160, Loss: 0.2416
Batch 170, Loss: 0.2652
Batch 180, Loss: 0.2643
Batch 190, Loss: 0.2724
Batch 200, Loss: 0.2256
Batch 210, Loss: 0.2098
Batch 220, Loss: 0.2507
Batch 230, Loss: 0.2310
Batch 240, Loss: 0.2611
Batch 250, Loss: 0.2468
Batch 260, Loss: 0.2320
Batch 270, Loss: 0.2657
Batch 280, Loss: 0.2519
Batch 290, Loss: 0.2460
Batch 300, Loss: 0.2440
Batch 310, Loss: 0.2653
Batch 320, Loss: 0.2413
Batch 330, Loss: 0.2390
Batch 340, Loss: 0.2303
Batch 350, Loss: 0.2541
Batch 360, Loss: 0.2654
Batch 370, Loss: 0.2444
Batch 380, Loss: 0.2244
Batch 390, Loss: 0.2414
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.491204500198364 seconds
Epoch 190 accuracy: 79.79%
Batch 10, Loss: 0.2332
Batch 20, Loss: 0.2059
Batch 30, Loss: 0.2834
Batch 40, Loss: 0.2379
Batch 50, Loss: 0.2588
Batch 60, Loss: 0.2571
Batch 70, Loss: 0.2081
Batch 80, Loss: 0.2367
Batch 90, Loss: 0.2390
Batch 100, Loss: 0.2401
Batch 110, Loss: 0.2546
Batch 120, Loss: 0.2334
Batch 130, Loss: 0.2745
Batch 140, Loss: 0.2202
Batch 150, Loss: 0.2399
Batch 160, Loss: 0.2535
Batch 170, Loss: 0.2485
Batch 180, Loss: 0.2239
Batch 190, Loss: 0.2494
Batch 200, Loss: 0.2459
Batch 210, Loss: 0.2807
Batch 220, Loss: 0.2274
Batch 230, Loss: 0.2239
Batch 240, Loss: 0.2309
Batch 250, Loss: 0.2556
Batch 260, Loss: 0.2305
Batch 270, Loss: 0.2554
Batch 280, Loss: 0.2288
Batch 290, Loss: 0.2424
Batch 300, Loss: 0.2458
Batch 310, Loss: 0.2196
Batch 320, Loss: 0.2311
Batch 330, Loss: 0.2611
Batch 340, Loss: 0.2825
Batch 350, Loss: 0.2375
Batch 360, Loss: 0.2387
Batch 370, Loss: 0.2432
Batch 380, Loss: 0.2607
Batch 390, Loss: 0.2764
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.291661739349365 seconds
Epoch 191 accuracy: 79.86%
Batch 10, Loss: 0.2400
Batch 20, Loss: 0.2391
Batch 30, Loss: 0.2485
Batch 40, Loss: 0.2365
Batch 50, Loss: 0.2451
Batch 60, Loss: 0.2472
Batch 70, Loss: 0.2461
Batch 80, Loss: 0.2482
Batch 90, Loss: 0.2383
Batch 100, Loss: 0.2476
Batch 110, Loss: 0.2532
Batch 120, Loss: 0.2635
Batch 130, Loss: 0.2366
Batch 140, Loss: 0.2318
Batch 150, Loss: 0.2296
Batch 160, Loss: 0.2331
Batch 170, Loss: 0.2346
Batch 180, Loss: 0.2279
Batch 190, Loss: 0.2334
Batch 200, Loss: 0.2116
Batch 210, Loss: 0.2466
Batch 220, Loss: 0.2292
Batch 230, Loss: 0.2413
Batch 240, Loss: 0.2255
Batch 250, Loss: 0.2370
Batch 260, Loss: 0.2605
Batch 270, Loss: 0.2169
Batch 280, Loss: 0.2616
Batch 290, Loss: 0.2179
Batch 300, Loss: 0.2246
Batch 310, Loss: 0.2341
Batch 320, Loss: 0.2105
Batch 330, Loss: 0.2367
Batch 340, Loss: 0.2329
Batch 350, Loss: 0.2593
Batch 360, Loss: 0.2637
Batch 370, Loss: 0.2373
Batch 380, Loss: 0.2838
Batch 390, Loss: 0.2460
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.407668352127075 seconds
Epoch 192 accuracy: 79.71%
Batch 10, Loss: 0.2255
Batch 20, Loss: 0.2689
Batch 30, Loss: 0.2040
Batch 40, Loss: 0.2427
Batch 50, Loss: 0.2310
Batch 60, Loss: 0.2547
Batch 70, Loss: 0.2351
Batch 80, Loss: 0.2501
Batch 90, Loss: 0.2143
Batch 100, Loss: 0.2499
Batch 110, Loss: 0.2546
Batch 120, Loss: 0.2183
Batch 130, Loss: 0.2278
Batch 140, Loss: 0.2534
Batch 150, Loss: 0.2606
Batch 160, Loss: 0.2248
Batch 170, Loss: 0.2330
Batch 180, Loss: 0.2561
Batch 190, Loss: 0.2460
Batch 200, Loss: 0.2364
Batch 210, Loss: 0.2177
Batch 220, Loss: 0.2315
Batch 230, Loss: 0.2305
Batch 240, Loss: 0.2475
Batch 250, Loss: 0.2718
Batch 260, Loss: 0.2362
Batch 270, Loss: 0.2198
Batch 280, Loss: 0.2345
Batch 290, Loss: 0.2234
Batch 300, Loss: 0.2591
Batch 310, Loss: 0.2234
Batch 320, Loss: 0.2633
Batch 330, Loss: 0.2558
Batch 340, Loss: 0.2762
Batch 350, Loss: 0.2575
Batch 360, Loss: 0.2729
Batch 370, Loss: 0.2400
Batch 380, Loss: 0.2313
Batch 390, Loss: 0.2672
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.455357789993286 seconds
Epoch 193 accuracy: 79.82%
Batch 10, Loss: 0.2545
Batch 20, Loss: 0.2309
Batch 30, Loss: 0.2605
Batch 40, Loss: 0.2199
Batch 50, Loss: 0.2062
Batch 60, Loss: 0.2832
Batch 70, Loss: 0.2282
Batch 80, Loss: 0.2246
Batch 90, Loss: 0.2281
Batch 100, Loss: 0.2521
Batch 110, Loss: 0.2546
Batch 120, Loss: 0.2293
Batch 130, Loss: 0.2315
Batch 140, Loss: 0.2385
Batch 150, Loss: 0.2677
Batch 160, Loss: 0.2610
Batch 170, Loss: 0.2390
Batch 180, Loss: 0.2416
Batch 190, Loss: 0.2500
Batch 200, Loss: 0.2259
Batch 210, Loss: 0.2604
Batch 220, Loss: 0.2010
Batch 230, Loss: 0.2292
Batch 240, Loss: 0.2558
Batch 250, Loss: 0.2359
Batch 260, Loss: 0.2545
Batch 270, Loss: 0.2489
Batch 280, Loss: 0.2403
Batch 290, Loss: 0.2212
Batch 300, Loss: 0.2433
Batch 310, Loss: 0.2471
Batch 320, Loss: 0.2547
Batch 330, Loss: 0.2443
Batch 340, Loss: 0.2539
Batch 350, Loss: 0.2047
Batch 360, Loss: 0.2318
Batch 370, Loss: 0.2339
Batch 380, Loss: 0.2497
Batch 390, Loss: 0.2305
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.473260641098022 seconds
Epoch 194 accuracy: 79.81%
Batch 10, Loss: 0.2826
Batch 20, Loss: 0.2165
Batch 30, Loss: 0.2486
Batch 40, Loss: 0.2132
Batch 50, Loss: 0.2317
Batch 60, Loss: 0.2458
Batch 70, Loss: 0.2420
Batch 80, Loss: 0.2398
Batch 90, Loss: 0.2328
Batch 100, Loss: 0.2803
Batch 110, Loss: 0.2302
Batch 120, Loss: 0.1992
Batch 130, Loss: 0.2113
Batch 140, Loss: 0.2470
Batch 150, Loss: 0.2219
Batch 160, Loss: 0.2326
Batch 170, Loss: 0.2619
Batch 180, Loss: 0.2484
Batch 190, Loss: 0.2226
Batch 200, Loss: 0.2412
Batch 210, Loss: 0.2144
Batch 220, Loss: 0.2479
Batch 230, Loss: 0.2269
Batch 240, Loss: 0.1985
Batch 250, Loss: 0.2381
Batch 260, Loss: 0.2582
Batch 270, Loss: 0.2108
Batch 280, Loss: 0.2559
Batch 290, Loss: 0.2192
Batch 300, Loss: 0.2705
Batch 310, Loss: 0.2268
Batch 320, Loss: 0.2299
Batch 330, Loss: 0.2498
Batch 340, Loss: 0.2604
Batch 350, Loss: 0.2214
Batch 360, Loss: 0.2106
Batch 370, Loss: 0.2465
Batch 380, Loss: 0.2188
Batch 390, Loss: 0.2315
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.473052978515625 seconds
Epoch 195 accuracy: 79.88%
Batch 10, Loss: 0.2433
Batch 20, Loss: 0.2516
Batch 30, Loss: 0.2329
Batch 40, Loss: 0.2365
Batch 50, Loss: 0.2569
Batch 60, Loss: 0.2297
Batch 70, Loss: 0.2195
Batch 80, Loss: 0.2139
Batch 90, Loss: 0.2229
Batch 100, Loss: 0.2483
Batch 110, Loss: 0.2072
Batch 120, Loss: 0.2353
Batch 130, Loss: 0.2258
Batch 140, Loss: 0.2410
Batch 150, Loss: 0.2313
Batch 160, Loss: 0.2482
Batch 170, Loss: 0.2113
Batch 180, Loss: 0.2338
Batch 190, Loss: 0.2372
Batch 200, Loss: 0.2322
Batch 210, Loss: 0.2438
Batch 220, Loss: 0.2521
Batch 230, Loss: 0.2085
Batch 240, Loss: 0.2640
Batch 250, Loss: 0.2285
Batch 260, Loss: 0.2281
Batch 270, Loss: 0.2520
Batch 280, Loss: 0.2267
Batch 290, Loss: 0.2521
Batch 300, Loss: 0.2447
Batch 310, Loss: 0.2207
Batch 320, Loss: 0.2317
Batch 330, Loss: 0.2040
Batch 340, Loss: 0.2095
Batch 350, Loss: 0.2407
Batch 360, Loss: 0.2271
Batch 370, Loss: 0.2037
Batch 380, Loss: 0.2281
Batch 390, Loss: 0.2303
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.466145277023315 seconds
Epoch 196 accuracy: 79.89%
Batch 10, Loss: 0.2262
Batch 20, Loss: 0.2253
Batch 30, Loss: 0.2161
Batch 40, Loss: 0.2249
Batch 50, Loss: 0.2035
Batch 60, Loss: 0.2321
Batch 70, Loss: 0.2337
Batch 80, Loss: 0.2601
Batch 90, Loss: 0.2504
Batch 100, Loss: 0.2388
Batch 110, Loss: 0.2346
Batch 120, Loss: 0.2384
Batch 130, Loss: 0.2265
Batch 140, Loss: 0.2022
Batch 150, Loss: 0.2301
Batch 160, Loss: 0.2213
Batch 170, Loss: 0.2477
Batch 180, Loss: 0.2460
Batch 190, Loss: 0.2297
Batch 200, Loss: 0.2287
Batch 210, Loss: 0.2719
Batch 220, Loss: 0.2476
Batch 230, Loss: 0.2545
Batch 240, Loss: 0.2300
Batch 250, Loss: 0.2260
Batch 260, Loss: 0.2494
Batch 270, Loss: 0.2584
Batch 280, Loss: 0.2127
Batch 290, Loss: 0.2288
Batch 300, Loss: 0.2588
Batch 310, Loss: 0.2251
Batch 320, Loss: 0.2028
Batch 330, Loss: 0.2581
Batch 340, Loss: 0.2442
Batch 350, Loss: 0.2405
Batch 360, Loss: 0.2371
Batch 370, Loss: 0.2424
Batch 380, Loss: 0.2437
Batch 390, Loss: 0.2298
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.375346422195435 seconds
Epoch 197 accuracy: 79.83%
Batch 10, Loss: 0.1948
Batch 20, Loss: 0.2237
Batch 30, Loss: 0.2231
Batch 40, Loss: 0.2250
Batch 50, Loss: 0.2357
Batch 60, Loss: 0.2974
Batch 70, Loss: 0.2678
Batch 80, Loss: 0.2544
Batch 90, Loss: 0.2607
Batch 100, Loss: 0.2509
Batch 110, Loss: 0.2315
Batch 120, Loss: 0.2152
Batch 130, Loss: 0.2462
Batch 140, Loss: 0.2422
Batch 150, Loss: 0.2441
Batch 160, Loss: 0.2374
Batch 170, Loss: 0.2190
Batch 180, Loss: 0.2056
Batch 190, Loss: 0.2340
Batch 200, Loss: 0.2404
Batch 210, Loss: 0.2549
Batch 220, Loss: 0.2586
Batch 230, Loss: 0.2485
Batch 240, Loss: 0.2536
Batch 250, Loss: 0.2197
Batch 260, Loss: 0.2173
Batch 270, Loss: 0.2348
Batch 280, Loss: 0.2163
Batch 290, Loss: 0.2309
Batch 300, Loss: 0.2389
Batch 310, Loss: 0.2562
Batch 320, Loss: 0.2377
Batch 330, Loss: 0.2677
Batch 340, Loss: 0.2331
Batch 350, Loss: 0.2426
Batch 360, Loss: 0.2158
Batch 370, Loss: 0.2236
Batch 380, Loss: 0.2113
Batch 390, Loss: 0.2224
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.413068771362305 seconds
Epoch 198 accuracy: 79.83%
Batch 10, Loss: 0.2138
Batch 20, Loss: 0.2499
Batch 30, Loss: 0.2494
Batch 40, Loss: 0.2287
Batch 50, Loss: 0.2852
Batch 60, Loss: 0.2573
Batch 70, Loss: 0.2335
Batch 80, Loss: 0.2399
Batch 90, Loss: 0.2390
Batch 100, Loss: 0.2551
Batch 110, Loss: 0.2475
Batch 120, Loss: 0.2358
Batch 130, Loss: 0.2153
Batch 140, Loss: 0.2271
Batch 150, Loss: 0.2265
Batch 160, Loss: 0.2224
Batch 170, Loss: 0.2215
Batch 180, Loss: 0.2770
Batch 190, Loss: 0.2303
Batch 200, Loss: 0.2311
Batch 210, Loss: 0.2454
Batch 220, Loss: 0.2115
Batch 230, Loss: 0.2165
Batch 240, Loss: 0.2673
Batch 250, Loss: 0.2466
Batch 260, Loss: 0.2419
Batch 270, Loss: 0.2374
Batch 280, Loss: 0.2295
Batch 290, Loss: 0.2280
Batch 300, Loss: 0.2249
Batch 310, Loss: 0.2443
Batch 320, Loss: 0.2616
Batch 330, Loss: 0.2377
Batch 340, Loss: 0.2518
Batch 350, Loss: 0.2348
Batch 360, Loss: 0.2556
Batch 370, Loss: 0.2099
Batch 380, Loss: 0.2436
Batch 390, Loss: 0.2165
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.484060049057007 seconds
Epoch 199 accuracy: 79.77%
Batch 10, Loss: 0.2156
Batch 20, Loss: 0.2307
Batch 30, Loss: 0.2504
Batch 40, Loss: 0.2293
Batch 50, Loss: 0.2138
Batch 60, Loss: 0.2173
Batch 70, Loss: 0.2626
Batch 80, Loss: 0.2520
Batch 90, Loss: 0.2349
Batch 100, Loss: 0.2275
Batch 110, Loss: 0.2354
Batch 120, Loss: 0.2480
Batch 130, Loss: 0.2338
Batch 140, Loss: 0.2396
Batch 150, Loss: 0.2289
Batch 160, Loss: 0.2417
Batch 170, Loss: 0.2148
Batch 180, Loss: 0.2218
Batch 190, Loss: 0.2537
Batch 200, Loss: 0.2524
Batch 210, Loss: 0.2294
Batch 220, Loss: 0.2460
Batch 230, Loss: 0.2507
Batch 240, Loss: 0.2221
Batch 250, Loss: 0.2342
Batch 260, Loss: 0.2064
Batch 270, Loss: 0.2225
Batch 280, Loss: 0.2611
Batch 290, Loss: 0.2110
Batch 300, Loss: 0.2081
Batch 310, Loss: 0.2538
Batch 320, Loss: 0.2245
Batch 330, Loss: 0.2114
Batch 340, Loss: 0.2539
Batch 350, Loss: 0.2715
Batch 360, Loss: 0.2672
Batch 370, Loss: 0.2381
Batch 380, Loss: 0.2418
Batch 390, Loss: 0.2219
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.369150400161743 seconds
Epoch 200 accuracy: 79.66%
Total training time: 5089.624900102615 seconds
