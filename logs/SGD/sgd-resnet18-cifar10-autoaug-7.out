The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 3.5622
Batch 20, Loss: 2.7759
Batch 30, Loss: 1.9435
Batch 40, Loss: 1.9360
Batch 50, Loss: 1.7994
Batch 60, Loss: 1.7472
Batch 70, Loss: 1.6982
Batch 80, Loss: 1.6859
Batch 90, Loss: 1.6616
Batch 100, Loss: 1.6666
Batch 110, Loss: 1.6606
Batch 120, Loss: 1.6507
Batch 130, Loss: 1.6413
Batch 140, Loss: 1.6371
Batch 150, Loss: 1.6202
Batch 160, Loss: 1.6344
Batch 170, Loss: 1.6018
Batch 180, Loss: 1.6067
Batch 190, Loss: 1.6034
Batch 200, Loss: 1.5895
Batch 210, Loss: 1.5676
Batch 220, Loss: 1.5594
Batch 230, Loss: 1.5778
Batch 240, Loss: 1.5517
Batch 250, Loss: 1.5721
Batch 260, Loss: 1.5415
Batch 270, Loss: 1.5310
Batch 280, Loss: 1.5414
Batch 290, Loss: 1.5104
Batch 300, Loss: 1.5489
Batch 310, Loss: 1.5366
Batch 320, Loss: 1.5098
Batch 330, Loss: 1.5309
Batch 340, Loss: 1.4800
Batch 350, Loss: 1.5106
Batch 360, Loss: 1.5235
Batch 370, Loss: 1.5295
Batch 380, Loss: 1.5235
Batch 390, Loss: 1.5162
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.502628087997437 seconds
Epoch 1 accuracy: 32.33%
Batch 10, Loss: 1.5198
Batch 20, Loss: 1.5280
Batch 30, Loss: 1.4841
Batch 40, Loss: 1.5001
Batch 50, Loss: 1.4756
Batch 60, Loss: 1.4634
Batch 70, Loss: 1.4685
Batch 80, Loss: 1.4669
Batch 90, Loss: 1.4867
Batch 100, Loss: 1.4657
Batch 110, Loss: 1.4915
Batch 120, Loss: 1.4507
Batch 130, Loss: 1.4354
Batch 140, Loss: 1.4307
Batch 150, Loss: 1.3910
Batch 160, Loss: 1.4594
Batch 170, Loss: 1.4490
Batch 180, Loss: 1.4260
Batch 190, Loss: 1.4608
Batch 200, Loss: 1.4152
Batch 210, Loss: 1.4103
Batch 220, Loss: 1.4006
Batch 230, Loss: 1.3987
Batch 240, Loss: 1.4453
Batch 250, Loss: 1.4263
Batch 260, Loss: 1.4489
Batch 270, Loss: 1.4282
Batch 280, Loss: 1.4065
Batch 290, Loss: 1.3701
Batch 300, Loss: 1.3872
Batch 310, Loss: 1.3897
Batch 320, Loss: 1.3819
Batch 330, Loss: 1.3750
Batch 340, Loss: 1.3932
Batch 350, Loss: 1.3586
Batch 360, Loss: 1.3565
Batch 370, Loss: 1.3463
Batch 380, Loss: 1.3763
Batch 390, Loss: 1.3564
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.269610166549683 seconds
Epoch 2 accuracy: 43.89%
Batch 10, Loss: 1.4042
Batch 20, Loss: 1.3679
Batch 30, Loss: 1.3413
Batch 40, Loss: 1.3957
Batch 50, Loss: 1.3600
Batch 60, Loss: 1.3705
Batch 70, Loss: 1.3305
Batch 80, Loss: 1.3249
Batch 90, Loss: 1.3045
Batch 100, Loss: 1.3211
Batch 110, Loss: 1.2945
Batch 120, Loss: 1.3503
Batch 130, Loss: 1.3090
Batch 140, Loss: 1.2906
Batch 150, Loss: 1.2743
Batch 160, Loss: 1.2584
Batch 170, Loss: 1.3045
Batch 180, Loss: 1.3464
Batch 190, Loss: 1.2706
Batch 200, Loss: 1.2752
Batch 210, Loss: 1.2808
Batch 220, Loss: 1.3148
Batch 230, Loss: 1.3151
Batch 240, Loss: 1.2646
Batch 250, Loss: 1.2871
Batch 260, Loss: 1.2885
Batch 270, Loss: 1.2669
Batch 280, Loss: 1.2765
Batch 290, Loss: 1.2555
Batch 300, Loss: 1.2344
Batch 310, Loss: 1.2907
Batch 320, Loss: 1.2229
Batch 330, Loss: 1.2335
Batch 340, Loss: 1.1972
Batch 350, Loss: 1.2168
Batch 360, Loss: 1.2011
Batch 370, Loss: 1.1628
Batch 380, Loss: 1.1972
Batch 390, Loss: 1.1829
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.114888191223145 seconds
Epoch 3 accuracy: 53.75%
Batch 10, Loss: 1.2104
Batch 20, Loss: 1.1800
Batch 30, Loss: 1.2261
Batch 40, Loss: 1.1570
Batch 50, Loss: 1.1752
Batch 60, Loss: 1.1634
Batch 70, Loss: 1.1566
Batch 80, Loss: 1.1166
Batch 90, Loss: 1.2205
Batch 100, Loss: 1.1727
Batch 110, Loss: 1.1706
Batch 120, Loss: 1.1836
Batch 130, Loss: 1.1729
Batch 140, Loss: 1.1718
Batch 150, Loss: 1.1278
Batch 160, Loss: 1.1085
Batch 170, Loss: 1.1471
Batch 180, Loss: 1.1426
Batch 190, Loss: 1.1695
Batch 200, Loss: 1.1217
Batch 210, Loss: 1.1485
Batch 220, Loss: 1.1705
Batch 230, Loss: 1.1416
Batch 240, Loss: 1.1197
Batch 250, Loss: 1.0935
Batch 260, Loss: 1.1466
Batch 270, Loss: 1.1136
Batch 280, Loss: 1.1811
Batch 290, Loss: 1.1005
Batch 300, Loss: 1.1442
Batch 310, Loss: 1.0962
Batch 320, Loss: 1.0634
Batch 330, Loss: 1.0997
Batch 340, Loss: 1.1201
Batch 350, Loss: 1.0784
Batch 360, Loss: 1.1145
Batch 370, Loss: 1.0689
Batch 380, Loss: 1.0641
Batch 390, Loss: 1.0761
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.100425004959106 seconds
Epoch 4 accuracy: 57.36%
Batch 10, Loss: 1.1102
Batch 20, Loss: 1.0674
Batch 30, Loss: 1.0583
Batch 40, Loss: 1.0530
Batch 50, Loss: 1.0338
Batch 60, Loss: 1.0805
Batch 70, Loss: 1.0740
Batch 80, Loss: 1.0641
Batch 90, Loss: 1.0558
Batch 100, Loss: 1.1197
Batch 110, Loss: 1.0964
Batch 120, Loss: 1.0623
Batch 130, Loss: 1.0487
Batch 140, Loss: 1.0660
Batch 150, Loss: 1.0240
Batch 160, Loss: 1.0728
Batch 170, Loss: 1.0576
Batch 180, Loss: 1.0317
Batch 190, Loss: 1.0311
Batch 200, Loss: 1.0651
Batch 210, Loss: 1.0075
Batch 220, Loss: 1.0114
Batch 230, Loss: 1.0716
Batch 240, Loss: 1.0138
Batch 250, Loss: 1.0202
Batch 260, Loss: 1.0375
Batch 270, Loss: 1.0504
Batch 280, Loss: 1.0758
Batch 290, Loss: 1.0281
Batch 300, Loss: 1.0252
Batch 310, Loss: 1.0558
Batch 320, Loss: 0.9826
Batch 330, Loss: 0.9949
Batch 340, Loss: 1.0439
Batch 350, Loss: 0.9845
Batch 360, Loss: 1.0242
Batch 370, Loss: 0.9767
Batch 380, Loss: 1.0266
Batch 390, Loss: 0.9892
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.191975355148315 seconds
Epoch 5 accuracy: 63.04%
Batch 10, Loss: 0.9850
Batch 20, Loss: 1.0434
Batch 30, Loss: 1.0082
Batch 40, Loss: 0.9678
Batch 50, Loss: 0.9896
Batch 60, Loss: 0.9873
Batch 70, Loss: 0.9726
Batch 80, Loss: 0.9928
Batch 90, Loss: 0.9677
Batch 100, Loss: 1.0354
Batch 110, Loss: 0.9469
Batch 120, Loss: 0.9357
Batch 130, Loss: 0.9973
Batch 140, Loss: 0.9976
Batch 150, Loss: 0.9999
Batch 160, Loss: 0.9859
Batch 170, Loss: 0.9324
Batch 180, Loss: 1.0339
Batch 190, Loss: 0.9790
Batch 200, Loss: 0.9859
Batch 210, Loss: 1.0115
Batch 220, Loss: 0.9242
Batch 230, Loss: 0.9783
Batch 240, Loss: 0.9883
Batch 250, Loss: 1.0052
Batch 260, Loss: 0.9530
Batch 270, Loss: 0.9806
Batch 280, Loss: 0.9525
Batch 290, Loss: 0.9848
Batch 300, Loss: 0.9552
Batch 310, Loss: 0.9805
Batch 320, Loss: 0.9747
Batch 330, Loss: 0.9200
Batch 340, Loss: 0.9522
Batch 350, Loss: 0.9868
Batch 360, Loss: 0.9340
Batch 370, Loss: 0.9801
Batch 380, Loss: 0.9444
Batch 390, Loss: 0.9205
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.146759033203125 seconds
Epoch 6 accuracy: 65.23%
Batch 10, Loss: 0.9578
Batch 20, Loss: 0.9608
Batch 30, Loss: 0.9573
Batch 40, Loss: 0.9228
Batch 50, Loss: 0.9434
Batch 60, Loss: 0.9349
Batch 70, Loss: 0.9607
Batch 80, Loss: 0.9152
Batch 90, Loss: 0.9442
Batch 100, Loss: 0.9890
Batch 110, Loss: 0.9511
Batch 120, Loss: 0.8917
Batch 130, Loss: 0.9853
Batch 140, Loss: 0.9245
Batch 150, Loss: 0.9251
Batch 160, Loss: 0.9001
Batch 170, Loss: 0.9125
Batch 180, Loss: 0.9125
Batch 190, Loss: 0.9150
Batch 200, Loss: 0.9280
Batch 210, Loss: 0.9346
Batch 220, Loss: 0.9302
Batch 230, Loss: 0.8651
Batch 240, Loss: 0.8842
Batch 250, Loss: 0.9565
Batch 260, Loss: 0.9490
Batch 270, Loss: 0.8523
Batch 280, Loss: 0.9217
Batch 290, Loss: 0.8945
Batch 300, Loss: 0.9082
Batch 310, Loss: 0.8975
Batch 320, Loss: 0.8867
Batch 330, Loss: 0.9228
Batch 340, Loss: 0.8821
Batch 350, Loss: 0.9001
Batch 360, Loss: 0.8665
Batch 370, Loss: 0.9059
Batch 380, Loss: 0.9469
Batch 390, Loss: 0.8575
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.077150106430054 seconds
Epoch 7 accuracy: 66.03%
Batch 10, Loss: 0.9353
Batch 20, Loss: 0.8683
Batch 30, Loss: 0.9178
Batch 40, Loss: 0.8335
Batch 50, Loss: 0.8933
Batch 60, Loss: 0.8803
Batch 70, Loss: 0.8914
Batch 80, Loss: 0.9117
Batch 90, Loss: 0.8606
Batch 100, Loss: 0.8903
Batch 110, Loss: 0.9440
Batch 120, Loss: 0.9373
Batch 130, Loss: 0.8709
Batch 140, Loss: 0.8140
Batch 150, Loss: 0.8721
Batch 160, Loss: 0.8659
Batch 170, Loss: 0.8699
Batch 180, Loss: 0.8810
Batch 190, Loss: 0.8408
Batch 200, Loss: 0.8586
Batch 210, Loss: 0.8785
Batch 220, Loss: 0.8749
Batch 230, Loss: 0.8439
Batch 240, Loss: 0.8408
Batch 250, Loss: 0.8760
Batch 260, Loss: 0.8963
Batch 270, Loss: 0.8497
Batch 280, Loss: 0.8365
Batch 290, Loss: 0.8324
Batch 300, Loss: 0.8534
Batch 310, Loss: 0.8277
Batch 320, Loss: 0.8611
Batch 330, Loss: 0.8643
Batch 340, Loss: 0.7865
Batch 350, Loss: 0.8447
Batch 360, Loss: 0.8496
Batch 370, Loss: 0.8329
Batch 380, Loss: 0.7925
Batch 390, Loss: 0.8739
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.16118359565735 seconds
Epoch 8 accuracy: 66.92%
Batch 10, Loss: 0.8584
Batch 20, Loss: 0.8620
Batch 30, Loss: 0.8464
Batch 40, Loss: 0.8863
Batch 50, Loss: 0.8482
Batch 60, Loss: 0.8188
Batch 70, Loss: 0.8589
Batch 80, Loss: 0.8398
Batch 90, Loss: 0.8614
Batch 100, Loss: 0.8304
Batch 110, Loss: 0.8725
Batch 120, Loss: 0.8297
Batch 130, Loss: 0.8281
Batch 140, Loss: 0.8232
Batch 150, Loss: 0.8345
Batch 160, Loss: 0.7606
Batch 170, Loss: 0.7698
Batch 180, Loss: 0.8601
Batch 190, Loss: 0.8376
Batch 200, Loss: 0.8023
Batch 210, Loss: 0.8318
Batch 220, Loss: 0.8312
Batch 230, Loss: 0.8449
Batch 240, Loss: 0.8274
Batch 250, Loss: 0.7852
Batch 260, Loss: 0.8625
Batch 270, Loss: 0.8719
Batch 280, Loss: 0.8256
Batch 290, Loss: 0.7936
Batch 300, Loss: 0.8125
Batch 310, Loss: 0.8369
Batch 320, Loss: 0.7944
Batch 330, Loss: 0.8182
Batch 340, Loss: 0.8057
Batch 350, Loss: 0.7944
Batch 360, Loss: 0.7921
Batch 370, Loss: 0.7941
Batch 380, Loss: 0.7989
Batch 390, Loss: 0.8096
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.092275381088257 seconds
Epoch 9 accuracy: 70.1%
Batch 10, Loss: 0.8085
Batch 20, Loss: 0.8271
Batch 30, Loss: 0.7851
Batch 40, Loss: 0.7669
Batch 50, Loss: 0.8034
Batch 60, Loss: 0.8055
Batch 70, Loss: 0.7692
Batch 80, Loss: 0.7626
Batch 90, Loss: 0.7490
Batch 100, Loss: 0.7750
Batch 110, Loss: 0.7683
Batch 120, Loss: 0.8045
Batch 130, Loss: 0.7838
Batch 140, Loss: 0.7668
Batch 150, Loss: 0.8159
Batch 160, Loss: 0.8229
Batch 170, Loss: 0.7917
Batch 180, Loss: 0.7996
Batch 190, Loss: 0.7817
Batch 200, Loss: 0.8459
Batch 210, Loss: 0.8330
Batch 220, Loss: 0.7899
Batch 230, Loss: 0.7373
Batch 240, Loss: 0.7695
Batch 250, Loss: 0.7724
Batch 260, Loss: 0.8224
Batch 270, Loss: 0.8368
Batch 280, Loss: 0.7554
Batch 290, Loss: 0.7588
Batch 300, Loss: 0.7967
Batch 310, Loss: 0.8135
Batch 320, Loss: 0.7585
Batch 330, Loss: 0.7946
Batch 340, Loss: 0.8150
Batch 350, Loss: 0.7719
Batch 360, Loss: 0.7649
Batch 370, Loss: 0.7666
Batch 380, Loss: 0.7604
Batch 390, Loss: 0.8090
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.033796310424805 seconds
Epoch 10 accuracy: 71.53%
Batch 10, Loss: 0.7624
Batch 20, Loss: 0.8510
Batch 30, Loss: 0.7818
Batch 40, Loss: 0.7956
Batch 50, Loss: 0.7611
Batch 60, Loss: 0.7547
Batch 70, Loss: 0.7675
Batch 80, Loss: 0.7422
Batch 90, Loss: 0.7583
Batch 100, Loss: 0.7989
Batch 110, Loss: 0.7425
Batch 120, Loss: 0.7525
Batch 130, Loss: 0.8057
Batch 140, Loss: 0.7312
Batch 150, Loss: 0.7474
Batch 160, Loss: 0.7267
Batch 170, Loss: 0.7702
Batch 180, Loss: 0.8050
Batch 190, Loss: 0.7767
Batch 200, Loss: 0.7685
Batch 210, Loss: 0.7356
Batch 220, Loss: 0.7408
Batch 230, Loss: 0.7155
Batch 240, Loss: 0.7255
Batch 250, Loss: 0.7565
Batch 260, Loss: 0.7424
Batch 270, Loss: 0.7838
Batch 280, Loss: 0.7753
Batch 290, Loss: 0.7319
Batch 300, Loss: 0.7676
Batch 310, Loss: 0.7634
Batch 320, Loss: 0.7191
Batch 330, Loss: 0.7756
Batch 340, Loss: 0.8150
Batch 350, Loss: 0.7777
Batch 360, Loss: 0.7588
Batch 370, Loss: 0.7157
Batch 380, Loss: 0.7307
Batch 390, Loss: 0.7742
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.08005428314209 seconds
Epoch 11 accuracy: 75.11%
Batch 10, Loss: 0.6973
Batch 20, Loss: 0.7433
Batch 30, Loss: 0.7801
Batch 40, Loss: 0.7290
Batch 50, Loss: 0.7999
Batch 60, Loss: 0.7485
Batch 70, Loss: 0.7507
Batch 80, Loss: 0.7583
Batch 90, Loss: 0.7517
Batch 100, Loss: 0.7350
Batch 110, Loss: 0.7531
Batch 120, Loss: 0.7628
Batch 130, Loss: 0.7642
Batch 140, Loss: 0.6845
Batch 150, Loss: 0.7329
Batch 160, Loss: 0.7548
Batch 170, Loss: 0.7269
Batch 180, Loss: 0.7419
Batch 190, Loss: 0.7189
Batch 200, Loss: 0.7574
Batch 210, Loss: 0.7588
Batch 220, Loss: 0.7249
Batch 230, Loss: 0.7442
Batch 240, Loss: 0.7061
Batch 250, Loss: 0.7122
Batch 260, Loss: 0.7635
Batch 270, Loss: 0.7512
Batch 280, Loss: 0.7415
Batch 290, Loss: 0.7704
Batch 300, Loss: 0.7588
Batch 310, Loss: 0.7262
Batch 320, Loss: 0.7681
Batch 330, Loss: 0.7710
Batch 340, Loss: 0.7023
Batch 350, Loss: 0.7119
Batch 360, Loss: 0.7103
Batch 370, Loss: 0.7383
Batch 380, Loss: 0.7781
Batch 390, Loss: 0.7276
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.04734778404236 seconds
Epoch 12 accuracy: 67.73%
Batch 10, Loss: 0.7551
Batch 20, Loss: 0.7396
Batch 30, Loss: 0.7359
Batch 40, Loss: 0.7188
Batch 50, Loss: 0.7003
Batch 60, Loss: 0.7428
Batch 70, Loss: 0.7512
Batch 80, Loss: 0.7192
Batch 90, Loss: 0.7533
Batch 100, Loss: 0.7320
Batch 110, Loss: 0.7429
Batch 120, Loss: 0.7271
Batch 130, Loss: 0.7080
Batch 140, Loss: 0.6949
Batch 150, Loss: 0.7623
Batch 160, Loss: 0.7320
Batch 170, Loss: 0.7110
Batch 180, Loss: 0.7551
Batch 190, Loss: 0.7370
Batch 200, Loss: 0.7690
Batch 210, Loss: 0.7288
Batch 220, Loss: 0.6870
Batch 230, Loss: 0.7114
Batch 240, Loss: 0.6917
Batch 250, Loss: 0.6986
Batch 260, Loss: 0.7258
Batch 270, Loss: 0.7175
Batch 280, Loss: 0.7527
Batch 290, Loss: 0.7305
Batch 300, Loss: 0.7057
Batch 310, Loss: 0.7246
Batch 320, Loss: 0.7687
Batch 330, Loss: 0.7354
Batch 340, Loss: 0.7226
Batch 350, Loss: 0.7198
Batch 360, Loss: 0.7438
Batch 370, Loss: 0.7520
Batch 380, Loss: 0.7292
Batch 390, Loss: 0.7163
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.022773504257202 seconds
Epoch 13 accuracy: 74.94%
Batch 10, Loss: 0.6860
Batch 20, Loss: 0.6675
Batch 30, Loss: 0.7665
Batch 40, Loss: 0.6965
Batch 50, Loss: 0.7046
Batch 60, Loss: 0.7071
Batch 70, Loss: 0.7161
Batch 80, Loss: 0.7232
Batch 90, Loss: 0.7554
Batch 100, Loss: 0.7247
Batch 110, Loss: 0.7223
Batch 120, Loss: 0.6769
Batch 130, Loss: 0.6571
Batch 140, Loss: 0.7129
Batch 150, Loss: 0.7540
Batch 160, Loss: 0.7358
Batch 170, Loss: 0.6960
Batch 180, Loss: 0.7140
Batch 190, Loss: 0.7168
Batch 200, Loss: 0.6909
Batch 210, Loss: 0.7377
Batch 220, Loss: 0.7338
Batch 230, Loss: 0.6992
Batch 240, Loss: 0.7117
Batch 250, Loss: 0.7158
Batch 260, Loss: 0.6814
Batch 270, Loss: 0.7129
Batch 280, Loss: 0.7500
Batch 290, Loss: 0.7169
Batch 300, Loss: 0.7224
Batch 310, Loss: 0.7430
Batch 320, Loss: 0.6832
Batch 330, Loss: 0.7336
Batch 340, Loss: 0.6873
Batch 350, Loss: 0.6856
Batch 360, Loss: 0.7242
Batch 370, Loss: 0.7024
Batch 380, Loss: 0.6775
Batch 390, Loss: 0.7030
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.132766008377075 seconds
Epoch 14 accuracy: 75.59%
Batch 10, Loss: 0.6646
Batch 20, Loss: 0.6764
Batch 30, Loss: 0.7159
Batch 40, Loss: 0.7068
Batch 50, Loss: 0.7232
Batch 60, Loss: 0.6943
Batch 70, Loss: 0.7309
Batch 80, Loss: 0.6981
Batch 90, Loss: 0.6453
Batch 100, Loss: 0.6964
Batch 110, Loss: 0.6835
Batch 120, Loss: 0.6839
Batch 130, Loss: 0.6638
Batch 140, Loss: 0.6757
Batch 150, Loss: 0.6569
Batch 160, Loss: 0.6643
Batch 170, Loss: 0.6998
Batch 180, Loss: 0.6655
Batch 190, Loss: 0.6394
Batch 200, Loss: 0.6872
Batch 210, Loss: 0.7440
Batch 220, Loss: 0.6798
Batch 230, Loss: 0.6348
Batch 240, Loss: 0.7190
Batch 250, Loss: 0.7190
Batch 260, Loss: 0.7086
Batch 270, Loss: 0.7219
Batch 280, Loss: 0.6633
Batch 290, Loss: 0.6818
Batch 300, Loss: 0.7006
Batch 310, Loss: 0.6822
Batch 320, Loss: 0.7088
Batch 330, Loss: 0.6436
Batch 340, Loss: 0.6970
Batch 350, Loss: 0.6901
Batch 360, Loss: 0.7295
Batch 370, Loss: 0.7059
Batch 380, Loss: 0.6713
Batch 390, Loss: 0.6827
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.15327286720276 seconds
Epoch 15 accuracy: 76.35%
Batch 10, Loss: 0.6707
Batch 20, Loss: 0.6864
Batch 30, Loss: 0.6568
Batch 40, Loss: 0.6647
Batch 50, Loss: 0.6871
Batch 60, Loss: 0.6796
Batch 70, Loss: 0.6666
Batch 80, Loss: 0.7014
Batch 90, Loss: 0.6788
Batch 100, Loss: 0.6857
Batch 110, Loss: 0.6725
Batch 120, Loss: 0.6761
Batch 130, Loss: 0.6710
Batch 140, Loss: 0.7151
Batch 150, Loss: 0.6803
Batch 160, Loss: 0.6520
Batch 170, Loss: 0.6645
Batch 180, Loss: 0.6769
Batch 190, Loss: 0.7098
Batch 200, Loss: 0.6950
Batch 210, Loss: 0.7072
Batch 220, Loss: 0.6438
Batch 230, Loss: 0.6609
Batch 240, Loss: 0.6875
Batch 250, Loss: 0.6934
Batch 260, Loss: 0.6629
Batch 270, Loss: 0.6426
Batch 280, Loss: 0.6563
Batch 290, Loss: 0.6799
Batch 300, Loss: 0.6351
Batch 310, Loss: 0.6989
Batch 320, Loss: 0.6667
Batch 330, Loss: 0.7062
Batch 340, Loss: 0.6370
Batch 350, Loss: 0.6887
Batch 360, Loss: 0.6904
Batch 370, Loss: 0.6515
Batch 380, Loss: 0.6927
Batch 390, Loss: 0.6914
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.038330793380737 seconds
Epoch 16 accuracy: 79.5%
Batch 10, Loss: 0.7003
Batch 20, Loss: 0.6631
Batch 30, Loss: 0.6977
Batch 40, Loss: 0.6737
Batch 50, Loss: 0.6806
Batch 60, Loss: 0.6294
Batch 70, Loss: 0.7174
Batch 80, Loss: 0.6424
Batch 90, Loss: 0.6215
Batch 100, Loss: 0.6621
Batch 110, Loss: 0.7308
Batch 120, Loss: 0.6840
Batch 130, Loss: 0.6715
Batch 140, Loss: 0.6830
Batch 150, Loss: 0.6654
Batch 160, Loss: 0.6798
Batch 170, Loss: 0.7153
Batch 180, Loss: 0.6663
Batch 190, Loss: 0.7201
Batch 200, Loss: 0.6868
Batch 210, Loss: 0.6399
Batch 220, Loss: 0.6690
Batch 230, Loss: 0.6602
Batch 240, Loss: 0.6869
Batch 250, Loss: 0.6559
Batch 260, Loss: 0.6869
Batch 270, Loss: 0.6413
Batch 280, Loss: 0.6829
Batch 290, Loss: 0.6336
Batch 300, Loss: 0.6743
Batch 310, Loss: 0.6631
Batch 320, Loss: 0.6849
Batch 330, Loss: 0.6978
Batch 340, Loss: 0.6718
Batch 350, Loss: 0.6649
Batch 360, Loss: 0.6763
Batch 370, Loss: 0.6746
Batch 380, Loss: 0.6892
Batch 390, Loss: 0.6968
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.053677320480347 seconds
Epoch 17 accuracy: 79.74%
Batch 10, Loss: 0.6360
Batch 20, Loss: 0.6672
Batch 30, Loss: 0.6781
Batch 40, Loss: 0.6402
Batch 50, Loss: 0.6867
Batch 60, Loss: 0.6432
Batch 70, Loss: 0.6583
Batch 80, Loss: 0.6569
Batch 90, Loss: 0.6127
Batch 100, Loss: 0.6393
Batch 110, Loss: 0.7126
Batch 120, Loss: 0.6731
Batch 130, Loss: 0.6631
Batch 140, Loss: 0.6457
Batch 150, Loss: 0.6584
Batch 160, Loss: 0.6589
Batch 170, Loss: 0.6278
Batch 180, Loss: 0.6723
Batch 190, Loss: 0.6158
Batch 200, Loss: 0.6162
Batch 210, Loss: 0.6850
Batch 220, Loss: 0.6899
Batch 230, Loss: 0.6441
Batch 240, Loss: 0.6187
Batch 250, Loss: 0.6392
Batch 260, Loss: 0.6957
Batch 270, Loss: 0.6682
Batch 280, Loss: 0.6601
Batch 290, Loss: 0.6737
Batch 300, Loss: 0.6845
Batch 310, Loss: 0.6870
Batch 320, Loss: 0.6812
Batch 330, Loss: 0.6669
Batch 340, Loss: 0.6736
Batch 350, Loss: 0.6399
Batch 360, Loss: 0.6601
Batch 370, Loss: 0.6415
Batch 380, Loss: 0.6622
Batch 390, Loss: 0.6741
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.047536373138428 seconds
Epoch 18 accuracy: 76.1%
Batch 10, Loss: 0.6576
Batch 20, Loss: 0.6687
Batch 30, Loss: 0.6603
Batch 40, Loss: 0.6381
Batch 50, Loss: 0.6512
Batch 60, Loss: 0.6365
Batch 70, Loss: 0.6334
Batch 80, Loss: 0.6424
Batch 90, Loss: 0.6450
Batch 100, Loss: 0.6372
Batch 110, Loss: 0.6539
Batch 120, Loss: 0.6507
Batch 130, Loss: 0.6071
Batch 140, Loss: 0.6498
Batch 150, Loss: 0.6071
Batch 160, Loss: 0.6480
Batch 170, Loss: 0.6302
Batch 180, Loss: 0.6419
Batch 190, Loss: 0.6397
Batch 200, Loss: 0.6375
Batch 210, Loss: 0.6292
Batch 220, Loss: 0.6883
Batch 230, Loss: 0.7113
Batch 240, Loss: 0.6333
Batch 250, Loss: 0.6435
Batch 260, Loss: 0.6706
Batch 270, Loss: 0.6536
Batch 280, Loss: 0.6477
Batch 290, Loss: 0.6839
Batch 300, Loss: 0.6710
Batch 310, Loss: 0.6558
Batch 320, Loss: 0.6458
Batch 330, Loss: 0.6133
Batch 340, Loss: 0.6135
Batch 350, Loss: 0.6463
Batch 360, Loss: 0.6880
Batch 370, Loss: 0.7021
Batch 380, Loss: 0.6563
Batch 390, Loss: 0.6198
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.158804416656494 seconds
Epoch 19 accuracy: 79.61%
Batch 10, Loss: 0.6403
Batch 20, Loss: 0.6176
Batch 30, Loss: 0.6327
Batch 40, Loss: 0.6546
Batch 50, Loss: 0.6722
Batch 60, Loss: 0.6121
Batch 70, Loss: 0.6222
Batch 80, Loss: 0.6664
Batch 90, Loss: 0.6383
Batch 100, Loss: 0.6464
Batch 110, Loss: 0.6325
Batch 120, Loss: 0.6285
Batch 130, Loss: 0.6747
Batch 140, Loss: 0.6160
Batch 150, Loss: 0.6295
Batch 160, Loss: 0.6581
Batch 170, Loss: 0.6582
Batch 180, Loss: 0.6866
Batch 190, Loss: 0.6483
Batch 200, Loss: 0.6545
Batch 210, Loss: 0.6714
Batch 220, Loss: 0.6399
Batch 230, Loss: 0.6377
Batch 240, Loss: 0.5992
Batch 250, Loss: 0.6164
Batch 260, Loss: 0.6387
Batch 270, Loss: 0.6325
Batch 280, Loss: 0.6538
Batch 290, Loss: 0.6857
Batch 300, Loss: 0.6385
Batch 310, Loss: 0.6085
Batch 320, Loss: 0.6361
Batch 330, Loss: 0.6384
Batch 340, Loss: 0.6083
Batch 350, Loss: 0.6440
Batch 360, Loss: 0.6348
Batch 370, Loss: 0.6882
Batch 380, Loss: 0.6164
Batch 390, Loss: 0.6383
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.17367672920227 seconds
Epoch 20 accuracy: 77.01%
Batch 10, Loss: 0.6407
Batch 20, Loss: 0.5954
Batch 30, Loss: 0.6109
Batch 40, Loss: 0.6173
Batch 50, Loss: 0.6279
Batch 60, Loss: 0.6163
Batch 70, Loss: 0.6202
Batch 80, Loss: 0.6336
Batch 90, Loss: 0.6281
Batch 100, Loss: 0.6134
Batch 110, Loss: 0.6557
Batch 120, Loss: 0.6493
Batch 130, Loss: 0.6304
Batch 140, Loss: 0.6268
Batch 150, Loss: 0.6215
Batch 160, Loss: 0.6274
Batch 170, Loss: 0.6524
Batch 180, Loss: 0.6143
Batch 190, Loss: 0.6440
Batch 200, Loss: 0.6377
Batch 210, Loss: 0.6508
Batch 220, Loss: 0.6384
Batch 230, Loss: 0.6681
Batch 240, Loss: 0.6129
Batch 250, Loss: 0.6323
Batch 260, Loss: 0.6398
Batch 270, Loss: 0.6196
Batch 280, Loss: 0.5854
Batch 290, Loss: 0.6148
Batch 300, Loss: 0.6578
Batch 310, Loss: 0.6295
Batch 320, Loss: 0.6688
Batch 330, Loss: 0.6646
Batch 340, Loss: 0.6239
Batch 350, Loss: 0.6168
Batch 360, Loss: 0.6158
Batch 370, Loss: 0.6578
Batch 380, Loss: 0.6200
Batch 390, Loss: 0.6324
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.14056634902954 seconds
Epoch 21 accuracy: 73.84%
Batch 10, Loss: 0.6224
Batch 20, Loss: 0.6155
Batch 30, Loss: 0.6316
Batch 40, Loss: 0.6339
Batch 50, Loss: 0.6420
Batch 60, Loss: 0.6037
Batch 70, Loss: 0.6224
Batch 80, Loss: 0.6256
Batch 90, Loss: 0.6094
Batch 100, Loss: 0.6170
Batch 110, Loss: 0.6519
Batch 120, Loss: 0.6105
Batch 130, Loss: 0.5930
Batch 140, Loss: 0.6313
Batch 150, Loss: 0.6210
Batch 160, Loss: 0.6339
Batch 170, Loss: 0.6550
Batch 180, Loss: 0.6492
Batch 190, Loss: 0.6421
Batch 200, Loss: 0.6310
Batch 210, Loss: 0.6325
Batch 220, Loss: 0.6093
Batch 230, Loss: 0.6098
Batch 240, Loss: 0.6138
Batch 250, Loss: 0.6303
Batch 260, Loss: 0.6260
Batch 270, Loss: 0.6492
Batch 280, Loss: 0.6617
Batch 290, Loss: 0.6360
Batch 300, Loss: 0.6549
Batch 310, Loss: 0.6422
Batch 320, Loss: 0.6338
Batch 330, Loss: 0.6160
Batch 340, Loss: 0.6074
Batch 350, Loss: 0.5989
Batch 360, Loss: 0.5913
Batch 370, Loss: 0.6316
Batch 380, Loss: 0.6248
Batch 390, Loss: 0.5921
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.064000368118286 seconds
Epoch 22 accuracy: 81.61%
Batch 10, Loss: 0.6295
Batch 20, Loss: 0.6494
Batch 30, Loss: 0.6066
Batch 40, Loss: 0.6507
Batch 50, Loss: 0.6291
Batch 60, Loss: 0.6179
Batch 70, Loss: 0.6635
Batch 80, Loss: 0.6472
Batch 90, Loss: 0.6768
Batch 100, Loss: 0.6448
Batch 110, Loss: 0.6455
Batch 120, Loss: 0.5973
Batch 130, Loss: 0.6243
Batch 140, Loss: 0.5798
Batch 150, Loss: 0.6112
Batch 160, Loss: 0.6373
Batch 170, Loss: 0.6060
Batch 180, Loss: 0.6378
Batch 190, Loss: 0.6244
Batch 200, Loss: 0.6297
Batch 210, Loss: 0.6080
Batch 220, Loss: 0.5964
Batch 230, Loss: 0.6262
Batch 240, Loss: 0.6108
Batch 250, Loss: 0.6306
Batch 260, Loss: 0.6419
Batch 270, Loss: 0.6053
Batch 280, Loss: 0.6209
Batch 290, Loss: 0.5821
Batch 300, Loss: 0.5822
Batch 310, Loss: 0.6436
Batch 320, Loss: 0.6467
Batch 330, Loss: 0.6253
Batch 340, Loss: 0.6559
Batch 350, Loss: 0.6107
Batch 360, Loss: 0.6527
Batch 370, Loss: 0.6799
Batch 380, Loss: 0.6163
Batch 390, Loss: 0.6268
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.129981994628906 seconds
Epoch 23 accuracy: 82.56%
Batch 10, Loss: 0.6117
Batch 20, Loss: 0.6491
Batch 30, Loss: 0.5655
Batch 40, Loss: 0.5759
Batch 50, Loss: 0.6053
Batch 60, Loss: 0.5850
Batch 70, Loss: 0.6156
Batch 80, Loss: 0.6154
Batch 90, Loss: 0.5892
Batch 100, Loss: 0.5944
Batch 110, Loss: 0.6064
Batch 120, Loss: 0.6260
Batch 130, Loss: 0.6096
Batch 140, Loss: 0.6239
Batch 150, Loss: 0.6270
Batch 160, Loss: 0.6407
Batch 170, Loss: 0.5703
Batch 180, Loss: 0.6253
Batch 190, Loss: 0.6585
Batch 200, Loss: 0.6345
Batch 210, Loss: 0.6362
Batch 220, Loss: 0.6240
Batch 230, Loss: 0.6446
Batch 240, Loss: 0.5840
Batch 250, Loss: 0.5954
Batch 260, Loss: 0.6256
Batch 270, Loss: 0.6172
Batch 280, Loss: 0.6273
Batch 290, Loss: 0.6016
Batch 300, Loss: 0.5872
Batch 310, Loss: 0.5954
Batch 320, Loss: 0.6522
Batch 330, Loss: 0.6427
Batch 340, Loss: 0.5984
Batch 350, Loss: 0.5959
Batch 360, Loss: 0.6174
Batch 370, Loss: 0.6279
Batch 380, Loss: 0.5625
Batch 390, Loss: 0.5807
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.181634664535522 seconds
Epoch 24 accuracy: 80.37%
Batch 10, Loss: 0.6515
Batch 20, Loss: 0.5963
Batch 30, Loss: 0.6166
Batch 40, Loss: 0.6199
Batch 50, Loss: 0.6384
Batch 60, Loss: 0.6085
Batch 70, Loss: 0.5898
Batch 80, Loss: 0.6213
Batch 90, Loss: 0.6310
Batch 100, Loss: 0.5839
Batch 110, Loss: 0.6025
Batch 120, Loss: 0.6117
Batch 130, Loss: 0.6130
Batch 140, Loss: 0.6515
Batch 150, Loss: 0.5731
Batch 160, Loss: 0.6320
Batch 170, Loss: 0.5984
Batch 180, Loss: 0.5925
Batch 190, Loss: 0.5811
Batch 200, Loss: 0.6298
Batch 210, Loss: 0.5927
Batch 220, Loss: 0.5846
Batch 230, Loss: 0.5773
Batch 240, Loss: 0.6430
Batch 250, Loss: 0.6546
Batch 260, Loss: 0.6109
Batch 270, Loss: 0.5908
Batch 280, Loss: 0.6004
Batch 290, Loss: 0.5752
Batch 300, Loss: 0.6403
Batch 310, Loss: 0.6109
Batch 320, Loss: 0.5902
Batch 330, Loss: 0.6585
Batch 340, Loss: 0.6198
Batch 350, Loss: 0.5996
Batch 360, Loss: 0.6148
Batch 370, Loss: 0.6253
Batch 380, Loss: 0.6123
Batch 390, Loss: 0.5843
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.192115306854248 seconds
Epoch 25 accuracy: 81.04%
Batch 10, Loss: 0.5775
Batch 20, Loss: 0.5695
Batch 30, Loss: 0.6034
Batch 40, Loss: 0.6173
Batch 50, Loss: 0.6060
Batch 60, Loss: 0.6382
Batch 70, Loss: 0.6112
Batch 80, Loss: 0.6579
Batch 90, Loss: 0.5853
Batch 100, Loss: 0.6244
Batch 110, Loss: 0.6476
Batch 120, Loss: 0.6099
Batch 130, Loss: 0.6129
Batch 140, Loss: 0.5998
Batch 150, Loss: 0.5519
Batch 160, Loss: 0.6143
Batch 170, Loss: 0.5943
Batch 180, Loss: 0.6150
Batch 190, Loss: 0.6671
Batch 200, Loss: 0.5960
Batch 210, Loss: 0.5827
Batch 220, Loss: 0.5864
Batch 230, Loss: 0.5988
Batch 240, Loss: 0.6200
Batch 250, Loss: 0.5717
Batch 260, Loss: 0.6319
Batch 270, Loss: 0.6019
Batch 280, Loss: 0.5822
Batch 290, Loss: 0.6149
Batch 300, Loss: 0.6175
Batch 310, Loss: 0.5793
Batch 320, Loss: 0.5948
Batch 330, Loss: 0.6093
Batch 340, Loss: 0.6404
Batch 350, Loss: 0.6254
Batch 360, Loss: 0.6155
Batch 370, Loss: 0.5803
Batch 380, Loss: 0.5898
Batch 390, Loss: 0.5646
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.231646299362183 seconds
Epoch 26 accuracy: 79.05%
Batch 10, Loss: 0.6020
Batch 20, Loss: 0.6315
Batch 30, Loss: 0.5871
Batch 40, Loss: 0.5901
Batch 50, Loss: 0.6390
Batch 60, Loss: 0.6267
Batch 70, Loss: 0.5932
Batch 80, Loss: 0.6236
Batch 90, Loss: 0.5920
Batch 100, Loss: 0.5841
Batch 110, Loss: 0.6138
Batch 120, Loss: 0.6132
Batch 130, Loss: 0.6148
Batch 140, Loss: 0.5451
Batch 150, Loss: 0.5988
Batch 160, Loss: 0.5783
Batch 170, Loss: 0.6005
Batch 180, Loss: 0.6132
Batch 190, Loss: 0.5941
Batch 200, Loss: 0.6386
Batch 210, Loss: 0.5884
Batch 220, Loss: 0.5998
Batch 230, Loss: 0.5727
Batch 240, Loss: 0.6202
Batch 250, Loss: 0.5783
Batch 260, Loss: 0.6233
Batch 270, Loss: 0.6441
Batch 280, Loss: 0.6093
Batch 290, Loss: 0.6014
Batch 300, Loss: 0.5720
Batch 310, Loss: 0.6184
Batch 320, Loss: 0.5729
Batch 330, Loss: 0.6006
Batch 340, Loss: 0.6379
Batch 350, Loss: 0.5907
Batch 360, Loss: 0.6052
Batch 370, Loss: 0.5767
Batch 380, Loss: 0.6098
Batch 390, Loss: 0.5658
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.15657687187195 seconds
Epoch 27 accuracy: 81.84%
Batch 10, Loss: 0.5634
Batch 20, Loss: 0.6317
Batch 30, Loss: 0.5510
Batch 40, Loss: 0.6150
Batch 50, Loss: 0.5981
Batch 60, Loss: 0.6534
Batch 70, Loss: 0.6182
Batch 80, Loss: 0.6148
Batch 90, Loss: 0.6562
Batch 100, Loss: 0.6156
Batch 110, Loss: 0.6205
Batch 120, Loss: 0.5826
Batch 130, Loss: 0.6125
Batch 140, Loss: 0.5750
Batch 150, Loss: 0.6106
Batch 160, Loss: 0.5952
Batch 170, Loss: 0.5812
Batch 180, Loss: 0.5798
Batch 190, Loss: 0.6077
Batch 200, Loss: 0.6038
Batch 210, Loss: 0.5869
Batch 220, Loss: 0.5606
Batch 230, Loss: 0.5820
Batch 240, Loss: 0.5950
Batch 250, Loss: 0.6006
Batch 260, Loss: 0.5562
Batch 270, Loss: 0.5766
Batch 280, Loss: 0.5722
Batch 290, Loss: 0.6161
Batch 300, Loss: 0.6035
Batch 310, Loss: 0.6366
Batch 320, Loss: 0.5923
Batch 330, Loss: 0.5950
Batch 340, Loss: 0.6196
Batch 350, Loss: 0.5873
Batch 360, Loss: 0.5888
Batch 370, Loss: 0.5725
Batch 380, Loss: 0.5971
Batch 390, Loss: 0.5859
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.02259922027588 seconds
Epoch 28 accuracy: 77.44%
Batch 10, Loss: 0.6081
Batch 20, Loss: 0.5901
Batch 30, Loss: 0.5942
Batch 40, Loss: 0.6006
Batch 50, Loss: 0.5606
Batch 60, Loss: 0.5853
Batch 70, Loss: 0.6127
Batch 80, Loss: 0.6064
Batch 90, Loss: 0.6115
Batch 100, Loss: 0.5512
Batch 110, Loss: 0.5672
Batch 120, Loss: 0.6067
Batch 130, Loss: 0.5922
Batch 140, Loss: 0.6222
Batch 150, Loss: 0.5907
Batch 160, Loss: 0.5774
Batch 170, Loss: 0.5843
Batch 180, Loss: 0.5829
Batch 190, Loss: 0.5476
Batch 200, Loss: 0.5991
Batch 210, Loss: 0.6340
Batch 220, Loss: 0.5932
Batch 230, Loss: 0.5829
Batch 240, Loss: 0.5821
Batch 250, Loss: 0.5940
Batch 260, Loss: 0.5813
Batch 270, Loss: 0.5918
Batch 280, Loss: 0.5819
Batch 290, Loss: 0.5609
Batch 300, Loss: 0.5896
Batch 310, Loss: 0.6421
Batch 320, Loss: 0.5656
Batch 330, Loss: 0.5913
Batch 340, Loss: 0.5954
Batch 350, Loss: 0.5963
Batch 360, Loss: 0.6220
Batch 370, Loss: 0.5872
Batch 380, Loss: 0.6177
Batch 390, Loss: 0.5847
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.022359371185303 seconds
Epoch 29 accuracy: 81.03%
Batch 10, Loss: 0.5949
Batch 20, Loss: 0.5683
Batch 30, Loss: 0.5675
Batch 40, Loss: 0.5739
Batch 50, Loss: 0.5889
Batch 60, Loss: 0.6051
Batch 70, Loss: 0.5893
Batch 80, Loss: 0.6578
Batch 90, Loss: 0.5961
Batch 100, Loss: 0.5932
Batch 110, Loss: 0.5476
Batch 120, Loss: 0.5959
Batch 130, Loss: 0.6028
Batch 140, Loss: 0.5839
Batch 150, Loss: 0.5793
Batch 160, Loss: 0.5439
Batch 170, Loss: 0.5641
Batch 180, Loss: 0.6276
Batch 190, Loss: 0.6246
Batch 200, Loss: 0.5949
Batch 210, Loss: 0.5904
Batch 220, Loss: 0.5778
Batch 230, Loss: 0.5630
Batch 240, Loss: 0.6354
Batch 250, Loss: 0.5744
Batch 260, Loss: 0.5609
Batch 270, Loss: 0.5496
Batch 280, Loss: 0.6483
Batch 290, Loss: 0.5699
Batch 300, Loss: 0.5740
Batch 310, Loss: 0.5788
Batch 320, Loss: 0.6230
Batch 330, Loss: 0.5493
Batch 340, Loss: 0.5879
Batch 350, Loss: 0.6086
Batch 360, Loss: 0.5770
Batch 370, Loss: 0.5803
Batch 380, Loss: 0.5845
Batch 390, Loss: 0.5988
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.067685842514038 seconds
Epoch 30 accuracy: 81.95%
Batch 10, Loss: 0.5566
Batch 20, Loss: 0.5962
Batch 30, Loss: 0.6052
Batch 40, Loss: 0.5661
Batch 50, Loss: 0.6016
Batch 60, Loss: 0.5389
Batch 70, Loss: 0.5698
Batch 80, Loss: 0.5949
Batch 90, Loss: 0.5667
Batch 100, Loss: 0.5565
Batch 110, Loss: 0.5801
Batch 120, Loss: 0.5664
Batch 130, Loss: 0.5490
Batch 140, Loss: 0.5409
Batch 150, Loss: 0.6080
Batch 160, Loss: 0.5688
Batch 170, Loss: 0.5582
Batch 180, Loss: 0.6005
Batch 190, Loss: 0.5800
Batch 200, Loss: 0.6048
Batch 210, Loss: 0.5988
Batch 220, Loss: 0.5869
Batch 230, Loss: 0.6120
Batch 240, Loss: 0.6033
Batch 250, Loss: 0.5972
Batch 260, Loss: 0.5610
Batch 270, Loss: 0.5962
Batch 280, Loss: 0.5881
Batch 290, Loss: 0.6107
Batch 300, Loss: 0.5631
Batch 310, Loss: 0.6048
Batch 320, Loss: 0.5978
Batch 330, Loss: 0.6029
Batch 340, Loss: 0.6059
Batch 350, Loss: 0.5750
Batch 360, Loss: 0.5945
Batch 370, Loss: 0.6094
Batch 380, Loss: 0.5731
Batch 390, Loss: 0.6004
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.108495473861694 seconds
Epoch 31 accuracy: 76.63%
Batch 10, Loss: 0.5526
Batch 20, Loss: 0.5911
Batch 30, Loss: 0.5726
Batch 40, Loss: 0.5289
Batch 50, Loss: 0.5779
Batch 60, Loss: 0.5865
Batch 70, Loss: 0.5623
Batch 80, Loss: 0.6120
Batch 90, Loss: 0.5592
Batch 100, Loss: 0.5860
Batch 110, Loss: 0.5891
Batch 120, Loss: 0.5585
Batch 130, Loss: 0.5948
Batch 140, Loss: 0.5889
Batch 150, Loss: 0.5966
Batch 160, Loss: 0.5719
Batch 170, Loss: 0.5904
Batch 180, Loss: 0.5416
Batch 190, Loss: 0.6113
Batch 200, Loss: 0.5596
Batch 210, Loss: 0.6109
Batch 220, Loss: 0.5889
Batch 230, Loss: 0.5229
Batch 240, Loss: 0.5376
Batch 250, Loss: 0.6081
Batch 260, Loss: 0.6003
Batch 270, Loss: 0.5720
Batch 280, Loss: 0.5838
Batch 290, Loss: 0.5619
Batch 300, Loss: 0.5601
Batch 310, Loss: 0.5749
Batch 320, Loss: 0.5738
Batch 330, Loss: 0.5705
Batch 340, Loss: 0.5389
Batch 350, Loss: 0.5687
Batch 360, Loss: 0.5929
Batch 370, Loss: 0.5802
Batch 380, Loss: 0.5852
Batch 390, Loss: 0.6040
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.053756952285767 seconds
Epoch 32 accuracy: 78.73%
Batch 10, Loss: 0.5957
Batch 20, Loss: 0.6082
Batch 30, Loss: 0.5808
Batch 40, Loss: 0.5784
Batch 50, Loss: 0.5970
Batch 60, Loss: 0.5564
Batch 70, Loss: 0.5363
Batch 80, Loss: 0.5464
Batch 90, Loss: 0.5756
Batch 100, Loss: 0.5809
Batch 110, Loss: 0.5554
Batch 120, Loss: 0.5875
Batch 130, Loss: 0.5997
Batch 140, Loss: 0.5729
Batch 150, Loss: 0.5537
Batch 160, Loss: 0.5907
Batch 170, Loss: 0.5682
Batch 180, Loss: 0.5987
Batch 190, Loss: 0.5567
Batch 200, Loss: 0.5305
Batch 210, Loss: 0.5743
Batch 220, Loss: 0.5938
Batch 230, Loss: 0.5855
Batch 240, Loss: 0.5233
Batch 250, Loss: 0.5717
Batch 260, Loss: 0.5729
Batch 270, Loss: 0.5564
Batch 280, Loss: 0.6248
Batch 290, Loss: 0.5732
Batch 300, Loss: 0.6057
Batch 310, Loss: 0.5864
Batch 320, Loss: 0.5759
Batch 330, Loss: 0.5847
Batch 340, Loss: 0.5441
Batch 350, Loss: 0.6090
Batch 360, Loss: 0.5720
Batch 370, Loss: 0.5851
Batch 380, Loss: 0.6137
Batch 390, Loss: 0.5742
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.0506534576416 seconds
Epoch 33 accuracy: 74.02%
Batch 10, Loss: 0.5555
Batch 20, Loss: 0.5982
Batch 30, Loss: 0.6151
Batch 40, Loss: 0.5932
Batch 50, Loss: 0.6058
Batch 60, Loss: 0.5738
Batch 70, Loss: 0.5915
Batch 80, Loss: 0.5639
Batch 90, Loss: 0.5933
Batch 100, Loss: 0.5727
Batch 110, Loss: 0.6089
Batch 120, Loss: 0.6039
Batch 130, Loss: 0.6044
Batch 140, Loss: 0.5246
Batch 150, Loss: 0.5583
Batch 160, Loss: 0.5846
Batch 170, Loss: 0.5575
Batch 180, Loss: 0.5750
Batch 190, Loss: 0.5986
Batch 200, Loss: 0.5920
Batch 210, Loss: 0.5844
Batch 220, Loss: 0.5569
Batch 230, Loss: 0.5162
Batch 240, Loss: 0.6138
Batch 250, Loss: 0.5965
Batch 260, Loss: 0.5881
Batch 270, Loss: 0.5653
Batch 280, Loss: 0.6070
Batch 290, Loss: 0.5570
Batch 300, Loss: 0.5379
Batch 310, Loss: 0.5375
Batch 320, Loss: 0.6297
Batch 330, Loss: 0.5963
Batch 340, Loss: 0.5562
Batch 350, Loss: 0.5611
Batch 360, Loss: 0.5868
Batch 370, Loss: 0.5443
Batch 380, Loss: 0.5432
Batch 390, Loss: 0.5901
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.20422625541687 seconds
Epoch 34 accuracy: 81.56%
Batch 10, Loss: 0.6077
Batch 20, Loss: 0.5560
Batch 30, Loss: 0.5324
Batch 40, Loss: 0.5555
Batch 50, Loss: 0.5769
Batch 60, Loss: 0.6043
Batch 70, Loss: 0.5791
Batch 80, Loss: 0.5726
Batch 90, Loss: 0.5611
Batch 100, Loss: 0.5610
Batch 110, Loss: 0.5794
Batch 120, Loss: 0.5994
Batch 130, Loss: 0.5285
Batch 140, Loss: 0.5769
Batch 150, Loss: 0.5824
Batch 160, Loss: 0.5799
Batch 170, Loss: 0.5697
Batch 180, Loss: 0.5691
Batch 190, Loss: 0.5729
Batch 200, Loss: 0.5578
Batch 210, Loss: 0.5589
Batch 220, Loss: 0.5866
Batch 230, Loss: 0.5762
Batch 240, Loss: 0.5577
Batch 250, Loss: 0.5803
Batch 260, Loss: 0.5373
Batch 270, Loss: 0.5768
Batch 280, Loss: 0.5412
Batch 290, Loss: 0.5793
Batch 300, Loss: 0.6039
Batch 310, Loss: 0.5668
Batch 320, Loss: 0.5338
Batch 330, Loss: 0.6403
Batch 340, Loss: 0.5687
Batch 350, Loss: 0.6116
Batch 360, Loss: 0.5576
Batch 370, Loss: 0.6034
Batch 380, Loss: 0.6114
Batch 390, Loss: 0.6146
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.124462127685547 seconds
Epoch 35 accuracy: 80.8%
Batch 10, Loss: 0.5471
Batch 20, Loss: 0.5658
Batch 30, Loss: 0.5565
Batch 40, Loss: 0.5381
Batch 50, Loss: 0.5756
Batch 60, Loss: 0.5933
Batch 70, Loss: 0.5606
Batch 80, Loss: 0.5787
Batch 90, Loss: 0.6095
Batch 100, Loss: 0.5858
Batch 110, Loss: 0.5758
Batch 120, Loss: 0.5774
Batch 130, Loss: 0.5789
Batch 140, Loss: 0.5529
Batch 150, Loss: 0.6095
Batch 160, Loss: 0.6143
Batch 170, Loss: 0.5592
Batch 180, Loss: 0.5748
Batch 190, Loss: 0.5822
Batch 200, Loss: 0.5774
Batch 210, Loss: 0.5969
Batch 220, Loss: 0.5726
Batch 230, Loss: 0.5610
Batch 240, Loss: 0.5604
Batch 250, Loss: 0.5803
Batch 260, Loss: 0.5564
Batch 270, Loss: 0.5471
Batch 280, Loss: 0.5847
Batch 290, Loss: 0.5541
Batch 300, Loss: 0.5706
Batch 310, Loss: 0.5797
Batch 320, Loss: 0.5695
Batch 330, Loss: 0.5690
Batch 340, Loss: 0.5525
Batch 350, Loss: 0.5722
Batch 360, Loss: 0.5834
Batch 370, Loss: 0.5476
Batch 380, Loss: 0.6082
Batch 390, Loss: 0.5624
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.14372444152832 seconds
Epoch 36 accuracy: 79.91%
Batch 10, Loss: 0.6153
Batch 20, Loss: 0.5635
Batch 30, Loss: 0.5779
Batch 40, Loss: 0.5618
Batch 50, Loss: 0.5497
Batch 60, Loss: 0.5761
Batch 70, Loss: 0.5562
Batch 80, Loss: 0.5182
Batch 90, Loss: 0.5515
Batch 100, Loss: 0.5454
Batch 110, Loss: 0.5400
Batch 120, Loss: 0.5397
Batch 130, Loss: 0.5476
Batch 140, Loss: 0.6122
Batch 150, Loss: 0.5838
Batch 160, Loss: 0.5710
Batch 170, Loss: 0.6179
Batch 180, Loss: 0.5826
Batch 190, Loss: 0.5506
Batch 200, Loss: 0.5600
Batch 210, Loss: 0.5687
Batch 220, Loss: 0.5394
Batch 230, Loss: 0.5814
Batch 240, Loss: 0.5657
Batch 250, Loss: 0.6138
Batch 260, Loss: 0.6141
Batch 270, Loss: 0.5590
Batch 280, Loss: 0.5710
Batch 290, Loss: 0.5597
Batch 300, Loss: 0.5765
Batch 310, Loss: 0.5760
Batch 320, Loss: 0.5094
Batch 330, Loss: 0.5582
Batch 340, Loss: 0.5657
Batch 350, Loss: 0.5545
Batch 360, Loss: 0.5660
Batch 370, Loss: 0.5855
Batch 380, Loss: 0.5303
Batch 390, Loss: 0.5842
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.056034088134766 seconds
Epoch 37 accuracy: 80.32%
Batch 10, Loss: 0.5855
Batch 20, Loss: 0.5599
Batch 30, Loss: 0.5924
Batch 40, Loss: 0.5293
Batch 50, Loss: 0.5358
Batch 60, Loss: 0.5419
Batch 70, Loss: 0.5738
Batch 80, Loss: 0.5651
Batch 90, Loss: 0.5486
Batch 100, Loss: 0.5604
Batch 110, Loss: 0.5690
Batch 120, Loss: 0.5326
Batch 130, Loss: 0.5777
Batch 140, Loss: 0.5932
Batch 150, Loss: 0.5799
Batch 160, Loss: 0.5652
Batch 170, Loss: 0.5990
Batch 180, Loss: 0.5536
Batch 190, Loss: 0.5654
Batch 200, Loss: 0.5742
Batch 210, Loss: 0.5609
Batch 220, Loss: 0.5305
Batch 230, Loss: 0.5684
Batch 240, Loss: 0.5963
Batch 250, Loss: 0.5866
Batch 260, Loss: 0.5493
Batch 270, Loss: 0.6232
Batch 280, Loss: 0.5563
Batch 290, Loss: 0.5588
Batch 300, Loss: 0.5722
Batch 310, Loss: 0.5617
Batch 320, Loss: 0.5736
Batch 330, Loss: 0.5385
Batch 340, Loss: 0.5813
Batch 350, Loss: 0.5291
Batch 360, Loss: 0.5875
Batch 370, Loss: 0.5484
Batch 380, Loss: 0.5453
Batch 390, Loss: 0.5626
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.147224187850952 seconds
Epoch 38 accuracy: 82.29%
Batch 10, Loss: 0.5775
Batch 20, Loss: 0.5654
Batch 30, Loss: 0.6070
Batch 40, Loss: 0.6105
Batch 50, Loss: 0.5762
Batch 60, Loss: 0.5351
Batch 70, Loss: 0.5533
Batch 80, Loss: 0.5612
Batch 90, Loss: 0.5419
Batch 100, Loss: 0.6100
Batch 110, Loss: 0.5570
Batch 120, Loss: 0.5220
Batch 130, Loss: 0.5749
Batch 140, Loss: 0.5790
Batch 150, Loss: 0.5622
Batch 160, Loss: 0.5554
Batch 170, Loss: 0.5572
Batch 180, Loss: 0.6013
Batch 190, Loss: 0.5612
Batch 200, Loss: 0.5687
Batch 210, Loss: 0.5712
Batch 220, Loss: 0.6007
Batch 230, Loss: 0.5805
Batch 240, Loss: 0.5432
Batch 250, Loss: 0.5659
Batch 260, Loss: 0.5455
Batch 270, Loss: 0.5105
Batch 280, Loss: 0.5838
Batch 290, Loss: 0.5671
Batch 300, Loss: 0.5762
Batch 310, Loss: 0.5345
Batch 320, Loss: 0.5563
Batch 330, Loss: 0.5993
Batch 340, Loss: 0.5713
Batch 350, Loss: 0.5620
Batch 360, Loss: 0.5700
Batch 370, Loss: 0.5805
Batch 380, Loss: 0.5638
Batch 390, Loss: 0.5933
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.074602603912354 seconds
Epoch 39 accuracy: 81.36%
Batch 10, Loss: 0.5749
Batch 20, Loss: 0.5230
Batch 30, Loss: 0.5643
Batch 40, Loss: 0.6007
Batch 50, Loss: 0.5489
Batch 60, Loss: 0.5763
Batch 70, Loss: 0.5327
Batch 80, Loss: 0.5468
Batch 90, Loss: 0.5783
Batch 100, Loss: 0.5288
Batch 110, Loss: 0.5369
Batch 120, Loss: 0.5565
Batch 130, Loss: 0.5578
Batch 140, Loss: 0.6138
Batch 150, Loss: 0.5634
Batch 160, Loss: 0.5465
Batch 170, Loss: 0.5802
Batch 180, Loss: 0.5587
Batch 190, Loss: 0.5313
Batch 200, Loss: 0.5682
Batch 210, Loss: 0.5892
Batch 220, Loss: 0.5905
Batch 230, Loss: 0.5867
Batch 240, Loss: 0.5481
Batch 250, Loss: 0.5989
Batch 260, Loss: 0.5615
Batch 270, Loss: 0.5911
Batch 280, Loss: 0.5400
Batch 290, Loss: 0.5832
Batch 300, Loss: 0.5514
Batch 310, Loss: 0.5786
Batch 320, Loss: 0.5312
Batch 330, Loss: 0.5793
Batch 340, Loss: 0.5234
Batch 350, Loss: 0.5597
Batch 360, Loss: 0.5480
Batch 370, Loss: 0.5419
Batch 380, Loss: 0.6383
Batch 390, Loss: 0.5602
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.080291748046875 seconds
Epoch 40 accuracy: 83.33%
Batch 10, Loss: 0.5518
Batch 20, Loss: 0.5391
Batch 30, Loss: 0.5415
Batch 40, Loss: 0.5401
Batch 50, Loss: 0.5492
Batch 60, Loss: 0.5553
Batch 70, Loss: 0.5755
Batch 80, Loss: 0.5595
Batch 90, Loss: 0.5645
Batch 100, Loss: 0.5450
Batch 110, Loss: 0.5399
Batch 120, Loss: 0.5455
Batch 130, Loss: 0.5569
Batch 140, Loss: 0.5378
Batch 150, Loss: 0.5463
Batch 160, Loss: 0.5593
Batch 170, Loss: 0.5637
Batch 180, Loss: 0.5356
Batch 190, Loss: 0.5595
Batch 200, Loss: 0.5516
Batch 210, Loss: 0.5793
Batch 220, Loss: 0.5833
Batch 230, Loss: 0.5505
Batch 240, Loss: 0.5578
Batch 250, Loss: 0.5568
Batch 260, Loss: 0.5394
Batch 270, Loss: 0.5251
Batch 280, Loss: 0.5866
Batch 290, Loss: 0.5755
Batch 300, Loss: 0.5708
Batch 310, Loss: 0.5518
Batch 320, Loss: 0.5581
Batch 330, Loss: 0.5624
Batch 340, Loss: 0.5719
Batch 350, Loss: 0.5692
Batch 360, Loss: 0.5616
Batch 370, Loss: 0.5785
Batch 380, Loss: 0.5643
Batch 390, Loss: 0.6150
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.112213373184204 seconds
Epoch 41 accuracy: 80.01%
Batch 10, Loss: 0.5650
Batch 20, Loss: 0.5661
Batch 30, Loss: 0.5614
Batch 40, Loss: 0.5605
Batch 50, Loss: 0.5457
Batch 60, Loss: 0.5477
Batch 70, Loss: 0.5497
Batch 80, Loss: 0.6003
Batch 90, Loss: 0.5459
Batch 100, Loss: 0.5443
Batch 110, Loss: 0.5206
Batch 120, Loss: 0.5936
Batch 130, Loss: 0.5435
Batch 140, Loss: 0.5404
Batch 150, Loss: 0.5464
Batch 160, Loss: 0.5392
Batch 170, Loss: 0.5659
Batch 180, Loss: 0.5617
Batch 190, Loss: 0.5727
Batch 200, Loss: 0.5580
Batch 210, Loss: 0.5574
Batch 220, Loss: 0.5468
Batch 230, Loss: 0.5576
Batch 240, Loss: 0.5508
Batch 250, Loss: 0.5785
Batch 260, Loss: 0.5444
Batch 270, Loss: 0.5589
Batch 280, Loss: 0.5518
Batch 290, Loss: 0.6013
Batch 300, Loss: 0.5381
Batch 310, Loss: 0.5677
Batch 320, Loss: 0.5515
Batch 330, Loss: 0.5939
Batch 340, Loss: 0.5398
Batch 350, Loss: 0.5523
Batch 360, Loss: 0.5242
Batch 370, Loss: 0.5671
Batch 380, Loss: 0.5823
Batch 390, Loss: 0.5234
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.10326385498047 seconds
Epoch 42 accuracy: 83.5%
Batch 10, Loss: 0.5596
Batch 20, Loss: 0.5241
Batch 30, Loss: 0.5736
Batch 40, Loss: 0.5157
Batch 50, Loss: 0.5189
Batch 60, Loss: 0.5501
Batch 70, Loss: 0.5704
Batch 80, Loss: 0.5838
Batch 90, Loss: 0.5199
Batch 100, Loss: 0.5244
Batch 110, Loss: 0.5564
Batch 120, Loss: 0.5807
Batch 130, Loss: 0.5724
Batch 140, Loss: 0.5593
Batch 150, Loss: 0.5687
Batch 160, Loss: 0.6075
Batch 170, Loss: 0.5714
Batch 180, Loss: 0.5332
Batch 190, Loss: 0.5490
Batch 200, Loss: 0.5070
Batch 210, Loss: 0.5572
Batch 220, Loss: 0.5788
Batch 230, Loss: 0.5915
Batch 240, Loss: 0.5748
Batch 250, Loss: 0.5489
Batch 260, Loss: 0.5879
Batch 270, Loss: 0.5939
Batch 280, Loss: 0.5929
Batch 290, Loss: 0.5716
Batch 300, Loss: 0.5792
Batch 310, Loss: 0.5624
Batch 320, Loss: 0.6069
Batch 330, Loss: 0.5396
Batch 340, Loss: 0.5582
Batch 350, Loss: 0.5328
Batch 360, Loss: 0.5910
Batch 370, Loss: 0.5768
Batch 380, Loss: 0.5430
Batch 390, Loss: 0.5633
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.06579351425171 seconds
Epoch 43 accuracy: 82.65%
Batch 10, Loss: 0.5371
Batch 20, Loss: 0.5514
Batch 30, Loss: 0.5437
Batch 40, Loss: 0.5500
Batch 50, Loss: 0.5452
Batch 60, Loss: 0.5236
Batch 70, Loss: 0.5518
Batch 80, Loss: 0.5783
Batch 90, Loss: 0.5452
Batch 100, Loss: 0.5195
Batch 110, Loss: 0.5155
Batch 120, Loss: 0.5521
Batch 130, Loss: 0.5394
Batch 140, Loss: 0.5619
Batch 150, Loss: 0.5598
Batch 160, Loss: 0.5245
Batch 170, Loss: 0.5591
Batch 180, Loss: 0.5681
Batch 190, Loss: 0.5554
Batch 200, Loss: 0.5964
Batch 210, Loss: 0.5714
Batch 220, Loss: 0.5679
Batch 230, Loss: 0.5800
Batch 240, Loss: 0.4945
Batch 250, Loss: 0.5792
Batch 260, Loss: 0.5405
Batch 270, Loss: 0.5678
Batch 280, Loss: 0.6020
Batch 290, Loss: 0.5171
Batch 300, Loss: 0.5438
Batch 310, Loss: 0.5594
Batch 320, Loss: 0.5789
Batch 330, Loss: 0.5424
Batch 340, Loss: 0.5193
Batch 350, Loss: 0.5497
Batch 360, Loss: 0.5467
Batch 370, Loss: 0.5649
Batch 380, Loss: 0.5337
Batch 390, Loss: 0.5666
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.042851448059082 seconds
Epoch 44 accuracy: 82.16%
Batch 10, Loss: 0.5867
Batch 20, Loss: 0.5256
Batch 30, Loss: 0.5487
Batch 40, Loss: 0.5465
Batch 50, Loss: 0.5131
Batch 60, Loss: 0.5000
Batch 70, Loss: 0.5072
Batch 80, Loss: 0.5408
Batch 90, Loss: 0.5958
Batch 100, Loss: 0.5576
Batch 110, Loss: 0.5631
Batch 120, Loss: 0.5778
Batch 130, Loss: 0.5518
Batch 140, Loss: 0.5579
Batch 150, Loss: 0.5834
Batch 160, Loss: 0.5697
Batch 170, Loss: 0.5506
Batch 180, Loss: 0.5448
Batch 190, Loss: 0.5535
Batch 200, Loss: 0.5370
Batch 210, Loss: 0.5449
Batch 220, Loss: 0.5741
Batch 230, Loss: 0.5223
Batch 240, Loss: 0.5312
Batch 250, Loss: 0.5668
Batch 260, Loss: 0.5749
Batch 270, Loss: 0.5536
Batch 280, Loss: 0.5165
Batch 290, Loss: 0.5269
Batch 300, Loss: 0.5488
Batch 310, Loss: 0.5287
Batch 320, Loss: 0.5434
Batch 330, Loss: 0.5344
Batch 340, Loss: 0.5320
Batch 350, Loss: 0.5473
Batch 360, Loss: 0.5273
Batch 370, Loss: 0.5492
Batch 380, Loss: 0.5285
Batch 390, Loss: 0.6029
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.04976773262024 seconds
Epoch 45 accuracy: 85.02%
Batch 10, Loss: 0.5621
Batch 20, Loss: 0.5245
Batch 30, Loss: 0.5220
Batch 40, Loss: 0.5504
Batch 50, Loss: 0.5404
Batch 60, Loss: 0.5539
Batch 70, Loss: 0.5183
Batch 80, Loss: 0.5369
Batch 90, Loss: 0.4930
Batch 100, Loss: 0.5363
Batch 110, Loss: 0.5434
Batch 120, Loss: 0.5645
Batch 130, Loss: 0.5006
Batch 140, Loss: 0.5321
Batch 150, Loss: 0.5492
Batch 160, Loss: 0.5519
Batch 170, Loss: 0.5769
Batch 180, Loss: 0.5649
Batch 190, Loss: 0.5596
Batch 200, Loss: 0.6035
Batch 210, Loss: 0.5391
Batch 220, Loss: 0.5417
Batch 230, Loss: 0.5738
Batch 240, Loss: 0.5497
Batch 250, Loss: 0.5594
Batch 260, Loss: 0.5589
Batch 270, Loss: 0.5548
Batch 280, Loss: 0.5492
Batch 290, Loss: 0.5742
Batch 300, Loss: 0.5564
Batch 310, Loss: 0.5724
Batch 320, Loss: 0.5171
Batch 330, Loss: 0.5443
Batch 340, Loss: 0.5648
Batch 350, Loss: 0.5583
Batch 360, Loss: 0.5446
Batch 370, Loss: 0.5542
Batch 380, Loss: 0.5407
Batch 390, Loss: 0.5601
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.145928621292114 seconds
Epoch 46 accuracy: 84.93%
Batch 10, Loss: 0.5144
Batch 20, Loss: 0.5247
Batch 30, Loss: 0.5470
Batch 40, Loss: 0.5019
Batch 50, Loss: 0.5277
Batch 60, Loss: 0.5883
Batch 70, Loss: 0.5598
Batch 80, Loss: 0.5435
Batch 90, Loss: 0.5563
Batch 100, Loss: 0.5290
Batch 110, Loss: 0.5014
Batch 120, Loss: 0.5514
Batch 130, Loss: 0.5299
Batch 140, Loss: 0.5077
Batch 150, Loss: 0.5577
Batch 160, Loss: 0.5725
Batch 170, Loss: 0.5779
Batch 180, Loss: 0.5270
Batch 190, Loss: 0.5686
Batch 200, Loss: 0.5804
Batch 210, Loss: 0.5374
Batch 220, Loss: 0.5519
Batch 230, Loss: 0.5625
Batch 240, Loss: 0.5383
Batch 250, Loss: 0.5617
Batch 260, Loss: 0.5676
Batch 270, Loss: 0.5517
Batch 280, Loss: 0.5338
Batch 290, Loss: 0.5624
Batch 300, Loss: 0.5441
Batch 310, Loss: 0.5657
Batch 320, Loss: 0.5225
Batch 330, Loss: 0.5801
Batch 340, Loss: 0.5308
Batch 350, Loss: 0.5460
Batch 360, Loss: 0.5355
Batch 370, Loss: 0.5323
Batch 380, Loss: 0.5380
Batch 390, Loss: 0.5831
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.055481910705566 seconds
Epoch 47 accuracy: 83.89%
Batch 10, Loss: 0.5470
Batch 20, Loss: 0.5473
Batch 30, Loss: 0.5376
Batch 40, Loss: 0.5707
Batch 50, Loss: 0.5059
Batch 60, Loss: 0.5114
Batch 70, Loss: 0.5320
Batch 80, Loss: 0.5537
Batch 90, Loss: 0.5273
Batch 100, Loss: 0.5642
Batch 110, Loss: 0.5351
Batch 120, Loss: 0.5481
Batch 130, Loss: 0.5703
Batch 140, Loss: 0.5856
Batch 150, Loss: 0.5265
Batch 160, Loss: 0.5642
Batch 170, Loss: 0.5410
Batch 180, Loss: 0.5601
Batch 190, Loss: 0.5208
Batch 200, Loss: 0.5624
Batch 210, Loss: 0.4990
Batch 220, Loss: 0.5375
Batch 230, Loss: 0.5663
Batch 240, Loss: 0.5429
Batch 250, Loss: 0.4980
Batch 260, Loss: 0.5511
Batch 270, Loss: 0.5460
Batch 280, Loss: 0.5515
Batch 290, Loss: 0.5412
Batch 300, Loss: 0.5210
Batch 310, Loss: 0.5752
Batch 320, Loss: 0.5808
Batch 330, Loss: 0.5449
Batch 340, Loss: 0.5561
Batch 350, Loss: 0.5265
Batch 360, Loss: 0.5564
Batch 370, Loss: 0.5408
Batch 380, Loss: 0.5444
Batch 390, Loss: 0.5181
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.105653762817383 seconds
Epoch 48 accuracy: 84.65%
Batch 10, Loss: 0.5251
Batch 20, Loss: 0.5350
Batch 30, Loss: 0.5540
Batch 40, Loss: 0.5104
Batch 50, Loss: 0.5373
Batch 60, Loss: 0.5250
Batch 70, Loss: 0.5549
Batch 80, Loss: 0.5295
Batch 90, Loss: 0.5488
Batch 100, Loss: 0.5610
Batch 110, Loss: 0.5715
Batch 120, Loss: 0.5507
Batch 130, Loss: 0.5635
Batch 140, Loss: 0.5125
Batch 150, Loss: 0.5175
Batch 160, Loss: 0.5870
Batch 170, Loss: 0.5632
Batch 180, Loss: 0.5308
Batch 190, Loss: 0.5141
Batch 200, Loss: 0.5534
Batch 210, Loss: 0.5520
Batch 220, Loss: 0.5938
Batch 230, Loss: 0.5262
Batch 240, Loss: 0.5848
Batch 250, Loss: 0.5468
Batch 260, Loss: 0.5356
Batch 270, Loss: 0.5150
Batch 280, Loss: 0.5789
Batch 290, Loss: 0.5195
Batch 300, Loss: 0.5342
Batch 310, Loss: 0.4822
Batch 320, Loss: 0.5557
Batch 330, Loss: 0.5344
Batch 340, Loss: 0.5563
Batch 350, Loss: 0.5960
Batch 360, Loss: 0.5328
Batch 370, Loss: 0.5302
Batch 380, Loss: 0.5406
Batch 390, Loss: 0.5535
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.024059057235718 seconds
Epoch 49 accuracy: 80.76%
Batch 10, Loss: 0.5661
Batch 20, Loss: 0.5127
Batch 30, Loss: 0.5170
Batch 40, Loss: 0.5852
Batch 50, Loss: 0.5512
Batch 60, Loss: 0.5420
Batch 70, Loss: 0.5252
Batch 80, Loss: 0.5502
Batch 90, Loss: 0.5676
Batch 100, Loss: 0.5000
Batch 110, Loss: 0.6009
Batch 120, Loss: 0.5579
Batch 130, Loss: 0.5633
Batch 140, Loss: 0.5351
Batch 150, Loss: 0.5376
Batch 160, Loss: 0.5696
Batch 170, Loss: 0.5379
Batch 180, Loss: 0.5219
Batch 190, Loss: 0.5287
Batch 200, Loss: 0.5302
Batch 210, Loss: 0.5743
Batch 220, Loss: 0.5549
Batch 230, Loss: 0.5358
Batch 240, Loss: 0.5654
Batch 250, Loss: 0.5452
Batch 260, Loss: 0.5362
Batch 270, Loss: 0.5222
Batch 280, Loss: 0.5490
Batch 290, Loss: 0.5429
Batch 300, Loss: 0.5541
Batch 310, Loss: 0.5200
Batch 320, Loss: 0.5155
Batch 330, Loss: 0.5656
Batch 340, Loss: 0.5322
Batch 350, Loss: 0.5217
Batch 360, Loss: 0.5626
Batch 370, Loss: 0.5474
Batch 380, Loss: 0.5210
Batch 390, Loss: 0.5564
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.18158459663391 seconds
Epoch 50 accuracy: 83.01%
Batch 10, Loss: 0.5484
Batch 20, Loss: 0.5288
Batch 30, Loss: 0.5220
Batch 40, Loss: 0.5187
Batch 50, Loss: 0.5235
Batch 60, Loss: 0.5358
Batch 70, Loss: 0.5466
Batch 80, Loss: 0.5041
Batch 90, Loss: 0.4984
Batch 100, Loss: 0.5399
Batch 110, Loss: 0.5605
Batch 120, Loss: 0.5829
Batch 130, Loss: 0.5488
Batch 140, Loss: 0.5256
Batch 150, Loss: 0.5152
Batch 160, Loss: 0.5452
Batch 170, Loss: 0.5351
Batch 180, Loss: 0.5658
Batch 190, Loss: 0.5240
Batch 200, Loss: 0.5659
Batch 210, Loss: 0.5406
Batch 220, Loss: 0.5779
Batch 230, Loss: 0.5548
Batch 240, Loss: 0.5120
Batch 250, Loss: 0.5257
Batch 260, Loss: 0.5322
Batch 270, Loss: 0.5371
Batch 280, Loss: 0.5221
Batch 290, Loss: 0.5341
Batch 300, Loss: 0.4972
Batch 310, Loss: 0.5316
Batch 320, Loss: 0.5473
Batch 330, Loss: 0.5715
Batch 340, Loss: 0.5355
Batch 350, Loss: 0.5472
Batch 360, Loss: 0.5183
Batch 370, Loss: 0.5635
Batch 380, Loss: 0.5699
Batch 390, Loss: 0.4988
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.112006664276123 seconds
Epoch 51 accuracy: 82.81%
Batch 10, Loss: 0.5196
Batch 20, Loss: 0.5770
Batch 30, Loss: 0.5320
Batch 40, Loss: 0.5594
Batch 50, Loss: 0.5338
Batch 60, Loss: 0.5352
Batch 70, Loss: 0.5571
Batch 80, Loss: 0.5712
Batch 90, Loss: 0.5589
Batch 100, Loss: 0.5431
Batch 110, Loss: 0.5486
Batch 120, Loss: 0.5355
Batch 130, Loss: 0.5586
Batch 140, Loss: 0.5104
Batch 150, Loss: 0.5046
Batch 160, Loss: 0.5373
Batch 170, Loss: 0.4928
Batch 180, Loss: 0.5214
Batch 190, Loss: 0.5324
Batch 200, Loss: 0.5270
Batch 210, Loss: 0.5502
Batch 220, Loss: 0.5646
Batch 230, Loss: 0.5356
Batch 240, Loss: 0.5437
Batch 250, Loss: 0.5510
Batch 260, Loss: 0.5623
Batch 270, Loss: 0.5222
Batch 280, Loss: 0.5443
Batch 290, Loss: 0.5479
Batch 300, Loss: 0.5356
Batch 310, Loss: 0.5142
Batch 320, Loss: 0.5531
Batch 330, Loss: 0.5813
Batch 340, Loss: 0.5552
Batch 350, Loss: 0.5871
Batch 360, Loss: 0.5409
Batch 370, Loss: 0.5551
Batch 380, Loss: 0.5498
Batch 390, Loss: 0.5430
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.080068588256836 seconds
Epoch 52 accuracy: 81.81%
Batch 10, Loss: 0.5380
Batch 20, Loss: 0.5675
Batch 30, Loss: 0.5016
Batch 40, Loss: 0.5715
Batch 50, Loss: 0.5340
Batch 60, Loss: 0.5429
Batch 70, Loss: 0.5487
Batch 80, Loss: 0.5427
Batch 90, Loss: 0.5706
Batch 100, Loss: 0.5730
Batch 110, Loss: 0.5583
Batch 120, Loss: 0.5500
Batch 130, Loss: 0.5241
Batch 140, Loss: 0.5365
Batch 150, Loss: 0.5204
Batch 160, Loss: 0.5402
Batch 170, Loss: 0.5435
Batch 180, Loss: 0.5399
Batch 190, Loss: 0.5487
Batch 200, Loss: 0.5136
Batch 210, Loss: 0.5309
Batch 220, Loss: 0.5152
Batch 230, Loss: 0.5249
Batch 240, Loss: 0.5046
Batch 250, Loss: 0.5416
Batch 260, Loss: 0.5049
Batch 270, Loss: 0.5226
Batch 280, Loss: 0.5291
Batch 290, Loss: 0.4995
Batch 300, Loss: 0.5405
Batch 310, Loss: 0.5647
Batch 320, Loss: 0.6123
Batch 330, Loss: 0.5167
Batch 340, Loss: 0.5284
Batch 350, Loss: 0.5208
Batch 360, Loss: 0.5217
Batch 370, Loss: 0.5081
Batch 380, Loss: 0.5194
Batch 390, Loss: 0.5050
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.083542346954346 seconds
Epoch 53 accuracy: 85.51%
Batch 10, Loss: 0.5296
Batch 20, Loss: 0.5734
Batch 30, Loss: 0.4803
Batch 40, Loss: 0.5130
Batch 50, Loss: 0.5311
Batch 60, Loss: 0.4871
Batch 70, Loss: 0.5119
Batch 80, Loss: 0.5023
Batch 90, Loss: 0.5441
Batch 100, Loss: 0.5193
Batch 110, Loss: 0.5000
Batch 120, Loss: 0.5513
Batch 130, Loss: 0.5084
Batch 140, Loss: 0.5452
Batch 150, Loss: 0.5268
Batch 160, Loss: 0.5006
Batch 170, Loss: 0.5390
Batch 180, Loss: 0.5229
Batch 190, Loss: 0.5505
Batch 200, Loss: 0.5189
Batch 210, Loss: 0.5238
Batch 220, Loss: 0.5805
Batch 230, Loss: 0.5584
Batch 240, Loss: 0.5518
Batch 250, Loss: 0.5476
Batch 260, Loss: 0.5309
Batch 270, Loss: 0.5751
Batch 280, Loss: 0.5684
Batch 290, Loss: 0.5492
Batch 300, Loss: 0.5317
Batch 310, Loss: 0.5505
Batch 320, Loss: 0.5733
Batch 330, Loss: 0.5616
Batch 340, Loss: 0.5518
Batch 350, Loss: 0.5434
Batch 360, Loss: 0.4984
Batch 370, Loss: 0.5857
Batch 380, Loss: 0.5551
Batch 390, Loss: 0.5517
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.101123332977295 seconds
Epoch 54 accuracy: 83.7%
Batch 10, Loss: 0.5623
Batch 20, Loss: 0.4930
Batch 30, Loss: 0.5103
Batch 40, Loss: 0.5342
Batch 50, Loss: 0.5303
Batch 60, Loss: 0.4940
Batch 70, Loss: 0.5355
Batch 80, Loss: 0.5342
Batch 90, Loss: 0.5152
Batch 100, Loss: 0.4815
Batch 110, Loss: 0.5425
Batch 120, Loss: 0.5872
Batch 130, Loss: 0.5447
Batch 140, Loss: 0.5252
Batch 150, Loss: 0.5179
Batch 160, Loss: 0.5284
Batch 170, Loss: 0.5129
Batch 180, Loss: 0.5515
Batch 190, Loss: 0.5204
Batch 200, Loss: 0.5561
Batch 210, Loss: 0.5427
Batch 220, Loss: 0.5067
Batch 230, Loss: 0.5556
Batch 240, Loss: 0.5097
Batch 250, Loss: 0.4950
Batch 260, Loss: 0.5531
Batch 270, Loss: 0.5014
Batch 280, Loss: 0.5690
Batch 290, Loss: 0.5437
Batch 300, Loss: 0.5537
Batch 310, Loss: 0.5498
Batch 320, Loss: 0.5684
Batch 330, Loss: 0.5334
Batch 340, Loss: 0.5476
Batch 350, Loss: 0.5830
Batch 360, Loss: 0.5626
Batch 370, Loss: 0.5324
Batch 380, Loss: 0.4877
Batch 390, Loss: 0.5568
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.060983657836914 seconds
Epoch 55 accuracy: 84.64%
Batch 10, Loss: 0.5298
Batch 20, Loss: 0.5147
Batch 30, Loss: 0.4670
Batch 40, Loss: 0.5222
Batch 50, Loss: 0.5380
Batch 60, Loss: 0.4930
Batch 70, Loss: 0.5241
Batch 80, Loss: 0.5303
Batch 90, Loss: 0.5242
Batch 100, Loss: 0.5466
Batch 110, Loss: 0.4937
Batch 120, Loss: 0.5333
Batch 130, Loss: 0.5180
Batch 140, Loss: 0.5252
Batch 150, Loss: 0.5427
Batch 160, Loss: 0.5207
Batch 170, Loss: 0.5415
Batch 180, Loss: 0.5162
Batch 190, Loss: 0.4972
Batch 200, Loss: 0.5220
Batch 210, Loss: 0.5391
Batch 220, Loss: 0.5599
Batch 230, Loss: 0.5576
Batch 240, Loss: 0.5148
Batch 250, Loss: 0.5214
Batch 260, Loss: 0.5121
Batch 270, Loss: 0.5323
Batch 280, Loss: 0.5342
Batch 290, Loss: 0.5278
Batch 300, Loss: 0.5062
Batch 310, Loss: 0.5247
Batch 320, Loss: 0.5264
Batch 330, Loss: 0.5198
Batch 340, Loss: 0.5506
Batch 350, Loss: 0.5554
Batch 360, Loss: 0.5414
Batch 370, Loss: 0.5413
Batch 380, Loss: 0.5457
Batch 390, Loss: 0.5570
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.05271863937378 seconds
Epoch 56 accuracy: 81.21%
Batch 10, Loss: 0.5222
Batch 20, Loss: 0.5620
Batch 30, Loss: 0.5194
Batch 40, Loss: 0.5479
Batch 50, Loss: 0.5269
Batch 60, Loss: 0.5294
Batch 70, Loss: 0.5901
Batch 80, Loss: 0.5408
Batch 90, Loss: 0.5396
Batch 100, Loss: 0.5671
Batch 110, Loss: 0.5432
Batch 120, Loss: 0.5075
Batch 130, Loss: 0.5261
Batch 140, Loss: 0.4639
Batch 150, Loss: 0.5609
Batch 160, Loss: 0.5347
Batch 170, Loss: 0.5126
Batch 180, Loss: 0.5277
Batch 190, Loss: 0.5469
Batch 200, Loss: 0.5318
Batch 210, Loss: 0.5148
Batch 220, Loss: 0.5190
Batch 230, Loss: 0.5235
Batch 240, Loss: 0.5226
Batch 250, Loss: 0.5510
Batch 260, Loss: 0.5347
Batch 270, Loss: 0.4992
Batch 280, Loss: 0.4942
Batch 290, Loss: 0.5066
Batch 300, Loss: 0.5459
Batch 310, Loss: 0.5602
Batch 320, Loss: 0.5281
Batch 330, Loss: 0.5644
Batch 340, Loss: 0.4988
Batch 350, Loss: 0.5259
Batch 360, Loss: 0.5447
Batch 370, Loss: 0.4672
Batch 380, Loss: 0.5147
Batch 390, Loss: 0.5411
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.053093194961548 seconds
Epoch 57 accuracy: 83.84%
Batch 10, Loss: 0.5313
Batch 20, Loss: 0.5347
Batch 30, Loss: 0.5146
Batch 40, Loss: 0.5402
Batch 50, Loss: 0.4953
Batch 60, Loss: 0.5116
Batch 70, Loss: 0.5154
Batch 80, Loss: 0.5386
Batch 90, Loss: 0.5525
Batch 100, Loss: 0.5233
Batch 110, Loss: 0.5101
Batch 120, Loss: 0.4891
Batch 130, Loss: 0.5018
Batch 140, Loss: 0.5214
Batch 150, Loss: 0.5400
Batch 160, Loss: 0.5503
Batch 170, Loss: 0.5449
Batch 180, Loss: 0.5652
Batch 190, Loss: 0.5168
Batch 200, Loss: 0.5045
Batch 210, Loss: 0.4756
Batch 220, Loss: 0.5189
Batch 230, Loss: 0.5501
Batch 240, Loss: 0.5357
Batch 250, Loss: 0.5484
Batch 260, Loss: 0.5099
Batch 270, Loss: 0.5823
Batch 280, Loss: 0.5925
Batch 290, Loss: 0.5198
Batch 300, Loss: 0.5018
Batch 310, Loss: 0.5005
Batch 320, Loss: 0.5064
Batch 330, Loss: 0.4867
Batch 340, Loss: 0.5162
Batch 350, Loss: 0.5537
Batch 360, Loss: 0.5333
Batch 370, Loss: 0.5740
Batch 380, Loss: 0.5649
Batch 390, Loss: 0.5373
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.077481985092163 seconds
Epoch 58 accuracy: 85.46%
Batch 10, Loss: 0.5157
Batch 20, Loss: 0.5635
Batch 30, Loss: 0.5255
Batch 40, Loss: 0.5451
Batch 50, Loss: 0.5338
Batch 60, Loss: 0.5077
Batch 70, Loss: 0.5115
Batch 80, Loss: 0.4799
Batch 90, Loss: 0.5392
Batch 100, Loss: 0.5626
Batch 110, Loss: 0.5589
Batch 120, Loss: 0.5867
Batch 130, Loss: 0.5377
Batch 140, Loss: 0.5088
Batch 150, Loss: 0.5302
Batch 160, Loss: 0.5205
Batch 170, Loss: 0.5418
Batch 180, Loss: 0.5345
Batch 190, Loss: 0.5103
Batch 200, Loss: 0.5225
Batch 210, Loss: 0.5458
Batch 220, Loss: 0.5251
Batch 230, Loss: 0.5034
Batch 240, Loss: 0.5439
Batch 250, Loss: 0.5154
Batch 260, Loss: 0.5167
Batch 270, Loss: 0.5700
Batch 280, Loss: 0.5342
Batch 290, Loss: 0.5559
Batch 300, Loss: 0.5168
Batch 310, Loss: 0.5941
Batch 320, Loss: 0.5179
Batch 330, Loss: 0.5769
Batch 340, Loss: 0.5046
Batch 350, Loss: 0.5007
Batch 360, Loss: 0.4781
Batch 370, Loss: 0.4702
Batch 380, Loss: 0.5005
Batch 390, Loss: 0.4827
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.035532474517822 seconds
Epoch 59 accuracy: 81.51%
Batch 10, Loss: 0.4740
Batch 20, Loss: 0.4858
Batch 30, Loss: 0.5435
Batch 40, Loss: 0.5144
Batch 50, Loss: 0.5195
Batch 60, Loss: 0.5135
Batch 70, Loss: 0.5272
Batch 80, Loss: 0.4957
Batch 90, Loss: 0.5159
Batch 100, Loss: 0.5526
Batch 110, Loss: 0.5415
Batch 120, Loss: 0.4923
Batch 130, Loss: 0.5250
Batch 140, Loss: 0.5085
Batch 150, Loss: 0.5136
Batch 160, Loss: 0.5237
Batch 170, Loss: 0.5286
Batch 180, Loss: 0.5405
Batch 190, Loss: 0.5070
Batch 200, Loss: 0.5188
Batch 210, Loss: 0.5109
Batch 220, Loss: 0.5152
Batch 230, Loss: 0.5043
Batch 240, Loss: 0.5536
Batch 250, Loss: 0.5254
Batch 260, Loss: 0.5543
Batch 270, Loss: 0.5619
Batch 280, Loss: 0.5442
Batch 290, Loss: 0.5668
Batch 300, Loss: 0.5035
Batch 310, Loss: 0.5298
Batch 320, Loss: 0.5220
Batch 330, Loss: 0.5398
Batch 340, Loss: 0.5673
Batch 350, Loss: 0.5820
Batch 360, Loss: 0.5360
Batch 370, Loss: 0.4772
Batch 380, Loss: 0.5045
Batch 390, Loss: 0.5531
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.052869081497192 seconds
Epoch 60 accuracy: 81.48%
Batch 10, Loss: 0.5301
Batch 20, Loss: 0.4749
Batch 30, Loss: 0.5108
Batch 40, Loss: 0.5333
Batch 50, Loss: 0.5454
Batch 60, Loss: 0.5276
Batch 70, Loss: 0.5216
Batch 80, Loss: 0.4825
Batch 90, Loss: 0.5411
Batch 100, Loss: 0.4823
Batch 110, Loss: 0.5483
Batch 120, Loss: 0.5073
Batch 130, Loss: 0.5283
Batch 140, Loss: 0.4917
Batch 150, Loss: 0.5027
Batch 160, Loss: 0.4923
Batch 170, Loss: 0.4945
Batch 180, Loss: 0.5244
Batch 190, Loss: 0.5031
Batch 200, Loss: 0.5037
Batch 210, Loss: 0.5312
Batch 220, Loss: 0.5179
Batch 230, Loss: 0.5513
Batch 240, Loss: 0.5143
Batch 250, Loss: 0.5101
Batch 260, Loss: 0.5523
Batch 270, Loss: 0.5254
Batch 280, Loss: 0.5347
Batch 290, Loss: 0.5081
Batch 300, Loss: 0.5003
Batch 310, Loss: 0.4951
Batch 320, Loss: 0.5178
Batch 330, Loss: 0.5089
Batch 340, Loss: 0.5273
Batch 350, Loss: 0.4965
Batch 360, Loss: 0.5215
Batch 370, Loss: 0.5163
Batch 380, Loss: 0.5688
Batch 390, Loss: 0.5311
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.048291444778442 seconds
Epoch 61 accuracy: 86.4%
Batch 10, Loss: 0.5357
Batch 20, Loss: 0.5205
Batch 30, Loss: 0.4971
Batch 40, Loss: 0.4917
Batch 50, Loss: 0.4972
Batch 60, Loss: 0.5178
Batch 70, Loss: 0.5220
Batch 80, Loss: 0.4907
Batch 90, Loss: 0.5326
Batch 100, Loss: 0.5180
Batch 110, Loss: 0.5380
Batch 120, Loss: 0.5173
Batch 130, Loss: 0.5256
Batch 140, Loss: 0.5470
Batch 150, Loss: 0.5401
Batch 160, Loss: 0.5464
Batch 170, Loss: 0.5532
Batch 180, Loss: 0.5517
Batch 190, Loss: 0.5193
Batch 200, Loss: 0.4840
Batch 210, Loss: 0.4847
Batch 220, Loss: 0.5283
Batch 230, Loss: 0.5233
Batch 240, Loss: 0.5190
Batch 250, Loss: 0.4672
Batch 260, Loss: 0.5054
Batch 270, Loss: 0.5097
Batch 280, Loss: 0.5366
Batch 290, Loss: 0.5442
Batch 300, Loss: 0.5068
Batch 310, Loss: 0.5232
Batch 320, Loss: 0.5453
Batch 330, Loss: 0.5066
Batch 340, Loss: 0.5095
Batch 350, Loss: 0.5167
Batch 360, Loss: 0.5240
Batch 370, Loss: 0.4884
Batch 380, Loss: 0.5087
Batch 390, Loss: 0.5705
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 24.988040924072266 seconds
Epoch 62 accuracy: 85.07%
Batch 10, Loss: 0.5657
Batch 20, Loss: 0.5237
Batch 30, Loss: 0.5117
Batch 40, Loss: 0.5054
Batch 50, Loss: 0.5252
Batch 60, Loss: 0.5061
Batch 70, Loss: 0.5331
Batch 80, Loss: 0.4922
Batch 90, Loss: 0.4964
Batch 100, Loss: 0.5383
Batch 110, Loss: 0.5245
Batch 120, Loss: 0.5050
Batch 130, Loss: 0.4960
Batch 140, Loss: 0.4651
Batch 150, Loss: 0.4879
Batch 160, Loss: 0.5020
Batch 170, Loss: 0.5296
Batch 180, Loss: 0.5420
Batch 190, Loss: 0.5723
Batch 200, Loss: 0.5180
Batch 210, Loss: 0.5315
Batch 220, Loss: 0.5326
Batch 230, Loss: 0.4943
Batch 240, Loss: 0.5589
Batch 250, Loss: 0.5678
Batch 260, Loss: 0.5289
Batch 270, Loss: 0.5446
Batch 280, Loss: 0.5110
Batch 290, Loss: 0.5076
Batch 300, Loss: 0.5487
Batch 310, Loss: 0.5498
Batch 320, Loss: 0.4902
Batch 330, Loss: 0.5070
Batch 340, Loss: 0.4933
Batch 350, Loss: 0.4933
Batch 360, Loss: 0.5060
Batch 370, Loss: 0.5184
Batch 380, Loss: 0.4800
Batch 390, Loss: 0.5054
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.059290409088135 seconds
Epoch 63 accuracy: 86.06%
Batch 10, Loss: 0.4770
Batch 20, Loss: 0.4787
Batch 30, Loss: 0.4786
Batch 40, Loss: 0.5252
Batch 50, Loss: 0.5306
Batch 60, Loss: 0.4862
Batch 70, Loss: 0.4651
Batch 80, Loss: 0.5482
Batch 90, Loss: 0.5058
Batch 100, Loss: 0.5107
Batch 110, Loss: 0.4877
Batch 120, Loss: 0.5312
Batch 130, Loss: 0.5751
Batch 140, Loss: 0.5521
Batch 150, Loss: 0.5144
Batch 160, Loss: 0.5578
Batch 170, Loss: 0.5466
Batch 180, Loss: 0.5052
Batch 190, Loss: 0.4743
Batch 200, Loss: 0.4816
Batch 210, Loss: 0.5488
Batch 220, Loss: 0.5206
Batch 230, Loss: 0.5018
Batch 240, Loss: 0.5065
Batch 250, Loss: 0.5402
Batch 260, Loss: 0.5193
Batch 270, Loss: 0.5230
Batch 280, Loss: 0.5281
Batch 290, Loss: 0.5427
Batch 300, Loss: 0.5414
Batch 310, Loss: 0.4876
Batch 320, Loss: 0.5142
Batch 330, Loss: 0.4982
Batch 340, Loss: 0.5506
Batch 350, Loss: 0.5330
Batch 360, Loss: 0.5066
Batch 370, Loss: 0.5072
Batch 380, Loss: 0.4988
Batch 390, Loss: 0.5035
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.154593229293823 seconds
Epoch 64 accuracy: 82.83%
Batch 10, Loss: 0.5186
Batch 20, Loss: 0.5113
Batch 30, Loss: 0.5184
Batch 40, Loss: 0.5193
Batch 50, Loss: 0.5161
Batch 60, Loss: 0.5174
Batch 70, Loss: 0.5188
Batch 80, Loss: 0.4816
Batch 90, Loss: 0.5555
Batch 100, Loss: 0.5198
Batch 110, Loss: 0.5171
Batch 120, Loss: 0.5096
Batch 130, Loss: 0.4995
Batch 140, Loss: 0.5122
Batch 150, Loss: 0.5582
Batch 160, Loss: 0.5056
Batch 170, Loss: 0.5327
Batch 180, Loss: 0.5464
Batch 190, Loss: 0.5218
Batch 200, Loss: 0.5200
Batch 210, Loss: 0.5046
Batch 220, Loss: 0.4882
Batch 230, Loss: 0.4971
Batch 240, Loss: 0.5100
Batch 250, Loss: 0.4939
Batch 260, Loss: 0.4899
Batch 270, Loss: 0.5016
Batch 280, Loss: 0.5052
Batch 290, Loss: 0.5229
Batch 300, Loss: 0.4943
Batch 310, Loss: 0.4590
Batch 320, Loss: 0.5540
Batch 330, Loss: 0.5400
Batch 340, Loss: 0.5264
Batch 350, Loss: 0.5238
Batch 360, Loss: 0.5603
Batch 370, Loss: 0.5119
Batch 380, Loss: 0.4951
Batch 390, Loss: 0.5414
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.103005170822144 seconds
Epoch 65 accuracy: 85.24%
Batch 10, Loss: 0.4298
Batch 20, Loss: 0.4961
Batch 30, Loss: 0.4888
Batch 40, Loss: 0.5083
Batch 50, Loss: 0.5005
Batch 60, Loss: 0.4857
Batch 70, Loss: 0.5024
Batch 80, Loss: 0.5238
Batch 90, Loss: 0.5210
Batch 100, Loss: 0.4772
Batch 110, Loss: 0.5210
Batch 120, Loss: 0.5525
Batch 130, Loss: 0.4869
Batch 140, Loss: 0.5116
Batch 150, Loss: 0.5024
Batch 160, Loss: 0.4976
Batch 170, Loss: 0.5034
Batch 180, Loss: 0.5166
Batch 190, Loss: 0.5208
Batch 200, Loss: 0.5298
Batch 210, Loss: 0.5355
Batch 220, Loss: 0.4885
Batch 230, Loss: 0.5039
Batch 240, Loss: 0.5573
Batch 250, Loss: 0.4881
Batch 260, Loss: 0.5575
Batch 270, Loss: 0.5063
Batch 280, Loss: 0.5012
Batch 290, Loss: 0.5405
Batch 300, Loss: 0.4821
Batch 310, Loss: 0.5325
Batch 320, Loss: 0.5099
Batch 330, Loss: 0.5430
Batch 340, Loss: 0.5233
Batch 350, Loss: 0.5416
Batch 360, Loss: 0.5178
Batch 370, Loss: 0.4979
Batch 380, Loss: 0.5280
Batch 390, Loss: 0.5431
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.018563508987427 seconds
Epoch 66 accuracy: 86.49%
Batch 10, Loss: 0.5295
Batch 20, Loss: 0.5086
Batch 30, Loss: 0.5086
Batch 40, Loss: 0.5048
Batch 50, Loss: 0.5009
Batch 60, Loss: 0.4880
Batch 70, Loss: 0.5214
Batch 80, Loss: 0.5307
Batch 90, Loss: 0.4690
Batch 100, Loss: 0.4960
Batch 110, Loss: 0.4775
Batch 120, Loss: 0.5124
Batch 130, Loss: 0.4912
Batch 140, Loss: 0.5139
Batch 150, Loss: 0.4939
Batch 160, Loss: 0.4700
Batch 170, Loss: 0.4937
Batch 180, Loss: 0.4909
Batch 190, Loss: 0.5231
Batch 200, Loss: 0.5014
Batch 210, Loss: 0.4954
Batch 220, Loss: 0.5222
Batch 230, Loss: 0.5024
Batch 240, Loss: 0.5207
Batch 250, Loss: 0.5418
Batch 260, Loss: 0.5605
Batch 270, Loss: 0.4988
Batch 280, Loss: 0.5134
Batch 290, Loss: 0.5451
Batch 300, Loss: 0.4818
Batch 310, Loss: 0.4869
Batch 320, Loss: 0.5118
Batch 330, Loss: 0.5224
Batch 340, Loss: 0.5054
Batch 350, Loss: 0.5054
Batch 360, Loss: 0.4837
Batch 370, Loss: 0.5020
Batch 380, Loss: 0.5147
Batch 390, Loss: 0.5346
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.06179690361023 seconds
Epoch 67 accuracy: 80.35%
Batch 10, Loss: 0.5340
Batch 20, Loss: 0.5086
Batch 30, Loss: 0.5371
Batch 40, Loss: 0.5357
Batch 50, Loss: 0.4455
Batch 60, Loss: 0.4655
Batch 70, Loss: 0.4686
Batch 80, Loss: 0.4694
Batch 90, Loss: 0.4619
Batch 100, Loss: 0.5158
Batch 110, Loss: 0.5364
Batch 120, Loss: 0.5195
Batch 130, Loss: 0.5076
Batch 140, Loss: 0.4742
Batch 150, Loss: 0.4727
Batch 160, Loss: 0.5244
Batch 170, Loss: 0.5071
Batch 180, Loss: 0.4745
Batch 190, Loss: 0.5134
Batch 200, Loss: 0.5379
Batch 210, Loss: 0.4842
Batch 220, Loss: 0.5127
Batch 230, Loss: 0.5137
Batch 240, Loss: 0.5113
Batch 250, Loss: 0.4885
Batch 260, Loss: 0.5227
Batch 270, Loss: 0.4689
Batch 280, Loss: 0.5340
Batch 290, Loss: 0.5220
Batch 300, Loss: 0.5129
Batch 310, Loss: 0.5063
Batch 320, Loss: 0.5392
Batch 330, Loss: 0.4778
Batch 340, Loss: 0.5170
Batch 350, Loss: 0.5189
Batch 360, Loss: 0.5214
Batch 370, Loss: 0.5228
Batch 380, Loss: 0.5206
Batch 390, Loss: 0.5444
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.098843574523926 seconds
Epoch 68 accuracy: 84.25%
Batch 10, Loss: 0.4922
Batch 20, Loss: 0.4998
Batch 30, Loss: 0.4667
Batch 40, Loss: 0.4838
Batch 50, Loss: 0.4999
Batch 60, Loss: 0.5022
Batch 70, Loss: 0.5227
Batch 80, Loss: 0.4880
Batch 90, Loss: 0.5052
Batch 100, Loss: 0.5190
Batch 110, Loss: 0.4723
Batch 120, Loss: 0.5239
Batch 130, Loss: 0.4988
Batch 140, Loss: 0.5255
Batch 150, Loss: 0.5465
Batch 160, Loss: 0.4648
Batch 170, Loss: 0.4900
Batch 180, Loss: 0.5099
Batch 190, Loss: 0.5073
Batch 200, Loss: 0.5369
Batch 210, Loss: 0.5066
Batch 220, Loss: 0.5034
Batch 230, Loss: 0.5112
Batch 240, Loss: 0.4722
Batch 250, Loss: 0.4921
Batch 260, Loss: 0.4819
Batch 270, Loss: 0.4704
Batch 280, Loss: 0.5480
Batch 290, Loss: 0.5159
Batch 300, Loss: 0.5249
Batch 310, Loss: 0.5351
Batch 320, Loss: 0.5227
Batch 330, Loss: 0.4932
Batch 340, Loss: 0.5029
Batch 350, Loss: 0.5188
Batch 360, Loss: 0.5051
Batch 370, Loss: 0.4763
Batch 380, Loss: 0.5191
Batch 390, Loss: 0.4922
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.036023378372192 seconds
Epoch 69 accuracy: 86.66%
Batch 10, Loss: 0.4952
Batch 20, Loss: 0.4656
Batch 30, Loss: 0.5100
Batch 40, Loss: 0.4796
Batch 50, Loss: 0.4618
Batch 60, Loss: 0.4766
Batch 70, Loss: 0.5304
Batch 80, Loss: 0.4829
Batch 90, Loss: 0.4730
Batch 100, Loss: 0.4988
Batch 110, Loss: 0.5090
Batch 120, Loss: 0.4873
Batch 130, Loss: 0.5181
Batch 140, Loss: 0.4921
Batch 150, Loss: 0.5086
Batch 160, Loss: 0.5173
Batch 170, Loss: 0.5027
Batch 180, Loss: 0.4948
Batch 190, Loss: 0.4796
Batch 200, Loss: 0.5142
Batch 210, Loss: 0.4684
Batch 220, Loss: 0.5074
Batch 230, Loss: 0.5241
Batch 240, Loss: 0.4844
Batch 250, Loss: 0.5156
Batch 260, Loss: 0.5447
Batch 270, Loss: 0.5014
Batch 280, Loss: 0.4893
Batch 290, Loss: 0.4878
Batch 300, Loss: 0.5410
Batch 310, Loss: 0.4806
Batch 320, Loss: 0.4770
Batch 330, Loss: 0.5536
Batch 340, Loss: 0.5194
Batch 350, Loss: 0.5239
Batch 360, Loss: 0.4791
Batch 370, Loss: 0.5327
Batch 380, Loss: 0.5294
Batch 390, Loss: 0.5196
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.064743041992188 seconds
Epoch 70 accuracy: 85.1%
Batch 10, Loss: 0.5055
Batch 20, Loss: 0.5042
Batch 30, Loss: 0.4984
Batch 40, Loss: 0.5113
Batch 50, Loss: 0.4939
Batch 60, Loss: 0.5073
Batch 70, Loss: 0.5352
Batch 80, Loss: 0.5060
Batch 90, Loss: 0.4909
Batch 100, Loss: 0.4636
Batch 110, Loss: 0.5262
Batch 120, Loss: 0.4635
Batch 130, Loss: 0.4661
Batch 140, Loss: 0.5249
Batch 150, Loss: 0.4893
Batch 160, Loss: 0.5041
Batch 170, Loss: 0.4752
Batch 180, Loss: 0.5073
Batch 190, Loss: 0.5261
Batch 200, Loss: 0.4844
Batch 210, Loss: 0.4632
Batch 220, Loss: 0.5084
Batch 230, Loss: 0.5592
Batch 240, Loss: 0.5082
Batch 250, Loss: 0.5093
Batch 260, Loss: 0.5321
Batch 270, Loss: 0.4673
Batch 280, Loss: 0.4946
Batch 290, Loss: 0.4855
Batch 300, Loss: 0.5249
Batch 310, Loss: 0.4787
Batch 320, Loss: 0.5370
Batch 330, Loss: 0.5197
Batch 340, Loss: 0.5117
Batch 350, Loss: 0.5334
Batch 360, Loss: 0.4830
Batch 370, Loss: 0.5176
Batch 380, Loss: 0.4786
Batch 390, Loss: 0.5023
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.063086986541748 seconds
Epoch 71 accuracy: 85.09%
Batch 10, Loss: 0.5015
Batch 20, Loss: 0.4774
Batch 30, Loss: 0.4632
Batch 40, Loss: 0.4878
Batch 50, Loss: 0.4879
Batch 60, Loss: 0.4723
Batch 70, Loss: 0.5089
Batch 80, Loss: 0.5124
Batch 90, Loss: 0.5054
Batch 100, Loss: 0.5389
Batch 110, Loss: 0.4802
Batch 120, Loss: 0.4897
Batch 130, Loss: 0.5256
Batch 140, Loss: 0.5153
Batch 150, Loss: 0.4664
Batch 160, Loss: 0.4902
Batch 170, Loss: 0.4565
Batch 180, Loss: 0.4686
Batch 190, Loss: 0.4858
Batch 200, Loss: 0.4806
Batch 210, Loss: 0.5443
Batch 220, Loss: 0.5401
Batch 230, Loss: 0.4934
Batch 240, Loss: 0.5049
Batch 250, Loss: 0.5228
Batch 260, Loss: 0.5043
Batch 270, Loss: 0.5336
Batch 280, Loss: 0.5316
Batch 290, Loss: 0.5277
Batch 300, Loss: 0.4902
Batch 310, Loss: 0.5171
Batch 320, Loss: 0.5401
Batch 330, Loss: 0.5268
Batch 340, Loss: 0.5263
Batch 350, Loss: 0.5057
Batch 360, Loss: 0.5201
Batch 370, Loss: 0.5190
Batch 380, Loss: 0.4842
Batch 390, Loss: 0.4500
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.009563207626343 seconds
Epoch 72 accuracy: 85.12%
Batch 10, Loss: 0.5151
Batch 20, Loss: 0.4863
Batch 30, Loss: 0.4844
Batch 40, Loss: 0.4784
Batch 50, Loss: 0.5473
Batch 60, Loss: 0.4473
Batch 70, Loss: 0.4726
Batch 80, Loss: 0.5095
Batch 90, Loss: 0.4863
Batch 100, Loss: 0.5190
Batch 110, Loss: 0.4752
Batch 120, Loss: 0.5545
Batch 130, Loss: 0.4828
Batch 140, Loss: 0.5326
Batch 150, Loss: 0.4514
Batch 160, Loss: 0.5164
Batch 170, Loss: 0.4793
Batch 180, Loss: 0.4745
Batch 190, Loss: 0.5140
Batch 200, Loss: 0.5085
Batch 210, Loss: 0.4922
Batch 220, Loss: 0.5068
Batch 230, Loss: 0.4368
Batch 240, Loss: 0.5206
Batch 250, Loss: 0.4807
Batch 260, Loss: 0.5170
Batch 270, Loss: 0.4741
Batch 280, Loss: 0.4475
Batch 290, Loss: 0.4964
Batch 300, Loss: 0.4744
Batch 310, Loss: 0.4757
Batch 320, Loss: 0.4879
Batch 330, Loss: 0.5135
Batch 340, Loss: 0.4733
Batch 350, Loss: 0.4768
Batch 360, Loss: 0.4614
Batch 370, Loss: 0.4828
Batch 380, Loss: 0.4518
Batch 390, Loss: 0.4997
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.162559032440186 seconds
Epoch 73 accuracy: 84.81%
Batch 10, Loss: 0.5057
Batch 20, Loss: 0.4696
Batch 30, Loss: 0.5003
Batch 40, Loss: 0.4572
Batch 50, Loss: 0.4356
Batch 60, Loss: 0.5289
Batch 70, Loss: 0.4842
Batch 80, Loss: 0.5031
Batch 90, Loss: 0.5092
Batch 100, Loss: 0.4724
Batch 110, Loss: 0.5033
Batch 120, Loss: 0.5326
Batch 130, Loss: 0.5341
Batch 140, Loss: 0.5098
Batch 150, Loss: 0.5013
Batch 160, Loss: 0.4851
Batch 170, Loss: 0.4733
Batch 180, Loss: 0.5105
Batch 190, Loss: 0.4866
Batch 200, Loss: 0.4902
Batch 210, Loss: 0.5370
Batch 220, Loss: 0.4824
Batch 230, Loss: 0.5097
Batch 240, Loss: 0.4620
Batch 250, Loss: 0.4734
Batch 260, Loss: 0.4636
Batch 270, Loss: 0.4719
Batch 280, Loss: 0.4899
Batch 290, Loss: 0.4932
Batch 300, Loss: 0.5293
Batch 310, Loss: 0.4991
Batch 320, Loss: 0.4671
Batch 330, Loss: 0.4335
Batch 340, Loss: 0.4916
Batch 350, Loss: 0.5071
Batch 360, Loss: 0.5136
Batch 370, Loss: 0.4907
Batch 380, Loss: 0.5174
Batch 390, Loss: 0.5342
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.135008335113525 seconds
Epoch 74 accuracy: 87.36%
Batch 10, Loss: 0.4864
Batch 20, Loss: 0.4731
Batch 30, Loss: 0.4790
Batch 40, Loss: 0.4826
Batch 50, Loss: 0.5486
Batch 60, Loss: 0.5202
Batch 70, Loss: 0.4858
Batch 80, Loss: 0.4663
Batch 90, Loss: 0.4896
Batch 100, Loss: 0.4978
Batch 110, Loss: 0.4750
Batch 120, Loss: 0.4731
Batch 130, Loss: 0.4697
Batch 140, Loss: 0.5184
Batch 150, Loss: 0.4684
Batch 160, Loss: 0.4850
Batch 170, Loss: 0.4703
Batch 180, Loss: 0.4924
Batch 190, Loss: 0.4471
Batch 200, Loss: 0.5013
Batch 210, Loss: 0.4733
Batch 220, Loss: 0.4820
Batch 230, Loss: 0.4800
Batch 240, Loss: 0.5077
Batch 250, Loss: 0.5239
Batch 260, Loss: 0.4750
Batch 270, Loss: 0.5164
Batch 280, Loss: 0.5053
Batch 290, Loss: 0.4684
Batch 300, Loss: 0.4913
Batch 310, Loss: 0.4939
Batch 320, Loss: 0.4746
Batch 330, Loss: 0.5031
Batch 340, Loss: 0.5183
Batch 350, Loss: 0.4997
Batch 360, Loss: 0.4920
Batch 370, Loss: 0.4841
Batch 380, Loss: 0.5080
Batch 390, Loss: 0.5138
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.835364818572998 seconds
Epoch 75 accuracy: 85.14%
Batch 10, Loss: 0.4750
Batch 20, Loss: 0.4869
Batch 30, Loss: 0.4924
Batch 40, Loss: 0.4932
Batch 50, Loss: 0.5134
Batch 60, Loss: 0.4974
Batch 70, Loss: 0.5268
Batch 80, Loss: 0.4730
Batch 90, Loss: 0.4862
Batch 100, Loss: 0.4695
Batch 110, Loss: 0.5231
Batch 120, Loss: 0.4593
Batch 130, Loss: 0.4632
Batch 140, Loss: 0.4686
Batch 150, Loss: 0.5078
Batch 160, Loss: 0.5101
Batch 170, Loss: 0.4884
Batch 180, Loss: 0.5255
Batch 190, Loss: 0.5021
Batch 200, Loss: 0.5016
Batch 210, Loss: 0.4969
Batch 220, Loss: 0.5178
Batch 230, Loss: 0.4789
Batch 240, Loss: 0.4909
Batch 250, Loss: 0.4739
Batch 260, Loss: 0.4997
Batch 270, Loss: 0.4755
Batch 280, Loss: 0.4985
Batch 290, Loss: 0.5048
Batch 300, Loss: 0.5065
Batch 310, Loss: 0.5373
Batch 320, Loss: 0.4763
Batch 330, Loss: 0.4406
Batch 340, Loss: 0.4925
Batch 350, Loss: 0.5268
Batch 360, Loss: 0.4791
Batch 370, Loss: 0.5173
Batch 380, Loss: 0.5058
Batch 390, Loss: 0.5000
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.107894897460938 seconds
Epoch 76 accuracy: 84.35%
Batch 10, Loss: 0.5104
Batch 20, Loss: 0.4895
Batch 30, Loss: 0.5027
Batch 40, Loss: 0.4508
Batch 50, Loss: 0.5067
Batch 60, Loss: 0.5051
Batch 70, Loss: 0.5150
Batch 80, Loss: 0.5101
Batch 90, Loss: 0.4980
Batch 100, Loss: 0.4648
Batch 110, Loss: 0.5238
Batch 120, Loss: 0.4960
Batch 130, Loss: 0.5230
Batch 140, Loss: 0.4956
Batch 150, Loss: 0.4957
Batch 160, Loss: 0.5136
Batch 170, Loss: 0.4939
Batch 180, Loss: 0.4817
Batch 190, Loss: 0.4986
Batch 200, Loss: 0.4880
Batch 210, Loss: 0.4629
Batch 220, Loss: 0.5090
Batch 230, Loss: 0.4949
Batch 240, Loss: 0.4564
Batch 250, Loss: 0.5039
Batch 260, Loss: 0.4960
Batch 270, Loss: 0.4805
Batch 280, Loss: 0.4910
Batch 290, Loss: 0.4938
Batch 300, Loss: 0.4919
Batch 310, Loss: 0.4680
Batch 320, Loss: 0.4750
Batch 330, Loss: 0.4691
Batch 340, Loss: 0.4945
Batch 350, Loss: 0.4461
Batch 360, Loss: 0.5029
Batch 370, Loss: 0.5021
Batch 380, Loss: 0.5018
Batch 390, Loss: 0.4703
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.02525234222412 seconds
Epoch 77 accuracy: 86.84%
Batch 10, Loss: 0.4950
Batch 20, Loss: 0.4713
Batch 30, Loss: 0.4430
Batch 40, Loss: 0.4439
Batch 50, Loss: 0.5072
Batch 60, Loss: 0.4849
Batch 70, Loss: 0.5317
Batch 80, Loss: 0.5120
Batch 90, Loss: 0.4942
Batch 100, Loss: 0.4488
Batch 110, Loss: 0.5354
Batch 120, Loss: 0.4562
Batch 130, Loss: 0.5023
Batch 140, Loss: 0.4817
Batch 150, Loss: 0.4625
Batch 160, Loss: 0.4736
Batch 170, Loss: 0.4381
Batch 180, Loss: 0.4801
Batch 190, Loss: 0.4886
Batch 200, Loss: 0.4991
Batch 210, Loss: 0.5138
Batch 220, Loss: 0.4643
Batch 230, Loss: 0.5102
Batch 240, Loss: 0.4731
Batch 250, Loss: 0.4930
Batch 260, Loss: 0.5188
Batch 270, Loss: 0.5293
Batch 280, Loss: 0.4848
Batch 290, Loss: 0.4430
Batch 300, Loss: 0.4700
Batch 310, Loss: 0.4768
Batch 320, Loss: 0.4881
Batch 330, Loss: 0.4883
Batch 340, Loss: 0.4843
Batch 350, Loss: 0.4969
Batch 360, Loss: 0.5205
Batch 370, Loss: 0.4636
Batch 380, Loss: 0.4606
Batch 390, Loss: 0.4238
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.18514370918274 seconds
Epoch 78 accuracy: 86.0%
Batch 10, Loss: 0.4614
Batch 20, Loss: 0.4452
Batch 30, Loss: 0.4954
Batch 40, Loss: 0.5009
Batch 50, Loss: 0.4953
Batch 60, Loss: 0.4969
Batch 70, Loss: 0.4991
Batch 80, Loss: 0.4895
Batch 90, Loss: 0.4907
Batch 100, Loss: 0.5072
Batch 110, Loss: 0.4709
Batch 120, Loss: 0.4678
Batch 130, Loss: 0.4768
Batch 140, Loss: 0.4938
Batch 150, Loss: 0.4842
Batch 160, Loss: 0.4602
Batch 170, Loss: 0.4805
Batch 180, Loss: 0.4606
Batch 190, Loss: 0.5034
Batch 200, Loss: 0.4761
Batch 210, Loss: 0.4758
Batch 220, Loss: 0.4493
Batch 230, Loss: 0.4559
Batch 240, Loss: 0.4751
Batch 250, Loss: 0.4983
Batch 260, Loss: 0.4899
Batch 270, Loss: 0.4935
Batch 280, Loss: 0.5055
Batch 290, Loss: 0.5300
Batch 300, Loss: 0.4933
Batch 310, Loss: 0.4400
Batch 320, Loss: 0.5070
Batch 330, Loss: 0.4741
Batch 340, Loss: 0.4765
Batch 350, Loss: 0.5017
Batch 360, Loss: 0.4788
Batch 370, Loss: 0.4447
Batch 380, Loss: 0.4737
Batch 390, Loss: 0.5012
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.188923835754395 seconds
Epoch 79 accuracy: 86.88%
Batch 10, Loss: 0.5154
Batch 20, Loss: 0.4761
Batch 30, Loss: 0.5080
Batch 40, Loss: 0.4855
Batch 50, Loss: 0.4589
Batch 60, Loss: 0.5055
Batch 70, Loss: 0.5003
Batch 80, Loss: 0.4874
Batch 90, Loss: 0.4414
Batch 100, Loss: 0.4536
Batch 110, Loss: 0.4811
Batch 120, Loss: 0.4789
Batch 130, Loss: 0.4915
Batch 140, Loss: 0.4553
Batch 150, Loss: 0.4854
Batch 160, Loss: 0.4844
Batch 170, Loss: 0.4910
Batch 180, Loss: 0.4944
Batch 190, Loss: 0.4987
Batch 200, Loss: 0.4668
Batch 210, Loss: 0.5147
Batch 220, Loss: 0.5027
Batch 230, Loss: 0.4966
Batch 240, Loss: 0.5039
Batch 250, Loss: 0.4678
Batch 260, Loss: 0.4925
Batch 270, Loss: 0.5044
Batch 280, Loss: 0.5084
Batch 290, Loss: 0.4657
Batch 300, Loss: 0.4963
Batch 310, Loss: 0.4702
Batch 320, Loss: 0.4442
Batch 330, Loss: 0.4277
Batch 340, Loss: 0.4809
Batch 350, Loss: 0.5298
Batch 360, Loss: 0.4799
Batch 370, Loss: 0.4703
Batch 380, Loss: 0.4478
Batch 390, Loss: 0.4728
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.074085235595703 seconds
Epoch 80 accuracy: 86.77%
Batch 10, Loss: 0.5165
Batch 20, Loss: 0.4733
Batch 30, Loss: 0.4974
Batch 40, Loss: 0.4569
Batch 50, Loss: 0.4406
Batch 60, Loss: 0.5115
Batch 70, Loss: 0.4748
Batch 80, Loss: 0.4862
Batch 90, Loss: 0.4797
Batch 100, Loss: 0.4584
Batch 110, Loss: 0.4496
Batch 120, Loss: 0.4912
Batch 130, Loss: 0.4897
Batch 140, Loss: 0.4460
Batch 150, Loss: 0.4969
Batch 160, Loss: 0.4770
Batch 170, Loss: 0.4536
Batch 180, Loss: 0.5197
Batch 190, Loss: 0.4570
Batch 200, Loss: 0.4546
Batch 210, Loss: 0.4689
Batch 220, Loss: 0.4913
Batch 230, Loss: 0.5049
Batch 240, Loss: 0.4963
Batch 250, Loss: 0.4537
Batch 260, Loss: 0.4842
Batch 270, Loss: 0.4934
Batch 280, Loss: 0.4836
Batch 290, Loss: 0.4734
Batch 300, Loss: 0.4789
Batch 310, Loss: 0.4731
Batch 320, Loss: 0.5102
Batch 330, Loss: 0.4837
Batch 340, Loss: 0.4787
Batch 350, Loss: 0.4657
Batch 360, Loss: 0.4770
Batch 370, Loss: 0.4490
Batch 380, Loss: 0.5004
Batch 390, Loss: 0.5048
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.114856958389282 seconds
Epoch 81 accuracy: 86.37%
Batch 10, Loss: 0.4996
Batch 20, Loss: 0.5164
Batch 30, Loss: 0.4616
Batch 40, Loss: 0.4518
Batch 50, Loss: 0.4391
Batch 60, Loss: 0.4638
Batch 70, Loss: 0.4923
Batch 80, Loss: 0.4778
Batch 90, Loss: 0.4108
Batch 100, Loss: 0.4419
Batch 110, Loss: 0.4816
Batch 120, Loss: 0.4672
Batch 130, Loss: 0.4871
Batch 140, Loss: 0.5107
Batch 150, Loss: 0.4520
Batch 160, Loss: 0.5075
Batch 170, Loss: 0.4951
Batch 180, Loss: 0.4485
Batch 190, Loss: 0.4455
Batch 200, Loss: 0.4796
Batch 210, Loss: 0.4813
Batch 220, Loss: 0.4515
Batch 230, Loss: 0.4619
Batch 240, Loss: 0.4522
Batch 250, Loss: 0.4834
Batch 260, Loss: 0.4786
Batch 270, Loss: 0.4929
Batch 280, Loss: 0.4732
Batch 290, Loss: 0.4815
Batch 300, Loss: 0.4569
Batch 310, Loss: 0.4835
Batch 320, Loss: 0.4429
Batch 330, Loss: 0.4657
Batch 340, Loss: 0.4591
Batch 350, Loss: 0.4753
Batch 360, Loss: 0.5008
Batch 370, Loss: 0.4798
Batch 380, Loss: 0.4675
Batch 390, Loss: 0.5016
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.233891487121582 seconds
Epoch 82 accuracy: 85.64%
Batch 10, Loss: 0.4785
Batch 20, Loss: 0.4392
Batch 30, Loss: 0.4407
Batch 40, Loss: 0.4766
Batch 50, Loss: 0.4837
Batch 60, Loss: 0.4970
Batch 70, Loss: 0.5028
Batch 80, Loss: 0.4467
Batch 90, Loss: 0.4277
Batch 100, Loss: 0.4657
Batch 110, Loss: 0.4943
Batch 120, Loss: 0.4871
Batch 130, Loss: 0.4835
Batch 140, Loss: 0.4655
Batch 150, Loss: 0.4639
Batch 160, Loss: 0.4766
Batch 170, Loss: 0.4796
Batch 180, Loss: 0.5250
Batch 190, Loss: 0.5229
Batch 200, Loss: 0.4781
Batch 210, Loss: 0.4648
Batch 220, Loss: 0.4768
Batch 230, Loss: 0.4771
Batch 240, Loss: 0.4763
Batch 250, Loss: 0.5140
Batch 260, Loss: 0.4747
Batch 270, Loss: 0.4871
Batch 280, Loss: 0.4454
Batch 290, Loss: 0.4891
Batch 300, Loss: 0.4878
Batch 310, Loss: 0.4766
Batch 320, Loss: 0.4484
Batch 330, Loss: 0.4557
Batch 340, Loss: 0.4759
Batch 350, Loss: 0.4633
Batch 360, Loss: 0.4825
Batch 370, Loss: 0.4805
Batch 380, Loss: 0.4494
Batch 390, Loss: 0.4519
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.06202459335327 seconds
Epoch 83 accuracy: 87.29%
Batch 10, Loss: 0.5013
Batch 20, Loss: 0.4477
Batch 30, Loss: 0.5114
Batch 40, Loss: 0.4725
Batch 50, Loss: 0.4538
Batch 60, Loss: 0.4720
Batch 70, Loss: 0.4184
Batch 80, Loss: 0.4348
Batch 90, Loss: 0.5011
Batch 100, Loss: 0.4994
Batch 110, Loss: 0.4842
Batch 120, Loss: 0.4904
Batch 130, Loss: 0.4932
Batch 140, Loss: 0.4600
Batch 150, Loss: 0.4748
Batch 160, Loss: 0.4681
Batch 170, Loss: 0.4845
Batch 180, Loss: 0.4795
Batch 190, Loss: 0.4611
Batch 200, Loss: 0.4614
Batch 210, Loss: 0.4961
Batch 220, Loss: 0.4899
Batch 230, Loss: 0.5113
Batch 240, Loss: 0.4739
Batch 250, Loss: 0.4888
Batch 260, Loss: 0.5156
Batch 270, Loss: 0.4673
Batch 280, Loss: 0.4269
Batch 290, Loss: 0.4430
Batch 300, Loss: 0.4593
Batch 310, Loss: 0.5056
Batch 320, Loss: 0.4692
Batch 330, Loss: 0.4695
Batch 340, Loss: 0.4768
Batch 350, Loss: 0.4769
Batch 360, Loss: 0.4697
Batch 370, Loss: 0.4702
Batch 380, Loss: 0.5145
Batch 390, Loss: 0.4820
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.06747841835022 seconds
Epoch 84 accuracy: 88.01%
Batch 10, Loss: 0.4730
Batch 20, Loss: 0.4866
Batch 30, Loss: 0.4493
Batch 40, Loss: 0.4393
Batch 50, Loss: 0.4901
Batch 60, Loss: 0.4804
Batch 70, Loss: 0.4746
Batch 80, Loss: 0.4921
Batch 90, Loss: 0.4598
Batch 100, Loss: 0.4720
Batch 110, Loss: 0.4486
Batch 120, Loss: 0.4817
Batch 130, Loss: 0.4798
Batch 140, Loss: 0.5005
Batch 150, Loss: 0.4668
Batch 160, Loss: 0.5124
Batch 170, Loss: 0.4934
Batch 180, Loss: 0.4297
Batch 190, Loss: 0.4649
Batch 200, Loss: 0.4314
Batch 210, Loss: 0.4616
Batch 220, Loss: 0.4713
Batch 230, Loss: 0.4550
Batch 240, Loss: 0.4136
Batch 250, Loss: 0.4366
Batch 260, Loss: 0.4876
Batch 270, Loss: 0.4748
Batch 280, Loss: 0.4634
Batch 290, Loss: 0.4700
Batch 300, Loss: 0.4601
Batch 310, Loss: 0.5017
Batch 320, Loss: 0.4410
Batch 330, Loss: 0.4630
Batch 340, Loss: 0.4746
Batch 350, Loss: 0.5119
Batch 360, Loss: 0.4550
Batch 370, Loss: 0.5063
Batch 380, Loss: 0.4757
Batch 390, Loss: 0.4614
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.094478368759155 seconds
Epoch 85 accuracy: 87.43%
Batch 10, Loss: 0.5076
Batch 20, Loss: 0.4575
Batch 30, Loss: 0.4440
Batch 40, Loss: 0.4501
Batch 50, Loss: 0.4732
Batch 60, Loss: 0.4598
Batch 70, Loss: 0.4310
Batch 80, Loss: 0.4713
Batch 90, Loss: 0.4882
Batch 100, Loss: 0.4419
Batch 110, Loss: 0.4316
Batch 120, Loss: 0.4543
Batch 130, Loss: 0.4601
Batch 140, Loss: 0.4723
Batch 150, Loss: 0.4442
Batch 160, Loss: 0.4918
Batch 170, Loss: 0.4904
Batch 180, Loss: 0.4778
Batch 190, Loss: 0.4877
Batch 200, Loss: 0.4835
Batch 210, Loss: 0.5089
Batch 220, Loss: 0.4901
Batch 230, Loss: 0.4728
Batch 240, Loss: 0.4684
Batch 250, Loss: 0.4891
Batch 260, Loss: 0.4221
Batch 270, Loss: 0.4281
Batch 280, Loss: 0.4893
Batch 290, Loss: 0.5043
Batch 300, Loss: 0.4513
Batch 310, Loss: 0.4771
Batch 320, Loss: 0.4628
Batch 330, Loss: 0.4753
Batch 340, Loss: 0.4676
Batch 350, Loss: 0.4668
Batch 360, Loss: 0.4424
Batch 370, Loss: 0.4975
Batch 380, Loss: 0.4707
Batch 390, Loss: 0.4560
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.042806148529053 seconds
Epoch 86 accuracy: 85.28%
Batch 10, Loss: 0.4796
Batch 20, Loss: 0.4543
Batch 30, Loss: 0.3891
Batch 40, Loss: 0.4421
Batch 50, Loss: 0.4464
Batch 60, Loss: 0.4632
Batch 70, Loss: 0.4706
Batch 80, Loss: 0.4437
Batch 90, Loss: 0.4867
Batch 100, Loss: 0.4459
Batch 110, Loss: 0.4866
Batch 120, Loss: 0.4572
Batch 130, Loss: 0.4562
Batch 140, Loss: 0.4520
Batch 150, Loss: 0.4348
Batch 160, Loss: 0.4550
Batch 170, Loss: 0.4532
Batch 180, Loss: 0.4541
Batch 190, Loss: 0.5200
Batch 200, Loss: 0.5001
Batch 210, Loss: 0.4418
Batch 220, Loss: 0.4567
Batch 230, Loss: 0.4795
Batch 240, Loss: 0.4723
Batch 250, Loss: 0.4880
Batch 260, Loss: 0.5019
Batch 270, Loss: 0.4672
Batch 280, Loss: 0.4651
Batch 290, Loss: 0.5194
Batch 300, Loss: 0.4717
Batch 310, Loss: 0.4576
Batch 320, Loss: 0.4534
Batch 330, Loss: 0.4650
Batch 340, Loss: 0.4511
Batch 350, Loss: 0.4591
Batch 360, Loss: 0.4530
Batch 370, Loss: 0.4752
Batch 380, Loss: 0.4568
Batch 390, Loss: 0.4953
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.091456413269043 seconds
Epoch 87 accuracy: 87.88%
Batch 10, Loss: 0.4423
Batch 20, Loss: 0.4856
Batch 30, Loss: 0.4627
Batch 40, Loss: 0.4584
Batch 50, Loss: 0.4559
Batch 60, Loss: 0.4550
Batch 70, Loss: 0.4626
Batch 80, Loss: 0.4443
Batch 90, Loss: 0.4382
Batch 100, Loss: 0.4607
Batch 110, Loss: 0.4623
Batch 120, Loss: 0.4513
Batch 130, Loss: 0.4948
Batch 140, Loss: 0.4858
Batch 150, Loss: 0.4758
Batch 160, Loss: 0.4325
Batch 170, Loss: 0.4372
Batch 180, Loss: 0.4457
Batch 190, Loss: 0.4295
Batch 200, Loss: 0.4561
Batch 210, Loss: 0.5048
Batch 220, Loss: 0.4530
Batch 230, Loss: 0.4876
Batch 240, Loss: 0.5204
Batch 250, Loss: 0.4488
Batch 260, Loss: 0.4533
Batch 270, Loss: 0.4787
Batch 280, Loss: 0.4824
Batch 290, Loss: 0.4531
Batch 300, Loss: 0.4888
Batch 310, Loss: 0.4608
Batch 320, Loss: 0.4846
Batch 330, Loss: 0.4743
Batch 340, Loss: 0.4566
Batch 350, Loss: 0.5124
Batch 360, Loss: 0.4813
Batch 370, Loss: 0.4498
Batch 380, Loss: 0.5172
Batch 390, Loss: 0.4639
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.071189641952515 seconds
Epoch 88 accuracy: 87.74%
Batch 10, Loss: 0.4745
Batch 20, Loss: 0.4089
Batch 30, Loss: 0.4531
Batch 40, Loss: 0.4432
Batch 50, Loss: 0.4794
Batch 60, Loss: 0.4652
Batch 70, Loss: 0.4513
Batch 80, Loss: 0.5139
Batch 90, Loss: 0.4406
Batch 100, Loss: 0.4462
Batch 110, Loss: 0.4701
Batch 120, Loss: 0.4864
Batch 130, Loss: 0.4614
Batch 140, Loss: 0.4788
Batch 150, Loss: 0.4964
Batch 160, Loss: 0.4535
Batch 170, Loss: 0.4582
Batch 180, Loss: 0.4240
Batch 190, Loss: 0.4499
Batch 200, Loss: 0.4488
Batch 210, Loss: 0.4678
Batch 220, Loss: 0.5075
Batch 230, Loss: 0.4923
Batch 240, Loss: 0.4394
Batch 250, Loss: 0.4552
Batch 260, Loss: 0.4617
Batch 270, Loss: 0.4689
Batch 280, Loss: 0.4577
Batch 290, Loss: 0.4781
Batch 300, Loss: 0.4482
Batch 310, Loss: 0.4334
Batch 320, Loss: 0.4779
Batch 330, Loss: 0.4529
Batch 340, Loss: 0.4884
Batch 350, Loss: 0.4874
Batch 360, Loss: 0.4783
Batch 370, Loss: 0.4418
Batch 380, Loss: 0.4569
Batch 390, Loss: 0.4834
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.126843690872192 seconds
Epoch 89 accuracy: 86.49%
Batch 10, Loss: 0.4629
Batch 20, Loss: 0.4556
Batch 30, Loss: 0.4727
Batch 40, Loss: 0.4727
Batch 50, Loss: 0.4638
Batch 60, Loss: 0.4467
Batch 70, Loss: 0.4419
Batch 80, Loss: 0.4632
Batch 90, Loss: 0.4417
Batch 100, Loss: 0.4500
Batch 110, Loss: 0.4408
Batch 120, Loss: 0.4816
Batch 130, Loss: 0.4848
Batch 140, Loss: 0.4619
Batch 150, Loss: 0.4663
Batch 160, Loss: 0.4651
Batch 170, Loss: 0.4561
Batch 180, Loss: 0.4486
Batch 190, Loss: 0.4905
Batch 200, Loss: 0.4460
Batch 210, Loss: 0.4444
Batch 220, Loss: 0.4429
Batch 230, Loss: 0.4727
Batch 240, Loss: 0.4492
Batch 250, Loss: 0.4563
Batch 260, Loss: 0.4436
Batch 270, Loss: 0.4630
Batch 280, Loss: 0.4828
Batch 290, Loss: 0.4414
Batch 300, Loss: 0.4236
Batch 310, Loss: 0.4646
Batch 320, Loss: 0.4175
Batch 330, Loss: 0.4671
Batch 340, Loss: 0.4959
Batch 350, Loss: 0.4507
Batch 360, Loss: 0.4726
Batch 370, Loss: 0.4508
Batch 380, Loss: 0.4666
Batch 390, Loss: 0.4394
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.086013317108154 seconds
Epoch 90 accuracy: 85.36%
Batch 10, Loss: 0.4522
Batch 20, Loss: 0.4343
Batch 30, Loss: 0.4332
Batch 40, Loss: 0.4435
Batch 50, Loss: 0.4965
Batch 60, Loss: 0.4843
Batch 70, Loss: 0.4691
Batch 80, Loss: 0.4764
Batch 90, Loss: 0.4771
Batch 100, Loss: 0.4185
Batch 110, Loss: 0.4434
Batch 120, Loss: 0.4389
Batch 130, Loss: 0.4565
Batch 140, Loss: 0.4430
Batch 150, Loss: 0.4744
Batch 160, Loss: 0.4487
Batch 170, Loss: 0.4263
Batch 180, Loss: 0.4594
Batch 190, Loss: 0.4448
Batch 200, Loss: 0.4712
Batch 210, Loss: 0.4455
Batch 220, Loss: 0.4527
Batch 230, Loss: 0.4622
Batch 240, Loss: 0.4999
Batch 250, Loss: 0.4695
Batch 260, Loss: 0.4459
Batch 270, Loss: 0.4727
Batch 280, Loss: 0.4619
Batch 290, Loss: 0.4915
Batch 300, Loss: 0.4707
Batch 310, Loss: 0.5034
Batch 320, Loss: 0.4356
Batch 330, Loss: 0.4566
Batch 340, Loss: 0.4383
Batch 350, Loss: 0.4953
Batch 360, Loss: 0.4609
Batch 370, Loss: 0.4564
Batch 380, Loss: 0.4938
Batch 390, Loss: 0.4366
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.03846526145935 seconds
Epoch 91 accuracy: 87.1%
Batch 10, Loss: 0.4851
Batch 20, Loss: 0.4715
Batch 30, Loss: 0.4499
Batch 40, Loss: 0.4777
Batch 50, Loss: 0.4803
Batch 60, Loss: 0.4824
Batch 70, Loss: 0.4751
Batch 80, Loss: 0.4364
Batch 90, Loss: 0.4302
Batch 100, Loss: 0.4700
Batch 110, Loss: 0.4724
Batch 120, Loss: 0.4732
Batch 130, Loss: 0.4665
Batch 140, Loss: 0.4298
Batch 150, Loss: 0.4442
Batch 160, Loss: 0.4545
Batch 170, Loss: 0.4740
Batch 180, Loss: 0.4200
Batch 190, Loss: 0.5035
Batch 200, Loss: 0.4482
Batch 210, Loss: 0.4593
Batch 220, Loss: 0.4632
Batch 230, Loss: 0.4774
Batch 240, Loss: 0.4391
Batch 250, Loss: 0.4508
Batch 260, Loss: 0.4684
Batch 270, Loss: 0.4845
Batch 280, Loss: 0.4325
Batch 290, Loss: 0.4490
Batch 300, Loss: 0.4511
Batch 310, Loss: 0.4380
Batch 320, Loss: 0.4786
Batch 330, Loss: 0.4604
Batch 340, Loss: 0.4777
Batch 350, Loss: 0.4197
Batch 360, Loss: 0.4216
Batch 370, Loss: 0.4526
Batch 380, Loss: 0.4498
Batch 390, Loss: 0.4474
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.071107625961304 seconds
Epoch 92 accuracy: 88.38%
Batch 10, Loss: 0.4305
Batch 20, Loss: 0.4168
Batch 30, Loss: 0.4572
Batch 40, Loss: 0.4528
Batch 50, Loss: 0.4590
Batch 60, Loss: 0.4381
Batch 70, Loss: 0.4369
Batch 80, Loss: 0.4693
Batch 90, Loss: 0.4721
Batch 100, Loss: 0.4397
Batch 110, Loss: 0.4453
Batch 120, Loss: 0.5000
Batch 130, Loss: 0.4600
Batch 140, Loss: 0.4560
Batch 150, Loss: 0.4162
Batch 160, Loss: 0.4790
Batch 170, Loss: 0.4323
Batch 180, Loss: 0.4552
Batch 190, Loss: 0.4449
Batch 200, Loss: 0.4363
Batch 210, Loss: 0.4534
Batch 220, Loss: 0.4761
Batch 230, Loss: 0.4721
Batch 240, Loss: 0.4551
Batch 250, Loss: 0.4982
Batch 260, Loss: 0.4843
Batch 270, Loss: 0.4423
Batch 280, Loss: 0.4355
Batch 290, Loss: 0.4344
Batch 300, Loss: 0.4857
Batch 310, Loss: 0.4399
Batch 320, Loss: 0.4083
Batch 330, Loss: 0.4881
Batch 340, Loss: 0.4570
Batch 350, Loss: 0.4759
Batch 360, Loss: 0.4387
Batch 370, Loss: 0.4301
Batch 380, Loss: 0.4492
Batch 390, Loss: 0.4524
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.082285165786743 seconds
Epoch 93 accuracy: 88.81%
Batch 10, Loss: 0.4368
Batch 20, Loss: 0.4122
Batch 30, Loss: 0.4522
Batch 40, Loss: 0.3978
Batch 50, Loss: 0.3937
Batch 60, Loss: 0.4362
Batch 70, Loss: 0.4778
Batch 80, Loss: 0.4448
Batch 90, Loss: 0.4361
Batch 100, Loss: 0.4424
Batch 110, Loss: 0.3988
Batch 120, Loss: 0.4656
Batch 130, Loss: 0.4394
Batch 140, Loss: 0.4503
Batch 150, Loss: 0.4254
Batch 160, Loss: 0.4556
Batch 170, Loss: 0.5100
Batch 180, Loss: 0.4078
Batch 190, Loss: 0.4608
Batch 200, Loss: 0.4499
Batch 210, Loss: 0.4375
Batch 220, Loss: 0.4821
Batch 230, Loss: 0.4431
Batch 240, Loss: 0.4704
Batch 250, Loss: 0.4472
Batch 260, Loss: 0.4473
Batch 270, Loss: 0.4440
Batch 280, Loss: 0.4595
Batch 290, Loss: 0.4456
Batch 300, Loss: 0.4200
Batch 310, Loss: 0.4341
Batch 320, Loss: 0.4441
Batch 330, Loss: 0.4586
Batch 340, Loss: 0.4612
Batch 350, Loss: 0.4346
Batch 360, Loss: 0.4481
Batch 370, Loss: 0.4540
Batch 380, Loss: 0.4604
Batch 390, Loss: 0.4671
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.06972026824951 seconds
Epoch 94 accuracy: 87.64%
Batch 10, Loss: 0.4380
Batch 20, Loss: 0.4823
Batch 30, Loss: 0.4320
Batch 40, Loss: 0.4396
Batch 50, Loss: 0.4359
Batch 60, Loss: 0.4471
Batch 70, Loss: 0.4390
Batch 80, Loss: 0.4652
Batch 90, Loss: 0.4474
Batch 100, Loss: 0.4646
Batch 110, Loss: 0.4603
Batch 120, Loss: 0.4656
Batch 130, Loss: 0.5059
Batch 140, Loss: 0.4463
Batch 150, Loss: 0.4592
Batch 160, Loss: 0.4731
Batch 170, Loss: 0.4543
Batch 180, Loss: 0.4494
Batch 190, Loss: 0.4361
Batch 200, Loss: 0.4940
Batch 210, Loss: 0.4488
Batch 220, Loss: 0.4835
Batch 230, Loss: 0.4240
Batch 240, Loss: 0.4384
Batch 250, Loss: 0.4368
Batch 260, Loss: 0.4781
Batch 270, Loss: 0.4504
Batch 280, Loss: 0.4203
Batch 290, Loss: 0.4479
Batch 300, Loss: 0.4287
Batch 310, Loss: 0.4295
Batch 320, Loss: 0.4259
Batch 330, Loss: 0.4578
Batch 340, Loss: 0.4706
Batch 350, Loss: 0.4627
Batch 360, Loss: 0.4325
Batch 370, Loss: 0.4334
Batch 380, Loss: 0.4517
Batch 390, Loss: 0.4692
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.051347732543945 seconds
Epoch 95 accuracy: 84.99%
Batch 10, Loss: 0.4471
Batch 20, Loss: 0.4386
Batch 30, Loss: 0.4353
Batch 40, Loss: 0.4395
Batch 50, Loss: 0.4735
Batch 60, Loss: 0.4372
Batch 70, Loss: 0.4146
Batch 80, Loss: 0.4455
Batch 90, Loss: 0.4470
Batch 100, Loss: 0.4670
Batch 110, Loss: 0.4369
Batch 120, Loss: 0.4257
Batch 130, Loss: 0.4428
Batch 140, Loss: 0.4247
Batch 150, Loss: 0.3813
Batch 160, Loss: 0.4218
Batch 170, Loss: 0.4592
Batch 180, Loss: 0.4567
Batch 190, Loss: 0.4281
Batch 200, Loss: 0.4031
Batch 210, Loss: 0.4257
Batch 220, Loss: 0.4811
Batch 230, Loss: 0.4629
Batch 240, Loss: 0.4708
Batch 250, Loss: 0.4722
Batch 260, Loss: 0.4812
Batch 270, Loss: 0.4582
Batch 280, Loss: 0.4412
Batch 290, Loss: 0.4338
Batch 300, Loss: 0.4572
Batch 310, Loss: 0.4589
Batch 320, Loss: 0.3977
Batch 330, Loss: 0.4601
Batch 340, Loss: 0.4648
Batch 350, Loss: 0.4092
Batch 360, Loss: 0.4450
Batch 370, Loss: 0.4414
Batch 380, Loss: 0.4649
Batch 390, Loss: 0.4236
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.04630947113037 seconds
Epoch 96 accuracy: 87.45%
Batch 10, Loss: 0.4549
Batch 20, Loss: 0.4487
Batch 30, Loss: 0.4117
Batch 40, Loss: 0.4326
Batch 50, Loss: 0.4269
Batch 60, Loss: 0.4257
Batch 70, Loss: 0.4215
Batch 80, Loss: 0.4373
Batch 90, Loss: 0.4378
Batch 100, Loss: 0.5191
Batch 110, Loss: 0.4521
Batch 120, Loss: 0.4093
Batch 130, Loss: 0.4376
Batch 140, Loss: 0.4124
Batch 150, Loss: 0.4314
Batch 160, Loss: 0.4395
Batch 170, Loss: 0.4345
Batch 180, Loss: 0.4262
Batch 190, Loss: 0.4411
Batch 200, Loss: 0.4272
Batch 210, Loss: 0.4222
Batch 220, Loss: 0.4109
Batch 230, Loss: 0.4366
Batch 240, Loss: 0.4341
Batch 250, Loss: 0.4764
Batch 260, Loss: 0.4578
Batch 270, Loss: 0.4359
Batch 280, Loss: 0.4598
Batch 290, Loss: 0.4531
Batch 300, Loss: 0.4363
Batch 310, Loss: 0.4596
Batch 320, Loss: 0.4644
Batch 330, Loss: 0.4638
Batch 340, Loss: 0.4434
Batch 350, Loss: 0.4826
Batch 360, Loss: 0.4470
Batch 370, Loss: 0.4455
Batch 380, Loss: 0.4066
Batch 390, Loss: 0.4203
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.075326204299927 seconds
Epoch 97 accuracy: 87.85%
Batch 10, Loss: 0.4420
Batch 20, Loss: 0.4476
Batch 30, Loss: 0.4433
Batch 40, Loss: 0.4103
Batch 50, Loss: 0.4224
Batch 60, Loss: 0.4633
Batch 70, Loss: 0.4130
Batch 80, Loss: 0.4469
Batch 90, Loss: 0.4175
Batch 100, Loss: 0.4597
Batch 110, Loss: 0.4599
Batch 120, Loss: 0.4209
Batch 130, Loss: 0.4626
Batch 140, Loss: 0.4516
Batch 150, Loss: 0.4163
Batch 160, Loss: 0.4734
Batch 170, Loss: 0.4376
Batch 180, Loss: 0.4705
Batch 190, Loss: 0.4281
Batch 200, Loss: 0.4194
Batch 210, Loss: 0.4439
Batch 220, Loss: 0.4578
Batch 230, Loss: 0.4259
Batch 240, Loss: 0.4392
Batch 250, Loss: 0.4538
Batch 260, Loss: 0.4406
Batch 270, Loss: 0.4564
Batch 280, Loss: 0.4277
Batch 290, Loss: 0.4489
Batch 300, Loss: 0.4602
Batch 310, Loss: 0.4290
Batch 320, Loss: 0.4419
Batch 330, Loss: 0.4821
Batch 340, Loss: 0.4425
Batch 350, Loss: 0.4675
Batch 360, Loss: 0.4428
Batch 370, Loss: 0.4344
Batch 380, Loss: 0.4571
Batch 390, Loss: 0.4360
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.115782737731934 seconds
Epoch 98 accuracy: 88.31%
Batch 10, Loss: 0.4454
Batch 20, Loss: 0.4509
Batch 30, Loss: 0.4476
Batch 40, Loss: 0.4174
Batch 50, Loss: 0.4407
Batch 60, Loss: 0.4365
Batch 70, Loss: 0.4301
Batch 80, Loss: 0.4791
Batch 90, Loss: 0.4518
Batch 100, Loss: 0.4789
Batch 110, Loss: 0.4500
Batch 120, Loss: 0.4303
Batch 130, Loss: 0.4321
Batch 140, Loss: 0.4558
Batch 150, Loss: 0.4295
Batch 160, Loss: 0.4327
Batch 170, Loss: 0.4154
Batch 180, Loss: 0.4332
Batch 190, Loss: 0.4252
Batch 200, Loss: 0.4457
Batch 210, Loss: 0.4275
Batch 220, Loss: 0.4552
Batch 230, Loss: 0.4626
Batch 240, Loss: 0.4386
Batch 250, Loss: 0.4916
Batch 260, Loss: 0.4442
Batch 270, Loss: 0.4337
Batch 280, Loss: 0.4468
Batch 290, Loss: 0.4452
Batch 300, Loss: 0.4538
Batch 310, Loss: 0.4465
Batch 320, Loss: 0.4162
Batch 330, Loss: 0.4238
Batch 340, Loss: 0.4461
Batch 350, Loss: 0.4502
Batch 360, Loss: 0.4679
Batch 370, Loss: 0.4623
Batch 380, Loss: 0.4378
Batch 390, Loss: 0.4665
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.041946172714233 seconds
Epoch 99 accuracy: 87.17%
Batch 10, Loss: 0.4378
Batch 20, Loss: 0.4378
Batch 30, Loss: 0.4658
Batch 40, Loss: 0.4755
Batch 50, Loss: 0.4666
Batch 60, Loss: 0.4709
Batch 70, Loss: 0.4148
Batch 80, Loss: 0.4465
Batch 90, Loss: 0.4200
Batch 100, Loss: 0.4533
Batch 110, Loss: 0.4162
Batch 120, Loss: 0.4286
Batch 130, Loss: 0.4505
Batch 140, Loss: 0.4435
Batch 150, Loss: 0.4465
Batch 160, Loss: 0.4510
Batch 170, Loss: 0.4308
Batch 180, Loss: 0.4367
Batch 190, Loss: 0.4067
Batch 200, Loss: 0.4073
Batch 210, Loss: 0.4289
Batch 220, Loss: 0.4343
Batch 230, Loss: 0.4510
Batch 240, Loss: 0.4272
Batch 250, Loss: 0.4348
Batch 260, Loss: 0.4278
Batch 270, Loss: 0.3976
Batch 280, Loss: 0.4761
Batch 290, Loss: 0.4680
Batch 300, Loss: 0.4129
Batch 310, Loss: 0.4082
Batch 320, Loss: 0.4406
Batch 330, Loss: 0.4114
Batch 340, Loss: 0.4629
Batch 350, Loss: 0.4521
Batch 360, Loss: 0.4400
Batch 370, Loss: 0.4659
Batch 380, Loss: 0.4399
Batch 390, Loss: 0.4574
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.127012729644775 seconds
Epoch 100 accuracy: 87.05%
Batch 10, Loss: 0.4056
Batch 20, Loss: 0.4079
Batch 30, Loss: 0.3992
Batch 40, Loss: 0.4087
Batch 50, Loss: 0.4252
Batch 60, Loss: 0.4432
Batch 70, Loss: 0.4335
Batch 80, Loss: 0.4391
Batch 90, Loss: 0.4528
Batch 100, Loss: 0.4246
Batch 110, Loss: 0.4219
Batch 120, Loss: 0.4025
Batch 130, Loss: 0.4263
Batch 140, Loss: 0.4263
Batch 150, Loss: 0.4218
Batch 160, Loss: 0.4352
Batch 170, Loss: 0.3804
Batch 180, Loss: 0.4428
Batch 190, Loss: 0.4126
Batch 200, Loss: 0.4367
Batch 210, Loss: 0.4426
Batch 220, Loss: 0.4405
Batch 230, Loss: 0.4095
Batch 240, Loss: 0.4430
Batch 250, Loss: 0.3765
Batch 260, Loss: 0.4359
Batch 270, Loss: 0.4450
Batch 280, Loss: 0.4355
Batch 290, Loss: 0.4556
Batch 300, Loss: 0.4462
Batch 310, Loss: 0.4794
Batch 320, Loss: 0.4435
Batch 330, Loss: 0.4558
Batch 340, Loss: 0.4820
Batch 350, Loss: 0.4248
Batch 360, Loss: 0.4059
Batch 370, Loss: 0.4310
Batch 380, Loss: 0.4488
Batch 390, Loss: 0.4046
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.095548152923584 seconds
Epoch 101 accuracy: 86.94%
Batch 10, Loss: 0.4162
Batch 20, Loss: 0.4052
Batch 30, Loss: 0.4573
Batch 40, Loss: 0.4402
Batch 50, Loss: 0.4302
Batch 60, Loss: 0.4620
Batch 70, Loss: 0.4159
Batch 80, Loss: 0.4328
Batch 90, Loss: 0.4255
Batch 100, Loss: 0.4440
Batch 110, Loss: 0.4309
Batch 120, Loss: 0.4479
Batch 130, Loss: 0.4239
Batch 140, Loss: 0.4311
Batch 150, Loss: 0.4293
Batch 160, Loss: 0.3940
Batch 170, Loss: 0.4011
Batch 180, Loss: 0.4169
Batch 190, Loss: 0.4194
Batch 200, Loss: 0.4662
Batch 210, Loss: 0.4325
Batch 220, Loss: 0.4460
Batch 230, Loss: 0.4828
Batch 240, Loss: 0.4258
Batch 250, Loss: 0.3747
Batch 260, Loss: 0.4332
Batch 270, Loss: 0.4467
Batch 280, Loss: 0.4382
Batch 290, Loss: 0.4550
Batch 300, Loss: 0.4320
Batch 310, Loss: 0.4132
Batch 320, Loss: 0.4261
Batch 330, Loss: 0.4175
Batch 340, Loss: 0.4348
Batch 350, Loss: 0.4721
Batch 360, Loss: 0.4469
Batch 370, Loss: 0.3928
Batch 380, Loss: 0.4261
Batch 390, Loss: 0.4359
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.023927211761475 seconds
Epoch 102 accuracy: 89.68%
Batch 10, Loss: 0.4588
Batch 20, Loss: 0.4140
Batch 30, Loss: 0.4352
Batch 40, Loss: 0.4780
Batch 50, Loss: 0.4764
Batch 60, Loss: 0.4206
Batch 70, Loss: 0.4081
Batch 80, Loss: 0.4244
Batch 90, Loss: 0.4018
Batch 100, Loss: 0.4285
Batch 110, Loss: 0.4283
Batch 120, Loss: 0.4691
Batch 130, Loss: 0.4739
Batch 140, Loss: 0.4297
Batch 150, Loss: 0.4344
Batch 160, Loss: 0.4310
Batch 170, Loss: 0.4271
Batch 180, Loss: 0.4224
Batch 190, Loss: 0.4036
Batch 200, Loss: 0.3961
Batch 210, Loss: 0.4194
Batch 220, Loss: 0.4227
Batch 230, Loss: 0.4392
Batch 240, Loss: 0.4065
Batch 250, Loss: 0.4141
Batch 260, Loss: 0.4204
Batch 270, Loss: 0.4346
Batch 280, Loss: 0.4665
Batch 290, Loss: 0.4486
Batch 300, Loss: 0.4328
Batch 310, Loss: 0.4204
Batch 320, Loss: 0.3793
Batch 330, Loss: 0.4023
Batch 340, Loss: 0.4521
Batch 350, Loss: 0.4481
Batch 360, Loss: 0.4561
Batch 370, Loss: 0.4359
Batch 380, Loss: 0.4468
Batch 390, Loss: 0.4389
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.053136587142944 seconds
Epoch 103 accuracy: 89.62%
Batch 10, Loss: 0.4117
Batch 20, Loss: 0.4203
Batch 30, Loss: 0.4020
Batch 40, Loss: 0.4246
Batch 50, Loss: 0.4111
Batch 60, Loss: 0.4102
Batch 70, Loss: 0.3954
Batch 80, Loss: 0.4122
Batch 90, Loss: 0.4399
Batch 100, Loss: 0.3888
Batch 110, Loss: 0.4087
Batch 120, Loss: 0.4037
Batch 130, Loss: 0.4701
Batch 140, Loss: 0.4462
Batch 150, Loss: 0.3975
Batch 160, Loss: 0.4435
Batch 170, Loss: 0.4250
Batch 180, Loss: 0.4343
Batch 190, Loss: 0.4377
Batch 200, Loss: 0.4282
Batch 210, Loss: 0.4514
Batch 220, Loss: 0.4542
Batch 230, Loss: 0.4638
Batch 240, Loss: 0.4307
Batch 250, Loss: 0.4204
Batch 260, Loss: 0.4221
Batch 270, Loss: 0.4471
Batch 280, Loss: 0.4587
Batch 290, Loss: 0.4222
Batch 300, Loss: 0.4313
Batch 310, Loss: 0.4624
Batch 320, Loss: 0.4240
Batch 330, Loss: 0.4063
Batch 340, Loss: 0.4133
Batch 350, Loss: 0.3859
Batch 360, Loss: 0.4418
Batch 370, Loss: 0.4579
Batch 380, Loss: 0.4527
Batch 390, Loss: 0.4284
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.06353187561035 seconds
Epoch 104 accuracy: 87.13%
Batch 10, Loss: 0.4627
Batch 20, Loss: 0.3950
Batch 30, Loss: 0.4170
Batch 40, Loss: 0.4262
Batch 50, Loss: 0.4419
Batch 60, Loss: 0.4124
Batch 70, Loss: 0.4428
Batch 80, Loss: 0.4178
Batch 90, Loss: 0.3886
Batch 100, Loss: 0.4113
Batch 110, Loss: 0.4201
Batch 120, Loss: 0.4090
Batch 130, Loss: 0.4085
Batch 140, Loss: 0.4320
Batch 150, Loss: 0.4335
Batch 160, Loss: 0.4575
Batch 170, Loss: 0.4478
Batch 180, Loss: 0.4291
Batch 190, Loss: 0.4303
Batch 200, Loss: 0.4064
Batch 210, Loss: 0.4032
Batch 220, Loss: 0.4529
Batch 230, Loss: 0.4463
Batch 240, Loss: 0.4337
Batch 250, Loss: 0.4519
Batch 260, Loss: 0.4120
Batch 270, Loss: 0.4305
Batch 280, Loss: 0.4443
Batch 290, Loss: 0.3969
Batch 300, Loss: 0.4390
Batch 310, Loss: 0.4084
Batch 320, Loss: 0.4164
Batch 330, Loss: 0.3958
Batch 340, Loss: 0.4366
Batch 350, Loss: 0.3833
Batch 360, Loss: 0.4195
Batch 370, Loss: 0.4629
Batch 380, Loss: 0.4185
Batch 390, Loss: 0.4551
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.065770149230957 seconds
Epoch 105 accuracy: 88.88%
Batch 10, Loss: 0.4023
Batch 20, Loss: 0.4657
Batch 30, Loss: 0.3928
Batch 40, Loss: 0.3864
Batch 50, Loss: 0.3892
Batch 60, Loss: 0.4216
Batch 70, Loss: 0.4041
Batch 80, Loss: 0.4028
Batch 90, Loss: 0.4222
Batch 100, Loss: 0.4251
Batch 110, Loss: 0.4011
Batch 120, Loss: 0.4257
Batch 130, Loss: 0.4178
Batch 140, Loss: 0.4446
Batch 150, Loss: 0.3834
Batch 160, Loss: 0.4282
Batch 170, Loss: 0.4190
Batch 180, Loss: 0.4336
Batch 190, Loss: 0.4093
Batch 200, Loss: 0.4128
Batch 210, Loss: 0.4272
Batch 220, Loss: 0.4268
Batch 230, Loss: 0.4000
Batch 240, Loss: 0.4240
Batch 250, Loss: 0.4319
Batch 260, Loss: 0.4607
Batch 270, Loss: 0.4357
Batch 280, Loss: 0.4171
Batch 290, Loss: 0.4101
Batch 300, Loss: 0.4284
Batch 310, Loss: 0.4056
Batch 320, Loss: 0.4118
Batch 330, Loss: 0.4226
Batch 340, Loss: 0.4651
Batch 350, Loss: 0.4290
Batch 360, Loss: 0.4562
Batch 370, Loss: 0.4230
Batch 380, Loss: 0.4320
Batch 390, Loss: 0.4107
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.04349684715271 seconds
Epoch 106 accuracy: 88.52%
Batch 10, Loss: 0.4018
Batch 20, Loss: 0.3729
Batch 30, Loss: 0.4232
Batch 40, Loss: 0.4137
Batch 50, Loss: 0.4179
Batch 60, Loss: 0.3604
Batch 70, Loss: 0.4359
Batch 80, Loss: 0.4066
Batch 90, Loss: 0.4261
Batch 100, Loss: 0.4065
Batch 110, Loss: 0.4246
Batch 120, Loss: 0.4166
Batch 130, Loss: 0.4298
Batch 140, Loss: 0.4038
Batch 150, Loss: 0.4220
Batch 160, Loss: 0.4348
Batch 170, Loss: 0.4639
Batch 180, Loss: 0.4371
Batch 190, Loss: 0.4598
Batch 200, Loss: 0.3955
Batch 210, Loss: 0.4126
Batch 220, Loss: 0.4575
Batch 230, Loss: 0.3936
Batch 240, Loss: 0.3851
Batch 250, Loss: 0.3951
Batch 260, Loss: 0.4301
Batch 270, Loss: 0.4107
Batch 280, Loss: 0.4630
Batch 290, Loss: 0.4315
Batch 300, Loss: 0.3837
Batch 310, Loss: 0.4329
Batch 320, Loss: 0.4346
Batch 330, Loss: 0.4045
Batch 340, Loss: 0.4023
Batch 350, Loss: 0.3978
Batch 360, Loss: 0.3929
Batch 370, Loss: 0.3741
Batch 380, Loss: 0.3836
Batch 390, Loss: 0.3793
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 24.98516082763672 seconds
Epoch 107 accuracy: 88.8%
Batch 10, Loss: 0.3988
Batch 20, Loss: 0.4175
Batch 30, Loss: 0.4362
Batch 40, Loss: 0.3950
Batch 50, Loss: 0.4143
Batch 60, Loss: 0.4510
Batch 70, Loss: 0.4048
Batch 80, Loss: 0.4110
Batch 90, Loss: 0.4152
Batch 100, Loss: 0.4585
Batch 110, Loss: 0.4347
Batch 120, Loss: 0.4352
Batch 130, Loss: 0.4410
Batch 140, Loss: 0.4177
Batch 150, Loss: 0.3907
Batch 160, Loss: 0.4166
Batch 170, Loss: 0.3952
Batch 180, Loss: 0.4042
Batch 190, Loss: 0.4433
Batch 200, Loss: 0.4444
Batch 210, Loss: 0.3939
Batch 220, Loss: 0.4200
Batch 230, Loss: 0.4129
Batch 240, Loss: 0.4294
Batch 250, Loss: 0.4186
Batch 260, Loss: 0.4062
Batch 270, Loss: 0.4089
Batch 280, Loss: 0.4124
Batch 290, Loss: 0.4061
Batch 300, Loss: 0.4271
Batch 310, Loss: 0.4307
Batch 320, Loss: 0.4038
Batch 330, Loss: 0.4444
Batch 340, Loss: 0.4196
Batch 350, Loss: 0.4263
Batch 360, Loss: 0.4093
Batch 370, Loss: 0.4281
Batch 380, Loss: 0.4242
Batch 390, Loss: 0.4035
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 24.976983785629272 seconds
Epoch 108 accuracy: 90.54%
Batch 10, Loss: 0.3902
Batch 20, Loss: 0.4126
Batch 30, Loss: 0.3726
Batch 40, Loss: 0.3868
Batch 50, Loss: 0.4488
Batch 60, Loss: 0.4088
Batch 70, Loss: 0.4087
Batch 80, Loss: 0.4501
Batch 90, Loss: 0.4334
Batch 100, Loss: 0.4309
Batch 110, Loss: 0.4075
Batch 120, Loss: 0.3925
Batch 130, Loss: 0.3742
Batch 140, Loss: 0.4224
Batch 150, Loss: 0.3805
Batch 160, Loss: 0.3767
Batch 170, Loss: 0.4218
Batch 180, Loss: 0.3830
Batch 190, Loss: 0.4065
Batch 200, Loss: 0.4069
Batch 210, Loss: 0.3771
Batch 220, Loss: 0.4174
Batch 230, Loss: 0.4076
Batch 240, Loss: 0.4089
Batch 250, Loss: 0.4116
Batch 260, Loss: 0.4269
Batch 270, Loss: 0.3808
Batch 280, Loss: 0.4290
Batch 290, Loss: 0.4291
Batch 300, Loss: 0.4061
Batch 310, Loss: 0.4207
Batch 320, Loss: 0.3850
Batch 330, Loss: 0.4323
Batch 340, Loss: 0.4242
Batch 350, Loss: 0.4321
Batch 360, Loss: 0.4328
Batch 370, Loss: 0.4195
Batch 380, Loss: 0.4004
Batch 390, Loss: 0.4432
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.056078672409058 seconds
Epoch 109 accuracy: 88.42%
Batch 10, Loss: 0.4202
Batch 20, Loss: 0.4226
Batch 30, Loss: 0.4364
Batch 40, Loss: 0.3795
Batch 50, Loss: 0.4192
Batch 60, Loss: 0.4114
Batch 70, Loss: 0.4133
Batch 80, Loss: 0.4149
Batch 90, Loss: 0.4048
Batch 100, Loss: 0.4307
Batch 110, Loss: 0.3628
Batch 120, Loss: 0.4164
Batch 130, Loss: 0.3997
Batch 140, Loss: 0.4031
Batch 150, Loss: 0.4022
Batch 160, Loss: 0.4181
Batch 170, Loss: 0.3819
Batch 180, Loss: 0.4032
Batch 190, Loss: 0.4252
Batch 200, Loss: 0.4133
Batch 210, Loss: 0.4485
Batch 220, Loss: 0.4059
Batch 230, Loss: 0.3980
Batch 240, Loss: 0.3870
Batch 250, Loss: 0.4384
Batch 260, Loss: 0.4248
Batch 270, Loss: 0.3982
Batch 280, Loss: 0.4265
Batch 290, Loss: 0.4332
Batch 300, Loss: 0.4026
Batch 310, Loss: 0.3973
Batch 320, Loss: 0.4022
Batch 330, Loss: 0.4386
Batch 340, Loss: 0.3952
Batch 350, Loss: 0.4063
Batch 360, Loss: 0.4309
Batch 370, Loss: 0.4009
Batch 380, Loss: 0.3940
Batch 390, Loss: 0.4043
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.012523651123047 seconds
Epoch 110 accuracy: 85.7%
Batch 10, Loss: 0.4255
Batch 20, Loss: 0.3973
Batch 30, Loss: 0.3943
Batch 40, Loss: 0.3885
Batch 50, Loss: 0.3875
Batch 60, Loss: 0.4081
Batch 70, Loss: 0.4047
Batch 80, Loss: 0.3725
Batch 90, Loss: 0.4258
Batch 100, Loss: 0.3951
Batch 110, Loss: 0.4427
Batch 120, Loss: 0.3889
Batch 130, Loss: 0.4213
Batch 140, Loss: 0.3867
Batch 150, Loss: 0.4336
Batch 160, Loss: 0.3853
Batch 170, Loss: 0.4205
Batch 180, Loss: 0.3946
Batch 190, Loss: 0.4248
Batch 200, Loss: 0.3704
Batch 210, Loss: 0.4170
Batch 220, Loss: 0.4316
Batch 230, Loss: 0.3966
Batch 240, Loss: 0.3842
Batch 250, Loss: 0.4282
Batch 260, Loss: 0.3772
Batch 270, Loss: 0.4107
Batch 280, Loss: 0.4103
Batch 290, Loss: 0.4047
Batch 300, Loss: 0.4106
Batch 310, Loss: 0.4012
Batch 320, Loss: 0.4080
Batch 330, Loss: 0.3997
Batch 340, Loss: 0.4167
Batch 350, Loss: 0.4121
Batch 360, Loss: 0.4064
Batch 370, Loss: 0.4120
Batch 380, Loss: 0.3927
Batch 390, Loss: 0.4189
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.176449298858643 seconds
Epoch 111 accuracy: 90.15%
Batch 10, Loss: 0.3983
Batch 20, Loss: 0.3807
Batch 30, Loss: 0.4142
Batch 40, Loss: 0.4082
Batch 50, Loss: 0.4176
Batch 60, Loss: 0.3988
Batch 70, Loss: 0.3685
Batch 80, Loss: 0.4346
Batch 90, Loss: 0.3991
Batch 100, Loss: 0.3969
Batch 110, Loss: 0.4366
Batch 120, Loss: 0.3931
Batch 130, Loss: 0.3963
Batch 140, Loss: 0.4322
Batch 150, Loss: 0.3804
Batch 160, Loss: 0.4276
Batch 170, Loss: 0.4328
Batch 180, Loss: 0.4404
Batch 190, Loss: 0.4284
Batch 200, Loss: 0.4122
Batch 210, Loss: 0.4150
Batch 220, Loss: 0.3885
Batch 230, Loss: 0.3997
Batch 240, Loss: 0.4059
Batch 250, Loss: 0.4111
Batch 260, Loss: 0.3820
Batch 270, Loss: 0.4305
Batch 280, Loss: 0.4131
Batch 290, Loss: 0.4028
Batch 300, Loss: 0.4016
Batch 310, Loss: 0.4074
Batch 320, Loss: 0.3983
Batch 330, Loss: 0.3860
Batch 340, Loss: 0.3952
Batch 350, Loss: 0.4032
Batch 360, Loss: 0.4144
Batch 370, Loss: 0.4460
Batch 380, Loss: 0.4172
Batch 390, Loss: 0.3882
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.09417963027954 seconds
Epoch 112 accuracy: 89.52%
Batch 10, Loss: 0.4122
Batch 20, Loss: 0.4096
Batch 30, Loss: 0.4326
Batch 40, Loss: 0.4130
Batch 50, Loss: 0.4017
Batch 60, Loss: 0.3907
Batch 70, Loss: 0.4318
Batch 80, Loss: 0.4112
Batch 90, Loss: 0.4178
Batch 100, Loss: 0.4065
Batch 110, Loss: 0.3839
Batch 120, Loss: 0.3915
Batch 130, Loss: 0.3979
Batch 140, Loss: 0.4577
Batch 150, Loss: 0.3991
Batch 160, Loss: 0.4062
Batch 170, Loss: 0.3886
Batch 180, Loss: 0.3970
Batch 190, Loss: 0.4114
Batch 200, Loss: 0.4049
Batch 210, Loss: 0.4113
Batch 220, Loss: 0.3548
Batch 230, Loss: 0.3888
Batch 240, Loss: 0.4242
Batch 250, Loss: 0.3822
Batch 260, Loss: 0.4365
Batch 270, Loss: 0.3692
Batch 280, Loss: 0.4162
Batch 290, Loss: 0.4033
Batch 300, Loss: 0.4021
Batch 310, Loss: 0.4239
Batch 320, Loss: 0.3978
Batch 330, Loss: 0.3925
Batch 340, Loss: 0.4230
Batch 350, Loss: 0.3847
Batch 360, Loss: 0.3536
Batch 370, Loss: 0.3844
Batch 380, Loss: 0.4331
Batch 390, Loss: 0.3536
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.10188055038452 seconds
Epoch 113 accuracy: 90.01%
Batch 10, Loss: 0.3916
Batch 20, Loss: 0.3644
Batch 30, Loss: 0.3704
Batch 40, Loss: 0.4069
Batch 50, Loss: 0.3972
Batch 60, Loss: 0.4233
Batch 70, Loss: 0.3948
Batch 80, Loss: 0.4146
Batch 90, Loss: 0.3829
Batch 100, Loss: 0.4001
Batch 110, Loss: 0.3643
Batch 120, Loss: 0.4366
Batch 130, Loss: 0.3987
Batch 140, Loss: 0.3824
Batch 150, Loss: 0.4078
Batch 160, Loss: 0.4105
Batch 170, Loss: 0.4397
Batch 180, Loss: 0.4122
Batch 190, Loss: 0.3937
Batch 200, Loss: 0.4006
Batch 210, Loss: 0.4139
Batch 220, Loss: 0.3978
Batch 230, Loss: 0.3816
Batch 240, Loss: 0.3953
Batch 250, Loss: 0.4096
Batch 260, Loss: 0.3983
Batch 270, Loss: 0.4103
Batch 280, Loss: 0.4138
Batch 290, Loss: 0.4242
Batch 300, Loss: 0.3989
Batch 310, Loss: 0.3958
Batch 320, Loss: 0.3760
Batch 330, Loss: 0.3793
Batch 340, Loss: 0.4051
Batch 350, Loss: 0.4055
Batch 360, Loss: 0.4240
Batch 370, Loss: 0.4031
Batch 380, Loss: 0.4356
Batch 390, Loss: 0.3893
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.11825704574585 seconds
Epoch 114 accuracy: 91.01%
Batch 10, Loss: 0.4076
Batch 20, Loss: 0.4073
Batch 30, Loss: 0.3830
Batch 40, Loss: 0.4004
Batch 50, Loss: 0.3944
Batch 60, Loss: 0.3801
Batch 70, Loss: 0.3876
Batch 80, Loss: 0.4038
Batch 90, Loss: 0.3906
Batch 100, Loss: 0.4377
Batch 110, Loss: 0.4075
Batch 120, Loss: 0.3742
Batch 130, Loss: 0.3463
Batch 140, Loss: 0.3345
Batch 150, Loss: 0.3467
Batch 160, Loss: 0.3889
Batch 170, Loss: 0.3997
Batch 180, Loss: 0.4313
Batch 190, Loss: 0.3937
Batch 200, Loss: 0.4128
Batch 210, Loss: 0.3818
Batch 220, Loss: 0.3758
Batch 230, Loss: 0.4132
Batch 240, Loss: 0.3877
Batch 250, Loss: 0.3814
Batch 260, Loss: 0.3788
Batch 270, Loss: 0.3716
Batch 280, Loss: 0.3952
Batch 290, Loss: 0.3535
Batch 300, Loss: 0.3996
Batch 310, Loss: 0.3837
Batch 320, Loss: 0.4425
Batch 330, Loss: 0.4476
Batch 340, Loss: 0.4228
Batch 350, Loss: 0.4121
Batch 360, Loss: 0.4218
Batch 370, Loss: 0.4183
Batch 380, Loss: 0.4132
Batch 390, Loss: 0.3771
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.093120336532593 seconds
Epoch 115 accuracy: 90.71%
Batch 10, Loss: 0.3584
Batch 20, Loss: 0.3999
Batch 30, Loss: 0.3789
Batch 40, Loss: 0.4191
Batch 50, Loss: 0.3781
Batch 60, Loss: 0.3930
Batch 70, Loss: 0.3783
Batch 80, Loss: 0.3856
Batch 90, Loss: 0.3927
Batch 100, Loss: 0.3575
Batch 110, Loss: 0.3907
Batch 120, Loss: 0.3877
Batch 130, Loss: 0.3534
Batch 140, Loss: 0.3728
Batch 150, Loss: 0.3704
Batch 160, Loss: 0.4316
Batch 170, Loss: 0.4007
Batch 180, Loss: 0.3771
Batch 190, Loss: 0.3735
Batch 200, Loss: 0.3917
Batch 210, Loss: 0.3948
Batch 220, Loss: 0.3822
Batch 230, Loss: 0.4229
Batch 240, Loss: 0.3807
Batch 250, Loss: 0.4193
Batch 260, Loss: 0.3914
Batch 270, Loss: 0.3664
Batch 280, Loss: 0.4284
Batch 290, Loss: 0.3764
Batch 300, Loss: 0.3678
Batch 310, Loss: 0.3809
Batch 320, Loss: 0.4085
Batch 330, Loss: 0.3704
Batch 340, Loss: 0.3664
Batch 350, Loss: 0.3993
Batch 360, Loss: 0.4078
Batch 370, Loss: 0.3829
Batch 380, Loss: 0.3855
Batch 390, Loss: 0.3969
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.04374885559082 seconds
Epoch 116 accuracy: 88.71%
Batch 10, Loss: 0.3974
Batch 20, Loss: 0.3860
Batch 30, Loss: 0.4091
Batch 40, Loss: 0.3739
Batch 50, Loss: 0.4112
Batch 60, Loss: 0.4203
Batch 70, Loss: 0.3904
Batch 80, Loss: 0.3732
Batch 90, Loss: 0.3737
Batch 100, Loss: 0.4105
Batch 110, Loss: 0.3669
Batch 120, Loss: 0.3734
Batch 130, Loss: 0.3907
Batch 140, Loss: 0.3691
Batch 150, Loss: 0.4045
Batch 160, Loss: 0.4134
Batch 170, Loss: 0.4296
Batch 180, Loss: 0.4000
Batch 190, Loss: 0.4024
Batch 200, Loss: 0.4036
Batch 210, Loss: 0.4097
Batch 220, Loss: 0.4201
Batch 230, Loss: 0.4081
Batch 240, Loss: 0.3490
Batch 250, Loss: 0.3838
Batch 260, Loss: 0.3603
Batch 270, Loss: 0.3501
Batch 280, Loss: 0.4109
Batch 290, Loss: 0.4039
Batch 300, Loss: 0.4246
Batch 310, Loss: 0.4126
Batch 320, Loss: 0.4070
Batch 330, Loss: 0.3638
Batch 340, Loss: 0.4031
Batch 350, Loss: 0.3989
Batch 360, Loss: 0.4273
Batch 370, Loss: 0.3924
Batch 380, Loss: 0.3971
Batch 390, Loss: 0.4135
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.068899393081665 seconds
Epoch 117 accuracy: 89.61%
Batch 10, Loss: 0.3965
Batch 20, Loss: 0.3911
Batch 30, Loss: 0.3812
Batch 40, Loss: 0.3971
Batch 50, Loss: 0.4056
Batch 60, Loss: 0.3714
Batch 70, Loss: 0.3779
Batch 80, Loss: 0.3643
Batch 90, Loss: 0.3736
Batch 100, Loss: 0.3522
Batch 110, Loss: 0.3746
Batch 120, Loss: 0.3889
Batch 130, Loss: 0.3589
Batch 140, Loss: 0.3935
Batch 150, Loss: 0.4024
Batch 160, Loss: 0.3987
Batch 170, Loss: 0.4082
Batch 180, Loss: 0.4224
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.3671
Batch 210, Loss: 0.4180
Batch 220, Loss: 0.3166
Batch 230, Loss: 0.3896
Batch 240, Loss: 0.3844
Batch 250, Loss: 0.4021
Batch 260, Loss: 0.3721
Batch 270, Loss: 0.3727
Batch 280, Loss: 0.4098
Batch 290, Loss: 0.4131
Batch 300, Loss: 0.3984
Batch 310, Loss: 0.4213
Batch 320, Loss: 0.3422
Batch 330, Loss: 0.3627
Batch 340, Loss: 0.4013
Batch 350, Loss: 0.4067
Batch 360, Loss: 0.3833
Batch 370, Loss: 0.4290
Batch 380, Loss: 0.3884
Batch 390, Loss: 0.3904
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.082797527313232 seconds
Epoch 118 accuracy: 89.45%
Batch 10, Loss: 0.4101
Batch 20, Loss: 0.3721
Batch 30, Loss: 0.3798
Batch 40, Loss: 0.3672
Batch 50, Loss: 0.3500
Batch 60, Loss: 0.3405
Batch 70, Loss: 0.3504
Batch 80, Loss: 0.3889
Batch 90, Loss: 0.3844
Batch 100, Loss: 0.3823
Batch 110, Loss: 0.4152
Batch 120, Loss: 0.3683
Batch 130, Loss: 0.3577
Batch 140, Loss: 0.3880
Batch 150, Loss: 0.4310
Batch 160, Loss: 0.3755
Batch 170, Loss: 0.4126
Batch 180, Loss: 0.3623
Batch 190, Loss: 0.3793
Batch 200, Loss: 0.3926
Batch 210, Loss: 0.4253
Batch 220, Loss: 0.3979
Batch 230, Loss: 0.3641
Batch 240, Loss: 0.3862
Batch 250, Loss: 0.3608
Batch 260, Loss: 0.3723
Batch 270, Loss: 0.4079
Batch 280, Loss: 0.3654
Batch 290, Loss: 0.3871
Batch 300, Loss: 0.3769
Batch 310, Loss: 0.3670
Batch 320, Loss: 0.4072
Batch 330, Loss: 0.3738
Batch 340, Loss: 0.3995
Batch 350, Loss: 0.3642
Batch 360, Loss: 0.4061
Batch 370, Loss: 0.3976
Batch 380, Loss: 0.4225
Batch 390, Loss: 0.3611
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.01883363723755 seconds
Epoch 119 accuracy: 90.56%
Batch 10, Loss: 0.3674
Batch 20, Loss: 0.3642
Batch 30, Loss: 0.3595
Batch 40, Loss: 0.3557
Batch 50, Loss: 0.3374
Batch 60, Loss: 0.3598
Batch 70, Loss: 0.3906
Batch 80, Loss: 0.4158
Batch 90, Loss: 0.3834
Batch 100, Loss: 0.3922
Batch 110, Loss: 0.3704
Batch 120, Loss: 0.3996
Batch 130, Loss: 0.4058
Batch 140, Loss: 0.3651
Batch 150, Loss: 0.3695
Batch 160, Loss: 0.3991
Batch 170, Loss: 0.3795
Batch 180, Loss: 0.4000
Batch 190, Loss: 0.3854
Batch 200, Loss: 0.4049
Batch 210, Loss: 0.3627
Batch 220, Loss: 0.3407
Batch 230, Loss: 0.3263
Batch 240, Loss: 0.3638
Batch 250, Loss: 0.3882
Batch 260, Loss: 0.3886
Batch 270, Loss: 0.4095
Batch 280, Loss: 0.3693
Batch 290, Loss: 0.3681
Batch 300, Loss: 0.3667
Batch 310, Loss: 0.3825
Batch 320, Loss: 0.3753
Batch 330, Loss: 0.3865
Batch 340, Loss: 0.4122
Batch 350, Loss: 0.4021
Batch 360, Loss: 0.4175
Batch 370, Loss: 0.3643
Batch 380, Loss: 0.3738
Batch 390, Loss: 0.3985
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.08076572418213 seconds
Epoch 120 accuracy: 90.66%
Batch 10, Loss: 0.3465
Batch 20, Loss: 0.3862
Batch 30, Loss: 0.4005
Batch 40, Loss: 0.3791
Batch 50, Loss: 0.3317
Batch 60, Loss: 0.3538
Batch 70, Loss: 0.3663
Batch 80, Loss: 0.3981
Batch 90, Loss: 0.3724
Batch 100, Loss: 0.3979
Batch 110, Loss: 0.3608
Batch 120, Loss: 0.3901
Batch 130, Loss: 0.3798
Batch 140, Loss: 0.3712
Batch 150, Loss: 0.3800
Batch 160, Loss: 0.3456
Batch 170, Loss: 0.3932
Batch 180, Loss: 0.3717
Batch 190, Loss: 0.3806
Batch 200, Loss: 0.4196
Batch 210, Loss: 0.3908
Batch 220, Loss: 0.3811
Batch 230, Loss: 0.3772
Batch 240, Loss: 0.3985
Batch 250, Loss: 0.3751
Batch 260, Loss: 0.3573
Batch 270, Loss: 0.3769
Batch 280, Loss: 0.3632
Batch 290, Loss: 0.3510
Batch 300, Loss: 0.3816
Batch 310, Loss: 0.4167
Batch 320, Loss: 0.4003
Batch 330, Loss: 0.3903
Batch 340, Loss: 0.3656
Batch 350, Loss: 0.3437
Batch 360, Loss: 0.3435
Batch 370, Loss: 0.3952
Batch 380, Loss: 0.4042
Batch 390, Loss: 0.3898
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.05971121788025 seconds
Epoch 121 accuracy: 90.53%
Batch 10, Loss: 0.3734
Batch 20, Loss: 0.3551
Batch 30, Loss: 0.3693
Batch 40, Loss: 0.3825
Batch 50, Loss: 0.3940
Batch 60, Loss: 0.3838
Batch 70, Loss: 0.3733
Batch 80, Loss: 0.3578
Batch 90, Loss: 0.3669
Batch 100, Loss: 0.3971
Batch 110, Loss: 0.3839
Batch 120, Loss: 0.3771
Batch 130, Loss: 0.3799
Batch 140, Loss: 0.3658
Batch 150, Loss: 0.3747
Batch 160, Loss: 0.3682
Batch 170, Loss: 0.3905
Batch 180, Loss: 0.3616
Batch 190, Loss: 0.3518
Batch 200, Loss: 0.3995
Batch 210, Loss: 0.3665
Batch 220, Loss: 0.3626
Batch 230, Loss: 0.4091
Batch 240, Loss: 0.3786
Batch 250, Loss: 0.3610
Batch 260, Loss: 0.3418
Batch 270, Loss: 0.3728
Batch 280, Loss: 0.4088
Batch 290, Loss: 0.3754
Batch 300, Loss: 0.3871
Batch 310, Loss: 0.3692
Batch 320, Loss: 0.3494
Batch 330, Loss: 0.3764
Batch 340, Loss: 0.3425
Batch 350, Loss: 0.3742
Batch 360, Loss: 0.3804
Batch 370, Loss: 0.3965
Batch 380, Loss: 0.3679
Batch 390, Loss: 0.3607
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.10383653640747 seconds
Epoch 122 accuracy: 89.75%
Batch 10, Loss: 0.3666
Batch 20, Loss: 0.4101
Batch 30, Loss: 0.3969
Batch 40, Loss: 0.3939
Batch 50, Loss: 0.3997
Batch 60, Loss: 0.3212
Batch 70, Loss: 0.3401
Batch 80, Loss: 0.3591
Batch 90, Loss: 0.3659
Batch 100, Loss: 0.3875
Batch 110, Loss: 0.3431
Batch 120, Loss: 0.3724
Batch 130, Loss: 0.3989
Batch 140, Loss: 0.3423
Batch 150, Loss: 0.3969
Batch 160, Loss: 0.3828
Batch 170, Loss: 0.3625
Batch 180, Loss: 0.3756
Batch 190, Loss: 0.4058
Batch 200, Loss: 0.3299
Batch 210, Loss: 0.3708
Batch 220, Loss: 0.3517
Batch 230, Loss: 0.3532
Batch 240, Loss: 0.3585
Batch 250, Loss: 0.4049
Batch 260, Loss: 0.4034
Batch 270, Loss: 0.3653
Batch 280, Loss: 0.3913
Batch 290, Loss: 0.3983
Batch 300, Loss: 0.3928
Batch 310, Loss: 0.3808
Batch 320, Loss: 0.3353
Batch 330, Loss: 0.4325
Batch 340, Loss: 0.3887
Batch 350, Loss: 0.4044
Batch 360, Loss: 0.3854
Batch 370, Loss: 0.3986
Batch 380, Loss: 0.3903
Batch 390, Loss: 0.3650
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 24.991157293319702 seconds
Epoch 123 accuracy: 89.03%
Batch 10, Loss: 0.3743
Batch 20, Loss: 0.3582
Batch 30, Loss: 0.3707
Batch 40, Loss: 0.3633
Batch 50, Loss: 0.3812
Batch 60, Loss: 0.3682
Batch 70, Loss: 0.3392
Batch 80, Loss: 0.3658
Batch 90, Loss: 0.3464
Batch 100, Loss: 0.3430
Batch 110, Loss: 0.3622
Batch 120, Loss: 0.3427
Batch 130, Loss: 0.3489
Batch 140, Loss: 0.3757
Batch 150, Loss: 0.3638
Batch 160, Loss: 0.3569
Batch 170, Loss: 0.3677
Batch 180, Loss: 0.3656
Batch 190, Loss: 0.3676
Batch 200, Loss: 0.3855
Batch 210, Loss: 0.3763
Batch 220, Loss: 0.4015
Batch 230, Loss: 0.3985
Batch 240, Loss: 0.3371
Batch 250, Loss: 0.3676
Batch 260, Loss: 0.3756
Batch 270, Loss: 0.3931
Batch 280, Loss: 0.3956
Batch 290, Loss: 0.3785
Batch 300, Loss: 0.3858
Batch 310, Loss: 0.3719
Batch 320, Loss: 0.3660
Batch 330, Loss: 0.3506
Batch 340, Loss: 0.3512
Batch 350, Loss: 0.3257
Batch 360, Loss: 0.3903
Batch 370, Loss: 0.3910
Batch 380, Loss: 0.3803
Batch 390, Loss: 0.3791
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 24.994178295135498 seconds
Epoch 124 accuracy: 90.11%
Batch 10, Loss: 0.3684
Batch 20, Loss: 0.3476
Batch 30, Loss: 0.3523
Batch 40, Loss: 0.3743
Batch 50, Loss: 0.3750
Batch 60, Loss: 0.3341
Batch 70, Loss: 0.3131
Batch 80, Loss: 0.3947
Batch 90, Loss: 0.3959
Batch 100, Loss: 0.3987
Batch 110, Loss: 0.3532
Batch 120, Loss: 0.3472
Batch 130, Loss: 0.3384
Batch 140, Loss: 0.3537
Batch 150, Loss: 0.3760
Batch 160, Loss: 0.3614
Batch 170, Loss: 0.3617
Batch 180, Loss: 0.3720
Batch 190, Loss: 0.3494
Batch 200, Loss: 0.3903
Batch 210, Loss: 0.3776
Batch 220, Loss: 0.3666
Batch 230, Loss: 0.3873
Batch 240, Loss: 0.3913
Batch 250, Loss: 0.3892
Batch 260, Loss: 0.3546
Batch 270, Loss: 0.3451
Batch 280, Loss: 0.3829
Batch 290, Loss: 0.3742
Batch 300, Loss: 0.3661
Batch 310, Loss: 0.3779
Batch 320, Loss: 0.3366
Batch 330, Loss: 0.3897
Batch 340, Loss: 0.3950
Batch 350, Loss: 0.3798
Batch 360, Loss: 0.3874
Batch 370, Loss: 0.3408
Batch 380, Loss: 0.3587
Batch 390, Loss: 0.3716
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 24.941000938415527 seconds
Epoch 125 accuracy: 91.51%
Batch 10, Loss: 0.3324
Batch 20, Loss: 0.3602
Batch 30, Loss: 0.3668
Batch 40, Loss: 0.3490
Batch 50, Loss: 0.3510
Batch 60, Loss: 0.3256
Batch 70, Loss: 0.3549
Batch 80, Loss: 0.3649
Batch 90, Loss: 0.3786
Batch 100, Loss: 0.3570
Batch 110, Loss: 0.3677
Batch 120, Loss: 0.3827
Batch 130, Loss: 0.3992
Batch 140, Loss: 0.3431
Batch 150, Loss: 0.3510
Batch 160, Loss: 0.3487
Batch 170, Loss: 0.3485
Batch 180, Loss: 0.3463
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.3399
Batch 210, Loss: 0.3354
Batch 220, Loss: 0.3403
Batch 230, Loss: 0.3418
Batch 240, Loss: 0.3816
Batch 250, Loss: 0.3514
Batch 260, Loss: 0.3833
Batch 270, Loss: 0.3495
Batch 280, Loss: 0.3812
Batch 290, Loss: 0.3556
Batch 300, Loss: 0.3467
Batch 310, Loss: 0.3703
Batch 320, Loss: 0.3827
Batch 330, Loss: 0.3959
Batch 340, Loss: 0.3510
Batch 350, Loss: 0.3947
Batch 360, Loss: 0.3821
Batch 370, Loss: 0.3598
Batch 380, Loss: 0.3956
Batch 390, Loss: 0.3531
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.04797863960266 seconds
Epoch 126 accuracy: 90.23%
Batch 10, Loss: 0.3637
Batch 20, Loss: 0.3164
Batch 30, Loss: 0.3474
Batch 40, Loss: 0.3542
Batch 50, Loss: 0.3542
Batch 60, Loss: 0.3181
Batch 70, Loss: 0.3496
Batch 80, Loss: 0.3739
Batch 90, Loss: 0.3369
Batch 100, Loss: 0.3605
Batch 110, Loss: 0.3392
Batch 120, Loss: 0.3607
Batch 130, Loss: 0.3077
Batch 140, Loss: 0.3483
Batch 150, Loss: 0.3524
Batch 160, Loss: 0.3713
Batch 170, Loss: 0.3362
Batch 180, Loss: 0.3529
Batch 190, Loss: 0.3569
Batch 200, Loss: 0.3772
Batch 210, Loss: 0.3839
Batch 220, Loss: 0.3531
Batch 230, Loss: 0.3574
Batch 240, Loss: 0.3357
Batch 250, Loss: 0.3826
Batch 260, Loss: 0.3405
Batch 270, Loss: 0.3679
Batch 280, Loss: 0.4109
Batch 290, Loss: 0.4187
Batch 300, Loss: 0.3369
Batch 310, Loss: 0.3435
Batch 320, Loss: 0.3571
Batch 330, Loss: 0.3839
Batch 340, Loss: 0.3759
Batch 350, Loss: 0.3681
Batch 360, Loss: 0.3885
Batch 370, Loss: 0.3534
Batch 380, Loss: 0.3549
Batch 390, Loss: 0.3405
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.098738431930542 seconds
Epoch 127 accuracy: 90.36%
Batch 10, Loss: 0.3742
Batch 20, Loss: 0.3749
Batch 30, Loss: 0.3418
Batch 40, Loss: 0.3053
Batch 50, Loss: 0.3920
Batch 60, Loss: 0.3204
Batch 70, Loss: 0.3504
Batch 80, Loss: 0.3477
Batch 90, Loss: 0.3796
Batch 100, Loss: 0.3575
Batch 110, Loss: 0.3205
Batch 120, Loss: 0.3695
Batch 130, Loss: 0.3469
Batch 140, Loss: 0.3560
Batch 150, Loss: 0.3832
Batch 160, Loss: 0.3540
Batch 170, Loss: 0.3265
Batch 180, Loss: 0.3477
Batch 190, Loss: 0.3046
Batch 200, Loss: 0.3603
Batch 210, Loss: 0.3375
Batch 220, Loss: 0.4339
Batch 230, Loss: 0.3487
Batch 240, Loss: 0.3721
Batch 250, Loss: 0.3339
Batch 260, Loss: 0.3202
Batch 270, Loss: 0.3469
Batch 280, Loss: 0.3677
Batch 290, Loss: 0.3410
Batch 300, Loss: 0.3628
Batch 310, Loss: 0.3656
Batch 320, Loss: 0.3935
Batch 330, Loss: 0.3677
Batch 340, Loss: 0.3823
Batch 350, Loss: 0.3608
Batch 360, Loss: 0.3604
Batch 370, Loss: 0.3283
Batch 380, Loss: 0.3534
Batch 390, Loss: 0.3337
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.068340301513672 seconds
Epoch 128 accuracy: 91.11%
Batch 10, Loss: 0.3394
Batch 20, Loss: 0.3446
Batch 30, Loss: 0.3415
Batch 40, Loss: 0.3639
Batch 50, Loss: 0.4045
Batch 60, Loss: 0.3562
Batch 70, Loss: 0.3585
Batch 80, Loss: 0.3738
Batch 90, Loss: 0.3431
Batch 100, Loss: 0.3611
Batch 110, Loss: 0.3547
Batch 120, Loss: 0.3426
Batch 130, Loss: 0.3414
Batch 140, Loss: 0.3017
Batch 150, Loss: 0.3501
Batch 160, Loss: 0.3361
Batch 170, Loss: 0.3454
Batch 180, Loss: 0.3595
Batch 190, Loss: 0.3252
Batch 200, Loss: 0.3893
Batch 210, Loss: 0.3313
Batch 220, Loss: 0.3390
Batch 230, Loss: 0.3298
Batch 240, Loss: 0.3441
Batch 250, Loss: 0.3620
Batch 260, Loss: 0.3338
Batch 270, Loss: 0.3585
Batch 280, Loss: 0.3642
Batch 290, Loss: 0.3794
Batch 300, Loss: 0.3385
Batch 310, Loss: 0.3446
Batch 320, Loss: 0.3421
Batch 330, Loss: 0.3427
Batch 340, Loss: 0.3807
Batch 350, Loss: 0.3672
Batch 360, Loss: 0.3557
Batch 370, Loss: 0.3580
Batch 380, Loss: 0.3442
Batch 390, Loss: 0.3827
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 24.95827054977417 seconds
Epoch 129 accuracy: 89.49%
Batch 10, Loss: 0.3493
Batch 20, Loss: 0.3405
Batch 30, Loss: 0.3639
Batch 40, Loss: 0.3774
Batch 50, Loss: 0.3613
Batch 60, Loss: 0.3621
Batch 70, Loss: 0.3678
Batch 80, Loss: 0.3761
Batch 90, Loss: 0.3396
Batch 100, Loss: 0.3549
Batch 110, Loss: 0.3254
Batch 120, Loss: 0.3434
Batch 130, Loss: 0.3830
Batch 140, Loss: 0.3395
Batch 150, Loss: 0.3681
Batch 160, Loss: 0.3420
Batch 170, Loss: 0.3460
Batch 180, Loss: 0.3396
Batch 190, Loss: 0.3616
Batch 200, Loss: 0.3641
Batch 210, Loss: 0.3680
Batch 220, Loss: 0.3369
Batch 230, Loss: 0.3453
Batch 240, Loss: 0.3508
Batch 250, Loss: 0.3531
Batch 260, Loss: 0.3263
Batch 270, Loss: 0.3973
Batch 280, Loss: 0.3434
Batch 290, Loss: 0.3370
Batch 300, Loss: 0.3601
Batch 310, Loss: 0.3512
Batch 320, Loss: 0.3758
Batch 330, Loss: 0.3426
Batch 340, Loss: 0.3541
Batch 350, Loss: 0.3596
Batch 360, Loss: 0.3214
Batch 370, Loss: 0.3767
Batch 380, Loss: 0.3683
Batch 390, Loss: 0.3761
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 24.96059489250183 seconds
Epoch 130 accuracy: 91.82%
Batch 10, Loss: 0.3500
Batch 20, Loss: 0.3546
Batch 30, Loss: 0.3296
Batch 40, Loss: 0.3591
Batch 50, Loss: 0.3412
Batch 60, Loss: 0.3286
Batch 70, Loss: 0.3732
Batch 80, Loss: 0.3327
Batch 90, Loss: 0.3211
Batch 100, Loss: 0.3354
Batch 110, Loss: 0.3612
Batch 120, Loss: 0.3305
Batch 130, Loss: 0.3524
Batch 140, Loss: 0.3450
Batch 150, Loss: 0.3241
Batch 160, Loss: 0.3584
Batch 170, Loss: 0.3578
Batch 180, Loss: 0.3384
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.3633
Batch 210, Loss: 0.3545
Batch 220, Loss: 0.3375
Batch 230, Loss: 0.3654
Batch 240, Loss: 0.3368
Batch 250, Loss: 0.3828
Batch 260, Loss: 0.3592
Batch 270, Loss: 0.3662
Batch 280, Loss: 0.3389
Batch 290, Loss: 0.3419
Batch 300, Loss: 0.3400
Batch 310, Loss: 0.3217
Batch 320, Loss: 0.3554
Batch 330, Loss: 0.3655
Batch 340, Loss: 0.3400
Batch 350, Loss: 0.3626
Batch 360, Loss: 0.3466
Batch 370, Loss: 0.3739
Batch 380, Loss: 0.3558
Batch 390, Loss: 0.3294
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.017992734909058 seconds
Epoch 131 accuracy: 91.11%
Batch 10, Loss: 0.3269
Batch 20, Loss: 0.3415
Batch 30, Loss: 0.3501
Batch 40, Loss: 0.3473
Batch 50, Loss: 0.3525
Batch 60, Loss: 0.3621
Batch 70, Loss: 0.3656
Batch 80, Loss: 0.3690
Batch 90, Loss: 0.3293
Batch 100, Loss: 0.3828
Batch 110, Loss: 0.3720
Batch 120, Loss: 0.3382
Batch 130, Loss: 0.3423
Batch 140, Loss: 0.3263
Batch 150, Loss: 0.3404
Batch 160, Loss: 0.3476
Batch 170, Loss: 0.3143
Batch 180, Loss: 0.3420
Batch 190, Loss: 0.3356
Batch 200, Loss: 0.3516
Batch 210, Loss: 0.3686
Batch 220, Loss: 0.3415
Batch 230, Loss: 0.3490
Batch 240, Loss: 0.3435
Batch 250, Loss: 0.3219
Batch 260, Loss: 0.3733
Batch 270, Loss: 0.3150
Batch 280, Loss: 0.3295
Batch 290, Loss: 0.3390
Batch 300, Loss: 0.3528
Batch 310, Loss: 0.3369
Batch 320, Loss: 0.3109
Batch 330, Loss: 0.3374
Batch 340, Loss: 0.3312
Batch 350, Loss: 0.3525
Batch 360, Loss: 0.3669
Batch 370, Loss: 0.3590
Batch 380, Loss: 0.3311
Batch 390, Loss: 0.3572
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.069979667663574 seconds
Epoch 132 accuracy: 91.41%
Batch 10, Loss: 0.3210
Batch 20, Loss: 0.3442
Batch 30, Loss: 0.3504
Batch 40, Loss: 0.3200
Batch 50, Loss: 0.3554
Batch 60, Loss: 0.3185
Batch 70, Loss: 0.3601
Batch 80, Loss: 0.3173
Batch 90, Loss: 0.3548
Batch 100, Loss: 0.3384
Batch 110, Loss: 0.3383
Batch 120, Loss: 0.3394
Batch 130, Loss: 0.3423
Batch 140, Loss: 0.3400
Batch 150, Loss: 0.3537
Batch 160, Loss: 0.3437
Batch 170, Loss: 0.3408
Batch 180, Loss: 0.3235
Batch 190, Loss: 0.3247
Batch 200, Loss: 0.3219
Batch 210, Loss: 0.3103
Batch 220, Loss: 0.3358
Batch 230, Loss: 0.3633
Batch 240, Loss: 0.3690
Batch 250, Loss: 0.3483
Batch 260, Loss: 0.3419
Batch 270, Loss: 0.3613
Batch 280, Loss: 0.3529
Batch 290, Loss: 0.3315
Batch 300, Loss: 0.2816
Batch 310, Loss: 0.3560
Batch 320, Loss: 0.3512
Batch 330, Loss: 0.3361
Batch 340, Loss: 0.3762
Batch 350, Loss: 0.3805
Batch 360, Loss: 0.3452
Batch 370, Loss: 0.3545
Batch 380, Loss: 0.3398
Batch 390, Loss: 0.3617
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.087514638900757 seconds
Epoch 133 accuracy: 91.21%
Batch 10, Loss: 0.3417
Batch 20, Loss: 0.3078
Batch 30, Loss: 0.3383
Batch 40, Loss: 0.3544
Batch 50, Loss: 0.3250
Batch 60, Loss: 0.3306
Batch 70, Loss: 0.3267
Batch 80, Loss: 0.3147
Batch 90, Loss: 0.3212
Batch 100, Loss: 0.3478
Batch 110, Loss: 0.2969
Batch 120, Loss: 0.3280
Batch 130, Loss: 0.3388
Batch 140, Loss: 0.3149
Batch 150, Loss: 0.3108
Batch 160, Loss: 0.3679
Batch 170, Loss: 0.3737
Batch 180, Loss: 0.3441
Batch 190, Loss: 0.3227
Batch 200, Loss: 0.3568
Batch 210, Loss: 0.3565
Batch 220, Loss: 0.3643
Batch 230, Loss: 0.3453
Batch 240, Loss: 0.3395
Batch 250, Loss: 0.3503
Batch 260, Loss: 0.3592
Batch 270, Loss: 0.3041
Batch 280, Loss: 0.3376
Batch 290, Loss: 0.3489
Batch 300, Loss: 0.3520
Batch 310, Loss: 0.3292
Batch 320, Loss: 0.3238
Batch 330, Loss: 0.3272
Batch 340, Loss: 0.3457
Batch 350, Loss: 0.3485
Batch 360, Loss: 0.3191
Batch 370, Loss: 0.3410
Batch 380, Loss: 0.3179
Batch 390, Loss: 0.3502
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.062009811401367 seconds
Epoch 134 accuracy: 92.6%
Batch 10, Loss: 0.3324
Batch 20, Loss: 0.3766
Batch 30, Loss: 0.3532
Batch 40, Loss: 0.3541
Batch 50, Loss: 0.3296
Batch 60, Loss: 0.3388
Batch 70, Loss: 0.3381
Batch 80, Loss: 0.3309
Batch 90, Loss: 0.3673
Batch 100, Loss: 0.3037
Batch 110, Loss: 0.3224
Batch 120, Loss: 0.3032
Batch 130, Loss: 0.3455
Batch 140, Loss: 0.3179
Batch 150, Loss: 0.3634
Batch 160, Loss: 0.3197
Batch 170, Loss: 0.3487
Batch 180, Loss: 0.3396
Batch 190, Loss: 0.3495
Batch 200, Loss: 0.3509
Batch 210, Loss: 0.3213
Batch 220, Loss: 0.3042
Batch 230, Loss: 0.3397
Batch 240, Loss: 0.3301
Batch 250, Loss: 0.3300
Batch 260, Loss: 0.3519
Batch 270, Loss: 0.3336
Batch 280, Loss: 0.3515
Batch 290, Loss: 0.3639
Batch 300, Loss: 0.3335
Batch 310, Loss: 0.3554
Batch 320, Loss: 0.3495
Batch 330, Loss: 0.3654
Batch 340, Loss: 0.3548
Batch 350, Loss: 0.3151
Batch 360, Loss: 0.3388
Batch 370, Loss: 0.3249
Batch 380, Loss: 0.3685
Batch 390, Loss: 0.3433
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.053393602371216 seconds
Epoch 135 accuracy: 91.96%
Batch 10, Loss: 0.3447
Batch 20, Loss: 0.3001
Batch 30, Loss: 0.3295
Batch 40, Loss: 0.3053
Batch 50, Loss: 0.3012
Batch 60, Loss: 0.3207
Batch 70, Loss: 0.3079
Batch 80, Loss: 0.3102
Batch 90, Loss: 0.3290
Batch 100, Loss: 0.3526
Batch 110, Loss: 0.3502
Batch 120, Loss: 0.3133
Batch 130, Loss: 0.3603
Batch 140, Loss: 0.3387
Batch 150, Loss: 0.3215
Batch 160, Loss: 0.3116
Batch 170, Loss: 0.3585
Batch 180, Loss: 0.3221
Batch 190, Loss: 0.3391
Batch 200, Loss: 0.3298
Batch 210, Loss: 0.3357
Batch 220, Loss: 0.3421
Batch 230, Loss: 0.3382
Batch 240, Loss: 0.3516
Batch 250, Loss: 0.3463
Batch 260, Loss: 0.3353
Batch 270, Loss: 0.3801
Batch 280, Loss: 0.3079
Batch 290, Loss: 0.3136
Batch 300, Loss: 0.3219
Batch 310, Loss: 0.3171
Batch 320, Loss: 0.3609
Batch 330, Loss: 0.3243
Batch 340, Loss: 0.3179
Batch 350, Loss: 0.3531
Batch 360, Loss: 0.3224
Batch 370, Loss: 0.3264
Batch 380, Loss: 0.3542
Batch 390, Loss: 0.3421
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.114418029785156 seconds
Epoch 136 accuracy: 92.96%
Batch 10, Loss: 0.3112
Batch 20, Loss: 0.3327
Batch 30, Loss: 0.3212
Batch 40, Loss: 0.3265
Batch 50, Loss: 0.3378
Batch 60, Loss: 0.3434
Batch 70, Loss: 0.3034
Batch 80, Loss: 0.3576
Batch 90, Loss: 0.3556
Batch 100, Loss: 0.3350
Batch 110, Loss: 0.3114
Batch 120, Loss: 0.3625
Batch 130, Loss: 0.3310
Batch 140, Loss: 0.3149
Batch 150, Loss: 0.3253
Batch 160, Loss: 0.2985
Batch 170, Loss: 0.3504
Batch 180, Loss: 0.3012
Batch 190, Loss: 0.3051
Batch 200, Loss: 0.3029
Batch 210, Loss: 0.3153
Batch 220, Loss: 0.3266
Batch 230, Loss: 0.3109
Batch 240, Loss: 0.3005
Batch 250, Loss: 0.3156
Batch 260, Loss: 0.2974
Batch 270, Loss: 0.3278
Batch 280, Loss: 0.3015
Batch 290, Loss: 0.3433
Batch 300, Loss: 0.3318
Batch 310, Loss: 0.3337
Batch 320, Loss: 0.3459
Batch 330, Loss: 0.3468
Batch 340, Loss: 0.3180
Batch 350, Loss: 0.3095
Batch 360, Loss: 0.3409
Batch 370, Loss: 0.3288
Batch 380, Loss: 0.3498
Batch 390, Loss: 0.3304
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.075097799301147 seconds
Epoch 137 accuracy: 91.24%
Batch 10, Loss: 0.3211
Batch 20, Loss: 0.3064
Batch 30, Loss: 0.3003
Batch 40, Loss: 0.2934
Batch 50, Loss: 0.2928
Batch 60, Loss: 0.2914
Batch 70, Loss: 0.2661
Batch 80, Loss: 0.3019
Batch 90, Loss: 0.3102
Batch 100, Loss: 0.3146
Batch 110, Loss: 0.3070
Batch 120, Loss: 0.3226
Batch 130, Loss: 0.3585
Batch 140, Loss: 0.3180
Batch 150, Loss: 0.3325
Batch 160, Loss: 0.3339
Batch 170, Loss: 0.3308
Batch 180, Loss: 0.3488
Batch 190, Loss: 0.3443
Batch 200, Loss: 0.3214
Batch 210, Loss: 0.3498
Batch 220, Loss: 0.3264
Batch 230, Loss: 0.3094
Batch 240, Loss: 0.3489
Batch 250, Loss: 0.3393
Batch 260, Loss: 0.3681
Batch 270, Loss: 0.3290
Batch 280, Loss: 0.3089
Batch 290, Loss: 0.3167
Batch 300, Loss: 0.3074
Batch 310, Loss: 0.3283
Batch 320, Loss: 0.3460
Batch 330, Loss: 0.3153
Batch 340, Loss: 0.3310
Batch 350, Loss: 0.3060
Batch 360, Loss: 0.3070
Batch 370, Loss: 0.3369
Batch 380, Loss: 0.3374
Batch 390, Loss: 0.3057
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.0382137298584 seconds
Epoch 138 accuracy: 92.85%
Batch 10, Loss: 0.2816
Batch 20, Loss: 0.2982
Batch 30, Loss: 0.3291
Batch 40, Loss: 0.3326
Batch 50, Loss: 0.3026
Batch 60, Loss: 0.3277
Batch 70, Loss: 0.3336
Batch 80, Loss: 0.3020
Batch 90, Loss: 0.3295
Batch 100, Loss: 0.3122
Batch 110, Loss: 0.3141
Batch 120, Loss: 0.2889
Batch 130, Loss: 0.3041
Batch 140, Loss: 0.3010
Batch 150, Loss: 0.3032
Batch 160, Loss: 0.3181
Batch 170, Loss: 0.2956
Batch 180, Loss: 0.3040
Batch 190, Loss: 0.3442
Batch 200, Loss: 0.3249
Batch 210, Loss: 0.3097
Batch 220, Loss: 0.3243
Batch 230, Loss: 0.3011
Batch 240, Loss: 0.3031
Batch 250, Loss: 0.3181
Batch 260, Loss: 0.3432
Batch 270, Loss: 0.3102
Batch 280, Loss: 0.3145
Batch 290, Loss: 0.3266
Batch 300, Loss: 0.3104
Batch 310, Loss: 0.3337
Batch 320, Loss: 0.3603
Batch 330, Loss: 0.3285
Batch 340, Loss: 0.3249
Batch 350, Loss: 0.3068
Batch 360, Loss: 0.3188
Batch 370, Loss: 0.3836
Batch 380, Loss: 0.3838
Batch 390, Loss: 0.2961
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.101671934127808 seconds
Epoch 139 accuracy: 91.99%
Batch 10, Loss: 0.3221
Batch 20, Loss: 0.3088
Batch 30, Loss: 0.2815
Batch 40, Loss: 0.3160
Batch 50, Loss: 0.2962
Batch 60, Loss: 0.3443
Batch 70, Loss: 0.3606
Batch 80, Loss: 0.3298
Batch 90, Loss: 0.2984
Batch 100, Loss: 0.3500
Batch 110, Loss: 0.3190
Batch 120, Loss: 0.3419
Batch 130, Loss: 0.2936
Batch 140, Loss: 0.2857
Batch 150, Loss: 0.2946
Batch 160, Loss: 0.3009
Batch 170, Loss: 0.3322
Batch 180, Loss: 0.3289
Batch 190, Loss: 0.3124
Batch 200, Loss: 0.3168
Batch 210, Loss: 0.3098
Batch 220, Loss: 0.3200
Batch 230, Loss: 0.3230
Batch 240, Loss: 0.2972
Batch 250, Loss: 0.3067
Batch 260, Loss: 0.3210
Batch 270, Loss: 0.3013
Batch 280, Loss: 0.3154
Batch 290, Loss: 0.3405
Batch 300, Loss: 0.3204
Batch 310, Loss: 0.3265
Batch 320, Loss: 0.3142
Batch 330, Loss: 0.2948
Batch 340, Loss: 0.3495
Batch 350, Loss: 0.3591
Batch 360, Loss: 0.3391
Batch 370, Loss: 0.3113
Batch 380, Loss: 0.2914
Batch 390, Loss: 0.2988
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.057640314102173 seconds
Epoch 140 accuracy: 92.79%
Batch 10, Loss: 0.2927
Batch 20, Loss: 0.2837
Batch 30, Loss: 0.3159
Batch 40, Loss: 0.3175
Batch 50, Loss: 0.3208
Batch 60, Loss: 0.3105
Batch 70, Loss: 0.2923
Batch 80, Loss: 0.3081
Batch 90, Loss: 0.2912
Batch 100, Loss: 0.3290
Batch 110, Loss: 0.3194
Batch 120, Loss: 0.2987
Batch 130, Loss: 0.3129
Batch 140, Loss: 0.3117
Batch 150, Loss: 0.2896
Batch 160, Loss: 0.2964
Batch 170, Loss: 0.3103
Batch 180, Loss: 0.3161
Batch 190, Loss: 0.3182
Batch 200, Loss: 0.3145
Batch 210, Loss: 0.3181
Batch 220, Loss: 0.3069
Batch 230, Loss: 0.3035
Batch 240, Loss: 0.3007
Batch 250, Loss: 0.3431
Batch 260, Loss: 0.3245
Batch 270, Loss: 0.3400
Batch 280, Loss: 0.3326
Batch 290, Loss: 0.3146
Batch 300, Loss: 0.3105
Batch 310, Loss: 0.3068
Batch 320, Loss: 0.3188
Batch 330, Loss: 0.2947
Batch 340, Loss: 0.3051
Batch 350, Loss: 0.2833
Batch 360, Loss: 0.3129
Batch 370, Loss: 0.3326
Batch 380, Loss: 0.3244
Batch 390, Loss: 0.3202
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.140190839767456 seconds
Epoch 141 accuracy: 91.41%
Batch 10, Loss: 0.2988
Batch 20, Loss: 0.2937
Batch 30, Loss: 0.2714
Batch 40, Loss: 0.2872
Batch 50, Loss: 0.2965
Batch 60, Loss: 0.2964
Batch 70, Loss: 0.3008
Batch 80, Loss: 0.2967
Batch 90, Loss: 0.3244
Batch 100, Loss: 0.3551
Batch 110, Loss: 0.3283
Batch 120, Loss: 0.3092
Batch 130, Loss: 0.2943
Batch 140, Loss: 0.3120
Batch 150, Loss: 0.3072
Batch 160, Loss: 0.3294
Batch 170, Loss: 0.3190
Batch 180, Loss: 0.3156
Batch 190, Loss: 0.3232
Batch 200, Loss: 0.3089
Batch 210, Loss: 0.3363
Batch 220, Loss: 0.2899
Batch 230, Loss: 0.3272
Batch 240, Loss: 0.3235
Batch 250, Loss: 0.3037
Batch 260, Loss: 0.3125
Batch 270, Loss: 0.3202
Batch 280, Loss: 0.2982
Batch 290, Loss: 0.3000
Batch 300, Loss: 0.3252
Batch 310, Loss: 0.3233
Batch 320, Loss: 0.3309
Batch 330, Loss: 0.3065
Batch 340, Loss: 0.3336
Batch 350, Loss: 0.3182
Batch 360, Loss: 0.3165
Batch 370, Loss: 0.2899
Batch 380, Loss: 0.3229
Batch 390, Loss: 0.3236
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 24.99808931350708 seconds
Epoch 142 accuracy: 92.5%
Batch 10, Loss: 0.2882
Batch 20, Loss: 0.2757
Batch 30, Loss: 0.2828
Batch 40, Loss: 0.2799
Batch 50, Loss: 0.2982
Batch 60, Loss: 0.2949
Batch 70, Loss: 0.2922
Batch 80, Loss: 0.2766
Batch 90, Loss: 0.3357
Batch 100, Loss: 0.2798
Batch 110, Loss: 0.3292
Batch 120, Loss: 0.2952
Batch 130, Loss: 0.3062
Batch 140, Loss: 0.2937
Batch 150, Loss: 0.2944
Batch 160, Loss: 0.3139
Batch 170, Loss: 0.3232
Batch 180, Loss: 0.3448
Batch 190, Loss: 0.3360
Batch 200, Loss: 0.3208
Batch 210, Loss: 0.2944
Batch 220, Loss: 0.3248
Batch 230, Loss: 0.3208
Batch 240, Loss: 0.2930
Batch 250, Loss: 0.3209
Batch 260, Loss: 0.2997
Batch 270, Loss: 0.3522
Batch 280, Loss: 0.2915
Batch 290, Loss: 0.3021
Batch 300, Loss: 0.2995
Batch 310, Loss: 0.3261
Batch 320, Loss: 0.3084
Batch 330, Loss: 0.3139
Batch 340, Loss: 0.3101
Batch 350, Loss: 0.3259
Batch 360, Loss: 0.2907
Batch 370, Loss: 0.3103
Batch 380, Loss: 0.2538
Batch 390, Loss: 0.2879
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.091763496398926 seconds
Epoch 143 accuracy: 92.83%
Batch 10, Loss: 0.2881
Batch 20, Loss: 0.2989
Batch 30, Loss: 0.2804
Batch 40, Loss: 0.2945
Batch 50, Loss: 0.2820
Batch 60, Loss: 0.3029
Batch 70, Loss: 0.3357
Batch 80, Loss: 0.3400
Batch 90, Loss: 0.3065
Batch 100, Loss: 0.3078
Batch 110, Loss: 0.2776
Batch 120, Loss: 0.2885
Batch 130, Loss: 0.3106
Batch 140, Loss: 0.2968
Batch 150, Loss: 0.2992
Batch 160, Loss: 0.3435
Batch 170, Loss: 0.3064
Batch 180, Loss: 0.3028
Batch 190, Loss: 0.3061
Batch 200, Loss: 0.2794
Batch 210, Loss: 0.2905
Batch 220, Loss: 0.3066
Batch 230, Loss: 0.2962
Batch 240, Loss: 0.3073
Batch 250, Loss: 0.3218
Batch 260, Loss: 0.3048
Batch 270, Loss: 0.2951
Batch 280, Loss: 0.2984
Batch 290, Loss: 0.3115
Batch 300, Loss: 0.2978
Batch 310, Loss: 0.2956
Batch 320, Loss: 0.2985
Batch 330, Loss: 0.3009
Batch 340, Loss: 0.2645
Batch 350, Loss: 0.3391
Batch 360, Loss: 0.3042
Batch 370, Loss: 0.2960
Batch 380, Loss: 0.3103
Batch 390, Loss: 0.3069
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.171136617660522 seconds
Epoch 144 accuracy: 93.25%
Batch 10, Loss: 0.2822
Batch 20, Loss: 0.3078
Batch 30, Loss: 0.2839
Batch 40, Loss: 0.2984
Batch 50, Loss: 0.3291
Batch 60, Loss: 0.2844
Batch 70, Loss: 0.2838
Batch 80, Loss: 0.3000
Batch 90, Loss: 0.3455
Batch 100, Loss: 0.2878
Batch 110, Loss: 0.3013
Batch 120, Loss: 0.3107
Batch 130, Loss: 0.2578
Batch 140, Loss: 0.2930
Batch 150, Loss: 0.3297
Batch 160, Loss: 0.2694
Batch 170, Loss: 0.3071
Batch 180, Loss: 0.2944
Batch 190, Loss: 0.2888
Batch 200, Loss: 0.2904
Batch 210, Loss: 0.2679
Batch 220, Loss: 0.2786
Batch 230, Loss: 0.3045
Batch 240, Loss: 0.2917
Batch 250, Loss: 0.2885
Batch 260, Loss: 0.3416
Batch 270, Loss: 0.3161
Batch 280, Loss: 0.2969
Batch 290, Loss: 0.2913
Batch 300, Loss: 0.2828
Batch 310, Loss: 0.3189
Batch 320, Loss: 0.2771
Batch 330, Loss: 0.3110
Batch 340, Loss: 0.2683
Batch 350, Loss: 0.3068
Batch 360, Loss: 0.3113
Batch 370, Loss: 0.2732
Batch 380, Loss: 0.3096
Batch 390, Loss: 0.2981
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.083119869232178 seconds
Epoch 145 accuracy: 92.97%
Batch 10, Loss: 0.3016
Batch 20, Loss: 0.3154
Batch 30, Loss: 0.2901
Batch 40, Loss: 0.3163
Batch 50, Loss: 0.3187
Batch 60, Loss: 0.2897
Batch 70, Loss: 0.3034
Batch 80, Loss: 0.2843
Batch 90, Loss: 0.2936
Batch 100, Loss: 0.3074
Batch 110, Loss: 0.2950
Batch 120, Loss: 0.3110
Batch 130, Loss: 0.2791
Batch 140, Loss: 0.2746
Batch 150, Loss: 0.3029
Batch 160, Loss: 0.2913
Batch 170, Loss: 0.3008
Batch 180, Loss: 0.2766
Batch 190, Loss: 0.3022
Batch 200, Loss: 0.2719
Batch 210, Loss: 0.3188
Batch 220, Loss: 0.3084
Batch 230, Loss: 0.3263
Batch 240, Loss: 0.2824
Batch 250, Loss: 0.2676
Batch 260, Loss: 0.2640
Batch 270, Loss: 0.2845
Batch 280, Loss: 0.2908
Batch 290, Loss: 0.3045
Batch 300, Loss: 0.3188
Batch 310, Loss: 0.3000
Batch 320, Loss: 0.2903
Batch 330, Loss: 0.3077
Batch 340, Loss: 0.2931
Batch 350, Loss: 0.2930
Batch 360, Loss: 0.2909
Batch 370, Loss: 0.2956
Batch 380, Loss: 0.2943
Batch 390, Loss: 0.3069
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.046006202697754 seconds
Epoch 146 accuracy: 93.16%
Batch 10, Loss: 0.3087
Batch 20, Loss: 0.2682
Batch 30, Loss: 0.2923
Batch 40, Loss: 0.3062
Batch 50, Loss: 0.3026
Batch 60, Loss: 0.3272
Batch 70, Loss: 0.2914
Batch 80, Loss: 0.2834
Batch 90, Loss: 0.3218
Batch 100, Loss: 0.2985
Batch 110, Loss: 0.2831
Batch 120, Loss: 0.2826
Batch 130, Loss: 0.2960
Batch 140, Loss: 0.2817
Batch 150, Loss: 0.2671
Batch 160, Loss: 0.2867
Batch 170, Loss: 0.2875
Batch 180, Loss: 0.2702
Batch 190, Loss: 0.2802
Batch 200, Loss: 0.2944
Batch 210, Loss: 0.3245
Batch 220, Loss: 0.2817
Batch 230, Loss: 0.2981
Batch 240, Loss: 0.2925
Batch 250, Loss: 0.2749
Batch 260, Loss: 0.2819
Batch 270, Loss: 0.2788
Batch 280, Loss: 0.2998
Batch 290, Loss: 0.2790
Batch 300, Loss: 0.2839
Batch 310, Loss: 0.3355
Batch 320, Loss: 0.2907
Batch 330, Loss: 0.2922
Batch 340, Loss: 0.3138
Batch 350, Loss: 0.2780
Batch 360, Loss: 0.2892
Batch 370, Loss: 0.2814
Batch 380, Loss: 0.3051
Batch 390, Loss: 0.2816
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.063746690750122 seconds
Epoch 147 accuracy: 93.54%
Batch 10, Loss: 0.2875
Batch 20, Loss: 0.3016
Batch 30, Loss: 0.3031
Batch 40, Loss: 0.2897
Batch 50, Loss: 0.2730
Batch 60, Loss: 0.2909
Batch 70, Loss: 0.3068
Batch 80, Loss: 0.2816
Batch 90, Loss: 0.2890
Batch 100, Loss: 0.2889
Batch 110, Loss: 0.3127
Batch 120, Loss: 0.2943
Batch 130, Loss: 0.2949
Batch 140, Loss: 0.3083
Batch 150, Loss: 0.2642
Batch 160, Loss: 0.2952
Batch 170, Loss: 0.2714
Batch 180, Loss: 0.2905
Batch 190, Loss: 0.2762
Batch 200, Loss: 0.3030
Batch 210, Loss: 0.2932
Batch 220, Loss: 0.2828
Batch 230, Loss: 0.2768
Batch 240, Loss: 0.3170
Batch 250, Loss: 0.3205
Batch 260, Loss: 0.2957
Batch 270, Loss: 0.2988
Batch 280, Loss: 0.2954
Batch 290, Loss: 0.2765
Batch 300, Loss: 0.2934
Batch 310, Loss: 0.2978
Batch 320, Loss: 0.3040
Batch 330, Loss: 0.2902
Batch 340, Loss: 0.2679
Batch 350, Loss: 0.2779
Batch 360, Loss: 0.3230
Batch 370, Loss: 0.3150
Batch 380, Loss: 0.2823
Batch 390, Loss: 0.2734
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.115519285202026 seconds
Epoch 148 accuracy: 93.26%
Batch 10, Loss: 0.2643
Batch 20, Loss: 0.2971
Batch 30, Loss: 0.2755
Batch 40, Loss: 0.2941
Batch 50, Loss: 0.2704
Batch 60, Loss: 0.2698
Batch 70, Loss: 0.2497
Batch 80, Loss: 0.2649
Batch 90, Loss: 0.2728
Batch 100, Loss: 0.2812
Batch 110, Loss: 0.2813
Batch 120, Loss: 0.2791
Batch 130, Loss: 0.2834
Batch 140, Loss: 0.2925
Batch 150, Loss: 0.2975
Batch 160, Loss: 0.2587
Batch 170, Loss: 0.3101
Batch 180, Loss: 0.2853
Batch 190, Loss: 0.2896
Batch 200, Loss: 0.2457
Batch 210, Loss: 0.2715
Batch 220, Loss: 0.2918
Batch 230, Loss: 0.2956
Batch 240, Loss: 0.2839
Batch 250, Loss: 0.2956
Batch 260, Loss: 0.2790
Batch 270, Loss: 0.2548
Batch 280, Loss: 0.3025
Batch 290, Loss: 0.2588
Batch 300, Loss: 0.2682
Batch 310, Loss: 0.2714
Batch 320, Loss: 0.2695
Batch 330, Loss: 0.2670
Batch 340, Loss: 0.2883
Batch 350, Loss: 0.2879
Batch 360, Loss: 0.3051
Batch 370, Loss: 0.2996
Batch 380, Loss: 0.2893
Batch 390, Loss: 0.3004
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.101969957351685 seconds
Epoch 149 accuracy: 93.1%
Batch 10, Loss: 0.2701
Batch 20, Loss: 0.2662
Batch 30, Loss: 0.2748
Batch 40, Loss: 0.2879
Batch 50, Loss: 0.2497
Batch 60, Loss: 0.2693
Batch 70, Loss: 0.2904
Batch 80, Loss: 0.2963
Batch 90, Loss: 0.2680
Batch 100, Loss: 0.2818
Batch 110, Loss: 0.2826
Batch 120, Loss: 0.2517
Batch 130, Loss: 0.2810
Batch 140, Loss: 0.2841
Batch 150, Loss: 0.2972
Batch 160, Loss: 0.2648
Batch 170, Loss: 0.2632
Batch 180, Loss: 0.2383
Batch 190, Loss: 0.2631
Batch 200, Loss: 0.2717
Batch 210, Loss: 0.2596
Batch 220, Loss: 0.2813
Batch 230, Loss: 0.2581
Batch 240, Loss: 0.2660
Batch 250, Loss: 0.2790
Batch 260, Loss: 0.3019
Batch 270, Loss: 0.3169
Batch 280, Loss: 0.2761
Batch 290, Loss: 0.2705
Batch 300, Loss: 0.2698
Batch 310, Loss: 0.2930
Batch 320, Loss: 0.2924
Batch 330, Loss: 0.2788
Batch 340, Loss: 0.3247
Batch 350, Loss: 0.2699
Batch 360, Loss: 0.2932
Batch 370, Loss: 0.2725
Batch 380, Loss: 0.2468
Batch 390, Loss: 0.2723
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.065521001815796 seconds
Epoch 150 accuracy: 94.24%
Batch 10, Loss: 0.2473
Batch 20, Loss: 0.2649
Batch 30, Loss: 0.2765
Batch 40, Loss: 0.2637
Batch 50, Loss: 0.2788
Batch 60, Loss: 0.2620
Batch 70, Loss: 0.2773
Batch 80, Loss: 0.2434
Batch 90, Loss: 0.2853
Batch 100, Loss: 0.2616
Batch 110, Loss: 0.2853
Batch 120, Loss: 0.2676
Batch 130, Loss: 0.2939
Batch 140, Loss: 0.2479
Batch 150, Loss: 0.2955
Batch 160, Loss: 0.2835
Batch 170, Loss: 0.2801
Batch 180, Loss: 0.2594
Batch 190, Loss: 0.2690
Batch 200, Loss: 0.2599
Batch 210, Loss: 0.2441
Batch 220, Loss: 0.3088
Batch 230, Loss: 0.2982
Batch 240, Loss: 0.2788
Batch 250, Loss: 0.2972
Batch 260, Loss: 0.2893
Batch 270, Loss: 0.2884
Batch 280, Loss: 0.2690
Batch 290, Loss: 0.2821
Batch 300, Loss: 0.2677
Batch 310, Loss: 0.2734
Batch 320, Loss: 0.2857
Batch 330, Loss: 0.2887
Batch 340, Loss: 0.2518
Batch 350, Loss: 0.2817
Batch 360, Loss: 0.2930
Batch 370, Loss: 0.2831
Batch 380, Loss: 0.2756
Batch 390, Loss: 0.2733
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.079795360565186 seconds
Epoch 151 accuracy: 94.06%
Batch 10, Loss: 0.2483
Batch 20, Loss: 0.2619
Batch 30, Loss: 0.2690
Batch 40, Loss: 0.2470
Batch 50, Loss: 0.2442
Batch 60, Loss: 0.2784
Batch 70, Loss: 0.2907
Batch 80, Loss: 0.2624
Batch 90, Loss: 0.2631
Batch 100, Loss: 0.2366
Batch 110, Loss: 0.2715
Batch 120, Loss: 0.3019
Batch 130, Loss: 0.2499
Batch 140, Loss: 0.2791
Batch 150, Loss: 0.2658
Batch 160, Loss: 0.2811
Batch 170, Loss: 0.3275
Batch 180, Loss: 0.2553
Batch 190, Loss: 0.2422
Batch 200, Loss: 0.2630
Batch 210, Loss: 0.2699
Batch 220, Loss: 0.2759
Batch 230, Loss: 0.2680
Batch 240, Loss: 0.2580
Batch 250, Loss: 0.2606
Batch 260, Loss: 0.2605
Batch 270, Loss: 0.2401
Batch 280, Loss: 0.2634
Batch 290, Loss: 0.2459
Batch 300, Loss: 0.2901
Batch 310, Loss: 0.2945
Batch 320, Loss: 0.3032
Batch 330, Loss: 0.2658
Batch 340, Loss: 0.2598
Batch 350, Loss: 0.2803
Batch 360, Loss: 0.2632
Batch 370, Loss: 0.2414
Batch 380, Loss: 0.2555
Batch 390, Loss: 0.3079
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.110252380371094 seconds
Epoch 152 accuracy: 93.17%
Batch 10, Loss: 0.2544
Batch 20, Loss: 0.2486
Batch 30, Loss: 0.2657
Batch 40, Loss: 0.2747
Batch 50, Loss: 0.2714
Batch 60, Loss: 0.2553
Batch 70, Loss: 0.2864
Batch 80, Loss: 0.2623
Batch 90, Loss: 0.2852
Batch 100, Loss: 0.2593
Batch 110, Loss: 0.2701
Batch 120, Loss: 0.2775
Batch 130, Loss: 0.2467
Batch 140, Loss: 0.2385
Batch 150, Loss: 0.2805
Batch 160, Loss: 0.2548
Batch 170, Loss: 0.2418
Batch 180, Loss: 0.2810
Batch 190, Loss: 0.2650
Batch 200, Loss: 0.2622
Batch 210, Loss: 0.2516
Batch 220, Loss: 0.2652
Batch 230, Loss: 0.2746
Batch 240, Loss: 0.2797
Batch 250, Loss: 0.2721
Batch 260, Loss: 0.2707
Batch 270, Loss: 0.2939
Batch 280, Loss: 0.2876
Batch 290, Loss: 0.2462
Batch 300, Loss: 0.2564
Batch 310, Loss: 0.2560
Batch 320, Loss: 0.2846
Batch 330, Loss: 0.2770
Batch 340, Loss: 0.2219
Batch 350, Loss: 0.2677
Batch 360, Loss: 0.2755
Batch 370, Loss: 0.2721
Batch 380, Loss: 0.2603
Batch 390, Loss: 0.2777
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.143555879592896 seconds
Epoch 153 accuracy: 93.72%
Batch 10, Loss: 0.2676
Batch 20, Loss: 0.2761
Batch 30, Loss: 0.2902
Batch 40, Loss: 0.2606
Batch 50, Loss: 0.2720
Batch 60, Loss: 0.2773
Batch 70, Loss: 0.2705
Batch 80, Loss: 0.2657
Batch 90, Loss: 0.2970
Batch 100, Loss: 0.2594
Batch 110, Loss: 0.2518
Batch 120, Loss: 0.2731
Batch 130, Loss: 0.2399
Batch 140, Loss: 0.2771
Batch 150, Loss: 0.2839
Batch 160, Loss: 0.2455
Batch 170, Loss: 0.3164
Batch 180, Loss: 0.2646
Batch 190, Loss: 0.2441
Batch 200, Loss: 0.2806
Batch 210, Loss: 0.2481
Batch 220, Loss: 0.2657
Batch 230, Loss: 0.2622
Batch 240, Loss: 0.2828
Batch 250, Loss: 0.2661
Batch 260, Loss: 0.2720
Batch 270, Loss: 0.2688
Batch 280, Loss: 0.3003
Batch 290, Loss: 0.2798
Batch 300, Loss: 0.2288
Batch 310, Loss: 0.2464
Batch 320, Loss: 0.2575
Batch 330, Loss: 0.2651
Batch 340, Loss: 0.2290
Batch 350, Loss: 0.2429
Batch 360, Loss: 0.2709
Batch 370, Loss: 0.2745
Batch 380, Loss: 0.2793
Batch 390, Loss: 0.2910
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.090129852294922 seconds
Epoch 154 accuracy: 94.36%
Batch 10, Loss: 0.2495
Batch 20, Loss: 0.2735
Batch 30, Loss: 0.2529
Batch 40, Loss: 0.2437
Batch 50, Loss: 0.2166
Batch 60, Loss: 0.2681
Batch 70, Loss: 0.2883
Batch 80, Loss: 0.2512
Batch 90, Loss: 0.2517
Batch 100, Loss: 0.2881
Batch 110, Loss: 0.2766
Batch 120, Loss: 0.3005
Batch 130, Loss: 0.2816
Batch 140, Loss: 0.2443
Batch 150, Loss: 0.2472
Batch 160, Loss: 0.2471
Batch 170, Loss: 0.2896
Batch 180, Loss: 0.2563
Batch 190, Loss: 0.2263
Batch 200, Loss: 0.2618
Batch 210, Loss: 0.2788
Batch 220, Loss: 0.2597
Batch 230, Loss: 0.2520
Batch 240, Loss: 0.2806
Batch 250, Loss: 0.2593
Batch 260, Loss: 0.2643
Batch 270, Loss: 0.2600
Batch 280, Loss: 0.2613
Batch 290, Loss: 0.2688
Batch 300, Loss: 0.2558
Batch 310, Loss: 0.2663
Batch 320, Loss: 0.2545
Batch 330, Loss: 0.2746
Batch 340, Loss: 0.2543
Batch 350, Loss: 0.2831
Batch 360, Loss: 0.2608
Batch 370, Loss: 0.2843
Batch 380, Loss: 0.2726
Batch 390, Loss: 0.2762
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.03841209411621 seconds
Epoch 155 accuracy: 93.96%
Batch 10, Loss: 0.2621
Batch 20, Loss: 0.2669
Batch 30, Loss: 0.2349
Batch 40, Loss: 0.2471
Batch 50, Loss: 0.2282
Batch 60, Loss: 0.2465
Batch 70, Loss: 0.2431
Batch 80, Loss: 0.2745
Batch 90, Loss: 0.2303
Batch 100, Loss: 0.2818
Batch 110, Loss: 0.2782
Batch 120, Loss: 0.2675
Batch 130, Loss: 0.2814
Batch 140, Loss: 0.2493
Batch 150, Loss: 0.2430
Batch 160, Loss: 0.2255
Batch 170, Loss: 0.2371
Batch 180, Loss: 0.2706
Batch 190, Loss: 0.2468
Batch 200, Loss: 0.2355
Batch 210, Loss: 0.2927
Batch 220, Loss: 0.2580
Batch 230, Loss: 0.2609
Batch 240, Loss: 0.2546
Batch 250, Loss: 0.2372
Batch 260, Loss: 0.2454
Batch 270, Loss: 0.2560
Batch 280, Loss: 0.2669
Batch 290, Loss: 0.2390
Batch 300, Loss: 0.2666
Batch 310, Loss: 0.2736
Batch 320, Loss: 0.2772
Batch 330, Loss: 0.2893
Batch 340, Loss: 0.2831
Batch 350, Loss: 0.2602
Batch 360, Loss: 0.2382
Batch 370, Loss: 0.2406
Batch 380, Loss: 0.2341
Batch 390, Loss: 0.2442
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.0489342212677 seconds
Epoch 156 accuracy: 93.64%
Batch 10, Loss: 0.2077
Batch 20, Loss: 0.2280
Batch 30, Loss: 0.2501
Batch 40, Loss: 0.2307
Batch 50, Loss: 0.2486
Batch 60, Loss: 0.2506
Batch 70, Loss: 0.2466
Batch 80, Loss: 0.2364
Batch 90, Loss: 0.2522
Batch 100, Loss: 0.2600
Batch 110, Loss: 0.2404
Batch 120, Loss: 0.3100
Batch 130, Loss: 0.2799
Batch 140, Loss: 0.2548
Batch 150, Loss: 0.2570
Batch 160, Loss: 0.2705
Batch 170, Loss: 0.2522
Batch 180, Loss: 0.2574
Batch 190, Loss: 0.2200
Batch 200, Loss: 0.2531
Batch 210, Loss: 0.2840
Batch 220, Loss: 0.2998
Batch 230, Loss: 0.2360
Batch 240, Loss: 0.2437
Batch 250, Loss: 0.2319
Batch 260, Loss: 0.2661
Batch 270, Loss: 0.2216
Batch 280, Loss: 0.2518
Batch 290, Loss: 0.2543
Batch 300, Loss: 0.2564
Batch 310, Loss: 0.2154
Batch 320, Loss: 0.2510
Batch 330, Loss: 0.2621
Batch 340, Loss: 0.2610
Batch 350, Loss: 0.2540
Batch 360, Loss: 0.2700
Batch 370, Loss: 0.3028
Batch 380, Loss: 0.2697
Batch 390, Loss: 0.2486
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.081864833831787 seconds
Epoch 157 accuracy: 94.16%
Batch 10, Loss: 0.2435
Batch 20, Loss: 0.2294
Batch 30, Loss: 0.2427
Batch 40, Loss: 0.2408
Batch 50, Loss: 0.2368
Batch 60, Loss: 0.2296
Batch 70, Loss: 0.2438
Batch 80, Loss: 0.2352
Batch 90, Loss: 0.2558
Batch 100, Loss: 0.2459
Batch 110, Loss: 0.2491
Batch 120, Loss: 0.2359
Batch 130, Loss: 0.2305
Batch 140, Loss: 0.2351
Batch 150, Loss: 0.2565
Batch 160, Loss: 0.2462
Batch 170, Loss: 0.2524
Batch 180, Loss: 0.2406
Batch 190, Loss: 0.2350
Batch 200, Loss: 0.2115
Batch 210, Loss: 0.2647
Batch 220, Loss: 0.2727
Batch 230, Loss: 0.2397
Batch 240, Loss: 0.2664
Batch 250, Loss: 0.2553
Batch 260, Loss: 0.2469
Batch 270, Loss: 0.2129
Batch 280, Loss: 0.2812
Batch 290, Loss: 0.2604
Batch 300, Loss: 0.2662
Batch 310, Loss: 0.2429
Batch 320, Loss: 0.2480
Batch 330, Loss: 0.2373
Batch 340, Loss: 0.2639
Batch 350, Loss: 0.2308
Batch 360, Loss: 0.2335
Batch 370, Loss: 0.2557
Batch 380, Loss: 0.2133
Batch 390, Loss: 0.2385
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.01164150238037 seconds
Epoch 158 accuracy: 93.84%
Batch 10, Loss: 0.2647
Batch 20, Loss: 0.2277
Batch 30, Loss: 0.2161
Batch 40, Loss: 0.2267
Batch 50, Loss: 0.2447
Batch 60, Loss: 0.2275
Batch 70, Loss: 0.2200
Batch 80, Loss: 0.2809
Batch 90, Loss: 0.2690
Batch 100, Loss: 0.2591
Batch 110, Loss: 0.2664
Batch 120, Loss: 0.2443
Batch 130, Loss: 0.2207
Batch 140, Loss: 0.2517
Batch 150, Loss: 0.2344
Batch 160, Loss: 0.2670
Batch 170, Loss: 0.2080
Batch 180, Loss: 0.2365
Batch 190, Loss: 0.2307
Batch 200, Loss: 0.2324
Batch 210, Loss: 0.2351
Batch 220, Loss: 0.2371
Batch 230, Loss: 0.2448
Batch 240, Loss: 0.2289
Batch 250, Loss: 0.2351
Batch 260, Loss: 0.2364
Batch 270, Loss: 0.2619
Batch 280, Loss: 0.2398
Batch 290, Loss: 0.2318
Batch 300, Loss: 0.2480
Batch 310, Loss: 0.2510
Batch 320, Loss: 0.2576
Batch 330, Loss: 0.2805
Batch 340, Loss: 0.2582
Batch 350, Loss: 0.2734
Batch 360, Loss: 0.2593
Batch 370, Loss: 0.2297
Batch 380, Loss: 0.2407
Batch 390, Loss: 0.2169
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 24.982754468917847 seconds
Epoch 159 accuracy: 94.18%
Batch 10, Loss: 0.2138
Batch 20, Loss: 0.2603
Batch 30, Loss: 0.2418
Batch 40, Loss: 0.2506
Batch 50, Loss: 0.2175
Batch 60, Loss: 0.2261
Batch 70, Loss: 0.2279
Batch 80, Loss: 0.2213
Batch 90, Loss: 0.2388
Batch 100, Loss: 0.2715
Batch 110, Loss: 0.2223
Batch 120, Loss: 0.2539
Batch 130, Loss: 0.2415
Batch 140, Loss: 0.2791
Batch 150, Loss: 0.2311
Batch 160, Loss: 0.2112
Batch 170, Loss: 0.2484
Batch 180, Loss: 0.2343
Batch 190, Loss: 0.2468
Batch 200, Loss: 0.2538
Batch 210, Loss: 0.2303
Batch 220, Loss: 0.2190
Batch 230, Loss: 0.2492
Batch 240, Loss: 0.2237
Batch 250, Loss: 0.2282
Batch 260, Loss: 0.2640
Batch 270, Loss: 0.2185
Batch 280, Loss: 0.2640
Batch 290, Loss: 0.2564
Batch 300, Loss: 0.2631
Batch 310, Loss: 0.2669
Batch 320, Loss: 0.2331
Batch 330, Loss: 0.2519
Batch 340, Loss: 0.2276
Batch 350, Loss: 0.2324
Batch 360, Loss: 0.2446
Batch 370, Loss: 0.2391
Batch 380, Loss: 0.2016
Batch 390, Loss: 0.2324
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.05203151702881 seconds
Epoch 160 accuracy: 94.22%
Batch 10, Loss: 0.2345
Batch 20, Loss: 0.2105
Batch 30, Loss: 0.2263
Batch 40, Loss: 0.2181
Batch 50, Loss: 0.2245
Batch 60, Loss: 0.2473
Batch 70, Loss: 0.2238
Batch 80, Loss: 0.2330
Batch 90, Loss: 0.2096
Batch 100, Loss: 0.2453
Batch 110, Loss: 0.2342
Batch 120, Loss: 0.2467
Batch 130, Loss: 0.2365
Batch 140, Loss: 0.2360
Batch 150, Loss: 0.2308
Batch 160, Loss: 0.2213
Batch 170, Loss: 0.2582
Batch 180, Loss: 0.2322
Batch 190, Loss: 0.2323
Batch 200, Loss: 0.2595
Batch 210, Loss: 0.2028
Batch 220, Loss: 0.2143
Batch 230, Loss: 0.2255
Batch 240, Loss: 0.2201
Batch 250, Loss: 0.2699
Batch 260, Loss: 0.2040
Batch 270, Loss: 0.2357
Batch 280, Loss: 0.2507
Batch 290, Loss: 0.2197
Batch 300, Loss: 0.2322
Batch 310, Loss: 0.2165
Batch 320, Loss: 0.2156
Batch 330, Loss: 0.2138
Batch 340, Loss: 0.2620
Batch 350, Loss: 0.2207
Batch 360, Loss: 0.2376
Batch 370, Loss: 0.2364
Batch 380, Loss: 0.2410
Batch 390, Loss: 0.2195
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.087223052978516 seconds
Epoch 161 accuracy: 94.3%
Batch 10, Loss: 0.2305
Batch 20, Loss: 0.2257
Batch 30, Loss: 0.2126
Batch 40, Loss: 0.1879
Batch 50, Loss: 0.2243
Batch 60, Loss: 0.2188
Batch 70, Loss: 0.2361
Batch 80, Loss: 0.2447
Batch 90, Loss: 0.2375
Batch 100, Loss: 0.2540
Batch 110, Loss: 0.2274
Batch 120, Loss: 0.2395
Batch 130, Loss: 0.2206
Batch 140, Loss: 0.2320
Batch 150, Loss: 0.2402
Batch 160, Loss: 0.2191
Batch 170, Loss: 0.2265
Batch 180, Loss: 0.2460
Batch 190, Loss: 0.2402
Batch 200, Loss: 0.2480
Batch 210, Loss: 0.2661
Batch 220, Loss: 0.2309
Batch 230, Loss: 0.2448
Batch 240, Loss: 0.2679
Batch 250, Loss: 0.2509
Batch 260, Loss: 0.2090
Batch 270, Loss: 0.2163
Batch 280, Loss: 0.2068
Batch 290, Loss: 0.2317
Batch 300, Loss: 0.2274
Batch 310, Loss: 0.2470
Batch 320, Loss: 0.2136
Batch 330, Loss: 0.2133
Batch 340, Loss: 0.2200
Batch 350, Loss: 0.2164
Batch 360, Loss: 0.2211
Batch 370, Loss: 0.2559
Batch 380, Loss: 0.2042
Batch 390, Loss: 0.2262
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.09031105041504 seconds
Epoch 162 accuracy: 94.72%
Batch 10, Loss: 0.2210
Batch 20, Loss: 0.2282
Batch 30, Loss: 0.2238
Batch 40, Loss: 0.2082
Batch 50, Loss: 0.2270
Batch 60, Loss: 0.2298
Batch 70, Loss: 0.2177
Batch 80, Loss: 0.2048
Batch 90, Loss: 0.2384
Batch 100, Loss: 0.2197
Batch 110, Loss: 0.2126
Batch 120, Loss: 0.2326
Batch 130, Loss: 0.2079
Batch 140, Loss: 0.2130
Batch 150, Loss: 0.2426
Batch 160, Loss: 0.2338
Batch 170, Loss: 0.2212
Batch 180, Loss: 0.2100
Batch 190, Loss: 0.2206
Batch 200, Loss: 0.2180
Batch 210, Loss: 0.2124
Batch 220, Loss: 0.2430
Batch 230, Loss: 0.2681
Batch 240, Loss: 0.2162
Batch 250, Loss: 0.2425
Batch 260, Loss: 0.2400
Batch 270, Loss: 0.2522
Batch 280, Loss: 0.2720
Batch 290, Loss: 0.2412
Batch 300, Loss: 0.2272
Batch 310, Loss: 0.2274
Batch 320, Loss: 0.2543
Batch 330, Loss: 0.2207
Batch 340, Loss: 0.1921
Batch 350, Loss: 0.2356
Batch 360, Loss: 0.2168
Batch 370, Loss: 0.2112
Batch 380, Loss: 0.1883
Batch 390, Loss: 0.2389
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.02777647972107 seconds
Epoch 163 accuracy: 94.63%
Batch 10, Loss: 0.2312
Batch 20, Loss: 0.2400
Batch 30, Loss: 0.2174
Batch 40, Loss: 0.1933
Batch 50, Loss: 0.2117
Batch 60, Loss: 0.2314
Batch 70, Loss: 0.1913
Batch 80, Loss: 0.2440
Batch 90, Loss: 0.2241
Batch 100, Loss: 0.2239
Batch 110, Loss: 0.2391
Batch 120, Loss: 0.2357
Batch 130, Loss: 0.2204
Batch 140, Loss: 0.2207
Batch 150, Loss: 0.2125
Batch 160, Loss: 0.2304
Batch 170, Loss: 0.2237
Batch 180, Loss: 0.2205
Batch 190, Loss: 0.2291
Batch 200, Loss: 0.1962
Batch 210, Loss: 0.2113
Batch 220, Loss: 0.2195
Batch 230, Loss: 0.2207
Batch 240, Loss: 0.2227
Batch 250, Loss: 0.2814
Batch 260, Loss: 0.2025
Batch 270, Loss: 0.2409
Batch 280, Loss: 0.2388
Batch 290, Loss: 0.2005
Batch 300, Loss: 0.2239
Batch 310, Loss: 0.2166
Batch 320, Loss: 0.2008
Batch 330, Loss: 0.2111
Batch 340, Loss: 0.2161
Batch 350, Loss: 0.2180
Batch 360, Loss: 0.1975
Batch 370, Loss: 0.2445
Batch 380, Loss: 0.2197
Batch 390, Loss: 0.2350
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.022854804992676 seconds
Epoch 164 accuracy: 94.67%
Batch 10, Loss: 0.1976
Batch 20, Loss: 0.2164
Batch 30, Loss: 0.2204
Batch 40, Loss: 0.2277
Batch 50, Loss: 0.2051
Batch 60, Loss: 0.2254
Batch 70, Loss: 0.2045
Batch 80, Loss: 0.2264
Batch 90, Loss: 0.2464
Batch 100, Loss: 0.2077
Batch 110, Loss: 0.1915
Batch 120, Loss: 0.2274
Batch 130, Loss: 0.1860
Batch 140, Loss: 0.2410
Batch 150, Loss: 0.2160
Batch 160, Loss: 0.2083
Batch 170, Loss: 0.2048
Batch 180, Loss: 0.2323
Batch 190, Loss: 0.2020
Batch 200, Loss: 0.2060
Batch 210, Loss: 0.2067
Batch 220, Loss: 0.2055
Batch 230, Loss: 0.1925
Batch 240, Loss: 0.2147
Batch 250, Loss: 0.2350
Batch 260, Loss: 0.2264
Batch 270, Loss: 0.2089
Batch 280, Loss: 0.2452
Batch 290, Loss: 0.2201
Batch 300, Loss: 0.1942
Batch 310, Loss: 0.2159
Batch 320, Loss: 0.1963
Batch 330, Loss: 0.2203
Batch 340, Loss: 0.2261
Batch 350, Loss: 0.2253
Batch 360, Loss: 0.2293
Batch 370, Loss: 0.2333
Batch 380, Loss: 0.2188
Batch 390, Loss: 0.2321
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.063222408294678 seconds
Epoch 165 accuracy: 94.5%
Batch 10, Loss: 0.2207
Batch 20, Loss: 0.2199
Batch 30, Loss: 0.2154
Batch 40, Loss: 0.2301
Batch 50, Loss: 0.2125
Batch 60, Loss: 0.2137
Batch 70, Loss: 0.2030
Batch 80, Loss: 0.2243
Batch 90, Loss: 0.2263
Batch 100, Loss: 0.2099
Batch 110, Loss: 0.2114
Batch 120, Loss: 0.1983
Batch 130, Loss: 0.2218
Batch 140, Loss: 0.2245
Batch 150, Loss: 0.2080
Batch 160, Loss: 0.2309
Batch 170, Loss: 0.2054
Batch 180, Loss: 0.2061
Batch 190, Loss: 0.2273
Batch 200, Loss: 0.2405
Batch 210, Loss: 0.2153
Batch 220, Loss: 0.2155
Batch 230, Loss: 0.2205
Batch 240, Loss: 0.1827
Batch 250, Loss: 0.1898
Batch 260, Loss: 0.2099
Batch 270, Loss: 0.2065
Batch 280, Loss: 0.2259
Batch 290, Loss: 0.2079
Batch 300, Loss: 0.2091
Batch 310, Loss: 0.2165
Batch 320, Loss: 0.2000
Batch 330, Loss: 0.2205
Batch 340, Loss: 0.2340
Batch 350, Loss: 0.2178
Batch 360, Loss: 0.1951
Batch 370, Loss: 0.2082
Batch 380, Loss: 0.1978
Batch 390, Loss: 0.2095
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.09528374671936 seconds
Epoch 166 accuracy: 94.76%
Batch 10, Loss: 0.2135
Batch 20, Loss: 0.2283
Batch 30, Loss: 0.2117
Batch 40, Loss: 0.1880
Batch 50, Loss: 0.1999
Batch 60, Loss: 0.2243
Batch 70, Loss: 0.2045
Batch 80, Loss: 0.2213
Batch 90, Loss: 0.1896
Batch 100, Loss: 0.1863
Batch 110, Loss: 0.2131
Batch 120, Loss: 0.2323
Batch 130, Loss: 0.2257
Batch 140, Loss: 0.2244
Batch 150, Loss: 0.2168
Batch 160, Loss: 0.2434
Batch 170, Loss: 0.2000
Batch 180, Loss: 0.1865
Batch 190, Loss: 0.2096
Batch 200, Loss: 0.2241
Batch 210, Loss: 0.1936
Batch 220, Loss: 0.1953
Batch 230, Loss: 0.2202
Batch 240, Loss: 0.1972
Batch 250, Loss: 0.2217
Batch 260, Loss: 0.2249
Batch 270, Loss: 0.1782
Batch 280, Loss: 0.2285
Batch 290, Loss: 0.2202
Batch 300, Loss: 0.2347
Batch 310, Loss: 0.2126
Batch 320, Loss: 0.1837
Batch 330, Loss: 0.2077
Batch 340, Loss: 0.2195
Batch 350, Loss: 0.2085
Batch 360, Loss: 0.2370
Batch 370, Loss: 0.2382
Batch 380, Loss: 0.2076
Batch 390, Loss: 0.1955
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.05299687385559 seconds
Epoch 167 accuracy: 95.31%
Batch 10, Loss: 0.2356
Batch 20, Loss: 0.2167
Batch 30, Loss: 0.1968
Batch 40, Loss: 0.1850
Batch 50, Loss: 0.1944
Batch 60, Loss: 0.2308
Batch 70, Loss: 0.1963
Batch 80, Loss: 0.2091
Batch 90, Loss: 0.2072
Batch 100, Loss: 0.2142
Batch 110, Loss: 0.1878
Batch 120, Loss: 0.2142
Batch 130, Loss: 0.2193
Batch 140, Loss: 0.2140
Batch 150, Loss: 0.2582
Batch 160, Loss: 0.2139
Batch 170, Loss: 0.2222
Batch 180, Loss: 0.1687
Batch 190, Loss: 0.2108
Batch 200, Loss: 0.2243
Batch 210, Loss: 0.1839
Batch 220, Loss: 0.1949
Batch 230, Loss: 0.2021
Batch 240, Loss: 0.1981
Batch 250, Loss: 0.2241
Batch 260, Loss: 0.2244
Batch 270, Loss: 0.1987
Batch 280, Loss: 0.2189
Batch 290, Loss: 0.2164
Batch 300, Loss: 0.1777
Batch 310, Loss: 0.1896
Batch 320, Loss: 0.2057
Batch 330, Loss: 0.1928
Batch 340, Loss: 0.2036
Batch 350, Loss: 0.2140
Batch 360, Loss: 0.2096
Batch 370, Loss: 0.2228
Batch 380, Loss: 0.2084
Batch 390, Loss: 0.2186
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 24.993489980697632 seconds
Epoch 168 accuracy: 95.06%
Batch 10, Loss: 0.2048
Batch 20, Loss: 0.2122
Batch 30, Loss: 0.1867
Batch 40, Loss: 0.2026
Batch 50, Loss: 0.2195
Batch 60, Loss: 0.2101
Batch 70, Loss: 0.2203
Batch 80, Loss: 0.2010
Batch 90, Loss: 0.1947
Batch 100, Loss: 0.2192
Batch 110, Loss: 0.2110
Batch 120, Loss: 0.2183
Batch 130, Loss: 0.1942
Batch 140, Loss: 0.1964
Batch 150, Loss: 0.2274
Batch 160, Loss: 0.1902
Batch 170, Loss: 0.1939
Batch 180, Loss: 0.2059
Batch 190, Loss: 0.2063
Batch 200, Loss: 0.2199
Batch 210, Loss: 0.1803
Batch 220, Loss: 0.2002
Batch 230, Loss: 0.2016
Batch 240, Loss: 0.2085
Batch 250, Loss: 0.1979
Batch 260, Loss: 0.2083
Batch 270, Loss: 0.2116
Batch 280, Loss: 0.1925
Batch 290, Loss: 0.1980
Batch 300, Loss: 0.2293
Batch 310, Loss: 0.1993
Batch 320, Loss: 0.2021
Batch 330, Loss: 0.2242
Batch 340, Loss: 0.2030
Batch 350, Loss: 0.2202
Batch 360, Loss: 0.2075
Batch 370, Loss: 0.2292
Batch 380, Loss: 0.2341
Batch 390, Loss: 0.1903
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.01261019706726 seconds
Epoch 169 accuracy: 95.05%
Batch 10, Loss: 0.1923
Batch 20, Loss: 0.2122
Batch 30, Loss: 0.2125
Batch 40, Loss: 0.1810
Batch 50, Loss: 0.1882
Batch 60, Loss: 0.2156
Batch 70, Loss: 0.1901
Batch 80, Loss: 0.2109
Batch 90, Loss: 0.2009
Batch 100, Loss: 0.2142
Batch 110, Loss: 0.2079
Batch 120, Loss: 0.1835
Batch 130, Loss: 0.1734
Batch 140, Loss: 0.2033
Batch 150, Loss: 0.2008
Batch 160, Loss: 0.1755
Batch 170, Loss: 0.1945
Batch 180, Loss: 0.1777
Batch 190, Loss: 0.1927
Batch 200, Loss: 0.1739
Batch 210, Loss: 0.1955
Batch 220, Loss: 0.1647
Batch 230, Loss: 0.1863
Batch 240, Loss: 0.1925
Batch 250, Loss: 0.2187
Batch 260, Loss: 0.1988
Batch 270, Loss: 0.2099
Batch 280, Loss: 0.2057
Batch 290, Loss: 0.1887
Batch 300, Loss: 0.2388
Batch 310, Loss: 0.1771
Batch 320, Loss: 0.1894
Batch 330, Loss: 0.2100
Batch 340, Loss: 0.1771
Batch 350, Loss: 0.2110
Batch 360, Loss: 0.1951
Batch 370, Loss: 0.2206
Batch 380, Loss: 0.2236
Batch 390, Loss: 0.1789
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.04077696800232 seconds
Epoch 170 accuracy: 95.08%
Batch 10, Loss: 0.1938
Batch 20, Loss: 0.2054
Batch 30, Loss: 0.1929
Batch 40, Loss: 0.2099
Batch 50, Loss: 0.2056
Batch 60, Loss: 0.1858
Batch 70, Loss: 0.1940
Batch 80, Loss: 0.1768
Batch 90, Loss: 0.1838
Batch 100, Loss: 0.1844
Batch 110, Loss: 0.1681
Batch 120, Loss: 0.1922
Batch 130, Loss: 0.2144
Batch 140, Loss: 0.2073
Batch 150, Loss: 0.1919
Batch 160, Loss: 0.1924
Batch 170, Loss: 0.2041
Batch 180, Loss: 0.1926
Batch 190, Loss: 0.1909
Batch 200, Loss: 0.2222
Batch 210, Loss: 0.1798
Batch 220, Loss: 0.1808
Batch 230, Loss: 0.1774
Batch 240, Loss: 0.1667
Batch 250, Loss: 0.1973
Batch 260, Loss: 0.1972
Batch 270, Loss: 0.2276
Batch 280, Loss: 0.1597
Batch 290, Loss: 0.1883
Batch 300, Loss: 0.1874
Batch 310, Loss: 0.1851
Batch 320, Loss: 0.2232
Batch 330, Loss: 0.2141
Batch 340, Loss: 0.1840
Batch 350, Loss: 0.1724
Batch 360, Loss: 0.1907
Batch 370, Loss: 0.2150
Batch 380, Loss: 0.1963
Batch 390, Loss: 0.2118
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.058311462402344 seconds
Epoch 171 accuracy: 95.47%
Batch 10, Loss: 0.1842
Batch 20, Loss: 0.2164
Batch 30, Loss: 0.2208
Batch 40, Loss: 0.1788
Batch 50, Loss: 0.1866
Batch 60, Loss: 0.1677
Batch 70, Loss: 0.1926
Batch 80, Loss: 0.1762
Batch 90, Loss: 0.1882
Batch 100, Loss: 0.2032
Batch 110, Loss: 0.1724
Batch 120, Loss: 0.1763
Batch 130, Loss: 0.1732
Batch 140, Loss: 0.1869
Batch 150, Loss: 0.1836
Batch 160, Loss: 0.1672
Batch 170, Loss: 0.1752
Batch 180, Loss: 0.1817
Batch 190, Loss: 0.1720
Batch 200, Loss: 0.1949
Batch 210, Loss: 0.1725
Batch 220, Loss: 0.2029
Batch 230, Loss: 0.2163
Batch 240, Loss: 0.1821
Batch 250, Loss: 0.1808
Batch 260, Loss: 0.1715
Batch 270, Loss: 0.1852
Batch 280, Loss: 0.1681
Batch 290, Loss: 0.1821
Batch 300, Loss: 0.1952
Batch 310, Loss: 0.1765
Batch 320, Loss: 0.2056
Batch 330, Loss: 0.2251
Batch 340, Loss: 0.1827
Batch 350, Loss: 0.1921
Batch 360, Loss: 0.2200
Batch 370, Loss: 0.1943
Batch 380, Loss: 0.1764
Batch 390, Loss: 0.1901
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.065019607543945 seconds
Epoch 172 accuracy: 95.49%
Batch 10, Loss: 0.2002
Batch 20, Loss: 0.1294
Batch 30, Loss: 0.1859
Batch 40, Loss: 0.1764
Batch 50, Loss: 0.1790
Batch 60, Loss: 0.1947
Batch 70, Loss: 0.1658
Batch 80, Loss: 0.1686
Batch 90, Loss: 0.1744
Batch 100, Loss: 0.2092
Batch 110, Loss: 0.1894
Batch 120, Loss: 0.1903
Batch 130, Loss: 0.1959
Batch 140, Loss: 0.2056
Batch 150, Loss: 0.2130
Batch 160, Loss: 0.1846
Batch 170, Loss: 0.1822
Batch 180, Loss: 0.2191
Batch 190, Loss: 0.1617
Batch 200, Loss: 0.1925
Batch 210, Loss: 0.1825
Batch 220, Loss: 0.1543
Batch 230, Loss: 0.2108
Batch 240, Loss: 0.1747
Batch 250, Loss: 0.1790
Batch 260, Loss: 0.1746
Batch 270, Loss: 0.1970
Batch 280, Loss: 0.2199
Batch 290, Loss: 0.1625
Batch 300, Loss: 0.1779
Batch 310, Loss: 0.1844
Batch 320, Loss: 0.2011
Batch 330, Loss: 0.1906
Batch 340, Loss: 0.1887
Batch 350, Loss: 0.1791
Batch 360, Loss: 0.1839
Batch 370, Loss: 0.2204
Batch 380, Loss: 0.1821
Batch 390, Loss: 0.1678
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.034180641174316 seconds
Epoch 173 accuracy: 95.57%
Batch 10, Loss: 0.1750
Batch 20, Loss: 0.1981
Batch 30, Loss: 0.1781
Batch 40, Loss: 0.1661
Batch 50, Loss: 0.1979
Batch 60, Loss: 0.1616
Batch 70, Loss: 0.1930
Batch 80, Loss: 0.1533
Batch 90, Loss: 0.1979
Batch 100, Loss: 0.1884
Batch 110, Loss: 0.1992
Batch 120, Loss: 0.1618
Batch 130, Loss: 0.1780
Batch 140, Loss: 0.1919
Batch 150, Loss: 0.1920
Batch 160, Loss: 0.1588
Batch 170, Loss: 0.1809
Batch 180, Loss: 0.1742
Batch 190, Loss: 0.1702
Batch 200, Loss: 0.1834
Batch 210, Loss: 0.1710
Batch 220, Loss: 0.1828
Batch 230, Loss: 0.1796
Batch 240, Loss: 0.1851
Batch 250, Loss: 0.1701
Batch 260, Loss: 0.1772
Batch 270, Loss: 0.1651
Batch 280, Loss: 0.1773
Batch 290, Loss: 0.1572
Batch 300, Loss: 0.2052
Batch 310, Loss: 0.1765
Batch 320, Loss: 0.1620
Batch 330, Loss: 0.1858
Batch 340, Loss: 0.1661
Batch 350, Loss: 0.1696
Batch 360, Loss: 0.1919
Batch 370, Loss: 0.1773
Batch 380, Loss: 0.1613
Batch 390, Loss: 0.1872
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.04941463470459 seconds
Epoch 174 accuracy: 95.39%
Batch 10, Loss: 0.1687
Batch 20, Loss: 0.1546
Batch 30, Loss: 0.1751
Batch 40, Loss: 0.1975
Batch 50, Loss: 0.1768
Batch 60, Loss: 0.1739
Batch 70, Loss: 0.1878
Batch 80, Loss: 0.1764
Batch 90, Loss: 0.1809
Batch 100, Loss: 0.1565
Batch 110, Loss: 0.1939
Batch 120, Loss: 0.1871
Batch 130, Loss: 0.1478
Batch 140, Loss: 0.1966
Batch 150, Loss: 0.1651
Batch 160, Loss: 0.1600
Batch 170, Loss: 0.1704
Batch 180, Loss: 0.1860
Batch 190, Loss: 0.1906
Batch 200, Loss: 0.1865
Batch 210, Loss: 0.1573
Batch 220, Loss: 0.1889
Batch 230, Loss: 0.1633
Batch 240, Loss: 0.1848
Batch 250, Loss: 0.1766
Batch 260, Loss: 0.1613
Batch 270, Loss: 0.1689
Batch 280, Loss: 0.1815
Batch 290, Loss: 0.1589
Batch 300, Loss: 0.1913
Batch 310, Loss: 0.1773
Batch 320, Loss: 0.1659
Batch 330, Loss: 0.1776
Batch 340, Loss: 0.1730
Batch 350, Loss: 0.1835
Batch 360, Loss: 0.1772
Batch 370, Loss: 0.1832
Batch 380, Loss: 0.1965
Batch 390, Loss: 0.1898
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.076035976409912 seconds
Epoch 175 accuracy: 95.55%
Batch 10, Loss: 0.1700
Batch 20, Loss: 0.1768
Batch 30, Loss: 0.1535
Batch 40, Loss: 0.1565
Batch 50, Loss: 0.1851
Batch 60, Loss: 0.1640
Batch 70, Loss: 0.1844
Batch 80, Loss: 0.1647
Batch 90, Loss: 0.1599
Batch 100, Loss: 0.1646
Batch 110, Loss: 0.1793
Batch 120, Loss: 0.1655
Batch 130, Loss: 0.1731
Batch 140, Loss: 0.1771
Batch 150, Loss: 0.1681
Batch 160, Loss: 0.1917
Batch 170, Loss: 0.1658
Batch 180, Loss: 0.1770
Batch 190, Loss: 0.1852
Batch 200, Loss: 0.1804
Batch 210, Loss: 0.1592
Batch 220, Loss: 0.1908
Batch 230, Loss: 0.1957
Batch 240, Loss: 0.1635
Batch 250, Loss: 0.1553
Batch 260, Loss: 0.1812
Batch 270, Loss: 0.1595
Batch 280, Loss: 0.1792
Batch 290, Loss: 0.1690
Batch 300, Loss: 0.1672
Batch 310, Loss: 0.1809
Batch 320, Loss: 0.1463
Batch 330, Loss: 0.1743
Batch 340, Loss: 0.1731
Batch 350, Loss: 0.1890
Batch 360, Loss: 0.1746
Batch 370, Loss: 0.1741
Batch 380, Loss: 0.1639
Batch 390, Loss: 0.1805
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.068055629730225 seconds
Epoch 176 accuracy: 95.67%
Batch 10, Loss: 0.1752
Batch 20, Loss: 0.1777
Batch 30, Loss: 0.1683
Batch 40, Loss: 0.1443
Batch 50, Loss: 0.1691
Batch 60, Loss: 0.1875
Batch 70, Loss: 0.1307
Batch 80, Loss: 0.1634
Batch 90, Loss: 0.1870
Batch 100, Loss: 0.1817
Batch 110, Loss: 0.1649
Batch 120, Loss: 0.1704
Batch 130, Loss: 0.1581
Batch 140, Loss: 0.1701
Batch 150, Loss: 0.1884
Batch 160, Loss: 0.1805
Batch 170, Loss: 0.1781
Batch 180, Loss: 0.1727
Batch 190, Loss: 0.1827
Batch 200, Loss: 0.1647
Batch 210, Loss: 0.1766
Batch 220, Loss: 0.1837
Batch 230, Loss: 0.1681
Batch 240, Loss: 0.1563
Batch 250, Loss: 0.1586
Batch 260, Loss: 0.1729
Batch 270, Loss: 0.1797
Batch 280, Loss: 0.1768
Batch 290, Loss: 0.1594
Batch 300, Loss: 0.1757
Batch 310, Loss: 0.1821
Batch 320, Loss: 0.1829
Batch 330, Loss: 0.1939
Batch 340, Loss: 0.1601
Batch 350, Loss: 0.1656
Batch 360, Loss: 0.1594
Batch 370, Loss: 0.1774
Batch 380, Loss: 0.1683
Batch 390, Loss: 0.1659
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.00693988800049 seconds
Epoch 177 accuracy: 95.93%
Batch 10, Loss: 0.1670
Batch 20, Loss: 0.1520
Batch 30, Loss: 0.1814
Batch 40, Loss: 0.1567
Batch 50, Loss: 0.1702
Batch 60, Loss: 0.1697
Batch 70, Loss: 0.1542
Batch 80, Loss: 0.1593
Batch 90, Loss: 0.1788
Batch 100, Loss: 0.1403
Batch 110, Loss: 0.1552
Batch 120, Loss: 0.1845
Batch 130, Loss: 0.1675
Batch 140, Loss: 0.1507
Batch 150, Loss: 0.1615
Batch 160, Loss: 0.1945
Batch 170, Loss: 0.1631
Batch 180, Loss: 0.1655
Batch 190, Loss: 0.1632
Batch 200, Loss: 0.1661
Batch 210, Loss: 0.1785
Batch 220, Loss: 0.1729
Batch 230, Loss: 0.1714
Batch 240, Loss: 0.1662
Batch 250, Loss: 0.1846
Batch 260, Loss: 0.1670
Batch 270, Loss: 0.1542
Batch 280, Loss: 0.1852
Batch 290, Loss: 0.1503
Batch 300, Loss: 0.1655
Batch 310, Loss: 0.1561
Batch 320, Loss: 0.1713
Batch 330, Loss: 0.1830
Batch 340, Loss: 0.1666
Batch 350, Loss: 0.1818
Batch 360, Loss: 0.1687
Batch 370, Loss: 0.1440
Batch 380, Loss: 0.1420
Batch 390, Loss: 0.1762
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.03976273536682 seconds
Epoch 178 accuracy: 95.91%
Batch 10, Loss: 0.1795
Batch 20, Loss: 0.1862
Batch 30, Loss: 0.1633
Batch 40, Loss: 0.1587
Batch 50, Loss: 0.1626
Batch 60, Loss: 0.1623
Batch 70, Loss: 0.1854
Batch 80, Loss: 0.1470
Batch 90, Loss: 0.1703
Batch 100, Loss: 0.1658
Batch 110, Loss: 0.1729
Batch 120, Loss: 0.1671
Batch 130, Loss: 0.1554
Batch 140, Loss: 0.1675
Batch 150, Loss: 0.1701
Batch 160, Loss: 0.1653
Batch 170, Loss: 0.1778
Batch 180, Loss: 0.1638
Batch 190, Loss: 0.1595
Batch 200, Loss: 0.1682
Batch 210, Loss: 0.1770
Batch 220, Loss: 0.1689
Batch 230, Loss: 0.1620
Batch 240, Loss: 0.1458
Batch 250, Loss: 0.1852
Batch 260, Loss: 0.1487
Batch 270, Loss: 0.1682
Batch 280, Loss: 0.1841
Batch 290, Loss: 0.1653
Batch 300, Loss: 0.1744
Batch 310, Loss: 0.1659
Batch 320, Loss: 0.1574
Batch 330, Loss: 0.1376
Batch 340, Loss: 0.1803
Batch 350, Loss: 0.1714
Batch 360, Loss: 0.1759
Batch 370, Loss: 0.1640
Batch 380, Loss: 0.1580
Batch 390, Loss: 0.1705
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.064727783203125 seconds
Epoch 179 accuracy: 96.04%
Batch 10, Loss: 0.1624
Batch 20, Loss: 0.1611
Batch 30, Loss: 0.1551
Batch 40, Loss: 0.1561
Batch 50, Loss: 0.1528
Batch 60, Loss: 0.1530
Batch 70, Loss: 0.1716
Batch 80, Loss: 0.1555
Batch 90, Loss: 0.1822
Batch 100, Loss: 0.1628
Batch 110, Loss: 0.1559
Batch 120, Loss: 0.1623
Batch 130, Loss: 0.1573
Batch 140, Loss: 0.1657
Batch 150, Loss: 0.1706
Batch 160, Loss: 0.1632
Batch 170, Loss: 0.1725
Batch 180, Loss: 0.1664
Batch 190, Loss: 0.1651
Batch 200, Loss: 0.1549
Batch 210, Loss: 0.1496
Batch 220, Loss: 0.1550
Batch 230, Loss: 0.1274
Batch 240, Loss: 0.1387
Batch 250, Loss: 0.1663
Batch 260, Loss: 0.1640
Batch 270, Loss: 0.1344
Batch 280, Loss: 0.1523
Batch 290, Loss: 0.1581
Batch 300, Loss: 0.1683
Batch 310, Loss: 0.1688
Batch 320, Loss: 0.1437
Batch 330, Loss: 0.1716
Batch 340, Loss: 0.1547
Batch 350, Loss: 0.1441
Batch 360, Loss: 0.1412
Batch 370, Loss: 0.1553
Batch 380, Loss: 0.1524
Batch 390, Loss: 0.1533
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.062164545059204 seconds
Epoch 180 accuracy: 96.36%
Batch 10, Loss: 0.1716
Batch 20, Loss: 0.1626
Batch 30, Loss: 0.1757
Batch 40, Loss: 0.1400
Batch 50, Loss: 0.1392
Batch 60, Loss: 0.1444
Batch 70, Loss: 0.1615
Batch 80, Loss: 0.1317
Batch 90, Loss: 0.1462
Batch 100, Loss: 0.1514
Batch 110, Loss: 0.1636
Batch 120, Loss: 0.1800
Batch 130, Loss: 0.1319
Batch 140, Loss: 0.1541
Batch 150, Loss: 0.1405
Batch 160, Loss: 0.1688
Batch 170, Loss: 0.1665
Batch 180, Loss: 0.1645
Batch 190, Loss: 0.1547
Batch 200, Loss: 0.1560
Batch 210, Loss: 0.1501
Batch 220, Loss: 0.1607
Batch 230, Loss: 0.1439
Batch 240, Loss: 0.1447
Batch 250, Loss: 0.1421
Batch 260, Loss: 0.1734
Batch 270, Loss: 0.1386
Batch 280, Loss: 0.1645
Batch 290, Loss: 0.1386
Batch 300, Loss: 0.1530
Batch 310, Loss: 0.1660
Batch 320, Loss: 0.1652
Batch 330, Loss: 0.1563
Batch 340, Loss: 0.1588
Batch 350, Loss: 0.1753
Batch 360, Loss: 0.1471
Batch 370, Loss: 0.1630
Batch 380, Loss: 0.1602
Batch 390, Loss: 0.1507
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.091479778289795 seconds
Epoch 181 accuracy: 96.21%
Batch 10, Loss: 0.1459
Batch 20, Loss: 0.1316
Batch 30, Loss: 0.1442
Batch 40, Loss: 0.1604
Batch 50, Loss: 0.1528
Batch 60, Loss: 0.1694
Batch 70, Loss: 0.1465
Batch 80, Loss: 0.1342
Batch 90, Loss: 0.1452
Batch 100, Loss: 0.1489
Batch 110, Loss: 0.1580
Batch 120, Loss: 0.1512
Batch 130, Loss: 0.1375
Batch 140, Loss: 0.1582
Batch 150, Loss: 0.1454
Batch 160, Loss: 0.1515
Batch 170, Loss: 0.1537
Batch 180, Loss: 0.1523
Batch 190, Loss: 0.1538
Batch 200, Loss: 0.1356
Batch 210, Loss: 0.1312
Batch 220, Loss: 0.1434
Batch 230, Loss: 0.1772
Batch 240, Loss: 0.1486
Batch 250, Loss: 0.1693
Batch 260, Loss: 0.1612
Batch 270, Loss: 0.1392
Batch 280, Loss: 0.1709
Batch 290, Loss: 0.1085
Batch 300, Loss: 0.1679
Batch 310, Loss: 0.1612
Batch 320, Loss: 0.1494
Batch 330, Loss: 0.1436
Batch 340, Loss: 0.1485
Batch 350, Loss: 0.1517
Batch 360, Loss: 0.1335
Batch 370, Loss: 0.1505
Batch 380, Loss: 0.1693
Batch 390, Loss: 0.1302
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.08630681037903 seconds
Epoch 182 accuracy: 96.21%
Batch 10, Loss: 0.1474
Batch 20, Loss: 0.1529
Batch 30, Loss: 0.1345
Batch 40, Loss: 0.1589
Batch 50, Loss: 0.1286
Batch 60, Loss: 0.1418
Batch 70, Loss: 0.1785
Batch 80, Loss: 0.1376
Batch 90, Loss: 0.1550
Batch 100, Loss: 0.1617
Batch 110, Loss: 0.1455
Batch 120, Loss: 0.1476
Batch 130, Loss: 0.1487
Batch 140, Loss: 0.1365
Batch 150, Loss: 0.1695
Batch 160, Loss: 0.1747
Batch 170, Loss: 0.1362
Batch 180, Loss: 0.1428
Batch 190, Loss: 0.1464
Batch 200, Loss: 0.1492
Batch 210, Loss: 0.1546
Batch 220, Loss: 0.1506
Batch 230, Loss: 0.1519
Batch 240, Loss: 0.1424
Batch 250, Loss: 0.1644
Batch 260, Loss: 0.1647
Batch 270, Loss: 0.1376
Batch 280, Loss: 0.1580
Batch 290, Loss: 0.1425
Batch 300, Loss: 0.1719
Batch 310, Loss: 0.1402
Batch 320, Loss: 0.1436
Batch 330, Loss: 0.1519
Batch 340, Loss: 0.1596
Batch 350, Loss: 0.1340
Batch 360, Loss: 0.1247
Batch 370, Loss: 0.1507
Batch 380, Loss: 0.1505
Batch 390, Loss: 0.1303
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.09932827949524 seconds
Epoch 183 accuracy: 96.19%
Batch 10, Loss: 0.1539
Batch 20, Loss: 0.1447
Batch 30, Loss: 0.1504
Batch 40, Loss: 0.1472
Batch 50, Loss: 0.1638
Batch 60, Loss: 0.1470
Batch 70, Loss: 0.1571
Batch 80, Loss: 0.1599
Batch 90, Loss: 0.1430
Batch 100, Loss: 0.1487
Batch 110, Loss: 0.1372
Batch 120, Loss: 0.1518
Batch 130, Loss: 0.1393
Batch 140, Loss: 0.1376
Batch 150, Loss: 0.1606
Batch 160, Loss: 0.1512
Batch 170, Loss: 0.1437
Batch 180, Loss: 0.1405
Batch 190, Loss: 0.1313
Batch 200, Loss: 0.1538
Batch 210, Loss: 0.1377
Batch 220, Loss: 0.1682
Batch 230, Loss: 0.1386
Batch 240, Loss: 0.1379
Batch 250, Loss: 0.1371
Batch 260, Loss: 0.1349
Batch 270, Loss: 0.1524
Batch 280, Loss: 0.1303
Batch 290, Loss: 0.1625
Batch 300, Loss: 0.1546
Batch 310, Loss: 0.1459
Batch 320, Loss: 0.1553
Batch 330, Loss: 0.1243
Batch 340, Loss: 0.1372
Batch 350, Loss: 0.1282
Batch 360, Loss: 0.1515
Batch 370, Loss: 0.1534
Batch 380, Loss: 0.1514
Batch 390, Loss: 0.1806
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.099087715148926 seconds
Epoch 184 accuracy: 96.2%
Batch 10, Loss: 0.1315
Batch 20, Loss: 0.1453
Batch 30, Loss: 0.1469
Batch 40, Loss: 0.1490
Batch 50, Loss: 0.1363
Batch 60, Loss: 0.1258
Batch 70, Loss: 0.1480
Batch 80, Loss: 0.1495
Batch 90, Loss: 0.1504
Batch 100, Loss: 0.1539
Batch 110, Loss: 0.1437
Batch 120, Loss: 0.1416
Batch 130, Loss: 0.1375
Batch 140, Loss: 0.1688
Batch 150, Loss: 0.1369
Batch 160, Loss: 0.1303
Batch 170, Loss: 0.1401
Batch 180, Loss: 0.1334
Batch 190, Loss: 0.1356
Batch 200, Loss: 0.1469
Batch 210, Loss: 0.1455
Batch 220, Loss: 0.1507
Batch 230, Loss: 0.1191
Batch 240, Loss: 0.1565
Batch 250, Loss: 0.1178
Batch 260, Loss: 0.1532
Batch 270, Loss: 0.1464
Batch 280, Loss: 0.1425
Batch 290, Loss: 0.1383
Batch 300, Loss: 0.1579
Batch 310, Loss: 0.1421
Batch 320, Loss: 0.1369
Batch 330, Loss: 0.1473
Batch 340, Loss: 0.1481
Batch 350, Loss: 0.1343
Batch 360, Loss: 0.1488
Batch 370, Loss: 0.1353
Batch 380, Loss: 0.1710
Batch 390, Loss: 0.1565
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.07196068763733 seconds
Epoch 185 accuracy: 96.41%
Batch 10, Loss: 0.1464
Batch 20, Loss: 0.1415
Batch 30, Loss: 0.1414
Batch 40, Loss: 0.1262
Batch 50, Loss: 0.1469
Batch 60, Loss: 0.1401
Batch 70, Loss: 0.1377
Batch 80, Loss: 0.1275
Batch 90, Loss: 0.1614
Batch 100, Loss: 0.1235
Batch 110, Loss: 0.1703
Batch 120, Loss: 0.1568
Batch 130, Loss: 0.1371
Batch 140, Loss: 0.1169
Batch 150, Loss: 0.1440
Batch 160, Loss: 0.1411
Batch 170, Loss: 0.1251
Batch 180, Loss: 0.1476
Batch 190, Loss: 0.1427
Batch 200, Loss: 0.1304
Batch 210, Loss: 0.1391
Batch 220, Loss: 0.1218
Batch 230, Loss: 0.1418
Batch 240, Loss: 0.1391
Batch 250, Loss: 0.1645
Batch 260, Loss: 0.1334
Batch 270, Loss: 0.1444
Batch 280, Loss: 0.1398
Batch 290, Loss: 0.1324
Batch 300, Loss: 0.1402
Batch 310, Loss: 0.1523
Batch 320, Loss: 0.1441
Batch 330, Loss: 0.1229
Batch 340, Loss: 0.1376
Batch 350, Loss: 0.1426
Batch 360, Loss: 0.1434
Batch 370, Loss: 0.1384
Batch 380, Loss: 0.1427
Batch 390, Loss: 0.1409
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.127234935760498 seconds
Epoch 186 accuracy: 96.39%
Batch 10, Loss: 0.1351
Batch 20, Loss: 0.1274
Batch 30, Loss: 0.1295
Batch 40, Loss: 0.1523
Batch 50, Loss: 0.1402
Batch 60, Loss: 0.1371
Batch 70, Loss: 0.1439
Batch 80, Loss: 0.1442
Batch 90, Loss: 0.1239
Batch 100, Loss: 0.1497
Batch 110, Loss: 0.1227
Batch 120, Loss: 0.1518
Batch 130, Loss: 0.1315
Batch 140, Loss: 0.1472
Batch 150, Loss: 0.1398
Batch 160, Loss: 0.1417
Batch 170, Loss: 0.1233
Batch 180, Loss: 0.1489
Batch 190, Loss: 0.1362
Batch 200, Loss: 0.1321
Batch 210, Loss: 0.1356
Batch 220, Loss: 0.1368
Batch 230, Loss: 0.1466
Batch 240, Loss: 0.1300
Batch 250, Loss: 0.1299
Batch 260, Loss: 0.1268
Batch 270, Loss: 0.1361
Batch 280, Loss: 0.1387
Batch 290, Loss: 0.1365
Batch 300, Loss: 0.1394
Batch 310, Loss: 0.1492
Batch 320, Loss: 0.1422
Batch 330, Loss: 0.1288
Batch 340, Loss: 0.1479
Batch 350, Loss: 0.1625
Batch 360, Loss: 0.1408
Batch 370, Loss: 0.1182
Batch 380, Loss: 0.1390
Batch 390, Loss: 0.1473
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.03148913383484 seconds
Epoch 187 accuracy: 96.3%
Batch 10, Loss: 0.1413
Batch 20, Loss: 0.1507
Batch 30, Loss: 0.1284
Batch 40, Loss: 0.1554
Batch 50, Loss: 0.1304
Batch 60, Loss: 0.1529
Batch 70, Loss: 0.1402
Batch 80, Loss: 0.1202
Batch 90, Loss: 0.1314
Batch 100, Loss: 0.1326
Batch 110, Loss: 0.1435
Batch 120, Loss: 0.1399
Batch 130, Loss: 0.1631
Batch 140, Loss: 0.1399
Batch 150, Loss: 0.1435
Batch 160, Loss: 0.1173
Batch 170, Loss: 0.1355
Batch 180, Loss: 0.1523
Batch 190, Loss: 0.1210
Batch 200, Loss: 0.1201
Batch 210, Loss: 0.1364
Batch 220, Loss: 0.1290
Batch 230, Loss: 0.1454
Batch 240, Loss: 0.1477
Batch 250, Loss: 0.1408
Batch 260, Loss: 0.1304
Batch 270, Loss: 0.1221
Batch 280, Loss: 0.1302
Batch 290, Loss: 0.1367
Batch 300, Loss: 0.1302
Batch 310, Loss: 0.1308
Batch 320, Loss: 0.1375
Batch 330, Loss: 0.1358
Batch 340, Loss: 0.1547
Batch 350, Loss: 0.1399
Batch 360, Loss: 0.1185
Batch 370, Loss: 0.1402
Batch 380, Loss: 0.1248
Batch 390, Loss: 0.1285
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.04208254814148 seconds
Epoch 188 accuracy: 96.33%
Batch 10, Loss: 0.1201
Batch 20, Loss: 0.1355
Batch 30, Loss: 0.1436
Batch 40, Loss: 0.1464
Batch 50, Loss: 0.1581
Batch 60, Loss: 0.1359
Batch 70, Loss: 0.1304
Batch 80, Loss: 0.1465
Batch 90, Loss: 0.1373
Batch 100, Loss: 0.1246
Batch 110, Loss: 0.1315
Batch 120, Loss: 0.1311
Batch 130, Loss: 0.1413
Batch 140, Loss: 0.1447
Batch 150, Loss: 0.1432
Batch 160, Loss: 0.1272
Batch 170, Loss: 0.1427
Batch 180, Loss: 0.1258
Batch 190, Loss: 0.1254
Batch 200, Loss: 0.1463
Batch 210, Loss: 0.1052
Batch 220, Loss: 0.1495
Batch 230, Loss: 0.1191
Batch 240, Loss: 0.1706
Batch 250, Loss: 0.1235
Batch 260, Loss: 0.1205
Batch 270, Loss: 0.1571
Batch 280, Loss: 0.1641
Batch 290, Loss: 0.1213
Batch 300, Loss: 0.1155
Batch 310, Loss: 0.1462
Batch 320, Loss: 0.1296
Batch 330, Loss: 0.1519
Batch 340, Loss: 0.1195
Batch 350, Loss: 0.1308
Batch 360, Loss: 0.1384
Batch 370, Loss: 0.1373
Batch 380, Loss: 0.1403
Batch 390, Loss: 0.1344
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.057661533355713 seconds
Epoch 189 accuracy: 96.17%
Batch 10, Loss: 0.1392
Batch 20, Loss: 0.1467
Batch 30, Loss: 0.1445
Batch 40, Loss: 0.1362
Batch 50, Loss: 0.1269
Batch 60, Loss: 0.1430
Batch 70, Loss: 0.1494
Batch 80, Loss: 0.1365
Batch 90, Loss: 0.1104
Batch 100, Loss: 0.1204
Batch 110, Loss: 0.1209
Batch 120, Loss: 0.0989
Batch 130, Loss: 0.1302
Batch 140, Loss: 0.1260
Batch 150, Loss: 0.1343
Batch 160, Loss: 0.1270
Batch 170, Loss: 0.1375
Batch 180, Loss: 0.1480
Batch 190, Loss: 0.1167
Batch 200, Loss: 0.1147
Batch 210, Loss: 0.1200
Batch 220, Loss: 0.1455
Batch 230, Loss: 0.1527
Batch 240, Loss: 0.1453
Batch 250, Loss: 0.1462
Batch 260, Loss: 0.1219
Batch 270, Loss: 0.1143
Batch 280, Loss: 0.1482
Batch 290, Loss: 0.1333
Batch 300, Loss: 0.1336
Batch 310, Loss: 0.1339
Batch 320, Loss: 0.1321
Batch 330, Loss: 0.1159
Batch 340, Loss: 0.1221
Batch 350, Loss: 0.1190
Batch 360, Loss: 0.1122
Batch 370, Loss: 0.1088
Batch 380, Loss: 0.1502
Batch 390, Loss: 0.1453
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.030519723892212 seconds
Epoch 190 accuracy: 96.39%
Batch 10, Loss: 0.1363
Batch 20, Loss: 0.1279
Batch 30, Loss: 0.1308
Batch 40, Loss: 0.1254
Batch 50, Loss: 0.1206
Batch 60, Loss: 0.1402
Batch 70, Loss: 0.1393
Batch 80, Loss: 0.1346
Batch 90, Loss: 0.1379
Batch 100, Loss: 0.1335
Batch 110, Loss: 0.1243
Batch 120, Loss: 0.1306
Batch 130, Loss: 0.1216
Batch 140, Loss: 0.1321
Batch 150, Loss: 0.1406
Batch 160, Loss: 0.1318
Batch 170, Loss: 0.1229
Batch 180, Loss: 0.1183
Batch 190, Loss: 0.1255
Batch 200, Loss: 0.1417
Batch 210, Loss: 0.1245
Batch 220, Loss: 0.1305
Batch 230, Loss: 0.1619
Batch 240, Loss: 0.1264
Batch 250, Loss: 0.1421
Batch 260, Loss: 0.1245
Batch 270, Loss: 0.1438
Batch 280, Loss: 0.1346
Batch 290, Loss: 0.1137
Batch 300, Loss: 0.1414
Batch 310, Loss: 0.1369
Batch 320, Loss: 0.1299
Batch 330, Loss: 0.1238
Batch 340, Loss: 0.1283
Batch 350, Loss: 0.1365
Batch 360, Loss: 0.1123
Batch 370, Loss: 0.1480
Batch 380, Loss: 0.1282
Batch 390, Loss: 0.1354
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.079383611679077 seconds
Epoch 191 accuracy: 96.36%
Batch 10, Loss: 0.1542
Batch 20, Loss: 0.1447
Batch 30, Loss: 0.1228
Batch 40, Loss: 0.1262
Batch 50, Loss: 0.1593
Batch 60, Loss: 0.1508
Batch 70, Loss: 0.1309
Batch 80, Loss: 0.1308
Batch 90, Loss: 0.1206
Batch 100, Loss: 0.1414
Batch 110, Loss: 0.1338
Batch 120, Loss: 0.1205
Batch 130, Loss: 0.1268
Batch 140, Loss: 0.1279
Batch 150, Loss: 0.1338
Batch 160, Loss: 0.1243
Batch 170, Loss: 0.1483
Batch 180, Loss: 0.1392
Batch 190, Loss: 0.1252
Batch 200, Loss: 0.1328
Batch 210, Loss: 0.1190
Batch 220, Loss: 0.1223
Batch 230, Loss: 0.1449
Batch 240, Loss: 0.1301
Batch 250, Loss: 0.1322
Batch 260, Loss: 0.1190
Batch 270, Loss: 0.1144
Batch 280, Loss: 0.1247
Batch 290, Loss: 0.1268
Batch 300, Loss: 0.1160
Batch 310, Loss: 0.1126
Batch 320, Loss: 0.1130
Batch 330, Loss: 0.1276
Batch 340, Loss: 0.1252
Batch 350, Loss: 0.1195
Batch 360, Loss: 0.1284
Batch 370, Loss: 0.1274
Batch 380, Loss: 0.1252
Batch 390, Loss: 0.1344
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.162424325942993 seconds
Epoch 192 accuracy: 96.41%
Batch 10, Loss: 0.1224
Batch 20, Loss: 0.1282
Batch 30, Loss: 0.1160
Batch 40, Loss: 0.1278
Batch 50, Loss: 0.1222
Batch 60, Loss: 0.1354
Batch 70, Loss: 0.1187
Batch 80, Loss: 0.1181
Batch 90, Loss: 0.1518
Batch 100, Loss: 0.1343
Batch 110, Loss: 0.1219
Batch 120, Loss: 0.1382
Batch 130, Loss: 0.1338
Batch 140, Loss: 0.1225
Batch 150, Loss: 0.1302
Batch 160, Loss: 0.1235
Batch 170, Loss: 0.1232
Batch 180, Loss: 0.1334
Batch 190, Loss: 0.1330
Batch 200, Loss: 0.1329
Batch 210, Loss: 0.1128
Batch 220, Loss: 0.1149
Batch 230, Loss: 0.1039
Batch 240, Loss: 0.1027
Batch 250, Loss: 0.1170
Batch 260, Loss: 0.1014
Batch 270, Loss: 0.1318
Batch 280, Loss: 0.1467
Batch 290, Loss: 0.1425
Batch 300, Loss: 0.1148
Batch 310, Loss: 0.1312
Batch 320, Loss: 0.1252
Batch 330, Loss: 0.1438
Batch 340, Loss: 0.1341
Batch 350, Loss: 0.1204
Batch 360, Loss: 0.1272
Batch 370, Loss: 0.1219
Batch 380, Loss: 0.1142
Batch 390, Loss: 0.1405
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.050464868545532 seconds
Epoch 193 accuracy: 96.45%
Batch 10, Loss: 0.1316
Batch 20, Loss: 0.1249
Batch 30, Loss: 0.1382
Batch 40, Loss: 0.1197
Batch 50, Loss: 0.1342
Batch 60, Loss: 0.1336
Batch 70, Loss: 0.1489
Batch 80, Loss: 0.1441
Batch 90, Loss: 0.0991
Batch 100, Loss: 0.1552
Batch 110, Loss: 0.1441
Batch 120, Loss: 0.1345
Batch 130, Loss: 0.1191
Batch 140, Loss: 0.1399
Batch 150, Loss: 0.1274
Batch 160, Loss: 0.1201
Batch 170, Loss: 0.1342
Batch 180, Loss: 0.1521
Batch 190, Loss: 0.1323
Batch 200, Loss: 0.1042
Batch 210, Loss: 0.1189
Batch 220, Loss: 0.1286
Batch 230, Loss: 0.1212
Batch 240, Loss: 0.1139
Batch 250, Loss: 0.1199
Batch 260, Loss: 0.1231
Batch 270, Loss: 0.1403
Batch 280, Loss: 0.1266
Batch 290, Loss: 0.1096
Batch 300, Loss: 0.1076
Batch 310, Loss: 0.1512
Batch 320, Loss: 0.1059
Batch 330, Loss: 0.1206
Batch 340, Loss: 0.1282
Batch 350, Loss: 0.1155
Batch 360, Loss: 0.1305
Batch 370, Loss: 0.1252
Batch 380, Loss: 0.1391
Batch 390, Loss: 0.1403
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.080724000930786 seconds
Epoch 194 accuracy: 96.41%
Batch 10, Loss: 0.1080
Batch 20, Loss: 0.1183
Batch 30, Loss: 0.1354
Batch 40, Loss: 0.1318
Batch 50, Loss: 0.1267
Batch 60, Loss: 0.0973
Batch 70, Loss: 0.1212
Batch 80, Loss: 0.1200
Batch 90, Loss: 0.1111
Batch 100, Loss: 0.1269
Batch 110, Loss: 0.1235
Batch 120, Loss: 0.1320
Batch 130, Loss: 0.1192
Batch 140, Loss: 0.1171
Batch 150, Loss: 0.1275
Batch 160, Loss: 0.1265
Batch 170, Loss: 0.1229
Batch 180, Loss: 0.1132
Batch 190, Loss: 0.1357
Batch 200, Loss: 0.1335
Batch 210, Loss: 0.1279
Batch 220, Loss: 0.1343
Batch 230, Loss: 0.1337
Batch 240, Loss: 0.1240
Batch 250, Loss: 0.1234
Batch 260, Loss: 0.0998
Batch 270, Loss: 0.1233
Batch 280, Loss: 0.1107
Batch 290, Loss: 0.1163
Batch 300, Loss: 0.1343
Batch 310, Loss: 0.1615
Batch 320, Loss: 0.1296
Batch 330, Loss: 0.1330
Batch 340, Loss: 0.1273
Batch 350, Loss: 0.1289
Batch 360, Loss: 0.1157
Batch 370, Loss: 0.1265
Batch 380, Loss: 0.1458
Batch 390, Loss: 0.1288
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.0377995967865 seconds
Epoch 195 accuracy: 96.54%
Batch 10, Loss: 0.1392
Batch 20, Loss: 0.1269
Batch 30, Loss: 0.1159
Batch 40, Loss: 0.1377
Batch 50, Loss: 0.1231
Batch 60, Loss: 0.1211
Batch 70, Loss: 0.1323
Batch 80, Loss: 0.1141
Batch 90, Loss: 0.1249
Batch 100, Loss: 0.1327
Batch 110, Loss: 0.1282
Batch 120, Loss: 0.1366
Batch 130, Loss: 0.1268
Batch 140, Loss: 0.1353
Batch 150, Loss: 0.1294
Batch 160, Loss: 0.1340
Batch 170, Loss: 0.1105
Batch 180, Loss: 0.1135
Batch 190, Loss: 0.1067
Batch 200, Loss: 0.1065
Batch 210, Loss: 0.1207
Batch 220, Loss: 0.1142
Batch 230, Loss: 0.1290
Batch 240, Loss: 0.1360
Batch 250, Loss: 0.1144
Batch 260, Loss: 0.1189
Batch 270, Loss: 0.1323
Batch 280, Loss: 0.1081
Batch 290, Loss: 0.1186
Batch 300, Loss: 0.1324
Batch 310, Loss: 0.1424
Batch 320, Loss: 0.1197
Batch 330, Loss: 0.1190
Batch 340, Loss: 0.1098
Batch 350, Loss: 0.1341
Batch 360, Loss: 0.1404
Batch 370, Loss: 0.1101
Batch 380, Loss: 0.1281
Batch 390, Loss: 0.1127
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.068522930145264 seconds
Epoch 196 accuracy: 96.49%
Batch 10, Loss: 0.1374
Batch 20, Loss: 0.1110
Batch 30, Loss: 0.1393
Batch 40, Loss: 0.1251
Batch 50, Loss: 0.1307
Batch 60, Loss: 0.1311
Batch 70, Loss: 0.1256
Batch 80, Loss: 0.1102
Batch 90, Loss: 0.1437
Batch 100, Loss: 0.1592
Batch 110, Loss: 0.1391
Batch 120, Loss: 0.1149
Batch 130, Loss: 0.1197
Batch 140, Loss: 0.1248
Batch 150, Loss: 0.1335
Batch 160, Loss: 0.1315
Batch 170, Loss: 0.1541
Batch 180, Loss: 0.1329
Batch 190, Loss: 0.1227
Batch 200, Loss: 0.1218
Batch 210, Loss: 0.1281
Batch 220, Loss: 0.1206
Batch 230, Loss: 0.1270
Batch 240, Loss: 0.1312
Batch 250, Loss: 0.1094
Batch 260, Loss: 0.1409
Batch 270, Loss: 0.1282
Batch 280, Loss: 0.1389
Batch 290, Loss: 0.1125
Batch 300, Loss: 0.1272
Batch 310, Loss: 0.1236
Batch 320, Loss: 0.1141
Batch 330, Loss: 0.1203
Batch 340, Loss: 0.1355
Batch 350, Loss: 0.1163
Batch 360, Loss: 0.1295
Batch 370, Loss: 0.1438
Batch 380, Loss: 0.1263
Batch 390, Loss: 0.1277
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.028204202651978 seconds
Epoch 197 accuracy: 96.55%
Batch 10, Loss: 0.1189
Batch 20, Loss: 0.1362
Batch 30, Loss: 0.1133
Batch 40, Loss: 0.1310
Batch 50, Loss: 0.1256
Batch 60, Loss: 0.1166
Batch 70, Loss: 0.1196
Batch 80, Loss: 0.1226
Batch 90, Loss: 0.1375
Batch 100, Loss: 0.1394
Batch 110, Loss: 0.1152
Batch 120, Loss: 0.1147
Batch 130, Loss: 0.1211
Batch 140, Loss: 0.1244
Batch 150, Loss: 0.1150
Batch 160, Loss: 0.1450
Batch 170, Loss: 0.1001
Batch 180, Loss: 0.1492
Batch 190, Loss: 0.1132
Batch 200, Loss: 0.1189
Batch 210, Loss: 0.1119
Batch 220, Loss: 0.1166
Batch 230, Loss: 0.1104
Batch 240, Loss: 0.1270
Batch 250, Loss: 0.1226
Batch 260, Loss: 0.1206
Batch 270, Loss: 0.1271
Batch 280, Loss: 0.1162
Batch 290, Loss: 0.1160
Batch 300, Loss: 0.1266
Batch 310, Loss: 0.1162
Batch 320, Loss: 0.1263
Batch 330, Loss: 0.1314
Batch 340, Loss: 0.1305
Batch 350, Loss: 0.1042
Batch 360, Loss: 0.1046
Batch 370, Loss: 0.1333
Batch 380, Loss: 0.1194
Batch 390, Loss: 0.1342
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.097370147705078 seconds
Epoch 198 accuracy: 96.51%
Batch 10, Loss: 0.1260
Batch 20, Loss: 0.1294
Batch 30, Loss: 0.1076
Batch 40, Loss: 0.1296
Batch 50, Loss: 0.1105
Batch 60, Loss: 0.1386
Batch 70, Loss: 0.1253
Batch 80, Loss: 0.1207
Batch 90, Loss: 0.1080
Batch 100, Loss: 0.1443
Batch 110, Loss: 0.1406
Batch 120, Loss: 0.1340
Batch 130, Loss: 0.1216
Batch 140, Loss: 0.1092
Batch 150, Loss: 0.1173
Batch 160, Loss: 0.1247
Batch 170, Loss: 0.1205
Batch 180, Loss: 0.1207
Batch 190, Loss: 0.1224
Batch 200, Loss: 0.1281
Batch 210, Loss: 0.1123
Batch 220, Loss: 0.1419
Batch 230, Loss: 0.1201
Batch 240, Loss: 0.1161
Batch 250, Loss: 0.1341
Batch 260, Loss: 0.1187
Batch 270, Loss: 0.1113
Batch 280, Loss: 0.1357
Batch 290, Loss: 0.1412
Batch 300, Loss: 0.1263
Batch 310, Loss: 0.1312
Batch 320, Loss: 0.1267
Batch 330, Loss: 0.1248
Batch 340, Loss: 0.1358
Batch 350, Loss: 0.0981
Batch 360, Loss: 0.1345
Batch 370, Loss: 0.1276
Batch 380, Loss: 0.1157
Batch 390, Loss: 0.1002
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.018718004226685 seconds
Epoch 199 accuracy: 96.53%
Batch 10, Loss: 0.1361
Batch 20, Loss: 0.1290
Batch 30, Loss: 0.1266
Batch 40, Loss: 0.1353
Batch 50, Loss: 0.1168
Batch 60, Loss: 0.1462
Batch 70, Loss: 0.1247
Batch 80, Loss: 0.1173
Batch 90, Loss: 0.1431
Batch 100, Loss: 0.1175
Batch 110, Loss: 0.1188
Batch 120, Loss: 0.1287
Batch 130, Loss: 0.1203
Batch 140, Loss: 0.1494
Batch 150, Loss: 0.1170
Batch 160, Loss: 0.1402
Batch 170, Loss: 0.1100
Batch 180, Loss: 0.1016
Batch 190, Loss: 0.1245
Batch 200, Loss: 0.1315
Batch 210, Loss: 0.1337
Batch 220, Loss: 0.1042
Batch 230, Loss: 0.1225
Batch 240, Loss: 0.1177
Batch 250, Loss: 0.1236
Batch 260, Loss: 0.1301
Batch 270, Loss: 0.1149
Batch 280, Loss: 0.1444
Batch 290, Loss: 0.1239
Batch 300, Loss: 0.1468
Batch 310, Loss: 0.1232
Batch 320, Loss: 0.1164
Batch 330, Loss: 0.1186
Batch 340, Loss: 0.1152
Batch 350, Loss: 0.1188
Batch 360, Loss: 0.1078
Batch 370, Loss: 0.1217
Batch 380, Loss: 0.1166
Batch 390, Loss: 0.1357
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.096425533294678 seconds
Epoch 200 accuracy: 96.55%
Total training time: 5022.90069270134 seconds
