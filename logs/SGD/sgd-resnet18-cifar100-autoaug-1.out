The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1731
Batch 20, Loss: 4.2485
Batch 30, Loss: 4.1156
Batch 40, Loss: 3.8525
Batch 50, Loss: 3.7698
Batch 60, Loss: 3.7514
Batch 70, Loss: 3.7302
Batch 80, Loss: 3.7085
Batch 90, Loss: 3.6718
Batch 100, Loss: 3.6335
Batch 110, Loss: 3.6732
Batch 120, Loss: 3.6724
Batch 130, Loss: 3.6035
Batch 140, Loss: 3.6069
Batch 150, Loss: 3.6224
Batch 160, Loss: 3.5916
Batch 170, Loss: 3.6022
Batch 180, Loss: 3.5788
Batch 190, Loss: 3.5537
Batch 200, Loss: 3.5751
Batch 210, Loss: 3.5767
Batch 220, Loss: 3.5243
Batch 230, Loss: 3.5785
Batch 240, Loss: 3.5147
Batch 250, Loss: 3.5153
Batch 260, Loss: 3.5097
Batch 270, Loss: 3.5339
Batch 280, Loss: 3.4918
Batch 290, Loss: 3.4901
Batch 300, Loss: 3.5054
Batch 310, Loss: 3.4416
Batch 320, Loss: 3.4288
Batch 330, Loss: 3.4660
Batch 340, Loss: 3.4787
Batch 350, Loss: 3.4551
Batch 360, Loss: 3.4803
Batch 370, Loss: 3.4942
Batch 380, Loss: 3.4275
Batch 390, Loss: 3.4496
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.623594284057617 seconds
Epoch 1 accuracy: 8.93%
Batch 10, Loss: 3.4498
Batch 20, Loss: 3.4184
Batch 30, Loss: 3.4051
Batch 40, Loss: 3.3983
Batch 50, Loss: 3.3954
Batch 60, Loss: 3.4137
Batch 70, Loss: 3.3949
Batch 80, Loss: 3.4126
Batch 90, Loss: 3.3651
Batch 100, Loss: 3.3868
Batch 110, Loss: 3.3946
Batch 120, Loss: 3.4100
Batch 130, Loss: 3.3957
Batch 140, Loss: 3.3527
Batch 150, Loss: 3.2783
Batch 160, Loss: 3.3624
Batch 170, Loss: 3.3100
Batch 180, Loss: 3.3618
Batch 190, Loss: 3.3752
Batch 200, Loss: 3.3362
Batch 210, Loss: 3.3237
Batch 220, Loss: 3.3325
Batch 230, Loss: 3.3271
Batch 240, Loss: 3.2981
Batch 250, Loss: 3.2635
Batch 260, Loss: 3.3672
Batch 270, Loss: 3.2958
Batch 280, Loss: 3.3126
Batch 290, Loss: 3.2846
Batch 300, Loss: 3.2665
Batch 310, Loss: 3.2978
Batch 320, Loss: 3.2411
Batch 330, Loss: 3.2532
Batch 340, Loss: 3.2461
Batch 350, Loss: 3.2148
Batch 360, Loss: 3.2020
Batch 370, Loss: 3.2207
Batch 380, Loss: 3.2668
Batch 390, Loss: 3.2805
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.474162101745605 seconds
Epoch 2 accuracy: 14.26%
Batch 10, Loss: 3.2175
Batch 20, Loss: 3.2553
Batch 30, Loss: 3.2066
Batch 40, Loss: 3.1681
Batch 50, Loss: 3.2195
Batch 60, Loss: 3.1373
Batch 70, Loss: 3.1895
Batch 80, Loss: 3.1754
Batch 90, Loss: 3.1492
Batch 100, Loss: 3.1414
Batch 110, Loss: 3.1838
Batch 120, Loss: 3.1672
Batch 130, Loss: 3.1599
Batch 140, Loss: 3.1254
Batch 150, Loss: 3.1030
Batch 160, Loss: 3.0958
Batch 170, Loss: 3.1373
Batch 180, Loss: 3.0983
Batch 190, Loss: 3.1431
Batch 200, Loss: 3.1134
Batch 210, Loss: 3.1401
Batch 220, Loss: 3.0495
Batch 230, Loss: 3.1207
Batch 240, Loss: 3.0857
Batch 250, Loss: 3.0896
Batch 260, Loss: 3.0583
Batch 270, Loss: 3.0463
Batch 280, Loss: 3.0332
Batch 290, Loss: 3.0272
Batch 300, Loss: 3.1279
Batch 310, Loss: 3.0938
Batch 320, Loss: 3.1043
Batch 330, Loss: 3.0524
Batch 340, Loss: 2.9772
Batch 350, Loss: 3.0304
Batch 360, Loss: 3.0482
Batch 370, Loss: 2.9956
Batch 380, Loss: 2.9731
Batch 390, Loss: 2.9719
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.279025077819824 seconds
Epoch 3 accuracy: 21.58%
Batch 10, Loss: 2.9141
Batch 20, Loss: 3.0055
Batch 30, Loss: 2.9827
Batch 40, Loss: 2.9643
Batch 50, Loss: 2.9518
Batch 60, Loss: 2.8636
Batch 70, Loss: 2.9221
Batch 80, Loss: 2.8860
Batch 90, Loss: 2.9350
Batch 100, Loss: 2.9031
Batch 110, Loss: 2.9343
Batch 120, Loss: 2.9020
Batch 130, Loss: 2.9265
Batch 140, Loss: 2.8657
Batch 150, Loss: 2.8644
Batch 160, Loss: 2.8544
Batch 170, Loss: 2.7973
Batch 180, Loss: 2.7882
Batch 190, Loss: 2.9057
Batch 200, Loss: 2.8683
Batch 210, Loss: 2.8695
Batch 220, Loss: 2.7869
Batch 230, Loss: 2.7838
Batch 240, Loss: 2.8259
Batch 250, Loss: 2.7707
Batch 260, Loss: 2.7953
Batch 270, Loss: 2.7660
Batch 280, Loss: 2.7392
Batch 290, Loss: 2.7261
Batch 300, Loss: 2.8285
Batch 310, Loss: 2.7786
Batch 320, Loss: 2.7401
Batch 330, Loss: 2.7869
Batch 340, Loss: 2.7476
Batch 350, Loss: 2.6507
Batch 360, Loss: 2.6977
Batch 370, Loss: 2.6240
Batch 380, Loss: 2.7306
Batch 390, Loss: 2.7110
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.181515216827393 seconds
Epoch 4 accuracy: 23.55%
Batch 10, Loss: 2.7190
Batch 20, Loss: 2.6969
Batch 30, Loss: 2.7422
Batch 40, Loss: 2.6557
Batch 50, Loss: 2.7216
Batch 60, Loss: 2.5797
Batch 70, Loss: 2.6519
Batch 80, Loss: 2.6378
Batch 90, Loss: 2.5504
Batch 100, Loss: 2.5663
Batch 110, Loss: 2.6120
Batch 120, Loss: 2.6509
Batch 130, Loss: 2.6561
Batch 140, Loss: 2.5430
Batch 150, Loss: 2.5458
Batch 160, Loss: 2.5894
Batch 170, Loss: 2.5738
Batch 180, Loss: 2.5557
Batch 190, Loss: 2.5389
Batch 200, Loss: 2.5591
Batch 210, Loss: 2.6010
Batch 220, Loss: 2.5509
Batch 230, Loss: 2.5476
Batch 240, Loss: 2.5631
Batch 250, Loss: 2.5770
Batch 260, Loss: 2.5405
Batch 270, Loss: 2.5913
Batch 280, Loss: 2.5054
Batch 290, Loss: 2.5154
Batch 300, Loss: 2.4819
Batch 310, Loss: 2.4703
Batch 320, Loss: 2.5727
Batch 330, Loss: 2.4393
Batch 340, Loss: 2.4653
Batch 350, Loss: 2.4561
Batch 360, Loss: 2.4666
Batch 370, Loss: 2.5296
Batch 380, Loss: 2.4417
Batch 390, Loss: 2.4357
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.32614755630493 seconds
Epoch 5 accuracy: 31.13%
Batch 10, Loss: 2.3865
Batch 20, Loss: 2.3978
Batch 30, Loss: 2.4402
Batch 40, Loss: 2.4380
Batch 50, Loss: 2.4372
Batch 60, Loss: 2.4240
Batch 70, Loss: 2.4522
Batch 80, Loss: 2.3735
Batch 90, Loss: 2.4712
Batch 100, Loss: 2.3882
Batch 110, Loss: 2.3639
Batch 120, Loss: 2.3818
Batch 130, Loss: 2.3528
Batch 140, Loss: 2.2881
Batch 150, Loss: 2.3090
Batch 160, Loss: 2.3074
Batch 170, Loss: 2.2423
Batch 180, Loss: 2.4199
Batch 190, Loss: 2.3646
Batch 200, Loss: 2.4352
Batch 210, Loss: 2.4184
Batch 220, Loss: 2.3820
Batch 230, Loss: 2.3306
Batch 240, Loss: 2.3477
Batch 250, Loss: 2.3504
Batch 260, Loss: 2.3013
Batch 270, Loss: 2.3453
Batch 280, Loss: 2.4023
Batch 290, Loss: 2.3132
Batch 300, Loss: 2.3864
Batch 310, Loss: 2.3300
Batch 320, Loss: 2.3053
Batch 330, Loss: 2.3045
Batch 340, Loss: 2.3016
Batch 350, Loss: 2.3214
Batch 360, Loss: 2.1997
Batch 370, Loss: 2.2961
Batch 380, Loss: 2.2843
Batch 390, Loss: 2.2470
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.190566539764404 seconds
Epoch 6 accuracy: 32.56%
Batch 10, Loss: 2.2823
Batch 20, Loss: 2.2258
Batch 30, Loss: 2.2600
Batch 40, Loss: 2.2512
Batch 50, Loss: 2.1986
Batch 60, Loss: 2.2738
Batch 70, Loss: 2.2636
Batch 80, Loss: 2.2356
Batch 90, Loss: 2.2482
Batch 100, Loss: 2.2334
Batch 110, Loss: 2.2471
Batch 120, Loss: 2.2415
Batch 130, Loss: 2.2195
Batch 140, Loss: 2.1982
Batch 150, Loss: 2.1415
Batch 160, Loss: 2.1910
Batch 170, Loss: 2.2337
Batch 180, Loss: 2.1879
Batch 190, Loss: 2.2475
Batch 200, Loss: 2.1971
Batch 210, Loss: 2.2505
Batch 220, Loss: 2.1446
Batch 230, Loss: 2.2238
Batch 240, Loss: 2.2240
Batch 250, Loss: 2.1658
Batch 260, Loss: 2.1564
Batch 270, Loss: 2.1507
Batch 280, Loss: 2.1410
Batch 290, Loss: 2.1902
Batch 300, Loss: 2.1632
Batch 310, Loss: 2.2044
Batch 320, Loss: 2.1882
Batch 330, Loss: 2.1843
Batch 340, Loss: 2.1654
Batch 350, Loss: 2.1395
Batch 360, Loss: 2.1328
Batch 370, Loss: 2.1186
Batch 380, Loss: 2.2016
Batch 390, Loss: 2.1344
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.09400463104248 seconds
Epoch 7 accuracy: 41.17%
Batch 10, Loss: 2.0794
Batch 20, Loss: 2.0918
Batch 30, Loss: 2.1174
Batch 40, Loss: 2.1870
Batch 50, Loss: 2.1175
Batch 60, Loss: 2.0785
Batch 70, Loss: 2.0784
Batch 80, Loss: 2.0862
Batch 90, Loss: 2.0747
Batch 100, Loss: 2.0649
Batch 110, Loss: 2.1082
Batch 120, Loss: 2.1015
Batch 130, Loss: 2.0690
Batch 140, Loss: 2.1076
Batch 150, Loss: 2.0823
Batch 160, Loss: 2.1063
Batch 170, Loss: 2.0949
Batch 180, Loss: 2.1087
Batch 190, Loss: 2.0699
Batch 200, Loss: 2.0895
Batch 210, Loss: 2.1330
Batch 220, Loss: 2.0723
Batch 230, Loss: 2.0741
Batch 240, Loss: 2.0950
Batch 250, Loss: 2.1241
Batch 260, Loss: 2.0427
Batch 270, Loss: 1.9985
Batch 280, Loss: 2.0735
Batch 290, Loss: 2.0400
Batch 300, Loss: 2.1232
Batch 310, Loss: 2.0956
Batch 320, Loss: 2.0747
Batch 330, Loss: 2.0018
Batch 340, Loss: 2.0583
Batch 350, Loss: 2.0185
Batch 360, Loss: 2.0525
Batch 370, Loss: 2.0747
Batch 380, Loss: 2.0756
Batch 390, Loss: 2.1006
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.16443395614624 seconds
Epoch 8 accuracy: 42.1%
Batch 10, Loss: 2.0507
Batch 20, Loss: 2.0560
Batch 30, Loss: 1.9790
Batch 40, Loss: 1.9622
Batch 50, Loss: 2.0824
Batch 60, Loss: 2.0294
Batch 70, Loss: 1.9869
Batch 80, Loss: 1.9483
Batch 90, Loss: 1.9784
Batch 100, Loss: 2.0227
Batch 110, Loss: 1.9800
Batch 120, Loss: 1.9968
Batch 130, Loss: 2.0174
Batch 140, Loss: 2.0108
Batch 150, Loss: 1.9435
Batch 160, Loss: 1.9772
Batch 170, Loss: 2.0415
Batch 180, Loss: 2.0044
Batch 190, Loss: 1.9793
Batch 200, Loss: 1.9666
Batch 210, Loss: 2.0609
Batch 220, Loss: 2.0341
Batch 230, Loss: 2.0062
Batch 240, Loss: 1.9740
Batch 250, Loss: 1.9879
Batch 260, Loss: 2.0011
Batch 270, Loss: 1.9233
Batch 280, Loss: 1.9903
Batch 290, Loss: 1.9692
Batch 300, Loss: 1.9408
Batch 310, Loss: 2.0325
Batch 320, Loss: 1.9775
Batch 330, Loss: 2.0318
Batch 340, Loss: 1.9611
Batch 350, Loss: 1.9836
Batch 360, Loss: 1.8655
Batch 370, Loss: 1.9618
Batch 380, Loss: 1.9353
Batch 390, Loss: 1.9653
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.176992416381836 seconds
Epoch 9 accuracy: 42.76%
Batch 10, Loss: 1.9341
Batch 20, Loss: 1.9295
Batch 30, Loss: 1.9412
Batch 40, Loss: 1.9678
Batch 50, Loss: 1.8549
Batch 60, Loss: 2.0138
Batch 70, Loss: 1.8968
Batch 80, Loss: 1.9735
Batch 90, Loss: 1.9482
Batch 100, Loss: 1.9013
Batch 110, Loss: 1.8875
Batch 120, Loss: 1.9359
Batch 130, Loss: 1.9122
Batch 140, Loss: 1.9395
Batch 150, Loss: 1.9184
Batch 160, Loss: 1.8824
Batch 170, Loss: 1.9455
Batch 180, Loss: 1.9692
Batch 190, Loss: 1.9944
Batch 200, Loss: 1.9216
Batch 210, Loss: 1.9563
Batch 220, Loss: 1.9909
Batch 230, Loss: 1.9502
Batch 240, Loss: 1.9046
Batch 250, Loss: 1.8805
Batch 260, Loss: 1.9329
Batch 270, Loss: 1.9209
Batch 280, Loss: 1.8803
Batch 290, Loss: 1.9490
Batch 300, Loss: 1.9495
Batch 310, Loss: 1.9101
Batch 320, Loss: 1.9225
Batch 330, Loss: 1.8562
Batch 340, Loss: 1.8934
Batch 350, Loss: 1.8868
Batch 360, Loss: 1.9228
Batch 370, Loss: 1.9257
Batch 380, Loss: 1.8976
Batch 390, Loss: 1.9802
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.163572788238525 seconds
Epoch 10 accuracy: 45.82%
Batch 10, Loss: 1.8412
Batch 20, Loss: 1.8127
Batch 30, Loss: 1.8094
Batch 40, Loss: 1.9210
Batch 50, Loss: 1.8107
Batch 60, Loss: 1.9010
Batch 70, Loss: 1.8705
Batch 80, Loss: 1.8839
Batch 90, Loss: 1.8491
Batch 100, Loss: 1.8096
Batch 110, Loss: 1.8884
Batch 120, Loss: 1.9116
Batch 130, Loss: 1.9070
Batch 140, Loss: 1.8879
Batch 150, Loss: 1.8469
Batch 160, Loss: 1.8846
Batch 170, Loss: 1.8889
Batch 180, Loss: 1.8890
Batch 190, Loss: 1.9160
Batch 200, Loss: 1.9374
Batch 210, Loss: 1.8498
Batch 220, Loss: 1.8373
Batch 230, Loss: 1.8173
Batch 240, Loss: 1.8009
Batch 250, Loss: 1.7670
Batch 260, Loss: 1.8557
Batch 270, Loss: 1.8499
Batch 280, Loss: 1.8583
Batch 290, Loss: 1.8656
Batch 300, Loss: 1.8738
Batch 310, Loss: 1.7703
Batch 320, Loss: 1.8437
Batch 330, Loss: 1.9042
Batch 340, Loss: 1.9243
Batch 350, Loss: 1.9391
Batch 360, Loss: 1.9396
Batch 370, Loss: 1.9029
Batch 380, Loss: 1.8355
Batch 390, Loss: 1.8926
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.199856281280518 seconds
Epoch 11 accuracy: 49.04%
Batch 10, Loss: 1.7933
Batch 20, Loss: 1.8887
Batch 30, Loss: 1.7890
Batch 40, Loss: 1.7776
Batch 50, Loss: 1.8011
Batch 60, Loss: 1.8064
Batch 70, Loss: 1.8488
Batch 80, Loss: 1.7849
Batch 90, Loss: 1.8202
Batch 100, Loss: 1.8107
Batch 110, Loss: 1.8430
Batch 120, Loss: 1.8398
Batch 130, Loss: 1.7993
Batch 140, Loss: 1.8218
Batch 150, Loss: 1.7985
Batch 160, Loss: 1.7931
Batch 170, Loss: 1.8169
Batch 180, Loss: 1.8270
Batch 190, Loss: 1.7948
Batch 200, Loss: 1.8123
Batch 210, Loss: 1.8163
Batch 220, Loss: 1.8203
Batch 230, Loss: 1.8344
Batch 240, Loss: 1.8893
Batch 250, Loss: 1.8251
Batch 260, Loss: 1.8306
Batch 270, Loss: 1.7860
Batch 280, Loss: 1.8748
Batch 290, Loss: 1.8655
Batch 300, Loss: 1.8482
Batch 310, Loss: 1.8987
Batch 320, Loss: 1.8276
Batch 330, Loss: 1.8179
Batch 340, Loss: 1.8062
Batch 350, Loss: 1.7064
Batch 360, Loss: 1.8078
Batch 370, Loss: 1.8184
Batch 380, Loss: 1.8182
Batch 390, Loss: 1.8284
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.15584087371826 seconds
Epoch 12 accuracy: 46.86%
Batch 10, Loss: 1.7560
Batch 20, Loss: 1.6983
Batch 30, Loss: 1.8306
Batch 40, Loss: 1.7501
Batch 50, Loss: 1.8162
Batch 60, Loss: 1.7194
Batch 70, Loss: 1.7739
Batch 80, Loss: 1.7565
Batch 90, Loss: 1.7647
Batch 100, Loss: 1.7751
Batch 110, Loss: 1.7549
Batch 120, Loss: 1.7925
Batch 130, Loss: 1.8165
Batch 140, Loss: 1.8202
Batch 150, Loss: 1.7912
Batch 160, Loss: 1.8392
Batch 170, Loss: 1.7674
Batch 180, Loss: 1.7321
Batch 190, Loss: 1.7886
Batch 200, Loss: 1.7608
Batch 210, Loss: 1.7625
Batch 220, Loss: 1.7751
Batch 230, Loss: 1.8179
Batch 240, Loss: 1.7280
Batch 250, Loss: 1.7699
Batch 260, Loss: 1.7909
Batch 270, Loss: 1.7867
Batch 280, Loss: 1.8386
Batch 290, Loss: 1.7549
Batch 300, Loss: 1.7769
Batch 310, Loss: 1.7857
Batch 320, Loss: 1.7558
Batch 330, Loss: 1.7626
Batch 340, Loss: 1.7575
Batch 350, Loss: 1.7874
Batch 360, Loss: 1.7601
Batch 370, Loss: 1.7684
Batch 380, Loss: 1.7803
Batch 390, Loss: 1.8212
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.145450353622437 seconds
Epoch 13 accuracy: 46.93%
Batch 10, Loss: 1.8035
Batch 20, Loss: 1.7052
Batch 30, Loss: 1.7234
Batch 40, Loss: 1.7423
Batch 50, Loss: 1.6963
Batch 60, Loss: 1.7769
Batch 70, Loss: 1.7713
Batch 80, Loss: 1.7938
Batch 90, Loss: 1.7036
Batch 100, Loss: 1.7475
Batch 110, Loss: 1.7240
Batch 120, Loss: 1.6527
Batch 130, Loss: 1.6337
Batch 140, Loss: 1.7564
Batch 150, Loss: 1.7476
Batch 160, Loss: 1.7768
Batch 170, Loss: 1.7850
Batch 180, Loss: 1.7511
Batch 190, Loss: 1.7164
Batch 200, Loss: 1.7837
Batch 210, Loss: 1.7645
Batch 220, Loss: 1.7459
Batch 230, Loss: 1.7585
Batch 240, Loss: 1.7074
Batch 250, Loss: 1.7577
Batch 260, Loss: 1.7061
Batch 270, Loss: 1.7399
Batch 280, Loss: 1.8009
Batch 290, Loss: 1.8263
Batch 300, Loss: 1.7627
Batch 310, Loss: 1.7243
Batch 320, Loss: 1.7726
Batch 330, Loss: 1.7048
Batch 340, Loss: 1.7627
Batch 350, Loss: 1.7341
Batch 360, Loss: 1.8185
Batch 370, Loss: 1.7964
Batch 380, Loss: 1.7434
Batch 390, Loss: 1.7883
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.22541856765747 seconds
Epoch 14 accuracy: 51.58%
Batch 10, Loss: 1.6848
Batch 20, Loss: 1.7255
Batch 30, Loss: 1.7116
Batch 40, Loss: 1.7685
Batch 50, Loss: 1.6630
Batch 60, Loss: 1.7142
Batch 70, Loss: 1.7366
Batch 80, Loss: 1.7307
Batch 90, Loss: 1.7271
Batch 100, Loss: 1.7051
Batch 110, Loss: 1.6964
Batch 120, Loss: 1.7100
Batch 130, Loss: 1.6690
Batch 140, Loss: 1.8108
Batch 150, Loss: 1.7081
Batch 160, Loss: 1.6925
Batch 170, Loss: 1.7238
Batch 180, Loss: 1.7376
Batch 190, Loss: 1.6821
Batch 200, Loss: 1.7539
Batch 210, Loss: 1.6875
Batch 220, Loss: 1.7590
Batch 230, Loss: 1.7592
Batch 240, Loss: 1.6870
Batch 250, Loss: 1.7104
Batch 260, Loss: 1.7090
Batch 270, Loss: 1.8144
Batch 280, Loss: 1.7480
Batch 290, Loss: 1.7036
Batch 300, Loss: 1.7089
Batch 310, Loss: 1.6785
Batch 320, Loss: 1.7772
Batch 330, Loss: 1.7080
Batch 340, Loss: 1.6825
Batch 350, Loss: 1.6405
Batch 360, Loss: 1.7635
Batch 370, Loss: 1.8122
Batch 380, Loss: 1.7573
Batch 390, Loss: 1.6973
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.335908889770508 seconds
Epoch 15 accuracy: 53.3%
Batch 10, Loss: 1.5992
Batch 20, Loss: 1.6672
Batch 30, Loss: 1.6538
Batch 40, Loss: 1.6820
Batch 50, Loss: 1.6465
Batch 60, Loss: 1.6361
Batch 70, Loss: 1.6814
Batch 80, Loss: 1.7474
Batch 90, Loss: 1.7976
Batch 100, Loss: 1.7142
Batch 110, Loss: 1.7246
Batch 120, Loss: 1.6852
Batch 130, Loss: 1.7101
Batch 140, Loss: 1.6704
Batch 150, Loss: 1.6598
Batch 160, Loss: 1.6357
Batch 170, Loss: 1.5998
Batch 180, Loss: 1.7008
Batch 190, Loss: 1.6506
Batch 200, Loss: 1.7019
Batch 210, Loss: 1.7180
Batch 220, Loss: 1.6919
Batch 230, Loss: 1.6284
Batch 240, Loss: 1.6844
Batch 250, Loss: 1.7454
Batch 260, Loss: 1.7471
Batch 270, Loss: 1.7111
Batch 280, Loss: 1.6788
Batch 290, Loss: 1.7108
Batch 300, Loss: 1.6846
Batch 310, Loss: 1.6514
Batch 320, Loss: 1.6872
Batch 330, Loss: 1.7116
Batch 340, Loss: 1.6933
Batch 350, Loss: 1.6358
Batch 360, Loss: 1.6661
Batch 370, Loss: 1.7294
Batch 380, Loss: 1.7142
Batch 390, Loss: 1.7395
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.27549958229065 seconds
Epoch 16 accuracy: 49.31%
Batch 10, Loss: 1.6479
Batch 20, Loss: 1.6400
Batch 30, Loss: 1.6689
Batch 40, Loss: 1.7016
Batch 50, Loss: 1.6373
Batch 60, Loss: 1.6067
Batch 70, Loss: 1.6464
Batch 80, Loss: 1.6983
Batch 90, Loss: 1.7066
Batch 100, Loss: 1.6149
Batch 110, Loss: 1.6179
Batch 120, Loss: 1.6425
Batch 130, Loss: 1.6319
Batch 140, Loss: 1.6994
Batch 150, Loss: 1.7222
Batch 160, Loss: 1.6554
Batch 170, Loss: 1.7282
Batch 180, Loss: 1.6410
Batch 190, Loss: 1.6793
Batch 200, Loss: 1.6991
Batch 210, Loss: 1.6482
Batch 220, Loss: 1.6776
Batch 230, Loss: 1.6555
Batch 240, Loss: 1.6619
Batch 250, Loss: 1.6067
Batch 260, Loss: 1.7124
Batch 270, Loss: 1.6551
Batch 280, Loss: 1.6566
Batch 290, Loss: 1.6664
Batch 300, Loss: 1.6030
Batch 310, Loss: 1.6918
Batch 320, Loss: 1.6650
Batch 330, Loss: 1.7515
Batch 340, Loss: 1.6613
Batch 350, Loss: 1.6534
Batch 360, Loss: 1.6669
Batch 370, Loss: 1.6259
Batch 380, Loss: 1.6548
Batch 390, Loss: 1.6885
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.339880228042603 seconds
Epoch 17 accuracy: 54.14%
Batch 10, Loss: 1.5878
Batch 20, Loss: 1.6758
Batch 30, Loss: 1.6701
Batch 40, Loss: 1.5816
Batch 50, Loss: 1.5991
Batch 60, Loss: 1.6613
Batch 70, Loss: 1.6423
Batch 80, Loss: 1.6276
Batch 90, Loss: 1.6656
Batch 100, Loss: 1.6059
Batch 110, Loss: 1.7009
Batch 120, Loss: 1.6767
Batch 130, Loss: 1.6102
Batch 140, Loss: 1.6287
Batch 150, Loss: 1.6881
Batch 160, Loss: 1.6241
Batch 170, Loss: 1.6115
Batch 180, Loss: 1.6733
Batch 190, Loss: 1.6165
Batch 200, Loss: 1.6924
Batch 210, Loss: 1.6494
Batch 220, Loss: 1.6433
Batch 230, Loss: 1.7058
Batch 240, Loss: 1.7010
Batch 250, Loss: 1.6483
Batch 260, Loss: 1.6956
Batch 270, Loss: 1.5961
Batch 280, Loss: 1.6681
Batch 290, Loss: 1.7076
Batch 300, Loss: 1.7094
Batch 310, Loss: 1.6692
Batch 320, Loss: 1.6343
Batch 330, Loss: 1.7290
Batch 340, Loss: 1.6041
Batch 350, Loss: 1.6324
Batch 360, Loss: 1.6422
Batch 370, Loss: 1.5997
Batch 380, Loss: 1.6300
Batch 390, Loss: 1.6476
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.156914710998535 seconds
Epoch 18 accuracy: 53.71%
Batch 10, Loss: 1.6056
Batch 20, Loss: 1.6185
Batch 30, Loss: 1.6007
Batch 40, Loss: 1.6230
Batch 50, Loss: 1.6383
Batch 60, Loss: 1.6358
Batch 70, Loss: 1.6960
Batch 80, Loss: 1.5950
Batch 90, Loss: 1.5439
Batch 100, Loss: 1.6856
Batch 110, Loss: 1.6365
Batch 120, Loss: 1.6923
Batch 130, Loss: 1.6146
Batch 140, Loss: 1.5859
Batch 150, Loss: 1.6018
Batch 160, Loss: 1.5901
Batch 170, Loss: 1.6666
Batch 180, Loss: 1.6404
Batch 190, Loss: 1.5697
Batch 200, Loss: 1.6673
Batch 210, Loss: 1.6565
Batch 220, Loss: 1.6219
Batch 230, Loss: 1.6549
Batch 240, Loss: 1.6317
Batch 250, Loss: 1.6095
Batch 260, Loss: 1.7304
Batch 270, Loss: 1.7701
Batch 280, Loss: 1.6285
Batch 290, Loss: 1.5934
Batch 300, Loss: 1.6431
Batch 310, Loss: 1.6868
Batch 320, Loss: 1.7009
Batch 330, Loss: 1.6419
Batch 340, Loss: 1.5818
Batch 350, Loss: 1.6337
Batch 360, Loss: 1.6987
Batch 370, Loss: 1.6631
Batch 380, Loss: 1.6355
Batch 390, Loss: 1.6208
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.295794010162354 seconds
Epoch 19 accuracy: 53.95%
Batch 10, Loss: 1.5526
Batch 20, Loss: 1.5482
Batch 30, Loss: 1.6455
Batch 40, Loss: 1.5366
Batch 50, Loss: 1.5849
Batch 60, Loss: 1.5700
Batch 70, Loss: 1.6272
Batch 80, Loss: 1.6351
Batch 90, Loss: 1.5474
Batch 100, Loss: 1.5937
Batch 110, Loss: 1.5934
Batch 120, Loss: 1.5897
Batch 130, Loss: 1.6742
Batch 140, Loss: 1.5777
Batch 150, Loss: 1.5894
Batch 160, Loss: 1.5545
Batch 170, Loss: 1.6104
Batch 180, Loss: 1.5907
Batch 190, Loss: 1.5862
Batch 200, Loss: 1.6092
Batch 210, Loss: 1.5462
Batch 220, Loss: 1.6489
Batch 230, Loss: 1.5951
Batch 240, Loss: 1.6491
Batch 250, Loss: 1.6525
Batch 260, Loss: 1.6283
Batch 270, Loss: 1.7095
Batch 280, Loss: 1.5883
Batch 290, Loss: 1.6285
Batch 300, Loss: 1.6225
Batch 310, Loss: 1.6514
Batch 320, Loss: 1.6357
Batch 330, Loss: 1.6382
Batch 340, Loss: 1.6158
Batch 350, Loss: 1.6665
Batch 360, Loss: 1.6361
Batch 370, Loss: 1.6276
Batch 380, Loss: 1.5800
Batch 390, Loss: 1.5936
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.41531729698181 seconds
Epoch 20 accuracy: 54.57%
Batch 10, Loss: 1.5804
Batch 20, Loss: 1.5408
Batch 30, Loss: 1.5888
Batch 40, Loss: 1.5267
Batch 50, Loss: 1.5758
Batch 60, Loss: 1.5544
Batch 70, Loss: 1.5760
Batch 80, Loss: 1.5229
Batch 90, Loss: 1.5689
Batch 100, Loss: 1.5441
Batch 110, Loss: 1.5349
Batch 120, Loss: 1.6293
Batch 130, Loss: 1.6973
Batch 140, Loss: 1.6165
Batch 150, Loss: 1.6411
Batch 160, Loss: 1.6155
Batch 170, Loss: 1.6141
Batch 180, Loss: 1.6321
Batch 190, Loss: 1.6617
Batch 200, Loss: 1.5833
Batch 210, Loss: 1.5727
Batch 220, Loss: 1.6373
Batch 230, Loss: 1.5488
Batch 240, Loss: 1.6117
Batch 250, Loss: 1.5831
Batch 260, Loss: 1.6586
Batch 270, Loss: 1.6562
Batch 280, Loss: 1.6288
Batch 290, Loss: 1.5797
Batch 300, Loss: 1.5833
Batch 310, Loss: 1.5884
Batch 320, Loss: 1.6015
Batch 330, Loss: 1.5887
Batch 340, Loss: 1.6382
Batch 350, Loss: 1.6216
Batch 360, Loss: 1.5354
Batch 370, Loss: 1.6317
Batch 380, Loss: 1.6432
Batch 390, Loss: 1.6439
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.236186981201172 seconds
Epoch 21 accuracy: 55.12%
Batch 10, Loss: 1.5260
Batch 20, Loss: 1.5418
Batch 30, Loss: 1.5634
Batch 40, Loss: 1.5901
Batch 50, Loss: 1.6802
Batch 60, Loss: 1.5978
Batch 70, Loss: 1.5868
Batch 80, Loss: 1.6066
Batch 90, Loss: 1.6387
Batch 100, Loss: 1.6145
Batch 110, Loss: 1.5757
Batch 120, Loss: 1.5702
Batch 130, Loss: 1.5795
Batch 140, Loss: 1.6110
Batch 150, Loss: 1.5950
Batch 160, Loss: 1.6302
Batch 170, Loss: 1.5775
Batch 180, Loss: 1.5749
Batch 190, Loss: 1.6325
Batch 200, Loss: 1.6317
Batch 210, Loss: 1.6278
Batch 220, Loss: 1.5713
Batch 230, Loss: 1.6309
Batch 240, Loss: 1.5988
Batch 250, Loss: 1.6841
Batch 260, Loss: 1.6293
Batch 270, Loss: 1.5738
Batch 280, Loss: 1.6248
Batch 290, Loss: 1.5877
Batch 300, Loss: 1.6232
Batch 310, Loss: 1.6115
Batch 320, Loss: 1.6149
Batch 330, Loss: 1.5601
Batch 340, Loss: 1.5899
Batch 350, Loss: 1.6219
Batch 360, Loss: 1.5820
Batch 370, Loss: 1.5771
Batch 380, Loss: 1.6396
Batch 390, Loss: 1.5455
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.340887784957886 seconds
Epoch 22 accuracy: 54.1%
Batch 10, Loss: 1.5551
Batch 20, Loss: 1.6122
Batch 30, Loss: 1.5643
Batch 40, Loss: 1.5399
Batch 50, Loss: 1.5876
Batch 60, Loss: 1.5416
Batch 70, Loss: 1.5430
Batch 80, Loss: 1.5453
Batch 90, Loss: 1.5028
Batch 100, Loss: 1.5894
Batch 110, Loss: 1.5594
Batch 120, Loss: 1.6876
Batch 130, Loss: 1.5566
Batch 140, Loss: 1.4815
Batch 150, Loss: 1.5609
Batch 160, Loss: 1.5698
Batch 170, Loss: 1.6073
Batch 180, Loss: 1.5899
Batch 190, Loss: 1.6258
Batch 200, Loss: 1.5220
Batch 210, Loss: 1.6210
Batch 220, Loss: 1.6038
Batch 230, Loss: 1.6251
Batch 240, Loss: 1.5959
Batch 250, Loss: 1.5815
Batch 260, Loss: 1.5981
Batch 270, Loss: 1.5981
Batch 280, Loss: 1.5446
Batch 290, Loss: 1.6131
Batch 300, Loss: 1.6516
Batch 310, Loss: 1.5476
Batch 320, Loss: 1.4976
Batch 330, Loss: 1.5819
Batch 340, Loss: 1.5743
Batch 350, Loss: 1.6003
Batch 360, Loss: 1.6102
Batch 370, Loss: 1.5797
Batch 380, Loss: 1.5613
Batch 390, Loss: 1.6565
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.242666721343994 seconds
Epoch 23 accuracy: 53.2%
Batch 10, Loss: 1.5172
Batch 20, Loss: 1.4953
Batch 30, Loss: 1.5416
Batch 40, Loss: 1.5067
Batch 50, Loss: 1.5038
Batch 60, Loss: 1.5480
Batch 70, Loss: 1.5242
Batch 80, Loss: 1.5898
Batch 90, Loss: 1.5648
Batch 100, Loss: 1.5826
Batch 110, Loss: 1.5687
Batch 120, Loss: 1.5917
Batch 130, Loss: 1.6203
Batch 140, Loss: 1.5001
Batch 150, Loss: 1.5382
Batch 160, Loss: 1.5607
Batch 170, Loss: 1.6161
Batch 180, Loss: 1.6069
Batch 190, Loss: 1.5455
Batch 200, Loss: 1.6009
Batch 210, Loss: 1.5552
Batch 220, Loss: 1.5185
Batch 230, Loss: 1.5464
Batch 240, Loss: 1.4970
Batch 250, Loss: 1.6131
Batch 260, Loss: 1.5921
Batch 270, Loss: 1.4903
Batch 280, Loss: 1.5917
Batch 290, Loss: 1.5768
Batch 300, Loss: 1.6435
Batch 310, Loss: 1.6108
Batch 320, Loss: 1.5664
Batch 330, Loss: 1.5281
Batch 340, Loss: 1.5809
Batch 350, Loss: 1.5632
Batch 360, Loss: 1.5480
Batch 370, Loss: 1.5632
Batch 380, Loss: 1.6379
Batch 390, Loss: 1.5801
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.22687530517578 seconds
Epoch 24 accuracy: 54.17%
Batch 10, Loss: 1.4793
Batch 20, Loss: 1.5718
Batch 30, Loss: 1.5430
Batch 40, Loss: 1.5013
Batch 50, Loss: 1.5277
Batch 60, Loss: 1.5227
Batch 70, Loss: 1.5357
Batch 80, Loss: 1.6099
Batch 90, Loss: 1.5706
Batch 100, Loss: 1.5629
Batch 110, Loss: 1.5231
Batch 120, Loss: 1.4872
Batch 130, Loss: 1.5327
Batch 140, Loss: 1.5783
Batch 150, Loss: 1.5407
Batch 160, Loss: 1.5844
Batch 170, Loss: 1.5168
Batch 180, Loss: 1.6373
Batch 190, Loss: 1.6242
Batch 200, Loss: 1.5543
Batch 210, Loss: 1.4937
Batch 220, Loss: 1.5280
Batch 230, Loss: 1.6063
Batch 240, Loss: 1.5510
Batch 250, Loss: 1.5467
Batch 260, Loss: 1.5821
Batch 270, Loss: 1.6051
Batch 280, Loss: 1.5546
Batch 290, Loss: 1.5458
Batch 300, Loss: 1.6109
Batch 310, Loss: 1.5878
Batch 320, Loss: 1.5693
Batch 330, Loss: 1.5643
Batch 340, Loss: 1.5758
Batch 350, Loss: 1.5637
Batch 360, Loss: 1.5619
Batch 370, Loss: 1.5687
Batch 380, Loss: 1.5744
Batch 390, Loss: 1.6165
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.20586085319519 seconds
Epoch 25 accuracy: 53.51%
Batch 10, Loss: 1.5699
Batch 20, Loss: 1.4843
Batch 30, Loss: 1.4401
Batch 40, Loss: 1.4579
Batch 50, Loss: 1.5374
Batch 60, Loss: 1.4775
Batch 70, Loss: 1.6020
Batch 80, Loss: 1.5113
Batch 90, Loss: 1.5124
Batch 100, Loss: 1.5284
Batch 110, Loss: 1.5920
Batch 120, Loss: 1.5713
Batch 130, Loss: 1.5482
Batch 140, Loss: 1.5601
Batch 150, Loss: 1.4998
Batch 160, Loss: 1.5912
Batch 170, Loss: 1.5475
Batch 180, Loss: 1.5610
Batch 190, Loss: 1.5319
Batch 200, Loss: 1.5618
Batch 210, Loss: 1.5824
Batch 220, Loss: 1.5244
Batch 230, Loss: 1.6299
Batch 240, Loss: 1.6064
Batch 250, Loss: 1.5167
Batch 260, Loss: 1.4662
Batch 270, Loss: 1.4719
Batch 280, Loss: 1.5890
Batch 290, Loss: 1.4842
Batch 300, Loss: 1.5521
Batch 310, Loss: 1.5488
Batch 320, Loss: 1.5962
Batch 330, Loss: 1.4674
Batch 340, Loss: 1.5942
Batch 350, Loss: 1.5562
Batch 360, Loss: 1.5274
Batch 370, Loss: 1.5236
Batch 380, Loss: 1.6099
Batch 390, Loss: 1.6226
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.10526704788208 seconds
Epoch 26 accuracy: 51.11%
Batch 10, Loss: 1.5636
Batch 20, Loss: 1.5478
Batch 30, Loss: 1.5480
Batch 40, Loss: 1.4836
Batch 50, Loss: 1.4685
Batch 60, Loss: 1.5375
Batch 70, Loss: 1.4672
Batch 80, Loss: 1.5799
Batch 90, Loss: 1.5512
Batch 100, Loss: 1.4956
Batch 110, Loss: 1.5339
Batch 120, Loss: 1.5728
Batch 130, Loss: 1.5895
Batch 140, Loss: 1.5650
Batch 150, Loss: 1.4844
Batch 160, Loss: 1.5268
Batch 170, Loss: 1.5522
Batch 180, Loss: 1.5382
Batch 190, Loss: 1.5583
Batch 200, Loss: 1.5640
Batch 210, Loss: 1.5504
Batch 220, Loss: 1.5353
Batch 230, Loss: 1.5067
Batch 240, Loss: 1.5402
Batch 250, Loss: 1.5464
Batch 260, Loss: 1.5650
Batch 270, Loss: 1.5924
Batch 280, Loss: 1.5254
Batch 290, Loss: 1.4903
Batch 300, Loss: 1.6054
Batch 310, Loss: 1.5841
Batch 320, Loss: 1.5811
Batch 330, Loss: 1.6153
Batch 340, Loss: 1.5645
Batch 350, Loss: 1.5031
Batch 360, Loss: 1.4717
Batch 370, Loss: 1.5293
Batch 380, Loss: 1.5652
Batch 390, Loss: 1.5833
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.15363049507141 seconds
Epoch 27 accuracy: 53.88%
Batch 10, Loss: 1.5369
Batch 20, Loss: 1.5050
Batch 30, Loss: 1.5043
Batch 40, Loss: 1.4766
Batch 50, Loss: 1.5122
Batch 60, Loss: 1.5414
Batch 70, Loss: 1.5964
Batch 80, Loss: 1.5906
Batch 90, Loss: 1.4769
Batch 100, Loss: 1.5193
Batch 110, Loss: 1.4929
Batch 120, Loss: 1.4961
Batch 130, Loss: 1.4960
Batch 140, Loss: 1.5124
Batch 150, Loss: 1.5999
Batch 160, Loss: 1.5127
Batch 170, Loss: 1.5252
Batch 180, Loss: 1.5355
Batch 190, Loss: 1.5295
Batch 200, Loss: 1.5331
Batch 210, Loss: 1.5143
Batch 220, Loss: 1.6043
Batch 230, Loss: 1.5171
Batch 240, Loss: 1.5955
Batch 250, Loss: 1.5202
Batch 260, Loss: 1.6184
Batch 270, Loss: 1.5135
Batch 280, Loss: 1.6054
Batch 290, Loss: 1.5540
Batch 300, Loss: 1.5113
Batch 310, Loss: 1.4986
Batch 320, Loss: 1.5285
Batch 330, Loss: 1.5497
Batch 340, Loss: 1.5654
Batch 350, Loss: 1.6351
Batch 360, Loss: 1.5392
Batch 370, Loss: 1.5133
Batch 380, Loss: 1.4969
Batch 390, Loss: 1.5430
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.142439365386963 seconds
Epoch 28 accuracy: 57.57%
Batch 10, Loss: 1.5016
Batch 20, Loss: 1.4969
Batch 30, Loss: 1.5252
Batch 40, Loss: 1.5070
Batch 50, Loss: 1.5227
Batch 60, Loss: 1.4594
Batch 70, Loss: 1.4704
Batch 80, Loss: 1.4329
Batch 90, Loss: 1.5060
Batch 100, Loss: 1.5071
Batch 110, Loss: 1.4684
Batch 120, Loss: 1.5105
Batch 130, Loss: 1.5422
Batch 140, Loss: 1.5528
Batch 150, Loss: 1.5235
Batch 160, Loss: 1.5409
Batch 170, Loss: 1.4685
Batch 180, Loss: 1.5696
Batch 190, Loss: 1.5886
Batch 200, Loss: 1.5630
Batch 210, Loss: 1.5184
Batch 220, Loss: 1.5450
Batch 230, Loss: 1.5505
Batch 240, Loss: 1.5730
Batch 250, Loss: 1.5857
Batch 260, Loss: 1.5675
Batch 270, Loss: 1.5146
Batch 280, Loss: 1.4843
Batch 290, Loss: 1.5646
Batch 300, Loss: 1.5376
Batch 310, Loss: 1.6166
Batch 320, Loss: 1.5169
Batch 330, Loss: 1.5171
Batch 340, Loss: 1.5353
Batch 350, Loss: 1.5333
Batch 360, Loss: 1.5025
Batch 370, Loss: 1.4983
Batch 380, Loss: 1.5306
Batch 390, Loss: 1.4859
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.163522958755493 seconds
Epoch 29 accuracy: 58.74%
Batch 10, Loss: 1.4034
Batch 20, Loss: 1.4816
Batch 30, Loss: 1.4839
Batch 40, Loss: 1.5059
Batch 50, Loss: 1.4651
Batch 60, Loss: 1.4706
Batch 70, Loss: 1.4999
Batch 80, Loss: 1.4615
Batch 90, Loss: 1.5005
Batch 100, Loss: 1.5052
Batch 110, Loss: 1.5464
Batch 120, Loss: 1.5061
Batch 130, Loss: 1.4452
Batch 140, Loss: 1.4721
Batch 150, Loss: 1.4869
Batch 160, Loss: 1.5246
Batch 170, Loss: 1.4676
Batch 180, Loss: 1.4312
Batch 190, Loss: 1.5529
Batch 200, Loss: 1.5541
Batch 210, Loss: 1.5225
Batch 220, Loss: 1.5561
Batch 230, Loss: 1.5188
Batch 240, Loss: 1.4945
Batch 250, Loss: 1.5363
Batch 260, Loss: 1.4742
Batch 270, Loss: 1.5366
Batch 280, Loss: 1.5106
Batch 290, Loss: 1.5828
Batch 300, Loss: 1.5843
Batch 310, Loss: 1.5722
Batch 320, Loss: 1.6034
Batch 330, Loss: 1.5329
Batch 340, Loss: 1.6097
Batch 350, Loss: 1.5282
Batch 360, Loss: 1.5098
Batch 370, Loss: 1.4940
Batch 380, Loss: 1.5322
Batch 390, Loss: 1.5145
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.482832431793213 seconds
Epoch 30 accuracy: 55.32%
Batch 10, Loss: 1.4940
Batch 20, Loss: 1.4556
Batch 30, Loss: 1.4884
Batch 40, Loss: 1.4905
Batch 50, Loss: 1.5228
Batch 60, Loss: 1.4726
Batch 70, Loss: 1.4946
Batch 80, Loss: 1.5406
Batch 90, Loss: 1.5343
Batch 100, Loss: 1.4550
Batch 110, Loss: 1.4850
Batch 120, Loss: 1.5242
Batch 130, Loss: 1.4661
Batch 140, Loss: 1.5172
Batch 150, Loss: 1.5319
Batch 160, Loss: 1.4793
Batch 170, Loss: 1.4987
Batch 180, Loss: 1.5180
Batch 190, Loss: 1.4709
Batch 200, Loss: 1.4887
Batch 210, Loss: 1.5616
Batch 220, Loss: 1.4819
Batch 230, Loss: 1.5265
Batch 240, Loss: 1.5078
Batch 250, Loss: 1.5165
Batch 260, Loss: 1.5398
Batch 270, Loss: 1.5301
Batch 280, Loss: 1.4858
Batch 290, Loss: 1.5371
Batch 300, Loss: 1.5363
Batch 310, Loss: 1.5215
Batch 320, Loss: 1.4998
Batch 330, Loss: 1.4870
Batch 340, Loss: 1.5604
Batch 350, Loss: 1.5890
Batch 360, Loss: 1.5231
Batch 370, Loss: 1.4661
Batch 380, Loss: 1.4876
Batch 390, Loss: 1.4979
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.15797734260559 seconds
Epoch 31 accuracy: 55.74%
Batch 10, Loss: 1.4674
Batch 20, Loss: 1.4792
Batch 30, Loss: 1.4889
Batch 40, Loss: 1.5411
Batch 50, Loss: 1.5122
Batch 60, Loss: 1.4761
Batch 70, Loss: 1.5121
Batch 80, Loss: 1.5339
Batch 90, Loss: 1.4976
Batch 100, Loss: 1.4895
Batch 110, Loss: 1.4752
Batch 120, Loss: 1.5168
Batch 130, Loss: 1.3978
Batch 140, Loss: 1.4746
Batch 150, Loss: 1.4589
Batch 160, Loss: 1.4825
Batch 170, Loss: 1.5229
Batch 180, Loss: 1.5361
Batch 190, Loss: 1.5507
Batch 200, Loss: 1.5496
Batch 210, Loss: 1.5000
Batch 220, Loss: 1.5094
Batch 230, Loss: 1.4826
Batch 240, Loss: 1.5229
Batch 250, Loss: 1.4709
Batch 260, Loss: 1.4505
Batch 270, Loss: 1.5291
Batch 280, Loss: 1.5341
Batch 290, Loss: 1.5096
Batch 300, Loss: 1.5001
Batch 310, Loss: 1.5137
Batch 320, Loss: 1.5358
Batch 330, Loss: 1.4912
Batch 340, Loss: 1.5259
Batch 350, Loss: 1.4501
Batch 360, Loss: 1.4551
Batch 370, Loss: 1.5772
Batch 380, Loss: 1.5539
Batch 390, Loss: 1.4816
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.151907444000244 seconds
Epoch 32 accuracy: 55.9%
Batch 10, Loss: 1.3773
Batch 20, Loss: 1.4156
Batch 30, Loss: 1.4538
Batch 40, Loss: 1.3906
Batch 50, Loss: 1.4310
Batch 60, Loss: 1.4420
Batch 70, Loss: 1.4453
Batch 80, Loss: 1.4694
Batch 90, Loss: 1.4985
Batch 100, Loss: 1.4227
Batch 110, Loss: 1.4750
Batch 120, Loss: 1.3873
Batch 130, Loss: 1.4616
Batch 140, Loss: 1.4990
Batch 150, Loss: 1.4821
Batch 160, Loss: 1.5036
Batch 170, Loss: 1.4773
Batch 180, Loss: 1.5837
Batch 190, Loss: 1.5276
Batch 200, Loss: 1.4965
Batch 210, Loss: 1.5358
Batch 220, Loss: 1.5093
Batch 230, Loss: 1.5201
Batch 240, Loss: 1.5594
Batch 250, Loss: 1.4373
Batch 260, Loss: 1.5185
Batch 270, Loss: 1.5116
Batch 280, Loss: 1.5010
Batch 290, Loss: 1.5416
Batch 300, Loss: 1.5562
Batch 310, Loss: 1.5353
Batch 320, Loss: 1.4738
Batch 330, Loss: 1.5560
Batch 340, Loss: 1.5264
Batch 350, Loss: 1.4112
Batch 360, Loss: 1.5670
Batch 370, Loss: 1.5794
Batch 380, Loss: 1.5508
Batch 390, Loss: 1.5254
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.144516468048096 seconds
Epoch 33 accuracy: 53.94%
Batch 10, Loss: 1.4664
Batch 20, Loss: 1.4552
Batch 30, Loss: 1.4426
Batch 40, Loss: 1.5051
Batch 50, Loss: 1.4284
Batch 60, Loss: 1.4519
Batch 70, Loss: 1.4869
Batch 80, Loss: 1.4522
Batch 90, Loss: 1.4604
Batch 100, Loss: 1.5177
Batch 110, Loss: 1.4942
Batch 120, Loss: 1.4546
Batch 130, Loss: 1.5157
Batch 140, Loss: 1.4855
Batch 150, Loss: 1.4392
Batch 160, Loss: 1.4941
Batch 170, Loss: 1.5360
Batch 180, Loss: 1.4797
Batch 190, Loss: 1.4959
Batch 200, Loss: 1.4901
Batch 210, Loss: 1.4961
Batch 220, Loss: 1.5515
Batch 230, Loss: 1.5231
Batch 240, Loss: 1.5048
Batch 250, Loss: 1.5085
Batch 260, Loss: 1.5331
Batch 270, Loss: 1.5068
Batch 280, Loss: 1.5029
Batch 290, Loss: 1.5278
Batch 300, Loss: 1.4372
Batch 310, Loss: 1.4899
Batch 320, Loss: 1.4622
Batch 330, Loss: 1.4488
Batch 340, Loss: 1.4836
Batch 350, Loss: 1.5035
Batch 360, Loss: 1.5089
Batch 370, Loss: 1.5219
Batch 380, Loss: 1.4704
Batch 390, Loss: 1.4674
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.224749088287354 seconds
Epoch 34 accuracy: 55.36%
Batch 10, Loss: 1.5437
Batch 20, Loss: 1.3961
Batch 30, Loss: 1.4477
Batch 40, Loss: 1.4922
Batch 50, Loss: 1.4007
Batch 60, Loss: 1.4564
Batch 70, Loss: 1.4540
Batch 80, Loss: 1.4863
Batch 90, Loss: 1.4911
Batch 100, Loss: 1.4477
Batch 110, Loss: 1.4336
Batch 120, Loss: 1.4999
Batch 130, Loss: 1.4925
Batch 140, Loss: 1.4305
Batch 150, Loss: 1.4720
Batch 160, Loss: 1.5259
Batch 170, Loss: 1.5142
Batch 180, Loss: 1.4009
Batch 190, Loss: 1.5223
Batch 200, Loss: 1.5407
Batch 210, Loss: 1.5031
Batch 220, Loss: 1.4776
Batch 230, Loss: 1.4708
Batch 240, Loss: 1.4553
Batch 250, Loss: 1.5202
Batch 260, Loss: 1.5222
Batch 270, Loss: 1.5041
Batch 280, Loss: 1.5252
Batch 290, Loss: 1.4943
Batch 300, Loss: 1.5311
Batch 310, Loss: 1.4490
Batch 320, Loss: 1.4554
Batch 330, Loss: 1.3931
Batch 340, Loss: 1.4744
Batch 350, Loss: 1.4762
Batch 360, Loss: 1.4897
Batch 370, Loss: 1.5078
Batch 380, Loss: 1.5010
Batch 390, Loss: 1.4621
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.185227870941162 seconds
Epoch 35 accuracy: 53.15%
Batch 10, Loss: 1.4486
Batch 20, Loss: 1.5472
Batch 30, Loss: 1.4878
Batch 40, Loss: 1.4315
Batch 50, Loss: 1.4500
Batch 60, Loss: 1.4189
Batch 70, Loss: 1.4592
Batch 80, Loss: 1.3899
Batch 90, Loss: 1.4913
Batch 100, Loss: 1.3932
Batch 110, Loss: 1.5294
Batch 120, Loss: 1.4820
Batch 130, Loss: 1.5091
Batch 140, Loss: 1.4661
Batch 150, Loss: 1.4671
Batch 160, Loss: 1.5177
Batch 170, Loss: 1.5357
Batch 180, Loss: 1.4785
Batch 190, Loss: 1.4337
Batch 200, Loss: 1.4418
Batch 210, Loss: 1.5008
Batch 220, Loss: 1.4781
Batch 230, Loss: 1.5065
Batch 240, Loss: 1.5662
Batch 250, Loss: 1.4223
Batch 260, Loss: 1.4702
Batch 270, Loss: 1.4940
Batch 280, Loss: 1.4608
Batch 290, Loss: 1.4932
Batch 300, Loss: 1.4574
Batch 310, Loss: 1.4771
Batch 320, Loss: 1.4631
Batch 330, Loss: 1.4146
Batch 340, Loss: 1.4859
Batch 350, Loss: 1.4037
Batch 360, Loss: 1.4497
Batch 370, Loss: 1.4499
Batch 380, Loss: 1.4786
Batch 390, Loss: 1.4369
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.268861055374146 seconds
Epoch 36 accuracy: 54.69%
Batch 10, Loss: 1.4400
Batch 20, Loss: 1.4395
Batch 30, Loss: 1.3816
Batch 40, Loss: 1.4319
Batch 50, Loss: 1.5211
Batch 60, Loss: 1.5133
Batch 70, Loss: 1.4596
Batch 80, Loss: 1.3894
Batch 90, Loss: 1.3870
Batch 100, Loss: 1.4552
Batch 110, Loss: 1.5406
Batch 120, Loss: 1.4198
Batch 130, Loss: 1.4657
Batch 140, Loss: 1.4829
Batch 150, Loss: 1.4952
Batch 160, Loss: 1.4697
Batch 170, Loss: 1.4628
Batch 180, Loss: 1.4743
Batch 190, Loss: 1.4116
Batch 200, Loss: 1.4889
Batch 210, Loss: 1.4738
Batch 220, Loss: 1.4691
Batch 230, Loss: 1.4471
Batch 240, Loss: 1.5107
Batch 250, Loss: 1.4646
Batch 260, Loss: 1.4872
Batch 270, Loss: 1.4499
Batch 280, Loss: 1.5158
Batch 290, Loss: 1.4852
Batch 300, Loss: 1.4832
Batch 310, Loss: 1.5295
Batch 320, Loss: 1.5171
Batch 330, Loss: 1.5279
Batch 340, Loss: 1.4576
Batch 350, Loss: 1.4608
Batch 360, Loss: 1.4692
Batch 370, Loss: 1.5843
Batch 380, Loss: 1.4685
Batch 390, Loss: 1.5090
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.16115164756775 seconds
Epoch 37 accuracy: 55.48%
Batch 10, Loss: 1.3700
Batch 20, Loss: 1.4011
Batch 30, Loss: 1.4573
Batch 40, Loss: 1.4290
Batch 50, Loss: 1.4531
Batch 60, Loss: 1.4672
Batch 70, Loss: 1.5026
Batch 80, Loss: 1.4344
Batch 90, Loss: 1.4962
Batch 100, Loss: 1.4175
Batch 110, Loss: 1.4263
Batch 120, Loss: 1.5154
Batch 130, Loss: 1.4371
Batch 140, Loss: 1.4191
Batch 150, Loss: 1.4564
Batch 160, Loss: 1.4291
Batch 170, Loss: 1.4077
Batch 180, Loss: 1.4031
Batch 190, Loss: 1.4535
Batch 200, Loss: 1.4523
Batch 210, Loss: 1.4134
Batch 220, Loss: 1.4982
Batch 230, Loss: 1.4808
Batch 240, Loss: 1.5204
Batch 250, Loss: 1.5016
Batch 260, Loss: 1.5032
Batch 270, Loss: 1.4667
Batch 280, Loss: 1.4859
Batch 290, Loss: 1.4073
Batch 300, Loss: 1.4981
Batch 310, Loss: 1.5258
Batch 320, Loss: 1.4426
Batch 330, Loss: 1.4397
Batch 340, Loss: 1.4209
Batch 350, Loss: 1.4953
Batch 360, Loss: 1.4551
Batch 370, Loss: 1.5349
Batch 380, Loss: 1.4719
Batch 390, Loss: 1.4906
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.201223611831665 seconds
Epoch 38 accuracy: 53.67%
Batch 10, Loss: 1.4237
Batch 20, Loss: 1.4124
Batch 30, Loss: 1.4399
Batch 40, Loss: 1.4076
Batch 50, Loss: 1.4261
Batch 60, Loss: 1.3899
Batch 70, Loss: 1.4219
Batch 80, Loss: 1.4306
Batch 90, Loss: 1.3863
Batch 100, Loss: 1.4766
Batch 110, Loss: 1.4602
Batch 120, Loss: 1.4667
Batch 130, Loss: 1.4568
Batch 140, Loss: 1.5469
Batch 150, Loss: 1.4441
Batch 160, Loss: 1.4698
Batch 170, Loss: 1.4352
Batch 180, Loss: 1.4551
Batch 190, Loss: 1.4289
Batch 200, Loss: 1.4833
Batch 210, Loss: 1.4194
Batch 220, Loss: 1.4786
Batch 230, Loss: 1.4171
Batch 240, Loss: 1.5056
Batch 250, Loss: 1.5105
Batch 260, Loss: 1.4432
Batch 270, Loss: 1.4802
Batch 280, Loss: 1.4548
Batch 290, Loss: 1.4703
Batch 300, Loss: 1.5227
Batch 310, Loss: 1.4060
Batch 320, Loss: 1.4122
Batch 330, Loss: 1.5153
Batch 340, Loss: 1.5069
Batch 350, Loss: 1.5465
Batch 360, Loss: 1.4914
Batch 370, Loss: 1.4913
Batch 380, Loss: 1.4578
Batch 390, Loss: 1.4371
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.149097204208374 seconds
Epoch 39 accuracy: 56.86%
Batch 10, Loss: 1.3966
Batch 20, Loss: 1.4174
Batch 30, Loss: 1.4384
Batch 40, Loss: 1.5064
Batch 50, Loss: 1.4621
Batch 60, Loss: 1.4562
Batch 70, Loss: 1.4045
Batch 80, Loss: 1.4644
Batch 90, Loss: 1.4529
Batch 100, Loss: 1.4542
Batch 110, Loss: 1.4678
Batch 120, Loss: 1.3928
Batch 130, Loss: 1.4428
Batch 140, Loss: 1.4611
Batch 150, Loss: 1.4282
Batch 160, Loss: 1.4544
Batch 170, Loss: 1.3726
Batch 180, Loss: 1.4792
Batch 190, Loss: 1.4733
Batch 200, Loss: 1.4603
Batch 210, Loss: 1.4116
Batch 220, Loss: 1.4001
Batch 230, Loss: 1.5247
Batch 240, Loss: 1.4417
Batch 250, Loss: 1.4413
Batch 260, Loss: 1.4700
Batch 270, Loss: 1.4526
Batch 280, Loss: 1.4204
Batch 290, Loss: 1.5044
Batch 300, Loss: 1.4904
Batch 310, Loss: 1.4518
Batch 320, Loss: 1.4397
Batch 330, Loss: 1.4427
Batch 340, Loss: 1.4454
Batch 350, Loss: 1.5387
Batch 360, Loss: 1.4963
Batch 370, Loss: 1.4754
Batch 380, Loss: 1.4786
Batch 390, Loss: 1.3895
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.237077951431274 seconds
Epoch 40 accuracy: 57.72%
Batch 10, Loss: 1.3987
Batch 20, Loss: 1.3876
Batch 30, Loss: 1.3782
Batch 40, Loss: 1.4841
Batch 50, Loss: 1.4377
Batch 60, Loss: 1.4386
Batch 70, Loss: 1.4300
Batch 80, Loss: 1.3868
Batch 90, Loss: 1.4554
Batch 100, Loss: 1.4243
Batch 110, Loss: 1.3730
Batch 120, Loss: 1.4413
Batch 130, Loss: 1.4140
Batch 140, Loss: 1.4466
Batch 150, Loss: 1.3981
Batch 160, Loss: 1.5289
Batch 170, Loss: 1.4698
Batch 180, Loss: 1.4300
Batch 190, Loss: 1.4385
Batch 200, Loss: 1.4600
Batch 210, Loss: 1.4613
Batch 220, Loss: 1.4503
Batch 230, Loss: 1.4483
Batch 240, Loss: 1.3711
Batch 250, Loss: 1.4326
Batch 260, Loss: 1.4299
Batch 270, Loss: 1.4722
Batch 280, Loss: 1.4727
Batch 290, Loss: 1.4574
Batch 300, Loss: 1.4762
Batch 310, Loss: 1.3885
Batch 320, Loss: 1.4700
Batch 330, Loss: 1.4840
Batch 340, Loss: 1.5145
Batch 350, Loss: 1.4581
Batch 360, Loss: 1.4567
Batch 370, Loss: 1.4328
Batch 380, Loss: 1.4559
Batch 390, Loss: 1.4709
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.27104663848877 seconds
Epoch 41 accuracy: 58.04%
Batch 10, Loss: 1.4193
Batch 20, Loss: 1.4192
Batch 30, Loss: 1.4021
Batch 40, Loss: 1.3391
Batch 50, Loss: 1.3137
Batch 60, Loss: 1.3718
Batch 70, Loss: 1.3561
Batch 80, Loss: 1.4188
Batch 90, Loss: 1.4396
Batch 100, Loss: 1.4452
Batch 110, Loss: 1.4826
Batch 120, Loss: 1.4004
Batch 130, Loss: 1.4147
Batch 140, Loss: 1.4600
Batch 150, Loss: 1.3846
Batch 160, Loss: 1.4422
Batch 170, Loss: 1.4151
Batch 180, Loss: 1.4505
Batch 190, Loss: 1.4918
Batch 200, Loss: 1.4642
Batch 210, Loss: 1.3705
Batch 220, Loss: 1.4435
Batch 230, Loss: 1.3853
Batch 240, Loss: 1.4658
Batch 250, Loss: 1.4168
Batch 260, Loss: 1.4737
Batch 270, Loss: 1.5662
Batch 280, Loss: 1.4755
Batch 290, Loss: 1.4184
Batch 300, Loss: 1.4665
Batch 310, Loss: 1.4436
Batch 320, Loss: 1.4817
Batch 330, Loss: 1.4932
Batch 340, Loss: 1.4227
Batch 350, Loss: 1.4670
Batch 360, Loss: 1.4802
Batch 370, Loss: 1.4221
Batch 380, Loss: 1.4747
Batch 390, Loss: 1.4844
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.319870233535767 seconds
Epoch 42 accuracy: 57.59%
Batch 10, Loss: 1.3982
Batch 20, Loss: 1.4259
Batch 30, Loss: 1.4030
Batch 40, Loss: 1.4480
Batch 50, Loss: 1.3894
Batch 60, Loss: 1.4508
Batch 70, Loss: 1.5104
Batch 80, Loss: 1.4181
Batch 90, Loss: 1.4181
Batch 100, Loss: 1.3855
Batch 110, Loss: 1.4582
Batch 120, Loss: 1.4118
Batch 130, Loss: 1.4305
Batch 140, Loss: 1.4369
Batch 150, Loss: 1.5044
Batch 160, Loss: 1.4127
Batch 170, Loss: 1.4169
Batch 180, Loss: 1.4028
Batch 190, Loss: 1.4347
Batch 200, Loss: 1.4442
Batch 210, Loss: 1.4555
Batch 220, Loss: 1.4884
Batch 230, Loss: 1.4603
Batch 240, Loss: 1.4622
Batch 250, Loss: 1.4224
Batch 260, Loss: 1.4587
Batch 270, Loss: 1.4298
Batch 280, Loss: 1.3881
Batch 290, Loss: 1.3907
Batch 300, Loss: 1.4956
Batch 310, Loss: 1.4731
Batch 320, Loss: 1.4934
Batch 330, Loss: 1.4472
Batch 340, Loss: 1.4990
Batch 350, Loss: 1.4854
Batch 360, Loss: 1.4229
Batch 370, Loss: 1.5655
Batch 380, Loss: 1.3483
Batch 390, Loss: 1.4615
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.263674020767212 seconds
Epoch 43 accuracy: 54.89%
Batch 10, Loss: 1.3715
Batch 20, Loss: 1.3470
Batch 30, Loss: 1.3858
Batch 40, Loss: 1.4210
Batch 50, Loss: 1.4040
Batch 60, Loss: 1.3339
Batch 70, Loss: 1.3383
Batch 80, Loss: 1.3296
Batch 90, Loss: 1.3880
Batch 100, Loss: 1.3870
Batch 110, Loss: 1.4115
Batch 120, Loss: 1.4199
Batch 130, Loss: 1.4449
Batch 140, Loss: 1.3389
Batch 150, Loss: 1.4603
Batch 160, Loss: 1.4745
Batch 170, Loss: 1.5236
Batch 180, Loss: 1.5067
Batch 190, Loss: 1.4852
Batch 200, Loss: 1.3760
Batch 210, Loss: 1.4788
Batch 220, Loss: 1.3714
Batch 230, Loss: 1.3840
Batch 240, Loss: 1.4312
Batch 250, Loss: 1.4050
Batch 260, Loss: 1.4769
Batch 270, Loss: 1.4126
Batch 280, Loss: 1.4858
Batch 290, Loss: 1.4617
Batch 300, Loss: 1.4550
Batch 310, Loss: 1.4739
Batch 320, Loss: 1.5208
Batch 330, Loss: 1.4511
Batch 340, Loss: 1.4200
Batch 350, Loss: 1.4249
Batch 360, Loss: 1.4213
Batch 370, Loss: 1.4168
Batch 380, Loss: 1.4438
Batch 390, Loss: 1.5082
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.045745849609375 seconds
Epoch 44 accuracy: 59.85%
Batch 10, Loss: 1.3665
Batch 20, Loss: 1.3651
Batch 30, Loss: 1.4712
Batch 40, Loss: 1.4102
Batch 50, Loss: 1.3446
Batch 60, Loss: 1.4091
Batch 70, Loss: 1.3690
Batch 80, Loss: 1.4519
Batch 90, Loss: 1.4522
Batch 100, Loss: 1.3517
Batch 110, Loss: 1.3622
Batch 120, Loss: 1.3233
Batch 130, Loss: 1.4263
Batch 140, Loss: 1.4340
Batch 150, Loss: 1.4340
Batch 160, Loss: 1.3459
Batch 170, Loss: 1.5083
Batch 180, Loss: 1.4348
Batch 190, Loss: 1.4330
Batch 200, Loss: 1.4021
Batch 210, Loss: 1.3881
Batch 220, Loss: 1.4635
Batch 230, Loss: 1.3987
Batch 240, Loss: 1.5150
Batch 250, Loss: 1.4711
Batch 260, Loss: 1.3952
Batch 270, Loss: 1.3986
Batch 280, Loss: 1.4645
Batch 290, Loss: 1.4391
Batch 300, Loss: 1.4506
Batch 310, Loss: 1.4065
Batch 320, Loss: 1.4309
Batch 330, Loss: 1.5020
Batch 340, Loss: 1.4237
Batch 350, Loss: 1.4781
Batch 360, Loss: 1.4710
Batch 370, Loss: 1.4091
Batch 380, Loss: 1.5180
Batch 390, Loss: 1.4640
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.090482473373413 seconds
Epoch 45 accuracy: 58.52%
Batch 10, Loss: 1.3647
Batch 20, Loss: 1.3750
Batch 30, Loss: 1.4087
Batch 40, Loss: 1.3764
Batch 50, Loss: 1.4500
Batch 60, Loss: 1.3575
Batch 70, Loss: 1.4422
Batch 80, Loss: 1.3831
Batch 90, Loss: 1.3909
Batch 100, Loss: 1.3647
Batch 110, Loss: 1.4997
Batch 120, Loss: 1.4159
Batch 130, Loss: 1.3974
Batch 140, Loss: 1.4429
Batch 150, Loss: 1.3608
Batch 160, Loss: 1.3827
Batch 170, Loss: 1.4406
Batch 180, Loss: 1.4973
Batch 190, Loss: 1.3711
Batch 200, Loss: 1.3740
Batch 210, Loss: 1.4423
Batch 220, Loss: 1.4043
Batch 230, Loss: 1.4334
Batch 240, Loss: 1.4224
Batch 250, Loss: 1.4142
Batch 260, Loss: 1.3848
Batch 270, Loss: 1.4571
Batch 280, Loss: 1.5066
Batch 290, Loss: 1.4886
Batch 300, Loss: 1.4516
Batch 310, Loss: 1.4710
Batch 320, Loss: 1.4357
Batch 330, Loss: 1.4789
Batch 340, Loss: 1.3938
Batch 350, Loss: 1.4666
Batch 360, Loss: 1.3901
Batch 370, Loss: 1.4284
Batch 380, Loss: 1.4895
Batch 390, Loss: 1.3744
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.090330600738525 seconds
Epoch 46 accuracy: 59.21%
Batch 10, Loss: 1.4297
Batch 20, Loss: 1.3586
Batch 30, Loss: 1.3535
Batch 40, Loss: 1.3628
Batch 50, Loss: 1.3416
Batch 60, Loss: 1.3700
Batch 70, Loss: 1.3822
Batch 80, Loss: 1.3813
Batch 90, Loss: 1.4018
Batch 100, Loss: 1.4305
Batch 110, Loss: 1.3643
Batch 120, Loss: 1.3446
Batch 130, Loss: 1.3794
Batch 140, Loss: 1.3620
Batch 150, Loss: 1.4885
Batch 160, Loss: 1.4086
Batch 170, Loss: 1.4426
Batch 180, Loss: 1.3482
Batch 190, Loss: 1.3640
Batch 200, Loss: 1.4239
Batch 210, Loss: 1.4461
Batch 220, Loss: 1.4411
Batch 230, Loss: 1.4846
Batch 240, Loss: 1.3961
Batch 250, Loss: 1.5280
Batch 260, Loss: 1.4368
Batch 270, Loss: 1.4661
Batch 280, Loss: 1.4116
Batch 290, Loss: 1.4298
Batch 300, Loss: 1.4731
Batch 310, Loss: 1.4337
Batch 320, Loss: 1.4487
Batch 330, Loss: 1.4376
Batch 340, Loss: 1.3814
Batch 350, Loss: 1.4002
Batch 360, Loss: 1.3970
Batch 370, Loss: 1.4450
Batch 380, Loss: 1.5155
Batch 390, Loss: 1.4509
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.084476232528687 seconds
Epoch 47 accuracy: 55.6%
Batch 10, Loss: 1.3442
Batch 20, Loss: 1.3902
Batch 30, Loss: 1.4052
Batch 40, Loss: 1.4478
Batch 50, Loss: 1.4136
Batch 60, Loss: 1.3474
Batch 70, Loss: 1.3668
Batch 80, Loss: 1.3494
Batch 90, Loss: 1.3737
Batch 100, Loss: 1.3740
Batch 110, Loss: 1.4675
Batch 120, Loss: 1.3668
Batch 130, Loss: 1.3680
Batch 140, Loss: 1.4084
Batch 150, Loss: 1.4665
Batch 160, Loss: 1.3948
Batch 170, Loss: 1.4563
Batch 180, Loss: 1.5059
Batch 190, Loss: 1.3783
Batch 200, Loss: 1.3828
Batch 210, Loss: 1.3983
Batch 220, Loss: 1.3866
Batch 230, Loss: 1.4811
Batch 240, Loss: 1.3849
Batch 250, Loss: 1.3658
Batch 260, Loss: 1.3541
Batch 270, Loss: 1.3735
Batch 280, Loss: 1.3709
Batch 290, Loss: 1.5082
Batch 300, Loss: 1.4352
Batch 310, Loss: 1.4656
Batch 320, Loss: 1.4716
Batch 330, Loss: 1.4273
Batch 340, Loss: 1.4660
Batch 350, Loss: 1.4657
Batch 360, Loss: 1.4504
Batch 370, Loss: 1.4663
Batch 380, Loss: 1.4188
Batch 390, Loss: 1.4629
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.243987560272217 seconds
Epoch 48 accuracy: 59.99%
Batch 10, Loss: 1.3671
Batch 20, Loss: 1.3610
Batch 30, Loss: 1.3571
Batch 40, Loss: 1.4192
Batch 50, Loss: 1.3744
Batch 60, Loss: 1.4237
Batch 70, Loss: 1.3966
Batch 80, Loss: 1.4166
Batch 90, Loss: 1.3859
Batch 100, Loss: 1.3993
Batch 110, Loss: 1.3828
Batch 120, Loss: 1.3537
Batch 130, Loss: 1.3563
Batch 140, Loss: 1.3947
Batch 150, Loss: 1.4636
Batch 160, Loss: 1.3544
Batch 170, Loss: 1.3672
Batch 180, Loss: 1.3817
Batch 190, Loss: 1.4174
Batch 200, Loss: 1.3962
Batch 210, Loss: 1.4160
Batch 220, Loss: 1.4119
Batch 230, Loss: 1.4267
Batch 240, Loss: 1.4795
Batch 250, Loss: 1.4668
Batch 260, Loss: 1.4180
Batch 270, Loss: 1.3967
Batch 280, Loss: 1.3585
Batch 290, Loss: 1.4004
Batch 300, Loss: 1.4891
Batch 310, Loss: 1.4657
Batch 320, Loss: 1.4787
Batch 330, Loss: 1.4392
Batch 340, Loss: 1.4010
Batch 350, Loss: 1.4468
Batch 360, Loss: 1.4392
Batch 370, Loss: 1.4525
Batch 380, Loss: 1.4591
Batch 390, Loss: 1.4167
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.271249771118164 seconds
Epoch 49 accuracy: 57.96%
Batch 10, Loss: 1.4504
Batch 20, Loss: 1.4138
Batch 30, Loss: 1.3511
Batch 40, Loss: 1.3060
Batch 50, Loss: 1.3028
Batch 60, Loss: 1.2772
Batch 70, Loss: 1.3193
Batch 80, Loss: 1.3864
Batch 90, Loss: 1.3923
Batch 100, Loss: 1.3415
Batch 110, Loss: 1.3350
Batch 120, Loss: 1.4047
Batch 130, Loss: 1.4308
Batch 140, Loss: 1.4163
Batch 150, Loss: 1.4574
Batch 160, Loss: 1.4001
Batch 170, Loss: 1.3780
Batch 180, Loss: 1.4634
Batch 190, Loss: 1.4811
Batch 200, Loss: 1.4019
Batch 210, Loss: 1.3211
Batch 220, Loss: 1.4484
Batch 230, Loss: 1.3500
Batch 240, Loss: 1.3618
Batch 250, Loss: 1.3712
Batch 260, Loss: 1.4441
Batch 270, Loss: 1.3522
Batch 280, Loss: 1.4291
Batch 290, Loss: 1.4417
Batch 300, Loss: 1.4891
Batch 310, Loss: 1.4347
Batch 320, Loss: 1.3956
Batch 330, Loss: 1.3664
Batch 340, Loss: 1.4115
Batch 350, Loss: 1.4485
Batch 360, Loss: 1.4593
Batch 370, Loss: 1.4174
Batch 380, Loss: 1.3912
Batch 390, Loss: 1.4175
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.22842836380005 seconds
Epoch 50 accuracy: 61.39%
Batch 10, Loss: 1.3173
Batch 20, Loss: 1.3153
Batch 30, Loss: 1.3067
Batch 40, Loss: 1.3841
Batch 50, Loss: 1.3300
Batch 60, Loss: 1.2928
Batch 70, Loss: 1.3766
Batch 80, Loss: 1.3249
Batch 90, Loss: 1.3443
Batch 100, Loss: 1.3621
Batch 110, Loss: 1.4208
Batch 120, Loss: 1.3183
Batch 130, Loss: 1.3995
Batch 140, Loss: 1.4287
Batch 150, Loss: 1.3792
Batch 160, Loss: 1.4160
Batch 170, Loss: 1.3644
Batch 180, Loss: 1.3928
Batch 190, Loss: 1.4302
Batch 200, Loss: 1.4485
Batch 210, Loss: 1.4250
Batch 220, Loss: 1.3972
Batch 230, Loss: 1.3878
Batch 240, Loss: 1.4206
Batch 250, Loss: 1.3904
Batch 260, Loss: 1.4009
Batch 270, Loss: 1.4070
Batch 280, Loss: 1.3539
Batch 290, Loss: 1.4328
Batch 300, Loss: 1.4622
Batch 310, Loss: 1.4384
Batch 320, Loss: 1.4506
Batch 330, Loss: 1.4308
Batch 340, Loss: 1.4123
Batch 350, Loss: 1.3689
Batch 360, Loss: 1.3801
Batch 370, Loss: 1.3984
Batch 380, Loss: 1.4293
Batch 390, Loss: 1.4215
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.05498504638672 seconds
Epoch 51 accuracy: 58.57%
Batch 10, Loss: 1.3736
Batch 20, Loss: 1.3822
Batch 30, Loss: 1.4221
Batch 40, Loss: 1.3714
Batch 50, Loss: 1.3298
Batch 60, Loss: 1.3338
Batch 70, Loss: 1.3919
Batch 80, Loss: 1.3928
Batch 90, Loss: 1.3910
Batch 100, Loss: 1.3567
Batch 110, Loss: 1.4056
Batch 120, Loss: 1.4217
Batch 130, Loss: 1.4264
Batch 140, Loss: 1.4071
Batch 150, Loss: 1.4069
Batch 160, Loss: 1.3817
Batch 170, Loss: 1.3451
Batch 180, Loss: 1.3815
Batch 190, Loss: 1.4217
Batch 200, Loss: 1.2628
Batch 210, Loss: 1.3990
Batch 220, Loss: 1.4046
Batch 230, Loss: 1.3605
Batch 240, Loss: 1.4267
Batch 250, Loss: 1.4373
Batch 260, Loss: 1.4189
Batch 270, Loss: 1.4316
Batch 280, Loss: 1.3668
Batch 290, Loss: 1.4226
Batch 300, Loss: 1.3777
Batch 310, Loss: 1.4185
Batch 320, Loss: 1.4375
Batch 330, Loss: 1.3915
Batch 340, Loss: 1.4603
Batch 350, Loss: 1.3900
Batch 360, Loss: 1.4068
Batch 370, Loss: 1.3380
Batch 380, Loss: 1.3973
Batch 390, Loss: 1.4059
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.239164352416992 seconds
Epoch 52 accuracy: 58.84%
Batch 10, Loss: 1.3548
Batch 20, Loss: 1.2831
Batch 30, Loss: 1.2901
Batch 40, Loss: 1.3561
Batch 50, Loss: 1.3768
Batch 60, Loss: 1.3578
Batch 70, Loss: 1.3812
Batch 80, Loss: 1.3837
Batch 90, Loss: 1.3672
Batch 100, Loss: 1.3550
Batch 110, Loss: 1.3196
Batch 120, Loss: 1.3399
Batch 130, Loss: 1.3968
Batch 140, Loss: 1.3688
Batch 150, Loss: 1.3862
Batch 160, Loss: 1.3977
Batch 170, Loss: 1.3240
Batch 180, Loss: 1.3694
Batch 190, Loss: 1.3836
Batch 200, Loss: 1.4022
Batch 210, Loss: 1.3644
Batch 220, Loss: 1.3952
Batch 230, Loss: 1.4707
Batch 240, Loss: 1.4002
Batch 250, Loss: 1.3749
Batch 260, Loss: 1.3701
Batch 270, Loss: 1.4107
Batch 280, Loss: 1.3341
Batch 290, Loss: 1.4435
Batch 300, Loss: 1.3781
Batch 310, Loss: 1.3644
Batch 320, Loss: 1.4116
Batch 330, Loss: 1.4880
Batch 340, Loss: 1.4608
Batch 350, Loss: 1.5045
Batch 360, Loss: 1.4116
Batch 370, Loss: 1.4708
Batch 380, Loss: 1.3168
Batch 390, Loss: 1.4221
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.152666807174683 seconds
Epoch 53 accuracy: 58.81%
Batch 10, Loss: 1.3738
Batch 20, Loss: 1.2796
Batch 30, Loss: 1.4052
Batch 40, Loss: 1.3634
Batch 50, Loss: 1.3839
Batch 60, Loss: 1.4105
Batch 70, Loss: 1.3218
Batch 80, Loss: 1.4147
Batch 90, Loss: 1.3394
Batch 100, Loss: 1.3400
Batch 110, Loss: 1.3625
Batch 120, Loss: 1.3183
Batch 130, Loss: 1.3539
Batch 140, Loss: 1.3297
Batch 150, Loss: 1.3571
Batch 160, Loss: 1.3613
Batch 170, Loss: 1.3827
Batch 180, Loss: 1.3824
Batch 190, Loss: 1.3617
Batch 200, Loss: 1.3909
Batch 210, Loss: 1.3497
Batch 220, Loss: 1.3941
Batch 230, Loss: 1.4251
Batch 240, Loss: 1.3544
Batch 250, Loss: 1.4535
Batch 260, Loss: 1.3677
Batch 270, Loss: 1.3740
Batch 280, Loss: 1.4340
Batch 290, Loss: 1.3383
Batch 300, Loss: 1.3997
Batch 310, Loss: 1.3904
Batch 320, Loss: 1.3823
Batch 330, Loss: 1.4126
Batch 340, Loss: 1.4566
Batch 350, Loss: 1.4280
Batch 360, Loss: 1.4352
Batch 370, Loss: 1.3920
Batch 380, Loss: 1.4307
Batch 390, Loss: 1.3693
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.04984211921692 seconds
Epoch 54 accuracy: 58.45%
Batch 10, Loss: 1.3957
Batch 20, Loss: 1.3654
Batch 30, Loss: 1.3658
Batch 40, Loss: 1.3277
Batch 50, Loss: 1.2998
Batch 60, Loss: 1.2979
Batch 70, Loss: 1.3065
Batch 80, Loss: 1.3928
Batch 90, Loss: 1.3176
Batch 100, Loss: 1.3432
Batch 110, Loss: 1.3208
Batch 120, Loss: 1.3010
Batch 130, Loss: 1.3909
Batch 140, Loss: 1.2822
Batch 150, Loss: 1.3693
Batch 160, Loss: 1.3868
Batch 170, Loss: 1.3998
Batch 180, Loss: 1.3775
Batch 190, Loss: 1.4418
Batch 200, Loss: 1.4180
Batch 210, Loss: 1.3676
Batch 220, Loss: 1.3962
Batch 230, Loss: 1.3661
Batch 240, Loss: 1.4567
Batch 250, Loss: 1.3851
Batch 260, Loss: 1.3705
Batch 270, Loss: 1.3973
Batch 280, Loss: 1.3755
Batch 290, Loss: 1.4195
Batch 300, Loss: 1.4428
Batch 310, Loss: 1.4196
Batch 320, Loss: 1.3679
Batch 330, Loss: 1.3913
Batch 340, Loss: 1.3281
Batch 350, Loss: 1.4151
Batch 360, Loss: 1.3910
Batch 370, Loss: 1.3701
Batch 380, Loss: 1.3935
Batch 390, Loss: 1.3787
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.292632341384888 seconds
Epoch 55 accuracy: 55.45%
Batch 10, Loss: 1.3641
Batch 20, Loss: 1.3193
Batch 30, Loss: 1.3830
Batch 40, Loss: 1.3277
Batch 50, Loss: 1.3578
Batch 60, Loss: 1.3424
Batch 70, Loss: 1.3314
Batch 80, Loss: 1.3375
Batch 90, Loss: 1.3151
Batch 100, Loss: 1.3843
Batch 110, Loss: 1.3652
Batch 120, Loss: 1.3182
Batch 130, Loss: 1.3886
Batch 140, Loss: 1.4178
Batch 150, Loss: 1.4193
Batch 160, Loss: 1.4067
Batch 170, Loss: 1.3808
Batch 180, Loss: 1.3652
Batch 190, Loss: 1.3826
Batch 200, Loss: 1.3381
Batch 210, Loss: 1.3936
Batch 220, Loss: 1.3030
Batch 230, Loss: 1.2911
Batch 240, Loss: 1.2836
Batch 250, Loss: 1.3452
Batch 260, Loss: 1.3339
Batch 270, Loss: 1.3551
Batch 280, Loss: 1.4004
Batch 290, Loss: 1.4124
Batch 300, Loss: 1.4377
Batch 310, Loss: 1.3476
Batch 320, Loss: 1.3810
Batch 330, Loss: 1.3483
Batch 340, Loss: 1.3624
Batch 350, Loss: 1.2789
Batch 360, Loss: 1.3220
Batch 370, Loss: 1.3945
Batch 380, Loss: 1.4130
Batch 390, Loss: 1.4115
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.247243881225586 seconds
Epoch 56 accuracy: 59.49%
Batch 10, Loss: 1.3741
Batch 20, Loss: 1.3206
Batch 30, Loss: 1.3375
Batch 40, Loss: 1.2956
Batch 50, Loss: 1.3613
Batch 60, Loss: 1.3957
Batch 70, Loss: 1.3435
Batch 80, Loss: 1.4080
Batch 90, Loss: 1.3026
Batch 100, Loss: 1.3246
Batch 110, Loss: 1.3157
Batch 120, Loss: 1.3325
Batch 130, Loss: 1.3423
Batch 140, Loss: 1.3635
Batch 150, Loss: 1.3488
Batch 160, Loss: 1.3711
Batch 170, Loss: 1.3766
Batch 180, Loss: 1.3580
Batch 190, Loss: 1.3579
Batch 200, Loss: 1.3723
Batch 210, Loss: 1.4057
Batch 220, Loss: 1.3342
Batch 230, Loss: 1.3816
Batch 240, Loss: 1.2680
Batch 250, Loss: 1.3372
Batch 260, Loss: 1.3580
Batch 270, Loss: 1.4059
Batch 280, Loss: 1.3973
Batch 290, Loss: 1.4001
Batch 300, Loss: 1.3992
Batch 310, Loss: 1.3941
Batch 320, Loss: 1.3528
Batch 330, Loss: 1.3699
Batch 340, Loss: 1.3542
Batch 350, Loss: 1.4277
Batch 360, Loss: 1.3832
Batch 370, Loss: 1.3751
Batch 380, Loss: 1.4085
Batch 390, Loss: 1.4037
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.146364450454712 seconds
Epoch 57 accuracy: 58.41%
Batch 10, Loss: 1.3301
Batch 20, Loss: 1.3895
Batch 30, Loss: 1.3681
Batch 40, Loss: 1.3169
Batch 50, Loss: 1.3227
Batch 60, Loss: 1.2962
Batch 70, Loss: 1.3370
Batch 80, Loss: 1.3711
Batch 90, Loss: 1.3786
Batch 100, Loss: 1.3283
Batch 110, Loss: 1.3621
Batch 120, Loss: 1.3376
Batch 130, Loss: 1.3193
Batch 140, Loss: 1.3148
Batch 150, Loss: 1.3592
Batch 160, Loss: 1.3447
Batch 170, Loss: 1.3378
Batch 180, Loss: 1.3268
Batch 190, Loss: 1.3955
Batch 200, Loss: 1.3276
Batch 210, Loss: 1.4081
Batch 220, Loss: 1.3231
Batch 230, Loss: 1.4037
Batch 240, Loss: 1.3568
Batch 250, Loss: 1.3900
Batch 260, Loss: 1.4217
Batch 270, Loss: 1.4488
Batch 280, Loss: 1.3693
Batch 290, Loss: 1.3217
Batch 300, Loss: 1.4851
Batch 310, Loss: 1.3718
Batch 320, Loss: 1.3258
Batch 330, Loss: 1.3588
Batch 340, Loss: 1.3453
Batch 350, Loss: 1.4122
Batch 360, Loss: 1.4045
Batch 370, Loss: 1.3874
Batch 380, Loss: 1.3658
Batch 390, Loss: 1.4405
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.138821363449097 seconds
Epoch 58 accuracy: 58.27%
Batch 10, Loss: 1.2788
Batch 20, Loss: 1.3528
Batch 30, Loss: 1.2771
Batch 40, Loss: 1.3610
Batch 50, Loss: 1.3090
Batch 60, Loss: 1.3851
Batch 70, Loss: 1.3993
Batch 80, Loss: 1.2958
Batch 90, Loss: 1.2995
Batch 100, Loss: 1.3756
Batch 110, Loss: 1.3377
Batch 120, Loss: 1.3283
Batch 130, Loss: 1.3738
Batch 140, Loss: 1.3411
Batch 150, Loss: 1.3588
Batch 160, Loss: 1.3839
Batch 170, Loss: 1.3331
Batch 180, Loss: 1.3937
Batch 190, Loss: 1.3922
Batch 200, Loss: 1.4188
Batch 210, Loss: 1.4297
Batch 220, Loss: 1.3487
Batch 230, Loss: 1.3537
Batch 240, Loss: 1.3660
Batch 250, Loss: 1.2697
Batch 260, Loss: 1.3637
Batch 270, Loss: 1.4109
Batch 280, Loss: 1.3066
Batch 290, Loss: 1.3399
Batch 300, Loss: 1.3980
Batch 310, Loss: 1.3771
Batch 320, Loss: 1.2880
Batch 330, Loss: 1.3540
Batch 340, Loss: 1.3397
Batch 350, Loss: 1.3206
Batch 360, Loss: 1.2952
Batch 370, Loss: 1.3700
Batch 380, Loss: 1.4421
Batch 390, Loss: 1.3941
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.333311319351196 seconds
Epoch 59 accuracy: 60.68%
Batch 10, Loss: 1.2643
Batch 20, Loss: 1.3324
Batch 30, Loss: 1.3244
Batch 40, Loss: 1.2920
Batch 50, Loss: 1.3356
Batch 60, Loss: 1.3717
Batch 70, Loss: 1.3143
Batch 80, Loss: 1.3261
Batch 90, Loss: 1.3497
Batch 100, Loss: 1.3126
Batch 110, Loss: 1.2704
Batch 120, Loss: 1.3458
Batch 130, Loss: 1.3358
Batch 140, Loss: 1.3150
Batch 150, Loss: 1.3826
Batch 160, Loss: 1.3514
Batch 170, Loss: 1.3784
Batch 180, Loss: 1.3546
Batch 190, Loss: 1.3322
Batch 200, Loss: 1.3143
Batch 210, Loss: 1.2507
Batch 220, Loss: 1.3412
Batch 230, Loss: 1.3353
Batch 240, Loss: 1.4128
Batch 250, Loss: 1.3557
Batch 260, Loss: 1.3859
Batch 270, Loss: 1.3966
Batch 280, Loss: 1.4365
Batch 290, Loss: 1.3608
Batch 300, Loss: 1.3166
Batch 310, Loss: 1.3442
Batch 320, Loss: 1.4227
Batch 330, Loss: 1.3589
Batch 340, Loss: 1.3692
Batch 350, Loss: 1.3539
Batch 360, Loss: 1.3773
Batch 370, Loss: 1.3585
Batch 380, Loss: 1.3430
Batch 390, Loss: 1.3190
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.14834761619568 seconds
Epoch 60 accuracy: 60.4%
Batch 10, Loss: 1.3339
Batch 20, Loss: 1.2761
Batch 30, Loss: 1.2812
Batch 40, Loss: 1.3763
Batch 50, Loss: 1.2736
Batch 60, Loss: 1.3284
Batch 70, Loss: 1.3373
Batch 80, Loss: 1.3305
Batch 90, Loss: 1.3131
Batch 100, Loss: 1.3294
Batch 110, Loss: 1.3825
Batch 120, Loss: 1.2112
Batch 130, Loss: 1.3589
Batch 140, Loss: 1.2629
Batch 150, Loss: 1.3837
Batch 160, Loss: 1.3083
Batch 170, Loss: 1.3706
Batch 180, Loss: 1.2983
Batch 190, Loss: 1.3321
Batch 200, Loss: 1.3759
Batch 210, Loss: 1.3680
Batch 220, Loss: 1.3447
Batch 230, Loss: 1.3654
Batch 240, Loss: 1.3313
Batch 250, Loss: 1.3132
Batch 260, Loss: 1.3492
Batch 270, Loss: 1.3607
Batch 280, Loss: 1.4266
Batch 290, Loss: 1.2750
Batch 300, Loss: 1.3567
Batch 310, Loss: 1.3618
Batch 320, Loss: 1.3108
Batch 330, Loss: 1.3171
Batch 340, Loss: 1.3852
Batch 350, Loss: 1.3978
Batch 360, Loss: 1.3799
Batch 370, Loss: 1.3393
Batch 380, Loss: 1.3159
Batch 390, Loss: 1.3575
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.221729040145874 seconds
Epoch 61 accuracy: 61.21%
Batch 10, Loss: 1.2542
Batch 20, Loss: 1.2766
Batch 30, Loss: 1.2327
Batch 40, Loss: 1.3028
Batch 50, Loss: 1.3498
Batch 60, Loss: 1.2854
Batch 70, Loss: 1.2334
Batch 80, Loss: 1.2713
Batch 90, Loss: 1.3366
Batch 100, Loss: 1.3140
Batch 110, Loss: 1.2941
Batch 120, Loss: 1.3151
Batch 130, Loss: 1.3172
Batch 140, Loss: 1.3380
Batch 150, Loss: 1.4051
Batch 160, Loss: 1.2756
Batch 170, Loss: 1.3621
Batch 180, Loss: 1.3362
Batch 190, Loss: 1.3116
Batch 200, Loss: 1.2754
Batch 210, Loss: 1.3106
Batch 220, Loss: 1.3326
Batch 230, Loss: 1.3830
Batch 240, Loss: 1.3704
Batch 250, Loss: 1.3548
Batch 260, Loss: 1.3747
Batch 270, Loss: 1.3973
Batch 280, Loss: 1.3449
Batch 290, Loss: 1.4243
Batch 300, Loss: 1.2944
Batch 310, Loss: 1.3549
Batch 320, Loss: 1.4112
Batch 330, Loss: 1.3578
Batch 340, Loss: 1.4323
Batch 350, Loss: 1.3505
Batch 360, Loss: 1.3599
Batch 370, Loss: 1.3456
Batch 380, Loss: 1.3963
Batch 390, Loss: 1.3542
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.160695552825928 seconds
Epoch 62 accuracy: 60.4%
Batch 10, Loss: 1.3133
Batch 20, Loss: 1.3105
Batch 30, Loss: 1.2584
Batch 40, Loss: 1.2880
Batch 50, Loss: 1.2731
Batch 60, Loss: 1.2591
Batch 70, Loss: 1.3053
Batch 80, Loss: 1.2980
Batch 90, Loss: 1.2675
Batch 100, Loss: 1.2950
Batch 110, Loss: 1.3085
Batch 120, Loss: 1.3213
Batch 130, Loss: 1.4005
Batch 140, Loss: 1.2922
Batch 150, Loss: 1.2836
Batch 160, Loss: 1.2854
Batch 170, Loss: 1.2929
Batch 180, Loss: 1.2995
Batch 190, Loss: 1.2710
Batch 200, Loss: 1.3393
Batch 210, Loss: 1.3605
Batch 220, Loss: 1.3540
Batch 230, Loss: 1.3521
Batch 240, Loss: 1.3483
Batch 250, Loss: 1.4440
Batch 260, Loss: 1.4149
Batch 270, Loss: 1.2822
Batch 280, Loss: 1.3412
Batch 290, Loss: 1.4204
Batch 300, Loss: 1.3770
Batch 310, Loss: 1.4494
Batch 320, Loss: 1.2939
Batch 330, Loss: 1.3095
Batch 340, Loss: 1.4028
Batch 350, Loss: 1.4166
Batch 360, Loss: 1.3276
Batch 370, Loss: 1.3167
Batch 380, Loss: 1.4139
Batch 390, Loss: 1.3758
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.13220524787903 seconds
Epoch 63 accuracy: 60.08%
Batch 10, Loss: 1.2589
Batch 20, Loss: 1.3677
Batch 30, Loss: 1.2809
Batch 40, Loss: 1.2348
Batch 50, Loss: 1.2240
Batch 60, Loss: 1.2494
Batch 70, Loss: 1.2219
Batch 80, Loss: 1.2514
Batch 90, Loss: 1.3812
Batch 100, Loss: 1.2485
Batch 110, Loss: 1.3303
Batch 120, Loss: 1.3598
Batch 130, Loss: 1.2337
Batch 140, Loss: 1.3223
Batch 150, Loss: 1.3055
Batch 160, Loss: 1.3651
Batch 170, Loss: 1.3295
Batch 180, Loss: 1.3220
Batch 190, Loss: 1.3436
Batch 200, Loss: 1.3376
Batch 210, Loss: 1.3006
Batch 220, Loss: 1.3823
Batch 230, Loss: 1.3570
Batch 240, Loss: 1.3340
Batch 250, Loss: 1.3122
Batch 260, Loss: 1.3356
Batch 270, Loss: 1.3659
Batch 280, Loss: 1.3277
Batch 290, Loss: 1.3267
Batch 300, Loss: 1.3746
Batch 310, Loss: 1.3234
Batch 320, Loss: 1.3967
Batch 330, Loss: 1.3162
Batch 340, Loss: 1.3447
Batch 350, Loss: 1.3667
Batch 360, Loss: 1.3530
Batch 370, Loss: 1.3737
Batch 380, Loss: 1.3326
Batch 390, Loss: 1.3109
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.29248285293579 seconds
Epoch 64 accuracy: 60.42%
Batch 10, Loss: 1.3024
Batch 20, Loss: 1.3054
Batch 30, Loss: 1.2925
Batch 40, Loss: 1.2905
Batch 50, Loss: 1.3034
Batch 60, Loss: 1.2983
Batch 70, Loss: 1.3085
Batch 80, Loss: 1.2363
Batch 90, Loss: 1.2725
Batch 100, Loss: 1.3231
Batch 110, Loss: 1.3280
Batch 120, Loss: 1.3124
Batch 130, Loss: 1.3528
Batch 140, Loss: 1.3386
Batch 150, Loss: 1.2971
Batch 160, Loss: 1.3362
Batch 170, Loss: 1.3244
Batch 180, Loss: 1.3962
Batch 190, Loss: 1.3034
Batch 200, Loss: 1.2938
Batch 210, Loss: 1.3273
Batch 220, Loss: 1.2746
Batch 230, Loss: 1.3052
Batch 240, Loss: 1.3435
Batch 250, Loss: 1.4239
Batch 260, Loss: 1.3603
Batch 270, Loss: 1.2900
Batch 280, Loss: 1.3469
Batch 290, Loss: 1.3242
Batch 300, Loss: 1.3156
Batch 310, Loss: 1.3182
Batch 320, Loss: 1.3714
Batch 330, Loss: 1.3314
Batch 340, Loss: 1.3588
Batch 350, Loss: 1.3607
Batch 360, Loss: 1.3563
Batch 370, Loss: 1.3718
Batch 380, Loss: 1.3375
Batch 390, Loss: 1.3720
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.266627311706543 seconds
Epoch 65 accuracy: 60.92%
Batch 10, Loss: 1.2712
Batch 20, Loss: 1.3581
Batch 30, Loss: 1.2308
Batch 40, Loss: 1.3101
Batch 50, Loss: 1.3259
Batch 60, Loss: 1.3055
Batch 70, Loss: 1.2925
Batch 80, Loss: 1.2823
Batch 90, Loss: 1.3736
Batch 100, Loss: 1.2758
Batch 110, Loss: 1.2927
Batch 120, Loss: 1.3109
Batch 130, Loss: 1.3032
Batch 140, Loss: 1.3032
Batch 150, Loss: 1.2582
Batch 160, Loss: 1.3314
Batch 170, Loss: 1.2598
Batch 180, Loss: 1.2585
Batch 190, Loss: 1.3644
Batch 200, Loss: 1.3548
Batch 210, Loss: 1.3844
Batch 220, Loss: 1.3263
Batch 230, Loss: 1.2978
Batch 240, Loss: 1.3099
Batch 250, Loss: 1.3205
Batch 260, Loss: 1.2978
Batch 270, Loss: 1.3403
Batch 280, Loss: 1.3274
Batch 290, Loss: 1.3310
Batch 300, Loss: 1.3595
Batch 310, Loss: 1.3147
Batch 320, Loss: 1.3916
Batch 330, Loss: 1.3232
Batch 340, Loss: 1.3124
Batch 350, Loss: 1.3158
Batch 360, Loss: 1.3671
Batch 370, Loss: 1.3732
Batch 380, Loss: 1.3144
Batch 390, Loss: 1.4040
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.088255882263184 seconds
Epoch 66 accuracy: 60.78%
Batch 10, Loss: 1.2298
Batch 20, Loss: 1.2389
Batch 30, Loss: 1.2291
Batch 40, Loss: 1.3168
Batch 50, Loss: 1.2960
Batch 60, Loss: 1.3014
Batch 70, Loss: 1.3508
Batch 80, Loss: 1.2510
Batch 90, Loss: 1.3022
Batch 100, Loss: 1.2743
Batch 110, Loss: 1.2654
Batch 120, Loss: 1.2903
Batch 130, Loss: 1.2761
Batch 140, Loss: 1.3493
Batch 150, Loss: 1.3899
Batch 160, Loss: 1.3630
Batch 170, Loss: 1.3269
Batch 180, Loss: 1.3819
Batch 190, Loss: 1.2928
Batch 200, Loss: 1.3183
Batch 210, Loss: 1.3558
Batch 220, Loss: 1.3519
Batch 230, Loss: 1.2829
Batch 240, Loss: 1.2391
Batch 250, Loss: 1.3165
Batch 260, Loss: 1.2887
Batch 270, Loss: 1.3359
Batch 280, Loss: 1.2731
Batch 290, Loss: 1.3225
Batch 300, Loss: 1.3694
Batch 310, Loss: 1.2792
Batch 320, Loss: 1.2773
Batch 330, Loss: 1.2842
Batch 340, Loss: 1.3024
Batch 350, Loss: 1.3458
Batch 360, Loss: 1.3335
Batch 370, Loss: 1.3849
Batch 380, Loss: 1.2678
Batch 390, Loss: 1.4004
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.221567153930664 seconds
Epoch 67 accuracy: 58.94%
Batch 10, Loss: 1.2782
Batch 20, Loss: 1.2771
Batch 30, Loss: 1.2345
Batch 40, Loss: 1.3279
Batch 50, Loss: 1.2865
Batch 60, Loss: 1.2932
Batch 70, Loss: 1.2830
Batch 80, Loss: 1.2912
Batch 90, Loss: 1.2712
Batch 100, Loss: 1.2971
Batch 110, Loss: 1.3029
Batch 120, Loss: 1.2433
Batch 130, Loss: 1.3203
Batch 140, Loss: 1.1828
Batch 150, Loss: 1.3148
Batch 160, Loss: 1.3723
Batch 170, Loss: 1.2446
Batch 180, Loss: 1.3422
Batch 190, Loss: 1.3004
Batch 200, Loss: 1.2798
Batch 210, Loss: 1.3591
Batch 220, Loss: 1.3231
Batch 230, Loss: 1.3200
Batch 240, Loss: 1.3800
Batch 250, Loss: 1.3073
Batch 260, Loss: 1.3495
Batch 270, Loss: 1.2949
Batch 280, Loss: 1.2775
Batch 290, Loss: 1.3623
Batch 300, Loss: 1.3752
Batch 310, Loss: 1.3026
Batch 320, Loss: 1.3665
Batch 330, Loss: 1.3382
Batch 340, Loss: 1.2990
Batch 350, Loss: 1.3426
Batch 360, Loss: 1.3158
Batch 370, Loss: 1.3006
Batch 380, Loss: 1.3386
Batch 390, Loss: 1.3419
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.356245517730713 seconds
Epoch 68 accuracy: 56.23%
Batch 10, Loss: 1.3239
Batch 20, Loss: 1.2805
Batch 30, Loss: 1.2912
Batch 40, Loss: 1.2937
Batch 50, Loss: 1.2632
Batch 60, Loss: 1.2151
Batch 70, Loss: 1.3133
Batch 80, Loss: 1.3174
Batch 90, Loss: 1.2150
Batch 100, Loss: 1.2288
Batch 110, Loss: 1.2901
Batch 120, Loss: 1.2894
Batch 130, Loss: 1.2319
Batch 140, Loss: 1.3435
Batch 150, Loss: 1.2693
Batch 160, Loss: 1.2851
Batch 170, Loss: 1.2997
Batch 180, Loss: 1.3359
Batch 190, Loss: 1.2793
Batch 200, Loss: 1.3382
Batch 210, Loss: 1.4297
Batch 220, Loss: 1.3296
Batch 230, Loss: 1.2689
Batch 240, Loss: 1.3526
Batch 250, Loss: 1.2805
Batch 260, Loss: 1.3198
Batch 270, Loss: 1.3248
Batch 280, Loss: 1.2758
Batch 290, Loss: 1.2275
Batch 300, Loss: 1.3172
Batch 310, Loss: 1.3440
Batch 320, Loss: 1.2763
Batch 330, Loss: 1.2919
Batch 340, Loss: 1.3464
Batch 350, Loss: 1.2818
Batch 360, Loss: 1.3514
Batch 370, Loss: 1.3002
Batch 380, Loss: 1.3386
Batch 390, Loss: 1.3071
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.11195969581604 seconds
Epoch 69 accuracy: 56.85%
Batch 10, Loss: 1.2161
Batch 20, Loss: 1.1862
Batch 30, Loss: 1.2284
Batch 40, Loss: 1.2656
Batch 50, Loss: 1.2416
Batch 60, Loss: 1.2209
Batch 70, Loss: 1.2590
Batch 80, Loss: 1.3491
Batch 90, Loss: 1.2394
Batch 100, Loss: 1.2830
Batch 110, Loss: 1.2631
Batch 120, Loss: 1.2228
Batch 130, Loss: 1.2540
Batch 140, Loss: 1.2586
Batch 150, Loss: 1.2736
Batch 160, Loss: 1.2829
Batch 170, Loss: 1.2358
Batch 180, Loss: 1.2932
Batch 190, Loss: 1.3131
Batch 200, Loss: 1.3322
Batch 210, Loss: 1.3058
Batch 220, Loss: 1.2752
Batch 230, Loss: 1.3253
Batch 240, Loss: 1.2544
Batch 250, Loss: 1.3072
Batch 260, Loss: 1.2239
Batch 270, Loss: 1.3363
Batch 280, Loss: 1.3668
Batch 290, Loss: 1.2539
Batch 300, Loss: 1.3608
Batch 310, Loss: 1.3694
Batch 320, Loss: 1.3744
Batch 330, Loss: 1.3836
Batch 340, Loss: 1.2925
Batch 350, Loss: 1.3414
Batch 360, Loss: 1.2994
Batch 370, Loss: 1.3440
Batch 380, Loss: 1.3136
Batch 390, Loss: 1.2611
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.136932849884033 seconds
Epoch 70 accuracy: 60.01%
Batch 10, Loss: 1.2283
Batch 20, Loss: 1.2429
Batch 30, Loss: 1.2792
Batch 40, Loss: 1.2751
Batch 50, Loss: 1.2871
Batch 60, Loss: 1.2489
Batch 70, Loss: 1.3124
Batch 80, Loss: 1.2566
Batch 90, Loss: 1.2277
Batch 100, Loss: 1.2376
Batch 110, Loss: 1.1875
Batch 120, Loss: 1.3213
Batch 130, Loss: 1.3306
Batch 140, Loss: 1.3511
Batch 150, Loss: 1.3071
Batch 160, Loss: 1.2665
Batch 170, Loss: 1.3002
Batch 180, Loss: 1.2371
Batch 190, Loss: 1.3198
Batch 200, Loss: 1.3088
Batch 210, Loss: 1.3444
Batch 220, Loss: 1.3597
Batch 230, Loss: 1.2975
Batch 240, Loss: 1.3123
Batch 250, Loss: 1.3230
Batch 260, Loss: 1.2212
Batch 270, Loss: 1.2849
Batch 280, Loss: 1.2904
Batch 290, Loss: 1.2635
Batch 300, Loss: 1.2805
Batch 310, Loss: 1.2388
Batch 320, Loss: 1.3100
Batch 330, Loss: 1.3017
Batch 340, Loss: 1.3005
Batch 350, Loss: 1.2497
Batch 360, Loss: 1.3261
Batch 370, Loss: 1.2866
Batch 380, Loss: 1.2596
Batch 390, Loss: 1.2431
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.248955488204956 seconds
Epoch 71 accuracy: 64.36%
Batch 10, Loss: 1.2107
Batch 20, Loss: 1.2197
Batch 30, Loss: 1.2283
Batch 40, Loss: 1.2237
Batch 50, Loss: 1.2518
Batch 60, Loss: 1.2598
Batch 70, Loss: 1.2985
Batch 80, Loss: 1.3050
Batch 90, Loss: 1.2619
Batch 100, Loss: 1.2573
Batch 110, Loss: 1.3239
Batch 120, Loss: 1.2487
Batch 130, Loss: 1.2882
Batch 140, Loss: 1.2767
Batch 150, Loss: 1.2515
Batch 160, Loss: 1.2336
Batch 170, Loss: 1.2866
Batch 180, Loss: 1.3173
Batch 190, Loss: 1.2529
Batch 200, Loss: 1.2597
Batch 210, Loss: 1.3328
Batch 220, Loss: 1.2911
Batch 230, Loss: 1.2872
Batch 240, Loss: 1.3288
Batch 250, Loss: 1.2771
Batch 260, Loss: 1.3158
Batch 270, Loss: 1.3013
Batch 280, Loss: 1.2809
Batch 290, Loss: 1.3124
Batch 300, Loss: 1.2986
Batch 310, Loss: 1.3290
Batch 320, Loss: 1.3088
Batch 330, Loss: 1.2725
Batch 340, Loss: 1.3135
Batch 350, Loss: 1.2518
Batch 360, Loss: 1.3260
Batch 370, Loss: 1.3131
Batch 380, Loss: 1.2719
Batch 390, Loss: 1.2660
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.322235822677612 seconds
Epoch 72 accuracy: 61.08%
Batch 10, Loss: 1.2303
Batch 20, Loss: 1.2116
Batch 30, Loss: 1.2129
Batch 40, Loss: 1.1844
Batch 50, Loss: 1.2394
Batch 60, Loss: 1.2378
Batch 70, Loss: 1.2479
Batch 80, Loss: 1.3017
Batch 90, Loss: 1.2763
Batch 100, Loss: 1.2486
Batch 110, Loss: 1.2349
Batch 120, Loss: 1.2844
Batch 130, Loss: 1.2593
Batch 140, Loss: 1.2613
Batch 150, Loss: 1.2547
Batch 160, Loss: 1.3218
Batch 170, Loss: 1.2555
Batch 180, Loss: 1.2896
Batch 190, Loss: 1.2665
Batch 200, Loss: 1.3368
Batch 210, Loss: 1.3103
Batch 220, Loss: 1.3505
Batch 230, Loss: 1.2854
Batch 240, Loss: 1.3375
Batch 250, Loss: 1.2526
Batch 260, Loss: 1.2736
Batch 270, Loss: 1.3154
Batch 280, Loss: 1.3468
Batch 290, Loss: 1.3237
Batch 300, Loss: 1.3186
Batch 310, Loss: 1.2657
Batch 320, Loss: 1.2785
Batch 330, Loss: 1.3334
Batch 340, Loss: 1.3520
Batch 350, Loss: 1.2839
Batch 360, Loss: 1.2611
Batch 370, Loss: 1.2784
Batch 380, Loss: 1.2956
Batch 390, Loss: 1.3045
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.245652198791504 seconds
Epoch 73 accuracy: 60.73%
Batch 10, Loss: 1.2565
Batch 20, Loss: 1.2639
Batch 30, Loss: 1.2750
Batch 40, Loss: 1.2692
Batch 50, Loss: 1.1998
Batch 60, Loss: 1.2476
Batch 70, Loss: 1.2197
Batch 80, Loss: 1.2438
Batch 90, Loss: 1.2784
Batch 100, Loss: 1.2115
Batch 110, Loss: 1.1684
Batch 120, Loss: 1.3058
Batch 130, Loss: 1.2898
Batch 140, Loss: 1.3302
Batch 150, Loss: 1.3310
Batch 160, Loss: 1.2812
Batch 170, Loss: 1.2339
Batch 180, Loss: 1.2479
Batch 190, Loss: 1.1922
Batch 200, Loss: 1.3426
Batch 210, Loss: 1.2496
Batch 220, Loss: 1.2538
Batch 230, Loss: 1.2657
Batch 240, Loss: 1.2942
Batch 250, Loss: 1.3397
Batch 260, Loss: 1.2783
Batch 270, Loss: 1.2956
Batch 280, Loss: 1.3445
Batch 290, Loss: 1.2523
Batch 300, Loss: 1.2569
Batch 310, Loss: 1.2714
Batch 320, Loss: 1.3229
Batch 330, Loss: 1.3401
Batch 340, Loss: 1.3247
Batch 350, Loss: 1.2736
Batch 360, Loss: 1.3570
Batch 370, Loss: 1.3772
Batch 380, Loss: 1.3009
Batch 390, Loss: 1.2580
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.2792067527771 seconds
Epoch 74 accuracy: 61.52%
Batch 10, Loss: 1.2381
Batch 20, Loss: 1.2629
Batch 30, Loss: 1.1608
Batch 40, Loss: 1.1725
Batch 50, Loss: 1.1669
Batch 60, Loss: 1.2632
Batch 70, Loss: 1.2324
Batch 80, Loss: 1.3384
Batch 90, Loss: 1.2099
Batch 100, Loss: 1.2705
Batch 110, Loss: 1.2886
Batch 120, Loss: 1.2237
Batch 130, Loss: 1.2875
Batch 140, Loss: 1.2748
Batch 150, Loss: 1.2894
Batch 160, Loss: 1.2611
Batch 170, Loss: 1.2997
Batch 180, Loss: 1.3114
Batch 190, Loss: 1.3497
Batch 200, Loss: 1.2249
Batch 210, Loss: 1.2768
Batch 220, Loss: 1.2878
Batch 230, Loss: 1.2988
Batch 240, Loss: 1.2908
Batch 250, Loss: 1.2286
Batch 260, Loss: 1.3104
Batch 270, Loss: 1.2820
Batch 280, Loss: 1.2850
Batch 290, Loss: 1.2831
Batch 300, Loss: 1.3357
Batch 310, Loss: 1.2619
Batch 320, Loss: 1.3071
Batch 330, Loss: 1.2144
Batch 340, Loss: 1.3432
Batch 350, Loss: 1.2354
Batch 360, Loss: 1.3233
Batch 370, Loss: 1.3112
Batch 380, Loss: 1.3501
Batch 390, Loss: 1.2855
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.579089403152466 seconds
Epoch 75 accuracy: 63.49%
Batch 10, Loss: 1.2272
Batch 20, Loss: 1.1954
Batch 30, Loss: 1.2424
Batch 40, Loss: 1.2181
Batch 50, Loss: 1.2106
Batch 60, Loss: 1.2719
Batch 70, Loss: 1.1996
Batch 80, Loss: 1.2270
Batch 90, Loss: 1.2029
Batch 100, Loss: 1.2137
Batch 110, Loss: 1.2995
Batch 120, Loss: 1.2348
Batch 130, Loss: 1.3178
Batch 140, Loss: 1.1996
Batch 150, Loss: 1.1920
Batch 160, Loss: 1.2644
Batch 170, Loss: 1.2492
Batch 180, Loss: 1.2699
Batch 190, Loss: 1.2451
Batch 200, Loss: 1.2084
Batch 210, Loss: 1.1810
Batch 220, Loss: 1.2987
Batch 230, Loss: 1.3053
Batch 240, Loss: 1.3503
Batch 250, Loss: 1.2433
Batch 260, Loss: 1.2407
Batch 270, Loss: 1.2995
Batch 280, Loss: 1.2819
Batch 290, Loss: 1.3696
Batch 300, Loss: 1.3269
Batch 310, Loss: 1.2653
Batch 320, Loss: 1.2220
Batch 330, Loss: 1.2591
Batch 340, Loss: 1.3302
Batch 350, Loss: 1.2729
Batch 360, Loss: 1.1921
Batch 370, Loss: 1.2615
Batch 380, Loss: 1.2920
Batch 390, Loss: 1.2856
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.31493306159973 seconds
Epoch 76 accuracy: 61.58%
Batch 10, Loss: 1.2122
Batch 20, Loss: 1.2357
Batch 30, Loss: 1.1697
Batch 40, Loss: 1.2683
Batch 50, Loss: 1.1718
Batch 60, Loss: 1.1640
Batch 70, Loss: 1.1944
Batch 80, Loss: 1.2567
Batch 90, Loss: 1.1731
Batch 100, Loss: 1.2030
Batch 110, Loss: 1.2101
Batch 120, Loss: 1.2484
Batch 130, Loss: 1.2429
Batch 140, Loss: 1.2866
Batch 150, Loss: 1.2721
Batch 160, Loss: 1.2568
Batch 170, Loss: 1.3143
Batch 180, Loss: 1.3077
Batch 190, Loss: 1.2578
Batch 200, Loss: 1.2132
Batch 210, Loss: 1.2225
Batch 220, Loss: 1.2859
Batch 230, Loss: 1.2721
Batch 240, Loss: 1.3117
Batch 250, Loss: 1.3209
Batch 260, Loss: 1.2423
Batch 270, Loss: 1.2485
Batch 280, Loss: 1.2389
Batch 290, Loss: 1.2391
Batch 300, Loss: 1.2639
Batch 310, Loss: 1.2833
Batch 320, Loss: 1.3181
Batch 330, Loss: 1.3032
Batch 340, Loss: 1.2935
Batch 350, Loss: 1.2818
Batch 360, Loss: 1.2737
Batch 370, Loss: 1.2758
Batch 380, Loss: 1.2641
Batch 390, Loss: 1.2677
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.34703230857849 seconds
Epoch 77 accuracy: 60.04%
Batch 10, Loss: 1.2352
Batch 20, Loss: 1.2309
Batch 30, Loss: 1.1901
Batch 40, Loss: 1.2474
Batch 50, Loss: 1.2054
Batch 60, Loss: 1.1408
Batch 70, Loss: 1.1516
Batch 80, Loss: 1.2453
Batch 90, Loss: 1.1984
Batch 100, Loss: 1.1707
Batch 110, Loss: 1.2314
Batch 120, Loss: 1.1668
Batch 130, Loss: 1.2859
Batch 140, Loss: 1.2814
Batch 150, Loss: 1.3039
Batch 160, Loss: 1.2108
Batch 170, Loss: 1.2658
Batch 180, Loss: 1.3172
Batch 190, Loss: 1.2769
Batch 200, Loss: 1.2150
Batch 210, Loss: 1.2291
Batch 220, Loss: 1.2497
Batch 230, Loss: 1.2198
Batch 240, Loss: 1.2567
Batch 250, Loss: 1.2528
Batch 260, Loss: 1.1744
Batch 270, Loss: 1.3161
Batch 280, Loss: 1.2473
Batch 290, Loss: 1.2386
Batch 300, Loss: 1.2311
Batch 310, Loss: 1.2654
Batch 320, Loss: 1.2252
Batch 330, Loss: 1.3233
Batch 340, Loss: 1.2612
Batch 350, Loss: 1.3031
Batch 360, Loss: 1.2404
Batch 370, Loss: 1.2346
Batch 380, Loss: 1.2561
Batch 390, Loss: 1.2901
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.2528018951416 seconds
Epoch 78 accuracy: 63.62%
Batch 10, Loss: 1.1901
Batch 20, Loss: 1.1757
Batch 30, Loss: 1.2030
Batch 40, Loss: 1.1696
Batch 50, Loss: 1.1574
Batch 60, Loss: 1.2480
Batch 70, Loss: 1.1807
Batch 80, Loss: 1.2504
Batch 90, Loss: 1.2917
Batch 100, Loss: 1.1753
Batch 110, Loss: 1.2285
Batch 120, Loss: 1.1826
Batch 130, Loss: 1.2419
Batch 140, Loss: 1.2794
Batch 150, Loss: 1.2617
Batch 160, Loss: 1.2853
Batch 170, Loss: 1.2834
Batch 180, Loss: 1.2287
Batch 190, Loss: 1.2961
Batch 200, Loss: 1.3142
Batch 210, Loss: 1.2380
Batch 220, Loss: 1.2870
Batch 230, Loss: 1.2165
Batch 240, Loss: 1.2423
Batch 250, Loss: 1.2243
Batch 260, Loss: 1.2106
Batch 270, Loss: 1.2416
Batch 280, Loss: 1.1847
Batch 290, Loss: 1.2548
Batch 300, Loss: 1.2275
Batch 310, Loss: 1.2266
Batch 320, Loss: 1.2331
Batch 330, Loss: 1.2710
Batch 340, Loss: 1.2281
Batch 350, Loss: 1.2938
Batch 360, Loss: 1.2886
Batch 370, Loss: 1.3257
Batch 380, Loss: 1.2581
Batch 390, Loss: 1.2944
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.0452778339386 seconds
Epoch 79 accuracy: 63.45%
Batch 10, Loss: 1.1564
Batch 20, Loss: 1.1148
Batch 30, Loss: 1.2338
Batch 40, Loss: 1.2209
Batch 50, Loss: 1.2349
Batch 60, Loss: 1.2620
Batch 70, Loss: 1.2116
Batch 80, Loss: 1.1790
Batch 90, Loss: 1.2645
Batch 100, Loss: 1.2247
Batch 110, Loss: 1.2171
Batch 120, Loss: 1.2727
Batch 130, Loss: 1.2290
Batch 140, Loss: 1.2215
Batch 150, Loss: 1.2189
Batch 160, Loss: 1.2123
Batch 170, Loss: 1.2547
Batch 180, Loss: 1.2411
Batch 190, Loss: 1.2736
Batch 200, Loss: 1.3261
Batch 210, Loss: 1.2558
Batch 220, Loss: 1.2037
Batch 230, Loss: 1.1793
Batch 240, Loss: 1.2064
Batch 250, Loss: 1.2057
Batch 260, Loss: 1.2493
Batch 270, Loss: 1.2494
Batch 280, Loss: 1.2114
Batch 290, Loss: 1.2840
Batch 300, Loss: 1.2720
Batch 310, Loss: 1.2241
Batch 320, Loss: 1.2527
Batch 330, Loss: 1.2634
Batch 340, Loss: 1.2086
Batch 350, Loss: 1.2365
Batch 360, Loss: 1.2445
Batch 370, Loss: 1.1950
Batch 380, Loss: 1.2575
Batch 390, Loss: 1.1807
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.103103399276733 seconds
Epoch 80 accuracy: 64.04%
Batch 10, Loss: 1.2000
Batch 20, Loss: 1.1557
Batch 30, Loss: 1.1884
Batch 40, Loss: 1.1677
Batch 50, Loss: 1.1980
Batch 60, Loss: 1.2017
Batch 70, Loss: 1.1825
Batch 80, Loss: 1.2408
Batch 90, Loss: 1.2219
Batch 100, Loss: 1.2122
Batch 110, Loss: 1.2487
Batch 120, Loss: 1.1471
Batch 130, Loss: 1.2082
Batch 140, Loss: 1.1850
Batch 150, Loss: 1.1698
Batch 160, Loss: 1.2111
Batch 170, Loss: 1.1860
Batch 180, Loss: 1.1993
Batch 190, Loss: 1.2435
Batch 200, Loss: 1.2040
Batch 210, Loss: 1.2532
Batch 220, Loss: 1.2066
Batch 230, Loss: 1.1995
Batch 240, Loss: 1.2902
Batch 250, Loss: 1.2097
Batch 260, Loss: 1.2305
Batch 270, Loss: 1.3075
Batch 280, Loss: 1.2161
Batch 290, Loss: 1.2390
Batch 300, Loss: 1.2469
Batch 310, Loss: 1.2264
Batch 320, Loss: 1.2445
Batch 330, Loss: 1.2625
Batch 340, Loss: 1.2183
Batch 350, Loss: 1.2369
Batch 360, Loss: 1.2423
Batch 370, Loss: 1.2026
Batch 380, Loss: 1.2808
Batch 390, Loss: 1.2138
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.144498825073242 seconds
Epoch 81 accuracy: 62.7%
Batch 10, Loss: 1.1761
Batch 20, Loss: 1.1618
Batch 30, Loss: 1.1334
Batch 40, Loss: 1.1886
Batch 50, Loss: 1.1735
Batch 60, Loss: 1.2041
Batch 70, Loss: 1.2233
Batch 80, Loss: 1.2486
Batch 90, Loss: 1.1934
Batch 100, Loss: 1.1370
Batch 110, Loss: 1.2390
Batch 120, Loss: 1.1468
Batch 130, Loss: 1.1676
Batch 140, Loss: 1.1004
Batch 150, Loss: 1.1729
Batch 160, Loss: 1.1858
Batch 170, Loss: 1.1902
Batch 180, Loss: 1.2280
Batch 190, Loss: 1.2121
Batch 200, Loss: 1.1716
Batch 210, Loss: 1.2644
Batch 220, Loss: 1.2191
Batch 230, Loss: 1.2519
Batch 240, Loss: 1.2727
Batch 250, Loss: 1.1966
Batch 260, Loss: 1.3142
Batch 270, Loss: 1.2476
Batch 280, Loss: 1.2319
Batch 290, Loss: 1.2262
Batch 300, Loss: 1.1756
Batch 310, Loss: 1.2349
Batch 320, Loss: 1.3261
Batch 330, Loss: 1.2505
Batch 340, Loss: 1.3105
Batch 350, Loss: 1.2930
Batch 360, Loss: 1.2254
Batch 370, Loss: 1.2899
Batch 380, Loss: 1.2720
Batch 390, Loss: 1.2323
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.12528085708618 seconds
Epoch 82 accuracy: 62.55%
Batch 10, Loss: 1.1745
Batch 20, Loss: 1.2453
Batch 30, Loss: 1.1978
Batch 40, Loss: 1.2028
Batch 50, Loss: 1.2019
Batch 60, Loss: 1.2081
Batch 70, Loss: 1.1990
Batch 80, Loss: 1.1902
Batch 90, Loss: 1.1337
Batch 100, Loss: 1.1526
Batch 110, Loss: 1.1676
Batch 120, Loss: 1.2173
Batch 130, Loss: 1.3096
Batch 140, Loss: 1.1698
Batch 150, Loss: 1.2470
Batch 160, Loss: 1.2004
Batch 170, Loss: 1.2112
Batch 180, Loss: 1.1478
Batch 190, Loss: 1.2031
Batch 200, Loss: 1.1997
Batch 210, Loss: 1.2227
Batch 220, Loss: 1.2666
Batch 230, Loss: 1.2478
Batch 240, Loss: 1.2583
Batch 250, Loss: 1.2265
Batch 260, Loss: 1.2232
Batch 270, Loss: 1.2212
Batch 280, Loss: 1.2363
Batch 290, Loss: 1.2108
Batch 300, Loss: 1.1895
Batch 310, Loss: 1.2059
Batch 320, Loss: 1.2933
Batch 330, Loss: 1.2810
Batch 340, Loss: 1.2553
Batch 350, Loss: 1.3152
Batch 360, Loss: 1.2129
Batch 370, Loss: 1.2557
Batch 380, Loss: 1.2723
Batch 390, Loss: 1.2265
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.269829511642456 seconds
Epoch 83 accuracy: 64.55%
Batch 10, Loss: 1.2062
Batch 20, Loss: 1.2027
Batch 30, Loss: 1.1631
Batch 40, Loss: 1.1262
Batch 50, Loss: 1.1176
Batch 60, Loss: 1.1001
Batch 70, Loss: 1.1906
Batch 80, Loss: 1.2203
Batch 90, Loss: 1.1859
Batch 100, Loss: 1.2321
Batch 110, Loss: 1.2204
Batch 120, Loss: 1.1719
Batch 130, Loss: 1.2114
Batch 140, Loss: 1.2584
Batch 150, Loss: 1.2507
Batch 160, Loss: 1.1896
Batch 170, Loss: 1.1922
Batch 180, Loss: 1.1650
Batch 190, Loss: 1.1967
Batch 200, Loss: 1.2079
Batch 210, Loss: 1.1665
Batch 220, Loss: 1.1986
Batch 230, Loss: 1.2196
Batch 240, Loss: 1.1630
Batch 250, Loss: 1.1738
Batch 260, Loss: 1.1929
Batch 270, Loss: 1.2571
Batch 280, Loss: 1.2323
Batch 290, Loss: 1.2702
Batch 300, Loss: 1.2071
Batch 310, Loss: 1.2764
Batch 320, Loss: 1.2037
Batch 330, Loss: 1.2044
Batch 340, Loss: 1.1950
Batch 350, Loss: 1.2132
Batch 360, Loss: 1.2511
Batch 370, Loss: 1.2656
Batch 380, Loss: 1.1915
Batch 390, Loss: 1.2941
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.174325227737427 seconds
Epoch 84 accuracy: 63.09%
Batch 10, Loss: 1.1530
Batch 20, Loss: 1.1842
Batch 30, Loss: 1.1193
Batch 40, Loss: 1.1243
Batch 50, Loss: 1.1536
Batch 60, Loss: 1.1547
Batch 70, Loss: 1.1669
Batch 80, Loss: 1.1473
Batch 90, Loss: 1.1370
Batch 100, Loss: 1.1476
Batch 110, Loss: 1.1948
Batch 120, Loss: 1.1949
Batch 130, Loss: 1.1820
Batch 140, Loss: 1.2013
Batch 150, Loss: 1.2459
Batch 160, Loss: 1.3093
Batch 170, Loss: 1.2484
Batch 180, Loss: 1.1915
Batch 190, Loss: 1.1792
Batch 200, Loss: 1.1385
Batch 210, Loss: 1.1981
Batch 220, Loss: 1.2062
Batch 230, Loss: 1.2173
Batch 240, Loss: 1.2970
Batch 250, Loss: 1.2962
Batch 260, Loss: 1.2782
Batch 270, Loss: 1.2380
Batch 280, Loss: 1.2241
Batch 290, Loss: 1.2877
Batch 300, Loss: 1.2554
Batch 310, Loss: 1.2187
Batch 320, Loss: 1.2397
Batch 330, Loss: 1.1491
Batch 340, Loss: 1.2212
Batch 350, Loss: 1.1641
Batch 360, Loss: 1.2094
Batch 370, Loss: 1.2418
Batch 380, Loss: 1.1796
Batch 390, Loss: 1.2566
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.268659591674805 seconds
Epoch 85 accuracy: 65.35%
Batch 10, Loss: 1.1576
Batch 20, Loss: 1.2060
Batch 30, Loss: 1.1401
Batch 40, Loss: 1.1807
Batch 50, Loss: 1.1628
Batch 60, Loss: 1.1883
Batch 70, Loss: 1.2201
Batch 80, Loss: 1.1529
Batch 90, Loss: 1.1259
Batch 100, Loss: 1.1743
Batch 110, Loss: 1.1777
Batch 120, Loss: 1.1635
Batch 130, Loss: 1.1243
Batch 140, Loss: 1.1829
Batch 150, Loss: 1.2322
Batch 160, Loss: 1.1724
Batch 170, Loss: 1.1984
Batch 180, Loss: 1.1878
Batch 190, Loss: 1.2253
Batch 200, Loss: 1.2011
Batch 210, Loss: 1.1858
Batch 220, Loss: 1.2033
Batch 230, Loss: 1.1656
Batch 240, Loss: 1.1996
Batch 250, Loss: 1.2242
Batch 260, Loss: 1.2166
Batch 270, Loss: 1.2316
Batch 280, Loss: 1.2077
Batch 290, Loss: 1.1568
Batch 300, Loss: 1.1674
Batch 310, Loss: 1.1474
Batch 320, Loss: 1.2286
Batch 330, Loss: 1.2261
Batch 340, Loss: 1.2187
Batch 350, Loss: 1.2655
Batch 360, Loss: 1.1930
Batch 370, Loss: 1.1839
Batch 380, Loss: 1.2239
Batch 390, Loss: 1.1586
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.268651723861694 seconds
Epoch 86 accuracy: 64.04%
Batch 10, Loss: 1.1394
Batch 20, Loss: 1.1278
Batch 30, Loss: 1.1354
Batch 40, Loss: 1.1552
Batch 50, Loss: 1.1397
Batch 60, Loss: 1.0933
Batch 70, Loss: 1.1273
Batch 80, Loss: 1.2451
Batch 90, Loss: 1.1900
Batch 100, Loss: 1.1554
Batch 110, Loss: 1.1952
Batch 120, Loss: 1.2476
Batch 130, Loss: 1.2202
Batch 140, Loss: 1.2000
Batch 150, Loss: 1.1911
Batch 160, Loss: 1.1986
Batch 170, Loss: 1.2132
Batch 180, Loss: 1.1765
Batch 190, Loss: 1.1637
Batch 200, Loss: 1.1934
Batch 210, Loss: 1.1791
Batch 220, Loss: 1.1839
Batch 230, Loss: 1.2444
Batch 240, Loss: 1.2270
Batch 250, Loss: 1.1140
Batch 260, Loss: 1.2292
Batch 270, Loss: 1.2425
Batch 280, Loss: 1.1769
Batch 290, Loss: 1.2434
Batch 300, Loss: 1.2374
Batch 310, Loss: 1.1751
Batch 320, Loss: 1.2697
Batch 330, Loss: 1.1701
Batch 340, Loss: 1.2654
Batch 350, Loss: 1.1801
Batch 360, Loss: 1.1555
Batch 370, Loss: 1.1929
Batch 380, Loss: 1.1634
Batch 390, Loss: 1.2853
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.286246299743652 seconds
Epoch 87 accuracy: 61.42%
Batch 10, Loss: 1.1490
Batch 20, Loss: 1.1415
Batch 30, Loss: 1.0960
Batch 40, Loss: 1.1676
Batch 50, Loss: 1.2079
Batch 60, Loss: 1.1243
Batch 70, Loss: 1.1636
Batch 80, Loss: 1.1211
Batch 90, Loss: 1.1696
Batch 100, Loss: 1.1162
Batch 110, Loss: 1.1506
Batch 120, Loss: 1.2227
Batch 130, Loss: 1.1244
Batch 140, Loss: 1.2174
Batch 150, Loss: 1.1836
Batch 160, Loss: 1.1559
Batch 170, Loss: 1.2067
Batch 180, Loss: 1.2306
Batch 190, Loss: 1.2194
Batch 200, Loss: 1.1252
Batch 210, Loss: 1.1789
Batch 220, Loss: 1.1659
Batch 230, Loss: 1.1758
Batch 240, Loss: 1.1501
Batch 250, Loss: 1.2009
Batch 260, Loss: 1.2230
Batch 270, Loss: 1.2240
Batch 280, Loss: 1.1627
Batch 290, Loss: 1.1816
Batch 300, Loss: 1.1969
Batch 310, Loss: 1.1803
Batch 320, Loss: 1.1750
Batch 330, Loss: 1.2214
Batch 340, Loss: 1.1391
Batch 350, Loss: 1.1684
Batch 360, Loss: 1.1886
Batch 370, Loss: 1.1908
Batch 380, Loss: 1.2823
Batch 390, Loss: 1.2001
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.086909532546997 seconds
Epoch 88 accuracy: 62.53%
Batch 10, Loss: 1.0831
Batch 20, Loss: 1.2135
Batch 30, Loss: 1.1047
Batch 40, Loss: 1.1067
Batch 50, Loss: 1.1668
Batch 60, Loss: 1.1206
Batch 70, Loss: 1.1758
Batch 80, Loss: 1.1372
Batch 90, Loss: 1.1361
Batch 100, Loss: 1.1389
Batch 110, Loss: 1.1172
Batch 120, Loss: 1.1510
Batch 130, Loss: 1.2141
Batch 140, Loss: 1.1704
Batch 150, Loss: 1.1590
Batch 160, Loss: 1.1799
Batch 170, Loss: 1.2758
Batch 180, Loss: 1.1569
Batch 190, Loss: 1.1861
Batch 200, Loss: 1.1930
Batch 210, Loss: 1.2149
Batch 220, Loss: 1.2772
Batch 230, Loss: 1.1480
Batch 240, Loss: 1.1928
Batch 250, Loss: 1.2023
Batch 260, Loss: 1.1848
Batch 270, Loss: 1.1948
Batch 280, Loss: 1.1807
Batch 290, Loss: 1.1835
Batch 300, Loss: 1.1883
Batch 310, Loss: 1.2031
Batch 320, Loss: 1.1707
Batch 330, Loss: 1.2203
Batch 340, Loss: 1.2348
Batch 350, Loss: 1.1611
Batch 360, Loss: 1.2561
Batch 370, Loss: 1.1926
Batch 380, Loss: 1.2312
Batch 390, Loss: 1.2844
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.151226043701172 seconds
Epoch 89 accuracy: 60.82%
Batch 10, Loss: 1.1348
Batch 20, Loss: 1.0919
Batch 30, Loss: 1.1397
Batch 40, Loss: 1.1213
Batch 50, Loss: 1.1276
Batch 60, Loss: 1.1676
Batch 70, Loss: 1.1769
Batch 80, Loss: 1.0927
Batch 90, Loss: 1.1092
Batch 100, Loss: 1.2199
Batch 110, Loss: 1.1860
Batch 120, Loss: 1.1581
Batch 130, Loss: 1.1613
Batch 140, Loss: 1.1974
Batch 150, Loss: 1.1778
Batch 160, Loss: 1.2221
Batch 170, Loss: 1.1913
Batch 180, Loss: 1.1522
Batch 190, Loss: 1.0988
Batch 200, Loss: 1.2283
Batch 210, Loss: 1.2060
Batch 220, Loss: 1.1676
Batch 230, Loss: 1.2168
Batch 240, Loss: 1.2299
Batch 250, Loss: 1.2104
Batch 260, Loss: 1.1361
Batch 270, Loss: 1.2004
Batch 280, Loss: 1.2207
Batch 290, Loss: 1.1716
Batch 300, Loss: 1.1714
Batch 310, Loss: 1.2069
Batch 320, Loss: 1.1529
Batch 330, Loss: 1.1338
Batch 340, Loss: 1.1781
Batch 350, Loss: 1.1669
Batch 360, Loss: 1.2499
Batch 370, Loss: 1.1939
Batch 380, Loss: 1.2072
Batch 390, Loss: 1.2027
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.198113203048706 seconds
Epoch 90 accuracy: 61.15%
Batch 10, Loss: 1.1291
Batch 20, Loss: 1.0697
Batch 30, Loss: 1.1573
Batch 40, Loss: 1.0938
Batch 50, Loss: 1.0972
Batch 60, Loss: 1.0737
Batch 70, Loss: 1.1260
Batch 80, Loss: 1.1392
Batch 90, Loss: 1.1856
Batch 100, Loss: 1.1533
Batch 110, Loss: 1.1652
Batch 120, Loss: 1.1713
Batch 130, Loss: 1.1614
Batch 140, Loss: 1.1204
Batch 150, Loss: 1.1616
Batch 160, Loss: 1.1473
Batch 170, Loss: 1.1107
Batch 180, Loss: 1.1564
Batch 190, Loss: 1.1444
Batch 200, Loss: 1.1840
Batch 210, Loss: 1.1374
Batch 220, Loss: 1.1201
Batch 230, Loss: 1.1431
Batch 240, Loss: 1.1270
Batch 250, Loss: 1.1191
Batch 260, Loss: 1.1716
Batch 270, Loss: 1.2129
Batch 280, Loss: 1.2303
Batch 290, Loss: 1.1777
Batch 300, Loss: 1.1441
Batch 310, Loss: 1.1781
Batch 320, Loss: 1.2090
Batch 330, Loss: 1.1755
Batch 340, Loss: 1.2346
Batch 350, Loss: 1.1522
Batch 360, Loss: 1.1510
Batch 370, Loss: 1.1518
Batch 380, Loss: 1.1612
Batch 390, Loss: 1.1754
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.124923944473267 seconds
Epoch 91 accuracy: 63.42%
Batch 10, Loss: 1.0857
Batch 20, Loss: 1.0566
Batch 30, Loss: 1.1716
Batch 40, Loss: 1.1185
Batch 50, Loss: 1.1208
Batch 60, Loss: 1.1394
Batch 70, Loss: 1.0945
Batch 80, Loss: 1.1106
Batch 90, Loss: 1.1597
Batch 100, Loss: 1.1283
Batch 110, Loss: 1.1603
Batch 120, Loss: 1.2203
Batch 130, Loss: 1.1057
Batch 140, Loss: 1.1793
Batch 150, Loss: 1.1215
Batch 160, Loss: 1.1530
Batch 170, Loss: 1.1398
Batch 180, Loss: 1.1543
Batch 190, Loss: 1.1869
Batch 200, Loss: 1.1941
Batch 210, Loss: 1.1428
Batch 220, Loss: 1.1170
Batch 230, Loss: 1.1834
Batch 240, Loss: 1.2063
Batch 250, Loss: 1.2836
Batch 260, Loss: 1.2450
Batch 270, Loss: 1.1576
Batch 280, Loss: 1.1573
Batch 290, Loss: 1.1967
Batch 300, Loss: 1.1448
Batch 310, Loss: 1.1528
Batch 320, Loss: 1.2168
Batch 330, Loss: 1.1527
Batch 340, Loss: 1.1244
Batch 350, Loss: 1.2487
Batch 360, Loss: 1.2135
Batch 370, Loss: 1.2301
Batch 380, Loss: 1.1818
Batch 390, Loss: 1.1763
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.19756317138672 seconds
Epoch 92 accuracy: 65.76%
Batch 10, Loss: 1.1247
Batch 20, Loss: 1.1005
Batch 30, Loss: 1.1173
Batch 40, Loss: 1.0704
Batch 50, Loss: 1.0845
Batch 60, Loss: 1.0640
Batch 70, Loss: 1.1415
Batch 80, Loss: 1.1263
Batch 90, Loss: 1.1403
Batch 100, Loss: 1.0881
Batch 110, Loss: 1.1378
Batch 120, Loss: 1.1413
Batch 130, Loss: 1.0496
Batch 140, Loss: 1.1374
Batch 150, Loss: 1.1342
Batch 160, Loss: 1.1658
Batch 170, Loss: 1.1303
Batch 180, Loss: 1.1706
Batch 190, Loss: 1.1421
Batch 200, Loss: 1.1411
Batch 210, Loss: 1.1440
Batch 220, Loss: 1.1741
Batch 230, Loss: 1.1131
Batch 240, Loss: 1.1612
Batch 250, Loss: 1.1711
Batch 260, Loss: 1.1879
Batch 270, Loss: 1.1776
Batch 280, Loss: 1.1430
Batch 290, Loss: 1.1190
Batch 300, Loss: 1.1858
Batch 310, Loss: 1.1407
Batch 320, Loss: 1.1257
Batch 330, Loss: 1.1983
Batch 340, Loss: 1.1725
Batch 350, Loss: 1.1762
Batch 360, Loss: 1.2014
Batch 370, Loss: 1.1564
Batch 380, Loss: 1.2006
Batch 390, Loss: 1.2586
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.243839502334595 seconds
Epoch 93 accuracy: 66.07%
Batch 10, Loss: 1.0586
Batch 20, Loss: 1.1293
Batch 30, Loss: 1.1077
Batch 40, Loss: 1.0240
Batch 50, Loss: 1.0718
Batch 60, Loss: 1.1425
Batch 70, Loss: 1.1340
Batch 80, Loss: 1.1399
Batch 90, Loss: 1.1711
Batch 100, Loss: 1.1555
Batch 110, Loss: 1.1006
Batch 120, Loss: 1.0954
Batch 130, Loss: 1.1542
Batch 140, Loss: 1.1206
Batch 150, Loss: 1.1334
Batch 160, Loss: 1.1265
Batch 170, Loss: 1.0789
Batch 180, Loss: 1.1630
Batch 190, Loss: 1.1797
Batch 200, Loss: 1.2164
Batch 210, Loss: 1.1412
Batch 220, Loss: 1.1572
Batch 230, Loss: 1.1260
Batch 240, Loss: 1.1476
Batch 250, Loss: 1.1649
Batch 260, Loss: 1.1575
Batch 270, Loss: 1.1735
Batch 280, Loss: 1.1321
Batch 290, Loss: 1.1477
Batch 300, Loss: 1.1048
Batch 310, Loss: 1.1403
Batch 320, Loss: 1.1537
Batch 330, Loss: 1.1774
Batch 340, Loss: 1.1582
Batch 350, Loss: 1.1319
Batch 360, Loss: 1.1667
Batch 370, Loss: 1.1772
Batch 380, Loss: 1.1795
Batch 390, Loss: 1.1787
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.233155965805054 seconds
Epoch 94 accuracy: 64.03%
Batch 10, Loss: 1.0759
Batch 20, Loss: 1.1318
Batch 30, Loss: 1.0897
Batch 40, Loss: 1.0495
Batch 50, Loss: 1.1013
Batch 60, Loss: 1.1191
Batch 70, Loss: 1.1774
Batch 80, Loss: 1.1024
Batch 90, Loss: 1.1315
Batch 100, Loss: 1.0745
Batch 110, Loss: 1.1196
Batch 120, Loss: 1.1259
Batch 130, Loss: 1.1689
Batch 140, Loss: 1.1103
Batch 150, Loss: 1.1254
Batch 160, Loss: 1.1546
Batch 170, Loss: 1.1312
Batch 180, Loss: 1.1652
Batch 190, Loss: 1.1372
Batch 200, Loss: 1.1216
Batch 210, Loss: 1.2195
Batch 220, Loss: 1.1553
Batch 230, Loss: 1.1538
Batch 240, Loss: 1.1589
Batch 250, Loss: 1.1238
Batch 260, Loss: 1.1388
Batch 270, Loss: 1.1145
Batch 280, Loss: 1.1586
Batch 290, Loss: 1.2078
Batch 300, Loss: 1.1965
Batch 310, Loss: 1.1653
Batch 320, Loss: 1.1013
Batch 330, Loss: 1.1817
Batch 340, Loss: 1.0755
Batch 350, Loss: 1.2048
Batch 360, Loss: 1.1884
Batch 370, Loss: 1.1728
Batch 380, Loss: 1.0915
Batch 390, Loss: 1.1622
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.238921880722046 seconds
Epoch 95 accuracy: 66.86%
Batch 10, Loss: 0.9964
Batch 20, Loss: 1.1185
Batch 30, Loss: 1.0222
Batch 40, Loss: 1.1039
Batch 50, Loss: 1.1004
Batch 60, Loss: 1.1714
Batch 70, Loss: 1.0560
Batch 80, Loss: 1.1112
Batch 90, Loss: 1.1401
Batch 100, Loss: 1.1028
Batch 110, Loss: 1.1444
Batch 120, Loss: 1.1272
Batch 130, Loss: 1.1403
Batch 140, Loss: 1.1796
Batch 150, Loss: 1.0899
Batch 160, Loss: 1.0968
Batch 170, Loss: 1.1233
Batch 180, Loss: 1.1449
Batch 190, Loss: 1.1672
Batch 200, Loss: 1.1033
Batch 210, Loss: 1.1296
Batch 220, Loss: 1.1500
Batch 230, Loss: 1.1320
Batch 240, Loss: 1.1554
Batch 250, Loss: 1.1814
Batch 260, Loss: 1.1530
Batch 270, Loss: 1.1690
Batch 280, Loss: 1.1525
Batch 290, Loss: 1.1382
Batch 300, Loss: 1.1614
Batch 310, Loss: 1.1436
Batch 320, Loss: 1.1404
Batch 330, Loss: 1.1208
Batch 340, Loss: 1.1121
Batch 350, Loss: 1.1220
Batch 360, Loss: 1.1803
Batch 370, Loss: 1.1018
Batch 380, Loss: 1.1421
Batch 390, Loss: 1.0500
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.289406299591064 seconds
Epoch 96 accuracy: 63.15%
Batch 10, Loss: 1.0872
Batch 20, Loss: 1.0074
Batch 30, Loss: 1.0497
Batch 40, Loss: 1.0766
Batch 50, Loss: 1.1025
Batch 60, Loss: 1.0820
Batch 70, Loss: 1.0918
Batch 80, Loss: 1.1123
Batch 90, Loss: 1.1145
Batch 100, Loss: 1.0955
Batch 110, Loss: 1.1456
Batch 120, Loss: 1.1158
Batch 130, Loss: 1.0614
Batch 140, Loss: 1.1163
Batch 150, Loss: 1.1242
Batch 160, Loss: 1.0989
Batch 170, Loss: 1.1090
Batch 180, Loss: 1.1445
Batch 190, Loss: 1.1426
Batch 200, Loss: 1.1292
Batch 210, Loss: 1.0764
Batch 220, Loss: 1.0710
Batch 230, Loss: 1.1276
Batch 240, Loss: 1.0831
Batch 250, Loss: 1.1158
Batch 260, Loss: 1.0638
Batch 270, Loss: 1.1820
Batch 280, Loss: 1.1479
Batch 290, Loss: 1.1504
Batch 300, Loss: 1.1291
Batch 310, Loss: 1.1665
Batch 320, Loss: 1.1436
Batch 330, Loss: 1.1231
Batch 340, Loss: 1.1362
Batch 350, Loss: 1.1619
Batch 360, Loss: 1.1068
Batch 370, Loss: 1.1200
Batch 380, Loss: 1.1499
Batch 390, Loss: 1.2211
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.313983917236328 seconds
Epoch 97 accuracy: 62.93%
Batch 10, Loss: 1.0577
Batch 20, Loss: 1.0464
Batch 30, Loss: 1.0300
Batch 40, Loss: 1.1217
Batch 50, Loss: 1.1258
Batch 60, Loss: 1.1101
Batch 70, Loss: 1.0937
Batch 80, Loss: 1.1277
Batch 90, Loss: 1.0314
Batch 100, Loss: 1.0575
Batch 110, Loss: 1.0938
Batch 120, Loss: 1.0717
Batch 130, Loss: 1.1114
Batch 140, Loss: 1.1069
Batch 150, Loss: 1.0603
Batch 160, Loss: 1.1413
Batch 170, Loss: 1.1262
Batch 180, Loss: 1.1560
Batch 190, Loss: 1.0860
Batch 200, Loss: 1.1375
Batch 210, Loss: 1.1191
Batch 220, Loss: 1.0930
Batch 230, Loss: 1.1628
Batch 240, Loss: 1.1508
Batch 250, Loss: 1.1509
Batch 260, Loss: 1.1358
Batch 270, Loss: 1.1460
Batch 280, Loss: 1.1447
Batch 290, Loss: 1.1591
Batch 300, Loss: 1.0912
Batch 310, Loss: 1.1443
Batch 320, Loss: 1.1661
Batch 330, Loss: 1.1758
Batch 340, Loss: 1.1007
Batch 350, Loss: 1.1332
Batch 360, Loss: 1.1554
Batch 370, Loss: 1.0922
Batch 380, Loss: 1.1116
Batch 390, Loss: 1.1323
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.277655601501465 seconds
Epoch 98 accuracy: 62.97%
Batch 10, Loss: 1.1219
Batch 20, Loss: 1.0799
Batch 30, Loss: 1.0814
Batch 40, Loss: 1.0884
Batch 50, Loss: 0.9891
Batch 60, Loss: 1.0758
Batch 70, Loss: 1.1104
Batch 80, Loss: 1.0791
Batch 90, Loss: 1.0984
Batch 100, Loss: 1.0868
Batch 110, Loss: 1.0670
Batch 120, Loss: 1.0647
Batch 130, Loss: 1.1151
Batch 140, Loss: 1.1325
Batch 150, Loss: 1.0584
Batch 160, Loss: 1.0910
Batch 170, Loss: 1.1623
Batch 180, Loss: 1.1446
Batch 190, Loss: 1.0938
Batch 200, Loss: 1.0712
Batch 210, Loss: 1.0893
Batch 220, Loss: 1.0507
Batch 230, Loss: 1.1001
Batch 240, Loss: 1.1113
Batch 250, Loss: 1.1484
Batch 260, Loss: 1.1323
Batch 270, Loss: 1.2060
Batch 280, Loss: 1.1735
Batch 290, Loss: 1.1041
Batch 300, Loss: 1.0856
Batch 310, Loss: 1.0772
Batch 320, Loss: 1.1463
Batch 330, Loss: 1.1832
Batch 340, Loss: 1.0539
Batch 350, Loss: 1.0459
Batch 360, Loss: 1.1320
Batch 370, Loss: 1.1002
Batch 380, Loss: 1.1206
Batch 390, Loss: 1.1444
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.2437527179718 seconds
Epoch 99 accuracy: 63.74%
Batch 10, Loss: 1.0273
Batch 20, Loss: 1.0787
Batch 30, Loss: 1.0136
Batch 40, Loss: 1.0445
Batch 50, Loss: 1.0551
Batch 60, Loss: 1.0525
Batch 70, Loss: 1.0622
Batch 80, Loss: 1.0622
Batch 90, Loss: 1.0826
Batch 100, Loss: 1.0592
Batch 110, Loss: 1.1453
Batch 120, Loss: 1.0718
Batch 130, Loss: 1.1180
Batch 140, Loss: 1.1159
Batch 150, Loss: 1.1705
Batch 160, Loss: 1.1047
Batch 170, Loss: 1.0667
Batch 180, Loss: 1.1618
Batch 190, Loss: 1.1379
Batch 200, Loss: 1.0838
Batch 210, Loss: 1.0969
Batch 220, Loss: 1.0408
Batch 230, Loss: 1.1058
Batch 240, Loss: 1.0968
Batch 250, Loss: 1.0453
Batch 260, Loss: 1.0884
Batch 270, Loss: 1.1881
Batch 280, Loss: 1.1141
Batch 290, Loss: 1.1289
Batch 300, Loss: 1.0666
Batch 310, Loss: 1.1348
Batch 320, Loss: 1.0699
Batch 330, Loss: 1.1473
Batch 340, Loss: 1.0969
Batch 350, Loss: 1.1108
Batch 360, Loss: 1.1374
Batch 370, Loss: 1.1544
Batch 380, Loss: 1.1266
Batch 390, Loss: 1.1681
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.18402934074402 seconds
Epoch 100 accuracy: 64.29%
Batch 10, Loss: 1.0756
Batch 20, Loss: 1.0470
Batch 30, Loss: 1.0497
Batch 40, Loss: 1.0715
Batch 50, Loss: 1.0175
Batch 60, Loss: 1.1162
Batch 70, Loss: 1.0381
Batch 80, Loss: 1.0921
Batch 90, Loss: 1.0432
Batch 100, Loss: 1.0392
Batch 110, Loss: 1.0690
Batch 120, Loss: 1.0676
Batch 130, Loss: 1.0956
Batch 140, Loss: 1.0860
Batch 150, Loss: 1.0661
Batch 160, Loss: 1.1110
Batch 170, Loss: 1.1547
Batch 180, Loss: 1.1539
Batch 190, Loss: 1.0792
Batch 200, Loss: 1.1208
Batch 210, Loss: 1.0837
Batch 220, Loss: 1.1210
Batch 230, Loss: 1.0611
Batch 240, Loss: 1.0773
Batch 250, Loss: 1.0926
Batch 260, Loss: 1.1420
Batch 270, Loss: 1.1211
Batch 280, Loss: 1.0867
Batch 290, Loss: 1.0666
Batch 300, Loss: 1.0805
Batch 310, Loss: 1.1253
Batch 320, Loss: 1.1070
Batch 330, Loss: 1.0885
Batch 340, Loss: 1.1391
Batch 350, Loss: 1.1685
Batch 360, Loss: 1.1320
Batch 370, Loss: 1.0648
Batch 380, Loss: 1.1011
Batch 390, Loss: 1.1703
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.277684450149536 seconds
Epoch 101 accuracy: 67.02%
Batch 10, Loss: 1.0801
Batch 20, Loss: 1.0346
Batch 30, Loss: 1.0981
Batch 40, Loss: 1.0483
Batch 50, Loss: 1.0821
Batch 60, Loss: 1.0425
Batch 70, Loss: 1.0460
Batch 80, Loss: 1.0541
Batch 90, Loss: 1.1294
Batch 100, Loss: 1.0939
Batch 110, Loss: 1.0690
Batch 120, Loss: 1.0689
Batch 130, Loss: 1.0429
Batch 140, Loss: 1.0605
Batch 150, Loss: 1.0477
Batch 160, Loss: 1.0597
Batch 170, Loss: 1.1033
Batch 180, Loss: 1.0783
Batch 190, Loss: 1.0405
Batch 200, Loss: 1.1603
Batch 210, Loss: 1.0852
Batch 220, Loss: 1.1092
Batch 230, Loss: 1.1538
Batch 240, Loss: 1.0740
Batch 250, Loss: 1.0455
Batch 260, Loss: 1.0528
Batch 270, Loss: 1.1277
Batch 280, Loss: 1.0404
Batch 290, Loss: 1.0831
Batch 300, Loss: 1.1505
Batch 310, Loss: 1.1137
Batch 320, Loss: 1.1048
Batch 330, Loss: 1.0931
Batch 340, Loss: 1.1349
Batch 350, Loss: 1.0763
Batch 360, Loss: 1.1183
Batch 370, Loss: 1.1149
Batch 380, Loss: 1.1110
Batch 390, Loss: 1.1448
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.12147855758667 seconds
Epoch 102 accuracy: 66.94%
Batch 10, Loss: 1.0292
Batch 20, Loss: 1.0279
Batch 30, Loss: 1.0472
Batch 40, Loss: 0.9991
Batch 50, Loss: 1.0364
Batch 60, Loss: 1.0406
Batch 70, Loss: 1.0128
Batch 80, Loss: 1.1205
Batch 90, Loss: 1.1173
Batch 100, Loss: 1.0671
Batch 110, Loss: 1.0955
Batch 120, Loss: 1.0476
Batch 130, Loss: 1.0051
Batch 140, Loss: 1.0556
Batch 150, Loss: 0.9780
Batch 160, Loss: 1.0682
Batch 170, Loss: 1.1168
Batch 180, Loss: 1.0568
Batch 190, Loss: 1.0773
Batch 200, Loss: 1.1005
Batch 210, Loss: 1.0923
Batch 220, Loss: 1.1259
Batch 230, Loss: 1.0823
Batch 240, Loss: 1.0912
Batch 250, Loss: 1.1084
Batch 260, Loss: 1.0502
Batch 270, Loss: 1.0722
Batch 280, Loss: 1.1002
Batch 290, Loss: 1.0542
Batch 300, Loss: 1.0574
Batch 310, Loss: 1.1374
Batch 320, Loss: 1.1288
Batch 330, Loss: 1.0762
Batch 340, Loss: 1.0802
Batch 350, Loss: 1.1171
Batch 360, Loss: 1.0864
Batch 370, Loss: 1.1323
Batch 380, Loss: 1.0921
Batch 390, Loss: 1.1246
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.12396740913391 seconds
Epoch 103 accuracy: 67.24%
Batch 10, Loss: 1.0480
Batch 20, Loss: 1.0877
Batch 30, Loss: 1.0065
Batch 40, Loss: 1.0312
Batch 50, Loss: 0.9541
Batch 60, Loss: 1.0152
Batch 70, Loss: 1.0255
Batch 80, Loss: 1.0303
Batch 90, Loss: 1.0031
Batch 100, Loss: 1.0394
Batch 110, Loss: 1.0633
Batch 120, Loss: 1.0109
Batch 130, Loss: 1.0275
Batch 140, Loss: 1.0554
Batch 150, Loss: 1.0451
Batch 160, Loss: 1.0725
Batch 170, Loss: 1.0120
Batch 180, Loss: 1.0612
Batch 190, Loss: 1.0746
Batch 200, Loss: 1.0316
Batch 210, Loss: 1.0279
Batch 220, Loss: 1.1070
Batch 230, Loss: 1.0326
Batch 240, Loss: 1.0440
Batch 250, Loss: 1.0535
Batch 260, Loss: 1.0695
Batch 270, Loss: 1.0715
Batch 280, Loss: 1.0563
Batch 290, Loss: 1.1623
Batch 300, Loss: 1.1354
Batch 310, Loss: 1.1649
Batch 320, Loss: 1.0837
Batch 330, Loss: 1.1166
Batch 340, Loss: 1.1188
Batch 350, Loss: 1.0693
Batch 360, Loss: 1.1076
Batch 370, Loss: 1.1255
Batch 380, Loss: 1.0852
Batch 390, Loss: 1.0777
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.209551572799683 seconds
Epoch 104 accuracy: 66.74%
Batch 10, Loss: 0.9902
Batch 20, Loss: 1.0500
Batch 30, Loss: 1.0363
Batch 40, Loss: 0.9531
Batch 50, Loss: 1.0302
Batch 60, Loss: 1.0123
Batch 70, Loss: 1.0203
Batch 80, Loss: 1.0594
Batch 90, Loss: 1.0130
Batch 100, Loss: 0.9927
Batch 110, Loss: 1.0470
Batch 120, Loss: 1.0815
Batch 130, Loss: 0.9790
Batch 140, Loss: 1.0891
Batch 150, Loss: 1.0798
Batch 160, Loss: 1.0257
Batch 170, Loss: 1.0329
Batch 180, Loss: 1.0508
Batch 190, Loss: 1.0174
Batch 200, Loss: 1.1132
Batch 210, Loss: 1.0430
Batch 220, Loss: 1.0376
Batch 230, Loss: 1.0726
Batch 240, Loss: 1.0530
Batch 250, Loss: 1.0828
Batch 260, Loss: 1.1088
Batch 270, Loss: 1.0587
Batch 280, Loss: 1.0767
Batch 290, Loss: 1.1099
Batch 300, Loss: 1.1089
Batch 310, Loss: 1.0575
Batch 320, Loss: 1.0577
Batch 330, Loss: 1.1170
Batch 340, Loss: 1.0214
Batch 350, Loss: 1.0576
Batch 360, Loss: 1.1036
Batch 370, Loss: 1.0884
Batch 380, Loss: 1.0585
Batch 390, Loss: 1.0343
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.072830200195312 seconds
Epoch 105 accuracy: 62.33%
Batch 10, Loss: 1.0458
Batch 20, Loss: 1.0776
Batch 30, Loss: 1.0471
Batch 40, Loss: 0.9924
Batch 50, Loss: 0.9864
Batch 60, Loss: 1.0360
Batch 70, Loss: 0.9930
Batch 80, Loss: 0.9903
Batch 90, Loss: 0.9876
Batch 100, Loss: 1.0261
Batch 110, Loss: 1.0192
Batch 120, Loss: 1.0686
Batch 130, Loss: 0.9927
Batch 140, Loss: 0.9836
Batch 150, Loss: 1.0390
Batch 160, Loss: 1.0395
Batch 170, Loss: 1.0141
Batch 180, Loss: 1.1213
Batch 190, Loss: 1.1074
Batch 200, Loss: 0.9891
Batch 210, Loss: 1.0755
Batch 220, Loss: 1.1103
Batch 230, Loss: 1.0844
Batch 240, Loss: 1.0591
Batch 250, Loss: 1.0729
Batch 260, Loss: 1.0272
Batch 270, Loss: 1.0315
Batch 280, Loss: 1.0556
Batch 290, Loss: 1.0708
Batch 300, Loss: 1.0928
Batch 310, Loss: 1.0660
Batch 320, Loss: 0.9943
Batch 330, Loss: 1.0682
Batch 340, Loss: 1.1460
Batch 350, Loss: 1.1013
Batch 360, Loss: 1.0797
Batch 370, Loss: 1.1231
Batch 380, Loss: 1.1018
Batch 390, Loss: 1.0789
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.194255828857422 seconds
Epoch 106 accuracy: 66.36%
Batch 10, Loss: 1.0021
Batch 20, Loss: 0.9991
Batch 30, Loss: 0.9848
Batch 40, Loss: 1.0335
Batch 50, Loss: 0.9900
Batch 60, Loss: 1.0206
Batch 70, Loss: 0.9826
Batch 80, Loss: 1.0159
Batch 90, Loss: 0.9753
Batch 100, Loss: 1.0808
Batch 110, Loss: 0.9829
Batch 120, Loss: 0.9909
Batch 130, Loss: 0.9963
Batch 140, Loss: 1.0475
Batch 150, Loss: 1.0478
Batch 160, Loss: 1.0540
Batch 170, Loss: 1.0732
Batch 180, Loss: 1.0174
Batch 190, Loss: 0.9727
Batch 200, Loss: 1.0710
Batch 210, Loss: 1.0735
Batch 220, Loss: 1.0466
Batch 230, Loss: 1.0339
Batch 240, Loss: 1.0294
Batch 250, Loss: 1.0402
Batch 260, Loss: 1.0912
Batch 270, Loss: 1.0941
Batch 280, Loss: 1.0394
Batch 290, Loss: 1.0871
Batch 300, Loss: 1.0808
Batch 310, Loss: 1.0576
Batch 320, Loss: 1.0104
Batch 330, Loss: 1.0675
Batch 340, Loss: 1.0797
Batch 350, Loss: 1.0929
Batch 360, Loss: 1.1054
Batch 370, Loss: 1.1113
Batch 380, Loss: 1.0631
Batch 390, Loss: 1.0461
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.12455654144287 seconds
Epoch 107 accuracy: 67.85%
Batch 10, Loss: 0.9749
Batch 20, Loss: 0.9831
Batch 30, Loss: 1.0377
Batch 40, Loss: 0.9630
Batch 50, Loss: 0.9680
Batch 60, Loss: 1.0212
Batch 70, Loss: 1.0148
Batch 80, Loss: 0.9993
Batch 90, Loss: 0.9686
Batch 100, Loss: 1.0668
Batch 110, Loss: 1.0055
Batch 120, Loss: 1.0285
Batch 130, Loss: 1.0361
Batch 140, Loss: 0.9974
Batch 150, Loss: 1.0711
Batch 160, Loss: 1.0757
Batch 170, Loss: 1.0099
Batch 180, Loss: 1.0109
Batch 190, Loss: 1.0773
Batch 200, Loss: 1.0612
Batch 210, Loss: 1.0913
Batch 220, Loss: 1.0177
Batch 230, Loss: 0.9496
Batch 240, Loss: 0.9829
Batch 250, Loss: 1.0547
Batch 260, Loss: 1.0229
Batch 270, Loss: 1.0241
Batch 280, Loss: 1.0843
Batch 290, Loss: 1.0232
Batch 300, Loss: 1.0349
Batch 310, Loss: 1.0688
Batch 320, Loss: 1.0733
Batch 330, Loss: 1.0929
Batch 340, Loss: 1.0346
Batch 350, Loss: 1.1194
Batch 360, Loss: 1.0811
Batch 370, Loss: 1.0705
Batch 380, Loss: 1.0478
Batch 390, Loss: 1.0401
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.089425563812256 seconds
Epoch 108 accuracy: 67.78%
Batch 10, Loss: 0.9842
Batch 20, Loss: 0.9785
Batch 30, Loss: 0.9708
Batch 40, Loss: 1.0071
Batch 50, Loss: 0.9722
Batch 60, Loss: 1.0280
Batch 70, Loss: 1.0371
Batch 80, Loss: 1.0022
Batch 90, Loss: 1.0070
Batch 100, Loss: 1.0426
Batch 110, Loss: 1.0804
Batch 120, Loss: 1.0506
Batch 130, Loss: 0.9539
Batch 140, Loss: 1.0093
Batch 150, Loss: 1.0670
Batch 160, Loss: 1.0215
Batch 170, Loss: 0.9817
Batch 180, Loss: 1.0115
Batch 190, Loss: 1.0008
Batch 200, Loss: 0.9678
Batch 210, Loss: 1.0077
Batch 220, Loss: 1.0354
Batch 230, Loss: 1.0514
Batch 240, Loss: 1.0646
Batch 250, Loss: 1.1159
Batch 260, Loss: 1.0345
Batch 270, Loss: 1.0252
Batch 280, Loss: 1.0494
Batch 290, Loss: 1.0486
Batch 300, Loss: 1.0464
Batch 310, Loss: 1.0353
Batch 320, Loss: 1.0204
Batch 330, Loss: 1.1215
Batch 340, Loss: 1.0692
Batch 350, Loss: 1.0922
Batch 360, Loss: 1.0312
Batch 370, Loss: 1.0505
Batch 380, Loss: 1.0193
Batch 390, Loss: 1.0099
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.243921756744385 seconds
Epoch 109 accuracy: 67.12%
Batch 10, Loss: 0.9728
Batch 20, Loss: 0.9800
Batch 30, Loss: 0.9247
Batch 40, Loss: 0.9652
Batch 50, Loss: 0.9496
Batch 60, Loss: 0.9924
Batch 70, Loss: 0.9980
Batch 80, Loss: 1.0100
Batch 90, Loss: 1.0022
Batch 100, Loss: 0.9809
Batch 110, Loss: 0.9965
Batch 120, Loss: 0.9872
Batch 130, Loss: 1.0234
Batch 140, Loss: 0.9737
Batch 150, Loss: 0.9657
Batch 160, Loss: 1.0133
Batch 170, Loss: 0.9702
Batch 180, Loss: 0.9918
Batch 190, Loss: 0.9834
Batch 200, Loss: 0.9506
Batch 210, Loss: 1.0122
Batch 220, Loss: 1.0129
Batch 230, Loss: 1.0204
Batch 240, Loss: 1.0798
Batch 250, Loss: 1.0249
Batch 260, Loss: 1.0451
Batch 270, Loss: 1.0835
Batch 280, Loss: 1.0053
Batch 290, Loss: 0.9152
Batch 300, Loss: 1.0148
Batch 310, Loss: 1.0457
Batch 320, Loss: 1.0954
Batch 330, Loss: 1.0422
Batch 340, Loss: 1.0199
Batch 350, Loss: 1.0504
Batch 360, Loss: 1.0839
Batch 370, Loss: 1.0703
Batch 380, Loss: 1.0616
Batch 390, Loss: 1.0867
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.231080770492554 seconds
Epoch 110 accuracy: 68.43%
Batch 10, Loss: 0.9778
Batch 20, Loss: 0.9989
Batch 30, Loss: 1.0114
Batch 40, Loss: 0.9791
Batch 50, Loss: 0.9396
Batch 60, Loss: 1.0149
Batch 70, Loss: 0.9635
Batch 80, Loss: 0.9568
Batch 90, Loss: 0.9900
Batch 100, Loss: 0.9812
Batch 110, Loss: 0.9866
Batch 120, Loss: 1.0178
Batch 130, Loss: 1.0034
Batch 140, Loss: 1.0318
Batch 150, Loss: 1.0874
Batch 160, Loss: 1.0182
Batch 170, Loss: 0.9683
Batch 180, Loss: 0.9907
Batch 190, Loss: 1.0023
Batch 200, Loss: 0.9905
Batch 210, Loss: 0.9854
Batch 220, Loss: 0.9857
Batch 230, Loss: 1.0376
Batch 240, Loss: 1.0154
Batch 250, Loss: 0.9956
Batch 260, Loss: 1.0096
Batch 270, Loss: 1.0260
Batch 280, Loss: 1.0135
Batch 290, Loss: 1.0375
Batch 300, Loss: 1.0364
Batch 310, Loss: 1.0331
Batch 320, Loss: 1.0354
Batch 330, Loss: 1.0345
Batch 340, Loss: 1.0563
Batch 350, Loss: 1.0477
Batch 360, Loss: 1.0145
Batch 370, Loss: 1.0357
Batch 380, Loss: 0.9828
Batch 390, Loss: 1.0156
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.273563623428345 seconds
Epoch 111 accuracy: 69.11%
Batch 10, Loss: 0.9553
Batch 20, Loss: 0.9553
Batch 30, Loss: 0.9072
Batch 40, Loss: 0.9790
Batch 50, Loss: 1.0111
Batch 60, Loss: 1.0131
Batch 70, Loss: 0.9145
Batch 80, Loss: 1.0034
Batch 90, Loss: 0.9714
Batch 100, Loss: 0.9505
Batch 110, Loss: 0.9849
Batch 120, Loss: 0.9444
Batch 130, Loss: 0.9216
Batch 140, Loss: 0.9917
Batch 150, Loss: 0.9771
Batch 160, Loss: 1.0170
Batch 170, Loss: 1.0964
Batch 180, Loss: 1.0153
Batch 190, Loss: 1.0374
Batch 200, Loss: 1.0050
Batch 210, Loss: 1.0035
Batch 220, Loss: 1.0224
Batch 230, Loss: 1.0196
Batch 240, Loss: 0.9616
Batch 250, Loss: 0.9370
Batch 260, Loss: 1.0182
Batch 270, Loss: 1.0667
Batch 280, Loss: 1.0420
Batch 290, Loss: 0.9870
Batch 300, Loss: 1.0170
Batch 310, Loss: 1.0573
Batch 320, Loss: 1.0272
Batch 330, Loss: 1.0145
Batch 340, Loss: 1.0031
Batch 350, Loss: 1.1029
Batch 360, Loss: 1.0302
Batch 370, Loss: 1.0348
Batch 380, Loss: 1.0489
Batch 390, Loss: 1.0055
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.199642419815063 seconds
Epoch 112 accuracy: 65.87%
Batch 10, Loss: 0.9442
Batch 20, Loss: 0.9705
Batch 30, Loss: 0.9016
Batch 40, Loss: 0.9549
Batch 50, Loss: 0.9412
Batch 60, Loss: 0.9600
Batch 70, Loss: 0.9825
Batch 80, Loss: 0.9918
Batch 90, Loss: 1.0217
Batch 100, Loss: 0.9496
Batch 110, Loss: 0.8738
Batch 120, Loss: 0.9638
Batch 130, Loss: 0.9320
Batch 140, Loss: 0.9833
Batch 150, Loss: 1.0326
Batch 160, Loss: 1.0191
Batch 170, Loss: 0.9997
Batch 180, Loss: 1.0137
Batch 190, Loss: 1.0198
Batch 200, Loss: 0.9821
Batch 210, Loss: 1.0287
Batch 220, Loss: 1.0144
Batch 230, Loss: 0.9469
Batch 240, Loss: 1.0078
Batch 250, Loss: 1.0496
Batch 260, Loss: 1.0489
Batch 270, Loss: 0.9929
Batch 280, Loss: 1.0083
Batch 290, Loss: 0.9879
Batch 300, Loss: 0.9843
Batch 310, Loss: 0.9612
Batch 320, Loss: 1.1016
Batch 330, Loss: 1.0115
Batch 340, Loss: 1.0497
Batch 350, Loss: 1.0375
Batch 360, Loss: 1.0177
Batch 370, Loss: 1.0162
Batch 380, Loss: 1.0224
Batch 390, Loss: 1.0154
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.119099140167236 seconds
Epoch 113 accuracy: 68.84%
Batch 10, Loss: 0.9512
Batch 20, Loss: 0.9640
Batch 30, Loss: 0.9360
Batch 40, Loss: 0.9471
Batch 50, Loss: 0.9432
Batch 60, Loss: 0.9556
Batch 70, Loss: 0.9449
Batch 80, Loss: 0.9718
Batch 90, Loss: 0.9668
Batch 100, Loss: 0.9544
Batch 110, Loss: 0.9476
Batch 120, Loss: 0.9334
Batch 130, Loss: 1.0023
Batch 140, Loss: 0.9521
Batch 150, Loss: 0.9941
Batch 160, Loss: 0.9901
Batch 170, Loss: 0.9658
Batch 180, Loss: 1.0031
Batch 190, Loss: 1.0284
Batch 200, Loss: 0.9553
Batch 210, Loss: 0.9558
Batch 220, Loss: 0.9689
Batch 230, Loss: 1.0283
Batch 240, Loss: 0.9634
Batch 250, Loss: 0.9846
Batch 260, Loss: 0.9810
Batch 270, Loss: 0.9923
Batch 280, Loss: 1.0134
Batch 290, Loss: 1.0551
Batch 300, Loss: 1.0234
Batch 310, Loss: 1.0025
Batch 320, Loss: 1.0134
Batch 330, Loss: 1.0248
Batch 340, Loss: 1.0374
Batch 350, Loss: 1.0115
Batch 360, Loss: 1.0132
Batch 370, Loss: 1.0393
Batch 380, Loss: 0.9987
Batch 390, Loss: 1.0246
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.087474822998047 seconds
Epoch 114 accuracy: 68.6%
Batch 10, Loss: 0.9341
Batch 20, Loss: 0.9733
Batch 30, Loss: 0.9160
Batch 40, Loss: 0.9225
Batch 50, Loss: 0.9305
Batch 60, Loss: 0.9396
Batch 70, Loss: 0.9200
Batch 80, Loss: 1.0091
Batch 90, Loss: 1.0094
Batch 100, Loss: 0.9333
Batch 110, Loss: 0.9284
Batch 120, Loss: 0.9696
Batch 130, Loss: 0.9548
Batch 140, Loss: 0.9320
Batch 150, Loss: 0.9819
Batch 160, Loss: 0.9932
Batch 170, Loss: 0.9902
Batch 180, Loss: 0.9686
Batch 190, Loss: 0.9997
Batch 200, Loss: 0.9162
Batch 210, Loss: 0.9634
Batch 220, Loss: 0.9373
Batch 230, Loss: 1.0058
Batch 240, Loss: 0.9812
Batch 250, Loss: 0.9561
Batch 260, Loss: 0.9902
Batch 270, Loss: 0.9625
Batch 280, Loss: 0.9426
Batch 290, Loss: 0.9814
Batch 300, Loss: 0.9357
Batch 310, Loss: 0.9539
Batch 320, Loss: 1.0084
Batch 330, Loss: 1.0139
Batch 340, Loss: 1.0046
Batch 350, Loss: 0.9926
Batch 360, Loss: 0.9713
Batch 370, Loss: 1.0737
Batch 380, Loss: 1.0146
Batch 390, Loss: 1.0095
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.047982692718506 seconds
Epoch 115 accuracy: 67.25%
Batch 10, Loss: 0.9791
Batch 20, Loss: 0.9637
Batch 30, Loss: 0.9021
Batch 40, Loss: 0.9136
Batch 50, Loss: 0.9519
Batch 60, Loss: 0.8798
Batch 70, Loss: 0.9067
Batch 80, Loss: 0.8791
Batch 90, Loss: 0.9079
Batch 100, Loss: 1.0045
Batch 110, Loss: 0.9511
Batch 120, Loss: 0.9338
Batch 130, Loss: 0.9349
Batch 140, Loss: 0.9709
Batch 150, Loss: 1.0166
Batch 160, Loss: 0.9605
Batch 170, Loss: 0.9794
Batch 180, Loss: 0.9899
Batch 190, Loss: 0.9897
Batch 200, Loss: 1.0487
Batch 210, Loss: 0.9864
Batch 220, Loss: 0.9257
Batch 230, Loss: 0.9331
Batch 240, Loss: 0.9731
Batch 250, Loss: 0.9761
Batch 260, Loss: 0.9726
Batch 270, Loss: 1.0249
Batch 280, Loss: 1.0236
Batch 290, Loss: 0.9902
Batch 300, Loss: 0.9565
Batch 310, Loss: 1.0035
Batch 320, Loss: 0.9723
Batch 330, Loss: 1.0264
Batch 340, Loss: 0.9814
Batch 350, Loss: 0.9811
Batch 360, Loss: 0.9530
Batch 370, Loss: 0.9707
Batch 380, Loss: 1.0590
Batch 390, Loss: 0.9863
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.093218326568604 seconds
Epoch 116 accuracy: 69.05%
Batch 10, Loss: 0.8850
Batch 20, Loss: 0.8413
Batch 30, Loss: 0.8515
Batch 40, Loss: 0.8644
Batch 50, Loss: 0.9185
Batch 60, Loss: 0.9300
Batch 70, Loss: 0.9258
Batch 80, Loss: 0.9074
Batch 90, Loss: 0.9137
Batch 100, Loss: 0.9202
Batch 110, Loss: 0.9311
Batch 120, Loss: 0.8929
Batch 130, Loss: 0.9012
Batch 140, Loss: 0.9548
Batch 150, Loss: 0.9171
Batch 160, Loss: 0.9854
Batch 170, Loss: 0.9459
Batch 180, Loss: 0.9447
Batch 190, Loss: 0.9845
Batch 200, Loss: 0.9417
Batch 210, Loss: 0.9602
Batch 220, Loss: 0.9148
Batch 230, Loss: 0.9709
Batch 240, Loss: 0.9586
Batch 250, Loss: 1.0003
Batch 260, Loss: 0.9956
Batch 270, Loss: 1.0369
Batch 280, Loss: 0.9453
Batch 290, Loss: 0.9589
Batch 300, Loss: 0.9415
Batch 310, Loss: 0.9564
Batch 320, Loss: 0.9244
Batch 330, Loss: 0.9307
Batch 340, Loss: 1.0028
Batch 350, Loss: 0.9418
Batch 360, Loss: 0.9742
Batch 370, Loss: 1.0204
Batch 380, Loss: 1.0206
Batch 390, Loss: 0.9862
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.074623823165894 seconds
Epoch 117 accuracy: 69.2%
Batch 10, Loss: 0.8906
Batch 20, Loss: 0.8662
Batch 30, Loss: 0.9076
Batch 40, Loss: 0.8144
Batch 50, Loss: 0.9359
Batch 60, Loss: 0.9215
Batch 70, Loss: 0.8868
Batch 80, Loss: 0.9289
Batch 90, Loss: 0.9181
Batch 100, Loss: 0.8845
Batch 110, Loss: 0.9321
Batch 120, Loss: 0.9383
Batch 130, Loss: 0.8725
Batch 140, Loss: 0.8980
Batch 150, Loss: 0.9712
Batch 160, Loss: 0.9606
Batch 170, Loss: 0.8973
Batch 180, Loss: 0.9499
Batch 190, Loss: 0.9108
Batch 200, Loss: 0.9911
Batch 210, Loss: 0.9634
Batch 220, Loss: 0.9079
Batch 230, Loss: 0.9559
Batch 240, Loss: 0.9538
Batch 250, Loss: 0.9137
Batch 260, Loss: 0.9466
Batch 270, Loss: 0.9878
Batch 280, Loss: 0.9479
Batch 290, Loss: 1.0207
Batch 300, Loss: 0.9673
Batch 310, Loss: 0.9827
Batch 320, Loss: 0.9656
Batch 330, Loss: 0.9816
Batch 340, Loss: 0.9290
Batch 350, Loss: 0.9526
Batch 360, Loss: 0.9590
Batch 370, Loss: 0.9892
Batch 380, Loss: 1.0060
Batch 390, Loss: 0.9854
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.050702810287476 seconds
Epoch 118 accuracy: 66.11%
Batch 10, Loss: 0.9121
Batch 20, Loss: 0.9166
Batch 30, Loss: 0.8677
Batch 40, Loss: 0.9281
Batch 50, Loss: 0.8973
Batch 60, Loss: 0.9484
Batch 70, Loss: 0.8703
Batch 80, Loss: 0.9282
Batch 90, Loss: 0.8395
Batch 100, Loss: 0.9591
Batch 110, Loss: 0.9394
Batch 120, Loss: 0.8899
Batch 130, Loss: 0.9710
Batch 140, Loss: 0.9389
Batch 150, Loss: 0.8587
Batch 160, Loss: 0.9278
Batch 170, Loss: 0.9043
Batch 180, Loss: 0.9339
Batch 190, Loss: 0.8975
Batch 200, Loss: 0.8611
Batch 210, Loss: 0.9090
Batch 220, Loss: 0.9501
Batch 230, Loss: 0.9603
Batch 240, Loss: 0.9134
Batch 250, Loss: 0.9429
Batch 260, Loss: 0.9180
Batch 270, Loss: 0.9918
Batch 280, Loss: 0.9595
Batch 290, Loss: 0.9287
Batch 300, Loss: 1.0031
Batch 310, Loss: 0.9970
Batch 320, Loss: 1.0369
Batch 330, Loss: 1.0054
Batch 340, Loss: 0.9529
Batch 350, Loss: 0.9549
Batch 360, Loss: 0.9871
Batch 370, Loss: 0.9718
Batch 380, Loss: 0.9500
Batch 390, Loss: 0.9156
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.0269455909729 seconds
Epoch 119 accuracy: 68.58%
Batch 10, Loss: 0.9151
Batch 20, Loss: 0.8568
Batch 30, Loss: 0.9011
Batch 40, Loss: 0.8872
Batch 50, Loss: 0.8712
Batch 60, Loss: 0.8481
Batch 70, Loss: 0.8850
Batch 80, Loss: 0.8550
Batch 90, Loss: 0.9153
Batch 100, Loss: 0.9260
Batch 110, Loss: 0.9008
Batch 120, Loss: 0.9471
Batch 130, Loss: 0.9725
Batch 140, Loss: 0.9005
Batch 150, Loss: 0.9054
Batch 160, Loss: 0.8747
Batch 170, Loss: 0.8921
Batch 180, Loss: 0.9533
Batch 190, Loss: 0.9211
Batch 200, Loss: 0.9240
Batch 210, Loss: 0.9926
Batch 220, Loss: 0.9259
Batch 230, Loss: 0.9261
Batch 240, Loss: 0.9595
Batch 250, Loss: 0.9643
Batch 260, Loss: 0.9050
Batch 270, Loss: 0.9438
Batch 280, Loss: 0.9222
Batch 290, Loss: 0.9206
Batch 300, Loss: 0.9584
Batch 310, Loss: 0.9445
Batch 320, Loss: 0.9744
Batch 330, Loss: 0.9694
Batch 340, Loss: 0.9471
Batch 350, Loss: 0.9403
Batch 360, Loss: 0.9308
Batch 370, Loss: 0.9677
Batch 380, Loss: 0.9085
Batch 390, Loss: 0.9779
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.09766697883606 seconds
Epoch 120 accuracy: 69.5%
Batch 10, Loss: 0.9002
Batch 20, Loss: 0.9402
Batch 30, Loss: 0.8711
Batch 40, Loss: 0.8879
Batch 50, Loss: 0.9129
Batch 60, Loss: 0.8665
Batch 70, Loss: 0.9219
Batch 80, Loss: 0.9777
Batch 90, Loss: 0.9012
Batch 100, Loss: 0.8690
Batch 110, Loss: 0.9145
Batch 120, Loss: 0.8748
Batch 130, Loss: 0.8711
Batch 140, Loss: 0.8489
Batch 150, Loss: 0.8888
Batch 160, Loss: 0.9042
Batch 170, Loss: 0.9338
Batch 180, Loss: 0.8815
Batch 190, Loss: 0.9026
Batch 200, Loss: 0.9335
Batch 210, Loss: 0.9420
Batch 220, Loss: 0.9171
Batch 230, Loss: 0.9411
Batch 240, Loss: 0.9667
Batch 250, Loss: 0.8888
Batch 260, Loss: 0.9177
Batch 270, Loss: 0.9221
Batch 280, Loss: 0.9495
Batch 290, Loss: 1.0098
Batch 300, Loss: 0.9434
Batch 310, Loss: 0.9711
Batch 320, Loss: 0.9602
Batch 330, Loss: 0.9184
Batch 340, Loss: 0.9629
Batch 350, Loss: 0.9635
Batch 360, Loss: 0.9262
Batch 370, Loss: 1.0108
Batch 380, Loss: 0.9592
Batch 390, Loss: 0.9372
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.269887924194336 seconds
Epoch 121 accuracy: 67.02%
Batch 10, Loss: 0.8630
Batch 20, Loss: 0.8991
Batch 30, Loss: 0.8688
Batch 40, Loss: 0.9057
Batch 50, Loss: 0.8753
Batch 60, Loss: 0.8926
Batch 70, Loss: 0.8585
Batch 80, Loss: 0.8892
Batch 90, Loss: 0.9358
Batch 100, Loss: 0.8707
Batch 110, Loss: 0.8624
Batch 120, Loss: 0.8506
Batch 130, Loss: 0.8556
Batch 140, Loss: 0.9063
Batch 150, Loss: 0.8734
Batch 160, Loss: 0.8645
Batch 170, Loss: 0.8961
Batch 180, Loss: 0.8497
Batch 190, Loss: 0.8970
Batch 200, Loss: 0.8857
Batch 210, Loss: 0.9062
Batch 220, Loss: 0.9015
Batch 230, Loss: 0.9024
Batch 240, Loss: 0.8409
Batch 250, Loss: 0.9650
Batch 260, Loss: 0.9398
Batch 270, Loss: 0.9363
Batch 280, Loss: 0.9154
Batch 290, Loss: 0.9415
Batch 300, Loss: 0.8782
Batch 310, Loss: 0.8492
Batch 320, Loss: 0.9663
Batch 330, Loss: 0.9327
Batch 340, Loss: 0.9218
Batch 350, Loss: 0.9256
Batch 360, Loss: 0.9113
Batch 370, Loss: 0.9473
Batch 380, Loss: 0.9730
Batch 390, Loss: 0.8785
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.205758571624756 seconds
Epoch 122 accuracy: 70.1%
Batch 10, Loss: 0.8179
Batch 20, Loss: 0.9056
Batch 30, Loss: 0.8280
Batch 40, Loss: 0.8273
Batch 50, Loss: 0.8382
Batch 60, Loss: 0.8289
Batch 70, Loss: 0.8728
Batch 80, Loss: 0.8750
Batch 90, Loss: 0.8808
Batch 100, Loss: 0.9414
Batch 110, Loss: 0.9001
Batch 120, Loss: 0.8838
Batch 130, Loss: 0.8575
Batch 140, Loss: 0.8812
Batch 150, Loss: 0.8963
Batch 160, Loss: 0.8832
Batch 170, Loss: 0.8823
Batch 180, Loss: 0.8717
Batch 190, Loss: 0.9070
Batch 200, Loss: 0.8593
Batch 210, Loss: 0.8744
Batch 220, Loss: 0.8819
Batch 230, Loss: 0.8863
Batch 240, Loss: 0.8824
Batch 250, Loss: 0.8732
Batch 260, Loss: 0.8549
Batch 270, Loss: 0.8950
Batch 280, Loss: 0.9094
Batch 290, Loss: 0.9371
Batch 300, Loss: 0.8812
Batch 310, Loss: 0.9493
Batch 320, Loss: 0.9386
Batch 330, Loss: 0.9566
Batch 340, Loss: 0.9719
Batch 350, Loss: 0.8937
Batch 360, Loss: 0.9148
Batch 370, Loss: 0.9432
Batch 380, Loss: 0.9003
Batch 390, Loss: 0.9069
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.27868103981018 seconds
Epoch 123 accuracy: 70.37%
Batch 10, Loss: 0.8971
Batch 20, Loss: 0.8603
Batch 30, Loss: 0.8508
Batch 40, Loss: 0.8776
Batch 50, Loss: 0.8534
Batch 60, Loss: 0.8737
Batch 70, Loss: 0.8590
Batch 80, Loss: 0.8559
Batch 90, Loss: 0.8698
Batch 100, Loss: 0.8561
Batch 110, Loss: 0.8887
Batch 120, Loss: 0.8195
Batch 130, Loss: 0.8717
Batch 140, Loss: 0.9218
Batch 150, Loss: 0.8550
Batch 160, Loss: 0.8790
Batch 170, Loss: 0.8873
Batch 180, Loss: 0.9436
Batch 190, Loss: 0.9119
Batch 200, Loss: 0.8679
Batch 210, Loss: 0.8853
Batch 220, Loss: 0.9245
Batch 230, Loss: 0.8846
Batch 240, Loss: 0.9231
Batch 250, Loss: 0.8752
Batch 260, Loss: 0.8912
Batch 270, Loss: 0.8889
Batch 280, Loss: 0.8589
Batch 290, Loss: 0.8785
Batch 300, Loss: 0.8942
Batch 310, Loss: 0.9054
Batch 320, Loss: 0.9488
Batch 330, Loss: 0.9225
Batch 340, Loss: 0.8719
Batch 350, Loss: 0.9103
Batch 360, Loss: 0.8934
Batch 370, Loss: 0.8633
Batch 380, Loss: 0.9271
Batch 390, Loss: 0.9031
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.135483741760254 seconds
Epoch 124 accuracy: 67.53%
Batch 10, Loss: 0.8899
Batch 20, Loss: 0.8830
Batch 30, Loss: 0.7926
Batch 40, Loss: 0.8425
Batch 50, Loss: 0.8374
Batch 60, Loss: 0.8331
Batch 70, Loss: 0.8574
Batch 80, Loss: 0.7921
Batch 90, Loss: 0.8305
Batch 100, Loss: 0.8656
Batch 110, Loss: 0.8183
Batch 120, Loss: 0.9222
Batch 130, Loss: 0.8764
Batch 140, Loss: 0.8697
Batch 150, Loss: 0.9019
Batch 160, Loss: 0.8898
Batch 170, Loss: 0.8599
Batch 180, Loss: 0.8622
Batch 190, Loss: 0.9047
Batch 200, Loss: 0.8293
Batch 210, Loss: 0.9008
Batch 220, Loss: 0.8613
Batch 230, Loss: 0.9160
Batch 240, Loss: 0.8501
Batch 250, Loss: 0.8871
Batch 260, Loss: 0.9109
Batch 270, Loss: 0.8971
Batch 280, Loss: 0.8964
Batch 290, Loss: 0.9050
Batch 300, Loss: 0.9011
Batch 310, Loss: 0.9130
Batch 320, Loss: 0.8423
Batch 330, Loss: 0.9276
Batch 340, Loss: 0.8951
Batch 350, Loss: 0.8607
Batch 360, Loss: 0.8998
Batch 370, Loss: 0.9071
Batch 380, Loss: 0.9147
Batch 390, Loss: 0.9015
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.104607343673706 seconds
Epoch 125 accuracy: 69.83%
Batch 10, Loss: 0.8704
Batch 20, Loss: 0.8670
Batch 30, Loss: 0.9072
Batch 40, Loss: 0.7937
Batch 50, Loss: 0.8561
Batch 60, Loss: 0.8627
Batch 70, Loss: 0.8005
Batch 80, Loss: 0.8177
Batch 90, Loss: 0.8535
Batch 100, Loss: 0.8309
Batch 110, Loss: 0.8492
Batch 120, Loss: 0.8886
Batch 130, Loss: 0.8807
Batch 140, Loss: 0.8884
Batch 150, Loss: 0.8885
Batch 160, Loss: 0.8672
Batch 170, Loss: 0.8724
Batch 180, Loss: 0.8692
Batch 190, Loss: 0.8532
Batch 200, Loss: 0.8347
Batch 210, Loss: 0.8428
Batch 220, Loss: 0.8956
Batch 230, Loss: 0.8689
Batch 240, Loss: 0.8433
Batch 250, Loss: 0.9102
Batch 260, Loss: 0.9022
Batch 270, Loss: 0.8669
Batch 280, Loss: 0.8761
Batch 290, Loss: 0.9135
Batch 300, Loss: 0.8756
Batch 310, Loss: 0.9091
Batch 320, Loss: 0.8895
Batch 330, Loss: 0.8322
Batch 340, Loss: 0.9210
Batch 350, Loss: 0.8761
Batch 360, Loss: 0.8253
Batch 370, Loss: 0.9562
Batch 380, Loss: 0.8832
Batch 390, Loss: 0.8764
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.121037483215332 seconds
Epoch 126 accuracy: 71.02%
Batch 10, Loss: 0.8290
Batch 20, Loss: 0.8557
Batch 30, Loss: 0.8074
Batch 40, Loss: 0.7971
Batch 50, Loss: 0.8158
Batch 60, Loss: 0.8569
Batch 70, Loss: 0.8378
Batch 80, Loss: 0.8709
Batch 90, Loss: 0.8047
Batch 100, Loss: 0.8522
Batch 110, Loss: 0.8158
Batch 120, Loss: 0.8051
Batch 130, Loss: 0.8584
Batch 140, Loss: 0.8083
Batch 150, Loss: 0.8772
Batch 160, Loss: 0.8325
Batch 170, Loss: 0.8676
Batch 180, Loss: 0.8802
Batch 190, Loss: 0.8216
Batch 200, Loss: 0.8598
Batch 210, Loss: 0.8805
Batch 220, Loss: 0.9010
Batch 230, Loss: 0.8876
Batch 240, Loss: 0.8732
Batch 250, Loss: 0.8471
Batch 260, Loss: 0.8440
Batch 270, Loss: 0.8189
Batch 280, Loss: 0.8716
Batch 290, Loss: 0.9363
Batch 300, Loss: 0.8343
Batch 310, Loss: 0.9087
Batch 320, Loss: 0.8396
Batch 330, Loss: 0.8753
Batch 340, Loss: 0.8735
Batch 350, Loss: 0.8931
Batch 360, Loss: 0.8847
Batch 370, Loss: 0.8840
Batch 380, Loss: 0.8930
Batch 390, Loss: 0.8216
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.126364946365356 seconds
Epoch 127 accuracy: 70.52%
Batch 10, Loss: 0.8277
Batch 20, Loss: 0.7936
Batch 30, Loss: 0.8515
Batch 40, Loss: 0.8160
Batch 50, Loss: 0.8502
Batch 60, Loss: 0.8389
Batch 70, Loss: 0.8331
Batch 80, Loss: 0.7527
Batch 90, Loss: 0.8204
Batch 100, Loss: 0.7863
Batch 110, Loss: 0.7274
Batch 120, Loss: 0.8325
Batch 130, Loss: 0.8835
Batch 140, Loss: 0.8482
Batch 150, Loss: 0.7874
Batch 160, Loss: 0.8198
Batch 170, Loss: 0.8290
Batch 180, Loss: 0.8294
Batch 190, Loss: 0.8596
Batch 200, Loss: 0.8377
Batch 210, Loss: 0.8708
Batch 220, Loss: 0.8196
Batch 230, Loss: 0.8673
Batch 240, Loss: 0.8324
Batch 250, Loss: 0.9056
Batch 260, Loss: 0.8408
Batch 270, Loss: 0.8685
Batch 280, Loss: 0.8573
Batch 290, Loss: 0.8300
Batch 300, Loss: 0.8463
Batch 310, Loss: 0.8828
Batch 320, Loss: 0.8691
Batch 330, Loss: 0.8474
Batch 340, Loss: 0.8546
Batch 350, Loss: 0.8477
Batch 360, Loss: 0.8552
Batch 370, Loss: 0.8507
Batch 380, Loss: 0.8869
Batch 390, Loss: 0.8727
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.18377184867859 seconds
Epoch 128 accuracy: 69.71%
Batch 10, Loss: 0.7732
Batch 20, Loss: 0.7831
Batch 30, Loss: 0.7855
Batch 40, Loss: 0.8069
Batch 50, Loss: 0.7829
Batch 60, Loss: 0.7730
Batch 70, Loss: 0.8151
Batch 80, Loss: 0.7920
Batch 90, Loss: 0.7993
Batch 100, Loss: 0.8586
Batch 110, Loss: 0.7587
Batch 120, Loss: 0.8017
Batch 130, Loss: 0.8214
Batch 140, Loss: 0.8057
Batch 150, Loss: 0.7921
Batch 160, Loss: 0.8679
Batch 170, Loss: 0.8438
Batch 180, Loss: 0.8685
Batch 190, Loss: 0.8638
Batch 200, Loss: 0.8543
Batch 210, Loss: 0.8489
Batch 220, Loss: 0.8340
Batch 230, Loss: 0.8544
Batch 240, Loss: 0.7870
Batch 250, Loss: 0.8392
Batch 260, Loss: 0.8678
Batch 270, Loss: 0.8430
Batch 280, Loss: 0.8766
Batch 290, Loss: 0.8752
Batch 300, Loss: 0.8832
Batch 310, Loss: 0.8723
Batch 320, Loss: 0.8733
Batch 330, Loss: 0.8236
Batch 340, Loss: 0.8224
Batch 350, Loss: 0.8456
Batch 360, Loss: 0.8460
Batch 370, Loss: 0.8438
Batch 380, Loss: 0.8655
Batch 390, Loss: 0.8805
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.109384536743164 seconds
Epoch 129 accuracy: 70.56%
Batch 10, Loss: 0.7765
Batch 20, Loss: 0.8521
Batch 30, Loss: 0.7435
Batch 40, Loss: 0.8103
Batch 50, Loss: 0.7984
Batch 60, Loss: 0.8287
Batch 70, Loss: 0.7928
Batch 80, Loss: 0.7513
Batch 90, Loss: 0.8176
Batch 100, Loss: 0.7472
Batch 110, Loss: 0.7668
Batch 120, Loss: 0.7840
Batch 130, Loss: 0.7613
Batch 140, Loss: 0.8274
Batch 150, Loss: 0.8348
Batch 160, Loss: 0.8305
Batch 170, Loss: 0.7982
Batch 180, Loss: 0.8223
Batch 190, Loss: 0.8173
Batch 200, Loss: 0.8275
Batch 210, Loss: 0.8526
Batch 220, Loss: 0.7903
Batch 230, Loss: 0.8027
Batch 240, Loss: 0.8229
Batch 250, Loss: 0.8548
Batch 260, Loss: 0.7759
Batch 270, Loss: 0.7905
Batch 280, Loss: 0.8219
Batch 290, Loss: 0.8588
Batch 300, Loss: 0.8217
Batch 310, Loss: 0.8557
Batch 320, Loss: 0.8077
Batch 330, Loss: 0.8319
Batch 340, Loss: 0.8432
Batch 350, Loss: 0.8300
Batch 360, Loss: 0.8938
Batch 370, Loss: 0.8382
Batch 380, Loss: 0.8484
Batch 390, Loss: 0.8317
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.20070242881775 seconds
Epoch 130 accuracy: 71.0%
Batch 10, Loss: 0.7442
Batch 20, Loss: 0.7831
Batch 30, Loss: 0.8053
Batch 40, Loss: 0.7905
Batch 50, Loss: 0.7725
Batch 60, Loss: 0.7544
Batch 70, Loss: 0.8014
Batch 80, Loss: 0.8187
Batch 90, Loss: 0.8116
Batch 100, Loss: 0.7683
Batch 110, Loss: 0.7487
Batch 120, Loss: 0.8427
Batch 130, Loss: 0.7691
Batch 140, Loss: 0.8165
Batch 150, Loss: 0.8111
Batch 160, Loss: 0.8292
Batch 170, Loss: 0.8395
Batch 180, Loss: 0.7994
Batch 190, Loss: 0.8184
Batch 200, Loss: 0.8352
Batch 210, Loss: 0.8401
Batch 220, Loss: 0.8879
Batch 230, Loss: 0.8114
Batch 240, Loss: 0.8262
Batch 250, Loss: 0.8070
Batch 260, Loss: 0.8168
Batch 270, Loss: 0.8585
Batch 280, Loss: 0.8445
Batch 290, Loss: 0.8687
Batch 300, Loss: 0.8512
Batch 310, Loss: 0.8076
Batch 320, Loss: 0.8583
Batch 330, Loss: 0.8806
Batch 340, Loss: 0.8350
Batch 350, Loss: 0.8186
Batch 360, Loss: 0.8153
Batch 370, Loss: 0.8373
Batch 380, Loss: 0.8476
Batch 390, Loss: 0.8342
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.322064638137817 seconds
Epoch 131 accuracy: 71.95%
Batch 10, Loss: 0.7900
Batch 20, Loss: 0.8042
Batch 30, Loss: 0.7594
Batch 40, Loss: 0.8582
Batch 50, Loss: 0.7538
Batch 60, Loss: 0.8181
Batch 70, Loss: 0.7662
Batch 80, Loss: 0.8044
Batch 90, Loss: 0.7896
Batch 100, Loss: 0.7561
Batch 110, Loss: 0.7603
Batch 120, Loss: 0.7510
Batch 130, Loss: 0.7379
Batch 140, Loss: 0.8001
Batch 150, Loss: 0.7314
Batch 160, Loss: 0.7979
Batch 170, Loss: 0.7698
Batch 180, Loss: 0.7459
Batch 190, Loss: 0.8075
Batch 200, Loss: 0.7417
Batch 210, Loss: 0.8125
Batch 220, Loss: 0.8177
Batch 230, Loss: 0.8523
Batch 240, Loss: 0.8001
Batch 250, Loss: 0.8198
Batch 260, Loss: 0.8046
Batch 270, Loss: 0.8257
Batch 280, Loss: 0.7980
Batch 290, Loss: 0.8063
Batch 300, Loss: 0.8110
Batch 310, Loss: 0.8482
Batch 320, Loss: 0.8152
Batch 330, Loss: 0.8108
Batch 340, Loss: 0.7727
Batch 350, Loss: 0.8078
Batch 360, Loss: 0.8621
Batch 370, Loss: 0.7856
Batch 380, Loss: 0.8868
Batch 390, Loss: 0.8471
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.155845880508423 seconds
Epoch 132 accuracy: 69.49%
Batch 10, Loss: 0.7606
Batch 20, Loss: 0.7471
Batch 30, Loss: 0.8274
Batch 40, Loss: 0.7648
Batch 50, Loss: 0.8218
Batch 60, Loss: 0.8056
Batch 70, Loss: 0.7420
Batch 80, Loss: 0.7586
Batch 90, Loss: 0.7288
Batch 100, Loss: 0.8301
Batch 110, Loss: 0.7568
Batch 120, Loss: 0.7369
Batch 130, Loss: 0.7651
Batch 140, Loss: 0.7239
Batch 150, Loss: 0.7765
Batch 160, Loss: 0.7621
Batch 170, Loss: 0.8601
Batch 180, Loss: 0.7774
Batch 190, Loss: 0.8379
Batch 200, Loss: 0.8072
Batch 210, Loss: 0.7649
Batch 220, Loss: 0.7448
Batch 230, Loss: 0.8289
Batch 240, Loss: 0.8027
Batch 250, Loss: 0.8556
Batch 260, Loss: 0.7919
Batch 270, Loss: 0.8125
Batch 280, Loss: 0.7880
Batch 290, Loss: 0.8239
Batch 300, Loss: 0.8150
Batch 310, Loss: 0.8415
Batch 320, Loss: 0.8122
Batch 330, Loss: 0.7805
Batch 340, Loss: 0.7943
Batch 350, Loss: 0.8251
Batch 360, Loss: 0.8289
Batch 370, Loss: 0.7700
Batch 380, Loss: 0.8410
Batch 390, Loss: 0.8337
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.16781449317932 seconds
Epoch 133 accuracy: 71.6%
Batch 10, Loss: 0.7587
Batch 20, Loss: 0.7839
Batch 30, Loss: 0.7839
Batch 40, Loss: 0.7393
Batch 50, Loss: 0.7282
Batch 60, Loss: 0.7803
Batch 70, Loss: 0.7366
Batch 80, Loss: 0.7427
Batch 90, Loss: 0.7590
Batch 100, Loss: 0.7395
Batch 110, Loss: 0.7436
Batch 120, Loss: 0.8085
Batch 130, Loss: 0.7699
Batch 140, Loss: 0.7529
Batch 150, Loss: 0.8056
Batch 160, Loss: 0.7183
Batch 170, Loss: 0.7989
Batch 180, Loss: 0.7828
Batch 190, Loss: 0.8028
Batch 200, Loss: 0.7706
Batch 210, Loss: 0.7946
Batch 220, Loss: 0.7849
Batch 230, Loss: 0.7578
Batch 240, Loss: 0.7989
Batch 250, Loss: 0.7705
Batch 260, Loss: 0.7091
Batch 270, Loss: 0.7924
Batch 280, Loss: 0.8169
Batch 290, Loss: 0.7913
Batch 300, Loss: 0.8153
Batch 310, Loss: 0.7863
Batch 320, Loss: 0.7598
Batch 330, Loss: 0.7909
Batch 340, Loss: 0.8422
Batch 350, Loss: 0.7982
Batch 360, Loss: 0.8724
Batch 370, Loss: 0.8211
Batch 380, Loss: 0.8088
Batch 390, Loss: 0.8116
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.15403699874878 seconds
Epoch 134 accuracy: 72.03%
Batch 10, Loss: 0.7802
Batch 20, Loss: 0.7472
Batch 30, Loss: 0.7127
Batch 40, Loss: 0.7252
Batch 50, Loss: 0.6991
Batch 60, Loss: 0.7384
Batch 70, Loss: 0.7188
Batch 80, Loss: 0.7337
Batch 90, Loss: 0.7368
Batch 100, Loss: 0.7477
Batch 110, Loss: 0.7663
Batch 120, Loss: 0.8208
Batch 130, Loss: 0.7460
Batch 140, Loss: 0.7772
Batch 150, Loss: 0.7379
Batch 160, Loss: 0.7892
Batch 170, Loss: 0.7929
Batch 180, Loss: 0.7544
Batch 190, Loss: 0.7892
Batch 200, Loss: 0.7119
Batch 210, Loss: 0.7819
Batch 220, Loss: 0.7648
Batch 230, Loss: 0.7611
Batch 240, Loss: 0.8342
Batch 250, Loss: 0.8220
Batch 260, Loss: 0.8103
Batch 270, Loss: 0.7926
Batch 280, Loss: 0.7855
Batch 290, Loss: 0.7539
Batch 300, Loss: 0.7592
Batch 310, Loss: 0.7604
Batch 320, Loss: 0.7660
Batch 330, Loss: 0.8420
Batch 340, Loss: 0.7729
Batch 350, Loss: 0.8386
Batch 360, Loss: 0.7971
Batch 370, Loss: 0.7786
Batch 380, Loss: 0.8120
Batch 390, Loss: 0.7786
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.17928385734558 seconds
Epoch 135 accuracy: 73.15%
Batch 10, Loss: 0.7560
Batch 20, Loss: 0.7886
Batch 30, Loss: 0.7492
Batch 40, Loss: 0.7021
Batch 50, Loss: 0.7643
Batch 60, Loss: 0.7165
Batch 70, Loss: 0.6765
Batch 80, Loss: 0.7142
Batch 90, Loss: 0.7261
Batch 100, Loss: 0.7392
Batch 110, Loss: 0.7413
Batch 120, Loss: 0.7264
Batch 130, Loss: 0.7485
Batch 140, Loss: 0.7465
Batch 150, Loss: 0.7184
Batch 160, Loss: 0.7478
Batch 170, Loss: 0.7263
Batch 180, Loss: 0.7996
Batch 190, Loss: 0.7494
Batch 200, Loss: 0.7307
Batch 210, Loss: 0.7529
Batch 220, Loss: 0.7543
Batch 230, Loss: 0.8038
Batch 240, Loss: 0.7802
Batch 250, Loss: 0.7530
Batch 260, Loss: 0.7647
Batch 270, Loss: 0.7839
Batch 280, Loss: 0.7192
Batch 290, Loss: 0.7520
Batch 300, Loss: 0.8145
Batch 310, Loss: 0.6828
Batch 320, Loss: 0.7240
Batch 330, Loss: 0.6989
Batch 340, Loss: 0.7599
Batch 350, Loss: 0.7683
Batch 360, Loss: 0.7285
Batch 370, Loss: 0.8018
Batch 380, Loss: 0.8023
Batch 390, Loss: 0.7986
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.411921501159668 seconds
Epoch 136 accuracy: 72.52%
Batch 10, Loss: 0.7242
Batch 20, Loss: 0.6699
Batch 30, Loss: 0.7328
Batch 40, Loss: 0.7284
Batch 50, Loss: 0.7169
Batch 60, Loss: 0.7620
Batch 70, Loss: 0.7506
Batch 80, Loss: 0.7156
Batch 90, Loss: 0.7383
Batch 100, Loss: 0.7092
Batch 110, Loss: 0.7384
Batch 120, Loss: 0.6877
Batch 130, Loss: 0.7298
Batch 140, Loss: 0.7257
Batch 150, Loss: 0.7417
Batch 160, Loss: 0.7292
Batch 170, Loss: 0.7324
Batch 180, Loss: 0.7146
Batch 190, Loss: 0.6643
Batch 200, Loss: 0.7367
Batch 210, Loss: 0.7321
Batch 220, Loss: 0.8104
Batch 230, Loss: 0.7301
Batch 240, Loss: 0.7274
Batch 250, Loss: 0.8225
Batch 260, Loss: 0.7924
Batch 270, Loss: 0.7413
Batch 280, Loss: 0.7631
Batch 290, Loss: 0.7423
Batch 300, Loss: 0.7625
Batch 310, Loss: 0.7600
Batch 320, Loss: 0.7316
Batch 330, Loss: 0.8072
Batch 340, Loss: 0.7295
Batch 350, Loss: 0.7635
Batch 360, Loss: 0.7712
Batch 370, Loss: 0.7978
Batch 380, Loss: 0.7862
Batch 390, Loss: 0.7696
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.250970363616943 seconds
Epoch 137 accuracy: 71.38%
Batch 10, Loss: 0.6497
Batch 20, Loss: 0.7667
Batch 30, Loss: 0.7028
Batch 40, Loss: 0.7320
Batch 50, Loss: 0.7045
Batch 60, Loss: 0.6899
Batch 70, Loss: 0.7016
Batch 80, Loss: 0.6944
Batch 90, Loss: 0.7407
Batch 100, Loss: 0.7534
Batch 110, Loss: 0.7677
Batch 120, Loss: 0.7723
Batch 130, Loss: 0.7181
Batch 140, Loss: 0.6866
Batch 150, Loss: 0.7708
Batch 160, Loss: 0.6926
Batch 170, Loss: 0.7916
Batch 180, Loss: 0.7640
Batch 190, Loss: 0.7131
Batch 200, Loss: 0.7843
Batch 210, Loss: 0.7613
Batch 220, Loss: 0.7070
Batch 230, Loss: 0.7366
Batch 240, Loss: 0.7702
Batch 250, Loss: 0.7775
Batch 260, Loss: 0.8234
Batch 270, Loss: 0.7542
Batch 280, Loss: 0.7511
Batch 290, Loss: 0.7767
Batch 300, Loss: 0.7571
Batch 310, Loss: 0.8418
Batch 320, Loss: 0.7520
Batch 330, Loss: 0.7748
Batch 340, Loss: 0.7262
Batch 350, Loss: 0.7751
Batch 360, Loss: 0.7439
Batch 370, Loss: 0.7769
Batch 380, Loss: 0.7822
Batch 390, Loss: 0.7284
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.29605460166931 seconds
Epoch 138 accuracy: 72.34%
Batch 10, Loss: 0.7136
Batch 20, Loss: 0.6960
Batch 30, Loss: 0.7462
Batch 40, Loss: 0.7137
Batch 50, Loss: 0.7186
Batch 60, Loss: 0.7250
Batch 70, Loss: 0.7194
Batch 80, Loss: 0.6581
Batch 90, Loss: 0.6780
Batch 100, Loss: 0.7426
Batch 110, Loss: 0.7219
Batch 120, Loss: 0.7030
Batch 130, Loss: 0.7243
Batch 140, Loss: 0.7262
Batch 150, Loss: 0.6707
Batch 160, Loss: 0.7265
Batch 170, Loss: 0.6571
Batch 180, Loss: 0.7309
Batch 190, Loss: 0.6860
Batch 200, Loss: 0.7494
Batch 210, Loss: 0.7349
Batch 220, Loss: 0.7302
Batch 230, Loss: 0.6893
Batch 240, Loss: 0.7393
Batch 250, Loss: 0.7090
Batch 260, Loss: 0.7322
Batch 270, Loss: 0.7467
Batch 280, Loss: 0.7200
Batch 290, Loss: 0.7613
Batch 300, Loss: 0.7237
Batch 310, Loss: 0.7309
Batch 320, Loss: 0.7267
Batch 330, Loss: 0.7237
Batch 340, Loss: 0.7007
Batch 350, Loss: 0.7209
Batch 360, Loss: 0.7757
Batch 370, Loss: 0.7659
Batch 380, Loss: 0.7438
Batch 390, Loss: 0.7889
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.118379831314087 seconds
Epoch 139 accuracy: 72.18%
Batch 10, Loss: 0.6695
Batch 20, Loss: 0.7023
Batch 30, Loss: 0.6702
Batch 40, Loss: 0.7604
Batch 50, Loss: 0.6731
Batch 60, Loss: 0.6825
Batch 70, Loss: 0.6791
Batch 80, Loss: 0.6743
Batch 90, Loss: 0.6762
Batch 100, Loss: 0.7115
Batch 110, Loss: 0.7063
Batch 120, Loss: 0.7153
Batch 130, Loss: 0.6853
Batch 140, Loss: 0.7290
Batch 150, Loss: 0.7230
Batch 160, Loss: 0.7061
Batch 170, Loss: 0.7337
Batch 180, Loss: 0.7238
Batch 190, Loss: 0.7074
Batch 200, Loss: 0.7170
Batch 210, Loss: 0.7420
Batch 220, Loss: 0.6983
Batch 230, Loss: 0.6808
Batch 240, Loss: 0.7029
Batch 250, Loss: 0.8011
Batch 260, Loss: 0.7396
Batch 270, Loss: 0.6945
Batch 280, Loss: 0.7607
Batch 290, Loss: 0.6900
Batch 300, Loss: 0.7382
Batch 310, Loss: 0.7686
Batch 320, Loss: 0.7270
Batch 330, Loss: 0.7708
Batch 340, Loss: 0.7724
Batch 350, Loss: 0.7455
Batch 360, Loss: 0.7560
Batch 370, Loss: 0.7661
Batch 380, Loss: 0.7344
Batch 390, Loss: 0.7362
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.141536235809326 seconds
Epoch 140 accuracy: 73.02%
Batch 10, Loss: 0.6680
Batch 20, Loss: 0.6489
Batch 30, Loss: 0.6366
Batch 40, Loss: 0.6367
Batch 50, Loss: 0.6142
Batch 60, Loss: 0.6864
Batch 70, Loss: 0.6848
Batch 80, Loss: 0.6772
Batch 90, Loss: 0.7181
Batch 100, Loss: 0.6956
Batch 110, Loss: 0.6399
Batch 120, Loss: 0.7095
Batch 130, Loss: 0.6426
Batch 140, Loss: 0.7364
Batch 150, Loss: 0.6464
Batch 160, Loss: 0.7037
Batch 170, Loss: 0.6823
Batch 180, Loss: 0.7381
Batch 190, Loss: 0.7217
Batch 200, Loss: 0.7181
Batch 210, Loss: 0.6787
Batch 220, Loss: 0.7089
Batch 230, Loss: 0.7064
Batch 240, Loss: 0.7226
Batch 250, Loss: 0.7210
Batch 260, Loss: 0.7270
Batch 270, Loss: 0.6878
Batch 280, Loss: 0.7365
Batch 290, Loss: 0.7723
Batch 300, Loss: 0.7409
Batch 310, Loss: 0.7518
Batch 320, Loss: 0.6794
Batch 330, Loss: 0.7633
Batch 340, Loss: 0.6992
Batch 350, Loss: 0.7255
Batch 360, Loss: 0.7133
Batch 370, Loss: 0.7253
Batch 380, Loss: 0.7552
Batch 390, Loss: 0.7122
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.105546236038208 seconds
Epoch 141 accuracy: 72.83%
Batch 10, Loss: 0.6429
Batch 20, Loss: 0.6894
Batch 30, Loss: 0.6960
Batch 40, Loss: 0.6876
Batch 50, Loss: 0.6634
Batch 60, Loss: 0.6722
Batch 70, Loss: 0.5915
Batch 80, Loss: 0.6581
Batch 90, Loss: 0.6382
Batch 100, Loss: 0.6435
Batch 110, Loss: 0.6582
Batch 120, Loss: 0.6320
Batch 130, Loss: 0.6976
Batch 140, Loss: 0.6420
Batch 150, Loss: 0.6706
Batch 160, Loss: 0.6871
Batch 170, Loss: 0.7157
Batch 180, Loss: 0.6872
Batch 190, Loss: 0.6767
Batch 200, Loss: 0.6576
Batch 210, Loss: 0.7034
Batch 220, Loss: 0.6975
Batch 230, Loss: 0.7008
Batch 240, Loss: 0.6908
Batch 250, Loss: 0.6482
Batch 260, Loss: 0.7153
Batch 270, Loss: 0.6805
Batch 280, Loss: 0.7410
Batch 290, Loss: 0.6706
Batch 300, Loss: 0.7130
Batch 310, Loss: 0.7202
Batch 320, Loss: 0.6694
Batch 330, Loss: 0.7665
Batch 340, Loss: 0.7239
Batch 350, Loss: 0.7308
Batch 360, Loss: 0.6664
Batch 370, Loss: 0.7352
Batch 380, Loss: 0.7276
Batch 390, Loss: 0.7224
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.121381521224976 seconds
Epoch 142 accuracy: 73.53%
Batch 10, Loss: 0.6650
Batch 20, Loss: 0.6352
Batch 30, Loss: 0.6400
Batch 40, Loss: 0.6548
Batch 50, Loss: 0.6415
Batch 60, Loss: 0.6291
Batch 70, Loss: 0.6235
Batch 80, Loss: 0.6749
Batch 90, Loss: 0.6553
Batch 100, Loss: 0.6637
Batch 110, Loss: 0.6727
Batch 120, Loss: 0.6819
Batch 130, Loss: 0.6595
Batch 140, Loss: 0.6779
Batch 150, Loss: 0.6340
Batch 160, Loss: 0.6793
Batch 170, Loss: 0.7092
Batch 180, Loss: 0.6783
Batch 190, Loss: 0.7187
Batch 200, Loss: 0.6731
Batch 210, Loss: 0.7422
Batch 220, Loss: 0.6696
Batch 230, Loss: 0.6642
Batch 240, Loss: 0.6698
Batch 250, Loss: 0.7052
Batch 260, Loss: 0.6828
Batch 270, Loss: 0.6980
Batch 280, Loss: 0.6770
Batch 290, Loss: 0.7337
Batch 300, Loss: 0.7586
Batch 310, Loss: 0.6942
Batch 320, Loss: 0.6694
Batch 330, Loss: 0.7109
Batch 340, Loss: 0.6538
Batch 350, Loss: 0.6513
Batch 360, Loss: 0.7182
Batch 370, Loss: 0.6646
Batch 380, Loss: 0.6883
Batch 390, Loss: 0.6770
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.084495782852173 seconds
Epoch 143 accuracy: 71.84%
Batch 10, Loss: 0.5932
Batch 20, Loss: 0.6359
Batch 30, Loss: 0.6564
Batch 40, Loss: 0.7017
Batch 50, Loss: 0.6684
Batch 60, Loss: 0.6422
Batch 70, Loss: 0.6652
Batch 80, Loss: 0.6741
Batch 90, Loss: 0.6284
Batch 100, Loss: 0.6498
Batch 110, Loss: 0.6346
Batch 120, Loss: 0.7149
Batch 130, Loss: 0.7139
Batch 140, Loss: 0.6671
Batch 150, Loss: 0.6894
Batch 160, Loss: 0.6447
Batch 170, Loss: 0.7014
Batch 180, Loss: 0.6748
Batch 190, Loss: 0.6560
Batch 200, Loss: 0.6731
Batch 210, Loss: 0.6329
Batch 220, Loss: 0.7359
Batch 230, Loss: 0.6862
Batch 240, Loss: 0.6553
Batch 250, Loss: 0.6609
Batch 260, Loss: 0.7245
Batch 270, Loss: 0.6637
Batch 280, Loss: 0.6453
Batch 290, Loss: 0.7212
Batch 300, Loss: 0.6371
Batch 310, Loss: 0.6694
Batch 320, Loss: 0.6797
Batch 330, Loss: 0.6345
Batch 340, Loss: 0.6815
Batch 350, Loss: 0.6476
Batch 360, Loss: 0.7297
Batch 370, Loss: 0.6582
Batch 380, Loss: 0.6950
Batch 390, Loss: 0.7359
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.119109630584717 seconds
Epoch 144 accuracy: 73.79%
Batch 10, Loss: 0.6493
Batch 20, Loss: 0.6988
Batch 30, Loss: 0.6433
Batch 40, Loss: 0.6417
Batch 50, Loss: 0.6610
Batch 60, Loss: 0.6707
Batch 70, Loss: 0.6500
Batch 80, Loss: 0.6319
Batch 90, Loss: 0.6255
Batch 100, Loss: 0.6244
Batch 110, Loss: 0.6884
Batch 120, Loss: 0.6273
Batch 130, Loss: 0.6523
Batch 140, Loss: 0.6251
Batch 150, Loss: 0.6737
Batch 160, Loss: 0.6346
Batch 170, Loss: 0.6277
Batch 180, Loss: 0.6386
Batch 190, Loss: 0.6185
Batch 200, Loss: 0.6316
Batch 210, Loss: 0.6791
Batch 220, Loss: 0.6610
Batch 230, Loss: 0.6810
Batch 240, Loss: 0.6590
Batch 250, Loss: 0.6903
Batch 260, Loss: 0.6328
Batch 270, Loss: 0.6881
Batch 280, Loss: 0.6655
Batch 290, Loss: 0.6686
Batch 300, Loss: 0.6709
Batch 310, Loss: 0.6535
Batch 320, Loss: 0.7002
Batch 330, Loss: 0.6636
Batch 340, Loss: 0.6530
Batch 350, Loss: 0.6730
Batch 360, Loss: 0.6508
Batch 370, Loss: 0.6870
Batch 380, Loss: 0.6804
Batch 390, Loss: 0.6762
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.14855146408081 seconds
Epoch 145 accuracy: 73.27%
Batch 10, Loss: 0.6240
Batch 20, Loss: 0.6155
Batch 30, Loss: 0.5894
Batch 40, Loss: 0.6276
Batch 50, Loss: 0.6097
Batch 60, Loss: 0.6763
Batch 70, Loss: 0.6586
Batch 80, Loss: 0.6809
Batch 90, Loss: 0.6136
Batch 100, Loss: 0.6252
Batch 110, Loss: 0.6171
Batch 120, Loss: 0.5545
Batch 130, Loss: 0.6101
Batch 140, Loss: 0.6026
Batch 150, Loss: 0.6270
Batch 160, Loss: 0.6048
Batch 170, Loss: 0.6787
Batch 180, Loss: 0.6900
Batch 190, Loss: 0.6025
Batch 200, Loss: 0.6253
Batch 210, Loss: 0.6133
Batch 220, Loss: 0.6216
Batch 230, Loss: 0.6567
Batch 240, Loss: 0.7347
Batch 250, Loss: 0.6893
Batch 260, Loss: 0.6729
Batch 270, Loss: 0.7026
Batch 280, Loss: 0.6859
Batch 290, Loss: 0.6569
Batch 300, Loss: 0.6679
Batch 310, Loss: 0.6399
Batch 320, Loss: 0.6813
Batch 330, Loss: 0.6679
Batch 340, Loss: 0.6736
Batch 350, Loss: 0.6918
Batch 360, Loss: 0.6716
Batch 370, Loss: 0.6894
Batch 380, Loss: 0.6582
Batch 390, Loss: 0.6664
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.242804765701294 seconds
Epoch 146 accuracy: 74.23%
Batch 10, Loss: 0.6452
Batch 20, Loss: 0.6291
Batch 30, Loss: 0.6173
Batch 40, Loss: 0.6363
Batch 50, Loss: 0.5759
Batch 60, Loss: 0.6195
Batch 70, Loss: 0.6138
Batch 80, Loss: 0.5593
Batch 90, Loss: 0.5988
Batch 100, Loss: 0.6126
Batch 110, Loss: 0.6346
Batch 120, Loss: 0.6064
Batch 130, Loss: 0.6083
Batch 140, Loss: 0.6391
Batch 150, Loss: 0.5924
Batch 160, Loss: 0.5976
Batch 170, Loss: 0.5880
Batch 180, Loss: 0.6786
Batch 190, Loss: 0.6032
Batch 200, Loss: 0.6284
Batch 210, Loss: 0.6483
Batch 220, Loss: 0.6093
Batch 230, Loss: 0.6071
Batch 240, Loss: 0.6590
Batch 250, Loss: 0.6613
Batch 260, Loss: 0.6767
Batch 270, Loss: 0.5928
Batch 280, Loss: 0.6503
Batch 290, Loss: 0.6125
Batch 300, Loss: 0.6706
Batch 310, Loss: 0.6435
Batch 320, Loss: 0.6205
Batch 330, Loss: 0.7069
Batch 340, Loss: 0.6700
Batch 350, Loss: 0.7303
Batch 360, Loss: 0.6176
Batch 370, Loss: 0.6645
Batch 380, Loss: 0.6548
Batch 390, Loss: 0.6945
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.25264549255371 seconds
Epoch 147 accuracy: 74.2%
Batch 10, Loss: 0.6304
Batch 20, Loss: 0.6265
Batch 30, Loss: 0.6213
Batch 40, Loss: 0.6484
Batch 50, Loss: 0.6707
Batch 60, Loss: 0.5723
Batch 70, Loss: 0.5772
Batch 80, Loss: 0.5862
Batch 90, Loss: 0.6219
Batch 100, Loss: 0.6116
Batch 110, Loss: 0.6458
Batch 120, Loss: 0.5956
Batch 130, Loss: 0.6071
Batch 140, Loss: 0.6059
Batch 150, Loss: 0.6390
Batch 160, Loss: 0.6131
Batch 170, Loss: 0.6632
Batch 180, Loss: 0.6246
Batch 190, Loss: 0.6234
Batch 200, Loss: 0.6167
Batch 210, Loss: 0.6243
Batch 220, Loss: 0.6817
Batch 230, Loss: 0.5951
Batch 240, Loss: 0.6280
Batch 250, Loss: 0.6259
Batch 260, Loss: 0.6269
Batch 270, Loss: 0.5998
Batch 280, Loss: 0.6529
Batch 290, Loss: 0.6126
Batch 300, Loss: 0.6356
Batch 310, Loss: 0.6202
Batch 320, Loss: 0.6176
Batch 330, Loss: 0.6367
Batch 340, Loss: 0.5949
Batch 350, Loss: 0.6001
Batch 360, Loss: 0.6540
Batch 370, Loss: 0.6182
Batch 380, Loss: 0.6356
Batch 390, Loss: 0.6501
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.11344838142395 seconds
Epoch 148 accuracy: 74.47%
Batch 10, Loss: 0.6166
Batch 20, Loss: 0.5759
Batch 30, Loss: 0.6207
Batch 40, Loss: 0.6355
Batch 50, Loss: 0.6262
Batch 60, Loss: 0.5618
Batch 70, Loss: 0.6421
Batch 80, Loss: 0.5909
Batch 90, Loss: 0.6078
Batch 100, Loss: 0.6307
Batch 110, Loss: 0.6015
Batch 120, Loss: 0.5844
Batch 130, Loss: 0.5906
Batch 140, Loss: 0.6541
Batch 150, Loss: 0.6166
Batch 160, Loss: 0.5808
Batch 170, Loss: 0.6127
Batch 180, Loss: 0.6325
Batch 190, Loss: 0.5996
Batch 200, Loss: 0.6306
Batch 210, Loss: 0.6088
Batch 220, Loss: 0.6450
Batch 230, Loss: 0.6005
Batch 240, Loss: 0.6102
Batch 250, Loss: 0.6237
Batch 260, Loss: 0.5913
Batch 270, Loss: 0.6673
Batch 280, Loss: 0.6802
Batch 290, Loss: 0.6345
Batch 300, Loss: 0.6405
Batch 310, Loss: 0.6039
Batch 320, Loss: 0.6099
Batch 330, Loss: 0.6071
Batch 340, Loss: 0.6650
Batch 350, Loss: 0.6962
Batch 360, Loss: 0.6202
Batch 370, Loss: 0.6060
Batch 380, Loss: 0.6089
Batch 390, Loss: 0.5931
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.177282333374023 seconds
Epoch 149 accuracy: 74.38%
Batch 10, Loss: 0.5740
Batch 20, Loss: 0.5993
Batch 30, Loss: 0.5811
Batch 40, Loss: 0.5269
Batch 50, Loss: 0.5799
Batch 60, Loss: 0.5867
Batch 70, Loss: 0.5753
Batch 80, Loss: 0.5583
Batch 90, Loss: 0.5784
Batch 100, Loss: 0.6181
Batch 110, Loss: 0.5967
Batch 120, Loss: 0.5800
Batch 130, Loss: 0.5688
Batch 140, Loss: 0.5673
Batch 150, Loss: 0.6264
Batch 160, Loss: 0.5901
Batch 170, Loss: 0.5973
Batch 180, Loss: 0.5696
Batch 190, Loss: 0.5544
Batch 200, Loss: 0.6277
Batch 210, Loss: 0.5544
Batch 220, Loss: 0.6133
Batch 230, Loss: 0.5815
Batch 240, Loss: 0.6217
Batch 250, Loss: 0.5369
Batch 260, Loss: 0.5881
Batch 270, Loss: 0.5910
Batch 280, Loss: 0.5588
Batch 290, Loss: 0.5763
Batch 300, Loss: 0.6145
Batch 310, Loss: 0.6273
Batch 320, Loss: 0.5867
Batch 330, Loss: 0.6518
Batch 340, Loss: 0.6158
Batch 350, Loss: 0.5398
Batch 360, Loss: 0.5971
Batch 370, Loss: 0.5671
Batch 380, Loss: 0.6070
Batch 390, Loss: 0.6251
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.04979920387268 seconds
Epoch 150 accuracy: 74.16%
Batch 10, Loss: 0.5667
Batch 20, Loss: 0.6062
Batch 30, Loss: 0.5733
Batch 40, Loss: 0.5491
Batch 50, Loss: 0.5791
Batch 60, Loss: 0.5712
Batch 70, Loss: 0.5578
Batch 80, Loss: 0.6010
Batch 90, Loss: 0.5840
Batch 100, Loss: 0.5499
Batch 110, Loss: 0.5539
Batch 120, Loss: 0.5422
Batch 130, Loss: 0.5840
Batch 140, Loss: 0.5816
Batch 150, Loss: 0.5506
Batch 160, Loss: 0.5613
Batch 170, Loss: 0.5778
Batch 180, Loss: 0.5572
Batch 190, Loss: 0.5872
Batch 200, Loss: 0.6137
Batch 210, Loss: 0.5929
Batch 220, Loss: 0.6273
Batch 230, Loss: 0.5802
Batch 240, Loss: 0.5596
Batch 250, Loss: 0.5897
Batch 260, Loss: 0.5854
Batch 270, Loss: 0.5615
Batch 280, Loss: 0.5869
Batch 290, Loss: 0.5873
Batch 300, Loss: 0.5657
Batch 310, Loss: 0.5623
Batch 320, Loss: 0.6366
Batch 330, Loss: 0.5685
Batch 340, Loss: 0.6016
Batch 350, Loss: 0.6276
Batch 360, Loss: 0.6200
Batch 370, Loss: 0.6187
Batch 380, Loss: 0.6040
Batch 390, Loss: 0.6257
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.055726289749146 seconds
Epoch 151 accuracy: 75.38%
Batch 10, Loss: 0.5283
Batch 20, Loss: 0.5639
Batch 30, Loss: 0.5738
Batch 40, Loss: 0.5618
Batch 50, Loss: 0.5584
Batch 60, Loss: 0.5576
Batch 70, Loss: 0.5641
Batch 80, Loss: 0.6003
Batch 90, Loss: 0.5511
Batch 100, Loss: 0.5759
Batch 110, Loss: 0.5743
Batch 120, Loss: 0.5648
Batch 130, Loss: 0.5620
Batch 140, Loss: 0.5489
Batch 150, Loss: 0.5860
Batch 160, Loss: 0.5991
Batch 170, Loss: 0.5715
Batch 180, Loss: 0.5571
Batch 190, Loss: 0.5449
Batch 200, Loss: 0.5767
Batch 210, Loss: 0.5877
Batch 220, Loss: 0.5321
Batch 230, Loss: 0.6111
Batch 240, Loss: 0.5424
Batch 250, Loss: 0.5697
Batch 260, Loss: 0.5834
Batch 270, Loss: 0.5980
Batch 280, Loss: 0.5914
Batch 290, Loss: 0.5629
Batch 300, Loss: 0.6101
Batch 310, Loss: 0.6102
Batch 320, Loss: 0.6114
Batch 330, Loss: 0.5955
Batch 340, Loss: 0.6012
Batch 350, Loss: 0.5608
Batch 360, Loss: 0.5734
Batch 370, Loss: 0.5971
Batch 380, Loss: 0.6048
Batch 390, Loss: 0.5734
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.084474325180054 seconds
Epoch 152 accuracy: 75.48%
Batch 10, Loss: 0.5285
Batch 20, Loss: 0.4964
Batch 30, Loss: 0.5686
Batch 40, Loss: 0.5457
Batch 50, Loss: 0.5667
Batch 60, Loss: 0.5203
Batch 70, Loss: 0.5466
Batch 80, Loss: 0.5000
Batch 90, Loss: 0.5697
Batch 100, Loss: 0.5446
Batch 110, Loss: 0.5370
Batch 120, Loss: 0.5625
Batch 130, Loss: 0.5499
Batch 140, Loss: 0.5655
Batch 150, Loss: 0.5824
Batch 160, Loss: 0.5723
Batch 170, Loss: 0.6267
Batch 180, Loss: 0.5702
Batch 190, Loss: 0.5462
Batch 200, Loss: 0.5319
Batch 210, Loss: 0.5648
Batch 220, Loss: 0.5686
Batch 230, Loss: 0.5587
Batch 240, Loss: 0.5819
Batch 250, Loss: 0.5169
Batch 260, Loss: 0.5762
Batch 270, Loss: 0.5567
Batch 280, Loss: 0.5713
Batch 290, Loss: 0.5911
Batch 300, Loss: 0.5272
Batch 310, Loss: 0.5398
Batch 320, Loss: 0.5663
Batch 330, Loss: 0.5705
Batch 340, Loss: 0.5888
Batch 350, Loss: 0.5392
Batch 360, Loss: 0.5883
Batch 370, Loss: 0.5723
Batch 380, Loss: 0.5822
Batch 390, Loss: 0.6194
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.09416174888611 seconds
Epoch 153 accuracy: 74.13%
Batch 10, Loss: 0.5900
Batch 20, Loss: 0.5129
Batch 30, Loss: 0.5677
Batch 40, Loss: 0.5412
Batch 50, Loss: 0.5966
Batch 60, Loss: 0.5772
Batch 70, Loss: 0.5471
Batch 80, Loss: 0.4852
Batch 90, Loss: 0.5330
Batch 100, Loss: 0.5492
Batch 110, Loss: 0.5017
Batch 120, Loss: 0.5450
Batch 130, Loss: 0.5463
Batch 140, Loss: 0.5681
Batch 150, Loss: 0.5321
Batch 160, Loss: 0.5786
Batch 170, Loss: 0.5400
Batch 180, Loss: 0.5756
Batch 190, Loss: 0.5348
Batch 200, Loss: 0.5351
Batch 210, Loss: 0.5168
Batch 220, Loss: 0.5469
Batch 230, Loss: 0.5251
Batch 240, Loss: 0.6164
Batch 250, Loss: 0.5138
Batch 260, Loss: 0.5992
Batch 270, Loss: 0.5786
Batch 280, Loss: 0.5843
Batch 290, Loss: 0.5640
Batch 300, Loss: 0.5606
Batch 310, Loss: 0.5451
Batch 320, Loss: 0.5442
Batch 330, Loss: 0.5537
Batch 340, Loss: 0.5541
Batch 350, Loss: 0.5451
Batch 360, Loss: 0.5357
Batch 370, Loss: 0.5513
Batch 380, Loss: 0.5431
Batch 390, Loss: 0.5495
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.22528839111328 seconds
Epoch 154 accuracy: 75.23%
Batch 10, Loss: 0.5538
Batch 20, Loss: 0.5097
Batch 30, Loss: 0.5255
Batch 40, Loss: 0.5103
Batch 50, Loss: 0.5597
Batch 60, Loss: 0.5207
Batch 70, Loss: 0.5040
Batch 80, Loss: 0.4997
Batch 90, Loss: 0.5583
Batch 100, Loss: 0.5255
Batch 110, Loss: 0.5464
Batch 120, Loss: 0.5155
Batch 130, Loss: 0.5435
Batch 140, Loss: 0.5802
Batch 150, Loss: 0.5272
Batch 160, Loss: 0.5037
Batch 170, Loss: 0.5904
Batch 180, Loss: 0.5021
Batch 190, Loss: 0.5071
Batch 200, Loss: 0.5290
Batch 210, Loss: 0.5372
Batch 220, Loss: 0.5494
Batch 230, Loss: 0.5539
Batch 240, Loss: 0.5613
Batch 250, Loss: 0.5387
Batch 260, Loss: 0.5703
Batch 270, Loss: 0.5168
Batch 280, Loss: 0.5513
Batch 290, Loss: 0.5633
Batch 300, Loss: 0.5267
Batch 310, Loss: 0.5713
Batch 320, Loss: 0.5654
Batch 330, Loss: 0.5622
Batch 340, Loss: 0.5665
Batch 350, Loss: 0.5495
Batch 360, Loss: 0.5149
Batch 370, Loss: 0.5582
Batch 380, Loss: 0.5627
Batch 390, Loss: 0.5653
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.21789574623108 seconds
Epoch 155 accuracy: 75.33%
Batch 10, Loss: 0.5023
Batch 20, Loss: 0.5158
Batch 30, Loss: 0.5352
Batch 40, Loss: 0.5211
Batch 50, Loss: 0.4920
Batch 60, Loss: 0.5193
Batch 70, Loss: 0.5022
Batch 80, Loss: 0.4853
Batch 90, Loss: 0.5218
Batch 100, Loss: 0.4855
Batch 110, Loss: 0.4990
Batch 120, Loss: 0.4971
Batch 130, Loss: 0.5551
Batch 140, Loss: 0.5303
Batch 150, Loss: 0.5285
Batch 160, Loss: 0.5303
Batch 170, Loss: 0.5454
Batch 180, Loss: 0.5693
Batch 190, Loss: 0.5127
Batch 200, Loss: 0.5303
Batch 210, Loss: 0.5115
Batch 220, Loss: 0.4939
Batch 230, Loss: 0.5212
Batch 240, Loss: 0.5702
Batch 250, Loss: 0.4926
Batch 260, Loss: 0.4921
Batch 270, Loss: 0.5008
Batch 280, Loss: 0.6045
Batch 290, Loss: 0.5318
Batch 300, Loss: 0.5734
Batch 310, Loss: 0.4960
Batch 320, Loss: 0.5206
Batch 330, Loss: 0.5707
Batch 340, Loss: 0.5314
Batch 350, Loss: 0.5417
Batch 360, Loss: 0.5891
Batch 370, Loss: 0.5164
Batch 380, Loss: 0.5314
Batch 390, Loss: 0.5357
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.25474238395691 seconds
Epoch 156 accuracy: 75.21%
Batch 10, Loss: 0.5200
Batch 20, Loss: 0.5032
Batch 30, Loss: 0.4783
Batch 40, Loss: 0.4959
Batch 50, Loss: 0.4818
Batch 60, Loss: 0.4814
Batch 70, Loss: 0.4912
Batch 80, Loss: 0.4939
Batch 90, Loss: 0.5372
Batch 100, Loss: 0.5169
Batch 110, Loss: 0.4724
Batch 120, Loss: 0.4920
Batch 130, Loss: 0.4877
Batch 140, Loss: 0.5181
Batch 150, Loss: 0.4822
Batch 160, Loss: 0.5189
Batch 170, Loss: 0.5143
Batch 180, Loss: 0.4788
Batch 190, Loss: 0.4784
Batch 200, Loss: 0.4994
Batch 210, Loss: 0.4662
Batch 220, Loss: 0.4867
Batch 230, Loss: 0.4767
Batch 240, Loss: 0.5211
Batch 250, Loss: 0.5383
Batch 260, Loss: 0.5060
Batch 270, Loss: 0.4978
Batch 280, Loss: 0.5025
Batch 290, Loss: 0.4977
Batch 300, Loss: 0.5201
Batch 310, Loss: 0.4932
Batch 320, Loss: 0.5269
Batch 330, Loss: 0.5125
Batch 340, Loss: 0.5062
Batch 350, Loss: 0.5587
Batch 360, Loss: 0.5509
Batch 370, Loss: 0.5248
Batch 380, Loss: 0.5308
Batch 390, Loss: 0.4994
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.21331000328064 seconds
Epoch 157 accuracy: 75.89%
Batch 10, Loss: 0.4330
Batch 20, Loss: 0.5062
Batch 30, Loss: 0.4811
Batch 40, Loss: 0.4234
Batch 50, Loss: 0.5028
Batch 60, Loss: 0.4633
Batch 70, Loss: 0.4831
Batch 80, Loss: 0.5131
Batch 90, Loss: 0.4939
Batch 100, Loss: 0.4518
Batch 110, Loss: 0.4819
Batch 120, Loss: 0.4859
Batch 130, Loss: 0.5122
Batch 140, Loss: 0.4546
Batch 150, Loss: 0.4938
Batch 160, Loss: 0.4718
Batch 170, Loss: 0.4595
Batch 180, Loss: 0.4853
Batch 190, Loss: 0.5110
Batch 200, Loss: 0.4927
Batch 210, Loss: 0.5009
Batch 220, Loss: 0.4930
Batch 230, Loss: 0.4764
Batch 240, Loss: 0.4422
Batch 250, Loss: 0.5447
Batch 260, Loss: 0.4772
Batch 270, Loss: 0.5239
Batch 280, Loss: 0.4751
Batch 290, Loss: 0.5298
Batch 300, Loss: 0.5126
Batch 310, Loss: 0.4891
Batch 320, Loss: 0.4921
Batch 330, Loss: 0.4824
Batch 340, Loss: 0.4866
Batch 350, Loss: 0.5333
Batch 360, Loss: 0.5326
Batch 370, Loss: 0.4878
Batch 380, Loss: 0.5555
Batch 390, Loss: 0.5189
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.09116554260254 seconds
Epoch 158 accuracy: 76.78%
Batch 10, Loss: 0.4544
Batch 20, Loss: 0.5136
Batch 30, Loss: 0.4822
Batch 40, Loss: 0.4940
Batch 50, Loss: 0.4711
Batch 60, Loss: 0.4995
Batch 70, Loss: 0.4705
Batch 80, Loss: 0.4863
Batch 90, Loss: 0.4725
Batch 100, Loss: 0.4733
Batch 110, Loss: 0.5116
Batch 120, Loss: 0.5042
Batch 130, Loss: 0.4711
Batch 140, Loss: 0.4884
Batch 150, Loss: 0.4766
Batch 160, Loss: 0.4965
Batch 170, Loss: 0.4775
Batch 180, Loss: 0.4776
Batch 190, Loss: 0.4588
Batch 200, Loss: 0.5166
Batch 210, Loss: 0.4696
Batch 220, Loss: 0.4854
Batch 230, Loss: 0.5177
Batch 240, Loss: 0.5204
Batch 250, Loss: 0.4610
Batch 260, Loss: 0.5027
Batch 270, Loss: 0.5014
Batch 280, Loss: 0.5468
Batch 290, Loss: 0.4531
Batch 300, Loss: 0.4650
Batch 310, Loss: 0.4915
Batch 320, Loss: 0.4900
Batch 330, Loss: 0.4684
Batch 340, Loss: 0.4519
Batch 350, Loss: 0.4892
Batch 360, Loss: 0.5273
Batch 370, Loss: 0.4949
Batch 380, Loss: 0.5035
Batch 390, Loss: 0.4911
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.178751945495605 seconds
Epoch 159 accuracy: 75.92%
Batch 10, Loss: 0.4509
Batch 20, Loss: 0.4757
Batch 30, Loss: 0.4852
Batch 40, Loss: 0.4458
Batch 50, Loss: 0.4612
Batch 60, Loss: 0.4260
Batch 70, Loss: 0.4903
Batch 80, Loss: 0.4820
Batch 90, Loss: 0.4392
Batch 100, Loss: 0.5006
Batch 110, Loss: 0.4502
Batch 120, Loss: 0.4919
Batch 130, Loss: 0.4237
Batch 140, Loss: 0.4775
Batch 150, Loss: 0.4783
Batch 160, Loss: 0.4831
Batch 170, Loss: 0.4711
Batch 180, Loss: 0.4512
Batch 190, Loss: 0.4499
Batch 200, Loss: 0.4757
Batch 210, Loss: 0.4881
Batch 220, Loss: 0.4791
Batch 230, Loss: 0.4615
Batch 240, Loss: 0.4666
Batch 250, Loss: 0.4573
Batch 260, Loss: 0.4441
Batch 270, Loss: 0.4695
Batch 280, Loss: 0.4720
Batch 290, Loss: 0.4842
Batch 300, Loss: 0.4684
Batch 310, Loss: 0.4791
Batch 320, Loss: 0.4826
Batch 330, Loss: 0.4762
Batch 340, Loss: 0.4694
Batch 350, Loss: 0.4796
Batch 360, Loss: 0.5118
Batch 370, Loss: 0.4758
Batch 380, Loss: 0.5600
Batch 390, Loss: 0.5064
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.184147596359253 seconds
Epoch 160 accuracy: 75.47%
Batch 10, Loss: 0.4968
Batch 20, Loss: 0.4299
Batch 30, Loss: 0.4901
Batch 40, Loss: 0.4453
Batch 50, Loss: 0.4495
Batch 60, Loss: 0.4978
Batch 70, Loss: 0.4411
Batch 80, Loss: 0.4556
Batch 90, Loss: 0.4677
Batch 100, Loss: 0.4815
Batch 110, Loss: 0.4506
Batch 120, Loss: 0.4775
Batch 130, Loss: 0.4479
Batch 140, Loss: 0.4497
Batch 150, Loss: 0.4342
Batch 160, Loss: 0.4436
Batch 170, Loss: 0.4729
Batch 180, Loss: 0.4813
Batch 190, Loss: 0.4650
Batch 200, Loss: 0.4837
Batch 210, Loss: 0.4589
Batch 220, Loss: 0.5073
Batch 230, Loss: 0.5020
Batch 240, Loss: 0.4650
Batch 250, Loss: 0.4700
Batch 260, Loss: 0.4671
Batch 270, Loss: 0.4948
Batch 280, Loss: 0.4790
Batch 290, Loss: 0.4908
Batch 300, Loss: 0.4658
Batch 310, Loss: 0.4747
Batch 320, Loss: 0.4966
Batch 330, Loss: 0.4680
Batch 340, Loss: 0.4485
Batch 350, Loss: 0.4758
Batch 360, Loss: 0.4675
Batch 370, Loss: 0.4476
Batch 380, Loss: 0.4748
Batch 390, Loss: 0.4271
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.166026830673218 seconds
Epoch 161 accuracy: 76.11%
Batch 10, Loss: 0.4524
Batch 20, Loss: 0.4530
Batch 30, Loss: 0.4405
Batch 40, Loss: 0.4386
Batch 50, Loss: 0.4426
Batch 60, Loss: 0.4535
Batch 70, Loss: 0.4085
Batch 80, Loss: 0.4652
Batch 90, Loss: 0.4492
Batch 100, Loss: 0.4182
Batch 110, Loss: 0.4410
Batch 120, Loss: 0.4165
Batch 130, Loss: 0.4249
Batch 140, Loss: 0.4512
Batch 150, Loss: 0.4282
Batch 160, Loss: 0.4282
Batch 170, Loss: 0.4719
Batch 180, Loss: 0.4144
Batch 190, Loss: 0.4573
Batch 200, Loss: 0.4743
Batch 210, Loss: 0.4568
Batch 220, Loss: 0.4700
Batch 230, Loss: 0.4377
Batch 240, Loss: 0.4430
Batch 250, Loss: 0.4573
Batch 260, Loss: 0.4606
Batch 270, Loss: 0.4475
Batch 280, Loss: 0.4493
Batch 290, Loss: 0.4362
Batch 300, Loss: 0.5163
Batch 310, Loss: 0.4550
Batch 320, Loss: 0.4684
Batch 330, Loss: 0.4020
Batch 340, Loss: 0.4626
Batch 350, Loss: 0.4495
Batch 360, Loss: 0.4711
Batch 370, Loss: 0.4822
Batch 380, Loss: 0.4440
Batch 390, Loss: 0.4252
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.365973234176636 seconds
Epoch 162 accuracy: 76.9%
Batch 10, Loss: 0.4290
Batch 20, Loss: 0.4321
Batch 30, Loss: 0.4123
Batch 40, Loss: 0.4578
Batch 50, Loss: 0.4109
Batch 60, Loss: 0.4318
Batch 70, Loss: 0.4048
Batch 80, Loss: 0.4383
Batch 90, Loss: 0.4452
Batch 100, Loss: 0.4431
Batch 110, Loss: 0.4584
Batch 120, Loss: 0.4265
Batch 130, Loss: 0.4601
Batch 140, Loss: 0.4493
Batch 150, Loss: 0.4156
Batch 160, Loss: 0.4022
Batch 170, Loss: 0.4923
Batch 180, Loss: 0.4073
Batch 190, Loss: 0.4397
Batch 200, Loss: 0.4518
Batch 210, Loss: 0.4556
Batch 220, Loss: 0.4493
Batch 230, Loss: 0.4330
Batch 240, Loss: 0.4779
Batch 250, Loss: 0.4509
Batch 260, Loss: 0.4210
Batch 270, Loss: 0.4786
Batch 280, Loss: 0.4545
Batch 290, Loss: 0.4809
Batch 300, Loss: 0.4812
Batch 310, Loss: 0.4579
Batch 320, Loss: 0.4283
Batch 330, Loss: 0.4604
Batch 340, Loss: 0.4317
Batch 350, Loss: 0.4684
Batch 360, Loss: 0.4166
Batch 370, Loss: 0.4655
Batch 380, Loss: 0.4825
Batch 390, Loss: 0.4155
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.16333270072937 seconds
Epoch 163 accuracy: 76.56%
Batch 10, Loss: 0.3822
Batch 20, Loss: 0.4137
Batch 30, Loss: 0.4411
Batch 40, Loss: 0.4284
Batch 50, Loss: 0.4172
Batch 60, Loss: 0.4456
Batch 70, Loss: 0.4511
Batch 80, Loss: 0.4197
Batch 90, Loss: 0.4251
Batch 100, Loss: 0.4084
Batch 110, Loss: 0.4352
Batch 120, Loss: 0.4213
Batch 130, Loss: 0.4684
Batch 140, Loss: 0.3837
Batch 150, Loss: 0.4142
Batch 160, Loss: 0.4040
Batch 170, Loss: 0.4429
Batch 180, Loss: 0.4379
Batch 190, Loss: 0.4506
Batch 200, Loss: 0.4631
Batch 210, Loss: 0.4423
Batch 220, Loss: 0.4409
Batch 230, Loss: 0.3958
Batch 240, Loss: 0.4043
Batch 250, Loss: 0.4099
Batch 260, Loss: 0.4354
Batch 270, Loss: 0.4311
Batch 280, Loss: 0.4385
Batch 290, Loss: 0.4360
Batch 300, Loss: 0.4192
Batch 310, Loss: 0.3790
Batch 320, Loss: 0.4790
Batch 330, Loss: 0.4717
Batch 340, Loss: 0.4477
Batch 350, Loss: 0.4256
Batch 360, Loss: 0.4307
Batch 370, Loss: 0.4709
Batch 380, Loss: 0.4380
Batch 390, Loss: 0.4675
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.23710823059082 seconds
Epoch 164 accuracy: 76.87%
Batch 10, Loss: 0.4074
Batch 20, Loss: 0.4495
Batch 30, Loss: 0.4405
Batch 40, Loss: 0.4306
Batch 50, Loss: 0.4304
Batch 60, Loss: 0.4405
Batch 70, Loss: 0.3872
Batch 80, Loss: 0.3965
Batch 90, Loss: 0.4193
Batch 100, Loss: 0.3895
Batch 110, Loss: 0.3971
Batch 120, Loss: 0.3832
Batch 130, Loss: 0.3790
Batch 140, Loss: 0.3954
Batch 150, Loss: 0.4099
Batch 160, Loss: 0.3883
Batch 170, Loss: 0.4013
Batch 180, Loss: 0.3548
Batch 190, Loss: 0.3862
Batch 200, Loss: 0.4371
Batch 210, Loss: 0.3873
Batch 220, Loss: 0.4348
Batch 230, Loss: 0.4081
Batch 240, Loss: 0.4314
Batch 250, Loss: 0.4216
Batch 260, Loss: 0.4315
Batch 270, Loss: 0.4163
Batch 280, Loss: 0.4145
Batch 290, Loss: 0.4098
Batch 300, Loss: 0.4262
Batch 310, Loss: 0.4247
Batch 320, Loss: 0.4201
Batch 330, Loss: 0.4302
Batch 340, Loss: 0.4089
Batch 350, Loss: 0.4725
Batch 360, Loss: 0.4298
Batch 370, Loss: 0.4315
Batch 380, Loss: 0.4224
Batch 390, Loss: 0.4294
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.112029552459717 seconds
Epoch 165 accuracy: 77.33%
Batch 10, Loss: 0.4040
Batch 20, Loss: 0.3804
Batch 30, Loss: 0.3950
Batch 40, Loss: 0.3773
Batch 50, Loss: 0.4181
Batch 60, Loss: 0.4209
Batch 70, Loss: 0.4162
Batch 80, Loss: 0.3962
Batch 90, Loss: 0.3932
Batch 100, Loss: 0.4340
Batch 110, Loss: 0.4215
Batch 120, Loss: 0.4008
Batch 130, Loss: 0.3865
Batch 140, Loss: 0.4462
Batch 150, Loss: 0.4709
Batch 160, Loss: 0.4198
Batch 170, Loss: 0.4817
Batch 180, Loss: 0.4197
Batch 190, Loss: 0.4310
Batch 200, Loss: 0.4226
Batch 210, Loss: 0.4138
Batch 220, Loss: 0.4206
Batch 230, Loss: 0.4139
Batch 240, Loss: 0.4210
Batch 250, Loss: 0.3948
Batch 260, Loss: 0.4353
Batch 270, Loss: 0.4241
Batch 280, Loss: 0.4254
Batch 290, Loss: 0.4082
Batch 300, Loss: 0.3919
Batch 310, Loss: 0.4415
Batch 320, Loss: 0.4123
Batch 330, Loss: 0.4344
Batch 340, Loss: 0.4354
Batch 350, Loss: 0.4267
Batch 360, Loss: 0.4109
Batch 370, Loss: 0.4045
Batch 380, Loss: 0.4145
Batch 390, Loss: 0.4176
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.136223554611206 seconds
Epoch 166 accuracy: 77.96%
Batch 10, Loss: 0.3849
Batch 20, Loss: 0.4299
Batch 30, Loss: 0.3866
Batch 40, Loss: 0.3750
Batch 50, Loss: 0.4058
Batch 60, Loss: 0.4162
Batch 70, Loss: 0.4051
Batch 80, Loss: 0.4098
Batch 90, Loss: 0.3709
Batch 100, Loss: 0.4087
Batch 110, Loss: 0.3784
Batch 120, Loss: 0.4015
Batch 130, Loss: 0.3574
Batch 140, Loss: 0.3744
Batch 150, Loss: 0.3891
Batch 160, Loss: 0.4177
Batch 170, Loss: 0.4095
Batch 180, Loss: 0.4143
Batch 190, Loss: 0.4029
Batch 200, Loss: 0.4365
Batch 210, Loss: 0.3960
Batch 220, Loss: 0.3718
Batch 230, Loss: 0.4152
Batch 240, Loss: 0.3809
Batch 250, Loss: 0.3997
Batch 260, Loss: 0.4015
Batch 270, Loss: 0.4178
Batch 280, Loss: 0.4349
Batch 290, Loss: 0.3927
Batch 300, Loss: 0.4232
Batch 310, Loss: 0.3972
Batch 320, Loss: 0.4014
Batch 330, Loss: 0.4406
Batch 340, Loss: 0.4208
Batch 350, Loss: 0.3787
Batch 360, Loss: 0.3980
Batch 370, Loss: 0.4055
Batch 380, Loss: 0.4433
Batch 390, Loss: 0.4231
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.066356658935547 seconds
Epoch 167 accuracy: 77.13%
Batch 10, Loss: 0.3853
Batch 20, Loss: 0.3569
Batch 30, Loss: 0.4023
Batch 40, Loss: 0.3904
Batch 50, Loss: 0.3718
Batch 60, Loss: 0.3695
Batch 70, Loss: 0.3959
Batch 80, Loss: 0.3941
Batch 90, Loss: 0.4045
Batch 100, Loss: 0.3694
Batch 110, Loss: 0.3848
Batch 120, Loss: 0.4057
Batch 130, Loss: 0.3617
Batch 140, Loss: 0.4097
Batch 150, Loss: 0.3503
Batch 160, Loss: 0.3733
Batch 170, Loss: 0.4101
Batch 180, Loss: 0.4404
Batch 190, Loss: 0.3804
Batch 200, Loss: 0.4405
Batch 210, Loss: 0.4011
Batch 220, Loss: 0.3697
Batch 230, Loss: 0.3780
Batch 240, Loss: 0.3888
Batch 250, Loss: 0.4111
Batch 260, Loss: 0.3822
Batch 270, Loss: 0.3708
Batch 280, Loss: 0.4015
Batch 290, Loss: 0.3995
Batch 300, Loss: 0.3772
Batch 310, Loss: 0.4042
Batch 320, Loss: 0.3572
Batch 330, Loss: 0.4062
Batch 340, Loss: 0.3760
Batch 350, Loss: 0.4129
Batch 360, Loss: 0.4034
Batch 370, Loss: 0.3802
Batch 380, Loss: 0.4207
Batch 390, Loss: 0.4041
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.11078667640686 seconds
Epoch 168 accuracy: 77.51%
Batch 10, Loss: 0.3617
Batch 20, Loss: 0.3594
Batch 30, Loss: 0.3638
Batch 40, Loss: 0.3436
Batch 50, Loss: 0.3709
Batch 60, Loss: 0.3770
Batch 70, Loss: 0.3877
Batch 80, Loss: 0.3496
Batch 90, Loss: 0.3473
Batch 100, Loss: 0.4011
Batch 110, Loss: 0.3518
Batch 120, Loss: 0.3873
Batch 130, Loss: 0.3908
Batch 140, Loss: 0.3932
Batch 150, Loss: 0.4165
Batch 160, Loss: 0.3806
Batch 170, Loss: 0.3735
Batch 180, Loss: 0.3834
Batch 190, Loss: 0.4018
Batch 200, Loss: 0.3946
Batch 210, Loss: 0.3528
Batch 220, Loss: 0.3653
Batch 230, Loss: 0.3669
Batch 240, Loss: 0.3622
Batch 250, Loss: 0.3840
Batch 260, Loss: 0.3751
Batch 270, Loss: 0.3635
Batch 280, Loss: 0.3480
Batch 290, Loss: 0.3970
Batch 300, Loss: 0.3922
Batch 310, Loss: 0.3779
Batch 320, Loss: 0.3879
Batch 330, Loss: 0.3818
Batch 340, Loss: 0.3720
Batch 350, Loss: 0.3536
Batch 360, Loss: 0.3813
Batch 370, Loss: 0.4071
Batch 380, Loss: 0.3525
Batch 390, Loss: 0.3588
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.08144760131836 seconds
Epoch 169 accuracy: 77.6%
Batch 10, Loss: 0.3719
Batch 20, Loss: 0.3425
Batch 30, Loss: 0.3662
Batch 40, Loss: 0.3707
Batch 50, Loss: 0.3473
Batch 60, Loss: 0.3452
Batch 70, Loss: 0.3291
Batch 80, Loss: 0.3260
Batch 90, Loss: 0.3545
Batch 100, Loss: 0.3862
Batch 110, Loss: 0.3713
Batch 120, Loss: 0.3562
Batch 130, Loss: 0.3721
Batch 140, Loss: 0.3503
Batch 150, Loss: 0.4183
Batch 160, Loss: 0.3666
Batch 170, Loss: 0.3963
Batch 180, Loss: 0.3956
Batch 190, Loss: 0.4189
Batch 200, Loss: 0.3868
Batch 210, Loss: 0.3778
Batch 220, Loss: 0.4048
Batch 230, Loss: 0.3535
Batch 240, Loss: 0.3681
Batch 250, Loss: 0.3858
Batch 260, Loss: 0.3868
Batch 270, Loss: 0.3638
Batch 280, Loss: 0.3671
Batch 290, Loss: 0.3472
Batch 300, Loss: 0.3740
Batch 310, Loss: 0.3765
Batch 320, Loss: 0.3823
Batch 330, Loss: 0.3839
Batch 340, Loss: 0.3921
Batch 350, Loss: 0.3861
Batch 360, Loss: 0.3659
Batch 370, Loss: 0.3905
Batch 380, Loss: 0.4124
Batch 390, Loss: 0.4051
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.162816524505615 seconds
Epoch 170 accuracy: 78.18%
Batch 10, Loss: 0.3608
Batch 20, Loss: 0.3671
Batch 30, Loss: 0.3908
Batch 40, Loss: 0.3234
Batch 50, Loss: 0.3670
Batch 60, Loss: 0.3428
Batch 70, Loss: 0.3404
Batch 80, Loss: 0.3466
Batch 90, Loss: 0.3822
Batch 100, Loss: 0.3244
Batch 110, Loss: 0.3752
Batch 120, Loss: 0.3639
Batch 130, Loss: 0.3916
Batch 140, Loss: 0.3461
Batch 150, Loss: 0.3469
Batch 160, Loss: 0.3614
Batch 170, Loss: 0.3433
Batch 180, Loss: 0.3712
Batch 190, Loss: 0.3847
Batch 200, Loss: 0.3411
Batch 210, Loss: 0.3683
Batch 220, Loss: 0.3408
Batch 230, Loss: 0.3810
Batch 240, Loss: 0.3488
Batch 250, Loss: 0.3668
Batch 260, Loss: 0.3414
Batch 270, Loss: 0.4130
Batch 280, Loss: 0.3583
Batch 290, Loss: 0.3150
Batch 300, Loss: 0.3682
Batch 310, Loss: 0.3769
Batch 320, Loss: 0.3489
Batch 330, Loss: 0.3527
Batch 340, Loss: 0.3638
Batch 350, Loss: 0.3526
Batch 360, Loss: 0.3884
Batch 370, Loss: 0.3678
Batch 380, Loss: 0.3838
Batch 390, Loss: 0.3701
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.204254865646362 seconds
Epoch 171 accuracy: 77.91%
Batch 10, Loss: 0.3682
Batch 20, Loss: 0.3508
Batch 30, Loss: 0.3358
Batch 40, Loss: 0.3439
Batch 50, Loss: 0.3362
Batch 60, Loss: 0.3488
Batch 70, Loss: 0.3628
Batch 80, Loss: 0.3489
Batch 90, Loss: 0.3791
Batch 100, Loss: 0.3367
Batch 110, Loss: 0.3677
Batch 120, Loss: 0.3558
Batch 130, Loss: 0.3087
Batch 140, Loss: 0.3401
Batch 150, Loss: 0.3648
Batch 160, Loss: 0.3626
Batch 170, Loss: 0.3623
Batch 180, Loss: 0.3712
Batch 190, Loss: 0.3545
Batch 200, Loss: 0.3217
Batch 210, Loss: 0.3391
Batch 220, Loss: 0.3848
Batch 230, Loss: 0.3635
Batch 240, Loss: 0.3775
Batch 250, Loss: 0.3216
Batch 260, Loss: 0.3193
Batch 270, Loss: 0.3835
Batch 280, Loss: 0.3545
Batch 290, Loss: 0.3650
Batch 300, Loss: 0.3610
Batch 310, Loss: 0.3286
Batch 320, Loss: 0.3699
Batch 330, Loss: 0.3550
Batch 340, Loss: 0.3706
Batch 350, Loss: 0.3690
Batch 360, Loss: 0.3494
Batch 370, Loss: 0.3666
Batch 380, Loss: 0.3461
Batch 390, Loss: 0.3877
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.20952582359314 seconds
Epoch 172 accuracy: 78.2%
Batch 10, Loss: 0.3309
Batch 20, Loss: 0.3727
Batch 30, Loss: 0.3431
Batch 40, Loss: 0.3259
Batch 50, Loss: 0.3374
Batch 60, Loss: 0.3768
Batch 70, Loss: 0.3696
Batch 80, Loss: 0.3255
Batch 90, Loss: 0.3042
Batch 100, Loss: 0.3248
Batch 110, Loss: 0.3404
Batch 120, Loss: 0.3609
Batch 130, Loss: 0.3348
Batch 140, Loss: 0.3522
Batch 150, Loss: 0.3083
Batch 160, Loss: 0.3724
Batch 170, Loss: 0.3515
Batch 180, Loss: 0.3283
Batch 190, Loss: 0.3232
Batch 200, Loss: 0.3339
Batch 210, Loss: 0.3366
Batch 220, Loss: 0.3535
Batch 230, Loss: 0.3255
Batch 240, Loss: 0.3441
Batch 250, Loss: 0.3355
Batch 260, Loss: 0.3290
Batch 270, Loss: 0.3290
Batch 280, Loss: 0.3534
Batch 290, Loss: 0.3426
Batch 300, Loss: 0.3413
Batch 310, Loss: 0.3864
Batch 320, Loss: 0.3435
Batch 330, Loss: 0.3470
Batch 340, Loss: 0.3374
Batch 350, Loss: 0.3654
Batch 360, Loss: 0.3377
Batch 370, Loss: 0.3572
Batch 380, Loss: 0.3580
Batch 390, Loss: 0.3627
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.209357261657715 seconds
Epoch 173 accuracy: 78.38%
Batch 10, Loss: 0.3181
Batch 20, Loss: 0.3161
Batch 30, Loss: 0.3160
Batch 40, Loss: 0.3273
Batch 50, Loss: 0.3195
Batch 60, Loss: 0.3281
Batch 70, Loss: 0.3381
Batch 80, Loss: 0.2984
Batch 90, Loss: 0.3219
Batch 100, Loss: 0.3176
Batch 110, Loss: 0.3202
Batch 120, Loss: 0.3253
Batch 130, Loss: 0.3292
Batch 140, Loss: 0.2924
Batch 150, Loss: 0.3181
Batch 160, Loss: 0.2908
Batch 170, Loss: 0.2995
Batch 180, Loss: 0.3652
Batch 190, Loss: 0.3678
Batch 200, Loss: 0.3574
Batch 210, Loss: 0.3721
Batch 220, Loss: 0.3087
Batch 230, Loss: 0.3216
Batch 240, Loss: 0.3385
Batch 250, Loss: 0.3077
Batch 260, Loss: 0.2770
Batch 270, Loss: 0.3170
Batch 280, Loss: 0.3361
Batch 290, Loss: 0.3702
Batch 300, Loss: 0.2897
Batch 310, Loss: 0.3699
Batch 320, Loss: 0.3299
Batch 330, Loss: 0.3404
Batch 340, Loss: 0.3624
Batch 350, Loss: 0.3287
Batch 360, Loss: 0.3433
Batch 370, Loss: 0.3457
Batch 380, Loss: 0.3674
Batch 390, Loss: 0.3437
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.302648782730103 seconds
Epoch 174 accuracy: 78.45%
Batch 10, Loss: 0.3270
Batch 20, Loss: 0.3211
Batch 30, Loss: 0.3191
Batch 40, Loss: 0.3014
Batch 50, Loss: 0.3454
Batch 60, Loss: 0.3301
Batch 70, Loss: 0.3033
Batch 80, Loss: 0.3345
Batch 90, Loss: 0.3362
Batch 100, Loss: 0.3319
Batch 110, Loss: 0.2884
Batch 120, Loss: 0.3222
Batch 130, Loss: 0.3502
Batch 140, Loss: 0.3198
Batch 150, Loss: 0.3571
Batch 160, Loss: 0.3202
Batch 170, Loss: 0.3161
Batch 180, Loss: 0.3034
Batch 190, Loss: 0.3071
Batch 200, Loss: 0.3604
Batch 210, Loss: 0.3262
Batch 220, Loss: 0.3302
Batch 230, Loss: 0.3311
Batch 240, Loss: 0.3330
Batch 250, Loss: 0.3268
Batch 260, Loss: 0.3189
Batch 270, Loss: 0.3372
Batch 280, Loss: 0.3188
Batch 290, Loss: 0.3237
Batch 300, Loss: 0.3215
Batch 310, Loss: 0.2943
Batch 320, Loss: 0.2999
Batch 330, Loss: 0.3447
Batch 340, Loss: 0.3184
Batch 350, Loss: 0.3532
Batch 360, Loss: 0.3430
Batch 370, Loss: 0.3460
Batch 380, Loss: 0.3572
Batch 390, Loss: 0.3490
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.199214935302734 seconds
Epoch 175 accuracy: 78.82%
Batch 10, Loss: 0.2880
Batch 20, Loss: 0.3278
Batch 30, Loss: 0.2912
Batch 40, Loss: 0.3112
Batch 50, Loss: 0.3531
Batch 60, Loss: 0.3257
Batch 70, Loss: 0.3242
Batch 80, Loss: 0.2953
Batch 90, Loss: 0.3197
Batch 100, Loss: 0.3378
Batch 110, Loss: 0.2989
Batch 120, Loss: 0.3391
Batch 130, Loss: 0.3301
Batch 140, Loss: 0.3391
Batch 150, Loss: 0.3179
Batch 160, Loss: 0.2970
Batch 170, Loss: 0.3030
Batch 180, Loss: 0.2996
Batch 190, Loss: 0.3149
Batch 200, Loss: 0.3259
Batch 210, Loss: 0.3139
Batch 220, Loss: 0.3220
Batch 230, Loss: 0.2983
Batch 240, Loss: 0.3382
Batch 250, Loss: 0.3555
Batch 260, Loss: 0.3074
Batch 270, Loss: 0.2975
Batch 280, Loss: 0.3164
Batch 290, Loss: 0.2884
Batch 300, Loss: 0.3137
Batch 310, Loss: 0.3252
Batch 320, Loss: 0.3008
Batch 330, Loss: 0.3305
Batch 340, Loss: 0.3356
Batch 350, Loss: 0.3086
Batch 360, Loss: 0.3270
Batch 370, Loss: 0.3194
Batch 380, Loss: 0.3139
Batch 390, Loss: 0.3158
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.124793767929077 seconds
Epoch 176 accuracy: 78.99%
Batch 10, Loss: 0.3293
Batch 20, Loss: 0.3200
Batch 30, Loss: 0.2788
Batch 40, Loss: 0.2830
Batch 50, Loss: 0.3244
Batch 60, Loss: 0.3135
Batch 70, Loss: 0.3221
Batch 80, Loss: 0.3305
Batch 90, Loss: 0.3136
Batch 100, Loss: 0.3021
Batch 110, Loss: 0.3161
Batch 120, Loss: 0.2722
Batch 130, Loss: 0.3348
Batch 140, Loss: 0.3333
Batch 150, Loss: 0.3494
Batch 160, Loss: 0.3249
Batch 170, Loss: 0.3427
Batch 180, Loss: 0.2793
Batch 190, Loss: 0.3114
Batch 200, Loss: 0.3101
Batch 210, Loss: 0.3004
Batch 220, Loss: 0.3464
Batch 230, Loss: 0.2983
Batch 240, Loss: 0.2944
Batch 250, Loss: 0.3057
Batch 260, Loss: 0.3102
Batch 270, Loss: 0.3139
Batch 280, Loss: 0.3276
Batch 290, Loss: 0.2898
Batch 300, Loss: 0.3395
Batch 310, Loss: 0.3208
Batch 320, Loss: 0.3118
Batch 330, Loss: 0.2869
Batch 340, Loss: 0.3084
Batch 350, Loss: 0.3243
Batch 360, Loss: 0.3159
Batch 370, Loss: 0.3146
Batch 380, Loss: 0.3314
Batch 390, Loss: 0.3111
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.16140913963318 seconds
Epoch 177 accuracy: 78.86%
Batch 10, Loss: 0.2996
Batch 20, Loss: 0.2954
Batch 30, Loss: 0.3232
Batch 40, Loss: 0.3051
Batch 50, Loss: 0.3255
Batch 60, Loss: 0.3015
Batch 70, Loss: 0.2766
Batch 80, Loss: 0.2735
Batch 90, Loss: 0.3215
Batch 100, Loss: 0.2938
Batch 110, Loss: 0.2804
Batch 120, Loss: 0.2645
Batch 130, Loss: 0.3251
Batch 140, Loss: 0.3001
Batch 150, Loss: 0.2957
Batch 160, Loss: 0.3321
Batch 170, Loss: 0.3107
Batch 180, Loss: 0.3090
Batch 190, Loss: 0.3057
Batch 200, Loss: 0.3169
Batch 210, Loss: 0.3025
Batch 220, Loss: 0.2701
Batch 230, Loss: 0.3033
Batch 240, Loss: 0.3035
Batch 250, Loss: 0.2825
Batch 260, Loss: 0.3155
Batch 270, Loss: 0.3170
Batch 280, Loss: 0.3100
Batch 290, Loss: 0.3108
Batch 300, Loss: 0.3642
Batch 310, Loss: 0.3158
Batch 320, Loss: 0.2924
Batch 330, Loss: 0.2737
Batch 340, Loss: 0.2883
Batch 350, Loss: 0.3026
Batch 360, Loss: 0.3305
Batch 370, Loss: 0.3001
Batch 380, Loss: 0.3067
Batch 390, Loss: 0.2790
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.20117473602295 seconds
Epoch 178 accuracy: 79.19%
Batch 10, Loss: 0.2968
Batch 20, Loss: 0.2924
Batch 30, Loss: 0.2963
Batch 40, Loss: 0.2700
Batch 50, Loss: 0.3015
Batch 60, Loss: 0.3136
Batch 70, Loss: 0.2833
Batch 80, Loss: 0.2851
Batch 90, Loss: 0.2825
Batch 100, Loss: 0.3014
Batch 110, Loss: 0.2854
Batch 120, Loss: 0.3026
Batch 130, Loss: 0.2894
Batch 140, Loss: 0.3221
Batch 150, Loss: 0.3211
Batch 160, Loss: 0.3002
Batch 170, Loss: 0.2904
Batch 180, Loss: 0.2945
Batch 190, Loss: 0.2992
Batch 200, Loss: 0.2908
Batch 210, Loss: 0.3503
Batch 220, Loss: 0.3111
Batch 230, Loss: 0.3296
Batch 240, Loss: 0.3046
Batch 250, Loss: 0.3400
Batch 260, Loss: 0.3057
Batch 270, Loss: 0.3082
Batch 280, Loss: 0.2841
Batch 290, Loss: 0.3017
Batch 300, Loss: 0.2882
Batch 310, Loss: 0.3188
Batch 320, Loss: 0.2978
Batch 330, Loss: 0.2937
Batch 340, Loss: 0.3178
Batch 350, Loss: 0.3093
Batch 360, Loss: 0.2898
Batch 370, Loss: 0.3020
Batch 380, Loss: 0.3016
Batch 390, Loss: 0.3075
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.33963108062744 seconds
Epoch 179 accuracy: 79.53%
Batch 10, Loss: 0.2934
Batch 20, Loss: 0.2897
Batch 30, Loss: 0.3025
Batch 40, Loss: 0.2834
Batch 50, Loss: 0.2863
Batch 60, Loss: 0.2787
Batch 70, Loss: 0.2490
Batch 80, Loss: 0.3234
Batch 90, Loss: 0.3036
Batch 100, Loss: 0.3162
Batch 110, Loss: 0.2978
Batch 120, Loss: 0.2725
Batch 130, Loss: 0.2787
Batch 140, Loss: 0.2973
Batch 150, Loss: 0.2817
Batch 160, Loss: 0.3018
Batch 170, Loss: 0.3259
Batch 180, Loss: 0.2830
Batch 190, Loss: 0.2668
Batch 200, Loss: 0.2887
Batch 210, Loss: 0.3223
Batch 220, Loss: 0.2963
Batch 230, Loss: 0.2861
Batch 240, Loss: 0.2903
Batch 250, Loss: 0.2775
Batch 260, Loss: 0.2776
Batch 270, Loss: 0.2871
Batch 280, Loss: 0.2899
Batch 290, Loss: 0.3130
Batch 300, Loss: 0.2943
Batch 310, Loss: 0.2917
Batch 320, Loss: 0.2977
Batch 330, Loss: 0.2828
Batch 340, Loss: 0.3299
Batch 350, Loss: 0.2695
Batch 360, Loss: 0.2965
Batch 370, Loss: 0.3093
Batch 380, Loss: 0.2888
Batch 390, Loss: 0.2788
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.167861461639404 seconds
Epoch 180 accuracy: 79.29%
Batch 10, Loss: 0.2827
Batch 20, Loss: 0.2914
Batch 30, Loss: 0.2732
Batch 40, Loss: 0.3157
Batch 50, Loss: 0.2952
Batch 60, Loss: 0.2701
Batch 70, Loss: 0.2983
Batch 80, Loss: 0.3031
Batch 90, Loss: 0.2676
Batch 100, Loss: 0.2824
Batch 110, Loss: 0.2903
Batch 120, Loss: 0.2499
Batch 130, Loss: 0.2819
Batch 140, Loss: 0.2985
Batch 150, Loss: 0.2667
Batch 160, Loss: 0.2978
Batch 170, Loss: 0.2838
Batch 180, Loss: 0.2919
Batch 190, Loss: 0.2916
Batch 200, Loss: 0.3223
Batch 210, Loss: 0.2718
Batch 220, Loss: 0.2877
Batch 230, Loss: 0.2874
Batch 240, Loss: 0.3129
Batch 250, Loss: 0.3241
Batch 260, Loss: 0.2916
Batch 270, Loss: 0.2687
Batch 280, Loss: 0.2882
Batch 290, Loss: 0.2721
Batch 300, Loss: 0.2970
Batch 310, Loss: 0.2770
Batch 320, Loss: 0.2915
Batch 330, Loss: 0.2908
Batch 340, Loss: 0.2817
Batch 350, Loss: 0.2902
Batch 360, Loss: 0.2902
Batch 370, Loss: 0.2968
Batch 380, Loss: 0.2847
Batch 390, Loss: 0.2860
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.0791916847229 seconds
Epoch 181 accuracy: 79.48%
Batch 10, Loss: 0.2634
Batch 20, Loss: 0.2813
Batch 30, Loss: 0.2932
Batch 40, Loss: 0.3034
Batch 50, Loss: 0.2898
Batch 60, Loss: 0.2459
Batch 70, Loss: 0.2820
Batch 80, Loss: 0.2649
Batch 90, Loss: 0.2705
Batch 100, Loss: 0.2685
Batch 110, Loss: 0.2986
Batch 120, Loss: 0.2808
Batch 130, Loss: 0.2892
Batch 140, Loss: 0.2783
Batch 150, Loss: 0.2787
Batch 160, Loss: 0.3038
Batch 170, Loss: 0.2469
Batch 180, Loss: 0.3068
Batch 190, Loss: 0.2546
Batch 200, Loss: 0.2852
Batch 210, Loss: 0.2747
Batch 220, Loss: 0.2761
Batch 230, Loss: 0.2574
Batch 240, Loss: 0.2658
Batch 250, Loss: 0.2549
Batch 260, Loss: 0.2570
Batch 270, Loss: 0.2813
Batch 280, Loss: 0.2976
Batch 290, Loss: 0.2870
Batch 300, Loss: 0.2706
Batch 310, Loss: 0.3152
Batch 320, Loss: 0.3021
Batch 330, Loss: 0.3191
Batch 340, Loss: 0.2701
Batch 350, Loss: 0.2956
Batch 360, Loss: 0.3326
Batch 370, Loss: 0.2763
Batch 380, Loss: 0.2673
Batch 390, Loss: 0.2702
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.241201639175415 seconds
Epoch 182 accuracy: 79.56%
Batch 10, Loss: 0.2956
Batch 20, Loss: 0.2570
Batch 30, Loss: 0.2505
Batch 40, Loss: 0.3097
Batch 50, Loss: 0.2815
Batch 60, Loss: 0.2720
Batch 70, Loss: 0.2728
Batch 80, Loss: 0.2415
Batch 90, Loss: 0.2877
Batch 100, Loss: 0.2813
Batch 110, Loss: 0.2775
Batch 120, Loss: 0.2418
Batch 130, Loss: 0.2575
Batch 140, Loss: 0.2833
Batch 150, Loss: 0.2692
Batch 160, Loss: 0.2782
Batch 170, Loss: 0.2627
Batch 180, Loss: 0.2860
Batch 190, Loss: 0.2440
Batch 200, Loss: 0.2802
Batch 210, Loss: 0.3056
Batch 220, Loss: 0.2716
Batch 230, Loss: 0.2842
Batch 240, Loss: 0.2754
Batch 250, Loss: 0.2683
Batch 260, Loss: 0.2697
Batch 270, Loss: 0.2610
Batch 280, Loss: 0.2863
Batch 290, Loss: 0.2707
Batch 300, Loss: 0.2847
Batch 310, Loss: 0.2805
Batch 320, Loss: 0.2582
Batch 330, Loss: 0.2861
Batch 340, Loss: 0.2978
Batch 350, Loss: 0.2624
Batch 360, Loss: 0.2818
Batch 370, Loss: 0.2658
Batch 380, Loss: 0.2566
Batch 390, Loss: 0.2925
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.140908002853394 seconds
Epoch 183 accuracy: 79.71%
Batch 10, Loss: 0.2742
Batch 20, Loss: 0.2508
Batch 30, Loss: 0.2738
Batch 40, Loss: 0.2864
Batch 50, Loss: 0.2836
Batch 60, Loss: 0.2626
Batch 70, Loss: 0.2688
Batch 80, Loss: 0.2797
Batch 90, Loss: 0.2691
Batch 100, Loss: 0.2725
Batch 110, Loss: 0.2561
Batch 120, Loss: 0.2459
Batch 130, Loss: 0.2543
Batch 140, Loss: 0.2950
Batch 150, Loss: 0.2860
Batch 160, Loss: 0.2721
Batch 170, Loss: 0.2684
Batch 180, Loss: 0.2672
Batch 190, Loss: 0.2842
Batch 200, Loss: 0.3001
Batch 210, Loss: 0.2611
Batch 220, Loss: 0.2941
Batch 230, Loss: 0.3185
Batch 240, Loss: 0.2721
Batch 250, Loss: 0.2836
Batch 260, Loss: 0.2610
Batch 270, Loss: 0.2625
Batch 280, Loss: 0.2462
Batch 290, Loss: 0.2597
Batch 300, Loss: 0.2420
Batch 310, Loss: 0.3090
Batch 320, Loss: 0.2765
Batch 330, Loss: 0.2941
Batch 340, Loss: 0.2406
Batch 350, Loss: 0.2986
Batch 360, Loss: 0.2676
Batch 370, Loss: 0.2484
Batch 380, Loss: 0.3096
Batch 390, Loss: 0.2917
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.371667623519897 seconds
Epoch 184 accuracy: 80.0%
Batch 10, Loss: 0.2569
Batch 20, Loss: 0.2937
Batch 30, Loss: 0.2679
Batch 40, Loss: 0.2548
Batch 50, Loss: 0.2742
Batch 60, Loss: 0.2767
Batch 70, Loss: 0.2495
Batch 80, Loss: 0.2663
Batch 90, Loss: 0.2500
Batch 100, Loss: 0.2774
Batch 110, Loss: 0.2685
Batch 120, Loss: 0.2832
Batch 130, Loss: 0.2888
Batch 140, Loss: 0.2573
Batch 150, Loss: 0.3051
Batch 160, Loss: 0.2976
Batch 170, Loss: 0.2658
Batch 180, Loss: 0.2781
Batch 190, Loss: 0.2562
Batch 200, Loss: 0.2863
Batch 210, Loss: 0.2528
Batch 220, Loss: 0.2430
Batch 230, Loss: 0.2582
Batch 240, Loss: 0.2737
Batch 250, Loss: 0.2692
Batch 260, Loss: 0.2722
Batch 270, Loss: 0.2391
Batch 280, Loss: 0.2847
Batch 290, Loss: 0.2835
Batch 300, Loss: 0.2842
Batch 310, Loss: 0.2484
Batch 320, Loss: 0.2728
Batch 330, Loss: 0.2496
Batch 340, Loss: 0.2697
Batch 350, Loss: 0.2871
Batch 360, Loss: 0.2825
Batch 370, Loss: 0.2407
Batch 380, Loss: 0.2849
Batch 390, Loss: 0.2744
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.11329746246338 seconds
Epoch 185 accuracy: 79.77%
Batch 10, Loss: 0.2857
Batch 20, Loss: 0.2959
Batch 30, Loss: 0.2920
Batch 40, Loss: 0.2485
Batch 50, Loss: 0.2853
Batch 60, Loss: 0.2649
Batch 70, Loss: 0.2488
Batch 80, Loss: 0.2703
Batch 90, Loss: 0.2625
Batch 100, Loss: 0.2577
Batch 110, Loss: 0.2577
Batch 120, Loss: 0.2419
Batch 130, Loss: 0.2876
Batch 140, Loss: 0.2814
Batch 150, Loss: 0.2573
Batch 160, Loss: 0.2514
Batch 170, Loss: 0.2475
Batch 180, Loss: 0.2481
Batch 190, Loss: 0.2761
Batch 200, Loss: 0.2945
Batch 210, Loss: 0.2640
Batch 220, Loss: 0.2436
Batch 230, Loss: 0.2435
Batch 240, Loss: 0.2794
Batch 250, Loss: 0.2756
Batch 260, Loss: 0.2592
Batch 270, Loss: 0.2574
Batch 280, Loss: 0.2567
Batch 290, Loss: 0.2671
Batch 300, Loss: 0.2747
Batch 310, Loss: 0.2686
Batch 320, Loss: 0.2898
Batch 330, Loss: 0.2916
Batch 340, Loss: 0.2627
Batch 350, Loss: 0.2644
Batch 360, Loss: 0.2388
Batch 370, Loss: 0.2696
Batch 380, Loss: 0.2345
Batch 390, Loss: 0.2369
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.265138864517212 seconds
Epoch 186 accuracy: 79.94%
Batch 10, Loss: 0.2628
Batch 20, Loss: 0.2673
Batch 30, Loss: 0.2634
Batch 40, Loss: 0.2668
Batch 50, Loss: 0.2179
Batch 60, Loss: 0.2470
Batch 70, Loss: 0.2367
Batch 80, Loss: 0.2437
Batch 90, Loss: 0.2484
Batch 100, Loss: 0.2808
Batch 110, Loss: 0.2411
Batch 120, Loss: 0.2446
Batch 130, Loss: 0.2557
Batch 140, Loss: 0.2642
Batch 150, Loss: 0.2326
Batch 160, Loss: 0.2589
Batch 170, Loss: 0.2633
Batch 180, Loss: 0.2613
Batch 190, Loss: 0.2634
Batch 200, Loss: 0.2543
Batch 210, Loss: 0.2560
Batch 220, Loss: 0.2522
Batch 230, Loss: 0.2483
Batch 240, Loss: 0.2662
Batch 250, Loss: 0.2600
Batch 260, Loss: 0.2526
Batch 270, Loss: 0.2467
Batch 280, Loss: 0.2749
Batch 290, Loss: 0.2409
Batch 300, Loss: 0.2454
Batch 310, Loss: 0.2407
Batch 320, Loss: 0.2750
Batch 330, Loss: 0.2389
Batch 340, Loss: 0.2736
Batch 350, Loss: 0.2410
Batch 360, Loss: 0.2673
Batch 370, Loss: 0.2769
Batch 380, Loss: 0.2680
Batch 390, Loss: 0.2285
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.06752371788025 seconds
Epoch 187 accuracy: 80.13%
Batch 10, Loss: 0.2900
Batch 20, Loss: 0.2576
Batch 30, Loss: 0.2403
Batch 40, Loss: 0.2289
Batch 50, Loss: 0.2389
Batch 60, Loss: 0.2412
Batch 70, Loss: 0.2129
Batch 80, Loss: 0.2514
Batch 90, Loss: 0.2642
Batch 100, Loss: 0.2154
Batch 110, Loss: 0.2193
Batch 120, Loss: 0.2278
Batch 130, Loss: 0.2588
Batch 140, Loss: 0.2588
Batch 150, Loss: 0.2489
Batch 160, Loss: 0.2702
Batch 170, Loss: 0.2368
Batch 180, Loss: 0.2429
Batch 190, Loss: 0.2667
Batch 200, Loss: 0.2578
Batch 210, Loss: 0.2502
Batch 220, Loss: 0.2646
Batch 230, Loss: 0.2955
Batch 240, Loss: 0.2383
Batch 250, Loss: 0.2387
Batch 260, Loss: 0.2455
Batch 270, Loss: 0.2286
Batch 280, Loss: 0.2291
Batch 290, Loss: 0.2363
Batch 300, Loss: 0.2723
Batch 310, Loss: 0.2544
Batch 320, Loss: 0.2643
Batch 330, Loss: 0.2687
Batch 340, Loss: 0.2505
Batch 350, Loss: 0.3074
Batch 360, Loss: 0.2460
Batch 370, Loss: 0.2489
Batch 380, Loss: 0.2607
Batch 390, Loss: 0.2811
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.11071491241455 seconds
Epoch 188 accuracy: 79.99%
Batch 10, Loss: 0.2462
Batch 20, Loss: 0.2518
Batch 30, Loss: 0.2469
Batch 40, Loss: 0.2528
Batch 50, Loss: 0.2676
Batch 60, Loss: 0.2289
Batch 70, Loss: 0.2511
Batch 80, Loss: 0.2593
Batch 90, Loss: 0.2363
Batch 100, Loss: 0.2320
Batch 110, Loss: 0.2525
Batch 120, Loss: 0.2619
Batch 130, Loss: 0.2525
Batch 140, Loss: 0.2705
Batch 150, Loss: 0.2306
Batch 160, Loss: 0.2938
Batch 170, Loss: 0.2428
Batch 180, Loss: 0.2420
Batch 190, Loss: 0.2589
Batch 200, Loss: 0.2619
Batch 210, Loss: 0.2470
Batch 220, Loss: 0.2581
Batch 230, Loss: 0.2424
Batch 240, Loss: 0.2118
Batch 250, Loss: 0.2480
Batch 260, Loss: 0.2526
Batch 270, Loss: 0.2681
Batch 280, Loss: 0.2633
Batch 290, Loss: 0.2638
Batch 300, Loss: 0.2452
Batch 310, Loss: 0.2263
Batch 320, Loss: 0.2424
Batch 330, Loss: 0.2613
Batch 340, Loss: 0.2639
Batch 350, Loss: 0.2086
Batch 360, Loss: 0.2645
Batch 370, Loss: 0.2604
Batch 380, Loss: 0.2763
Batch 390, Loss: 0.2478
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.147320985794067 seconds
Epoch 189 accuracy: 80.07%
Batch 10, Loss: 0.2448
Batch 20, Loss: 0.2424
Batch 30, Loss: 0.2559
Batch 40, Loss: 0.2459
Batch 50, Loss: 0.2346
Batch 60, Loss: 0.2225
Batch 70, Loss: 0.2859
Batch 80, Loss: 0.2410
Batch 90, Loss: 0.2425
Batch 100, Loss: 0.2308
Batch 110, Loss: 0.2618
Batch 120, Loss: 0.2406
Batch 130, Loss: 0.2620
Batch 140, Loss: 0.2851
Batch 150, Loss: 0.2428
Batch 160, Loss: 0.2337
Batch 170, Loss: 0.2225
Batch 180, Loss: 0.2405
Batch 190, Loss: 0.2534
Batch 200, Loss: 0.2406
Batch 210, Loss: 0.2448
Batch 220, Loss: 0.2603
Batch 230, Loss: 0.2420
Batch 240, Loss: 0.2478
Batch 250, Loss: 0.2572
Batch 260, Loss: 0.2475
Batch 270, Loss: 0.2603
Batch 280, Loss: 0.2379
Batch 290, Loss: 0.2449
Batch 300, Loss: 0.2496
Batch 310, Loss: 0.2382
Batch 320, Loss: 0.2431
Batch 330, Loss: 0.2624
Batch 340, Loss: 0.2550
Batch 350, Loss: 0.2674
Batch 360, Loss: 0.2307
Batch 370, Loss: 0.2500
Batch 380, Loss: 0.2372
Batch 390, Loss: 0.2472
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.103201389312744 seconds
Epoch 190 accuracy: 80.07%
Batch 10, Loss: 0.2491
Batch 20, Loss: 0.2393
Batch 30, Loss: 0.2612
Batch 40, Loss: 0.2505
Batch 50, Loss: 0.2463
Batch 60, Loss: 0.2619
Batch 70, Loss: 0.2523
Batch 80, Loss: 0.2526
Batch 90, Loss: 0.2465
Batch 100, Loss: 0.2314
Batch 110, Loss: 0.2797
Batch 120, Loss: 0.2738
Batch 130, Loss: 0.2770
Batch 140, Loss: 0.2592
Batch 150, Loss: 0.2319
Batch 160, Loss: 0.2483
Batch 170, Loss: 0.2410
Batch 180, Loss: 0.2372
Batch 190, Loss: 0.2450
Batch 200, Loss: 0.2166
Batch 210, Loss: 0.2357
Batch 220, Loss: 0.2157
Batch 230, Loss: 0.2429
Batch 240, Loss: 0.2256
Batch 250, Loss: 0.2672
Batch 260, Loss: 0.2586
Batch 270, Loss: 0.2472
Batch 280, Loss: 0.2382
Batch 290, Loss: 0.2564
Batch 300, Loss: 0.2509
Batch 310, Loss: 0.2411
Batch 320, Loss: 0.2834
Batch 330, Loss: 0.2182
Batch 340, Loss: 0.2518
Batch 350, Loss: 0.2548
Batch 360, Loss: 0.2229
Batch 370, Loss: 0.2645
Batch 380, Loss: 0.2620
Batch 390, Loss: 0.2359
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.091016054153442 seconds
Epoch 191 accuracy: 80.22%
Batch 10, Loss: 0.2472
Batch 20, Loss: 0.2361
Batch 30, Loss: 0.2383
Batch 40, Loss: 0.2635
Batch 50, Loss: 0.2287
Batch 60, Loss: 0.2322
Batch 70, Loss: 0.2514
Batch 80, Loss: 0.2361
Batch 90, Loss: 0.2304
Batch 100, Loss: 0.2551
Batch 110, Loss: 0.2359
Batch 120, Loss: 0.2302
Batch 130, Loss: 0.2603
Batch 140, Loss: 0.2954
Batch 150, Loss: 0.2298
Batch 160, Loss: 0.2324
Batch 170, Loss: 0.2872
Batch 180, Loss: 0.2439
Batch 190, Loss: 0.2609
Batch 200, Loss: 0.2373
Batch 210, Loss: 0.2497
Batch 220, Loss: 0.2159
Batch 230, Loss: 0.2383
Batch 240, Loss: 0.2590
Batch 250, Loss: 0.2206
Batch 260, Loss: 0.2354
Batch 270, Loss: 0.2449
Batch 280, Loss: 0.2636
Batch 290, Loss: 0.2247
Batch 300, Loss: 0.2490
Batch 310, Loss: 0.2539
Batch 320, Loss: 0.2315
Batch 330, Loss: 0.2588
Batch 340, Loss: 0.2364
Batch 350, Loss: 0.2149
Batch 360, Loss: 0.2330
Batch 370, Loss: 0.2532
Batch 380, Loss: 0.2292
Batch 390, Loss: 0.2626
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.157376766204834 seconds
Epoch 192 accuracy: 80.21%
Batch 10, Loss: 0.2349
Batch 20, Loss: 0.2437
Batch 30, Loss: 0.2529
Batch 40, Loss: 0.2581
Batch 50, Loss: 0.2328
Batch 60, Loss: 0.2379
Batch 70, Loss: 0.2550
Batch 80, Loss: 0.2370
Batch 90, Loss: 0.2233
Batch 100, Loss: 0.2357
Batch 110, Loss: 0.2552
Batch 120, Loss: 0.2437
Batch 130, Loss: 0.2282
Batch 140, Loss: 0.2319
Batch 150, Loss: 0.2360
Batch 160, Loss: 0.2325
Batch 170, Loss: 0.2556
Batch 180, Loss: 0.2139
Batch 190, Loss: 0.2533
Batch 200, Loss: 0.2650
Batch 210, Loss: 0.2135
Batch 220, Loss: 0.2192
Batch 230, Loss: 0.2735
Batch 240, Loss: 0.2276
Batch 250, Loss: 0.2472
Batch 260, Loss: 0.2315
Batch 270, Loss: 0.2491
Batch 280, Loss: 0.2262
Batch 290, Loss: 0.2302
Batch 300, Loss: 0.2423
Batch 310, Loss: 0.2378
Batch 320, Loss: 0.2423
Batch 330, Loss: 0.2113
Batch 340, Loss: 0.2204
Batch 350, Loss: 0.2186
Batch 360, Loss: 0.2341
Batch 370, Loss: 0.2199
Batch 380, Loss: 0.2454
Batch 390, Loss: 0.2214
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.35957145690918 seconds
Epoch 193 accuracy: 80.22%
Batch 10, Loss: 0.2596
Batch 20, Loss: 0.2245
Batch 30, Loss: 0.1974
Batch 40, Loss: 0.2490
Batch 50, Loss: 0.2322
Batch 60, Loss: 0.2477
Batch 70, Loss: 0.2383
Batch 80, Loss: 0.2495
Batch 90, Loss: 0.2433
Batch 100, Loss: 0.2335
Batch 110, Loss: 0.2668
Batch 120, Loss: 0.2483
Batch 130, Loss: 0.2544
Batch 140, Loss: 0.2489
Batch 150, Loss: 0.2414
Batch 160, Loss: 0.2593
Batch 170, Loss: 0.2565
Batch 180, Loss: 0.2260
Batch 190, Loss: 0.2516
Batch 200, Loss: 0.2597
Batch 210, Loss: 0.2197
Batch 220, Loss: 0.2365
Batch 230, Loss: 0.2192
Batch 240, Loss: 0.2250
Batch 250, Loss: 0.2339
Batch 260, Loss: 0.2666
Batch 270, Loss: 0.2610
Batch 280, Loss: 0.2242
Batch 290, Loss: 0.2421
Batch 300, Loss: 0.2368
Batch 310, Loss: 0.2348
Batch 320, Loss: 0.2593
Batch 330, Loss: 0.2434
Batch 340, Loss: 0.2343
Batch 350, Loss: 0.2580
Batch 360, Loss: 0.2407
Batch 370, Loss: 0.2563
Batch 380, Loss: 0.2464
Batch 390, Loss: 0.2435
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.194753885269165 seconds
Epoch 194 accuracy: 80.04%
Batch 10, Loss: 0.2233
Batch 20, Loss: 0.2461
Batch 30, Loss: 0.2161
Batch 40, Loss: 0.2457
Batch 50, Loss: 0.2302
Batch 60, Loss: 0.2209
Batch 70, Loss: 0.2660
Batch 80, Loss: 0.2675
Batch 90, Loss: 0.2132
Batch 100, Loss: 0.2182
Batch 110, Loss: 0.2337
Batch 120, Loss: 0.2321
Batch 130, Loss: 0.2468
Batch 140, Loss: 0.2427
Batch 150, Loss: 0.2150
Batch 160, Loss: 0.2753
Batch 170, Loss: 0.2310
Batch 180, Loss: 0.2160
Batch 190, Loss: 0.2419
Batch 200, Loss: 0.2126
Batch 210, Loss: 0.2282
Batch 220, Loss: 0.2582
Batch 230, Loss: 0.2155
Batch 240, Loss: 0.2339
Batch 250, Loss: 0.2285
Batch 260, Loss: 0.2485
Batch 270, Loss: 0.2388
Batch 280, Loss: 0.2597
Batch 290, Loss: 0.2403
Batch 300, Loss: 0.2339
Batch 310, Loss: 0.2453
Batch 320, Loss: 0.2154
Batch 330, Loss: 0.2440
Batch 340, Loss: 0.2437
Batch 350, Loss: 0.2651
Batch 360, Loss: 0.2666
Batch 370, Loss: 0.2250
Batch 380, Loss: 0.2263
Batch 390, Loss: 0.2180
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.228053092956543 seconds
Epoch 195 accuracy: 80.32%
Batch 10, Loss: 0.2450
Batch 20, Loss: 0.2145
Batch 30, Loss: 0.2690
Batch 40, Loss: 0.2564
Batch 50, Loss: 0.2175
Batch 60, Loss: 0.2448
Batch 70, Loss: 0.2288
Batch 80, Loss: 0.2411
Batch 90, Loss: 0.2143
Batch 100, Loss: 0.2359
Batch 110, Loss: 0.2304
Batch 120, Loss: 0.2669
Batch 130, Loss: 0.2533
Batch 140, Loss: 0.2448
Batch 150, Loss: 0.2059
Batch 160, Loss: 0.2389
Batch 170, Loss: 0.2388
Batch 180, Loss: 0.2371
Batch 190, Loss: 0.2527
Batch 200, Loss: 0.2372
Batch 210, Loss: 0.2383
Batch 220, Loss: 0.2724
Batch 230, Loss: 0.2192
Batch 240, Loss: 0.2201
Batch 250, Loss: 0.2656
Batch 260, Loss: 0.2721
Batch 270, Loss: 0.2564
Batch 280, Loss: 0.2323
Batch 290, Loss: 0.2614
Batch 300, Loss: 0.2601
Batch 310, Loss: 0.2278
Batch 320, Loss: 0.2460
Batch 330, Loss: 0.2317
Batch 340, Loss: 0.2529
Batch 350, Loss: 0.2656
Batch 360, Loss: 0.2076
Batch 370, Loss: 0.2401
Batch 380, Loss: 0.2432
Batch 390, Loss: 0.2298
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.30539298057556 seconds
Epoch 196 accuracy: 80.26%
Batch 10, Loss: 0.2398
Batch 20, Loss: 0.2447
Batch 30, Loss: 0.2254
Batch 40, Loss: 0.2506
Batch 50, Loss: 0.2276
Batch 60, Loss: 0.2187
Batch 70, Loss: 0.2264
Batch 80, Loss: 0.2408
Batch 90, Loss: 0.2274
Batch 100, Loss: 0.2669
Batch 110, Loss: 0.2434
Batch 120, Loss: 0.2559
Batch 130, Loss: 0.2206
Batch 140, Loss: 0.2113
Batch 150, Loss: 0.2236
Batch 160, Loss: 0.2080
Batch 170, Loss: 0.2334
Batch 180, Loss: 0.2274
Batch 190, Loss: 0.2082
Batch 200, Loss: 0.2629
Batch 210, Loss: 0.2351
Batch 220, Loss: 0.2223
Batch 230, Loss: 0.2256
Batch 240, Loss: 0.1949
Batch 250, Loss: 0.2626
Batch 260, Loss: 0.2203
Batch 270, Loss: 0.2490
Batch 280, Loss: 0.2378
Batch 290, Loss: 0.2418
Batch 300, Loss: 0.2400
Batch 310, Loss: 0.2189
Batch 320, Loss: 0.2370
Batch 330, Loss: 0.2358
Batch 340, Loss: 0.2495
Batch 350, Loss: 0.2486
Batch 360, Loss: 0.2540
Batch 370, Loss: 0.2420
Batch 380, Loss: 0.2439
Batch 390, Loss: 0.2354
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.110435962677002 seconds
Epoch 197 accuracy: 80.27%
Batch 10, Loss: 0.2450
Batch 20, Loss: 0.2325
Batch 30, Loss: 0.2438
Batch 40, Loss: 0.2383
Batch 50, Loss: 0.2830
Batch 60, Loss: 0.2375
Batch 70, Loss: 0.2303
Batch 80, Loss: 0.2525
Batch 90, Loss: 0.2316
Batch 100, Loss: 0.2286
Batch 110, Loss: 0.2300
Batch 120, Loss: 0.2330
Batch 130, Loss: 0.2050
Batch 140, Loss: 0.2396
Batch 150, Loss: 0.2231
Batch 160, Loss: 0.2307
Batch 170, Loss: 0.2336
Batch 180, Loss: 0.2550
Batch 190, Loss: 0.2343
Batch 200, Loss: 0.2408
Batch 210, Loss: 0.2359
Batch 220, Loss: 0.2298
Batch 230, Loss: 0.2472
Batch 240, Loss: 0.2358
Batch 250, Loss: 0.2291
Batch 260, Loss: 0.2142
Batch 270, Loss: 0.2407
Batch 280, Loss: 0.2234
Batch 290, Loss: 0.2228
Batch 300, Loss: 0.2299
Batch 310, Loss: 0.2411
Batch 320, Loss: 0.2189
Batch 330, Loss: 0.2367
Batch 340, Loss: 0.2365
Batch 350, Loss: 0.2283
Batch 360, Loss: 0.2388
Batch 370, Loss: 0.2182
Batch 380, Loss: 0.2249
Batch 390, Loss: 0.2150
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.25467848777771 seconds
Epoch 198 accuracy: 80.28%
Batch 10, Loss: 0.2217
Batch 20, Loss: 0.2307
Batch 30, Loss: 0.2517
Batch 40, Loss: 0.2431
Batch 50, Loss: 0.2215
Batch 60, Loss: 0.2346
Batch 70, Loss: 0.2697
Batch 80, Loss: 0.2609
Batch 90, Loss: 0.2170
Batch 100, Loss: 0.2031
Batch 110, Loss: 0.2515
Batch 120, Loss: 0.2365
Batch 130, Loss: 0.2222
Batch 140, Loss: 0.2123
Batch 150, Loss: 0.2756
Batch 160, Loss: 0.2254
Batch 170, Loss: 0.2391
Batch 180, Loss: 0.2309
Batch 190, Loss: 0.2425
Batch 200, Loss: 0.2235
Batch 210, Loss: 0.2115
Batch 220, Loss: 0.2238
Batch 230, Loss: 0.2334
Batch 240, Loss: 0.2463
Batch 250, Loss: 0.2201
Batch 260, Loss: 0.2273
Batch 270, Loss: 0.2634
Batch 280, Loss: 0.2302
Batch 290, Loss: 0.2715
Batch 300, Loss: 0.2582
Batch 310, Loss: 0.2149
Batch 320, Loss: 0.2570
Batch 330, Loss: 0.2183
Batch 340, Loss: 0.2528
Batch 350, Loss: 0.2457
Batch 360, Loss: 0.2219
Batch 370, Loss: 0.2403
Batch 380, Loss: 0.2227
Batch 390, Loss: 0.2296
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.259050130844116 seconds
Epoch 199 accuracy: 80.23%
Batch 10, Loss: 0.2234
Batch 20, Loss: 0.2316
Batch 30, Loss: 0.2642
Batch 40, Loss: 0.1947
Batch 50, Loss: 0.2307
Batch 60, Loss: 0.2422
Batch 70, Loss: 0.2075
Batch 80, Loss: 0.2329
Batch 90, Loss: 0.2377
Batch 100, Loss: 0.2407
Batch 110, Loss: 0.2228
Batch 120, Loss: 0.2539
Batch 130, Loss: 0.2088
Batch 140, Loss: 0.2667
Batch 150, Loss: 0.2524
Batch 160, Loss: 0.2224
Batch 170, Loss: 0.2146
Batch 180, Loss: 0.2298
Batch 190, Loss: 0.2273
Batch 200, Loss: 0.2465
Batch 210, Loss: 0.2430
Batch 220, Loss: 0.2324
Batch 230, Loss: 0.2289
Batch 240, Loss: 0.2289
Batch 250, Loss: 0.2404
Batch 260, Loss: 0.2439
Batch 270, Loss: 0.2471
Batch 280, Loss: 0.2352
Batch 290, Loss: 0.2283
Batch 300, Loss: 0.2575
Batch 310, Loss: 0.2031
Batch 320, Loss: 0.2285
Batch 330, Loss: 0.2080
Batch 340, Loss: 0.2275
Batch 350, Loss: 0.2473
Batch 360, Loss: 0.2419
Batch 370, Loss: 0.2675
Batch 380, Loss: 0.2409
Batch 390, Loss: 0.2334
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.303394079208374 seconds
Epoch 200 accuracy: 80.14%
Total training time: 5045.653111934662 seconds
