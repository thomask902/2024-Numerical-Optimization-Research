The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.0615
Batch 20, Loss: 4.2002
Batch 30, Loss: 4.0220
Batch 40, Loss: 3.8038
Batch 50, Loss: 3.6575
Batch 60, Loss: 3.5019
Batch 70, Loss: 3.4971
Batch 80, Loss: 3.4859
Batch 90, Loss: 3.3900
Batch 100, Loss: 3.3697
Batch 110, Loss: 3.3387
Batch 120, Loss: 3.3676
Batch 130, Loss: 3.3279
Batch 140, Loss: 3.2811
Batch 150, Loss: 3.2478
Batch 160, Loss: 3.3134
Batch 170, Loss: 3.2171
Batch 180, Loss: 3.2220
Batch 190, Loss: 3.3009
Batch 200, Loss: 3.2619
Batch 210, Loss: 3.1868
Batch 220, Loss: 3.2062
Batch 230, Loss: 3.1921
Batch 240, Loss: 3.1677
Batch 250, Loss: 3.1430
Batch 260, Loss: 3.2080
Batch 270, Loss: 3.1378
Batch 280, Loss: 3.1646
Batch 290, Loss: 3.1633
Batch 300, Loss: 3.0979
Batch 310, Loss: 3.0620
Batch 320, Loss: 3.0685
Batch 330, Loss: 3.0657
Batch 340, Loss: 3.0826
Batch 350, Loss: 3.0497
Batch 360, Loss: 3.0651
Batch 370, Loss: 3.0639
Batch 380, Loss: 3.0674
Batch 390, Loss: 3.0338
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 48.23182463645935 seconds
Epoch 1 accuracy: 14.54%
Batch 10, Loss: 3.0123
Batch 20, Loss: 2.9974
Batch 30, Loss: 2.9448
Batch 40, Loss: 2.9581
Batch 50, Loss: 2.9919
Batch 60, Loss: 2.9201
Batch 70, Loss: 3.0165
Batch 80, Loss: 2.9760
Batch 90, Loss: 2.8794
Batch 100, Loss: 2.8945
Batch 110, Loss: 2.8957
Batch 120, Loss: 2.8943
Batch 130, Loss: 2.8751
Batch 140, Loss: 2.9031
Batch 150, Loss: 2.9059
Batch 160, Loss: 2.8427
Batch 170, Loss: 2.8043
Batch 180, Loss: 2.7852
Batch 190, Loss: 2.8572
Batch 200, Loss: 2.7495
Batch 210, Loss: 2.7638
Batch 220, Loss: 2.8191
Batch 230, Loss: 2.7685
Batch 240, Loss: 2.7530
Batch 250, Loss: 2.8247
Batch 260, Loss: 2.7933
Batch 270, Loss: 2.7760
Batch 280, Loss: 2.7241
Batch 290, Loss: 2.7650
Batch 300, Loss: 2.7348
Batch 310, Loss: 2.6787
Batch 320, Loss: 2.7146
Batch 330, Loss: 2.7046
Batch 340, Loss: 2.6635
Batch 350, Loss: 2.6949
Batch 360, Loss: 2.7033
Batch 370, Loss: 2.6808
Batch 380, Loss: 2.6887
Batch 390, Loss: 2.6215
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.156424283981323 seconds
Epoch 2 accuracy: 22.37%
Batch 10, Loss: 2.6172
Batch 20, Loss: 2.5575
Batch 30, Loss: 2.5745
Batch 40, Loss: 2.6874
Batch 50, Loss: 2.6050
Batch 60, Loss: 2.5696
Batch 70, Loss: 2.5874
Batch 80, Loss: 2.6037
Batch 90, Loss: 2.5920
Batch 100, Loss: 2.6008
Batch 110, Loss: 2.5165
Batch 120, Loss: 2.5046
Batch 130, Loss: 2.5256
Batch 140, Loss: 2.5432
Batch 150, Loss: 2.5741
Batch 160, Loss: 2.6020
Batch 170, Loss: 2.5447
Batch 180, Loss: 2.4808
Batch 190, Loss: 2.5445
Batch 200, Loss: 2.5328
Batch 210, Loss: 2.5810
Batch 220, Loss: 2.4825
Batch 230, Loss: 2.4969
Batch 240, Loss: 2.4483
Batch 250, Loss: 2.5471
Batch 260, Loss: 2.4484
Batch 270, Loss: 2.4343
Batch 280, Loss: 2.4263
Batch 290, Loss: 2.4781
Batch 300, Loss: 2.4415
Batch 310, Loss: 2.3904
Batch 320, Loss: 2.3869
Batch 330, Loss: 2.3370
Batch 340, Loss: 2.4230
Batch 350, Loss: 2.4241
Batch 360, Loss: 2.3803
Batch 370, Loss: 2.3784
Batch 380, Loss: 2.3360
Batch 390, Loss: 2.2617
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.235259294509888 seconds
Epoch 3 accuracy: 27.35%
Batch 10, Loss: 2.3470
Batch 20, Loss: 2.3115
Batch 30, Loss: 2.3274
Batch 40, Loss: 2.2570
Batch 50, Loss: 2.2755
Batch 60, Loss: 2.2719
Batch 70, Loss: 2.2809
Batch 80, Loss: 2.2483
Batch 90, Loss: 2.2874
Batch 100, Loss: 2.2197
Batch 110, Loss: 2.2615
Batch 120, Loss: 2.2700
Batch 130, Loss: 2.2372
Batch 140, Loss: 2.2642
Batch 150, Loss: 2.1913
Batch 160, Loss: 2.1795
Batch 170, Loss: 2.1460
Batch 180, Loss: 2.2137
Batch 190, Loss: 2.2300
Batch 200, Loss: 2.2384
Batch 210, Loss: 2.1948
Batch 220, Loss: 2.2119
Batch 230, Loss: 2.1561
Batch 240, Loss: 2.0986
Batch 250, Loss: 2.1458
Batch 260, Loss: 2.2183
Batch 270, Loss: 2.2007
Batch 280, Loss: 2.1107
Batch 290, Loss: 2.1208
Batch 300, Loss: 2.1312
Batch 310, Loss: 2.1820
Batch 320, Loss: 2.1287
Batch 330, Loss: 2.1255
Batch 340, Loss: 2.0891
Batch 350, Loss: 2.1539
Batch 360, Loss: 2.1144
Batch 370, Loss: 2.0836
Batch 380, Loss: 2.0587
Batch 390, Loss: 2.1026
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.23342990875244 seconds
Epoch 4 accuracy: 35.84%
Batch 10, Loss: 2.0303
Batch 20, Loss: 2.0091
Batch 30, Loss: 1.9801
Batch 40, Loss: 2.0489
Batch 50, Loss: 1.9796
Batch 60, Loss: 2.0012
Batch 70, Loss: 2.0822
Batch 80, Loss: 2.0398
Batch 90, Loss: 2.1323
Batch 100, Loss: 1.9941
Batch 110, Loss: 2.0293
Batch 120, Loss: 2.0170
Batch 130, Loss: 2.0082
Batch 140, Loss: 1.9194
Batch 150, Loss: 1.9254
Batch 160, Loss: 1.9726
Batch 170, Loss: 1.9901
Batch 180, Loss: 1.9742
Batch 190, Loss: 1.9523
Batch 200, Loss: 1.8746
Batch 210, Loss: 1.9316
Batch 220, Loss: 1.9747
Batch 230, Loss: 1.8755
Batch 240, Loss: 1.9811
Batch 250, Loss: 1.9300
Batch 260, Loss: 1.9405
Batch 270, Loss: 1.9368
Batch 280, Loss: 1.9458
Batch 290, Loss: 1.8484
Batch 300, Loss: 1.8596
Batch 310, Loss: 1.8755
Batch 320, Loss: 1.8676
Batch 330, Loss: 1.8912
Batch 340, Loss: 1.9203
Batch 350, Loss: 1.9368
Batch 360, Loss: 1.9350
Batch 370, Loss: 1.8449
Batch 380, Loss: 1.8336
Batch 390, Loss: 1.8873
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.2486674785614 seconds
Epoch 5 accuracy: 38.25%
Batch 10, Loss: 1.8730
Batch 20, Loss: 1.8271
Batch 30, Loss: 1.8158
Batch 40, Loss: 1.7880
Batch 50, Loss: 1.7597
Batch 60, Loss: 1.7704
Batch 70, Loss: 1.6944
Batch 80, Loss: 1.8613
Batch 90, Loss: 1.7971
Batch 100, Loss: 1.8185
Batch 110, Loss: 1.7985
Batch 120, Loss: 1.8454
Batch 130, Loss: 1.7923
Batch 140, Loss: 1.7324
Batch 150, Loss: 1.7796
Batch 160, Loss: 1.7565
Batch 170, Loss: 1.7600
Batch 180, Loss: 1.8003
Batch 190, Loss: 1.7824
Batch 200, Loss: 1.7203
Batch 210, Loss: 1.7734
Batch 220, Loss: 1.8089
Batch 230, Loss: 1.7514
Batch 240, Loss: 1.7700
Batch 250, Loss: 1.7619
Batch 260, Loss: 1.6688
Batch 270, Loss: 1.7784
Batch 280, Loss: 1.7596
Batch 290, Loss: 1.7460
Batch 300, Loss: 1.7726
Batch 310, Loss: 1.7960
Batch 320, Loss: 1.7763
Batch 330, Loss: 1.7783
Batch 340, Loss: 1.7544
Batch 350, Loss: 1.6844
Batch 360, Loss: 1.6798
Batch 370, Loss: 1.6470
Batch 380, Loss: 1.7217
Batch 390, Loss: 1.7472
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.12194800376892 seconds
Epoch 6 accuracy: 40.0%
Batch 10, Loss: 1.6920
Batch 20, Loss: 1.6384
Batch 30, Loss: 1.5997
Batch 40, Loss: 1.6998
Batch 50, Loss: 1.5938
Batch 60, Loss: 1.6390
Batch 70, Loss: 1.5641
Batch 80, Loss: 1.6077
Batch 90, Loss: 1.6619
Batch 100, Loss: 1.6077
Batch 110, Loss: 1.6824
Batch 120, Loss: 1.6440
Batch 130, Loss: 1.6491
Batch 140, Loss: 1.6827
Batch 150, Loss: 1.6946
Batch 160, Loss: 1.7397
Batch 170, Loss: 1.6712
Batch 180, Loss: 1.6384
Batch 190, Loss: 1.6290
Batch 200, Loss: 1.5930
Batch 210, Loss: 1.6070
Batch 220, Loss: 1.6370
Batch 230, Loss: 1.6550
Batch 240, Loss: 1.5731
Batch 250, Loss: 1.6354
Batch 260, Loss: 1.6210
Batch 270, Loss: 1.6446
Batch 280, Loss: 1.5753
Batch 290, Loss: 1.6288
Batch 300, Loss: 1.6650
Batch 310, Loss: 1.6231
Batch 320, Loss: 1.6356
Batch 330, Loss: 1.6136
Batch 340, Loss: 1.5843
Batch 350, Loss: 1.6127
Batch 360, Loss: 1.6433
Batch 370, Loss: 1.5961
Batch 380, Loss: 1.6056
Batch 390, Loss: 1.5496
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.18730401992798 seconds
Epoch 7 accuracy: 45.67%
Batch 10, Loss: 1.5659
Batch 20, Loss: 1.5314
Batch 30, Loss: 1.4794
Batch 40, Loss: 1.5023
Batch 50, Loss: 1.5543
Batch 60, Loss: 1.5501
Batch 70, Loss: 1.5662
Batch 80, Loss: 1.5446
Batch 90, Loss: 1.5211
Batch 100, Loss: 1.5065
Batch 110, Loss: 1.4929
Batch 120, Loss: 1.5094
Batch 130, Loss: 1.5601
Batch 140, Loss: 1.5163
Batch 150, Loss: 1.5219
Batch 160, Loss: 1.5717
Batch 170, Loss: 1.4944
Batch 180, Loss: 1.5601
Batch 190, Loss: 1.5733
Batch 200, Loss: 1.5733
Batch 210, Loss: 1.5355
Batch 220, Loss: 1.4713
Batch 230, Loss: 1.5622
Batch 240, Loss: 1.5654
Batch 250, Loss: 1.5091
Batch 260, Loss: 1.5613
Batch 270, Loss: 1.4840
Batch 280, Loss: 1.4889
Batch 290, Loss: 1.5340
Batch 300, Loss: 1.4969
Batch 310, Loss: 1.4726
Batch 320, Loss: 1.4738
Batch 330, Loss: 1.4482
Batch 340, Loss: 1.5280
Batch 350, Loss: 1.5649
Batch 360, Loss: 1.5272
Batch 370, Loss: 1.4971
Batch 380, Loss: 1.6070
Batch 390, Loss: 1.5233
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.26578164100647 seconds
Epoch 8 accuracy: 47.31%
Batch 10, Loss: 1.4370
Batch 20, Loss: 1.3547
Batch 30, Loss: 1.4160
Batch 40, Loss: 1.4355
Batch 50, Loss: 1.4337
Batch 60, Loss: 1.4779
Batch 70, Loss: 1.3984
Batch 80, Loss: 1.4910
Batch 90, Loss: 1.4291
Batch 100, Loss: 1.4382
Batch 110, Loss: 1.4456
Batch 120, Loss: 1.5015
Batch 130, Loss: 1.4221
Batch 140, Loss: 1.4262
Batch 150, Loss: 1.4997
Batch 160, Loss: 1.5010
Batch 170, Loss: 1.5193
Batch 180, Loss: 1.5330
Batch 190, Loss: 1.4537
Batch 200, Loss: 1.4194
Batch 210, Loss: 1.5280
Batch 220, Loss: 1.4573
Batch 230, Loss: 1.4301
Batch 240, Loss: 1.4640
Batch 250, Loss: 1.4982
Batch 260, Loss: 1.4604
Batch 270, Loss: 1.5085
Batch 280, Loss: 1.4613
Batch 290, Loss: 1.4445
Batch 300, Loss: 1.4689
Batch 310, Loss: 1.4905
Batch 320, Loss: 1.4457
Batch 330, Loss: 1.4526
Batch 340, Loss: 1.4261
Batch 350, Loss: 1.4028
Batch 360, Loss: 1.4732
Batch 370, Loss: 1.4329
Batch 380, Loss: 1.4316
Batch 390, Loss: 1.4267
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.178425550460815 seconds
Epoch 9 accuracy: 47.28%
Batch 10, Loss: 1.3942
Batch 20, Loss: 1.3461
Batch 30, Loss: 1.3278
Batch 40, Loss: 1.4364
Batch 50, Loss: 1.3517
Batch 60, Loss: 1.3533
Batch 70, Loss: 1.3462
Batch 80, Loss: 1.4801
Batch 90, Loss: 1.3942
Batch 100, Loss: 1.4674
Batch 110, Loss: 1.3704
Batch 120, Loss: 1.3873
Batch 130, Loss: 1.3532
Batch 140, Loss: 1.3284
Batch 150, Loss: 1.4203
Batch 160, Loss: 1.4032
Batch 170, Loss: 1.2944
Batch 180, Loss: 1.3476
Batch 190, Loss: 1.4010
Batch 200, Loss: 1.4476
Batch 210, Loss: 1.4490
Batch 220, Loss: 1.3395
Batch 230, Loss: 1.3697
Batch 240, Loss: 1.4177
Batch 250, Loss: 1.3644
Batch 260, Loss: 1.4005
Batch 270, Loss: 1.4672
Batch 280, Loss: 1.3642
Batch 290, Loss: 1.4056
Batch 300, Loss: 1.4101
Batch 310, Loss: 1.3888
Batch 320, Loss: 1.4367
Batch 330, Loss: 1.4217
Batch 340, Loss: 1.4300
Batch 350, Loss: 1.4257
Batch 360, Loss: 1.4876
Batch 370, Loss: 1.4669
Batch 380, Loss: 1.4686
Batch 390, Loss: 1.4286
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.095178842544556 seconds
Epoch 10 accuracy: 48.39%
Batch 10, Loss: 1.3239
Batch 20, Loss: 1.3257
Batch 30, Loss: 1.2762
Batch 40, Loss: 1.3391
Batch 50, Loss: 1.3088
Batch 60, Loss: 1.3440
Batch 70, Loss: 1.3488
Batch 80, Loss: 1.3379
Batch 90, Loss: 1.3125
Batch 100, Loss: 1.3855
Batch 110, Loss: 1.3616
Batch 120, Loss: 1.3615
Batch 130, Loss: 1.3689
Batch 140, Loss: 1.3451
Batch 150, Loss: 1.3390
Batch 160, Loss: 1.2917
Batch 170, Loss: 1.3222
Batch 180, Loss: 1.3502
Batch 190, Loss: 1.3468
Batch 200, Loss: 1.3178
Batch 210, Loss: 1.3492
Batch 220, Loss: 1.3836
Batch 230, Loss: 1.3530
Batch 240, Loss: 1.2837
Batch 250, Loss: 1.3566
Batch 260, Loss: 1.3946
Batch 270, Loss: 1.4363
Batch 280, Loss: 1.3573
Batch 290, Loss: 1.3638
Batch 300, Loss: 1.3871
Batch 310, Loss: 1.3456
Batch 320, Loss: 1.3148
Batch 330, Loss: 1.3736
Batch 340, Loss: 1.3877
Batch 350, Loss: 1.3587
Batch 360, Loss: 1.3674
Batch 370, Loss: 1.2686
Batch 380, Loss: 1.2936
Batch 390, Loss: 1.3606
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.09255838394165 seconds
Epoch 11 accuracy: 51.24%
Batch 10, Loss: 1.2804
Batch 20, Loss: 1.2668
Batch 30, Loss: 1.2442
Batch 40, Loss: 1.2954
Batch 50, Loss: 1.3117
Batch 60, Loss: 1.2309
Batch 70, Loss: 1.2717
Batch 80, Loss: 1.2822
Batch 90, Loss: 1.3292
Batch 100, Loss: 1.2743
Batch 110, Loss: 1.3272
Batch 120, Loss: 1.2937
Batch 130, Loss: 1.2391
Batch 140, Loss: 1.2942
Batch 150, Loss: 1.3562
Batch 160, Loss: 1.3232
Batch 170, Loss: 1.4053
Batch 180, Loss: 1.3969
Batch 190, Loss: 1.3156
Batch 200, Loss: 1.3311
Batch 210, Loss: 1.3056
Batch 220, Loss: 1.3108
Batch 230, Loss: 1.3104
Batch 240, Loss: 1.3434
Batch 250, Loss: 1.3290
Batch 260, Loss: 1.3582
Batch 270, Loss: 1.3212
Batch 280, Loss: 1.3263
Batch 290, Loss: 1.3724
Batch 300, Loss: 1.2986
Batch 310, Loss: 1.3686
Batch 320, Loss: 1.3561
Batch 330, Loss: 1.3675
Batch 340, Loss: 1.2458
Batch 350, Loss: 1.2899
Batch 360, Loss: 1.3453
Batch 370, Loss: 1.3361
Batch 380, Loss: 1.3103
Batch 390, Loss: 1.3067
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.184439659118652 seconds
Epoch 12 accuracy: 52.77%
Batch 10, Loss: 1.2359
Batch 20, Loss: 1.2515
Batch 30, Loss: 1.3034
Batch 40, Loss: 1.3077
Batch 50, Loss: 1.2472
Batch 60, Loss: 1.2511
Batch 70, Loss: 1.2143
Batch 80, Loss: 1.3000
Batch 90, Loss: 1.3034
Batch 100, Loss: 1.2381
Batch 110, Loss: 1.2598
Batch 120, Loss: 1.2500
Batch 130, Loss: 1.3063
Batch 140, Loss: 1.3017
Batch 150, Loss: 1.2838
Batch 160, Loss: 1.3207
Batch 170, Loss: 1.2618
Batch 180, Loss: 1.2957
Batch 190, Loss: 1.2941
Batch 200, Loss: 1.2675
Batch 210, Loss: 1.2952
Batch 220, Loss: 1.2740
Batch 230, Loss: 1.2531
Batch 240, Loss: 1.3281
Batch 250, Loss: 1.3251
Batch 260, Loss: 1.2707
Batch 270, Loss: 1.2928
Batch 280, Loss: 1.2794
Batch 290, Loss: 1.2290
Batch 300, Loss: 1.3318
Batch 310, Loss: 1.2933
Batch 320, Loss: 1.2430
Batch 330, Loss: 1.2949
Batch 340, Loss: 1.3792
Batch 350, Loss: 1.2729
Batch 360, Loss: 1.2856
Batch 370, Loss: 1.2022
Batch 380, Loss: 1.2659
Batch 390, Loss: 1.2958
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.122373819351196 seconds
Epoch 13 accuracy: 48.59%
Batch 10, Loss: 1.1706
Batch 20, Loss: 1.1730
Batch 30, Loss: 1.1805
Batch 40, Loss: 1.2267
Batch 50, Loss: 1.2486
Batch 60, Loss: 1.1985
Batch 70, Loss: 1.1949
Batch 80, Loss: 1.2117
Batch 90, Loss: 1.1888
Batch 100, Loss: 1.2578
Batch 110, Loss: 1.2772
Batch 120, Loss: 1.2052
Batch 130, Loss: 1.2467
Batch 140, Loss: 1.2668
Batch 150, Loss: 1.2168
Batch 160, Loss: 1.2292
Batch 170, Loss: 1.1674
Batch 180, Loss: 1.2763
Batch 190, Loss: 1.1903
Batch 200, Loss: 1.2800
Batch 210, Loss: 1.2796
Batch 220, Loss: 1.2359
Batch 230, Loss: 1.2295
Batch 240, Loss: 1.2512
Batch 250, Loss: 1.2591
Batch 260, Loss: 1.2966
Batch 270, Loss: 1.3497
Batch 280, Loss: 1.2893
Batch 290, Loss: 1.2670
Batch 300, Loss: 1.2574
Batch 310, Loss: 1.2669
Batch 320, Loss: 1.2307
Batch 330, Loss: 1.2092
Batch 340, Loss: 1.2349
Batch 350, Loss: 1.2848
Batch 360, Loss: 1.2611
Batch 370, Loss: 1.3200
Batch 380, Loss: 1.3375
Batch 390, Loss: 1.2497
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.2710702419281 seconds
Epoch 14 accuracy: 53.48%
Batch 10, Loss: 1.1843
Batch 20, Loss: 1.2014
Batch 30, Loss: 1.1446
Batch 40, Loss: 1.1821
Batch 50, Loss: 1.2256
Batch 60, Loss: 1.1561
Batch 70, Loss: 1.2386
Batch 80, Loss: 1.1390
Batch 90, Loss: 1.2140
Batch 100, Loss: 1.2903
Batch 110, Loss: 1.2409
Batch 120, Loss: 1.1890
Batch 130, Loss: 1.2367
Batch 140, Loss: 1.1778
Batch 150, Loss: 1.1690
Batch 160, Loss: 1.2016
Batch 170, Loss: 1.2190
Batch 180, Loss: 1.2461
Batch 190, Loss: 1.2108
Batch 200, Loss: 1.2213
Batch 210, Loss: 1.1910
Batch 220, Loss: 1.2079
Batch 230, Loss: 1.1841
Batch 240, Loss: 1.2226
Batch 250, Loss: 1.1947
Batch 260, Loss: 1.1695
Batch 270, Loss: 1.2268
Batch 280, Loss: 1.2238
Batch 290, Loss: 1.3219
Batch 300, Loss: 1.2551
Batch 310, Loss: 1.2543
Batch 320, Loss: 1.2063
Batch 330, Loss: 1.2127
Batch 340, Loss: 1.1943
Batch 350, Loss: 1.2085
Batch 360, Loss: 1.2281
Batch 370, Loss: 1.3014
Batch 380, Loss: 1.2658
Batch 390, Loss: 1.2247
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.267410039901733 seconds
Epoch 15 accuracy: 54.15%
Batch 10, Loss: 1.1294
Batch 20, Loss: 1.2234
Batch 30, Loss: 1.1596
Batch 40, Loss: 1.1019
Batch 50, Loss: 1.1250
Batch 60, Loss: 1.1111
Batch 70, Loss: 1.0951
Batch 80, Loss: 1.1119
Batch 90, Loss: 1.1604
Batch 100, Loss: 1.1450
Batch 110, Loss: 1.1965
Batch 120, Loss: 1.2230
Batch 130, Loss: 1.1894
Batch 140, Loss: 1.1559
Batch 150, Loss: 1.1704
Batch 160, Loss: 1.2090
Batch 170, Loss: 1.2154
Batch 180, Loss: 1.2211
Batch 190, Loss: 1.1801
Batch 200, Loss: 1.1937
Batch 210, Loss: 1.1922
Batch 220, Loss: 1.2094
Batch 230, Loss: 1.1627
Batch 240, Loss: 1.2524
Batch 250, Loss: 1.2565
Batch 260, Loss: 1.2052
Batch 270, Loss: 1.2024
Batch 280, Loss: 1.2176
Batch 290, Loss: 1.1935
Batch 300, Loss: 1.2068
Batch 310, Loss: 1.2679
Batch 320, Loss: 1.2765
Batch 330, Loss: 1.2656
Batch 340, Loss: 1.2416
Batch 350, Loss: 1.2034
Batch 360, Loss: 1.1783
Batch 370, Loss: 1.2275
Batch 380, Loss: 1.2059
Batch 390, Loss: 1.2938
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.151087760925293 seconds
Epoch 16 accuracy: 52.02%
Batch 10, Loss: 1.1045
Batch 20, Loss: 1.0699
Batch 30, Loss: 1.1476
Batch 40, Loss: 1.0998
Batch 50, Loss: 1.0741
Batch 60, Loss: 1.1637
Batch 70, Loss: 1.1726
Batch 80, Loss: 1.1255
Batch 90, Loss: 1.1547
Batch 100, Loss: 1.1709
Batch 110, Loss: 1.1670
Batch 120, Loss: 1.1303
Batch 130, Loss: 1.2127
Batch 140, Loss: 1.1602
Batch 150, Loss: 1.1660
Batch 160, Loss: 1.1338
Batch 170, Loss: 1.1859
Batch 180, Loss: 1.0865
Batch 190, Loss: 1.2483
Batch 200, Loss: 1.1767
Batch 210, Loss: 1.1949
Batch 220, Loss: 1.1108
Batch 230, Loss: 1.2167
Batch 240, Loss: 1.2123
Batch 250, Loss: 1.2195
Batch 260, Loss: 1.1755
Batch 270, Loss: 1.1964
Batch 280, Loss: 1.1364
Batch 290, Loss: 1.2273
Batch 300, Loss: 1.1749
Batch 310, Loss: 1.2391
Batch 320, Loss: 1.1747
Batch 330, Loss: 1.1730
Batch 340, Loss: 1.2733
Batch 350, Loss: 1.1801
Batch 360, Loss: 1.2228
Batch 370, Loss: 1.1745
Batch 380, Loss: 1.2219
Batch 390, Loss: 1.1982
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.078055143356323 seconds
Epoch 17 accuracy: 56.35%
Batch 10, Loss: 1.0883
Batch 20, Loss: 1.0492
Batch 30, Loss: 1.0630
Batch 40, Loss: 1.0762
Batch 50, Loss: 1.1261
Batch 60, Loss: 1.1515
Batch 70, Loss: 1.0933
Batch 80, Loss: 1.1750
Batch 90, Loss: 1.1518
Batch 100, Loss: 1.1471
Batch 110, Loss: 1.1524
Batch 120, Loss: 1.0717
Batch 130, Loss: 1.1006
Batch 140, Loss: 1.1374
Batch 150, Loss: 1.0992
Batch 160, Loss: 1.1926
Batch 170, Loss: 1.1472
Batch 180, Loss: 1.1503
Batch 190, Loss: 1.1657
Batch 200, Loss: 1.2269
Batch 210, Loss: 1.1990
Batch 220, Loss: 1.1529
Batch 230, Loss: 1.1037
Batch 240, Loss: 1.1336
Batch 250, Loss: 1.1462
Batch 260, Loss: 1.1466
Batch 270, Loss: 1.1878
Batch 280, Loss: 1.1603
Batch 290, Loss: 1.1742
Batch 300, Loss: 1.1714
Batch 310, Loss: 1.2128
Batch 320, Loss: 1.1354
Batch 330, Loss: 1.1334
Batch 340, Loss: 1.1813
Batch 350, Loss: 1.2639
Batch 360, Loss: 1.1949
Batch 370, Loss: 1.1757
Batch 380, Loss: 1.1411
Batch 390, Loss: 1.1822
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.253878355026245 seconds
Epoch 18 accuracy: 53.68%
Batch 10, Loss: 1.0918
Batch 20, Loss: 1.0824
Batch 30, Loss: 1.0589
Batch 40, Loss: 1.0973
Batch 50, Loss: 1.1160
Batch 60, Loss: 1.1147
Batch 70, Loss: 1.0813
Batch 80, Loss: 1.0982
Batch 90, Loss: 1.1573
Batch 100, Loss: 1.1088
Batch 110, Loss: 1.0463
Batch 120, Loss: 1.1404
Batch 130, Loss: 1.1271
Batch 140, Loss: 1.0916
Batch 150, Loss: 1.1587
Batch 160, Loss: 1.1253
Batch 170, Loss: 1.1171
Batch 180, Loss: 1.1029
Batch 190, Loss: 1.2173
Batch 200, Loss: 1.1503
Batch 210, Loss: 1.1527
Batch 220, Loss: 1.1246
Batch 230, Loss: 1.1604
Batch 240, Loss: 1.1562
Batch 250, Loss: 1.1413
Batch 260, Loss: 1.2143
Batch 270, Loss: 1.1100
Batch 280, Loss: 1.2029
Batch 290, Loss: 1.1454
Batch 300, Loss: 1.1354
Batch 310, Loss: 1.1802
Batch 320, Loss: 1.1736
Batch 330, Loss: 1.0931
Batch 340, Loss: 1.1458
Batch 350, Loss: 1.1741
Batch 360, Loss: 1.2077
Batch 370, Loss: 1.1673
Batch 380, Loss: 1.1578
Batch 390, Loss: 1.2136
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.195444345474243 seconds
Epoch 19 accuracy: 54.05%
Batch 10, Loss: 1.0830
Batch 20, Loss: 1.0467
Batch 30, Loss: 1.0919
Batch 40, Loss: 1.0710
Batch 50, Loss: 1.0624
Batch 60, Loss: 1.0564
Batch 70, Loss: 1.0643
Batch 80, Loss: 1.0482
Batch 90, Loss: 1.0886
Batch 100, Loss: 1.0875
Batch 110, Loss: 1.1685
Batch 120, Loss: 1.1172
Batch 130, Loss: 1.1860
Batch 140, Loss: 1.1567
Batch 150, Loss: 1.1123
Batch 160, Loss: 1.1519
Batch 170, Loss: 1.1496
Batch 180, Loss: 1.1309
Batch 190, Loss: 1.1501
Batch 200, Loss: 1.1806
Batch 210, Loss: 1.0911
Batch 220, Loss: 1.0961
Batch 230, Loss: 1.1416
Batch 240, Loss: 1.1316
Batch 250, Loss: 1.1696
Batch 260, Loss: 1.1575
Batch 270, Loss: 1.1719
Batch 280, Loss: 1.1761
Batch 290, Loss: 1.1820
Batch 300, Loss: 1.1285
Batch 310, Loss: 1.1508
Batch 320, Loss: 1.1749
Batch 330, Loss: 1.1482
Batch 340, Loss: 1.1293
Batch 350, Loss: 1.1245
Batch 360, Loss: 1.1124
Batch 370, Loss: 1.1746
Batch 380, Loss: 1.1792
Batch 390, Loss: 1.1784
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.222033262252808 seconds
Epoch 20 accuracy: 52.76%
Batch 10, Loss: 1.1120
Batch 20, Loss: 1.0725
Batch 30, Loss: 1.1010
Batch 40, Loss: 1.0384
Batch 50, Loss: 1.0168
Batch 60, Loss: 1.0694
Batch 70, Loss: 1.1127
Batch 80, Loss: 1.0747
Batch 90, Loss: 1.1121
Batch 100, Loss: 1.0668
Batch 110, Loss: 1.1318
Batch 120, Loss: 1.1585
Batch 130, Loss: 1.1466
Batch 140, Loss: 1.1030
Batch 150, Loss: 1.0799
Batch 160, Loss: 1.1255
Batch 170, Loss: 1.0984
Batch 180, Loss: 1.1261
Batch 190, Loss: 1.1407
Batch 200, Loss: 1.0710
Batch 210, Loss: 1.1219
Batch 220, Loss: 1.1228
Batch 230, Loss: 1.0675
Batch 240, Loss: 1.1092
Batch 250, Loss: 1.1241
Batch 260, Loss: 1.1259
Batch 270, Loss: 1.1287
Batch 280, Loss: 1.1452
Batch 290, Loss: 1.1681
Batch 300, Loss: 1.1134
Batch 310, Loss: 1.1108
Batch 320, Loss: 1.0999
Batch 330, Loss: 1.1673
Batch 340, Loss: 1.1109
Batch 350, Loss: 1.1264
Batch 360, Loss: 1.0828
Batch 370, Loss: 1.1659
Batch 380, Loss: 1.2014
Batch 390, Loss: 1.1070
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.088743925094604 seconds
Epoch 21 accuracy: 57.15%
Batch 10, Loss: 1.0114
Batch 20, Loss: 1.0204
Batch 30, Loss: 1.0891
Batch 40, Loss: 1.0411
Batch 50, Loss: 1.0497
Batch 60, Loss: 1.0086
Batch 70, Loss: 1.0291
Batch 80, Loss: 1.1045
Batch 90, Loss: 1.0824
Batch 100, Loss: 0.9947
Batch 110, Loss: 1.1036
Batch 120, Loss: 1.1061
Batch 130, Loss: 1.0942
Batch 140, Loss: 1.0983
Batch 150, Loss: 1.1274
Batch 160, Loss: 1.0558
Batch 170, Loss: 1.0309
Batch 180, Loss: 1.1171
Batch 190, Loss: 1.0424
Batch 200, Loss: 1.0359
Batch 210, Loss: 1.1181
Batch 220, Loss: 1.0622
Batch 230, Loss: 1.0725
Batch 240, Loss: 1.1182
Batch 250, Loss: 1.1046
Batch 260, Loss: 1.1373
Batch 270, Loss: 1.1767
Batch 280, Loss: 1.1368
Batch 290, Loss: 1.1697
Batch 300, Loss: 1.1119
Batch 310, Loss: 1.0785
Batch 320, Loss: 1.1694
Batch 330, Loss: 1.1299
Batch 340, Loss: 1.1513
Batch 350, Loss: 1.1684
Batch 360, Loss: 1.1156
Batch 370, Loss: 1.1146
Batch 380, Loss: 1.1356
Batch 390, Loss: 1.1617
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.281877756118774 seconds
Epoch 22 accuracy: 55.28%
Batch 10, Loss: 1.0803
Batch 20, Loss: 1.0162
Batch 30, Loss: 0.9582
Batch 40, Loss: 1.0048
Batch 50, Loss: 0.9772
Batch 60, Loss: 1.0591
Batch 70, Loss: 1.1032
Batch 80, Loss: 1.0003
Batch 90, Loss: 1.0681
Batch 100, Loss: 1.0346
Batch 110, Loss: 1.1153
Batch 120, Loss: 1.1135
Batch 130, Loss: 1.0607
Batch 140, Loss: 1.0944
Batch 150, Loss: 1.1166
Batch 160, Loss: 1.0933
Batch 170, Loss: 1.0793
Batch 180, Loss: 1.1026
Batch 190, Loss: 1.1256
Batch 200, Loss: 1.0655
Batch 210, Loss: 1.1433
Batch 220, Loss: 1.1035
Batch 230, Loss: 1.0728
Batch 240, Loss: 1.1043
Batch 250, Loss: 1.0713
Batch 260, Loss: 1.1069
Batch 270, Loss: 1.1001
Batch 280, Loss: 1.0840
Batch 290, Loss: 1.1018
Batch 300, Loss: 1.0765
Batch 310, Loss: 1.1063
Batch 320, Loss: 1.0838
Batch 330, Loss: 1.1382
Batch 340, Loss: 1.1294
Batch 350, Loss: 1.0373
Batch 360, Loss: 1.0932
Batch 370, Loss: 1.0806
Batch 380, Loss: 1.1167
Batch 390, Loss: 1.1056
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.166924476623535 seconds
Epoch 23 accuracy: 53.42%
Batch 10, Loss: 1.0276
Batch 20, Loss: 0.9355
Batch 30, Loss: 1.0291
Batch 40, Loss: 1.0051
Batch 50, Loss: 1.0445
Batch 60, Loss: 1.0823
Batch 70, Loss: 1.0408
Batch 80, Loss: 1.0605
Batch 90, Loss: 1.0922
Batch 100, Loss: 1.1135
Batch 110, Loss: 1.0176
Batch 120, Loss: 1.0454
Batch 130, Loss: 1.0981
Batch 140, Loss: 1.0720
Batch 150, Loss: 1.0488
Batch 160, Loss: 1.0684
Batch 170, Loss: 1.0761
Batch 180, Loss: 1.1184
Batch 190, Loss: 1.0548
Batch 200, Loss: 1.0678
Batch 210, Loss: 1.0753
Batch 220, Loss: 1.0371
Batch 230, Loss: 1.0818
Batch 240, Loss: 1.0723
Batch 250, Loss: 1.0614
Batch 260, Loss: 1.0723
Batch 270, Loss: 1.0593
Batch 280, Loss: 1.0802
Batch 290, Loss: 1.1491
Batch 300, Loss: 1.0939
Batch 310, Loss: 1.1291
Batch 320, Loss: 1.0665
Batch 330, Loss: 1.0973
Batch 340, Loss: 1.1039
Batch 350, Loss: 1.1247
Batch 360, Loss: 1.1575
Batch 370, Loss: 1.0674
Batch 380, Loss: 1.0600
Batch 390, Loss: 1.1077
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.18277645111084 seconds
Epoch 24 accuracy: 58.41%
Batch 10, Loss: 0.9635
Batch 20, Loss: 1.0105
Batch 30, Loss: 1.0331
Batch 40, Loss: 1.0458
Batch 50, Loss: 1.0448
Batch 60, Loss: 1.0171
Batch 70, Loss: 0.9931
Batch 80, Loss: 1.0152
Batch 90, Loss: 1.0962
Batch 100, Loss: 1.0120
Batch 110, Loss: 1.0560
Batch 120, Loss: 1.0949
Batch 130, Loss: 1.1316
Batch 140, Loss: 1.0014
Batch 150, Loss: 1.0336
Batch 160, Loss: 1.0868
Batch 170, Loss: 1.0621
Batch 180, Loss: 1.0754
Batch 190, Loss: 1.0879
Batch 200, Loss: 1.0310
Batch 210, Loss: 1.0316
Batch 220, Loss: 1.0413
Batch 230, Loss: 1.0902
Batch 240, Loss: 1.0647
Batch 250, Loss: 1.0985
Batch 260, Loss: 1.0628
Batch 270, Loss: 1.0366
Batch 280, Loss: 1.1169
Batch 290, Loss: 1.0887
Batch 300, Loss: 1.0585
Batch 310, Loss: 1.0600
Batch 320, Loss: 1.0530
Batch 330, Loss: 1.0152
Batch 340, Loss: 1.0912
Batch 350, Loss: 1.1233
Batch 360, Loss: 1.1039
Batch 370, Loss: 1.1082
Batch 380, Loss: 1.1073
Batch 390, Loss: 1.1000
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.188734769821167 seconds
Epoch 25 accuracy: 52.12%
Batch 10, Loss: 0.9857
Batch 20, Loss: 1.0115
Batch 30, Loss: 0.9822
Batch 40, Loss: 0.9199
Batch 50, Loss: 0.9807
Batch 60, Loss: 1.0089
Batch 70, Loss: 0.9921
Batch 80, Loss: 1.0298
Batch 90, Loss: 1.0580
Batch 100, Loss: 1.0284
Batch 110, Loss: 0.9966
Batch 120, Loss: 1.0223
Batch 130, Loss: 1.0486
Batch 140, Loss: 1.0367
Batch 150, Loss: 1.0495
Batch 160, Loss: 1.0083
Batch 170, Loss: 1.1401
Batch 180, Loss: 1.0679
Batch 190, Loss: 1.0896
Batch 200, Loss: 1.1399
Batch 210, Loss: 1.0817
Batch 220, Loss: 1.0755
Batch 230, Loss: 1.1434
Batch 240, Loss: 1.0300
Batch 250, Loss: 1.0630
Batch 260, Loss: 1.0693
Batch 270, Loss: 1.0741
Batch 280, Loss: 1.0687
Batch 290, Loss: 1.1090
Batch 300, Loss: 1.1218
Batch 310, Loss: 1.1239
Batch 320, Loss: 1.0532
Batch 330, Loss: 1.0450
Batch 340, Loss: 1.0839
Batch 350, Loss: 1.1074
Batch 360, Loss: 1.1074
Batch 370, Loss: 1.1160
Batch 380, Loss: 1.0068
Batch 390, Loss: 1.1041
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.199356079101562 seconds
Epoch 26 accuracy: 56.71%
Batch 10, Loss: 0.9908
Batch 20, Loss: 0.9621
Batch 30, Loss: 0.9953
Batch 40, Loss: 0.9731
Batch 50, Loss: 0.9797
Batch 60, Loss: 0.9522
Batch 70, Loss: 0.9715
Batch 80, Loss: 1.0380
Batch 90, Loss: 1.0712
Batch 100, Loss: 1.0231
Batch 110, Loss: 1.0333
Batch 120, Loss: 1.0219
Batch 130, Loss: 0.9649
Batch 140, Loss: 1.0666
Batch 150, Loss: 0.9829
Batch 160, Loss: 1.0735
Batch 170, Loss: 1.0949
Batch 180, Loss: 1.0655
Batch 190, Loss: 1.0314
Batch 200, Loss: 1.0664
Batch 210, Loss: 1.1092
Batch 220, Loss: 1.0844
Batch 230, Loss: 1.1008
Batch 240, Loss: 1.0431
Batch 250, Loss: 1.0278
Batch 260, Loss: 1.0609
Batch 270, Loss: 1.1046
Batch 280, Loss: 1.0377
Batch 290, Loss: 1.0734
Batch 300, Loss: 1.0357
Batch 310, Loss: 1.1154
Batch 320, Loss: 1.1069
Batch 330, Loss: 1.0720
Batch 340, Loss: 1.1119
Batch 350, Loss: 1.1001
Batch 360, Loss: 1.0322
Batch 370, Loss: 1.0740
Batch 380, Loss: 1.0911
Batch 390, Loss: 1.1087
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.18440079689026 seconds
Epoch 27 accuracy: 56.12%
Batch 10, Loss: 0.9644
Batch 20, Loss: 0.9797
Batch 30, Loss: 0.9127
Batch 40, Loss: 0.9874
Batch 50, Loss: 1.0331
Batch 60, Loss: 0.9665
Batch 70, Loss: 0.9896
Batch 80, Loss: 0.9906
Batch 90, Loss: 0.9602
Batch 100, Loss: 0.9898
Batch 110, Loss: 1.0089
Batch 120, Loss: 1.0473
Batch 130, Loss: 1.0156
Batch 140, Loss: 0.9884
Batch 150, Loss: 1.0852
Batch 160, Loss: 1.0317
Batch 170, Loss: 1.0048
Batch 180, Loss: 0.9863
Batch 190, Loss: 1.0184
Batch 200, Loss: 0.9259
Batch 210, Loss: 0.9658
Batch 220, Loss: 1.0545
Batch 230, Loss: 1.0750
Batch 240, Loss: 1.0531
Batch 250, Loss: 1.0354
Batch 260, Loss: 1.0803
Batch 270, Loss: 1.0843
Batch 280, Loss: 1.1024
Batch 290, Loss: 1.0256
Batch 300, Loss: 1.1020
Batch 310, Loss: 1.1184
Batch 320, Loss: 1.0538
Batch 330, Loss: 1.0461
Batch 340, Loss: 1.0213
Batch 350, Loss: 0.9839
Batch 360, Loss: 1.1219
Batch 370, Loss: 1.1022
Batch 380, Loss: 1.1520
Batch 390, Loss: 1.0576
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.25124478340149 seconds
Epoch 28 accuracy: 54.84%
Batch 10, Loss: 1.0193
Batch 20, Loss: 0.9487
Batch 30, Loss: 1.0186
Batch 40, Loss: 1.0043
Batch 50, Loss: 0.9863
Batch 60, Loss: 0.9550
Batch 70, Loss: 0.9626
Batch 80, Loss: 0.8987
Batch 90, Loss: 0.9844
Batch 100, Loss: 0.9933
Batch 110, Loss: 0.9459
Batch 120, Loss: 0.9132
Batch 130, Loss: 0.9780
Batch 140, Loss: 1.0435
Batch 150, Loss: 1.0127
Batch 160, Loss: 1.0391
Batch 170, Loss: 1.0111
Batch 180, Loss: 1.0016
Batch 190, Loss: 1.0520
Batch 200, Loss: 1.0403
Batch 210, Loss: 1.0760
Batch 220, Loss: 1.0755
Batch 230, Loss: 1.1122
Batch 240, Loss: 1.0387
Batch 250, Loss: 0.9919
Batch 260, Loss: 0.9910
Batch 270, Loss: 1.0228
Batch 280, Loss: 1.0305
Batch 290, Loss: 1.0554
Batch 300, Loss: 1.0680
Batch 310, Loss: 1.0509
Batch 320, Loss: 1.0351
Batch 330, Loss: 1.0608
Batch 340, Loss: 1.0460
Batch 350, Loss: 0.9899
Batch 360, Loss: 0.9904
Batch 370, Loss: 1.0479
Batch 380, Loss: 1.0992
Batch 390, Loss: 1.0838
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.22348642349243 seconds
Epoch 29 accuracy: 57.31%
Batch 10, Loss: 0.9566
Batch 20, Loss: 0.9377
Batch 30, Loss: 0.9374
Batch 40, Loss: 0.9902
Batch 50, Loss: 0.9434
Batch 60, Loss: 0.9877
Batch 70, Loss: 0.9608
Batch 80, Loss: 1.0175
Batch 90, Loss: 1.0236
Batch 100, Loss: 1.0380
Batch 110, Loss: 1.0391
Batch 120, Loss: 0.9549
Batch 130, Loss: 1.0083
Batch 140, Loss: 1.0253
Batch 150, Loss: 1.0121
Batch 160, Loss: 1.0152
Batch 170, Loss: 1.0376
Batch 180, Loss: 1.0241
Batch 190, Loss: 1.0092
Batch 200, Loss: 1.0735
Batch 210, Loss: 1.0040
Batch 220, Loss: 1.0041
Batch 230, Loss: 1.0186
Batch 240, Loss: 1.0183
Batch 250, Loss: 0.9915
Batch 260, Loss: 1.0268
Batch 270, Loss: 1.0168
Batch 280, Loss: 1.0228
Batch 290, Loss: 1.0593
Batch 300, Loss: 0.9810
Batch 310, Loss: 1.0550
Batch 320, Loss: 1.0715
Batch 330, Loss: 1.0920
Batch 340, Loss: 1.0953
Batch 350, Loss: 1.0650
Batch 360, Loss: 1.0968
Batch 370, Loss: 1.0854
Batch 380, Loss: 1.0686
Batch 390, Loss: 1.0437
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.17432403564453 seconds
Epoch 30 accuracy: 57.87%
Batch 10, Loss: 0.9235
Batch 20, Loss: 0.8758
Batch 30, Loss: 0.9090
Batch 40, Loss: 0.9461
Batch 50, Loss: 0.9614
Batch 60, Loss: 1.0187
Batch 70, Loss: 1.0228
Batch 80, Loss: 0.9249
Batch 90, Loss: 1.0087
Batch 100, Loss: 1.0247
Batch 110, Loss: 1.0339
Batch 120, Loss: 0.9945
Batch 130, Loss: 1.0034
Batch 140, Loss: 0.9508
Batch 150, Loss: 0.9719
Batch 160, Loss: 1.0859
Batch 170, Loss: 1.0129
Batch 180, Loss: 1.0507
Batch 190, Loss: 1.0201
Batch 200, Loss: 1.0321
Batch 210, Loss: 1.0533
Batch 220, Loss: 1.0294
Batch 230, Loss: 0.9360
Batch 240, Loss: 1.0027
Batch 250, Loss: 1.0080
Batch 260, Loss: 1.0499
Batch 270, Loss: 1.0825
Batch 280, Loss: 1.0334
Batch 290, Loss: 1.0584
Batch 300, Loss: 1.0529
Batch 310, Loss: 1.0830
Batch 320, Loss: 1.0171
Batch 330, Loss: 1.0655
Batch 340, Loss: 1.0351
Batch 350, Loss: 1.1052
Batch 360, Loss: 1.0736
Batch 370, Loss: 0.9894
Batch 380, Loss: 1.1032
Batch 390, Loss: 1.0258
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.194318771362305 seconds
Epoch 31 accuracy: 56.96%
Batch 10, Loss: 0.9299
Batch 20, Loss: 0.9520
Batch 30, Loss: 0.9385
Batch 40, Loss: 0.9169
Batch 50, Loss: 0.9602
Batch 60, Loss: 0.9472
Batch 70, Loss: 0.9539
Batch 80, Loss: 0.9349
Batch 90, Loss: 0.9909
Batch 100, Loss: 0.9455
Batch 110, Loss: 0.9645
Batch 120, Loss: 0.9505
Batch 130, Loss: 1.0139
Batch 140, Loss: 1.0062
Batch 150, Loss: 1.0629
Batch 160, Loss: 0.9900
Batch 170, Loss: 0.9918
Batch 180, Loss: 1.0368
Batch 190, Loss: 1.0374
Batch 200, Loss: 1.0226
Batch 210, Loss: 1.0096
Batch 220, Loss: 0.9720
Batch 230, Loss: 1.0507
Batch 240, Loss: 1.0923
Batch 250, Loss: 1.0799
Batch 260, Loss: 1.0407
Batch 270, Loss: 1.0451
Batch 280, Loss: 1.0078
Batch 290, Loss: 0.9775
Batch 300, Loss: 1.0213
Batch 310, Loss: 1.0033
Batch 320, Loss: 1.0208
Batch 330, Loss: 1.0657
Batch 340, Loss: 1.0509
Batch 350, Loss: 1.0637
Batch 360, Loss: 1.0520
Batch 370, Loss: 1.0249
Batch 380, Loss: 1.1013
Batch 390, Loss: 1.0436
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.192094564437866 seconds
Epoch 32 accuracy: 54.32%
Batch 10, Loss: 0.9877
Batch 20, Loss: 0.9247
Batch 30, Loss: 0.8885
Batch 40, Loss: 0.9511
Batch 50, Loss: 0.9857
Batch 60, Loss: 0.9236
Batch 70, Loss: 0.9081
Batch 80, Loss: 0.9717
Batch 90, Loss: 0.9456
Batch 100, Loss: 1.0109
Batch 110, Loss: 1.0311
Batch 120, Loss: 1.0080
Batch 130, Loss: 0.9876
Batch 140, Loss: 1.0124
Batch 150, Loss: 1.0270
Batch 160, Loss: 1.0174
Batch 170, Loss: 1.0075
Batch 180, Loss: 1.0149
Batch 190, Loss: 0.9807
Batch 200, Loss: 0.9760
Batch 210, Loss: 1.0155
Batch 220, Loss: 0.9895
Batch 230, Loss: 1.0285
Batch 240, Loss: 1.0678
Batch 250, Loss: 0.9967
Batch 260, Loss: 0.9867
Batch 270, Loss: 1.0241
Batch 280, Loss: 1.0700
Batch 290, Loss: 1.0439
Batch 300, Loss: 0.9925
Batch 310, Loss: 1.0069
Batch 320, Loss: 1.0446
Batch 330, Loss: 1.0368
Batch 340, Loss: 1.0474
Batch 350, Loss: 1.0275
Batch 360, Loss: 0.9819
Batch 370, Loss: 1.0538
Batch 380, Loss: 1.0814
Batch 390, Loss: 1.0197
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.151817083358765 seconds
Epoch 33 accuracy: 57.41%
Batch 10, Loss: 0.9133
Batch 20, Loss: 0.8642
Batch 30, Loss: 0.9359
Batch 40, Loss: 0.9402
Batch 50, Loss: 0.9667
Batch 60, Loss: 0.9687
Batch 70, Loss: 0.9498
Batch 80, Loss: 0.9652
Batch 90, Loss: 0.9763
Batch 100, Loss: 0.9855
Batch 110, Loss: 0.9503
Batch 120, Loss: 0.9807
Batch 130, Loss: 1.0191
Batch 140, Loss: 0.9901
Batch 150, Loss: 0.9504
Batch 160, Loss: 1.0180
Batch 170, Loss: 0.9858
Batch 180, Loss: 0.9721
Batch 190, Loss: 0.9925
Batch 200, Loss: 1.0592
Batch 210, Loss: 1.0276
Batch 220, Loss: 0.9698
Batch 230, Loss: 1.0584
Batch 240, Loss: 1.0074
Batch 250, Loss: 0.9781
Batch 260, Loss: 1.0127
Batch 270, Loss: 1.0422
Batch 280, Loss: 0.9618
Batch 290, Loss: 0.9931
Batch 300, Loss: 0.9854
Batch 310, Loss: 0.9823
Batch 320, Loss: 1.0230
Batch 330, Loss: 1.0660
Batch 340, Loss: 0.9811
Batch 350, Loss: 0.9749
Batch 360, Loss: 1.0941
Batch 370, Loss: 1.0016
Batch 380, Loss: 0.9976
Batch 390, Loss: 1.0147
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.175620555877686 seconds
Epoch 34 accuracy: 58.42%
Batch 10, Loss: 0.8997
Batch 20, Loss: 0.9218
Batch 30, Loss: 0.9442
Batch 40, Loss: 0.9073
Batch 50, Loss: 0.9956
Batch 60, Loss: 0.9086
Batch 70, Loss: 0.9602
Batch 80, Loss: 0.8958
Batch 90, Loss: 0.9234
Batch 100, Loss: 0.9582
Batch 110, Loss: 0.9387
Batch 120, Loss: 0.9786
Batch 130, Loss: 0.9751
Batch 140, Loss: 0.9484
Batch 150, Loss: 1.0253
Batch 160, Loss: 0.9940
Batch 170, Loss: 0.9491
Batch 180, Loss: 0.9882
Batch 190, Loss: 1.0196
Batch 200, Loss: 1.0176
Batch 210, Loss: 1.0322
Batch 220, Loss: 0.9471
Batch 230, Loss: 0.9637
Batch 240, Loss: 0.9739
Batch 250, Loss: 0.9405
Batch 260, Loss: 1.0116
Batch 270, Loss: 1.0365
Batch 280, Loss: 1.0115
Batch 290, Loss: 1.0010
Batch 300, Loss: 0.9960
Batch 310, Loss: 1.1020
Batch 320, Loss: 1.1031
Batch 330, Loss: 1.0226
Batch 340, Loss: 1.0174
Batch 350, Loss: 0.9735
Batch 360, Loss: 0.9919
Batch 370, Loss: 1.0354
Batch 380, Loss: 1.0526
Batch 390, Loss: 1.0646
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.078636169433594 seconds
Epoch 35 accuracy: 58.09%
Batch 10, Loss: 0.9154
Batch 20, Loss: 1.0109
Batch 30, Loss: 0.9292
Batch 40, Loss: 0.9000
Batch 50, Loss: 0.9576
Batch 60, Loss: 0.9384
Batch 70, Loss: 0.9077
Batch 80, Loss: 0.9927
Batch 90, Loss: 0.9899
Batch 100, Loss: 0.9630
Batch 110, Loss: 0.9498
Batch 120, Loss: 0.9542
Batch 130, Loss: 0.9379
Batch 140, Loss: 0.9853
Batch 150, Loss: 0.9440
Batch 160, Loss: 0.9861
Batch 170, Loss: 0.9712
Batch 180, Loss: 0.9887
Batch 190, Loss: 0.9690
Batch 200, Loss: 0.9318
Batch 210, Loss: 0.9710
Batch 220, Loss: 0.9911
Batch 230, Loss: 0.9658
Batch 240, Loss: 0.9650
Batch 250, Loss: 0.9413
Batch 260, Loss: 1.0498
Batch 270, Loss: 0.9772
Batch 280, Loss: 1.0648
Batch 290, Loss: 1.0621
Batch 300, Loss: 1.0656
Batch 310, Loss: 0.9288
Batch 320, Loss: 1.0131
Batch 330, Loss: 1.0241
Batch 340, Loss: 1.0713
Batch 350, Loss: 1.0334
Batch 360, Loss: 0.9872
Batch 370, Loss: 0.9842
Batch 380, Loss: 1.0239
Batch 390, Loss: 0.9766
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.140017986297607 seconds
Epoch 36 accuracy: 58.15%
Batch 10, Loss: 0.9325
Batch 20, Loss: 0.8774
Batch 30, Loss: 0.8765
Batch 40, Loss: 0.8723
Batch 50, Loss: 0.9476
Batch 60, Loss: 0.9637
Batch 70, Loss: 0.9459
Batch 80, Loss: 0.8796
Batch 90, Loss: 0.9243
Batch 100, Loss: 0.8811
Batch 110, Loss: 0.9711
Batch 120, Loss: 0.9529
Batch 130, Loss: 0.8597
Batch 140, Loss: 0.9440
Batch 150, Loss: 0.9942
Batch 160, Loss: 0.9350
Batch 170, Loss: 1.0000
Batch 180, Loss: 0.9563
Batch 190, Loss: 0.9631
Batch 200, Loss: 0.9077
Batch 210, Loss: 0.9897
Batch 220, Loss: 0.9637
Batch 230, Loss: 0.9551
Batch 240, Loss: 0.9905
Batch 250, Loss: 0.9772
Batch 260, Loss: 1.0045
Batch 270, Loss: 1.0057
Batch 280, Loss: 0.9871
Batch 290, Loss: 1.0584
Batch 300, Loss: 1.0322
Batch 310, Loss: 1.0119
Batch 320, Loss: 1.0058
Batch 330, Loss: 1.0062
Batch 340, Loss: 1.0071
Batch 350, Loss: 0.9935
Batch 360, Loss: 0.9227
Batch 370, Loss: 0.9330
Batch 380, Loss: 0.9784
Batch 390, Loss: 0.9837
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.11784291267395 seconds
Epoch 37 accuracy: 58.98%
Batch 10, Loss: 0.8927
Batch 20, Loss: 0.8973
Batch 30, Loss: 0.8672
Batch 40, Loss: 0.9291
Batch 50, Loss: 0.9181
Batch 60, Loss: 0.8608
Batch 70, Loss: 0.8879
Batch 80, Loss: 0.9168
Batch 90, Loss: 0.9173
Batch 100, Loss: 0.9211
Batch 110, Loss: 0.9414
Batch 120, Loss: 0.9312
Batch 130, Loss: 0.9255
Batch 140, Loss: 0.9357
Batch 150, Loss: 1.0080
Batch 160, Loss: 1.0056
Batch 170, Loss: 0.9869
Batch 180, Loss: 0.9845
Batch 190, Loss: 0.9951
Batch 200, Loss: 1.0065
Batch 210, Loss: 0.9868
Batch 220, Loss: 0.9846
Batch 230, Loss: 1.0211
Batch 240, Loss: 0.9840
Batch 250, Loss: 1.0175
Batch 260, Loss: 1.0228
Batch 270, Loss: 0.9645
Batch 280, Loss: 0.9784
Batch 290, Loss: 1.0045
Batch 300, Loss: 1.0380
Batch 310, Loss: 1.0043
Batch 320, Loss: 0.9474
Batch 330, Loss: 1.0029
Batch 340, Loss: 0.9924
Batch 350, Loss: 0.9960
Batch 360, Loss: 0.9823
Batch 370, Loss: 0.9908
Batch 380, Loss: 0.9730
Batch 390, Loss: 0.9939
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.09478259086609 seconds
Epoch 38 accuracy: 55.81%
Batch 10, Loss: 0.9023
Batch 20, Loss: 0.8692
Batch 30, Loss: 0.9037
Batch 40, Loss: 0.8673
Batch 50, Loss: 0.8651
Batch 60, Loss: 0.9123
Batch 70, Loss: 0.9318
Batch 80, Loss: 0.9625
Batch 90, Loss: 0.9106
Batch 100, Loss: 0.9513
Batch 110, Loss: 0.9304
Batch 120, Loss: 0.9776
Batch 130, Loss: 0.9655
Batch 140, Loss: 0.9655
Batch 150, Loss: 0.9547
Batch 160, Loss: 0.9552
Batch 170, Loss: 0.9666
Batch 180, Loss: 1.0013
Batch 190, Loss: 0.9722
Batch 200, Loss: 0.9497
Batch 210, Loss: 0.9745
Batch 220, Loss: 0.9866
Batch 230, Loss: 0.9531
Batch 240, Loss: 0.9668
Batch 250, Loss: 1.0145
Batch 260, Loss: 0.9910
Batch 270, Loss: 0.9982
Batch 280, Loss: 0.9897
Batch 290, Loss: 1.0302
Batch 300, Loss: 1.0044
Batch 310, Loss: 0.9945
Batch 320, Loss: 0.9591
Batch 330, Loss: 1.0024
Batch 340, Loss: 1.0389
Batch 350, Loss: 1.0001
Batch 360, Loss: 1.0422
Batch 370, Loss: 0.9944
Batch 380, Loss: 0.9728
Batch 390, Loss: 1.0702
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.20012378692627 seconds
Epoch 39 accuracy: 59.0%
Batch 10, Loss: 0.8857
Batch 20, Loss: 0.9186
Batch 30, Loss: 0.8593
Batch 40, Loss: 0.8436
Batch 50, Loss: 0.8620
Batch 60, Loss: 0.9253
Batch 70, Loss: 0.9274
Batch 80, Loss: 0.9795
Batch 90, Loss: 0.9242
Batch 100, Loss: 0.9429
Batch 110, Loss: 0.9107
Batch 120, Loss: 0.9299
Batch 130, Loss: 0.9481
Batch 140, Loss: 0.9272
Batch 150, Loss: 0.9291
Batch 160, Loss: 0.9073
Batch 170, Loss: 0.9819
Batch 180, Loss: 0.9261
Batch 190, Loss: 0.9456
Batch 200, Loss: 0.9822
Batch 210, Loss: 0.9699
Batch 220, Loss: 0.9209
Batch 230, Loss: 0.9876
Batch 240, Loss: 0.9769
Batch 250, Loss: 0.8797
Batch 260, Loss: 0.9091
Batch 270, Loss: 0.9643
Batch 280, Loss: 0.9492
Batch 290, Loss: 0.9858
Batch 300, Loss: 0.9739
Batch 310, Loss: 1.0064
Batch 320, Loss: 0.9730
Batch 330, Loss: 1.0257
Batch 340, Loss: 0.9895
Batch 350, Loss: 0.9833
Batch 360, Loss: 0.9848
Batch 370, Loss: 0.9739
Batch 380, Loss: 0.9574
Batch 390, Loss: 0.9829
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.127479076385498 seconds
Epoch 40 accuracy: 60.21%
Batch 10, Loss: 0.8435
Batch 20, Loss: 0.8972
Batch 30, Loss: 0.8446
Batch 40, Loss: 0.8448
Batch 50, Loss: 0.8800
Batch 60, Loss: 0.9212
Batch 70, Loss: 0.9311
Batch 80, Loss: 0.9023
Batch 90, Loss: 0.9434
Batch 100, Loss: 0.9230
Batch 110, Loss: 0.9341
Batch 120, Loss: 0.9607
Batch 130, Loss: 0.9131
Batch 140, Loss: 0.9688
Batch 150, Loss: 0.9187
Batch 160, Loss: 0.9216
Batch 170, Loss: 0.9676
Batch 180, Loss: 0.9373
Batch 190, Loss: 0.9629
Batch 200, Loss: 0.8764
Batch 210, Loss: 0.9146
Batch 220, Loss: 0.9863
Batch 230, Loss: 0.9567
Batch 240, Loss: 1.0071
Batch 250, Loss: 0.9267
Batch 260, Loss: 0.9126
Batch 270, Loss: 0.9382
Batch 280, Loss: 0.9720
Batch 290, Loss: 1.0369
Batch 300, Loss: 1.0377
Batch 310, Loss: 0.9973
Batch 320, Loss: 0.9944
Batch 330, Loss: 0.9757
Batch 340, Loss: 0.9393
Batch 350, Loss: 0.9790
Batch 360, Loss: 1.0028
Batch 370, Loss: 1.0004
Batch 380, Loss: 1.0287
Batch 390, Loss: 1.0108
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.197264909744263 seconds
Epoch 41 accuracy: 60.61%
Batch 10, Loss: 0.8750
Batch 20, Loss: 0.9488
Batch 30, Loss: 0.8997
Batch 40, Loss: 0.8398
Batch 50, Loss: 0.9008
Batch 60, Loss: 0.8686
Batch 70, Loss: 0.9110
Batch 80, Loss: 0.8467
Batch 90, Loss: 0.8619
Batch 100, Loss: 0.9089
Batch 110, Loss: 0.8976
Batch 120, Loss: 0.8767
Batch 130, Loss: 0.8791
Batch 140, Loss: 0.9199
Batch 150, Loss: 0.9922
Batch 160, Loss: 0.9251
Batch 170, Loss: 0.8848
Batch 180, Loss: 0.9628
Batch 190, Loss: 0.8879
Batch 200, Loss: 0.9441
Batch 210, Loss: 0.9949
Batch 220, Loss: 0.9273
Batch 230, Loss: 0.9474
Batch 240, Loss: 0.9446
Batch 250, Loss: 0.9652
Batch 260, Loss: 0.9134
Batch 270, Loss: 0.9562
Batch 280, Loss: 0.9799
Batch 290, Loss: 0.9762
Batch 300, Loss: 0.9947
Batch 310, Loss: 0.9935
Batch 320, Loss: 0.9255
Batch 330, Loss: 1.0025
Batch 340, Loss: 1.0194
Batch 350, Loss: 0.9733
Batch 360, Loss: 0.9570
Batch 370, Loss: 1.0003
Batch 380, Loss: 1.0079
Batch 390, Loss: 0.9782
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.08447289466858 seconds
Epoch 42 accuracy: 56.06%
Batch 10, Loss: 0.9245
Batch 20, Loss: 0.8436
Batch 30, Loss: 0.9182
Batch 40, Loss: 0.8914
Batch 50, Loss: 0.8467
Batch 60, Loss: 0.8912
Batch 70, Loss: 0.8558
Batch 80, Loss: 0.8596
Batch 90, Loss: 0.8750
Batch 100, Loss: 0.9037
Batch 110, Loss: 0.9139
Batch 120, Loss: 0.8997
Batch 130, Loss: 0.9433
Batch 140, Loss: 0.9683
Batch 150, Loss: 0.9516
Batch 160, Loss: 0.8968
Batch 170, Loss: 0.9472
Batch 180, Loss: 0.9427
Batch 190, Loss: 0.9399
Batch 200, Loss: 0.9826
Batch 210, Loss: 0.9041
Batch 220, Loss: 0.9499
Batch 230, Loss: 0.8937
Batch 240, Loss: 0.9320
Batch 250, Loss: 0.9381
Batch 260, Loss: 0.9594
Batch 270, Loss: 0.9680
Batch 280, Loss: 0.9646
Batch 290, Loss: 0.9922
Batch 300, Loss: 0.9382
Batch 310, Loss: 0.9478
Batch 320, Loss: 0.9554
Batch 330, Loss: 0.9620
Batch 340, Loss: 1.0654
Batch 350, Loss: 0.9550
Batch 360, Loss: 0.9820
Batch 370, Loss: 0.9805
Batch 380, Loss: 0.9656
Batch 390, Loss: 1.0037
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.146652698516846 seconds
Epoch 43 accuracy: 61.06%
Batch 10, Loss: 0.8564
Batch 20, Loss: 0.8755
Batch 30, Loss: 0.8625
Batch 40, Loss: 0.8684
Batch 50, Loss: 0.8586
Batch 60, Loss: 0.8568
Batch 70, Loss: 0.8731
Batch 80, Loss: 0.9039
Batch 90, Loss: 0.9011
Batch 100, Loss: 0.9038
Batch 110, Loss: 0.8497
Batch 120, Loss: 0.8703
Batch 130, Loss: 0.8714
Batch 140, Loss: 0.9216
Batch 150, Loss: 0.9002
Batch 160, Loss: 0.8871
Batch 170, Loss: 0.9288
Batch 180, Loss: 0.9190
Batch 190, Loss: 0.9348
Batch 200, Loss: 0.9216
Batch 210, Loss: 0.9098
Batch 220, Loss: 0.9475
Batch 230, Loss: 0.9245
Batch 240, Loss: 0.9034
Batch 250, Loss: 0.9419
Batch 260, Loss: 0.9871
Batch 270, Loss: 0.9754
Batch 280, Loss: 0.9411
Batch 290, Loss: 0.9414
Batch 300, Loss: 0.9677
Batch 310, Loss: 0.9767
Batch 320, Loss: 0.9693
Batch 330, Loss: 0.9588
Batch 340, Loss: 0.9402
Batch 350, Loss: 0.9496
Batch 360, Loss: 0.9426
Batch 370, Loss: 0.9474
Batch 380, Loss: 0.9577
Batch 390, Loss: 1.0089
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.213127374649048 seconds
Epoch 44 accuracy: 55.08%
Batch 10, Loss: 0.8834
Batch 20, Loss: 0.8446
Batch 30, Loss: 0.8954
Batch 40, Loss: 0.9060
Batch 50, Loss: 0.8774
Batch 60, Loss: 0.8936
Batch 70, Loss: 0.8815
Batch 80, Loss: 0.8811
Batch 90, Loss: 0.8581
Batch 100, Loss: 0.9228
Batch 110, Loss: 0.8700
Batch 120, Loss: 0.9265
Batch 130, Loss: 0.9066
Batch 140, Loss: 0.9035
Batch 150, Loss: 0.9318
Batch 160, Loss: 0.9091
Batch 170, Loss: 0.9437
Batch 180, Loss: 0.9346
Batch 190, Loss: 0.9041
Batch 200, Loss: 0.9467
Batch 210, Loss: 0.9134
Batch 220, Loss: 0.9397
Batch 230, Loss: 1.0037
Batch 240, Loss: 0.9586
Batch 250, Loss: 0.9595
Batch 260, Loss: 0.9852
Batch 270, Loss: 0.9575
Batch 280, Loss: 0.9259
Batch 290, Loss: 0.8924
Batch 300, Loss: 0.9371
Batch 310, Loss: 0.9491
Batch 320, Loss: 0.9680
Batch 330, Loss: 0.9610
Batch 340, Loss: 1.0099
Batch 350, Loss: 0.9335
Batch 360, Loss: 0.9271
Batch 370, Loss: 0.9458
Batch 380, Loss: 0.9821
Batch 390, Loss: 0.9558
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.127716302871704 seconds
Epoch 45 accuracy: 61.05%
Batch 10, Loss: 0.8740
Batch 20, Loss: 0.8532
Batch 30, Loss: 0.8361
Batch 40, Loss: 0.7988
Batch 50, Loss: 0.8455
Batch 60, Loss: 0.8224
Batch 70, Loss: 0.8887
Batch 80, Loss: 0.8393
Batch 90, Loss: 0.8153
Batch 100, Loss: 0.8944
Batch 110, Loss: 0.9170
Batch 120, Loss: 0.8872
Batch 130, Loss: 0.9314
Batch 140, Loss: 0.9141
Batch 150, Loss: 0.9261
Batch 160, Loss: 0.9364
Batch 170, Loss: 0.9375
Batch 180, Loss: 0.8541
Batch 190, Loss: 0.8778
Batch 200, Loss: 0.8832
Batch 210, Loss: 0.9782
Batch 220, Loss: 0.9484
Batch 230, Loss: 0.9378
Batch 240, Loss: 0.9149
Batch 250, Loss: 0.9681
Batch 260, Loss: 0.9036
Batch 270, Loss: 0.9178
Batch 280, Loss: 0.9515
Batch 290, Loss: 0.9579
Batch 300, Loss: 0.9959
Batch 310, Loss: 0.9744
Batch 320, Loss: 0.9358
Batch 330, Loss: 0.9671
Batch 340, Loss: 0.9363
Batch 350, Loss: 0.9289
Batch 360, Loss: 0.9061
Batch 370, Loss: 0.9991
Batch 380, Loss: 0.9803
Batch 390, Loss: 1.0072
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.181192874908447 seconds
Epoch 46 accuracy: 55.8%
Batch 10, Loss: 0.8872
Batch 20, Loss: 0.8003
Batch 30, Loss: 0.8539
Batch 40, Loss: 0.8306
Batch 50, Loss: 0.8470
Batch 60, Loss: 0.8834
Batch 70, Loss: 0.8793
Batch 80, Loss: 0.8238
Batch 90, Loss: 0.8819
Batch 100, Loss: 0.9171
Batch 110, Loss: 0.9424
Batch 120, Loss: 0.8888
Batch 130, Loss: 0.8860
Batch 140, Loss: 0.9219
Batch 150, Loss: 0.9709
Batch 160, Loss: 0.8676
Batch 170, Loss: 0.9553
Batch 180, Loss: 0.8985
Batch 190, Loss: 0.8584
Batch 200, Loss: 0.9461
Batch 210, Loss: 0.9295
Batch 220, Loss: 0.9592
Batch 230, Loss: 0.8919
Batch 240, Loss: 0.9800
Batch 250, Loss: 0.9701
Batch 260, Loss: 0.9709
Batch 270, Loss: 0.9327
Batch 280, Loss: 0.9285
Batch 290, Loss: 0.9026
Batch 300, Loss: 0.8601
Batch 310, Loss: 0.9649
Batch 320, Loss: 0.9241
Batch 330, Loss: 0.9600
Batch 340, Loss: 0.9364
Batch 350, Loss: 0.9378
Batch 360, Loss: 1.0161
Batch 370, Loss: 0.9192
Batch 380, Loss: 0.9468
Batch 390, Loss: 0.9938
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.210808992385864 seconds
Epoch 47 accuracy: 58.77%
Batch 10, Loss: 0.8510
Batch 20, Loss: 0.8281
Batch 30, Loss: 0.8785
Batch 40, Loss: 0.8007
Batch 50, Loss: 0.8311
Batch 60, Loss: 0.7786
Batch 70, Loss: 0.8512
Batch 80, Loss: 0.8245
Batch 90, Loss: 0.8693
Batch 100, Loss: 0.8794
Batch 110, Loss: 0.8785
Batch 120, Loss: 0.8858
Batch 130, Loss: 0.8900
Batch 140, Loss: 0.9404
Batch 150, Loss: 0.8702
Batch 160, Loss: 0.8910
Batch 170, Loss: 0.9180
Batch 180, Loss: 0.9028
Batch 190, Loss: 0.9401
Batch 200, Loss: 0.8472
Batch 210, Loss: 0.8850
Batch 220, Loss: 0.8617
Batch 230, Loss: 0.8860
Batch 240, Loss: 0.9192
Batch 250, Loss: 0.9429
Batch 260, Loss: 0.9772
Batch 270, Loss: 0.9637
Batch 280, Loss: 0.9678
Batch 290, Loss: 0.9481
Batch 300, Loss: 0.9503
Batch 310, Loss: 0.9418
Batch 320, Loss: 0.9956
Batch 330, Loss: 0.9132
Batch 340, Loss: 0.9718
Batch 350, Loss: 0.9558
Batch 360, Loss: 0.9271
Batch 370, Loss: 0.9400
Batch 380, Loss: 0.9429
Batch 390, Loss: 0.9719
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.14294981956482 seconds
Epoch 48 accuracy: 59.38%
Batch 10, Loss: 0.8731
Batch 20, Loss: 0.8405
Batch 30, Loss: 0.8055
Batch 40, Loss: 0.7962
Batch 50, Loss: 0.8605
Batch 60, Loss: 0.8765
Batch 70, Loss: 0.8580
Batch 80, Loss: 0.8522
Batch 90, Loss: 0.8565
Batch 100, Loss: 0.8655
Batch 110, Loss: 0.8466
Batch 120, Loss: 0.8905
Batch 130, Loss: 0.8898
Batch 140, Loss: 0.8664
Batch 150, Loss: 0.8937
Batch 160, Loss: 0.9030
Batch 170, Loss: 0.8449
Batch 180, Loss: 0.8905
Batch 190, Loss: 0.8737
Batch 200, Loss: 0.9262
Batch 210, Loss: 0.9246
Batch 220, Loss: 0.9350
Batch 230, Loss: 0.8930
Batch 240, Loss: 0.8788
Batch 250, Loss: 0.9234
Batch 260, Loss: 0.8992
Batch 270, Loss: 0.9073
Batch 280, Loss: 0.8885
Batch 290, Loss: 0.9430
Batch 300, Loss: 0.8880
Batch 310, Loss: 0.9120
Batch 320, Loss: 0.9607
Batch 330, Loss: 0.9205
Batch 340, Loss: 0.9504
Batch 350, Loss: 0.9546
Batch 360, Loss: 0.9743
Batch 370, Loss: 0.9716
Batch 380, Loss: 0.9236
Batch 390, Loss: 0.9181
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.149852514266968 seconds
Epoch 49 accuracy: 59.02%
Batch 10, Loss: 0.8615
Batch 20, Loss: 0.8628
Batch 30, Loss: 0.8192
Batch 40, Loss: 0.8097
Batch 50, Loss: 0.9032
Batch 60, Loss: 0.8565
Batch 70, Loss: 0.8357
Batch 80, Loss: 0.8492
Batch 90, Loss: 0.8846
Batch 100, Loss: 0.8975
Batch 110, Loss: 0.9110
Batch 120, Loss: 0.8634
Batch 130, Loss: 0.8907
Batch 140, Loss: 0.9132
Batch 150, Loss: 0.9044
Batch 160, Loss: 0.9028
Batch 170, Loss: 0.8816
Batch 180, Loss: 0.9320
Batch 190, Loss: 0.8613
Batch 200, Loss: 0.8648
Batch 210, Loss: 0.9113
Batch 220, Loss: 0.9251
Batch 230, Loss: 0.8808
Batch 240, Loss: 0.8874
Batch 250, Loss: 0.8972
Batch 260, Loss: 0.9172
Batch 270, Loss: 0.8924
Batch 280, Loss: 0.9398
Batch 290, Loss: 0.9521
Batch 300, Loss: 0.9506
Batch 310, Loss: 0.9264
Batch 320, Loss: 0.9383
Batch 330, Loss: 0.9306
Batch 340, Loss: 0.9196
Batch 350, Loss: 0.8902
Batch 360, Loss: 0.9068
Batch 370, Loss: 0.8431
Batch 380, Loss: 0.8833
Batch 390, Loss: 0.9741
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.212419509887695 seconds
Epoch 50 accuracy: 54.95%
Batch 10, Loss: 0.8145
Batch 20, Loss: 0.8046
Batch 30, Loss: 0.8577
Batch 40, Loss: 0.7384
Batch 50, Loss: 0.7998
Batch 60, Loss: 0.8506
Batch 70, Loss: 0.8263
Batch 80, Loss: 0.8239
Batch 90, Loss: 0.8668
Batch 100, Loss: 0.8519
Batch 110, Loss: 0.9019
Batch 120, Loss: 0.8623
Batch 130, Loss: 0.9196
Batch 140, Loss: 0.9005
Batch 150, Loss: 0.9046
Batch 160, Loss: 0.9657
Batch 170, Loss: 0.9361
Batch 180, Loss: 0.9051
Batch 190, Loss: 0.8956
Batch 200, Loss: 0.8763
Batch 210, Loss: 0.8611
Batch 220, Loss: 0.8792
Batch 230, Loss: 0.8838
Batch 240, Loss: 0.9549
Batch 250, Loss: 0.9181
Batch 260, Loss: 0.9143
Batch 270, Loss: 0.9611
Batch 280, Loss: 0.8890
Batch 290, Loss: 0.9363
Batch 300, Loss: 0.8900
Batch 310, Loss: 0.9040
Batch 320, Loss: 0.9799
Batch 330, Loss: 0.9509
Batch 340, Loss: 0.9216
Batch 350, Loss: 0.9065
Batch 360, Loss: 0.8830
Batch 370, Loss: 0.9011
Batch 380, Loss: 0.9260
Batch 390, Loss: 0.9488
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.17810869216919 seconds
Epoch 51 accuracy: 53.99%
Batch 10, Loss: 0.7908
Batch 20, Loss: 0.8222
Batch 30, Loss: 0.7947
Batch 40, Loss: 0.8227
Batch 50, Loss: 0.7894
Batch 60, Loss: 0.8514
Batch 70, Loss: 0.8523
Batch 80, Loss: 0.8058
Batch 90, Loss: 0.8356
Batch 100, Loss: 0.8430
Batch 110, Loss: 0.8342
Batch 120, Loss: 0.8159
Batch 130, Loss: 0.8739
Batch 140, Loss: 0.8341
Batch 150, Loss: 0.9031
Batch 160, Loss: 0.9041
Batch 170, Loss: 0.8347
Batch 180, Loss: 0.9522
Batch 190, Loss: 0.9541
Batch 200, Loss: 0.9151
Batch 210, Loss: 0.8519
Batch 220, Loss: 0.9007
Batch 230, Loss: 0.9113
Batch 240, Loss: 0.9303
Batch 250, Loss: 0.9381
Batch 260, Loss: 0.9336
Batch 270, Loss: 0.9813
Batch 280, Loss: 0.9179
Batch 290, Loss: 0.9270
Batch 300, Loss: 0.9091
Batch 310, Loss: 0.9462
Batch 320, Loss: 0.9290
Batch 330, Loss: 0.8972
Batch 340, Loss: 0.9181
Batch 350, Loss: 0.9359
Batch 360, Loss: 0.9825
Batch 370, Loss: 0.9274
Batch 380, Loss: 0.9141
Batch 390, Loss: 0.9719
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.182697534561157 seconds
Epoch 52 accuracy: 59.86%
Batch 10, Loss: 0.8402
Batch 20, Loss: 0.8434
Batch 30, Loss: 0.7551
Batch 40, Loss: 0.8234
Batch 50, Loss: 0.7897
Batch 60, Loss: 0.7995
Batch 70, Loss: 0.8365
Batch 80, Loss: 0.8839
Batch 90, Loss: 0.8585
Batch 100, Loss: 0.8559
Batch 110, Loss: 0.8541
Batch 120, Loss: 0.8234
Batch 130, Loss: 0.8167
Batch 140, Loss: 0.8551
Batch 150, Loss: 0.8704
Batch 160, Loss: 0.8765
Batch 170, Loss: 0.8738
Batch 180, Loss: 0.8828
Batch 190, Loss: 0.9279
Batch 200, Loss: 0.8916
Batch 210, Loss: 0.9033
Batch 220, Loss: 0.8749
Batch 230, Loss: 0.9101
Batch 240, Loss: 0.8845
Batch 250, Loss: 0.9325
Batch 260, Loss: 0.9595
Batch 270, Loss: 0.9101
Batch 280, Loss: 0.8805
Batch 290, Loss: 0.8559
Batch 300, Loss: 0.9000
Batch 310, Loss: 0.8945
Batch 320, Loss: 0.8982
Batch 330, Loss: 0.9118
Batch 340, Loss: 0.8768
Batch 350, Loss: 0.8995
Batch 360, Loss: 0.9120
Batch 370, Loss: 0.9203
Batch 380, Loss: 0.9095
Batch 390, Loss: 0.8898
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.166367769241333 seconds
Epoch 53 accuracy: 57.83%
Batch 10, Loss: 0.8736
Batch 20, Loss: 0.8201
Batch 30, Loss: 0.7975
Batch 40, Loss: 0.8365
Batch 50, Loss: 0.8426
Batch 60, Loss: 0.8308
Batch 70, Loss: 0.8211
Batch 80, Loss: 0.8678
Batch 90, Loss: 0.8646
Batch 100, Loss: 0.8384
Batch 110, Loss: 0.8681
Batch 120, Loss: 0.8731
Batch 130, Loss: 0.8215
Batch 140, Loss: 0.8214
Batch 150, Loss: 0.8365
Batch 160, Loss: 0.8685
Batch 170, Loss: 0.8585
Batch 180, Loss: 0.8214
Batch 190, Loss: 0.8430
Batch 200, Loss: 0.8200
Batch 210, Loss: 0.8288
Batch 220, Loss: 0.8974
Batch 230, Loss: 0.8620
Batch 240, Loss: 0.8896
Batch 250, Loss: 0.8305
Batch 260, Loss: 0.8684
Batch 270, Loss: 0.8765
Batch 280, Loss: 0.9130
Batch 290, Loss: 0.8759
Batch 300, Loss: 0.8963
Batch 310, Loss: 0.8968
Batch 320, Loss: 0.9105
Batch 330, Loss: 0.9032
Batch 340, Loss: 0.9030
Batch 350, Loss: 0.9348
Batch 360, Loss: 0.9290
Batch 370, Loss: 0.9390
Batch 380, Loss: 0.9379
Batch 390, Loss: 0.8529
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.132286071777344 seconds
Epoch 54 accuracy: 60.3%
Batch 10, Loss: 0.7887
Batch 20, Loss: 0.7928
Batch 30, Loss: 0.8401
Batch 40, Loss: 0.8008
Batch 50, Loss: 0.7886
Batch 60, Loss: 0.8088
Batch 70, Loss: 0.8660
Batch 80, Loss: 0.8706
Batch 90, Loss: 0.8559
Batch 100, Loss: 0.8193
Batch 110, Loss: 0.8333
Batch 120, Loss: 0.8758
Batch 130, Loss: 0.8364
Batch 140, Loss: 0.8454
Batch 150, Loss: 0.8651
Batch 160, Loss: 0.8867
Batch 170, Loss: 0.8209
Batch 180, Loss: 0.7865
Batch 190, Loss: 0.8817
Batch 200, Loss: 0.8855
Batch 210, Loss: 0.8981
Batch 220, Loss: 0.8870
Batch 230, Loss: 0.8445
Batch 240, Loss: 0.8453
Batch 250, Loss: 0.8303
Batch 260, Loss: 0.8687
Batch 270, Loss: 0.8927
Batch 280, Loss: 0.8931
Batch 290, Loss: 0.9466
Batch 300, Loss: 0.9099
Batch 310, Loss: 0.9172
Batch 320, Loss: 0.9035
Batch 330, Loss: 0.9250
Batch 340, Loss: 0.9180
Batch 350, Loss: 0.8857
Batch 360, Loss: 0.9393
Batch 370, Loss: 0.8799
Batch 380, Loss: 0.9525
Batch 390, Loss: 0.9268
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.092232942581177 seconds
Epoch 55 accuracy: 60.83%
Batch 10, Loss: 0.7538
Batch 20, Loss: 0.8256
Batch 30, Loss: 0.8005
Batch 40, Loss: 0.8598
Batch 50, Loss: 0.8020
Batch 60, Loss: 0.7906
Batch 70, Loss: 0.8643
Batch 80, Loss: 0.8448
Batch 90, Loss: 0.8274
Batch 100, Loss: 0.8013
Batch 110, Loss: 0.7859
Batch 120, Loss: 0.8667
Batch 130, Loss: 0.8167
Batch 140, Loss: 0.8565
Batch 150, Loss: 0.8716
Batch 160, Loss: 0.8297
Batch 170, Loss: 0.8418
Batch 180, Loss: 0.8555
Batch 190, Loss: 0.8867
Batch 200, Loss: 0.8741
Batch 210, Loss: 0.8569
Batch 220, Loss: 0.8551
Batch 230, Loss: 0.8847
Batch 240, Loss: 0.8862
Batch 250, Loss: 0.8685
Batch 260, Loss: 0.9049
Batch 270, Loss: 0.8998
Batch 280, Loss: 0.8963
Batch 290, Loss: 0.9356
Batch 300, Loss: 0.9287
Batch 310, Loss: 0.9108
Batch 320, Loss: 0.9021
Batch 330, Loss: 0.8261
Batch 340, Loss: 0.8785
Batch 350, Loss: 0.8706
Batch 360, Loss: 0.9093
Batch 370, Loss: 0.8714
Batch 380, Loss: 0.9552
Batch 390, Loss: 0.9676
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.151302099227905 seconds
Epoch 56 accuracy: 58.77%
Batch 10, Loss: 0.8966
Batch 20, Loss: 0.7888
Batch 30, Loss: 0.7460
Batch 40, Loss: 0.7489
Batch 50, Loss: 0.8023
Batch 60, Loss: 0.8243
Batch 70, Loss: 0.7648
Batch 80, Loss: 0.7838
Batch 90, Loss: 0.7842
Batch 100, Loss: 0.7760
Batch 110, Loss: 0.8205
Batch 120, Loss: 0.8000
Batch 130, Loss: 0.8701
Batch 140, Loss: 0.8336
Batch 150, Loss: 0.8382
Batch 160, Loss: 0.8653
Batch 170, Loss: 0.8162
Batch 180, Loss: 0.8549
Batch 190, Loss: 0.8561
Batch 200, Loss: 0.9144
Batch 210, Loss: 0.8749
Batch 220, Loss: 0.9006
Batch 230, Loss: 0.9343
Batch 240, Loss: 0.9091
Batch 250, Loss: 0.8950
Batch 260, Loss: 0.8767
Batch 270, Loss: 0.8338
Batch 280, Loss: 0.9465
Batch 290, Loss: 0.8344
Batch 300, Loss: 0.8826
Batch 310, Loss: 0.8435
Batch 320, Loss: 0.8573
Batch 330, Loss: 0.8423
Batch 340, Loss: 0.8635
Batch 350, Loss: 0.9693
Batch 360, Loss: 0.9150
Batch 370, Loss: 0.9373
Batch 380, Loss: 0.8713
Batch 390, Loss: 0.9358
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.116921186447144 seconds
Epoch 57 accuracy: 55.3%
Batch 10, Loss: 0.7856
Batch 20, Loss: 0.7838
Batch 30, Loss: 0.8062
Batch 40, Loss: 0.7764
Batch 50, Loss: 0.7610
Batch 60, Loss: 0.7988
Batch 70, Loss: 0.8366
Batch 80, Loss: 0.7844
Batch 90, Loss: 0.8015
Batch 100, Loss: 0.8312
Batch 110, Loss: 0.8066
Batch 120, Loss: 0.8274
Batch 130, Loss: 0.8385
Batch 140, Loss: 0.8429
Batch 150, Loss: 0.8158
Batch 160, Loss: 0.8475
Batch 170, Loss: 0.8091
Batch 180, Loss: 0.8301
Batch 190, Loss: 0.8700
Batch 200, Loss: 0.8087
Batch 210, Loss: 0.8390
Batch 220, Loss: 0.8504
Batch 230, Loss: 0.8310
Batch 240, Loss: 0.8498
Batch 250, Loss: 0.8718
Batch 260, Loss: 0.8060
Batch 270, Loss: 0.8530
Batch 280, Loss: 0.8722
Batch 290, Loss: 0.8841
Batch 300, Loss: 0.9028
Batch 310, Loss: 0.8971
Batch 320, Loss: 0.9282
Batch 330, Loss: 0.9068
Batch 340, Loss: 0.8261
Batch 350, Loss: 0.8942
Batch 360, Loss: 0.8771
Batch 370, Loss: 0.8632
Batch 380, Loss: 0.9066
Batch 390, Loss: 0.8683
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.140875577926636 seconds
Epoch 58 accuracy: 59.17%
Batch 10, Loss: 0.7817
Batch 20, Loss: 0.8036
Batch 30, Loss: 0.7484
Batch 40, Loss: 0.7710
Batch 50, Loss: 0.7580
Batch 60, Loss: 0.7961
Batch 70, Loss: 0.8143
Batch 80, Loss: 0.8452
Batch 90, Loss: 0.7843
Batch 100, Loss: 0.8622
Batch 110, Loss: 0.8620
Batch 120, Loss: 0.8050
Batch 130, Loss: 0.8352
Batch 140, Loss: 0.8536
Batch 150, Loss: 0.8171
Batch 160, Loss: 0.8343
Batch 170, Loss: 0.8789
Batch 180, Loss: 0.8451
Batch 190, Loss: 0.8456
Batch 200, Loss: 0.8863
Batch 210, Loss: 0.9138
Batch 220, Loss: 0.8567
Batch 230, Loss: 0.8492
Batch 240, Loss: 0.8498
Batch 250, Loss: 0.9300
Batch 260, Loss: 0.8648
Batch 270, Loss: 0.8493
Batch 280, Loss: 0.8860
Batch 290, Loss: 0.8789
Batch 300, Loss: 0.8726
Batch 310, Loss: 0.8819
Batch 320, Loss: 0.9109
Batch 330, Loss: 0.8820
Batch 340, Loss: 0.8237
Batch 350, Loss: 0.8595
Batch 360, Loss: 0.8638
Batch 370, Loss: 0.8574
Batch 380, Loss: 0.8691
Batch 390, Loss: 0.9010
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 24.999220848083496 seconds
Epoch 59 accuracy: 63.35%
Batch 10, Loss: 0.7796
Batch 20, Loss: 0.7558
Batch 30, Loss: 0.7238
Batch 40, Loss: 0.7409
Batch 50, Loss: 0.7526
Batch 60, Loss: 0.7261
Batch 70, Loss: 0.7923
Batch 80, Loss: 0.7853
Batch 90, Loss: 0.7568
Batch 100, Loss: 0.7306
Batch 110, Loss: 0.8091
Batch 120, Loss: 0.7899
Batch 130, Loss: 0.7714
Batch 140, Loss: 0.8466
Batch 150, Loss: 0.8612
Batch 160, Loss: 0.8479
Batch 170, Loss: 0.7850
Batch 180, Loss: 0.8036
Batch 190, Loss: 0.9149
Batch 200, Loss: 0.8344
Batch 210, Loss: 0.9240
Batch 220, Loss: 0.8679
Batch 230, Loss: 0.9037
Batch 240, Loss: 0.8775
Batch 250, Loss: 0.8720
Batch 260, Loss: 0.8704
Batch 270, Loss: 0.9162
Batch 280, Loss: 0.8571
Batch 290, Loss: 0.8576
Batch 300, Loss: 0.8712
Batch 310, Loss: 0.8472
Batch 320, Loss: 0.8683
Batch 330, Loss: 0.8677
Batch 340, Loss: 0.8587
Batch 350, Loss: 0.9028
Batch 360, Loss: 0.8718
Batch 370, Loss: 0.8993
Batch 380, Loss: 0.8196
Batch 390, Loss: 0.8364
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.100741147994995 seconds
Epoch 60 accuracy: 59.16%
Batch 10, Loss: 0.7342
Batch 20, Loss: 0.7956
Batch 30, Loss: 0.7678
Batch 40, Loss: 0.8227
Batch 50, Loss: 0.7893
Batch 60, Loss: 0.7344
Batch 70, Loss: 0.7558
Batch 80, Loss: 0.8008
Batch 90, Loss: 0.7278
Batch 100, Loss: 0.8134
Batch 110, Loss: 0.8078
Batch 120, Loss: 0.8032
Batch 130, Loss: 0.7906
Batch 140, Loss: 0.8092
Batch 150, Loss: 0.8111
Batch 160, Loss: 0.8685
Batch 170, Loss: 0.8491
Batch 180, Loss: 0.8027
Batch 190, Loss: 0.8621
Batch 200, Loss: 0.8351
Batch 210, Loss: 0.8235
Batch 220, Loss: 0.9303
Batch 230, Loss: 0.8692
Batch 240, Loss: 0.8491
Batch 250, Loss: 0.8751
Batch 260, Loss: 0.8185
Batch 270, Loss: 0.8714
Batch 280, Loss: 0.8813
Batch 290, Loss: 0.8441
Batch 300, Loss: 0.8467
Batch 310, Loss: 0.8565
Batch 320, Loss: 0.8646
Batch 330, Loss: 0.8236
Batch 340, Loss: 0.8862
Batch 350, Loss: 0.8880
Batch 360, Loss: 0.8784
Batch 370, Loss: 0.9034
Batch 380, Loss: 0.8932
Batch 390, Loss: 0.8539
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.1470365524292 seconds
Epoch 61 accuracy: 59.88%
Batch 10, Loss: 0.7698
Batch 20, Loss: 0.7236
Batch 30, Loss: 0.7651
Batch 40, Loss: 0.7406
Batch 50, Loss: 0.7883
Batch 60, Loss: 0.7748
Batch 70, Loss: 0.7809
Batch 80, Loss: 0.7645
Batch 90, Loss: 0.7825
Batch 100, Loss: 0.8546
Batch 110, Loss: 0.7716
Batch 120, Loss: 0.8205
Batch 130, Loss: 0.8354
Batch 140, Loss: 0.7770
Batch 150, Loss: 0.7950
Batch 160, Loss: 0.8524
Batch 170, Loss: 0.8293
Batch 180, Loss: 0.8220
Batch 190, Loss: 0.8050
Batch 200, Loss: 0.8520
Batch 210, Loss: 0.8547
Batch 220, Loss: 0.8608
Batch 230, Loss: 0.9153
Batch 240, Loss: 0.8245
Batch 250, Loss: 0.8802
Batch 260, Loss: 0.8179
Batch 270, Loss: 0.8686
Batch 280, Loss: 0.8839
Batch 290, Loss: 0.8813
Batch 300, Loss: 0.8277
Batch 310, Loss: 0.8795
Batch 320, Loss: 0.8267
Batch 330, Loss: 0.8771
Batch 340, Loss: 0.8158
Batch 350, Loss: 0.8840
Batch 360, Loss: 0.8973
Batch 370, Loss: 0.8993
Batch 380, Loss: 0.8698
Batch 390, Loss: 0.8598
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.09353542327881 seconds
Epoch 62 accuracy: 63.66%
Batch 10, Loss: 0.7646
Batch 20, Loss: 0.6907
Batch 30, Loss: 0.7176
Batch 40, Loss: 0.7847
Batch 50, Loss: 0.7438
Batch 60, Loss: 0.8140
Batch 70, Loss: 0.7818
Batch 80, Loss: 0.7383
Batch 90, Loss: 0.7172
Batch 100, Loss: 0.7769
Batch 110, Loss: 0.7908
Batch 120, Loss: 0.7681
Batch 130, Loss: 0.8078
Batch 140, Loss: 0.8193
Batch 150, Loss: 0.7599
Batch 160, Loss: 0.8351
Batch 170, Loss: 0.8075
Batch 180, Loss: 0.8579
Batch 190, Loss: 0.7777
Batch 200, Loss: 0.8113
Batch 210, Loss: 0.8175
Batch 220, Loss: 0.8788
Batch 230, Loss: 0.8275
Batch 240, Loss: 0.8344
Batch 250, Loss: 0.8129
Batch 260, Loss: 0.8301
Batch 270, Loss: 0.8527
Batch 280, Loss: 0.8671
Batch 290, Loss: 0.8661
Batch 300, Loss: 0.8520
Batch 310, Loss: 0.8352
Batch 320, Loss: 0.8700
Batch 330, Loss: 0.8711
Batch 340, Loss: 0.8303
Batch 350, Loss: 0.8572
Batch 360, Loss: 0.9017
Batch 370, Loss: 0.8657
Batch 380, Loss: 0.8278
Batch 390, Loss: 0.8651
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.110146522521973 seconds
Epoch 63 accuracy: 61.91%
Batch 10, Loss: 0.7720
Batch 20, Loss: 0.7584
Batch 30, Loss: 0.7437
Batch 40, Loss: 0.7277
Batch 50, Loss: 0.7209
Batch 60, Loss: 0.7096
Batch 70, Loss: 0.7597
Batch 80, Loss: 0.7843
Batch 90, Loss: 0.7561
Batch 100, Loss: 0.8004
Batch 110, Loss: 0.7943
Batch 120, Loss: 0.7952
Batch 130, Loss: 0.7982
Batch 140, Loss: 0.8220
Batch 150, Loss: 0.8166
Batch 160, Loss: 0.7687
Batch 170, Loss: 0.8081
Batch 180, Loss: 0.7840
Batch 190, Loss: 0.8080
Batch 200, Loss: 0.8059
Batch 210, Loss: 0.8387
Batch 220, Loss: 0.8384
Batch 230, Loss: 0.8521
Batch 240, Loss: 0.8697
Batch 250, Loss: 0.8041
Batch 260, Loss: 0.8554
Batch 270, Loss: 0.8235
Batch 280, Loss: 0.9011
Batch 290, Loss: 0.8443
Batch 300, Loss: 0.8555
Batch 310, Loss: 0.8224
Batch 320, Loss: 0.8201
Batch 330, Loss: 0.8877
Batch 340, Loss: 0.8598
Batch 350, Loss: 0.8563
Batch 360, Loss: 0.8736
Batch 370, Loss: 0.8748
Batch 380, Loss: 0.8392
Batch 390, Loss: 0.8740
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.11569905281067 seconds
Epoch 64 accuracy: 61.34%
Batch 10, Loss: 0.7717
Batch 20, Loss: 0.7735
Batch 30, Loss: 0.7331
Batch 40, Loss: 0.7096
Batch 50, Loss: 0.7482
Batch 60, Loss: 0.6932
Batch 70, Loss: 0.7122
Batch 80, Loss: 0.7363
Batch 90, Loss: 0.7318
Batch 100, Loss: 0.8021
Batch 110, Loss: 0.8474
Batch 120, Loss: 0.8055
Batch 130, Loss: 0.7729
Batch 140, Loss: 0.7857
Batch 150, Loss: 0.8070
Batch 160, Loss: 0.7562
Batch 170, Loss: 0.8027
Batch 180, Loss: 0.7978
Batch 190, Loss: 0.8356
Batch 200, Loss: 0.7750
Batch 210, Loss: 0.8197
Batch 220, Loss: 0.7849
Batch 230, Loss: 0.8093
Batch 240, Loss: 0.8059
Batch 250, Loss: 0.7983
Batch 260, Loss: 0.8151
Batch 270, Loss: 0.8094
Batch 280, Loss: 0.8208
Batch 290, Loss: 0.8376
Batch 300, Loss: 0.8392
Batch 310, Loss: 0.8110
Batch 320, Loss: 0.8897
Batch 330, Loss: 0.8521
Batch 340, Loss: 0.9127
Batch 350, Loss: 0.8722
Batch 360, Loss: 0.8041
Batch 370, Loss: 0.8365
Batch 380, Loss: 0.8646
Batch 390, Loss: 0.8504
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.21408176422119 seconds
Epoch 65 accuracy: 63.0%
Batch 10, Loss: 0.7975
Batch 20, Loss: 0.6979
Batch 30, Loss: 0.7041
Batch 40, Loss: 0.7089
Batch 50, Loss: 0.7204
Batch 60, Loss: 0.7424
Batch 70, Loss: 0.7543
Batch 80, Loss: 0.7408
Batch 90, Loss: 0.8094
Batch 100, Loss: 0.7676
Batch 110, Loss: 0.8198
Batch 120, Loss: 0.8244
Batch 130, Loss: 0.8181
Batch 140, Loss: 0.8006
Batch 150, Loss: 0.7274
Batch 160, Loss: 0.8074
Batch 170, Loss: 0.8344
Batch 180, Loss: 0.7608
Batch 190, Loss: 0.7652
Batch 200, Loss: 0.8488
Batch 210, Loss: 0.7687
Batch 220, Loss: 0.8107
Batch 230, Loss: 0.8217
Batch 240, Loss: 0.7631
Batch 250, Loss: 0.7875
Batch 260, Loss: 0.7985
Batch 270, Loss: 0.8325
Batch 280, Loss: 0.8560
Batch 290, Loss: 0.8754
Batch 300, Loss: 0.8225
Batch 310, Loss: 0.8027
Batch 320, Loss: 0.8512
Batch 330, Loss: 0.8326
Batch 340, Loss: 0.8820
Batch 350, Loss: 0.8120
Batch 360, Loss: 0.8618
Batch 370, Loss: 0.8476
Batch 380, Loss: 0.8112
Batch 390, Loss: 0.8486
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.180498123168945 seconds
Epoch 66 accuracy: 60.8%
Batch 10, Loss: 0.7415
Batch 20, Loss: 0.7059
Batch 30, Loss: 0.7487
Batch 40, Loss: 0.6704
Batch 50, Loss: 0.6622
Batch 60, Loss: 0.7414
Batch 70, Loss: 0.7863
Batch 80, Loss: 0.7233
Batch 90, Loss: 0.7599
Batch 100, Loss: 0.7378
Batch 110, Loss: 0.7810
Batch 120, Loss: 0.7771
Batch 130, Loss: 0.7535
Batch 140, Loss: 0.7679
Batch 150, Loss: 0.7519
Batch 160, Loss: 0.7991
Batch 170, Loss: 0.7957
Batch 180, Loss: 0.8206
Batch 190, Loss: 0.8045
Batch 200, Loss: 0.8006
Batch 210, Loss: 0.8064
Batch 220, Loss: 0.8090
Batch 230, Loss: 0.8147
Batch 240, Loss: 0.7653
Batch 250, Loss: 0.8000
Batch 260, Loss: 0.8116
Batch 270, Loss: 0.8101
Batch 280, Loss: 0.7450
Batch 290, Loss: 0.7858
Batch 300, Loss: 0.8360
Batch 310, Loss: 0.8869
Batch 320, Loss: 0.8986
Batch 330, Loss: 0.8500
Batch 340, Loss: 0.9043
Batch 350, Loss: 0.8700
Batch 360, Loss: 0.8675
Batch 370, Loss: 0.8453
Batch 380, Loss: 0.8706
Batch 390, Loss: 0.8590
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.133252143859863 seconds
Epoch 67 accuracy: 61.26%
Batch 10, Loss: 0.7821
Batch 20, Loss: 0.7593
Batch 30, Loss: 0.7535
Batch 40, Loss: 0.7449
Batch 50, Loss: 0.6938
Batch 60, Loss: 0.7324
Batch 70, Loss: 0.7400
Batch 80, Loss: 0.7270
Batch 90, Loss: 0.7904
Batch 100, Loss: 0.7733
Batch 110, Loss: 0.8013
Batch 120, Loss: 0.7350
Batch 130, Loss: 0.7482
Batch 140, Loss: 0.7759
Batch 150, Loss: 0.7607
Batch 160, Loss: 0.7609
Batch 170, Loss: 0.7744
Batch 180, Loss: 0.8015
Batch 190, Loss: 0.7527
Batch 200, Loss: 0.7825
Batch 210, Loss: 0.8020
Batch 220, Loss: 0.7770
Batch 230, Loss: 0.7399
Batch 240, Loss: 0.7889
Batch 250, Loss: 0.8360
Batch 260, Loss: 0.8501
Batch 270, Loss: 0.8102
Batch 280, Loss: 0.7792
Batch 290, Loss: 0.8162
Batch 300, Loss: 0.8228
Batch 310, Loss: 0.8678
Batch 320, Loss: 0.8651
Batch 330, Loss: 0.7904
Batch 340, Loss: 0.7957
Batch 350, Loss: 0.7676
Batch 360, Loss: 0.8142
Batch 370, Loss: 0.8221
Batch 380, Loss: 0.8751
Batch 390, Loss: 0.8797
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.211599111557007 seconds
Epoch 68 accuracy: 62.28%
Batch 10, Loss: 0.7285
Batch 20, Loss: 0.7050
Batch 30, Loss: 0.6945
Batch 40, Loss: 0.7472
Batch 50, Loss: 0.7573
Batch 60, Loss: 0.7056
Batch 70, Loss: 0.6970
Batch 80, Loss: 0.7312
Batch 90, Loss: 0.7034
Batch 100, Loss: 0.7683
Batch 110, Loss: 0.8593
Batch 120, Loss: 0.7606
Batch 130, Loss: 0.7592
Batch 140, Loss: 0.8070
Batch 150, Loss: 0.7513
Batch 160, Loss: 0.7523
Batch 170, Loss: 0.7891
Batch 180, Loss: 0.7181
Batch 190, Loss: 0.7217
Batch 200, Loss: 0.8159
Batch 210, Loss: 0.7964
Batch 220, Loss: 0.8150
Batch 230, Loss: 0.7645
Batch 240, Loss: 0.7612
Batch 250, Loss: 0.7670
Batch 260, Loss: 0.7981
Batch 270, Loss: 0.8385
Batch 280, Loss: 0.8564
Batch 290, Loss: 0.7964
Batch 300, Loss: 0.8653
Batch 310, Loss: 0.8316
Batch 320, Loss: 0.8371
Batch 330, Loss: 0.8477
Batch 340, Loss: 0.8364
Batch 350, Loss: 0.7911
Batch 360, Loss: 0.8586
Batch 370, Loss: 0.8099
Batch 380, Loss: 0.8032
Batch 390, Loss: 0.8279
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.19901990890503 seconds
Epoch 69 accuracy: 63.33%
Batch 10, Loss: 0.7054
Batch 20, Loss: 0.7088
Batch 30, Loss: 0.6994
Batch 40, Loss: 0.6981
Batch 50, Loss: 0.7434
Batch 60, Loss: 0.6666
Batch 70, Loss: 0.7203
Batch 80, Loss: 0.7045
Batch 90, Loss: 0.7160
Batch 100, Loss: 0.7419
Batch 110, Loss: 0.7603
Batch 120, Loss: 0.7735
Batch 130, Loss: 0.7881
Batch 140, Loss: 0.7810
Batch 150, Loss: 0.7400
Batch 160, Loss: 0.7350
Batch 170, Loss: 0.7762
Batch 180, Loss: 0.7503
Batch 190, Loss: 0.7628
Batch 200, Loss: 0.7612
Batch 210, Loss: 0.7901
Batch 220, Loss: 0.8141
Batch 230, Loss: 0.8035
Batch 240, Loss: 0.8115
Batch 250, Loss: 0.7625
Batch 260, Loss: 0.8008
Batch 270, Loss: 0.8273
Batch 280, Loss: 0.8101
Batch 290, Loss: 0.8032
Batch 300, Loss: 0.8161
Batch 310, Loss: 0.8034
Batch 320, Loss: 0.8120
Batch 330, Loss: 0.8386
Batch 340, Loss: 0.8542
Batch 350, Loss: 0.8298
Batch 360, Loss: 0.8255
Batch 370, Loss: 0.8012
Batch 380, Loss: 0.7895
Batch 390, Loss: 0.8403
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.305776357650757 seconds
Epoch 70 accuracy: 62.28%
Batch 10, Loss: 0.7103
Batch 20, Loss: 0.7119
Batch 30, Loss: 0.7401
Batch 40, Loss: 0.7107
Batch 50, Loss: 0.7566
Batch 60, Loss: 0.7450
Batch 70, Loss: 0.6845
Batch 80, Loss: 0.7121
Batch 90, Loss: 0.7348
Batch 100, Loss: 0.7048
Batch 110, Loss: 0.7367
Batch 120, Loss: 0.7383
Batch 130, Loss: 0.7526
Batch 140, Loss: 0.7590
Batch 150, Loss: 0.7190
Batch 160, Loss: 0.7867
Batch 170, Loss: 0.7864
Batch 180, Loss: 0.7328
Batch 190, Loss: 0.7460
Batch 200, Loss: 0.8039
Batch 210, Loss: 0.7989
Batch 220, Loss: 0.7655
Batch 230, Loss: 0.8735
Batch 240, Loss: 0.7800
Batch 250, Loss: 0.7938
Batch 260, Loss: 0.7807
Batch 270, Loss: 0.7961
Batch 280, Loss: 0.8377
Batch 290, Loss: 0.7643
Batch 300, Loss: 0.7757
Batch 310, Loss: 0.8225
Batch 320, Loss: 0.7849
Batch 330, Loss: 0.8069
Batch 340, Loss: 0.8658
Batch 350, Loss: 0.8316
Batch 360, Loss: 0.8526
Batch 370, Loss: 0.7787
Batch 380, Loss: 0.8121
Batch 390, Loss: 0.8356
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.160923719406128 seconds
Epoch 71 accuracy: 61.21%
Batch 10, Loss: 0.7171
Batch 20, Loss: 0.6547
Batch 30, Loss: 0.6944
Batch 40, Loss: 0.6674
Batch 50, Loss: 0.6814
Batch 60, Loss: 0.6701
Batch 70, Loss: 0.7275
Batch 80, Loss: 0.7509
Batch 90, Loss: 0.7837
Batch 100, Loss: 0.7431
Batch 110, Loss: 0.7127
Batch 120, Loss: 0.7292
Batch 130, Loss: 0.7742
Batch 140, Loss: 0.7336
Batch 150, Loss: 0.7376
Batch 160, Loss: 0.7638
Batch 170, Loss: 0.7291
Batch 180, Loss: 0.7801
Batch 190, Loss: 0.7862
Batch 200, Loss: 0.7776
Batch 210, Loss: 0.7817
Batch 220, Loss: 0.7836
Batch 230, Loss: 0.8216
Batch 240, Loss: 0.7610
Batch 250, Loss: 0.7849
Batch 260, Loss: 0.7921
Batch 270, Loss: 0.7449
Batch 280, Loss: 0.7855
Batch 290, Loss: 0.7628
Batch 300, Loss: 0.7547
Batch 310, Loss: 0.7934
Batch 320, Loss: 0.7493
Batch 330, Loss: 0.7638
Batch 340, Loss: 0.7579
Batch 350, Loss: 0.7914
Batch 360, Loss: 0.8205
Batch 370, Loss: 0.8442
Batch 380, Loss: 0.8568
Batch 390, Loss: 0.7825
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.24020767211914 seconds
Epoch 72 accuracy: 63.75%
Batch 10, Loss: 0.6492
Batch 20, Loss: 0.6653
Batch 30, Loss: 0.7069
Batch 40, Loss: 0.6383
Batch 50, Loss: 0.7129
Batch 60, Loss: 0.7317
Batch 70, Loss: 0.7154
Batch 80, Loss: 0.6603
Batch 90, Loss: 0.6671
Batch 100, Loss: 0.7029
Batch 110, Loss: 0.7159
Batch 120, Loss: 0.7539
Batch 130, Loss: 0.7757
Batch 140, Loss: 0.7826
Batch 150, Loss: 0.7862
Batch 160, Loss: 0.7275
Batch 170, Loss: 0.7825
Batch 180, Loss: 0.7613
Batch 190, Loss: 0.7384
Batch 200, Loss: 0.7134
Batch 210, Loss: 0.7804
Batch 220, Loss: 0.7805
Batch 230, Loss: 0.7536
Batch 240, Loss: 0.7449
Batch 250, Loss: 0.7434
Batch 260, Loss: 0.6962
Batch 270, Loss: 0.7662
Batch 280, Loss: 0.7838
Batch 290, Loss: 0.7915
Batch 300, Loss: 0.8029
Batch 310, Loss: 0.7863
Batch 320, Loss: 0.8331
Batch 330, Loss: 0.9143
Batch 340, Loss: 0.8355
Batch 350, Loss: 0.8350
Batch 360, Loss: 0.8407
Batch 370, Loss: 0.8437
Batch 380, Loss: 0.8210
Batch 390, Loss: 0.7454
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.183547496795654 seconds
Epoch 73 accuracy: 63.78%
Batch 10, Loss: 0.6785
Batch 20, Loss: 0.6789
Batch 30, Loss: 0.6395
Batch 40, Loss: 0.6622
Batch 50, Loss: 0.6842
Batch 60, Loss: 0.7017
Batch 70, Loss: 0.6899
Batch 80, Loss: 0.6982
Batch 90, Loss: 0.6892
Batch 100, Loss: 0.7207
Batch 110, Loss: 0.7307
Batch 120, Loss: 0.7519
Batch 130, Loss: 0.7122
Batch 140, Loss: 0.7037
Batch 150, Loss: 0.7379
Batch 160, Loss: 0.7384
Batch 170, Loss: 0.7255
Batch 180, Loss: 0.7222
Batch 190, Loss: 0.7293
Batch 200, Loss: 0.7870
Batch 210, Loss: 0.7662
Batch 220, Loss: 0.7654
Batch 230, Loss: 0.7609
Batch 240, Loss: 0.7320
Batch 250, Loss: 0.7712
Batch 260, Loss: 0.8449
Batch 270, Loss: 0.7911
Batch 280, Loss: 0.8316
Batch 290, Loss: 0.7835
Batch 300, Loss: 0.7936
Batch 310, Loss: 0.7819
Batch 320, Loss: 0.7669
Batch 330, Loss: 0.7734
Batch 340, Loss: 0.7792
Batch 350, Loss: 0.7676
Batch 360, Loss: 0.8363
Batch 370, Loss: 0.8054
Batch 380, Loss: 0.7878
Batch 390, Loss: 0.8038
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.09408402442932 seconds
Epoch 74 accuracy: 59.52%
Batch 10, Loss: 0.6495
Batch 20, Loss: 0.6553
Batch 30, Loss: 0.6704
Batch 40, Loss: 0.6582
Batch 50, Loss: 0.6808
Batch 60, Loss: 0.7133
Batch 70, Loss: 0.7202
Batch 80, Loss: 0.7057
Batch 90, Loss: 0.6991
Batch 100, Loss: 0.7570
Batch 110, Loss: 0.6914
Batch 120, Loss: 0.7011
Batch 130, Loss: 0.7564
Batch 140, Loss: 0.7201
Batch 150, Loss: 0.7482
Batch 160, Loss: 0.7366
Batch 170, Loss: 0.7291
Batch 180, Loss: 0.7051
Batch 190, Loss: 0.7753
Batch 200, Loss: 0.7746
Batch 210, Loss: 0.7429
Batch 220, Loss: 0.7436
Batch 230, Loss: 0.6932
Batch 240, Loss: 0.7604
Batch 250, Loss: 0.7875
Batch 260, Loss: 0.7591
Batch 270, Loss: 0.7608
Batch 280, Loss: 0.7752
Batch 290, Loss: 0.7520
Batch 300, Loss: 0.7440
Batch 310, Loss: 0.7961
Batch 320, Loss: 0.7274
Batch 330, Loss: 0.7306
Batch 340, Loss: 0.7788
Batch 350, Loss: 0.8177
Batch 360, Loss: 0.6936
Batch 370, Loss: 0.7907
Batch 380, Loss: 0.7639
Batch 390, Loss: 0.8002
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.371741771697998 seconds
Epoch 75 accuracy: 60.38%
Batch 10, Loss: 0.7139
Batch 20, Loss: 0.6767
Batch 30, Loss: 0.6426
Batch 40, Loss: 0.7183
Batch 50, Loss: 0.6389
Batch 60, Loss: 0.7088
Batch 70, Loss: 0.6606
Batch 80, Loss: 0.6806
Batch 90, Loss: 0.6805
Batch 100, Loss: 0.6870
Batch 110, Loss: 0.7138
Batch 120, Loss: 0.7054
Batch 130, Loss: 0.6759
Batch 140, Loss: 0.7329
Batch 150, Loss: 0.7212
Batch 160, Loss: 0.7550
Batch 170, Loss: 0.7307
Batch 180, Loss: 0.7282
Batch 190, Loss: 0.6769
Batch 200, Loss: 0.7128
Batch 210, Loss: 0.7183
Batch 220, Loss: 0.7289
Batch 230, Loss: 0.7599
Batch 240, Loss: 0.7571
Batch 250, Loss: 0.7943
Batch 260, Loss: 0.8144
Batch 270, Loss: 0.7673
Batch 280, Loss: 0.7401
Batch 290, Loss: 0.7859
Batch 300, Loss: 0.7692
Batch 310, Loss: 0.8105
Batch 320, Loss: 0.7784
Batch 330, Loss: 0.7573
Batch 340, Loss: 0.7953
Batch 350, Loss: 0.8010
Batch 360, Loss: 0.7851
Batch 370, Loss: 0.7617
Batch 380, Loss: 0.7639
Batch 390, Loss: 0.7802
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.06827712059021 seconds
Epoch 76 accuracy: 65.16%
Batch 10, Loss: 0.6990
Batch 20, Loss: 0.6717
Batch 30, Loss: 0.6713
Batch 40, Loss: 0.6385
Batch 50, Loss: 0.6717
Batch 60, Loss: 0.6691
Batch 70, Loss: 0.6324
Batch 80, Loss: 0.6634
Batch 90, Loss: 0.7109
Batch 100, Loss: 0.7049
Batch 110, Loss: 0.7041
Batch 120, Loss: 0.6761
Batch 130, Loss: 0.6781
Batch 140, Loss: 0.7593
Batch 150, Loss: 0.6973
Batch 160, Loss: 0.7101
Batch 170, Loss: 0.7499
Batch 180, Loss: 0.7230
Batch 190, Loss: 0.7321
Batch 200, Loss: 0.7392
Batch 210, Loss: 0.7503
Batch 220, Loss: 0.6842
Batch 230, Loss: 0.7319
Batch 240, Loss: 0.7230
Batch 250, Loss: 0.7385
Batch 260, Loss: 0.7390
Batch 270, Loss: 0.7516
Batch 280, Loss: 0.7701
Batch 290, Loss: 0.7937
Batch 300, Loss: 0.7393
Batch 310, Loss: 0.7483
Batch 320, Loss: 0.7671
Batch 330, Loss: 0.7257
Batch 340, Loss: 0.7860
Batch 350, Loss: 0.7648
Batch 360, Loss: 0.7770
Batch 370, Loss: 0.7636
Batch 380, Loss: 0.8157
Batch 390, Loss: 0.8323
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.101524591445923 seconds
Epoch 77 accuracy: 61.76%
Batch 10, Loss: 0.7010
Batch 20, Loss: 0.6736
Batch 30, Loss: 0.6515
Batch 40, Loss: 0.6557
Batch 50, Loss: 0.6616
Batch 60, Loss: 0.6678
Batch 70, Loss: 0.7080
Batch 80, Loss: 0.6780
Batch 90, Loss: 0.6792
Batch 100, Loss: 0.7042
Batch 110, Loss: 0.6983
Batch 120, Loss: 0.6606
Batch 130, Loss: 0.6937
Batch 140, Loss: 0.7326
Batch 150, Loss: 0.6511
Batch 160, Loss: 0.7066
Batch 170, Loss: 0.7436
Batch 180, Loss: 0.6941
Batch 190, Loss: 0.7444
Batch 200, Loss: 0.7257
Batch 210, Loss: 0.7467
Batch 220, Loss: 0.6970
Batch 230, Loss: 0.7335
Batch 240, Loss: 0.7414
Batch 250, Loss: 0.7591
Batch 260, Loss: 0.8036
Batch 270, Loss: 0.7502
Batch 280, Loss: 0.7676
Batch 290, Loss: 0.7878
Batch 300, Loss: 0.7684
Batch 310, Loss: 0.7400
Batch 320, Loss: 0.7558
Batch 330, Loss: 0.7811
Batch 340, Loss: 0.7994
Batch 350, Loss: 0.8265
Batch 360, Loss: 0.7685
Batch 370, Loss: 0.7324
Batch 380, Loss: 0.7199
Batch 390, Loss: 0.7832
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.145284414291382 seconds
Epoch 78 accuracy: 63.08%
Batch 10, Loss: 0.6514
Batch 20, Loss: 0.6271
Batch 30, Loss: 0.6531
Batch 40, Loss: 0.6447
Batch 50, Loss: 0.6248
Batch 60, Loss: 0.6590
Batch 70, Loss: 0.6363
Batch 80, Loss: 0.6476
Batch 90, Loss: 0.6608
Batch 100, Loss: 0.6646
Batch 110, Loss: 0.7172
Batch 120, Loss: 0.6732
Batch 130, Loss: 0.6729
Batch 140, Loss: 0.7123
Batch 150, Loss: 0.7091
Batch 160, Loss: 0.7102
Batch 170, Loss: 0.7003
Batch 180, Loss: 0.7060
Batch 190, Loss: 0.7189
Batch 200, Loss: 0.7431
Batch 210, Loss: 0.7367
Batch 220, Loss: 0.7324
Batch 230, Loss: 0.7103
Batch 240, Loss: 0.7289
Batch 250, Loss: 0.7065
Batch 260, Loss: 0.7301
Batch 270, Loss: 0.7634
Batch 280, Loss: 0.7386
Batch 290, Loss: 0.7512
Batch 300, Loss: 0.7237
Batch 310, Loss: 0.7974
Batch 320, Loss: 0.7502
Batch 330, Loss: 0.7337
Batch 340, Loss: 0.8045
Batch 350, Loss: 0.8182
Batch 360, Loss: 0.7316
Batch 370, Loss: 0.7925
Batch 380, Loss: 0.7720
Batch 390, Loss: 0.7502
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.06169080734253 seconds
Epoch 79 accuracy: 62.86%
Batch 10, Loss: 0.6525
Batch 20, Loss: 0.6982
Batch 30, Loss: 0.6421
Batch 40, Loss: 0.6266
Batch 50, Loss: 0.6343
Batch 60, Loss: 0.6154
Batch 70, Loss: 0.6650
Batch 80, Loss: 0.6630
Batch 90, Loss: 0.6709
Batch 100, Loss: 0.6721
Batch 110, Loss: 0.7220
Batch 120, Loss: 0.6573
Batch 130, Loss: 0.6790
Batch 140, Loss: 0.6831
Batch 150, Loss: 0.7155
Batch 160, Loss: 0.7055
Batch 170, Loss: 0.6863
Batch 180, Loss: 0.7265
Batch 190, Loss: 0.6848
Batch 200, Loss: 0.7177
Batch 210, Loss: 0.7560
Batch 220, Loss: 0.7105
Batch 230, Loss: 0.7172
Batch 240, Loss: 0.7317
Batch 250, Loss: 0.7110
Batch 260, Loss: 0.7617
Batch 270, Loss: 0.7635
Batch 280, Loss: 0.7246
Batch 290, Loss: 0.7354
Batch 300, Loss: 0.6925
Batch 310, Loss: 0.7354
Batch 320, Loss: 0.7411
Batch 330, Loss: 0.7670
Batch 340, Loss: 0.7582
Batch 350, Loss: 0.7574
Batch 360, Loss: 0.7975
Batch 370, Loss: 0.7485
Batch 380, Loss: 0.7757
Batch 390, Loss: 0.8131
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.166951656341553 seconds
Epoch 80 accuracy: 63.02%
Batch 10, Loss: 0.6839
Batch 20, Loss: 0.6726
Batch 30, Loss: 0.6411
Batch 40, Loss: 0.6365
Batch 50, Loss: 0.6279
Batch 60, Loss: 0.6168
Batch 70, Loss: 0.6480
Batch 80, Loss: 0.6279
Batch 90, Loss: 0.6358
Batch 100, Loss: 0.6215
Batch 110, Loss: 0.6580
Batch 120, Loss: 0.6356
Batch 130, Loss: 0.6399
Batch 140, Loss: 0.6907
Batch 150, Loss: 0.6916
Batch 160, Loss: 0.6835
Batch 170, Loss: 0.7223
Batch 180, Loss: 0.6979
Batch 190, Loss: 0.7379
Batch 200, Loss: 0.6901
Batch 210, Loss: 0.6686
Batch 220, Loss: 0.6793
Batch 230, Loss: 0.7301
Batch 240, Loss: 0.7137
Batch 250, Loss: 0.7452
Batch 260, Loss: 0.7555
Batch 270, Loss: 0.7449
Batch 280, Loss: 0.7181
Batch 290, Loss: 0.7056
Batch 300, Loss: 0.7224
Batch 310, Loss: 0.7676
Batch 320, Loss: 0.7488
Batch 330, Loss: 0.7614
Batch 340, Loss: 0.7920
Batch 350, Loss: 0.7994
Batch 360, Loss: 0.7559
Batch 370, Loss: 0.7536
Batch 380, Loss: 0.7796
Batch 390, Loss: 0.7511
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.156676769256592 seconds
Epoch 81 accuracy: 61.93%
Batch 10, Loss: 0.7073
Batch 20, Loss: 0.6100
Batch 30, Loss: 0.6525
Batch 40, Loss: 0.6202
Batch 50, Loss: 0.6449
Batch 60, Loss: 0.6428
Batch 70, Loss: 0.6401
Batch 80, Loss: 0.6298
Batch 90, Loss: 0.6607
Batch 100, Loss: 0.6487
Batch 110, Loss: 0.6219
Batch 120, Loss: 0.6752
Batch 130, Loss: 0.7009
Batch 140, Loss: 0.6935
Batch 150, Loss: 0.6520
Batch 160, Loss: 0.6736
Batch 170, Loss: 0.6793
Batch 180, Loss: 0.6828
Batch 190, Loss: 0.6844
Batch 200, Loss: 0.6859
Batch 210, Loss: 0.7278
Batch 220, Loss: 0.6971
Batch 230, Loss: 0.7154
Batch 240, Loss: 0.7036
Batch 250, Loss: 0.7355
Batch 260, Loss: 0.7205
Batch 270, Loss: 0.7129
Batch 280, Loss: 0.7466
Batch 290, Loss: 0.7206
Batch 300, Loss: 0.7424
Batch 310, Loss: 0.7580
Batch 320, Loss: 0.7858
Batch 330, Loss: 0.7256
Batch 340, Loss: 0.7170
Batch 350, Loss: 0.7409
Batch 360, Loss: 0.7478
Batch 370, Loss: 0.7415
Batch 380, Loss: 0.7547
Batch 390, Loss: 0.7029
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.124950647354126 seconds
Epoch 82 accuracy: 66.49%
Batch 10, Loss: 0.6455
Batch 20, Loss: 0.5749
Batch 30, Loss: 0.5738
Batch 40, Loss: 0.5958
Batch 50, Loss: 0.6210
Batch 60, Loss: 0.6621
Batch 70, Loss: 0.6376
Batch 80, Loss: 0.6280
Batch 90, Loss: 0.6251
Batch 100, Loss: 0.6189
Batch 110, Loss: 0.6234
Batch 120, Loss: 0.6769
Batch 130, Loss: 0.6039
Batch 140, Loss: 0.6775
Batch 150, Loss: 0.6723
Batch 160, Loss: 0.7082
Batch 170, Loss: 0.6887
Batch 180, Loss: 0.6898
Batch 190, Loss: 0.6932
Batch 200, Loss: 0.6905
Batch 210, Loss: 0.7198
Batch 220, Loss: 0.7230
Batch 230, Loss: 0.7127
Batch 240, Loss: 0.6982
Batch 250, Loss: 0.7685
Batch 260, Loss: 0.7538
Batch 270, Loss: 0.7607
Batch 280, Loss: 0.7298
Batch 290, Loss: 0.7193
Batch 300, Loss: 0.6944
Batch 310, Loss: 0.7829
Batch 320, Loss: 0.7073
Batch 330, Loss: 0.7606
Batch 340, Loss: 0.7227
Batch 350, Loss: 0.7683
Batch 360, Loss: 0.7724
Batch 370, Loss: 0.7380
Batch 380, Loss: 0.7294
Batch 390, Loss: 0.7386
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.148897409439087 seconds
Epoch 83 accuracy: 65.37%
Batch 10, Loss: 0.5966
Batch 20, Loss: 0.6171
Batch 30, Loss: 0.5979
Batch 40, Loss: 0.5775
Batch 50, Loss: 0.6030
Batch 60, Loss: 0.6108
Batch 70, Loss: 0.6185
Batch 80, Loss: 0.6449
Batch 90, Loss: 0.6346
Batch 100, Loss: 0.6182
Batch 110, Loss: 0.6597
Batch 120, Loss: 0.6598
Batch 130, Loss: 0.6240
Batch 140, Loss: 0.6744
Batch 150, Loss: 0.6510
Batch 160, Loss: 0.6180
Batch 170, Loss: 0.6415
Batch 180, Loss: 0.6646
Batch 190, Loss: 0.7161
Batch 200, Loss: 0.6830
Batch 210, Loss: 0.7217
Batch 220, Loss: 0.7120
Batch 230, Loss: 0.6936
Batch 240, Loss: 0.6805
Batch 250, Loss: 0.7015
Batch 260, Loss: 0.7366
Batch 270, Loss: 0.6924
Batch 280, Loss: 0.6928
Batch 290, Loss: 0.7015
Batch 300, Loss: 0.7174
Batch 310, Loss: 0.6949
Batch 320, Loss: 0.7565
Batch 330, Loss: 0.6961
Batch 340, Loss: 0.7763
Batch 350, Loss: 0.7267
Batch 360, Loss: 0.7021
Batch 370, Loss: 0.7324
Batch 380, Loss: 0.7179
Batch 390, Loss: 0.7462
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.05873441696167 seconds
Epoch 84 accuracy: 63.64%
Batch 10, Loss: 0.6149
Batch 20, Loss: 0.6303
Batch 30, Loss: 0.6207
Batch 40, Loss: 0.5969
Batch 50, Loss: 0.6352
Batch 60, Loss: 0.6413
Batch 70, Loss: 0.6014
Batch 80, Loss: 0.5952
Batch 90, Loss: 0.6621
Batch 100, Loss: 0.5671
Batch 110, Loss: 0.6092
Batch 120, Loss: 0.6031
Batch 130, Loss: 0.6373
Batch 140, Loss: 0.6791
Batch 150, Loss: 0.6593
Batch 160, Loss: 0.6826
Batch 170, Loss: 0.6823
Batch 180, Loss: 0.6765
Batch 190, Loss: 0.6656
Batch 200, Loss: 0.6582
Batch 210, Loss: 0.6990
Batch 220, Loss: 0.7172
Batch 230, Loss: 0.6777
Batch 240, Loss: 0.6710
Batch 250, Loss: 0.6864
Batch 260, Loss: 0.6929
Batch 270, Loss: 0.7020
Batch 280, Loss: 0.6923
Batch 290, Loss: 0.7348
Batch 300, Loss: 0.6954
Batch 310, Loss: 0.7116
Batch 320, Loss: 0.7094
Batch 330, Loss: 0.7373
Batch 340, Loss: 0.7509
Batch 350, Loss: 0.7017
Batch 360, Loss: 0.7298
Batch 370, Loss: 0.7162
Batch 380, Loss: 0.7494
Batch 390, Loss: 0.7321
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.13819718360901 seconds
Epoch 85 accuracy: 63.41%
Batch 10, Loss: 0.6413
Batch 20, Loss: 0.5713
Batch 30, Loss: 0.5813
Batch 40, Loss: 0.6306
Batch 50, Loss: 0.5717
Batch 60, Loss: 0.6131
Batch 70, Loss: 0.6295
Batch 80, Loss: 0.6185
Batch 90, Loss: 0.6258
Batch 100, Loss: 0.6729
Batch 110, Loss: 0.5779
Batch 120, Loss: 0.6389
Batch 130, Loss: 0.6358
Batch 140, Loss: 0.6371
Batch 150, Loss: 0.6646
Batch 160, Loss: 0.6251
Batch 170, Loss: 0.6325
Batch 180, Loss: 0.6263
Batch 190, Loss: 0.6500
Batch 200, Loss: 0.6812
Batch 210, Loss: 0.6777
Batch 220, Loss: 0.6623
Batch 230, Loss: 0.6337
Batch 240, Loss: 0.6914
Batch 250, Loss: 0.6756
Batch 260, Loss: 0.6973
Batch 270, Loss: 0.7079
Batch 280, Loss: 0.6610
Batch 290, Loss: 0.7206
Batch 300, Loss: 0.7246
Batch 310, Loss: 0.7337
Batch 320, Loss: 0.7700
Batch 330, Loss: 0.7009
Batch 340, Loss: 0.7038
Batch 350, Loss: 0.7414
Batch 360, Loss: 0.7247
Batch 370, Loss: 0.6815
Batch 380, Loss: 0.7329
Batch 390, Loss: 0.7207
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.127061367034912 seconds
Epoch 86 accuracy: 64.57%
Batch 10, Loss: 0.6002
Batch 20, Loss: 0.5682
Batch 30, Loss: 0.5952
Batch 40, Loss: 0.6453
Batch 50, Loss: 0.5888
Batch 60, Loss: 0.5974
Batch 70, Loss: 0.6268
Batch 80, Loss: 0.6146
Batch 90, Loss: 0.6694
Batch 100, Loss: 0.6380
Batch 110, Loss: 0.6357
Batch 120, Loss: 0.6318
Batch 130, Loss: 0.6281
Batch 140, Loss: 0.6739
Batch 150, Loss: 0.6504
Batch 160, Loss: 0.6284
Batch 170, Loss: 0.6526
Batch 180, Loss: 0.6268
Batch 190, Loss: 0.6553
Batch 200, Loss: 0.6427
Batch 210, Loss: 0.6767
Batch 220, Loss: 0.6774
Batch 230, Loss: 0.6886
Batch 240, Loss: 0.6370
Batch 250, Loss: 0.6816
Batch 260, Loss: 0.6875
Batch 270, Loss: 0.6960
Batch 280, Loss: 0.6761
Batch 290, Loss: 0.6999
Batch 300, Loss: 0.6320
Batch 310, Loss: 0.7102
Batch 320, Loss: 0.7372
Batch 330, Loss: 0.7318
Batch 340, Loss: 0.7475
Batch 350, Loss: 0.7460
Batch 360, Loss: 0.7075
Batch 370, Loss: 0.7139
Batch 380, Loss: 0.6999
Batch 390, Loss: 0.7445
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.20031237602234 seconds
Epoch 87 accuracy: 64.89%
Batch 10, Loss: 0.6072
Batch 20, Loss: 0.6852
Batch 30, Loss: 0.5960
Batch 40, Loss: 0.6110
Batch 50, Loss: 0.5985
Batch 60, Loss: 0.6218
Batch 70, Loss: 0.5952
Batch 80, Loss: 0.6097
Batch 90, Loss: 0.6238
Batch 100, Loss: 0.6279
Batch 110, Loss: 0.5897
Batch 120, Loss: 0.6135
Batch 130, Loss: 0.5925
Batch 140, Loss: 0.6073
Batch 150, Loss: 0.6488
Batch 160, Loss: 0.6412
Batch 170, Loss: 0.6789
Batch 180, Loss: 0.6758
Batch 190, Loss: 0.6305
Batch 200, Loss: 0.6562
Batch 210, Loss: 0.7033
Batch 220, Loss: 0.6498
Batch 230, Loss: 0.6729
Batch 240, Loss: 0.6502
Batch 250, Loss: 0.6627
Batch 260, Loss: 0.6839
Batch 270, Loss: 0.6900
Batch 280, Loss: 0.6668
Batch 290, Loss: 0.7126
Batch 300, Loss: 0.6593
Batch 310, Loss: 0.6840
Batch 320, Loss: 0.6835
Batch 330, Loss: 0.7080
Batch 340, Loss: 0.6705
Batch 350, Loss: 0.7164
Batch 360, Loss: 0.7035
Batch 370, Loss: 0.6616
Batch 380, Loss: 0.7360
Batch 390, Loss: 0.7591
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.118313550949097 seconds
Epoch 88 accuracy: 63.09%
Batch 10, Loss: 0.6389
Batch 20, Loss: 0.6097
Batch 30, Loss: 0.5861
Batch 40, Loss: 0.5984
Batch 50, Loss: 0.5899
Batch 60, Loss: 0.5740
Batch 70, Loss: 0.6157
Batch 80, Loss: 0.6319
Batch 90, Loss: 0.5902
Batch 100, Loss: 0.6290
Batch 110, Loss: 0.5862
Batch 120, Loss: 0.6588
Batch 130, Loss: 0.6306
Batch 140, Loss: 0.6210
Batch 150, Loss: 0.6093
Batch 160, Loss: 0.6115
Batch 170, Loss: 0.6710
Batch 180, Loss: 0.6247
Batch 190, Loss: 0.6566
Batch 200, Loss: 0.6168
Batch 210, Loss: 0.6578
Batch 220, Loss: 0.6363
Batch 230, Loss: 0.6412
Batch 240, Loss: 0.6555
Batch 250, Loss: 0.6757
Batch 260, Loss: 0.6258
Batch 270, Loss: 0.6717
Batch 280, Loss: 0.6385
Batch 290, Loss: 0.7116
Batch 300, Loss: 0.7429
Batch 310, Loss: 0.6763
Batch 320, Loss: 0.6893
Batch 330, Loss: 0.6432
Batch 340, Loss: 0.7209
Batch 350, Loss: 0.7011
Batch 360, Loss: 0.7246
Batch 370, Loss: 0.6841
Batch 380, Loss: 0.6762
Batch 390, Loss: 0.6965
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.057894706726074 seconds
Epoch 89 accuracy: 64.43%
Batch 10, Loss: 0.5611
Batch 20, Loss: 0.6001
Batch 30, Loss: 0.5673
Batch 40, Loss: 0.5466
Batch 50, Loss: 0.5584
Batch 60, Loss: 0.5690
Batch 70, Loss: 0.5805
Batch 80, Loss: 0.5895
Batch 90, Loss: 0.5714
Batch 100, Loss: 0.6027
Batch 110, Loss: 0.6241
Batch 120, Loss: 0.6116
Batch 130, Loss: 0.5966
Batch 140, Loss: 0.6346
Batch 150, Loss: 0.5935
Batch 160, Loss: 0.6451
Batch 170, Loss: 0.6002
Batch 180, Loss: 0.6369
Batch 190, Loss: 0.6500
Batch 200, Loss: 0.6199
Batch 210, Loss: 0.5896
Batch 220, Loss: 0.6954
Batch 230, Loss: 0.6579
Batch 240, Loss: 0.6216
Batch 250, Loss: 0.6861
Batch 260, Loss: 0.6247
Batch 270, Loss: 0.6549
Batch 280, Loss: 0.6914
Batch 290, Loss: 0.6697
Batch 300, Loss: 0.6789
Batch 310, Loss: 0.7034
Batch 320, Loss: 0.6727
Batch 330, Loss: 0.6765
Batch 340, Loss: 0.6431
Batch 350, Loss: 0.7043
Batch 360, Loss: 0.7031
Batch 370, Loss: 0.6884
Batch 380, Loss: 0.7373
Batch 390, Loss: 0.6272
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.133172512054443 seconds
Epoch 90 accuracy: 62.43%
Batch 10, Loss: 0.5926
Batch 20, Loss: 0.5688
Batch 30, Loss: 0.6153
Batch 40, Loss: 0.5676
Batch 50, Loss: 0.5448
Batch 60, Loss: 0.5632
Batch 70, Loss: 0.5161
Batch 80, Loss: 0.5324
Batch 90, Loss: 0.5268
Batch 100, Loss: 0.6126
Batch 110, Loss: 0.6030
Batch 120, Loss: 0.6099
Batch 130, Loss: 0.5867
Batch 140, Loss: 0.6326
Batch 150, Loss: 0.5789
Batch 160, Loss: 0.5906
Batch 170, Loss: 0.6110
Batch 180, Loss: 0.6385
Batch 190, Loss: 0.6202
Batch 200, Loss: 0.6498
Batch 210, Loss: 0.6530
Batch 220, Loss: 0.6796
Batch 230, Loss: 0.6364
Batch 240, Loss: 0.6519
Batch 250, Loss: 0.6259
Batch 260, Loss: 0.6663
Batch 270, Loss: 0.6549
Batch 280, Loss: 0.6808
Batch 290, Loss: 0.6794
Batch 300, Loss: 0.7285
Batch 310, Loss: 0.6733
Batch 320, Loss: 0.6893
Batch 330, Loss: 0.6849
Batch 340, Loss: 0.6612
Batch 350, Loss: 0.7225
Batch 360, Loss: 0.6909
Batch 370, Loss: 0.7081
Batch 380, Loss: 0.7467
Batch 390, Loss: 0.6929
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.20749592781067 seconds
Epoch 91 accuracy: 64.54%
Batch 10, Loss: 0.5703
Batch 20, Loss: 0.5607
Batch 30, Loss: 0.5849
Batch 40, Loss: 0.5002
Batch 50, Loss: 0.5654
Batch 60, Loss: 0.5462
Batch 70, Loss: 0.5726
Batch 80, Loss: 0.5297
Batch 90, Loss: 0.5455
Batch 100, Loss: 0.5842
Batch 110, Loss: 0.5655
Batch 120, Loss: 0.5988
Batch 130, Loss: 0.5868
Batch 140, Loss: 0.5854
Batch 150, Loss: 0.5710
Batch 160, Loss: 0.5939
Batch 170, Loss: 0.6455
Batch 180, Loss: 0.6390
Batch 190, Loss: 0.5740
Batch 200, Loss: 0.5992
Batch 210, Loss: 0.6263
Batch 220, Loss: 0.5745
Batch 230, Loss: 0.6309
Batch 240, Loss: 0.6236
Batch 250, Loss: 0.6560
Batch 260, Loss: 0.6435
Batch 270, Loss: 0.6535
Batch 280, Loss: 0.6683
Batch 290, Loss: 0.6646
Batch 300, Loss: 0.6040
Batch 310, Loss: 0.6253
Batch 320, Loss: 0.6775
Batch 330, Loss: 0.6438
Batch 340, Loss: 0.7166
Batch 350, Loss: 0.6194
Batch 360, Loss: 0.6981
Batch 370, Loss: 0.7188
Batch 380, Loss: 0.6618
Batch 390, Loss: 0.7040
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.10241436958313 seconds
Epoch 92 accuracy: 65.94%
Batch 10, Loss: 0.5654
Batch 20, Loss: 0.5204
Batch 30, Loss: 0.5627
Batch 40, Loss: 0.5289
Batch 50, Loss: 0.5684
Batch 60, Loss: 0.5475
Batch 70, Loss: 0.5367
Batch 80, Loss: 0.5187
Batch 90, Loss: 0.5213
Batch 100, Loss: 0.5551
Batch 110, Loss: 0.5448
Batch 120, Loss: 0.5713
Batch 130, Loss: 0.6111
Batch 140, Loss: 0.5823
Batch 150, Loss: 0.6151
Batch 160, Loss: 0.6537
Batch 170, Loss: 0.6518
Batch 180, Loss: 0.6166
Batch 190, Loss: 0.6306
Batch 200, Loss: 0.6017
Batch 210, Loss: 0.6692
Batch 220, Loss: 0.6402
Batch 230, Loss: 0.6291
Batch 240, Loss: 0.6188
Batch 250, Loss: 0.6345
Batch 260, Loss: 0.6421
Batch 270, Loss: 0.6669
Batch 280, Loss: 0.6266
Batch 290, Loss: 0.6319
Batch 300, Loss: 0.6279
Batch 310, Loss: 0.6610
Batch 320, Loss: 0.6432
Batch 330, Loss: 0.6728
Batch 340, Loss: 0.6531
Batch 350, Loss: 0.6448
Batch 360, Loss: 0.6598
Batch 370, Loss: 0.6163
Batch 380, Loss: 0.6589
Batch 390, Loss: 0.6663
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.1048743724823 seconds
Epoch 93 accuracy: 65.62%
Batch 10, Loss: 0.5732
Batch 20, Loss: 0.5348
Batch 30, Loss: 0.5171
Batch 40, Loss: 0.5296
Batch 50, Loss: 0.5048
Batch 60, Loss: 0.5388
Batch 70, Loss: 0.5392
Batch 80, Loss: 0.5638
Batch 90, Loss: 0.5772
Batch 100, Loss: 0.5495
Batch 110, Loss: 0.5553
Batch 120, Loss: 0.5535
Batch 130, Loss: 0.5779
Batch 140, Loss: 0.5551
Batch 150, Loss: 0.5786
Batch 160, Loss: 0.5736
Batch 170, Loss: 0.5499
Batch 180, Loss: 0.6050
Batch 190, Loss: 0.6358
Batch 200, Loss: 0.5958
Batch 210, Loss: 0.6382
Batch 220, Loss: 0.6638
Batch 230, Loss: 0.6668
Batch 240, Loss: 0.6555
Batch 250, Loss: 0.6087
Batch 260, Loss: 0.6174
Batch 270, Loss: 0.6616
Batch 280, Loss: 0.6296
Batch 290, Loss: 0.6046
Batch 300, Loss: 0.6039
Batch 310, Loss: 0.6201
Batch 320, Loss: 0.6339
Batch 330, Loss: 0.6230
Batch 340, Loss: 0.6795
Batch 350, Loss: 0.6335
Batch 360, Loss: 0.6376
Batch 370, Loss: 0.6641
Batch 380, Loss: 0.6892
Batch 390, Loss: 0.6933
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.08230948448181 seconds
Epoch 94 accuracy: 64.56%
Batch 10, Loss: 0.5663
Batch 20, Loss: 0.5363
Batch 30, Loss: 0.5144
Batch 40, Loss: 0.5185
Batch 50, Loss: 0.5247
Batch 60, Loss: 0.5063
Batch 70, Loss: 0.5401
Batch 80, Loss: 0.5465
Batch 90, Loss: 0.5299
Batch 100, Loss: 0.5473
Batch 110, Loss: 0.5263
Batch 120, Loss: 0.5265
Batch 130, Loss: 0.5435
Batch 140, Loss: 0.5915
Batch 150, Loss: 0.5619
Batch 160, Loss: 0.5755
Batch 170, Loss: 0.5518
Batch 180, Loss: 0.5522
Batch 190, Loss: 0.5680
Batch 200, Loss: 0.6142
Batch 210, Loss: 0.5758
Batch 220, Loss: 0.5865
Batch 230, Loss: 0.6035
Batch 240, Loss: 0.5916
Batch 250, Loss: 0.6040
Batch 260, Loss: 0.5914
Batch 270, Loss: 0.6490
Batch 280, Loss: 0.6253
Batch 290, Loss: 0.6333
Batch 300, Loss: 0.6790
Batch 310, Loss: 0.6089
Batch 320, Loss: 0.6418
Batch 330, Loss: 0.6452
Batch 340, Loss: 0.6435
Batch 350, Loss: 0.6623
Batch 360, Loss: 0.7084
Batch 370, Loss: 0.7020
Batch 380, Loss: 0.6703
Batch 390, Loss: 0.6669
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.154740571975708 seconds
Epoch 95 accuracy: 65.75%
Batch 10, Loss: 0.5805
Batch 20, Loss: 0.5602
Batch 30, Loss: 0.5416
Batch 40, Loss: 0.5151
Batch 50, Loss: 0.5189
Batch 60, Loss: 0.5735
Batch 70, Loss: 0.5182
Batch 80, Loss: 0.5319
Batch 90, Loss: 0.5380
Batch 100, Loss: 0.5416
Batch 110, Loss: 0.5531
Batch 120, Loss: 0.5392
Batch 130, Loss: 0.5322
Batch 140, Loss: 0.5716
Batch 150, Loss: 0.5484
Batch 160, Loss: 0.5576
Batch 170, Loss: 0.5582
Batch 180, Loss: 0.5630
Batch 190, Loss: 0.5858
Batch 200, Loss: 0.5497
Batch 210, Loss: 0.5770
Batch 220, Loss: 0.6305
Batch 230, Loss: 0.6144
Batch 240, Loss: 0.5925
Batch 250, Loss: 0.5787
Batch 260, Loss: 0.6543
Batch 270, Loss: 0.6308
Batch 280, Loss: 0.6140
Batch 290, Loss: 0.6225
Batch 300, Loss: 0.6407
Batch 310, Loss: 0.6317
Batch 320, Loss: 0.6469
Batch 330, Loss: 0.6023
Batch 340, Loss: 0.6235
Batch 350, Loss: 0.6327
Batch 360, Loss: 0.6252
Batch 370, Loss: 0.6447
Batch 380, Loss: 0.6349
Batch 390, Loss: 0.6545
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.151001930236816 seconds
Epoch 96 accuracy: 64.13%
Batch 10, Loss: 0.5560
Batch 20, Loss: 0.5134
Batch 30, Loss: 0.5232
Batch 40, Loss: 0.5536
Batch 50, Loss: 0.5252
Batch 60, Loss: 0.5458
Batch 70, Loss: 0.5361
Batch 80, Loss: 0.4844
Batch 90, Loss: 0.5234
Batch 100, Loss: 0.5158
Batch 110, Loss: 0.5367
Batch 120, Loss: 0.5239
Batch 130, Loss: 0.5633
Batch 140, Loss: 0.5486
Batch 150, Loss: 0.5461
Batch 160, Loss: 0.6034
Batch 170, Loss: 0.5532
Batch 180, Loss: 0.5934
Batch 190, Loss: 0.5982
Batch 200, Loss: 0.5773
Batch 210, Loss: 0.5453
Batch 220, Loss: 0.5819
Batch 230, Loss: 0.5976
Batch 240, Loss: 0.6141
Batch 250, Loss: 0.6088
Batch 260, Loss: 0.6036
Batch 270, Loss: 0.6877
Batch 280, Loss: 0.6767
Batch 290, Loss: 0.5686
Batch 300, Loss: 0.5714
Batch 310, Loss: 0.6122
Batch 320, Loss: 0.6227
Batch 330, Loss: 0.6561
Batch 340, Loss: 0.6615
Batch 350, Loss: 0.6272
Batch 360, Loss: 0.5964
Batch 370, Loss: 0.5790
Batch 380, Loss: 0.6457
Batch 390, Loss: 0.6567
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.228052616119385 seconds
Epoch 97 accuracy: 67.11%
Batch 10, Loss: 0.5471
Batch 20, Loss: 0.5004
Batch 30, Loss: 0.5403
Batch 40, Loss: 0.5237
Batch 50, Loss: 0.5180
Batch 60, Loss: 0.5305
Batch 70, Loss: 0.5364
Batch 80, Loss: 0.5391
Batch 90, Loss: 0.5683
Batch 100, Loss: 0.5410
Batch 110, Loss: 0.5045
Batch 120, Loss: 0.5136
Batch 130, Loss: 0.5285
Batch 140, Loss: 0.5400
Batch 150, Loss: 0.6025
Batch 160, Loss: 0.5490
Batch 170, Loss: 0.5667
Batch 180, Loss: 0.5533
Batch 190, Loss: 0.5670
Batch 200, Loss: 0.5917
Batch 210, Loss: 0.5601
Batch 220, Loss: 0.5956
Batch 230, Loss: 0.5349
Batch 240, Loss: 0.5808
Batch 250, Loss: 0.5829
Batch 260, Loss: 0.5730
Batch 270, Loss: 0.6220
Batch 280, Loss: 0.5993
Batch 290, Loss: 0.6192
Batch 300, Loss: 0.6028
Batch 310, Loss: 0.6150
Batch 320, Loss: 0.6282
Batch 330, Loss: 0.6297
Batch 340, Loss: 0.6278
Batch 350, Loss: 0.5942
Batch 360, Loss: 0.6288
Batch 370, Loss: 0.5951
Batch 380, Loss: 0.6103
Batch 390, Loss: 0.6015
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.159160614013672 seconds
Epoch 98 accuracy: 66.04%
Batch 10, Loss: 0.5045
Batch 20, Loss: 0.5337
Batch 30, Loss: 0.4987
Batch 40, Loss: 0.4921
Batch 50, Loss: 0.4414
Batch 60, Loss: 0.5112
Batch 70, Loss: 0.5045
Batch 80, Loss: 0.5112
Batch 90, Loss: 0.4876
Batch 100, Loss: 0.5250
Batch 110, Loss: 0.5367
Batch 120, Loss: 0.4909
Batch 130, Loss: 0.5247
Batch 140, Loss: 0.5443
Batch 150, Loss: 0.5445
Batch 160, Loss: 0.5228
Batch 170, Loss: 0.5270
Batch 180, Loss: 0.5533
Batch 190, Loss: 0.5210
Batch 200, Loss: 0.5378
Batch 210, Loss: 0.5542
Batch 220, Loss: 0.5588
Batch 230, Loss: 0.5605
Batch 240, Loss: 0.5756
Batch 250, Loss: 0.5965
Batch 260, Loss: 0.5757
Batch 270, Loss: 0.6194
Batch 280, Loss: 0.5822
Batch 290, Loss: 0.5788
Batch 300, Loss: 0.5479
Batch 310, Loss: 0.6169
Batch 320, Loss: 0.6005
Batch 330, Loss: 0.5897
Batch 340, Loss: 0.6336
Batch 350, Loss: 0.6581
Batch 360, Loss: 0.6035
Batch 370, Loss: 0.6079
Batch 380, Loss: 0.6000
Batch 390, Loss: 0.6101
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.130114793777466 seconds
Epoch 99 accuracy: 66.98%
Batch 10, Loss: 0.5031
Batch 20, Loss: 0.5205
Batch 30, Loss: 0.5191
Batch 40, Loss: 0.4848
Batch 50, Loss: 0.5091
Batch 60, Loss: 0.5056
Batch 70, Loss: 0.5087
Batch 80, Loss: 0.5229
Batch 90, Loss: 0.5157
Batch 100, Loss: 0.5246
Batch 110, Loss: 0.5628
Batch 120, Loss: 0.5411
Batch 130, Loss: 0.5362
Batch 140, Loss: 0.4972
Batch 150, Loss: 0.5209
Batch 160, Loss: 0.5403
Batch 170, Loss: 0.5880
Batch 180, Loss: 0.5287
Batch 190, Loss: 0.5728
Batch 200, Loss: 0.5517
Batch 210, Loss: 0.5373
Batch 220, Loss: 0.5745
Batch 230, Loss: 0.5246
Batch 240, Loss: 0.5646
Batch 250, Loss: 0.5258
Batch 260, Loss: 0.5844
Batch 270, Loss: 0.5685
Batch 280, Loss: 0.5788
Batch 290, Loss: 0.5877
Batch 300, Loss: 0.5737
Batch 310, Loss: 0.5829
Batch 320, Loss: 0.6498
Batch 330, Loss: 0.5818
Batch 340, Loss: 0.5814
Batch 350, Loss: 0.5775
Batch 360, Loss: 0.5734
Batch 370, Loss: 0.5925
Batch 380, Loss: 0.6502
Batch 390, Loss: 0.6298
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.040895700454712 seconds
Epoch 100 accuracy: 65.2%
Batch 10, Loss: 0.5171
Batch 20, Loss: 0.5098
Batch 30, Loss: 0.4787
Batch 40, Loss: 0.4808
Batch 50, Loss: 0.5158
Batch 60, Loss: 0.5016
Batch 70, Loss: 0.4945
Batch 80, Loss: 0.5343
Batch 90, Loss: 0.5186
Batch 100, Loss: 0.5169
Batch 110, Loss: 0.5012
Batch 120, Loss: 0.5209
Batch 130, Loss: 0.4875
Batch 140, Loss: 0.5107
Batch 150, Loss: 0.4965
Batch 160, Loss: 0.5778
Batch 170, Loss: 0.5455
Batch 180, Loss: 0.5612
Batch 190, Loss: 0.5387
Batch 200, Loss: 0.5758
Batch 210, Loss: 0.5953
Batch 220, Loss: 0.5587
Batch 230, Loss: 0.5324
Batch 240, Loss: 0.5747
Batch 250, Loss: 0.5817
Batch 260, Loss: 0.5859
Batch 270, Loss: 0.5973
Batch 280, Loss: 0.6156
Batch 290, Loss: 0.5788
Batch 300, Loss: 0.5671
Batch 310, Loss: 0.5664
Batch 320, Loss: 0.5538
Batch 330, Loss: 0.5593
Batch 340, Loss: 0.5841
Batch 350, Loss: 0.6033
Batch 360, Loss: 0.5923
Batch 370, Loss: 0.5623
Batch 380, Loss: 0.5529
Batch 390, Loss: 0.5593
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.11909580230713 seconds
Epoch 101 accuracy: 66.74%
Batch 10, Loss: 0.4827
Batch 20, Loss: 0.4940
Batch 30, Loss: 0.4941
Batch 40, Loss: 0.4621
Batch 50, Loss: 0.4635
Batch 60, Loss: 0.4792
Batch 70, Loss: 0.4918
Batch 80, Loss: 0.4723
Batch 90, Loss: 0.4592
Batch 100, Loss: 0.4744
Batch 110, Loss: 0.4967
Batch 120, Loss: 0.5503
Batch 130, Loss: 0.5299
Batch 140, Loss: 0.5178
Batch 150, Loss: 0.4807
Batch 160, Loss: 0.5378
Batch 170, Loss: 0.5501
Batch 180, Loss: 0.4927
Batch 190, Loss: 0.5417
Batch 200, Loss: 0.5607
Batch 210, Loss: 0.5324
Batch 220, Loss: 0.5745
Batch 230, Loss: 0.5412
Batch 240, Loss: 0.5580
Batch 250, Loss: 0.5275
Batch 260, Loss: 0.5836
Batch 270, Loss: 0.5518
Batch 280, Loss: 0.5655
Batch 290, Loss: 0.5771
Batch 300, Loss: 0.5470
Batch 310, Loss: 0.5696
Batch 320, Loss: 0.5709
Batch 330, Loss: 0.5719
Batch 340, Loss: 0.5479
Batch 350, Loss: 0.6086
Batch 360, Loss: 0.5737
Batch 370, Loss: 0.5721
Batch 380, Loss: 0.5603
Batch 390, Loss: 0.6161
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.095035076141357 seconds
Epoch 102 accuracy: 65.15%
Batch 10, Loss: 0.4759
Batch 20, Loss: 0.4888
Batch 30, Loss: 0.4902
Batch 40, Loss: 0.5066
Batch 50, Loss: 0.4694
Batch 60, Loss: 0.5082
Batch 70, Loss: 0.4898
Batch 80, Loss: 0.5063
Batch 90, Loss: 0.4666
Batch 100, Loss: 0.4774
Batch 110, Loss: 0.4802
Batch 120, Loss: 0.5016
Batch 130, Loss: 0.4669
Batch 140, Loss: 0.4631
Batch 150, Loss: 0.4950
Batch 160, Loss: 0.4906
Batch 170, Loss: 0.4686
Batch 180, Loss: 0.4864
Batch 190, Loss: 0.4953
Batch 200, Loss: 0.5408
Batch 210, Loss: 0.5260
Batch 220, Loss: 0.5152
Batch 230, Loss: 0.5003
Batch 240, Loss: 0.5113
Batch 250, Loss: 0.5485
Batch 260, Loss: 0.5617
Batch 270, Loss: 0.5549
Batch 280, Loss: 0.5611
Batch 290, Loss: 0.5508
Batch 300, Loss: 0.5674
Batch 310, Loss: 0.5441
Batch 320, Loss: 0.5409
Batch 330, Loss: 0.5710
Batch 340, Loss: 0.5480
Batch 350, Loss: 0.5500
Batch 360, Loss: 0.5712
Batch 370, Loss: 0.5825
Batch 380, Loss: 0.5885
Batch 390, Loss: 0.6164
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.14150595664978 seconds
Epoch 103 accuracy: 63.58%
Batch 10, Loss: 0.4782
Batch 20, Loss: 0.4529
Batch 30, Loss: 0.5129
Batch 40, Loss: 0.4862
Batch 50, Loss: 0.4835
Batch 60, Loss: 0.4820
Batch 70, Loss: 0.4691
Batch 80, Loss: 0.4599
Batch 90, Loss: 0.5109
Batch 100, Loss: 0.4714
Batch 110, Loss: 0.4753
Batch 120, Loss: 0.4765
Batch 130, Loss: 0.4605
Batch 140, Loss: 0.5066
Batch 150, Loss: 0.4686
Batch 160, Loss: 0.5138
Batch 170, Loss: 0.4998
Batch 180, Loss: 0.5209
Batch 190, Loss: 0.5113
Batch 200, Loss: 0.5009
Batch 210, Loss: 0.5037
Batch 220, Loss: 0.5190
Batch 230, Loss: 0.5267
Batch 240, Loss: 0.5882
Batch 250, Loss: 0.5513
Batch 260, Loss: 0.5515
Batch 270, Loss: 0.5216
Batch 280, Loss: 0.5856
Batch 290, Loss: 0.5423
Batch 300, Loss: 0.5746
Batch 310, Loss: 0.5605
Batch 320, Loss: 0.5861
Batch 330, Loss: 0.5391
Batch 340, Loss: 0.5868
Batch 350, Loss: 0.5720
Batch 360, Loss: 0.5887
Batch 370, Loss: 0.5347
Batch 380, Loss: 0.6259
Batch 390, Loss: 0.5604
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.156649351119995 seconds
Epoch 104 accuracy: 66.68%
Batch 10, Loss: 0.4927
Batch 20, Loss: 0.4458
Batch 30, Loss: 0.4773
Batch 40, Loss: 0.4597
Batch 50, Loss: 0.4264
Batch 60, Loss: 0.4538
Batch 70, Loss: 0.4397
Batch 80, Loss: 0.4959
Batch 90, Loss: 0.4539
Batch 100, Loss: 0.4795
Batch 110, Loss: 0.4760
Batch 120, Loss: 0.4731
Batch 130, Loss: 0.5064
Batch 140, Loss: 0.4900
Batch 150, Loss: 0.4834
Batch 160, Loss: 0.5188
Batch 170, Loss: 0.4761
Batch 180, Loss: 0.4842
Batch 190, Loss: 0.4967
Batch 200, Loss: 0.5255
Batch 210, Loss: 0.5643
Batch 220, Loss: 0.5540
Batch 230, Loss: 0.5256
Batch 240, Loss: 0.5479
Batch 250, Loss: 0.5787
Batch 260, Loss: 0.5674
Batch 270, Loss: 0.5580
Batch 280, Loss: 0.5481
Batch 290, Loss: 0.5458
Batch 300, Loss: 0.5392
Batch 310, Loss: 0.5451
Batch 320, Loss: 0.6068
Batch 330, Loss: 0.5317
Batch 340, Loss: 0.5660
Batch 350, Loss: 0.5657
Batch 360, Loss: 0.5459
Batch 370, Loss: 0.5394
Batch 380, Loss: 0.5469
Batch 390, Loss: 0.5961
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.115276098251343 seconds
Epoch 105 accuracy: 67.33%
Batch 10, Loss: 0.4711
Batch 20, Loss: 0.4543
Batch 30, Loss: 0.4152
Batch 40, Loss: 0.4528
Batch 50, Loss: 0.4439
Batch 60, Loss: 0.4260
Batch 70, Loss: 0.4558
Batch 80, Loss: 0.4783
Batch 90, Loss: 0.4294
Batch 100, Loss: 0.4429
Batch 110, Loss: 0.4513
Batch 120, Loss: 0.4867
Batch 130, Loss: 0.4539
Batch 140, Loss: 0.4835
Batch 150, Loss: 0.4644
Batch 160, Loss: 0.4648
Batch 170, Loss: 0.4843
Batch 180, Loss: 0.4957
Batch 190, Loss: 0.4628
Batch 200, Loss: 0.4746
Batch 210, Loss: 0.5124
Batch 220, Loss: 0.4609
Batch 230, Loss: 0.4869
Batch 240, Loss: 0.5558
Batch 250, Loss: 0.5173
Batch 260, Loss: 0.5044
Batch 270, Loss: 0.5005
Batch 280, Loss: 0.5329
Batch 290, Loss: 0.5439
Batch 300, Loss: 0.5198
Batch 310, Loss: 0.5180
Batch 320, Loss: 0.5215
Batch 330, Loss: 0.5342
Batch 340, Loss: 0.5801
Batch 350, Loss: 0.5781
Batch 360, Loss: 0.5383
Batch 370, Loss: 0.5712
Batch 380, Loss: 0.5752
Batch 390, Loss: 0.5796
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.185688734054565 seconds
Epoch 106 accuracy: 64.93%
Batch 10, Loss: 0.4753
Batch 20, Loss: 0.4753
Batch 30, Loss: 0.4710
Batch 40, Loss: 0.4745
Batch 50, Loss: 0.4478
Batch 60, Loss: 0.4413
Batch 70, Loss: 0.4538
Batch 80, Loss: 0.4368
Batch 90, Loss: 0.4583
Batch 100, Loss: 0.4822
Batch 110, Loss: 0.4565
Batch 120, Loss: 0.4752
Batch 130, Loss: 0.4990
Batch 140, Loss: 0.4818
Batch 150, Loss: 0.4806
Batch 160, Loss: 0.4867
Batch 170, Loss: 0.4945
Batch 180, Loss: 0.5373
Batch 190, Loss: 0.4815
Batch 200, Loss: 0.5326
Batch 210, Loss: 0.5291
Batch 220, Loss: 0.5386
Batch 230, Loss: 0.5625
Batch 240, Loss: 0.5180
Batch 250, Loss: 0.5253
Batch 260, Loss: 0.5692
Batch 270, Loss: 0.5427
Batch 280, Loss: 0.5172
Batch 290, Loss: 0.4946
Batch 300, Loss: 0.5241
Batch 310, Loss: 0.5129
Batch 320, Loss: 0.5196
Batch 330, Loss: 0.5015
Batch 340, Loss: 0.5497
Batch 350, Loss: 0.5260
Batch 360, Loss: 0.5605
Batch 370, Loss: 0.5034
Batch 380, Loss: 0.5309
Batch 390, Loss: 0.5773
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.14773988723755 seconds
Epoch 107 accuracy: 66.89%
Batch 10, Loss: 0.4428
Batch 20, Loss: 0.4378
Batch 30, Loss: 0.4503
Batch 40, Loss: 0.4476
Batch 50, Loss: 0.4205
Batch 60, Loss: 0.4039
Batch 70, Loss: 0.4209
Batch 80, Loss: 0.4285
Batch 90, Loss: 0.3981
Batch 100, Loss: 0.4292
Batch 110, Loss: 0.4395
Batch 120, Loss: 0.4193
Batch 130, Loss: 0.4185
Batch 140, Loss: 0.4257
Batch 150, Loss: 0.4327
Batch 160, Loss: 0.4546
Batch 170, Loss: 0.4330
Batch 180, Loss: 0.4996
Batch 190, Loss: 0.4793
Batch 200, Loss: 0.5059
Batch 210, Loss: 0.4968
Batch 220, Loss: 0.5351
Batch 230, Loss: 0.4749
Batch 240, Loss: 0.5123
Batch 250, Loss: 0.4622
Batch 260, Loss: 0.4913
Batch 270, Loss: 0.4931
Batch 280, Loss: 0.5161
Batch 290, Loss: 0.4962
Batch 300, Loss: 0.5199
Batch 310, Loss: 0.5215
Batch 320, Loss: 0.5065
Batch 330, Loss: 0.5397
Batch 340, Loss: 0.5007
Batch 350, Loss: 0.5213
Batch 360, Loss: 0.5132
Batch 370, Loss: 0.5391
Batch 380, Loss: 0.5198
Batch 390, Loss: 0.5183
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.18683123588562 seconds
Epoch 108 accuracy: 66.9%
Batch 10, Loss: 0.4430
Batch 20, Loss: 0.4296
Batch 30, Loss: 0.4318
Batch 40, Loss: 0.3834
Batch 50, Loss: 0.4307
Batch 60, Loss: 0.4762
Batch 70, Loss: 0.4308
Batch 80, Loss: 0.4673
Batch 90, Loss: 0.4095
Batch 100, Loss: 0.4425
Batch 110, Loss: 0.4272
Batch 120, Loss: 0.4319
Batch 130, Loss: 0.4513
Batch 140, Loss: 0.4417
Batch 150, Loss: 0.4626
Batch 160, Loss: 0.4361
Batch 170, Loss: 0.4582
Batch 180, Loss: 0.4600
Batch 190, Loss: 0.4929
Batch 200, Loss: 0.4853
Batch 210, Loss: 0.5006
Batch 220, Loss: 0.4862
Batch 230, Loss: 0.4951
Batch 240, Loss: 0.4976
Batch 250, Loss: 0.4464
Batch 260, Loss: 0.4689
Batch 270, Loss: 0.5022
Batch 280, Loss: 0.4949
Batch 290, Loss: 0.4996
Batch 300, Loss: 0.5275
Batch 310, Loss: 0.5372
Batch 320, Loss: 0.5120
Batch 330, Loss: 0.5513
Batch 340, Loss: 0.4945
Batch 350, Loss: 0.5504
Batch 360, Loss: 0.5252
Batch 370, Loss: 0.5303
Batch 380, Loss: 0.5517
Batch 390, Loss: 0.4854
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.11035943031311 seconds
Epoch 109 accuracy: 68.29%
Batch 10, Loss: 0.4298
Batch 20, Loss: 0.4552
Batch 30, Loss: 0.4177
Batch 40, Loss: 0.4108
Batch 50, Loss: 0.3930
Batch 60, Loss: 0.3976
Batch 70, Loss: 0.4040
Batch 80, Loss: 0.4254
Batch 90, Loss: 0.4217
Batch 100, Loss: 0.4406
Batch 110, Loss: 0.4444
Batch 120, Loss: 0.4508
Batch 130, Loss: 0.3756
Batch 140, Loss: 0.4141
Batch 150, Loss: 0.4541
Batch 160, Loss: 0.4629
Batch 170, Loss: 0.4396
Batch 180, Loss: 0.4612
Batch 190, Loss: 0.4801
Batch 200, Loss: 0.4899
Batch 210, Loss: 0.4777
Batch 220, Loss: 0.4762
Batch 230, Loss: 0.4967
Batch 240, Loss: 0.4724
Batch 250, Loss: 0.4675
Batch 260, Loss: 0.5143
Batch 270, Loss: 0.4729
Batch 280, Loss: 0.4691
Batch 290, Loss: 0.4641
Batch 300, Loss: 0.4809
Batch 310, Loss: 0.5324
Batch 320, Loss: 0.5263
Batch 330, Loss: 0.5066
Batch 340, Loss: 0.5541
Batch 350, Loss: 0.5274
Batch 360, Loss: 0.5348
Batch 370, Loss: 0.5219
Batch 380, Loss: 0.4954
Batch 390, Loss: 0.5182
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.10719084739685 seconds
Epoch 110 accuracy: 67.14%
Batch 10, Loss: 0.4447
Batch 20, Loss: 0.4310
Batch 30, Loss: 0.4280
Batch 40, Loss: 0.4629
Batch 50, Loss: 0.4394
Batch 60, Loss: 0.4439
Batch 70, Loss: 0.4341
Batch 80, Loss: 0.4623
Batch 90, Loss: 0.4618
Batch 100, Loss: 0.4489
Batch 110, Loss: 0.4155
Batch 120, Loss: 0.4112
Batch 130, Loss: 0.4165
Batch 140, Loss: 0.4297
Batch 150, Loss: 0.4222
Batch 160, Loss: 0.4475
Batch 170, Loss: 0.4212
Batch 180, Loss: 0.4450
Batch 190, Loss: 0.4493
Batch 200, Loss: 0.4514
Batch 210, Loss: 0.4600
Batch 220, Loss: 0.4128
Batch 230, Loss: 0.4492
Batch 240, Loss: 0.4598
Batch 250, Loss: 0.4950
Batch 260, Loss: 0.4230
Batch 270, Loss: 0.4148
Batch 280, Loss: 0.4549
Batch 290, Loss: 0.4871
Batch 300, Loss: 0.5246
Batch 310, Loss: 0.4907
Batch 320, Loss: 0.5088
Batch 330, Loss: 0.4925
Batch 340, Loss: 0.4771
Batch 350, Loss: 0.4887
Batch 360, Loss: 0.5208
Batch 370, Loss: 0.5104
Batch 380, Loss: 0.4967
Batch 390, Loss: 0.5278
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.16628074645996 seconds
Epoch 111 accuracy: 66.81%
Batch 10, Loss: 0.4313
Batch 20, Loss: 0.4211
Batch 30, Loss: 0.4488
Batch 40, Loss: 0.4114
Batch 50, Loss: 0.4313
Batch 60, Loss: 0.4218
Batch 70, Loss: 0.4249
Batch 80, Loss: 0.4024
Batch 90, Loss: 0.3951
Batch 100, Loss: 0.4021
Batch 110, Loss: 0.4343
Batch 120, Loss: 0.4594
Batch 130, Loss: 0.4198
Batch 140, Loss: 0.3971
Batch 150, Loss: 0.4118
Batch 160, Loss: 0.4276
Batch 170, Loss: 0.4120
Batch 180, Loss: 0.4129
Batch 190, Loss: 0.4531
Batch 200, Loss: 0.4049
Batch 210, Loss: 0.4886
Batch 220, Loss: 0.4468
Batch 230, Loss: 0.4578
Batch 240, Loss: 0.4569
Batch 250, Loss: 0.4675
Batch 260, Loss: 0.4113
Batch 270, Loss: 0.4331
Batch 280, Loss: 0.4814
Batch 290, Loss: 0.4635
Batch 300, Loss: 0.4717
Batch 310, Loss: 0.4560
Batch 320, Loss: 0.4908
Batch 330, Loss: 0.4455
Batch 340, Loss: 0.4758
Batch 350, Loss: 0.4779
Batch 360, Loss: 0.4676
Batch 370, Loss: 0.5033
Batch 380, Loss: 0.5083
Batch 390, Loss: 0.5221
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.228410959243774 seconds
Epoch 112 accuracy: 68.14%
Batch 10, Loss: 0.3893
Batch 20, Loss: 0.4219
Batch 30, Loss: 0.3875
Batch 40, Loss: 0.3990
Batch 50, Loss: 0.3738
Batch 60, Loss: 0.3975
Batch 70, Loss: 0.3904
Batch 80, Loss: 0.3685
Batch 90, Loss: 0.3799
Batch 100, Loss: 0.3869
Batch 110, Loss: 0.3872
Batch 120, Loss: 0.4335
Batch 130, Loss: 0.4149
Batch 140, Loss: 0.4201
Batch 150, Loss: 0.4316
Batch 160, Loss: 0.4323
Batch 170, Loss: 0.4484
Batch 180, Loss: 0.4294
Batch 190, Loss: 0.4492
Batch 200, Loss: 0.3805
Batch 210, Loss: 0.4418
Batch 220, Loss: 0.3993
Batch 230, Loss: 0.4529
Batch 240, Loss: 0.4368
Batch 250, Loss: 0.4499
Batch 260, Loss: 0.4631
Batch 270, Loss: 0.4700
Batch 280, Loss: 0.4654
Batch 290, Loss: 0.4726
Batch 300, Loss: 0.4575
Batch 310, Loss: 0.4806
Batch 320, Loss: 0.4846
Batch 330, Loss: 0.4950
Batch 340, Loss: 0.4630
Batch 350, Loss: 0.4724
Batch 360, Loss: 0.5126
Batch 370, Loss: 0.4964
Batch 380, Loss: 0.4811
Batch 390, Loss: 0.4650
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.197885036468506 seconds
Epoch 113 accuracy: 65.12%
Batch 10, Loss: 0.4293
Batch 20, Loss: 0.3992
Batch 30, Loss: 0.3725
Batch 40, Loss: 0.3654
Batch 50, Loss: 0.3774
Batch 60, Loss: 0.3981
Batch 70, Loss: 0.3835
Batch 80, Loss: 0.4062
Batch 90, Loss: 0.3724
Batch 100, Loss: 0.3926
Batch 110, Loss: 0.3841
Batch 120, Loss: 0.3942
Batch 130, Loss: 0.4266
Batch 140, Loss: 0.4193
Batch 150, Loss: 0.4076
Batch 160, Loss: 0.3978
Batch 170, Loss: 0.4227
Batch 180, Loss: 0.4074
Batch 190, Loss: 0.4551
Batch 200, Loss: 0.4113
Batch 210, Loss: 0.4363
Batch 220, Loss: 0.4292
Batch 230, Loss: 0.4641
Batch 240, Loss: 0.4525
Batch 250, Loss: 0.4554
Batch 260, Loss: 0.4258
Batch 270, Loss: 0.4479
Batch 280, Loss: 0.4686
Batch 290, Loss: 0.4321
Batch 300, Loss: 0.4430
Batch 310, Loss: 0.4342
Batch 320, Loss: 0.4460
Batch 330, Loss: 0.4713
Batch 340, Loss: 0.4867
Batch 350, Loss: 0.4840
Batch 360, Loss: 0.4856
Batch 370, Loss: 0.4870
Batch 380, Loss: 0.4699
Batch 390, Loss: 0.4914
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.068943977355957 seconds
Epoch 114 accuracy: 68.43%
Batch 10, Loss: 0.4304
Batch 20, Loss: 0.3988
Batch 30, Loss: 0.3792
Batch 40, Loss: 0.4024
Batch 50, Loss: 0.3816
Batch 60, Loss: 0.3980
Batch 70, Loss: 0.3749
Batch 80, Loss: 0.3767
Batch 90, Loss: 0.4025
Batch 100, Loss: 0.4118
Batch 110, Loss: 0.3818
Batch 120, Loss: 0.3939
Batch 130, Loss: 0.3919
Batch 140, Loss: 0.4057
Batch 150, Loss: 0.3840
Batch 160, Loss: 0.3931
Batch 170, Loss: 0.4057
Batch 180, Loss: 0.4460
Batch 190, Loss: 0.4207
Batch 200, Loss: 0.4051
Batch 210, Loss: 0.3968
Batch 220, Loss: 0.4097
Batch 230, Loss: 0.4224
Batch 240, Loss: 0.4458
Batch 250, Loss: 0.4011
Batch 260, Loss: 0.4515
Batch 270, Loss: 0.4624
Batch 280, Loss: 0.4328
Batch 290, Loss: 0.4795
Batch 300, Loss: 0.4137
Batch 310, Loss: 0.4339
Batch 320, Loss: 0.4499
Batch 330, Loss: 0.4512
Batch 340, Loss: 0.4203
Batch 350, Loss: 0.4729
Batch 360, Loss: 0.4531
Batch 370, Loss: 0.4677
Batch 380, Loss: 0.4530
Batch 390, Loss: 0.4520
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.0843665599823 seconds
Epoch 115 accuracy: 67.12%
Batch 10, Loss: 0.3775
Batch 20, Loss: 0.3677
Batch 30, Loss: 0.3939
Batch 40, Loss: 0.3876
Batch 50, Loss: 0.3966
Batch 60, Loss: 0.3884
Batch 70, Loss: 0.3889
Batch 80, Loss: 0.3616
Batch 90, Loss: 0.3897
Batch 100, Loss: 0.3734
Batch 110, Loss: 0.3581
Batch 120, Loss: 0.4206
Batch 130, Loss: 0.4279
Batch 140, Loss: 0.3831
Batch 150, Loss: 0.3765
Batch 160, Loss: 0.3826
Batch 170, Loss: 0.3716
Batch 180, Loss: 0.4309
Batch 190, Loss: 0.3782
Batch 200, Loss: 0.4049
Batch 210, Loss: 0.4208
Batch 220, Loss: 0.4389
Batch 230, Loss: 0.3806
Batch 240, Loss: 0.4420
Batch 250, Loss: 0.4352
Batch 260, Loss: 0.4051
Batch 270, Loss: 0.4065
Batch 280, Loss: 0.4005
Batch 290, Loss: 0.4289
Batch 300, Loss: 0.4018
Batch 310, Loss: 0.4707
Batch 320, Loss: 0.4259
Batch 330, Loss: 0.4182
Batch 340, Loss: 0.4537
Batch 350, Loss: 0.4522
Batch 360, Loss: 0.4773
Batch 370, Loss: 0.4772
Batch 380, Loss: 0.4670
Batch 390, Loss: 0.4638
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.088364124298096 seconds
Epoch 116 accuracy: 68.48%
Batch 10, Loss: 0.3997
Batch 20, Loss: 0.3841
Batch 30, Loss: 0.3693
Batch 40, Loss: 0.3619
Batch 50, Loss: 0.3676
Batch 60, Loss: 0.3528
Batch 70, Loss: 0.3628
Batch 80, Loss: 0.3545
Batch 90, Loss: 0.3608
Batch 100, Loss: 0.3636
Batch 110, Loss: 0.3880
Batch 120, Loss: 0.3694
Batch 130, Loss: 0.3736
Batch 140, Loss: 0.3974
Batch 150, Loss: 0.4166
Batch 160, Loss: 0.3807
Batch 170, Loss: 0.3827
Batch 180, Loss: 0.4106
Batch 190, Loss: 0.4051
Batch 200, Loss: 0.3841
Batch 210, Loss: 0.4137
Batch 220, Loss: 0.4127
Batch 230, Loss: 0.4327
Batch 240, Loss: 0.4237
Batch 250, Loss: 0.4089
Batch 260, Loss: 0.4474
Batch 270, Loss: 0.4499
Batch 280, Loss: 0.3959
Batch 290, Loss: 0.4407
Batch 300, Loss: 0.4252
Batch 310, Loss: 0.4822
Batch 320, Loss: 0.4622
Batch 330, Loss: 0.4462
Batch 340, Loss: 0.4265
Batch 350, Loss: 0.4343
Batch 360, Loss: 0.4517
Batch 370, Loss: 0.4352
Batch 380, Loss: 0.4815
Batch 390, Loss: 0.4714
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.10480833053589 seconds
Epoch 117 accuracy: 66.45%
Batch 10, Loss: 0.3830
Batch 20, Loss: 0.3713
Batch 30, Loss: 0.3815
Batch 40, Loss: 0.3605
Batch 50, Loss: 0.3483
Batch 60, Loss: 0.3418
Batch 70, Loss: 0.3583
Batch 80, Loss: 0.3879
Batch 90, Loss: 0.3413
Batch 100, Loss: 0.3573
Batch 110, Loss: 0.4027
Batch 120, Loss: 0.3611
Batch 130, Loss: 0.3785
Batch 140, Loss: 0.4159
Batch 150, Loss: 0.3932
Batch 160, Loss: 0.3887
Batch 170, Loss: 0.3834
Batch 180, Loss: 0.3652
Batch 190, Loss: 0.3896
Batch 200, Loss: 0.3698
Batch 210, Loss: 0.3874
Batch 220, Loss: 0.4026
Batch 230, Loss: 0.3888
Batch 240, Loss: 0.3940
Batch 250, Loss: 0.3839
Batch 260, Loss: 0.4201
Batch 270, Loss: 0.4380
Batch 280, Loss: 0.4318
Batch 290, Loss: 0.4167
Batch 300, Loss: 0.4170
Batch 310, Loss: 0.4203
Batch 320, Loss: 0.4194
Batch 330, Loss: 0.4212
Batch 340, Loss: 0.4349
Batch 350, Loss: 0.4581
Batch 360, Loss: 0.4369
Batch 370, Loss: 0.4058
Batch 380, Loss: 0.4614
Batch 390, Loss: 0.4498
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.142963409423828 seconds
Epoch 118 accuracy: 69.17%
Batch 10, Loss: 0.3585
Batch 20, Loss: 0.3708
Batch 30, Loss: 0.3611
Batch 40, Loss: 0.3635
Batch 50, Loss: 0.3388
Batch 60, Loss: 0.3117
Batch 70, Loss: 0.3452
Batch 80, Loss: 0.3559
Batch 90, Loss: 0.3269
Batch 100, Loss: 0.3245
Batch 110, Loss: 0.3694
Batch 120, Loss: 0.3708
Batch 130, Loss: 0.3410
Batch 140, Loss: 0.3361
Batch 150, Loss: 0.3374
Batch 160, Loss: 0.3666
Batch 170, Loss: 0.3676
Batch 180, Loss: 0.3662
Batch 190, Loss: 0.3923
Batch 200, Loss: 0.3787
Batch 210, Loss: 0.3946
Batch 220, Loss: 0.3903
Batch 230, Loss: 0.3760
Batch 240, Loss: 0.3865
Batch 250, Loss: 0.4112
Batch 260, Loss: 0.4354
Batch 270, Loss: 0.4058
Batch 280, Loss: 0.4109
Batch 290, Loss: 0.4086
Batch 300, Loss: 0.4146
Batch 310, Loss: 0.4065
Batch 320, Loss: 0.4209
Batch 330, Loss: 0.3827
Batch 340, Loss: 0.4221
Batch 350, Loss: 0.4226
Batch 360, Loss: 0.4030
Batch 370, Loss: 0.4103
Batch 380, Loss: 0.4432
Batch 390, Loss: 0.4273
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.191084623336792 seconds
Epoch 119 accuracy: 69.7%
Batch 10, Loss: 0.3430
Batch 20, Loss: 0.3452
Batch 30, Loss: 0.3637
Batch 40, Loss: 0.3500
Batch 50, Loss: 0.3393
Batch 60, Loss: 0.3321
Batch 70, Loss: 0.3226
Batch 80, Loss: 0.3552
Batch 90, Loss: 0.3546
Batch 100, Loss: 0.3800
Batch 110, Loss: 0.3824
Batch 120, Loss: 0.3499
Batch 130, Loss: 0.3680
Batch 140, Loss: 0.3647
Batch 150, Loss: 0.3359
Batch 160, Loss: 0.3658
Batch 170, Loss: 0.3691
Batch 180, Loss: 0.3896
Batch 190, Loss: 0.3877
Batch 200, Loss: 0.4042
Batch 210, Loss: 0.4075
Batch 220, Loss: 0.3496
Batch 230, Loss: 0.3648
Batch 240, Loss: 0.3760
Batch 250, Loss: 0.3913
Batch 260, Loss: 0.4227
Batch 270, Loss: 0.4323
Batch 280, Loss: 0.3723
Batch 290, Loss: 0.3754
Batch 300, Loss: 0.3846
Batch 310, Loss: 0.4144
Batch 320, Loss: 0.4248
Batch 330, Loss: 0.4217
Batch 340, Loss: 0.3885
Batch 350, Loss: 0.4211
Batch 360, Loss: 0.4179
Batch 370, Loss: 0.4298
Batch 380, Loss: 0.4336
Batch 390, Loss: 0.4296
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.095842599868774 seconds
Epoch 120 accuracy: 68.22%
Batch 10, Loss: 0.3335
Batch 20, Loss: 0.3380
Batch 30, Loss: 0.3345
Batch 40, Loss: 0.3320
Batch 50, Loss: 0.3459
Batch 60, Loss: 0.3336
Batch 70, Loss: 0.3293
Batch 80, Loss: 0.3178
Batch 90, Loss: 0.3101
Batch 100, Loss: 0.3287
Batch 110, Loss: 0.3186
Batch 120, Loss: 0.3329
Batch 130, Loss: 0.3221
Batch 140, Loss: 0.3265
Batch 150, Loss: 0.3320
Batch 160, Loss: 0.3300
Batch 170, Loss: 0.3370
Batch 180, Loss: 0.3597
Batch 190, Loss: 0.3508
Batch 200, Loss: 0.3578
Batch 210, Loss: 0.3625
Batch 220, Loss: 0.3615
Batch 230, Loss: 0.4009
Batch 240, Loss: 0.3529
Batch 250, Loss: 0.3837
Batch 260, Loss: 0.3925
Batch 270, Loss: 0.4013
Batch 280, Loss: 0.3971
Batch 290, Loss: 0.3923
Batch 300, Loss: 0.4040
Batch 310, Loss: 0.3554
Batch 320, Loss: 0.4004
Batch 330, Loss: 0.3944
Batch 340, Loss: 0.3941
Batch 350, Loss: 0.4162
Batch 360, Loss: 0.4069
Batch 370, Loss: 0.4092
Batch 380, Loss: 0.4107
Batch 390, Loss: 0.4272
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.174623250961304 seconds
Epoch 121 accuracy: 67.51%
Batch 10, Loss: 0.3329
Batch 20, Loss: 0.3689
Batch 30, Loss: 0.3401
Batch 40, Loss: 0.3068
Batch 50, Loss: 0.3224
Batch 60, Loss: 0.3183
Batch 70, Loss: 0.3193
Batch 80, Loss: 0.3408
Batch 90, Loss: 0.3412
Batch 100, Loss: 0.3528
Batch 110, Loss: 0.3309
Batch 120, Loss: 0.3141
Batch 130, Loss: 0.3392
Batch 140, Loss: 0.3342
Batch 150, Loss: 0.3355
Batch 160, Loss: 0.3614
Batch 170, Loss: 0.3599
Batch 180, Loss: 0.3586
Batch 190, Loss: 0.3339
Batch 200, Loss: 0.3409
Batch 210, Loss: 0.3479
Batch 220, Loss: 0.3492
Batch 230, Loss: 0.3478
Batch 240, Loss: 0.3465
Batch 250, Loss: 0.3294
Batch 260, Loss: 0.3807
Batch 270, Loss: 0.3719
Batch 280, Loss: 0.3988
Batch 290, Loss: 0.3811
Batch 300, Loss: 0.3704
Batch 310, Loss: 0.3777
Batch 320, Loss: 0.4200
Batch 330, Loss: 0.3949
Batch 340, Loss: 0.3741
Batch 350, Loss: 0.4011
Batch 360, Loss: 0.3714
Batch 370, Loss: 0.3951
Batch 380, Loss: 0.3922
Batch 390, Loss: 0.3962
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.02887725830078 seconds
Epoch 122 accuracy: 67.71%
Batch 10, Loss: 0.3382
Batch 20, Loss: 0.3166
Batch 30, Loss: 0.3007
Batch 40, Loss: 0.3093
Batch 50, Loss: 0.2958
Batch 60, Loss: 0.3119
Batch 70, Loss: 0.3297
Batch 80, Loss: 0.3565
Batch 90, Loss: 0.3113
Batch 100, Loss: 0.3496
Batch 110, Loss: 0.3129
Batch 120, Loss: 0.3350
Batch 130, Loss: 0.3181
Batch 140, Loss: 0.3071
Batch 150, Loss: 0.3164
Batch 160, Loss: 0.3130
Batch 170, Loss: 0.3206
Batch 180, Loss: 0.3633
Batch 190, Loss: 0.3478
Batch 200, Loss: 0.3277
Batch 210, Loss: 0.3590
Batch 220, Loss: 0.3428
Batch 230, Loss: 0.3621
Batch 240, Loss: 0.3706
Batch 250, Loss: 0.3609
Batch 260, Loss: 0.3781
Batch 270, Loss: 0.3764
Batch 280, Loss: 0.3706
Batch 290, Loss: 0.3659
Batch 300, Loss: 0.3717
Batch 310, Loss: 0.3402
Batch 320, Loss: 0.3664
Batch 330, Loss: 0.3814
Batch 340, Loss: 0.3679
Batch 350, Loss: 0.3784
Batch 360, Loss: 0.3941
Batch 370, Loss: 0.4043
Batch 380, Loss: 0.3890
Batch 390, Loss: 0.3929
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.225173711776733 seconds
Epoch 123 accuracy: 69.04%
Batch 10, Loss: 0.3289
Batch 20, Loss: 0.3021
Batch 30, Loss: 0.2852
Batch 40, Loss: 0.2975
Batch 50, Loss: 0.2936
Batch 60, Loss: 0.2913
Batch 70, Loss: 0.2743
Batch 80, Loss: 0.3051
Batch 90, Loss: 0.3055
Batch 100, Loss: 0.3092
Batch 110, Loss: 0.3365
Batch 120, Loss: 0.3066
Batch 130, Loss: 0.3174
Batch 140, Loss: 0.3211
Batch 150, Loss: 0.3139
Batch 160, Loss: 0.3073
Batch 170, Loss: 0.3177
Batch 180, Loss: 0.3330
Batch 190, Loss: 0.3525
Batch 200, Loss: 0.3509
Batch 210, Loss: 0.3535
Batch 220, Loss: 0.3575
Batch 230, Loss: 0.3206
Batch 240, Loss: 0.3591
Batch 250, Loss: 0.3324
Batch 260, Loss: 0.3574
Batch 270, Loss: 0.3641
Batch 280, Loss: 0.3619
Batch 290, Loss: 0.3887
Batch 300, Loss: 0.3762
Batch 310, Loss: 0.3598
Batch 320, Loss: 0.3179
Batch 330, Loss: 0.3178
Batch 340, Loss: 0.3567
Batch 350, Loss: 0.3785
Batch 360, Loss: 0.3487
Batch 370, Loss: 0.3843
Batch 380, Loss: 0.3854
Batch 390, Loss: 0.4012
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.152991771697998 seconds
Epoch 124 accuracy: 67.74%
Batch 10, Loss: 0.3154
Batch 20, Loss: 0.3166
Batch 30, Loss: 0.2950
Batch 40, Loss: 0.3376
Batch 50, Loss: 0.3057
Batch 60, Loss: 0.2980
Batch 70, Loss: 0.2927
Batch 80, Loss: 0.2951
Batch 90, Loss: 0.2991
Batch 100, Loss: 0.3072
Batch 110, Loss: 0.3220
Batch 120, Loss: 0.2817
Batch 130, Loss: 0.3045
Batch 140, Loss: 0.2810
Batch 150, Loss: 0.2956
Batch 160, Loss: 0.3218
Batch 170, Loss: 0.3334
Batch 180, Loss: 0.3260
Batch 190, Loss: 0.3365
Batch 200, Loss: 0.3487
Batch 210, Loss: 0.3840
Batch 220, Loss: 0.3626
Batch 230, Loss: 0.3428
Batch 240, Loss: 0.3699
Batch 250, Loss: 0.3430
Batch 260, Loss: 0.3494
Batch 270, Loss: 0.3413
Batch 280, Loss: 0.3476
Batch 290, Loss: 0.3587
Batch 300, Loss: 0.3588
Batch 310, Loss: 0.3342
Batch 320, Loss: 0.3543
Batch 330, Loss: 0.3703
Batch 340, Loss: 0.3907
Batch 350, Loss: 0.3498
Batch 360, Loss: 0.3955
Batch 370, Loss: 0.3330
Batch 380, Loss: 0.3598
Batch 390, Loss: 0.3660
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.194170236587524 seconds
Epoch 125 accuracy: 70.1%
Batch 10, Loss: 0.2914
Batch 20, Loss: 0.3144
Batch 30, Loss: 0.2978
Batch 40, Loss: 0.2945
Batch 50, Loss: 0.2793
Batch 60, Loss: 0.2972
Batch 70, Loss: 0.3022
Batch 80, Loss: 0.2946
Batch 90, Loss: 0.3169
Batch 100, Loss: 0.2986
Batch 110, Loss: 0.3264
Batch 120, Loss: 0.2927
Batch 130, Loss: 0.2949
Batch 140, Loss: 0.2903
Batch 150, Loss: 0.2902
Batch 160, Loss: 0.2994
Batch 170, Loss: 0.3129
Batch 180, Loss: 0.3107
Batch 190, Loss: 0.3184
Batch 200, Loss: 0.3260
Batch 210, Loss: 0.3475
Batch 220, Loss: 0.3229
Batch 230, Loss: 0.3054
Batch 240, Loss: 0.3293
Batch 250, Loss: 0.3472
Batch 260, Loss: 0.3609
Batch 270, Loss: 0.3432
Batch 280, Loss: 0.3565
Batch 290, Loss: 0.3381
Batch 300, Loss: 0.3522
Batch 310, Loss: 0.3627
Batch 320, Loss: 0.3661
Batch 330, Loss: 0.3580
Batch 340, Loss: 0.3580
Batch 350, Loss: 0.3630
Batch 360, Loss: 0.3495
Batch 370, Loss: 0.3425
Batch 380, Loss: 0.3621
Batch 390, Loss: 0.3429
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.147605657577515 seconds
Epoch 126 accuracy: 69.7%
Batch 10, Loss: 0.3001
Batch 20, Loss: 0.2775
Batch 30, Loss: 0.3040
Batch 40, Loss: 0.2825
Batch 50, Loss: 0.2965
Batch 60, Loss: 0.2827
Batch 70, Loss: 0.2827
Batch 80, Loss: 0.2875
Batch 90, Loss: 0.2936
Batch 100, Loss: 0.2686
Batch 110, Loss: 0.2931
Batch 120, Loss: 0.2718
Batch 130, Loss: 0.2924
Batch 140, Loss: 0.3021
Batch 150, Loss: 0.3002
Batch 160, Loss: 0.3054
Batch 170, Loss: 0.2967
Batch 180, Loss: 0.2958
Batch 190, Loss: 0.2998
Batch 200, Loss: 0.3093
Batch 210, Loss: 0.3238
Batch 220, Loss: 0.3216
Batch 230, Loss: 0.3110
Batch 240, Loss: 0.2915
Batch 250, Loss: 0.2845
Batch 260, Loss: 0.3009
Batch 270, Loss: 0.3073
Batch 280, Loss: 0.3487
Batch 290, Loss: 0.3567
Batch 300, Loss: 0.3302
Batch 310, Loss: 0.3310
Batch 320, Loss: 0.3149
Batch 330, Loss: 0.3139
Batch 340, Loss: 0.3372
Batch 350, Loss: 0.3226
Batch 360, Loss: 0.3089
Batch 370, Loss: 0.3533
Batch 380, Loss: 0.3293
Batch 390, Loss: 0.3644
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.157771587371826 seconds
Epoch 127 accuracy: 70.39%
Batch 10, Loss: 0.3038
Batch 20, Loss: 0.2868
Batch 30, Loss: 0.2895
Batch 40, Loss: 0.2781
Batch 50, Loss: 0.2678
Batch 60, Loss: 0.2740
Batch 70, Loss: 0.2872
Batch 80, Loss: 0.2961
Batch 90, Loss: 0.2878
Batch 100, Loss: 0.2886
Batch 110, Loss: 0.2840
Batch 120, Loss: 0.2670
Batch 130, Loss: 0.2877
Batch 140, Loss: 0.2901
Batch 150, Loss: 0.2952
Batch 160, Loss: 0.2926
Batch 170, Loss: 0.2811
Batch 180, Loss: 0.2955
Batch 190, Loss: 0.2822
Batch 200, Loss: 0.2773
Batch 210, Loss: 0.2944
Batch 220, Loss: 0.3238
Batch 230, Loss: 0.3060
Batch 240, Loss: 0.2989
Batch 250, Loss: 0.2691
Batch 260, Loss: 0.3162
Batch 270, Loss: 0.3047
Batch 280, Loss: 0.3298
Batch 290, Loss: 0.3203
Batch 300, Loss: 0.3111
Batch 310, Loss: 0.3143
Batch 320, Loss: 0.3414
Batch 330, Loss: 0.3254
Batch 340, Loss: 0.3427
Batch 350, Loss: 0.3470
Batch 360, Loss: 0.3292
Batch 370, Loss: 0.3707
Batch 380, Loss: 0.3409
Batch 390, Loss: 0.3334
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.188629627227783 seconds
Epoch 128 accuracy: 69.54%
Batch 10, Loss: 0.2857
Batch 20, Loss: 0.2528
Batch 30, Loss: 0.2708
Batch 40, Loss: 0.2628
Batch 50, Loss: 0.2611
Batch 60, Loss: 0.2855
Batch 70, Loss: 0.2630
Batch 80, Loss: 0.2621
Batch 90, Loss: 0.2833
Batch 100, Loss: 0.2900
Batch 110, Loss: 0.2760
Batch 120, Loss: 0.2815
Batch 130, Loss: 0.2598
Batch 140, Loss: 0.2564
Batch 150, Loss: 0.2761
Batch 160, Loss: 0.2553
Batch 170, Loss: 0.2680
Batch 180, Loss: 0.2805
Batch 190, Loss: 0.2818
Batch 200, Loss: 0.2819
Batch 210, Loss: 0.2903
Batch 220, Loss: 0.2894
Batch 230, Loss: 0.2911
Batch 240, Loss: 0.2933
Batch 250, Loss: 0.3152
Batch 260, Loss: 0.3364
Batch 270, Loss: 0.3103
Batch 280, Loss: 0.2956
Batch 290, Loss: 0.3130
Batch 300, Loss: 0.3204
Batch 310, Loss: 0.3169
Batch 320, Loss: 0.3014
Batch 330, Loss: 0.3269
Batch 340, Loss: 0.3243
Batch 350, Loss: 0.3234
Batch 360, Loss: 0.3411
Batch 370, Loss: 0.3150
Batch 380, Loss: 0.3283
Batch 390, Loss: 0.3100
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.232574939727783 seconds
Epoch 129 accuracy: 70.41%
Batch 10, Loss: 0.2673
Batch 20, Loss: 0.2889
Batch 30, Loss: 0.2590
Batch 40, Loss: 0.2946
Batch 50, Loss: 0.2864
Batch 60, Loss: 0.2597
Batch 70, Loss: 0.2862
Batch 80, Loss: 0.2721
Batch 90, Loss: 0.2592
Batch 100, Loss: 0.2737
Batch 110, Loss: 0.2581
Batch 120, Loss: 0.2698
Batch 130, Loss: 0.2964
Batch 140, Loss: 0.2887
Batch 150, Loss: 0.2792
Batch 160, Loss: 0.2818
Batch 170, Loss: 0.2913
Batch 180, Loss: 0.2866
Batch 190, Loss: 0.2886
Batch 200, Loss: 0.2841
Batch 210, Loss: 0.2962
Batch 220, Loss: 0.3030
Batch 230, Loss: 0.2882
Batch 240, Loss: 0.2939
Batch 250, Loss: 0.3036
Batch 260, Loss: 0.3231
Batch 270, Loss: 0.2933
Batch 280, Loss: 0.3126
Batch 290, Loss: 0.3079
Batch 300, Loss: 0.2881
Batch 310, Loss: 0.3048
Batch 320, Loss: 0.3010
Batch 330, Loss: 0.3072
Batch 340, Loss: 0.2776
Batch 350, Loss: 0.3172
Batch 360, Loss: 0.3203
Batch 370, Loss: 0.3287
Batch 380, Loss: 0.3314
Batch 390, Loss: 0.3092
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.146701335906982 seconds
Epoch 130 accuracy: 71.13%
Batch 10, Loss: 0.2852
Batch 20, Loss: 0.2702
Batch 30, Loss: 0.2797
Batch 40, Loss: 0.2645
Batch 50, Loss: 0.2512
Batch 60, Loss: 0.2663
Batch 70, Loss: 0.2665
Batch 80, Loss: 0.2531
Batch 90, Loss: 0.2565
Batch 100, Loss: 0.2602
Batch 110, Loss: 0.2832
Batch 120, Loss: 0.2479
Batch 130, Loss: 0.2758
Batch 140, Loss: 0.2558
Batch 150, Loss: 0.2526
Batch 160, Loss: 0.2755
Batch 170, Loss: 0.3108
Batch 180, Loss: 0.2745
Batch 190, Loss: 0.2744
Batch 200, Loss: 0.2703
Batch 210, Loss: 0.2753
Batch 220, Loss: 0.2636
Batch 230, Loss: 0.2706
Batch 240, Loss: 0.2900
Batch 250, Loss: 0.2732
Batch 260, Loss: 0.2825
Batch 270, Loss: 0.2938
Batch 280, Loss: 0.3178
Batch 290, Loss: 0.3128
Batch 300, Loss: 0.3168
Batch 310, Loss: 0.2912
Batch 320, Loss: 0.2969
Batch 330, Loss: 0.3200
Batch 340, Loss: 0.3468
Batch 350, Loss: 0.3257
Batch 360, Loss: 0.3459
Batch 370, Loss: 0.3514
Batch 380, Loss: 0.3259
Batch 390, Loss: 0.3452
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.075997591018677 seconds
Epoch 131 accuracy: 68.45%
Batch 10, Loss: 0.2736
Batch 20, Loss: 0.2416
Batch 30, Loss: 0.2321
Batch 40, Loss: 0.2500
Batch 50, Loss: 0.2798
Batch 60, Loss: 0.2603
Batch 70, Loss: 0.2332
Batch 80, Loss: 0.2295
Batch 90, Loss: 0.2453
Batch 100, Loss: 0.2681
Batch 110, Loss: 0.2457
Batch 120, Loss: 0.2561
Batch 130, Loss: 0.2822
Batch 140, Loss: 0.2561
Batch 150, Loss: 0.2546
Batch 160, Loss: 0.2579
Batch 170, Loss: 0.2565
Batch 180, Loss: 0.2546
Batch 190, Loss: 0.2753
Batch 200, Loss: 0.2615
Batch 210, Loss: 0.2706
Batch 220, Loss: 0.2781
Batch 230, Loss: 0.2690
Batch 240, Loss: 0.2928
Batch 250, Loss: 0.2639
Batch 260, Loss: 0.2624
Batch 270, Loss: 0.2617
Batch 280, Loss: 0.2840
Batch 290, Loss: 0.2828
Batch 300, Loss: 0.2758
Batch 310, Loss: 0.2885
Batch 320, Loss: 0.2873
Batch 330, Loss: 0.2725
Batch 340, Loss: 0.3206
Batch 350, Loss: 0.2793
Batch 360, Loss: 0.3004
Batch 370, Loss: 0.2937
Batch 380, Loss: 0.2974
Batch 390, Loss: 0.3169
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.205360174179077 seconds
Epoch 132 accuracy: 69.78%
Batch 10, Loss: 0.2447
Batch 20, Loss: 0.2544
Batch 30, Loss: 0.2323
Batch 40, Loss: 0.2355
Batch 50, Loss: 0.2282
Batch 60, Loss: 0.2425
Batch 70, Loss: 0.2441
Batch 80, Loss: 0.2344
Batch 90, Loss: 0.2512
Batch 100, Loss: 0.2262
Batch 110, Loss: 0.2521
Batch 120, Loss: 0.2530
Batch 130, Loss: 0.2490
Batch 140, Loss: 0.2471
Batch 150, Loss: 0.2541
Batch 160, Loss: 0.2494
Batch 170, Loss: 0.2546
Batch 180, Loss: 0.2659
Batch 190, Loss: 0.2769
Batch 200, Loss: 0.2443
Batch 210, Loss: 0.2545
Batch 220, Loss: 0.2352
Batch 230, Loss: 0.2507
Batch 240, Loss: 0.2631
Batch 250, Loss: 0.2421
Batch 260, Loss: 0.2484
Batch 270, Loss: 0.2438
Batch 280, Loss: 0.2762
Batch 290, Loss: 0.2703
Batch 300, Loss: 0.2728
Batch 310, Loss: 0.2682
Batch 320, Loss: 0.2685
Batch 330, Loss: 0.2652
Batch 340, Loss: 0.2747
Batch 350, Loss: 0.2520
Batch 360, Loss: 0.2649
Batch 370, Loss: 0.2644
Batch 380, Loss: 0.3003
Batch 390, Loss: 0.2958
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.072981595993042 seconds
Epoch 133 accuracy: 69.71%
Batch 10, Loss: 0.2413
Batch 20, Loss: 0.2379
Batch 30, Loss: 0.2083
Batch 40, Loss: 0.2259
Batch 50, Loss: 0.2197
Batch 60, Loss: 0.2482
Batch 70, Loss: 0.2422
Batch 80, Loss: 0.2431
Batch 90, Loss: 0.2572
Batch 100, Loss: 0.2455
Batch 110, Loss: 0.2345
Batch 120, Loss: 0.2478
Batch 130, Loss: 0.2377
Batch 140, Loss: 0.2562
Batch 150, Loss: 0.2435
Batch 160, Loss: 0.2118
Batch 170, Loss: 0.2568
Batch 180, Loss: 0.2418
Batch 190, Loss: 0.2493
Batch 200, Loss: 0.2493
Batch 210, Loss: 0.2352
Batch 220, Loss: 0.2578
Batch 230, Loss: 0.2786
Batch 240, Loss: 0.2704
Batch 250, Loss: 0.2803
Batch 260, Loss: 0.2383
Batch 270, Loss: 0.2754
Batch 280, Loss: 0.2531
Batch 290, Loss: 0.2594
Batch 300, Loss: 0.2633
Batch 310, Loss: 0.2600
Batch 320, Loss: 0.2758
Batch 330, Loss: 0.2530
Batch 340, Loss: 0.2850
Batch 350, Loss: 0.2646
Batch 360, Loss: 0.2512
Batch 370, Loss: 0.2662
Batch 380, Loss: 0.2709
Batch 390, Loss: 0.2633
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.272050142288208 seconds
Epoch 134 accuracy: 71.26%
Batch 10, Loss: 0.2226
Batch 20, Loss: 0.2311
Batch 30, Loss: 0.2183
Batch 40, Loss: 0.2178
Batch 50, Loss: 0.2205
Batch 60, Loss: 0.2203
Batch 70, Loss: 0.2185
Batch 80, Loss: 0.2367
Batch 90, Loss: 0.2187
Batch 100, Loss: 0.2157
Batch 110, Loss: 0.2339
Batch 120, Loss: 0.2268
Batch 130, Loss: 0.2215
Batch 140, Loss: 0.2178
Batch 150, Loss: 0.2261
Batch 160, Loss: 0.2177
Batch 170, Loss: 0.2211
Batch 180, Loss: 0.2206
Batch 190, Loss: 0.2479
Batch 200, Loss: 0.2429
Batch 210, Loss: 0.2314
Batch 220, Loss: 0.2449
Batch 230, Loss: 0.2282
Batch 240, Loss: 0.2335
Batch 250, Loss: 0.2345
Batch 260, Loss: 0.2692
Batch 270, Loss: 0.2638
Batch 280, Loss: 0.2483
Batch 290, Loss: 0.2467
Batch 300, Loss: 0.2442
Batch 310, Loss: 0.2509
Batch 320, Loss: 0.2647
Batch 330, Loss: 0.2623
Batch 340, Loss: 0.2666
Batch 350, Loss: 0.2415
Batch 360, Loss: 0.2526
Batch 370, Loss: 0.2577
Batch 380, Loss: 0.2513
Batch 390, Loss: 0.2640
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.230269193649292 seconds
Epoch 135 accuracy: 70.69%
Batch 10, Loss: 0.2271
Batch 20, Loss: 0.2254
Batch 30, Loss: 0.2118
Batch 40, Loss: 0.2412
Batch 50, Loss: 0.2207
Batch 60, Loss: 0.2213
Batch 70, Loss: 0.2418
Batch 80, Loss: 0.2307
Batch 90, Loss: 0.2138
Batch 100, Loss: 0.2339
Batch 110, Loss: 0.2059
Batch 120, Loss: 0.2321
Batch 130, Loss: 0.2280
Batch 140, Loss: 0.2050
Batch 150, Loss: 0.2100
Batch 160, Loss: 0.2197
Batch 170, Loss: 0.2253
Batch 180, Loss: 0.2115
Batch 190, Loss: 0.2243
Batch 200, Loss: 0.2410
Batch 210, Loss: 0.2500
Batch 220, Loss: 0.2498
Batch 230, Loss: 0.2288
Batch 240, Loss: 0.2374
Batch 250, Loss: 0.2607
Batch 260, Loss: 0.2325
Batch 270, Loss: 0.2400
Batch 280, Loss: 0.2462
Batch 290, Loss: 0.2408
Batch 300, Loss: 0.2428
Batch 310, Loss: 0.2603
Batch 320, Loss: 0.2604
Batch 330, Loss: 0.2650
Batch 340, Loss: 0.2781
Batch 350, Loss: 0.2508
Batch 360, Loss: 0.2492
Batch 370, Loss: 0.2631
Batch 380, Loss: 0.2684
Batch 390, Loss: 0.2748
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.142085313796997 seconds
Epoch 136 accuracy: 72.22%
Batch 10, Loss: 0.2256
Batch 20, Loss: 0.2244
Batch 30, Loss: 0.2384
Batch 40, Loss: 0.2235
Batch 50, Loss: 0.2121
Batch 60, Loss: 0.1928
Batch 70, Loss: 0.2068
Batch 80, Loss: 0.1964
Batch 90, Loss: 0.2151
Batch 100, Loss: 0.1932
Batch 110, Loss: 0.2146
Batch 120, Loss: 0.2040
Batch 130, Loss: 0.2208
Batch 140, Loss: 0.2032
Batch 150, Loss: 0.2001
Batch 160, Loss: 0.2019
Batch 170, Loss: 0.2168
Batch 180, Loss: 0.2092
Batch 190, Loss: 0.2201
Batch 200, Loss: 0.2192
Batch 210, Loss: 0.2117
Batch 220, Loss: 0.2208
Batch 230, Loss: 0.2280
Batch 240, Loss: 0.2157
Batch 250, Loss: 0.2319
Batch 260, Loss: 0.2332
Batch 270, Loss: 0.2295
Batch 280, Loss: 0.2267
Batch 290, Loss: 0.2574
Batch 300, Loss: 0.2293
Batch 310, Loss: 0.2383
Batch 320, Loss: 0.2471
Batch 330, Loss: 0.2684
Batch 340, Loss: 0.2476
Batch 350, Loss: 0.2718
Batch 360, Loss: 0.2610
Batch 370, Loss: 0.2530
Batch 380, Loss: 0.2837
Batch 390, Loss: 0.2797
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.151751279830933 seconds
Epoch 137 accuracy: 70.16%
Batch 10, Loss: 0.2497
Batch 20, Loss: 0.2179
Batch 30, Loss: 0.2340
Batch 40, Loss: 0.2274
Batch 50, Loss: 0.2176
Batch 60, Loss: 0.2036
Batch 70, Loss: 0.2140
Batch 80, Loss: 0.1998
Batch 90, Loss: 0.1972
Batch 100, Loss: 0.2019
Batch 110, Loss: 0.2133
Batch 120, Loss: 0.2036
Batch 130, Loss: 0.2020
Batch 140, Loss: 0.2200
Batch 150, Loss: 0.2167
Batch 160, Loss: 0.2024
Batch 170, Loss: 0.1983
Batch 180, Loss: 0.2315
Batch 190, Loss: 0.2124
Batch 200, Loss: 0.2151
Batch 210, Loss: 0.2369
Batch 220, Loss: 0.2412
Batch 230, Loss: 0.2052
Batch 240, Loss: 0.2231
Batch 250, Loss: 0.2305
Batch 260, Loss: 0.2232
Batch 270, Loss: 0.2173
Batch 280, Loss: 0.2292
Batch 290, Loss: 0.2183
Batch 300, Loss: 0.2324
Batch 310, Loss: 0.2527
Batch 320, Loss: 0.2397
Batch 330, Loss: 0.2317
Batch 340, Loss: 0.2198
Batch 350, Loss: 0.2281
Batch 360, Loss: 0.2382
Batch 370, Loss: 0.2230
Batch 380, Loss: 0.2510
Batch 390, Loss: 0.2200
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.254612684249878 seconds
Epoch 138 accuracy: 72.24%
Batch 10, Loss: 0.2229
Batch 20, Loss: 0.2177
Batch 30, Loss: 0.1827
Batch 40, Loss: 0.2071
Batch 50, Loss: 0.2060
Batch 60, Loss: 0.1891
Batch 70, Loss: 0.1929
Batch 80, Loss: 0.1762
Batch 90, Loss: 0.1980
Batch 100, Loss: 0.1974
Batch 110, Loss: 0.1963
Batch 120, Loss: 0.2056
Batch 130, Loss: 0.2153
Batch 140, Loss: 0.2039
Batch 150, Loss: 0.1913
Batch 160, Loss: 0.2000
Batch 170, Loss: 0.2044
Batch 180, Loss: 0.2016
Batch 190, Loss: 0.1969
Batch 200, Loss: 0.2117
Batch 210, Loss: 0.1921
Batch 220, Loss: 0.1880
Batch 230, Loss: 0.2091
Batch 240, Loss: 0.2040
Batch 250, Loss: 0.2116
Batch 260, Loss: 0.2194
Batch 270, Loss: 0.2080
Batch 280, Loss: 0.2172
Batch 290, Loss: 0.2034
Batch 300, Loss: 0.2099
Batch 310, Loss: 0.2013
Batch 320, Loss: 0.2128
Batch 330, Loss: 0.2167
Batch 340, Loss: 0.2169
Batch 350, Loss: 0.2375
Batch 360, Loss: 0.2057
Batch 370, Loss: 0.2224
Batch 380, Loss: 0.2163
Batch 390, Loss: 0.2140
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.196345329284668 seconds
Epoch 139 accuracy: 73.14%
Batch 10, Loss: 0.1861
Batch 20, Loss: 0.1829
Batch 30, Loss: 0.1826
Batch 40, Loss: 0.1806
Batch 50, Loss: 0.1756
Batch 60, Loss: 0.1742
Batch 70, Loss: 0.1777
Batch 80, Loss: 0.1948
Batch 90, Loss: 0.1876
Batch 100, Loss: 0.1828
Batch 110, Loss: 0.1951
Batch 120, Loss: 0.1942
Batch 130, Loss: 0.1854
Batch 140, Loss: 0.1840
Batch 150, Loss: 0.1943
Batch 160, Loss: 0.1856
Batch 170, Loss: 0.1990
Batch 180, Loss: 0.2001
Batch 190, Loss: 0.2030
Batch 200, Loss: 0.2052
Batch 210, Loss: 0.2016
Batch 220, Loss: 0.1865
Batch 230, Loss: 0.1859
Batch 240, Loss: 0.2007
Batch 250, Loss: 0.1891
Batch 260, Loss: 0.1879
Batch 270, Loss: 0.1905
Batch 280, Loss: 0.2010
Batch 290, Loss: 0.2022
Batch 300, Loss: 0.2340
Batch 310, Loss: 0.2333
Batch 320, Loss: 0.2250
Batch 330, Loss: 0.2281
Batch 340, Loss: 0.2170
Batch 350, Loss: 0.2217
Batch 360, Loss: 0.2407
Batch 370, Loss: 0.2224
Batch 380, Loss: 0.2258
Batch 390, Loss: 0.2260
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.15141010284424 seconds
Epoch 140 accuracy: 70.36%
Batch 10, Loss: 0.2000
Batch 20, Loss: 0.1801
Batch 30, Loss: 0.1937
Batch 40, Loss: 0.1656
Batch 50, Loss: 0.1675
Batch 60, Loss: 0.1726
Batch 70, Loss: 0.1907
Batch 80, Loss: 0.1751
Batch 90, Loss: 0.1758
Batch 100, Loss: 0.1906
Batch 110, Loss: 0.1784
Batch 120, Loss: 0.1843
Batch 130, Loss: 0.1909
Batch 140, Loss: 0.1755
Batch 150, Loss: 0.1920
Batch 160, Loss: 0.1829
Batch 170, Loss: 0.1894
Batch 180, Loss: 0.2097
Batch 190, Loss: 0.1933
Batch 200, Loss: 0.2039
Batch 210, Loss: 0.1902
Batch 220, Loss: 0.1847
Batch 230, Loss: 0.1928
Batch 240, Loss: 0.1780
Batch 250, Loss: 0.1996
Batch 260, Loss: 0.2114
Batch 270, Loss: 0.1900
Batch 280, Loss: 0.2074
Batch 290, Loss: 0.2144
Batch 300, Loss: 0.2177
Batch 310, Loss: 0.1963
Batch 320, Loss: 0.2224
Batch 330, Loss: 0.2094
Batch 340, Loss: 0.2373
Batch 350, Loss: 0.2375
Batch 360, Loss: 0.2051
Batch 370, Loss: 0.2300
Batch 380, Loss: 0.2108
Batch 390, Loss: 0.2317
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.17536234855652 seconds
Epoch 141 accuracy: 72.46%
Batch 10, Loss: 0.1869
Batch 20, Loss: 0.1815
Batch 30, Loss: 0.1885
Batch 40, Loss: 0.1992
Batch 50, Loss: 0.1723
Batch 60, Loss: 0.1730
Batch 70, Loss: 0.1670
Batch 80, Loss: 0.1916
Batch 90, Loss: 0.1863
Batch 100, Loss: 0.1944
Batch 110, Loss: 0.1639
Batch 120, Loss: 0.1699
Batch 130, Loss: 0.1891
Batch 140, Loss: 0.1732
Batch 150, Loss: 0.1942
Batch 160, Loss: 0.1731
Batch 170, Loss: 0.1752
Batch 180, Loss: 0.1744
Batch 190, Loss: 0.1743
Batch 200, Loss: 0.1747
Batch 210, Loss: 0.1861
Batch 220, Loss: 0.1917
Batch 230, Loss: 0.1824
Batch 240, Loss: 0.1795
Batch 250, Loss: 0.1982
Batch 260, Loss: 0.2014
Batch 270, Loss: 0.2033
Batch 280, Loss: 0.1858
Batch 290, Loss: 0.1881
Batch 300, Loss: 0.1952
Batch 310, Loss: 0.2137
Batch 320, Loss: 0.1970
Batch 330, Loss: 0.2092
Batch 340, Loss: 0.1983
Batch 350, Loss: 0.2048
Batch 360, Loss: 0.1970
Batch 370, Loss: 0.2145
Batch 380, Loss: 0.2180
Batch 390, Loss: 0.2151
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.21638059616089 seconds
Epoch 142 accuracy: 73.17%
Batch 10, Loss: 0.1957
Batch 20, Loss: 0.1941
Batch 30, Loss: 0.1877
Batch 40, Loss: 0.1803
Batch 50, Loss: 0.1739
Batch 60, Loss: 0.1766
Batch 70, Loss: 0.1775
Batch 80, Loss: 0.1756
Batch 90, Loss: 0.1656
Batch 100, Loss: 0.1766
Batch 110, Loss: 0.1648
Batch 120, Loss: 0.1832
Batch 130, Loss: 0.1738
Batch 140, Loss: 0.1792
Batch 150, Loss: 0.1701
Batch 160, Loss: 0.1845
Batch 170, Loss: 0.1604
Batch 180, Loss: 0.1889
Batch 190, Loss: 0.1853
Batch 200, Loss: 0.1593
Batch 210, Loss: 0.1804
Batch 220, Loss: 0.1707
Batch 230, Loss: 0.1795
Batch 240, Loss: 0.1951
Batch 250, Loss: 0.1951
Batch 260, Loss: 0.1849
Batch 270, Loss: 0.1840
Batch 280, Loss: 0.2017
Batch 290, Loss: 0.1658
Batch 300, Loss: 0.1871
Batch 310, Loss: 0.1868
Batch 320, Loss: 0.1942
Batch 330, Loss: 0.1698
Batch 340, Loss: 0.1816
Batch 350, Loss: 0.1881
Batch 360, Loss: 0.1964
Batch 370, Loss: 0.1932
Batch 380, Loss: 0.2248
Batch 390, Loss: 0.2176
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.16757345199585 seconds
Epoch 143 accuracy: 73.19%
Batch 10, Loss: 0.1628
Batch 20, Loss: 0.1549
Batch 30, Loss: 0.1765
Batch 40, Loss: 0.1763
Batch 50, Loss: 0.1546
Batch 60, Loss: 0.1658
Batch 70, Loss: 0.1528
Batch 80, Loss: 0.1648
Batch 90, Loss: 0.1685
Batch 100, Loss: 0.1871
Batch 110, Loss: 0.1840
Batch 120, Loss: 0.1635
Batch 130, Loss: 0.1743
Batch 140, Loss: 0.1727
Batch 150, Loss: 0.1836
Batch 160, Loss: 0.1668
Batch 170, Loss: 0.1890
Batch 180, Loss: 0.1710
Batch 190, Loss: 0.1796
Batch 200, Loss: 0.1745
Batch 210, Loss: 0.1706
Batch 220, Loss: 0.1683
Batch 230, Loss: 0.1720
Batch 240, Loss: 0.1881
Batch 250, Loss: 0.1795
Batch 260, Loss: 0.1739
Batch 270, Loss: 0.1606
Batch 280, Loss: 0.1842
Batch 290, Loss: 0.1893
Batch 300, Loss: 0.1841
Batch 310, Loss: 0.1611
Batch 320, Loss: 0.1806
Batch 330, Loss: 0.1759
Batch 340, Loss: 0.1902
Batch 350, Loss: 0.1939
Batch 360, Loss: 0.1790
Batch 370, Loss: 0.1994
Batch 380, Loss: 0.1968
Batch 390, Loss: 0.1980
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.127876043319702 seconds
Epoch 144 accuracy: 73.82%
Batch 10, Loss: 0.1764
Batch 20, Loss: 0.1701
Batch 30, Loss: 0.1687
Batch 40, Loss: 0.1781
Batch 50, Loss: 0.1594
Batch 60, Loss: 0.1547
Batch 70, Loss: 0.1477
Batch 80, Loss: 0.1750
Batch 90, Loss: 0.1538
Batch 100, Loss: 0.1459
Batch 110, Loss: 0.1494
Batch 120, Loss: 0.1393
Batch 130, Loss: 0.1640
Batch 140, Loss: 0.1560
Batch 150, Loss: 0.1624
Batch 160, Loss: 0.1587
Batch 170, Loss: 0.1594
Batch 180, Loss: 0.1559
Batch 190, Loss: 0.1658
Batch 200, Loss: 0.1592
Batch 210, Loss: 0.1632
Batch 220, Loss: 0.1573
Batch 230, Loss: 0.1621
Batch 240, Loss: 0.1585
Batch 250, Loss: 0.1615
Batch 260, Loss: 0.1631
Batch 270, Loss: 0.1676
Batch 280, Loss: 0.1647
Batch 290, Loss: 0.1598
Batch 300, Loss: 0.1728
Batch 310, Loss: 0.1868
Batch 320, Loss: 0.1814
Batch 330, Loss: 0.1864
Batch 340, Loss: 0.1857
Batch 350, Loss: 0.1846
Batch 360, Loss: 0.1982
Batch 370, Loss: 0.1776
Batch 380, Loss: 0.1779
Batch 390, Loss: 0.1861
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.15053629875183 seconds
Epoch 145 accuracy: 73.61%
Batch 10, Loss: 0.1542
Batch 20, Loss: 0.1552
Batch 30, Loss: 0.1534
Batch 40, Loss: 0.1511
Batch 50, Loss: 0.1552
Batch 60, Loss: 0.1463
Batch 70, Loss: 0.1544
Batch 80, Loss: 0.1433
Batch 90, Loss: 0.1438
Batch 100, Loss: 0.1474
Batch 110, Loss: 0.1339
Batch 120, Loss: 0.1443
Batch 130, Loss: 0.1551
Batch 140, Loss: 0.1429
Batch 150, Loss: 0.1329
Batch 160, Loss: 0.1602
Batch 170, Loss: 0.1504
Batch 180, Loss: 0.1479
Batch 190, Loss: 0.1583
Batch 200, Loss: 0.1681
Batch 210, Loss: 0.1622
Batch 220, Loss: 0.1531
Batch 230, Loss: 0.1589
Batch 240, Loss: 0.1615
Batch 250, Loss: 0.1586
Batch 260, Loss: 0.1748
Batch 270, Loss: 0.1496
Batch 280, Loss: 0.1836
Batch 290, Loss: 0.1683
Batch 300, Loss: 0.1607
Batch 310, Loss: 0.1566
Batch 320, Loss: 0.1537
Batch 330, Loss: 0.1526
Batch 340, Loss: 0.1485
Batch 350, Loss: 0.1745
Batch 360, Loss: 0.1656
Batch 370, Loss: 0.1620
Batch 380, Loss: 0.1615
Batch 390, Loss: 0.1766
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.137595891952515 seconds
Epoch 146 accuracy: 73.67%
Batch 10, Loss: 0.1345
Batch 20, Loss: 0.1366
Batch 30, Loss: 0.1407
Batch 40, Loss: 0.1404
Batch 50, Loss: 0.1500
Batch 60, Loss: 0.1481
Batch 70, Loss: 0.1469
Batch 80, Loss: 0.1471
Batch 90, Loss: 0.1435
Batch 100, Loss: 0.1500
Batch 110, Loss: 0.1376
Batch 120, Loss: 0.1421
Batch 130, Loss: 0.1511
Batch 140, Loss: 0.1436
Batch 150, Loss: 0.1449
Batch 160, Loss: 0.1356
Batch 170, Loss: 0.1339
Batch 180, Loss: 0.1641
Batch 190, Loss: 0.1416
Batch 200, Loss: 0.1527
Batch 210, Loss: 0.1523
Batch 220, Loss: 0.1500
Batch 230, Loss: 0.1536
Batch 240, Loss: 0.1601
Batch 250, Loss: 0.1469
Batch 260, Loss: 0.1593
Batch 270, Loss: 0.1452
Batch 280, Loss: 0.1559
Batch 290, Loss: 0.1636
Batch 300, Loss: 0.1655
Batch 310, Loss: 0.1625
Batch 320, Loss: 0.1629
Batch 330, Loss: 0.1703
Batch 340, Loss: 0.1758
Batch 350, Loss: 0.1630
Batch 360, Loss: 0.1754
Batch 370, Loss: 0.1614
Batch 380, Loss: 0.1627
Batch 390, Loss: 0.1525
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.1680166721344 seconds
Epoch 147 accuracy: 73.81%
Batch 10, Loss: 0.1386
Batch 20, Loss: 0.1302
Batch 30, Loss: 0.1387
Batch 40, Loss: 0.1255
Batch 50, Loss: 0.1438
Batch 60, Loss: 0.1309
Batch 70, Loss: 0.1481
Batch 80, Loss: 0.1485
Batch 90, Loss: 0.1348
Batch 100, Loss: 0.1427
Batch 110, Loss: 0.1286
Batch 120, Loss: 0.1417
Batch 130, Loss: 0.1359
Batch 140, Loss: 0.1521
Batch 150, Loss: 0.1385
Batch 160, Loss: 0.1329
Batch 170, Loss: 0.1378
Batch 180, Loss: 0.1318
Batch 190, Loss: 0.1349
Batch 200, Loss: 0.1437
Batch 210, Loss: 0.1371
Batch 220, Loss: 0.1367
Batch 230, Loss: 0.1444
Batch 240, Loss: 0.1533
Batch 250, Loss: 0.1493
Batch 260, Loss: 0.1467
Batch 270, Loss: 0.1356
Batch 280, Loss: 0.1517
Batch 290, Loss: 0.1506
Batch 300, Loss: 0.1636
Batch 310, Loss: 0.1459
Batch 320, Loss: 0.1419
Batch 330, Loss: 0.1399
Batch 340, Loss: 0.1687
Batch 350, Loss: 0.1549
Batch 360, Loss: 0.1492
Batch 370, Loss: 0.1675
Batch 380, Loss: 0.1386
Batch 390, Loss: 0.1457
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.138543367385864 seconds
Epoch 148 accuracy: 74.44%
Batch 10, Loss: 0.1343
Batch 20, Loss: 0.1302
Batch 30, Loss: 0.1299
Batch 40, Loss: 0.1354
Batch 50, Loss: 0.1406
Batch 60, Loss: 0.1170
Batch 70, Loss: 0.1399
Batch 80, Loss: 0.1244
Batch 90, Loss: 0.1213
Batch 100, Loss: 0.1236
Batch 110, Loss: 0.1221
Batch 120, Loss: 0.1318
Batch 130, Loss: 0.1231
Batch 140, Loss: 0.1306
Batch 150, Loss: 0.1396
Batch 160, Loss: 0.1342
Batch 170, Loss: 0.1203
Batch 180, Loss: 0.1279
Batch 190, Loss: 0.1293
Batch 200, Loss: 0.1379
Batch 210, Loss: 0.1313
Batch 220, Loss: 0.1331
Batch 230, Loss: 0.1356
Batch 240, Loss: 0.1398
Batch 250, Loss: 0.1297
Batch 260, Loss: 0.1339
Batch 270, Loss: 0.1438
Batch 280, Loss: 0.1429
Batch 290, Loss: 0.1276
Batch 300, Loss: 0.1280
Batch 310, Loss: 0.1348
Batch 320, Loss: 0.1349
Batch 330, Loss: 0.1329
Batch 340, Loss: 0.1465
Batch 350, Loss: 0.1293
Batch 360, Loss: 0.1299
Batch 370, Loss: 0.1356
Batch 380, Loss: 0.1333
Batch 390, Loss: 0.1431
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.167213439941406 seconds
Epoch 149 accuracy: 73.34%
Batch 10, Loss: 0.1234
Batch 20, Loss: 0.1278
Batch 30, Loss: 0.1264
Batch 40, Loss: 0.1267
Batch 50, Loss: 0.1235
Batch 60, Loss: 0.1293
Batch 70, Loss: 0.1231
Batch 80, Loss: 0.1279
Batch 90, Loss: 0.1315
Batch 100, Loss: 0.1201
Batch 110, Loss: 0.1309
Batch 120, Loss: 0.1185
Batch 130, Loss: 0.1357
Batch 140, Loss: 0.1266
Batch 150, Loss: 0.1241
Batch 160, Loss: 0.1172
Batch 170, Loss: 0.1227
Batch 180, Loss: 0.1350
Batch 190, Loss: 0.1336
Batch 200, Loss: 0.1333
Batch 210, Loss: 0.1235
Batch 220, Loss: 0.1213
Batch 230, Loss: 0.1331
Batch 240, Loss: 0.1392
Batch 250, Loss: 0.1417
Batch 260, Loss: 0.1358
Batch 270, Loss: 0.1463
Batch 280, Loss: 0.1499
Batch 290, Loss: 0.1344
Batch 300, Loss: 0.1346
Batch 310, Loss: 0.1352
Batch 320, Loss: 0.1453
Batch 330, Loss: 0.1353
Batch 340, Loss: 0.1481
Batch 350, Loss: 0.1382
Batch 360, Loss: 0.1364
Batch 370, Loss: 0.1616
Batch 380, Loss: 0.1442
Batch 390, Loss: 0.1502
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.198160886764526 seconds
Epoch 150 accuracy: 74.57%
Batch 10, Loss: 0.1198
Batch 20, Loss: 0.1223
Batch 30, Loss: 0.1215
Batch 40, Loss: 0.1283
Batch 50, Loss: 0.1195
Batch 60, Loss: 0.1212
Batch 70, Loss: 0.1145
Batch 80, Loss: 0.1125
Batch 90, Loss: 0.1214
Batch 100, Loss: 0.1142
Batch 110, Loss: 0.1280
Batch 120, Loss: 0.1216
Batch 130, Loss: 0.1239
Batch 140, Loss: 0.1190
Batch 150, Loss: 0.1175
Batch 160, Loss: 0.1295
Batch 170, Loss: 0.1148
Batch 180, Loss: 0.1116
Batch 190, Loss: 0.1225
Batch 200, Loss: 0.1194
Batch 210, Loss: 0.1142
Batch 220, Loss: 0.1294
Batch 230, Loss: 0.1236
Batch 240, Loss: 0.1268
Batch 250, Loss: 0.1302
Batch 260, Loss: 0.1266
Batch 270, Loss: 0.1302
Batch 280, Loss: 0.1326
Batch 290, Loss: 0.1309
Batch 300, Loss: 0.1146
Batch 310, Loss: 0.1144
Batch 320, Loss: 0.1335
Batch 330, Loss: 0.1341
Batch 340, Loss: 0.1289
Batch 350, Loss: 0.1301
Batch 360, Loss: 0.1233
Batch 370, Loss: 0.1264
Batch 380, Loss: 0.1278
Batch 390, Loss: 0.1183
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.142661094665527 seconds
Epoch 151 accuracy: 75.24%
Batch 10, Loss: 0.1118
Batch 20, Loss: 0.1044
Batch 30, Loss: 0.1247
Batch 40, Loss: 0.1156
Batch 50, Loss: 0.1223
Batch 60, Loss: 0.1096
Batch 70, Loss: 0.1140
Batch 80, Loss: 0.1229
Batch 90, Loss: 0.1121
Batch 100, Loss: 0.1138
Batch 110, Loss: 0.1073
Batch 120, Loss: 0.1004
Batch 130, Loss: 0.1169
Batch 140, Loss: 0.1147
Batch 150, Loss: 0.1127
Batch 160, Loss: 0.1224
Batch 170, Loss: 0.1084
Batch 180, Loss: 0.1199
Batch 190, Loss: 0.1098
Batch 200, Loss: 0.1143
Batch 210, Loss: 0.1101
Batch 220, Loss: 0.1114
Batch 230, Loss: 0.1129
Batch 240, Loss: 0.1048
Batch 250, Loss: 0.1140
Batch 260, Loss: 0.1072
Batch 270, Loss: 0.1237
Batch 280, Loss: 0.1267
Batch 290, Loss: 0.1145
Batch 300, Loss: 0.1297
Batch 310, Loss: 0.1332
Batch 320, Loss: 0.1205
Batch 330, Loss: 0.1187
Batch 340, Loss: 0.1244
Batch 350, Loss: 0.1202
Batch 360, Loss: 0.1243
Batch 370, Loss: 0.1207
Batch 380, Loss: 0.1233
Batch 390, Loss: 0.1274
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.043233156204224 seconds
Epoch 152 accuracy: 74.5%
Batch 10, Loss: 0.1166
Batch 20, Loss: 0.1248
Batch 30, Loss: 0.1170
Batch 40, Loss: 0.1021
Batch 50, Loss: 0.1045
Batch 60, Loss: 0.1126
Batch 70, Loss: 0.1030
Batch 80, Loss: 0.1087
Batch 90, Loss: 0.1005
Batch 100, Loss: 0.1081
Batch 110, Loss: 0.1093
Batch 120, Loss: 0.1066
Batch 130, Loss: 0.1051
Batch 140, Loss: 0.0965
Batch 150, Loss: 0.0987
Batch 160, Loss: 0.1034
Batch 170, Loss: 0.0982
Batch 180, Loss: 0.1074
Batch 190, Loss: 0.1050
Batch 200, Loss: 0.0979
Batch 210, Loss: 0.1250
Batch 220, Loss: 0.1041
Batch 230, Loss: 0.1133
Batch 240, Loss: 0.1024
Batch 250, Loss: 0.1053
Batch 260, Loss: 0.1110
Batch 270, Loss: 0.1084
Batch 280, Loss: 0.1136
Batch 290, Loss: 0.1156
Batch 300, Loss: 0.1073
Batch 310, Loss: 0.1117
Batch 320, Loss: 0.1155
Batch 330, Loss: 0.1158
Batch 340, Loss: 0.1159
Batch 350, Loss: 0.1174
Batch 360, Loss: 0.1242
Batch 370, Loss: 0.1025
Batch 380, Loss: 0.1116
Batch 390, Loss: 0.1032
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.102900505065918 seconds
Epoch 153 accuracy: 75.28%
Batch 10, Loss: 0.1075
Batch 20, Loss: 0.0989
Batch 30, Loss: 0.0999
Batch 40, Loss: 0.0949
Batch 50, Loss: 0.0988
Batch 60, Loss: 0.0977
Batch 70, Loss: 0.1032
Batch 80, Loss: 0.1106
Batch 90, Loss: 0.1030
Batch 100, Loss: 0.0984
Batch 110, Loss: 0.0936
Batch 120, Loss: 0.0976
Batch 130, Loss: 0.1058
Batch 140, Loss: 0.0982
Batch 150, Loss: 0.0926
Batch 160, Loss: 0.1079
Batch 170, Loss: 0.1013
Batch 180, Loss: 0.1009
Batch 190, Loss: 0.1031
Batch 200, Loss: 0.1029
Batch 210, Loss: 0.1088
Batch 220, Loss: 0.1074
Batch 230, Loss: 0.1057
Batch 240, Loss: 0.0913
Batch 250, Loss: 0.0980
Batch 260, Loss: 0.0996
Batch 270, Loss: 0.1101
Batch 280, Loss: 0.1101
Batch 290, Loss: 0.0897
Batch 300, Loss: 0.0974
Batch 310, Loss: 0.0961
Batch 320, Loss: 0.0950
Batch 330, Loss: 0.0999
Batch 340, Loss: 0.0981
Batch 350, Loss: 0.1074
Batch 360, Loss: 0.1037
Batch 370, Loss: 0.1072
Batch 380, Loss: 0.1088
Batch 390, Loss: 0.1127
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.241923570632935 seconds
Epoch 154 accuracy: 76.08%
Batch 10, Loss: 0.0938
Batch 20, Loss: 0.0931
Batch 30, Loss: 0.1050
Batch 40, Loss: 0.0753
Batch 50, Loss: 0.0945
Batch 60, Loss: 0.0917
Batch 70, Loss: 0.1027
Batch 80, Loss: 0.1045
Batch 90, Loss: 0.0915
Batch 100, Loss: 0.0868
Batch 110, Loss: 0.0915
Batch 120, Loss: 0.0965
Batch 130, Loss: 0.0883
Batch 140, Loss: 0.0973
Batch 150, Loss: 0.0976
Batch 160, Loss: 0.0924
Batch 170, Loss: 0.0876
Batch 180, Loss: 0.0992
Batch 190, Loss: 0.0952
Batch 200, Loss: 0.0885
Batch 210, Loss: 0.0912
Batch 220, Loss: 0.0961
Batch 230, Loss: 0.1100
Batch 240, Loss: 0.0896
Batch 250, Loss: 0.1012
Batch 260, Loss: 0.0992
Batch 270, Loss: 0.0924
Batch 280, Loss: 0.1057
Batch 290, Loss: 0.1084
Batch 300, Loss: 0.1027
Batch 310, Loss: 0.1197
Batch 320, Loss: 0.1027
Batch 330, Loss: 0.0980
Batch 340, Loss: 0.1110
Batch 350, Loss: 0.1094
Batch 360, Loss: 0.1067
Batch 370, Loss: 0.0966
Batch 380, Loss: 0.0959
Batch 390, Loss: 0.0937
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.17663812637329 seconds
Epoch 155 accuracy: 75.51%
Batch 10, Loss: 0.0977
Batch 20, Loss: 0.0884
Batch 30, Loss: 0.0842
Batch 40, Loss: 0.0905
Batch 50, Loss: 0.0912
Batch 60, Loss: 0.0862
Batch 70, Loss: 0.0767
Batch 80, Loss: 0.0824
Batch 90, Loss: 0.0905
Batch 100, Loss: 0.0894
Batch 110, Loss: 0.0857
Batch 120, Loss: 0.0848
Batch 130, Loss: 0.0913
Batch 140, Loss: 0.0886
Batch 150, Loss: 0.0765
Batch 160, Loss: 0.0815
Batch 170, Loss: 0.0849
Batch 180, Loss: 0.0812
Batch 190, Loss: 0.0890
Batch 200, Loss: 0.0821
Batch 210, Loss: 0.0892
Batch 220, Loss: 0.0949
Batch 230, Loss: 0.0988
Batch 240, Loss: 0.0906
Batch 250, Loss: 0.0906
Batch 260, Loss: 0.1011
Batch 270, Loss: 0.0970
Batch 280, Loss: 0.0851
Batch 290, Loss: 0.0929
Batch 300, Loss: 0.0950
Batch 310, Loss: 0.0958
Batch 320, Loss: 0.0895
Batch 330, Loss: 0.0943
Batch 340, Loss: 0.0958
Batch 350, Loss: 0.0942
Batch 360, Loss: 0.1009
Batch 370, Loss: 0.0888
Batch 380, Loss: 0.0955
Batch 390, Loss: 0.1064
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.09191608428955 seconds
Epoch 156 accuracy: 75.93%
Batch 10, Loss: 0.0856
Batch 20, Loss: 0.0903
Batch 30, Loss: 0.0872
Batch 40, Loss: 0.0766
Batch 50, Loss: 0.0854
Batch 60, Loss: 0.0847
Batch 70, Loss: 0.0782
Batch 80, Loss: 0.0768
Batch 90, Loss: 0.0946
Batch 100, Loss: 0.0819
Batch 110, Loss: 0.0880
Batch 120, Loss: 0.0834
Batch 130, Loss: 0.0765
Batch 140, Loss: 0.0851
Batch 150, Loss: 0.0898
Batch 160, Loss: 0.0769
Batch 170, Loss: 0.0890
Batch 180, Loss: 0.0892
Batch 190, Loss: 0.0810
Batch 200, Loss: 0.0909
Batch 210, Loss: 0.0900
Batch 220, Loss: 0.0990
Batch 230, Loss: 0.0923
Batch 240, Loss: 0.1003
Batch 250, Loss: 0.0957
Batch 260, Loss: 0.0834
Batch 270, Loss: 0.0878
Batch 280, Loss: 0.0895
Batch 290, Loss: 0.0857
Batch 300, Loss: 0.0995
Batch 310, Loss: 0.0913
Batch 320, Loss: 0.0984
Batch 330, Loss: 0.0857
Batch 340, Loss: 0.0907
Batch 350, Loss: 0.0952
Batch 360, Loss: 0.0840
Batch 370, Loss: 0.0979
Batch 380, Loss: 0.0867
Batch 390, Loss: 0.0924
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.189865589141846 seconds
Epoch 157 accuracy: 75.89%
Batch 10, Loss: 0.0871
Batch 20, Loss: 0.0837
Batch 30, Loss: 0.0792
Batch 40, Loss: 0.0902
Batch 50, Loss: 0.0771
Batch 60, Loss: 0.0818
Batch 70, Loss: 0.0820
Batch 80, Loss: 0.0850
Batch 90, Loss: 0.0839
Batch 100, Loss: 0.0828
Batch 110, Loss: 0.0815
Batch 120, Loss: 0.0830
Batch 130, Loss: 0.0803
Batch 140, Loss: 0.0946
Batch 150, Loss: 0.0851
Batch 160, Loss: 0.0773
Batch 170, Loss: 0.0876
Batch 180, Loss: 0.0877
Batch 190, Loss: 0.0800
Batch 200, Loss: 0.0936
Batch 210, Loss: 0.0926
Batch 220, Loss: 0.0893
Batch 230, Loss: 0.0824
Batch 240, Loss: 0.0872
Batch 250, Loss: 0.0884
Batch 260, Loss: 0.0787
Batch 270, Loss: 0.0840
Batch 280, Loss: 0.0846
Batch 290, Loss: 0.0777
Batch 300, Loss: 0.0841
Batch 310, Loss: 0.0786
Batch 320, Loss: 0.0820
Batch 330, Loss: 0.0768
Batch 340, Loss: 0.0765
Batch 350, Loss: 0.0829
Batch 360, Loss: 0.0855
Batch 370, Loss: 0.0813
Batch 380, Loss: 0.0854
Batch 390, Loss: 0.0864
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.184641122817993 seconds
Epoch 158 accuracy: 76.23%
Batch 10, Loss: 0.0797
Batch 20, Loss: 0.0792
Batch 30, Loss: 0.0708
Batch 40, Loss: 0.0744
Batch 50, Loss: 0.0822
Batch 60, Loss: 0.0775
Batch 70, Loss: 0.0650
Batch 80, Loss: 0.0710
Batch 90, Loss: 0.0821
Batch 100, Loss: 0.0868
Batch 110, Loss: 0.0748
Batch 120, Loss: 0.0677
Batch 130, Loss: 0.0730
Batch 140, Loss: 0.0782
Batch 150, Loss: 0.0818
Batch 160, Loss: 0.0735
Batch 170, Loss: 0.0716
Batch 180, Loss: 0.0788
Batch 190, Loss: 0.0754
Batch 200, Loss: 0.0744
Batch 210, Loss: 0.0806
Batch 220, Loss: 0.0833
Batch 230, Loss: 0.0737
Batch 240, Loss: 0.0690
Batch 250, Loss: 0.0869
Batch 260, Loss: 0.0871
Batch 270, Loss: 0.0745
Batch 280, Loss: 0.0752
Batch 290, Loss: 0.0817
Batch 300, Loss: 0.0759
Batch 310, Loss: 0.0832
Batch 320, Loss: 0.0858
Batch 330, Loss: 0.0897
Batch 340, Loss: 0.0896
Batch 350, Loss: 0.0819
Batch 360, Loss: 0.0865
Batch 370, Loss: 0.0792
Batch 380, Loss: 0.0762
Batch 390, Loss: 0.0824
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.15486216545105 seconds
Epoch 159 accuracy: 76.74%
Batch 10, Loss: 0.0727
Batch 20, Loss: 0.0724
Batch 30, Loss: 0.0715
Batch 40, Loss: 0.0767
Batch 50, Loss: 0.0687
Batch 60, Loss: 0.0682
Batch 70, Loss: 0.0729
Batch 80, Loss: 0.0700
Batch 90, Loss: 0.0676
Batch 100, Loss: 0.0686
Batch 110, Loss: 0.0745
Batch 120, Loss: 0.0744
Batch 130, Loss: 0.0773
Batch 140, Loss: 0.0731
Batch 150, Loss: 0.0722
Batch 160, Loss: 0.0697
Batch 170, Loss: 0.0673
Batch 180, Loss: 0.0725
Batch 190, Loss: 0.0754
Batch 200, Loss: 0.0750
Batch 210, Loss: 0.0754
Batch 220, Loss: 0.0739
Batch 230, Loss: 0.0774
Batch 240, Loss: 0.0829
Batch 250, Loss: 0.0772
Batch 260, Loss: 0.0713
Batch 270, Loss: 0.0653
Batch 280, Loss: 0.0780
Batch 290, Loss: 0.0816
Batch 300, Loss: 0.0678
Batch 310, Loss: 0.0887
Batch 320, Loss: 0.0793
Batch 330, Loss: 0.0818
Batch 340, Loss: 0.0707
Batch 350, Loss: 0.0780
Batch 360, Loss: 0.0711
Batch 370, Loss: 0.0725
Batch 380, Loss: 0.0752
Batch 390, Loss: 0.0745
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.155309200286865 seconds
Epoch 160 accuracy: 76.55%
Batch 10, Loss: 0.0675
Batch 20, Loss: 0.0751
Batch 30, Loss: 0.0722
Batch 40, Loss: 0.0666
Batch 50, Loss: 0.0655
Batch 60, Loss: 0.0716
Batch 70, Loss: 0.0692
Batch 80, Loss: 0.0707
Batch 90, Loss: 0.0687
Batch 100, Loss: 0.0689
Batch 110, Loss: 0.0684
Batch 120, Loss: 0.0737
Batch 130, Loss: 0.0696
Batch 140, Loss: 0.0680
Batch 150, Loss: 0.0695
Batch 160, Loss: 0.0654
Batch 170, Loss: 0.0683
Batch 180, Loss: 0.0706
Batch 190, Loss: 0.0698
Batch 200, Loss: 0.0654
Batch 210, Loss: 0.0673
Batch 220, Loss: 0.0673
Batch 230, Loss: 0.0646
Batch 240, Loss: 0.0666
Batch 250, Loss: 0.0704
Batch 260, Loss: 0.0732
Batch 270, Loss: 0.0669
Batch 280, Loss: 0.0713
Batch 290, Loss: 0.0739
Batch 300, Loss: 0.0802
Batch 310, Loss: 0.0675
Batch 320, Loss: 0.0747
Batch 330, Loss: 0.0704
Batch 340, Loss: 0.0745
Batch 350, Loss: 0.0684
Batch 360, Loss: 0.0681
Batch 370, Loss: 0.0738
Batch 380, Loss: 0.0710
Batch 390, Loss: 0.0717
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.1574444770813 seconds
Epoch 161 accuracy: 77.04%
Batch 10, Loss: 0.0653
Batch 20, Loss: 0.0695
Batch 30, Loss: 0.0644
Batch 40, Loss: 0.0685
Batch 50, Loss: 0.0652
Batch 60, Loss: 0.0628
Batch 70, Loss: 0.0692
Batch 80, Loss: 0.0631
Batch 90, Loss: 0.0680
Batch 100, Loss: 0.0582
Batch 110, Loss: 0.0616
Batch 120, Loss: 0.0636
Batch 130, Loss: 0.0626
Batch 140, Loss: 0.0637
Batch 150, Loss: 0.0637
Batch 160, Loss: 0.0601
Batch 170, Loss: 0.0682
Batch 180, Loss: 0.0590
Batch 190, Loss: 0.0627
Batch 200, Loss: 0.0624
Batch 210, Loss: 0.0694
Batch 220, Loss: 0.0662
Batch 230, Loss: 0.0738
Batch 240, Loss: 0.0695
Batch 250, Loss: 0.0689
Batch 260, Loss: 0.0783
Batch 270, Loss: 0.0704
Batch 280, Loss: 0.0649
Batch 290, Loss: 0.0720
Batch 300, Loss: 0.0700
Batch 310, Loss: 0.0626
Batch 320, Loss: 0.0615
Batch 330, Loss: 0.0737
Batch 340, Loss: 0.0629
Batch 350, Loss: 0.0665
Batch 360, Loss: 0.0705
Batch 370, Loss: 0.0683
Batch 380, Loss: 0.0618
Batch 390, Loss: 0.0655
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.15580463409424 seconds
Epoch 162 accuracy: 77.16%
Batch 10, Loss: 0.0642
Batch 20, Loss: 0.0686
Batch 30, Loss: 0.0559
Batch 40, Loss: 0.0568
Batch 50, Loss: 0.0689
Batch 60, Loss: 0.0615
Batch 70, Loss: 0.0555
Batch 80, Loss: 0.0626
Batch 90, Loss: 0.0616
Batch 100, Loss: 0.0571
Batch 110, Loss: 0.0673
Batch 120, Loss: 0.0625
Batch 130, Loss: 0.0609
Batch 140, Loss: 0.0581
Batch 150, Loss: 0.0579
Batch 160, Loss: 0.0568
Batch 170, Loss: 0.0648
Batch 180, Loss: 0.0563
Batch 190, Loss: 0.0570
Batch 200, Loss: 0.0621
Batch 210, Loss: 0.0587
Batch 220, Loss: 0.0703
Batch 230, Loss: 0.0576
Batch 240, Loss: 0.0619
Batch 250, Loss: 0.0601
Batch 260, Loss: 0.0555
Batch 270, Loss: 0.0548
Batch 280, Loss: 0.0600
Batch 290, Loss: 0.0636
Batch 300, Loss: 0.0638
Batch 310, Loss: 0.0639
Batch 320, Loss: 0.0735
Batch 330, Loss: 0.0636
Batch 340, Loss: 0.0574
Batch 350, Loss: 0.0599
Batch 360, Loss: 0.0578
Batch 370, Loss: 0.0619
Batch 380, Loss: 0.0654
Batch 390, Loss: 0.0669
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.14387011528015 seconds
Epoch 163 accuracy: 77.66%
Batch 10, Loss: 0.0560
Batch 20, Loss: 0.0576
Batch 30, Loss: 0.0618
Batch 40, Loss: 0.0596
Batch 50, Loss: 0.0502
Batch 60, Loss: 0.0615
Batch 70, Loss: 0.0643
Batch 80, Loss: 0.0603
Batch 90, Loss: 0.0619
Batch 100, Loss: 0.0594
Batch 110, Loss: 0.0563
Batch 120, Loss: 0.0528
Batch 130, Loss: 0.0560
Batch 140, Loss: 0.0502
Batch 150, Loss: 0.0578
Batch 160, Loss: 0.0535
Batch 170, Loss: 0.0545
Batch 180, Loss: 0.0637
Batch 190, Loss: 0.0545
Batch 200, Loss: 0.0599
Batch 210, Loss: 0.0564
Batch 220, Loss: 0.0547
Batch 230, Loss: 0.0651
Batch 240, Loss: 0.0584
Batch 250, Loss: 0.0584
Batch 260, Loss: 0.0577
Batch 270, Loss: 0.0608
Batch 280, Loss: 0.0568
Batch 290, Loss: 0.0522
Batch 300, Loss: 0.0549
Batch 310, Loss: 0.0634
Batch 320, Loss: 0.0557
Batch 330, Loss: 0.0557
Batch 340, Loss: 0.0612
Batch 350, Loss: 0.0575
Batch 360, Loss: 0.0554
Batch 370, Loss: 0.0594
Batch 380, Loss: 0.0581
Batch 390, Loss: 0.0635
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.12752652168274 seconds
Epoch 164 accuracy: 77.82%
Batch 10, Loss: 0.0555
Batch 20, Loss: 0.0505
Batch 30, Loss: 0.0513
Batch 40, Loss: 0.0506
Batch 50, Loss: 0.0526
Batch 60, Loss: 0.0516
Batch 70, Loss: 0.0511
Batch 80, Loss: 0.0519
Batch 90, Loss: 0.0579
Batch 100, Loss: 0.0492
Batch 110, Loss: 0.0484
Batch 120, Loss: 0.0571
Batch 130, Loss: 0.0509
Batch 140, Loss: 0.0509
Batch 150, Loss: 0.0531
Batch 160, Loss: 0.0491
Batch 170, Loss: 0.0515
Batch 180, Loss: 0.0499
Batch 190, Loss: 0.0482
Batch 200, Loss: 0.0537
Batch 210, Loss: 0.0517
Batch 220, Loss: 0.0551
Batch 230, Loss: 0.0509
Batch 240, Loss: 0.0563
Batch 250, Loss: 0.0613
Batch 260, Loss: 0.0557
Batch 270, Loss: 0.0518
Batch 280, Loss: 0.0506
Batch 290, Loss: 0.0556
Batch 300, Loss: 0.0526
Batch 310, Loss: 0.0613
Batch 320, Loss: 0.0483
Batch 330, Loss: 0.0511
Batch 340, Loss: 0.0553
Batch 350, Loss: 0.0562
Batch 360, Loss: 0.0605
Batch 370, Loss: 0.0536
Batch 380, Loss: 0.0554
Batch 390, Loss: 0.0618
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.067371606826782 seconds
Epoch 165 accuracy: 77.54%
Batch 10, Loss: 0.0522
Batch 20, Loss: 0.0541
Batch 30, Loss: 0.0559
Batch 40, Loss: 0.0555
Batch 50, Loss: 0.0529
Batch 60, Loss: 0.0570
Batch 70, Loss: 0.0513
Batch 80, Loss: 0.0534
Batch 90, Loss: 0.0539
Batch 100, Loss: 0.0472
Batch 110, Loss: 0.0510
Batch 120, Loss: 0.0489
Batch 130, Loss: 0.0519
Batch 140, Loss: 0.0558
Batch 150, Loss: 0.0459
Batch 160, Loss: 0.0417
Batch 170, Loss: 0.0531
Batch 180, Loss: 0.0480
Batch 190, Loss: 0.0492
Batch 200, Loss: 0.0513
Batch 210, Loss: 0.0491
Batch 220, Loss: 0.0557
Batch 230, Loss: 0.0476
Batch 240, Loss: 0.0521
Batch 250, Loss: 0.0496
Batch 260, Loss: 0.0512
Batch 270, Loss: 0.0563
Batch 280, Loss: 0.0526
Batch 290, Loss: 0.0505
Batch 300, Loss: 0.0594
Batch 310, Loss: 0.0516
Batch 320, Loss: 0.0517
Batch 330, Loss: 0.0514
Batch 340, Loss: 0.0553
Batch 350, Loss: 0.0660
Batch 360, Loss: 0.0601
Batch 370, Loss: 0.0559
Batch 380, Loss: 0.0513
Batch 390, Loss: 0.0505
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.166006565093994 seconds
Epoch 166 accuracy: 77.71%
Batch 10, Loss: 0.0498
Batch 20, Loss: 0.0511
Batch 30, Loss: 0.0432
Batch 40, Loss: 0.0551
Batch 50, Loss: 0.0453
Batch 60, Loss: 0.0500
Batch 70, Loss: 0.0463
Batch 80, Loss: 0.0454
Batch 90, Loss: 0.0531
Batch 100, Loss: 0.0409
Batch 110, Loss: 0.0486
Batch 120, Loss: 0.0479
Batch 130, Loss: 0.0534
Batch 140, Loss: 0.0457
Batch 150, Loss: 0.0542
Batch 160, Loss: 0.0501
Batch 170, Loss: 0.0513
Batch 180, Loss: 0.0533
Batch 190, Loss: 0.0469
Batch 200, Loss: 0.0519
Batch 210, Loss: 0.0530
Batch 220, Loss: 0.0466
Batch 230, Loss: 0.0430
Batch 240, Loss: 0.0533
Batch 250, Loss: 0.0447
Batch 260, Loss: 0.0562
Batch 270, Loss: 0.0478
Batch 280, Loss: 0.0501
Batch 290, Loss: 0.0520
Batch 300, Loss: 0.0458
Batch 310, Loss: 0.0500
Batch 320, Loss: 0.0483
Batch 330, Loss: 0.0472
Batch 340, Loss: 0.0441
Batch 350, Loss: 0.0457
Batch 360, Loss: 0.0474
Batch 370, Loss: 0.0474
Batch 380, Loss: 0.0527
Batch 390, Loss: 0.0501
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.071905374526978 seconds
Epoch 167 accuracy: 77.96%
Batch 10, Loss: 0.0377
Batch 20, Loss: 0.0403
Batch 30, Loss: 0.0451
Batch 40, Loss: 0.0455
Batch 50, Loss: 0.0465
Batch 60, Loss: 0.0413
Batch 70, Loss: 0.0431
Batch 80, Loss: 0.0439
Batch 90, Loss: 0.0440
Batch 100, Loss: 0.0428
Batch 110, Loss: 0.0438
Batch 120, Loss: 0.0514
Batch 130, Loss: 0.0475
Batch 140, Loss: 0.0449
Batch 150, Loss: 0.0457
Batch 160, Loss: 0.0436
Batch 170, Loss: 0.0467
Batch 180, Loss: 0.0420
Batch 190, Loss: 0.0463
Batch 200, Loss: 0.0408
Batch 210, Loss: 0.0457
Batch 220, Loss: 0.0468
Batch 230, Loss: 0.0471
Batch 240, Loss: 0.0391
Batch 250, Loss: 0.0466
Batch 260, Loss: 0.0400
Batch 270, Loss: 0.0450
Batch 280, Loss: 0.0452
Batch 290, Loss: 0.0435
Batch 300, Loss: 0.0479
Batch 310, Loss: 0.0480
Batch 320, Loss: 0.0409
Batch 330, Loss: 0.0534
Batch 340, Loss: 0.0438
Batch 350, Loss: 0.0458
Batch 360, Loss: 0.0436
Batch 370, Loss: 0.0474
Batch 380, Loss: 0.0486
Batch 390, Loss: 0.0444
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.157771587371826 seconds
Epoch 168 accuracy: 78.06%
Batch 10, Loss: 0.0436
Batch 20, Loss: 0.0420
Batch 30, Loss: 0.0397
Batch 40, Loss: 0.0460
Batch 50, Loss: 0.0431
Batch 60, Loss: 0.0415
Batch 70, Loss: 0.0483
Batch 80, Loss: 0.0410
Batch 90, Loss: 0.0395
Batch 100, Loss: 0.0433
Batch 110, Loss: 0.0435
Batch 120, Loss: 0.0434
Batch 130, Loss: 0.0498
Batch 140, Loss: 0.0472
Batch 150, Loss: 0.0497
Batch 160, Loss: 0.0443
Batch 170, Loss: 0.0477
Batch 180, Loss: 0.0478
Batch 190, Loss: 0.0427
Batch 200, Loss: 0.0540
Batch 210, Loss: 0.0491
Batch 220, Loss: 0.0387
Batch 230, Loss: 0.0496
Batch 240, Loss: 0.0471
Batch 250, Loss: 0.0466
Batch 260, Loss: 0.0463
Batch 270, Loss: 0.0448
Batch 280, Loss: 0.0414
Batch 290, Loss: 0.0435
Batch 300, Loss: 0.0451
Batch 310, Loss: 0.0441
Batch 320, Loss: 0.0483
Batch 330, Loss: 0.0461
Batch 340, Loss: 0.0462
Batch 350, Loss: 0.0439
Batch 360, Loss: 0.0465
Batch 370, Loss: 0.0380
Batch 380, Loss: 0.0480
Batch 390, Loss: 0.0465
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.075005054473877 seconds
Epoch 169 accuracy: 78.19%
Batch 10, Loss: 0.0429
Batch 20, Loss: 0.0427
Batch 30, Loss: 0.0443
Batch 40, Loss: 0.0414
Batch 50, Loss: 0.0460
Batch 60, Loss: 0.0433
Batch 70, Loss: 0.0419
Batch 80, Loss: 0.0393
Batch 90, Loss: 0.0463
Batch 100, Loss: 0.0406
Batch 110, Loss: 0.0431
Batch 120, Loss: 0.0373
Batch 130, Loss: 0.0418
Batch 140, Loss: 0.0382
Batch 150, Loss: 0.0426
Batch 160, Loss: 0.0496
Batch 170, Loss: 0.0413
Batch 180, Loss: 0.0413
Batch 190, Loss: 0.0370
Batch 200, Loss: 0.0396
Batch 210, Loss: 0.0418
Batch 220, Loss: 0.0375
Batch 230, Loss: 0.0388
Batch 240, Loss: 0.0446
Batch 250, Loss: 0.0404
Batch 260, Loss: 0.0419
Batch 270, Loss: 0.0379
Batch 280, Loss: 0.0384
Batch 290, Loss: 0.0427
Batch 300, Loss: 0.0382
Batch 310, Loss: 0.0346
Batch 320, Loss: 0.0432
Batch 330, Loss: 0.0405
Batch 340, Loss: 0.0437
Batch 350, Loss: 0.0481
Batch 360, Loss: 0.0413
Batch 370, Loss: 0.0435
Batch 380, Loss: 0.0378
Batch 390, Loss: 0.0438
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.148863792419434 seconds
Epoch 170 accuracy: 78.33%
Batch 10, Loss: 0.0456
Batch 20, Loss: 0.0365
Batch 30, Loss: 0.0403
Batch 40, Loss: 0.0440
Batch 50, Loss: 0.0379
Batch 60, Loss: 0.0387
Batch 70, Loss: 0.0386
Batch 80, Loss: 0.0384
Batch 90, Loss: 0.0427
Batch 100, Loss: 0.0366
Batch 110, Loss: 0.0373
Batch 120, Loss: 0.0380
Batch 130, Loss: 0.0362
Batch 140, Loss: 0.0377
Batch 150, Loss: 0.0394
Batch 160, Loss: 0.0368
Batch 170, Loss: 0.0431
Batch 180, Loss: 0.0383
Batch 190, Loss: 0.0449
Batch 200, Loss: 0.0365
Batch 210, Loss: 0.0459
Batch 220, Loss: 0.0405
Batch 230, Loss: 0.0359
Batch 240, Loss: 0.0443
Batch 250, Loss: 0.0417
Batch 260, Loss: 0.0391
Batch 270, Loss: 0.0395
Batch 280, Loss: 0.0383
Batch 290, Loss: 0.0386
Batch 300, Loss: 0.0354
Batch 310, Loss: 0.0386
Batch 320, Loss: 0.0391
Batch 330, Loss: 0.0387
Batch 340, Loss: 0.0455
Batch 350, Loss: 0.0376
Batch 360, Loss: 0.0452
Batch 370, Loss: 0.0431
Batch 380, Loss: 0.0408
Batch 390, Loss: 0.0442
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.1557879447937 seconds
Epoch 171 accuracy: 78.54%
Batch 10, Loss: 0.0346
Batch 20, Loss: 0.0382
Batch 30, Loss: 0.0398
Batch 40, Loss: 0.0371
Batch 50, Loss: 0.0388
Batch 60, Loss: 0.0334
Batch 70, Loss: 0.0356
Batch 80, Loss: 0.0404
Batch 90, Loss: 0.0398
Batch 100, Loss: 0.0412
Batch 110, Loss: 0.0374
Batch 120, Loss: 0.0347
Batch 130, Loss: 0.0354
Batch 140, Loss: 0.0353
Batch 150, Loss: 0.0399
Batch 160, Loss: 0.0432
Batch 170, Loss: 0.0365
Batch 180, Loss: 0.0354
Batch 190, Loss: 0.0380
Batch 200, Loss: 0.0406
Batch 210, Loss: 0.0361
Batch 220, Loss: 0.0465
Batch 230, Loss: 0.0415
Batch 240, Loss: 0.0376
Batch 250, Loss: 0.0415
Batch 260, Loss: 0.0350
Batch 270, Loss: 0.0358
Batch 280, Loss: 0.0381
Batch 290, Loss: 0.0357
Batch 300, Loss: 0.0445
Batch 310, Loss: 0.0401
Batch 320, Loss: 0.0378
Batch 330, Loss: 0.0384
Batch 340, Loss: 0.0362
Batch 350, Loss: 0.0329
Batch 360, Loss: 0.0383
Batch 370, Loss: 0.0402
Batch 380, Loss: 0.0443
Batch 390, Loss: 0.0324
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.128188133239746 seconds
Epoch 172 accuracy: 78.61%
Batch 10, Loss: 0.0355
Batch 20, Loss: 0.0345
Batch 30, Loss: 0.0324
Batch 40, Loss: 0.0363
Batch 50, Loss: 0.0377
Batch 60, Loss: 0.0398
Batch 70, Loss: 0.0339
Batch 80, Loss: 0.0369
Batch 90, Loss: 0.0366
Batch 100, Loss: 0.0360
Batch 110, Loss: 0.0362
Batch 120, Loss: 0.0370
Batch 130, Loss: 0.0363
Batch 140, Loss: 0.0368
Batch 150, Loss: 0.0356
Batch 160, Loss: 0.0354
Batch 170, Loss: 0.0335
Batch 180, Loss: 0.0359
Batch 190, Loss: 0.0331
Batch 200, Loss: 0.0374
Batch 210, Loss: 0.0326
Batch 220, Loss: 0.0321
Batch 230, Loss: 0.0340
Batch 240, Loss: 0.0317
Batch 250, Loss: 0.0361
Batch 260, Loss: 0.0346
Batch 270, Loss: 0.0356
Batch 280, Loss: 0.0378
Batch 290, Loss: 0.0329
Batch 300, Loss: 0.0349
Batch 310, Loss: 0.0329
Batch 320, Loss: 0.0368
Batch 330, Loss: 0.0353
Batch 340, Loss: 0.0391
Batch 350, Loss: 0.0363
Batch 360, Loss: 0.0421
Batch 370, Loss: 0.0434
Batch 380, Loss: 0.0354
Batch 390, Loss: 0.0393
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.196455001831055 seconds
Epoch 173 accuracy: 78.54%
Batch 10, Loss: 0.0351
Batch 20, Loss: 0.0343
Batch 30, Loss: 0.0343
Batch 40, Loss: 0.0359
Batch 50, Loss: 0.0360
Batch 60, Loss: 0.0320
Batch 70, Loss: 0.0392
Batch 80, Loss: 0.0329
Batch 90, Loss: 0.0379
Batch 100, Loss: 0.0339
Batch 110, Loss: 0.0399
Batch 120, Loss: 0.0330
Batch 130, Loss: 0.0347
Batch 140, Loss: 0.0320
Batch 150, Loss: 0.0359
Batch 160, Loss: 0.0338
Batch 170, Loss: 0.0339
Batch 180, Loss: 0.0304
Batch 190, Loss: 0.0312
Batch 200, Loss: 0.0387
Batch 210, Loss: 0.0305
Batch 220, Loss: 0.0328
Batch 230, Loss: 0.0326
Batch 240, Loss: 0.0341
Batch 250, Loss: 0.0322
Batch 260, Loss: 0.0383
Batch 270, Loss: 0.0366
Batch 280, Loss: 0.0324
Batch 290, Loss: 0.0328
Batch 300, Loss: 0.0324
Batch 310, Loss: 0.0322
Batch 320, Loss: 0.0340
Batch 330, Loss: 0.0330
Batch 340, Loss: 0.0332
Batch 350, Loss: 0.0319
Batch 360, Loss: 0.0367
Batch 370, Loss: 0.0312
Batch 380, Loss: 0.0342
Batch 390, Loss: 0.0305
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.09986639022827 seconds
Epoch 174 accuracy: 78.61%
Batch 10, Loss: 0.0351
Batch 20, Loss: 0.0331
Batch 30, Loss: 0.0318
Batch 40, Loss: 0.0322
Batch 50, Loss: 0.0309
Batch 60, Loss: 0.0369
Batch 70, Loss: 0.0309
Batch 80, Loss: 0.0321
Batch 90, Loss: 0.0312
Batch 100, Loss: 0.0316
Batch 110, Loss: 0.0297
Batch 120, Loss: 0.0322
Batch 130, Loss: 0.0329
Batch 140, Loss: 0.0389
Batch 150, Loss: 0.0313
Batch 160, Loss: 0.0332
Batch 170, Loss: 0.0324
Batch 180, Loss: 0.0303
Batch 190, Loss: 0.0326
Batch 200, Loss: 0.0320
Batch 210, Loss: 0.0313
Batch 220, Loss: 0.0367
Batch 230, Loss: 0.0341
Batch 240, Loss: 0.0357
Batch 250, Loss: 0.0354
Batch 260, Loss: 0.0352
Batch 270, Loss: 0.0301
Batch 280, Loss: 0.0371
Batch 290, Loss: 0.0351
Batch 300, Loss: 0.0333
Batch 310, Loss: 0.0351
Batch 320, Loss: 0.0327
Batch 330, Loss: 0.0339
Batch 340, Loss: 0.0303
Batch 350, Loss: 0.0343
Batch 360, Loss: 0.0318
Batch 370, Loss: 0.0378
Batch 380, Loss: 0.0335
Batch 390, Loss: 0.0353
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.138110637664795 seconds
Epoch 175 accuracy: 79.12%
Batch 10, Loss: 0.0376
Batch 20, Loss: 0.0304
Batch 30, Loss: 0.0309
Batch 40, Loss: 0.0318
Batch 50, Loss: 0.0321
Batch 60, Loss: 0.0312
Batch 70, Loss: 0.0311
Batch 80, Loss: 0.0334
Batch 90, Loss: 0.0296
Batch 100, Loss: 0.0294
Batch 110, Loss: 0.0292
Batch 120, Loss: 0.0304
Batch 130, Loss: 0.0295
Batch 140, Loss: 0.0333
Batch 150, Loss: 0.0329
Batch 160, Loss: 0.0310
Batch 170, Loss: 0.0315
Batch 180, Loss: 0.0302
Batch 190, Loss: 0.0388
Batch 200, Loss: 0.0302
Batch 210, Loss: 0.0316
Batch 220, Loss: 0.0317
Batch 230, Loss: 0.0344
Batch 240, Loss: 0.0340
Batch 250, Loss: 0.0302
Batch 260, Loss: 0.0316
Batch 270, Loss: 0.0297
Batch 280, Loss: 0.0291
Batch 290, Loss: 0.0332
Batch 300, Loss: 0.0325
Batch 310, Loss: 0.0266
Batch 320, Loss: 0.0319
Batch 330, Loss: 0.0347
Batch 340, Loss: 0.0306
Batch 350, Loss: 0.0301
Batch 360, Loss: 0.0326
Batch 370, Loss: 0.0346
Batch 380, Loss: 0.0334
Batch 390, Loss: 0.0305
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.055994749069214 seconds
Epoch 176 accuracy: 79.2%
Batch 10, Loss: 0.0271
Batch 20, Loss: 0.0288
Batch 30, Loss: 0.0258
Batch 40, Loss: 0.0255
Batch 50, Loss: 0.0297
Batch 60, Loss: 0.0276
Batch 70, Loss: 0.0323
Batch 80, Loss: 0.0272
Batch 90, Loss: 0.0300
Batch 100, Loss: 0.0291
Batch 110, Loss: 0.0297
Batch 120, Loss: 0.0270
Batch 130, Loss: 0.0280
Batch 140, Loss: 0.0343
Batch 150, Loss: 0.0317
Batch 160, Loss: 0.0330
Batch 170, Loss: 0.0306
Batch 180, Loss: 0.0284
Batch 190, Loss: 0.0297
Batch 200, Loss: 0.0320
Batch 210, Loss: 0.0345
Batch 220, Loss: 0.0302
Batch 230, Loss: 0.0298
Batch 240, Loss: 0.0291
Batch 250, Loss: 0.0323
Batch 260, Loss: 0.0337
Batch 270, Loss: 0.0316
Batch 280, Loss: 0.0344
Batch 290, Loss: 0.0280
Batch 300, Loss: 0.0326
Batch 310, Loss: 0.0346
Batch 320, Loss: 0.0298
Batch 330, Loss: 0.0286
Batch 340, Loss: 0.0342
Batch 350, Loss: 0.0280
Batch 360, Loss: 0.0298
Batch 370, Loss: 0.0268
Batch 380, Loss: 0.0309
Batch 390, Loss: 0.0312
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.080066442489624 seconds
Epoch 177 accuracy: 79.14%
Batch 10, Loss: 0.0295
Batch 20, Loss: 0.0323
Batch 30, Loss: 0.0297
Batch 40, Loss: 0.0256
Batch 50, Loss: 0.0280
Batch 60, Loss: 0.0347
Batch 70, Loss: 0.0300
Batch 80, Loss: 0.0267
Batch 90, Loss: 0.0276
Batch 100, Loss: 0.0298
Batch 110, Loss: 0.0278
Batch 120, Loss: 0.0257
Batch 130, Loss: 0.0291
Batch 140, Loss: 0.0280
Batch 150, Loss: 0.0293
Batch 160, Loss: 0.0297
Batch 170, Loss: 0.0283
Batch 180, Loss: 0.0295
Batch 190, Loss: 0.0274
Batch 200, Loss: 0.0358
Batch 210, Loss: 0.0286
Batch 220, Loss: 0.0310
Batch 230, Loss: 0.0308
Batch 240, Loss: 0.0291
Batch 250, Loss: 0.0265
Batch 260, Loss: 0.0312
Batch 270, Loss: 0.0303
Batch 280, Loss: 0.0330
Batch 290, Loss: 0.0287
Batch 300, Loss: 0.0306
Batch 310, Loss: 0.0298
Batch 320, Loss: 0.0268
Batch 330, Loss: 0.0316
Batch 340, Loss: 0.0288
Batch 350, Loss: 0.0274
Batch 360, Loss: 0.0291
Batch 370, Loss: 0.0296
Batch 380, Loss: 0.0271
Batch 390, Loss: 0.0282
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.04226517677307 seconds
Epoch 178 accuracy: 79.14%
Batch 10, Loss: 0.0261
Batch 20, Loss: 0.0255
Batch 30, Loss: 0.0338
Batch 40, Loss: 0.0326
Batch 50, Loss: 0.0301
Batch 60, Loss: 0.0274
Batch 70, Loss: 0.0272
Batch 80, Loss: 0.0286
Batch 90, Loss: 0.0275
Batch 100, Loss: 0.0304
Batch 110, Loss: 0.0270
Batch 120, Loss: 0.0279
Batch 130, Loss: 0.0296
Batch 140, Loss: 0.0294
Batch 150, Loss: 0.0263
Batch 160, Loss: 0.0291
Batch 170, Loss: 0.0311
Batch 180, Loss: 0.0300
Batch 190, Loss: 0.0302
Batch 200, Loss: 0.0280
Batch 210, Loss: 0.0262
Batch 220, Loss: 0.0291
Batch 230, Loss: 0.0298
Batch 240, Loss: 0.0292
Batch 250, Loss: 0.0273
Batch 260, Loss: 0.0318
Batch 270, Loss: 0.0321
Batch 280, Loss: 0.0300
Batch 290, Loss: 0.0303
Batch 300, Loss: 0.0347
Batch 310, Loss: 0.0293
Batch 320, Loss: 0.0279
Batch 330, Loss: 0.0310
Batch 340, Loss: 0.0256
Batch 350, Loss: 0.0276
Batch 360, Loss: 0.0274
Batch 370, Loss: 0.0310
Batch 380, Loss: 0.0295
Batch 390, Loss: 0.0307
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.027578830718994 seconds
Epoch 179 accuracy: 79.41%
Batch 10, Loss: 0.0300
Batch 20, Loss: 0.0284
Batch 30, Loss: 0.0252
Batch 40, Loss: 0.0253
Batch 50, Loss: 0.0257
Batch 60, Loss: 0.0270
Batch 70, Loss: 0.0330
Batch 80, Loss: 0.0280
Batch 90, Loss: 0.0271
Batch 100, Loss: 0.0243
Batch 110, Loss: 0.0318
Batch 120, Loss: 0.0286
Batch 130, Loss: 0.0294
Batch 140, Loss: 0.0292
Batch 150, Loss: 0.0303
Batch 160, Loss: 0.0280
Batch 170, Loss: 0.0269
Batch 180, Loss: 0.0289
Batch 190, Loss: 0.0245
Batch 200, Loss: 0.0314
Batch 210, Loss: 0.0274
Batch 220, Loss: 0.0237
Batch 230, Loss: 0.0263
Batch 240, Loss: 0.0332
Batch 250, Loss: 0.0294
Batch 260, Loss: 0.0283
Batch 270, Loss: 0.0267
Batch 280, Loss: 0.0253
Batch 290, Loss: 0.0251
Batch 300, Loss: 0.0299
Batch 310, Loss: 0.0257
Batch 320, Loss: 0.0273
Batch 330, Loss: 0.0280
Batch 340, Loss: 0.0286
Batch 350, Loss: 0.0282
Batch 360, Loss: 0.0288
Batch 370, Loss: 0.0243
Batch 380, Loss: 0.0307
Batch 390, Loss: 0.0274
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.223787307739258 seconds
Epoch 180 accuracy: 79.18%
Batch 10, Loss: 0.0274
Batch 20, Loss: 0.0258
Batch 30, Loss: 0.0270
Batch 40, Loss: 0.0295
Batch 50, Loss: 0.0231
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0251
Batch 80, Loss: 0.0245
Batch 90, Loss: 0.0307
Batch 100, Loss: 0.0283
Batch 110, Loss: 0.0290
Batch 120, Loss: 0.0267
Batch 130, Loss: 0.0260
Batch 140, Loss: 0.0239
Batch 150, Loss: 0.0266
Batch 160, Loss: 0.0271
Batch 170, Loss: 0.0303
Batch 180, Loss: 0.0296
Batch 190, Loss: 0.0267
Batch 200, Loss: 0.0259
Batch 210, Loss: 0.0284
Batch 220, Loss: 0.0281
Batch 230, Loss: 0.0271
Batch 240, Loss: 0.0254
Batch 250, Loss: 0.0247
Batch 260, Loss: 0.0276
Batch 270, Loss: 0.0286
Batch 280, Loss: 0.0250
Batch 290, Loss: 0.0286
Batch 300, Loss: 0.0267
Batch 310, Loss: 0.0284
Batch 320, Loss: 0.0242
Batch 330, Loss: 0.0274
Batch 340, Loss: 0.0249
Batch 350, Loss: 0.0277
Batch 360, Loss: 0.0277
Batch 370, Loss: 0.0290
Batch 380, Loss: 0.0268
Batch 390, Loss: 0.0296
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.073091983795166 seconds
Epoch 181 accuracy: 79.14%
Batch 10, Loss: 0.0255
Batch 20, Loss: 0.0272
Batch 30, Loss: 0.0276
Batch 40, Loss: 0.0263
Batch 50, Loss: 0.0268
Batch 60, Loss: 0.0271
Batch 70, Loss: 0.0251
Batch 80, Loss: 0.0219
Batch 90, Loss: 0.0254
Batch 100, Loss: 0.0247
Batch 110, Loss: 0.0249
Batch 120, Loss: 0.0308
Batch 130, Loss: 0.0269
Batch 140, Loss: 0.0244
Batch 150, Loss: 0.0297
Batch 160, Loss: 0.0237
Batch 170, Loss: 0.0273
Batch 180, Loss: 0.0260
Batch 190, Loss: 0.0291
Batch 200, Loss: 0.0242
Batch 210, Loss: 0.0271
Batch 220, Loss: 0.0251
Batch 230, Loss: 0.0273
Batch 240, Loss: 0.0235
Batch 250, Loss: 0.0253
Batch 260, Loss: 0.0268
Batch 270, Loss: 0.0255
Batch 280, Loss: 0.0264
Batch 290, Loss: 0.0275
Batch 300, Loss: 0.0299
Batch 310, Loss: 0.0290
Batch 320, Loss: 0.0238
Batch 330, Loss: 0.0260
Batch 340, Loss: 0.0236
Batch 350, Loss: 0.0259
Batch 360, Loss: 0.0256
Batch 370, Loss: 0.0230
Batch 380, Loss: 0.0271
Batch 390, Loss: 0.0268
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.090996265411377 seconds
Epoch 182 accuracy: 79.44%
Batch 10, Loss: 0.0263
Batch 20, Loss: 0.0300
Batch 30, Loss: 0.0291
Batch 40, Loss: 0.0279
Batch 50, Loss: 0.0237
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0239
Batch 80, Loss: 0.0278
Batch 90, Loss: 0.0243
Batch 100, Loss: 0.0286
Batch 110, Loss: 0.0283
Batch 120, Loss: 0.0265
Batch 130, Loss: 0.0261
Batch 140, Loss: 0.0264
Batch 150, Loss: 0.0268
Batch 160, Loss: 0.0255
Batch 170, Loss: 0.0274
Batch 180, Loss: 0.0235
Batch 190, Loss: 0.0239
Batch 200, Loss: 0.0255
Batch 210, Loss: 0.0268
Batch 220, Loss: 0.0255
Batch 230, Loss: 0.0253
Batch 240, Loss: 0.0269
Batch 250, Loss: 0.0249
Batch 260, Loss: 0.0275
Batch 270, Loss: 0.0241
Batch 280, Loss: 0.0278
Batch 290, Loss: 0.0301
Batch 300, Loss: 0.0292
Batch 310, Loss: 0.0247
Batch 320, Loss: 0.0257
Batch 330, Loss: 0.0248
Batch 340, Loss: 0.0247
Batch 350, Loss: 0.0257
Batch 360, Loss: 0.0264
Batch 370, Loss: 0.0257
Batch 380, Loss: 0.0249
Batch 390, Loss: 0.0262
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.019779443740845 seconds
Epoch 183 accuracy: 79.43%
Batch 10, Loss: 0.0228
Batch 20, Loss: 0.0270
Batch 30, Loss: 0.0222
Batch 40, Loss: 0.0251
Batch 50, Loss: 0.0273
Batch 60, Loss: 0.0256
Batch 70, Loss: 0.0257
Batch 80, Loss: 0.0278
Batch 90, Loss: 0.0251
Batch 100, Loss: 0.0245
Batch 110, Loss: 0.0240
Batch 120, Loss: 0.0289
Batch 130, Loss: 0.0235
Batch 140, Loss: 0.0264
Batch 150, Loss: 0.0266
Batch 160, Loss: 0.0257
Batch 170, Loss: 0.0236
Batch 180, Loss: 0.0247
Batch 190, Loss: 0.0279
Batch 200, Loss: 0.0263
Batch 210, Loss: 0.0237
Batch 220, Loss: 0.0236
Batch 230, Loss: 0.0250
Batch 240, Loss: 0.0279
Batch 250, Loss: 0.0278
Batch 260, Loss: 0.0225
Batch 270, Loss: 0.0269
Batch 280, Loss: 0.0243
Batch 290, Loss: 0.0251
Batch 300, Loss: 0.0236
Batch 310, Loss: 0.0241
Batch 320, Loss: 0.0273
Batch 330, Loss: 0.0240
Batch 340, Loss: 0.0253
Batch 350, Loss: 0.0260
Batch 360, Loss: 0.0284
Batch 370, Loss: 0.0254
Batch 380, Loss: 0.0289
Batch 390, Loss: 0.0263
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.230336666107178 seconds
Epoch 184 accuracy: 79.49%
Batch 10, Loss: 0.0244
Batch 20, Loss: 0.0245
Batch 30, Loss: 0.0233
Batch 40, Loss: 0.0223
Batch 50, Loss: 0.0237
Batch 60, Loss: 0.0251
Batch 70, Loss: 0.0234
Batch 80, Loss: 0.0240
Batch 90, Loss: 0.0263
Batch 100, Loss: 0.0253
Batch 110, Loss: 0.0247
Batch 120, Loss: 0.0234
Batch 130, Loss: 0.0228
Batch 140, Loss: 0.0210
Batch 150, Loss: 0.0267
Batch 160, Loss: 0.0266
Batch 170, Loss: 0.0249
Batch 180, Loss: 0.0287
Batch 190, Loss: 0.0236
Batch 200, Loss: 0.0251
Batch 210, Loss: 0.0256
Batch 220, Loss: 0.0223
Batch 230, Loss: 0.0260
Batch 240, Loss: 0.0245
Batch 250, Loss: 0.0242
Batch 260, Loss: 0.0225
Batch 270, Loss: 0.0251
Batch 280, Loss: 0.0275
Batch 290, Loss: 0.0230
Batch 300, Loss: 0.0237
Batch 310, Loss: 0.0272
Batch 320, Loss: 0.0282
Batch 330, Loss: 0.0241
Batch 340, Loss: 0.0265
Batch 350, Loss: 0.0252
Batch 360, Loss: 0.0263
Batch 370, Loss: 0.0265
Batch 380, Loss: 0.0256
Batch 390, Loss: 0.0221
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.13517999649048 seconds
Epoch 185 accuracy: 79.6%
Batch 10, Loss: 0.0232
Batch 20, Loss: 0.0246
Batch 30, Loss: 0.0244
Batch 40, Loss: 0.0236
Batch 50, Loss: 0.0249
Batch 60, Loss: 0.0212
Batch 70, Loss: 0.0251
Batch 80, Loss: 0.0237
Batch 90, Loss: 0.0248
Batch 100, Loss: 0.0218
Batch 110, Loss: 0.0265
Batch 120, Loss: 0.0214
Batch 130, Loss: 0.0229
Batch 140, Loss: 0.0209
Batch 150, Loss: 0.0238
Batch 160, Loss: 0.0223
Batch 170, Loss: 0.0255
Batch 180, Loss: 0.0223
Batch 190, Loss: 0.0274
Batch 200, Loss: 0.0240
Batch 210, Loss: 0.0268
Batch 220, Loss: 0.0209
Batch 230, Loss: 0.0233
Batch 240, Loss: 0.0228
Batch 250, Loss: 0.0255
Batch 260, Loss: 0.0238
Batch 270, Loss: 0.0247
Batch 280, Loss: 0.0255
Batch 290, Loss: 0.0227
Batch 300, Loss: 0.0239
Batch 310, Loss: 0.0230
Batch 320, Loss: 0.0239
Batch 330, Loss: 0.0260
Batch 340, Loss: 0.0222
Batch 350, Loss: 0.0263
Batch 360, Loss: 0.0244
Batch 370, Loss: 0.0241
Batch 380, Loss: 0.0230
Batch 390, Loss: 0.0246
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.12617254257202 seconds
Epoch 186 accuracy: 79.58%
Batch 10, Loss: 0.0258
Batch 20, Loss: 0.0249
Batch 30, Loss: 0.0232
Batch 40, Loss: 0.0255
Batch 50, Loss: 0.0231
Batch 60, Loss: 0.0234
Batch 70, Loss: 0.0215
Batch 80, Loss: 0.0242
Batch 90, Loss: 0.0228
Batch 100, Loss: 0.0232
Batch 110, Loss: 0.0237
Batch 120, Loss: 0.0208
Batch 130, Loss: 0.0225
Batch 140, Loss: 0.0228
Batch 150, Loss: 0.0239
Batch 160, Loss: 0.0227
Batch 170, Loss: 0.0221
Batch 180, Loss: 0.0217
Batch 190, Loss: 0.0249
Batch 200, Loss: 0.0281
Batch 210, Loss: 0.0227
Batch 220, Loss: 0.0242
Batch 230, Loss: 0.0287
Batch 240, Loss: 0.0238
Batch 250, Loss: 0.0251
Batch 260, Loss: 0.0249
Batch 270, Loss: 0.0232
Batch 280, Loss: 0.0241
Batch 290, Loss: 0.0221
Batch 300, Loss: 0.0279
Batch 310, Loss: 0.0258
Batch 320, Loss: 0.0218
Batch 330, Loss: 0.0282
Batch 340, Loss: 0.0231
Batch 350, Loss: 0.0248
Batch 360, Loss: 0.0224
Batch 370, Loss: 0.0248
Batch 380, Loss: 0.0239
Batch 390, Loss: 0.0245
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.110433340072632 seconds
Epoch 187 accuracy: 79.56%
Batch 10, Loss: 0.0232
Batch 20, Loss: 0.0244
Batch 30, Loss: 0.0224
Batch 40, Loss: 0.0217
Batch 50, Loss: 0.0252
Batch 60, Loss: 0.0232
Batch 70, Loss: 0.0222
Batch 80, Loss: 0.0226
Batch 90, Loss: 0.0232
Batch 100, Loss: 0.0227
Batch 110, Loss: 0.0234
Batch 120, Loss: 0.0261
Batch 130, Loss: 0.0237
Batch 140, Loss: 0.0242
Batch 150, Loss: 0.0216
Batch 160, Loss: 0.0278
Batch 170, Loss: 0.0221
Batch 180, Loss: 0.0234
Batch 190, Loss: 0.0238
Batch 200, Loss: 0.0219
Batch 210, Loss: 0.0242
Batch 220, Loss: 0.0246
Batch 230, Loss: 0.0203
Batch 240, Loss: 0.0241
Batch 250, Loss: 0.0253
Batch 260, Loss: 0.0228
Batch 270, Loss: 0.0219
Batch 280, Loss: 0.0212
Batch 290, Loss: 0.0245
Batch 300, Loss: 0.0249
Batch 310, Loss: 0.0225
Batch 320, Loss: 0.0281
Batch 330, Loss: 0.0257
Batch 340, Loss: 0.0224
Batch 350, Loss: 0.0226
Batch 360, Loss: 0.0220
Batch 370, Loss: 0.0238
Batch 380, Loss: 0.0229
Batch 390, Loss: 0.0209
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.16505479812622 seconds
Epoch 188 accuracy: 79.62%
Batch 10, Loss: 0.0214
Batch 20, Loss: 0.0239
Batch 30, Loss: 0.0213
Batch 40, Loss: 0.0227
Batch 50, Loss: 0.0253
Batch 60, Loss: 0.0220
Batch 70, Loss: 0.0211
Batch 80, Loss: 0.0218
Batch 90, Loss: 0.0255
Batch 100, Loss: 0.0230
Batch 110, Loss: 0.0218
Batch 120, Loss: 0.0250
Batch 130, Loss: 0.0251
Batch 140, Loss: 0.0216
Batch 150, Loss: 0.0254
Batch 160, Loss: 0.0240
Batch 170, Loss: 0.0219
Batch 180, Loss: 0.0253
Batch 190, Loss: 0.0252
Batch 200, Loss: 0.0221
Batch 210, Loss: 0.0256
Batch 220, Loss: 0.0243
Batch 230, Loss: 0.0210
Batch 240, Loss: 0.0228
Batch 250, Loss: 0.0238
Batch 260, Loss: 0.0219
Batch 270, Loss: 0.0216
Batch 280, Loss: 0.0222
Batch 290, Loss: 0.0227
Batch 300, Loss: 0.0229
Batch 310, Loss: 0.0224
Batch 320, Loss: 0.0203
Batch 330, Loss: 0.0243
Batch 340, Loss: 0.0233
Batch 350, Loss: 0.0241
Batch 360, Loss: 0.0226
Batch 370, Loss: 0.0213
Batch 380, Loss: 0.0250
Batch 390, Loss: 0.0229
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.090060234069824 seconds
Epoch 189 accuracy: 79.54%
Batch 10, Loss: 0.0235
Batch 20, Loss: 0.0228
Batch 30, Loss: 0.0230
Batch 40, Loss: 0.0261
Batch 50, Loss: 0.0230
Batch 60, Loss: 0.0209
Batch 70, Loss: 0.0226
Batch 80, Loss: 0.0218
Batch 90, Loss: 0.0276
Batch 100, Loss: 0.0225
Batch 110, Loss: 0.0219
Batch 120, Loss: 0.0202
Batch 130, Loss: 0.0215
Batch 140, Loss: 0.0249
Batch 150, Loss: 0.0226
Batch 160, Loss: 0.0228
Batch 170, Loss: 0.0210
Batch 180, Loss: 0.0213
Batch 190, Loss: 0.0243
Batch 200, Loss: 0.0254
Batch 210, Loss: 0.0263
Batch 220, Loss: 0.0212
Batch 230, Loss: 0.0214
Batch 240, Loss: 0.0199
Batch 250, Loss: 0.0224
Batch 260, Loss: 0.0231
Batch 270, Loss: 0.0226
Batch 280, Loss: 0.0230
Batch 290, Loss: 0.0206
Batch 300, Loss: 0.0225
Batch 310, Loss: 0.0232
Batch 320, Loss: 0.0222
Batch 330, Loss: 0.0231
Batch 340, Loss: 0.0196
Batch 350, Loss: 0.0263
Batch 360, Loss: 0.0256
Batch 370, Loss: 0.0216
Batch 380, Loss: 0.0219
Batch 390, Loss: 0.0218
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.094998836517334 seconds
Epoch 190 accuracy: 79.65%
Batch 10, Loss: 0.0241
Batch 20, Loss: 0.0230
Batch 30, Loss: 0.0214
Batch 40, Loss: 0.0261
Batch 50, Loss: 0.0216
Batch 60, Loss: 0.0222
Batch 70, Loss: 0.0243
Batch 80, Loss: 0.0208
Batch 90, Loss: 0.0224
Batch 100, Loss: 0.0218
Batch 110, Loss: 0.0238
Batch 120, Loss: 0.0240
Batch 130, Loss: 0.0229
Batch 140, Loss: 0.0237
Batch 150, Loss: 0.0241
Batch 160, Loss: 0.0204
Batch 170, Loss: 0.0216
Batch 180, Loss: 0.0219
Batch 190, Loss: 0.0239
Batch 200, Loss: 0.0213
Batch 210, Loss: 0.0212
Batch 220, Loss: 0.0235
Batch 230, Loss: 0.0228
Batch 240, Loss: 0.0213
Batch 250, Loss: 0.0227
Batch 260, Loss: 0.0216
Batch 270, Loss: 0.0206
Batch 280, Loss: 0.0211
Batch 290, Loss: 0.0220
Batch 300, Loss: 0.0254
Batch 310, Loss: 0.0244
Batch 320, Loss: 0.0228
Batch 330, Loss: 0.0210
Batch 340, Loss: 0.0223
Batch 350, Loss: 0.0204
Batch 360, Loss: 0.0191
Batch 370, Loss: 0.0206
Batch 380, Loss: 0.0220
Batch 390, Loss: 0.0220
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.18251395225525 seconds
Epoch 191 accuracy: 79.7%
Batch 10, Loss: 0.0214
Batch 20, Loss: 0.0213
Batch 30, Loss: 0.0197
Batch 40, Loss: 0.0217
Batch 50, Loss: 0.0233
Batch 60, Loss: 0.0219
Batch 70, Loss: 0.0223
Batch 80, Loss: 0.0219
Batch 90, Loss: 0.0224
Batch 100, Loss: 0.0206
Batch 110, Loss: 0.0213
Batch 120, Loss: 0.0217
Batch 130, Loss: 0.0221
Batch 140, Loss: 0.0219
Batch 150, Loss: 0.0229
Batch 160, Loss: 0.0232
Batch 170, Loss: 0.0221
Batch 180, Loss: 0.0213
Batch 190, Loss: 0.0224
Batch 200, Loss: 0.0233
Batch 210, Loss: 0.0225
Batch 220, Loss: 0.0202
Batch 230, Loss: 0.0238
Batch 240, Loss: 0.0204
Batch 250, Loss: 0.0227
Batch 260, Loss: 0.0198
Batch 270, Loss: 0.0252
Batch 280, Loss: 0.0231
Batch 290, Loss: 0.0208
Batch 300, Loss: 0.0222
Batch 310, Loss: 0.0213
Batch 320, Loss: 0.0200
Batch 330, Loss: 0.0219
Batch 340, Loss: 0.0218
Batch 350, Loss: 0.0224
Batch 360, Loss: 0.0223
Batch 370, Loss: 0.0199
Batch 380, Loss: 0.0211
Batch 390, Loss: 0.0230
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.048974752426147 seconds
Epoch 192 accuracy: 79.71%
Batch 10, Loss: 0.0236
Batch 20, Loss: 0.0255
Batch 30, Loss: 0.0226
Batch 40, Loss: 0.0236
Batch 50, Loss: 0.0199
Batch 60, Loss: 0.0225
Batch 70, Loss: 0.0212
Batch 80, Loss: 0.0231
Batch 90, Loss: 0.0214
Batch 100, Loss: 0.0223
Batch 110, Loss: 0.0219
Batch 120, Loss: 0.0233
Batch 130, Loss: 0.0214
Batch 140, Loss: 0.0254
Batch 150, Loss: 0.0212
Batch 160, Loss: 0.0233
Batch 170, Loss: 0.0240
Batch 180, Loss: 0.0220
Batch 190, Loss: 0.0214
Batch 200, Loss: 0.0218
Batch 210, Loss: 0.0226
Batch 220, Loss: 0.0209
Batch 230, Loss: 0.0255
Batch 240, Loss: 0.0251
Batch 250, Loss: 0.0194
Batch 260, Loss: 0.0220
Batch 270, Loss: 0.0218
Batch 280, Loss: 0.0223
Batch 290, Loss: 0.0239
Batch 300, Loss: 0.0185
Batch 310, Loss: 0.0206
Batch 320, Loss: 0.0264
Batch 330, Loss: 0.0222
Batch 340, Loss: 0.0232
Batch 350, Loss: 0.0205
Batch 360, Loss: 0.0205
Batch 370, Loss: 0.0224
Batch 380, Loss: 0.0242
Batch 390, Loss: 0.0220
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.10841178894043 seconds
Epoch 193 accuracy: 79.51%
Batch 10, Loss: 0.0213
Batch 20, Loss: 0.0213
Batch 30, Loss: 0.0197
Batch 40, Loss: 0.0210
Batch 50, Loss: 0.0213
Batch 60, Loss: 0.0215
Batch 70, Loss: 0.0223
Batch 80, Loss: 0.0220
Batch 90, Loss: 0.0226
Batch 100, Loss: 0.0217
Batch 110, Loss: 0.0232
Batch 120, Loss: 0.0198
Batch 130, Loss: 0.0233
Batch 140, Loss: 0.0242
Batch 150, Loss: 0.0211
Batch 160, Loss: 0.0216
Batch 170, Loss: 0.0201
Batch 180, Loss: 0.0213
Batch 190, Loss: 0.0202
Batch 200, Loss: 0.0241
Batch 210, Loss: 0.0247
Batch 220, Loss: 0.0227
Batch 230, Loss: 0.0236
Batch 240, Loss: 0.0225
Batch 250, Loss: 0.0216
Batch 260, Loss: 0.0233
Batch 270, Loss: 0.0193
Batch 280, Loss: 0.0204
Batch 290, Loss: 0.0214
Batch 300, Loss: 0.0203
Batch 310, Loss: 0.0206
Batch 320, Loss: 0.0232
Batch 330, Loss: 0.0225
Batch 340, Loss: 0.0224
Batch 350, Loss: 0.0247
Batch 360, Loss: 0.0298
Batch 370, Loss: 0.0225
Batch 380, Loss: 0.0239
Batch 390, Loss: 0.0218
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.169156789779663 seconds
Epoch 194 accuracy: 79.62%
Batch 10, Loss: 0.0208
Batch 20, Loss: 0.0230
Batch 30, Loss: 0.0221
Batch 40, Loss: 0.0212
Batch 50, Loss: 0.0210
Batch 60, Loss: 0.0197
Batch 70, Loss: 0.0211
Batch 80, Loss: 0.0209
Batch 90, Loss: 0.0260
Batch 100, Loss: 0.0209
Batch 110, Loss: 0.0240
Batch 120, Loss: 0.0208
Batch 130, Loss: 0.0230
Batch 140, Loss: 0.0223
Batch 150, Loss: 0.0195
Batch 160, Loss: 0.0258
Batch 170, Loss: 0.0208
Batch 180, Loss: 0.0210
Batch 190, Loss: 0.0210
Batch 200, Loss: 0.0250
Batch 210, Loss: 0.0191
Batch 220, Loss: 0.0238
Batch 230, Loss: 0.0221
Batch 240, Loss: 0.0224
Batch 250, Loss: 0.0249
Batch 260, Loss: 0.0211
Batch 270, Loss: 0.0200
Batch 280, Loss: 0.0224
Batch 290, Loss: 0.0200
Batch 300, Loss: 0.0221
Batch 310, Loss: 0.0215
Batch 320, Loss: 0.0230
Batch 330, Loss: 0.0188
Batch 340, Loss: 0.0236
Batch 350, Loss: 0.0251
Batch 360, Loss: 0.0235
Batch 370, Loss: 0.0239
Batch 380, Loss: 0.0212
Batch 390, Loss: 0.0216
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.199817180633545 seconds
Epoch 195 accuracy: 79.72%
Batch 10, Loss: 0.0207
Batch 20, Loss: 0.0218
Batch 30, Loss: 0.0188
Batch 40, Loss: 0.0233
Batch 50, Loss: 0.0235
Batch 60, Loss: 0.0231
Batch 70, Loss: 0.0228
Batch 80, Loss: 0.0262
Batch 90, Loss: 0.0233
Batch 100, Loss: 0.0209
Batch 110, Loss: 0.0229
Batch 120, Loss: 0.0234
Batch 130, Loss: 0.0234
Batch 140, Loss: 0.0203
Batch 150, Loss: 0.0221
Batch 160, Loss: 0.0226
Batch 170, Loss: 0.0233
Batch 180, Loss: 0.0218
Batch 190, Loss: 0.0195
Batch 200, Loss: 0.0225
Batch 210, Loss: 0.0207
Batch 220, Loss: 0.0202
Batch 230, Loss: 0.0209
Batch 240, Loss: 0.0221
Batch 250, Loss: 0.0209
Batch 260, Loss: 0.0205
Batch 270, Loss: 0.0225
Batch 280, Loss: 0.0222
Batch 290, Loss: 0.0244
Batch 300, Loss: 0.0226
Batch 310, Loss: 0.0210
Batch 320, Loss: 0.0238
Batch 330, Loss: 0.0269
Batch 340, Loss: 0.0247
Batch 350, Loss: 0.0195
Batch 360, Loss: 0.0201
Batch 370, Loss: 0.0221
Batch 380, Loss: 0.0216
Batch 390, Loss: 0.0209
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.141136646270752 seconds
Epoch 196 accuracy: 79.61%
Batch 10, Loss: 0.0211
Batch 20, Loss: 0.0199
Batch 30, Loss: 0.0205
Batch 40, Loss: 0.0193
Batch 50, Loss: 0.0198
Batch 60, Loss: 0.0206
Batch 70, Loss: 0.0203
Batch 80, Loss: 0.0198
Batch 90, Loss: 0.0228
Batch 100, Loss: 0.0218
Batch 110, Loss: 0.0241
Batch 120, Loss: 0.0216
Batch 130, Loss: 0.0224
Batch 140, Loss: 0.0268
Batch 150, Loss: 0.0215
Batch 160, Loss: 0.0224
Batch 170, Loss: 0.0198
Batch 180, Loss: 0.0224
Batch 190, Loss: 0.0221
Batch 200, Loss: 0.0195
Batch 210, Loss: 0.0221
Batch 220, Loss: 0.0196
Batch 230, Loss: 0.0218
Batch 240, Loss: 0.0250
Batch 250, Loss: 0.0185
Batch 260, Loss: 0.0197
Batch 270, Loss: 0.0198
Batch 280, Loss: 0.0214
Batch 290, Loss: 0.0228
Batch 300, Loss: 0.0224
Batch 310, Loss: 0.0223
Batch 320, Loss: 0.0182
Batch 330, Loss: 0.0223
Batch 340, Loss: 0.0195
Batch 350, Loss: 0.0211
Batch 360, Loss: 0.0207
Batch 370, Loss: 0.0227
Batch 380, Loss: 0.0220
Batch 390, Loss: 0.0216
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.117574214935303 seconds
Epoch 197 accuracy: 79.67%
Batch 10, Loss: 0.0209
Batch 20, Loss: 0.0214
Batch 30, Loss: 0.0239
Batch 40, Loss: 0.0221
Batch 50, Loss: 0.0221
Batch 60, Loss: 0.0230
Batch 70, Loss: 0.0244
Batch 80, Loss: 0.0240
Batch 90, Loss: 0.0220
Batch 100, Loss: 0.0236
Batch 110, Loss: 0.0238
Batch 120, Loss: 0.0264
Batch 130, Loss: 0.0221
Batch 140, Loss: 0.0209
Batch 150, Loss: 0.0199
Batch 160, Loss: 0.0203
Batch 170, Loss: 0.0226
Batch 180, Loss: 0.0225
Batch 190, Loss: 0.0233
Batch 200, Loss: 0.0204
Batch 210, Loss: 0.0179
Batch 220, Loss: 0.0229
Batch 230, Loss: 0.0207
Batch 240, Loss: 0.0181
Batch 250, Loss: 0.0223
Batch 260, Loss: 0.0239
Batch 270, Loss: 0.0220
Batch 280, Loss: 0.0259
Batch 290, Loss: 0.0239
Batch 300, Loss: 0.0198
Batch 310, Loss: 0.0222
Batch 320, Loss: 0.0195
Batch 330, Loss: 0.0245
Batch 340, Loss: 0.0214
Batch 350, Loss: 0.0214
Batch 360, Loss: 0.0225
Batch 370, Loss: 0.0216
Batch 380, Loss: 0.0220
Batch 390, Loss: 0.0196
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.12616777420044 seconds
Epoch 198 accuracy: 79.71%
Batch 10, Loss: 0.0212
Batch 20, Loss: 0.0212
Batch 30, Loss: 0.0206
Batch 40, Loss: 0.0231
Batch 50, Loss: 0.0194
Batch 60, Loss: 0.0195
Batch 70, Loss: 0.0197
Batch 80, Loss: 0.0215
Batch 90, Loss: 0.0221
Batch 100, Loss: 0.0230
Batch 110, Loss: 0.0207
Batch 120, Loss: 0.0204
Batch 130, Loss: 0.0217
Batch 140, Loss: 0.0226
Batch 150, Loss: 0.0203
Batch 160, Loss: 0.0235
Batch 170, Loss: 0.0205
Batch 180, Loss: 0.0218
Batch 190, Loss: 0.0237
Batch 200, Loss: 0.0227
Batch 210, Loss: 0.0216
Batch 220, Loss: 0.0198
Batch 230, Loss: 0.0210
Batch 240, Loss: 0.0234
Batch 250, Loss: 0.0207
Batch 260, Loss: 0.0196
Batch 270, Loss: 0.0229
Batch 280, Loss: 0.0204
Batch 290, Loss: 0.0204
Batch 300, Loss: 0.0229
Batch 310, Loss: 0.0230
Batch 320, Loss: 0.0225
Batch 330, Loss: 0.0244
Batch 340, Loss: 0.0241
Batch 350, Loss: 0.0213
Batch 360, Loss: 0.0215
Batch 370, Loss: 0.0204
Batch 380, Loss: 0.0200
Batch 390, Loss: 0.0227
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.147881984710693 seconds
Epoch 199 accuracy: 79.77%
Batch 10, Loss: 0.0228
Batch 20, Loss: 0.0239
Batch 30, Loss: 0.0230
Batch 40, Loss: 0.0278
Batch 50, Loss: 0.0222
Batch 60, Loss: 0.0230
Batch 70, Loss: 0.0225
Batch 80, Loss: 0.0204
Batch 90, Loss: 0.0205
Batch 100, Loss: 0.0235
Batch 110, Loss: 0.0227
Batch 120, Loss: 0.0239
Batch 130, Loss: 0.0226
Batch 140, Loss: 0.0212
Batch 150, Loss: 0.0248
Batch 160, Loss: 0.0213
Batch 170, Loss: 0.0204
Batch 180, Loss: 0.0241
Batch 190, Loss: 0.0203
Batch 200, Loss: 0.0240
Batch 210, Loss: 0.0237
Batch 220, Loss: 0.0205
Batch 230, Loss: 0.0223
Batch 240, Loss: 0.0230
Batch 250, Loss: 0.0227
Batch 260, Loss: 0.0222
Batch 270, Loss: 0.0234
Batch 280, Loss: 0.0196
Batch 290, Loss: 0.0207
Batch 300, Loss: 0.0210
Batch 310, Loss: 0.0233
Batch 320, Loss: 0.0255
Batch 330, Loss: 0.0208
Batch 340, Loss: 0.0194
Batch 350, Loss: 0.0207
Batch 360, Loss: 0.0219
Batch 370, Loss: 0.0193
Batch 380, Loss: 0.0206
Batch 390, Loss: 0.0216
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.109532833099365 seconds
Epoch 200 accuracy: 79.73%
Total training time: 5053.398640632629 seconds
