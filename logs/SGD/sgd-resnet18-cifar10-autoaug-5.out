The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 3.3681
Batch 20, Loss: 3.5601
Batch 30, Loss: 2.2017
Batch 40, Loss: 2.0178
Batch 50, Loss: 1.8877
Batch 60, Loss: 1.8085
Batch 70, Loss: 1.7292
Batch 80, Loss: 1.7159
Batch 90, Loss: 1.7040
Batch 100, Loss: 1.6957
Batch 110, Loss: 1.6848
Batch 120, Loss: 1.6641
Batch 130, Loss: 1.6618
Batch 140, Loss: 1.6517
Batch 150, Loss: 1.6838
Batch 160, Loss: 1.6546
Batch 170, Loss: 1.6358
Batch 180, Loss: 1.6345
Batch 190, Loss: 1.6154
Batch 200, Loss: 1.6024
Batch 210, Loss: 1.5897
Batch 220, Loss: 1.5936
Batch 230, Loss: 1.5814
Batch 240, Loss: 1.5900
Batch 250, Loss: 1.5614
Batch 260, Loss: 1.5656
Batch 270, Loss: 1.5436
Batch 280, Loss: 1.5394
Batch 290, Loss: 1.5651
Batch 300, Loss: 1.5492
Batch 310, Loss: 1.5188
Batch 320, Loss: 1.5502
Batch 330, Loss: 1.5291
Batch 340, Loss: 1.5125
Batch 350, Loss: 1.5392
Batch 360, Loss: 1.5104
Batch 370, Loss: 1.5285
Batch 380, Loss: 1.5321
Batch 390, Loss: 1.4928
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.62356972694397 seconds
Epoch 1 accuracy: 35.84%
Batch 10, Loss: 1.4908
Batch 20, Loss: 1.5029
Batch 30, Loss: 1.5035
Batch 40, Loss: 1.4867
Batch 50, Loss: 1.4957
Batch 60, Loss: 1.4734
Batch 70, Loss: 1.4482
Batch 80, Loss: 1.4780
Batch 90, Loss: 1.4573
Batch 100, Loss: 1.4872
Batch 110, Loss: 1.4857
Batch 120, Loss: 1.4622
Batch 130, Loss: 1.4531
Batch 140, Loss: 1.4807
Batch 150, Loss: 1.4661
Batch 160, Loss: 1.4526
Batch 170, Loss: 1.4416
Batch 180, Loss: 1.4378
Batch 190, Loss: 1.4372
Batch 200, Loss: 1.4195
Batch 210, Loss: 1.4237
Batch 220, Loss: 1.4626
Batch 230, Loss: 1.4519
Batch 240, Loss: 1.4475
Batch 250, Loss: 1.4406
Batch 260, Loss: 1.4573
Batch 270, Loss: 1.4241
Batch 280, Loss: 1.4420
Batch 290, Loss: 1.4653
Batch 300, Loss: 1.4401
Batch 310, Loss: 1.4080
Batch 320, Loss: 1.3753
Batch 330, Loss: 1.4474
Batch 340, Loss: 1.4058
Batch 350, Loss: 1.3629
Batch 360, Loss: 1.4159
Batch 370, Loss: 1.4079
Batch 380, Loss: 1.4016
Batch 390, Loss: 1.3773
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.131216287612915 seconds
Epoch 2 accuracy: 41.39%
Batch 10, Loss: 1.3691
Batch 20, Loss: 1.3680
Batch 30, Loss: 1.3533
Batch 40, Loss: 1.3594
Batch 50, Loss: 1.3660
Batch 60, Loss: 1.3737
Batch 70, Loss: 1.3633
Batch 80, Loss: 1.3730
Batch 90, Loss: 1.3725
Batch 100, Loss: 1.3672
Batch 110, Loss: 1.3266
Batch 120, Loss: 1.3470
Batch 130, Loss: 1.3695
Batch 140, Loss: 1.3357
Batch 150, Loss: 1.3780
Batch 160, Loss: 1.3310
Batch 170, Loss: 1.3241
Batch 180, Loss: 1.2928
Batch 190, Loss: 1.2919
Batch 200, Loss: 1.2962
Batch 210, Loss: 1.3057
Batch 220, Loss: 1.2822
Batch 230, Loss: 1.2968
Batch 240, Loss: 1.3109
Batch 250, Loss: 1.3481
Batch 260, Loss: 1.2903
Batch 270, Loss: 1.3234
Batch 280, Loss: 1.3417
Batch 290, Loss: 1.2955
Batch 300, Loss: 1.2480
Batch 310, Loss: 1.2327
Batch 320, Loss: 1.2654
Batch 330, Loss: 1.2884
Batch 340, Loss: 1.2538
Batch 350, Loss: 1.2735
Batch 360, Loss: 1.2484
Batch 370, Loss: 1.2610
Batch 380, Loss: 1.2642
Batch 390, Loss: 1.2332
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.16266179084778 seconds
Epoch 3 accuracy: 50.77%
Batch 10, Loss: 1.2347
Batch 20, Loss: 1.2691
Batch 30, Loss: 1.2339
Batch 40, Loss: 1.2558
Batch 50, Loss: 1.2574
Batch 60, Loss: 1.2066
Batch 70, Loss: 1.2269
Batch 80, Loss: 1.2548
Batch 90, Loss: 1.2653
Batch 100, Loss: 1.2389
Batch 110, Loss: 1.2391
Batch 120, Loss: 1.1935
Batch 130, Loss: 1.2331
Batch 140, Loss: 1.2055
Batch 150, Loss: 1.2219
Batch 160, Loss: 1.1799
Batch 170, Loss: 1.1941
Batch 180, Loss: 1.2012
Batch 190, Loss: 1.2030
Batch 200, Loss: 1.2367
Batch 210, Loss: 1.1986
Batch 220, Loss: 1.1617
Batch 230, Loss: 1.1875
Batch 240, Loss: 1.1714
Batch 250, Loss: 1.2029
Batch 260, Loss: 1.1808
Batch 270, Loss: 1.1659
Batch 280, Loss: 1.1629
Batch 290, Loss: 1.2045
Batch 300, Loss: 1.1952
Batch 310, Loss: 1.1589
Batch 320, Loss: 1.0954
Batch 330, Loss: 1.1213
Batch 340, Loss: 1.2020
Batch 350, Loss: 1.1759
Batch 360, Loss: 1.1862
Batch 370, Loss: 1.1186
Batch 380, Loss: 1.1259
Batch 390, Loss: 1.1391
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.06452441215515 seconds
Epoch 4 accuracy: 53.95%
Batch 10, Loss: 1.1659
Batch 20, Loss: 1.1439
Batch 30, Loss: 1.1455
Batch 40, Loss: 1.1484
Batch 50, Loss: 1.1471
Batch 60, Loss: 1.1358
Batch 70, Loss: 1.1169
Batch 80, Loss: 1.1407
Batch 90, Loss: 1.0771
Batch 100, Loss: 1.1267
Batch 110, Loss: 1.1385
Batch 120, Loss: 1.1406
Batch 130, Loss: 1.0849
Batch 140, Loss: 1.1001
Batch 150, Loss: 1.0914
Batch 160, Loss: 1.0934
Batch 170, Loss: 1.0927
Batch 180, Loss: 1.1124
Batch 190, Loss: 1.1012
Batch 200, Loss: 1.0731
Batch 210, Loss: 1.0187
Batch 220, Loss: 1.1013
Batch 230, Loss: 1.1142
Batch 240, Loss: 1.1514
Batch 250, Loss: 1.0858
Batch 260, Loss: 1.0498
Batch 270, Loss: 1.1080
Batch 280, Loss: 1.0572
Batch 290, Loss: 1.0135
Batch 300, Loss: 1.0714
Batch 310, Loss: 1.0827
Batch 320, Loss: 1.0947
Batch 330, Loss: 1.0461
Batch 340, Loss: 1.0571
Batch 350, Loss: 1.0866
Batch 360, Loss: 1.0798
Batch 370, Loss: 1.0677
Batch 380, Loss: 1.0625
Batch 390, Loss: 1.0489
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.12291193008423 seconds
Epoch 5 accuracy: 59.22%
Batch 10, Loss: 1.0742
Batch 20, Loss: 1.0693
Batch 30, Loss: 1.0677
Batch 40, Loss: 1.0648
Batch 50, Loss: 1.0580
Batch 60, Loss: 1.0560
Batch 70, Loss: 1.0698
Batch 80, Loss: 1.0500
Batch 90, Loss: 1.0215
Batch 100, Loss: 1.0218
Batch 110, Loss: 0.9968
Batch 120, Loss: 1.0627
Batch 130, Loss: 1.0374
Batch 140, Loss: 1.0354
Batch 150, Loss: 1.0231
Batch 160, Loss: 1.0173
Batch 170, Loss: 1.0374
Batch 180, Loss: 1.0076
Batch 190, Loss: 0.9880
Batch 200, Loss: 0.9960
Batch 210, Loss: 1.0068
Batch 220, Loss: 1.0257
Batch 230, Loss: 1.0179
Batch 240, Loss: 1.0106
Batch 250, Loss: 1.0396
Batch 260, Loss: 0.9764
Batch 270, Loss: 1.0146
Batch 280, Loss: 1.0034
Batch 290, Loss: 0.9820
Batch 300, Loss: 0.9713
Batch 310, Loss: 1.0051
Batch 320, Loss: 0.9980
Batch 330, Loss: 0.9631
Batch 340, Loss: 0.9827
Batch 350, Loss: 1.0045
Batch 360, Loss: 1.0248
Batch 370, Loss: 1.0171
Batch 380, Loss: 0.9674
Batch 390, Loss: 1.0248
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.13410997390747 seconds
Epoch 6 accuracy: 59.71%
Batch 10, Loss: 1.0033
Batch 20, Loss: 1.0181
Batch 30, Loss: 0.9757
Batch 40, Loss: 0.9722
Batch 50, Loss: 0.9955
Batch 60, Loss: 0.9556
Batch 70, Loss: 1.0126
Batch 80, Loss: 0.9816
Batch 90, Loss: 0.9457
Batch 100, Loss: 0.9069
Batch 110, Loss: 0.9326
Batch 120, Loss: 0.9760
Batch 130, Loss: 0.9439
Batch 140, Loss: 0.9391
Batch 150, Loss: 0.9662
Batch 160, Loss: 0.9767
Batch 170, Loss: 0.9434
Batch 180, Loss: 0.9461
Batch 190, Loss: 0.9090
Batch 200, Loss: 0.9763
Batch 210, Loss: 0.9757
Batch 220, Loss: 0.9083
Batch 230, Loss: 0.9577
Batch 240, Loss: 0.9569
Batch 250, Loss: 0.9398
Batch 260, Loss: 0.9991
Batch 270, Loss: 0.9937
Batch 280, Loss: 0.9653
Batch 290, Loss: 0.9547
Batch 300, Loss: 0.9526
Batch 310, Loss: 0.9220
Batch 320, Loss: 0.8722
Batch 330, Loss: 0.9078
Batch 340, Loss: 0.9160
Batch 350, Loss: 0.9640
Batch 360, Loss: 0.9870
Batch 370, Loss: 0.9589
Batch 380, Loss: 0.8651
Batch 390, Loss: 0.9295
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.122726440429688 seconds
Epoch 7 accuracy: 63.63%
Batch 10, Loss: 0.9372
Batch 20, Loss: 0.9528
Batch 30, Loss: 0.9358
Batch 40, Loss: 0.8684
Batch 50, Loss: 0.8874
Batch 60, Loss: 0.9326
Batch 70, Loss: 0.9657
Batch 80, Loss: 0.9344
Batch 90, Loss: 0.9788
Batch 100, Loss: 0.9598
Batch 110, Loss: 0.9216
Batch 120, Loss: 0.9066
Batch 130, Loss: 0.9572
Batch 140, Loss: 0.9549
Batch 150, Loss: 0.8600
Batch 160, Loss: 0.9140
Batch 170, Loss: 0.8914
Batch 180, Loss: 0.9024
Batch 190, Loss: 0.8720
Batch 200, Loss: 0.8859
Batch 210, Loss: 0.8960
Batch 220, Loss: 0.8506
Batch 230, Loss: 0.9005
Batch 240, Loss: 0.8983
Batch 250, Loss: 0.8799
Batch 260, Loss: 0.8699
Batch 270, Loss: 0.9397
Batch 280, Loss: 0.8598
Batch 290, Loss: 0.8691
Batch 300, Loss: 0.8739
Batch 310, Loss: 0.8953
Batch 320, Loss: 0.8768
Batch 330, Loss: 0.9088
Batch 340, Loss: 0.8903
Batch 350, Loss: 0.9002
Batch 360, Loss: 0.8775
Batch 370, Loss: 0.8788
Batch 380, Loss: 0.8858
Batch 390, Loss: 0.8810
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.21933102607727 seconds
Epoch 8 accuracy: 61.86%
Batch 10, Loss: 0.8716
Batch 20, Loss: 0.8735
Batch 30, Loss: 0.8644
Batch 40, Loss: 0.8528
Batch 50, Loss: 0.8543
Batch 60, Loss: 0.8559
Batch 70, Loss: 0.8279
Batch 80, Loss: 0.8729
Batch 90, Loss: 0.8854
Batch 100, Loss: 0.8490
Batch 110, Loss: 0.8262
Batch 120, Loss: 0.8165
Batch 130, Loss: 0.8153
Batch 140, Loss: 0.8431
Batch 150, Loss: 0.9095
Batch 160, Loss: 0.8408
Batch 170, Loss: 0.8552
Batch 180, Loss: 0.8947
Batch 190, Loss: 0.8286
Batch 200, Loss: 0.8537
Batch 210, Loss: 0.8382
Batch 220, Loss: 0.8100
Batch 230, Loss: 0.8642
Batch 240, Loss: 0.7781
Batch 250, Loss: 0.8510
Batch 260, Loss: 0.8200
Batch 270, Loss: 0.8313
Batch 280, Loss: 0.8045
Batch 290, Loss: 0.8375
Batch 300, Loss: 0.8072
Batch 310, Loss: 0.8613
Batch 320, Loss: 0.8120
Batch 330, Loss: 0.8498
Batch 340, Loss: 0.8371
Batch 350, Loss: 0.8191
Batch 360, Loss: 0.8883
Batch 370, Loss: 0.8443
Batch 380, Loss: 0.8412
Batch 390, Loss: 0.8220
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.194031476974487 seconds
Epoch 9 accuracy: 72.13%
Batch 10, Loss: 0.7905
Batch 20, Loss: 0.8208
Batch 30, Loss: 0.8499
Batch 40, Loss: 0.8443
Batch 50, Loss: 0.8483
Batch 60, Loss: 0.8361
Batch 70, Loss: 0.7701
Batch 80, Loss: 0.8726
Batch 90, Loss: 0.7781
Batch 100, Loss: 0.8100
Batch 110, Loss: 0.8336
Batch 120, Loss: 0.7829
Batch 130, Loss: 0.8223
Batch 140, Loss: 0.8130
Batch 150, Loss: 0.8279
Batch 160, Loss: 0.8120
Batch 170, Loss: 0.7434
Batch 180, Loss: 0.7828
Batch 190, Loss: 0.7958
Batch 200, Loss: 0.8358
Batch 210, Loss: 0.7520
Batch 220, Loss: 0.7710
Batch 230, Loss: 0.8288
Batch 240, Loss: 0.8170
Batch 250, Loss: 0.7834
Batch 260, Loss: 0.7999
Batch 270, Loss: 0.8066
Batch 280, Loss: 0.7976
Batch 290, Loss: 0.7978
Batch 300, Loss: 0.8157
Batch 310, Loss: 0.7937
Batch 320, Loss: 0.8000
Batch 330, Loss: 0.8137
Batch 340, Loss: 0.7824
Batch 350, Loss: 0.8140
Batch 360, Loss: 0.7882
Batch 370, Loss: 0.7749
Batch 380, Loss: 0.7688
Batch 390, Loss: 0.7965
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.18973183631897 seconds
Epoch 10 accuracy: 72.88%
Batch 10, Loss: 0.7835
Batch 20, Loss: 0.7726
Batch 30, Loss: 0.7951
Batch 40, Loss: 0.7780
Batch 50, Loss: 0.7889
Batch 60, Loss: 0.7952
Batch 70, Loss: 0.7935
Batch 80, Loss: 0.7879
Batch 90, Loss: 0.7222
Batch 100, Loss: 0.7786
Batch 110, Loss: 0.7961
Batch 120, Loss: 0.7184
Batch 130, Loss: 0.7660
Batch 140, Loss: 0.7346
Batch 150, Loss: 0.7632
Batch 160, Loss: 0.8049
Batch 170, Loss: 0.8318
Batch 180, Loss: 0.8313
Batch 190, Loss: 0.7532
Batch 200, Loss: 0.8144
Batch 210, Loss: 0.8124
Batch 220, Loss: 0.7825
Batch 230, Loss: 0.8174
Batch 240, Loss: 0.8212
Batch 250, Loss: 0.8103
Batch 260, Loss: 0.7955
Batch 270, Loss: 0.7800
Batch 280, Loss: 0.7553
Batch 290, Loss: 0.7511
Batch 300, Loss: 0.7787
Batch 310, Loss: 0.7459
Batch 320, Loss: 0.8146
Batch 330, Loss: 0.8317
Batch 340, Loss: 0.7745
Batch 350, Loss: 0.7644
Batch 360, Loss: 0.7235
Batch 370, Loss: 0.7423
Batch 380, Loss: 0.7951
Batch 390, Loss: 0.7721
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.171906232833862 seconds
Epoch 11 accuracy: 73.02%
Batch 10, Loss: 0.7516
Batch 20, Loss: 0.7793
Batch 30, Loss: 0.7525
Batch 40, Loss: 0.7587
Batch 50, Loss: 0.7439
Batch 60, Loss: 0.7485
Batch 70, Loss: 0.7186
Batch 80, Loss: 0.7429
Batch 90, Loss: 0.7486
Batch 100, Loss: 0.7344
Batch 110, Loss: 0.7762
Batch 120, Loss: 0.7630
Batch 130, Loss: 0.7362
Batch 140, Loss: 0.7540
Batch 150, Loss: 0.7657
Batch 160, Loss: 0.7411
Batch 170, Loss: 0.7799
Batch 180, Loss: 0.7481
Batch 190, Loss: 0.7702
Batch 200, Loss: 0.7025
Batch 210, Loss: 0.7343
Batch 220, Loss: 0.7642
Batch 230, Loss: 0.7678
Batch 240, Loss: 0.7558
Batch 250, Loss: 0.7588
Batch 260, Loss: 0.7343
Batch 270, Loss: 0.7685
Batch 280, Loss: 0.7235
Batch 290, Loss: 0.7516
Batch 300, Loss: 0.7849
Batch 310, Loss: 0.6976
Batch 320, Loss: 0.7474
Batch 330, Loss: 0.7605
Batch 340, Loss: 0.7210
Batch 350, Loss: 0.7077
Batch 360, Loss: 0.7605
Batch 370, Loss: 0.7296
Batch 380, Loss: 0.7617
Batch 390, Loss: 0.7450
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.130010843276978 seconds
Epoch 12 accuracy: 71.55%
Batch 10, Loss: 0.7209
Batch 20, Loss: 0.6773
Batch 30, Loss: 0.8084
Batch 40, Loss: 0.7523
Batch 50, Loss: 0.7581
Batch 60, Loss: 0.7930
Batch 70, Loss: 0.7279
Batch 80, Loss: 0.7307
Batch 90, Loss: 0.7196
Batch 100, Loss: 0.7667
Batch 110, Loss: 0.7460
Batch 120, Loss: 0.7145
Batch 130, Loss: 0.7347
Batch 140, Loss: 0.7395
Batch 150, Loss: 0.7337
Batch 160, Loss: 0.7481
Batch 170, Loss: 0.7687
Batch 180, Loss: 0.7718
Batch 190, Loss: 0.7595
Batch 200, Loss: 0.7010
Batch 210, Loss: 0.7143
Batch 220, Loss: 0.7348
Batch 230, Loss: 0.7211
Batch 240, Loss: 0.7846
Batch 250, Loss: 0.7748
Batch 260, Loss: 0.7359
Batch 270, Loss: 0.7313
Batch 280, Loss: 0.7533
Batch 290, Loss: 0.7602
Batch 300, Loss: 0.7259
Batch 310, Loss: 0.7236
Batch 320, Loss: 0.7111
Batch 330, Loss: 0.7058
Batch 340, Loss: 0.7233
Batch 350, Loss: 0.6886
Batch 360, Loss: 0.7121
Batch 370, Loss: 0.7275
Batch 380, Loss: 0.6774
Batch 390, Loss: 0.7318
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.22032403945923 seconds
Epoch 13 accuracy: 77.17%
Batch 10, Loss: 0.6835
Batch 20, Loss: 0.7151
Batch 30, Loss: 0.7126
Batch 40, Loss: 0.6950
Batch 50, Loss: 0.7043
Batch 60, Loss: 0.7157
Batch 70, Loss: 0.7017
Batch 80, Loss: 0.7336
Batch 90, Loss: 0.7196
Batch 100, Loss: 0.7002
Batch 110, Loss: 0.7110
Batch 120, Loss: 0.6840
Batch 130, Loss: 0.7313
Batch 140, Loss: 0.7110
Batch 150, Loss: 0.7164
Batch 160, Loss: 0.6767
Batch 170, Loss: 0.6951
Batch 180, Loss: 0.7024
Batch 190, Loss: 0.7365
Batch 200, Loss: 0.7275
Batch 210, Loss: 0.7573
Batch 220, Loss: 0.7383
Batch 230, Loss: 0.7021
Batch 240, Loss: 0.7142
Batch 250, Loss: 0.6859
Batch 260, Loss: 0.6993
Batch 270, Loss: 0.7229
Batch 280, Loss: 0.7344
Batch 290, Loss: 0.6993
Batch 300, Loss: 0.7131
Batch 310, Loss: 0.6920
Batch 320, Loss: 0.7386
Batch 330, Loss: 0.7281
Batch 340, Loss: 0.7075
Batch 350, Loss: 0.7003
Batch 360, Loss: 0.7095
Batch 370, Loss: 0.6924
Batch 380, Loss: 0.7136
Batch 390, Loss: 0.6816
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.22222328186035 seconds
Epoch 14 accuracy: 72.88%
Batch 10, Loss: 0.6949
Batch 20, Loss: 0.6861
Batch 30, Loss: 0.6591
Batch 40, Loss: 0.7169
Batch 50, Loss: 0.6605
Batch 60, Loss: 0.7372
Batch 70, Loss: 0.6809
Batch 80, Loss: 0.6883
Batch 90, Loss: 0.6843
Batch 100, Loss: 0.7391
Batch 110, Loss: 0.7283
Batch 120, Loss: 0.6874
Batch 130, Loss: 0.6763
Batch 140, Loss: 0.6919
Batch 150, Loss: 0.6573
Batch 160, Loss: 0.7336
Batch 170, Loss: 0.6845
Batch 180, Loss: 0.6955
Batch 190, Loss: 0.7104
Batch 200, Loss: 0.7212
Batch 210, Loss: 0.7434
Batch 220, Loss: 0.6817
Batch 230, Loss: 0.6799
Batch 240, Loss: 0.7523
Batch 250, Loss: 0.6522
Batch 260, Loss: 0.6837
Batch 270, Loss: 0.6865
Batch 280, Loss: 0.6905
Batch 290, Loss: 0.6704
Batch 300, Loss: 0.7098
Batch 310, Loss: 0.7405
Batch 320, Loss: 0.7094
Batch 330, Loss: 0.6849
Batch 340, Loss: 0.6905
Batch 350, Loss: 0.6231
Batch 360, Loss: 0.6672
Batch 370, Loss: 0.6768
Batch 380, Loss: 0.7174
Batch 390, Loss: 0.7204
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.137388467788696 seconds
Epoch 15 accuracy: 79.39%
Batch 10, Loss: 0.6957
Batch 20, Loss: 0.6540
Batch 30, Loss: 0.6698
Batch 40, Loss: 0.6408
Batch 50, Loss: 0.7202
Batch 60, Loss: 0.6987
Batch 70, Loss: 0.6843
Batch 80, Loss: 0.6651
Batch 90, Loss: 0.6915
Batch 100, Loss: 0.6908
Batch 110, Loss: 0.6990
Batch 120, Loss: 0.7011
Batch 130, Loss: 0.7201
Batch 140, Loss: 0.6361
Batch 150, Loss: 0.6698
Batch 160, Loss: 0.6902
Batch 170, Loss: 0.7038
Batch 180, Loss: 0.6749
Batch 190, Loss: 0.6679
Batch 200, Loss: 0.7544
Batch 210, Loss: 0.6653
Batch 220, Loss: 0.6922
Batch 230, Loss: 0.6805
Batch 240, Loss: 0.6982
Batch 250, Loss: 0.6911
Batch 260, Loss: 0.6517
Batch 270, Loss: 0.6835
Batch 280, Loss: 0.6969
Batch 290, Loss: 0.6691
Batch 300, Loss: 0.6774
Batch 310, Loss: 0.6760
Batch 320, Loss: 0.7283
Batch 330, Loss: 0.7232
Batch 340, Loss: 0.6749
Batch 350, Loss: 0.6936
Batch 360, Loss: 0.6913
Batch 370, Loss: 0.6911
Batch 380, Loss: 0.6478
Batch 390, Loss: 0.7345
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.32648229598999 seconds
Epoch 16 accuracy: 76.1%
Batch 10, Loss: 0.6799
Batch 20, Loss: 0.6433
Batch 30, Loss: 0.6534
Batch 40, Loss: 0.7251
Batch 50, Loss: 0.7021
Batch 60, Loss: 0.6546
Batch 70, Loss: 0.6524
Batch 80, Loss: 0.6735
Batch 90, Loss: 0.6883
Batch 100, Loss: 0.7115
Batch 110, Loss: 0.6662
Batch 120, Loss: 0.6719
Batch 130, Loss: 0.7388
Batch 140, Loss: 0.6764
Batch 150, Loss: 0.6467
Batch 160, Loss: 0.7222
Batch 170, Loss: 0.7069
Batch 180, Loss: 0.6156
Batch 190, Loss: 0.6508
Batch 200, Loss: 0.6689
Batch 210, Loss: 0.7224
Batch 220, Loss: 0.6820
Batch 230, Loss: 0.6752
Batch 240, Loss: 0.6843
Batch 250, Loss: 0.6897
Batch 260, Loss: 0.6775
Batch 270, Loss: 0.6846
Batch 280, Loss: 0.6965
Batch 290, Loss: 0.6645
Batch 300, Loss: 0.7129
Batch 310, Loss: 0.7032
Batch 320, Loss: 0.7012
Batch 330, Loss: 0.6855
Batch 340, Loss: 0.6230
Batch 350, Loss: 0.7000
Batch 360, Loss: 0.7112
Batch 370, Loss: 0.6303
Batch 380, Loss: 0.6482
Batch 390, Loss: 0.6407
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.115469217300415 seconds
Epoch 17 accuracy: 79.16%
Batch 10, Loss: 0.6463
Batch 20, Loss: 0.6409
Batch 30, Loss: 0.6428
Batch 40, Loss: 0.6328
Batch 50, Loss: 0.6695
Batch 60, Loss: 0.6314
Batch 70, Loss: 0.6485
Batch 80, Loss: 0.6768
Batch 90, Loss: 0.6005
Batch 100, Loss: 0.6699
Batch 110, Loss: 0.6611
Batch 120, Loss: 0.6802
Batch 130, Loss: 0.6675
Batch 140, Loss: 0.6743
Batch 150, Loss: 0.6583
Batch 160, Loss: 0.6445
Batch 170, Loss: 0.6739
Batch 180, Loss: 0.6402
Batch 190, Loss: 0.6736
Batch 200, Loss: 0.6938
Batch 210, Loss: 0.6904
Batch 220, Loss: 0.6539
Batch 230, Loss: 0.6224
Batch 240, Loss: 0.6325
Batch 250, Loss: 0.6550
Batch 260, Loss: 0.6355
Batch 270, Loss: 0.6547
Batch 280, Loss: 0.7180
Batch 290, Loss: 0.6187
Batch 300, Loss: 0.6439
Batch 310, Loss: 0.6747
Batch 320, Loss: 0.6999
Batch 330, Loss: 0.6851
Batch 340, Loss: 0.6951
Batch 350, Loss: 0.6428
Batch 360, Loss: 0.6402
Batch 370, Loss: 0.6535
Batch 380, Loss: 0.6675
Batch 390, Loss: 0.6393
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.08960247039795 seconds
Epoch 18 accuracy: 76.83%
Batch 10, Loss: 0.6359
Batch 20, Loss: 0.6731
Batch 30, Loss: 0.6294
Batch 40, Loss: 0.6637
Batch 50, Loss: 0.6660
Batch 60, Loss: 0.6084
Batch 70, Loss: 0.6482
Batch 80, Loss: 0.6876
Batch 90, Loss: 0.6241
Batch 100, Loss: 0.6653
Batch 110, Loss: 0.6600
Batch 120, Loss: 0.6655
Batch 130, Loss: 0.6602
Batch 140, Loss: 0.6524
Batch 150, Loss: 0.6517
Batch 160, Loss: 0.6098
Batch 170, Loss: 0.6798
Batch 180, Loss: 0.6291
Batch 190, Loss: 0.6531
Batch 200, Loss: 0.6868
Batch 210, Loss: 0.7005
Batch 220, Loss: 0.6748
Batch 230, Loss: 0.6577
Batch 240, Loss: 0.6263
Batch 250, Loss: 0.6283
Batch 260, Loss: 0.6606
Batch 270, Loss: 0.6703
Batch 280, Loss: 0.6447
Batch 290, Loss: 0.6392
Batch 300, Loss: 0.7041
Batch 310, Loss: 0.6676
Batch 320, Loss: 0.6501
Batch 330, Loss: 0.6742
Batch 340, Loss: 0.6743
Batch 350, Loss: 0.6331
Batch 360, Loss: 0.6781
Batch 370, Loss: 0.6722
Batch 380, Loss: 0.6398
Batch 390, Loss: 0.6760
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.07769227027893 seconds
Epoch 19 accuracy: 78.11%
Batch 10, Loss: 0.6296
Batch 20, Loss: 0.6541
Batch 30, Loss: 0.6372
Batch 40, Loss: 0.6206
Batch 50, Loss: 0.6504
Batch 60, Loss: 0.6632
Batch 70, Loss: 0.6363
Batch 80, Loss: 0.6555
Batch 90, Loss: 0.6811
Batch 100, Loss: 0.6702
Batch 110, Loss: 0.6746
Batch 120, Loss: 0.7177
Batch 130, Loss: 0.6341
Batch 140, Loss: 0.6330
Batch 150, Loss: 0.6128
Batch 160, Loss: 0.6187
Batch 170, Loss: 0.6361
Batch 180, Loss: 0.6315
Batch 190, Loss: 0.6609
Batch 200, Loss: 0.6801
Batch 210, Loss: 0.6934
Batch 220, Loss: 0.6381
Batch 230, Loss: 0.6382
Batch 240, Loss: 0.6248
Batch 250, Loss: 0.6602
Batch 260, Loss: 0.6305
Batch 270, Loss: 0.6522
Batch 280, Loss: 0.6662
Batch 290, Loss: 0.6074
Batch 300, Loss: 0.6797
Batch 310, Loss: 0.6617
Batch 320, Loss: 0.6209
Batch 330, Loss: 0.6461
Batch 340, Loss: 0.6439
Batch 350, Loss: 0.6562
Batch 360, Loss: 0.6559
Batch 370, Loss: 0.6738
Batch 380, Loss: 0.6756
Batch 390, Loss: 0.6178
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.14924955368042 seconds
Epoch 20 accuracy: 71.45%
Batch 10, Loss: 0.6108
Batch 20, Loss: 0.6534
Batch 30, Loss: 0.6458
Batch 40, Loss: 0.6644
Batch 50, Loss: 0.6566
Batch 60, Loss: 0.6263
Batch 70, Loss: 0.6522
Batch 80, Loss: 0.6424
Batch 90, Loss: 0.6359
Batch 100, Loss: 0.6370
Batch 110, Loss: 0.6251
Batch 120, Loss: 0.6237
Batch 130, Loss: 0.6481
Batch 140, Loss: 0.6545
Batch 150, Loss: 0.6379
Batch 160, Loss: 0.6921
Batch 170, Loss: 0.6634
Batch 180, Loss: 0.6551
Batch 190, Loss: 0.6188
Batch 200, Loss: 0.5974
Batch 210, Loss: 0.6003
Batch 220, Loss: 0.6401
Batch 230, Loss: 0.6329
Batch 240, Loss: 0.6319
Batch 250, Loss: 0.6586
Batch 260, Loss: 0.6454
Batch 270, Loss: 0.6435
Batch 280, Loss: 0.6566
Batch 290, Loss: 0.6252
Batch 300, Loss: 0.6598
Batch 310, Loss: 0.6071
Batch 320, Loss: 0.6458
Batch 330, Loss: 0.6380
Batch 340, Loss: 0.6191
Batch 350, Loss: 0.6469
Batch 360, Loss: 0.6676
Batch 370, Loss: 0.5820
Batch 380, Loss: 0.6260
Batch 390, Loss: 0.6417
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.206912517547607 seconds
Epoch 21 accuracy: 77.75%
Batch 10, Loss: 0.6140
Batch 20, Loss: 0.6428
Batch 30, Loss: 0.6096
Batch 40, Loss: 0.6427
Batch 50, Loss: 0.6387
Batch 60, Loss: 0.5923
Batch 70, Loss: 0.6308
Batch 80, Loss: 0.6465
Batch 90, Loss: 0.6024
Batch 100, Loss: 0.6234
Batch 110, Loss: 0.6565
Batch 120, Loss: 0.6121
Batch 130, Loss: 0.6280
Batch 140, Loss: 0.6328
Batch 150, Loss: 0.5821
Batch 160, Loss: 0.6091
Batch 170, Loss: 0.6718
Batch 180, Loss: 0.6545
Batch 190, Loss: 0.6264
Batch 200, Loss: 0.6213
Batch 210, Loss: 0.6154
Batch 220, Loss: 0.6148
Batch 230, Loss: 0.6435
Batch 240, Loss: 0.6180
Batch 250, Loss: 0.6267
Batch 260, Loss: 0.6374
Batch 270, Loss: 0.6124
Batch 280, Loss: 0.6357
Batch 290, Loss: 0.6379
Batch 300, Loss: 0.6300
Batch 310, Loss: 0.6313
Batch 320, Loss: 0.6087
Batch 330, Loss: 0.6447
Batch 340, Loss: 0.6250
Batch 350, Loss: 0.6514
Batch 360, Loss: 0.6516
Batch 370, Loss: 0.6408
Batch 380, Loss: 0.6334
Batch 390, Loss: 0.6067
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.183831453323364 seconds
Epoch 22 accuracy: 81.35%
Batch 10, Loss: 0.5697
Batch 20, Loss: 0.6460
Batch 30, Loss: 0.6089
Batch 40, Loss: 0.6347
Batch 50, Loss: 0.6078
Batch 60, Loss: 0.6090
Batch 70, Loss: 0.6034
Batch 80, Loss: 0.6193
Batch 90, Loss: 0.6014
Batch 100, Loss: 0.6229
Batch 110, Loss: 0.6625
Batch 120, Loss: 0.6369
Batch 130, Loss: 0.5963
Batch 140, Loss: 0.6021
Batch 150, Loss: 0.6332
Batch 160, Loss: 0.6421
Batch 170, Loss: 0.6202
Batch 180, Loss: 0.6391
Batch 190, Loss: 0.6151
Batch 200, Loss: 0.6100
Batch 210, Loss: 0.6188
Batch 220, Loss: 0.6334
Batch 230, Loss: 0.6551
Batch 240, Loss: 0.6308
Batch 250, Loss: 0.6575
Batch 260, Loss: 0.6446
Batch 270, Loss: 0.6045
Batch 280, Loss: 0.6093
Batch 290, Loss: 0.6437
Batch 300, Loss: 0.6547
Batch 310, Loss: 0.5856
Batch 320, Loss: 0.6698
Batch 330, Loss: 0.5932
Batch 340, Loss: 0.6478
Batch 350, Loss: 0.6055
Batch 360, Loss: 0.6226
Batch 370, Loss: 0.5623
Batch 380, Loss: 0.6226
Batch 390, Loss: 0.6175
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.124967336654663 seconds
Epoch 23 accuracy: 79.72%
Batch 10, Loss: 0.6557
Batch 20, Loss: 0.5976
Batch 30, Loss: 0.6243
Batch 40, Loss: 0.5954
Batch 50, Loss: 0.6100
Batch 60, Loss: 0.5751
Batch 70, Loss: 0.6419
Batch 80, Loss: 0.6398
Batch 90, Loss: 0.5882
Batch 100, Loss: 0.6473
Batch 110, Loss: 0.6663
Batch 120, Loss: 0.6491
Batch 130, Loss: 0.6408
Batch 140, Loss: 0.5864
Batch 150, Loss: 0.6222
Batch 160, Loss: 0.6486
Batch 170, Loss: 0.6313
Batch 180, Loss: 0.6283
Batch 190, Loss: 0.6470
Batch 200, Loss: 0.6202
Batch 210, Loss: 0.6395
Batch 220, Loss: 0.5881
Batch 230, Loss: 0.6348
Batch 240, Loss: 0.6333
Batch 250, Loss: 0.6188
Batch 260, Loss: 0.6069
Batch 270, Loss: 0.6303
Batch 280, Loss: 0.6713
Batch 290, Loss: 0.6553
Batch 300, Loss: 0.6502
Batch 310, Loss: 0.6494
Batch 320, Loss: 0.6054
Batch 330, Loss: 0.6169
Batch 340, Loss: 0.6149
Batch 350, Loss: 0.6104
Batch 360, Loss: 0.6505
Batch 370, Loss: 0.6316
Batch 380, Loss: 0.5981
Batch 390, Loss: 0.6487
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.11919116973877 seconds
Epoch 24 accuracy: 80.9%
Batch 10, Loss: 0.5933
Batch 20, Loss: 0.6262
Batch 30, Loss: 0.5956
Batch 40, Loss: 0.5914
Batch 50, Loss: 0.5915
Batch 60, Loss: 0.6456
Batch 70, Loss: 0.6277
Batch 80, Loss: 0.6170
Batch 90, Loss: 0.6657
Batch 100, Loss: 0.6557
Batch 110, Loss: 0.6270
Batch 120, Loss: 0.5753
Batch 130, Loss: 0.6181
Batch 140, Loss: 0.6498
Batch 150, Loss: 0.6504
Batch 160, Loss: 0.5996
Batch 170, Loss: 0.6082
Batch 180, Loss: 0.5686
Batch 190, Loss: 0.5947
Batch 200, Loss: 0.6296
Batch 210, Loss: 0.6008
Batch 220, Loss: 0.5926
Batch 230, Loss: 0.6101
Batch 240, Loss: 0.6319
Batch 250, Loss: 0.6254
Batch 260, Loss: 0.5763
Batch 270, Loss: 0.5663
Batch 280, Loss: 0.5909
Batch 290, Loss: 0.6285
Batch 300, Loss: 0.6056
Batch 310, Loss: 0.6156
Batch 320, Loss: 0.6235
Batch 330, Loss: 0.6058
Batch 340, Loss: 0.5798
Batch 350, Loss: 0.5583
Batch 360, Loss: 0.6459
Batch 370, Loss: 0.6489
Batch 380, Loss: 0.6114
Batch 390, Loss: 0.6452
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.177122592926025 seconds
Epoch 25 accuracy: 77.36%
Batch 10, Loss: 0.6389
Batch 20, Loss: 0.6138
Batch 30, Loss: 0.6592
Batch 40, Loss: 0.6187
Batch 50, Loss: 0.6064
Batch 60, Loss: 0.5762
Batch 70, Loss: 0.6385
Batch 80, Loss: 0.6149
Batch 90, Loss: 0.6384
Batch 100, Loss: 0.5881
Batch 110, Loss: 0.6013
Batch 120, Loss: 0.5831
Batch 130, Loss: 0.6025
Batch 140, Loss: 0.6204
Batch 150, Loss: 0.6242
Batch 160, Loss: 0.5988
Batch 170, Loss: 0.6228
Batch 180, Loss: 0.6054
Batch 190, Loss: 0.6204
Batch 200, Loss: 0.5705
Batch 210, Loss: 0.5886
Batch 220, Loss: 0.6479
Batch 230, Loss: 0.6298
Batch 240, Loss: 0.6001
Batch 250, Loss: 0.6108
Batch 260, Loss: 0.6159
Batch 270, Loss: 0.6154
Batch 280, Loss: 0.6276
Batch 290, Loss: 0.6398
Batch 300, Loss: 0.6487
Batch 310, Loss: 0.5914
Batch 320, Loss: 0.5995
Batch 330, Loss: 0.5698
Batch 340, Loss: 0.5739
Batch 350, Loss: 0.5749
Batch 360, Loss: 0.6342
Batch 370, Loss: 0.5821
Batch 380, Loss: 0.6284
Batch 390, Loss: 0.6179
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.098629474639893 seconds
Epoch 26 accuracy: 79.59%
Batch 10, Loss: 0.6244
Batch 20, Loss: 0.6190
Batch 30, Loss: 0.5931
Batch 40, Loss: 0.5850
Batch 50, Loss: 0.6101
Batch 60, Loss: 0.5893
Batch 70, Loss: 0.6171
Batch 80, Loss: 0.6132
Batch 90, Loss: 0.6039
Batch 100, Loss: 0.5896
Batch 110, Loss: 0.6162
Batch 120, Loss: 0.6229
Batch 130, Loss: 0.5473
Batch 140, Loss: 0.5463
Batch 150, Loss: 0.5941
Batch 160, Loss: 0.5977
Batch 170, Loss: 0.6171
Batch 180, Loss: 0.6115
Batch 190, Loss: 0.6046
Batch 200, Loss: 0.5946
Batch 210, Loss: 0.5697
Batch 220, Loss: 0.6112
Batch 230, Loss: 0.5945
Batch 240, Loss: 0.6106
Batch 250, Loss: 0.5988
Batch 260, Loss: 0.5796
Batch 270, Loss: 0.6046
Batch 280, Loss: 0.6099
Batch 290, Loss: 0.5970
Batch 300, Loss: 0.6319
Batch 310, Loss: 0.6411
Batch 320, Loss: 0.6019
Batch 330, Loss: 0.5787
Batch 340, Loss: 0.5665
Batch 350, Loss: 0.6244
Batch 360, Loss: 0.6668
Batch 370, Loss: 0.6337
Batch 380, Loss: 0.6584
Batch 390, Loss: 0.6173
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.22308921813965 seconds
Epoch 27 accuracy: 79.88%
Batch 10, Loss: 0.5826
Batch 20, Loss: 0.6199
Batch 30, Loss: 0.6225
Batch 40, Loss: 0.6052
Batch 50, Loss: 0.5922
Batch 60, Loss: 0.5895
Batch 70, Loss: 0.5753
Batch 80, Loss: 0.6018
Batch 90, Loss: 0.5864
Batch 100, Loss: 0.6185
Batch 110, Loss: 0.5771
Batch 120, Loss: 0.5967
Batch 130, Loss: 0.6017
Batch 140, Loss: 0.6200
Batch 150, Loss: 0.5835
Batch 160, Loss: 0.6113
Batch 170, Loss: 0.5378
Batch 180, Loss: 0.5632
Batch 190, Loss: 0.5719
Batch 200, Loss: 0.6199
Batch 210, Loss: 0.6200
Batch 220, Loss: 0.6174
Batch 230, Loss: 0.5933
Batch 240, Loss: 0.6314
Batch 250, Loss: 0.5792
Batch 260, Loss: 0.6461
Batch 270, Loss: 0.6156
Batch 280, Loss: 0.6381
Batch 290, Loss: 0.5760
Batch 300, Loss: 0.6364
Batch 310, Loss: 0.6306
Batch 320, Loss: 0.5940
Batch 330, Loss: 0.5927
Batch 340, Loss: 0.6136
Batch 350, Loss: 0.6230
Batch 360, Loss: 0.6232
Batch 370, Loss: 0.5925
Batch 380, Loss: 0.6305
Batch 390, Loss: 0.6013
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.105318307876587 seconds
Epoch 28 accuracy: 78.95%
Batch 10, Loss: 0.6246
Batch 20, Loss: 0.6194
Batch 30, Loss: 0.5900
Batch 40, Loss: 0.5976
Batch 50, Loss: 0.5795
Batch 60, Loss: 0.5534
Batch 70, Loss: 0.5867
Batch 80, Loss: 0.5966
Batch 90, Loss: 0.6342
Batch 100, Loss: 0.6267
Batch 110, Loss: 0.6153
Batch 120, Loss: 0.5994
Batch 130, Loss: 0.6053
Batch 140, Loss: 0.6053
Batch 150, Loss: 0.6319
Batch 160, Loss: 0.6384
Batch 170, Loss: 0.6255
Batch 180, Loss: 0.6196
Batch 190, Loss: 0.5868
Batch 200, Loss: 0.6178
Batch 210, Loss: 0.5874
Batch 220, Loss: 0.5359
Batch 230, Loss: 0.6070
Batch 240, Loss: 0.6354
Batch 250, Loss: 0.5598
Batch 260, Loss: 0.6261
Batch 270, Loss: 0.6045
Batch 280, Loss: 0.6313
Batch 290, Loss: 0.5870
Batch 300, Loss: 0.6214
Batch 310, Loss: 0.5948
Batch 320, Loss: 0.5535
Batch 330, Loss: 0.6099
Batch 340, Loss: 0.6215
Batch 350, Loss: 0.5890
Batch 360, Loss: 0.5816
Batch 370, Loss: 0.5833
Batch 380, Loss: 0.5937
Batch 390, Loss: 0.6102
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.1358904838562 seconds
Epoch 29 accuracy: 81.04%
Batch 10, Loss: 0.6200
Batch 20, Loss: 0.5610
Batch 30, Loss: 0.6224
Batch 40, Loss: 0.5823
Batch 50, Loss: 0.6107
Batch 60, Loss: 0.5655
Batch 70, Loss: 0.5789
Batch 80, Loss: 0.6037
Batch 90, Loss: 0.5905
Batch 100, Loss: 0.5759
Batch 110, Loss: 0.6252
Batch 120, Loss: 0.5795
Batch 130, Loss: 0.6182
Batch 140, Loss: 0.5630
Batch 150, Loss: 0.6367
Batch 160, Loss: 0.5712
Batch 170, Loss: 0.5929
Batch 180, Loss: 0.6012
Batch 190, Loss: 0.5765
Batch 200, Loss: 0.5411
Batch 210, Loss: 0.5771
Batch 220, Loss: 0.5897
Batch 230, Loss: 0.6054
Batch 240, Loss: 0.5872
Batch 250, Loss: 0.5931
Batch 260, Loss: 0.5559
Batch 270, Loss: 0.5929
Batch 280, Loss: 0.6186
Batch 290, Loss: 0.6100
Batch 300, Loss: 0.6295
Batch 310, Loss: 0.6203
Batch 320, Loss: 0.5795
Batch 330, Loss: 0.5865
Batch 340, Loss: 0.6032
Batch 350, Loss: 0.5991
Batch 360, Loss: 0.5906
Batch 370, Loss: 0.6282
Batch 380, Loss: 0.6104
Batch 390, Loss: 0.5968
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.123058557510376 seconds
Epoch 30 accuracy: 81.89%
Batch 10, Loss: 0.5918
Batch 20, Loss: 0.6359
Batch 30, Loss: 0.5893
Batch 40, Loss: 0.6057
Batch 50, Loss: 0.6167
Batch 60, Loss: 0.5967
Batch 70, Loss: 0.5980
Batch 80, Loss: 0.5901
Batch 90, Loss: 0.5820
Batch 100, Loss: 0.5922
Batch 110, Loss: 0.5846
Batch 120, Loss: 0.6372
Batch 130, Loss: 0.6037
Batch 140, Loss: 0.5799
Batch 150, Loss: 0.5687
Batch 160, Loss: 0.5575
Batch 170, Loss: 0.6153
Batch 180, Loss: 0.5746
Batch 190, Loss: 0.5863
Batch 200, Loss: 0.5587
Batch 210, Loss: 0.5970
Batch 220, Loss: 0.6371
Batch 230, Loss: 0.6167
Batch 240, Loss: 0.5846
Batch 250, Loss: 0.5863
Batch 260, Loss: 0.6281
Batch 270, Loss: 0.5974
Batch 280, Loss: 0.5858
Batch 290, Loss: 0.5649
Batch 300, Loss: 0.5483
Batch 310, Loss: 0.5867
Batch 320, Loss: 0.5604
Batch 330, Loss: 0.5474
Batch 340, Loss: 0.6164
Batch 350, Loss: 0.5486
Batch 360, Loss: 0.5826
Batch 370, Loss: 0.5678
Batch 380, Loss: 0.6587
Batch 390, Loss: 0.6310
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.162121772766113 seconds
Epoch 31 accuracy: 83.14%
Batch 10, Loss: 0.5830
Batch 20, Loss: 0.6351
Batch 30, Loss: 0.5897
Batch 40, Loss: 0.5745
Batch 50, Loss: 0.5679
Batch 60, Loss: 0.5937
Batch 70, Loss: 0.6011
Batch 80, Loss: 0.5892
Batch 90, Loss: 0.6321
Batch 100, Loss: 0.6170
Batch 110, Loss: 0.5872
Batch 120, Loss: 0.5625
Batch 130, Loss: 0.5745
Batch 140, Loss: 0.5961
Batch 150, Loss: 0.5917
Batch 160, Loss: 0.5854
Batch 170, Loss: 0.6217
Batch 180, Loss: 0.6030
Batch 190, Loss: 0.5570
Batch 200, Loss: 0.6205
Batch 210, Loss: 0.6414
Batch 220, Loss: 0.6080
Batch 230, Loss: 0.5724
Batch 240, Loss: 0.5623
Batch 250, Loss: 0.6242
Batch 260, Loss: 0.5891
Batch 270, Loss: 0.5730
Batch 280, Loss: 0.5845
Batch 290, Loss: 0.5578
Batch 300, Loss: 0.5789
Batch 310, Loss: 0.5910
Batch 320, Loss: 0.5433
Batch 330, Loss: 0.5471
Batch 340, Loss: 0.5812
Batch 350, Loss: 0.5452
Batch 360, Loss: 0.5563
Batch 370, Loss: 0.6007
Batch 380, Loss: 0.6312
Batch 390, Loss: 0.6360
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.159458875656128 seconds
Epoch 32 accuracy: 81.86%
Batch 10, Loss: 0.6092
Batch 20, Loss: 0.5956
Batch 30, Loss: 0.5764
Batch 40, Loss: 0.5470
Batch 50, Loss: 0.6026
Batch 60, Loss: 0.5823
Batch 70, Loss: 0.5858
Batch 80, Loss: 0.6051
Batch 90, Loss: 0.5891
Batch 100, Loss: 0.5712
Batch 110, Loss: 0.5661
Batch 120, Loss: 0.5786
Batch 130, Loss: 0.6139
Batch 140, Loss: 0.5349
Batch 150, Loss: 0.5782
Batch 160, Loss: 0.6084
Batch 170, Loss: 0.5455
Batch 180, Loss: 0.5925
Batch 190, Loss: 0.6307
Batch 200, Loss: 0.5979
Batch 210, Loss: 0.5828
Batch 220, Loss: 0.5561
Batch 230, Loss: 0.5727
Batch 240, Loss: 0.5974
Batch 250, Loss: 0.5613
Batch 260, Loss: 0.6125
Batch 270, Loss: 0.5708
Batch 280, Loss: 0.5931
Batch 290, Loss: 0.5910
Batch 300, Loss: 0.5573
Batch 310, Loss: 0.6101
Batch 320, Loss: 0.5760
Batch 330, Loss: 0.6411
Batch 340, Loss: 0.5983
Batch 350, Loss: 0.5979
Batch 360, Loss: 0.5951
Batch 370, Loss: 0.5764
Batch 380, Loss: 0.6019
Batch 390, Loss: 0.6315
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.19965124130249 seconds
Epoch 33 accuracy: 80.08%
Batch 10, Loss: 0.6131
Batch 20, Loss: 0.5772
Batch 30, Loss: 0.5351
Batch 40, Loss: 0.5685
Batch 50, Loss: 0.5712
Batch 60, Loss: 0.6011
Batch 70, Loss: 0.5958
Batch 80, Loss: 0.5720
Batch 90, Loss: 0.5522
Batch 100, Loss: 0.5664
Batch 110, Loss: 0.5794
Batch 120, Loss: 0.5738
Batch 130, Loss: 0.5896
Batch 140, Loss: 0.6430
Batch 150, Loss: 0.5550
Batch 160, Loss: 0.5918
Batch 170, Loss: 0.6268
Batch 180, Loss: 0.5698
Batch 190, Loss: 0.5650
Batch 200, Loss: 0.5639
Batch 210, Loss: 0.6124
Batch 220, Loss: 0.5957
Batch 230, Loss: 0.5676
Batch 240, Loss: 0.5869
Batch 250, Loss: 0.6350
Batch 260, Loss: 0.5883
Batch 270, Loss: 0.5968
Batch 280, Loss: 0.5992
Batch 290, Loss: 0.5634
Batch 300, Loss: 0.5907
Batch 310, Loss: 0.5515
Batch 320, Loss: 0.5691
Batch 330, Loss: 0.5771
Batch 340, Loss: 0.5863
Batch 350, Loss: 0.6243
Batch 360, Loss: 0.6000
Batch 370, Loss: 0.5909
Batch 380, Loss: 0.5849
Batch 390, Loss: 0.5867
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.16241192817688 seconds
Epoch 34 accuracy: 84.15%
Batch 10, Loss: 0.5786
Batch 20, Loss: 0.5909
Batch 30, Loss: 0.5990
Batch 40, Loss: 0.5714
Batch 50, Loss: 0.5667
Batch 60, Loss: 0.5873
Batch 70, Loss: 0.5560
Batch 80, Loss: 0.5273
Batch 90, Loss: 0.5760
Batch 100, Loss: 0.5789
Batch 110, Loss: 0.5915
Batch 120, Loss: 0.5763
Batch 130, Loss: 0.5676
Batch 140, Loss: 0.6004
Batch 150, Loss: 0.6038
Batch 160, Loss: 0.5522
Batch 170, Loss: 0.5851
Batch 180, Loss: 0.5529
Batch 190, Loss: 0.5894
Batch 200, Loss: 0.5915
Batch 210, Loss: 0.5721
Batch 220, Loss: 0.5711
Batch 230, Loss: 0.5930
Batch 240, Loss: 0.6253
Batch 250, Loss: 0.6027
Batch 260, Loss: 0.6024
Batch 270, Loss: 0.5355
Batch 280, Loss: 0.5921
Batch 290, Loss: 0.5934
Batch 300, Loss: 0.5533
Batch 310, Loss: 0.5998
Batch 320, Loss: 0.6241
Batch 330, Loss: 0.5824
Batch 340, Loss: 0.6091
Batch 350, Loss: 0.5754
Batch 360, Loss: 0.5656
Batch 370, Loss: 0.5942
Batch 380, Loss: 0.5846
Batch 390, Loss: 0.5980
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.09206199645996 seconds
Epoch 35 accuracy: 78.87%
Batch 10, Loss: 0.5848
Batch 20, Loss: 0.5914
Batch 30, Loss: 0.6128
Batch 40, Loss: 0.5751
Batch 50, Loss: 0.6264
Batch 60, Loss: 0.5384
Batch 70, Loss: 0.5597
Batch 80, Loss: 0.5286
Batch 90, Loss: 0.5544
Batch 100, Loss: 0.6332
Batch 110, Loss: 0.5483
Batch 120, Loss: 0.5330
Batch 130, Loss: 0.5549
Batch 140, Loss: 0.5827
Batch 150, Loss: 0.6019
Batch 160, Loss: 0.5850
Batch 170, Loss: 0.6015
Batch 180, Loss: 0.6082
Batch 190, Loss: 0.5770
Batch 200, Loss: 0.5803
Batch 210, Loss: 0.6176
Batch 220, Loss: 0.5874
Batch 230, Loss: 0.5741
Batch 240, Loss: 0.5670
Batch 250, Loss: 0.6067
Batch 260, Loss: 0.5449
Batch 270, Loss: 0.5723
Batch 280, Loss: 0.5635
Batch 290, Loss: 0.5501
Batch 300, Loss: 0.5936
Batch 310, Loss: 0.5781
Batch 320, Loss: 0.5729
Batch 330, Loss: 0.5555
Batch 340, Loss: 0.5799
Batch 350, Loss: 0.5512
Batch 360, Loss: 0.5895
Batch 370, Loss: 0.5763
Batch 380, Loss: 0.5801
Batch 390, Loss: 0.5353
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.151902198791504 seconds
Epoch 36 accuracy: 84.3%
Batch 10, Loss: 0.5734
Batch 20, Loss: 0.6032
Batch 30, Loss: 0.6001
Batch 40, Loss: 0.5766
Batch 50, Loss: 0.5758
Batch 60, Loss: 0.5503
Batch 70, Loss: 0.5938
Batch 80, Loss: 0.5703
Batch 90, Loss: 0.5799
Batch 100, Loss: 0.6118
Batch 110, Loss: 0.5814
Batch 120, Loss: 0.5972
Batch 130, Loss: 0.5928
Batch 140, Loss: 0.6008
Batch 150, Loss: 0.5346
Batch 160, Loss: 0.5680
Batch 170, Loss: 0.5645
Batch 180, Loss: 0.5750
Batch 190, Loss: 0.5581
Batch 200, Loss: 0.6111
Batch 210, Loss: 0.6455
Batch 220, Loss: 0.6285
Batch 230, Loss: 0.5404
Batch 240, Loss: 0.5731
Batch 250, Loss: 0.5782
Batch 260, Loss: 0.5770
Batch 270, Loss: 0.5787
Batch 280, Loss: 0.5695
Batch 290, Loss: 0.5835
Batch 300, Loss: 0.6067
Batch 310, Loss: 0.5780
Batch 320, Loss: 0.5881
Batch 330, Loss: 0.6090
Batch 340, Loss: 0.5500
Batch 350, Loss: 0.5820
Batch 360, Loss: 0.5419
Batch 370, Loss: 0.5293
Batch 380, Loss: 0.5615
Batch 390, Loss: 0.6014
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.111254930496216 seconds
Epoch 37 accuracy: 81.19%
Batch 10, Loss: 0.5743
Batch 20, Loss: 0.5672
Batch 30, Loss: 0.5984
Batch 40, Loss: 0.5892
Batch 50, Loss: 0.5854
Batch 60, Loss: 0.5535
Batch 70, Loss: 0.5834
Batch 80, Loss: 0.5801
Batch 90, Loss: 0.5610
Batch 100, Loss: 0.5566
Batch 110, Loss: 0.5401
Batch 120, Loss: 0.5808
Batch 130, Loss: 0.5484
Batch 140, Loss: 0.5804
Batch 150, Loss: 0.5864
Batch 160, Loss: 0.5501
Batch 170, Loss: 0.5930
Batch 180, Loss: 0.5368
Batch 190, Loss: 0.5496
Batch 200, Loss: 0.5910
Batch 210, Loss: 0.5929
Batch 220, Loss: 0.5914
Batch 230, Loss: 0.6015
Batch 240, Loss: 0.5605
Batch 250, Loss: 0.6075
Batch 260, Loss: 0.6023
Batch 270, Loss: 0.5573
Batch 280, Loss: 0.5778
Batch 290, Loss: 0.5228
Batch 300, Loss: 0.6328
Batch 310, Loss: 0.5689
Batch 320, Loss: 0.5901
Batch 330, Loss: 0.5740
Batch 340, Loss: 0.5631
Batch 350, Loss: 0.5602
Batch 360, Loss: 0.5680
Batch 370, Loss: 0.5785
Batch 380, Loss: 0.5820
Batch 390, Loss: 0.5425
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.08980703353882 seconds
Epoch 38 accuracy: 84.26%
Batch 10, Loss: 0.6080
Batch 20, Loss: 0.5304
Batch 30, Loss: 0.5801
Batch 40, Loss: 0.5681
Batch 50, Loss: 0.5372
Batch 60, Loss: 0.5767
Batch 70, Loss: 0.5319
Batch 80, Loss: 0.5888
Batch 90, Loss: 0.5678
Batch 100, Loss: 0.5952
Batch 110, Loss: 0.5362
Batch 120, Loss: 0.5597
Batch 130, Loss: 0.6316
Batch 140, Loss: 0.5767
Batch 150, Loss: 0.5514
Batch 160, Loss: 0.5301
Batch 170, Loss: 0.5738
Batch 180, Loss: 0.5856
Batch 190, Loss: 0.5439
Batch 200, Loss: 0.6009
Batch 210, Loss: 0.5831
Batch 220, Loss: 0.5834
Batch 230, Loss: 0.5949
Batch 240, Loss: 0.6001
Batch 250, Loss: 0.5978
Batch 260, Loss: 0.5839
Batch 270, Loss: 0.5980
Batch 280, Loss: 0.5794
Batch 290, Loss: 0.5600
Batch 300, Loss: 0.5786
Batch 310, Loss: 0.5391
Batch 320, Loss: 0.5262
Batch 330, Loss: 0.5677
Batch 340, Loss: 0.5743
Batch 350, Loss: 0.5746
Batch 360, Loss: 0.5796
Batch 370, Loss: 0.5974
Batch 380, Loss: 0.5911
Batch 390, Loss: 0.5652
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.072143077850342 seconds
Epoch 39 accuracy: 76.91%
Batch 10, Loss: 0.5395
Batch 20, Loss: 0.5814
Batch 30, Loss: 0.5319
Batch 40, Loss: 0.5655
Batch 50, Loss: 0.5364
Batch 60, Loss: 0.5633
Batch 70, Loss: 0.5729
Batch 80, Loss: 0.6010
Batch 90, Loss: 0.5479
Batch 100, Loss: 0.5357
Batch 110, Loss: 0.5750
Batch 120, Loss: 0.5756
Batch 130, Loss: 0.6178
Batch 140, Loss: 0.5810
Batch 150, Loss: 0.5659
Batch 160, Loss: 0.5276
Batch 170, Loss: 0.5773
Batch 180, Loss: 0.5659
Batch 190, Loss: 0.5677
Batch 200, Loss: 0.5539
Batch 210, Loss: 0.5604
Batch 220, Loss: 0.5667
Batch 230, Loss: 0.5714
Batch 240, Loss: 0.5867
Batch 250, Loss: 0.5572
Batch 260, Loss: 0.5648
Batch 270, Loss: 0.5745
Batch 280, Loss: 0.5316
Batch 290, Loss: 0.6112
Batch 300, Loss: 0.5450
Batch 310, Loss: 0.5946
Batch 320, Loss: 0.5947
Batch 330, Loss: 0.5251
Batch 340, Loss: 0.5458
Batch 350, Loss: 0.5408
Batch 360, Loss: 0.5708
Batch 370, Loss: 0.5645
Batch 380, Loss: 0.5870
Batch 390, Loss: 0.6033
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.128010034561157 seconds
Epoch 40 accuracy: 81.59%
Batch 10, Loss: 0.5940
Batch 20, Loss: 0.6030
Batch 30, Loss: 0.5505
Batch 40, Loss: 0.5618
Batch 50, Loss: 0.5753
Batch 60, Loss: 0.5884
Batch 70, Loss: 0.5802
Batch 80, Loss: 0.5755
Batch 90, Loss: 0.5452
Batch 100, Loss: 0.5599
Batch 110, Loss: 0.5310
Batch 120, Loss: 0.5764
Batch 130, Loss: 0.5570
Batch 140, Loss: 0.5611
Batch 150, Loss: 0.5337
Batch 160, Loss: 0.5502
Batch 170, Loss: 0.5516
Batch 180, Loss: 0.5533
Batch 190, Loss: 0.5342
Batch 200, Loss: 0.5466
Batch 210, Loss: 0.5500
Batch 220, Loss: 0.5335
Batch 230, Loss: 0.5488
Batch 240, Loss: 0.5867
Batch 250, Loss: 0.5538
Batch 260, Loss: 0.5542
Batch 270, Loss: 0.5167
Batch 280, Loss: 0.5326
Batch 290, Loss: 0.5946
Batch 300, Loss: 0.5769
Batch 310, Loss: 0.5461
Batch 320, Loss: 0.5316
Batch 330, Loss: 0.5763
Batch 340, Loss: 0.5938
Batch 350, Loss: 0.5389
Batch 360, Loss: 0.5890
Batch 370, Loss: 0.5789
Batch 380, Loss: 0.5998
Batch 390, Loss: 0.5864
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.203320264816284 seconds
Epoch 41 accuracy: 80.84%
Batch 10, Loss: 0.5651
Batch 20, Loss: 0.5451
Batch 30, Loss: 0.5608
Batch 40, Loss: 0.5379
Batch 50, Loss: 0.5962
Batch 60, Loss: 0.5631
Batch 70, Loss: 0.6133
Batch 80, Loss: 0.6129
Batch 90, Loss: 0.5997
Batch 100, Loss: 0.5559
Batch 110, Loss: 0.5441
Batch 120, Loss: 0.5895
Batch 130, Loss: 0.5907
Batch 140, Loss: 0.5881
Batch 150, Loss: 0.5485
Batch 160, Loss: 0.5286
Batch 170, Loss: 0.5887
Batch 180, Loss: 0.5579
Batch 190, Loss: 0.5790
Batch 200, Loss: 0.5421
Batch 210, Loss: 0.5450
Batch 220, Loss: 0.5463
Batch 230, Loss: 0.5398
Batch 240, Loss: 0.5895
Batch 250, Loss: 0.5578
Batch 260, Loss: 0.5568
Batch 270, Loss: 0.5999
Batch 280, Loss: 0.5459
Batch 290, Loss: 0.5562
Batch 300, Loss: 0.5876
Batch 310, Loss: 0.5770
Batch 320, Loss: 0.5375
Batch 330, Loss: 0.5525
Batch 340, Loss: 0.5898
Batch 350, Loss: 0.5779
Batch 360, Loss: 0.5320
Batch 370, Loss: 0.5589
Batch 380, Loss: 0.5916
Batch 390, Loss: 0.5711
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.11696457862854 seconds
Epoch 42 accuracy: 84.52%
Batch 10, Loss: 0.5616
Batch 20, Loss: 0.5560
Batch 30, Loss: 0.5557
Batch 40, Loss: 0.5571
Batch 50, Loss: 0.5191
Batch 60, Loss: 0.5751
Batch 70, Loss: 0.5528
Batch 80, Loss: 0.5288
Batch 90, Loss: 0.5838
Batch 100, Loss: 0.5431
Batch 110, Loss: 0.5753
Batch 120, Loss: 0.5448
Batch 130, Loss: 0.5841
Batch 140, Loss: 0.5742
Batch 150, Loss: 0.5791
Batch 160, Loss: 0.5358
Batch 170, Loss: 0.4890
Batch 180, Loss: 0.5486
Batch 190, Loss: 0.5794
Batch 200, Loss: 0.5120
Batch 210, Loss: 0.5370
Batch 220, Loss: 0.5322
Batch 230, Loss: 0.5385
Batch 240, Loss: 0.5439
Batch 250, Loss: 0.6031
Batch 260, Loss: 0.5862
Batch 270, Loss: 0.5647
Batch 280, Loss: 0.5352
Batch 290, Loss: 0.5258
Batch 300, Loss: 0.5754
Batch 310, Loss: 0.5819
Batch 320, Loss: 0.5909
Batch 330, Loss: 0.5747
Batch 340, Loss: 0.5285
Batch 350, Loss: 0.5651
Batch 360, Loss: 0.5808
Batch 370, Loss: 0.5444
Batch 380, Loss: 0.5345
Batch 390, Loss: 0.5460
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.20427393913269 seconds
Epoch 43 accuracy: 84.83%
Batch 10, Loss: 0.5289
Batch 20, Loss: 0.5393
Batch 30, Loss: 0.5516
Batch 40, Loss: 0.5519
Batch 50, Loss: 0.5586
Batch 60, Loss: 0.5552
Batch 70, Loss: 0.5712
Batch 80, Loss: 0.5549
Batch 90, Loss: 0.5445
Batch 100, Loss: 0.5799
Batch 110, Loss: 0.5568
Batch 120, Loss: 0.5493
Batch 130, Loss: 0.5845
Batch 140, Loss: 0.5555
Batch 150, Loss: 0.5488
Batch 160, Loss: 0.5690
Batch 170, Loss: 0.5767
Batch 180, Loss: 0.5827
Batch 190, Loss: 0.5382
Batch 200, Loss: 0.5630
Batch 210, Loss: 0.5676
Batch 220, Loss: 0.5470
Batch 230, Loss: 0.5315
Batch 240, Loss: 0.5576
Batch 250, Loss: 0.5724
Batch 260, Loss: 0.5974
Batch 270, Loss: 0.5270
Batch 280, Loss: 0.5814
Batch 290, Loss: 0.5338
Batch 300, Loss: 0.5578
Batch 310, Loss: 0.5646
Batch 320, Loss: 0.5720
Batch 330, Loss: 0.5984
Batch 340, Loss: 0.5730
Batch 350, Loss: 0.5772
Batch 360, Loss: 0.5732
Batch 370, Loss: 0.5328
Batch 380, Loss: 0.5519
Batch 390, Loss: 0.5415
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.110568523406982 seconds
Epoch 44 accuracy: 82.63%
Batch 10, Loss: 0.5952
Batch 20, Loss: 0.5468
Batch 30, Loss: 0.5524
Batch 40, Loss: 0.5393
Batch 50, Loss: 0.5620
Batch 60, Loss: 0.5645
Batch 70, Loss: 0.4924
Batch 80, Loss: 0.5788
Batch 90, Loss: 0.5650
Batch 100, Loss: 0.5440
Batch 110, Loss: 0.5613
Batch 120, Loss: 0.5568
Batch 130, Loss: 0.5691
Batch 140, Loss: 0.5342
Batch 150, Loss: 0.5603
Batch 160, Loss: 0.5376
Batch 170, Loss: 0.5735
Batch 180, Loss: 0.5775
Batch 190, Loss: 0.5368
Batch 200, Loss: 0.5648
Batch 210, Loss: 0.5504
Batch 220, Loss: 0.5414
Batch 230, Loss: 0.5678
Batch 240, Loss: 0.5419
Batch 250, Loss: 0.5424
Batch 260, Loss: 0.5198
Batch 270, Loss: 0.5982
Batch 280, Loss: 0.5774
Batch 290, Loss: 0.5368
Batch 300, Loss: 0.5810
Batch 310, Loss: 0.5156
Batch 320, Loss: 0.5708
Batch 330, Loss: 0.5423
Batch 340, Loss: 0.5419
Batch 350, Loss: 0.5563
Batch 360, Loss: 0.5799
Batch 370, Loss: 0.5745
Batch 380, Loss: 0.5677
Batch 390, Loss: 0.5611
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.03293800354004 seconds
Epoch 45 accuracy: 79.98%
Batch 10, Loss: 0.5964
Batch 20, Loss: 0.5859
Batch 30, Loss: 0.5376
Batch 40, Loss: 0.5439
Batch 50, Loss: 0.5079
Batch 60, Loss: 0.5665
Batch 70, Loss: 0.5284
Batch 80, Loss: 0.5184
Batch 90, Loss: 0.5187
Batch 100, Loss: 0.5247
Batch 110, Loss: 0.5730
Batch 120, Loss: 0.5093
Batch 130, Loss: 0.5446
Batch 140, Loss: 0.5316
Batch 150, Loss: 0.5487
Batch 160, Loss: 0.5328
Batch 170, Loss: 0.5715
Batch 180, Loss: 0.5346
Batch 190, Loss: 0.5582
Batch 200, Loss: 0.5391
Batch 210, Loss: 0.5331
Batch 220, Loss: 0.5603
Batch 230, Loss: 0.5635
Batch 240, Loss: 0.5798
Batch 250, Loss: 0.5735
Batch 260, Loss: 0.5572
Batch 270, Loss: 0.5672
Batch 280, Loss: 0.5328
Batch 290, Loss: 0.5233
Batch 300, Loss: 0.5581
Batch 310, Loss: 0.5851
Batch 320, Loss: 0.5579
Batch 330, Loss: 0.5596
Batch 340, Loss: 0.5281
Batch 350, Loss: 0.5504
Batch 360, Loss: 0.5595
Batch 370, Loss: 0.5535
Batch 380, Loss: 0.5870
Batch 390, Loss: 0.5379
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.205166578292847 seconds
Epoch 46 accuracy: 82.42%
Batch 10, Loss: 0.5492
Batch 20, Loss: 0.5050
Batch 30, Loss: 0.5474
Batch 40, Loss: 0.5498
Batch 50, Loss: 0.5546
Batch 60, Loss: 0.5894
Batch 70, Loss: 0.5491
Batch 80, Loss: 0.5547
Batch 90, Loss: 0.5622
Batch 100, Loss: 0.5218
Batch 110, Loss: 0.5384
Batch 120, Loss: 0.5337
Batch 130, Loss: 0.5269
Batch 140, Loss: 0.5698
Batch 150, Loss: 0.5555
Batch 160, Loss: 0.5652
Batch 170, Loss: 0.5693
Batch 180, Loss: 0.5308
Batch 190, Loss: 0.5515
Batch 200, Loss: 0.5523
Batch 210, Loss: 0.5628
Batch 220, Loss: 0.5546
Batch 230, Loss: 0.4769
Batch 240, Loss: 0.5710
Batch 250, Loss: 0.5847
Batch 260, Loss: 0.5778
Batch 270, Loss: 0.5487
Batch 280, Loss: 0.5448
Batch 290, Loss: 0.5388
Batch 300, Loss: 0.4918
Batch 310, Loss: 0.5490
Batch 320, Loss: 0.5687
Batch 330, Loss: 0.5538
Batch 340, Loss: 0.4897
Batch 350, Loss: 0.5869
Batch 360, Loss: 0.5589
Batch 370, Loss: 0.5301
Batch 380, Loss: 0.5195
Batch 390, Loss: 0.5872
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.158975839614868 seconds
Epoch 47 accuracy: 82.07%
Batch 10, Loss: 0.5679
Batch 20, Loss: 0.5447
Batch 30, Loss: 0.5313
Batch 40, Loss: 0.5608
Batch 50, Loss: 0.5289
Batch 60, Loss: 0.5160
Batch 70, Loss: 0.5329
Batch 80, Loss: 0.5747
Batch 90, Loss: 0.5530
Batch 100, Loss: 0.5444
Batch 110, Loss: 0.5680
Batch 120, Loss: 0.5756
Batch 130, Loss: 0.6096
Batch 140, Loss: 0.5429
Batch 150, Loss: 0.5421
Batch 160, Loss: 0.5407
Batch 170, Loss: 0.5198
Batch 180, Loss: 0.5158
Batch 190, Loss: 0.5318
Batch 200, Loss: 0.5195
Batch 210, Loss: 0.5724
Batch 220, Loss: 0.5539
Batch 230, Loss: 0.5192
Batch 240, Loss: 0.5120
Batch 250, Loss: 0.5467
Batch 260, Loss: 0.5545
Batch 270, Loss: 0.5122
Batch 280, Loss: 0.5670
Batch 290, Loss: 0.5417
Batch 300, Loss: 0.5533
Batch 310, Loss: 0.5465
Batch 320, Loss: 0.5771
Batch 330, Loss: 0.5848
Batch 340, Loss: 0.5366
Batch 350, Loss: 0.5461
Batch 360, Loss: 0.5317
Batch 370, Loss: 0.5425
Batch 380, Loss: 0.5353
Batch 390, Loss: 0.5858
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.07780146598816 seconds
Epoch 48 accuracy: 76.97%
Batch 10, Loss: 0.5751
Batch 20, Loss: 0.5725
Batch 30, Loss: 0.5243
Batch 40, Loss: 0.5405
Batch 50, Loss: 0.5492
Batch 60, Loss: 0.5394
Batch 70, Loss: 0.5100
Batch 80, Loss: 0.5722
Batch 90, Loss: 0.5400
Batch 100, Loss: 0.5825
Batch 110, Loss: 0.5450
Batch 120, Loss: 0.5572
Batch 130, Loss: 0.5511
Batch 140, Loss: 0.5357
Batch 150, Loss: 0.5427
Batch 160, Loss: 0.5583
Batch 170, Loss: 0.5524
Batch 180, Loss: 0.5753
Batch 190, Loss: 0.5702
Batch 200, Loss: 0.5875
Batch 210, Loss: 0.4957
Batch 220, Loss: 0.5207
Batch 230, Loss: 0.5736
Batch 240, Loss: 0.5104
Batch 250, Loss: 0.5744
Batch 260, Loss: 0.5175
Batch 270, Loss: 0.5428
Batch 280, Loss: 0.5768
Batch 290, Loss: 0.5704
Batch 300, Loss: 0.6073
Batch 310, Loss: 0.5716
Batch 320, Loss: 0.5759
Batch 330, Loss: 0.5557
Batch 340, Loss: 0.5397
Batch 350, Loss: 0.5305
Batch 360, Loss: 0.5255
Batch 370, Loss: 0.5422
Batch 380, Loss: 0.5390
Batch 390, Loss: 0.5551
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.19406032562256 seconds
Epoch 49 accuracy: 83.33%
Batch 10, Loss: 0.5480
Batch 20, Loss: 0.5244
Batch 30, Loss: 0.5442
Batch 40, Loss: 0.5754
Batch 50, Loss: 0.5086
Batch 60, Loss: 0.5345
Batch 70, Loss: 0.5409
Batch 80, Loss: 0.5242
Batch 90, Loss: 0.5366
Batch 100, Loss: 0.5595
Batch 110, Loss: 0.5308
Batch 120, Loss: 0.5061
Batch 130, Loss: 0.5737
Batch 140, Loss: 0.5448
Batch 150, Loss: 0.5718
Batch 160, Loss: 0.5324
Batch 170, Loss: 0.5305
Batch 180, Loss: 0.5703
Batch 190, Loss: 0.5641
Batch 200, Loss: 0.5745
Batch 210, Loss: 0.5259
Batch 220, Loss: 0.5380
Batch 230, Loss: 0.5385
Batch 240, Loss: 0.5540
Batch 250, Loss: 0.5724
Batch 260, Loss: 0.5517
Batch 270, Loss: 0.5240
Batch 280, Loss: 0.5368
Batch 290, Loss: 0.5370
Batch 300, Loss: 0.5235
Batch 310, Loss: 0.4994
Batch 320, Loss: 0.5191
Batch 330, Loss: 0.5857
Batch 340, Loss: 0.5494
Batch 350, Loss: 0.5479
Batch 360, Loss: 0.5123
Batch 370, Loss: 0.5520
Batch 380, Loss: 0.5808
Batch 390, Loss: 0.5343
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.10704207420349 seconds
Epoch 50 accuracy: 81.76%
Batch 10, Loss: 0.5687
Batch 20, Loss: 0.5556
Batch 30, Loss: 0.5612
Batch 40, Loss: 0.4994
Batch 50, Loss: 0.5451
Batch 60, Loss: 0.5298
Batch 70, Loss: 0.5452
Batch 80, Loss: 0.5123
Batch 90, Loss: 0.5313
Batch 100, Loss: 0.5262
Batch 110, Loss: 0.5406
Batch 120, Loss: 0.5328
Batch 130, Loss: 0.5355
Batch 140, Loss: 0.5405
Batch 150, Loss: 0.5301
Batch 160, Loss: 0.5662
Batch 170, Loss: 0.5328
Batch 180, Loss: 0.5323
Batch 190, Loss: 0.5398
Batch 200, Loss: 0.5644
Batch 210, Loss: 0.5725
Batch 220, Loss: 0.5301
Batch 230, Loss: 0.5728
Batch 240, Loss: 0.5371
Batch 250, Loss: 0.5749
Batch 260, Loss: 0.5981
Batch 270, Loss: 0.5771
Batch 280, Loss: 0.5561
Batch 290, Loss: 0.5718
Batch 300, Loss: 0.5293
Batch 310, Loss: 0.5430
Batch 320, Loss: 0.5260
Batch 330, Loss: 0.5363
Batch 340, Loss: 0.5396
Batch 350, Loss: 0.5470
Batch 360, Loss: 0.4874
Batch 370, Loss: 0.4874
Batch 380, Loss: 0.5409
Batch 390, Loss: 0.5043
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.01865839958191 seconds
Epoch 51 accuracy: 83.22%
Batch 10, Loss: 0.5335
Batch 20, Loss: 0.5158
Batch 30, Loss: 0.5545
Batch 40, Loss: 0.5977
Batch 50, Loss: 0.5362
Batch 60, Loss: 0.5259
Batch 70, Loss: 0.5148
Batch 80, Loss: 0.5647
Batch 90, Loss: 0.5689
Batch 100, Loss: 0.5310
Batch 110, Loss: 0.5291
Batch 120, Loss: 0.5359
Batch 130, Loss: 0.5794
Batch 140, Loss: 0.5281
Batch 150, Loss: 0.5558
Batch 160, Loss: 0.5619
Batch 170, Loss: 0.5593
Batch 180, Loss: 0.5687
Batch 190, Loss: 0.5300
Batch 200, Loss: 0.5483
Batch 210, Loss: 0.5699
Batch 220, Loss: 0.5095
Batch 230, Loss: 0.5590
Batch 240, Loss: 0.5412
Batch 250, Loss: 0.5417
Batch 260, Loss: 0.5033
Batch 270, Loss: 0.5533
Batch 280, Loss: 0.4905
Batch 290, Loss: 0.5340
Batch 300, Loss: 0.5476
Batch 310, Loss: 0.5061
Batch 320, Loss: 0.5656
Batch 330, Loss: 0.5228
Batch 340, Loss: 0.5445
Batch 350, Loss: 0.5479
Batch 360, Loss: 0.5448
Batch 370, Loss: 0.5358
Batch 380, Loss: 0.5547
Batch 390, Loss: 0.5513
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.14642572402954 seconds
Epoch 52 accuracy: 83.76%
Batch 10, Loss: 0.5270
Batch 20, Loss: 0.5221
Batch 30, Loss: 0.5543
Batch 40, Loss: 0.5213
Batch 50, Loss: 0.4984
Batch 60, Loss: 0.5075
Batch 70, Loss: 0.4701
Batch 80, Loss: 0.5178
Batch 90, Loss: 0.5994
Batch 100, Loss: 0.5837
Batch 110, Loss: 0.5545
Batch 120, Loss: 0.5484
Batch 130, Loss: 0.5184
Batch 140, Loss: 0.5209
Batch 150, Loss: 0.5243
Batch 160, Loss: 0.5453
Batch 170, Loss: 0.5295
Batch 180, Loss: 0.5324
Batch 190, Loss: 0.5586
Batch 200, Loss: 0.5121
Batch 210, Loss: 0.5773
Batch 220, Loss: 0.5720
Batch 230, Loss: 0.5472
Batch 240, Loss: 0.5550
Batch 250, Loss: 0.6071
Batch 260, Loss: 0.5267
Batch 270, Loss: 0.5617
Batch 280, Loss: 0.5218
Batch 290, Loss: 0.5164
Batch 300, Loss: 0.5834
Batch 310, Loss: 0.5560
Batch 320, Loss: 0.5113
Batch 330, Loss: 0.6047
Batch 340, Loss: 0.5581
Batch 350, Loss: 0.5355
Batch 360, Loss: 0.5357
Batch 370, Loss: 0.5417
Batch 380, Loss: 0.5921
Batch 390, Loss: 0.5328
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.141603231430054 seconds
Epoch 53 accuracy: 83.84%
Batch 10, Loss: 0.5391
Batch 20, Loss: 0.5391
Batch 30, Loss: 0.4943
Batch 40, Loss: 0.5124
Batch 50, Loss: 0.5178
Batch 60, Loss: 0.5527
Batch 70, Loss: 0.5723
Batch 80, Loss: 0.5633
Batch 90, Loss: 0.5519
Batch 100, Loss: 0.5043
Batch 110, Loss: 0.5481
Batch 120, Loss: 0.5213
Batch 130, Loss: 0.5305
Batch 140, Loss: 0.5219
Batch 150, Loss: 0.5767
Batch 160, Loss: 0.5090
Batch 170, Loss: 0.5510
Batch 180, Loss: 0.5606
Batch 190, Loss: 0.5357
Batch 200, Loss: 0.5490
Batch 210, Loss: 0.5201
Batch 220, Loss: 0.5425
Batch 230, Loss: 0.5591
Batch 240, Loss: 0.5400
Batch 250, Loss: 0.5732
Batch 260, Loss: 0.5379
Batch 270, Loss: 0.5046
Batch 280, Loss: 0.4953
Batch 290, Loss: 0.5200
Batch 300, Loss: 0.5494
Batch 310, Loss: 0.5536
Batch 320, Loss: 0.5378
Batch 330, Loss: 0.5420
Batch 340, Loss: 0.5590
Batch 350, Loss: 0.5331
Batch 360, Loss: 0.5449
Batch 370, Loss: 0.5310
Batch 380, Loss: 0.5374
Batch 390, Loss: 0.4927
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.061039924621582 seconds
Epoch 54 accuracy: 84.82%
Batch 10, Loss: 0.5735
Batch 20, Loss: 0.5282
Batch 30, Loss: 0.5469
Batch 40, Loss: 0.5145
Batch 50, Loss: 0.5690
Batch 60, Loss: 0.5811
Batch 70, Loss: 0.5709
Batch 80, Loss: 0.5410
Batch 90, Loss: 0.5597
Batch 100, Loss: 0.5460
Batch 110, Loss: 0.5429
Batch 120, Loss: 0.5016
Batch 130, Loss: 0.5082
Batch 140, Loss: 0.4931
Batch 150, Loss: 0.5643
Batch 160, Loss: 0.5179
Batch 170, Loss: 0.5430
Batch 180, Loss: 0.5224
Batch 190, Loss: 0.5412
Batch 200, Loss: 0.5189
Batch 210, Loss: 0.5268
Batch 220, Loss: 0.5134
Batch 230, Loss: 0.5255
Batch 240, Loss: 0.5579
Batch 250, Loss: 0.4895
Batch 260, Loss: 0.5386
Batch 270, Loss: 0.5898
Batch 280, Loss: 0.5355
Batch 290, Loss: 0.5406
Batch 300, Loss: 0.5190
Batch 310, Loss: 0.5498
Batch 320, Loss: 0.5465
Batch 330, Loss: 0.5793
Batch 340, Loss: 0.5587
Batch 350, Loss: 0.4917
Batch 360, Loss: 0.5406
Batch 370, Loss: 0.5429
Batch 380, Loss: 0.5126
Batch 390, Loss: 0.5495
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.08423924446106 seconds
Epoch 55 accuracy: 79.2%
Batch 10, Loss: 0.5375
Batch 20, Loss: 0.5800
Batch 30, Loss: 0.5313
Batch 40, Loss: 0.5034
Batch 50, Loss: 0.5575
Batch 60, Loss: 0.5246
Batch 70, Loss: 0.4963
Batch 80, Loss: 0.5380
Batch 90, Loss: 0.5300
Batch 100, Loss: 0.5233
Batch 110, Loss: 0.5169
Batch 120, Loss: 0.5346
Batch 130, Loss: 0.5325
Batch 140, Loss: 0.5205
Batch 150, Loss: 0.5676
Batch 160, Loss: 0.5281
Batch 170, Loss: 0.5378
Batch 180, Loss: 0.5335
Batch 190, Loss: 0.5184
Batch 200, Loss: 0.4797
Batch 210, Loss: 0.4884
Batch 220, Loss: 0.5208
Batch 230, Loss: 0.5258
Batch 240, Loss: 0.5558
Batch 250, Loss: 0.5207
Batch 260, Loss: 0.5465
Batch 270, Loss: 0.5447
Batch 280, Loss: 0.5239
Batch 290, Loss: 0.5308
Batch 300, Loss: 0.5525
Batch 310, Loss: 0.5268
Batch 320, Loss: 0.5427
Batch 330, Loss: 0.5100
Batch 340, Loss: 0.5519
Batch 350, Loss: 0.5533
Batch 360, Loss: 0.5635
Batch 370, Loss: 0.5453
Batch 380, Loss: 0.5266
Batch 390, Loss: 0.5522
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.13096833229065 seconds
Epoch 56 accuracy: 81.31%
Batch 10, Loss: 0.5689
Batch 20, Loss: 0.5311
Batch 30, Loss: 0.5163
Batch 40, Loss: 0.5291
Batch 50, Loss: 0.5303
Batch 60, Loss: 0.4972
Batch 70, Loss: 0.5550
Batch 80, Loss: 0.5224
Batch 90, Loss: 0.5980
Batch 100, Loss: 0.5472
Batch 110, Loss: 0.5358
Batch 120, Loss: 0.5358
Batch 130, Loss: 0.5235
Batch 140, Loss: 0.5102
Batch 150, Loss: 0.5330
Batch 160, Loss: 0.5365
Batch 170, Loss: 0.5044
Batch 180, Loss: 0.5467
Batch 190, Loss: 0.5617
Batch 200, Loss: 0.5302
Batch 210, Loss: 0.5368
Batch 220, Loss: 0.5232
Batch 230, Loss: 0.5220
Batch 240, Loss: 0.5281
Batch 250, Loss: 0.5237
Batch 260, Loss: 0.5365
Batch 270, Loss: 0.5138
Batch 280, Loss: 0.5167
Batch 290, Loss: 0.5367
Batch 300, Loss: 0.5503
Batch 310, Loss: 0.5448
Batch 320, Loss: 0.5270
Batch 330, Loss: 0.5042
Batch 340, Loss: 0.5260
Batch 350, Loss: 0.5040
Batch 360, Loss: 0.5692
Batch 370, Loss: 0.5405
Batch 380, Loss: 0.5365
Batch 390, Loss: 0.5044
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.141366720199585 seconds
Epoch 57 accuracy: 83.19%
Batch 10, Loss: 0.5193
Batch 20, Loss: 0.5178
Batch 30, Loss: 0.4991
Batch 40, Loss: 0.5393
Batch 50, Loss: 0.5263
Batch 60, Loss: 0.5292
Batch 70, Loss: 0.4899
Batch 80, Loss: 0.5155
Batch 90, Loss: 0.5238
Batch 100, Loss: 0.5346
Batch 110, Loss: 0.5413
Batch 120, Loss: 0.5080
Batch 130, Loss: 0.5497
Batch 140, Loss: 0.5215
Batch 150, Loss: 0.5422
Batch 160, Loss: 0.5382
Batch 170, Loss: 0.5376
Batch 180, Loss: 0.5553
Batch 190, Loss: 0.5387
Batch 200, Loss: 0.5410
Batch 210, Loss: 0.5373
Batch 220, Loss: 0.5288
Batch 230, Loss: 0.5246
Batch 240, Loss: 0.5436
Batch 250, Loss: 0.5257
Batch 260, Loss: 0.5224
Batch 270, Loss: 0.5163
Batch 280, Loss: 0.5431
Batch 290, Loss: 0.5098
Batch 300, Loss: 0.4988
Batch 310, Loss: 0.5056
Batch 320, Loss: 0.5087
Batch 330, Loss: 0.5427
Batch 340, Loss: 0.5320
Batch 350, Loss: 0.5474
Batch 360, Loss: 0.5629
Batch 370, Loss: 0.5342
Batch 380, Loss: 0.5436
Batch 390, Loss: 0.5361
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.20637583732605 seconds
Epoch 58 accuracy: 84.81%
Batch 10, Loss: 0.5185
Batch 20, Loss: 0.5384
Batch 30, Loss: 0.5583
Batch 40, Loss: 0.4874
Batch 50, Loss: 0.5497
Batch 60, Loss: 0.4965
Batch 70, Loss: 0.5490
Batch 80, Loss: 0.5205
Batch 90, Loss: 0.5448
Batch 100, Loss: 0.5352
Batch 110, Loss: 0.5413
Batch 120, Loss: 0.5334
Batch 130, Loss: 0.5577
Batch 140, Loss: 0.5255
Batch 150, Loss: 0.4952
Batch 160, Loss: 0.5129
Batch 170, Loss: 0.4974
Batch 180, Loss: 0.5344
Batch 190, Loss: 0.5384
Batch 200, Loss: 0.5449
Batch 210, Loss: 0.5330
Batch 220, Loss: 0.5741
Batch 230, Loss: 0.5504
Batch 240, Loss: 0.5382
Batch 250, Loss: 0.5331
Batch 260, Loss: 0.5577
Batch 270, Loss: 0.5283
Batch 280, Loss: 0.5017
Batch 290, Loss: 0.4944
Batch 300, Loss: 0.5079
Batch 310, Loss: 0.5338
Batch 320, Loss: 0.5441
Batch 330, Loss: 0.5687
Batch 340, Loss: 0.5254
Batch 350, Loss: 0.5079
Batch 360, Loss: 0.5145
Batch 370, Loss: 0.4995
Batch 380, Loss: 0.5894
Batch 390, Loss: 0.5493
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.079110622406006 seconds
Epoch 59 accuracy: 83.05%
Batch 10, Loss: 0.5131
Batch 20, Loss: 0.5051
Batch 30, Loss: 0.5212
Batch 40, Loss: 0.5039
Batch 50, Loss: 0.4927
Batch 60, Loss: 0.5176
Batch 70, Loss: 0.5556
Batch 80, Loss: 0.5427
Batch 90, Loss: 0.5292
Batch 100, Loss: 0.5092
Batch 110, Loss: 0.4966
Batch 120, Loss: 0.5248
Batch 130, Loss: 0.5099
Batch 140, Loss: 0.5671
Batch 150, Loss: 0.5676
Batch 160, Loss: 0.5547
Batch 170, Loss: 0.5603
Batch 180, Loss: 0.4765
Batch 190, Loss: 0.5140
Batch 200, Loss: 0.4911
Batch 210, Loss: 0.4884
Batch 220, Loss: 0.5426
Batch 230, Loss: 0.5616
Batch 240, Loss: 0.5071
Batch 250, Loss: 0.5618
Batch 260, Loss: 0.5489
Batch 270, Loss: 0.5379
Batch 280, Loss: 0.5424
Batch 290, Loss: 0.5509
Batch 300, Loss: 0.5537
Batch 310, Loss: 0.5152
Batch 320, Loss: 0.5154
Batch 330, Loss: 0.5115
Batch 340, Loss: 0.5090
Batch 350, Loss: 0.5118
Batch 360, Loss: 0.5492
Batch 370, Loss: 0.5004
Batch 380, Loss: 0.5250
Batch 390, Loss: 0.5512
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.125512838363647 seconds
Epoch 60 accuracy: 83.07%
Batch 10, Loss: 0.5196
Batch 20, Loss: 0.4879
Batch 30, Loss: 0.4694
Batch 40, Loss: 0.5255
Batch 50, Loss: 0.5385
Batch 60, Loss: 0.5511
Batch 70, Loss: 0.4947
Batch 80, Loss: 0.4924
Batch 90, Loss: 0.5458
Batch 100, Loss: 0.4698
Batch 110, Loss: 0.5497
Batch 120, Loss: 0.5251
Batch 130, Loss: 0.5259
Batch 140, Loss: 0.5373
Batch 150, Loss: 0.5258
Batch 160, Loss: 0.5219
Batch 170, Loss: 0.5341
Batch 180, Loss: 0.4992
Batch 190, Loss: 0.5065
Batch 200, Loss: 0.5320
Batch 210, Loss: 0.5192
Batch 220, Loss: 0.5043
Batch 230, Loss: 0.5468
Batch 240, Loss: 0.5798
Batch 250, Loss: 0.5643
Batch 260, Loss: 0.5363
Batch 270, Loss: 0.5652
Batch 280, Loss: 0.5258
Batch 290, Loss: 0.5369
Batch 300, Loss: 0.5008
Batch 310, Loss: 0.5446
Batch 320, Loss: 0.5336
Batch 330, Loss: 0.5231
Batch 340, Loss: 0.5381
Batch 350, Loss: 0.4849
Batch 360, Loss: 0.5204
Batch 370, Loss: 0.5253
Batch 380, Loss: 0.5487
Batch 390, Loss: 0.5174
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.081924200057983 seconds
Epoch 61 accuracy: 80.59%
Batch 10, Loss: 0.5047
Batch 20, Loss: 0.5077
Batch 30, Loss: 0.4905
Batch 40, Loss: 0.4715
Batch 50, Loss: 0.4780
Batch 60, Loss: 0.4797
Batch 70, Loss: 0.5034
Batch 80, Loss: 0.5306
Batch 90, Loss: 0.5264
Batch 100, Loss: 0.5200
Batch 110, Loss: 0.5336
Batch 120, Loss: 0.5333
Batch 130, Loss: 0.5253
Batch 140, Loss: 0.5010
Batch 150, Loss: 0.5344
Batch 160, Loss: 0.5545
Batch 170, Loss: 0.5547
Batch 180, Loss: 0.5337
Batch 190, Loss: 0.5377
Batch 200, Loss: 0.5323
Batch 210, Loss: 0.5044
Batch 220, Loss: 0.5039
Batch 230, Loss: 0.5233
Batch 240, Loss: 0.4865
Batch 250, Loss: 0.4984
Batch 260, Loss: 0.5128
Batch 270, Loss: 0.5063
Batch 280, Loss: 0.5084
Batch 290, Loss: 0.5399
Batch 300, Loss: 0.5151
Batch 310, Loss: 0.5290
Batch 320, Loss: 0.5176
Batch 330, Loss: 0.5391
Batch 340, Loss: 0.5497
Batch 350, Loss: 0.5113
Batch 360, Loss: 0.5312
Batch 370, Loss: 0.5295
Batch 380, Loss: 0.4950
Batch 390, Loss: 0.5435
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.139322519302368 seconds
Epoch 62 accuracy: 80.87%
Batch 10, Loss: 0.5271
Batch 20, Loss: 0.4914
Batch 30, Loss: 0.5074
Batch 40, Loss: 0.5244
Batch 50, Loss: 0.4971
Batch 60, Loss: 0.5374
Batch 70, Loss: 0.5450
Batch 80, Loss: 0.5146
Batch 90, Loss: 0.5663
Batch 100, Loss: 0.5356
Batch 110, Loss: 0.5017
Batch 120, Loss: 0.4839
Batch 130, Loss: 0.5187
Batch 140, Loss: 0.5270
Batch 150, Loss: 0.5343
Batch 160, Loss: 0.4745
Batch 170, Loss: 0.5011
Batch 180, Loss: 0.5540
Batch 190, Loss: 0.4941
Batch 200, Loss: 0.5155
Batch 210, Loss: 0.5560
Batch 220, Loss: 0.5289
Batch 230, Loss: 0.4799
Batch 240, Loss: 0.5124
Batch 250, Loss: 0.5519
Batch 260, Loss: 0.5290
Batch 270, Loss: 0.4882
Batch 280, Loss: 0.5130
Batch 290, Loss: 0.5175
Batch 300, Loss: 0.5130
Batch 310, Loss: 0.5241
Batch 320, Loss: 0.5284
Batch 330, Loss: 0.5053
Batch 340, Loss: 0.5299
Batch 350, Loss: 0.5117
Batch 360, Loss: 0.4830
Batch 370, Loss: 0.5743
Batch 380, Loss: 0.5468
Batch 390, Loss: 0.5701
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.00980854034424 seconds
Epoch 63 accuracy: 85.47%
Batch 10, Loss: 0.5341
Batch 20, Loss: 0.5463
Batch 30, Loss: 0.5350
Batch 40, Loss: 0.5306
Batch 50, Loss: 0.4803
Batch 60, Loss: 0.4861
Batch 70, Loss: 0.5090
Batch 80, Loss: 0.5082
Batch 90, Loss: 0.5137
Batch 100, Loss: 0.4995
Batch 110, Loss: 0.5940
Batch 120, Loss: 0.5052
Batch 130, Loss: 0.5065
Batch 140, Loss: 0.5340
Batch 150, Loss: 0.5573
Batch 160, Loss: 0.5041
Batch 170, Loss: 0.5544
Batch 180, Loss: 0.5021
Batch 190, Loss: 0.5194
Batch 200, Loss: 0.4988
Batch 210, Loss: 0.5329
Batch 220, Loss: 0.5163
Batch 230, Loss: 0.5135
Batch 240, Loss: 0.5169
Batch 250, Loss: 0.4988
Batch 260, Loss: 0.5382
Batch 270, Loss: 0.5157
Batch 280, Loss: 0.5161
Batch 290, Loss: 0.4925
Batch 300, Loss: 0.5219
Batch 310, Loss: 0.5127
Batch 320, Loss: 0.5222
Batch 330, Loss: 0.4959
Batch 340, Loss: 0.4998
Batch 350, Loss: 0.5360
Batch 360, Loss: 0.5281
Batch 370, Loss: 0.4702
Batch 380, Loss: 0.5365
Batch 390, Loss: 0.5054
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.21795630455017 seconds
Epoch 64 accuracy: 85.15%
Batch 10, Loss: 0.5057
Batch 20, Loss: 0.5173
Batch 30, Loss: 0.5460
Batch 40, Loss: 0.5286
Batch 50, Loss: 0.5424
Batch 60, Loss: 0.5075
Batch 70, Loss: 0.4947
Batch 80, Loss: 0.5156
Batch 90, Loss: 0.5101
Batch 100, Loss: 0.5265
Batch 110, Loss: 0.5039
Batch 120, Loss: 0.4953
Batch 130, Loss: 0.5000
Batch 140, Loss: 0.5331
Batch 150, Loss: 0.4937
Batch 160, Loss: 0.5247
Batch 170, Loss: 0.5041
Batch 180, Loss: 0.5308
Batch 190, Loss: 0.5023
Batch 200, Loss: 0.5094
Batch 210, Loss: 0.5205
Batch 220, Loss: 0.5201
Batch 230, Loss: 0.5482
Batch 240, Loss: 0.5418
Batch 250, Loss: 0.4926
Batch 260, Loss: 0.5195
Batch 270, Loss: 0.5266
Batch 280, Loss: 0.5228
Batch 290, Loss: 0.5007
Batch 300, Loss: 0.5120
Batch 310, Loss: 0.5255
Batch 320, Loss: 0.4903
Batch 330, Loss: 0.5296
Batch 340, Loss: 0.5212
Batch 350, Loss: 0.5111
Batch 360, Loss: 0.5320
Batch 370, Loss: 0.5355
Batch 380, Loss: 0.4944
Batch 390, Loss: 0.5003
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.031060695648193 seconds
Epoch 65 accuracy: 86.02%
Batch 10, Loss: 0.4981
Batch 20, Loss: 0.5006
Batch 30, Loss: 0.5589
Batch 40, Loss: 0.5147
Batch 50, Loss: 0.5400
Batch 60, Loss: 0.4945
Batch 70, Loss: 0.5045
Batch 80, Loss: 0.5397
Batch 90, Loss: 0.5285
Batch 100, Loss: 0.5064
Batch 110, Loss: 0.4786
Batch 120, Loss: 0.4832
Batch 130, Loss: 0.5035
Batch 140, Loss: 0.4800
Batch 150, Loss: 0.5338
Batch 160, Loss: 0.5062
Batch 170, Loss: 0.4980
Batch 180, Loss: 0.4707
Batch 190, Loss: 0.4617
Batch 200, Loss: 0.5298
Batch 210, Loss: 0.5072
Batch 220, Loss: 0.4976
Batch 230, Loss: 0.4795
Batch 240, Loss: 0.5445
Batch 250, Loss: 0.5048
Batch 260, Loss: 0.5399
Batch 270, Loss: 0.4965
Batch 280, Loss: 0.5034
Batch 290, Loss: 0.5167
Batch 300, Loss: 0.5081
Batch 310, Loss: 0.5124
Batch 320, Loss: 0.5234
Batch 330, Loss: 0.5202
Batch 340, Loss: 0.5074
Batch 350, Loss: 0.4629
Batch 360, Loss: 0.5031
Batch 370, Loss: 0.5521
Batch 380, Loss: 0.5362
Batch 390, Loss: 0.5331
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.123592138290405 seconds
Epoch 66 accuracy: 85.51%
Batch 10, Loss: 0.4672
Batch 20, Loss: 0.4929
Batch 30, Loss: 0.4900
Batch 40, Loss: 0.4824
Batch 50, Loss: 0.4913
Batch 60, Loss: 0.5603
Batch 70, Loss: 0.5185
Batch 80, Loss: 0.5002
Batch 90, Loss: 0.5340
Batch 100, Loss: 0.4876
Batch 110, Loss: 0.5136
Batch 120, Loss: 0.5297
Batch 130, Loss: 0.4851
Batch 140, Loss: 0.5119
Batch 150, Loss: 0.5209
Batch 160, Loss: 0.5161
Batch 170, Loss: 0.4862
Batch 180, Loss: 0.5872
Batch 190, Loss: 0.4705
Batch 200, Loss: 0.4900
Batch 210, Loss: 0.5313
Batch 220, Loss: 0.5263
Batch 230, Loss: 0.5040
Batch 240, Loss: 0.4962
Batch 250, Loss: 0.5581
Batch 260, Loss: 0.4711
Batch 270, Loss: 0.4898
Batch 280, Loss: 0.5049
Batch 290, Loss: 0.5216
Batch 300, Loss: 0.5073
Batch 310, Loss: 0.5356
Batch 320, Loss: 0.5231
Batch 330, Loss: 0.5355
Batch 340, Loss: 0.5187
Batch 350, Loss: 0.5119
Batch 360, Loss: 0.4714
Batch 370, Loss: 0.5317
Batch 380, Loss: 0.4904
Batch 390, Loss: 0.5141
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.087369203567505 seconds
Epoch 67 accuracy: 86.75%
Batch 10, Loss: 0.5500
Batch 20, Loss: 0.5242
Batch 30, Loss: 0.4710
Batch 40, Loss: 0.4954
Batch 50, Loss: 0.5355
Batch 60, Loss: 0.5089
Batch 70, Loss: 0.4874
Batch 80, Loss: 0.4845
Batch 90, Loss: 0.5572
Batch 100, Loss: 0.5165
Batch 110, Loss: 0.5599
Batch 120, Loss: 0.5345
Batch 130, Loss: 0.4952
Batch 140, Loss: 0.4980
Batch 150, Loss: 0.5216
Batch 160, Loss: 0.5077
Batch 170, Loss: 0.5163
Batch 180, Loss: 0.4923
Batch 190, Loss: 0.4971
Batch 200, Loss: 0.4769
Batch 210, Loss: 0.5065
Batch 220, Loss: 0.5046
Batch 230, Loss: 0.5232
Batch 240, Loss: 0.5409
Batch 250, Loss: 0.5600
Batch 260, Loss: 0.5358
Batch 270, Loss: 0.5159
Batch 280, Loss: 0.5094
Batch 290, Loss: 0.5072
Batch 300, Loss: 0.5230
Batch 310, Loss: 0.5467
Batch 320, Loss: 0.4866
Batch 330, Loss: 0.5284
Batch 340, Loss: 0.4885
Batch 350, Loss: 0.4750
Batch 360, Loss: 0.5078
Batch 370, Loss: 0.5127
Batch 380, Loss: 0.5500
Batch 390, Loss: 0.5159
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.045339822769165 seconds
Epoch 68 accuracy: 85.03%
Batch 10, Loss: 0.4612
Batch 20, Loss: 0.4990
Batch 30, Loss: 0.5084
Batch 40, Loss: 0.5087
Batch 50, Loss: 0.4825
Batch 60, Loss: 0.4981
Batch 70, Loss: 0.4855
Batch 80, Loss: 0.5088
Batch 90, Loss: 0.5070
Batch 100, Loss: 0.5209
Batch 110, Loss: 0.4989
Batch 120, Loss: 0.5331
Batch 130, Loss: 0.5205
Batch 140, Loss: 0.4756
Batch 150, Loss: 0.5301
Batch 160, Loss: 0.5012
Batch 170, Loss: 0.5102
Batch 180, Loss: 0.5266
Batch 190, Loss: 0.5179
Batch 200, Loss: 0.5025
Batch 210, Loss: 0.4988
Batch 220, Loss: 0.5354
Batch 230, Loss: 0.5103
Batch 240, Loss: 0.5418
Batch 250, Loss: 0.5049
Batch 260, Loss: 0.4688
Batch 270, Loss: 0.5113
Batch 280, Loss: 0.5300
Batch 290, Loss: 0.5483
Batch 300, Loss: 0.4934
Batch 310, Loss: 0.5192
Batch 320, Loss: 0.5258
Batch 330, Loss: 0.5156
Batch 340, Loss: 0.5316
Batch 350, Loss: 0.5140
Batch 360, Loss: 0.5014
Batch 370, Loss: 0.5140
Batch 380, Loss: 0.5454
Batch 390, Loss: 0.5290
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.17220139503479 seconds
Epoch 69 accuracy: 82.85%
Batch 10, Loss: 0.4865
Batch 20, Loss: 0.4843
Batch 30, Loss: 0.5161
Batch 40, Loss: 0.4827
Batch 50, Loss: 0.4985
Batch 60, Loss: 0.4858
Batch 70, Loss: 0.5342
Batch 80, Loss: 0.4998
Batch 90, Loss: 0.5206
Batch 100, Loss: 0.5417
Batch 110, Loss: 0.5047
Batch 120, Loss: 0.4815
Batch 130, Loss: 0.5026
Batch 140, Loss: 0.5321
Batch 150, Loss: 0.5177
Batch 160, Loss: 0.5003
Batch 170, Loss: 0.4970
Batch 180, Loss: 0.5480
Batch 190, Loss: 0.5494
Batch 200, Loss: 0.5030
Batch 210, Loss: 0.4804
Batch 220, Loss: 0.4944
Batch 230, Loss: 0.5322
Batch 240, Loss: 0.4767
Batch 250, Loss: 0.4899
Batch 260, Loss: 0.5039
Batch 270, Loss: 0.5166
Batch 280, Loss: 0.4904
Batch 290, Loss: 0.4920
Batch 300, Loss: 0.5258
Batch 310, Loss: 0.5440
Batch 320, Loss: 0.5097
Batch 330, Loss: 0.5181
Batch 340, Loss: 0.5106
Batch 350, Loss: 0.5024
Batch 360, Loss: 0.4808
Batch 370, Loss: 0.5256
Batch 380, Loss: 0.5363
Batch 390, Loss: 0.5161
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.026062488555908 seconds
Epoch 70 accuracy: 87.45%
Batch 10, Loss: 0.4601
Batch 20, Loss: 0.4822
Batch 30, Loss: 0.4881
Batch 40, Loss: 0.5108
Batch 50, Loss: 0.5378
Batch 60, Loss: 0.4895
Batch 70, Loss: 0.5160
Batch 80, Loss: 0.4852
Batch 90, Loss: 0.5163
Batch 100, Loss: 0.5068
Batch 110, Loss: 0.5240
Batch 120, Loss: 0.5415
Batch 130, Loss: 0.4908
Batch 140, Loss: 0.5048
Batch 150, Loss: 0.4816
Batch 160, Loss: 0.4920
Batch 170, Loss: 0.5134
Batch 180, Loss: 0.5862
Batch 190, Loss: 0.5330
Batch 200, Loss: 0.5231
Batch 210, Loss: 0.5012
Batch 220, Loss: 0.4874
Batch 230, Loss: 0.5329
Batch 240, Loss: 0.5294
Batch 250, Loss: 0.5480
Batch 260, Loss: 0.4701
Batch 270, Loss: 0.4615
Batch 280, Loss: 0.5339
Batch 290, Loss: 0.4841
Batch 300, Loss: 0.5002
Batch 310, Loss: 0.5018
Batch 320, Loss: 0.5121
Batch 330, Loss: 0.4867
Batch 340, Loss: 0.5136
Batch 350, Loss: 0.5058
Batch 360, Loss: 0.4684
Batch 370, Loss: 0.4913
Batch 380, Loss: 0.4864
Batch 390, Loss: 0.5034
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.897913455963135 seconds
Epoch 71 accuracy: 86.71%
Batch 10, Loss: 0.5121
Batch 20, Loss: 0.4680
Batch 30, Loss: 0.4629
Batch 40, Loss: 0.5535
Batch 50, Loss: 0.5151
Batch 60, Loss: 0.4900
Batch 70, Loss: 0.4917
Batch 80, Loss: 0.4988
Batch 90, Loss: 0.5011
Batch 100, Loss: 0.4943
Batch 110, Loss: 0.4966
Batch 120, Loss: 0.5048
Batch 130, Loss: 0.4948
Batch 140, Loss: 0.4909
Batch 150, Loss: 0.5055
Batch 160, Loss: 0.4806
Batch 170, Loss: 0.4979
Batch 180, Loss: 0.5201
Batch 190, Loss: 0.5152
Batch 200, Loss: 0.4867
Batch 210, Loss: 0.5209
Batch 220, Loss: 0.5178
Batch 230, Loss: 0.5155
Batch 240, Loss: 0.4985
Batch 250, Loss: 0.5323
Batch 260, Loss: 0.4977
Batch 270, Loss: 0.4837
Batch 280, Loss: 0.5062
Batch 290, Loss: 0.5179
Batch 300, Loss: 0.5222
Batch 310, Loss: 0.5324
Batch 320, Loss: 0.4965
Batch 330, Loss: 0.4805
Batch 340, Loss: 0.5259
Batch 350, Loss: 0.5124
Batch 360, Loss: 0.5081
Batch 370, Loss: 0.4963
Batch 380, Loss: 0.5314
Batch 390, Loss: 0.4732
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.131179094314575 seconds
Epoch 72 accuracy: 85.18%
Batch 10, Loss: 0.5291
Batch 20, Loss: 0.5081
Batch 30, Loss: 0.4948
Batch 40, Loss: 0.4563
Batch 50, Loss: 0.4325
Batch 60, Loss: 0.4752
Batch 70, Loss: 0.4769
Batch 80, Loss: 0.4858
Batch 90, Loss: 0.4845
Batch 100, Loss: 0.5269
Batch 110, Loss: 0.5403
Batch 120, Loss: 0.4978
Batch 130, Loss: 0.4798
Batch 140, Loss: 0.5077
Batch 150, Loss: 0.4787
Batch 160, Loss: 0.4986
Batch 170, Loss: 0.4925
Batch 180, Loss: 0.5012
Batch 190, Loss: 0.4697
Batch 200, Loss: 0.5347
Batch 210, Loss: 0.5142
Batch 220, Loss: 0.5289
Batch 230, Loss: 0.5215
Batch 240, Loss: 0.4633
Batch 250, Loss: 0.4924
Batch 260, Loss: 0.4742
Batch 270, Loss: 0.4995
Batch 280, Loss: 0.5037
Batch 290, Loss: 0.5122
Batch 300, Loss: 0.5184
Batch 310, Loss: 0.4992
Batch 320, Loss: 0.4938
Batch 330, Loss: 0.4715
Batch 340, Loss: 0.4567
Batch 350, Loss: 0.4545
Batch 360, Loss: 0.4906
Batch 370, Loss: 0.5251
Batch 380, Loss: 0.5212
Batch 390, Loss: 0.5476
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.14305329322815 seconds
Epoch 73 accuracy: 84.71%
Batch 10, Loss: 0.5192
Batch 20, Loss: 0.4486
Batch 30, Loss: 0.4671
Batch 40, Loss: 0.5387
Batch 50, Loss: 0.5239
Batch 60, Loss: 0.4669
Batch 70, Loss: 0.4938
Batch 80, Loss: 0.5093
Batch 90, Loss: 0.4998
Batch 100, Loss: 0.4781
Batch 110, Loss: 0.4707
Batch 120, Loss: 0.5093
Batch 130, Loss: 0.5083
Batch 140, Loss: 0.4936
Batch 150, Loss: 0.5683
Batch 160, Loss: 0.5085
Batch 170, Loss: 0.5131
Batch 180, Loss: 0.5175
Batch 190, Loss: 0.4464
Batch 200, Loss: 0.4776
Batch 210, Loss: 0.5015
Batch 220, Loss: 0.4766
Batch 230, Loss: 0.4885
Batch 240, Loss: 0.5012
Batch 250, Loss: 0.4620
Batch 260, Loss: 0.4858
Batch 270, Loss: 0.5123
Batch 280, Loss: 0.5138
Batch 290, Loss: 0.4940
Batch 300, Loss: 0.5065
Batch 310, Loss: 0.5337
Batch 320, Loss: 0.5037
Batch 330, Loss: 0.4930
Batch 340, Loss: 0.5191
Batch 350, Loss: 0.4996
Batch 360, Loss: 0.4812
Batch 370, Loss: 0.4720
Batch 380, Loss: 0.4733
Batch 390, Loss: 0.4882
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.086440563201904 seconds
Epoch 74 accuracy: 84.17%
Batch 10, Loss: 0.5018
Batch 20, Loss: 0.4804
Batch 30, Loss: 0.4771
Batch 40, Loss: 0.4503
Batch 50, Loss: 0.4860
Batch 60, Loss: 0.4747
Batch 70, Loss: 0.4665
Batch 80, Loss: 0.4892
Batch 90, Loss: 0.5212
Batch 100, Loss: 0.5004
Batch 110, Loss: 0.5179
Batch 120, Loss: 0.5250
Batch 130, Loss: 0.4987
Batch 140, Loss: 0.4638
Batch 150, Loss: 0.5099
Batch 160, Loss: 0.5122
Batch 170, Loss: 0.4856
Batch 180, Loss: 0.4826
Batch 190, Loss: 0.4861
Batch 200, Loss: 0.4630
Batch 210, Loss: 0.4707
Batch 220, Loss: 0.4759
Batch 230, Loss: 0.5067
Batch 240, Loss: 0.5037
Batch 250, Loss: 0.4933
Batch 260, Loss: 0.5136
Batch 270, Loss: 0.5287
Batch 280, Loss: 0.4638
Batch 290, Loss: 0.4971
Batch 300, Loss: 0.4790
Batch 310, Loss: 0.4825
Batch 320, Loss: 0.5074
Batch 330, Loss: 0.4874
Batch 340, Loss: 0.5009
Batch 350, Loss: 0.5004
Batch 360, Loss: 0.4840
Batch 370, Loss: 0.4572
Batch 380, Loss: 0.4500
Batch 390, Loss: 0.4979
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.042957067489624 seconds
Epoch 75 accuracy: 87.51%
Batch 10, Loss: 0.5043
Batch 20, Loss: 0.5409
Batch 30, Loss: 0.5265
Batch 40, Loss: 0.4711
Batch 50, Loss: 0.4517
Batch 60, Loss: 0.4897
Batch 70, Loss: 0.5210
Batch 80, Loss: 0.4717
Batch 90, Loss: 0.4800
Batch 100, Loss: 0.4774
Batch 110, Loss: 0.5064
Batch 120, Loss: 0.5192
Batch 130, Loss: 0.5214
Batch 140, Loss: 0.4681
Batch 150, Loss: 0.4756
Batch 160, Loss: 0.5164
Batch 170, Loss: 0.4516
Batch 180, Loss: 0.5319
Batch 190, Loss: 0.5213
Batch 200, Loss: 0.4579
Batch 210, Loss: 0.5077
Batch 220, Loss: 0.4734
Batch 230, Loss: 0.5056
Batch 240, Loss: 0.4666
Batch 250, Loss: 0.4912
Batch 260, Loss: 0.5083
Batch 270, Loss: 0.5184
Batch 280, Loss: 0.5100
Batch 290, Loss: 0.4685
Batch 300, Loss: 0.4659
Batch 310, Loss: 0.5244
Batch 320, Loss: 0.5314
Batch 330, Loss: 0.5170
Batch 340, Loss: 0.5029
Batch 350, Loss: 0.4850
Batch 360, Loss: 0.5351
Batch 370, Loss: 0.4862
Batch 380, Loss: 0.5069
Batch 390, Loss: 0.5049
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.034247636795044 seconds
Epoch 76 accuracy: 83.24%
Batch 10, Loss: 0.5207
Batch 20, Loss: 0.4970
Batch 30, Loss: 0.4688
Batch 40, Loss: 0.4904
Batch 50, Loss: 0.4550
Batch 60, Loss: 0.4545
Batch 70, Loss: 0.5134
Batch 80, Loss: 0.5192
Batch 90, Loss: 0.5079
Batch 100, Loss: 0.4529
Batch 110, Loss: 0.5012
Batch 120, Loss: 0.4673
Batch 130, Loss: 0.4622
Batch 140, Loss: 0.4936
Batch 150, Loss: 0.4615
Batch 160, Loss: 0.5104
Batch 170, Loss: 0.4829
Batch 180, Loss: 0.5059
Batch 190, Loss: 0.5144
Batch 200, Loss: 0.5130
Batch 210, Loss: 0.4835
Batch 220, Loss: 0.4700
Batch 230, Loss: 0.4844
Batch 240, Loss: 0.4960
Batch 250, Loss: 0.4497
Batch 260, Loss: 0.4793
Batch 270, Loss: 0.4668
Batch 280, Loss: 0.4833
Batch 290, Loss: 0.5074
Batch 300, Loss: 0.5049
Batch 310, Loss: 0.4508
Batch 320, Loss: 0.5007
Batch 330, Loss: 0.4993
Batch 340, Loss: 0.5017
Batch 350, Loss: 0.4893
Batch 360, Loss: 0.5313
Batch 370, Loss: 0.4765
Batch 380, Loss: 0.4716
Batch 390, Loss: 0.5338
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.10838294029236 seconds
Epoch 77 accuracy: 83.13%
Batch 10, Loss: 0.4982
Batch 20, Loss: 0.4933
Batch 30, Loss: 0.4576
Batch 40, Loss: 0.4915
Batch 50, Loss: 0.4637
Batch 60, Loss: 0.4571
Batch 70, Loss: 0.4510
Batch 80, Loss: 0.4966
Batch 90, Loss: 0.4653
Batch 100, Loss: 0.5156
Batch 110, Loss: 0.4823
Batch 120, Loss: 0.5002
Batch 130, Loss: 0.4879
Batch 140, Loss: 0.4652
Batch 150, Loss: 0.5345
Batch 160, Loss: 0.5237
Batch 170, Loss: 0.4720
Batch 180, Loss: 0.4800
Batch 190, Loss: 0.5368
Batch 200, Loss: 0.5075
Batch 210, Loss: 0.5073
Batch 220, Loss: 0.5395
Batch 230, Loss: 0.5084
Batch 240, Loss: 0.4787
Batch 250, Loss: 0.5068
Batch 260, Loss: 0.5084
Batch 270, Loss: 0.5044
Batch 280, Loss: 0.4767
Batch 290, Loss: 0.4800
Batch 300, Loss: 0.4911
Batch 310, Loss: 0.4695
Batch 320, Loss: 0.4992
Batch 330, Loss: 0.5402
Batch 340, Loss: 0.4814
Batch 350, Loss: 0.4953
Batch 360, Loss: 0.4844
Batch 370, Loss: 0.4297
Batch 380, Loss: 0.5144
Batch 390, Loss: 0.4933
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.0190589427948 seconds
Epoch 78 accuracy: 86.96%
Batch 10, Loss: 0.4543
Batch 20, Loss: 0.4908
Batch 30, Loss: 0.4756
Batch 40, Loss: 0.4831
Batch 50, Loss: 0.4691
Batch 60, Loss: 0.4672
Batch 70, Loss: 0.4640
Batch 80, Loss: 0.4713
Batch 90, Loss: 0.4727
Batch 100, Loss: 0.4847
Batch 110, Loss: 0.4927
Batch 120, Loss: 0.5350
Batch 130, Loss: 0.4833
Batch 140, Loss: 0.5100
Batch 150, Loss: 0.4910
Batch 160, Loss: 0.4516
Batch 170, Loss: 0.4814
Batch 180, Loss: 0.4986
Batch 190, Loss: 0.4905
Batch 200, Loss: 0.4904
Batch 210, Loss: 0.5051
Batch 220, Loss: 0.5172
Batch 230, Loss: 0.5039
Batch 240, Loss: 0.5051
Batch 250, Loss: 0.5048
Batch 260, Loss: 0.5122
Batch 270, Loss: 0.4815
Batch 280, Loss: 0.4662
Batch 290, Loss: 0.4717
Batch 300, Loss: 0.4813
Batch 310, Loss: 0.4856
Batch 320, Loss: 0.5074
Batch 330, Loss: 0.5073
Batch 340, Loss: 0.5345
Batch 350, Loss: 0.4925
Batch 360, Loss: 0.4885
Batch 370, Loss: 0.4953
Batch 380, Loss: 0.4633
Batch 390, Loss: 0.5054
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.146533012390137 seconds
Epoch 79 accuracy: 82.36%
Batch 10, Loss: 0.4867
Batch 20, Loss: 0.4832
Batch 30, Loss: 0.4790
Batch 40, Loss: 0.4967
Batch 50, Loss: 0.4337
Batch 60, Loss: 0.4722
Batch 70, Loss: 0.4703
Batch 80, Loss: 0.4283
Batch 90, Loss: 0.4937
Batch 100, Loss: 0.4907
Batch 110, Loss: 0.4823
Batch 120, Loss: 0.5454
Batch 130, Loss: 0.5112
Batch 140, Loss: 0.4741
Batch 150, Loss: 0.5076
Batch 160, Loss: 0.4510
Batch 170, Loss: 0.4647
Batch 180, Loss: 0.4395
Batch 190, Loss: 0.5419
Batch 200, Loss: 0.5154
Batch 210, Loss: 0.4756
Batch 220, Loss: 0.4749
Batch 230, Loss: 0.5054
Batch 240, Loss: 0.4747
Batch 250, Loss: 0.5109
Batch 260, Loss: 0.5308
Batch 270, Loss: 0.4708
Batch 280, Loss: 0.4794
Batch 290, Loss: 0.4839
Batch 300, Loss: 0.5162
Batch 310, Loss: 0.5157
Batch 320, Loss: 0.4702
Batch 330, Loss: 0.5015
Batch 340, Loss: 0.4517
Batch 350, Loss: 0.5271
Batch 360, Loss: 0.5205
Batch 370, Loss: 0.4958
Batch 380, Loss: 0.4917
Batch 390, Loss: 0.5113
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.143521070480347 seconds
Epoch 80 accuracy: 86.33%
Batch 10, Loss: 0.4767
Batch 20, Loss: 0.5014
Batch 30, Loss: 0.5127
Batch 40, Loss: 0.4877
Batch 50, Loss: 0.5034
Batch 60, Loss: 0.4683
Batch 70, Loss: 0.4797
Batch 80, Loss: 0.4690
Batch 90, Loss: 0.4916
Batch 100, Loss: 0.4757
Batch 110, Loss: 0.4921
Batch 120, Loss: 0.5081
Batch 130, Loss: 0.4915
Batch 140, Loss: 0.4915
Batch 150, Loss: 0.5032
Batch 160, Loss: 0.4778
Batch 170, Loss: 0.4843
Batch 180, Loss: 0.4636
Batch 190, Loss: 0.4218
Batch 200, Loss: 0.4745
Batch 210, Loss: 0.4855
Batch 220, Loss: 0.4226
Batch 230, Loss: 0.4883
Batch 240, Loss: 0.4723
Batch 250, Loss: 0.4906
Batch 260, Loss: 0.4918
Batch 270, Loss: 0.4740
Batch 280, Loss: 0.4799
Batch 290, Loss: 0.4846
Batch 300, Loss: 0.4628
Batch 310, Loss: 0.4800
Batch 320, Loss: 0.4918
Batch 330, Loss: 0.5081
Batch 340, Loss: 0.4905
Batch 350, Loss: 0.4952
Batch 360, Loss: 0.5020
Batch 370, Loss: 0.5269
Batch 380, Loss: 0.5180
Batch 390, Loss: 0.4876
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.13199281692505 seconds
Epoch 81 accuracy: 83.77%
Batch 10, Loss: 0.4905
Batch 20, Loss: 0.4919
Batch 30, Loss: 0.4781
Batch 40, Loss: 0.4729
Batch 50, Loss: 0.4831
Batch 60, Loss: 0.4702
Batch 70, Loss: 0.4658
Batch 80, Loss: 0.4691
Batch 90, Loss: 0.4649
Batch 100, Loss: 0.5258
Batch 110, Loss: 0.4834
Batch 120, Loss: 0.4513
Batch 130, Loss: 0.4576
Batch 140, Loss: 0.4725
Batch 150, Loss: 0.4797
Batch 160, Loss: 0.4441
Batch 170, Loss: 0.4431
Batch 180, Loss: 0.5083
Batch 190, Loss: 0.4821
Batch 200, Loss: 0.4482
Batch 210, Loss: 0.4700
Batch 220, Loss: 0.4710
Batch 230, Loss: 0.4513
Batch 240, Loss: 0.4646
Batch 250, Loss: 0.4793
Batch 260, Loss: 0.4925
Batch 270, Loss: 0.4864
Batch 280, Loss: 0.5129
Batch 290, Loss: 0.4888
Batch 300, Loss: 0.4579
Batch 310, Loss: 0.4819
Batch 320, Loss: 0.4455
Batch 330, Loss: 0.4577
Batch 340, Loss: 0.4887
Batch 350, Loss: 0.4748
Batch 360, Loss: 0.4913
Batch 370, Loss: 0.5079
Batch 380, Loss: 0.4710
Batch 390, Loss: 0.5077
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.140933990478516 seconds
Epoch 82 accuracy: 84.57%
Batch 10, Loss: 0.4966
Batch 20, Loss: 0.4684
Batch 30, Loss: 0.4512
Batch 40, Loss: 0.4651
Batch 50, Loss: 0.4290
Batch 60, Loss: 0.4296
Batch 70, Loss: 0.4625
Batch 80, Loss: 0.4889
Batch 90, Loss: 0.4596
Batch 100, Loss: 0.4914
Batch 110, Loss: 0.4736
Batch 120, Loss: 0.4490
Batch 130, Loss: 0.4384
Batch 140, Loss: 0.4746
Batch 150, Loss: 0.5114
Batch 160, Loss: 0.4992
Batch 170, Loss: 0.5027
Batch 180, Loss: 0.4745
Batch 190, Loss: 0.4471
Batch 200, Loss: 0.4504
Batch 210, Loss: 0.4629
Batch 220, Loss: 0.4653
Batch 230, Loss: 0.4687
Batch 240, Loss: 0.4887
Batch 250, Loss: 0.4674
Batch 260, Loss: 0.4761
Batch 270, Loss: 0.4616
Batch 280, Loss: 0.4927
Batch 290, Loss: 0.4911
Batch 300, Loss: 0.4649
Batch 310, Loss: 0.4952
Batch 320, Loss: 0.4891
Batch 330, Loss: 0.4902
Batch 340, Loss: 0.4549
Batch 350, Loss: 0.4882
Batch 360, Loss: 0.4939
Batch 370, Loss: 0.4794
Batch 380, Loss: 0.4668
Batch 390, Loss: 0.4923
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.19889998435974 seconds
Epoch 83 accuracy: 85.83%
Batch 10, Loss: 0.4631
Batch 20, Loss: 0.4854
Batch 30, Loss: 0.4614
Batch 40, Loss: 0.4620
Batch 50, Loss: 0.4919
Batch 60, Loss: 0.4427
Batch 70, Loss: 0.4706
Batch 80, Loss: 0.4668
Batch 90, Loss: 0.4380
Batch 100, Loss: 0.4715
Batch 110, Loss: 0.4657
Batch 120, Loss: 0.4537
Batch 130, Loss: 0.4393
Batch 140, Loss: 0.4438
Batch 150, Loss: 0.5046
Batch 160, Loss: 0.4706
Batch 170, Loss: 0.4758
Batch 180, Loss: 0.4730
Batch 190, Loss: 0.4749
Batch 200, Loss: 0.5018
Batch 210, Loss: 0.4728
Batch 220, Loss: 0.4775
Batch 230, Loss: 0.4976
Batch 240, Loss: 0.4736
Batch 250, Loss: 0.4786
Batch 260, Loss: 0.4526
Batch 270, Loss: 0.4902
Batch 280, Loss: 0.4632
Batch 290, Loss: 0.4907
Batch 300, Loss: 0.5085
Batch 310, Loss: 0.4626
Batch 320, Loss: 0.5093
Batch 330, Loss: 0.4898
Batch 340, Loss: 0.4690
Batch 350, Loss: 0.4680
Batch 360, Loss: 0.4817
Batch 370, Loss: 0.4785
Batch 380, Loss: 0.4856
Batch 390, Loss: 0.4945
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.09315299987793 seconds
Epoch 84 accuracy: 86.22%
Batch 10, Loss: 0.4656
Batch 20, Loss: 0.4648
Batch 30, Loss: 0.4145
Batch 40, Loss: 0.4282
Batch 50, Loss: 0.4718
Batch 60, Loss: 0.4727
Batch 70, Loss: 0.4637
Batch 80, Loss: 0.4864
Batch 90, Loss: 0.4697
Batch 100, Loss: 0.5183
Batch 110, Loss: 0.4899
Batch 120, Loss: 0.5136
Batch 130, Loss: 0.5119
Batch 140, Loss: 0.4566
Batch 150, Loss: 0.4756
Batch 160, Loss: 0.4625
Batch 170, Loss: 0.4655
Batch 180, Loss: 0.4821
Batch 190, Loss: 0.4817
Batch 200, Loss: 0.4490
Batch 210, Loss: 0.4845
Batch 220, Loss: 0.4841
Batch 230, Loss: 0.4831
Batch 240, Loss: 0.5039
Batch 250, Loss: 0.4845
Batch 260, Loss: 0.4642
Batch 270, Loss: 0.5159
Batch 280, Loss: 0.5096
Batch 290, Loss: 0.4883
Batch 300, Loss: 0.4992
Batch 310, Loss: 0.4680
Batch 320, Loss: 0.5054
Batch 330, Loss: 0.4871
Batch 340, Loss: 0.4706
Batch 350, Loss: 0.4724
Batch 360, Loss: 0.4832
Batch 370, Loss: 0.4725
Batch 380, Loss: 0.4686
Batch 390, Loss: 0.4318
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.09032416343689 seconds
Epoch 85 accuracy: 87.1%
Batch 10, Loss: 0.4825
Batch 20, Loss: 0.4607
Batch 30, Loss: 0.4606
Batch 40, Loss: 0.4533
Batch 50, Loss: 0.4802
Batch 60, Loss: 0.4798
Batch 70, Loss: 0.4621
Batch 80, Loss: 0.4387
Batch 90, Loss: 0.4999
Batch 100, Loss: 0.4852
Batch 110, Loss: 0.4502
Batch 120, Loss: 0.4882
Batch 130, Loss: 0.4791
Batch 140, Loss: 0.4744
Batch 150, Loss: 0.4511
Batch 160, Loss: 0.5025
Batch 170, Loss: 0.4431
Batch 180, Loss: 0.4631
Batch 190, Loss: 0.5116
Batch 200, Loss: 0.4513
Batch 210, Loss: 0.4657
Batch 220, Loss: 0.4939
Batch 230, Loss: 0.4527
Batch 240, Loss: 0.5013
Batch 250, Loss: 0.4687
Batch 260, Loss: 0.4624
Batch 270, Loss: 0.4912
Batch 280, Loss: 0.4871
Batch 290, Loss: 0.4939
Batch 300, Loss: 0.4466
Batch 310, Loss: 0.4803
Batch 320, Loss: 0.4492
Batch 330, Loss: 0.4703
Batch 340, Loss: 0.4962
Batch 350, Loss: 0.4599
Batch 360, Loss: 0.4531
Batch 370, Loss: 0.4811
Batch 380, Loss: 0.4851
Batch 390, Loss: 0.4941
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.082056045532227 seconds
Epoch 86 accuracy: 84.55%
Batch 10, Loss: 0.4416
Batch 20, Loss: 0.4764
Batch 30, Loss: 0.4610
Batch 40, Loss: 0.4483
Batch 50, Loss: 0.4758
Batch 60, Loss: 0.4817
Batch 70, Loss: 0.4794
Batch 80, Loss: 0.4853
Batch 90, Loss: 0.4596
Batch 100, Loss: 0.5337
Batch 110, Loss: 0.4763
Batch 120, Loss: 0.4623
Batch 130, Loss: 0.4787
Batch 140, Loss: 0.4673
Batch 150, Loss: 0.4744
Batch 160, Loss: 0.4416
Batch 170, Loss: 0.4619
Batch 180, Loss: 0.4645
Batch 190, Loss: 0.4480
Batch 200, Loss: 0.5041
Batch 210, Loss: 0.5090
Batch 220, Loss: 0.4806
Batch 230, Loss: 0.4654
Batch 240, Loss: 0.4717
Batch 250, Loss: 0.4317
Batch 260, Loss: 0.4368
Batch 270, Loss: 0.4177
Batch 280, Loss: 0.4561
Batch 290, Loss: 0.4805
Batch 300, Loss: 0.4680
Batch 310, Loss: 0.5046
Batch 320, Loss: 0.4460
Batch 330, Loss: 0.4647
Batch 340, Loss: 0.4794
Batch 350, Loss: 0.4464
Batch 360, Loss: 0.4884
Batch 370, Loss: 0.4523
Batch 380, Loss: 0.4570
Batch 390, Loss: 0.4939
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.180498600006104 seconds
Epoch 87 accuracy: 89.13%
Batch 10, Loss: 0.4597
Batch 20, Loss: 0.4417
Batch 30, Loss: 0.4605
Batch 40, Loss: 0.4492
Batch 50, Loss: 0.4290
Batch 60, Loss: 0.4452
Batch 70, Loss: 0.4584
Batch 80, Loss: 0.4869
Batch 90, Loss: 0.4739
Batch 100, Loss: 0.4683
Batch 110, Loss: 0.4640
Batch 120, Loss: 0.4571
Batch 130, Loss: 0.4773
Batch 140, Loss: 0.4653
Batch 150, Loss: 0.4664
Batch 160, Loss: 0.4634
Batch 170, Loss: 0.4821
Batch 180, Loss: 0.4862
Batch 190, Loss: 0.4743
Batch 200, Loss: 0.5098
Batch 210, Loss: 0.4390
Batch 220, Loss: 0.4567
Batch 230, Loss: 0.4687
Batch 240, Loss: 0.4698
Batch 250, Loss: 0.4545
Batch 260, Loss: 0.4382
Batch 270, Loss: 0.4465
Batch 280, Loss: 0.4683
Batch 290, Loss: 0.4809
Batch 300, Loss: 0.5033
Batch 310, Loss: 0.4807
Batch 320, Loss: 0.4407
Batch 330, Loss: 0.4623
Batch 340, Loss: 0.4514
Batch 350, Loss: 0.5020
Batch 360, Loss: 0.4779
Batch 370, Loss: 0.4457
Batch 380, Loss: 0.4744
Batch 390, Loss: 0.4985
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.155630111694336 seconds
Epoch 88 accuracy: 86.91%
Batch 10, Loss: 0.4563
Batch 20, Loss: 0.4453
Batch 30, Loss: 0.4778
Batch 40, Loss: 0.4559
Batch 50, Loss: 0.4673
Batch 60, Loss: 0.4929
Batch 70, Loss: 0.4791
Batch 80, Loss: 0.5019
Batch 90, Loss: 0.4565
Batch 100, Loss: 0.4518
Batch 110, Loss: 0.4671
Batch 120, Loss: 0.4276
Batch 130, Loss: 0.4052
Batch 140, Loss: 0.4571
Batch 150, Loss: 0.4676
Batch 160, Loss: 0.5121
Batch 170, Loss: 0.4979
Batch 180, Loss: 0.4815
Batch 190, Loss: 0.4609
Batch 200, Loss: 0.4367
Batch 210, Loss: 0.4546
Batch 220, Loss: 0.4374
Batch 230, Loss: 0.4825
Batch 240, Loss: 0.4870
Batch 250, Loss: 0.4960
Batch 260, Loss: 0.4533
Batch 270, Loss: 0.4670
Batch 280, Loss: 0.4739
Batch 290, Loss: 0.4565
Batch 300, Loss: 0.4971
Batch 310, Loss: 0.4845
Batch 320, Loss: 0.4809
Batch 330, Loss: 0.4880
Batch 340, Loss: 0.4754
Batch 350, Loss: 0.4334
Batch 360, Loss: 0.4743
Batch 370, Loss: 0.4988
Batch 380, Loss: 0.4585
Batch 390, Loss: 0.4683
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.135289907455444 seconds
Epoch 89 accuracy: 88.66%
Batch 10, Loss: 0.4895
Batch 20, Loss: 0.4486
Batch 30, Loss: 0.4189
Batch 40, Loss: 0.4858
Batch 50, Loss: 0.4654
Batch 60, Loss: 0.4974
Batch 70, Loss: 0.4412
Batch 80, Loss: 0.4590
Batch 90, Loss: 0.4151
Batch 100, Loss: 0.4778
Batch 110, Loss: 0.4592
Batch 120, Loss: 0.4981
Batch 130, Loss: 0.5239
Batch 140, Loss: 0.4451
Batch 150, Loss: 0.4512
Batch 160, Loss: 0.4462
Batch 170, Loss: 0.4387
Batch 180, Loss: 0.4741
Batch 190, Loss: 0.4975
Batch 200, Loss: 0.4574
Batch 210, Loss: 0.4745
Batch 220, Loss: 0.4940
Batch 230, Loss: 0.4983
Batch 240, Loss: 0.4605
Batch 250, Loss: 0.4531
Batch 260, Loss: 0.4558
Batch 270, Loss: 0.4578
Batch 280, Loss: 0.4335
Batch 290, Loss: 0.4650
Batch 300, Loss: 0.4636
Batch 310, Loss: 0.4934
Batch 320, Loss: 0.4453
Batch 330, Loss: 0.4799
Batch 340, Loss: 0.4777
Batch 350, Loss: 0.4590
Batch 360, Loss: 0.4662
Batch 370, Loss: 0.4825
Batch 380, Loss: 0.4426
Batch 390, Loss: 0.5163
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.037028312683105 seconds
Epoch 90 accuracy: 86.95%
Batch 10, Loss: 0.4571
Batch 20, Loss: 0.4611
Batch 30, Loss: 0.4503
Batch 40, Loss: 0.4550
Batch 50, Loss: 0.4539
Batch 60, Loss: 0.4604
Batch 70, Loss: 0.4341
Batch 80, Loss: 0.4242
Batch 90, Loss: 0.4789
Batch 100, Loss: 0.4453
Batch 110, Loss: 0.4642
Batch 120, Loss: 0.4550
Batch 130, Loss: 0.4916
Batch 140, Loss: 0.4937
Batch 150, Loss: 0.4847
Batch 160, Loss: 0.4691
Batch 170, Loss: 0.4723
Batch 180, Loss: 0.4357
Batch 190, Loss: 0.4557
Batch 200, Loss: 0.5013
Batch 210, Loss: 0.4468
Batch 220, Loss: 0.4453
Batch 230, Loss: 0.4466
Batch 240, Loss: 0.4198
Batch 250, Loss: 0.4436
Batch 260, Loss: 0.4393
Batch 270, Loss: 0.4611
Batch 280, Loss: 0.4516
Batch 290, Loss: 0.4505
Batch 300, Loss: 0.4585
Batch 310, Loss: 0.4733
Batch 320, Loss: 0.4622
Batch 330, Loss: 0.4950
Batch 340, Loss: 0.4360
Batch 350, Loss: 0.4625
Batch 360, Loss: 0.4426
Batch 370, Loss: 0.4844
Batch 380, Loss: 0.4774
Batch 390, Loss: 0.4354
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.080524682998657 seconds
Epoch 91 accuracy: 87.94%
Batch 10, Loss: 0.4283
Batch 20, Loss: 0.4475
Batch 30, Loss: 0.4113
Batch 40, Loss: 0.4308
Batch 50, Loss: 0.4336
Batch 60, Loss: 0.4568
Batch 70, Loss: 0.4625
Batch 80, Loss: 0.4414
Batch 90, Loss: 0.4477
Batch 100, Loss: 0.4324
Batch 110, Loss: 0.4327
Batch 120, Loss: 0.4975
Batch 130, Loss: 0.4614
Batch 140, Loss: 0.4375
Batch 150, Loss: 0.4770
Batch 160, Loss: 0.4886
Batch 170, Loss: 0.4534
Batch 180, Loss: 0.4502
Batch 190, Loss: 0.4743
Batch 200, Loss: 0.4645
Batch 210, Loss: 0.4493
Batch 220, Loss: 0.4454
Batch 230, Loss: 0.4434
Batch 240, Loss: 0.4706
Batch 250, Loss: 0.4287
Batch 260, Loss: 0.4579
Batch 270, Loss: 0.4517
Batch 280, Loss: 0.4664
Batch 290, Loss: 0.4528
Batch 300, Loss: 0.4302
Batch 310, Loss: 0.4709
Batch 320, Loss: 0.4258
Batch 330, Loss: 0.4488
Batch 340, Loss: 0.4577
Batch 350, Loss: 0.4489
Batch 360, Loss: 0.4159
Batch 370, Loss: 0.4858
Batch 380, Loss: 0.4794
Batch 390, Loss: 0.4353
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.04341769218445 seconds
Epoch 92 accuracy: 88.15%
Batch 10, Loss: 0.4236
Batch 20, Loss: 0.4416
Batch 30, Loss: 0.4508
Batch 40, Loss: 0.4767
Batch 50, Loss: 0.4530
Batch 60, Loss: 0.5130
Batch 70, Loss: 0.4686
Batch 80, Loss: 0.4289
Batch 90, Loss: 0.4460
Batch 100, Loss: 0.4994
Batch 110, Loss: 0.4791
Batch 120, Loss: 0.4358
Batch 130, Loss: 0.4526
Batch 140, Loss: 0.4609
Batch 150, Loss: 0.4673
Batch 160, Loss: 0.4694
Batch 170, Loss: 0.4191
Batch 180, Loss: 0.4686
Batch 190, Loss: 0.4630
Batch 200, Loss: 0.4484
Batch 210, Loss: 0.4318
Batch 220, Loss: 0.4580
Batch 230, Loss: 0.4523
Batch 240, Loss: 0.4711
Batch 250, Loss: 0.4490
Batch 260, Loss: 0.4189
Batch 270, Loss: 0.4318
Batch 280, Loss: 0.4440
Batch 290, Loss: 0.4457
Batch 300, Loss: 0.4586
Batch 310, Loss: 0.4500
Batch 320, Loss: 0.4475
Batch 330, Loss: 0.4433
Batch 340, Loss: 0.4404
Batch 350, Loss: 0.4352
Batch 360, Loss: 0.4209
Batch 370, Loss: 0.4373
Batch 380, Loss: 0.4643
Batch 390, Loss: 0.4531
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.102551698684692 seconds
Epoch 93 accuracy: 87.7%
Batch 10, Loss: 0.4604
Batch 20, Loss: 0.4276
Batch 30, Loss: 0.4596
Batch 40, Loss: 0.4569
Batch 50, Loss: 0.4127
Batch 60, Loss: 0.4858
Batch 70, Loss: 0.4522
Batch 80, Loss: 0.4095
Batch 90, Loss: 0.4703
Batch 100, Loss: 0.4342
Batch 110, Loss: 0.4109
Batch 120, Loss: 0.4404
Batch 130, Loss: 0.4100
Batch 140, Loss: 0.4712
Batch 150, Loss: 0.4655
Batch 160, Loss: 0.4426
Batch 170, Loss: 0.4810
Batch 180, Loss: 0.4656
Batch 190, Loss: 0.4686
Batch 200, Loss: 0.4264
Batch 210, Loss: 0.4534
Batch 220, Loss: 0.4345
Batch 230, Loss: 0.3836
Batch 240, Loss: 0.4549
Batch 250, Loss: 0.4301
Batch 260, Loss: 0.4497
Batch 270, Loss: 0.4203
Batch 280, Loss: 0.4569
Batch 290, Loss: 0.4730
Batch 300, Loss: 0.4740
Batch 310, Loss: 0.4829
Batch 320, Loss: 0.4384
Batch 330, Loss: 0.4820
Batch 340, Loss: 0.4575
Batch 350, Loss: 0.4635
Batch 360, Loss: 0.4230
Batch 370, Loss: 0.4294
Batch 380, Loss: 0.4499
Batch 390, Loss: 0.4694
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.014100551605225 seconds
Epoch 94 accuracy: 88.99%
Batch 10, Loss: 0.4325
Batch 20, Loss: 0.4607
Batch 30, Loss: 0.4474
Batch 40, Loss: 0.4148
Batch 50, Loss: 0.4405
Batch 60, Loss: 0.4302
Batch 70, Loss: 0.4078
Batch 80, Loss: 0.4390
Batch 90, Loss: 0.4575
Batch 100, Loss: 0.4383
Batch 110, Loss: 0.4533
Batch 120, Loss: 0.4506
Batch 130, Loss: 0.4562
Batch 140, Loss: 0.4694
Batch 150, Loss: 0.4428
Batch 160, Loss: 0.4579
Batch 170, Loss: 0.4555
Batch 180, Loss: 0.4466
Batch 190, Loss: 0.4664
Batch 200, Loss: 0.4678
Batch 210, Loss: 0.4211
Batch 220, Loss: 0.4583
Batch 230, Loss: 0.4047
Batch 240, Loss: 0.4582
Batch 250, Loss: 0.4513
Batch 260, Loss: 0.4851
Batch 270, Loss: 0.4420
Batch 280, Loss: 0.4348
Batch 290, Loss: 0.4850
Batch 300, Loss: 0.4694
Batch 310, Loss: 0.4470
Batch 320, Loss: 0.4522
Batch 330, Loss: 0.4643
Batch 340, Loss: 0.4848
Batch 350, Loss: 0.4598
Batch 360, Loss: 0.4666
Batch 370, Loss: 0.4646
Batch 380, Loss: 0.4643
Batch 390, Loss: 0.4308
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.157337427139282 seconds
Epoch 95 accuracy: 86.11%
Batch 10, Loss: 0.4125
Batch 20, Loss: 0.4343
Batch 30, Loss: 0.4162
Batch 40, Loss: 0.4485
Batch 50, Loss: 0.4510
Batch 60, Loss: 0.4628
Batch 70, Loss: 0.4264
Batch 80, Loss: 0.4412
Batch 90, Loss: 0.4489
Batch 100, Loss: 0.4163
Batch 110, Loss: 0.4774
Batch 120, Loss: 0.4348
Batch 130, Loss: 0.4425
Batch 140, Loss: 0.4222
Batch 150, Loss: 0.4552
Batch 160, Loss: 0.4574
Batch 170, Loss: 0.4463
Batch 180, Loss: 0.3786
Batch 190, Loss: 0.4417
Batch 200, Loss: 0.4506
Batch 210, Loss: 0.4422
Batch 220, Loss: 0.4954
Batch 230, Loss: 0.4049
Batch 240, Loss: 0.4392
Batch 250, Loss: 0.4793
Batch 260, Loss: 0.4256
Batch 270, Loss: 0.4503
Batch 280, Loss: 0.4895
Batch 290, Loss: 0.4849
Batch 300, Loss: 0.4038
Batch 310, Loss: 0.4551
Batch 320, Loss: 0.4628
Batch 330, Loss: 0.4156
Batch 340, Loss: 0.4464
Batch 350, Loss: 0.4703
Batch 360, Loss: 0.4672
Batch 370, Loss: 0.4301
Batch 380, Loss: 0.4473
Batch 390, Loss: 0.4328
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.189515352249146 seconds
Epoch 96 accuracy: 88.67%
Batch 10, Loss: 0.4172
Batch 20, Loss: 0.4600
Batch 30, Loss: 0.4470
Batch 40, Loss: 0.4397
Batch 50, Loss: 0.4599
Batch 60, Loss: 0.4321
Batch 70, Loss: 0.4277
Batch 80, Loss: 0.4383
Batch 90, Loss: 0.4579
Batch 100, Loss: 0.4599
Batch 110, Loss: 0.4747
Batch 120, Loss: 0.4382
Batch 130, Loss: 0.4923
Batch 140, Loss: 0.4643
Batch 150, Loss: 0.4425
Batch 160, Loss: 0.4482
Batch 170, Loss: 0.4384
Batch 180, Loss: 0.4640
Batch 190, Loss: 0.4727
Batch 200, Loss: 0.4580
Batch 210, Loss: 0.4769
Batch 220, Loss: 0.4426
Batch 230, Loss: 0.4506
Batch 240, Loss: 0.4445
Batch 250, Loss: 0.4986
Batch 260, Loss: 0.4464
Batch 270, Loss: 0.4270
Batch 280, Loss: 0.4408
Batch 290, Loss: 0.4332
Batch 300, Loss: 0.4440
Batch 310, Loss: 0.4354
Batch 320, Loss: 0.4231
Batch 330, Loss: 0.4289
Batch 340, Loss: 0.4431
Batch 350, Loss: 0.4386
Batch 360, Loss: 0.4672
Batch 370, Loss: 0.4705
Batch 380, Loss: 0.4618
Batch 390, Loss: 0.5047
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.016713857650757 seconds
Epoch 97 accuracy: 87.66%
Batch 10, Loss: 0.4491
Batch 20, Loss: 0.4621
Batch 30, Loss: 0.4315
Batch 40, Loss: 0.4569
Batch 50, Loss: 0.4636
Batch 60, Loss: 0.4138
Batch 70, Loss: 0.4504
Batch 80, Loss: 0.4683
Batch 90, Loss: 0.4174
Batch 100, Loss: 0.4524
Batch 110, Loss: 0.4431
Batch 120, Loss: 0.4479
Batch 130, Loss: 0.4177
Batch 140, Loss: 0.4853
Batch 150, Loss: 0.4523
Batch 160, Loss: 0.4427
Batch 170, Loss: 0.4387
Batch 180, Loss: 0.4361
Batch 190, Loss: 0.4421
Batch 200, Loss: 0.4594
Batch 210, Loss: 0.4529
Batch 220, Loss: 0.4224
Batch 230, Loss: 0.3981
Batch 240, Loss: 0.4103
Batch 250, Loss: 0.4271
Batch 260, Loss: 0.4328
Batch 270, Loss: 0.4953
Batch 280, Loss: 0.4702
Batch 290, Loss: 0.4625
Batch 300, Loss: 0.4345
Batch 310, Loss: 0.4567
Batch 320, Loss: 0.4216
Batch 330, Loss: 0.4280
Batch 340, Loss: 0.4155
Batch 350, Loss: 0.4761
Batch 360, Loss: 0.4095
Batch 370, Loss: 0.4665
Batch 380, Loss: 0.4561
Batch 390, Loss: 0.4605
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.093174695968628 seconds
Epoch 98 accuracy: 83.24%
Batch 10, Loss: 0.4453
Batch 20, Loss: 0.4049
Batch 30, Loss: 0.4245
Batch 40, Loss: 0.4206
Batch 50, Loss: 0.4496
Batch 60, Loss: 0.4059
Batch 70, Loss: 0.4296
Batch 80, Loss: 0.4109
Batch 90, Loss: 0.4078
Batch 100, Loss: 0.4309
Batch 110, Loss: 0.4219
Batch 120, Loss: 0.4366
Batch 130, Loss: 0.4443
Batch 140, Loss: 0.4531
Batch 150, Loss: 0.4493
Batch 160, Loss: 0.3921
Batch 170, Loss: 0.4644
Batch 180, Loss: 0.4261
Batch 190, Loss: 0.4331
Batch 200, Loss: 0.4175
Batch 210, Loss: 0.4356
Batch 220, Loss: 0.4587
Batch 230, Loss: 0.4627
Batch 240, Loss: 0.4284
Batch 250, Loss: 0.4505
Batch 260, Loss: 0.4276
Batch 270, Loss: 0.4511
Batch 280, Loss: 0.4532
Batch 290, Loss: 0.4390
Batch 300, Loss: 0.4837
Batch 310, Loss: 0.4716
Batch 320, Loss: 0.4375
Batch 330, Loss: 0.4433
Batch 340, Loss: 0.4373
Batch 350, Loss: 0.4398
Batch 360, Loss: 0.4277
Batch 370, Loss: 0.4569
Batch 380, Loss: 0.4568
Batch 390, Loss: 0.4125
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.04012441635132 seconds
Epoch 99 accuracy: 86.5%
Batch 10, Loss: 0.4238
Batch 20, Loss: 0.4677
Batch 30, Loss: 0.4377
Batch 40, Loss: 0.4668
Batch 50, Loss: 0.4415
Batch 60, Loss: 0.4528
Batch 70, Loss: 0.4124
Batch 80, Loss: 0.4248
Batch 90, Loss: 0.4428
Batch 100, Loss: 0.4501
Batch 110, Loss: 0.4180
Batch 120, Loss: 0.4382
Batch 130, Loss: 0.4347
Batch 140, Loss: 0.3892
Batch 150, Loss: 0.4340
Batch 160, Loss: 0.4627
Batch 170, Loss: 0.4542
Batch 180, Loss: 0.4350
Batch 190, Loss: 0.4273
Batch 200, Loss: 0.4009
Batch 210, Loss: 0.4652
Batch 220, Loss: 0.4188
Batch 230, Loss: 0.4394
Batch 240, Loss: 0.4366
Batch 250, Loss: 0.4060
Batch 260, Loss: 0.4504
Batch 270, Loss: 0.4452
Batch 280, Loss: 0.4216
Batch 290, Loss: 0.4627
Batch 300, Loss: 0.4886
Batch 310, Loss: 0.4532
Batch 320, Loss: 0.4423
Batch 330, Loss: 0.4643
Batch 340, Loss: 0.3975
Batch 350, Loss: 0.3961
Batch 360, Loss: 0.4418
Batch 370, Loss: 0.4356
Batch 380, Loss: 0.4654
Batch 390, Loss: 0.4310
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.044365167617798 seconds
Epoch 100 accuracy: 87.97%
Batch 10, Loss: 0.4667
Batch 20, Loss: 0.4395
Batch 30, Loss: 0.4192
Batch 40, Loss: 0.4546
Batch 50, Loss: 0.4251
Batch 60, Loss: 0.4260
Batch 70, Loss: 0.4222
Batch 80, Loss: 0.4193
Batch 90, Loss: 0.4444
Batch 100, Loss: 0.4458
Batch 110, Loss: 0.4148
Batch 120, Loss: 0.4381
Batch 130, Loss: 0.4616
Batch 140, Loss: 0.4277
Batch 150, Loss: 0.4230
Batch 160, Loss: 0.4763
Batch 170, Loss: 0.4454
Batch 180, Loss: 0.4359
Batch 190, Loss: 0.4454
Batch 200, Loss: 0.4225
Batch 210, Loss: 0.4389
Batch 220, Loss: 0.4231
Batch 230, Loss: 0.4025
Batch 240, Loss: 0.4315
Batch 250, Loss: 0.4454
Batch 260, Loss: 0.4229
Batch 270, Loss: 0.4416
Batch 280, Loss: 0.4333
Batch 290, Loss: 0.4491
Batch 300, Loss: 0.3957
Batch 310, Loss: 0.4515
Batch 320, Loss: 0.4446
Batch 330, Loss: 0.4754
Batch 340, Loss: 0.4452
Batch 350, Loss: 0.4520
Batch 360, Loss: 0.4382
Batch 370, Loss: 0.4258
Batch 380, Loss: 0.4054
Batch 390, Loss: 0.4263
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.16707158088684 seconds
Epoch 101 accuracy: 88.14%
Batch 10, Loss: 0.4698
Batch 20, Loss: 0.4634
Batch 30, Loss: 0.4577
Batch 40, Loss: 0.3928
Batch 50, Loss: 0.4481
Batch 60, Loss: 0.4164
Batch 70, Loss: 0.4259
Batch 80, Loss: 0.4053
Batch 90, Loss: 0.4111
Batch 100, Loss: 0.4178
Batch 110, Loss: 0.4579
Batch 120, Loss: 0.4601
Batch 130, Loss: 0.4272
Batch 140, Loss: 0.4553
Batch 150, Loss: 0.4658
Batch 160, Loss: 0.4281
Batch 170, Loss: 0.4440
Batch 180, Loss: 0.4540
Batch 190, Loss: 0.4466
Batch 200, Loss: 0.4325
Batch 210, Loss: 0.4580
Batch 220, Loss: 0.4308
Batch 230, Loss: 0.4235
Batch 240, Loss: 0.4393
Batch 250, Loss: 0.4215
Batch 260, Loss: 0.4389
Batch 270, Loss: 0.4042
Batch 280, Loss: 0.4049
Batch 290, Loss: 0.4081
Batch 300, Loss: 0.4257
Batch 310, Loss: 0.4700
Batch 320, Loss: 0.4547
Batch 330, Loss: 0.4024
Batch 340, Loss: 0.4222
Batch 350, Loss: 0.4990
Batch 360, Loss: 0.4314
Batch 370, Loss: 0.4442
Batch 380, Loss: 0.3914
Batch 390, Loss: 0.4319
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.13360619544983 seconds
Epoch 102 accuracy: 88.31%
Batch 10, Loss: 0.4268
Batch 20, Loss: 0.4299
Batch 30, Loss: 0.4244
Batch 40, Loss: 0.3980
Batch 50, Loss: 0.4332
Batch 60, Loss: 0.4432
Batch 70, Loss: 0.4437
Batch 80, Loss: 0.4076
Batch 90, Loss: 0.4363
Batch 100, Loss: 0.3996
Batch 110, Loss: 0.4463
Batch 120, Loss: 0.4064
Batch 130, Loss: 0.4217
Batch 140, Loss: 0.4778
Batch 150, Loss: 0.4206
Batch 160, Loss: 0.4462
Batch 170, Loss: 0.3995
Batch 180, Loss: 0.4631
Batch 190, Loss: 0.4171
Batch 200, Loss: 0.4421
Batch 210, Loss: 0.4202
Batch 220, Loss: 0.4263
Batch 230, Loss: 0.4629
Batch 240, Loss: 0.4184
Batch 250, Loss: 0.4347
Batch 260, Loss: 0.4392
Batch 270, Loss: 0.4253
Batch 280, Loss: 0.4365
Batch 290, Loss: 0.4482
Batch 300, Loss: 0.4104
Batch 310, Loss: 0.4402
Batch 320, Loss: 0.4221
Batch 330, Loss: 0.4287
Batch 340, Loss: 0.4882
Batch 350, Loss: 0.4177
Batch 360, Loss: 0.4480
Batch 370, Loss: 0.4465
Batch 380, Loss: 0.4397
Batch 390, Loss: 0.4517
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.064913511276245 seconds
Epoch 103 accuracy: 86.39%
Batch 10, Loss: 0.4262
Batch 20, Loss: 0.4251
Batch 30, Loss: 0.4414
Batch 40, Loss: 0.4183
Batch 50, Loss: 0.4141
Batch 60, Loss: 0.4184
Batch 70, Loss: 0.4151
Batch 80, Loss: 0.4277
Batch 90, Loss: 0.4409
Batch 100, Loss: 0.4232
Batch 110, Loss: 0.4117
Batch 120, Loss: 0.3958
Batch 130, Loss: 0.4146
Batch 140, Loss: 0.4649
Batch 150, Loss: 0.4281
Batch 160, Loss: 0.4341
Batch 170, Loss: 0.4688
Batch 180, Loss: 0.4595
Batch 190, Loss: 0.4310
Batch 200, Loss: 0.4454
Batch 210, Loss: 0.4135
Batch 220, Loss: 0.4292
Batch 230, Loss: 0.4153
Batch 240, Loss: 0.4176
Batch 250, Loss: 0.4604
Batch 260, Loss: 0.4346
Batch 270, Loss: 0.4283
Batch 280, Loss: 0.4407
Batch 290, Loss: 0.4109
Batch 300, Loss: 0.4613
Batch 310, Loss: 0.4499
Batch 320, Loss: 0.4179
Batch 330, Loss: 0.4170
Batch 340, Loss: 0.4219
Batch 350, Loss: 0.4377
Batch 360, Loss: 0.4333
Batch 370, Loss: 0.4039
Batch 380, Loss: 0.4055
Batch 390, Loss: 0.4232
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.096330881118774 seconds
Epoch 104 accuracy: 85.21%
Batch 10, Loss: 0.4351
Batch 20, Loss: 0.4281
Batch 30, Loss: 0.4578
Batch 40, Loss: 0.4527
Batch 50, Loss: 0.4294
Batch 60, Loss: 0.4203
Batch 70, Loss: 0.3955
Batch 80, Loss: 0.4336
Batch 90, Loss: 0.4300
Batch 100, Loss: 0.3804
Batch 110, Loss: 0.4378
Batch 120, Loss: 0.4336
Batch 130, Loss: 0.4095
Batch 140, Loss: 0.4451
Batch 150, Loss: 0.4565
Batch 160, Loss: 0.4348
Batch 170, Loss: 0.4498
Batch 180, Loss: 0.4255
Batch 190, Loss: 0.4327
Batch 200, Loss: 0.4109
Batch 210, Loss: 0.4434
Batch 220, Loss: 0.4074
Batch 230, Loss: 0.4333
Batch 240, Loss: 0.4232
Batch 250, Loss: 0.4131
Batch 260, Loss: 0.4069
Batch 270, Loss: 0.4185
Batch 280, Loss: 0.4234
Batch 290, Loss: 0.4498
Batch 300, Loss: 0.4529
Batch 310, Loss: 0.3785
Batch 320, Loss: 0.4096
Batch 330, Loss: 0.4482
Batch 340, Loss: 0.4056
Batch 350, Loss: 0.4030
Batch 360, Loss: 0.4315
Batch 370, Loss: 0.3923
Batch 380, Loss: 0.4331
Batch 390, Loss: 0.3944
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.05679702758789 seconds
Epoch 105 accuracy: 89.29%
Batch 10, Loss: 0.3971
Batch 20, Loss: 0.4398
Batch 30, Loss: 0.4284
Batch 40, Loss: 0.4015
Batch 50, Loss: 0.4010
Batch 60, Loss: 0.4181
Batch 70, Loss: 0.4196
Batch 80, Loss: 0.4350
Batch 90, Loss: 0.4386
Batch 100, Loss: 0.4208
Batch 110, Loss: 0.3978
Batch 120, Loss: 0.4054
Batch 130, Loss: 0.4309
Batch 140, Loss: 0.3921
Batch 150, Loss: 0.4020
Batch 160, Loss: 0.4233
Batch 170, Loss: 0.3989
Batch 180, Loss: 0.4091
Batch 190, Loss: 0.4173
Batch 200, Loss: 0.4283
Batch 210, Loss: 0.4134
Batch 220, Loss: 0.4499
Batch 230, Loss: 0.4608
Batch 240, Loss: 0.3883
Batch 250, Loss: 0.4049
Batch 260, Loss: 0.4665
Batch 270, Loss: 0.4206
Batch 280, Loss: 0.4355
Batch 290, Loss: 0.4278
Batch 300, Loss: 0.4365
Batch 310, Loss: 0.4054
Batch 320, Loss: 0.4095
Batch 330, Loss: 0.4063
Batch 340, Loss: 0.4543
Batch 350, Loss: 0.4385
Batch 360, Loss: 0.3965
Batch 370, Loss: 0.4270
Batch 380, Loss: 0.4019
Batch 390, Loss: 0.4465
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.03193712234497 seconds
Epoch 106 accuracy: 88.05%
Batch 10, Loss: 0.4095
Batch 20, Loss: 0.4100
Batch 30, Loss: 0.4042
Batch 40, Loss: 0.4187
Batch 50, Loss: 0.4140
Batch 60, Loss: 0.4306
Batch 70, Loss: 0.3977
Batch 80, Loss: 0.4226
Batch 90, Loss: 0.3846
Batch 100, Loss: 0.4440
Batch 110, Loss: 0.4130
Batch 120, Loss: 0.4076
Batch 130, Loss: 0.4210
Batch 140, Loss: 0.3949
Batch 150, Loss: 0.4484
Batch 160, Loss: 0.4125
Batch 170, Loss: 0.4415
Batch 180, Loss: 0.4170
Batch 190, Loss: 0.4049
Batch 200, Loss: 0.4372
Batch 210, Loss: 0.4501
Batch 220, Loss: 0.4499
Batch 230, Loss: 0.4305
Batch 240, Loss: 0.4095
Batch 250, Loss: 0.4651
Batch 260, Loss: 0.4430
Batch 270, Loss: 0.4083
Batch 280, Loss: 0.4384
Batch 290, Loss: 0.4263
Batch 300, Loss: 0.4233
Batch 310, Loss: 0.4195
Batch 320, Loss: 0.4194
Batch 330, Loss: 0.4485
Batch 340, Loss: 0.4372
Batch 350, Loss: 0.4194
Batch 360, Loss: 0.4163
Batch 370, Loss: 0.4131
Batch 380, Loss: 0.4097
Batch 390, Loss: 0.4263
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.00764274597168 seconds
Epoch 107 accuracy: 88.84%
Batch 10, Loss: 0.3956
Batch 20, Loss: 0.4188
Batch 30, Loss: 0.4030
Batch 40, Loss: 0.4083
Batch 50, Loss: 0.4222
Batch 60, Loss: 0.4098
Batch 70, Loss: 0.4261
Batch 80, Loss: 0.4384
Batch 90, Loss: 0.4726
Batch 100, Loss: 0.4170
Batch 110, Loss: 0.4078
Batch 120, Loss: 0.4669
Batch 130, Loss: 0.4166
Batch 140, Loss: 0.3948
Batch 150, Loss: 0.4178
Batch 160, Loss: 0.3750
Batch 170, Loss: 0.4447
Batch 180, Loss: 0.4078
Batch 190, Loss: 0.4356
Batch 200, Loss: 0.4113
Batch 210, Loss: 0.3982
Batch 220, Loss: 0.4422
Batch 230, Loss: 0.3850
Batch 240, Loss: 0.3854
Batch 250, Loss: 0.4067
Batch 260, Loss: 0.4208
Batch 270, Loss: 0.4330
Batch 280, Loss: 0.4333
Batch 290, Loss: 0.4249
Batch 300, Loss: 0.4140
Batch 310, Loss: 0.3960
Batch 320, Loss: 0.4377
Batch 330, Loss: 0.4384
Batch 340, Loss: 0.4419
Batch 350, Loss: 0.3973
Batch 360, Loss: 0.4207
Batch 370, Loss: 0.4246
Batch 380, Loss: 0.4252
Batch 390, Loss: 0.4518
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.149544715881348 seconds
Epoch 108 accuracy: 88.33%
Batch 10, Loss: 0.3910
Batch 20, Loss: 0.4076
Batch 30, Loss: 0.4062
Batch 40, Loss: 0.4237
Batch 50, Loss: 0.3649
Batch 60, Loss: 0.3961
Batch 70, Loss: 0.4075
Batch 80, Loss: 0.4331
Batch 90, Loss: 0.4008
Batch 100, Loss: 0.4481
Batch 110, Loss: 0.3776
Batch 120, Loss: 0.4108
Batch 130, Loss: 0.3949
Batch 140, Loss: 0.4551
Batch 150, Loss: 0.4238
Batch 160, Loss: 0.3964
Batch 170, Loss: 0.3988
Batch 180, Loss: 0.4475
Batch 190, Loss: 0.4084
Batch 200, Loss: 0.3977
Batch 210, Loss: 0.3991
Batch 220, Loss: 0.4381
Batch 230, Loss: 0.4036
Batch 240, Loss: 0.4632
Batch 250, Loss: 0.4029
Batch 260, Loss: 0.4150
Batch 270, Loss: 0.4065
Batch 280, Loss: 0.4360
Batch 290, Loss: 0.4107
Batch 300, Loss: 0.4471
Batch 310, Loss: 0.4419
Batch 320, Loss: 0.4250
Batch 330, Loss: 0.4465
Batch 340, Loss: 0.4088
Batch 350, Loss: 0.4102
Batch 360, Loss: 0.4324
Batch 370, Loss: 0.4118
Batch 380, Loss: 0.4131
Batch 390, Loss: 0.4409
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.028059720993042 seconds
Epoch 109 accuracy: 90.16%
Batch 10, Loss: 0.3881
Batch 20, Loss: 0.3979
Batch 30, Loss: 0.4409
Batch 40, Loss: 0.3942
Batch 50, Loss: 0.4170
Batch 60, Loss: 0.4325
Batch 70, Loss: 0.3831
Batch 80, Loss: 0.4077
Batch 90, Loss: 0.4258
Batch 100, Loss: 0.3971
Batch 110, Loss: 0.3861
Batch 120, Loss: 0.3978
Batch 130, Loss: 0.3987
Batch 140, Loss: 0.4020
Batch 150, Loss: 0.4167
Batch 160, Loss: 0.4041
Batch 170, Loss: 0.4166
Batch 180, Loss: 0.3965
Batch 190, Loss: 0.3772
Batch 200, Loss: 0.3971
Batch 210, Loss: 0.4336
Batch 220, Loss: 0.3808
Batch 230, Loss: 0.3920
Batch 240, Loss: 0.4174
Batch 250, Loss: 0.4159
Batch 260, Loss: 0.3948
Batch 270, Loss: 0.3846
Batch 280, Loss: 0.3985
Batch 290, Loss: 0.4392
Batch 300, Loss: 0.4247
Batch 310, Loss: 0.3816
Batch 320, Loss: 0.4374
Batch 330, Loss: 0.4325
Batch 340, Loss: 0.4084
Batch 350, Loss: 0.4129
Batch 360, Loss: 0.4325
Batch 370, Loss: 0.4311
Batch 380, Loss: 0.4273
Batch 390, Loss: 0.4408
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.047269105911255 seconds
Epoch 110 accuracy: 87.8%
Batch 10, Loss: 0.3690
Batch 20, Loss: 0.4122
Batch 30, Loss: 0.4114
Batch 40, Loss: 0.4337
Batch 50, Loss: 0.3852
Batch 60, Loss: 0.3972
Batch 70, Loss: 0.4025
Batch 80, Loss: 0.4209
Batch 90, Loss: 0.4066
Batch 100, Loss: 0.4158
Batch 110, Loss: 0.4166
Batch 120, Loss: 0.4204
Batch 130, Loss: 0.4440
Batch 140, Loss: 0.4116
Batch 150, Loss: 0.4024
Batch 160, Loss: 0.3888
Batch 170, Loss: 0.4135
Batch 180, Loss: 0.4131
Batch 190, Loss: 0.4044
Batch 200, Loss: 0.4589
Batch 210, Loss: 0.4351
Batch 220, Loss: 0.4056
Batch 230, Loss: 0.4225
Batch 240, Loss: 0.4314
Batch 250, Loss: 0.4349
Batch 260, Loss: 0.3820
Batch 270, Loss: 0.4079
Batch 280, Loss: 0.4100
Batch 290, Loss: 0.4496
Batch 300, Loss: 0.3948
Batch 310, Loss: 0.3834
Batch 320, Loss: 0.3873
Batch 330, Loss: 0.4093
Batch 340, Loss: 0.3689
Batch 350, Loss: 0.4424
Batch 360, Loss: 0.4616
Batch 370, Loss: 0.4132
Batch 380, Loss: 0.4094
Batch 390, Loss: 0.4223
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.95613718032837 seconds
Epoch 111 accuracy: 89.42%
Batch 10, Loss: 0.3892
Batch 20, Loss: 0.4311
Batch 30, Loss: 0.4048
Batch 40, Loss: 0.4106
Batch 50, Loss: 0.3938
Batch 60, Loss: 0.4127
Batch 70, Loss: 0.4337
Batch 80, Loss: 0.3976
Batch 90, Loss: 0.3899
Batch 100, Loss: 0.4187
Batch 110, Loss: 0.3892
Batch 120, Loss: 0.3999
Batch 130, Loss: 0.3640
Batch 140, Loss: 0.4066
Batch 150, Loss: 0.4040
Batch 160, Loss: 0.3970
Batch 170, Loss: 0.4075
Batch 180, Loss: 0.4297
Batch 190, Loss: 0.4197
Batch 200, Loss: 0.3726
Batch 210, Loss: 0.3938
Batch 220, Loss: 0.3738
Batch 230, Loss: 0.3830
Batch 240, Loss: 0.3875
Batch 250, Loss: 0.3963
Batch 260, Loss: 0.3995
Batch 270, Loss: 0.4054
Batch 280, Loss: 0.4183
Batch 290, Loss: 0.4221
Batch 300, Loss: 0.3957
Batch 310, Loss: 0.3933
Batch 320, Loss: 0.4639
Batch 330, Loss: 0.4278
Batch 340, Loss: 0.4143
Batch 350, Loss: 0.4005
Batch 360, Loss: 0.4129
Batch 370, Loss: 0.3895
Batch 380, Loss: 0.4523
Batch 390, Loss: 0.4090
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.007078647613525 seconds
Epoch 112 accuracy: 89.14%
Batch 10, Loss: 0.3356
Batch 20, Loss: 0.3978
Batch 30, Loss: 0.3696
Batch 40, Loss: 0.4283
Batch 50, Loss: 0.4078
Batch 60, Loss: 0.3962
Batch 70, Loss: 0.4121
Batch 80, Loss: 0.3825
Batch 90, Loss: 0.3853
Batch 100, Loss: 0.3956
Batch 110, Loss: 0.4044
Batch 120, Loss: 0.4033
Batch 130, Loss: 0.3822
Batch 140, Loss: 0.3920
Batch 150, Loss: 0.3927
Batch 160, Loss: 0.3813
Batch 170, Loss: 0.3926
Batch 180, Loss: 0.4217
Batch 190, Loss: 0.4108
Batch 200, Loss: 0.3952
Batch 210, Loss: 0.3965
Batch 220, Loss: 0.3838
Batch 230, Loss: 0.4101
Batch 240, Loss: 0.3727
Batch 250, Loss: 0.4106
Batch 260, Loss: 0.4237
Batch 270, Loss: 0.3988
Batch 280, Loss: 0.3866
Batch 290, Loss: 0.4026
Batch 300, Loss: 0.4210
Batch 310, Loss: 0.3908
Batch 320, Loss: 0.4196
Batch 330, Loss: 0.4119
Batch 340, Loss: 0.4076
Batch 350, Loss: 0.3997
Batch 360, Loss: 0.3731
Batch 370, Loss: 0.4194
Batch 380, Loss: 0.3588
Batch 390, Loss: 0.4359
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.03348994255066 seconds
Epoch 113 accuracy: 89.8%
Batch 10, Loss: 0.3854
Batch 20, Loss: 0.3908
Batch 30, Loss: 0.4059
Batch 40, Loss: 0.4075
Batch 50, Loss: 0.4170
Batch 60, Loss: 0.3736
Batch 70, Loss: 0.4100
Batch 80, Loss: 0.4136
Batch 90, Loss: 0.3825
Batch 100, Loss: 0.3814
Batch 110, Loss: 0.3812
Batch 120, Loss: 0.3977
Batch 130, Loss: 0.4244
Batch 140, Loss: 0.4289
Batch 150, Loss: 0.3986
Batch 160, Loss: 0.4168
Batch 170, Loss: 0.3649
Batch 180, Loss: 0.4186
Batch 190, Loss: 0.4459
Batch 200, Loss: 0.4083
Batch 210, Loss: 0.4348
Batch 220, Loss: 0.4052
Batch 230, Loss: 0.4099
Batch 240, Loss: 0.3955
Batch 250, Loss: 0.4041
Batch 260, Loss: 0.4026
Batch 270, Loss: 0.4001
Batch 280, Loss: 0.3675
Batch 290, Loss: 0.3705
Batch 300, Loss: 0.3976
Batch 310, Loss: 0.4494
Batch 320, Loss: 0.3890
Batch 330, Loss: 0.4124
Batch 340, Loss: 0.4517
Batch 350, Loss: 0.4116
Batch 360, Loss: 0.3848
Batch 370, Loss: 0.3871
Batch 380, Loss: 0.4219
Batch 390, Loss: 0.3947
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.038711071014404 seconds
Epoch 114 accuracy: 90.26%
Batch 10, Loss: 0.4408
Batch 20, Loss: 0.3600
Batch 30, Loss: 0.3995
Batch 40, Loss: 0.3693
Batch 50, Loss: 0.3923
Batch 60, Loss: 0.4091
Batch 70, Loss: 0.4047
Batch 80, Loss: 0.3662
Batch 90, Loss: 0.3794
Batch 100, Loss: 0.3833
Batch 110, Loss: 0.3675
Batch 120, Loss: 0.3774
Batch 130, Loss: 0.3903
Batch 140, Loss: 0.4057
Batch 150, Loss: 0.4148
Batch 160, Loss: 0.3720
Batch 170, Loss: 0.3929
Batch 180, Loss: 0.3871
Batch 190, Loss: 0.3622
Batch 200, Loss: 0.4101
Batch 210, Loss: 0.3845
Batch 220, Loss: 0.3852
Batch 230, Loss: 0.3928
Batch 240, Loss: 0.3868
Batch 250, Loss: 0.4073
Batch 260, Loss: 0.3872
Batch 270, Loss: 0.3887
Batch 280, Loss: 0.3963
Batch 290, Loss: 0.4328
Batch 300, Loss: 0.4123
Batch 310, Loss: 0.3857
Batch 320, Loss: 0.4038
Batch 330, Loss: 0.4074
Batch 340, Loss: 0.3741
Batch 350, Loss: 0.4222
Batch 360, Loss: 0.3762
Batch 370, Loss: 0.3425
Batch 380, Loss: 0.4251
Batch 390, Loss: 0.3779
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.00469207763672 seconds
Epoch 115 accuracy: 89.36%
Batch 10, Loss: 0.3912
Batch 20, Loss: 0.4070
Batch 30, Loss: 0.4572
Batch 40, Loss: 0.3613
Batch 50, Loss: 0.3800
Batch 60, Loss: 0.4137
Batch 70, Loss: 0.4037
Batch 80, Loss: 0.4112
Batch 90, Loss: 0.3918
Batch 100, Loss: 0.4021
Batch 110, Loss: 0.3816
Batch 120, Loss: 0.3880
Batch 130, Loss: 0.4060
Batch 140, Loss: 0.3897
Batch 150, Loss: 0.4198
Batch 160, Loss: 0.3696
Batch 170, Loss: 0.3912
Batch 180, Loss: 0.4023
Batch 190, Loss: 0.3649
Batch 200, Loss: 0.4320
Batch 210, Loss: 0.3867
Batch 220, Loss: 0.3518
Batch 230, Loss: 0.3653
Batch 240, Loss: 0.3750
Batch 250, Loss: 0.3991
Batch 260, Loss: 0.4025
Batch 270, Loss: 0.3873
Batch 280, Loss: 0.4172
Batch 290, Loss: 0.3838
Batch 300, Loss: 0.4606
Batch 310, Loss: 0.3877
Batch 320, Loss: 0.4136
Batch 330, Loss: 0.3781
Batch 340, Loss: 0.3934
Batch 350, Loss: 0.4113
Batch 360, Loss: 0.3973
Batch 370, Loss: 0.3769
Batch 380, Loss: 0.3895
Batch 390, Loss: 0.3990
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 24.95708417892456 seconds
Epoch 116 accuracy: 89.94%
Batch 10, Loss: 0.3730
Batch 20, Loss: 0.4025
Batch 30, Loss: 0.3780
Batch 40, Loss: 0.3771
Batch 50, Loss: 0.3902
Batch 60, Loss: 0.3785
Batch 70, Loss: 0.3797
Batch 80, Loss: 0.3716
Batch 90, Loss: 0.3981
Batch 100, Loss: 0.3716
Batch 110, Loss: 0.4195
Batch 120, Loss: 0.4115
Batch 130, Loss: 0.3782
Batch 140, Loss: 0.4009
Batch 150, Loss: 0.3813
Batch 160, Loss: 0.4169
Batch 170, Loss: 0.3771
Batch 180, Loss: 0.3728
Batch 190, Loss: 0.4133
Batch 200, Loss: 0.3777
Batch 210, Loss: 0.3768
Batch 220, Loss: 0.4224
Batch 230, Loss: 0.3847
Batch 240, Loss: 0.3922
Batch 250, Loss: 0.4669
Batch 260, Loss: 0.3866
Batch 270, Loss: 0.3917
Batch 280, Loss: 0.4001
Batch 290, Loss: 0.3853
Batch 300, Loss: 0.3541
Batch 310, Loss: 0.3730
Batch 320, Loss: 0.3835
Batch 330, Loss: 0.3875
Batch 340, Loss: 0.4035
Batch 350, Loss: 0.4060
Batch 360, Loss: 0.4063
Batch 370, Loss: 0.3629
Batch 380, Loss: 0.4086
Batch 390, Loss: 0.4234
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 24.925888299942017 seconds
Epoch 117 accuracy: 90.7%
Batch 10, Loss: 0.3659
Batch 20, Loss: 0.3433
Batch 30, Loss: 0.3653
Batch 40, Loss: 0.3699
Batch 50, Loss: 0.3930
Batch 60, Loss: 0.3762
Batch 70, Loss: 0.3954
Batch 80, Loss: 0.3568
Batch 90, Loss: 0.3544
Batch 100, Loss: 0.3875
Batch 110, Loss: 0.3858
Batch 120, Loss: 0.3870
Batch 130, Loss: 0.3887
Batch 140, Loss: 0.4263
Batch 150, Loss: 0.3839
Batch 160, Loss: 0.3783
Batch 170, Loss: 0.4157
Batch 180, Loss: 0.3808
Batch 190, Loss: 0.3726
Batch 200, Loss: 0.4024
Batch 210, Loss: 0.3593
Batch 220, Loss: 0.4043
Batch 230, Loss: 0.4049
Batch 240, Loss: 0.4176
Batch 250, Loss: 0.4115
Batch 260, Loss: 0.3984
Batch 270, Loss: 0.3905
Batch 280, Loss: 0.3791
Batch 290, Loss: 0.4005
Batch 300, Loss: 0.3823
Batch 310, Loss: 0.3595
Batch 320, Loss: 0.3706
Batch 330, Loss: 0.3795
Batch 340, Loss: 0.3680
Batch 350, Loss: 0.4101
Batch 360, Loss: 0.3787
Batch 370, Loss: 0.4007
Batch 380, Loss: 0.4248
Batch 390, Loss: 0.3702
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 24.985914945602417 seconds
Epoch 118 accuracy: 90.72%
Batch 10, Loss: 0.3960
Batch 20, Loss: 0.3901
Batch 30, Loss: 0.3842
Batch 40, Loss: 0.3875
Batch 50, Loss: 0.3580
Batch 60, Loss: 0.4061
Batch 70, Loss: 0.4153
Batch 80, Loss: 0.4371
Batch 90, Loss: 0.3714
Batch 100, Loss: 0.4035
Batch 110, Loss: 0.3648
Batch 120, Loss: 0.3746
Batch 130, Loss: 0.3896
Batch 140, Loss: 0.3656
Batch 150, Loss: 0.3896
Batch 160, Loss: 0.3422
Batch 170, Loss: 0.3940
Batch 180, Loss: 0.3921
Batch 190, Loss: 0.3931
Batch 200, Loss: 0.3717
Batch 210, Loss: 0.3978
Batch 220, Loss: 0.4073
Batch 230, Loss: 0.3566
Batch 240, Loss: 0.3713
Batch 250, Loss: 0.4154
Batch 260, Loss: 0.3760
Batch 270, Loss: 0.4091
Batch 280, Loss: 0.4119
Batch 290, Loss: 0.3585
Batch 300, Loss: 0.4337
Batch 310, Loss: 0.3674
Batch 320, Loss: 0.4172
Batch 330, Loss: 0.4317
Batch 340, Loss: 0.3841
Batch 350, Loss: 0.3822
Batch 360, Loss: 0.4068
Batch 370, Loss: 0.4005
Batch 380, Loss: 0.3521
Batch 390, Loss: 0.3701
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.04631233215332 seconds
Epoch 119 accuracy: 89.21%
Batch 10, Loss: 0.3661
Batch 20, Loss: 0.3969
Batch 30, Loss: 0.3677
Batch 40, Loss: 0.3874
Batch 50, Loss: 0.3755
Batch 60, Loss: 0.4041
Batch 70, Loss: 0.3908
Batch 80, Loss: 0.3824
Batch 90, Loss: 0.4035
Batch 100, Loss: 0.3903
Batch 110, Loss: 0.3449
Batch 120, Loss: 0.3564
Batch 130, Loss: 0.3703
Batch 140, Loss: 0.3677
Batch 150, Loss: 0.3497
Batch 160, Loss: 0.3702
Batch 170, Loss: 0.3697
Batch 180, Loss: 0.3950
Batch 190, Loss: 0.3470
Batch 200, Loss: 0.3712
Batch 210, Loss: 0.3979
Batch 220, Loss: 0.3717
Batch 230, Loss: 0.3468
Batch 240, Loss: 0.3881
Batch 250, Loss: 0.4039
Batch 260, Loss: 0.3980
Batch 270, Loss: 0.3719
Batch 280, Loss: 0.4178
Batch 290, Loss: 0.4032
Batch 300, Loss: 0.3868
Batch 310, Loss: 0.4014
Batch 320, Loss: 0.4003
Batch 330, Loss: 0.3896
Batch 340, Loss: 0.4186
Batch 350, Loss: 0.3655
Batch 360, Loss: 0.3791
Batch 370, Loss: 0.3859
Batch 380, Loss: 0.3771
Batch 390, Loss: 0.3558
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.02323007583618 seconds
Epoch 120 accuracy: 90.19%
Batch 10, Loss: 0.3560
Batch 20, Loss: 0.3474
Batch 30, Loss: 0.3706
Batch 40, Loss: 0.3810
Batch 50, Loss: 0.3620
Batch 60, Loss: 0.3512
Batch 70, Loss: 0.3881
Batch 80, Loss: 0.3400
Batch 90, Loss: 0.3821
Batch 100, Loss: 0.3713
Batch 110, Loss: 0.4066
Batch 120, Loss: 0.3686
Batch 130, Loss: 0.3866
Batch 140, Loss: 0.3719
Batch 150, Loss: 0.4390
Batch 160, Loss: 0.3745
Batch 170, Loss: 0.4129
Batch 180, Loss: 0.3630
Batch 190, Loss: 0.3723
Batch 200, Loss: 0.3395
Batch 210, Loss: 0.3536
Batch 220, Loss: 0.3959
Batch 230, Loss: 0.3813
Batch 240, Loss: 0.4233
Batch 250, Loss: 0.3927
Batch 260, Loss: 0.3877
Batch 270, Loss: 0.3790
Batch 280, Loss: 0.4008
Batch 290, Loss: 0.3778
Batch 300, Loss: 0.4068
Batch 310, Loss: 0.3816
Batch 320, Loss: 0.3988
Batch 330, Loss: 0.3762
Batch 340, Loss: 0.3574
Batch 350, Loss: 0.4244
Batch 360, Loss: 0.3462
Batch 370, Loss: 0.3577
Batch 380, Loss: 0.3395
Batch 390, Loss: 0.3727
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.054178714752197 seconds
Epoch 121 accuracy: 89.59%
Batch 10, Loss: 0.3277
Batch 20, Loss: 0.3665
Batch 30, Loss: 0.3607
Batch 40, Loss: 0.3769
Batch 50, Loss: 0.3988
Batch 60, Loss: 0.3650
Batch 70, Loss: 0.3518
Batch 80, Loss: 0.3574
Batch 90, Loss: 0.3638
Batch 100, Loss: 0.3588
Batch 110, Loss: 0.3832
Batch 120, Loss: 0.3878
Batch 130, Loss: 0.3596
Batch 140, Loss: 0.4277
Batch 150, Loss: 0.3652
Batch 160, Loss: 0.3785
Batch 170, Loss: 0.3939
Batch 180, Loss: 0.3704
Batch 190, Loss: 0.3712
Batch 200, Loss: 0.3753
Batch 210, Loss: 0.3530
Batch 220, Loss: 0.3777
Batch 230, Loss: 0.3700
Batch 240, Loss: 0.3854
Batch 250, Loss: 0.3878
Batch 260, Loss: 0.3848
Batch 270, Loss: 0.3784
Batch 280, Loss: 0.3818
Batch 290, Loss: 0.4050
Batch 300, Loss: 0.3838
Batch 310, Loss: 0.3832
Batch 320, Loss: 0.4013
Batch 330, Loss: 0.3656
Batch 340, Loss: 0.4239
Batch 350, Loss: 0.3686
Batch 360, Loss: 0.3886
Batch 370, Loss: 0.3653
Batch 380, Loss: 0.3925
Batch 390, Loss: 0.3898
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.011727809906006 seconds
Epoch 122 accuracy: 89.96%
Batch 10, Loss: 0.3589
Batch 20, Loss: 0.3626
Batch 30, Loss: 0.3673
Batch 40, Loss: 0.3475
Batch 50, Loss: 0.3264
Batch 60, Loss: 0.4243
Batch 70, Loss: 0.3593
Batch 80, Loss: 0.3655
Batch 90, Loss: 0.3508
Batch 100, Loss: 0.3589
Batch 110, Loss: 0.3838
Batch 120, Loss: 0.3907
Batch 130, Loss: 0.3802
Batch 140, Loss: 0.3577
Batch 150, Loss: 0.3773
Batch 160, Loss: 0.3769
Batch 170, Loss: 0.3892
Batch 180, Loss: 0.3606
Batch 190, Loss: 0.3726
Batch 200, Loss: 0.3816
Batch 210, Loss: 0.3642
Batch 220, Loss: 0.3912
Batch 230, Loss: 0.3978
Batch 240, Loss: 0.3746
Batch 250, Loss: 0.3627
Batch 260, Loss: 0.3832
Batch 270, Loss: 0.4010
Batch 280, Loss: 0.4101
Batch 290, Loss: 0.3711
Batch 300, Loss: 0.3795
Batch 310, Loss: 0.3818
Batch 320, Loss: 0.3875
Batch 330, Loss: 0.3524
Batch 340, Loss: 0.3697
Batch 350, Loss: 0.3570
Batch 360, Loss: 0.3950
Batch 370, Loss: 0.3752
Batch 380, Loss: 0.3508
Batch 390, Loss: 0.3517
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.133943557739258 seconds
Epoch 123 accuracy: 90.86%
Batch 10, Loss: 0.3550
Batch 20, Loss: 0.3543
Batch 30, Loss: 0.3535
Batch 40, Loss: 0.3495
Batch 50, Loss: 0.3416
Batch 60, Loss: 0.3776
Batch 70, Loss: 0.3550
Batch 80, Loss: 0.3464
Batch 90, Loss: 0.3583
Batch 100, Loss: 0.3864
Batch 110, Loss: 0.3838
Batch 120, Loss: 0.3654
Batch 130, Loss: 0.3899
Batch 140, Loss: 0.3926
Batch 150, Loss: 0.3929
Batch 160, Loss: 0.3422
Batch 170, Loss: 0.3934
Batch 180, Loss: 0.3866
Batch 190, Loss: 0.3686
Batch 200, Loss: 0.3504
Batch 210, Loss: 0.3892
Batch 220, Loss: 0.3619
Batch 230, Loss: 0.3727
Batch 240, Loss: 0.3685
Batch 250, Loss: 0.4067
Batch 260, Loss: 0.4037
Batch 270, Loss: 0.4069
Batch 280, Loss: 0.3768
Batch 290, Loss: 0.3709
Batch 300, Loss: 0.3553
Batch 310, Loss: 0.3820
Batch 320, Loss: 0.3569
Batch 330, Loss: 0.3851
Batch 340, Loss: 0.3784
Batch 350, Loss: 0.3938
Batch 360, Loss: 0.4141
Batch 370, Loss: 0.3679
Batch 380, Loss: 0.3536
Batch 390, Loss: 0.3968
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.09361696243286 seconds
Epoch 124 accuracy: 91.12%
Batch 10, Loss: 0.3903
Batch 20, Loss: 0.3724
Batch 30, Loss: 0.3337
Batch 40, Loss: 0.3753
Batch 50, Loss: 0.3464
Batch 60, Loss: 0.3558
Batch 70, Loss: 0.3580
Batch 80, Loss: 0.3777
Batch 90, Loss: 0.3999
Batch 100, Loss: 0.3696
Batch 110, Loss: 0.3468
Batch 120, Loss: 0.3545
Batch 130, Loss: 0.3781
Batch 140, Loss: 0.3617
Batch 150, Loss: 0.3461
Batch 160, Loss: 0.4258
Batch 170, Loss: 0.3774
Batch 180, Loss: 0.3887
Batch 190, Loss: 0.3581
Batch 200, Loss: 0.3404
Batch 210, Loss: 0.3801
Batch 220, Loss: 0.3411
Batch 230, Loss: 0.3614
Batch 240, Loss: 0.3859
Batch 250, Loss: 0.3485
Batch 260, Loss: 0.4018
Batch 270, Loss: 0.3998
Batch 280, Loss: 0.3848
Batch 290, Loss: 0.3437
Batch 300, Loss: 0.3506
Batch 310, Loss: 0.3718
Batch 320, Loss: 0.3926
Batch 330, Loss: 0.3852
Batch 340, Loss: 0.3790
Batch 350, Loss: 0.3522
Batch 360, Loss: 0.3347
Batch 370, Loss: 0.3440
Batch 380, Loss: 0.3916
Batch 390, Loss: 0.3701
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.053205251693726 seconds
Epoch 125 accuracy: 90.69%
Batch 10, Loss: 0.3846
Batch 20, Loss: 0.3610
Batch 30, Loss: 0.3479
Batch 40, Loss: 0.3533
Batch 50, Loss: 0.3133
Batch 60, Loss: 0.3321
Batch 70, Loss: 0.3559
Batch 80, Loss: 0.3887
Batch 90, Loss: 0.3392
Batch 100, Loss: 0.3740
Batch 110, Loss: 0.3619
Batch 120, Loss: 0.3742
Batch 130, Loss: 0.3462
Batch 140, Loss: 0.3722
Batch 150, Loss: 0.4020
Batch 160, Loss: 0.3480
Batch 170, Loss: 0.3268
Batch 180, Loss: 0.3655
Batch 190, Loss: 0.3948
Batch 200, Loss: 0.3601
Batch 210, Loss: 0.3694
Batch 220, Loss: 0.3483
Batch 230, Loss: 0.3764
Batch 240, Loss: 0.3824
Batch 250, Loss: 0.3337
Batch 260, Loss: 0.3745
Batch 270, Loss: 0.3709
Batch 280, Loss: 0.3438
Batch 290, Loss: 0.3904
Batch 300, Loss: 0.3552
Batch 310, Loss: 0.4116
Batch 320, Loss: 0.3960
Batch 330, Loss: 0.3800
Batch 340, Loss: 0.3547
Batch 350, Loss: 0.3758
Batch 360, Loss: 0.3715
Batch 370, Loss: 0.3603
Batch 380, Loss: 0.3716
Batch 390, Loss: 0.3432
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.14462971687317 seconds
Epoch 126 accuracy: 91.88%
Batch 10, Loss: 0.3392
Batch 20, Loss: 0.3538
Batch 30, Loss: 0.3716
Batch 40, Loss: 0.3469
Batch 50, Loss: 0.3635
Batch 60, Loss: 0.3291
Batch 70, Loss: 0.3591
Batch 80, Loss: 0.3683
Batch 90, Loss: 0.3384
Batch 100, Loss: 0.3670
Batch 110, Loss: 0.3499
Batch 120, Loss: 0.3565
Batch 130, Loss: 0.3360
Batch 140, Loss: 0.3451
Batch 150, Loss: 0.3694
Batch 160, Loss: 0.3342
Batch 170, Loss: 0.3613
Batch 180, Loss: 0.4018
Batch 190, Loss: 0.3600
Batch 200, Loss: 0.3479
Batch 210, Loss: 0.3640
Batch 220, Loss: 0.3363
Batch 230, Loss: 0.3498
Batch 240, Loss: 0.3230
Batch 250, Loss: 0.3536
Batch 260, Loss: 0.3971
Batch 270, Loss: 0.3620
Batch 280, Loss: 0.3772
Batch 290, Loss: 0.3736
Batch 300, Loss: 0.3501
Batch 310, Loss: 0.3339
Batch 320, Loss: 0.3762
Batch 330, Loss: 0.3749
Batch 340, Loss: 0.3899
Batch 350, Loss: 0.3521
Batch 360, Loss: 0.3693
Batch 370, Loss: 0.3548
Batch 380, Loss: 0.3514
Batch 390, Loss: 0.3505
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.03383994102478 seconds
Epoch 127 accuracy: 91.96%
Batch 10, Loss: 0.3735
Batch 20, Loss: 0.3693
Batch 30, Loss: 0.3812
Batch 40, Loss: 0.3559
Batch 50, Loss: 0.3364
Batch 60, Loss: 0.3469
Batch 70, Loss: 0.3494
Batch 80, Loss: 0.3627
Batch 90, Loss: 0.3655
Batch 100, Loss: 0.3394
Batch 110, Loss: 0.3492
Batch 120, Loss: 0.3587
Batch 130, Loss: 0.3403
Batch 140, Loss: 0.3383
Batch 150, Loss: 0.3550
Batch 160, Loss: 0.3635
Batch 170, Loss: 0.3676
Batch 180, Loss: 0.3765
Batch 190, Loss: 0.3633
Batch 200, Loss: 0.3904
Batch 210, Loss: 0.3572
Batch 220, Loss: 0.3642
Batch 230, Loss: 0.3786
Batch 240, Loss: 0.3405
Batch 250, Loss: 0.3741
Batch 260, Loss: 0.3393
Batch 270, Loss: 0.3712
Batch 280, Loss: 0.3366
Batch 290, Loss: 0.3780
Batch 300, Loss: 0.3827
Batch 310, Loss: 0.3427
Batch 320, Loss: 0.3690
Batch 330, Loss: 0.3497
Batch 340, Loss: 0.3570
Batch 350, Loss: 0.3654
Batch 360, Loss: 0.3579
Batch 370, Loss: 0.3596
Batch 380, Loss: 0.3509
Batch 390, Loss: 0.3667
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.102822065353394 seconds
Epoch 128 accuracy: 91.54%
Batch 10, Loss: 0.3538
Batch 20, Loss: 0.3762
Batch 30, Loss: 0.3587
Batch 40, Loss: 0.3608
Batch 50, Loss: 0.3368
Batch 60, Loss: 0.3332
Batch 70, Loss: 0.3579
Batch 80, Loss: 0.3401
Batch 90, Loss: 0.3344
Batch 100, Loss: 0.3903
Batch 110, Loss: 0.3280
Batch 120, Loss: 0.3532
Batch 130, Loss: 0.3599
Batch 140, Loss: 0.3607
Batch 150, Loss: 0.3711
Batch 160, Loss: 0.3764
Batch 170, Loss: 0.3480
Batch 180, Loss: 0.3814
Batch 190, Loss: 0.3565
Batch 200, Loss: 0.3585
Batch 210, Loss: 0.3647
Batch 220, Loss: 0.3721
Batch 230, Loss: 0.3349
Batch 240, Loss: 0.3945
Batch 250, Loss: 0.3688
Batch 260, Loss: 0.3606
Batch 270, Loss: 0.3591
Batch 280, Loss: 0.3321
Batch 290, Loss: 0.3865
Batch 300, Loss: 0.3536
Batch 310, Loss: 0.3770
Batch 320, Loss: 0.3387
Batch 330, Loss: 0.3393
Batch 340, Loss: 0.3463
Batch 350, Loss: 0.3591
Batch 360, Loss: 0.3604
Batch 370, Loss: 0.3629
Batch 380, Loss: 0.3840
Batch 390, Loss: 0.3587
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.01482915878296 seconds
Epoch 129 accuracy: 90.57%
Batch 10, Loss: 0.3380
Batch 20, Loss: 0.3666
Batch 30, Loss: 0.3675
Batch 40, Loss: 0.3822
Batch 50, Loss: 0.3416
Batch 60, Loss: 0.3647
Batch 70, Loss: 0.3438
Batch 80, Loss: 0.3476
Batch 90, Loss: 0.3414
Batch 100, Loss: 0.3882
Batch 110, Loss: 0.3596
Batch 120, Loss: 0.3628
Batch 130, Loss: 0.3162
Batch 140, Loss: 0.3458
Batch 150, Loss: 0.3455
Batch 160, Loss: 0.3398
Batch 170, Loss: 0.3353
Batch 180, Loss: 0.3467
Batch 190, Loss: 0.3626
Batch 200, Loss: 0.3385
Batch 210, Loss: 0.3413
Batch 220, Loss: 0.3292
Batch 230, Loss: 0.3736
Batch 240, Loss: 0.3331
Batch 250, Loss: 0.3337
Batch 260, Loss: 0.3445
Batch 270, Loss: 0.3660
Batch 280, Loss: 0.3443
Batch 290, Loss: 0.3690
Batch 300, Loss: 0.3534
Batch 310, Loss: 0.3563
Batch 320, Loss: 0.3904
Batch 330, Loss: 0.3551
Batch 340, Loss: 0.3749
Batch 350, Loss: 0.3599
Batch 360, Loss: 0.3956
Batch 370, Loss: 0.3632
Batch 380, Loss: 0.3487
Batch 390, Loss: 0.3398
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.17165756225586 seconds
Epoch 130 accuracy: 91.49%
Batch 10, Loss: 0.3398
Batch 20, Loss: 0.3546
Batch 30, Loss: 0.3389
Batch 40, Loss: 0.3682
Batch 50, Loss: 0.3777
Batch 60, Loss: 0.3613
Batch 70, Loss: 0.3425
Batch 80, Loss: 0.3255
Batch 90, Loss: 0.3467
Batch 100, Loss: 0.3388
Batch 110, Loss: 0.3383
Batch 120, Loss: 0.3310
Batch 130, Loss: 0.3730
Batch 140, Loss: 0.3747
Batch 150, Loss: 0.2962
Batch 160, Loss: 0.3235
Batch 170, Loss: 0.3305
Batch 180, Loss: 0.3665
Batch 190, Loss: 0.3271
Batch 200, Loss: 0.3255
Batch 210, Loss: 0.3588
Batch 220, Loss: 0.3712
Batch 230, Loss: 0.3322
Batch 240, Loss: 0.3270
Batch 250, Loss: 0.3393
Batch 260, Loss: 0.3475
Batch 270, Loss: 0.3500
Batch 280, Loss: 0.3362
Batch 290, Loss: 0.3541
Batch 300, Loss: 0.3698
Batch 310, Loss: 0.3782
Batch 320, Loss: 0.3661
Batch 330, Loss: 0.3672
Batch 340, Loss: 0.3205
Batch 350, Loss: 0.3420
Batch 360, Loss: 0.3666
Batch 370, Loss: 0.3676
Batch 380, Loss: 0.3735
Batch 390, Loss: 0.3322
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.11436700820923 seconds
Epoch 131 accuracy: 91.4%
Batch 10, Loss: 0.3351
Batch 20, Loss: 0.3677
Batch 30, Loss: 0.3413
Batch 40, Loss: 0.3418
Batch 50, Loss: 0.3387
Batch 60, Loss: 0.3301
Batch 70, Loss: 0.3061
Batch 80, Loss: 0.3145
Batch 90, Loss: 0.3250
Batch 100, Loss: 0.3563
Batch 110, Loss: 0.3409
Batch 120, Loss: 0.3529
Batch 130, Loss: 0.3636
Batch 140, Loss: 0.3445
Batch 150, Loss: 0.3296
Batch 160, Loss: 0.3171
Batch 170, Loss: 0.3425
Batch 180, Loss: 0.3563
Batch 190, Loss: 0.3383
Batch 200, Loss: 0.3402
Batch 210, Loss: 0.3320
Batch 220, Loss: 0.3338
Batch 230, Loss: 0.3454
Batch 240, Loss: 0.3228
Batch 250, Loss: 0.3275
Batch 260, Loss: 0.3537
Batch 270, Loss: 0.3615
Batch 280, Loss: 0.3552
Batch 290, Loss: 0.3672
Batch 300, Loss: 0.3569
Batch 310, Loss: 0.3498
Batch 320, Loss: 0.3447
Batch 330, Loss: 0.3511
Batch 340, Loss: 0.3793
Batch 350, Loss: 0.3671
Batch 360, Loss: 0.3802
Batch 370, Loss: 0.3384
Batch 380, Loss: 0.3582
Batch 390, Loss: 0.3401
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.006000757217407 seconds
Epoch 132 accuracy: 91.22%
Batch 10, Loss: 0.3216
Batch 20, Loss: 0.3286
Batch 30, Loss: 0.3651
Batch 40, Loss: 0.3495
Batch 50, Loss: 0.3571
Batch 60, Loss: 0.3107
Batch 70, Loss: 0.3159
Batch 80, Loss: 0.3775
Batch 90, Loss: 0.3503
Batch 100, Loss: 0.3582
Batch 110, Loss: 0.3424
Batch 120, Loss: 0.3434
Batch 130, Loss: 0.3404
Batch 140, Loss: 0.3326
Batch 150, Loss: 0.3640
Batch 160, Loss: 0.3404
Batch 170, Loss: 0.3170
Batch 180, Loss: 0.3358
Batch 190, Loss: 0.3469
Batch 200, Loss: 0.3277
Batch 210, Loss: 0.3542
Batch 220, Loss: 0.3095
Batch 230, Loss: 0.3435
Batch 240, Loss: 0.3810
Batch 250, Loss: 0.3272
Batch 260, Loss: 0.3480
Batch 270, Loss: 0.3402
Batch 280, Loss: 0.3467
Batch 290, Loss: 0.3145
Batch 300, Loss: 0.3526
Batch 310, Loss: 0.3259
Batch 320, Loss: 0.3792
Batch 330, Loss: 0.3462
Batch 340, Loss: 0.3218
Batch 350, Loss: 0.3521
Batch 360, Loss: 0.3421
Batch 370, Loss: 0.3550
Batch 380, Loss: 0.3362
Batch 390, Loss: 0.3397
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 24.999881982803345 seconds
Epoch 133 accuracy: 90.33%
Batch 10, Loss: 0.3097
Batch 20, Loss: 0.3391
Batch 30, Loss: 0.3533
Batch 40, Loss: 0.3260
Batch 50, Loss: 0.3259
Batch 60, Loss: 0.3222
Batch 70, Loss: 0.3151
Batch 80, Loss: 0.3312
Batch 90, Loss: 0.3409
Batch 100, Loss: 0.3300
Batch 110, Loss: 0.3427
Batch 120, Loss: 0.3487
Batch 130, Loss: 0.3212
Batch 140, Loss: 0.3430
Batch 150, Loss: 0.3602
Batch 160, Loss: 0.3473
Batch 170, Loss: 0.3546
Batch 180, Loss: 0.3557
Batch 190, Loss: 0.3303
Batch 200, Loss: 0.3302
Batch 210, Loss: 0.3193
Batch 220, Loss: 0.3216
Batch 230, Loss: 0.3244
Batch 240, Loss: 0.3167
Batch 250, Loss: 0.3587
Batch 260, Loss: 0.3673
Batch 270, Loss: 0.3673
Batch 280, Loss: 0.3586
Batch 290, Loss: 0.3479
Batch 300, Loss: 0.3657
Batch 310, Loss: 0.3203
Batch 320, Loss: 0.3685
Batch 330, Loss: 0.3463
Batch 340, Loss: 0.3339
Batch 350, Loss: 0.3419
Batch 360, Loss: 0.3252
Batch 370, Loss: 0.3264
Batch 380, Loss: 0.3616
Batch 390, Loss: 0.3396
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.04651689529419 seconds
Epoch 134 accuracy: 92.11%
Batch 10, Loss: 0.3544
Batch 20, Loss: 0.3026
Batch 30, Loss: 0.3240
Batch 40, Loss: 0.3308
Batch 50, Loss: 0.3300
Batch 60, Loss: 0.3468
Batch 70, Loss: 0.3143
Batch 80, Loss: 0.3393
Batch 90, Loss: 0.3359
Batch 100, Loss: 0.3196
Batch 110, Loss: 0.3568
Batch 120, Loss: 0.3457
Batch 130, Loss: 0.3235
Batch 140, Loss: 0.3045
Batch 150, Loss: 0.3290
Batch 160, Loss: 0.3214
Batch 170, Loss: 0.3440
Batch 180, Loss: 0.3527
Batch 190, Loss: 0.3544
Batch 200, Loss: 0.3357
Batch 210, Loss: 0.3398
Batch 220, Loss: 0.3358
Batch 230, Loss: 0.3131
Batch 240, Loss: 0.3211
Batch 250, Loss: 0.3332
Batch 260, Loss: 0.3114
Batch 270, Loss: 0.3768
Batch 280, Loss: 0.3426
Batch 290, Loss: 0.3563
Batch 300, Loss: 0.3254
Batch 310, Loss: 0.3137
Batch 320, Loss: 0.3352
Batch 330, Loss: 0.3551
Batch 340, Loss: 0.3125
Batch 350, Loss: 0.3322
Batch 360, Loss: 0.3534
Batch 370, Loss: 0.3204
Batch 380, Loss: 0.3530
Batch 390, Loss: 0.2946
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.15445852279663 seconds
Epoch 135 accuracy: 91.43%
Batch 10, Loss: 0.3330
Batch 20, Loss: 0.2902
Batch 30, Loss: 0.3434
Batch 40, Loss: 0.3129
Batch 50, Loss: 0.3201
Batch 60, Loss: 0.3109
Batch 70, Loss: 0.3119
Batch 80, Loss: 0.3216
Batch 90, Loss: 0.3433
Batch 100, Loss: 0.3181
Batch 110, Loss: 0.3349
Batch 120, Loss: 0.3370
Batch 130, Loss: 0.3413
Batch 140, Loss: 0.3307
Batch 150, Loss: 0.3143
Batch 160, Loss: 0.3349
Batch 170, Loss: 0.3390
Batch 180, Loss: 0.3063
Batch 190, Loss: 0.3393
Batch 200, Loss: 0.3290
Batch 210, Loss: 0.3509
Batch 220, Loss: 0.3344
Batch 230, Loss: 0.3408
Batch 240, Loss: 0.3254
Batch 250, Loss: 0.3346
Batch 260, Loss: 0.3116
Batch 270, Loss: 0.3273
Batch 280, Loss: 0.3180
Batch 290, Loss: 0.3272
Batch 300, Loss: 0.3402
Batch 310, Loss: 0.3525
Batch 320, Loss: 0.3152
Batch 330, Loss: 0.3386
Batch 340, Loss: 0.3158
Batch 350, Loss: 0.3451
Batch 360, Loss: 0.3519
Batch 370, Loss: 0.3220
Batch 380, Loss: 0.3582
Batch 390, Loss: 0.3637
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.045544862747192 seconds
Epoch 136 accuracy: 91.75%
Batch 10, Loss: 0.3116
Batch 20, Loss: 0.3236
Batch 30, Loss: 0.3156
Batch 40, Loss: 0.2967
Batch 50, Loss: 0.2971
Batch 60, Loss: 0.3373
Batch 70, Loss: 0.2980
Batch 80, Loss: 0.3142
Batch 90, Loss: 0.2918
Batch 100, Loss: 0.3238
Batch 110, Loss: 0.3256
Batch 120, Loss: 0.3284
Batch 130, Loss: 0.3311
Batch 140, Loss: 0.3418
Batch 150, Loss: 0.3285
Batch 160, Loss: 0.3425
Batch 170, Loss: 0.3185
Batch 180, Loss: 0.3393
Batch 190, Loss: 0.3534
Batch 200, Loss: 0.3209
Batch 210, Loss: 0.3484
Batch 220, Loss: 0.3233
Batch 230, Loss: 0.3439
Batch 240, Loss: 0.3365
Batch 250, Loss: 0.3417
Batch 260, Loss: 0.3486
Batch 270, Loss: 0.3556
Batch 280, Loss: 0.3038
Batch 290, Loss: 0.3293
Batch 300, Loss: 0.3201
Batch 310, Loss: 0.3436
Batch 320, Loss: 0.3249
Batch 330, Loss: 0.3197
Batch 340, Loss: 0.3315
Batch 350, Loss: 0.2946
Batch 360, Loss: 0.3466
Batch 370, Loss: 0.3375
Batch 380, Loss: 0.3405
Batch 390, Loss: 0.3332
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.019593954086304 seconds
Epoch 137 accuracy: 92.44%
Batch 10, Loss: 0.3144
Batch 20, Loss: 0.3363
Batch 30, Loss: 0.2998
Batch 40, Loss: 0.3113
Batch 50, Loss: 0.3327
Batch 60, Loss: 0.3120
Batch 70, Loss: 0.3440
Batch 80, Loss: 0.3208
Batch 90, Loss: 0.2962
Batch 100, Loss: 0.3187
Batch 110, Loss: 0.3177
Batch 120, Loss: 0.3465
Batch 130, Loss: 0.3279
Batch 140, Loss: 0.3155
Batch 150, Loss: 0.2884
Batch 160, Loss: 0.3168
Batch 170, Loss: 0.3242
Batch 180, Loss: 0.3380
Batch 190, Loss: 0.3283
Batch 200, Loss: 0.3282
Batch 210, Loss: 0.3095
Batch 220, Loss: 0.3098
Batch 230, Loss: 0.3554
Batch 240, Loss: 0.3558
Batch 250, Loss: 0.3470
Batch 260, Loss: 0.3139
Batch 270, Loss: 0.3371
Batch 280, Loss: 0.3382
Batch 290, Loss: 0.3144
Batch 300, Loss: 0.3099
Batch 310, Loss: 0.3270
Batch 320, Loss: 0.3148
Batch 330, Loss: 0.3285
Batch 340, Loss: 0.3577
Batch 350, Loss: 0.3198
Batch 360, Loss: 0.3330
Batch 370, Loss: 0.3236
Batch 380, Loss: 0.3217
Batch 390, Loss: 0.2986
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.00115132331848 seconds
Epoch 138 accuracy: 92.29%
Batch 10, Loss: 0.3099
Batch 20, Loss: 0.3154
Batch 30, Loss: 0.3315
Batch 40, Loss: 0.3173
Batch 50, Loss: 0.3345
Batch 60, Loss: 0.3275
Batch 70, Loss: 0.3227
Batch 80, Loss: 0.3166
Batch 90, Loss: 0.3046
Batch 100, Loss: 0.3353
Batch 110, Loss: 0.3279
Batch 120, Loss: 0.3358
Batch 130, Loss: 0.3609
Batch 140, Loss: 0.3235
Batch 150, Loss: 0.3322
Batch 160, Loss: 0.3450
Batch 170, Loss: 0.2919
Batch 180, Loss: 0.2903
Batch 190, Loss: 0.3289
Batch 200, Loss: 0.3036
Batch 210, Loss: 0.3270
Batch 220, Loss: 0.3171
Batch 230, Loss: 0.3471
Batch 240, Loss: 0.3385
Batch 250, Loss: 0.3309
Batch 260, Loss: 0.3474
Batch 270, Loss: 0.3144
Batch 280, Loss: 0.3323
Batch 290, Loss: 0.3255
Batch 300, Loss: 0.3066
Batch 310, Loss: 0.3109
Batch 320, Loss: 0.3171
Batch 330, Loss: 0.3258
Batch 340, Loss: 0.3009
Batch 350, Loss: 0.3273
Batch 360, Loss: 0.3156
Batch 370, Loss: 0.3052
Batch 380, Loss: 0.3176
Batch 390, Loss: 0.3347
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.011107683181763 seconds
Epoch 139 accuracy: 92.57%
Batch 10, Loss: 0.3295
Batch 20, Loss: 0.3178
Batch 30, Loss: 0.2976
Batch 40, Loss: 0.3275
Batch 50, Loss: 0.2893
Batch 60, Loss: 0.3344
Batch 70, Loss: 0.3321
Batch 80, Loss: 0.3371
Batch 90, Loss: 0.3246
Batch 100, Loss: 0.3115
Batch 110, Loss: 0.3127
Batch 120, Loss: 0.3300
Batch 130, Loss: 0.3390
Batch 140, Loss: 0.3155
Batch 150, Loss: 0.3190
Batch 160, Loss: 0.3229
Batch 170, Loss: 0.2874
Batch 180, Loss: 0.3273
Batch 190, Loss: 0.3225
Batch 200, Loss: 0.3386
Batch 210, Loss: 0.3139
Batch 220, Loss: 0.3219
Batch 230, Loss: 0.3589
Batch 240, Loss: 0.3096
Batch 250, Loss: 0.3217
Batch 260, Loss: 0.2900
Batch 270, Loss: 0.3140
Batch 280, Loss: 0.3253
Batch 290, Loss: 0.3264
Batch 300, Loss: 0.3338
Batch 310, Loss: 0.3105
Batch 320, Loss: 0.3073
Batch 330, Loss: 0.3121
Batch 340, Loss: 0.3251
Batch 350, Loss: 0.3054
Batch 360, Loss: 0.3309
Batch 370, Loss: 0.3270
Batch 380, Loss: 0.2951
Batch 390, Loss: 0.3159
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.109380960464478 seconds
Epoch 140 accuracy: 92.52%
Batch 10, Loss: 0.2762
Batch 20, Loss: 0.3030
Batch 30, Loss: 0.3365
Batch 40, Loss: 0.3081
Batch 50, Loss: 0.3196
Batch 60, Loss: 0.3046
Batch 70, Loss: 0.3035
Batch 80, Loss: 0.3066
Batch 90, Loss: 0.3215
Batch 100, Loss: 0.3145
Batch 110, Loss: 0.3186
Batch 120, Loss: 0.3335
Batch 130, Loss: 0.3040
Batch 140, Loss: 0.3178
Batch 150, Loss: 0.3128
Batch 160, Loss: 0.3398
Batch 170, Loss: 0.3109
Batch 180, Loss: 0.3092
Batch 190, Loss: 0.3535
Batch 200, Loss: 0.3270
Batch 210, Loss: 0.2909
Batch 220, Loss: 0.3009
Batch 230, Loss: 0.3113
Batch 240, Loss: 0.2963
Batch 250, Loss: 0.3031
Batch 260, Loss: 0.2687
Batch 270, Loss: 0.2740
Batch 280, Loss: 0.3285
Batch 290, Loss: 0.3321
Batch 300, Loss: 0.3231
Batch 310, Loss: 0.3540
Batch 320, Loss: 0.3297
Batch 330, Loss: 0.3463
Batch 340, Loss: 0.3195
Batch 350, Loss: 0.3127
Batch 360, Loss: 0.2825
Batch 370, Loss: 0.2989
Batch 380, Loss: 0.2926
Batch 390, Loss: 0.3041
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 24.99747085571289 seconds
Epoch 141 accuracy: 92.76%
Batch 10, Loss: 0.3026
Batch 20, Loss: 0.3082
Batch 30, Loss: 0.3060
Batch 40, Loss: 0.3152
Batch 50, Loss: 0.2974
Batch 60, Loss: 0.3198
Batch 70, Loss: 0.2872
Batch 80, Loss: 0.2989
Batch 90, Loss: 0.3023
Batch 100, Loss: 0.2892
Batch 110, Loss: 0.3134
Batch 120, Loss: 0.3070
Batch 130, Loss: 0.3360
Batch 140, Loss: 0.3254
Batch 150, Loss: 0.3145
Batch 160, Loss: 0.3417
Batch 170, Loss: 0.3147
Batch 180, Loss: 0.3009
Batch 190, Loss: 0.3210
Batch 200, Loss: 0.3198
Batch 210, Loss: 0.2919
Batch 220, Loss: 0.2930
Batch 230, Loss: 0.3049
Batch 240, Loss: 0.3105
Batch 250, Loss: 0.2938
Batch 260, Loss: 0.2927
Batch 270, Loss: 0.3267
Batch 280, Loss: 0.3109
Batch 290, Loss: 0.3201
Batch 300, Loss: 0.3152
Batch 310, Loss: 0.3272
Batch 320, Loss: 0.3128
Batch 330, Loss: 0.3173
Batch 340, Loss: 0.3449
Batch 350, Loss: 0.3213
Batch 360, Loss: 0.3068
Batch 370, Loss: 0.3048
Batch 380, Loss: 0.3270
Batch 390, Loss: 0.3252
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.076045036315918 seconds
Epoch 142 accuracy: 92.4%
Batch 10, Loss: 0.3332
Batch 20, Loss: 0.3349
Batch 30, Loss: 0.2976
Batch 40, Loss: 0.2857
Batch 50, Loss: 0.3181
Batch 60, Loss: 0.2913
Batch 70, Loss: 0.2956
Batch 80, Loss: 0.3118
Batch 90, Loss: 0.2472
Batch 100, Loss: 0.2779
Batch 110, Loss: 0.2820
Batch 120, Loss: 0.2797
Batch 130, Loss: 0.2715
Batch 140, Loss: 0.3074
Batch 150, Loss: 0.3072
Batch 160, Loss: 0.3256
Batch 170, Loss: 0.3061
Batch 180, Loss: 0.2840
Batch 190, Loss: 0.3126
Batch 200, Loss: 0.3308
Batch 210, Loss: 0.2945
Batch 220, Loss: 0.3214
Batch 230, Loss: 0.3080
Batch 240, Loss: 0.3270
Batch 250, Loss: 0.3016
Batch 260, Loss: 0.2839
Batch 270, Loss: 0.3144
Batch 280, Loss: 0.2771
Batch 290, Loss: 0.3054
Batch 300, Loss: 0.3093
Batch 310, Loss: 0.3114
Batch 320, Loss: 0.3196
Batch 330, Loss: 0.3377
Batch 340, Loss: 0.2813
Batch 350, Loss: 0.3103
Batch 360, Loss: 0.2860
Batch 370, Loss: 0.2867
Batch 380, Loss: 0.3193
Batch 390, Loss: 0.3260
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.097374439239502 seconds
Epoch 143 accuracy: 93.24%
Batch 10, Loss: 0.2889
Batch 20, Loss: 0.3210
Batch 30, Loss: 0.3414
Batch 40, Loss: 0.3020
Batch 50, Loss: 0.3061
Batch 60, Loss: 0.3030
Batch 70, Loss: 0.2856
Batch 80, Loss: 0.2877
Batch 90, Loss: 0.2841
Batch 100, Loss: 0.3003
Batch 110, Loss: 0.3213
Batch 120, Loss: 0.2924
Batch 130, Loss: 0.3136
Batch 140, Loss: 0.3223
Batch 150, Loss: 0.2787
Batch 160, Loss: 0.3015
Batch 170, Loss: 0.3211
Batch 180, Loss: 0.2986
Batch 190, Loss: 0.3224
Batch 200, Loss: 0.3158
Batch 210, Loss: 0.2930
Batch 220, Loss: 0.3156
Batch 230, Loss: 0.3053
Batch 240, Loss: 0.2998
Batch 250, Loss: 0.2958
Batch 260, Loss: 0.3020
Batch 270, Loss: 0.3126
Batch 280, Loss: 0.2914
Batch 290, Loss: 0.3251
Batch 300, Loss: 0.2901
Batch 310, Loss: 0.3038
Batch 320, Loss: 0.2929
Batch 330, Loss: 0.3135
Batch 340, Loss: 0.3070
Batch 350, Loss: 0.3127
Batch 360, Loss: 0.2675
Batch 370, Loss: 0.2911
Batch 380, Loss: 0.3011
Batch 390, Loss: 0.3033
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.124110221862793 seconds
Epoch 144 accuracy: 92.79%
Batch 10, Loss: 0.2875
Batch 20, Loss: 0.3084
Batch 30, Loss: 0.3208
Batch 40, Loss: 0.2864
Batch 50, Loss: 0.2854
Batch 60, Loss: 0.2718
Batch 70, Loss: 0.2736
Batch 80, Loss: 0.2549
Batch 90, Loss: 0.3221
Batch 100, Loss: 0.2722
Batch 110, Loss: 0.2990
Batch 120, Loss: 0.2906
Batch 130, Loss: 0.2865
Batch 140, Loss: 0.3297
Batch 150, Loss: 0.2904
Batch 160, Loss: 0.2985
Batch 170, Loss: 0.2979
Batch 180, Loss: 0.2879
Batch 190, Loss: 0.2969
Batch 200, Loss: 0.3068
Batch 210, Loss: 0.2989
Batch 220, Loss: 0.2936
Batch 230, Loss: 0.2874
Batch 240, Loss: 0.3064
Batch 250, Loss: 0.3324
Batch 260, Loss: 0.2917
Batch 270, Loss: 0.3328
Batch 280, Loss: 0.3064
Batch 290, Loss: 0.2891
Batch 300, Loss: 0.2937
Batch 310, Loss: 0.2927
Batch 320, Loss: 0.2927
Batch 330, Loss: 0.3228
Batch 340, Loss: 0.2896
Batch 350, Loss: 0.2942
Batch 360, Loss: 0.2654
Batch 370, Loss: 0.2840
Batch 380, Loss: 0.3042
Batch 390, Loss: 0.3329
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.107601404190063 seconds
Epoch 145 accuracy: 92.11%
Batch 10, Loss: 0.2764
Batch 20, Loss: 0.3098
Batch 30, Loss: 0.2962
Batch 40, Loss: 0.2766
Batch 50, Loss: 0.2946
Batch 60, Loss: 0.3035
Batch 70, Loss: 0.3126
Batch 80, Loss: 0.2680
Batch 90, Loss: 0.2804
Batch 100, Loss: 0.3129
Batch 110, Loss: 0.2879
Batch 120, Loss: 0.2837
Batch 130, Loss: 0.3160
Batch 140, Loss: 0.2985
Batch 150, Loss: 0.2893
Batch 160, Loss: 0.2883
Batch 170, Loss: 0.3180
Batch 180, Loss: 0.2757
Batch 190, Loss: 0.2797
Batch 200, Loss: 0.2877
Batch 210, Loss: 0.3259
Batch 220, Loss: 0.2933
Batch 230, Loss: 0.3090
Batch 240, Loss: 0.3229
Batch 250, Loss: 0.3247
Batch 260, Loss: 0.2853
Batch 270, Loss: 0.2726
Batch 280, Loss: 0.3394
Batch 290, Loss: 0.3246
Batch 300, Loss: 0.3406
Batch 310, Loss: 0.2741
Batch 320, Loss: 0.3197
Batch 330, Loss: 0.3011
Batch 340, Loss: 0.2644
Batch 350, Loss: 0.3088
Batch 360, Loss: 0.3001
Batch 370, Loss: 0.2499
Batch 380, Loss: 0.2962
Batch 390, Loss: 0.2977
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.093759536743164 seconds
Epoch 146 accuracy: 93.44%
Batch 10, Loss: 0.3008
Batch 20, Loss: 0.2719
Batch 30, Loss: 0.2877
Batch 40, Loss: 0.3197
Batch 50, Loss: 0.2831
Batch 60, Loss: 0.2946
Batch 70, Loss: 0.2932
Batch 80, Loss: 0.3026
Batch 90, Loss: 0.2977
Batch 100, Loss: 0.2930
Batch 110, Loss: 0.3306
Batch 120, Loss: 0.2758
Batch 130, Loss: 0.3068
Batch 140, Loss: 0.3066
Batch 150, Loss: 0.3064
Batch 160, Loss: 0.2945
Batch 170, Loss: 0.3011
Batch 180, Loss: 0.2762
Batch 190, Loss: 0.2947
Batch 200, Loss: 0.2809
Batch 210, Loss: 0.2714
Batch 220, Loss: 0.3108
Batch 230, Loss: 0.3317
Batch 240, Loss: 0.2823
Batch 250, Loss: 0.3298
Batch 260, Loss: 0.2767
Batch 270, Loss: 0.3099
Batch 280, Loss: 0.3096
Batch 290, Loss: 0.3374
Batch 300, Loss: 0.2717
Batch 310, Loss: 0.2863
Batch 320, Loss: 0.2741
Batch 330, Loss: 0.3085
Batch 340, Loss: 0.3094
Batch 350, Loss: 0.2681
Batch 360, Loss: 0.2921
Batch 370, Loss: 0.2903
Batch 380, Loss: 0.3166
Batch 390, Loss: 0.2905
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.024719715118408 seconds
Epoch 147 accuracy: 92.24%
Batch 10, Loss: 0.2759
Batch 20, Loss: 0.2896
Batch 30, Loss: 0.2786
Batch 40, Loss: 0.2802
Batch 50, Loss: 0.2714
Batch 60, Loss: 0.2953
Batch 70, Loss: 0.2903
Batch 80, Loss: 0.3007
Batch 90, Loss: 0.2818
Batch 100, Loss: 0.2922
Batch 110, Loss: 0.2900
Batch 120, Loss: 0.3408
Batch 130, Loss: 0.2620
Batch 140, Loss: 0.2709
Batch 150, Loss: 0.2983
Batch 160, Loss: 0.3047
Batch 170, Loss: 0.3011
Batch 180, Loss: 0.2736
Batch 190, Loss: 0.2888
Batch 200, Loss: 0.3077
Batch 210, Loss: 0.2893
Batch 220, Loss: 0.2904
Batch 230, Loss: 0.3190
Batch 240, Loss: 0.2982
Batch 250, Loss: 0.2839
Batch 260, Loss: 0.2868
Batch 270, Loss: 0.2553
Batch 280, Loss: 0.2989
Batch 290, Loss: 0.2902
Batch 300, Loss: 0.3113
Batch 310, Loss: 0.2822
Batch 320, Loss: 0.2841
Batch 330, Loss: 0.2783
Batch 340, Loss: 0.3057
Batch 350, Loss: 0.2921
Batch 360, Loss: 0.2880
Batch 370, Loss: 0.2811
Batch 380, Loss: 0.2769
Batch 390, Loss: 0.2651
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.137110233306885 seconds
Epoch 148 accuracy: 93.55%
Batch 10, Loss: 0.2790
Batch 20, Loss: 0.2790
Batch 30, Loss: 0.2653
Batch 40, Loss: 0.2841
Batch 50, Loss: 0.3091
Batch 60, Loss: 0.2983
Batch 70, Loss: 0.2750
Batch 80, Loss: 0.2950
Batch 90, Loss: 0.2738
Batch 100, Loss: 0.2801
Batch 110, Loss: 0.2657
Batch 120, Loss: 0.2469
Batch 130, Loss: 0.2989
Batch 140, Loss: 0.2849
Batch 150, Loss: 0.2663
Batch 160, Loss: 0.2947
Batch 170, Loss: 0.3004
Batch 180, Loss: 0.2846
Batch 190, Loss: 0.2794
Batch 200, Loss: 0.2674
Batch 210, Loss: 0.3107
Batch 220, Loss: 0.3061
Batch 230, Loss: 0.2763
Batch 240, Loss: 0.2980
Batch 250, Loss: 0.2920
Batch 260, Loss: 0.2798
Batch 270, Loss: 0.3074
Batch 280, Loss: 0.2909
Batch 290, Loss: 0.2957
Batch 300, Loss: 0.2610
Batch 310, Loss: 0.3110
Batch 320, Loss: 0.2869
Batch 330, Loss: 0.2699
Batch 340, Loss: 0.2695
Batch 350, Loss: 0.3012
Batch 360, Loss: 0.2733
Batch 370, Loss: 0.2808
Batch 380, Loss: 0.2939
Batch 390, Loss: 0.2699
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.097588539123535 seconds
Epoch 149 accuracy: 93.52%
Batch 10, Loss: 0.2501
Batch 20, Loss: 0.2530
Batch 30, Loss: 0.2375
Batch 40, Loss: 0.2976
Batch 50, Loss: 0.2957
Batch 60, Loss: 0.2877
Batch 70, Loss: 0.2985
Batch 80, Loss: 0.2786
Batch 90, Loss: 0.2965
Batch 100, Loss: 0.3059
Batch 110, Loss: 0.2663
Batch 120, Loss: 0.3066
Batch 130, Loss: 0.2968
Batch 140, Loss: 0.2891
Batch 150, Loss: 0.2705
Batch 160, Loss: 0.3239
Batch 170, Loss: 0.3134
Batch 180, Loss: 0.2839
Batch 190, Loss: 0.2527
Batch 200, Loss: 0.2853
Batch 210, Loss: 0.2548
Batch 220, Loss: 0.2438
Batch 230, Loss: 0.2852
Batch 240, Loss: 0.2673
Batch 250, Loss: 0.2966
Batch 260, Loss: 0.3145
Batch 270, Loss: 0.3015
Batch 280, Loss: 0.2930
Batch 290, Loss: 0.2789
Batch 300, Loss: 0.2803
Batch 310, Loss: 0.2872
Batch 320, Loss: 0.2673
Batch 330, Loss: 0.2679
Batch 340, Loss: 0.2875
Batch 350, Loss: 0.2904
Batch 360, Loss: 0.2885
Batch 370, Loss: 0.2838
Batch 380, Loss: 0.2910
Batch 390, Loss: 0.2687
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.103870630264282 seconds
Epoch 150 accuracy: 93.23%
Batch 10, Loss: 0.2750
Batch 20, Loss: 0.2822
Batch 30, Loss: 0.2768
Batch 40, Loss: 0.2858
Batch 50, Loss: 0.2815
Batch 60, Loss: 0.2720
Batch 70, Loss: 0.2700
Batch 80, Loss: 0.2545
Batch 90, Loss: 0.2836
Batch 100, Loss: 0.2397
Batch 110, Loss: 0.2728
Batch 120, Loss: 0.2905
Batch 130, Loss: 0.3140
Batch 140, Loss: 0.2827
Batch 150, Loss: 0.2581
Batch 160, Loss: 0.2774
Batch 170, Loss: 0.2461
Batch 180, Loss: 0.2770
Batch 190, Loss: 0.2845
Batch 200, Loss: 0.2869
Batch 210, Loss: 0.2393
Batch 220, Loss: 0.2752
Batch 230, Loss: 0.3016
Batch 240, Loss: 0.2710
Batch 250, Loss: 0.2781
Batch 260, Loss: 0.2781
Batch 270, Loss: 0.2640
Batch 280, Loss: 0.2651
Batch 290, Loss: 0.2882
Batch 300, Loss: 0.2846
Batch 310, Loss: 0.2913
Batch 320, Loss: 0.2498
Batch 330, Loss: 0.2816
Batch 340, Loss: 0.3031
Batch 350, Loss: 0.2996
Batch 360, Loss: 0.2717
Batch 370, Loss: 0.2489
Batch 380, Loss: 0.2659
Batch 390, Loss: 0.2851
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.06825828552246 seconds
Epoch 151 accuracy: 93.82%
Batch 10, Loss: 0.2626
Batch 20, Loss: 0.2720
Batch 30, Loss: 0.2734
Batch 40, Loss: 0.2840
Batch 50, Loss: 0.2852
Batch 60, Loss: 0.2662
Batch 70, Loss: 0.2603
Batch 80, Loss: 0.2540
Batch 90, Loss: 0.2755
Batch 100, Loss: 0.2755
Batch 110, Loss: 0.2742
Batch 120, Loss: 0.2547
Batch 130, Loss: 0.2606
Batch 140, Loss: 0.2613
Batch 150, Loss: 0.2902
Batch 160, Loss: 0.2999
Batch 170, Loss: 0.2742
Batch 180, Loss: 0.2622
Batch 190, Loss: 0.2605
Batch 200, Loss: 0.2618
Batch 210, Loss: 0.2440
Batch 220, Loss: 0.2700
Batch 230, Loss: 0.2644
Batch 240, Loss: 0.2423
Batch 250, Loss: 0.2822
Batch 260, Loss: 0.2661
Batch 270, Loss: 0.2727
Batch 280, Loss: 0.2927
Batch 290, Loss: 0.2878
Batch 300, Loss: 0.2958
Batch 310, Loss: 0.2761
Batch 320, Loss: 0.2680
Batch 330, Loss: 0.2978
Batch 340, Loss: 0.2702
Batch 350, Loss: 0.3003
Batch 360, Loss: 0.2642
Batch 370, Loss: 0.3023
Batch 380, Loss: 0.2630
Batch 390, Loss: 0.2503
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.19217824935913 seconds
Epoch 152 accuracy: 94.44%
Batch 10, Loss: 0.2633
Batch 20, Loss: 0.2646
Batch 30, Loss: 0.2581
Batch 40, Loss: 0.2803
Batch 50, Loss: 0.2719
Batch 60, Loss: 0.2662
Batch 70, Loss: 0.2425
Batch 80, Loss: 0.2998
Batch 90, Loss: 0.2678
Batch 100, Loss: 0.2666
Batch 110, Loss: 0.2417
Batch 120, Loss: 0.2448
Batch 130, Loss: 0.2377
Batch 140, Loss: 0.2648
Batch 150, Loss: 0.2772
Batch 160, Loss: 0.2968
Batch 170, Loss: 0.2599
Batch 180, Loss: 0.2538
Batch 190, Loss: 0.2687
Batch 200, Loss: 0.2509
Batch 210, Loss: 0.2471
Batch 220, Loss: 0.2536
Batch 230, Loss: 0.2806
Batch 240, Loss: 0.2651
Batch 250, Loss: 0.2757
Batch 260, Loss: 0.2524
Batch 270, Loss: 0.2535
Batch 280, Loss: 0.2530
Batch 290, Loss: 0.2744
Batch 300, Loss: 0.2435
Batch 310, Loss: 0.2837
Batch 320, Loss: 0.2795
Batch 330, Loss: 0.2525
Batch 340, Loss: 0.2414
Batch 350, Loss: 0.2933
Batch 360, Loss: 0.2722
Batch 370, Loss: 0.2873
Batch 380, Loss: 0.2995
Batch 390, Loss: 0.2955
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.424959182739258 seconds
Epoch 153 accuracy: 93.21%
Batch 10, Loss: 0.3001
Batch 20, Loss: 0.2677
Batch 30, Loss: 0.2726
Batch 40, Loss: 0.2835
Batch 50, Loss: 0.2789
Batch 60, Loss: 0.2744
Batch 70, Loss: 0.2495
Batch 80, Loss: 0.2182
Batch 90, Loss: 0.2771
Batch 100, Loss: 0.3070
Batch 110, Loss: 0.2426
Batch 120, Loss: 0.2863
Batch 130, Loss: 0.2548
Batch 140, Loss: 0.2807
Batch 150, Loss: 0.2584
Batch 160, Loss: 0.2849
Batch 170, Loss: 0.2878
Batch 180, Loss: 0.2721
Batch 190, Loss: 0.2836
Batch 200, Loss: 0.2317
Batch 210, Loss: 0.2753
Batch 220, Loss: 0.2393
Batch 230, Loss: 0.2471
Batch 240, Loss: 0.2501
Batch 250, Loss: 0.2835
Batch 260, Loss: 0.2556
Batch 270, Loss: 0.2840
Batch 280, Loss: 0.2818
Batch 290, Loss: 0.2600
Batch 300, Loss: 0.2796
Batch 310, Loss: 0.2865
Batch 320, Loss: 0.2609
Batch 330, Loss: 0.2772
Batch 340, Loss: 0.2684
Batch 350, Loss: 0.2566
Batch 360, Loss: 0.2536
Batch 370, Loss: 0.2784
Batch 380, Loss: 0.2869
Batch 390, Loss: 0.2909
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.001763105392456 seconds
Epoch 154 accuracy: 93.33%
Batch 10, Loss: 0.2759
Batch 20, Loss: 0.2739
Batch 30, Loss: 0.2484
Batch 40, Loss: 0.2535
Batch 50, Loss: 0.2557
Batch 60, Loss: 0.2468
Batch 70, Loss: 0.2534
Batch 80, Loss: 0.2670
Batch 90, Loss: 0.3129
Batch 100, Loss: 0.2831
Batch 110, Loss: 0.2682
Batch 120, Loss: 0.2371
Batch 130, Loss: 0.2357
Batch 140, Loss: 0.2647
Batch 150, Loss: 0.2758
Batch 160, Loss: 0.2567
Batch 170, Loss: 0.2913
Batch 180, Loss: 0.2430
Batch 190, Loss: 0.2307
Batch 200, Loss: 0.2428
Batch 210, Loss: 0.2610
Batch 220, Loss: 0.2549
Batch 230, Loss: 0.2300
Batch 240, Loss: 0.2586
Batch 250, Loss: 0.2480
Batch 260, Loss: 0.2577
Batch 270, Loss: 0.2718
Batch 280, Loss: 0.2650
Batch 290, Loss: 0.2786
Batch 300, Loss: 0.2698
Batch 310, Loss: 0.2233
Batch 320, Loss: 0.3005
Batch 330, Loss: 0.2661
Batch 340, Loss: 0.2519
Batch 350, Loss: 0.2535
Batch 360, Loss: 0.2599
Batch 370, Loss: 0.2652
Batch 380, Loss: 0.2825
Batch 390, Loss: 0.2516
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.09541916847229 seconds
Epoch 155 accuracy: 94.29%
Batch 10, Loss: 0.2545
Batch 20, Loss: 0.2321
Batch 30, Loss: 0.2469
Batch 40, Loss: 0.2814
Batch 50, Loss: 0.2255
Batch 60, Loss: 0.2571
Batch 70, Loss: 0.2616
Batch 80, Loss: 0.2571
Batch 90, Loss: 0.2591
Batch 100, Loss: 0.2565
Batch 110, Loss: 0.2433
Batch 120, Loss: 0.2826
Batch 130, Loss: 0.2407
Batch 140, Loss: 0.2931
Batch 150, Loss: 0.2932
Batch 160, Loss: 0.2712
Batch 170, Loss: 0.2578
Batch 180, Loss: 0.2475
Batch 190, Loss: 0.2730
Batch 200, Loss: 0.2683
Batch 210, Loss: 0.2663
Batch 220, Loss: 0.2461
Batch 230, Loss: 0.2622
Batch 240, Loss: 0.2617
Batch 250, Loss: 0.2738
Batch 260, Loss: 0.2633
Batch 270, Loss: 0.2641
Batch 280, Loss: 0.2639
Batch 290, Loss: 0.2560
Batch 300, Loss: 0.2549
Batch 310, Loss: 0.2236
Batch 320, Loss: 0.2434
Batch 330, Loss: 0.2592
Batch 340, Loss: 0.2552
Batch 350, Loss: 0.2597
Batch 360, Loss: 0.2534
Batch 370, Loss: 0.2734
Batch 380, Loss: 0.2632
Batch 390, Loss: 0.2494
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.116669178009033 seconds
Epoch 156 accuracy: 94.33%
Batch 10, Loss: 0.2527
Batch 20, Loss: 0.2732
Batch 30, Loss: 0.2478
Batch 40, Loss: 0.2514
Batch 50, Loss: 0.2508
Batch 60, Loss: 0.2236
Batch 70, Loss: 0.2682
Batch 80, Loss: 0.2273
Batch 90, Loss: 0.2488
Batch 100, Loss: 0.2546
Batch 110, Loss: 0.2417
Batch 120, Loss: 0.2523
Batch 130, Loss: 0.2366
Batch 140, Loss: 0.2214
Batch 150, Loss: 0.2318
Batch 160, Loss: 0.2608
Batch 170, Loss: 0.2736
Batch 180, Loss: 0.2380
Batch 190, Loss: 0.2626
Batch 200, Loss: 0.2554
Batch 210, Loss: 0.2646
Batch 220, Loss: 0.2478
Batch 230, Loss: 0.2574
Batch 240, Loss: 0.2811
Batch 250, Loss: 0.2883
Batch 260, Loss: 0.2207
Batch 270, Loss: 0.2519
Batch 280, Loss: 0.2463
Batch 290, Loss: 0.2520
Batch 300, Loss: 0.2343
Batch 310, Loss: 0.2737
Batch 320, Loss: 0.2638
Batch 330, Loss: 0.2551
Batch 340, Loss: 0.2873
Batch 350, Loss: 0.2737
Batch 360, Loss: 0.2547
Batch 370, Loss: 0.2500
Batch 380, Loss: 0.2589
Batch 390, Loss: 0.2511
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.0286066532135 seconds
Epoch 157 accuracy: 94.38%
Batch 10, Loss: 0.2300
Batch 20, Loss: 0.2574
Batch 30, Loss: 0.2393
Batch 40, Loss: 0.2455
Batch 50, Loss: 0.2372
Batch 60, Loss: 0.2601
Batch 70, Loss: 0.2526
Batch 80, Loss: 0.2630
Batch 90, Loss: 0.2451
Batch 100, Loss: 0.2582
Batch 110, Loss: 0.2491
Batch 120, Loss: 0.2513
Batch 130, Loss: 0.2702
Batch 140, Loss: 0.2399
Batch 150, Loss: 0.2363
Batch 160, Loss: 0.2512
Batch 170, Loss: 0.2619
Batch 180, Loss: 0.2667
Batch 190, Loss: 0.2334
Batch 200, Loss: 0.2513
Batch 210, Loss: 0.2341
Batch 220, Loss: 0.2745
Batch 230, Loss: 0.2703
Batch 240, Loss: 0.2630
Batch 250, Loss: 0.2686
Batch 260, Loss: 0.2498
Batch 270, Loss: 0.2569
Batch 280, Loss: 0.2275
Batch 290, Loss: 0.2172
Batch 300, Loss: 0.2447
Batch 310, Loss: 0.2525
Batch 320, Loss: 0.2333
Batch 330, Loss: 0.2551
Batch 340, Loss: 0.2669
Batch 350, Loss: 0.2192
Batch 360, Loss: 0.2075
Batch 370, Loss: 0.2687
Batch 380, Loss: 0.2476
Batch 390, Loss: 0.2671
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.035111665725708 seconds
Epoch 158 accuracy: 93.61%
Batch 10, Loss: 0.2584
Batch 20, Loss: 0.2457
Batch 30, Loss: 0.2153
Batch 40, Loss: 0.2385
Batch 50, Loss: 0.2221
Batch 60, Loss: 0.2035
Batch 70, Loss: 0.2512
Batch 80, Loss: 0.2355
Batch 90, Loss: 0.2475
Batch 100, Loss: 0.2465
Batch 110, Loss: 0.2438
Batch 120, Loss: 0.2609
Batch 130, Loss: 0.2451
Batch 140, Loss: 0.2774
Batch 150, Loss: 0.2439
Batch 160, Loss: 0.2535
Batch 170, Loss: 0.2579
Batch 180, Loss: 0.2423
Batch 190, Loss: 0.2350
Batch 200, Loss: 0.2403
Batch 210, Loss: 0.2349
Batch 220, Loss: 0.2347
Batch 230, Loss: 0.2289
Batch 240, Loss: 0.2413
Batch 250, Loss: 0.2715
Batch 260, Loss: 0.2542
Batch 270, Loss: 0.2293
Batch 280, Loss: 0.2321
Batch 290, Loss: 0.2408
Batch 300, Loss: 0.2662
Batch 310, Loss: 0.2578
Batch 320, Loss: 0.2649
Batch 330, Loss: 0.2600
Batch 340, Loss: 0.2353
Batch 350, Loss: 0.2534
Batch 360, Loss: 0.2439
Batch 370, Loss: 0.2489
Batch 380, Loss: 0.2406
Batch 390, Loss: 0.2418
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.100351810455322 seconds
Epoch 159 accuracy: 94.67%
Batch 10, Loss: 0.2310
Batch 20, Loss: 0.2266
Batch 30, Loss: 0.2557
Batch 40, Loss: 0.2251
Batch 50, Loss: 0.2579
Batch 60, Loss: 0.2318
Batch 70, Loss: 0.2411
Batch 80, Loss: 0.2210
Batch 90, Loss: 0.2278
Batch 100, Loss: 0.2467
Batch 110, Loss: 0.2384
Batch 120, Loss: 0.2336
Batch 130, Loss: 0.2511
Batch 140, Loss: 0.2499
Batch 150, Loss: 0.2256
Batch 160, Loss: 0.2234
Batch 170, Loss: 0.2446
Batch 180, Loss: 0.2161
Batch 190, Loss: 0.2199
Batch 200, Loss: 0.2370
Batch 210, Loss: 0.2508
Batch 220, Loss: 0.2034
Batch 230, Loss: 0.2292
Batch 240, Loss: 0.2467
Batch 250, Loss: 0.2335
Batch 260, Loss: 0.2394
Batch 270, Loss: 0.2425
Batch 280, Loss: 0.2537
Batch 290, Loss: 0.2538
Batch 300, Loss: 0.2321
Batch 310, Loss: 0.2315
Batch 320, Loss: 0.2218
Batch 330, Loss: 0.2622
Batch 340, Loss: 0.2451
Batch 350, Loss: 0.2346
Batch 360, Loss: 0.2581
Batch 370, Loss: 0.2412
Batch 380, Loss: 0.2641
Batch 390, Loss: 0.2500
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.17833924293518 seconds
Epoch 160 accuracy: 94.58%
Batch 10, Loss: 0.2225
Batch 20, Loss: 0.2239
Batch 30, Loss: 0.2261
Batch 40, Loss: 0.2517
Batch 50, Loss: 0.2531
Batch 60, Loss: 0.2306
Batch 70, Loss: 0.2506
Batch 80, Loss: 0.2218
Batch 90, Loss: 0.2210
Batch 100, Loss: 0.2419
Batch 110, Loss: 0.2327
Batch 120, Loss: 0.2360
Batch 130, Loss: 0.2191
Batch 140, Loss: 0.2227
Batch 150, Loss: 0.2407
Batch 160, Loss: 0.2201
Batch 170, Loss: 0.2548
Batch 180, Loss: 0.2731
Batch 190, Loss: 0.2579
Batch 200, Loss: 0.2435
Batch 210, Loss: 0.2286
Batch 220, Loss: 0.2271
Batch 230, Loss: 0.2333
Batch 240, Loss: 0.2229
Batch 250, Loss: 0.2283
Batch 260, Loss: 0.2429
Batch 270, Loss: 0.2455
Batch 280, Loss: 0.2271
Batch 290, Loss: 0.2255
Batch 300, Loss: 0.2253
Batch 310, Loss: 0.2424
Batch 320, Loss: 0.2385
Batch 330, Loss: 0.2556
Batch 340, Loss: 0.2262
Batch 350, Loss: 0.2569
Batch 360, Loss: 0.2385
Batch 370, Loss: 0.2365
Batch 380, Loss: 0.2137
Batch 390, Loss: 0.2396
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.112648725509644 seconds
Epoch 161 accuracy: 94.54%
Batch 10, Loss: 0.2109
Batch 20, Loss: 0.2458
Batch 30, Loss: 0.2416
Batch 40, Loss: 0.2204
Batch 50, Loss: 0.2146
Batch 60, Loss: 0.2310
Batch 70, Loss: 0.2278
Batch 80, Loss: 0.2247
Batch 90, Loss: 0.2338
Batch 100, Loss: 0.2321
Batch 110, Loss: 0.2125
Batch 120, Loss: 0.2401
Batch 130, Loss: 0.2212
Batch 140, Loss: 0.2194
Batch 150, Loss: 0.2367
Batch 160, Loss: 0.2232
Batch 170, Loss: 0.2339
Batch 180, Loss: 0.2607
Batch 190, Loss: 0.2444
Batch 200, Loss: 0.2342
Batch 210, Loss: 0.2192
Batch 220, Loss: 0.2208
Batch 230, Loss: 0.2141
Batch 240, Loss: 0.2413
Batch 250, Loss: 0.2260
Batch 260, Loss: 0.2143
Batch 270, Loss: 0.2321
Batch 280, Loss: 0.2477
Batch 290, Loss: 0.2254
Batch 300, Loss: 0.2387
Batch 310, Loss: 0.2250
Batch 320, Loss: 0.2123
Batch 330, Loss: 0.2365
Batch 340, Loss: 0.2445
Batch 350, Loss: 0.2251
Batch 360, Loss: 0.2378
Batch 370, Loss: 0.2376
Batch 380, Loss: 0.2422
Batch 390, Loss: 0.2604
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.343550443649292 seconds
Epoch 162 accuracy: 94.35%
Batch 10, Loss: 0.2231
Batch 20, Loss: 0.2437
Batch 30, Loss: 0.2041
Batch 40, Loss: 0.2466
Batch 50, Loss: 0.2392
Batch 60, Loss: 0.2187
Batch 70, Loss: 0.2201
Batch 80, Loss: 0.2477
Batch 90, Loss: 0.2494
Batch 100, Loss: 0.1919
Batch 110, Loss: 0.1950
Batch 120, Loss: 0.2127
Batch 130, Loss: 0.2331
Batch 140, Loss: 0.2142
Batch 150, Loss: 0.2363
Batch 160, Loss: 0.2172
Batch 170, Loss: 0.2323
Batch 180, Loss: 0.2409
Batch 190, Loss: 0.2325
Batch 200, Loss: 0.2446
Batch 210, Loss: 0.2241
Batch 220, Loss: 0.2453
Batch 230, Loss: 0.2429
Batch 240, Loss: 0.2522
Batch 250, Loss: 0.2216
Batch 260, Loss: 0.2456
Batch 270, Loss: 0.2147
Batch 280, Loss: 0.2459
Batch 290, Loss: 0.2146
Batch 300, Loss: 0.2224
Batch 310, Loss: 0.1922
Batch 320, Loss: 0.2398
Batch 330, Loss: 0.2464
Batch 340, Loss: 0.2249
Batch 350, Loss: 0.2371
Batch 360, Loss: 0.2099
Batch 370, Loss: 0.2414
Batch 380, Loss: 0.1853
Batch 390, Loss: 0.2240
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.147364377975464 seconds
Epoch 163 accuracy: 94.63%
Batch 10, Loss: 0.2194
Batch 20, Loss: 0.2309
Batch 30, Loss: 0.2101
Batch 40, Loss: 0.2384
Batch 50, Loss: 0.2440
Batch 60, Loss: 0.2213
Batch 70, Loss: 0.2207
Batch 80, Loss: 0.2167
Batch 90, Loss: 0.2114
Batch 100, Loss: 0.2116
Batch 110, Loss: 0.2104
Batch 120, Loss: 0.2172
Batch 130, Loss: 0.2225
Batch 140, Loss: 0.2548
Batch 150, Loss: 0.2198
Batch 160, Loss: 0.2137
Batch 170, Loss: 0.2137
Batch 180, Loss: 0.2531
Batch 190, Loss: 0.2357
Batch 200, Loss: 0.2179
Batch 210, Loss: 0.2304
Batch 220, Loss: 0.2365
Batch 230, Loss: 0.2102
Batch 240, Loss: 0.1970
Batch 250, Loss: 0.2385
Batch 260, Loss: 0.2149
Batch 270, Loss: 0.2347
Batch 280, Loss: 0.2285
Batch 290, Loss: 0.2334
Batch 300, Loss: 0.2152
Batch 310, Loss: 0.2089
Batch 320, Loss: 0.1949
Batch 330, Loss: 0.2190
Batch 340, Loss: 0.2218
Batch 350, Loss: 0.2306
Batch 360, Loss: 0.2374
Batch 370, Loss: 0.2411
Batch 380, Loss: 0.2072
Batch 390, Loss: 0.2220
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.181004285812378 seconds
Epoch 164 accuracy: 94.56%
Batch 10, Loss: 0.1918
Batch 20, Loss: 0.2212
Batch 30, Loss: 0.1936
Batch 40, Loss: 0.2056
Batch 50, Loss: 0.2064
Batch 60, Loss: 0.1977
Batch 70, Loss: 0.2253
Batch 80, Loss: 0.2242
Batch 90, Loss: 0.2131
Batch 100, Loss: 0.2491
Batch 110, Loss: 0.2342
Batch 120, Loss: 0.2023
Batch 130, Loss: 0.2164
Batch 140, Loss: 0.2303
Batch 150, Loss: 0.1864
Batch 160, Loss: 0.2082
Batch 170, Loss: 0.2300
Batch 180, Loss: 0.2097
Batch 190, Loss: 0.2259
Batch 200, Loss: 0.2112
Batch 210, Loss: 0.2326
Batch 220, Loss: 0.2208
Batch 230, Loss: 0.2098
Batch 240, Loss: 0.2399
Batch 250, Loss: 0.2366
Batch 260, Loss: 0.2004
Batch 270, Loss: 0.2113
Batch 280, Loss: 0.2180
Batch 290, Loss: 0.2004
Batch 300, Loss: 0.2238
Batch 310, Loss: 0.1984
Batch 320, Loss: 0.2136
Batch 330, Loss: 0.1986
Batch 340, Loss: 0.2046
Batch 350, Loss: 0.2345
Batch 360, Loss: 0.2454
Batch 370, Loss: 0.2280
Batch 380, Loss: 0.2323
Batch 390, Loss: 0.2138
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.34786057472229 seconds
Epoch 165 accuracy: 95.03%
Batch 10, Loss: 0.2378
Batch 20, Loss: 0.2055
Batch 30, Loss: 0.2259
Batch 40, Loss: 0.2051
Batch 50, Loss: 0.2136
Batch 60, Loss: 0.1932
Batch 70, Loss: 0.2220
Batch 80, Loss: 0.2120
Batch 90, Loss: 0.2009
Batch 100, Loss: 0.2145
Batch 110, Loss: 0.2205
Batch 120, Loss: 0.2043
Batch 130, Loss: 0.2066
Batch 140, Loss: 0.2349
Batch 150, Loss: 0.2200
Batch 160, Loss: 0.1942
Batch 170, Loss: 0.2094
Batch 180, Loss: 0.1788
Batch 190, Loss: 0.2221
Batch 200, Loss: 0.2035
Batch 210, Loss: 0.2018
Batch 220, Loss: 0.2196
Batch 230, Loss: 0.1975
Batch 240, Loss: 0.2105
Batch 250, Loss: 0.2391
Batch 260, Loss: 0.2069
Batch 270, Loss: 0.2106
Batch 280, Loss: 0.2229
Batch 290, Loss: 0.2089
Batch 300, Loss: 0.2062
Batch 310, Loss: 0.2264
Batch 320, Loss: 0.2126
Batch 330, Loss: 0.2335
Batch 340, Loss: 0.2238
Batch 350, Loss: 0.1897
Batch 360, Loss: 0.2100
Batch 370, Loss: 0.2273
Batch 380, Loss: 0.2037
Batch 390, Loss: 0.2026
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 24.915329217910767 seconds
Epoch 166 accuracy: 94.96%
Batch 10, Loss: 0.2088
Batch 20, Loss: 0.2200
Batch 30, Loss: 0.1950
Batch 40, Loss: 0.2174
Batch 50, Loss: 0.2102
Batch 60, Loss: 0.1850
Batch 70, Loss: 0.2081
Batch 80, Loss: 0.2140
Batch 90, Loss: 0.2281
Batch 100, Loss: 0.2164
Batch 110, Loss: 0.1962
Batch 120, Loss: 0.2067
Batch 130, Loss: 0.2186
Batch 140, Loss: 0.1971
Batch 150, Loss: 0.1863
Batch 160, Loss: 0.2208
Batch 170, Loss: 0.2193
Batch 180, Loss: 0.1994
Batch 190, Loss: 0.2150
Batch 200, Loss: 0.2151
Batch 210, Loss: 0.2105
Batch 220, Loss: 0.2242
Batch 230, Loss: 0.2025
Batch 240, Loss: 0.2069
Batch 250, Loss: 0.2326
Batch 260, Loss: 0.2125
Batch 270, Loss: 0.2087
Batch 280, Loss: 0.2109
Batch 290, Loss: 0.2293
Batch 300, Loss: 0.2056
Batch 310, Loss: 0.2303
Batch 320, Loss: 0.2163
Batch 330, Loss: 0.2148
Batch 340, Loss: 0.1954
Batch 350, Loss: 0.2296
Batch 360, Loss: 0.2071
Batch 370, Loss: 0.2011
Batch 380, Loss: 0.2178
Batch 390, Loss: 0.2157
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.067409992218018 seconds
Epoch 167 accuracy: 95.18%
Batch 10, Loss: 0.1772
Batch 20, Loss: 0.1895
Batch 30, Loss: 0.2016
Batch 40, Loss: 0.1978
Batch 50, Loss: 0.2070
Batch 60, Loss: 0.2153
Batch 70, Loss: 0.1961
Batch 80, Loss: 0.1935
Batch 90, Loss: 0.1880
Batch 100, Loss: 0.2297
Batch 110, Loss: 0.2090
Batch 120, Loss: 0.2088
Batch 130, Loss: 0.1891
Batch 140, Loss: 0.2170
Batch 150, Loss: 0.1868
Batch 160, Loss: 0.2244
Batch 170, Loss: 0.2078
Batch 180, Loss: 0.2076
Batch 190, Loss: 0.1913
Batch 200, Loss: 0.1985
Batch 210, Loss: 0.2304
Batch 220, Loss: 0.1791
Batch 230, Loss: 0.2201
Batch 240, Loss: 0.2247
Batch 250, Loss: 0.1939
Batch 260, Loss: 0.2056
Batch 270, Loss: 0.2147
Batch 280, Loss: 0.2082
Batch 290, Loss: 0.1933
Batch 300, Loss: 0.2175
Batch 310, Loss: 0.1889
Batch 320, Loss: 0.1709
Batch 330, Loss: 0.1778
Batch 340, Loss: 0.2137
Batch 350, Loss: 0.2058
Batch 360, Loss: 0.2020
Batch 370, Loss: 0.1918
Batch 380, Loss: 0.2223
Batch 390, Loss: 0.2093
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.05287265777588 seconds
Epoch 168 accuracy: 95.0%
Batch 10, Loss: 0.2131
Batch 20, Loss: 0.2152
Batch 30, Loss: 0.1873
Batch 40, Loss: 0.2284
Batch 50, Loss: 0.2142
Batch 60, Loss: 0.1980
Batch 70, Loss: 0.1974
Batch 80, Loss: 0.2059
Batch 90, Loss: 0.1940
Batch 100, Loss: 0.1944
Batch 110, Loss: 0.1777
Batch 120, Loss: 0.2034
Batch 130, Loss: 0.1678
Batch 140, Loss: 0.1763
Batch 150, Loss: 0.1996
Batch 160, Loss: 0.2057
Batch 170, Loss: 0.1869
Batch 180, Loss: 0.2171
Batch 190, Loss: 0.1885
Batch 200, Loss: 0.1815
Batch 210, Loss: 0.2330
Batch 220, Loss: 0.2181
Batch 230, Loss: 0.1969
Batch 240, Loss: 0.2063
Batch 250, Loss: 0.1829
Batch 260, Loss: 0.2015
Batch 270, Loss: 0.1902
Batch 280, Loss: 0.1830
Batch 290, Loss: 0.1758
Batch 300, Loss: 0.1991
Batch 310, Loss: 0.2136
Batch 320, Loss: 0.1901
Batch 330, Loss: 0.2083
Batch 340, Loss: 0.2128
Batch 350, Loss: 0.1894
Batch 360, Loss: 0.2134
Batch 370, Loss: 0.2276
Batch 380, Loss: 0.2140
Batch 390, Loss: 0.1842
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.135703086853027 seconds
Epoch 169 accuracy: 95.23%
Batch 10, Loss: 0.2155
Batch 20, Loss: 0.1971
Batch 30, Loss: 0.1884
Batch 40, Loss: 0.2062
Batch 50, Loss: 0.1770
Batch 60, Loss: 0.1594
Batch 70, Loss: 0.1878
Batch 80, Loss: 0.2068
Batch 90, Loss: 0.2282
Batch 100, Loss: 0.2069
Batch 110, Loss: 0.2186
Batch 120, Loss: 0.1725
Batch 130, Loss: 0.2076
Batch 140, Loss: 0.1899
Batch 150, Loss: 0.1853
Batch 160, Loss: 0.2013
Batch 170, Loss: 0.1893
Batch 180, Loss: 0.1924
Batch 190, Loss: 0.1933
Batch 200, Loss: 0.2128
Batch 210, Loss: 0.2185
Batch 220, Loss: 0.1990
Batch 230, Loss: 0.2204
Batch 240, Loss: 0.2164
Batch 250, Loss: 0.2025
Batch 260, Loss: 0.1900
Batch 270, Loss: 0.1914
Batch 280, Loss: 0.2034
Batch 290, Loss: 0.2063
Batch 300, Loss: 0.1956
Batch 310, Loss: 0.1928
Batch 320, Loss: 0.2091
Batch 330, Loss: 0.1837
Batch 340, Loss: 0.2057
Batch 350, Loss: 0.2144
Batch 360, Loss: 0.1939
Batch 370, Loss: 0.2036
Batch 380, Loss: 0.2126
Batch 390, Loss: 0.2058
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.267543077468872 seconds
Epoch 170 accuracy: 94.99%
Batch 10, Loss: 0.2089
Batch 20, Loss: 0.2051
Batch 30, Loss: 0.2034
Batch 40, Loss: 0.2031
Batch 50, Loss: 0.2032
Batch 60, Loss: 0.2115
Batch 70, Loss: 0.1799
Batch 80, Loss: 0.2044
Batch 90, Loss: 0.1990
Batch 100, Loss: 0.2101
Batch 110, Loss: 0.1886
Batch 120, Loss: 0.2118
Batch 130, Loss: 0.1840
Batch 140, Loss: 0.2011
Batch 150, Loss: 0.1903
Batch 160, Loss: 0.2013
Batch 170, Loss: 0.1806
Batch 180, Loss: 0.1919
Batch 190, Loss: 0.1951
Batch 200, Loss: 0.2083
Batch 210, Loss: 0.1930
Batch 220, Loss: 0.2115
Batch 230, Loss: 0.1792
Batch 240, Loss: 0.1785
Batch 250, Loss: 0.2017
Batch 260, Loss: 0.2098
Batch 270, Loss: 0.1911
Batch 280, Loss: 0.1943
Batch 290, Loss: 0.1852
Batch 300, Loss: 0.2285
Batch 310, Loss: 0.2409
Batch 320, Loss: 0.2118
Batch 330, Loss: 0.1820
Batch 340, Loss: 0.1708
Batch 350, Loss: 0.2235
Batch 360, Loss: 0.1904
Batch 370, Loss: 0.1905
Batch 380, Loss: 0.2127
Batch 390, Loss: 0.1993
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.216431379318237 seconds
Epoch 171 accuracy: 95.63%
Batch 10, Loss: 0.1782
Batch 20, Loss: 0.2242
Batch 30, Loss: 0.2120
Batch 40, Loss: 0.2096
Batch 50, Loss: 0.1762
Batch 60, Loss: 0.1770
Batch 70, Loss: 0.1823
Batch 80, Loss: 0.1964
Batch 90, Loss: 0.1966
Batch 100, Loss: 0.1764
Batch 110, Loss: 0.2079
Batch 120, Loss: 0.1774
Batch 130, Loss: 0.1891
Batch 140, Loss: 0.1896
Batch 150, Loss: 0.1849
Batch 160, Loss: 0.2026
Batch 170, Loss: 0.2032
Batch 180, Loss: 0.2022
Batch 190, Loss: 0.1872
Batch 200, Loss: 0.2050
Batch 210, Loss: 0.1857
Batch 220, Loss: 0.1739
Batch 230, Loss: 0.1953
Batch 240, Loss: 0.2045
Batch 250, Loss: 0.1700
Batch 260, Loss: 0.1862
Batch 270, Loss: 0.1510
Batch 280, Loss: 0.1980
Batch 290, Loss: 0.1901
Batch 300, Loss: 0.2237
Batch 310, Loss: 0.1853
Batch 320, Loss: 0.1836
Batch 330, Loss: 0.1853
Batch 340, Loss: 0.2281
Batch 350, Loss: 0.1949
Batch 360, Loss: 0.1651
Batch 370, Loss: 0.1914
Batch 380, Loss: 0.1962
Batch 390, Loss: 0.1765
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.024810791015625 seconds
Epoch 172 accuracy: 95.46%
Batch 10, Loss: 0.1703
Batch 20, Loss: 0.1563
Batch 30, Loss: 0.1918
Batch 40, Loss: 0.2193
Batch 50, Loss: 0.1963
Batch 60, Loss: 0.1736
Batch 70, Loss: 0.2005
Batch 80, Loss: 0.1946
Batch 90, Loss: 0.1961
Batch 100, Loss: 0.2009
Batch 110, Loss: 0.1569
Batch 120, Loss: 0.1765
Batch 130, Loss: 0.1647
Batch 140, Loss: 0.1755
Batch 150, Loss: 0.1755
Batch 160, Loss: 0.1763
Batch 170, Loss: 0.1685
Batch 180, Loss: 0.1663
Batch 190, Loss: 0.1908
Batch 200, Loss: 0.1797
Batch 210, Loss: 0.2012
Batch 220, Loss: 0.1713
Batch 230, Loss: 0.1980
Batch 240, Loss: 0.1887
Batch 250, Loss: 0.1963
Batch 260, Loss: 0.1828
Batch 270, Loss: 0.1649
Batch 280, Loss: 0.1959
Batch 290, Loss: 0.1900
Batch 300, Loss: 0.1951
Batch 310, Loss: 0.1701
Batch 320, Loss: 0.1680
Batch 330, Loss: 0.1936
Batch 340, Loss: 0.1934
Batch 350, Loss: 0.1661
Batch 360, Loss: 0.1802
Batch 370, Loss: 0.1857
Batch 380, Loss: 0.1861
Batch 390, Loss: 0.2058
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.03872013092041 seconds
Epoch 173 accuracy: 95.1%
Batch 10, Loss: 0.2141
Batch 20, Loss: 0.1927
Batch 30, Loss: 0.2020
Batch 40, Loss: 0.1887
Batch 50, Loss: 0.1843
Batch 60, Loss: 0.1716
Batch 70, Loss: 0.1981
Batch 80, Loss: 0.1776
Batch 90, Loss: 0.1768
Batch 100, Loss: 0.2046
Batch 110, Loss: 0.1794
Batch 120, Loss: 0.1681
Batch 130, Loss: 0.1531
Batch 140, Loss: 0.1815
Batch 150, Loss: 0.1645
Batch 160, Loss: 0.1775
Batch 170, Loss: 0.2288
Batch 180, Loss: 0.1575
Batch 190, Loss: 0.1808
Batch 200, Loss: 0.1683
Batch 210, Loss: 0.1697
Batch 220, Loss: 0.1699
Batch 230, Loss: 0.1774
Batch 240, Loss: 0.1796
Batch 250, Loss: 0.1698
Batch 260, Loss: 0.1557
Batch 270, Loss: 0.2062
Batch 280, Loss: 0.1878
Batch 290, Loss: 0.1896
Batch 300, Loss: 0.1659
Batch 310, Loss: 0.1656
Batch 320, Loss: 0.1727
Batch 330, Loss: 0.2036
Batch 340, Loss: 0.2009
Batch 350, Loss: 0.1911
Batch 360, Loss: 0.1578
Batch 370, Loss: 0.1913
Batch 380, Loss: 0.1969
Batch 390, Loss: 0.1707
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.12873148918152 seconds
Epoch 174 accuracy: 95.66%
Batch 10, Loss: 0.2008
Batch 20, Loss: 0.1824
Batch 30, Loss: 0.1752
Batch 40, Loss: 0.1421
Batch 50, Loss: 0.1915
Batch 60, Loss: 0.1902
Batch 70, Loss: 0.1861
Batch 80, Loss: 0.1686
Batch 90, Loss: 0.1863
Batch 100, Loss: 0.1829
Batch 110, Loss: 0.1831
Batch 120, Loss: 0.1685
Batch 130, Loss: 0.1796
Batch 140, Loss: 0.1868
Batch 150, Loss: 0.2101
Batch 160, Loss: 0.1861
Batch 170, Loss: 0.1848
Batch 180, Loss: 0.1809
Batch 190, Loss: 0.1667
Batch 200, Loss: 0.1696
Batch 210, Loss: 0.1872
Batch 220, Loss: 0.1585
Batch 230, Loss: 0.1918
Batch 240, Loss: 0.1899
Batch 250, Loss: 0.1623
Batch 260, Loss: 0.1785
Batch 270, Loss: 0.1553
Batch 280, Loss: 0.1901
Batch 290, Loss: 0.1648
Batch 300, Loss: 0.1386
Batch 310, Loss: 0.1642
Batch 320, Loss: 0.1437
Batch 330, Loss: 0.1653
Batch 340, Loss: 0.2021
Batch 350, Loss: 0.2010
Batch 360, Loss: 0.1781
Batch 370, Loss: 0.1647
Batch 380, Loss: 0.1761
Batch 390, Loss: 0.1829
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.08604121208191 seconds
Epoch 175 accuracy: 95.67%
Batch 10, Loss: 0.1690
Batch 20, Loss: 0.2003
Batch 30, Loss: 0.1561
Batch 40, Loss: 0.1808
Batch 50, Loss: 0.1716
Batch 60, Loss: 0.1690
Batch 70, Loss: 0.1938
Batch 80, Loss: 0.1707
Batch 90, Loss: 0.1729
Batch 100, Loss: 0.1962
Batch 110, Loss: 0.1775
Batch 120, Loss: 0.1858
Batch 130, Loss: 0.1499
Batch 140, Loss: 0.1905
Batch 150, Loss: 0.1801
Batch 160, Loss: 0.1871
Batch 170, Loss: 0.1570
Batch 180, Loss: 0.1790
Batch 190, Loss: 0.1786
Batch 200, Loss: 0.1822
Batch 210, Loss: 0.1571
Batch 220, Loss: 0.1869
Batch 230, Loss: 0.1624
Batch 240, Loss: 0.1716
Batch 250, Loss: 0.1541
Batch 260, Loss: 0.1677
Batch 270, Loss: 0.1848
Batch 280, Loss: 0.1739
Batch 290, Loss: 0.1900
Batch 300, Loss: 0.1725
Batch 310, Loss: 0.1723
Batch 320, Loss: 0.1480
Batch 330, Loss: 0.1761
Batch 340, Loss: 0.1706
Batch 350, Loss: 0.1644
Batch 360, Loss: 0.1902
Batch 370, Loss: 0.1753
Batch 380, Loss: 0.1555
Batch 390, Loss: 0.1664
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.014007091522217 seconds
Epoch 176 accuracy: 95.62%
Batch 10, Loss: 0.1853
Batch 20, Loss: 0.1563
Batch 30, Loss: 0.1722
Batch 40, Loss: 0.1887
Batch 50, Loss: 0.1976
Batch 60, Loss: 0.1685
Batch 70, Loss: 0.1613
Batch 80, Loss: 0.1486
Batch 90, Loss: 0.1578
Batch 100, Loss: 0.1707
Batch 110, Loss: 0.1397
Batch 120, Loss: 0.1702
Batch 130, Loss: 0.1748
Batch 140, Loss: 0.1690
Batch 150, Loss: 0.1573
Batch 160, Loss: 0.1742
Batch 170, Loss: 0.1481
Batch 180, Loss: 0.1561
Batch 190, Loss: 0.1596
Batch 200, Loss: 0.1698
Batch 210, Loss: 0.1743
Batch 220, Loss: 0.1593
Batch 230, Loss: 0.1770
Batch 240, Loss: 0.1804
Batch 250, Loss: 0.1840
Batch 260, Loss: 0.1796
Batch 270, Loss: 0.1638
Batch 280, Loss: 0.1392
Batch 290, Loss: 0.1740
Batch 300, Loss: 0.1720
Batch 310, Loss: 0.1459
Batch 320, Loss: 0.1686
Batch 330, Loss: 0.1653
Batch 340, Loss: 0.1688
Batch 350, Loss: 0.1896
Batch 360, Loss: 0.1744
Batch 370, Loss: 0.1809
Batch 380, Loss: 0.1713
Batch 390, Loss: 0.1665
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.12772250175476 seconds
Epoch 177 accuracy: 95.51%
Batch 10, Loss: 0.1755
Batch 20, Loss: 0.1663
Batch 30, Loss: 0.1723
Batch 40, Loss: 0.1608
Batch 50, Loss: 0.1854
Batch 60, Loss: 0.1790
Batch 70, Loss: 0.1649
Batch 80, Loss: 0.1520
Batch 90, Loss: 0.1750
Batch 100, Loss: 0.1634
Batch 110, Loss: 0.1671
Batch 120, Loss: 0.1898
Batch 130, Loss: 0.1705
Batch 140, Loss: 0.1726
Batch 150, Loss: 0.1558
Batch 160, Loss: 0.1633
Batch 170, Loss: 0.1749
Batch 180, Loss: 0.1737
Batch 190, Loss: 0.1568
Batch 200, Loss: 0.1757
Batch 210, Loss: 0.1600
Batch 220, Loss: 0.1964
Batch 230, Loss: 0.1760
Batch 240, Loss: 0.1530
Batch 250, Loss: 0.1732
Batch 260, Loss: 0.1720
Batch 270, Loss: 0.1875
Batch 280, Loss: 0.1579
Batch 290, Loss: 0.1765
Batch 300, Loss: 0.1866
Batch 310, Loss: 0.1768
Batch 320, Loss: 0.1442
Batch 330, Loss: 0.2043
Batch 340, Loss: 0.1836
Batch 350, Loss: 0.1660
Batch 360, Loss: 0.1800
Batch 370, Loss: 0.1570
Batch 380, Loss: 0.1553
Batch 390, Loss: 0.1572
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.413639068603516 seconds
Epoch 178 accuracy: 95.81%
Batch 10, Loss: 0.1811
Batch 20, Loss: 0.1439
Batch 30, Loss: 0.1611
Batch 40, Loss: 0.1480
Batch 50, Loss: 0.1446
Batch 60, Loss: 0.1563
Batch 70, Loss: 0.1508
Batch 80, Loss: 0.1795
Batch 90, Loss: 0.1606
Batch 100, Loss: 0.1926
Batch 110, Loss: 0.1488
Batch 120, Loss: 0.1718
Batch 130, Loss: 0.1757
Batch 140, Loss: 0.1498
Batch 150, Loss: 0.1648
Batch 160, Loss: 0.1819
Batch 170, Loss: 0.1763
Batch 180, Loss: 0.1642
Batch 190, Loss: 0.1490
Batch 200, Loss: 0.1598
Batch 210, Loss: 0.1347
Batch 220, Loss: 0.1816
Batch 230, Loss: 0.1720
Batch 240, Loss: 0.1559
Batch 250, Loss: 0.1689
Batch 260, Loss: 0.1717
Batch 270, Loss: 0.1685
Batch 280, Loss: 0.1699
Batch 290, Loss: 0.1440
Batch 300, Loss: 0.1668
Batch 310, Loss: 0.1552
Batch 320, Loss: 0.1553
Batch 330, Loss: 0.1408
Batch 340, Loss: 0.1556
Batch 350, Loss: 0.1759
Batch 360, Loss: 0.1425
Batch 370, Loss: 0.1482
Batch 380, Loss: 0.1581
Batch 390, Loss: 0.1657
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.065341472625732 seconds
Epoch 179 accuracy: 95.63%
Batch 10, Loss: 0.1479
Batch 20, Loss: 0.1820
Batch 30, Loss: 0.1453
Batch 40, Loss: 0.1491
Batch 50, Loss: 0.1730
Batch 60, Loss: 0.1512
Batch 70, Loss: 0.1529
Batch 80, Loss: 0.1725
Batch 90, Loss: 0.1602
Batch 100, Loss: 0.1378
Batch 110, Loss: 0.1451
Batch 120, Loss: 0.1804
Batch 130, Loss: 0.1703
Batch 140, Loss: 0.1621
Batch 150, Loss: 0.1557
Batch 160, Loss: 0.1662
Batch 170, Loss: 0.1879
Batch 180, Loss: 0.1385
Batch 190, Loss: 0.1591
Batch 200, Loss: 0.1417
Batch 210, Loss: 0.1444
Batch 220, Loss: 0.1548
Batch 230, Loss: 0.1526
Batch 240, Loss: 0.1651
Batch 250, Loss: 0.1834
Batch 260, Loss: 0.1609
Batch 270, Loss: 0.1825
Batch 280, Loss: 0.1460
Batch 290, Loss: 0.1692
Batch 300, Loss: 0.1499
Batch 310, Loss: 0.1632
Batch 320, Loss: 0.1643
Batch 330, Loss: 0.1417
Batch 340, Loss: 0.1506
Batch 350, Loss: 0.1642
Batch 360, Loss: 0.1639
Batch 370, Loss: 0.1808
Batch 380, Loss: 0.1793
Batch 390, Loss: 0.1911
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.0489501953125 seconds
Epoch 180 accuracy: 95.69%
Batch 10, Loss: 0.1665
Batch 20, Loss: 0.1587
Batch 30, Loss: 0.1662
Batch 40, Loss: 0.1462
Batch 50, Loss: 0.1743
Batch 60, Loss: 0.1476
Batch 70, Loss: 0.1559
Batch 80, Loss: 0.1652
Batch 90, Loss: 0.1364
Batch 100, Loss: 0.1478
Batch 110, Loss: 0.1569
Batch 120, Loss: 0.1611
Batch 130, Loss: 0.1599
Batch 140, Loss: 0.1727
Batch 150, Loss: 0.1814
Batch 160, Loss: 0.1404
Batch 170, Loss: 0.1655
Batch 180, Loss: 0.1486
Batch 190, Loss: 0.1462
Batch 200, Loss: 0.1425
Batch 210, Loss: 0.1766
Batch 220, Loss: 0.1551
Batch 230, Loss: 0.1607
Batch 240, Loss: 0.1370
Batch 250, Loss: 0.1639
Batch 260, Loss: 0.1639
Batch 270, Loss: 0.1613
Batch 280, Loss: 0.1509
Batch 290, Loss: 0.1597
Batch 300, Loss: 0.1438
Batch 310, Loss: 0.1476
Batch 320, Loss: 0.1757
Batch 330, Loss: 0.1650
Batch 340, Loss: 0.1427
Batch 350, Loss: 0.1514
Batch 360, Loss: 0.1780
Batch 370, Loss: 0.1743
Batch 380, Loss: 0.1379
Batch 390, Loss: 0.1559
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.047073125839233 seconds
Epoch 181 accuracy: 95.96%
Batch 10, Loss: 0.1588
Batch 20, Loss: 0.1495
Batch 30, Loss: 0.1465
Batch 40, Loss: 0.1525
Batch 50, Loss: 0.1544
Batch 60, Loss: 0.1756
Batch 70, Loss: 0.1516
Batch 80, Loss: 0.1371
Batch 90, Loss: 0.1593
Batch 100, Loss: 0.1507
Batch 110, Loss: 0.1507
Batch 120, Loss: 0.1518
Batch 130, Loss: 0.1432
Batch 140, Loss: 0.1567
Batch 150, Loss: 0.1541
Batch 160, Loss: 0.1518
Batch 170, Loss: 0.1373
Batch 180, Loss: 0.1382
Batch 190, Loss: 0.1487
Batch 200, Loss: 0.1411
Batch 210, Loss: 0.1539
Batch 220, Loss: 0.1523
Batch 230, Loss: 0.1455
Batch 240, Loss: 0.1721
Batch 250, Loss: 0.1601
Batch 260, Loss: 0.1657
Batch 270, Loss: 0.1459
Batch 280, Loss: 0.1586
Batch 290, Loss: 0.1267
Batch 300, Loss: 0.1637
Batch 310, Loss: 0.1444
Batch 320, Loss: 0.1519
Batch 330, Loss: 0.1489
Batch 340, Loss: 0.1437
Batch 350, Loss: 0.1611
Batch 360, Loss: 0.1710
Batch 370, Loss: 0.1555
Batch 380, Loss: 0.1537
Batch 390, Loss: 0.1482
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 24.984099864959717 seconds
Epoch 182 accuracy: 95.97%
Batch 10, Loss: 0.1408
Batch 20, Loss: 0.1360
Batch 30, Loss: 0.1657
Batch 40, Loss: 0.1436
Batch 50, Loss: 0.1586
Batch 60, Loss: 0.1314
Batch 70, Loss: 0.1517
Batch 80, Loss: 0.1475
Batch 90, Loss: 0.1667
Batch 100, Loss: 0.1390
Batch 110, Loss: 0.1428
Batch 120, Loss: 0.1272
Batch 130, Loss: 0.1423
Batch 140, Loss: 0.1842
Batch 150, Loss: 0.1534
Batch 160, Loss: 0.1615
Batch 170, Loss: 0.1650
Batch 180, Loss: 0.1469
Batch 190, Loss: 0.1551
Batch 200, Loss: 0.1544
Batch 210, Loss: 0.1480
Batch 220, Loss: 0.1437
Batch 230, Loss: 0.1354
Batch 240, Loss: 0.1483
Batch 250, Loss: 0.1548
Batch 260, Loss: 0.1503
Batch 270, Loss: 0.1438
Batch 280, Loss: 0.1544
Batch 290, Loss: 0.1690
Batch 300, Loss: 0.1518
Batch 310, Loss: 0.1486
Batch 320, Loss: 0.1500
Batch 330, Loss: 0.1461
Batch 340, Loss: 0.1304
Batch 350, Loss: 0.1385
Batch 360, Loss: 0.1495
Batch 370, Loss: 0.1404
Batch 380, Loss: 0.1159
Batch 390, Loss: 0.1466
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.027896881103516 seconds
Epoch 183 accuracy: 95.9%
Batch 10, Loss: 0.1493
Batch 20, Loss: 0.1365
Batch 30, Loss: 0.1509
Batch 40, Loss: 0.1441
Batch 50, Loss: 0.1508
Batch 60, Loss: 0.1458
Batch 70, Loss: 0.1461
Batch 80, Loss: 0.1664
Batch 90, Loss: 0.1511
Batch 100, Loss: 0.1599
Batch 110, Loss: 0.1319
Batch 120, Loss: 0.1469
Batch 130, Loss: 0.1332
Batch 140, Loss: 0.1506
Batch 150, Loss: 0.1610
Batch 160, Loss: 0.1450
Batch 170, Loss: 0.1496
Batch 180, Loss: 0.1372
Batch 190, Loss: 0.1417
Batch 200, Loss: 0.1430
Batch 210, Loss: 0.1652
Batch 220, Loss: 0.1419
Batch 230, Loss: 0.1213
Batch 240, Loss: 0.1272
Batch 250, Loss: 0.1532
Batch 260, Loss: 0.1596
Batch 270, Loss: 0.1566
Batch 280, Loss: 0.1525
Batch 290, Loss: 0.1457
Batch 300, Loss: 0.1366
Batch 310, Loss: 0.1619
Batch 320, Loss: 0.1692
Batch 330, Loss: 0.1316
Batch 340, Loss: 0.1655
Batch 350, Loss: 0.1550
Batch 360, Loss: 0.1551
Batch 370, Loss: 0.1442
Batch 380, Loss: 0.1636
Batch 390, Loss: 0.1484
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 24.967527151107788 seconds
Epoch 184 accuracy: 96.02%
Batch 10, Loss: 0.1484
Batch 20, Loss: 0.1528
Batch 30, Loss: 0.1304
Batch 40, Loss: 0.1442
Batch 50, Loss: 0.1371
Batch 60, Loss: 0.1564
Batch 70, Loss: 0.1328
Batch 80, Loss: 0.1345
Batch 90, Loss: 0.1339
Batch 100, Loss: 0.1411
Batch 110, Loss: 0.1342
Batch 120, Loss: 0.1565
Batch 130, Loss: 0.1434
Batch 140, Loss: 0.1425
Batch 150, Loss: 0.1362
Batch 160, Loss: 0.1338
Batch 170, Loss: 0.1395
Batch 180, Loss: 0.1247
Batch 190, Loss: 0.1466
Batch 200, Loss: 0.1277
Batch 210, Loss: 0.1581
Batch 220, Loss: 0.1477
Batch 230, Loss: 0.1241
Batch 240, Loss: 0.1478
Batch 250, Loss: 0.1398
Batch 260, Loss: 0.1508
Batch 270, Loss: 0.1673
Batch 280, Loss: 0.1491
Batch 290, Loss: 0.1588
Batch 300, Loss: 0.1502
Batch 310, Loss: 0.1404
Batch 320, Loss: 0.1441
Batch 330, Loss: 0.1386
Batch 340, Loss: 0.1245
Batch 350, Loss: 0.1602
Batch 360, Loss: 0.1458
Batch 370, Loss: 0.1349
Batch 380, Loss: 0.1313
Batch 390, Loss: 0.1481
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 24.983661651611328 seconds
Epoch 185 accuracy: 96.15%
Batch 10, Loss: 0.1356
Batch 20, Loss: 0.1304
Batch 30, Loss: 0.1603
Batch 40, Loss: 0.1480
Batch 50, Loss: 0.1350
Batch 60, Loss: 0.1535
Batch 70, Loss: 0.1582
Batch 80, Loss: 0.1285
Batch 90, Loss: 0.1682
Batch 100, Loss: 0.1423
Batch 110, Loss: 0.1336
Batch 120, Loss: 0.1308
Batch 130, Loss: 0.1192
Batch 140, Loss: 0.1429
Batch 150, Loss: 0.1408
Batch 160, Loss: 0.1131
Batch 170, Loss: 0.1423
Batch 180, Loss: 0.1353
Batch 190, Loss: 0.1425
Batch 200, Loss: 0.1396
Batch 210, Loss: 0.1409
Batch 220, Loss: 0.1306
Batch 230, Loss: 0.1523
Batch 240, Loss: 0.1424
Batch 250, Loss: 0.1328
Batch 260, Loss: 0.1484
Batch 270, Loss: 0.1347
Batch 280, Loss: 0.1454
Batch 290, Loss: 0.1350
Batch 300, Loss: 0.1372
Batch 310, Loss: 0.1465
Batch 320, Loss: 0.1287
Batch 330, Loss: 0.1527
Batch 340, Loss: 0.1377
Batch 350, Loss: 0.1528
Batch 360, Loss: 0.1154
Batch 370, Loss: 0.1338
Batch 380, Loss: 0.1387
Batch 390, Loss: 0.1521
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 24.997629642486572 seconds
Epoch 186 accuracy: 95.97%
Batch 10, Loss: 0.1443
Batch 20, Loss: 0.1344
Batch 30, Loss: 0.1319
Batch 40, Loss: 0.1352
Batch 50, Loss: 0.1397
Batch 60, Loss: 0.1545
Batch 70, Loss: 0.1346
Batch 80, Loss: 0.1355
Batch 90, Loss: 0.1645
Batch 100, Loss: 0.1375
Batch 110, Loss: 0.1307
Batch 120, Loss: 0.1285
Batch 130, Loss: 0.1358
Batch 140, Loss: 0.1590
Batch 150, Loss: 0.1233
Batch 160, Loss: 0.1217
Batch 170, Loss: 0.1360
Batch 180, Loss: 0.1257
Batch 190, Loss: 0.1495
Batch 200, Loss: 0.1272
Batch 210, Loss: 0.1398
Batch 220, Loss: 0.1281
Batch 230, Loss: 0.1537
Batch 240, Loss: 0.1595
Batch 250, Loss: 0.1488
Batch 260, Loss: 0.1315
Batch 270, Loss: 0.1379
Batch 280, Loss: 0.1324
Batch 290, Loss: 0.1241
Batch 300, Loss: 0.1798
Batch 310, Loss: 0.1441
Batch 320, Loss: 0.1410
Batch 330, Loss: 0.1708
Batch 340, Loss: 0.1487
Batch 350, Loss: 0.1231
Batch 360, Loss: 0.1364
Batch 370, Loss: 0.1403
Batch 380, Loss: 0.1502
Batch 390, Loss: 0.1132
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 24.99197554588318 seconds
Epoch 187 accuracy: 96.13%
Batch 10, Loss: 0.1317
Batch 20, Loss: 0.1275
Batch 30, Loss: 0.1452
Batch 40, Loss: 0.1280
Batch 50, Loss: 0.1232
Batch 60, Loss: 0.1376
Batch 70, Loss: 0.1565
Batch 80, Loss: 0.1339
Batch 90, Loss: 0.1531
Batch 100, Loss: 0.1420
Batch 110, Loss: 0.1513
Batch 120, Loss: 0.1205
Batch 130, Loss: 0.1264
Batch 140, Loss: 0.1478
Batch 150, Loss: 0.1278
Batch 160, Loss: 0.1476
Batch 170, Loss: 0.1365
Batch 180, Loss: 0.1407
Batch 190, Loss: 0.1495
Batch 200, Loss: 0.1432
Batch 210, Loss: 0.1416
Batch 220, Loss: 0.1383
Batch 230, Loss: 0.1658
Batch 240, Loss: 0.1340
Batch 250, Loss: 0.1495
Batch 260, Loss: 0.1361
Batch 270, Loss: 0.1249
Batch 280, Loss: 0.1351
Batch 290, Loss: 0.1238
Batch 300, Loss: 0.1448
Batch 310, Loss: 0.1386
Batch 320, Loss: 0.1278
Batch 330, Loss: 0.1487
Batch 340, Loss: 0.1438
Batch 350, Loss: 0.1259
Batch 360, Loss: 0.1565
Batch 370, Loss: 0.1347
Batch 380, Loss: 0.1464
Batch 390, Loss: 0.1228
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.059803247451782 seconds
Epoch 188 accuracy: 96.14%
Batch 10, Loss: 0.1496
Batch 20, Loss: 0.1374
Batch 30, Loss: 0.1128
Batch 40, Loss: 0.1384
Batch 50, Loss: 0.1219
Batch 60, Loss: 0.1499
Batch 70, Loss: 0.1415
Batch 80, Loss: 0.1279
Batch 90, Loss: 0.1700
Batch 100, Loss: 0.1301
Batch 110, Loss: 0.1328
Batch 120, Loss: 0.1195
Batch 130, Loss: 0.1276
Batch 140, Loss: 0.1393
Batch 150, Loss: 0.1412
Batch 160, Loss: 0.1367
Batch 170, Loss: 0.1455
Batch 180, Loss: 0.1334
Batch 190, Loss: 0.1371
Batch 200, Loss: 0.1302
Batch 210, Loss: 0.1421
Batch 220, Loss: 0.1466
Batch 230, Loss: 0.1266
Batch 240, Loss: 0.1486
Batch 250, Loss: 0.1623
Batch 260, Loss: 0.1413
Batch 270, Loss: 0.1312
Batch 280, Loss: 0.1398
Batch 290, Loss: 0.1197
Batch 300, Loss: 0.1179
Batch 310, Loss: 0.1369
Batch 320, Loss: 0.1418
Batch 330, Loss: 0.1298
Batch 340, Loss: 0.1331
Batch 350, Loss: 0.1451
Batch 360, Loss: 0.1445
Batch 370, Loss: 0.1441
Batch 380, Loss: 0.1467
Batch 390, Loss: 0.1147
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.144041061401367 seconds
Epoch 189 accuracy: 96.22%
Batch 10, Loss: 0.1385
Batch 20, Loss: 0.1484
Batch 30, Loss: 0.1317
Batch 40, Loss: 0.1355
Batch 50, Loss: 0.1255
Batch 60, Loss: 0.1421
Batch 70, Loss: 0.1385
Batch 80, Loss: 0.1287
Batch 90, Loss: 0.1549
Batch 100, Loss: 0.1397
Batch 110, Loss: 0.1250
Batch 120, Loss: 0.1179
Batch 130, Loss: 0.1514
Batch 140, Loss: 0.1407
Batch 150, Loss: 0.1241
Batch 160, Loss: 0.1281
Batch 170, Loss: 0.1351
Batch 180, Loss: 0.1203
Batch 190, Loss: 0.1248
Batch 200, Loss: 0.1415
Batch 210, Loss: 0.1232
Batch 220, Loss: 0.1381
Batch 230, Loss: 0.1284
Batch 240, Loss: 0.1355
Batch 250, Loss: 0.1147
Batch 260, Loss: 0.1506
Batch 270, Loss: 0.1332
Batch 280, Loss: 0.1292
Batch 290, Loss: 0.1375
Batch 300, Loss: 0.1409
Batch 310, Loss: 0.1283
Batch 320, Loss: 0.1438
Batch 330, Loss: 0.1118
Batch 340, Loss: 0.1398
Batch 350, Loss: 0.1129
Batch 360, Loss: 0.1486
Batch 370, Loss: 0.1254
Batch 380, Loss: 0.1360
Batch 390, Loss: 0.1404
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.082812786102295 seconds
Epoch 190 accuracy: 96.23%
Batch 10, Loss: 0.1414
Batch 20, Loss: 0.1275
Batch 30, Loss: 0.1477
Batch 40, Loss: 0.1538
Batch 50, Loss: 0.1341
Batch 60, Loss: 0.1397
Batch 70, Loss: 0.1287
Batch 80, Loss: 0.1269
Batch 90, Loss: 0.1321
Batch 100, Loss: 0.1303
Batch 110, Loss: 0.1179
Batch 120, Loss: 0.1090
Batch 130, Loss: 0.1464
Batch 140, Loss: 0.1419
Batch 150, Loss: 0.1475
Batch 160, Loss: 0.1411
Batch 170, Loss: 0.1192
Batch 180, Loss: 0.1353
Batch 190, Loss: 0.1397
Batch 200, Loss: 0.1308
Batch 210, Loss: 0.1258
Batch 220, Loss: 0.1516
Batch 230, Loss: 0.1137
Batch 240, Loss: 0.1298
Batch 250, Loss: 0.1354
Batch 260, Loss: 0.1453
Batch 270, Loss: 0.1375
Batch 280, Loss: 0.1615
Batch 290, Loss: 0.1291
Batch 300, Loss: 0.1361
Batch 310, Loss: 0.1136
Batch 320, Loss: 0.1648
Batch 330, Loss: 0.1475
Batch 340, Loss: 0.1092
Batch 350, Loss: 0.1307
Batch 360, Loss: 0.1220
Batch 370, Loss: 0.1325
Batch 380, Loss: 0.1294
Batch 390, Loss: 0.1369
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.240522861480713 seconds
Epoch 191 accuracy: 96.34%
Batch 10, Loss: 0.1534
Batch 20, Loss: 0.1405
Batch 30, Loss: 0.1219
Batch 40, Loss: 0.1310
Batch 50, Loss: 0.1397
Batch 60, Loss: 0.1201
Batch 70, Loss: 0.1301
Batch 80, Loss: 0.1081
Batch 90, Loss: 0.1260
Batch 100, Loss: 0.1232
Batch 110, Loss: 0.1083
Batch 120, Loss: 0.1133
Batch 130, Loss: 0.1210
Batch 140, Loss: 0.1025
Batch 150, Loss: 0.1366
Batch 160, Loss: 0.1262
Batch 170, Loss: 0.1182
Batch 180, Loss: 0.1368
Batch 190, Loss: 0.1225
Batch 200, Loss: 0.1287
Batch 210, Loss: 0.1373
Batch 220, Loss: 0.1429
Batch 230, Loss: 0.1230
Batch 240, Loss: 0.1322
Batch 250, Loss: 0.1365
Batch 260, Loss: 0.1349
Batch 270, Loss: 0.1288
Batch 280, Loss: 0.1328
Batch 290, Loss: 0.1452
Batch 300, Loss: 0.1303
Batch 310, Loss: 0.1328
Batch 320, Loss: 0.1280
Batch 330, Loss: 0.1248
Batch 340, Loss: 0.1078
Batch 350, Loss: 0.1334
Batch 360, Loss: 0.1246
Batch 370, Loss: 0.1541
Batch 380, Loss: 0.1323
Batch 390, Loss: 0.1358
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.201627016067505 seconds
Epoch 192 accuracy: 96.29%
Batch 10, Loss: 0.1118
Batch 20, Loss: 0.1276
Batch 30, Loss: 0.1543
Batch 40, Loss: 0.1150
Batch 50, Loss: 0.1417
Batch 60, Loss: 0.1165
Batch 70, Loss: 0.1133
Batch 80, Loss: 0.1300
Batch 90, Loss: 0.1339
Batch 100, Loss: 0.1300
Batch 110, Loss: 0.1167
Batch 120, Loss: 0.1262
Batch 130, Loss: 0.1262
Batch 140, Loss: 0.1304
Batch 150, Loss: 0.1503
Batch 160, Loss: 0.1238
Batch 170, Loss: 0.1234
Batch 180, Loss: 0.1287
Batch 190, Loss: 0.1240
Batch 200, Loss: 0.1309
Batch 210, Loss: 0.1357
Batch 220, Loss: 0.1127
Batch 230, Loss: 0.1353
Batch 240, Loss: 0.1498
Batch 250, Loss: 0.1225
Batch 260, Loss: 0.1127
Batch 270, Loss: 0.1149
Batch 280, Loss: 0.1266
Batch 290, Loss: 0.1295
Batch 300, Loss: 0.1252
Batch 310, Loss: 0.1165
Batch 320, Loss: 0.1350
Batch 330, Loss: 0.1106
Batch 340, Loss: 0.1337
Batch 350, Loss: 0.1340
Batch 360, Loss: 0.1069
Batch 370, Loss: 0.1556
Batch 380, Loss: 0.1229
Batch 390, Loss: 0.1448
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.249844074249268 seconds
Epoch 193 accuracy: 96.27%
Batch 10, Loss: 0.1081
Batch 20, Loss: 0.1184
Batch 30, Loss: 0.1243
Batch 40, Loss: 0.1505
Batch 50, Loss: 0.1094
Batch 60, Loss: 0.1159
Batch 70, Loss: 0.1185
Batch 80, Loss: 0.1113
Batch 90, Loss: 0.1519
Batch 100, Loss: 0.1464
Batch 110, Loss: 0.1229
Batch 120, Loss: 0.1257
Batch 130, Loss: 0.1387
Batch 140, Loss: 0.1227
Batch 150, Loss: 0.1261
Batch 160, Loss: 0.1347
Batch 170, Loss: 0.1138
Batch 180, Loss: 0.1257
Batch 190, Loss: 0.1039
Batch 200, Loss: 0.1337
Batch 210, Loss: 0.1288
Batch 220, Loss: 0.1436
Batch 230, Loss: 0.1196
Batch 240, Loss: 0.1269
Batch 250, Loss: 0.1291
Batch 260, Loss: 0.1334
Batch 270, Loss: 0.1294
Batch 280, Loss: 0.1249
Batch 290, Loss: 0.1227
Batch 300, Loss: 0.1483
Batch 310, Loss: 0.1312
Batch 320, Loss: 0.1181
Batch 330, Loss: 0.1271
Batch 340, Loss: 0.1135
Batch 350, Loss: 0.1354
Batch 360, Loss: 0.1208
Batch 370, Loss: 0.1322
Batch 380, Loss: 0.1494
Batch 390, Loss: 0.1222
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.090681314468384 seconds
Epoch 194 accuracy: 96.34%
Batch 10, Loss: 0.1119
Batch 20, Loss: 0.1214
Batch 30, Loss: 0.1087
Batch 40, Loss: 0.1304
Batch 50, Loss: 0.1365
Batch 60, Loss: 0.1357
Batch 70, Loss: 0.1130
Batch 80, Loss: 0.1210
Batch 90, Loss: 0.1564
Batch 100, Loss: 0.1165
Batch 110, Loss: 0.1319
Batch 120, Loss: 0.1357
Batch 130, Loss: 0.1405
Batch 140, Loss: 0.1476
Batch 150, Loss: 0.1204
Batch 160, Loss: 0.1209
Batch 170, Loss: 0.1224
Batch 180, Loss: 0.1271
Batch 190, Loss: 0.1286
Batch 200, Loss: 0.1541
Batch 210, Loss: 0.1293
Batch 220, Loss: 0.1206
Batch 230, Loss: 0.1054
Batch 240, Loss: 0.1391
Batch 250, Loss: 0.1066
Batch 260, Loss: 0.1455
Batch 270, Loss: 0.1413
Batch 280, Loss: 0.1320
Batch 290, Loss: 0.1250
Batch 300, Loss: 0.1349
Batch 310, Loss: 0.1351
Batch 320, Loss: 0.1186
Batch 330, Loss: 0.1358
Batch 340, Loss: 0.1156
Batch 350, Loss: 0.1318
Batch 360, Loss: 0.1312
Batch 370, Loss: 0.1295
Batch 380, Loss: 0.1327
Batch 390, Loss: 0.1244
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.19509720802307 seconds
Epoch 195 accuracy: 96.31%
Batch 10, Loss: 0.1113
Batch 20, Loss: 0.1195
Batch 30, Loss: 0.1480
Batch 40, Loss: 0.1360
Batch 50, Loss: 0.1191
Batch 60, Loss: 0.1227
Batch 70, Loss: 0.1268
Batch 80, Loss: 0.1149
Batch 90, Loss: 0.1195
Batch 100, Loss: 0.1461
Batch 110, Loss: 0.1361
Batch 120, Loss: 0.1307
Batch 130, Loss: 0.1352
Batch 140, Loss: 0.1247
Batch 150, Loss: 0.1185
Batch 160, Loss: 0.1156
Batch 170, Loss: 0.1341
Batch 180, Loss: 0.1250
Batch 190, Loss: 0.1097
Batch 200, Loss: 0.1293
Batch 210, Loss: 0.1327
Batch 220, Loss: 0.1398
Batch 230, Loss: 0.1107
Batch 240, Loss: 0.1217
Batch 250, Loss: 0.1054
Batch 260, Loss: 0.1357
Batch 270, Loss: 0.1335
Batch 280, Loss: 0.1249
Batch 290, Loss: 0.1255
Batch 300, Loss: 0.1227
Batch 310, Loss: 0.1237
Batch 320, Loss: 0.1326
Batch 330, Loss: 0.1303
Batch 340, Loss: 0.1308
Batch 350, Loss: 0.1432
Batch 360, Loss: 0.1304
Batch 370, Loss: 0.1393
Batch 380, Loss: 0.1314
Batch 390, Loss: 0.1284
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.1790714263916 seconds
Epoch 196 accuracy: 96.24%
Batch 10, Loss: 0.1206
Batch 20, Loss: 0.1333
Batch 30, Loss: 0.1012
Batch 40, Loss: 0.1246
Batch 50, Loss: 0.1165
Batch 60, Loss: 0.1378
Batch 70, Loss: 0.1236
Batch 80, Loss: 0.1249
Batch 90, Loss: 0.1359
Batch 100, Loss: 0.1197
Batch 110, Loss: 0.1063
Batch 120, Loss: 0.1178
Batch 130, Loss: 0.1157
Batch 140, Loss: 0.1340
Batch 150, Loss: 0.1084
Batch 160, Loss: 0.1348
Batch 170, Loss: 0.1268
Batch 180, Loss: 0.1060
Batch 190, Loss: 0.1205
Batch 200, Loss: 0.1180
Batch 210, Loss: 0.1298
Batch 220, Loss: 0.1343
Batch 230, Loss: 0.1007
Batch 240, Loss: 0.1360
Batch 250, Loss: 0.1112
Batch 260, Loss: 0.1556
Batch 270, Loss: 0.1328
Batch 280, Loss: 0.1291
Batch 290, Loss: 0.1175
Batch 300, Loss: 0.1067
Batch 310, Loss: 0.1334
Batch 320, Loss: 0.1142
Batch 330, Loss: 0.1230
Batch 340, Loss: 0.1175
Batch 350, Loss: 0.1370
Batch 360, Loss: 0.1176
Batch 370, Loss: 0.1182
Batch 380, Loss: 0.1150
Batch 390, Loss: 0.1151
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.061519145965576 seconds
Epoch 197 accuracy: 96.29%
Batch 10, Loss: 0.1259
Batch 20, Loss: 0.1439
Batch 30, Loss: 0.1249
Batch 40, Loss: 0.1271
Batch 50, Loss: 0.1382
Batch 60, Loss: 0.1391
Batch 70, Loss: 0.1417
Batch 80, Loss: 0.1281
Batch 90, Loss: 0.1215
Batch 100, Loss: 0.1240
Batch 110, Loss: 0.1274
Batch 120, Loss: 0.1254
Batch 130, Loss: 0.1194
Batch 140, Loss: 0.1323
Batch 150, Loss: 0.1219
Batch 160, Loss: 0.1250
Batch 170, Loss: 0.1113
Batch 180, Loss: 0.1199
Batch 190, Loss: 0.1236
Batch 200, Loss: 0.1074
Batch 210, Loss: 0.1305
Batch 220, Loss: 0.1275
Batch 230, Loss: 0.1288
Batch 240, Loss: 0.1245
Batch 250, Loss: 0.1071
Batch 260, Loss: 0.1280
Batch 270, Loss: 0.1168
Batch 280, Loss: 0.1178
Batch 290, Loss: 0.1198
Batch 300, Loss: 0.1516
Batch 310, Loss: 0.1387
Batch 320, Loss: 0.1343
Batch 330, Loss: 0.1220
Batch 340, Loss: 0.1095
Batch 350, Loss: 0.1225
Batch 360, Loss: 0.1234
Batch 370, Loss: 0.1191
Batch 380, Loss: 0.1395
Batch 390, Loss: 0.1340
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.27929925918579 seconds
Epoch 198 accuracy: 96.39%
Batch 10, Loss: 0.1142
Batch 20, Loss: 0.1063
Batch 30, Loss: 0.1290
Batch 40, Loss: 0.1170
Batch 50, Loss: 0.1190
Batch 60, Loss: 0.1316
Batch 70, Loss: 0.1188
Batch 80, Loss: 0.1148
Batch 90, Loss: 0.1391
Batch 100, Loss: 0.1242
Batch 110, Loss: 0.1407
Batch 120, Loss: 0.1326
Batch 130, Loss: 0.1384
Batch 140, Loss: 0.1046
Batch 150, Loss: 0.1148
Batch 160, Loss: 0.1506
Batch 170, Loss: 0.1305
Batch 180, Loss: 0.1461
Batch 190, Loss: 0.1244
Batch 200, Loss: 0.1290
Batch 210, Loss: 0.1275
Batch 220, Loss: 0.1220
Batch 230, Loss: 0.1368
Batch 240, Loss: 0.1141
Batch 250, Loss: 0.1297
Batch 260, Loss: 0.1223
Batch 270, Loss: 0.1355
Batch 280, Loss: 0.1215
Batch 290, Loss: 0.1159
Batch 300, Loss: 0.1198
Batch 310, Loss: 0.1058
Batch 320, Loss: 0.1394
Batch 330, Loss: 0.1501
Batch 340, Loss: 0.1342
Batch 350, Loss: 0.1328
Batch 360, Loss: 0.1430
Batch 370, Loss: 0.1202
Batch 380, Loss: 0.1173
Batch 390, Loss: 0.1306
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.27220606803894 seconds
Epoch 199 accuracy: 96.4%
Batch 10, Loss: 0.1071
Batch 20, Loss: 0.1386
Batch 30, Loss: 0.1202
Batch 40, Loss: 0.1286
Batch 50, Loss: 0.1023
Batch 60, Loss: 0.1219
Batch 70, Loss: 0.1219
Batch 80, Loss: 0.1360
Batch 90, Loss: 0.1277
Batch 100, Loss: 0.1135
Batch 110, Loss: 0.1369
Batch 120, Loss: 0.1442
Batch 130, Loss: 0.1266
Batch 140, Loss: 0.1403
Batch 150, Loss: 0.1343
Batch 160, Loss: 0.1314
Batch 170, Loss: 0.1205
Batch 180, Loss: 0.1284
Batch 190, Loss: 0.1247
Batch 200, Loss: 0.0951
Batch 210, Loss: 0.1279
Batch 220, Loss: 0.1333
Batch 230, Loss: 0.1095
Batch 240, Loss: 0.1096
Batch 250, Loss: 0.1236
Batch 260, Loss: 0.1225
Batch 270, Loss: 0.1195
Batch 280, Loss: 0.1150
Batch 290, Loss: 0.1325
Batch 300, Loss: 0.1251
Batch 310, Loss: 0.1362
Batch 320, Loss: 0.0894
Batch 330, Loss: 0.1302
Batch 340, Loss: 0.1218
Batch 350, Loss: 0.1460
Batch 360, Loss: 0.1235
Batch 370, Loss: 0.1442
Batch 380, Loss: 0.1269
Batch 390, Loss: 0.1323
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.091261386871338 seconds
Epoch 200 accuracy: 96.33%
Total training time: 5028.917061090469 seconds
