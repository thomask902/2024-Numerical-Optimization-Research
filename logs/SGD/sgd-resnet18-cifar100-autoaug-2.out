The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1309
Batch 20, Loss: 4.2638
Batch 30, Loss: 3.9740
Batch 40, Loss: 3.8928
Batch 50, Loss: 3.8074
Batch 60, Loss: 3.7294
Batch 70, Loss: 3.7097
Batch 80, Loss: 3.6690
Batch 90, Loss: 3.6472
Batch 100, Loss: 3.6255
Batch 110, Loss: 3.6146
Batch 120, Loss: 3.6463
Batch 130, Loss: 3.5809
Batch 140, Loss: 3.6005
Batch 150, Loss: 3.5780
Batch 160, Loss: 3.5592
Batch 170, Loss: 3.5769
Batch 180, Loss: 3.5766
Batch 190, Loss: 3.5127
Batch 200, Loss: 3.5260
Batch 210, Loss: 3.4995
Batch 220, Loss: 3.4952
Batch 230, Loss: 3.4805
Batch 240, Loss: 3.5154
Batch 250, Loss: 3.5117
Batch 260, Loss: 3.4682
Batch 270, Loss: 3.4761
Batch 280, Loss: 3.4893
Batch 290, Loss: 3.4700
Batch 300, Loss: 3.4449
Batch 310, Loss: 3.4669
Batch 320, Loss: 3.4401
Batch 330, Loss: 3.4121
Batch 340, Loss: 3.4056
Batch 350, Loss: 3.4569
Batch 360, Loss: 3.4108
Batch 370, Loss: 3.4289
Batch 380, Loss: 3.4027
Batch 390, Loss: 3.4098
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.497871160507202 seconds
Epoch 1 accuracy: 9.65%
Batch 10, Loss: 3.4011
Batch 20, Loss: 3.3994
Batch 30, Loss: 3.3969
Batch 40, Loss: 3.3911
Batch 50, Loss: 3.3573
Batch 60, Loss: 3.3470
Batch 70, Loss: 3.3857
Batch 80, Loss: 3.3087
Batch 90, Loss: 3.3619
Batch 100, Loss: 3.3511
Batch 110, Loss: 3.3692
Batch 120, Loss: 3.3052
Batch 130, Loss: 3.3214
Batch 140, Loss: 3.3125
Batch 150, Loss: 3.3020
Batch 160, Loss: 3.3152
Batch 170, Loss: 3.3241
Batch 180, Loss: 3.2940
Batch 190, Loss: 3.2653
Batch 200, Loss: 3.3020
Batch 210, Loss: 3.2736
Batch 220, Loss: 3.2470
Batch 230, Loss: 3.2813
Batch 240, Loss: 3.3006
Batch 250, Loss: 3.2698
Batch 260, Loss: 3.2813
Batch 270, Loss: 3.2430
Batch 280, Loss: 3.2533
Batch 290, Loss: 3.1885
Batch 300, Loss: 3.1903
Batch 310, Loss: 3.1930
Batch 320, Loss: 3.2201
Batch 330, Loss: 3.1505
Batch 340, Loss: 3.1757
Batch 350, Loss: 3.2301
Batch 360, Loss: 3.1955
Batch 370, Loss: 3.1341
Batch 380, Loss: 3.1691
Batch 390, Loss: 3.1431
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.40373992919922 seconds
Epoch 2 accuracy: 17.8%
Batch 10, Loss: 3.1493
Batch 20, Loss: 3.1226
Batch 30, Loss: 3.1059
Batch 40, Loss: 3.1011
Batch 50, Loss: 3.1130
Batch 60, Loss: 3.0685
Batch 70, Loss: 3.0798
Batch 80, Loss: 3.1661
Batch 90, Loss: 3.0890
Batch 100, Loss: 3.1136
Batch 110, Loss: 3.1068
Batch 120, Loss: 3.0957
Batch 130, Loss: 3.0056
Batch 140, Loss: 3.0555
Batch 150, Loss: 3.0790
Batch 160, Loss: 2.9825
Batch 170, Loss: 3.0126
Batch 180, Loss: 3.0549
Batch 190, Loss: 2.9563
Batch 200, Loss: 2.9920
Batch 210, Loss: 2.9740
Batch 220, Loss: 3.0188
Batch 230, Loss: 2.9413
Batch 240, Loss: 2.8691
Batch 250, Loss: 2.9780
Batch 260, Loss: 2.9691
Batch 270, Loss: 2.9256
Batch 280, Loss: 2.9702
Batch 290, Loss: 2.9087
Batch 300, Loss: 2.9256
Batch 310, Loss: 2.9626
Batch 320, Loss: 2.8462
Batch 330, Loss: 2.8820
Batch 340, Loss: 2.9054
Batch 350, Loss: 2.9210
Batch 360, Loss: 2.8774
Batch 370, Loss: 2.8152
Batch 380, Loss: 2.8790
Batch 390, Loss: 2.8264
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.38100266456604 seconds
Epoch 3 accuracy: 22.88%
Batch 10, Loss: 2.8138
Batch 20, Loss: 2.7962
Batch 30, Loss: 2.7773
Batch 40, Loss: 2.8178
Batch 50, Loss: 2.7824
Batch 60, Loss: 2.8261
Batch 70, Loss: 2.8235
Batch 80, Loss: 2.7516
Batch 90, Loss: 2.7732
Batch 100, Loss: 2.8137
Batch 110, Loss: 2.7076
Batch 120, Loss: 2.7789
Batch 130, Loss: 2.7399
Batch 140, Loss: 2.7206
Batch 150, Loss: 2.7184
Batch 160, Loss: 2.6936
Batch 170, Loss: 2.7334
Batch 180, Loss: 2.6658
Batch 190, Loss: 2.6996
Batch 200, Loss: 2.7348
Batch 210, Loss: 2.6219
Batch 220, Loss: 2.6510
Batch 230, Loss: 2.6760
Batch 240, Loss: 2.6467
Batch 250, Loss: 2.5919
Batch 260, Loss: 2.5366
Batch 270, Loss: 2.6748
Batch 280, Loss: 2.6150
Batch 290, Loss: 2.6672
Batch 300, Loss: 2.6320
Batch 310, Loss: 2.5877
Batch 320, Loss: 2.6542
Batch 330, Loss: 2.6443
Batch 340, Loss: 2.5989
Batch 350, Loss: 2.6311
Batch 360, Loss: 2.5382
Batch 370, Loss: 2.5467
Batch 380, Loss: 2.5588
Batch 390, Loss: 2.6168
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.445709943771362 seconds
Epoch 4 accuracy: 30.28%
Batch 10, Loss: 2.4506
Batch 20, Loss: 2.4566
Batch 30, Loss: 2.5025
Batch 40, Loss: 2.5522
Batch 50, Loss: 2.4917
Batch 60, Loss: 2.4649
Batch 70, Loss: 2.5356
Batch 80, Loss: 2.4391
Batch 90, Loss: 2.5549
Batch 100, Loss: 2.5180
Batch 110, Loss: 2.4692
Batch 120, Loss: 2.4958
Batch 130, Loss: 2.4283
Batch 140, Loss: 2.4055
Batch 150, Loss: 2.4679
Batch 160, Loss: 2.4595
Batch 170, Loss: 2.4312
Batch 180, Loss: 2.3754
Batch 190, Loss: 2.4016
Batch 200, Loss: 2.4340
Batch 210, Loss: 2.4389
Batch 220, Loss: 2.4159
Batch 230, Loss: 2.3985
Batch 240, Loss: 2.3872
Batch 250, Loss: 2.4232
Batch 260, Loss: 2.4257
Batch 270, Loss: 2.3257
Batch 280, Loss: 2.4653
Batch 290, Loss: 2.4401
Batch 300, Loss: 2.3834
Batch 310, Loss: 2.4290
Batch 320, Loss: 2.3823
Batch 330, Loss: 2.3621
Batch 340, Loss: 2.3492
Batch 350, Loss: 2.2898
Batch 360, Loss: 2.3376
Batch 370, Loss: 2.3123
Batch 380, Loss: 2.3116
Batch 390, Loss: 2.3119
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.366891145706177 seconds
Epoch 5 accuracy: 34.72%
Batch 10, Loss: 2.3489
Batch 20, Loss: 2.3429
Batch 30, Loss: 2.2908
Batch 40, Loss: 2.2991
Batch 50, Loss: 2.3331
Batch 60, Loss: 2.2592
Batch 70, Loss: 2.2593
Batch 80, Loss: 2.2577
Batch 90, Loss: 2.2678
Batch 100, Loss: 2.3297
Batch 110, Loss: 2.2341
Batch 120, Loss: 2.2701
Batch 130, Loss: 2.2775
Batch 140, Loss: 2.2833
Batch 150, Loss: 2.2165
Batch 160, Loss: 2.3043
Batch 170, Loss: 2.2371
Batch 180, Loss: 2.2359
Batch 190, Loss: 2.2198
Batch 200, Loss: 2.3058
Batch 210, Loss: 2.2739
Batch 220, Loss: 2.2715
Batch 230, Loss: 2.1765
Batch 240, Loss: 2.2602
Batch 250, Loss: 2.2108
Batch 260, Loss: 2.1742
Batch 270, Loss: 2.1990
Batch 280, Loss: 2.2411
Batch 290, Loss: 2.2275
Batch 300, Loss: 2.1757
Batch 310, Loss: 2.2532
Batch 320, Loss: 2.1908
Batch 330, Loss: 2.2007
Batch 340, Loss: 2.1078
Batch 350, Loss: 2.2092
Batch 360, Loss: 2.3240
Batch 370, Loss: 2.1517
Batch 380, Loss: 2.2262
Batch 390, Loss: 2.1442
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.4185528755188 seconds
Epoch 6 accuracy: 39.55%
Batch 10, Loss: 2.1045
Batch 20, Loss: 2.0907
Batch 30, Loss: 2.1372
Batch 40, Loss: 2.1915
Batch 50, Loss: 2.1395
Batch 60, Loss: 1.9611
Batch 70, Loss: 2.0803
Batch 80, Loss: 2.1472
Batch 90, Loss: 2.1609
Batch 100, Loss: 2.1675
Batch 110, Loss: 2.1279
Batch 120, Loss: 2.1728
Batch 130, Loss: 2.0931
Batch 140, Loss: 2.1423
Batch 150, Loss: 2.0608
Batch 160, Loss: 2.0902
Batch 170, Loss: 2.1311
Batch 180, Loss: 2.1217
Batch 190, Loss: 2.1924
Batch 200, Loss: 2.0711
Batch 210, Loss: 2.1249
Batch 220, Loss: 2.0879
Batch 230, Loss: 2.1233
Batch 240, Loss: 2.0502
Batch 250, Loss: 2.1362
Batch 260, Loss: 2.0848
Batch 270, Loss: 2.0979
Batch 280, Loss: 2.0527
Batch 290, Loss: 2.0814
Batch 300, Loss: 2.0662
Batch 310, Loss: 2.1159
Batch 320, Loss: 2.0376
Batch 330, Loss: 2.0476
Batch 340, Loss: 2.0911
Batch 350, Loss: 2.0971
Batch 360, Loss: 2.0569
Batch 370, Loss: 2.0551
Batch 380, Loss: 2.0242
Batch 390, Loss: 2.0438
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.456255435943604 seconds
Epoch 7 accuracy: 40.45%
Batch 10, Loss: 1.9870
Batch 20, Loss: 2.0451
Batch 30, Loss: 1.9981
Batch 40, Loss: 2.0323
Batch 50, Loss: 2.0387
Batch 60, Loss: 2.0373
Batch 70, Loss: 1.9090
Batch 80, Loss: 2.0276
Batch 90, Loss: 1.9924
Batch 100, Loss: 1.9515
Batch 110, Loss: 2.0133
Batch 120, Loss: 2.0393
Batch 130, Loss: 2.0002
Batch 140, Loss: 2.0921
Batch 150, Loss: 2.0961
Batch 160, Loss: 2.0245
Batch 170, Loss: 2.0651
Batch 180, Loss: 2.0262
Batch 190, Loss: 2.0182
Batch 200, Loss: 2.0413
Batch 210, Loss: 2.0110
Batch 220, Loss: 2.0521
Batch 230, Loss: 1.9694
Batch 240, Loss: 2.0467
Batch 250, Loss: 2.0349
Batch 260, Loss: 1.9812
Batch 270, Loss: 1.9691
Batch 280, Loss: 2.0018
Batch 290, Loss: 1.9791
Batch 300, Loss: 1.9426
Batch 310, Loss: 2.0185
Batch 320, Loss: 2.0449
Batch 330, Loss: 2.0284
Batch 340, Loss: 2.0306
Batch 350, Loss: 2.0529
Batch 360, Loss: 2.0412
Batch 370, Loss: 1.9723
Batch 380, Loss: 2.0003
Batch 390, Loss: 1.9428
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.427114248275757 seconds
Epoch 8 accuracy: 44.0%
Batch 10, Loss: 1.9156
Batch 20, Loss: 1.9818
Batch 30, Loss: 2.0304
Batch 40, Loss: 2.0198
Batch 50, Loss: 1.9321
Batch 60, Loss: 1.9110
Batch 70, Loss: 1.9659
Batch 80, Loss: 1.9604
Batch 90, Loss: 1.9059
Batch 100, Loss: 1.9811
Batch 110, Loss: 1.8780
Batch 120, Loss: 1.8819
Batch 130, Loss: 2.0052
Batch 140, Loss: 1.9308
Batch 150, Loss: 1.9452
Batch 160, Loss: 1.9679
Batch 170, Loss: 1.8745
Batch 180, Loss: 1.9253
Batch 190, Loss: 1.9705
Batch 200, Loss: 1.9747
Batch 210, Loss: 1.9729
Batch 220, Loss: 1.9515
Batch 230, Loss: 1.9869
Batch 240, Loss: 1.9338
Batch 250, Loss: 1.9326
Batch 260, Loss: 1.9027
Batch 270, Loss: 1.9258
Batch 280, Loss: 1.9944
Batch 290, Loss: 1.9668
Batch 300, Loss: 1.9425
Batch 310, Loss: 1.9566
Batch 320, Loss: 1.9155
Batch 330, Loss: 1.9103
Batch 340, Loss: 1.8452
Batch 350, Loss: 1.9310
Batch 360, Loss: 1.9106
Batch 370, Loss: 1.9492
Batch 380, Loss: 1.8823
Batch 390, Loss: 1.9111
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.472045421600342 seconds
Epoch 9 accuracy: 42.57%
Batch 10, Loss: 1.9198
Batch 20, Loss: 1.9355
Batch 30, Loss: 1.8379
Batch 40, Loss: 1.8545
Batch 50, Loss: 1.8419
Batch 60, Loss: 1.8321
Batch 70, Loss: 1.8776
Batch 80, Loss: 1.8788
Batch 90, Loss: 1.9134
Batch 100, Loss: 1.8324
Batch 110, Loss: 1.9216
Batch 120, Loss: 1.9042
Batch 130, Loss: 1.8908
Batch 140, Loss: 1.8655
Batch 150, Loss: 1.8308
Batch 160, Loss: 1.8660
Batch 170, Loss: 1.8878
Batch 180, Loss: 1.9051
Batch 190, Loss: 1.8898
Batch 200, Loss: 1.8895
Batch 210, Loss: 1.9108
Batch 220, Loss: 1.8488
Batch 230, Loss: 1.8859
Batch 240, Loss: 1.8545
Batch 250, Loss: 1.8867
Batch 260, Loss: 1.8103
Batch 270, Loss: 1.8702
Batch 280, Loss: 1.9506
Batch 290, Loss: 1.8443
Batch 300, Loss: 1.8568
Batch 310, Loss: 1.8937
Batch 320, Loss: 1.8627
Batch 330, Loss: 1.9047
Batch 340, Loss: 1.8699
Batch 350, Loss: 1.9416
Batch 360, Loss: 1.8848
Batch 370, Loss: 1.8457
Batch 380, Loss: 1.9260
Batch 390, Loss: 1.9167
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.37887477874756 seconds
Epoch 10 accuracy: 49.64%
Batch 10, Loss: 1.8097
Batch 20, Loss: 1.8920
Batch 30, Loss: 1.8400
Batch 40, Loss: 1.8532
Batch 50, Loss: 1.8357
Batch 60, Loss: 1.8531
Batch 70, Loss: 1.7940
Batch 80, Loss: 1.8057
Batch 90, Loss: 1.8491
Batch 100, Loss: 1.7640
Batch 110, Loss: 1.8720
Batch 120, Loss: 1.7722
Batch 130, Loss: 1.8603
Batch 140, Loss: 1.8150
Batch 150, Loss: 1.7892
Batch 160, Loss: 1.7800
Batch 170, Loss: 1.7393
Batch 180, Loss: 1.8224
Batch 190, Loss: 1.8610
Batch 200, Loss: 1.8148
Batch 210, Loss: 1.8036
Batch 220, Loss: 1.7987
Batch 230, Loss: 1.8544
Batch 240, Loss: 1.8310
Batch 250, Loss: 1.8786
Batch 260, Loss: 1.8876
Batch 270, Loss: 1.7777
Batch 280, Loss: 1.7926
Batch 290, Loss: 1.8818
Batch 300, Loss: 1.9344
Batch 310, Loss: 1.8166
Batch 320, Loss: 1.8397
Batch 330, Loss: 1.8366
Batch 340, Loss: 1.8284
Batch 350, Loss: 1.8105
Batch 360, Loss: 1.9115
Batch 370, Loss: 1.8526
Batch 380, Loss: 1.8333
Batch 390, Loss: 1.8349
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.366472959518433 seconds
Epoch 11 accuracy: 46.94%
Batch 10, Loss: 1.8031
Batch 20, Loss: 1.8200
Batch 30, Loss: 1.7988
Batch 40, Loss: 1.7546
Batch 50, Loss: 1.8607
Batch 60, Loss: 1.7841
Batch 70, Loss: 1.8121
Batch 80, Loss: 1.7978
Batch 90, Loss: 1.7260
Batch 100, Loss: 1.7516
Batch 110, Loss: 1.8177
Batch 120, Loss: 1.7730
Batch 130, Loss: 1.7403
Batch 140, Loss: 1.7838
Batch 150, Loss: 1.7530
Batch 160, Loss: 1.8501
Batch 170, Loss: 1.8297
Batch 180, Loss: 1.7212
Batch 190, Loss: 1.7635
Batch 200, Loss: 1.7556
Batch 210, Loss: 1.8432
Batch 220, Loss: 1.7727
Batch 230, Loss: 1.8370
Batch 240, Loss: 1.8253
Batch 250, Loss: 1.8097
Batch 260, Loss: 1.8732
Batch 270, Loss: 1.8390
Batch 280, Loss: 1.8536
Batch 290, Loss: 1.8219
Batch 300, Loss: 1.8514
Batch 310, Loss: 1.7344
Batch 320, Loss: 1.7736
Batch 330, Loss: 1.7406
Batch 340, Loss: 1.8142
Batch 350, Loss: 1.7991
Batch 360, Loss: 1.8026
Batch 370, Loss: 1.8345
Batch 380, Loss: 1.8133
Batch 390, Loss: 1.7759
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.357455730438232 seconds
Epoch 12 accuracy: 42.07%
Batch 10, Loss: 1.7318
Batch 20, Loss: 1.7416
Batch 30, Loss: 1.7369
Batch 40, Loss: 1.8397
Batch 50, Loss: 1.7407
Batch 60, Loss: 1.7750
Batch 70, Loss: 1.7463
Batch 80, Loss: 1.6841
Batch 90, Loss: 1.7649
Batch 100, Loss: 1.7423
Batch 110, Loss: 1.6762
Batch 120, Loss: 1.7523
Batch 130, Loss: 1.7642
Batch 140, Loss: 1.7738
Batch 150, Loss: 1.7971
Batch 160, Loss: 1.8091
Batch 170, Loss: 1.7577
Batch 180, Loss: 1.7647
Batch 190, Loss: 1.7493
Batch 200, Loss: 1.7489
Batch 210, Loss: 1.6852
Batch 220, Loss: 1.7538
Batch 230, Loss: 1.7497
Batch 240, Loss: 1.7404
Batch 250, Loss: 1.7349
Batch 260, Loss: 1.7173
Batch 270, Loss: 1.6937
Batch 280, Loss: 1.8480
Batch 290, Loss: 1.7119
Batch 300, Loss: 1.7684
Batch 310, Loss: 1.7796
Batch 320, Loss: 1.7702
Batch 330, Loss: 1.7741
Batch 340, Loss: 1.7734
Batch 350, Loss: 1.7766
Batch 360, Loss: 1.7528
Batch 370, Loss: 1.6868
Batch 380, Loss: 1.7645
Batch 390, Loss: 1.7877
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.385573387145996 seconds
Epoch 13 accuracy: 51.55%
Batch 10, Loss: 1.7395
Batch 20, Loss: 1.6824
Batch 30, Loss: 1.7685
Batch 40, Loss: 1.7171
Batch 50, Loss: 1.7405
Batch 60, Loss: 1.6999
Batch 70, Loss: 1.7279
Batch 80, Loss: 1.8298
Batch 90, Loss: 1.7479
Batch 100, Loss: 1.6812
Batch 110, Loss: 1.7130
Batch 120, Loss: 1.7759
Batch 130, Loss: 1.6900
Batch 140, Loss: 1.7222
Batch 150, Loss: 1.6448
Batch 160, Loss: 1.6433
Batch 170, Loss: 1.7641
Batch 180, Loss: 1.7122
Batch 190, Loss: 1.7602
Batch 200, Loss: 1.7462
Batch 210, Loss: 1.6864
Batch 220, Loss: 1.7680
Batch 230, Loss: 1.7474
Batch 240, Loss: 1.7195
Batch 250, Loss: 1.7230
Batch 260, Loss: 1.7149
Batch 270, Loss: 1.7232
Batch 280, Loss: 1.6934
Batch 290, Loss: 1.8022
Batch 300, Loss: 1.7710
Batch 310, Loss: 1.6942
Batch 320, Loss: 1.7869
Batch 330, Loss: 1.7450
Batch 340, Loss: 1.6800
Batch 350, Loss: 1.6592
Batch 360, Loss: 1.7506
Batch 370, Loss: 1.7667
Batch 380, Loss: 1.7428
Batch 390, Loss: 1.7501
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.282795429229736 seconds
Epoch 14 accuracy: 51.31%
Batch 10, Loss: 1.6839
Batch 20, Loss: 1.6672
Batch 30, Loss: 1.6587
Batch 40, Loss: 1.6349
Batch 50, Loss: 1.6605
Batch 60, Loss: 1.6749
Batch 70, Loss: 1.6226
Batch 80, Loss: 1.6872
Batch 90, Loss: 1.6938
Batch 100, Loss: 1.6950
Batch 110, Loss: 1.6344
Batch 120, Loss: 1.6657
Batch 130, Loss: 1.6279
Batch 140, Loss: 1.7287
Batch 150, Loss: 1.6543
Batch 160, Loss: 1.5944
Batch 170, Loss: 1.6683
Batch 180, Loss: 1.7155
Batch 190, Loss: 1.7369
Batch 200, Loss: 1.6875
Batch 210, Loss: 1.7593
Batch 220, Loss: 1.7299
Batch 230, Loss: 1.7650
Batch 240, Loss: 1.5883
Batch 250, Loss: 1.7289
Batch 260, Loss: 1.6929
Batch 270, Loss: 1.7613
Batch 280, Loss: 1.7066
Batch 290, Loss: 1.7331
Batch 300, Loss: 1.6885
Batch 310, Loss: 1.6958
Batch 320, Loss: 1.6849
Batch 330, Loss: 1.6595
Batch 340, Loss: 1.7414
Batch 350, Loss: 1.7410
Batch 360, Loss: 1.7081
Batch 370, Loss: 1.7016
Batch 380, Loss: 1.7750
Batch 390, Loss: 1.6897
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.352843523025513 seconds
Epoch 15 accuracy: 46.15%
Batch 10, Loss: 1.6570
Batch 20, Loss: 1.6410
Batch 30, Loss: 1.7205
Batch 40, Loss: 1.6656
Batch 50, Loss: 1.6498
Batch 60, Loss: 1.5924
Batch 70, Loss: 1.7305
Batch 80, Loss: 1.6777
Batch 90, Loss: 1.6906
Batch 100, Loss: 1.7037
Batch 110, Loss: 1.6265
Batch 120, Loss: 1.6224
Batch 130, Loss: 1.6576
Batch 140, Loss: 1.6277
Batch 150, Loss: 1.6755
Batch 160, Loss: 1.6795
Batch 170, Loss: 1.7093
Batch 180, Loss: 1.7309
Batch 190, Loss: 1.7115
Batch 200, Loss: 1.7312
Batch 210, Loss: 1.6411
Batch 220, Loss: 1.7064
Batch 230, Loss: 1.7312
Batch 240, Loss: 1.6722
Batch 250, Loss: 1.6883
Batch 260, Loss: 1.6647
Batch 270, Loss: 1.7208
Batch 280, Loss: 1.6592
Batch 290, Loss: 1.7012
Batch 300, Loss: 1.6913
Batch 310, Loss: 1.7639
Batch 320, Loss: 1.6884
Batch 330, Loss: 1.7159
Batch 340, Loss: 1.7630
Batch 350, Loss: 1.7648
Batch 360, Loss: 1.7060
Batch 370, Loss: 1.6821
Batch 380, Loss: 1.6276
Batch 390, Loss: 1.7191
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.360097646713257 seconds
Epoch 16 accuracy: 49.22%
Batch 10, Loss: 1.6626
Batch 20, Loss: 1.5932
Batch 30, Loss: 1.6157
Batch 40, Loss: 1.5840
Batch 50, Loss: 1.6547
Batch 60, Loss: 1.6644
Batch 70, Loss: 1.6480
Batch 80, Loss: 1.6306
Batch 90, Loss: 1.6876
Batch 100, Loss: 1.7193
Batch 110, Loss: 1.6094
Batch 120, Loss: 1.6539
Batch 130, Loss: 1.6433
Batch 140, Loss: 1.6269
Batch 150, Loss: 1.6896
Batch 160, Loss: 1.6092
Batch 170, Loss: 1.6082
Batch 180, Loss: 1.6923
Batch 190, Loss: 1.6936
Batch 200, Loss: 1.6906
Batch 210, Loss: 1.6129
Batch 220, Loss: 1.6573
Batch 230, Loss: 1.7076
Batch 240, Loss: 1.6754
Batch 250, Loss: 1.7139
Batch 260, Loss: 1.6737
Batch 270, Loss: 1.6245
Batch 280, Loss: 1.6611
Batch 290, Loss: 1.6312
Batch 300, Loss: 1.6576
Batch 310, Loss: 1.6306
Batch 320, Loss: 1.6873
Batch 330, Loss: 1.6883
Batch 340, Loss: 1.6862
Batch 350, Loss: 1.6986
Batch 360, Loss: 1.6413
Batch 370, Loss: 1.6986
Batch 380, Loss: 1.6280
Batch 390, Loss: 1.7297
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.350529432296753 seconds
Epoch 17 accuracy: 54.37%
Batch 10, Loss: 1.6157
Batch 20, Loss: 1.6271
Batch 30, Loss: 1.6011
Batch 40, Loss: 1.6214
Batch 50, Loss: 1.6150
Batch 60, Loss: 1.6926
Batch 70, Loss: 1.6013
Batch 80, Loss: 1.6131
Batch 90, Loss: 1.6586
Batch 100, Loss: 1.6280
Batch 110, Loss: 1.6294
Batch 120, Loss: 1.5926
Batch 130, Loss: 1.6381
Batch 140, Loss: 1.6502
Batch 150, Loss: 1.6356
Batch 160, Loss: 1.6272
Batch 170, Loss: 1.6181
Batch 180, Loss: 1.7031
Batch 190, Loss: 1.6666
Batch 200, Loss: 1.6572
Batch 210, Loss: 1.6536
Batch 220, Loss: 1.6036
Batch 230, Loss: 1.6131
Batch 240, Loss: 1.6581
Batch 250, Loss: 1.6159
Batch 260, Loss: 1.6775
Batch 270, Loss: 1.5856
Batch 280, Loss: 1.6364
Batch 290, Loss: 1.6255
Batch 300, Loss: 1.7010
Batch 310, Loss: 1.6451
Batch 320, Loss: 1.6750
Batch 330, Loss: 1.6681
Batch 340, Loss: 1.6338
Batch 350, Loss: 1.6812
Batch 360, Loss: 1.6731
Batch 370, Loss: 1.6696
Batch 380, Loss: 1.7067
Batch 390, Loss: 1.6307
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.286887884140015 seconds
Epoch 18 accuracy: 50.6%
Batch 10, Loss: 1.6393
Batch 20, Loss: 1.6125
Batch 30, Loss: 1.5359
Batch 40, Loss: 1.5514
Batch 50, Loss: 1.5911
Batch 60, Loss: 1.6093
Batch 70, Loss: 1.6753
Batch 80, Loss: 1.5972
Batch 90, Loss: 1.5787
Batch 100, Loss: 1.6420
Batch 110, Loss: 1.6298
Batch 120, Loss: 1.6394
Batch 130, Loss: 1.6156
Batch 140, Loss: 1.6449
Batch 150, Loss: 1.6575
Batch 160, Loss: 1.6600
Batch 170, Loss: 1.6929
Batch 180, Loss: 1.5903
Batch 190, Loss: 1.5745
Batch 200, Loss: 1.6453
Batch 210, Loss: 1.6277
Batch 220, Loss: 1.6811
Batch 230, Loss: 1.6190
Batch 240, Loss: 1.6243
Batch 250, Loss: 1.5939
Batch 260, Loss: 1.6087
Batch 270, Loss: 1.6670
Batch 280, Loss: 1.6283
Batch 290, Loss: 1.6786
Batch 300, Loss: 1.6726
Batch 310, Loss: 1.6818
Batch 320, Loss: 1.5943
Batch 330, Loss: 1.6273
Batch 340, Loss: 1.6201
Batch 350, Loss: 1.6655
Batch 360, Loss: 1.6278
Batch 370, Loss: 1.6479
Batch 380, Loss: 1.6020
Batch 390, Loss: 1.6520
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.40702533721924 seconds
Epoch 19 accuracy: 51.69%
Batch 10, Loss: 1.5938
Batch 20, Loss: 1.5777
Batch 30, Loss: 1.5826
Batch 40, Loss: 1.5445
Batch 50, Loss: 1.5797
Batch 60, Loss: 1.6071
Batch 70, Loss: 1.5854
Batch 80, Loss: 1.6336
Batch 90, Loss: 1.5856
Batch 100, Loss: 1.6020
Batch 110, Loss: 1.6624
Batch 120, Loss: 1.5917
Batch 130, Loss: 1.6600
Batch 140, Loss: 1.6293
Batch 150, Loss: 1.5929
Batch 160, Loss: 1.6442
Batch 170, Loss: 1.5557
Batch 180, Loss: 1.5690
Batch 190, Loss: 1.6702
Batch 200, Loss: 1.5739
Batch 210, Loss: 1.6633
Batch 220, Loss: 1.5880
Batch 230, Loss: 1.6452
Batch 240, Loss: 1.6472
Batch 250, Loss: 1.5960
Batch 260, Loss: 1.6004
Batch 270, Loss: 1.6068
Batch 280, Loss: 1.6213
Batch 290, Loss: 1.6620
Batch 300, Loss: 1.7330
Batch 310, Loss: 1.5704
Batch 320, Loss: 1.6162
Batch 330, Loss: 1.5878
Batch 340, Loss: 1.6911
Batch 350, Loss: 1.5718
Batch 360, Loss: 1.6299
Batch 370, Loss: 1.6547
Batch 380, Loss: 1.6565
Batch 390, Loss: 1.6324
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.350321054458618 seconds
Epoch 20 accuracy: 54.95%
Batch 10, Loss: 1.6102
Batch 20, Loss: 1.5399
Batch 30, Loss: 1.5857
Batch 40, Loss: 1.5664
Batch 50, Loss: 1.6368
Batch 60, Loss: 1.6414
Batch 70, Loss: 1.6229
Batch 80, Loss: 1.6246
Batch 90, Loss: 1.6107
Batch 100, Loss: 1.5664
Batch 110, Loss: 1.5972
Batch 120, Loss: 1.5811
Batch 130, Loss: 1.5712
Batch 140, Loss: 1.5358
Batch 150, Loss: 1.5609
Batch 160, Loss: 1.5228
Batch 170, Loss: 1.6035
Batch 180, Loss: 1.5994
Batch 190, Loss: 1.6168
Batch 200, Loss: 1.6388
Batch 210, Loss: 1.5680
Batch 220, Loss: 1.6557
Batch 230, Loss: 1.5711
Batch 240, Loss: 1.6487
Batch 250, Loss: 1.5817
Batch 260, Loss: 1.6237
Batch 270, Loss: 1.5580
Batch 280, Loss: 1.6206
Batch 290, Loss: 1.5790
Batch 300, Loss: 1.6633
Batch 310, Loss: 1.6488
Batch 320, Loss: 1.6845
Batch 330, Loss: 1.6154
Batch 340, Loss: 1.6499
Batch 350, Loss: 1.5762
Batch 360, Loss: 1.6041
Batch 370, Loss: 1.5865
Batch 380, Loss: 1.6306
Batch 390, Loss: 1.6272
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.37978172302246 seconds
Epoch 21 accuracy: 51.71%
Batch 10, Loss: 1.5308
Batch 20, Loss: 1.5276
Batch 30, Loss: 1.5169
Batch 40, Loss: 1.5951
Batch 50, Loss: 1.6506
Batch 60, Loss: 1.5899
Batch 70, Loss: 1.5873
Batch 80, Loss: 1.5485
Batch 90, Loss: 1.5371
Batch 100, Loss: 1.5645
Batch 110, Loss: 1.6496
Batch 120, Loss: 1.5453
Batch 130, Loss: 1.5625
Batch 140, Loss: 1.6025
Batch 150, Loss: 1.5801
Batch 160, Loss: 1.5568
Batch 170, Loss: 1.5613
Batch 180, Loss: 1.5741
Batch 190, Loss: 1.5345
Batch 200, Loss: 1.6134
Batch 210, Loss: 1.5754
Batch 220, Loss: 1.6354
Batch 230, Loss: 1.6024
Batch 240, Loss: 1.5072
Batch 250, Loss: 1.6534
Batch 260, Loss: 1.5273
Batch 270, Loss: 1.5863
Batch 280, Loss: 1.5873
Batch 290, Loss: 1.5816
Batch 300, Loss: 1.5171
Batch 310, Loss: 1.6836
Batch 320, Loss: 1.5479
Batch 330, Loss: 1.5534
Batch 340, Loss: 1.6424
Batch 350, Loss: 1.5889
Batch 360, Loss: 1.5567
Batch 370, Loss: 1.6253
Batch 380, Loss: 1.6725
Batch 390, Loss: 1.5985
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.412248849868774 seconds
Epoch 22 accuracy: 50.43%
Batch 10, Loss: 1.5368
Batch 20, Loss: 1.4786
Batch 30, Loss: 1.5493
Batch 40, Loss: 1.5772
Batch 50, Loss: 1.5771
Batch 60, Loss: 1.5516
Batch 70, Loss: 1.6026
Batch 80, Loss: 1.5919
Batch 90, Loss: 1.6199
Batch 100, Loss: 1.5652
Batch 110, Loss: 1.5503
Batch 120, Loss: 1.5897
Batch 130, Loss: 1.6289
Batch 140, Loss: 1.5773
Batch 150, Loss: 1.5553
Batch 160, Loss: 1.5998
Batch 170, Loss: 1.5231
Batch 180, Loss: 1.6146
Batch 190, Loss: 1.5975
Batch 200, Loss: 1.5715
Batch 210, Loss: 1.5783
Batch 220, Loss: 1.6492
Batch 230, Loss: 1.6122
Batch 240, Loss: 1.5178
Batch 250, Loss: 1.4778
Batch 260, Loss: 1.6231
Batch 270, Loss: 1.5776
Batch 280, Loss: 1.5502
Batch 290, Loss: 1.5526
Batch 300, Loss: 1.6136
Batch 310, Loss: 1.5929
Batch 320, Loss: 1.5813
Batch 330, Loss: 1.5820
Batch 340, Loss: 1.5940
Batch 350, Loss: 1.5792
Batch 360, Loss: 1.6084
Batch 370, Loss: 1.6359
Batch 380, Loss: 1.6188
Batch 390, Loss: 1.5992
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.401931047439575 seconds
Epoch 23 accuracy: 54.38%
Batch 10, Loss: 1.5516
Batch 20, Loss: 1.5094
Batch 30, Loss: 1.5623
Batch 40, Loss: 1.5798
Batch 50, Loss: 1.5858
Batch 60, Loss: 1.4983
Batch 70, Loss: 1.5141
Batch 80, Loss: 1.5410
Batch 90, Loss: 1.5974
Batch 100, Loss: 1.5410
Batch 110, Loss: 1.5397
Batch 120, Loss: 1.5142
Batch 130, Loss: 1.6376
Batch 140, Loss: 1.5821
Batch 150, Loss: 1.5941
Batch 160, Loss: 1.5500
Batch 170, Loss: 1.5892
Batch 180, Loss: 1.6048
Batch 190, Loss: 1.5532
Batch 200, Loss: 1.5765
Batch 210, Loss: 1.5866
Batch 220, Loss: 1.5608
Batch 230, Loss: 1.6188
Batch 240, Loss: 1.6000
Batch 250, Loss: 1.6331
Batch 260, Loss: 1.5266
Batch 270, Loss: 1.5816
Batch 280, Loss: 1.6254
Batch 290, Loss: 1.5664
Batch 300, Loss: 1.4904
Batch 310, Loss: 1.5090
Batch 320, Loss: 1.6236
Batch 330, Loss: 1.5550
Batch 340, Loss: 1.5323
Batch 350, Loss: 1.5782
Batch 360, Loss: 1.5343
Batch 370, Loss: 1.5360
Batch 380, Loss: 1.5708
Batch 390, Loss: 1.5012
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.497188091278076 seconds
Epoch 24 accuracy: 51.85%
Batch 10, Loss: 1.5125
Batch 20, Loss: 1.5438
Batch 30, Loss: 1.5194
Batch 40, Loss: 1.5860
Batch 50, Loss: 1.6065
Batch 60, Loss: 1.5348
Batch 70, Loss: 1.4930
Batch 80, Loss: 1.5869
Batch 90, Loss: 1.5312
Batch 100, Loss: 1.5176
Batch 110, Loss: 1.4656
Batch 120, Loss: 1.5014
Batch 130, Loss: 1.5842
Batch 140, Loss: 1.4346
Batch 150, Loss: 1.4877
Batch 160, Loss: 1.5341
Batch 170, Loss: 1.5219
Batch 180, Loss: 1.5699
Batch 190, Loss: 1.5300
Batch 200, Loss: 1.5541
Batch 210, Loss: 1.5671
Batch 220, Loss: 1.5433
Batch 230, Loss: 1.4415
Batch 240, Loss: 1.5060
Batch 250, Loss: 1.6359
Batch 260, Loss: 1.5965
Batch 270, Loss: 1.6088
Batch 280, Loss: 1.5550
Batch 290, Loss: 1.6001
Batch 300, Loss: 1.6090
Batch 310, Loss: 1.5994
Batch 320, Loss: 1.6038
Batch 330, Loss: 1.5159
Batch 340, Loss: 1.6238
Batch 350, Loss: 1.6063
Batch 360, Loss: 1.5136
Batch 370, Loss: 1.5835
Batch 380, Loss: 1.5759
Batch 390, Loss: 1.6284
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.423216581344604 seconds
Epoch 25 accuracy: 56.78%
Batch 10, Loss: 1.5232
Batch 20, Loss: 1.5966
Batch 30, Loss: 1.5654
Batch 40, Loss: 1.4974
Batch 50, Loss: 1.5160
Batch 60, Loss: 1.4892
Batch 70, Loss: 1.5254
Batch 80, Loss: 1.4415
Batch 90, Loss: 1.5153
Batch 100, Loss: 1.5031
Batch 110, Loss: 1.5411
Batch 120, Loss: 1.5320
Batch 130, Loss: 1.5830
Batch 140, Loss: 1.5624
Batch 150, Loss: 1.5874
Batch 160, Loss: 1.5236
Batch 170, Loss: 1.4739
Batch 180, Loss: 1.5133
Batch 190, Loss: 1.5688
Batch 200, Loss: 1.5768
Batch 210, Loss: 1.6015
Batch 220, Loss: 1.6049
Batch 230, Loss: 1.5568
Batch 240, Loss: 1.6058
Batch 250, Loss: 1.5097
Batch 260, Loss: 1.5228
Batch 270, Loss: 1.5936
Batch 280, Loss: 1.6911
Batch 290, Loss: 1.5018
Batch 300, Loss: 1.5969
Batch 310, Loss: 1.6227
Batch 320, Loss: 1.5519
Batch 330, Loss: 1.5848
Batch 340, Loss: 1.5965
Batch 350, Loss: 1.6012
Batch 360, Loss: 1.4783
Batch 370, Loss: 1.4978
Batch 380, Loss: 1.5599
Batch 390, Loss: 1.6114
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.33754539489746 seconds
Epoch 26 accuracy: 57.1%
Batch 10, Loss: 1.5028
Batch 20, Loss: 1.4640
Batch 30, Loss: 1.5238
Batch 40, Loss: 1.5789
Batch 50, Loss: 1.4885
Batch 60, Loss: 1.4786
Batch 70, Loss: 1.5854
Batch 80, Loss: 1.5368
Batch 90, Loss: 1.5272
Batch 100, Loss: 1.5055
Batch 110, Loss: 1.5415
Batch 120, Loss: 1.5011
Batch 130, Loss: 1.4984
Batch 140, Loss: 1.5208
Batch 150, Loss: 1.5917
Batch 160, Loss: 1.4960
Batch 170, Loss: 1.5359
Batch 180, Loss: 1.5585
Batch 190, Loss: 1.5542
Batch 200, Loss: 1.5249
Batch 210, Loss: 1.5528
Batch 220, Loss: 1.5497
Batch 230, Loss: 1.5123
Batch 240, Loss: 1.6169
Batch 250, Loss: 1.4442
Batch 260, Loss: 1.6181
Batch 270, Loss: 1.6348
Batch 280, Loss: 1.5698
Batch 290, Loss: 1.5488
Batch 300, Loss: 1.5256
Batch 310, Loss: 1.5301
Batch 320, Loss: 1.5110
Batch 330, Loss: 1.5846
Batch 340, Loss: 1.5211
Batch 350, Loss: 1.5169
Batch 360, Loss: 1.5375
Batch 370, Loss: 1.5553
Batch 380, Loss: 1.6234
Batch 390, Loss: 1.5017
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.37324285507202 seconds
Epoch 27 accuracy: 54.19%
Batch 10, Loss: 1.5529
Batch 20, Loss: 1.5273
Batch 30, Loss: 1.4794
Batch 40, Loss: 1.5491
Batch 50, Loss: 1.4565
Batch 60, Loss: 1.4594
Batch 70, Loss: 1.5050
Batch 80, Loss: 1.4794
Batch 90, Loss: 1.4650
Batch 100, Loss: 1.4950
Batch 110, Loss: 1.5537
Batch 120, Loss: 1.6126
Batch 130, Loss: 1.5273
Batch 140, Loss: 1.5148
Batch 150, Loss: 1.5741
Batch 160, Loss: 1.5122
Batch 170, Loss: 1.4897
Batch 180, Loss: 1.5957
Batch 190, Loss: 1.5661
Batch 200, Loss: 1.5960
Batch 210, Loss: 1.5542
Batch 220, Loss: 1.5499
Batch 230, Loss: 1.5405
Batch 240, Loss: 1.5234
Batch 250, Loss: 1.5281
Batch 260, Loss: 1.5658
Batch 270, Loss: 1.5456
Batch 280, Loss: 1.5186
Batch 290, Loss: 1.5335
Batch 300, Loss: 1.5290
Batch 310, Loss: 1.5454
Batch 320, Loss: 1.5735
Batch 330, Loss: 1.5837
Batch 340, Loss: 1.5460
Batch 350, Loss: 1.5032
Batch 360, Loss: 1.5694
Batch 370, Loss: 1.5373
Batch 380, Loss: 1.6066
Batch 390, Loss: 1.5162
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.39863109588623 seconds
Epoch 28 accuracy: 53.46%
Batch 10, Loss: 1.4855
Batch 20, Loss: 1.4619
Batch 30, Loss: 1.5464
Batch 40, Loss: 1.4844
Batch 50, Loss: 1.5032
Batch 60, Loss: 1.5077
Batch 70, Loss: 1.5526
Batch 80, Loss: 1.4935
Batch 90, Loss: 1.5355
Batch 100, Loss: 1.5434
Batch 110, Loss: 1.5610
Batch 120, Loss: 1.4642
Batch 130, Loss: 1.5326
Batch 140, Loss: 1.5050
Batch 150, Loss: 1.5738
Batch 160, Loss: 1.5468
Batch 170, Loss: 1.5149
Batch 180, Loss: 1.5833
Batch 190, Loss: 1.4954
Batch 200, Loss: 1.4551
Batch 210, Loss: 1.5776
Batch 220, Loss: 1.5492
Batch 230, Loss: 1.5071
Batch 240, Loss: 1.4813
Batch 250, Loss: 1.4694
Batch 260, Loss: 1.5224
Batch 270, Loss: 1.4664
Batch 280, Loss: 1.6061
Batch 290, Loss: 1.6122
Batch 300, Loss: 1.5769
Batch 310, Loss: 1.5682
Batch 320, Loss: 1.5175
Batch 330, Loss: 1.5430
Batch 340, Loss: 1.5794
Batch 350, Loss: 1.5620
Batch 360, Loss: 1.5421
Batch 370, Loss: 1.5297
Batch 380, Loss: 1.4796
Batch 390, Loss: 1.5290
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.393039226531982 seconds
Epoch 29 accuracy: 54.66%
Batch 10, Loss: 1.4226
Batch 20, Loss: 1.4874
Batch 30, Loss: 1.5060
Batch 40, Loss: 1.4567
Batch 50, Loss: 1.4724
Batch 60, Loss: 1.4504
Batch 70, Loss: 1.4673
Batch 80, Loss: 1.4571
Batch 90, Loss: 1.4617
Batch 100, Loss: 1.5653
Batch 110, Loss: 1.5688
Batch 120, Loss: 1.4633
Batch 130, Loss: 1.5007
Batch 140, Loss: 1.4869
Batch 150, Loss: 1.5081
Batch 160, Loss: 1.5082
Batch 170, Loss: 1.5232
Batch 180, Loss: 1.5048
Batch 190, Loss: 1.5944
Batch 200, Loss: 1.5330
Batch 210, Loss: 1.5266
Batch 220, Loss: 1.5509
Batch 230, Loss: 1.4580
Batch 240, Loss: 1.5266
Batch 250, Loss: 1.4609
Batch 260, Loss: 1.5555
Batch 270, Loss: 1.5544
Batch 280, Loss: 1.5256
Batch 290, Loss: 1.5516
Batch 300, Loss: 1.5823
Batch 310, Loss: 1.4928
Batch 320, Loss: 1.6220
Batch 330, Loss: 1.4635
Batch 340, Loss: 1.5249
Batch 350, Loss: 1.5585
Batch 360, Loss: 1.5434
Batch 370, Loss: 1.5504
Batch 380, Loss: 1.4876
Batch 390, Loss: 1.5468
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.296665906906128 seconds
Epoch 30 accuracy: 53.84%
Batch 10, Loss: 1.4892
Batch 20, Loss: 1.4417
Batch 30, Loss: 1.5106
Batch 40, Loss: 1.4603
Batch 50, Loss: 1.5618
Batch 60, Loss: 1.5645
Batch 70, Loss: 1.4897
Batch 80, Loss: 1.4746
Batch 90, Loss: 1.5163
Batch 100, Loss: 1.5167
Batch 110, Loss: 1.5191
Batch 120, Loss: 1.4532
Batch 130, Loss: 1.5149
Batch 140, Loss: 1.4957
Batch 150, Loss: 1.4969
Batch 160, Loss: 1.4848
Batch 170, Loss: 1.4357
Batch 180, Loss: 1.5212
Batch 190, Loss: 1.5347
Batch 200, Loss: 1.5464
Batch 210, Loss: 1.5286
Batch 220, Loss: 1.4908
Batch 230, Loss: 1.5849
Batch 240, Loss: 1.5175
Batch 250, Loss: 1.5265
Batch 260, Loss: 1.4714
Batch 270, Loss: 1.4932
Batch 280, Loss: 1.5668
Batch 290, Loss: 1.5266
Batch 300, Loss: 1.4956
Batch 310, Loss: 1.4857
Batch 320, Loss: 1.4303
Batch 330, Loss: 1.4712
Batch 340, Loss: 1.5120
Batch 350, Loss: 1.5561
Batch 360, Loss: 1.5009
Batch 370, Loss: 1.5423
Batch 380, Loss: 1.5377
Batch 390, Loss: 1.5032
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.407355308532715 seconds
Epoch 31 accuracy: 56.48%
Batch 10, Loss: 1.5022
Batch 20, Loss: 1.4720
Batch 30, Loss: 1.4652
Batch 40, Loss: 1.4354
Batch 50, Loss: 1.5206
Batch 60, Loss: 1.5298
Batch 70, Loss: 1.4668
Batch 80, Loss: 1.4223
Batch 90, Loss: 1.4836
Batch 100, Loss: 1.4768
Batch 110, Loss: 1.4385
Batch 120, Loss: 1.3856
Batch 130, Loss: 1.4742
Batch 140, Loss: 1.4867
Batch 150, Loss: 1.5646
Batch 160, Loss: 1.4700
Batch 170, Loss: 1.5181
Batch 180, Loss: 1.4659
Batch 190, Loss: 1.4936
Batch 200, Loss: 1.5171
Batch 210, Loss: 1.4906
Batch 220, Loss: 1.5436
Batch 230, Loss: 1.4739
Batch 240, Loss: 1.4911
Batch 250, Loss: 1.5189
Batch 260, Loss: 1.4943
Batch 270, Loss: 1.4885
Batch 280, Loss: 1.4600
Batch 290, Loss: 1.4976
Batch 300, Loss: 1.6008
Batch 310, Loss: 1.5151
Batch 320, Loss: 1.4347
Batch 330, Loss: 1.4623
Batch 340, Loss: 1.5562
Batch 350, Loss: 1.5826
Batch 360, Loss: 1.5041
Batch 370, Loss: 1.5897
Batch 380, Loss: 1.5966
Batch 390, Loss: 1.5164
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.44182300567627 seconds
Epoch 32 accuracy: 51.56%
Batch 10, Loss: 1.4327
Batch 20, Loss: 1.4475
Batch 30, Loss: 1.4244
Batch 40, Loss: 1.5529
Batch 50, Loss: 1.4290
Batch 60, Loss: 1.3937
Batch 70, Loss: 1.5232
Batch 80, Loss: 1.5284
Batch 90, Loss: 1.4850
Batch 100, Loss: 1.4845
Batch 110, Loss: 1.4782
Batch 120, Loss: 1.4290
Batch 130, Loss: 1.4545
Batch 140, Loss: 1.5163
Batch 150, Loss: 1.5178
Batch 160, Loss: 1.4986
Batch 170, Loss: 1.5258
Batch 180, Loss: 1.5152
Batch 190, Loss: 1.5506
Batch 200, Loss: 1.5353
Batch 210, Loss: 1.5071
Batch 220, Loss: 1.5935
Batch 230, Loss: 1.4806
Batch 240, Loss: 1.4721
Batch 250, Loss: 1.5549
Batch 260, Loss: 1.4975
Batch 270, Loss: 1.5037
Batch 280, Loss: 1.4552
Batch 290, Loss: 1.4624
Batch 300, Loss: 1.5247
Batch 310, Loss: 1.5178
Batch 320, Loss: 1.5199
Batch 330, Loss: 1.5549
Batch 340, Loss: 1.4971
Batch 350, Loss: 1.4796
Batch 360, Loss: 1.5377
Batch 370, Loss: 1.4806
Batch 380, Loss: 1.5080
Batch 390, Loss: 1.4703
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.47750687599182 seconds
Epoch 33 accuracy: 57.9%
Batch 10, Loss: 1.5053
Batch 20, Loss: 1.5122
Batch 30, Loss: 1.4567
Batch 40, Loss: 1.4727
Batch 50, Loss: 1.4403
Batch 60, Loss: 1.4657
Batch 70, Loss: 1.4521
Batch 80, Loss: 1.4542
Batch 90, Loss: 1.4667
Batch 100, Loss: 1.4707
Batch 110, Loss: 1.4656
Batch 120, Loss: 1.4727
Batch 130, Loss: 1.5224
Batch 140, Loss: 1.4512
Batch 150, Loss: 1.5474
Batch 160, Loss: 1.5535
Batch 170, Loss: 1.5227
Batch 180, Loss: 1.4859
Batch 190, Loss: 1.4543
Batch 200, Loss: 1.5241
Batch 210, Loss: 1.4804
Batch 220, Loss: 1.5070
Batch 230, Loss: 1.5268
Batch 240, Loss: 1.5622
Batch 250, Loss: 1.4860
Batch 260, Loss: 1.4205
Batch 270, Loss: 1.4937
Batch 280, Loss: 1.4622
Batch 290, Loss: 1.5637
Batch 300, Loss: 1.5737
Batch 310, Loss: 1.4978
Batch 320, Loss: 1.5330
Batch 330, Loss: 1.4817
Batch 340, Loss: 1.5141
Batch 350, Loss: 1.4951
Batch 360, Loss: 1.5171
Batch 370, Loss: 1.4950
Batch 380, Loss: 1.4870
Batch 390, Loss: 1.5007
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.352949619293213 seconds
Epoch 34 accuracy: 54.47%
Batch 10, Loss: 1.4137
Batch 20, Loss: 1.5126
Batch 30, Loss: 1.3804
Batch 40, Loss: 1.5102
Batch 50, Loss: 1.4161
Batch 60, Loss: 1.4541
Batch 70, Loss: 1.5261
Batch 80, Loss: 1.4801
Batch 90, Loss: 1.4458
Batch 100, Loss: 1.4451
Batch 110, Loss: 1.4911
Batch 120, Loss: 1.5463
Batch 130, Loss: 1.4587
Batch 140, Loss: 1.5736
Batch 150, Loss: 1.5140
Batch 160, Loss: 1.5162
Batch 170, Loss: 1.5168
Batch 180, Loss: 1.5196
Batch 190, Loss: 1.4576
Batch 200, Loss: 1.4700
Batch 210, Loss: 1.5186
Batch 220, Loss: 1.4421
Batch 230, Loss: 1.4964
Batch 240, Loss: 1.4817
Batch 250, Loss: 1.4552
Batch 260, Loss: 1.4416
Batch 270, Loss: 1.4734
Batch 280, Loss: 1.4744
Batch 290, Loss: 1.5283
Batch 300, Loss: 1.4959
Batch 310, Loss: 1.4803
Batch 320, Loss: 1.4843
Batch 330, Loss: 1.4638
Batch 340, Loss: 1.4482
Batch 350, Loss: 1.5020
Batch 360, Loss: 1.4717
Batch 370, Loss: 1.5003
Batch 380, Loss: 1.4446
Batch 390, Loss: 1.5170
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.42205834388733 seconds
Epoch 35 accuracy: 55.03%
Batch 10, Loss: 1.4471
Batch 20, Loss: 1.4248
Batch 30, Loss: 1.4440
Batch 40, Loss: 1.4214
Batch 50, Loss: 1.5104
Batch 60, Loss: 1.4647
Batch 70, Loss: 1.4663
Batch 80, Loss: 1.4717
Batch 90, Loss: 1.4348
Batch 100, Loss: 1.4520
Batch 110, Loss: 1.4460
Batch 120, Loss: 1.4623
Batch 130, Loss: 1.4547
Batch 140, Loss: 1.4665
Batch 150, Loss: 1.4681
Batch 160, Loss: 1.4790
Batch 170, Loss: 1.5108
Batch 180, Loss: 1.4946
Batch 190, Loss: 1.4777
Batch 200, Loss: 1.4940
Batch 210, Loss: 1.4949
Batch 220, Loss: 1.5048
Batch 230, Loss: 1.4220
Batch 240, Loss: 1.5165
Batch 250, Loss: 1.4545
Batch 260, Loss: 1.4920
Batch 270, Loss: 1.5106
Batch 280, Loss: 1.5246
Batch 290, Loss: 1.4947
Batch 300, Loss: 1.4456
Batch 310, Loss: 1.5001
Batch 320, Loss: 1.5039
Batch 330, Loss: 1.5175
Batch 340, Loss: 1.4747
Batch 350, Loss: 1.5231
Batch 360, Loss: 1.5381
Batch 370, Loss: 1.4624
Batch 380, Loss: 1.4722
Batch 390, Loss: 1.4954
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.329014778137207 seconds
Epoch 36 accuracy: 54.96%
Batch 10, Loss: 1.4661
Batch 20, Loss: 1.4368
Batch 30, Loss: 1.4075
Batch 40, Loss: 1.4480
Batch 50, Loss: 1.4913
Batch 60, Loss: 1.4133
Batch 70, Loss: 1.4487
Batch 80, Loss: 1.4674
Batch 90, Loss: 1.4626
Batch 100, Loss: 1.4395
Batch 110, Loss: 1.4213
Batch 120, Loss: 1.4836
Batch 130, Loss: 1.4227
Batch 140, Loss: 1.5071
Batch 150, Loss: 1.4571
Batch 160, Loss: 1.4132
Batch 170, Loss: 1.4354
Batch 180, Loss: 1.4707
Batch 190, Loss: 1.4180
Batch 200, Loss: 1.4840
Batch 210, Loss: 1.4679
Batch 220, Loss: 1.4907
Batch 230, Loss: 1.4741
Batch 240, Loss: 1.4483
Batch 250, Loss: 1.4968
Batch 260, Loss: 1.4952
Batch 270, Loss: 1.4689
Batch 280, Loss: 1.4175
Batch 290, Loss: 1.4592
Batch 300, Loss: 1.5565
Batch 310, Loss: 1.4286
Batch 320, Loss: 1.5372
Batch 330, Loss: 1.4871
Batch 340, Loss: 1.5756
Batch 350, Loss: 1.4718
Batch 360, Loss: 1.5550
Batch 370, Loss: 1.5186
Batch 380, Loss: 1.5628
Batch 390, Loss: 1.4845
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.355117559432983 seconds
Epoch 37 accuracy: 56.1%
Batch 10, Loss: 1.4333
Batch 20, Loss: 1.3909
Batch 30, Loss: 1.4402
Batch 40, Loss: 1.3480
Batch 50, Loss: 1.4084
Batch 60, Loss: 1.3981
Batch 70, Loss: 1.4073
Batch 80, Loss: 1.4819
Batch 90, Loss: 1.4797
Batch 100, Loss: 1.4120
Batch 110, Loss: 1.4357
Batch 120, Loss: 1.4562
Batch 130, Loss: 1.4489
Batch 140, Loss: 1.4204
Batch 150, Loss: 1.5170
Batch 160, Loss: 1.4016
Batch 170, Loss: 1.3833
Batch 180, Loss: 1.4690
Batch 190, Loss: 1.4591
Batch 200, Loss: 1.4975
Batch 210, Loss: 1.4584
Batch 220, Loss: 1.5554
Batch 230, Loss: 1.4753
Batch 240, Loss: 1.5152
Batch 250, Loss: 1.4574
Batch 260, Loss: 1.4316
Batch 270, Loss: 1.4784
Batch 280, Loss: 1.4451
Batch 290, Loss: 1.4352
Batch 300, Loss: 1.4720
Batch 310, Loss: 1.4302
Batch 320, Loss: 1.5433
Batch 330, Loss: 1.3887
Batch 340, Loss: 1.5208
Batch 350, Loss: 1.5410
Batch 360, Loss: 1.4329
Batch 370, Loss: 1.4745
Batch 380, Loss: 1.5024
Batch 390, Loss: 1.4954
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.41631293296814 seconds
Epoch 38 accuracy: 58.85%
Batch 10, Loss: 1.4143
Batch 20, Loss: 1.3668
Batch 30, Loss: 1.3794
Batch 40, Loss: 1.4207
Batch 50, Loss: 1.4306
Batch 60, Loss: 1.3896
Batch 70, Loss: 1.4731
Batch 80, Loss: 1.4864
Batch 90, Loss: 1.4184
Batch 100, Loss: 1.4611
Batch 110, Loss: 1.4895
Batch 120, Loss: 1.3949
Batch 130, Loss: 1.4601
Batch 140, Loss: 1.4898
Batch 150, Loss: 1.4902
Batch 160, Loss: 1.5397
Batch 170, Loss: 1.4132
Batch 180, Loss: 1.4321
Batch 190, Loss: 1.4144
Batch 200, Loss: 1.4393
Batch 210, Loss: 1.4124
Batch 220, Loss: 1.4935
Batch 230, Loss: 1.4931
Batch 240, Loss: 1.5361
Batch 250, Loss: 1.4877
Batch 260, Loss: 1.4444
Batch 270, Loss: 1.4891
Batch 280, Loss: 1.5438
Batch 290, Loss: 1.4340
Batch 300, Loss: 1.4550
Batch 310, Loss: 1.4384
Batch 320, Loss: 1.4868
Batch 330, Loss: 1.4942
Batch 340, Loss: 1.4915
Batch 350, Loss: 1.4614
Batch 360, Loss: 1.4986
Batch 370, Loss: 1.4413
Batch 380, Loss: 1.5017
Batch 390, Loss: 1.5064
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.319575548171997 seconds
Epoch 39 accuracy: 57.62%
Batch 10, Loss: 1.3587
Batch 20, Loss: 1.4133
Batch 30, Loss: 1.4051
Batch 40, Loss: 1.3995
Batch 50, Loss: 1.4232
Batch 60, Loss: 1.4139
Batch 70, Loss: 1.4530
Batch 80, Loss: 1.4093
Batch 90, Loss: 1.4646
Batch 100, Loss: 1.4950
Batch 110, Loss: 1.4809
Batch 120, Loss: 1.3992
Batch 130, Loss: 1.4719
Batch 140, Loss: 1.3887
Batch 150, Loss: 1.4552
Batch 160, Loss: 1.4596
Batch 170, Loss: 1.4830
Batch 180, Loss: 1.4824
Batch 190, Loss: 1.4076
Batch 200, Loss: 1.3469
Batch 210, Loss: 1.4756
Batch 220, Loss: 1.5047
Batch 230, Loss: 1.5229
Batch 240, Loss: 1.4658
Batch 250, Loss: 1.4514
Batch 260, Loss: 1.4729
Batch 270, Loss: 1.5148
Batch 280, Loss: 1.4445
Batch 290, Loss: 1.4265
Batch 300, Loss: 1.4940
Batch 310, Loss: 1.5091
Batch 320, Loss: 1.4925
Batch 330, Loss: 1.4869
Batch 340, Loss: 1.4779
Batch 350, Loss: 1.4765
Batch 360, Loss: 1.5646
Batch 370, Loss: 1.4965
Batch 380, Loss: 1.4868
Batch 390, Loss: 1.5487
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.326256036758423 seconds
Epoch 40 accuracy: 56.71%
Batch 10, Loss: 1.4790
Batch 20, Loss: 1.3648
Batch 30, Loss: 1.4459
Batch 40, Loss: 1.4145
Batch 50, Loss: 1.4612
Batch 60, Loss: 1.4443
Batch 70, Loss: 1.4443
Batch 80, Loss: 1.4170
Batch 90, Loss: 1.4479
Batch 100, Loss: 1.4334
Batch 110, Loss: 1.4498
Batch 120, Loss: 1.4199
Batch 130, Loss: 1.4569
Batch 140, Loss: 1.4452
Batch 150, Loss: 1.4226
Batch 160, Loss: 1.3872
Batch 170, Loss: 1.4039
Batch 180, Loss: 1.4054
Batch 190, Loss: 1.4180
Batch 200, Loss: 1.4763
Batch 210, Loss: 1.4625
Batch 220, Loss: 1.4105
Batch 230, Loss: 1.4717
Batch 240, Loss: 1.4744
Batch 250, Loss: 1.5219
Batch 260, Loss: 1.4776
Batch 270, Loss: 1.4515
Batch 280, Loss: 1.4546
Batch 290, Loss: 1.4256
Batch 300, Loss: 1.4350
Batch 310, Loss: 1.5142
Batch 320, Loss: 1.4933
Batch 330, Loss: 1.4611
Batch 340, Loss: 1.4686
Batch 350, Loss: 1.4690
Batch 360, Loss: 1.3939
Batch 370, Loss: 1.4088
Batch 380, Loss: 1.4646
Batch 390, Loss: 1.4051
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.430482387542725 seconds
Epoch 41 accuracy: 55.29%
Batch 10, Loss: 1.4421
Batch 20, Loss: 1.3992
Batch 30, Loss: 1.3746
Batch 40, Loss: 1.4171
Batch 50, Loss: 1.3932
Batch 60, Loss: 1.4066
Batch 70, Loss: 1.4297
Batch 80, Loss: 1.3286
Batch 90, Loss: 1.4091
Batch 100, Loss: 1.4339
Batch 110, Loss: 1.4175
Batch 120, Loss: 1.4473
Batch 130, Loss: 1.4294
Batch 140, Loss: 1.4164
Batch 150, Loss: 1.4156
Batch 160, Loss: 1.5020
Batch 170, Loss: 1.4429
Batch 180, Loss: 1.4471
Batch 190, Loss: 1.4620
Batch 200, Loss: 1.4789
Batch 210, Loss: 1.4488
Batch 220, Loss: 1.4103
Batch 230, Loss: 1.4916
Batch 240, Loss: 1.4945
Batch 250, Loss: 1.5569
Batch 260, Loss: 1.4782
Batch 270, Loss: 1.4824
Batch 280, Loss: 1.4773
Batch 290, Loss: 1.3970
Batch 300, Loss: 1.4699
Batch 310, Loss: 1.4961
Batch 320, Loss: 1.4816
Batch 330, Loss: 1.4403
Batch 340, Loss: 1.3902
Batch 350, Loss: 1.4051
Batch 360, Loss: 1.4856
Batch 370, Loss: 1.4818
Batch 380, Loss: 1.4575
Batch 390, Loss: 1.5279
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.415626287460327 seconds
Epoch 42 accuracy: 55.87%
Batch 10, Loss: 1.3563
Batch 20, Loss: 1.4306
Batch 30, Loss: 1.3571
Batch 40, Loss: 1.4257
Batch 50, Loss: 1.4334
Batch 60, Loss: 1.3611
Batch 70, Loss: 1.4998
Batch 80, Loss: 1.4670
Batch 90, Loss: 1.5111
Batch 100, Loss: 1.4187
Batch 110, Loss: 1.3207
Batch 120, Loss: 1.3956
Batch 130, Loss: 1.4094
Batch 140, Loss: 1.3883
Batch 150, Loss: 1.4247
Batch 160, Loss: 1.4298
Batch 170, Loss: 1.4503
Batch 180, Loss: 1.3703
Batch 190, Loss: 1.4547
Batch 200, Loss: 1.4091
Batch 210, Loss: 1.3928
Batch 220, Loss: 1.3854
Batch 230, Loss: 1.4426
Batch 240, Loss: 1.4369
Batch 250, Loss: 1.4801
Batch 260, Loss: 1.4617
Batch 270, Loss: 1.3851
Batch 280, Loss: 1.4684
Batch 290, Loss: 1.4845
Batch 300, Loss: 1.4868
Batch 310, Loss: 1.4519
Batch 320, Loss: 1.4560
Batch 330, Loss: 1.4733
Batch 340, Loss: 1.4089
Batch 350, Loss: 1.4628
Batch 360, Loss: 1.4717
Batch 370, Loss: 1.4490
Batch 380, Loss: 1.4693
Batch 390, Loss: 1.4592
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.269001722335815 seconds
Epoch 43 accuracy: 55.7%
Batch 10, Loss: 1.3611
Batch 20, Loss: 1.3862
Batch 30, Loss: 1.3302
Batch 40, Loss: 1.3435
Batch 50, Loss: 1.3784
Batch 60, Loss: 1.4278
Batch 70, Loss: 1.4324
Batch 80, Loss: 1.4145
Batch 90, Loss: 1.4180
Batch 100, Loss: 1.4307
Batch 110, Loss: 1.4299
Batch 120, Loss: 1.3763
Batch 130, Loss: 1.4232
Batch 140, Loss: 1.4404
Batch 150, Loss: 1.4206
Batch 160, Loss: 1.4571
Batch 170, Loss: 1.4056
Batch 180, Loss: 1.3985
Batch 190, Loss: 1.4120
Batch 200, Loss: 1.4697
Batch 210, Loss: 1.4606
Batch 220, Loss: 1.4046
Batch 230, Loss: 1.4334
Batch 240, Loss: 1.4415
Batch 250, Loss: 1.3777
Batch 260, Loss: 1.4266
Batch 270, Loss: 1.4225
Batch 280, Loss: 1.3839
Batch 290, Loss: 1.3930
Batch 300, Loss: 1.4026
Batch 310, Loss: 1.4547
Batch 320, Loss: 1.4502
Batch 330, Loss: 1.5155
Batch 340, Loss: 1.4723
Batch 350, Loss: 1.5077
Batch 360, Loss: 1.4631
Batch 370, Loss: 1.4553
Batch 380, Loss: 1.4267
Batch 390, Loss: 1.4835
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.35155177116394 seconds
Epoch 44 accuracy: 55.56%
Batch 10, Loss: 1.4499
Batch 20, Loss: 1.3290
Batch 30, Loss: 1.4452
Batch 40, Loss: 1.3855
Batch 50, Loss: 1.3643
Batch 60, Loss: 1.4324
Batch 70, Loss: 1.4106
Batch 80, Loss: 1.4325
Batch 90, Loss: 1.4449
Batch 100, Loss: 1.4699
Batch 110, Loss: 1.4241
Batch 120, Loss: 1.3446
Batch 130, Loss: 1.4418
Batch 140, Loss: 1.3886
Batch 150, Loss: 1.4169
Batch 160, Loss: 1.4165
Batch 170, Loss: 1.4457
Batch 180, Loss: 1.4319
Batch 190, Loss: 1.3625
Batch 200, Loss: 1.3703
Batch 210, Loss: 1.4554
Batch 220, Loss: 1.4557
Batch 230, Loss: 1.4877
Batch 240, Loss: 1.4781
Batch 250, Loss: 1.4477
Batch 260, Loss: 1.4651
Batch 270, Loss: 1.4393
Batch 280, Loss: 1.3662
Batch 290, Loss: 1.4677
Batch 300, Loss: 1.3971
Batch 310, Loss: 1.5096
Batch 320, Loss: 1.4495
Batch 330, Loss: 1.3734
Batch 340, Loss: 1.4431
Batch 350, Loss: 1.4718
Batch 360, Loss: 1.4582
Batch 370, Loss: 1.4348
Batch 380, Loss: 1.4273
Batch 390, Loss: 1.4935
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.327037811279297 seconds
Epoch 45 accuracy: 56.86%
Batch 10, Loss: 1.3546
Batch 20, Loss: 1.4221
Batch 30, Loss: 1.3064
Batch 40, Loss: 1.3825
Batch 50, Loss: 1.3594
Batch 60, Loss: 1.4266
Batch 70, Loss: 1.4097
Batch 80, Loss: 1.4360
Batch 90, Loss: 1.3332
Batch 100, Loss: 1.4009
Batch 110, Loss: 1.3877
Batch 120, Loss: 1.4416
Batch 130, Loss: 1.4439
Batch 140, Loss: 1.4692
Batch 150, Loss: 1.3176
Batch 160, Loss: 1.4597
Batch 170, Loss: 1.4192
Batch 180, Loss: 1.4164
Batch 190, Loss: 1.4620
Batch 200, Loss: 1.3711
Batch 210, Loss: 1.4706
Batch 220, Loss: 1.4562
Batch 230, Loss: 1.4723
Batch 240, Loss: 1.4349
Batch 250, Loss: 1.4844
Batch 260, Loss: 1.4847
Batch 270, Loss: 1.4031
Batch 280, Loss: 1.4533
Batch 290, Loss: 1.4337
Batch 300, Loss: 1.4252
Batch 310, Loss: 1.4760
Batch 320, Loss: 1.4770
Batch 330, Loss: 1.3937
Batch 340, Loss: 1.4081
Batch 350, Loss: 1.4205
Batch 360, Loss: 1.4382
Batch 370, Loss: 1.4391
Batch 380, Loss: 1.5108
Batch 390, Loss: 1.4343
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.398019313812256 seconds
Epoch 46 accuracy: 55.64%
Batch 10, Loss: 1.3175
Batch 20, Loss: 1.3974
Batch 30, Loss: 1.3534
Batch 40, Loss: 1.3948
Batch 50, Loss: 1.3903
Batch 60, Loss: 1.4559
Batch 70, Loss: 1.4174
Batch 80, Loss: 1.3663
Batch 90, Loss: 1.3789
Batch 100, Loss: 1.4470
Batch 110, Loss: 1.4163
Batch 120, Loss: 1.4669
Batch 130, Loss: 1.3672
Batch 140, Loss: 1.3893
Batch 150, Loss: 1.3927
Batch 160, Loss: 1.4141
Batch 170, Loss: 1.3942
Batch 180, Loss: 1.4794
Batch 190, Loss: 1.4059
Batch 200, Loss: 1.4810
Batch 210, Loss: 1.3868
Batch 220, Loss: 1.3763
Batch 230, Loss: 1.4404
Batch 240, Loss: 1.4491
Batch 250, Loss: 1.4271
Batch 260, Loss: 1.3847
Batch 270, Loss: 1.4250
Batch 280, Loss: 1.4020
Batch 290, Loss: 1.3956
Batch 300, Loss: 1.3631
Batch 310, Loss: 1.4629
Batch 320, Loss: 1.4335
Batch 330, Loss: 1.4570
Batch 340, Loss: 1.4168
Batch 350, Loss: 1.4436
Batch 360, Loss: 1.4106
Batch 370, Loss: 1.4153
Batch 380, Loss: 1.4343
Batch 390, Loss: 1.4204
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.283106327056885 seconds
Epoch 47 accuracy: 56.4%
Batch 10, Loss: 1.3322
Batch 20, Loss: 1.3560
Batch 30, Loss: 1.4553
Batch 40, Loss: 1.3422
Batch 50, Loss: 1.3574
Batch 60, Loss: 1.4028
Batch 70, Loss: 1.3443
Batch 80, Loss: 1.4531
Batch 90, Loss: 1.3764
Batch 100, Loss: 1.4278
Batch 110, Loss: 1.4463
Batch 120, Loss: 1.3612
Batch 130, Loss: 1.4013
Batch 140, Loss: 1.3917
Batch 150, Loss: 1.4583
Batch 160, Loss: 1.4307
Batch 170, Loss: 1.4192
Batch 180, Loss: 1.3702
Batch 190, Loss: 1.4421
Batch 200, Loss: 1.3873
Batch 210, Loss: 1.3691
Batch 220, Loss: 1.3930
Batch 230, Loss: 1.4328
Batch 240, Loss: 1.4459
Batch 250, Loss: 1.4740
Batch 260, Loss: 1.4284
Batch 270, Loss: 1.4612
Batch 280, Loss: 1.4303
Batch 290, Loss: 1.4119
Batch 300, Loss: 1.5143
Batch 310, Loss: 1.4333
Batch 320, Loss: 1.4179
Batch 330, Loss: 1.3863
Batch 340, Loss: 1.4640
Batch 350, Loss: 1.4375
Batch 360, Loss: 1.4362
Batch 370, Loss: 1.3992
Batch 380, Loss: 1.3805
Batch 390, Loss: 1.3752
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.32920813560486 seconds
Epoch 48 accuracy: 58.35%
Batch 10, Loss: 1.3062
Batch 20, Loss: 1.4239
Batch 30, Loss: 1.3724
Batch 40, Loss: 1.3749
Batch 50, Loss: 1.3486
Batch 60, Loss: 1.4201
Batch 70, Loss: 1.3930
Batch 80, Loss: 1.3306
Batch 90, Loss: 1.3630
Batch 100, Loss: 1.4128
Batch 110, Loss: 1.3166
Batch 120, Loss: 1.4214
Batch 130, Loss: 1.4833
Batch 140, Loss: 1.3830
Batch 150, Loss: 1.4018
Batch 160, Loss: 1.4303
Batch 170, Loss: 1.2871
Batch 180, Loss: 1.4018
Batch 190, Loss: 1.4605
Batch 200, Loss: 1.4115
Batch 210, Loss: 1.4532
Batch 220, Loss: 1.4890
Batch 230, Loss: 1.3822
Batch 240, Loss: 1.3443
Batch 250, Loss: 1.4089
Batch 260, Loss: 1.4103
Batch 270, Loss: 1.3323
Batch 280, Loss: 1.4183
Batch 290, Loss: 1.4420
Batch 300, Loss: 1.4547
Batch 310, Loss: 1.4620
Batch 320, Loss: 1.4653
Batch 330, Loss: 1.4070
Batch 340, Loss: 1.3795
Batch 350, Loss: 1.4750
Batch 360, Loss: 1.4197
Batch 370, Loss: 1.4148
Batch 380, Loss: 1.4415
Batch 390, Loss: 1.4232
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.333365201950073 seconds
Epoch 49 accuracy: 57.75%
Batch 10, Loss: 1.3404
Batch 20, Loss: 1.4107
Batch 30, Loss: 1.2978
Batch 40, Loss: 1.4283
Batch 50, Loss: 1.3717
Batch 60, Loss: 1.3103
Batch 70, Loss: 1.3935
Batch 80, Loss: 1.3835
Batch 90, Loss: 1.3895
Batch 100, Loss: 1.4173
Batch 110, Loss: 1.3480
Batch 120, Loss: 1.3616
Batch 130, Loss: 1.3717
Batch 140, Loss: 1.3591
Batch 150, Loss: 1.3538
Batch 160, Loss: 1.4279
Batch 170, Loss: 1.3646
Batch 180, Loss: 1.3621
Batch 190, Loss: 1.4046
Batch 200, Loss: 1.4275
Batch 210, Loss: 1.4254
Batch 220, Loss: 1.3313
Batch 230, Loss: 1.4217
Batch 240, Loss: 1.3232
Batch 250, Loss: 1.3844
Batch 260, Loss: 1.3590
Batch 270, Loss: 1.4094
Batch 280, Loss: 1.4559
Batch 290, Loss: 1.3792
Batch 300, Loss: 1.4194
Batch 310, Loss: 1.4306
Batch 320, Loss: 1.3908
Batch 330, Loss: 1.4708
Batch 340, Loss: 1.4230
Batch 350, Loss: 1.3653
Batch 360, Loss: 1.3561
Batch 370, Loss: 1.3782
Batch 380, Loss: 1.4096
Batch 390, Loss: 1.4474
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.485005855560303 seconds
Epoch 50 accuracy: 59.71%
Batch 10, Loss: 1.4329
Batch 20, Loss: 1.3550
Batch 30, Loss: 1.4037
Batch 40, Loss: 1.3298
Batch 50, Loss: 1.3598
Batch 60, Loss: 1.3599
Batch 70, Loss: 1.3610
Batch 80, Loss: 1.3786
Batch 90, Loss: 1.3715
Batch 100, Loss: 1.4224
Batch 110, Loss: 1.4088
Batch 120, Loss: 1.3750
Batch 130, Loss: 1.3211
Batch 140, Loss: 1.3028
Batch 150, Loss: 1.3800
Batch 160, Loss: 1.3595
Batch 170, Loss: 1.3606
Batch 180, Loss: 1.4097
Batch 190, Loss: 1.3822
Batch 200, Loss: 1.3423
Batch 210, Loss: 1.4568
Batch 220, Loss: 1.4214
Batch 230, Loss: 1.4411
Batch 240, Loss: 1.4112
Batch 250, Loss: 1.3518
Batch 260, Loss: 1.4481
Batch 270, Loss: 1.4102
Batch 280, Loss: 1.3791
Batch 290, Loss: 1.4509
Batch 300, Loss: 1.3675
Batch 310, Loss: 1.4445
Batch 320, Loss: 1.4172
Batch 330, Loss: 1.4164
Batch 340, Loss: 1.4290
Batch 350, Loss: 1.3984
Batch 360, Loss: 1.4209
Batch 370, Loss: 1.4164
Batch 380, Loss: 1.3480
Batch 390, Loss: 1.4511
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.40801191329956 seconds
Epoch 51 accuracy: 58.52%
Batch 10, Loss: 1.3894
Batch 20, Loss: 1.3352
Batch 30, Loss: 1.3186
Batch 40, Loss: 1.3099
Batch 50, Loss: 1.3712
Batch 60, Loss: 1.3008
Batch 70, Loss: 1.3097
Batch 80, Loss: 1.4022
Batch 90, Loss: 1.3739
Batch 100, Loss: 1.3509
Batch 110, Loss: 1.3311
Batch 120, Loss: 1.4428
Batch 130, Loss: 1.4183
Batch 140, Loss: 1.4309
Batch 150, Loss: 1.4213
Batch 160, Loss: 1.3506
Batch 170, Loss: 1.3755
Batch 180, Loss: 1.3828
Batch 190, Loss: 1.4055
Batch 200, Loss: 1.3794
Batch 210, Loss: 1.3730
Batch 220, Loss: 1.3668
Batch 230, Loss: 1.4150
Batch 240, Loss: 1.3620
Batch 250, Loss: 1.4972
Batch 260, Loss: 1.4078
Batch 270, Loss: 1.4060
Batch 280, Loss: 1.3598
Batch 290, Loss: 1.3741
Batch 300, Loss: 1.4340
Batch 310, Loss: 1.4533
Batch 320, Loss: 1.4043
Batch 330, Loss: 1.4205
Batch 340, Loss: 1.3908
Batch 350, Loss: 1.3852
Batch 360, Loss: 1.3736
Batch 370, Loss: 1.3820
Batch 380, Loss: 1.4067
Batch 390, Loss: 1.3927
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.395781993865967 seconds
Epoch 52 accuracy: 58.37%
Batch 10, Loss: 1.3641
Batch 20, Loss: 1.3373
Batch 30, Loss: 1.3131
Batch 40, Loss: 1.3515
Batch 50, Loss: 1.3385
Batch 60, Loss: 1.3671
Batch 70, Loss: 1.3438
Batch 80, Loss: 1.3471
Batch 90, Loss: 1.3773
Batch 100, Loss: 1.3392
Batch 110, Loss: 1.3183
Batch 120, Loss: 1.3916
Batch 130, Loss: 1.3924
Batch 140, Loss: 1.3985
Batch 150, Loss: 1.3538
Batch 160, Loss: 1.3818
Batch 170, Loss: 1.3943
Batch 180, Loss: 1.3738
Batch 190, Loss: 1.3450
Batch 200, Loss: 1.3706
Batch 210, Loss: 1.3777
Batch 220, Loss: 1.4426
Batch 230, Loss: 1.4082
Batch 240, Loss: 1.4164
Batch 250, Loss: 1.3754
Batch 260, Loss: 1.3672
Batch 270, Loss: 1.4388
Batch 280, Loss: 1.3550
Batch 290, Loss: 1.3690
Batch 300, Loss: 1.4440
Batch 310, Loss: 1.4415
Batch 320, Loss: 1.3456
Batch 330, Loss: 1.4554
Batch 340, Loss: 1.4357
Batch 350, Loss: 1.4262
Batch 360, Loss: 1.4758
Batch 370, Loss: 1.4975
Batch 380, Loss: 1.3476
Batch 390, Loss: 1.4475
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.24938464164734 seconds
Epoch 53 accuracy: 59.84%
Batch 10, Loss: 1.3645
Batch 20, Loss: 1.3098
Batch 30, Loss: 1.3489
Batch 40, Loss: 1.2649
Batch 50, Loss: 1.3969
Batch 60, Loss: 1.3680
Batch 70, Loss: 1.3859
Batch 80, Loss: 1.3390
Batch 90, Loss: 1.3533
Batch 100, Loss: 1.3472
Batch 110, Loss: 1.3850
Batch 120, Loss: 1.3604
Batch 130, Loss: 1.3525
Batch 140, Loss: 1.3799
Batch 150, Loss: 1.4005
Batch 160, Loss: 1.3453
Batch 170, Loss: 1.2978
Batch 180, Loss: 1.3672
Batch 190, Loss: 1.3377
Batch 200, Loss: 1.3506
Batch 210, Loss: 1.4110
Batch 220, Loss: 1.3641
Batch 230, Loss: 1.4423
Batch 240, Loss: 1.3753
Batch 250, Loss: 1.4101
Batch 260, Loss: 1.3453
Batch 270, Loss: 1.3940
Batch 280, Loss: 1.3761
Batch 290, Loss: 1.3968
Batch 300, Loss: 1.4077
Batch 310, Loss: 1.4073
Batch 320, Loss: 1.4121
Batch 330, Loss: 1.4093
Batch 340, Loss: 1.3973
Batch 350, Loss: 1.4117
Batch 360, Loss: 1.4170
Batch 370, Loss: 1.3761
Batch 380, Loss: 1.3491
Batch 390, Loss: 1.3802
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.325631856918335 seconds
Epoch 54 accuracy: 58.22%
Batch 10, Loss: 1.3733
Batch 20, Loss: 1.3032
Batch 30, Loss: 1.3439
Batch 40, Loss: 1.3441
Batch 50, Loss: 1.3953
Batch 60, Loss: 1.3344
Batch 70, Loss: 1.3400
Batch 80, Loss: 1.3610
Batch 90, Loss: 1.3914
Batch 100, Loss: 1.4420
Batch 110, Loss: 1.3852
Batch 120, Loss: 1.4271
Batch 130, Loss: 1.4262
Batch 140, Loss: 1.3663
Batch 150, Loss: 1.3701
Batch 160, Loss: 1.3978
Batch 170, Loss: 1.3546
Batch 180, Loss: 1.3775
Batch 190, Loss: 1.3769
Batch 200, Loss: 1.3601
Batch 210, Loss: 1.4494
Batch 220, Loss: 1.3481
Batch 230, Loss: 1.2976
Batch 240, Loss: 1.4359
Batch 250, Loss: 1.3584
Batch 260, Loss: 1.3421
Batch 270, Loss: 1.3246
Batch 280, Loss: 1.3793
Batch 290, Loss: 1.3314
Batch 300, Loss: 1.3384
Batch 310, Loss: 1.3538
Batch 320, Loss: 1.3360
Batch 330, Loss: 1.3902
Batch 340, Loss: 1.3500
Batch 350, Loss: 1.4663
Batch 360, Loss: 1.4131
Batch 370, Loss: 1.3732
Batch 380, Loss: 1.3528
Batch 390, Loss: 1.3849
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.352649211883545 seconds
Epoch 55 accuracy: 58.46%
Batch 10, Loss: 1.3454
Batch 20, Loss: 1.3169
Batch 30, Loss: 1.3512
Batch 40, Loss: 1.3362
Batch 50, Loss: 1.3754
Batch 60, Loss: 1.3650
Batch 70, Loss: 1.2873
Batch 80, Loss: 1.3350
Batch 90, Loss: 1.3675
Batch 100, Loss: 1.3409
Batch 110, Loss: 1.3431
Batch 120, Loss: 1.3227
Batch 130, Loss: 1.3669
Batch 140, Loss: 1.3795
Batch 150, Loss: 1.3408
Batch 160, Loss: 1.3525
Batch 170, Loss: 1.3541
Batch 180, Loss: 1.3504
Batch 190, Loss: 1.4326
Batch 200, Loss: 1.3641
Batch 210, Loss: 1.3575
Batch 220, Loss: 1.3599
Batch 230, Loss: 1.3088
Batch 240, Loss: 1.3186
Batch 250, Loss: 1.3302
Batch 260, Loss: 1.4011
Batch 270, Loss: 1.4057
Batch 280, Loss: 1.3870
Batch 290, Loss: 1.3492
Batch 300, Loss: 1.3376
Batch 310, Loss: 1.4172
Batch 320, Loss: 1.4355
Batch 330, Loss: 1.3743
Batch 340, Loss: 1.4222
Batch 350, Loss: 1.3020
Batch 360, Loss: 1.4267
Batch 370, Loss: 1.4714
Batch 380, Loss: 1.4247
Batch 390, Loss: 1.3716
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.351256608963013 seconds
Epoch 56 accuracy: 60.06%
Batch 10, Loss: 1.2669
Batch 20, Loss: 1.2701
Batch 30, Loss: 1.3066
Batch 40, Loss: 1.3091
Batch 50, Loss: 1.3802
Batch 60, Loss: 1.3279
Batch 70, Loss: 1.3331
Batch 80, Loss: 1.3399
Batch 90, Loss: 1.2908
Batch 100, Loss: 1.3561
Batch 110, Loss: 1.2930
Batch 120, Loss: 1.4057
Batch 130, Loss: 1.2640
Batch 140, Loss: 1.3282
Batch 150, Loss: 1.3897
Batch 160, Loss: 1.3856
Batch 170, Loss: 1.3607
Batch 180, Loss: 1.3318
Batch 190, Loss: 1.2878
Batch 200, Loss: 1.4267
Batch 210, Loss: 1.3910
Batch 220, Loss: 1.3806
Batch 230, Loss: 1.3409
Batch 240, Loss: 1.4103
Batch 250, Loss: 1.5015
Batch 260, Loss: 1.3924
Batch 270, Loss: 1.3767
Batch 280, Loss: 1.3915
Batch 290, Loss: 1.3662
Batch 300, Loss: 1.3489
Batch 310, Loss: 1.3689
Batch 320, Loss: 1.4777
Batch 330, Loss: 1.3545
Batch 340, Loss: 1.4432
Batch 350, Loss: 1.3937
Batch 360, Loss: 1.3603
Batch 370, Loss: 1.4159
Batch 380, Loss: 1.3559
Batch 390, Loss: 1.3753
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.2928307056427 seconds
Epoch 57 accuracy: 59.11%
Batch 10, Loss: 1.3209
Batch 20, Loss: 1.3146
Batch 30, Loss: 1.3159
Batch 40, Loss: 1.3606
Batch 50, Loss: 1.3231
Batch 60, Loss: 1.3407
Batch 70, Loss: 1.3231
Batch 80, Loss: 1.3076
Batch 90, Loss: 1.3237
Batch 100, Loss: 1.3788
Batch 110, Loss: 1.2931
Batch 120, Loss: 1.4263
Batch 130, Loss: 1.3831
Batch 140, Loss: 1.3663
Batch 150, Loss: 1.3254
Batch 160, Loss: 1.4277
Batch 170, Loss: 1.2710
Batch 180, Loss: 1.3901
Batch 190, Loss: 1.3691
Batch 200, Loss: 1.2664
Batch 210, Loss: 1.3594
Batch 220, Loss: 1.3560
Batch 230, Loss: 1.3070
Batch 240, Loss: 1.3308
Batch 250, Loss: 1.3405
Batch 260, Loss: 1.2982
Batch 270, Loss: 1.4001
Batch 280, Loss: 1.3439
Batch 290, Loss: 1.4389
Batch 300, Loss: 1.3430
Batch 310, Loss: 1.3846
Batch 320, Loss: 1.3853
Batch 330, Loss: 1.4070
Batch 340, Loss: 1.4430
Batch 350, Loss: 1.3925
Batch 360, Loss: 1.3213
Batch 370, Loss: 1.3961
Batch 380, Loss: 1.3731
Batch 390, Loss: 1.4186
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.257622480392456 seconds
Epoch 58 accuracy: 60.08%
Batch 10, Loss: 1.2983
Batch 20, Loss: 1.3301
Batch 30, Loss: 1.3074
Batch 40, Loss: 1.3399
Batch 50, Loss: 1.3268
Batch 60, Loss: 1.3030
Batch 70, Loss: 1.3076
Batch 80, Loss: 1.3187
Batch 90, Loss: 1.2793
Batch 100, Loss: 1.4136
Batch 110, Loss: 1.3165
Batch 120, Loss: 1.3298
Batch 130, Loss: 1.3488
Batch 140, Loss: 1.3832
Batch 150, Loss: 1.3015
Batch 160, Loss: 1.3342
Batch 170, Loss: 1.3334
Batch 180, Loss: 1.3852
Batch 190, Loss: 1.3763
Batch 200, Loss: 1.4045
Batch 210, Loss: 1.2837
Batch 220, Loss: 1.3559
Batch 230, Loss: 1.4075
Batch 240, Loss: 1.3038
Batch 250, Loss: 1.4590
Batch 260, Loss: 1.2965
Batch 270, Loss: 1.4087
Batch 280, Loss: 1.3107
Batch 290, Loss: 1.4167
Batch 300, Loss: 1.3507
Batch 310, Loss: 1.3611
Batch 320, Loss: 1.3686
Batch 330, Loss: 1.3543
Batch 340, Loss: 1.4161
Batch 350, Loss: 1.3100
Batch 360, Loss: 1.3809
Batch 370, Loss: 1.3303
Batch 380, Loss: 1.4074
Batch 390, Loss: 1.3556
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.20337176322937 seconds
Epoch 59 accuracy: 60.09%
Batch 10, Loss: 1.2803
Batch 20, Loss: 1.3034
Batch 30, Loss: 1.2909
Batch 40, Loss: 1.2305
Batch 50, Loss: 1.2630
Batch 60, Loss: 1.2677
Batch 70, Loss: 1.3345
Batch 80, Loss: 1.3038
Batch 90, Loss: 1.3501
Batch 100, Loss: 1.3656
Batch 110, Loss: 1.3710
Batch 120, Loss: 1.3423
Batch 130, Loss: 1.2971
Batch 140, Loss: 1.3381
Batch 150, Loss: 1.3547
Batch 160, Loss: 1.3456
Batch 170, Loss: 1.3854
Batch 180, Loss: 1.3263
Batch 190, Loss: 1.4065
Batch 200, Loss: 1.3822
Batch 210, Loss: 1.3535
Batch 220, Loss: 1.4333
Batch 230, Loss: 1.3637
Batch 240, Loss: 1.3682
Batch 250, Loss: 1.3743
Batch 260, Loss: 1.3674
Batch 270, Loss: 1.2949
Batch 280, Loss: 1.3423
Batch 290, Loss: 1.3982
Batch 300, Loss: 1.3306
Batch 310, Loss: 1.3835
Batch 320, Loss: 1.3924
Batch 330, Loss: 1.3532
Batch 340, Loss: 1.3305
Batch 350, Loss: 1.3295
Batch 360, Loss: 1.3977
Batch 370, Loss: 1.4253
Batch 380, Loss: 1.3552
Batch 390, Loss: 1.2761
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.211861610412598 seconds
Epoch 60 accuracy: 59.46%
Batch 10, Loss: 1.3370
Batch 20, Loss: 1.2775
Batch 30, Loss: 1.2888
Batch 40, Loss: 1.3085
Batch 50, Loss: 1.3023
Batch 60, Loss: 1.2667
Batch 70, Loss: 1.3597
Batch 80, Loss: 1.3199
Batch 90, Loss: 1.2927
Batch 100, Loss: 1.3289
Batch 110, Loss: 1.2582
Batch 120, Loss: 1.3436
Batch 130, Loss: 1.3531
Batch 140, Loss: 1.3368
Batch 150, Loss: 1.3895
Batch 160, Loss: 1.2930
Batch 170, Loss: 1.3642
Batch 180, Loss: 1.3458
Batch 190, Loss: 1.3933
Batch 200, Loss: 1.3461
Batch 210, Loss: 1.2975
Batch 220, Loss: 1.2337
Batch 230, Loss: 1.4283
Batch 240, Loss: 1.4194
Batch 250, Loss: 1.3514
Batch 260, Loss: 1.3605
Batch 270, Loss: 1.2849
Batch 280, Loss: 1.3974
Batch 290, Loss: 1.3361
Batch 300, Loss: 1.3971
Batch 310, Loss: 1.4434
Batch 320, Loss: 1.3982
Batch 330, Loss: 1.3710
Batch 340, Loss: 1.3742
Batch 350, Loss: 1.3760
Batch 360, Loss: 1.3867
Batch 370, Loss: 1.4364
Batch 380, Loss: 1.3437
Batch 390, Loss: 1.4032
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.307703495025635 seconds
Epoch 61 accuracy: 61.45%
Batch 10, Loss: 1.2377
Batch 20, Loss: 1.2632
Batch 30, Loss: 1.2954
Batch 40, Loss: 1.2956
Batch 50, Loss: 1.3260
Batch 60, Loss: 1.3401
Batch 70, Loss: 1.3424
Batch 80, Loss: 1.3106
Batch 90, Loss: 1.2532
Batch 100, Loss: 1.3275
Batch 110, Loss: 1.3051
Batch 120, Loss: 1.3152
Batch 130, Loss: 1.3522
Batch 140, Loss: 1.3028
Batch 150, Loss: 1.3567
Batch 160, Loss: 1.3539
Batch 170, Loss: 1.2783
Batch 180, Loss: 1.3026
Batch 190, Loss: 1.3671
Batch 200, Loss: 1.3667
Batch 210, Loss: 1.3368
Batch 220, Loss: 1.3991
Batch 230, Loss: 1.3206
Batch 240, Loss: 1.3584
Batch 250, Loss: 1.3066
Batch 260, Loss: 1.2999
Batch 270, Loss: 1.3227
Batch 280, Loss: 1.2931
Batch 290, Loss: 1.3636
Batch 300, Loss: 1.3311
Batch 310, Loss: 1.3249
Batch 320, Loss: 1.3808
Batch 330, Loss: 1.3138
Batch 340, Loss: 1.4155
Batch 350, Loss: 1.3717
Batch 360, Loss: 1.3387
Batch 370, Loss: 1.3057
Batch 380, Loss: 1.4318
Batch 390, Loss: 1.3528
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.246869325637817 seconds
Epoch 62 accuracy: 60.48%
Batch 10, Loss: 1.2913
Batch 20, Loss: 1.2891
Batch 30, Loss: 1.3410
Batch 40, Loss: 1.3090
Batch 50, Loss: 1.3744
Batch 60, Loss: 1.3551
Batch 70, Loss: 1.3423
Batch 80, Loss: 1.2608
Batch 90, Loss: 1.2811
Batch 100, Loss: 1.3332
Batch 110, Loss: 1.3708
Batch 120, Loss: 1.2776
Batch 130, Loss: 1.3625
Batch 140, Loss: 1.2847
Batch 150, Loss: 1.3712
Batch 160, Loss: 1.4019
Batch 170, Loss: 1.2842
Batch 180, Loss: 1.3194
Batch 190, Loss: 1.3370
Batch 200, Loss: 1.3864
Batch 210, Loss: 1.3245
Batch 220, Loss: 1.3394
Batch 230, Loss: 1.3266
Batch 240, Loss: 1.3923
Batch 250, Loss: 1.3298
Batch 260, Loss: 1.3277
Batch 270, Loss: 1.3647
Batch 280, Loss: 1.4190
Batch 290, Loss: 1.3229
Batch 300, Loss: 1.3426
Batch 310, Loss: 1.3563
Batch 320, Loss: 1.3666
Batch 330, Loss: 1.3462
Batch 340, Loss: 1.3588
Batch 350, Loss: 1.3567
Batch 360, Loss: 1.3772
Batch 370, Loss: 1.3487
Batch 380, Loss: 1.3192
Batch 390, Loss: 1.3371
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.254215240478516 seconds
Epoch 63 accuracy: 60.15%
Batch 10, Loss: 1.3481
Batch 20, Loss: 1.3153
Batch 30, Loss: 1.2576
Batch 40, Loss: 1.2738
Batch 50, Loss: 1.2845
Batch 60, Loss: 1.2573
Batch 70, Loss: 1.2573
Batch 80, Loss: 1.3014
Batch 90, Loss: 1.3609
Batch 100, Loss: 1.2798
Batch 110, Loss: 1.3847
Batch 120, Loss: 1.3008
Batch 130, Loss: 1.2826
Batch 140, Loss: 1.2950
Batch 150, Loss: 1.3078
Batch 160, Loss: 1.2808
Batch 170, Loss: 1.3100
Batch 180, Loss: 1.3275
Batch 190, Loss: 1.3363
Batch 200, Loss: 1.3530
Batch 210, Loss: 1.3071
Batch 220, Loss: 1.3307
Batch 230, Loss: 1.3383
Batch 240, Loss: 1.3817
Batch 250, Loss: 1.4065
Batch 260, Loss: 1.3583
Batch 270, Loss: 1.3039
Batch 280, Loss: 1.3330
Batch 290, Loss: 1.3405
Batch 300, Loss: 1.3230
Batch 310, Loss: 1.3863
Batch 320, Loss: 1.2574
Batch 330, Loss: 1.3296
Batch 340, Loss: 1.4183
Batch 350, Loss: 1.3981
Batch 360, Loss: 1.3768
Batch 370, Loss: 1.3202
Batch 380, Loss: 1.3059
Batch 390, Loss: 1.3885
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.23697304725647 seconds
Epoch 64 accuracy: 60.7%
Batch 10, Loss: 1.3341
Batch 20, Loss: 1.2740
Batch 30, Loss: 1.3385
Batch 40, Loss: 1.3332
Batch 50, Loss: 1.3371
Batch 60, Loss: 1.3080
Batch 70, Loss: 1.3227
Batch 80, Loss: 1.3501
Batch 90, Loss: 1.3078
Batch 100, Loss: 1.2820
Batch 110, Loss: 1.2641
Batch 120, Loss: 1.3311
Batch 130, Loss: 1.3445
Batch 140, Loss: 1.2863
Batch 150, Loss: 1.2712
Batch 160, Loss: 1.3158
Batch 170, Loss: 1.2816
Batch 180, Loss: 1.2489
Batch 190, Loss: 1.2498
Batch 200, Loss: 1.2895
Batch 210, Loss: 1.3231
Batch 220, Loss: 1.3030
Batch 230, Loss: 1.3245
Batch 240, Loss: 1.3404
Batch 250, Loss: 1.3995
Batch 260, Loss: 1.2972
Batch 270, Loss: 1.3310
Batch 280, Loss: 1.4435
Batch 290, Loss: 1.3348
Batch 300, Loss: 1.3250
Batch 310, Loss: 1.3587
Batch 320, Loss: 1.3064
Batch 330, Loss: 1.3648
Batch 340, Loss: 1.3544
Batch 350, Loss: 1.3583
Batch 360, Loss: 1.3830
Batch 370, Loss: 1.3298
Batch 380, Loss: 1.3418
Batch 390, Loss: 1.3670
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.210445642471313 seconds
Epoch 65 accuracy: 61.95%
Batch 10, Loss: 1.2029
Batch 20, Loss: 1.2521
Batch 30, Loss: 1.3099
Batch 40, Loss: 1.2352
Batch 50, Loss: 1.2409
Batch 60, Loss: 1.3117
Batch 70, Loss: 1.2892
Batch 80, Loss: 1.2634
Batch 90, Loss: 1.3236
Batch 100, Loss: 1.3375
Batch 110, Loss: 1.3300
Batch 120, Loss: 1.2969
Batch 130, Loss: 1.2617
Batch 140, Loss: 1.3461
Batch 150, Loss: 1.3021
Batch 160, Loss: 1.3241
Batch 170, Loss: 1.3383
Batch 180, Loss: 1.2961
Batch 190, Loss: 1.3064
Batch 200, Loss: 1.3165
Batch 210, Loss: 1.3174
Batch 220, Loss: 1.3073
Batch 230, Loss: 1.3316
Batch 240, Loss: 1.3026
Batch 250, Loss: 1.3240
Batch 260, Loss: 1.3457
Batch 270, Loss: 1.4026
Batch 280, Loss: 1.3661
Batch 290, Loss: 1.3218
Batch 300, Loss: 1.2630
Batch 310, Loss: 1.2449
Batch 320, Loss: 1.3147
Batch 330, Loss: 1.3264
Batch 340, Loss: 1.3111
Batch 350, Loss: 1.2880
Batch 360, Loss: 1.2913
Batch 370, Loss: 1.3374
Batch 380, Loss: 1.3030
Batch 390, Loss: 1.3107
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.31808853149414 seconds
Epoch 66 accuracy: 58.9%
Batch 10, Loss: 1.2874
Batch 20, Loss: 1.2797
Batch 30, Loss: 1.2769
Batch 40, Loss: 1.2998
Batch 50, Loss: 1.2759
Batch 60, Loss: 1.2566
Batch 70, Loss: 1.2728
Batch 80, Loss: 1.2925
Batch 90, Loss: 1.3256
Batch 100, Loss: 1.2953
Batch 110, Loss: 1.2550
Batch 120, Loss: 1.2949
Batch 130, Loss: 1.2394
Batch 140, Loss: 1.3271
Batch 150, Loss: 1.3725
Batch 160, Loss: 1.3010
Batch 170, Loss: 1.2786
Batch 180, Loss: 1.3036
Batch 190, Loss: 1.2652
Batch 200, Loss: 1.2957
Batch 210, Loss: 1.2704
Batch 220, Loss: 1.3070
Batch 230, Loss: 1.3552
Batch 240, Loss: 1.3177
Batch 250, Loss: 1.3517
Batch 260, Loss: 1.2896
Batch 270, Loss: 1.4072
Batch 280, Loss: 1.3760
Batch 290, Loss: 1.3734
Batch 300, Loss: 1.3097
Batch 310, Loss: 1.2926
Batch 320, Loss: 1.3182
Batch 330, Loss: 1.2845
Batch 340, Loss: 1.3752
Batch 350, Loss: 1.3271
Batch 360, Loss: 1.3243
Batch 370, Loss: 1.3486
Batch 380, Loss: 1.3299
Batch 390, Loss: 1.3195
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.326575756072998 seconds
Epoch 67 accuracy: 61.7%
Batch 10, Loss: 1.2534
Batch 20, Loss: 1.2861
Batch 30, Loss: 1.3188
Batch 40, Loss: 1.2645
Batch 50, Loss: 1.2883
Batch 60, Loss: 1.2857
Batch 70, Loss: 1.2663
Batch 80, Loss: 1.3407
Batch 90, Loss: 1.2893
Batch 100, Loss: 1.2738
Batch 110, Loss: 1.3386
Batch 120, Loss: 1.3078
Batch 130, Loss: 1.3204
Batch 140, Loss: 1.3108
Batch 150, Loss: 1.2857
Batch 160, Loss: 1.3039
Batch 170, Loss: 1.2833
Batch 180, Loss: 1.3218
Batch 190, Loss: 1.2721
Batch 200, Loss: 1.3855
Batch 210, Loss: 1.3439
Batch 220, Loss: 1.2888
Batch 230, Loss: 1.2791
Batch 240, Loss: 1.3426
Batch 250, Loss: 1.3860
Batch 260, Loss: 1.2831
Batch 270, Loss: 1.2952
Batch 280, Loss: 1.3104
Batch 290, Loss: 1.3388
Batch 300, Loss: 1.2834
Batch 310, Loss: 1.3669
Batch 320, Loss: 1.2892
Batch 330, Loss: 1.3689
Batch 340, Loss: 1.3431
Batch 350, Loss: 1.3229
Batch 360, Loss: 1.3778
Batch 370, Loss: 1.3397
Batch 380, Loss: 1.2934
Batch 390, Loss: 1.2893
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.696723699569702 seconds
Epoch 68 accuracy: 61.09%
Batch 10, Loss: 1.2488
Batch 20, Loss: 1.2303
Batch 30, Loss: 1.2699
Batch 40, Loss: 1.2269
Batch 50, Loss: 1.2588
Batch 60, Loss: 1.3005
Batch 70, Loss: 1.2526
Batch 80, Loss: 1.2907
Batch 90, Loss: 1.2754
Batch 100, Loss: 1.3418
Batch 110, Loss: 1.2935
Batch 120, Loss: 1.2095
Batch 130, Loss: 1.2466
Batch 140, Loss: 1.3230
Batch 150, Loss: 1.2920
Batch 160, Loss: 1.2715
Batch 170, Loss: 1.2443
Batch 180, Loss: 1.3162
Batch 190, Loss: 1.2680
Batch 200, Loss: 1.2910
Batch 210, Loss: 1.3481
Batch 220, Loss: 1.3660
Batch 230, Loss: 1.3646
Batch 240, Loss: 1.3400
Batch 250, Loss: 1.2959
Batch 260, Loss: 1.3283
Batch 270, Loss: 1.2792
Batch 280, Loss: 1.3292
Batch 290, Loss: 1.3624
Batch 300, Loss: 1.4071
Batch 310, Loss: 1.3423
Batch 320, Loss: 1.3330
Batch 330, Loss: 1.2557
Batch 340, Loss: 1.3206
Batch 350, Loss: 1.2964
Batch 360, Loss: 1.2275
Batch 370, Loss: 1.2570
Batch 380, Loss: 1.2870
Batch 390, Loss: 1.3375
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.29005193710327 seconds
Epoch 69 accuracy: 60.56%
Batch 10, Loss: 1.2748
Batch 20, Loss: 1.3221
Batch 30, Loss: 1.2290
Batch 40, Loss: 1.2268
Batch 50, Loss: 1.2346
Batch 60, Loss: 1.2844
Batch 70, Loss: 1.2101
Batch 80, Loss: 1.1966
Batch 90, Loss: 1.2760
Batch 100, Loss: 1.2689
Batch 110, Loss: 1.3259
Batch 120, Loss: 1.2469
Batch 130, Loss: 1.2601
Batch 140, Loss: 1.2584
Batch 150, Loss: 1.2747
Batch 160, Loss: 1.2175
Batch 170, Loss: 1.2443
Batch 180, Loss: 1.2970
Batch 190, Loss: 1.3131
Batch 200, Loss: 1.2981
Batch 210, Loss: 1.3108
Batch 220, Loss: 1.2704
Batch 230, Loss: 1.3685
Batch 240, Loss: 1.3844
Batch 250, Loss: 1.2664
Batch 260, Loss: 1.3089
Batch 270, Loss: 1.3085
Batch 280, Loss: 1.3876
Batch 290, Loss: 1.3125
Batch 300, Loss: 1.2467
Batch 310, Loss: 1.2777
Batch 320, Loss: 1.3252
Batch 330, Loss: 1.3333
Batch 340, Loss: 1.2893
Batch 350, Loss: 1.3025
Batch 360, Loss: 1.3063
Batch 370, Loss: 1.3737
Batch 380, Loss: 1.3965
Batch 390, Loss: 1.3514
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.267057418823242 seconds
Epoch 70 accuracy: 62.23%
Batch 10, Loss: 1.2942
Batch 20, Loss: 1.2699
Batch 30, Loss: 1.2648
Batch 40, Loss: 1.2384
Batch 50, Loss: 1.2197
Batch 60, Loss: 1.2289
Batch 70, Loss: 1.2433
Batch 80, Loss: 1.2623
Batch 90, Loss: 1.3110
Batch 100, Loss: 1.3066
Batch 110, Loss: 1.3195
Batch 120, Loss: 1.3714
Batch 130, Loss: 1.2415
Batch 140, Loss: 1.2509
Batch 150, Loss: 1.2337
Batch 160, Loss: 1.2570
Batch 170, Loss: 1.2763
Batch 180, Loss: 1.2294
Batch 190, Loss: 1.2937
Batch 200, Loss: 1.2788
Batch 210, Loss: 1.2775
Batch 220, Loss: 1.3178
Batch 230, Loss: 1.3157
Batch 240, Loss: 1.2649
Batch 250, Loss: 1.2783
Batch 260, Loss: 1.3509
Batch 270, Loss: 1.3042
Batch 280, Loss: 1.2785
Batch 290, Loss: 1.3345
Batch 300, Loss: 1.2774
Batch 310, Loss: 1.2797
Batch 320, Loss: 1.3204
Batch 330, Loss: 1.3267
Batch 340, Loss: 1.3630
Batch 350, Loss: 1.3128
Batch 360, Loss: 1.3008
Batch 370, Loss: 1.2854
Batch 380, Loss: 1.3465
Batch 390, Loss: 1.2589
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.376481771469116 seconds
Epoch 71 accuracy: 61.36%
Batch 10, Loss: 1.1984
Batch 20, Loss: 1.2471
Batch 30, Loss: 1.2639
Batch 40, Loss: 1.2337
Batch 50, Loss: 1.2525
Batch 60, Loss: 1.1763
Batch 70, Loss: 1.2528
Batch 80, Loss: 1.2347
Batch 90, Loss: 1.2427
Batch 100, Loss: 1.2956
Batch 110, Loss: 1.2511
Batch 120, Loss: 1.3036
Batch 130, Loss: 1.3178
Batch 140, Loss: 1.2760
Batch 150, Loss: 1.2969
Batch 160, Loss: 1.2915
Batch 170, Loss: 1.2854
Batch 180, Loss: 1.2947
Batch 190, Loss: 1.2757
Batch 200, Loss: 1.2515
Batch 210, Loss: 1.3188
Batch 220, Loss: 1.2481
Batch 230, Loss: 1.2450
Batch 240, Loss: 1.2706
Batch 250, Loss: 1.2832
Batch 260, Loss: 1.2588
Batch 270, Loss: 1.3309
Batch 280, Loss: 1.2395
Batch 290, Loss: 1.3062
Batch 300, Loss: 1.3264
Batch 310, Loss: 1.2913
Batch 320, Loss: 1.3026
Batch 330, Loss: 1.3351
Batch 340, Loss: 1.3272
Batch 350, Loss: 1.2823
Batch 360, Loss: 1.2676
Batch 370, Loss: 1.3544
Batch 380, Loss: 1.2641
Batch 390, Loss: 1.3110
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.381166219711304 seconds
Epoch 72 accuracy: 60.8%
Batch 10, Loss: 1.1980
Batch 20, Loss: 1.2231
Batch 30, Loss: 1.2508
Batch 40, Loss: 1.2245
Batch 50, Loss: 1.3016
Batch 60, Loss: 1.2416
Batch 70, Loss: 1.2244
Batch 80, Loss: 1.2880
Batch 90, Loss: 1.2556
Batch 100, Loss: 1.2719
Batch 110, Loss: 1.2811
Batch 120, Loss: 1.3176
Batch 130, Loss: 1.2666
Batch 140, Loss: 1.3095
Batch 150, Loss: 1.2390
Batch 160, Loss: 1.2897
Batch 170, Loss: 1.2899
Batch 180, Loss: 1.2750
Batch 190, Loss: 1.2402
Batch 200, Loss: 1.2791
Batch 210, Loss: 1.2468
Batch 220, Loss: 1.2385
Batch 230, Loss: 1.2307
Batch 240, Loss: 1.2769
Batch 250, Loss: 1.2837
Batch 260, Loss: 1.2954
Batch 270, Loss: 1.2248
Batch 280, Loss: 1.2718
Batch 290, Loss: 1.2582
Batch 300, Loss: 1.2579
Batch 310, Loss: 1.2970
Batch 320, Loss: 1.3619
Batch 330, Loss: 1.3098
Batch 340, Loss: 1.3183
Batch 350, Loss: 1.2989
Batch 360, Loss: 1.2914
Batch 370, Loss: 1.2858
Batch 380, Loss: 1.2783
Batch 390, Loss: 1.3240
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.448662757873535 seconds
Epoch 73 accuracy: 62.81%
Batch 10, Loss: 1.2655
Batch 20, Loss: 1.2758
Batch 30, Loss: 1.2040
Batch 40, Loss: 1.2212
Batch 50, Loss: 1.2723
Batch 60, Loss: 1.2634
Batch 70, Loss: 1.2408
Batch 80, Loss: 1.2547
Batch 90, Loss: 1.2985
Batch 100, Loss: 1.2874
Batch 110, Loss: 1.2331
Batch 120, Loss: 1.2534
Batch 130, Loss: 1.2354
Batch 140, Loss: 1.2598
Batch 150, Loss: 1.2667
Batch 160, Loss: 1.2663
Batch 170, Loss: 1.2543
Batch 180, Loss: 1.2194
Batch 190, Loss: 1.2896
Batch 200, Loss: 1.2858
Batch 210, Loss: 1.2495
Batch 220, Loss: 1.2213
Batch 230, Loss: 1.2413
Batch 240, Loss: 1.3390
Batch 250, Loss: 1.2623
Batch 260, Loss: 1.3350
Batch 270, Loss: 1.2607
Batch 280, Loss: 1.2305
Batch 290, Loss: 1.3403
Batch 300, Loss: 1.3224
Batch 310, Loss: 1.2249
Batch 320, Loss: 1.2240
Batch 330, Loss: 1.3380
Batch 340, Loss: 1.2748
Batch 350, Loss: 1.3000
Batch 360, Loss: 1.3178
Batch 370, Loss: 1.2881
Batch 380, Loss: 1.2871
Batch 390, Loss: 1.2504
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.2912175655365 seconds
Epoch 74 accuracy: 62.66%
Batch 10, Loss: 1.1969
Batch 20, Loss: 1.2376
Batch 30, Loss: 1.2474
Batch 40, Loss: 1.1615
Batch 50, Loss: 1.2630
Batch 60, Loss: 1.2665
Batch 70, Loss: 1.2062
Batch 80, Loss: 1.1966
Batch 90, Loss: 1.2162
Batch 100, Loss: 1.2428
Batch 110, Loss: 1.2776
Batch 120, Loss: 1.2427
Batch 130, Loss: 1.2942
Batch 140, Loss: 1.2471
Batch 150, Loss: 1.2219
Batch 160, Loss: 1.2860
Batch 170, Loss: 1.2207
Batch 180, Loss: 1.2451
Batch 190, Loss: 1.2216
Batch 200, Loss: 1.2528
Batch 210, Loss: 1.3195
Batch 220, Loss: 1.3089
Batch 230, Loss: 1.2696
Batch 240, Loss: 1.3094
Batch 250, Loss: 1.2478
Batch 260, Loss: 1.3083
Batch 270, Loss: 1.2999
Batch 280, Loss: 1.2943
Batch 290, Loss: 1.2499
Batch 300, Loss: 1.2624
Batch 310, Loss: 1.2241
Batch 320, Loss: 1.4146
Batch 330, Loss: 1.3070
Batch 340, Loss: 1.2935
Batch 350, Loss: 1.2285
Batch 360, Loss: 1.2862
Batch 370, Loss: 1.2670
Batch 380, Loss: 1.2999
Batch 390, Loss: 1.2965
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.346338987350464 seconds
Epoch 75 accuracy: 60.22%
Batch 10, Loss: 1.2999
Batch 20, Loss: 1.2360
Batch 30, Loss: 1.2490
Batch 40, Loss: 1.1843
Batch 50, Loss: 1.2096
Batch 60, Loss: 1.2280
Batch 70, Loss: 1.2311
Batch 80, Loss: 1.2713
Batch 90, Loss: 1.2550
Batch 100, Loss: 1.2067
Batch 110, Loss: 1.2195
Batch 120, Loss: 1.3075
Batch 130, Loss: 1.2760
Batch 140, Loss: 1.2384
Batch 150, Loss: 1.2746
Batch 160, Loss: 1.2578
Batch 170, Loss: 1.3032
Batch 180, Loss: 1.2564
Batch 190, Loss: 1.2440
Batch 200, Loss: 1.2596
Batch 210, Loss: 1.2483
Batch 220, Loss: 1.2117
Batch 230, Loss: 1.2394
Batch 240, Loss: 1.3015
Batch 250, Loss: 1.2086
Batch 260, Loss: 1.2238
Batch 270, Loss: 1.2335
Batch 280, Loss: 1.3297
Batch 290, Loss: 1.2757
Batch 300, Loss: 1.2402
Batch 310, Loss: 1.2644
Batch 320, Loss: 1.2440
Batch 330, Loss: 1.2807
Batch 340, Loss: 1.2743
Batch 350, Loss: 1.2579
Batch 360, Loss: 1.2968
Batch 370, Loss: 1.3091
Batch 380, Loss: 1.2646
Batch 390, Loss: 1.2677
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.442737817764282 seconds
Epoch 76 accuracy: 63.26%
Batch 10, Loss: 1.1673
Batch 20, Loss: 1.1618
Batch 30, Loss: 1.2093
Batch 40, Loss: 1.1939
Batch 50, Loss: 1.2413
Batch 60, Loss: 1.2116
Batch 70, Loss: 1.2385
Batch 80, Loss: 1.1835
Batch 90, Loss: 1.2215
Batch 100, Loss: 1.2658
Batch 110, Loss: 1.2247
Batch 120, Loss: 1.2394
Batch 130, Loss: 1.2116
Batch 140, Loss: 1.2275
Batch 150, Loss: 1.2732
Batch 160, Loss: 1.3053
Batch 170, Loss: 1.2976
Batch 180, Loss: 1.3400
Batch 190, Loss: 1.2203
Batch 200, Loss: 1.2526
Batch 210, Loss: 1.2647
Batch 220, Loss: 1.2902
Batch 230, Loss: 1.2569
Batch 240, Loss: 1.3514
Batch 250, Loss: 1.3350
Batch 260, Loss: 1.2296
Batch 270, Loss: 1.2343
Batch 280, Loss: 1.2540
Batch 290, Loss: 1.2383
Batch 300, Loss: 1.3630
Batch 310, Loss: 1.3116
Batch 320, Loss: 1.3049
Batch 330, Loss: 1.2578
Batch 340, Loss: 1.2733
Batch 350, Loss: 1.2640
Batch 360, Loss: 1.2257
Batch 370, Loss: 1.3123
Batch 380, Loss: 1.3596
Batch 390, Loss: 1.3091
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.41552734375 seconds
Epoch 77 accuracy: 61.12%
Batch 10, Loss: 1.1939
Batch 20, Loss: 1.2165
Batch 30, Loss: 1.1537
Batch 40, Loss: 1.1835
Batch 50, Loss: 1.2089
Batch 60, Loss: 1.1985
Batch 70, Loss: 1.1948
Batch 80, Loss: 1.2136
Batch 90, Loss: 1.2284
Batch 100, Loss: 1.2220
Batch 110, Loss: 1.2429
Batch 120, Loss: 1.2355
Batch 130, Loss: 1.2275
Batch 140, Loss: 1.2659
Batch 150, Loss: 1.2186
Batch 160, Loss: 1.1935
Batch 170, Loss: 1.2235
Batch 180, Loss: 1.2061
Batch 190, Loss: 1.3049
Batch 200, Loss: 1.2830
Batch 210, Loss: 1.2725
Batch 220, Loss: 1.3291
Batch 230, Loss: 1.2598
Batch 240, Loss: 1.2406
Batch 250, Loss: 1.2214
Batch 260, Loss: 1.2489
Batch 270, Loss: 1.2268
Batch 280, Loss: 1.2819
Batch 290, Loss: 1.2566
Batch 300, Loss: 1.2693
Batch 310, Loss: 1.2675
Batch 320, Loss: 1.2588
Batch 330, Loss: 1.2480
Batch 340, Loss: 1.1764
Batch 350, Loss: 1.2718
Batch 360, Loss: 1.3517
Batch 370, Loss: 1.2501
Batch 380, Loss: 1.3064
Batch 390, Loss: 1.2981
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.342787981033325 seconds
Epoch 78 accuracy: 62.65%
Batch 10, Loss: 1.1840
Batch 20, Loss: 1.1566
Batch 30, Loss: 1.2151
Batch 40, Loss: 1.2426
Batch 50, Loss: 1.1907
Batch 60, Loss: 1.2192
Batch 70, Loss: 1.2232
Batch 80, Loss: 1.2105
Batch 90, Loss: 1.2754
Batch 100, Loss: 1.2416
Batch 110, Loss: 1.2626
Batch 120, Loss: 1.2279
Batch 130, Loss: 1.2575
Batch 140, Loss: 1.2647
Batch 150, Loss: 1.2038
Batch 160, Loss: 1.2545
Batch 170, Loss: 1.1838
Batch 180, Loss: 1.2198
Batch 190, Loss: 1.2734
Batch 200, Loss: 1.2157
Batch 210, Loss: 1.2716
Batch 220, Loss: 1.3029
Batch 230, Loss: 1.3112
Batch 240, Loss: 1.2527
Batch 250, Loss: 1.2186
Batch 260, Loss: 1.2769
Batch 270, Loss: 1.2144
Batch 280, Loss: 1.2436
Batch 290, Loss: 1.3133
Batch 300, Loss: 1.3419
Batch 310, Loss: 1.2563
Batch 320, Loss: 1.2667
Batch 330, Loss: 1.2553
Batch 340, Loss: 1.2367
Batch 350, Loss: 1.2714
Batch 360, Loss: 1.2664
Batch 370, Loss: 1.2250
Batch 380, Loss: 1.2286
Batch 390, Loss: 1.2149
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.305188179016113 seconds
Epoch 79 accuracy: 62.11%
Batch 10, Loss: 1.2056
Batch 20, Loss: 1.1885
Batch 30, Loss: 1.2101
Batch 40, Loss: 1.1840
Batch 50, Loss: 1.1990
Batch 60, Loss: 1.1693
Batch 70, Loss: 1.0919
Batch 80, Loss: 1.2005
Batch 90, Loss: 1.1896
Batch 100, Loss: 1.2437
Batch 110, Loss: 1.3210
Batch 120, Loss: 1.1979
Batch 130, Loss: 1.2775
Batch 140, Loss: 1.1841
Batch 150, Loss: 1.2137
Batch 160, Loss: 1.2184
Batch 170, Loss: 1.2798
Batch 180, Loss: 1.2357
Batch 190, Loss: 1.2251
Batch 200, Loss: 1.2920
Batch 210, Loss: 1.2598
Batch 220, Loss: 1.2446
Batch 230, Loss: 1.2658
Batch 240, Loss: 1.2489
Batch 250, Loss: 1.3272
Batch 260, Loss: 1.3009
Batch 270, Loss: 1.2261
Batch 280, Loss: 1.2263
Batch 290, Loss: 1.2212
Batch 300, Loss: 1.2923
Batch 310, Loss: 1.2240
Batch 320, Loss: 1.2470
Batch 330, Loss: 1.2586
Batch 340, Loss: 1.3096
Batch 350, Loss: 1.2103
Batch 360, Loss: 1.3027
Batch 370, Loss: 1.3402
Batch 380, Loss: 1.1911
Batch 390, Loss: 1.2641
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.347379207611084 seconds
Epoch 80 accuracy: 63.43%
Batch 10, Loss: 1.1842
Batch 20, Loss: 1.1839
Batch 30, Loss: 1.1554
Batch 40, Loss: 1.2037
Batch 50, Loss: 1.2214
Batch 60, Loss: 1.1746
Batch 70, Loss: 1.2398
Batch 80, Loss: 1.1865
Batch 90, Loss: 1.2028
Batch 100, Loss: 1.2279
Batch 110, Loss: 1.2472
Batch 120, Loss: 1.2431
Batch 130, Loss: 1.2069
Batch 140, Loss: 1.2471
Batch 150, Loss: 1.2120
Batch 160, Loss: 1.2221
Batch 170, Loss: 1.2165
Batch 180, Loss: 1.2286
Batch 190, Loss: 1.2476
Batch 200, Loss: 1.2137
Batch 210, Loss: 1.2364
Batch 220, Loss: 1.2496
Batch 230, Loss: 1.2234
Batch 240, Loss: 1.2929
Batch 250, Loss: 1.2459
Batch 260, Loss: 1.2997
Batch 270, Loss: 1.2630
Batch 280, Loss: 1.2875
Batch 290, Loss: 1.2277
Batch 300, Loss: 1.2021
Batch 310, Loss: 1.2687
Batch 320, Loss: 1.3380
Batch 330, Loss: 1.3004
Batch 340, Loss: 1.2263
Batch 350, Loss: 1.1978
Batch 360, Loss: 1.2291
Batch 370, Loss: 1.1758
Batch 380, Loss: 1.2426
Batch 390, Loss: 1.2404
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.32944655418396 seconds
Epoch 81 accuracy: 62.64%
Batch 10, Loss: 1.2277
Batch 20, Loss: 1.1814
Batch 30, Loss: 1.1513
Batch 40, Loss: 1.1949
Batch 50, Loss: 1.1988
Batch 60, Loss: 1.2413
Batch 70, Loss: 1.1471
Batch 80, Loss: 1.2086
Batch 90, Loss: 1.2171
Batch 100, Loss: 1.2064
Batch 110, Loss: 1.1417
Batch 120, Loss: 1.2166
Batch 130, Loss: 1.1758
Batch 140, Loss: 1.2373
Batch 150, Loss: 1.2989
Batch 160, Loss: 1.2400
Batch 170, Loss: 1.1752
Batch 180, Loss: 1.2193
Batch 190, Loss: 1.1841
Batch 200, Loss: 1.2139
Batch 210, Loss: 1.2031
Batch 220, Loss: 1.2397
Batch 230, Loss: 1.2432
Batch 240, Loss: 1.2336
Batch 250, Loss: 1.2072
Batch 260, Loss: 1.1691
Batch 270, Loss: 1.2391
Batch 280, Loss: 1.1867
Batch 290, Loss: 1.1982
Batch 300, Loss: 1.2000
Batch 310, Loss: 1.2586
Batch 320, Loss: 1.2535
Batch 330, Loss: 1.2213
Batch 340, Loss: 1.2227
Batch 350, Loss: 1.2826
Batch 360, Loss: 1.2302
Batch 370, Loss: 1.2401
Batch 380, Loss: 1.2609
Batch 390, Loss: 1.2395
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.235994577407837 seconds
Epoch 82 accuracy: 61.53%
Batch 10, Loss: 1.1764
Batch 20, Loss: 1.2454
Batch 30, Loss: 1.1754
Batch 40, Loss: 1.2012
Batch 50, Loss: 1.2418
Batch 60, Loss: 1.1783
Batch 70, Loss: 1.1524
Batch 80, Loss: 1.2263
Batch 90, Loss: 1.1533
Batch 100, Loss: 1.1940
Batch 110, Loss: 1.1202
Batch 120, Loss: 1.1356
Batch 130, Loss: 1.1831
Batch 140, Loss: 1.1630
Batch 150, Loss: 1.1529
Batch 160, Loss: 1.2696
Batch 170, Loss: 1.1698
Batch 180, Loss: 1.2102
Batch 190, Loss: 1.1821
Batch 200, Loss: 1.2670
Batch 210, Loss: 1.2176
Batch 220, Loss: 1.2056
Batch 230, Loss: 1.1967
Batch 240, Loss: 1.2213
Batch 250, Loss: 1.2321
Batch 260, Loss: 1.2932
Batch 270, Loss: 1.2921
Batch 280, Loss: 1.2269
Batch 290, Loss: 1.2582
Batch 300, Loss: 1.2624
Batch 310, Loss: 1.2237
Batch 320, Loss: 1.2470
Batch 330, Loss: 1.2055
Batch 340, Loss: 1.1966
Batch 350, Loss: 1.2638
Batch 360, Loss: 1.2501
Batch 370, Loss: 1.2406
Batch 380, Loss: 1.2720
Batch 390, Loss: 1.2645
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.308205366134644 seconds
Epoch 83 accuracy: 62.57%
Batch 10, Loss: 1.1921
Batch 20, Loss: 1.1519
Batch 30, Loss: 1.1654
Batch 40, Loss: 1.1558
Batch 50, Loss: 1.1634
Batch 60, Loss: 1.0520
Batch 70, Loss: 1.1777
Batch 80, Loss: 1.1742
Batch 90, Loss: 1.1177
Batch 100, Loss: 1.2527
Batch 110, Loss: 1.1388
Batch 120, Loss: 1.1832
Batch 130, Loss: 1.1615
Batch 140, Loss: 1.2926
Batch 150, Loss: 1.1721
Batch 160, Loss: 1.2104
Batch 170, Loss: 1.2370
Batch 180, Loss: 1.2131
Batch 190, Loss: 1.2395
Batch 200, Loss: 1.2610
Batch 210, Loss: 1.1767
Batch 220, Loss: 1.2350
Batch 230, Loss: 1.2507
Batch 240, Loss: 1.2336
Batch 250, Loss: 1.2446
Batch 260, Loss: 1.1830
Batch 270, Loss: 1.2871
Batch 280, Loss: 1.1932
Batch 290, Loss: 1.2171
Batch 300, Loss: 1.2322
Batch 310, Loss: 1.2867
Batch 320, Loss: 1.2311
Batch 330, Loss: 1.1958
Batch 340, Loss: 1.2464
Batch 350, Loss: 1.2040
Batch 360, Loss: 1.1541
Batch 370, Loss: 1.1909
Batch 380, Loss: 1.3074
Batch 390, Loss: 1.2723
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.360492706298828 seconds
Epoch 84 accuracy: 62.33%
Batch 10, Loss: 1.1541
Batch 20, Loss: 1.1741
Batch 30, Loss: 1.1327
Batch 40, Loss: 1.1703
Batch 50, Loss: 1.1850
Batch 60, Loss: 1.2003
Batch 70, Loss: 1.0960
Batch 80, Loss: 1.2004
Batch 90, Loss: 1.2198
Batch 100, Loss: 1.1700
Batch 110, Loss: 1.1742
Batch 120, Loss: 1.1381
Batch 130, Loss: 1.2143
Batch 140, Loss: 1.2392
Batch 150, Loss: 1.1712
Batch 160, Loss: 1.2040
Batch 170, Loss: 1.2063
Batch 180, Loss: 1.2385
Batch 190, Loss: 1.2880
Batch 200, Loss: 1.2762
Batch 210, Loss: 1.1852
Batch 220, Loss: 1.3173
Batch 230, Loss: 1.2227
Batch 240, Loss: 1.2263
Batch 250, Loss: 1.2547
Batch 260, Loss: 1.1995
Batch 270, Loss: 1.2162
Batch 280, Loss: 1.1776
Batch 290, Loss: 1.1866
Batch 300, Loss: 1.1855
Batch 310, Loss: 1.2056
Batch 320, Loss: 1.2110
Batch 330, Loss: 1.2125
Batch 340, Loss: 1.2226
Batch 350, Loss: 1.2617
Batch 360, Loss: 1.2371
Batch 370, Loss: 1.2094
Batch 380, Loss: 1.2202
Batch 390, Loss: 1.2712
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.40289831161499 seconds
Epoch 85 accuracy: 62.13%
Batch 10, Loss: 1.1790
Batch 20, Loss: 1.1222
Batch 30, Loss: 1.1866
Batch 40, Loss: 1.2060
Batch 50, Loss: 1.1731
Batch 60, Loss: 1.1634
Batch 70, Loss: 1.0987
Batch 80, Loss: 1.0992
Batch 90, Loss: 1.1682
Batch 100, Loss: 1.2146
Batch 110, Loss: 1.1674
Batch 120, Loss: 1.2056
Batch 130, Loss: 1.2303
Batch 140, Loss: 1.1724
Batch 150, Loss: 1.2447
Batch 160, Loss: 1.2541
Batch 170, Loss: 1.1677
Batch 180, Loss: 1.1838
Batch 190, Loss: 1.1671
Batch 200, Loss: 1.1739
Batch 210, Loss: 1.1903
Batch 220, Loss: 1.1489
Batch 230, Loss: 1.1487
Batch 240, Loss: 1.2382
Batch 250, Loss: 1.2311
Batch 260, Loss: 1.1248
Batch 270, Loss: 1.2275
Batch 280, Loss: 1.1676
Batch 290, Loss: 1.2570
Batch 300, Loss: 1.2197
Batch 310, Loss: 1.2103
Batch 320, Loss: 1.2655
Batch 330, Loss: 1.1712
Batch 340, Loss: 1.2269
Batch 350, Loss: 1.2373
Batch 360, Loss: 1.2587
Batch 370, Loss: 1.2418
Batch 380, Loss: 1.2358
Batch 390, Loss: 1.2364
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.3842716217041 seconds
Epoch 86 accuracy: 64.07%
Batch 10, Loss: 1.1602
Batch 20, Loss: 1.1529
Batch 30, Loss: 1.1443
Batch 40, Loss: 1.2051
Batch 50, Loss: 1.1438
Batch 60, Loss: 1.1460
Batch 70, Loss: 1.1233
Batch 80, Loss: 1.1861
Batch 90, Loss: 1.2224
Batch 100, Loss: 1.1487
Batch 110, Loss: 1.0837
Batch 120, Loss: 1.2053
Batch 130, Loss: 1.1351
Batch 140, Loss: 1.2250
Batch 150, Loss: 1.2161
Batch 160, Loss: 1.1931
Batch 170, Loss: 1.2321
Batch 180, Loss: 1.2254
Batch 190, Loss: 1.1862
Batch 200, Loss: 1.2038
Batch 210, Loss: 1.1864
Batch 220, Loss: 1.1609
Batch 230, Loss: 1.1742
Batch 240, Loss: 1.2238
Batch 250, Loss: 1.2285
Batch 260, Loss: 1.2422
Batch 270, Loss: 1.2191
Batch 280, Loss: 1.2062
Batch 290, Loss: 1.1640
Batch 300, Loss: 1.2137
Batch 310, Loss: 1.2013
Batch 320, Loss: 1.1985
Batch 330, Loss: 1.2514
Batch 340, Loss: 1.1832
Batch 350, Loss: 1.1699
Batch 360, Loss: 1.1429
Batch 370, Loss: 1.1893
Batch 380, Loss: 1.2704
Batch 390, Loss: 1.1798
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.325493574142456 seconds
Epoch 87 accuracy: 66.43%
Batch 10, Loss: 1.0966
Batch 20, Loss: 1.1364
Batch 30, Loss: 1.0819
Batch 40, Loss: 1.0986
Batch 50, Loss: 1.1352
Batch 60, Loss: 1.1380
Batch 70, Loss: 1.1705
Batch 80, Loss: 1.1867
Batch 90, Loss: 1.0999
Batch 100, Loss: 1.1855
Batch 110, Loss: 1.1820
Batch 120, Loss: 1.1820
Batch 130, Loss: 1.2264
Batch 140, Loss: 1.1956
Batch 150, Loss: 1.1621
Batch 160, Loss: 1.1521
Batch 170, Loss: 1.1432
Batch 180, Loss: 1.1345
Batch 190, Loss: 1.1825
Batch 200, Loss: 1.1931
Batch 210, Loss: 1.1270
Batch 220, Loss: 1.1640
Batch 230, Loss: 1.1928
Batch 240, Loss: 1.1710
Batch 250, Loss: 1.2253
Batch 260, Loss: 1.2062
Batch 270, Loss: 1.1934
Batch 280, Loss: 1.2078
Batch 290, Loss: 1.2192
Batch 300, Loss: 1.1803
Batch 310, Loss: 1.1966
Batch 320, Loss: 1.2413
Batch 330, Loss: 1.1896
Batch 340, Loss: 1.1345
Batch 350, Loss: 1.1989
Batch 360, Loss: 1.2235
Batch 370, Loss: 1.2411
Batch 380, Loss: 1.2696
Batch 390, Loss: 1.1964
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.427956104278564 seconds
Epoch 88 accuracy: 63.22%
Batch 10, Loss: 1.1099
Batch 20, Loss: 1.1300
Batch 30, Loss: 1.1571
Batch 40, Loss: 1.1273
Batch 50, Loss: 1.0826
Batch 60, Loss: 1.1394
Batch 70, Loss: 1.1300
Batch 80, Loss: 1.1151
Batch 90, Loss: 1.1406
Batch 100, Loss: 1.1802
Batch 110, Loss: 1.1961
Batch 120, Loss: 1.1866
Batch 130, Loss: 1.1949
Batch 140, Loss: 1.1441
Batch 150, Loss: 1.2008
Batch 160, Loss: 1.1930
Batch 170, Loss: 1.1178
Batch 180, Loss: 1.1764
Batch 190, Loss: 1.2393
Batch 200, Loss: 1.1682
Batch 210, Loss: 1.1562
Batch 220, Loss: 1.2160
Batch 230, Loss: 1.1169
Batch 240, Loss: 1.2251
Batch 250, Loss: 1.2233
Batch 260, Loss: 1.2001
Batch 270, Loss: 1.1543
Batch 280, Loss: 1.2292
Batch 290, Loss: 1.2477
Batch 300, Loss: 1.1934
Batch 310, Loss: 1.1870
Batch 320, Loss: 1.1036
Batch 330, Loss: 1.1896
Batch 340, Loss: 1.1640
Batch 350, Loss: 1.2657
Batch 360, Loss: 1.1659
Batch 370, Loss: 1.1653
Batch 380, Loss: 1.1953
Batch 390, Loss: 1.2084
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.329854488372803 seconds
Epoch 89 accuracy: 63.5%
Batch 10, Loss: 1.1730
Batch 20, Loss: 1.1785
Batch 30, Loss: 1.1921
Batch 40, Loss: 1.1438
Batch 50, Loss: 1.1757
Batch 60, Loss: 1.1587
Batch 70, Loss: 1.1046
Batch 80, Loss: 1.0773
Batch 90, Loss: 1.1799
Batch 100, Loss: 1.1558
Batch 110, Loss: 1.1691
Batch 120, Loss: 1.1286
Batch 130, Loss: 1.1343
Batch 140, Loss: 1.1355
Batch 150, Loss: 1.2056
Batch 160, Loss: 1.1965
Batch 170, Loss: 1.1976
Batch 180, Loss: 1.1694
Batch 190, Loss: 1.1580
Batch 200, Loss: 1.1718
Batch 210, Loss: 1.1716
Batch 220, Loss: 1.1559
Batch 230, Loss: 1.1689
Batch 240, Loss: 1.2159
Batch 250, Loss: 1.2160
Batch 260, Loss: 1.1784
Batch 270, Loss: 1.1530
Batch 280, Loss: 1.1947
Batch 290, Loss: 1.2231
Batch 300, Loss: 1.1261
Batch 310, Loss: 1.1895
Batch 320, Loss: 1.1016
Batch 330, Loss: 1.1974
Batch 340, Loss: 1.1511
Batch 350, Loss: 1.2353
Batch 360, Loss: 1.2181
Batch 370, Loss: 1.1883
Batch 380, Loss: 1.1562
Batch 390, Loss: 1.1551
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.354947805404663 seconds
Epoch 90 accuracy: 63.38%
Batch 10, Loss: 1.1326
Batch 20, Loss: 1.1323
Batch 30, Loss: 1.0750
Batch 40, Loss: 1.0907
Batch 50, Loss: 1.1230
Batch 60, Loss: 1.1189
Batch 70, Loss: 1.1473
Batch 80, Loss: 1.1547
Batch 90, Loss: 1.1302
Batch 100, Loss: 1.1230
Batch 110, Loss: 1.1416
Batch 120, Loss: 1.1470
Batch 130, Loss: 1.1741
Batch 140, Loss: 1.1713
Batch 150, Loss: 1.2279
Batch 160, Loss: 1.1775
Batch 170, Loss: 1.0810
Batch 180, Loss: 1.1484
Batch 190, Loss: 1.1924
Batch 200, Loss: 1.1502
Batch 210, Loss: 1.1094
Batch 220, Loss: 1.1412
Batch 230, Loss: 1.1575
Batch 240, Loss: 1.1573
Batch 250, Loss: 1.1142
Batch 260, Loss: 1.1875
Batch 270, Loss: 1.1804
Batch 280, Loss: 1.1650
Batch 290, Loss: 1.1882
Batch 300, Loss: 1.1760
Batch 310, Loss: 1.1378
Batch 320, Loss: 1.2066
Batch 330, Loss: 1.1460
Batch 340, Loss: 1.1458
Batch 350, Loss: 1.1808
Batch 360, Loss: 1.2135
Batch 370, Loss: 1.1654
Batch 380, Loss: 1.1711
Batch 390, Loss: 1.2082
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.266109466552734 seconds
Epoch 91 accuracy: 61.91%
Batch 10, Loss: 1.1343
Batch 20, Loss: 1.1747
Batch 30, Loss: 1.1299
Batch 40, Loss: 1.0878
Batch 50, Loss: 1.1495
Batch 60, Loss: 1.1083
Batch 70, Loss: 1.0847
Batch 80, Loss: 1.1065
Batch 90, Loss: 1.1685
Batch 100, Loss: 1.1144
Batch 110, Loss: 1.1561
Batch 120, Loss: 1.0905
Batch 130, Loss: 1.1824
Batch 140, Loss: 1.1853
Batch 150, Loss: 1.1383
Batch 160, Loss: 1.1414
Batch 170, Loss: 1.2111
Batch 180, Loss: 1.1502
Batch 190, Loss: 1.1728
Batch 200, Loss: 1.1950
Batch 210, Loss: 1.0549
Batch 220, Loss: 1.1602
Batch 230, Loss: 1.1431
Batch 240, Loss: 1.1630
Batch 250, Loss: 1.1452
Batch 260, Loss: 1.1686
Batch 270, Loss: 1.1681
Batch 280, Loss: 1.1485
Batch 290, Loss: 1.1394
Batch 300, Loss: 1.1728
Batch 310, Loss: 1.1434
Batch 320, Loss: 1.1736
Batch 330, Loss: 1.1860
Batch 340, Loss: 1.2333
Batch 350, Loss: 1.2377
Batch 360, Loss: 1.1888
Batch 370, Loss: 1.2226
Batch 380, Loss: 1.1758
Batch 390, Loss: 1.2089
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.303149700164795 seconds
Epoch 92 accuracy: 64.1%
Batch 10, Loss: 1.0892
Batch 20, Loss: 1.0853
Batch 30, Loss: 1.0851
Batch 40, Loss: 1.1087
Batch 50, Loss: 1.1032
Batch 60, Loss: 1.0142
Batch 70, Loss: 1.1178
Batch 80, Loss: 1.1182
Batch 90, Loss: 1.2040
Batch 100, Loss: 1.1295
Batch 110, Loss: 1.1384
Batch 120, Loss: 1.0959
Batch 130, Loss: 1.1600
Batch 140, Loss: 1.1486
Batch 150, Loss: 1.1505
Batch 160, Loss: 1.1406
Batch 170, Loss: 1.1518
Batch 180, Loss: 1.1853
Batch 190, Loss: 1.1953
Batch 200, Loss: 1.1086
Batch 210, Loss: 1.1435
Batch 220, Loss: 1.2112
Batch 230, Loss: 1.1625
Batch 240, Loss: 1.2210
Batch 250, Loss: 1.1383
Batch 260, Loss: 1.1323
Batch 270, Loss: 1.1611
Batch 280, Loss: 1.1764
Batch 290, Loss: 1.1947
Batch 300, Loss: 1.1273
Batch 310, Loss: 1.2014
Batch 320, Loss: 1.1614
Batch 330, Loss: 1.1680
Batch 340, Loss: 1.1340
Batch 350, Loss: 1.1596
Batch 360, Loss: 1.1511
Batch 370, Loss: 1.1385
Batch 380, Loss: 1.1384
Batch 390, Loss: 1.1110
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.208398818969727 seconds
Epoch 93 accuracy: 64.26%
Batch 10, Loss: 1.0759
Batch 20, Loss: 1.1385
Batch 30, Loss: 1.1034
Batch 40, Loss: 1.1342
Batch 50, Loss: 1.0530
Batch 60, Loss: 1.1921
Batch 70, Loss: 1.1018
Batch 80, Loss: 1.1121
Batch 90, Loss: 1.1013
Batch 100, Loss: 1.1470
Batch 110, Loss: 1.1806
Batch 120, Loss: 1.1268
Batch 130, Loss: 1.1047
Batch 140, Loss: 1.0811
Batch 150, Loss: 1.1795
Batch 160, Loss: 1.1580
Batch 170, Loss: 1.1493
Batch 180, Loss: 1.1581
Batch 190, Loss: 1.1578
Batch 200, Loss: 1.1669
Batch 210, Loss: 1.1117
Batch 220, Loss: 1.1415
Batch 230, Loss: 1.2242
Batch 240, Loss: 1.1540
Batch 250, Loss: 1.1147
Batch 260, Loss: 1.1290
Batch 270, Loss: 1.0812
Batch 280, Loss: 1.0931
Batch 290, Loss: 1.1765
Batch 300, Loss: 1.0900
Batch 310, Loss: 1.1636
Batch 320, Loss: 1.2131
Batch 330, Loss: 1.1920
Batch 340, Loss: 1.1696
Batch 350, Loss: 1.2189
Batch 360, Loss: 1.2344
Batch 370, Loss: 1.2058
Batch 380, Loss: 1.1846
Batch 390, Loss: 1.2138
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.380111932754517 seconds
Epoch 94 accuracy: 65.25%
Batch 10, Loss: 1.0952
Batch 20, Loss: 1.1362
Batch 30, Loss: 1.1094
Batch 40, Loss: 1.1302
Batch 50, Loss: 1.1398
Batch 60, Loss: 1.1350
Batch 70, Loss: 1.0717
Batch 80, Loss: 1.1255
Batch 90, Loss: 1.1131
Batch 100, Loss: 1.1513
Batch 110, Loss: 1.1568
Batch 120, Loss: 1.1310
Batch 130, Loss: 1.0882
Batch 140, Loss: 1.1114
Batch 150, Loss: 1.1059
Batch 160, Loss: 1.1007
Batch 170, Loss: 1.1192
Batch 180, Loss: 1.1220
Batch 190, Loss: 1.1523
Batch 200, Loss: 1.1328
Batch 210, Loss: 1.1383
Batch 220, Loss: 1.1253
Batch 230, Loss: 1.1122
Batch 240, Loss: 1.1407
Batch 250, Loss: 1.1747
Batch 260, Loss: 1.1539
Batch 270, Loss: 1.1354
Batch 280, Loss: 1.1813
Batch 290, Loss: 1.1951
Batch 300, Loss: 1.1208
Batch 310, Loss: 1.1728
Batch 320, Loss: 1.1608
Batch 330, Loss: 1.1434
Batch 340, Loss: 1.1759
Batch 350, Loss: 1.1507
Batch 360, Loss: 1.1698
Batch 370, Loss: 1.1668
Batch 380, Loss: 1.1668
Batch 390, Loss: 1.1846
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.402295112609863 seconds
Epoch 95 accuracy: 63.79%
Batch 10, Loss: 1.0854
Batch 20, Loss: 1.1007
Batch 30, Loss: 1.1090
Batch 40, Loss: 1.0828
Batch 50, Loss: 1.1132
Batch 60, Loss: 1.0431
Batch 70, Loss: 1.1260
Batch 80, Loss: 1.0900
Batch 90, Loss: 1.0461
Batch 100, Loss: 1.1030
Batch 110, Loss: 1.1413
Batch 120, Loss: 1.1362
Batch 130, Loss: 1.1241
Batch 140, Loss: 1.1564
Batch 150, Loss: 1.1183
Batch 160, Loss: 1.1260
Batch 170, Loss: 1.0923
Batch 180, Loss: 1.1510
Batch 190, Loss: 1.0901
Batch 200, Loss: 1.1267
Batch 210, Loss: 1.1360
Batch 220, Loss: 1.1602
Batch 230, Loss: 1.1535
Batch 240, Loss: 1.1000
Batch 250, Loss: 1.1394
Batch 260, Loss: 1.1243
Batch 270, Loss: 1.1538
Batch 280, Loss: 1.1550
Batch 290, Loss: 1.1510
Batch 300, Loss: 1.1282
Batch 310, Loss: 1.1722
Batch 320, Loss: 1.1474
Batch 330, Loss: 1.1136
Batch 340, Loss: 1.1212
Batch 350, Loss: 1.1746
Batch 360, Loss: 1.1883
Batch 370, Loss: 1.1275
Batch 380, Loss: 1.2187
Batch 390, Loss: 1.1827
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.3710355758667 seconds
Epoch 96 accuracy: 65.54%
Batch 10, Loss: 1.0720
Batch 20, Loss: 1.0875
Batch 30, Loss: 1.0910
Batch 40, Loss: 1.0840
Batch 50, Loss: 1.0350
Batch 60, Loss: 1.0595
Batch 70, Loss: 1.0388
Batch 80, Loss: 1.1088
Batch 90, Loss: 1.0996
Batch 100, Loss: 1.1440
Batch 110, Loss: 1.1209
Batch 120, Loss: 1.1572
Batch 130, Loss: 1.1263
Batch 140, Loss: 1.1462
Batch 150, Loss: 1.1380
Batch 160, Loss: 1.1199
Batch 170, Loss: 1.1406
Batch 180, Loss: 1.1602
Batch 190, Loss: 1.1007
Batch 200, Loss: 1.1762
Batch 210, Loss: 1.1414
Batch 220, Loss: 1.1375
Batch 230, Loss: 1.0870
Batch 240, Loss: 1.1079
Batch 250, Loss: 1.0824
Batch 260, Loss: 1.0859
Batch 270, Loss: 1.1670
Batch 280, Loss: 1.0806
Batch 290, Loss: 1.1531
Batch 300, Loss: 1.0412
Batch 310, Loss: 1.1977
Batch 320, Loss: 1.1044
Batch 330, Loss: 1.0867
Batch 340, Loss: 1.0749
Batch 350, Loss: 1.1542
Batch 360, Loss: 1.1344
Batch 370, Loss: 1.1411
Batch 380, Loss: 1.1792
Batch 390, Loss: 1.1646
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.393316745758057 seconds
Epoch 97 accuracy: 65.54%
Batch 10, Loss: 1.0499
Batch 20, Loss: 1.0523
Batch 30, Loss: 1.0482
Batch 40, Loss: 1.0583
Batch 50, Loss: 1.0597
Batch 60, Loss: 1.0933
Batch 70, Loss: 1.0275
Batch 80, Loss: 1.0731
Batch 90, Loss: 1.0842
Batch 100, Loss: 1.0906
Batch 110, Loss: 1.0841
Batch 120, Loss: 1.1289
Batch 130, Loss: 1.1338
Batch 140, Loss: 1.1120
Batch 150, Loss: 1.1132
Batch 160, Loss: 1.1350
Batch 170, Loss: 1.2021
Batch 180, Loss: 1.0762
Batch 190, Loss: 1.1654
Batch 200, Loss: 1.0942
Batch 210, Loss: 1.1842
Batch 220, Loss: 1.1481
Batch 230, Loss: 1.0484
Batch 240, Loss: 1.1524
Batch 250, Loss: 1.1334
Batch 260, Loss: 1.0415
Batch 270, Loss: 1.0978
Batch 280, Loss: 1.1375
Batch 290, Loss: 1.1027
Batch 300, Loss: 1.2079
Batch 310, Loss: 1.1245
Batch 320, Loss: 1.1327
Batch 330, Loss: 1.1367
Batch 340, Loss: 1.1502
Batch 350, Loss: 1.1292
Batch 360, Loss: 1.1851
Batch 370, Loss: 1.1599
Batch 380, Loss: 1.1475
Batch 390, Loss: 1.1567
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.31704831123352 seconds
Epoch 98 accuracy: 64.54%
Batch 10, Loss: 1.0517
Batch 20, Loss: 1.1179
Batch 30, Loss: 1.0863
Batch 40, Loss: 1.0969
Batch 50, Loss: 1.0821
Batch 60, Loss: 1.0056
Batch 70, Loss: 1.0760
Batch 80, Loss: 1.0970
Batch 90, Loss: 1.0598
Batch 100, Loss: 1.0894
Batch 110, Loss: 1.0499
Batch 120, Loss: 1.0788
Batch 130, Loss: 1.0656
Batch 140, Loss: 1.1264
Batch 150, Loss: 1.1316
Batch 160, Loss: 1.0439
Batch 170, Loss: 1.1323
Batch 180, Loss: 1.0912
Batch 190, Loss: 1.1644
Batch 200, Loss: 1.1282
Batch 210, Loss: 1.1171
Batch 220, Loss: 1.1116
Batch 230, Loss: 1.0921
Batch 240, Loss: 1.1028
Batch 250, Loss: 1.1086
Batch 260, Loss: 1.1228
Batch 270, Loss: 1.1605
Batch 280, Loss: 1.0793
Batch 290, Loss: 1.1362
Batch 300, Loss: 1.1179
Batch 310, Loss: 1.1416
Batch 320, Loss: 1.1410
Batch 330, Loss: 1.1522
Batch 340, Loss: 1.0785
Batch 350, Loss: 1.0782
Batch 360, Loss: 1.0550
Batch 370, Loss: 1.1301
Batch 380, Loss: 1.1387
Batch 390, Loss: 1.1451
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.331909894943237 seconds
Epoch 99 accuracy: 65.15%
Batch 10, Loss: 1.1351
Batch 20, Loss: 1.0380
Batch 30, Loss: 1.1128
Batch 40, Loss: 1.0254
Batch 50, Loss: 1.0329
Batch 60, Loss: 0.9872
Batch 70, Loss: 1.0892
Batch 80, Loss: 1.0199
Batch 90, Loss: 1.0750
Batch 100, Loss: 1.1126
Batch 110, Loss: 1.1164
Batch 120, Loss: 1.0784
Batch 130, Loss: 1.0601
Batch 140, Loss: 1.0912
Batch 150, Loss: 1.0749
Batch 160, Loss: 1.0722
Batch 170, Loss: 1.0890
Batch 180, Loss: 1.0828
Batch 190, Loss: 1.0808
Batch 200, Loss: 1.0663
Batch 210, Loss: 1.0631
Batch 220, Loss: 1.1024
Batch 230, Loss: 1.1363
Batch 240, Loss: 1.0936
Batch 250, Loss: 1.1234
Batch 260, Loss: 1.0642
Batch 270, Loss: 1.0911
Batch 280, Loss: 1.0814
Batch 290, Loss: 1.1405
Batch 300, Loss: 1.1204
Batch 310, Loss: 1.0943
Batch 320, Loss: 1.0898
Batch 330, Loss: 1.1197
Batch 340, Loss: 1.1347
Batch 350, Loss: 1.1436
Batch 360, Loss: 1.1165
Batch 370, Loss: 1.1281
Batch 380, Loss: 1.1790
Batch 390, Loss: 1.1371
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.321576595306396 seconds
Epoch 100 accuracy: 64.86%
Batch 10, Loss: 1.0865
Batch 20, Loss: 1.1078
Batch 30, Loss: 1.1195
Batch 40, Loss: 1.0804
Batch 50, Loss: 1.0593
Batch 60, Loss: 1.0462
Batch 70, Loss: 1.0352
Batch 80, Loss: 1.0455
Batch 90, Loss: 1.0077
Batch 100, Loss: 0.9535
Batch 110, Loss: 1.0674
Batch 120, Loss: 1.0334
Batch 130, Loss: 1.0594
Batch 140, Loss: 1.1136
Batch 150, Loss: 1.0808
Batch 160, Loss: 1.0902
Batch 170, Loss: 1.1177
Batch 180, Loss: 1.0521
Batch 190, Loss: 1.0915
Batch 200, Loss: 1.0929
Batch 210, Loss: 1.0976
Batch 220, Loss: 1.0876
Batch 230, Loss: 1.0705
Batch 240, Loss: 1.0609
Batch 250, Loss: 1.1032
Batch 260, Loss: 1.1565
Batch 270, Loss: 1.0695
Batch 280, Loss: 1.0863
Batch 290, Loss: 1.1007
Batch 300, Loss: 1.1076
Batch 310, Loss: 1.0869
Batch 320, Loss: 1.0576
Batch 330, Loss: 1.1360
Batch 340, Loss: 1.0331
Batch 350, Loss: 1.1662
Batch 360, Loss: 1.1397
Batch 370, Loss: 1.1153
Batch 380, Loss: 1.0998
Batch 390, Loss: 1.1008
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.186708450317383 seconds
Epoch 101 accuracy: 64.37%
Batch 10, Loss: 1.0180
Batch 20, Loss: 1.0378
Batch 30, Loss: 1.0916
Batch 40, Loss: 1.0107
Batch 50, Loss: 1.0029
Batch 60, Loss: 1.0247
Batch 70, Loss: 1.0634
Batch 80, Loss: 1.0338
Batch 90, Loss: 1.0270
Batch 100, Loss: 1.0566
Batch 110, Loss: 1.0665
Batch 120, Loss: 1.0872
Batch 130, Loss: 1.0723
Batch 140, Loss: 1.1326
Batch 150, Loss: 1.0767
Batch 160, Loss: 1.0602
Batch 170, Loss: 1.0721
Batch 180, Loss: 1.0920
Batch 190, Loss: 1.1232
Batch 200, Loss: 1.0555
Batch 210, Loss: 1.0859
Batch 220, Loss: 1.1142
Batch 230, Loss: 1.1228
Batch 240, Loss: 1.0839
Batch 250, Loss: 1.1104
Batch 260, Loss: 1.0957
Batch 270, Loss: 1.0881
Batch 280, Loss: 1.0565
Batch 290, Loss: 1.1093
Batch 300, Loss: 1.0951
Batch 310, Loss: 1.1367
Batch 320, Loss: 1.1306
Batch 330, Loss: 1.1213
Batch 340, Loss: 1.0972
Batch 350, Loss: 1.1453
Batch 360, Loss: 1.0624
Batch 370, Loss: 1.1069
Batch 380, Loss: 1.1191
Batch 390, Loss: 1.1203
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.298216819763184 seconds
Epoch 102 accuracy: 65.95%
Batch 10, Loss: 0.9886
Batch 20, Loss: 1.0447
Batch 30, Loss: 1.0068
Batch 40, Loss: 1.0513
Batch 50, Loss: 1.0094
Batch 60, Loss: 1.0221
Batch 70, Loss: 1.0898
Batch 80, Loss: 1.0820
Batch 90, Loss: 1.0469
Batch 100, Loss: 1.0147
Batch 110, Loss: 1.0236
Batch 120, Loss: 1.0907
Batch 130, Loss: 1.0054
Batch 140, Loss: 1.0405
Batch 150, Loss: 1.0811
Batch 160, Loss: 1.0059
Batch 170, Loss: 1.0934
Batch 180, Loss: 1.0708
Batch 190, Loss: 1.0555
Batch 200, Loss: 1.0038
Batch 210, Loss: 1.0890
Batch 220, Loss: 0.9918
Batch 230, Loss: 1.1745
Batch 240, Loss: 1.1044
Batch 250, Loss: 1.1321
Batch 260, Loss: 1.1061
Batch 270, Loss: 1.0883
Batch 280, Loss: 1.1030
Batch 290, Loss: 1.0782
Batch 300, Loss: 1.1071
Batch 310, Loss: 1.0716
Batch 320, Loss: 1.0956
Batch 330, Loss: 1.0630
Batch 340, Loss: 1.0518
Batch 350, Loss: 1.0538
Batch 360, Loss: 1.0586
Batch 370, Loss: 1.0779
Batch 380, Loss: 1.0862
Batch 390, Loss: 1.0915
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.308465480804443 seconds
Epoch 103 accuracy: 64.11%
Batch 10, Loss: 0.9947
Batch 20, Loss: 0.9706
Batch 30, Loss: 1.0326
Batch 40, Loss: 0.9984
Batch 50, Loss: 0.9714
Batch 60, Loss: 1.0118
Batch 70, Loss: 1.0696
Batch 80, Loss: 1.0567
Batch 90, Loss: 1.0679
Batch 100, Loss: 1.0582
Batch 110, Loss: 1.0020
Batch 120, Loss: 1.0187
Batch 130, Loss: 1.0163
Batch 140, Loss: 1.1118
Batch 150, Loss: 1.0968
Batch 160, Loss: 1.0384
Batch 170, Loss: 1.0443
Batch 180, Loss: 1.0706
Batch 190, Loss: 1.0387
Batch 200, Loss: 1.0516
Batch 210, Loss: 1.0595
Batch 220, Loss: 1.0754
Batch 230, Loss: 1.0344
Batch 240, Loss: 1.1282
Batch 250, Loss: 1.0593
Batch 260, Loss: 1.0539
Batch 270, Loss: 1.1235
Batch 280, Loss: 1.1390
Batch 290, Loss: 1.1574
Batch 300, Loss: 1.0238
Batch 310, Loss: 1.1064
Batch 320, Loss: 1.1022
Batch 330, Loss: 1.1236
Batch 340, Loss: 1.1067
Batch 350, Loss: 1.0851
Batch 360, Loss: 1.1418
Batch 370, Loss: 1.0981
Batch 380, Loss: 1.0784
Batch 390, Loss: 1.1554
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.358356952667236 seconds
Epoch 104 accuracy: 66.36%
Batch 10, Loss: 1.0307
Batch 20, Loss: 1.0236
Batch 30, Loss: 1.0204
Batch 40, Loss: 1.0461
Batch 50, Loss: 1.0152
Batch 60, Loss: 1.0058
Batch 70, Loss: 1.0472
Batch 80, Loss: 1.0282
Batch 90, Loss: 1.0259
Batch 100, Loss: 1.0570
Batch 110, Loss: 1.1372
Batch 120, Loss: 1.0950
Batch 130, Loss: 0.9905
Batch 140, Loss: 1.0743
Batch 150, Loss: 1.0173
Batch 160, Loss: 1.0429
Batch 170, Loss: 1.0356
Batch 180, Loss: 1.0168
Batch 190, Loss: 1.0025
Batch 200, Loss: 1.0881
Batch 210, Loss: 1.0336
Batch 220, Loss: 1.0928
Batch 230, Loss: 1.1254
Batch 240, Loss: 1.0593
Batch 250, Loss: 1.0483
Batch 260, Loss: 1.0767
Batch 270, Loss: 1.0963
Batch 280, Loss: 1.0354
Batch 290, Loss: 1.0658
Batch 300, Loss: 1.0278
Batch 310, Loss: 1.0920
Batch 320, Loss: 1.0477
Batch 330, Loss: 1.1360
Batch 340, Loss: 1.0076
Batch 350, Loss: 1.0765
Batch 360, Loss: 1.0561
Batch 370, Loss: 1.1135
Batch 380, Loss: 1.0950
Batch 390, Loss: 1.0984
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.24733257293701 seconds
Epoch 105 accuracy: 66.54%
Batch 10, Loss: 1.0045
Batch 20, Loss: 1.0406
Batch 30, Loss: 1.0648
Batch 40, Loss: 0.9661
Batch 50, Loss: 1.0139
Batch 60, Loss: 0.9836
Batch 70, Loss: 1.0265
Batch 80, Loss: 1.0627
Batch 90, Loss: 1.0970
Batch 100, Loss: 1.0308
Batch 110, Loss: 1.0035
Batch 120, Loss: 0.9887
Batch 130, Loss: 1.0121
Batch 140, Loss: 1.0603
Batch 150, Loss: 1.0690
Batch 160, Loss: 1.1119
Batch 170, Loss: 1.0382
Batch 180, Loss: 1.0385
Batch 190, Loss: 1.0411
Batch 200, Loss: 1.0825
Batch 210, Loss: 1.0136
Batch 220, Loss: 1.0802
Batch 230, Loss: 1.0200
Batch 240, Loss: 1.0808
Batch 250, Loss: 1.0342
Batch 260, Loss: 1.0186
Batch 270, Loss: 1.0462
Batch 280, Loss: 1.1069
Batch 290, Loss: 1.0738
Batch 300, Loss: 1.0641
Batch 310, Loss: 1.0856
Batch 320, Loss: 1.0914
Batch 330, Loss: 1.0998
Batch 340, Loss: 1.0918
Batch 350, Loss: 1.0427
Batch 360, Loss: 1.0711
Batch 370, Loss: 1.1172
Batch 380, Loss: 1.0517
Batch 390, Loss: 1.0944
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.286584615707397 seconds
Epoch 106 accuracy: 66.21%
Batch 10, Loss: 1.0010
Batch 20, Loss: 0.9602
Batch 30, Loss: 0.9980
Batch 40, Loss: 0.9872
Batch 50, Loss: 0.9569
Batch 60, Loss: 1.0509
Batch 70, Loss: 1.0743
Batch 80, Loss: 1.0190
Batch 90, Loss: 1.0319
Batch 100, Loss: 0.9958
Batch 110, Loss: 1.0202
Batch 120, Loss: 0.9907
Batch 130, Loss: 1.0534
Batch 140, Loss: 1.0259
Batch 150, Loss: 1.0248
Batch 160, Loss: 1.0698
Batch 170, Loss: 1.0011
Batch 180, Loss: 1.0167
Batch 190, Loss: 1.0500
Batch 200, Loss: 1.0538
Batch 210, Loss: 1.0204
Batch 220, Loss: 1.0069
Batch 230, Loss: 1.0067
Batch 240, Loss: 0.9966
Batch 250, Loss: 1.0805
Batch 260, Loss: 1.0935
Batch 270, Loss: 1.0399
Batch 280, Loss: 1.0962
Batch 290, Loss: 1.0073
Batch 300, Loss: 1.0487
Batch 310, Loss: 1.0341
Batch 320, Loss: 1.0497
Batch 330, Loss: 1.0998
Batch 340, Loss: 1.1011
Batch 350, Loss: 1.1019
Batch 360, Loss: 1.0619
Batch 370, Loss: 1.0101
Batch 380, Loss: 1.0365
Batch 390, Loss: 1.0301
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.214808702468872 seconds
Epoch 107 accuracy: 67.41%
Batch 10, Loss: 0.9944
Batch 20, Loss: 0.9854
Batch 30, Loss: 1.0310
Batch 40, Loss: 0.9681
Batch 50, Loss: 0.9814
Batch 60, Loss: 1.0187
Batch 70, Loss: 1.0172
Batch 80, Loss: 0.9544
Batch 90, Loss: 0.9856
Batch 100, Loss: 1.0037
Batch 110, Loss: 1.0279
Batch 120, Loss: 1.0754
Batch 130, Loss: 1.0377
Batch 140, Loss: 0.9630
Batch 150, Loss: 0.9946
Batch 160, Loss: 1.0058
Batch 170, Loss: 0.9349
Batch 180, Loss: 1.0226
Batch 190, Loss: 1.0155
Batch 200, Loss: 0.9983
Batch 210, Loss: 1.0003
Batch 220, Loss: 1.0877
Batch 230, Loss: 1.0692
Batch 240, Loss: 1.0695
Batch 250, Loss: 1.0253
Batch 260, Loss: 1.0210
Batch 270, Loss: 1.0473
Batch 280, Loss: 1.0657
Batch 290, Loss: 1.0779
Batch 300, Loss: 1.1082
Batch 310, Loss: 1.0707
Batch 320, Loss: 1.0660
Batch 330, Loss: 1.0794
Batch 340, Loss: 1.0411
Batch 350, Loss: 1.0380
Batch 360, Loss: 1.0759
Batch 370, Loss: 1.0366
Batch 380, Loss: 1.0031
Batch 390, Loss: 1.0483
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.3684401512146 seconds
Epoch 108 accuracy: 65.24%
Batch 10, Loss: 0.9401
Batch 20, Loss: 0.9572
Batch 30, Loss: 1.0464
Batch 40, Loss: 1.0017
Batch 50, Loss: 1.0522
Batch 60, Loss: 0.9887
Batch 70, Loss: 0.9792
Batch 80, Loss: 1.0227
Batch 90, Loss: 1.0125
Batch 100, Loss: 1.0333
Batch 110, Loss: 1.0527
Batch 120, Loss: 0.9987
Batch 130, Loss: 1.0080
Batch 140, Loss: 0.9900
Batch 150, Loss: 1.0059
Batch 160, Loss: 0.9971
Batch 170, Loss: 1.0120
Batch 180, Loss: 1.0449
Batch 190, Loss: 1.0527
Batch 200, Loss: 1.0236
Batch 210, Loss: 0.9842
Batch 220, Loss: 1.0466
Batch 230, Loss: 1.0688
Batch 240, Loss: 1.0763
Batch 250, Loss: 1.0414
Batch 260, Loss: 1.0152
Batch 270, Loss: 1.1406
Batch 280, Loss: 1.0411
Batch 290, Loss: 1.0217
Batch 300, Loss: 1.0563
Batch 310, Loss: 0.9932
Batch 320, Loss: 1.0520
Batch 330, Loss: 1.0180
Batch 340, Loss: 1.0520
Batch 350, Loss: 1.0818
Batch 360, Loss: 1.0302
Batch 370, Loss: 1.0483
Batch 380, Loss: 1.0562
Batch 390, Loss: 1.0079
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.39335346221924 seconds
Epoch 109 accuracy: 68.25%
Batch 10, Loss: 0.9433
Batch 20, Loss: 0.9886
Batch 30, Loss: 0.9503
Batch 40, Loss: 0.9737
Batch 50, Loss: 0.9178
Batch 60, Loss: 1.0038
Batch 70, Loss: 1.0186
Batch 80, Loss: 0.9417
Batch 90, Loss: 0.9856
Batch 100, Loss: 0.9733
Batch 110, Loss: 0.9417
Batch 120, Loss: 0.9917
Batch 130, Loss: 0.9896
Batch 140, Loss: 1.0817
Batch 150, Loss: 1.0060
Batch 160, Loss: 0.9999
Batch 170, Loss: 1.0886
Batch 180, Loss: 0.9399
Batch 190, Loss: 1.0339
Batch 200, Loss: 0.9455
Batch 210, Loss: 1.0348
Batch 220, Loss: 1.0214
Batch 230, Loss: 1.0118
Batch 240, Loss: 1.0225
Batch 250, Loss: 1.0611
Batch 260, Loss: 0.9916
Batch 270, Loss: 1.0244
Batch 280, Loss: 1.0497
Batch 290, Loss: 1.0601
Batch 300, Loss: 0.9772
Batch 310, Loss: 1.0463
Batch 320, Loss: 1.0236
Batch 330, Loss: 1.0778
Batch 340, Loss: 1.0573
Batch 350, Loss: 1.0733
Batch 360, Loss: 1.0328
Batch 370, Loss: 1.0373
Batch 380, Loss: 1.0020
Batch 390, Loss: 1.0186
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.38392472267151 seconds
Epoch 110 accuracy: 63.66%
Batch 10, Loss: 1.0073
Batch 20, Loss: 0.9642
Batch 30, Loss: 1.0005
Batch 40, Loss: 0.9465
Batch 50, Loss: 0.9614
Batch 60, Loss: 0.9001
Batch 70, Loss: 1.0078
Batch 80, Loss: 0.9597
Batch 90, Loss: 0.9871
Batch 100, Loss: 0.9885
Batch 110, Loss: 0.9951
Batch 120, Loss: 1.0279
Batch 130, Loss: 0.9322
Batch 140, Loss: 1.0187
Batch 150, Loss: 0.9562
Batch 160, Loss: 0.9767
Batch 170, Loss: 1.0076
Batch 180, Loss: 0.9834
Batch 190, Loss: 0.9818
Batch 200, Loss: 0.9763
Batch 210, Loss: 0.9829
Batch 220, Loss: 1.0647
Batch 230, Loss: 0.9731
Batch 240, Loss: 0.9704
Batch 250, Loss: 1.0182
Batch 260, Loss: 1.0293
Batch 270, Loss: 1.0616
Batch 280, Loss: 1.0232
Batch 290, Loss: 0.9735
Batch 300, Loss: 1.0110
Batch 310, Loss: 1.0361
Batch 320, Loss: 1.0460
Batch 330, Loss: 0.9937
Batch 340, Loss: 1.0061
Batch 350, Loss: 1.0516
Batch 360, Loss: 1.0430
Batch 370, Loss: 1.0440
Batch 380, Loss: 1.0488
Batch 390, Loss: 1.0455
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.220717906951904 seconds
Epoch 111 accuracy: 66.65%
Batch 10, Loss: 0.9532
Batch 20, Loss: 0.9421
Batch 30, Loss: 1.0006
Batch 40, Loss: 1.0277
Batch 50, Loss: 0.9209
Batch 60, Loss: 0.8924
Batch 70, Loss: 1.0401
Batch 80, Loss: 0.9654
Batch 90, Loss: 0.9619
Batch 100, Loss: 0.9539
Batch 110, Loss: 0.9691
Batch 120, Loss: 1.0103
Batch 130, Loss: 1.0629
Batch 140, Loss: 0.9771
Batch 150, Loss: 1.0030
Batch 160, Loss: 0.9678
Batch 170, Loss: 1.0143
Batch 180, Loss: 1.0416
Batch 190, Loss: 0.9969
Batch 200, Loss: 1.0484
Batch 210, Loss: 1.0843
Batch 220, Loss: 0.9763
Batch 230, Loss: 1.0583
Batch 240, Loss: 0.9840
Batch 250, Loss: 1.0160
Batch 260, Loss: 1.0292
Batch 270, Loss: 1.0402
Batch 280, Loss: 0.9744
Batch 290, Loss: 1.0638
Batch 300, Loss: 1.0033
Batch 310, Loss: 1.0284
Batch 320, Loss: 1.0739
Batch 330, Loss: 1.0112
Batch 340, Loss: 1.0190
Batch 350, Loss: 0.9917
Batch 360, Loss: 1.0201
Batch 370, Loss: 1.0781
Batch 380, Loss: 1.0309
Batch 390, Loss: 1.0371
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.336008548736572 seconds
Epoch 112 accuracy: 66.55%
Batch 10, Loss: 0.9803
Batch 20, Loss: 1.0157
Batch 30, Loss: 0.9295
Batch 40, Loss: 0.9279
Batch 50, Loss: 0.9596
Batch 60, Loss: 0.9722
Batch 70, Loss: 0.9714
Batch 80, Loss: 0.9067
Batch 90, Loss: 0.9620
Batch 100, Loss: 0.9335
Batch 110, Loss: 0.9940
Batch 120, Loss: 0.9792
Batch 130, Loss: 0.9893
Batch 140, Loss: 0.9218
Batch 150, Loss: 0.9876
Batch 160, Loss: 0.9893
Batch 170, Loss: 1.0386
Batch 180, Loss: 0.9990
Batch 190, Loss: 0.9585
Batch 200, Loss: 0.9531
Batch 210, Loss: 1.0177
Batch 220, Loss: 1.0351
Batch 230, Loss: 1.0149
Batch 240, Loss: 0.9685
Batch 250, Loss: 1.0124
Batch 260, Loss: 1.0015
Batch 270, Loss: 0.9917
Batch 280, Loss: 0.9807
Batch 290, Loss: 1.0077
Batch 300, Loss: 0.9820
Batch 310, Loss: 1.0100
Batch 320, Loss: 0.9959
Batch 330, Loss: 0.9756
Batch 340, Loss: 0.9793
Batch 350, Loss: 1.0706
Batch 360, Loss: 1.0117
Batch 370, Loss: 1.0754
Batch 380, Loss: 1.0190
Batch 390, Loss: 0.9565
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.298583984375 seconds
Epoch 113 accuracy: 68.85%
Batch 10, Loss: 0.9087
Batch 20, Loss: 0.9358
Batch 30, Loss: 0.9897
Batch 40, Loss: 0.8922
Batch 50, Loss: 0.9939
Batch 60, Loss: 0.9333
Batch 70, Loss: 0.9473
Batch 80, Loss: 0.9692
Batch 90, Loss: 0.9332
Batch 100, Loss: 0.9812
Batch 110, Loss: 0.9346
Batch 120, Loss: 0.9805
Batch 130, Loss: 0.9134
Batch 140, Loss: 0.9620
Batch 150, Loss: 0.9834
Batch 160, Loss: 0.9603
Batch 170, Loss: 0.9328
Batch 180, Loss: 0.9523
Batch 190, Loss: 1.0069
Batch 200, Loss: 0.9335
Batch 210, Loss: 1.0813
Batch 220, Loss: 0.9821
Batch 230, Loss: 0.9868
Batch 240, Loss: 1.0022
Batch 250, Loss: 1.0046
Batch 260, Loss: 1.0264
Batch 270, Loss: 0.9624
Batch 280, Loss: 0.9933
Batch 290, Loss: 1.0526
Batch 300, Loss: 1.0039
Batch 310, Loss: 0.9852
Batch 320, Loss: 0.9572
Batch 330, Loss: 0.9877
Batch 340, Loss: 0.9706
Batch 350, Loss: 0.9995
Batch 360, Loss: 0.9982
Batch 370, Loss: 1.0044
Batch 380, Loss: 1.0163
Batch 390, Loss: 1.0061
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.305598258972168 seconds
Epoch 114 accuracy: 69.85%
Batch 10, Loss: 0.9438
Batch 20, Loss: 0.9649
Batch 30, Loss: 0.9480
Batch 40, Loss: 0.9054
Batch 50, Loss: 0.9167
Batch 60, Loss: 0.9005
Batch 70, Loss: 0.9064
Batch 80, Loss: 0.8653
Batch 90, Loss: 0.9198
Batch 100, Loss: 0.9518
Batch 110, Loss: 0.9684
Batch 120, Loss: 0.9144
Batch 130, Loss: 0.9547
Batch 140, Loss: 0.9525
Batch 150, Loss: 1.0035
Batch 160, Loss: 0.9525
Batch 170, Loss: 0.9374
Batch 180, Loss: 0.9986
Batch 190, Loss: 0.9155
Batch 200, Loss: 0.9831
Batch 210, Loss: 0.9939
Batch 220, Loss: 0.9754
Batch 230, Loss: 0.9871
Batch 240, Loss: 0.9986
Batch 250, Loss: 1.0226
Batch 260, Loss: 0.9759
Batch 270, Loss: 1.0166
Batch 280, Loss: 0.9891
Batch 290, Loss: 0.9606
Batch 300, Loss: 0.9769
Batch 310, Loss: 0.9849
Batch 320, Loss: 0.9958
Batch 330, Loss: 0.9718
Batch 340, Loss: 0.9800
Batch 350, Loss: 1.0370
Batch 360, Loss: 0.9943
Batch 370, Loss: 1.0604
Batch 380, Loss: 1.0287
Batch 390, Loss: 0.9875
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.23104977607727 seconds
Epoch 115 accuracy: 68.67%
Batch 10, Loss: 0.9522
Batch 20, Loss: 0.9077
Batch 30, Loss: 0.9242
Batch 40, Loss: 0.9131
Batch 50, Loss: 0.8788
Batch 60, Loss: 0.9122
Batch 70, Loss: 0.8403
Batch 80, Loss: 0.9078
Batch 90, Loss: 0.9169
Batch 100, Loss: 0.9068
Batch 110, Loss: 0.9368
Batch 120, Loss: 1.0032
Batch 130, Loss: 0.9869
Batch 140, Loss: 0.9428
Batch 150, Loss: 0.9265
Batch 160, Loss: 0.9631
Batch 170, Loss: 1.0220
Batch 180, Loss: 0.9642
Batch 190, Loss: 0.9878
Batch 200, Loss: 0.9710
Batch 210, Loss: 0.9456
Batch 220, Loss: 1.0061
Batch 230, Loss: 0.9985
Batch 240, Loss: 0.9728
Batch 250, Loss: 1.0149
Batch 260, Loss: 0.9369
Batch 270, Loss: 0.9777
Batch 280, Loss: 0.9882
Batch 290, Loss: 1.0496
Batch 300, Loss: 0.9826
Batch 310, Loss: 1.0505
Batch 320, Loss: 0.9693
Batch 330, Loss: 0.9681
Batch 340, Loss: 0.9726
Batch 350, Loss: 0.9810
Batch 360, Loss: 0.9788
Batch 370, Loss: 0.9622
Batch 380, Loss: 1.0068
Batch 390, Loss: 1.0118
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.31205415725708 seconds
Epoch 116 accuracy: 68.03%
Batch 10, Loss: 0.9146
Batch 20, Loss: 0.9320
Batch 30, Loss: 0.8827
Batch 40, Loss: 0.9284
Batch 50, Loss: 0.9083
Batch 60, Loss: 0.9194
Batch 70, Loss: 0.9301
Batch 80, Loss: 0.9869
Batch 90, Loss: 0.8908
Batch 100, Loss: 0.9952
Batch 110, Loss: 0.9600
Batch 120, Loss: 0.9078
Batch 130, Loss: 0.9689
Batch 140, Loss: 0.9445
Batch 150, Loss: 0.9543
Batch 160, Loss: 0.9831
Batch 170, Loss: 0.9547
Batch 180, Loss: 0.9123
Batch 190, Loss: 0.9808
Batch 200, Loss: 0.9553
Batch 210, Loss: 0.9191
Batch 220, Loss: 0.9206
Batch 230, Loss: 0.9789
Batch 240, Loss: 0.9879
Batch 250, Loss: 0.9785
Batch 260, Loss: 0.9816
Batch 270, Loss: 0.9382
Batch 280, Loss: 0.9321
Batch 290, Loss: 0.9522
Batch 300, Loss: 1.0036
Batch 310, Loss: 0.9246
Batch 320, Loss: 0.9353
Batch 330, Loss: 0.9652
Batch 340, Loss: 0.9591
Batch 350, Loss: 0.9997
Batch 360, Loss: 0.9955
Batch 370, Loss: 1.0167
Batch 380, Loss: 1.0168
Batch 390, Loss: 1.0244
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.315653800964355 seconds
Epoch 117 accuracy: 67.11%
Batch 10, Loss: 0.8714
Batch 20, Loss: 0.9183
Batch 30, Loss: 0.8596
Batch 40, Loss: 0.9079
Batch 50, Loss: 0.9693
Batch 60, Loss: 0.8361
Batch 70, Loss: 0.9066
Batch 80, Loss: 0.9288
Batch 90, Loss: 0.9138
Batch 100, Loss: 0.9012
Batch 110, Loss: 0.9222
Batch 120, Loss: 0.8672
Batch 130, Loss: 0.8834
Batch 140, Loss: 0.9253
Batch 150, Loss: 0.9438
Batch 160, Loss: 0.9096
Batch 170, Loss: 0.9390
Batch 180, Loss: 0.9060
Batch 190, Loss: 0.9648
Batch 200, Loss: 0.9770
Batch 210, Loss: 0.9692
Batch 220, Loss: 0.9883
Batch 230, Loss: 0.9752
Batch 240, Loss: 0.9868
Batch 250, Loss: 0.9373
Batch 260, Loss: 0.9359
Batch 270, Loss: 0.9095
Batch 280, Loss: 0.8772
Batch 290, Loss: 0.9717
Batch 300, Loss: 0.9181
Batch 310, Loss: 0.9810
Batch 320, Loss: 0.9648
Batch 330, Loss: 0.9797
Batch 340, Loss: 0.9819
Batch 350, Loss: 0.9517
Batch 360, Loss: 0.9889
Batch 370, Loss: 0.9423
Batch 380, Loss: 0.9740
Batch 390, Loss: 0.9406
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.40664052963257 seconds
Epoch 118 accuracy: 70.55%
Batch 10, Loss: 0.8765
Batch 20, Loss: 0.8942
Batch 30, Loss: 0.9305
Batch 40, Loss: 0.9018
Batch 50, Loss: 0.8539
Batch 60, Loss: 0.9437
Batch 70, Loss: 0.9197
Batch 80, Loss: 0.9132
Batch 90, Loss: 0.8608
Batch 100, Loss: 0.8464
Batch 110, Loss: 0.9305
Batch 120, Loss: 0.9263
Batch 130, Loss: 0.9206
Batch 140, Loss: 0.9318
Batch 150, Loss: 0.9061
Batch 160, Loss: 0.9115
Batch 170, Loss: 0.9083
Batch 180, Loss: 0.9237
Batch 190, Loss: 0.9591
Batch 200, Loss: 0.9317
Batch 210, Loss: 0.9613
Batch 220, Loss: 0.9835
Batch 230, Loss: 0.9441
Batch 240, Loss: 1.0096
Batch 250, Loss: 0.9488
Batch 260, Loss: 0.9166
Batch 270, Loss: 0.9496
Batch 280, Loss: 0.9425
Batch 290, Loss: 0.9527
Batch 300, Loss: 1.0202
Batch 310, Loss: 0.9770
Batch 320, Loss: 1.0071
Batch 330, Loss: 0.9083
Batch 340, Loss: 0.9098
Batch 350, Loss: 0.9431
Batch 360, Loss: 0.9530
Batch 370, Loss: 0.9440
Batch 380, Loss: 0.9930
Batch 390, Loss: 0.9267
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.20814609527588 seconds
Epoch 119 accuracy: 68.46%
Batch 10, Loss: 0.8727
Batch 20, Loss: 0.8496
Batch 30, Loss: 0.8142
Batch 40, Loss: 0.8541
Batch 50, Loss: 0.8639
Batch 60, Loss: 0.8866
Batch 70, Loss: 0.9164
Batch 80, Loss: 0.8738
Batch 90, Loss: 0.9122
Batch 100, Loss: 0.9098
Batch 110, Loss: 0.9456
Batch 120, Loss: 0.8885
Batch 130, Loss: 0.8876
Batch 140, Loss: 0.8502
Batch 150, Loss: 0.9085
Batch 160, Loss: 0.8660
Batch 170, Loss: 0.9075
Batch 180, Loss: 0.9018
Batch 190, Loss: 0.8563
Batch 200, Loss: 0.9381
Batch 210, Loss: 0.9234
Batch 220, Loss: 0.8708
Batch 230, Loss: 0.8661
Batch 240, Loss: 0.8927
Batch 250, Loss: 0.8728
Batch 260, Loss: 0.9125
Batch 270, Loss: 0.9469
Batch 280, Loss: 0.9851
Batch 290, Loss: 0.9869
Batch 300, Loss: 0.9346
Batch 310, Loss: 0.9793
Batch 320, Loss: 0.9532
Batch 330, Loss: 0.9714
Batch 340, Loss: 0.9800
Batch 350, Loss: 0.9703
Batch 360, Loss: 0.9558
Batch 370, Loss: 0.9556
Batch 380, Loss: 0.9244
Batch 390, Loss: 0.9997
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.46076798439026 seconds
Epoch 120 accuracy: 67.97%
Batch 10, Loss: 0.8647
Batch 20, Loss: 0.9233
Batch 30, Loss: 0.9178
Batch 40, Loss: 0.8541
Batch 50, Loss: 0.8780
Batch 60, Loss: 0.9104
Batch 70, Loss: 0.8917
Batch 80, Loss: 0.9035
Batch 90, Loss: 0.8704
Batch 100, Loss: 0.8339
Batch 110, Loss: 0.8491
Batch 120, Loss: 0.8823
Batch 130, Loss: 0.8670
Batch 140, Loss: 0.9466
Batch 150, Loss: 0.8814
Batch 160, Loss: 0.9087
Batch 170, Loss: 0.9225
Batch 180, Loss: 0.9269
Batch 190, Loss: 0.8916
Batch 200, Loss: 0.9970
Batch 210, Loss: 0.9019
Batch 220, Loss: 0.9207
Batch 230, Loss: 0.8706
Batch 240, Loss: 0.9622
Batch 250, Loss: 0.9364
Batch 260, Loss: 0.8821
Batch 270, Loss: 0.9311
Batch 280, Loss: 0.9139
Batch 290, Loss: 0.9018
Batch 300, Loss: 1.0106
Batch 310, Loss: 0.9533
Batch 320, Loss: 0.9034
Batch 330, Loss: 0.9385
Batch 340, Loss: 0.8840
Batch 350, Loss: 0.9567
Batch 360, Loss: 0.9221
Batch 370, Loss: 0.8875
Batch 380, Loss: 0.9876
Batch 390, Loss: 0.9725
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.411422967910767 seconds
Epoch 121 accuracy: 69.34%
Batch 10, Loss: 0.8566
Batch 20, Loss: 0.9232
Batch 30, Loss: 0.8203
Batch 40, Loss: 0.8685
Batch 50, Loss: 0.8549
Batch 60, Loss: 0.9034
Batch 70, Loss: 0.8745
Batch 80, Loss: 0.8728
Batch 90, Loss: 0.8188
Batch 100, Loss: 0.8516
Batch 110, Loss: 0.8938
Batch 120, Loss: 0.8494
Batch 130, Loss: 0.9451
Batch 140, Loss: 0.8681
Batch 150, Loss: 0.8943
Batch 160, Loss: 0.9417
Batch 170, Loss: 0.8696
Batch 180, Loss: 0.9187
Batch 190, Loss: 0.8848
Batch 200, Loss: 0.9310
Batch 210, Loss: 0.9181
Batch 220, Loss: 0.8741
Batch 230, Loss: 0.9104
Batch 240, Loss: 0.9815
Batch 250, Loss: 0.8874
Batch 260, Loss: 0.9204
Batch 270, Loss: 0.9317
Batch 280, Loss: 0.9097
Batch 290, Loss: 0.9488
Batch 300, Loss: 0.9131
Batch 310, Loss: 0.9088
Batch 320, Loss: 0.9008
Batch 330, Loss: 0.9366
Batch 340, Loss: 0.9366
Batch 350, Loss: 0.9049
Batch 360, Loss: 0.9754
Batch 370, Loss: 0.9058
Batch 380, Loss: 0.9159
Batch 390, Loss: 0.9339
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.295166730880737 seconds
Epoch 122 accuracy: 67.22%
Batch 10, Loss: 0.8750
Batch 20, Loss: 0.9082
Batch 30, Loss: 0.8271
Batch 40, Loss: 0.8626
Batch 50, Loss: 0.8504
Batch 60, Loss: 0.8368
Batch 70, Loss: 0.7753
Batch 80, Loss: 0.8879
Batch 90, Loss: 0.8906
Batch 100, Loss: 0.8562
Batch 110, Loss: 0.8106
Batch 120, Loss: 0.8803
Batch 130, Loss: 0.8565
Batch 140, Loss: 0.8978
Batch 150, Loss: 0.8597
Batch 160, Loss: 0.8591
Batch 170, Loss: 0.9048
Batch 180, Loss: 0.8810
Batch 190, Loss: 0.9532
Batch 200, Loss: 0.8838
Batch 210, Loss: 0.9046
Batch 220, Loss: 0.8443
Batch 230, Loss: 0.9699
Batch 240, Loss: 0.9378
Batch 250, Loss: 0.9042
Batch 260, Loss: 0.9376
Batch 270, Loss: 0.8775
Batch 280, Loss: 0.8990
Batch 290, Loss: 0.8757
Batch 300, Loss: 0.9046
Batch 310, Loss: 0.9256
Batch 320, Loss: 0.9258
Batch 330, Loss: 0.8734
Batch 340, Loss: 0.9517
Batch 350, Loss: 0.8483
Batch 360, Loss: 0.9053
Batch 370, Loss: 0.8952
Batch 380, Loss: 0.9220
Batch 390, Loss: 0.9473
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.410504817962646 seconds
Epoch 123 accuracy: 69.38%
Batch 10, Loss: 0.8319
Batch 20, Loss: 0.8829
Batch 30, Loss: 0.8494
Batch 40, Loss: 0.8183
Batch 50, Loss: 0.8678
Batch 60, Loss: 0.8590
Batch 70, Loss: 0.8552
Batch 80, Loss: 0.9014
Batch 90, Loss: 0.8125
Batch 100, Loss: 0.8853
Batch 110, Loss: 0.8947
Batch 120, Loss: 0.8889
Batch 130, Loss: 0.9136
Batch 140, Loss: 0.8425
Batch 150, Loss: 0.9255
Batch 160, Loss: 0.8450
Batch 170, Loss: 0.8748
Batch 180, Loss: 0.8751
Batch 190, Loss: 0.9610
Batch 200, Loss: 0.9015
Batch 210, Loss: 0.8641
Batch 220, Loss: 0.9523
Batch 230, Loss: 0.9073
Batch 240, Loss: 0.8818
Batch 250, Loss: 0.8623
Batch 260, Loss: 0.9020
Batch 270, Loss: 0.8453
Batch 280, Loss: 0.8825
Batch 290, Loss: 0.9084
Batch 300, Loss: 0.9557
Batch 310, Loss: 0.9546
Batch 320, Loss: 0.9045
Batch 330, Loss: 0.9003
Batch 340, Loss: 0.9553
Batch 350, Loss: 0.9622
Batch 360, Loss: 0.9729
Batch 370, Loss: 0.8924
Batch 380, Loss: 0.8827
Batch 390, Loss: 0.9221
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.258663177490234 seconds
Epoch 124 accuracy: 70.08%
Batch 10, Loss: 0.8907
Batch 20, Loss: 0.8406
Batch 30, Loss: 0.8454
Batch 40, Loss: 0.8377
Batch 50, Loss: 0.8218
Batch 60, Loss: 0.8273
Batch 70, Loss: 0.8390
Batch 80, Loss: 0.8411
Batch 90, Loss: 0.8483
Batch 100, Loss: 0.8655
Batch 110, Loss: 0.8733
Batch 120, Loss: 0.8705
Batch 130, Loss: 0.8664
Batch 140, Loss: 0.8980
Batch 150, Loss: 0.8596
Batch 160, Loss: 0.8293
Batch 170, Loss: 0.8796
Batch 180, Loss: 0.8462
Batch 190, Loss: 0.8118
Batch 200, Loss: 0.8658
Batch 210, Loss: 0.9161
Batch 220, Loss: 0.8951
Batch 230, Loss: 0.9241
Batch 240, Loss: 0.9282
Batch 250, Loss: 0.8454
Batch 260, Loss: 0.8922
Batch 270, Loss: 0.8804
Batch 280, Loss: 0.9498
Batch 290, Loss: 0.8860
Batch 300, Loss: 0.8861
Batch 310, Loss: 0.9142
Batch 320, Loss: 0.8515
Batch 330, Loss: 0.8877
Batch 340, Loss: 0.9016
Batch 350, Loss: 0.8592
Batch 360, Loss: 0.9184
Batch 370, Loss: 0.8757
Batch 380, Loss: 0.8392
Batch 390, Loss: 0.8648
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.388140439987183 seconds
Epoch 125 accuracy: 70.67%
Batch 10, Loss: 0.8463
Batch 20, Loss: 0.7529
Batch 30, Loss: 0.8358
Batch 40, Loss: 0.8211
Batch 50, Loss: 0.8254
Batch 60, Loss: 0.8922
Batch 70, Loss: 0.8380
Batch 80, Loss: 0.8737
Batch 90, Loss: 0.8585
Batch 100, Loss: 0.8738
Batch 110, Loss: 0.8126
Batch 120, Loss: 0.7848
Batch 130, Loss: 0.8172
Batch 140, Loss: 0.8445
Batch 150, Loss: 0.8124
Batch 160, Loss: 0.8443
Batch 170, Loss: 0.8662
Batch 180, Loss: 0.8611
Batch 190, Loss: 0.8484
Batch 200, Loss: 0.8920
Batch 210, Loss: 0.8208
Batch 220, Loss: 0.8223
Batch 230, Loss: 0.8461
Batch 240, Loss: 0.8848
Batch 250, Loss: 0.8518
Batch 260, Loss: 0.8348
Batch 270, Loss: 0.8710
Batch 280, Loss: 0.8804
Batch 290, Loss: 0.8778
Batch 300, Loss: 0.9053
Batch 310, Loss: 0.8588
Batch 320, Loss: 0.8570
Batch 330, Loss: 0.8539
Batch 340, Loss: 0.8753
Batch 350, Loss: 0.9059
Batch 360, Loss: 0.9584
Batch 370, Loss: 0.8880
Batch 380, Loss: 0.9351
Batch 390, Loss: 0.9136
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.37585949897766 seconds
Epoch 126 accuracy: 70.66%
Batch 10, Loss: 0.8787
Batch 20, Loss: 0.7958
Batch 30, Loss: 0.8293
Batch 40, Loss: 0.8488
Batch 50, Loss: 0.8567
Batch 60, Loss: 0.8571
Batch 70, Loss: 0.8347
Batch 80, Loss: 0.8192
Batch 90, Loss: 0.8128
Batch 100, Loss: 0.7759
Batch 110, Loss: 0.7900
Batch 120, Loss: 0.7919
Batch 130, Loss: 0.8832
Batch 140, Loss: 0.8735
Batch 150, Loss: 0.8585
Batch 160, Loss: 0.8481
Batch 170, Loss: 0.8473
Batch 180, Loss: 0.8557
Batch 190, Loss: 0.8572
Batch 200, Loss: 0.8677
Batch 210, Loss: 0.8492
Batch 220, Loss: 0.8639
Batch 230, Loss: 0.9045
Batch 240, Loss: 0.7835
Batch 250, Loss: 0.8462
Batch 260, Loss: 0.8573
Batch 270, Loss: 0.8622
Batch 280, Loss: 0.8655
Batch 290, Loss: 0.9222
Batch 300, Loss: 0.8147
Batch 310, Loss: 0.8471
Batch 320, Loss: 0.8684
Batch 330, Loss: 0.8914
Batch 340, Loss: 0.8975
Batch 350, Loss: 0.8830
Batch 360, Loss: 0.8902
Batch 370, Loss: 0.9012
Batch 380, Loss: 0.8882
Batch 390, Loss: 0.8873
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.31509256362915 seconds
Epoch 127 accuracy: 70.07%
Batch 10, Loss: 0.7973
Batch 20, Loss: 0.7847
Batch 30, Loss: 0.8178
Batch 40, Loss: 0.7928
Batch 50, Loss: 0.8514
Batch 60, Loss: 0.7894
Batch 70, Loss: 0.7591
Batch 80, Loss: 0.8304
Batch 90, Loss: 0.8626
Batch 100, Loss: 0.8295
Batch 110, Loss: 0.7929
Batch 120, Loss: 0.8840
Batch 130, Loss: 0.8257
Batch 140, Loss: 0.8312
Batch 150, Loss: 0.8432
Batch 160, Loss: 0.8240
Batch 170, Loss: 0.8569
Batch 180, Loss: 0.8584
Batch 190, Loss: 0.7946
Batch 200, Loss: 0.8665
Batch 210, Loss: 0.8300
Batch 220, Loss: 0.9068
Batch 230, Loss: 0.8071
Batch 240, Loss: 0.9101
Batch 250, Loss: 0.8646
Batch 260, Loss: 0.8415
Batch 270, Loss: 0.8812
Batch 280, Loss: 0.8754
Batch 290, Loss: 0.9091
Batch 300, Loss: 0.8336
Batch 310, Loss: 0.8676
Batch 320, Loss: 0.8201
Batch 330, Loss: 0.8338
Batch 340, Loss: 0.8508
Batch 350, Loss: 0.8151
Batch 360, Loss: 0.8612
Batch 370, Loss: 0.8897
Batch 380, Loss: 0.8248
Batch 390, Loss: 0.8244
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.40823984146118 seconds
Epoch 128 accuracy: 70.88%
Batch 10, Loss: 0.7729
Batch 20, Loss: 0.8223
Batch 30, Loss: 0.8028
Batch 40, Loss: 0.8997
Batch 50, Loss: 0.8332
Batch 60, Loss: 0.8085
Batch 70, Loss: 0.8260
Batch 80, Loss: 0.8139
Batch 90, Loss: 0.8672
Batch 100, Loss: 0.8109
Batch 110, Loss: 0.8557
Batch 120, Loss: 0.8286
Batch 130, Loss: 0.8301
Batch 140, Loss: 0.8299
Batch 150, Loss: 0.8991
Batch 160, Loss: 0.8677
Batch 170, Loss: 0.7898
Batch 180, Loss: 0.8852
Batch 190, Loss: 0.7912
Batch 200, Loss: 0.8303
Batch 210, Loss: 0.8688
Batch 220, Loss: 0.8907
Batch 230, Loss: 0.8386
Batch 240, Loss: 0.8165
Batch 250, Loss: 0.7983
Batch 260, Loss: 0.7839
Batch 270, Loss: 0.8387
Batch 280, Loss: 0.8067
Batch 290, Loss: 0.8668
Batch 300, Loss: 0.8675
Batch 310, Loss: 0.8284
Batch 320, Loss: 0.8708
Batch 330, Loss: 0.8289
Batch 340, Loss: 0.9167
Batch 350, Loss: 0.8784
Batch 360, Loss: 0.8112
Batch 370, Loss: 0.8462
Batch 380, Loss: 0.8350
Batch 390, Loss: 0.8485
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.298052549362183 seconds
Epoch 129 accuracy: 70.48%
Batch 10, Loss: 0.8260
Batch 20, Loss: 0.8370
Batch 30, Loss: 0.8692
Batch 40, Loss: 0.8284
Batch 50, Loss: 0.7573
Batch 60, Loss: 0.7867
Batch 70, Loss: 0.8025
Batch 80, Loss: 0.7926
Batch 90, Loss: 0.8564
Batch 100, Loss: 0.8656
Batch 110, Loss: 0.7661
Batch 120, Loss: 0.8492
Batch 130, Loss: 0.8598
Batch 140, Loss: 0.7912
Batch 150, Loss: 0.7650
Batch 160, Loss: 0.8255
Batch 170, Loss: 0.8059
Batch 180, Loss: 0.8436
Batch 190, Loss: 0.7713
Batch 200, Loss: 0.8232
Batch 210, Loss: 0.8167
Batch 220, Loss: 0.8659
Batch 230, Loss: 0.8369
Batch 240, Loss: 0.8479
Batch 250, Loss: 0.8085
Batch 260, Loss: 0.7744
Batch 270, Loss: 0.8047
Batch 280, Loss: 0.8249
Batch 290, Loss: 0.8499
Batch 300, Loss: 0.8428
Batch 310, Loss: 0.8918
Batch 320, Loss: 0.8844
Batch 330, Loss: 0.7659
Batch 340, Loss: 0.8509
Batch 350, Loss: 0.8515
Batch 360, Loss: 0.8246
Batch 370, Loss: 0.8290
Batch 380, Loss: 0.8375
Batch 390, Loss: 0.8873
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.29976463317871 seconds
Epoch 130 accuracy: 71.31%
Batch 10, Loss: 0.8279
Batch 20, Loss: 0.7470
Batch 30, Loss: 0.7895
Batch 40, Loss: 0.7799
Batch 50, Loss: 0.7580
Batch 60, Loss: 0.8199
Batch 70, Loss: 0.8023
Batch 80, Loss: 0.7730
Batch 90, Loss: 0.7806
Batch 100, Loss: 0.7976
Batch 110, Loss: 0.8041
Batch 120, Loss: 0.8003
Batch 130, Loss: 0.7603
Batch 140, Loss: 0.7516
Batch 150, Loss: 0.8107
Batch 160, Loss: 0.7714
Batch 170, Loss: 0.8219
Batch 180, Loss: 0.7696
Batch 190, Loss: 0.7637
Batch 200, Loss: 0.8187
Batch 210, Loss: 0.8073
Batch 220, Loss: 0.7879
Batch 230, Loss: 0.8383
Batch 240, Loss: 0.7931
Batch 250, Loss: 0.8007
Batch 260, Loss: 0.7735
Batch 270, Loss: 0.8790
Batch 280, Loss: 0.7708
Batch 290, Loss: 0.7930
Batch 300, Loss: 0.7746
Batch 310, Loss: 0.7968
Batch 320, Loss: 0.8514
Batch 330, Loss: 0.8364
Batch 340, Loss: 0.8615
Batch 350, Loss: 0.8687
Batch 360, Loss: 0.8286
Batch 370, Loss: 0.8353
Batch 380, Loss: 0.8684
Batch 390, Loss: 0.8514
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.289170742034912 seconds
Epoch 131 accuracy: 70.92%
Batch 10, Loss: 0.8008
Batch 20, Loss: 0.7871
Batch 30, Loss: 0.7431
Batch 40, Loss: 0.7921
Batch 50, Loss: 0.7692
Batch 60, Loss: 0.7036
Batch 70, Loss: 0.7807
Batch 80, Loss: 0.8034
Batch 90, Loss: 0.7663
Batch 100, Loss: 0.7646
Batch 110, Loss: 0.8005
Batch 120, Loss: 0.7944
Batch 130, Loss: 0.7999
Batch 140, Loss: 0.7614
Batch 150, Loss: 0.7798
Batch 160, Loss: 0.8349
Batch 170, Loss: 0.8416
Batch 180, Loss: 0.7839
Batch 190, Loss: 0.7931
Batch 200, Loss: 0.7880
Batch 210, Loss: 0.8305
Batch 220, Loss: 0.7655
Batch 230, Loss: 0.7688
Batch 240, Loss: 0.7739
Batch 250, Loss: 0.8082
Batch 260, Loss: 0.7896
Batch 270, Loss: 0.8027
Batch 280, Loss: 0.8162
Batch 290, Loss: 0.8331
Batch 300, Loss: 0.8589
Batch 310, Loss: 0.8178
Batch 320, Loss: 0.8279
Batch 330, Loss: 0.8693
Batch 340, Loss: 0.8427
Batch 350, Loss: 0.8399
Batch 360, Loss: 0.8170
Batch 370, Loss: 0.8357
Batch 380, Loss: 0.8133
Batch 390, Loss: 0.8478
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.30387043952942 seconds
Epoch 132 accuracy: 71.55%
Batch 10, Loss: 0.7714
Batch 20, Loss: 0.7693
Batch 30, Loss: 0.8225
Batch 40, Loss: 0.7992
Batch 50, Loss: 0.7543
Batch 60, Loss: 0.8112
Batch 70, Loss: 0.7658
Batch 80, Loss: 0.7564
Batch 90, Loss: 0.7669
Batch 100, Loss: 0.7504
Batch 110, Loss: 0.7753
Batch 120, Loss: 0.8138
Batch 130, Loss: 0.8057
Batch 140, Loss: 0.7738
Batch 150, Loss: 0.7899
Batch 160, Loss: 0.7578
Batch 170, Loss: 0.7458
Batch 180, Loss: 0.7898
Batch 190, Loss: 0.8010
Batch 200, Loss: 0.8125
Batch 210, Loss: 0.8048
Batch 220, Loss: 0.7804
Batch 230, Loss: 0.7268
Batch 240, Loss: 0.7970
Batch 250, Loss: 0.8425
Batch 260, Loss: 0.7699
Batch 270, Loss: 0.7920
Batch 280, Loss: 0.7977
Batch 290, Loss: 0.8074
Batch 300, Loss: 0.7550
Batch 310, Loss: 0.8216
Batch 320, Loss: 0.8277
Batch 330, Loss: 0.8031
Batch 340, Loss: 0.7929
Batch 350, Loss: 0.8432
Batch 360, Loss: 0.8170
Batch 370, Loss: 0.7894
Batch 380, Loss: 0.8178
Batch 390, Loss: 0.8350
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.291614294052124 seconds
Epoch 133 accuracy: 71.14%
Batch 10, Loss: 0.7653
Batch 20, Loss: 0.7328
Batch 30, Loss: 0.7333
Batch 40, Loss: 0.7194
Batch 50, Loss: 0.7324
Batch 60, Loss: 0.7373
Batch 70, Loss: 0.7571
Batch 80, Loss: 0.7500
Batch 90, Loss: 0.7658
Batch 100, Loss: 0.7291
Batch 110, Loss: 0.7715
Batch 120, Loss: 0.7779
Batch 130, Loss: 0.8020
Batch 140, Loss: 0.7427
Batch 150, Loss: 0.7538
Batch 160, Loss: 0.8307
Batch 170, Loss: 0.7841
Batch 180, Loss: 0.7615
Batch 190, Loss: 0.7747
Batch 200, Loss: 0.7635
Batch 210, Loss: 0.7683
Batch 220, Loss: 0.7521
Batch 230, Loss: 0.7510
Batch 240, Loss: 0.7585
Batch 250, Loss: 0.7424
Batch 260, Loss: 0.8043
Batch 270, Loss: 0.7551
Batch 280, Loss: 0.7893
Batch 290, Loss: 0.7354
Batch 300, Loss: 0.8108
Batch 310, Loss: 0.8209
Batch 320, Loss: 0.8795
Batch 330, Loss: 0.8421
Batch 340, Loss: 0.8507
Batch 350, Loss: 0.7959
Batch 360, Loss: 0.8272
Batch 370, Loss: 0.7605
Batch 380, Loss: 0.7986
Batch 390, Loss: 0.8444
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.18830704689026 seconds
Epoch 134 accuracy: 71.75%
Batch 10, Loss: 0.7750
Batch 20, Loss: 0.7381
Batch 30, Loss: 0.7078
Batch 40, Loss: 0.7536
Batch 50, Loss: 0.7931
Batch 60, Loss: 0.7289
Batch 70, Loss: 0.7665
Batch 80, Loss: 0.7858
Batch 90, Loss: 0.7607
Batch 100, Loss: 0.7931
Batch 110, Loss: 0.7548
Batch 120, Loss: 0.7596
Batch 130, Loss: 0.7656
Batch 140, Loss: 0.7468
Batch 150, Loss: 0.8344
Batch 160, Loss: 0.8146
Batch 170, Loss: 0.7736
Batch 180, Loss: 0.7980
Batch 190, Loss: 0.7386
Batch 200, Loss: 0.8147
Batch 210, Loss: 0.7395
Batch 220, Loss: 0.7619
Batch 230, Loss: 0.7067
Batch 240, Loss: 0.7663
Batch 250, Loss: 0.7444
Batch 260, Loss: 0.7766
Batch 270, Loss: 0.8090
Batch 280, Loss: 0.8108
Batch 290, Loss: 0.7608
Batch 300, Loss: 0.7639
Batch 310, Loss: 0.8247
Batch 320, Loss: 0.7869
Batch 330, Loss: 0.7903
Batch 340, Loss: 0.8334
Batch 350, Loss: 0.8490
Batch 360, Loss: 0.8414
Batch 370, Loss: 0.8087
Batch 380, Loss: 0.8388
Batch 390, Loss: 0.7417
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.104026317596436 seconds
Epoch 135 accuracy: 71.25%
Batch 10, Loss: 0.7144
Batch 20, Loss: 0.7037
Batch 30, Loss: 0.7143
Batch 40, Loss: 0.7314
Batch 50, Loss: 0.7724
Batch 60, Loss: 0.7140
Batch 70, Loss: 0.7543
Batch 80, Loss: 0.7469
Batch 90, Loss: 0.7315
Batch 100, Loss: 0.7223
Batch 110, Loss: 0.7894
Batch 120, Loss: 0.7092
Batch 130, Loss: 0.7458
Batch 140, Loss: 0.7248
Batch 150, Loss: 0.7646
Batch 160, Loss: 0.7554
Batch 170, Loss: 0.7466
Batch 180, Loss: 0.7757
Batch 190, Loss: 0.7184
Batch 200, Loss: 0.8017
Batch 210, Loss: 0.7921
Batch 220, Loss: 0.7225
Batch 230, Loss: 0.7357
Batch 240, Loss: 0.7100
Batch 250, Loss: 0.7706
Batch 260, Loss: 0.7611
Batch 270, Loss: 0.7449
Batch 280, Loss: 0.7732
Batch 290, Loss: 0.7392
Batch 300, Loss: 0.8035
Batch 310, Loss: 0.8295
Batch 320, Loss: 0.7704
Batch 330, Loss: 0.7898
Batch 340, Loss: 0.8422
Batch 350, Loss: 0.7875
Batch 360, Loss: 0.7498
Batch 370, Loss: 0.7621
Batch 380, Loss: 0.8096
Batch 390, Loss: 0.7951
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.16478419303894 seconds
Epoch 136 accuracy: 72.15%
Batch 10, Loss: 0.7331
Batch 20, Loss: 0.7029
Batch 30, Loss: 0.6782
Batch 40, Loss: 0.6681
Batch 50, Loss: 0.6924
Batch 60, Loss: 0.7483
Batch 70, Loss: 0.7617
Batch 80, Loss: 0.7483
Batch 90, Loss: 0.6982
Batch 100, Loss: 0.6747
Batch 110, Loss: 0.7346
Batch 120, Loss: 0.7166
Batch 130, Loss: 0.7216
Batch 140, Loss: 0.7288
Batch 150, Loss: 0.7956
Batch 160, Loss: 0.7340
Batch 170, Loss: 0.7791
Batch 180, Loss: 0.7236
Batch 190, Loss: 0.7517
Batch 200, Loss: 0.7710
Batch 210, Loss: 0.7508
Batch 220, Loss: 0.8413
Batch 230, Loss: 0.7914
Batch 240, Loss: 0.7770
Batch 250, Loss: 0.8133
Batch 260, Loss: 0.7502
Batch 270, Loss: 0.7642
Batch 280, Loss: 0.8108
Batch 290, Loss: 0.7561
Batch 300, Loss: 0.7918
Batch 310, Loss: 0.7182
Batch 320, Loss: 0.7518
Batch 330, Loss: 0.7917
Batch 340, Loss: 0.7587
Batch 350, Loss: 0.7920
Batch 360, Loss: 0.7380
Batch 370, Loss: 0.7494
Batch 380, Loss: 0.8055
Batch 390, Loss: 0.7499
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.286649227142334 seconds
Epoch 137 accuracy: 71.6%
Batch 10, Loss: 0.7475
Batch 20, Loss: 0.7110
Batch 30, Loss: 0.7704
Batch 40, Loss: 0.7056
Batch 50, Loss: 0.7307
Batch 60, Loss: 0.7081
Batch 70, Loss: 0.6645
Batch 80, Loss: 0.6966
Batch 90, Loss: 0.7614
Batch 100, Loss: 0.7751
Batch 110, Loss: 0.6843
Batch 120, Loss: 0.7055
Batch 130, Loss: 0.7077
Batch 140, Loss: 0.7067
Batch 150, Loss: 0.7555
Batch 160, Loss: 0.7280
Batch 170, Loss: 0.6670
Batch 180, Loss: 0.7514
Batch 190, Loss: 0.7003
Batch 200, Loss: 0.7249
Batch 210, Loss: 0.7728
Batch 220, Loss: 0.7077
Batch 230, Loss: 0.7537
Batch 240, Loss: 0.7420
Batch 250, Loss: 0.7139
Batch 260, Loss: 0.7410
Batch 270, Loss: 0.7828
Batch 280, Loss: 0.7740
Batch 290, Loss: 0.7428
Batch 300, Loss: 0.7953
Batch 310, Loss: 0.7338
Batch 320, Loss: 0.7187
Batch 330, Loss: 0.7050
Batch 340, Loss: 0.7773
Batch 350, Loss: 0.7047
Batch 360, Loss: 0.8215
Batch 370, Loss: 0.6912
Batch 380, Loss: 0.7586
Batch 390, Loss: 0.7820
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.34612011909485 seconds
Epoch 138 accuracy: 73.27%
Batch 10, Loss: 0.6827
Batch 20, Loss: 0.6706
Batch 30, Loss: 0.7066
Batch 40, Loss: 0.6906
Batch 50, Loss: 0.6989
Batch 60, Loss: 0.7230
Batch 70, Loss: 0.6886
Batch 80, Loss: 0.7519
Batch 90, Loss: 0.6664
Batch 100, Loss: 0.7239
Batch 110, Loss: 0.7890
Batch 120, Loss: 0.7207
Batch 130, Loss: 0.7423
Batch 140, Loss: 0.7128
Batch 150, Loss: 0.7507
Batch 160, Loss: 0.7081
Batch 170, Loss: 0.7370
Batch 180, Loss: 0.7132
Batch 190, Loss: 0.7009
Batch 200, Loss: 0.7391
Batch 210, Loss: 0.7654
Batch 220, Loss: 0.7163
Batch 230, Loss: 0.7139
Batch 240, Loss: 0.6813
Batch 250, Loss: 0.7364
Batch 260, Loss: 0.6944
Batch 270, Loss: 0.7084
Batch 280, Loss: 0.7692
Batch 290, Loss: 0.7032
Batch 300, Loss: 0.7265
Batch 310, Loss: 0.7304
Batch 320, Loss: 0.7690
Batch 330, Loss: 0.7131
Batch 340, Loss: 0.7221
Batch 350, Loss: 0.7343
Batch 360, Loss: 0.7216
Batch 370, Loss: 0.7298
Batch 380, Loss: 0.7827
Batch 390, Loss: 0.7547
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.405428409576416 seconds
Epoch 139 accuracy: 69.98%
Batch 10, Loss: 0.6752
Batch 20, Loss: 0.6848
Batch 30, Loss: 0.6863
Batch 40, Loss: 0.6886
Batch 50, Loss: 0.7251
Batch 60, Loss: 0.7071
Batch 70, Loss: 0.6515
Batch 80, Loss: 0.6766
Batch 90, Loss: 0.7588
Batch 100, Loss: 0.6925
Batch 110, Loss: 0.6908
Batch 120, Loss: 0.6357
Batch 130, Loss: 0.7280
Batch 140, Loss: 0.7267
Batch 150, Loss: 0.7430
Batch 160, Loss: 0.7232
Batch 170, Loss: 0.7277
Batch 180, Loss: 0.6792
Batch 190, Loss: 0.7157
Batch 200, Loss: 0.6850
Batch 210, Loss: 0.7390
Batch 220, Loss: 0.7434
Batch 230, Loss: 0.7148
Batch 240, Loss: 0.6847
Batch 250, Loss: 0.7512
Batch 260, Loss: 0.7904
Batch 270, Loss: 0.6972
Batch 280, Loss: 0.7619
Batch 290, Loss: 0.7348
Batch 300, Loss: 0.6966
Batch 310, Loss: 0.7538
Batch 320, Loss: 0.7320
Batch 330, Loss: 0.7538
Batch 340, Loss: 0.7005
Batch 350, Loss: 0.7795
Batch 360, Loss: 0.7900
Batch 370, Loss: 0.7256
Batch 380, Loss: 0.7657
Batch 390, Loss: 0.7314
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.22827386856079 seconds
Epoch 140 accuracy: 72.97%
Batch 10, Loss: 0.6358
Batch 20, Loss: 0.7064
Batch 30, Loss: 0.6791
Batch 40, Loss: 0.7142
Batch 50, Loss: 0.6736
Batch 60, Loss: 0.7202
Batch 70, Loss: 0.6860
Batch 80, Loss: 0.6819
Batch 90, Loss: 0.6849
Batch 100, Loss: 0.7158
Batch 110, Loss: 0.7038
Batch 120, Loss: 0.7056
Batch 130, Loss: 0.6732
Batch 140, Loss: 0.7035
Batch 150, Loss: 0.6805
Batch 160, Loss: 0.6474
Batch 170, Loss: 0.7265
Batch 180, Loss: 0.6548
Batch 190, Loss: 0.7109
Batch 200, Loss: 0.6938
Batch 210, Loss: 0.7085
Batch 220, Loss: 0.7316
Batch 230, Loss: 0.7304
Batch 240, Loss: 0.7369
Batch 250, Loss: 0.7354
Batch 260, Loss: 0.7454
Batch 270, Loss: 0.7440
Batch 280, Loss: 0.7177
Batch 290, Loss: 0.7772
Batch 300, Loss: 0.7293
Batch 310, Loss: 0.7421
Batch 320, Loss: 0.6692
Batch 330, Loss: 0.6691
Batch 340, Loss: 0.7217
Batch 350, Loss: 0.7662
Batch 360, Loss: 0.7216
Batch 370, Loss: 0.6975
Batch 380, Loss: 0.7620
Batch 390, Loss: 0.7038
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.182589054107666 seconds
Epoch 141 accuracy: 71.88%
Batch 10, Loss: 0.7196
Batch 20, Loss: 0.6776
Batch 30, Loss: 0.6881
Batch 40, Loss: 0.6838
Batch 50, Loss: 0.6433
Batch 60, Loss: 0.6427
Batch 70, Loss: 0.6448
Batch 80, Loss: 0.6693
Batch 90, Loss: 0.6240
Batch 100, Loss: 0.6644
Batch 110, Loss: 0.6769
Batch 120, Loss: 0.6911
Batch 130, Loss: 0.6718
Batch 140, Loss: 0.6690
Batch 150, Loss: 0.6499
Batch 160, Loss: 0.7091
Batch 170, Loss: 0.6510
Batch 180, Loss: 0.6755
Batch 190, Loss: 0.6940
Batch 200, Loss: 0.7080
Batch 210, Loss: 0.6398
Batch 220, Loss: 0.6928
Batch 230, Loss: 0.6247
Batch 240, Loss: 0.7060
Batch 250, Loss: 0.7264
Batch 260, Loss: 0.6579
Batch 270, Loss: 0.6687
Batch 280, Loss: 0.7587
Batch 290, Loss: 0.7137
Batch 300, Loss: 0.6916
Batch 310, Loss: 0.6902
Batch 320, Loss: 0.7327
Batch 330, Loss: 0.7035
Batch 340, Loss: 0.7113
Batch 350, Loss: 0.6858
Batch 360, Loss: 0.7097
Batch 370, Loss: 0.7457
Batch 380, Loss: 0.7397
Batch 390, Loss: 0.6883
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.337634563446045 seconds
Epoch 142 accuracy: 72.73%
Batch 10, Loss: 0.6838
Batch 20, Loss: 0.6528
Batch 30, Loss: 0.6467
Batch 40, Loss: 0.6674
Batch 50, Loss: 0.6558
Batch 60, Loss: 0.6832
Batch 70, Loss: 0.6614
Batch 80, Loss: 0.6384
Batch 90, Loss: 0.6224
Batch 100, Loss: 0.6314
Batch 110, Loss: 0.7049
Batch 120, Loss: 0.6115
Batch 130, Loss: 0.6581
Batch 140, Loss: 0.6705
Batch 150, Loss: 0.7108
Batch 160, Loss: 0.6397
Batch 170, Loss: 0.6617
Batch 180, Loss: 0.6805
Batch 190, Loss: 0.6320
Batch 200, Loss: 0.6405
Batch 210, Loss: 0.6320
Batch 220, Loss: 0.7274
Batch 230, Loss: 0.6856
Batch 240, Loss: 0.6698
Batch 250, Loss: 0.7133
Batch 260, Loss: 0.6721
Batch 270, Loss: 0.6648
Batch 280, Loss: 0.6882
Batch 290, Loss: 0.7187
Batch 300, Loss: 0.6996
Batch 310, Loss: 0.6832
Batch 320, Loss: 0.6663
Batch 330, Loss: 0.6779
Batch 340, Loss: 0.6700
Batch 350, Loss: 0.7297
Batch 360, Loss: 0.7485
Batch 370, Loss: 0.7337
Batch 380, Loss: 0.7502
Batch 390, Loss: 0.7209
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.174866437911987 seconds
Epoch 143 accuracy: 73.12%
Batch 10, Loss: 0.6439
Batch 20, Loss: 0.6585
Batch 30, Loss: 0.6788
Batch 40, Loss: 0.6821
Batch 50, Loss: 0.5888
Batch 60, Loss: 0.6459
Batch 70, Loss: 0.6347
Batch 80, Loss: 0.6251
Batch 90, Loss: 0.6505
Batch 100, Loss: 0.6042
Batch 110, Loss: 0.6138
Batch 120, Loss: 0.6784
Batch 130, Loss: 0.6510
Batch 140, Loss: 0.6557
Batch 150, Loss: 0.7337
Batch 160, Loss: 0.6466
Batch 170, Loss: 0.6357
Batch 180, Loss: 0.6810
Batch 190, Loss: 0.6591
Batch 200, Loss: 0.6471
Batch 210, Loss: 0.6711
Batch 220, Loss: 0.6405
Batch 230, Loss: 0.6194
Batch 240, Loss: 0.6714
Batch 250, Loss: 0.6894
Batch 260, Loss: 0.6288
Batch 270, Loss: 0.6976
Batch 280, Loss: 0.6873
Batch 290, Loss: 0.6327
Batch 300, Loss: 0.7266
Batch 310, Loss: 0.6901
Batch 320, Loss: 0.6924
Batch 330, Loss: 0.7005
Batch 340, Loss: 0.7223
Batch 350, Loss: 0.6855
Batch 360, Loss: 0.7269
Batch 370, Loss: 0.6902
Batch 380, Loss: 0.7074
Batch 390, Loss: 0.7173
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.26545238494873 seconds
Epoch 144 accuracy: 73.14%
Batch 10, Loss: 0.5976
Batch 20, Loss: 0.6105
Batch 30, Loss: 0.6548
Batch 40, Loss: 0.6414
Batch 50, Loss: 0.6059
Batch 60, Loss: 0.6310
Batch 70, Loss: 0.6216
Batch 80, Loss: 0.6096
Batch 90, Loss: 0.6900
Batch 100, Loss: 0.6078
Batch 110, Loss: 0.6521
Batch 120, Loss: 0.5961
Batch 130, Loss: 0.6929
Batch 140, Loss: 0.6127
Batch 150, Loss: 0.6193
Batch 160, Loss: 0.6778
Batch 170, Loss: 0.6827
Batch 180, Loss: 0.5882
Batch 190, Loss: 0.6937
Batch 200, Loss: 0.6262
Batch 210, Loss: 0.6330
Batch 220, Loss: 0.6274
Batch 230, Loss: 0.6557
Batch 240, Loss: 0.6126
Batch 250, Loss: 0.6475
Batch 260, Loss: 0.6952
Batch 270, Loss: 0.7321
Batch 280, Loss: 0.6747
Batch 290, Loss: 0.6466
Batch 300, Loss: 0.7510
Batch 310, Loss: 0.6985
Batch 320, Loss: 0.6151
Batch 330, Loss: 0.6681
Batch 340, Loss: 0.6463
Batch 350, Loss: 0.6772
Batch 360, Loss: 0.6535
Batch 370, Loss: 0.6259
Batch 380, Loss: 0.6580
Batch 390, Loss: 0.7249
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.329906463623047 seconds
Epoch 145 accuracy: 73.58%
Batch 10, Loss: 0.6136
Batch 20, Loss: 0.6505
Batch 30, Loss: 0.6309
Batch 40, Loss: 0.6270
Batch 50, Loss: 0.6634
Batch 60, Loss: 0.6438
Batch 70, Loss: 0.6620
Batch 80, Loss: 0.6112
Batch 90, Loss: 0.6313
Batch 100, Loss: 0.6406
Batch 110, Loss: 0.5863
Batch 120, Loss: 0.6042
Batch 130, Loss: 0.6532
Batch 140, Loss: 0.6006
Batch 150, Loss: 0.6542
Batch 160, Loss: 0.6339
Batch 170, Loss: 0.6104
Batch 180, Loss: 0.6428
Batch 190, Loss: 0.6765
Batch 200, Loss: 0.6623
Batch 210, Loss: 0.6394
Batch 220, Loss: 0.6535
Batch 230, Loss: 0.7147
Batch 240, Loss: 0.6661
Batch 250, Loss: 0.6526
Batch 260, Loss: 0.6877
Batch 270, Loss: 0.6347
Batch 280, Loss: 0.6648
Batch 290, Loss: 0.6397
Batch 300, Loss: 0.6115
Batch 310, Loss: 0.6395
Batch 320, Loss: 0.6770
Batch 330, Loss: 0.6653
Batch 340, Loss: 0.6130
Batch 350, Loss: 0.6448
Batch 360, Loss: 0.6303
Batch 370, Loss: 0.6418
Batch 380, Loss: 0.7013
Batch 390, Loss: 0.6706
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.2850923538208 seconds
Epoch 146 accuracy: 73.52%
Batch 10, Loss: 0.6408
Batch 20, Loss: 0.6481
Batch 30, Loss: 0.6170
Batch 40, Loss: 0.6100
Batch 50, Loss: 0.6750
Batch 60, Loss: 0.6172
Batch 70, Loss: 0.6120
Batch 80, Loss: 0.6480
Batch 90, Loss: 0.6289
Batch 100, Loss: 0.6560
Batch 110, Loss: 0.6259
Batch 120, Loss: 0.6477
Batch 130, Loss: 0.6126
Batch 140, Loss: 0.6626
Batch 150, Loss: 0.6375
Batch 160, Loss: 0.6213
Batch 170, Loss: 0.6292
Batch 180, Loss: 0.6445
Batch 190, Loss: 0.6034
Batch 200, Loss: 0.6313
Batch 210, Loss: 0.6315
Batch 220, Loss: 0.6041
Batch 230, Loss: 0.6675
Batch 240, Loss: 0.6578
Batch 250, Loss: 0.6359
Batch 260, Loss: 0.6389
Batch 270, Loss: 0.6702
Batch 280, Loss: 0.6125
Batch 290, Loss: 0.6052
Batch 300, Loss: 0.6757
Batch 310, Loss: 0.6269
Batch 320, Loss: 0.6472
Batch 330, Loss: 0.6754
Batch 340, Loss: 0.6919
Batch 350, Loss: 0.6381
Batch 360, Loss: 0.6685
Batch 370, Loss: 0.6787
Batch 380, Loss: 0.6856
Batch 390, Loss: 0.6317
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.274728059768677 seconds
Epoch 147 accuracy: 73.64%
Batch 10, Loss: 0.5832
Batch 20, Loss: 0.6176
Batch 30, Loss: 0.6220
Batch 40, Loss: 0.6056
Batch 50, Loss: 0.6136
Batch 60, Loss: 0.5783
Batch 70, Loss: 0.5692
Batch 80, Loss: 0.6169
Batch 90, Loss: 0.5961
Batch 100, Loss: 0.5735
Batch 110, Loss: 0.5871
Batch 120, Loss: 0.5971
Batch 130, Loss: 0.5930
Batch 140, Loss: 0.5854
Batch 150, Loss: 0.6045
Batch 160, Loss: 0.6352
Batch 170, Loss: 0.6309
Batch 180, Loss: 0.6601
Batch 190, Loss: 0.5720
Batch 200, Loss: 0.6357
Batch 210, Loss: 0.5924
Batch 220, Loss: 0.6270
Batch 230, Loss: 0.6062
Batch 240, Loss: 0.6381
Batch 250, Loss: 0.6464
Batch 260, Loss: 0.6159
Batch 270, Loss: 0.6370
Batch 280, Loss: 0.6285
Batch 290, Loss: 0.6303
Batch 300, Loss: 0.6283
Batch 310, Loss: 0.6148
Batch 320, Loss: 0.5995
Batch 330, Loss: 0.6158
Batch 340, Loss: 0.6349
Batch 350, Loss: 0.6738
Batch 360, Loss: 0.6035
Batch 370, Loss: 0.6089
Batch 380, Loss: 0.6437
Batch 390, Loss: 0.6675
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.338281869888306 seconds
Epoch 148 accuracy: 74.62%
Batch 10, Loss: 0.5708
Batch 20, Loss: 0.5575
Batch 30, Loss: 0.5765
Batch 40, Loss: 0.5797
Batch 50, Loss: 0.5605
Batch 60, Loss: 0.5774
Batch 70, Loss: 0.6364
Batch 80, Loss: 0.5934
Batch 90, Loss: 0.6000
Batch 100, Loss: 0.5952
Batch 110, Loss: 0.6205
Batch 120, Loss: 0.5975
Batch 130, Loss: 0.5723
Batch 140, Loss: 0.6432
Batch 150, Loss: 0.5776
Batch 160, Loss: 0.6375
Batch 170, Loss: 0.6204
Batch 180, Loss: 0.5759
Batch 190, Loss: 0.6222
Batch 200, Loss: 0.6370
Batch 210, Loss: 0.5638
Batch 220, Loss: 0.5884
Batch 230, Loss: 0.6119
Batch 240, Loss: 0.6445
Batch 250, Loss: 0.5901
Batch 260, Loss: 0.5977
Batch 270, Loss: 0.5883
Batch 280, Loss: 0.6335
Batch 290, Loss: 0.6135
Batch 300, Loss: 0.6048
Batch 310, Loss: 0.6120
Batch 320, Loss: 0.5945
Batch 330, Loss: 0.7051
Batch 340, Loss: 0.6340
Batch 350, Loss: 0.5996
Batch 360, Loss: 0.5793
Batch 370, Loss: 0.6393
Batch 380, Loss: 0.5929
Batch 390, Loss: 0.6083
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.406129121780396 seconds
Epoch 149 accuracy: 74.01%
Batch 10, Loss: 0.5341
Batch 20, Loss: 0.5915
Batch 30, Loss: 0.6039
Batch 40, Loss: 0.5681
Batch 50, Loss: 0.5326
Batch 60, Loss: 0.5956
Batch 70, Loss: 0.5615
Batch 80, Loss: 0.6129
Batch 90, Loss: 0.5245
Batch 100, Loss: 0.5811
Batch 110, Loss: 0.6240
Batch 120, Loss: 0.5893
Batch 130, Loss: 0.5290
Batch 140, Loss: 0.5724
Batch 150, Loss: 0.6180
Batch 160, Loss: 0.5499
Batch 170, Loss: 0.6027
Batch 180, Loss: 0.6605
Batch 190, Loss: 0.6259
Batch 200, Loss: 0.5969
Batch 210, Loss: 0.5950
Batch 220, Loss: 0.5812
Batch 230, Loss: 0.6244
Batch 240, Loss: 0.6633
Batch 250, Loss: 0.5836
Batch 260, Loss: 0.5919
Batch 270, Loss: 0.6162
Batch 280, Loss: 0.6092
Batch 290, Loss: 0.6063
Batch 300, Loss: 0.6340
Batch 310, Loss: 0.6546
Batch 320, Loss: 0.6211
Batch 330, Loss: 0.6595
Batch 340, Loss: 0.5761
Batch 350, Loss: 0.5912
Batch 360, Loss: 0.5626
Batch 370, Loss: 0.6179
Batch 380, Loss: 0.6564
Batch 390, Loss: 0.5753
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.30814242362976 seconds
Epoch 150 accuracy: 73.45%
Batch 10, Loss: 0.5701
Batch 20, Loss: 0.5450
Batch 30, Loss: 0.5709
Batch 40, Loss: 0.5464
Batch 50, Loss: 0.5925
Batch 60, Loss: 0.5687
Batch 70, Loss: 0.5706
Batch 80, Loss: 0.6103
Batch 90, Loss: 0.5555
Batch 100, Loss: 0.5499
Batch 110, Loss: 0.5601
Batch 120, Loss: 0.6026
Batch 130, Loss: 0.5970
Batch 140, Loss: 0.5224
Batch 150, Loss: 0.5762
Batch 160, Loss: 0.5569
Batch 170, Loss: 0.5956
Batch 180, Loss: 0.5385
Batch 190, Loss: 0.5548
Batch 200, Loss: 0.5759
Batch 210, Loss: 0.5798
Batch 220, Loss: 0.5637
Batch 230, Loss: 0.5788
Batch 240, Loss: 0.6017
Batch 250, Loss: 0.5838
Batch 260, Loss: 0.5876
Batch 270, Loss: 0.5828
Batch 280, Loss: 0.6189
Batch 290, Loss: 0.6491
Batch 300, Loss: 0.6106
Batch 310, Loss: 0.6146
Batch 320, Loss: 0.6186
Batch 330, Loss: 0.6432
Batch 340, Loss: 0.5800
Batch 350, Loss: 0.5797
Batch 360, Loss: 0.5845
Batch 370, Loss: 0.5953
Batch 380, Loss: 0.6596
Batch 390, Loss: 0.6271
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.261709690093994 seconds
Epoch 151 accuracy: 74.26%
Batch 10, Loss: 0.5495
Batch 20, Loss: 0.5950
Batch 30, Loss: 0.5111
Batch 40, Loss: 0.5616
Batch 50, Loss: 0.5198
Batch 60, Loss: 0.5594
Batch 70, Loss: 0.5552
Batch 80, Loss: 0.5498
Batch 90, Loss: 0.5209
Batch 100, Loss: 0.5792
Batch 110, Loss: 0.5350
Batch 120, Loss: 0.5245
Batch 130, Loss: 0.5530
Batch 140, Loss: 0.5659
Batch 150, Loss: 0.5705
Batch 160, Loss: 0.5976
Batch 170, Loss: 0.5508
Batch 180, Loss: 0.5601
Batch 190, Loss: 0.5872
Batch 200, Loss: 0.5550
Batch 210, Loss: 0.5547
Batch 220, Loss: 0.5999
Batch 230, Loss: 0.5485
Batch 240, Loss: 0.5839
Batch 250, Loss: 0.5702
Batch 260, Loss: 0.5724
Batch 270, Loss: 0.5961
Batch 280, Loss: 0.6171
Batch 290, Loss: 0.5944
Batch 300, Loss: 0.5482
Batch 310, Loss: 0.5692
Batch 320, Loss: 0.5626
Batch 330, Loss: 0.5975
Batch 340, Loss: 0.6221
Batch 350, Loss: 0.5847
Batch 360, Loss: 0.5986
Batch 370, Loss: 0.5678
Batch 380, Loss: 0.5982
Batch 390, Loss: 0.5657
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.330509901046753 seconds
Epoch 152 accuracy: 74.69%
Batch 10, Loss: 0.5158
Batch 20, Loss: 0.5777
Batch 30, Loss: 0.5632
Batch 40, Loss: 0.5387
Batch 50, Loss: 0.5621
Batch 60, Loss: 0.5690
Batch 70, Loss: 0.5375
Batch 80, Loss: 0.5471
Batch 90, Loss: 0.5573
Batch 100, Loss: 0.5159
Batch 110, Loss: 0.5476
Batch 120, Loss: 0.6066
Batch 130, Loss: 0.5770
Batch 140, Loss: 0.5540
Batch 150, Loss: 0.5667
Batch 160, Loss: 0.5080
Batch 170, Loss: 0.6041
Batch 180, Loss: 0.5653
Batch 190, Loss: 0.5633
Batch 200, Loss: 0.5320
Batch 210, Loss: 0.5210
Batch 220, Loss: 0.5523
Batch 230, Loss: 0.6016
Batch 240, Loss: 0.5045
Batch 250, Loss: 0.5729
Batch 260, Loss: 0.5777
Batch 270, Loss: 0.5767
Batch 280, Loss: 0.5778
Batch 290, Loss: 0.5609
Batch 300, Loss: 0.5944
Batch 310, Loss: 0.5386
Batch 320, Loss: 0.6182
Batch 330, Loss: 0.6014
Batch 340, Loss: 0.6076
Batch 350, Loss: 0.5920
Batch 360, Loss: 0.5679
Batch 370, Loss: 0.6354
Batch 380, Loss: 0.5798
Batch 390, Loss: 0.5560
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.392952919006348 seconds
Epoch 153 accuracy: 75.24%
Batch 10, Loss: 0.5153
Batch 20, Loss: 0.5359
Batch 30, Loss: 0.5090
Batch 40, Loss: 0.5091
Batch 50, Loss: 0.5357
Batch 60, Loss: 0.5526
Batch 70, Loss: 0.5180
Batch 80, Loss: 0.5293
Batch 90, Loss: 0.5346
Batch 100, Loss: 0.5341
Batch 110, Loss: 0.5111
Batch 120, Loss: 0.5915
Batch 130, Loss: 0.5249
Batch 140, Loss: 0.5700
Batch 150, Loss: 0.5088
Batch 160, Loss: 0.5846
Batch 170, Loss: 0.4914
Batch 180, Loss: 0.5428
Batch 190, Loss: 0.5862
Batch 200, Loss: 0.5410
Batch 210, Loss: 0.5159
Batch 220, Loss: 0.5503
Batch 230, Loss: 0.5208
Batch 240, Loss: 0.5543
Batch 250, Loss: 0.5801
Batch 260, Loss: 0.5914
Batch 270, Loss: 0.5445
Batch 280, Loss: 0.5993
Batch 290, Loss: 0.5527
Batch 300, Loss: 0.5595
Batch 310, Loss: 0.5766
Batch 320, Loss: 0.5769
Batch 330, Loss: 0.5802
Batch 340, Loss: 0.5638
Batch 350, Loss: 0.5678
Batch 360, Loss: 0.5969
Batch 370, Loss: 0.5615
Batch 380, Loss: 0.5703
Batch 390, Loss: 0.5662
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.383476495742798 seconds
Epoch 154 accuracy: 75.12%
Batch 10, Loss: 0.5611
Batch 20, Loss: 0.4717
Batch 30, Loss: 0.5065
Batch 40, Loss: 0.5553
Batch 50, Loss: 0.5149
Batch 60, Loss: 0.5513
Batch 70, Loss: 0.5313
Batch 80, Loss: 0.5453
Batch 90, Loss: 0.4937
Batch 100, Loss: 0.5054
Batch 110, Loss: 0.5401
Batch 120, Loss: 0.5272
Batch 130, Loss: 0.5425
Batch 140, Loss: 0.5635
Batch 150, Loss: 0.5435
Batch 160, Loss: 0.5177
Batch 170, Loss: 0.5677
Batch 180, Loss: 0.4883
Batch 190, Loss: 0.5120
Batch 200, Loss: 0.5580
Batch 210, Loss: 0.5662
Batch 220, Loss: 0.5417
Batch 230, Loss: 0.5555
Batch 240, Loss: 0.5026
Batch 250, Loss: 0.5127
Batch 260, Loss: 0.5667
Batch 270, Loss: 0.5475
Batch 280, Loss: 0.5221
Batch 290, Loss: 0.5568
Batch 300, Loss: 0.5567
Batch 310, Loss: 0.5548
Batch 320, Loss: 0.5570
Batch 330, Loss: 0.5725
Batch 340, Loss: 0.5808
Batch 350, Loss: 0.5821
Batch 360, Loss: 0.5037
Batch 370, Loss: 0.5705
Batch 380, Loss: 0.5568
Batch 390, Loss: 0.5332
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.33601188659668 seconds
Epoch 155 accuracy: 75.17%
Batch 10, Loss: 0.5306
Batch 20, Loss: 0.5287
Batch 30, Loss: 0.5190
Batch 40, Loss: 0.5473
Batch 50, Loss: 0.5331
Batch 60, Loss: 0.5288
Batch 70, Loss: 0.5561
Batch 80, Loss: 0.5473
Batch 90, Loss: 0.5427
Batch 100, Loss: 0.4818
Batch 110, Loss: 0.4959
Batch 120, Loss: 0.5580
Batch 130, Loss: 0.4917
Batch 140, Loss: 0.5211
Batch 150, Loss: 0.5384
Batch 160, Loss: 0.5328
Batch 170, Loss: 0.5460
Batch 180, Loss: 0.5022
Batch 190, Loss: 0.5323
Batch 200, Loss: 0.5212
Batch 210, Loss: 0.4894
Batch 220, Loss: 0.5444
Batch 230, Loss: 0.5052
Batch 240, Loss: 0.5031
Batch 250, Loss: 0.5413
Batch 260, Loss: 0.5473
Batch 270, Loss: 0.5332
Batch 280, Loss: 0.5173
Batch 290, Loss: 0.4683
Batch 300, Loss: 0.5103
Batch 310, Loss: 0.5481
Batch 320, Loss: 0.5301
Batch 330, Loss: 0.5371
Batch 340, Loss: 0.5423
Batch 350, Loss: 0.5373
Batch 360, Loss: 0.5374
Batch 370, Loss: 0.5754
Batch 380, Loss: 0.5772
Batch 390, Loss: 0.5008
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.392521858215332 seconds
Epoch 156 accuracy: 75.04%
Batch 10, Loss: 0.5270
Batch 20, Loss: 0.5167
Batch 30, Loss: 0.5003
Batch 40, Loss: 0.5082
Batch 50, Loss: 0.4985
Batch 60, Loss: 0.4500
Batch 70, Loss: 0.4951
Batch 80, Loss: 0.5422
Batch 90, Loss: 0.4854
Batch 100, Loss: 0.4580
Batch 110, Loss: 0.4955
Batch 120, Loss: 0.4771
Batch 130, Loss: 0.5382
Batch 140, Loss: 0.5091
Batch 150, Loss: 0.4986
Batch 160, Loss: 0.5135
Batch 170, Loss: 0.5348
Batch 180, Loss: 0.5063
Batch 190, Loss: 0.4930
Batch 200, Loss: 0.5367
Batch 210, Loss: 0.5418
Batch 220, Loss: 0.4935
Batch 230, Loss: 0.5232
Batch 240, Loss: 0.5264
Batch 250, Loss: 0.5107
Batch 260, Loss: 0.5276
Batch 270, Loss: 0.5516
Batch 280, Loss: 0.5223
Batch 290, Loss: 0.5269
Batch 300, Loss: 0.5028
Batch 310, Loss: 0.5018
Batch 320, Loss: 0.4978
Batch 330, Loss: 0.5355
Batch 340, Loss: 0.5439
Batch 350, Loss: 0.5083
Batch 360, Loss: 0.5848
Batch 370, Loss: 0.5244
Batch 380, Loss: 0.5197
Batch 390, Loss: 0.5310
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.368292331695557 seconds
Epoch 157 accuracy: 75.03%
Batch 10, Loss: 0.4742
Batch 20, Loss: 0.4699
Batch 30, Loss: 0.4825
Batch 40, Loss: 0.4685
Batch 50, Loss: 0.4776
Batch 60, Loss: 0.4847
Batch 70, Loss: 0.5108
Batch 80, Loss: 0.5118
Batch 90, Loss: 0.5333
Batch 100, Loss: 0.5577
Batch 110, Loss: 0.4752
Batch 120, Loss: 0.5494
Batch 130, Loss: 0.4849
Batch 140, Loss: 0.4989
Batch 150, Loss: 0.4613
Batch 160, Loss: 0.5029
Batch 170, Loss: 0.4708
Batch 180, Loss: 0.5447
Batch 190, Loss: 0.4727
Batch 200, Loss: 0.4820
Batch 210, Loss: 0.5135
Batch 220, Loss: 0.4694
Batch 230, Loss: 0.4994
Batch 240, Loss: 0.5370
Batch 250, Loss: 0.5490
Batch 260, Loss: 0.5094
Batch 270, Loss: 0.4856
Batch 280, Loss: 0.5309
Batch 290, Loss: 0.4873
Batch 300, Loss: 0.4997
Batch 310, Loss: 0.5222
Batch 320, Loss: 0.5465
Batch 330, Loss: 0.5247
Batch 340, Loss: 0.5064
Batch 350, Loss: 0.5081
Batch 360, Loss: 0.4585
Batch 370, Loss: 0.5333
Batch 380, Loss: 0.5403
Batch 390, Loss: 0.5036
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.41568660736084 seconds
Epoch 158 accuracy: 76.11%
Batch 10, Loss: 0.5133
Batch 20, Loss: 0.4910
Batch 30, Loss: 0.4981
Batch 40, Loss: 0.4361
Batch 50, Loss: 0.4272
Batch 60, Loss: 0.4706
Batch 70, Loss: 0.4660
Batch 80, Loss: 0.4506
Batch 90, Loss: 0.4470
Batch 100, Loss: 0.4878
Batch 110, Loss: 0.4690
Batch 120, Loss: 0.4677
Batch 130, Loss: 0.5014
Batch 140, Loss: 0.4858
Batch 150, Loss: 0.5069
Batch 160, Loss: 0.4757
Batch 170, Loss: 0.5084
Batch 180, Loss: 0.5062
Batch 190, Loss: 0.4607
Batch 200, Loss: 0.5077
Batch 210, Loss: 0.4803
Batch 220, Loss: 0.4773
Batch 230, Loss: 0.4604
Batch 240, Loss: 0.4747
Batch 250, Loss: 0.4553
Batch 260, Loss: 0.5159
Batch 270, Loss: 0.5074
Batch 280, Loss: 0.4934
Batch 290, Loss: 0.4667
Batch 300, Loss: 0.4876
Batch 310, Loss: 0.4896
Batch 320, Loss: 0.5063
Batch 330, Loss: 0.5348
Batch 340, Loss: 0.5216
Batch 350, Loss: 0.4646
Batch 360, Loss: 0.4410
Batch 370, Loss: 0.4843
Batch 380, Loss: 0.5342
Batch 390, Loss: 0.5152
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.25098752975464 seconds
Epoch 159 accuracy: 76.14%
Batch 10, Loss: 0.4134
Batch 20, Loss: 0.4913
Batch 30, Loss: 0.4587
Batch 40, Loss: 0.4678
Batch 50, Loss: 0.4669
Batch 60, Loss: 0.3998
Batch 70, Loss: 0.4738
Batch 80, Loss: 0.4655
Batch 90, Loss: 0.4913
Batch 100, Loss: 0.5103
Batch 110, Loss: 0.4456
Batch 120, Loss: 0.4855
Batch 130, Loss: 0.5050
Batch 140, Loss: 0.4704
Batch 150, Loss: 0.5216
Batch 160, Loss: 0.4921
Batch 170, Loss: 0.4574
Batch 180, Loss: 0.4903
Batch 190, Loss: 0.5234
Batch 200, Loss: 0.4723
Batch 210, Loss: 0.4700
Batch 220, Loss: 0.4540
Batch 230, Loss: 0.4669
Batch 240, Loss: 0.5229
Batch 250, Loss: 0.4688
Batch 260, Loss: 0.4763
Batch 270, Loss: 0.4666
Batch 280, Loss: 0.5051
Batch 290, Loss: 0.4892
Batch 300, Loss: 0.5069
Batch 310, Loss: 0.4964
Batch 320, Loss: 0.5104
Batch 330, Loss: 0.4653
Batch 340, Loss: 0.4806
Batch 350, Loss: 0.5086
Batch 360, Loss: 0.4755
Batch 370, Loss: 0.4732
Batch 380, Loss: 0.4573
Batch 390, Loss: 0.4766
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.306039571762085 seconds
Epoch 160 accuracy: 77.05%
Batch 10, Loss: 0.4533
Batch 20, Loss: 0.4517
Batch 30, Loss: 0.4403
Batch 40, Loss: 0.4599
Batch 50, Loss: 0.4383
Batch 60, Loss: 0.4307
Batch 70, Loss: 0.4916
Batch 80, Loss: 0.4545
Batch 90, Loss: 0.4666
Batch 100, Loss: 0.4559
Batch 110, Loss: 0.4842
Batch 120, Loss: 0.4237
Batch 130, Loss: 0.4774
Batch 140, Loss: 0.4380
Batch 150, Loss: 0.4784
Batch 160, Loss: 0.4739
Batch 170, Loss: 0.4876
Batch 180, Loss: 0.4600
Batch 190, Loss: 0.4676
Batch 200, Loss: 0.4340
Batch 210, Loss: 0.4614
Batch 220, Loss: 0.4894
Batch 230, Loss: 0.4161
Batch 240, Loss: 0.4700
Batch 250, Loss: 0.4935
Batch 260, Loss: 0.5080
Batch 270, Loss: 0.4814
Batch 280, Loss: 0.4715
Batch 290, Loss: 0.4729
Batch 300, Loss: 0.4584
Batch 310, Loss: 0.4836
Batch 320, Loss: 0.5082
Batch 330, Loss: 0.4542
Batch 340, Loss: 0.4415
Batch 350, Loss: 0.4150
Batch 360, Loss: 0.4769
Batch 370, Loss: 0.4644
Batch 380, Loss: 0.4927
Batch 390, Loss: 0.4292
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.32094645500183 seconds
Epoch 161 accuracy: 75.46%
Batch 10, Loss: 0.4722
Batch 20, Loss: 0.4512
Batch 30, Loss: 0.4520
Batch 40, Loss: 0.4435
Batch 50, Loss: 0.4571
Batch 60, Loss: 0.4286
Batch 70, Loss: 0.4553
Batch 80, Loss: 0.4504
Batch 90, Loss: 0.4536
Batch 100, Loss: 0.4814
Batch 110, Loss: 0.4750
Batch 120, Loss: 0.4438
Batch 130, Loss: 0.4517
Batch 140, Loss: 0.4902
Batch 150, Loss: 0.4727
Batch 160, Loss: 0.4637
Batch 170, Loss: 0.4585
Batch 180, Loss: 0.4611
Batch 190, Loss: 0.4763
Batch 200, Loss: 0.4322
Batch 210, Loss: 0.4639
Batch 220, Loss: 0.4807
Batch 230, Loss: 0.4931
Batch 240, Loss: 0.4771
Batch 250, Loss: 0.4778
Batch 260, Loss: 0.4916
Batch 270, Loss: 0.4660
Batch 280, Loss: 0.4395
Batch 290, Loss: 0.4914
Batch 300, Loss: 0.4553
Batch 310, Loss: 0.4854
Batch 320, Loss: 0.4561
Batch 330, Loss: 0.4905
Batch 340, Loss: 0.4691
Batch 350, Loss: 0.4429
Batch 360, Loss: 0.4675
Batch 370, Loss: 0.4705
Batch 380, Loss: 0.4632
Batch 390, Loss: 0.4775
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.354171752929688 seconds
Epoch 162 accuracy: 76.87%
Batch 10, Loss: 0.4133
Batch 20, Loss: 0.4633
Batch 30, Loss: 0.4141
Batch 40, Loss: 0.4531
Batch 50, Loss: 0.4842
Batch 60, Loss: 0.4184
Batch 70, Loss: 0.4280
Batch 80, Loss: 0.4547
Batch 90, Loss: 0.4262
Batch 100, Loss: 0.4455
Batch 110, Loss: 0.4160
Batch 120, Loss: 0.4696
Batch 130, Loss: 0.4848
Batch 140, Loss: 0.4549
Batch 150, Loss: 0.4417
Batch 160, Loss: 0.4245
Batch 170, Loss: 0.4680
Batch 180, Loss: 0.4659
Batch 190, Loss: 0.4486
Batch 200, Loss: 0.4226
Batch 210, Loss: 0.4215
Batch 220, Loss: 0.4072
Batch 230, Loss: 0.4683
Batch 240, Loss: 0.4666
Batch 250, Loss: 0.4358
Batch 260, Loss: 0.4779
Batch 270, Loss: 0.4268
Batch 280, Loss: 0.4461
Batch 290, Loss: 0.4714
Batch 300, Loss: 0.4254
Batch 310, Loss: 0.4322
Batch 320, Loss: 0.4433
Batch 330, Loss: 0.4524
Batch 340, Loss: 0.4333
Batch 350, Loss: 0.4540
Batch 360, Loss: 0.4533
Batch 370, Loss: 0.4919
Batch 380, Loss: 0.4862
Batch 390, Loss: 0.4672
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.29337167739868 seconds
Epoch 163 accuracy: 76.26%
Batch 10, Loss: 0.4390
Batch 20, Loss: 0.4219
Batch 30, Loss: 0.4430
Batch 40, Loss: 0.4562
Batch 50, Loss: 0.4271
Batch 60, Loss: 0.4276
Batch 70, Loss: 0.4142
Batch 80, Loss: 0.4048
Batch 90, Loss: 0.4073
Batch 100, Loss: 0.4192
Batch 110, Loss: 0.4417
Batch 120, Loss: 0.4378
Batch 130, Loss: 0.4255
Batch 140, Loss: 0.4638
Batch 150, Loss: 0.4260
Batch 160, Loss: 0.4467
Batch 170, Loss: 0.4466
Batch 180, Loss: 0.4398
Batch 190, Loss: 0.4126
Batch 200, Loss: 0.4154
Batch 210, Loss: 0.4412
Batch 220, Loss: 0.4446
Batch 230, Loss: 0.4446
Batch 240, Loss: 0.4390
Batch 250, Loss: 0.4608
Batch 260, Loss: 0.4025
Batch 270, Loss: 0.4331
Batch 280, Loss: 0.3852
Batch 290, Loss: 0.4567
Batch 300, Loss: 0.4827
Batch 310, Loss: 0.4461
Batch 320, Loss: 0.3994
Batch 330, Loss: 0.4276
Batch 340, Loss: 0.4460
Batch 350, Loss: 0.4450
Batch 360, Loss: 0.4804
Batch 370, Loss: 0.4447
Batch 380, Loss: 0.4458
Batch 390, Loss: 0.4383
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.23072910308838 seconds
Epoch 164 accuracy: 77.34%
Batch 10, Loss: 0.4272
Batch 20, Loss: 0.4022
Batch 30, Loss: 0.3948
Batch 40, Loss: 0.4204
Batch 50, Loss: 0.4219
Batch 60, Loss: 0.4071
Batch 70, Loss: 0.3869
Batch 80, Loss: 0.3732
Batch 90, Loss: 0.4255
Batch 100, Loss: 0.4188
Batch 110, Loss: 0.4502
Batch 120, Loss: 0.4087
Batch 130, Loss: 0.4132
Batch 140, Loss: 0.4210
Batch 150, Loss: 0.4236
Batch 160, Loss: 0.4206
Batch 170, Loss: 0.4060
Batch 180, Loss: 0.4451
Batch 190, Loss: 0.4484
Batch 200, Loss: 0.3914
Batch 210, Loss: 0.4333
Batch 220, Loss: 0.4083
Batch 230, Loss: 0.4323
Batch 240, Loss: 0.4340
Batch 250, Loss: 0.4449
Batch 260, Loss: 0.4132
Batch 270, Loss: 0.3939
Batch 280, Loss: 0.4560
Batch 290, Loss: 0.4304
Batch 300, Loss: 0.4181
Batch 310, Loss: 0.4172
Batch 320, Loss: 0.4108
Batch 330, Loss: 0.4337
Batch 340, Loss: 0.4572
Batch 350, Loss: 0.4477
Batch 360, Loss: 0.4640
Batch 370, Loss: 0.4169
Batch 380, Loss: 0.4459
Batch 390, Loss: 0.3991
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.311801195144653 seconds
Epoch 165 accuracy: 77.22%
Batch 10, Loss: 0.4102
Batch 20, Loss: 0.3895
Batch 30, Loss: 0.4174
Batch 40, Loss: 0.3804
Batch 50, Loss: 0.3937
Batch 60, Loss: 0.4166
Batch 70, Loss: 0.4444
Batch 80, Loss: 0.4268
Batch 90, Loss: 0.4275
Batch 100, Loss: 0.4177
Batch 110, Loss: 0.4251
Batch 120, Loss: 0.4134
Batch 130, Loss: 0.4013
Batch 140, Loss: 0.3847
Batch 150, Loss: 0.4261
Batch 160, Loss: 0.4179
Batch 170, Loss: 0.4068
Batch 180, Loss: 0.4149
Batch 190, Loss: 0.4451
Batch 200, Loss: 0.4450
Batch 210, Loss: 0.3875
Batch 220, Loss: 0.4549
Batch 230, Loss: 0.3954
Batch 240, Loss: 0.3977
Batch 250, Loss: 0.3915
Batch 260, Loss: 0.3825
Batch 270, Loss: 0.3873
Batch 280, Loss: 0.3616
Batch 290, Loss: 0.3990
Batch 300, Loss: 0.4107
Batch 310, Loss: 0.3896
Batch 320, Loss: 0.4060
Batch 330, Loss: 0.4150
Batch 340, Loss: 0.4423
Batch 350, Loss: 0.4320
Batch 360, Loss: 0.3912
Batch 370, Loss: 0.4425
Batch 380, Loss: 0.4334
Batch 390, Loss: 0.4059
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.261371850967407 seconds
Epoch 166 accuracy: 77.21%
Batch 10, Loss: 0.3859
Batch 20, Loss: 0.3677
Batch 30, Loss: 0.3424
Batch 40, Loss: 0.3986
Batch 50, Loss: 0.3527
Batch 60, Loss: 0.4263
Batch 70, Loss: 0.3990
Batch 80, Loss: 0.4120
Batch 90, Loss: 0.3924
Batch 100, Loss: 0.3774
Batch 110, Loss: 0.4452
Batch 120, Loss: 0.3563
Batch 130, Loss: 0.4058
Batch 140, Loss: 0.4143
Batch 150, Loss: 0.4009
Batch 160, Loss: 0.4128
Batch 170, Loss: 0.3818
Batch 180, Loss: 0.4089
Batch 190, Loss: 0.4094
Batch 200, Loss: 0.3809
Batch 210, Loss: 0.3707
Batch 220, Loss: 0.3641
Batch 230, Loss: 0.4078
Batch 240, Loss: 0.4013
Batch 250, Loss: 0.3796
Batch 260, Loss: 0.4176
Batch 270, Loss: 0.4174
Batch 280, Loss: 0.3915
Batch 290, Loss: 0.3827
Batch 300, Loss: 0.3972
Batch 310, Loss: 0.4139
Batch 320, Loss: 0.3740
Batch 330, Loss: 0.4200
Batch 340, Loss: 0.4102
Batch 350, Loss: 0.4552
Batch 360, Loss: 0.3975
Batch 370, Loss: 0.3941
Batch 380, Loss: 0.4134
Batch 390, Loss: 0.4299
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.30371880531311 seconds
Epoch 167 accuracy: 77.26%
Batch 10, Loss: 0.3815
Batch 20, Loss: 0.3836
Batch 30, Loss: 0.4087
Batch 40, Loss: 0.3733
Batch 50, Loss: 0.3645
Batch 60, Loss: 0.3720
Batch 70, Loss: 0.3923
Batch 80, Loss: 0.3794
Batch 90, Loss: 0.3689
Batch 100, Loss: 0.4510
Batch 110, Loss: 0.4076
Batch 120, Loss: 0.3970
Batch 130, Loss: 0.3501
Batch 140, Loss: 0.4209
Batch 150, Loss: 0.3507
Batch 160, Loss: 0.3992
Batch 170, Loss: 0.4062
Batch 180, Loss: 0.3399
Batch 190, Loss: 0.3881
Batch 200, Loss: 0.4016
Batch 210, Loss: 0.3820
Batch 220, Loss: 0.4299
Batch 230, Loss: 0.3859
Batch 240, Loss: 0.3880
Batch 250, Loss: 0.3926
Batch 260, Loss: 0.4300
Batch 270, Loss: 0.4118
Batch 280, Loss: 0.4035
Batch 290, Loss: 0.3849
Batch 300, Loss: 0.3836
Batch 310, Loss: 0.3569
Batch 320, Loss: 0.3992
Batch 330, Loss: 0.4046
Batch 340, Loss: 0.3952
Batch 350, Loss: 0.4095
Batch 360, Loss: 0.4179
Batch 370, Loss: 0.4120
Batch 380, Loss: 0.4041
Batch 390, Loss: 0.3995
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.355948448181152 seconds
Epoch 168 accuracy: 77.37%
Batch 10, Loss: 0.3976
Batch 20, Loss: 0.3831
Batch 30, Loss: 0.3950
Batch 40, Loss: 0.4391
Batch 50, Loss: 0.3832
Batch 60, Loss: 0.3797
Batch 70, Loss: 0.3550
Batch 80, Loss: 0.3784
Batch 90, Loss: 0.3779
Batch 100, Loss: 0.3699
Batch 110, Loss: 0.3797
Batch 120, Loss: 0.3643
Batch 130, Loss: 0.3587
Batch 140, Loss: 0.3083
Batch 150, Loss: 0.3511
Batch 160, Loss: 0.3760
Batch 170, Loss: 0.3702
Batch 180, Loss: 0.3885
Batch 190, Loss: 0.3942
Batch 200, Loss: 0.3919
Batch 210, Loss: 0.3752
Batch 220, Loss: 0.3537
Batch 230, Loss: 0.3657
Batch 240, Loss: 0.4033
Batch 250, Loss: 0.3743
Batch 260, Loss: 0.3814
Batch 270, Loss: 0.3729
Batch 280, Loss: 0.3454
Batch 290, Loss: 0.3785
Batch 300, Loss: 0.3926
Batch 310, Loss: 0.3983
Batch 320, Loss: 0.3559
Batch 330, Loss: 0.3810
Batch 340, Loss: 0.4095
Batch 350, Loss: 0.3797
Batch 360, Loss: 0.3768
Batch 370, Loss: 0.4089
Batch 380, Loss: 0.4069
Batch 390, Loss: 0.4260
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.31972575187683 seconds
Epoch 169 accuracy: 77.75%
Batch 10, Loss: 0.3776
Batch 20, Loss: 0.3524
Batch 30, Loss: 0.3823
Batch 40, Loss: 0.3837
Batch 50, Loss: 0.3489
Batch 60, Loss: 0.3603
Batch 70, Loss: 0.3583
Batch 80, Loss: 0.3633
Batch 90, Loss: 0.3821
Batch 100, Loss: 0.3861
Batch 110, Loss: 0.3739
Batch 120, Loss: 0.3931
Batch 130, Loss: 0.3591
Batch 140, Loss: 0.3782
Batch 150, Loss: 0.3458
Batch 160, Loss: 0.3653
Batch 170, Loss: 0.3465
Batch 180, Loss: 0.3820
Batch 190, Loss: 0.3828
Batch 200, Loss: 0.3877
Batch 210, Loss: 0.3746
Batch 220, Loss: 0.3362
Batch 230, Loss: 0.3488
Batch 240, Loss: 0.3961
Batch 250, Loss: 0.3590
Batch 260, Loss: 0.3922
Batch 270, Loss: 0.4105
Batch 280, Loss: 0.3492
Batch 290, Loss: 0.3462
Batch 300, Loss: 0.3511
Batch 310, Loss: 0.3711
Batch 320, Loss: 0.4097
Batch 330, Loss: 0.3754
Batch 340, Loss: 0.3931
Batch 350, Loss: 0.3504
Batch 360, Loss: 0.4118
Batch 370, Loss: 0.3755
Batch 380, Loss: 0.3850
Batch 390, Loss: 0.3638
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.321127891540527 seconds
Epoch 170 accuracy: 77.68%
Batch 10, Loss: 0.3763
Batch 20, Loss: 0.3850
Batch 30, Loss: 0.3540
Batch 40, Loss: 0.3882
Batch 50, Loss: 0.3829
Batch 60, Loss: 0.3348
Batch 70, Loss: 0.3407
Batch 80, Loss: 0.3562
Batch 90, Loss: 0.3570
Batch 100, Loss: 0.3250
Batch 110, Loss: 0.3263
Batch 120, Loss: 0.3817
Batch 130, Loss: 0.3525
Batch 140, Loss: 0.3133
Batch 150, Loss: 0.3518
Batch 160, Loss: 0.3616
Batch 170, Loss: 0.3386
Batch 180, Loss: 0.3792
Batch 190, Loss: 0.3997
Batch 200, Loss: 0.3824
Batch 210, Loss: 0.3375
Batch 220, Loss: 0.3570
Batch 230, Loss: 0.3623
Batch 240, Loss: 0.4020
Batch 250, Loss: 0.3722
Batch 260, Loss: 0.3688
Batch 270, Loss: 0.3963
Batch 280, Loss: 0.3377
Batch 290, Loss: 0.3630
Batch 300, Loss: 0.3569
Batch 310, Loss: 0.3632
Batch 320, Loss: 0.3515
Batch 330, Loss: 0.4000
Batch 340, Loss: 0.3930
Batch 350, Loss: 0.3801
Batch 360, Loss: 0.3729
Batch 370, Loss: 0.3872
Batch 380, Loss: 0.3594
Batch 390, Loss: 0.3796
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.27182960510254 seconds
Epoch 171 accuracy: 78.13%
Batch 10, Loss: 0.3314
Batch 20, Loss: 0.3513
Batch 30, Loss: 0.3820
Batch 40, Loss: 0.3887
Batch 50, Loss: 0.3337
Batch 60, Loss: 0.3579
Batch 70, Loss: 0.3177
Batch 80, Loss: 0.3378
Batch 90, Loss: 0.3347
Batch 100, Loss: 0.3411
Batch 110, Loss: 0.3681
Batch 120, Loss: 0.3590
Batch 130, Loss: 0.3399
Batch 140, Loss: 0.3359
Batch 150, Loss: 0.3592
Batch 160, Loss: 0.3387
Batch 170, Loss: 0.3321
Batch 180, Loss: 0.3260
Batch 190, Loss: 0.3665
Batch 200, Loss: 0.3687
Batch 210, Loss: 0.3306
Batch 220, Loss: 0.3476
Batch 230, Loss: 0.3636
Batch 240, Loss: 0.3997
Batch 250, Loss: 0.3811
Batch 260, Loss: 0.3819
Batch 270, Loss: 0.3845
Batch 280, Loss: 0.3539
Batch 290, Loss: 0.3562
Batch 300, Loss: 0.3415
Batch 310, Loss: 0.3552
Batch 320, Loss: 0.4083
Batch 330, Loss: 0.3965
Batch 340, Loss: 0.3407
Batch 350, Loss: 0.3456
Batch 360, Loss: 0.3757
Batch 370, Loss: 0.3201
Batch 380, Loss: 0.3667
Batch 390, Loss: 0.3454
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.27208113670349 seconds
Epoch 172 accuracy: 78.76%
Batch 10, Loss: 0.3298
Batch 20, Loss: 0.3482
Batch 30, Loss: 0.2927
Batch 40, Loss: 0.3545
Batch 50, Loss: 0.3380
Batch 60, Loss: 0.3747
Batch 70, Loss: 0.3519
Batch 80, Loss: 0.3093
Batch 90, Loss: 0.3229
Batch 100, Loss: 0.3500
Batch 110, Loss: 0.2883
Batch 120, Loss: 0.4065
Batch 130, Loss: 0.3496
Batch 140, Loss: 0.3652
Batch 150, Loss: 0.3427
Batch 160, Loss: 0.3243
Batch 170, Loss: 0.3440
Batch 180, Loss: 0.3169
Batch 190, Loss: 0.3636
Batch 200, Loss: 0.3389
Batch 210, Loss: 0.3299
Batch 220, Loss: 0.3479
Batch 230, Loss: 0.3937
Batch 240, Loss: 0.3560
Batch 250, Loss: 0.3980
Batch 260, Loss: 0.3568
Batch 270, Loss: 0.3641
Batch 280, Loss: 0.3619
Batch 290, Loss: 0.3320
Batch 300, Loss: 0.3791
Batch 310, Loss: 0.3453
Batch 320, Loss: 0.3722
Batch 330, Loss: 0.3472
Batch 340, Loss: 0.3278
Batch 350, Loss: 0.3332
Batch 360, Loss: 0.3762
Batch 370, Loss: 0.3510
Batch 380, Loss: 0.3558
Batch 390, Loss: 0.3397
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.22408175468445 seconds
Epoch 173 accuracy: 78.58%
Batch 10, Loss: 0.3245
Batch 20, Loss: 0.3335
Batch 30, Loss: 0.3236
Batch 40, Loss: 0.3317
Batch 50, Loss: 0.3901
Batch 60, Loss: 0.3472
Batch 70, Loss: 0.3296
Batch 80, Loss: 0.3560
Batch 90, Loss: 0.3444
Batch 100, Loss: 0.3373
Batch 110, Loss: 0.3255
Batch 120, Loss: 0.3665
Batch 130, Loss: 0.3259
Batch 140, Loss: 0.3270
Batch 150, Loss: 0.3428
Batch 160, Loss: 0.3339
Batch 170, Loss: 0.3274
Batch 180, Loss: 0.3466
Batch 190, Loss: 0.3350
Batch 200, Loss: 0.3235
Batch 210, Loss: 0.3209
Batch 220, Loss: 0.3188
Batch 230, Loss: 0.3053
Batch 240, Loss: 0.3746
Batch 250, Loss: 0.3547
Batch 260, Loss: 0.3142
Batch 270, Loss: 0.3299
Batch 280, Loss: 0.3255
Batch 290, Loss: 0.3533
Batch 300, Loss: 0.3678
Batch 310, Loss: 0.3533
Batch 320, Loss: 0.3225
Batch 330, Loss: 0.3291
Batch 340, Loss: 0.3719
Batch 350, Loss: 0.3594
Batch 360, Loss: 0.3694
Batch 370, Loss: 0.3266
Batch 380, Loss: 0.3214
Batch 390, Loss: 0.3362
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.26979374885559 seconds
Epoch 174 accuracy: 78.45%
Batch 10, Loss: 0.3417
Batch 20, Loss: 0.2917
Batch 30, Loss: 0.3324
Batch 40, Loss: 0.3343
Batch 50, Loss: 0.2886
Batch 60, Loss: 0.3446
Batch 70, Loss: 0.3322
Batch 80, Loss: 0.3318
Batch 90, Loss: 0.3148
Batch 100, Loss: 0.3302
Batch 110, Loss: 0.3290
Batch 120, Loss: 0.3085
Batch 130, Loss: 0.3089
Batch 140, Loss: 0.3074
Batch 150, Loss: 0.3595
Batch 160, Loss: 0.3328
Batch 170, Loss: 0.3382
Batch 180, Loss: 0.2761
Batch 190, Loss: 0.3634
Batch 200, Loss: 0.3389
Batch 210, Loss: 0.3176
Batch 220, Loss: 0.2954
Batch 230, Loss: 0.3290
Batch 240, Loss: 0.3561
Batch 250, Loss: 0.3521
Batch 260, Loss: 0.3435
Batch 270, Loss: 0.3471
Batch 280, Loss: 0.2831
Batch 290, Loss: 0.3285
Batch 300, Loss: 0.3486
Batch 310, Loss: 0.3538
Batch 320, Loss: 0.3238
Batch 330, Loss: 0.3250
Batch 340, Loss: 0.3326
Batch 350, Loss: 0.3288
Batch 360, Loss: 0.3475
Batch 370, Loss: 0.3610
Batch 380, Loss: 0.3659
Batch 390, Loss: 0.3381
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.149871826171875 seconds
Epoch 175 accuracy: 78.54%
Batch 10, Loss: 0.3064
Batch 20, Loss: 0.3087
Batch 30, Loss: 0.3129
Batch 40, Loss: 0.3407
Batch 50, Loss: 0.3033
Batch 60, Loss: 0.3178
Batch 70, Loss: 0.3016
Batch 80, Loss: 0.3511
Batch 90, Loss: 0.3092
Batch 100, Loss: 0.2794
Batch 110, Loss: 0.3246
Batch 120, Loss: 0.3118
Batch 130, Loss: 0.3340
Batch 140, Loss: 0.3334
Batch 150, Loss: 0.3364
Batch 160, Loss: 0.3181
Batch 170, Loss: 0.3340
Batch 180, Loss: 0.3156
Batch 190, Loss: 0.3182
Batch 200, Loss: 0.3116
Batch 210, Loss: 0.3176
Batch 220, Loss: 0.3334
Batch 230, Loss: 0.2999
Batch 240, Loss: 0.3435
Batch 250, Loss: 0.2845
Batch 260, Loss: 0.3542
Batch 270, Loss: 0.3104
Batch 280, Loss: 0.3000
Batch 290, Loss: 0.2990
Batch 300, Loss: 0.3295
Batch 310, Loss: 0.2970
Batch 320, Loss: 0.2977
Batch 330, Loss: 0.2967
Batch 340, Loss: 0.3578
Batch 350, Loss: 0.2911
Batch 360, Loss: 0.3305
Batch 370, Loss: 0.3535
Batch 380, Loss: 0.2995
Batch 390, Loss: 0.3110
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.316384315490723 seconds
Epoch 176 accuracy: 78.94%
Batch 10, Loss: 0.2971
Batch 20, Loss: 0.2869
Batch 30, Loss: 0.3401
Batch 40, Loss: 0.3264
Batch 50, Loss: 0.3071
Batch 60, Loss: 0.2834
Batch 70, Loss: 0.3066
Batch 80, Loss: 0.2929
Batch 90, Loss: 0.2919
Batch 100, Loss: 0.3050
Batch 110, Loss: 0.3056
Batch 120, Loss: 0.3489
Batch 130, Loss: 0.2899
Batch 140, Loss: 0.3222
Batch 150, Loss: 0.3008
Batch 160, Loss: 0.2899
Batch 170, Loss: 0.3312
Batch 180, Loss: 0.3407
Batch 190, Loss: 0.2974
Batch 200, Loss: 0.3034
Batch 210, Loss: 0.3169
Batch 220, Loss: 0.2660
Batch 230, Loss: 0.2808
Batch 240, Loss: 0.3117
Batch 250, Loss: 0.2899
Batch 260, Loss: 0.3058
Batch 270, Loss: 0.3100
Batch 280, Loss: 0.3115
Batch 290, Loss: 0.3267
Batch 300, Loss: 0.3164
Batch 310, Loss: 0.3057
Batch 320, Loss: 0.2773
Batch 330, Loss: 0.3047
Batch 340, Loss: 0.2874
Batch 350, Loss: 0.3522
Batch 360, Loss: 0.3359
Batch 370, Loss: 0.3479
Batch 380, Loss: 0.3141
Batch 390, Loss: 0.3221
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.246768474578857 seconds
Epoch 177 accuracy: 79.38%
Batch 10, Loss: 0.3106
Batch 20, Loss: 0.3242
Batch 30, Loss: 0.2626
Batch 40, Loss: 0.3018
Batch 50, Loss: 0.3095
Batch 60, Loss: 0.3577
Batch 70, Loss: 0.3223
Batch 80, Loss: 0.2995
Batch 90, Loss: 0.3177
Batch 100, Loss: 0.3056
Batch 110, Loss: 0.2989
Batch 120, Loss: 0.3016
Batch 130, Loss: 0.2665
Batch 140, Loss: 0.2903
Batch 150, Loss: 0.2840
Batch 160, Loss: 0.3552
Batch 170, Loss: 0.3126
Batch 180, Loss: 0.3294
Batch 190, Loss: 0.3133
Batch 200, Loss: 0.3064
Batch 210, Loss: 0.3210
Batch 220, Loss: 0.3160
Batch 230, Loss: 0.3286
Batch 240, Loss: 0.3059
Batch 250, Loss: 0.2786
Batch 260, Loss: 0.3251
Batch 270, Loss: 0.3152
Batch 280, Loss: 0.3167
Batch 290, Loss: 0.2892
Batch 300, Loss: 0.2950
Batch 310, Loss: 0.3275
Batch 320, Loss: 0.2915
Batch 330, Loss: 0.2906
Batch 340, Loss: 0.3181
Batch 350, Loss: 0.3155
Batch 360, Loss: 0.2818
Batch 370, Loss: 0.3099
Batch 380, Loss: 0.3101
Batch 390, Loss: 0.2856
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.262654781341553 seconds
Epoch 178 accuracy: 79.71%
Batch 10, Loss: 0.2684
Batch 20, Loss: 0.3054
Batch 30, Loss: 0.2948
Batch 40, Loss: 0.2926
Batch 50, Loss: 0.3254
Batch 60, Loss: 0.2741
Batch 70, Loss: 0.2983
Batch 80, Loss: 0.3067
Batch 90, Loss: 0.2934
Batch 100, Loss: 0.3192
Batch 110, Loss: 0.3069
Batch 120, Loss: 0.3167
Batch 130, Loss: 0.2940
Batch 140, Loss: 0.2871
Batch 150, Loss: 0.3019
Batch 160, Loss: 0.3047
Batch 170, Loss: 0.3255
Batch 180, Loss: 0.2815
Batch 190, Loss: 0.2639
Batch 200, Loss: 0.2935
Batch 210, Loss: 0.3148
Batch 220, Loss: 0.2636
Batch 230, Loss: 0.3110
Batch 240, Loss: 0.3113
Batch 250, Loss: 0.3183
Batch 260, Loss: 0.2889
Batch 270, Loss: 0.2809
Batch 280, Loss: 0.2914
Batch 290, Loss: 0.3283
Batch 300, Loss: 0.3069
Batch 310, Loss: 0.2861
Batch 320, Loss: 0.3177
Batch 330, Loss: 0.3140
Batch 340, Loss: 0.2913
Batch 350, Loss: 0.3326
Batch 360, Loss: 0.3351
Batch 370, Loss: 0.2941
Batch 380, Loss: 0.2805
Batch 390, Loss: 0.2945
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.327497243881226 seconds
Epoch 179 accuracy: 79.09%
Batch 10, Loss: 0.2740
Batch 20, Loss: 0.2960
Batch 30, Loss: 0.2728
Batch 40, Loss: 0.2664
Batch 50, Loss: 0.2935
Batch 60, Loss: 0.2638
Batch 70, Loss: 0.2846
Batch 80, Loss: 0.3047
Batch 90, Loss: 0.3170
Batch 100, Loss: 0.2907
Batch 110, Loss: 0.2921
Batch 120, Loss: 0.2911
Batch 130, Loss: 0.2646
Batch 140, Loss: 0.2793
Batch 150, Loss: 0.2617
Batch 160, Loss: 0.3289
Batch 170, Loss: 0.3122
Batch 180, Loss: 0.3199
Batch 190, Loss: 0.2463
Batch 200, Loss: 0.2926
Batch 210, Loss: 0.2910
Batch 220, Loss: 0.2538
Batch 230, Loss: 0.2914
Batch 240, Loss: 0.3251
Batch 250, Loss: 0.2894
Batch 260, Loss: 0.3293
Batch 270, Loss: 0.2911
Batch 280, Loss: 0.2991
Batch 290, Loss: 0.2709
Batch 300, Loss: 0.3026
Batch 310, Loss: 0.3010
Batch 320, Loss: 0.2999
Batch 330, Loss: 0.2977
Batch 340, Loss: 0.2827
Batch 350, Loss: 0.2801
Batch 360, Loss: 0.3417
Batch 370, Loss: 0.3083
Batch 380, Loss: 0.3436
Batch 390, Loss: 0.3166
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.20184350013733 seconds
Epoch 180 accuracy: 79.37%
Batch 10, Loss: 0.2797
Batch 20, Loss: 0.2974
Batch 30, Loss: 0.2986
Batch 40, Loss: 0.2730
Batch 50, Loss: 0.3086
Batch 60, Loss: 0.2919
Batch 70, Loss: 0.3014
Batch 80, Loss: 0.2714
Batch 90, Loss: 0.3324
Batch 100, Loss: 0.3024
Batch 110, Loss: 0.2651
Batch 120, Loss: 0.2826
Batch 130, Loss: 0.2594
Batch 140, Loss: 0.2681
Batch 150, Loss: 0.2732
Batch 160, Loss: 0.3017
Batch 170, Loss: 0.2957
Batch 180, Loss: 0.3194
Batch 190, Loss: 0.2979
Batch 200, Loss: 0.2896
Batch 210, Loss: 0.2748
Batch 220, Loss: 0.2760
Batch 230, Loss: 0.2986
Batch 240, Loss: 0.3262
Batch 250, Loss: 0.3044
Batch 260, Loss: 0.2729
Batch 270, Loss: 0.2652
Batch 280, Loss: 0.2932
Batch 290, Loss: 0.2638
Batch 300, Loss: 0.2578
Batch 310, Loss: 0.2764
Batch 320, Loss: 0.2657
Batch 330, Loss: 0.3180
Batch 340, Loss: 0.3101
Batch 350, Loss: 0.2582
Batch 360, Loss: 0.2712
Batch 370, Loss: 0.2730
Batch 380, Loss: 0.3161
Batch 390, Loss: 0.2995
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.18203043937683 seconds
Epoch 181 accuracy: 79.39%
Batch 10, Loss: 0.2933
Batch 20, Loss: 0.2803
Batch 30, Loss: 0.2775
Batch 40, Loss: 0.2653
Batch 50, Loss: 0.3130
Batch 60, Loss: 0.3031
Batch 70, Loss: 0.3090
Batch 80, Loss: 0.2761
Batch 90, Loss: 0.2560
Batch 100, Loss: 0.3017
Batch 110, Loss: 0.2773
Batch 120, Loss: 0.2500
Batch 130, Loss: 0.2888
Batch 140, Loss: 0.2665
Batch 150, Loss: 0.2600
Batch 160, Loss: 0.2684
Batch 170, Loss: 0.2517
Batch 180, Loss: 0.3097
Batch 190, Loss: 0.2992
Batch 200, Loss: 0.2721
Batch 210, Loss: 0.2630
Batch 220, Loss: 0.2612
Batch 230, Loss: 0.2998
Batch 240, Loss: 0.2924
Batch 250, Loss: 0.2938
Batch 260, Loss: 0.2652
Batch 270, Loss: 0.2765
Batch 280, Loss: 0.2919
Batch 290, Loss: 0.2625
Batch 300, Loss: 0.2461
Batch 310, Loss: 0.3093
Batch 320, Loss: 0.2917
Batch 330, Loss: 0.2642
Batch 340, Loss: 0.2869
Batch 350, Loss: 0.2594
Batch 360, Loss: 0.2907
Batch 370, Loss: 0.2701
Batch 380, Loss: 0.2568
Batch 390, Loss: 0.2496
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.20214605331421 seconds
Epoch 182 accuracy: 79.63%
Batch 10, Loss: 0.2628
Batch 20, Loss: 0.2746
Batch 30, Loss: 0.2790
Batch 40, Loss: 0.2882
Batch 50, Loss: 0.2647
Batch 60, Loss: 0.2402
Batch 70, Loss: 0.2696
Batch 80, Loss: 0.2679
Batch 90, Loss: 0.2629
Batch 100, Loss: 0.2903
Batch 110, Loss: 0.2389
Batch 120, Loss: 0.3170
Batch 130, Loss: 0.2489
Batch 140, Loss: 0.2590
Batch 150, Loss: 0.2544
Batch 160, Loss: 0.2584
Batch 170, Loss: 0.2636
Batch 180, Loss: 0.2734
Batch 190, Loss: 0.2940
Batch 200, Loss: 0.2541
Batch 210, Loss: 0.2927
Batch 220, Loss: 0.2848
Batch 230, Loss: 0.2600
Batch 240, Loss: 0.2887
Batch 250, Loss: 0.2829
Batch 260, Loss: 0.2745
Batch 270, Loss: 0.2845
Batch 280, Loss: 0.2917
Batch 290, Loss: 0.2924
Batch 300, Loss: 0.2750
Batch 310, Loss: 0.2735
Batch 320, Loss: 0.2545
Batch 330, Loss: 0.2856
Batch 340, Loss: 0.2725
Batch 350, Loss: 0.2738
Batch 360, Loss: 0.2787
Batch 370, Loss: 0.2873
Batch 380, Loss: 0.2645
Batch 390, Loss: 0.2706
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.302816152572632 seconds
Epoch 183 accuracy: 79.77%
Batch 10, Loss: 0.2978
Batch 20, Loss: 0.2769
Batch 30, Loss: 0.2802
Batch 40, Loss: 0.2640
Batch 50, Loss: 0.2418
Batch 60, Loss: 0.2751
Batch 70, Loss: 0.2645
Batch 80, Loss: 0.2955
Batch 90, Loss: 0.2560
Batch 100, Loss: 0.2690
Batch 110, Loss: 0.2709
Batch 120, Loss: 0.3000
Batch 130, Loss: 0.2591
Batch 140, Loss: 0.2726
Batch 150, Loss: 0.2580
Batch 160, Loss: 0.2596
Batch 170, Loss: 0.2257
Batch 180, Loss: 0.2821
Batch 190, Loss: 0.2404
Batch 200, Loss: 0.2647
Batch 210, Loss: 0.2651
Batch 220, Loss: 0.2575
Batch 230, Loss: 0.2765
Batch 240, Loss: 0.2845
Batch 250, Loss: 0.2688
Batch 260, Loss: 0.2799
Batch 270, Loss: 0.2758
Batch 280, Loss: 0.2805
Batch 290, Loss: 0.2637
Batch 300, Loss: 0.2626
Batch 310, Loss: 0.3169
Batch 320, Loss: 0.3039
Batch 330, Loss: 0.2578
Batch 340, Loss: 0.2969
Batch 350, Loss: 0.2550
Batch 360, Loss: 0.2648
Batch 370, Loss: 0.2481
Batch 380, Loss: 0.2597
Batch 390, Loss: 0.2532
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.353983640670776 seconds
Epoch 184 accuracy: 79.83%
Batch 10, Loss: 0.2761
Batch 20, Loss: 0.2835
Batch 30, Loss: 0.2763
Batch 40, Loss: 0.2787
Batch 50, Loss: 0.2320
Batch 60, Loss: 0.2697
Batch 70, Loss: 0.2637
Batch 80, Loss: 0.2992
Batch 90, Loss: 0.2525
Batch 100, Loss: 0.2885
Batch 110, Loss: 0.3300
Batch 120, Loss: 0.2141
Batch 130, Loss: 0.2399
Batch 140, Loss: 0.2530
Batch 150, Loss: 0.2933
Batch 160, Loss: 0.2914
Batch 170, Loss: 0.2748
Batch 180, Loss: 0.2813
Batch 190, Loss: 0.2446
Batch 200, Loss: 0.2440
Batch 210, Loss: 0.2570
Batch 220, Loss: 0.2926
Batch 230, Loss: 0.2634
Batch 240, Loss: 0.2876
Batch 250, Loss: 0.2422
Batch 260, Loss: 0.2637
Batch 270, Loss: 0.2624
Batch 280, Loss: 0.2690
Batch 290, Loss: 0.2558
Batch 300, Loss: 0.2709
Batch 310, Loss: 0.2697
Batch 320, Loss: 0.2832
Batch 330, Loss: 0.2542
Batch 340, Loss: 0.2596
Batch 350, Loss: 0.2460
Batch 360, Loss: 0.2364
Batch 370, Loss: 0.2831
Batch 380, Loss: 0.2792
Batch 390, Loss: 0.2733
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.274479389190674 seconds
Epoch 185 accuracy: 79.88%
Batch 10, Loss: 0.2627
Batch 20, Loss: 0.2455
Batch 30, Loss: 0.2398
Batch 40, Loss: 0.2717
Batch 50, Loss: 0.3031
Batch 60, Loss: 0.2578
Batch 70, Loss: 0.2621
Batch 80, Loss: 0.2599
Batch 90, Loss: 0.2568
Batch 100, Loss: 0.2462
Batch 110, Loss: 0.2299
Batch 120, Loss: 0.2805
Batch 130, Loss: 0.2709
Batch 140, Loss: 0.2296
Batch 150, Loss: 0.2358
Batch 160, Loss: 0.2600
Batch 170, Loss: 0.2725
Batch 180, Loss: 0.2694
Batch 190, Loss: 0.2940
Batch 200, Loss: 0.2542
Batch 210, Loss: 0.2807
Batch 220, Loss: 0.2557
Batch 230, Loss: 0.2874
Batch 240, Loss: 0.2460
Batch 250, Loss: 0.2361
Batch 260, Loss: 0.2460
Batch 270, Loss: 0.2625
Batch 280, Loss: 0.2791
Batch 290, Loss: 0.2449
Batch 300, Loss: 0.2953
Batch 310, Loss: 0.2763
Batch 320, Loss: 0.2719
Batch 330, Loss: 0.2843
Batch 340, Loss: 0.2845
Batch 350, Loss: 0.2510
Batch 360, Loss: 0.2332
Batch 370, Loss: 0.2488
Batch 380, Loss: 0.2804
Batch 390, Loss: 0.2784
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.299562692642212 seconds
Epoch 186 accuracy: 79.84%
Batch 10, Loss: 0.2791
Batch 20, Loss: 0.2524
Batch 30, Loss: 0.2602
Batch 40, Loss: 0.2651
Batch 50, Loss: 0.2597
Batch 60, Loss: 0.2473
Batch 70, Loss: 0.2525
Batch 80, Loss: 0.2535
Batch 90, Loss: 0.2740
Batch 100, Loss: 0.2492
Batch 110, Loss: 0.2109
Batch 120, Loss: 0.2752
Batch 130, Loss: 0.2583
Batch 140, Loss: 0.2805
Batch 150, Loss: 0.2788
Batch 160, Loss: 0.2640
Batch 170, Loss: 0.2478
Batch 180, Loss: 0.2677
Batch 190, Loss: 0.2663
Batch 200, Loss: 0.2628
Batch 210, Loss: 0.2451
Batch 220, Loss: 0.2895
Batch 230, Loss: 0.2891
Batch 240, Loss: 0.2379
Batch 250, Loss: 0.2516
Batch 260, Loss: 0.2588
Batch 270, Loss: 0.2521
Batch 280, Loss: 0.2473
Batch 290, Loss: 0.2660
Batch 300, Loss: 0.2699
Batch 310, Loss: 0.2363
Batch 320, Loss: 0.2679
Batch 330, Loss: 0.2654
Batch 340, Loss: 0.2668
Batch 350, Loss: 0.2502
Batch 360, Loss: 0.2612
Batch 370, Loss: 0.2634
Batch 380, Loss: 0.2564
Batch 390, Loss: 0.2605
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.32041835784912 seconds
Epoch 187 accuracy: 80.08%
Batch 10, Loss: 0.2633
Batch 20, Loss: 0.2650
Batch 30, Loss: 0.2384
Batch 40, Loss: 0.2801
Batch 50, Loss: 0.2631
Batch 60, Loss: 0.2572
Batch 70, Loss: 0.2919
Batch 80, Loss: 0.2350
Batch 90, Loss: 0.2721
Batch 100, Loss: 0.2472
Batch 110, Loss: 0.2376
Batch 120, Loss: 0.2475
Batch 130, Loss: 0.2763
Batch 140, Loss: 0.2696
Batch 150, Loss: 0.2911
Batch 160, Loss: 0.2490
Batch 170, Loss: 0.2567
Batch 180, Loss: 0.2324
Batch 190, Loss: 0.2538
Batch 200, Loss: 0.2393
Batch 210, Loss: 0.2893
Batch 220, Loss: 0.2568
Batch 230, Loss: 0.2054
Batch 240, Loss: 0.2372
Batch 250, Loss: 0.2615
Batch 260, Loss: 0.2483
Batch 270, Loss: 0.2447
Batch 280, Loss: 0.2257
Batch 290, Loss: 0.2443
Batch 300, Loss: 0.2652
Batch 310, Loss: 0.2564
Batch 320, Loss: 0.2621
Batch 330, Loss: 0.2575
Batch 340, Loss: 0.2643
Batch 350, Loss: 0.2614
Batch 360, Loss: 0.2501
Batch 370, Loss: 0.2801
Batch 380, Loss: 0.2369
Batch 390, Loss: 0.2759
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.310340642929077 seconds
Epoch 188 accuracy: 80.01%
Batch 10, Loss: 0.2432
Batch 20, Loss: 0.2956
Batch 30, Loss: 0.2495
Batch 40, Loss: 0.2490
Batch 50, Loss: 0.2478
Batch 60, Loss: 0.2263
Batch 70, Loss: 0.2323
Batch 80, Loss: 0.2866
Batch 90, Loss: 0.2775
Batch 100, Loss: 0.2440
Batch 110, Loss: 0.2486
Batch 120, Loss: 0.2481
Batch 130, Loss: 0.2527
Batch 140, Loss: 0.2348
Batch 150, Loss: 0.2410
Batch 160, Loss: 0.2804
Batch 170, Loss: 0.2444
Batch 180, Loss: 0.2272
Batch 190, Loss: 0.2489
Batch 200, Loss: 0.2354
Batch 210, Loss: 0.2731
Batch 220, Loss: 0.2929
Batch 230, Loss: 0.2461
Batch 240, Loss: 0.2770
Batch 250, Loss: 0.2451
Batch 260, Loss: 0.2586
Batch 270, Loss: 0.2550
Batch 280, Loss: 0.2806
Batch 290, Loss: 0.2493
Batch 300, Loss: 0.2211
Batch 310, Loss: 0.2425
Batch 320, Loss: 0.2576
Batch 330, Loss: 0.2386
Batch 340, Loss: 0.2247
Batch 350, Loss: 0.2415
Batch 360, Loss: 0.2509
Batch 370, Loss: 0.2718
Batch 380, Loss: 0.2488
Batch 390, Loss: 0.2392
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.335175037384033 seconds
Epoch 189 accuracy: 80.01%
Batch 10, Loss: 0.2323
Batch 20, Loss: 0.2523
Batch 30, Loss: 0.2416
Batch 40, Loss: 0.2525
Batch 50, Loss: 0.2262
Batch 60, Loss: 0.2363
Batch 70, Loss: 0.2660
Batch 80, Loss: 0.2599
Batch 90, Loss: 0.2866
Batch 100, Loss: 0.2360
Batch 110, Loss: 0.2451
Batch 120, Loss: 0.2324
Batch 130, Loss: 0.2866
Batch 140, Loss: 0.2612
Batch 150, Loss: 0.2965
Batch 160, Loss: 0.2671
Batch 170, Loss: 0.2614
Batch 180, Loss: 0.2564
Batch 190, Loss: 0.2498
Batch 200, Loss: 0.2792
Batch 210, Loss: 0.2849
Batch 220, Loss: 0.2390
Batch 230, Loss: 0.2651
Batch 240, Loss: 0.2502
Batch 250, Loss: 0.2862
Batch 260, Loss: 0.2453
Batch 270, Loss: 0.2468
Batch 280, Loss: 0.2296
Batch 290, Loss: 0.2450
Batch 300, Loss: 0.2296
Batch 310, Loss: 0.2659
Batch 320, Loss: 0.2416
Batch 330, Loss: 0.2415
Batch 340, Loss: 0.2474
Batch 350, Loss: 0.2864
Batch 360, Loss: 0.2365
Batch 370, Loss: 0.2556
Batch 380, Loss: 0.2487
Batch 390, Loss: 0.2769
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.346982955932617 seconds
Epoch 190 accuracy: 79.99%
Batch 10, Loss: 0.2289
Batch 20, Loss: 0.2390
Batch 30, Loss: 0.2312
Batch 40, Loss: 0.2612
Batch 50, Loss: 0.2861
Batch 60, Loss: 0.2532
Batch 70, Loss: 0.2442
Batch 80, Loss: 0.2582
Batch 90, Loss: 0.2517
Batch 100, Loss: 0.2444
Batch 110, Loss: 0.2608
Batch 120, Loss: 0.2618
Batch 130, Loss: 0.2434
Batch 140, Loss: 0.2185
Batch 150, Loss: 0.2707
Batch 160, Loss: 0.2693
Batch 170, Loss: 0.2465
Batch 180, Loss: 0.2497
Batch 190, Loss: 0.2576
Batch 200, Loss: 0.2425
Batch 210, Loss: 0.2276
Batch 220, Loss: 0.2339
Batch 230, Loss: 0.2556
Batch 240, Loss: 0.2538
Batch 250, Loss: 0.2767
Batch 260, Loss: 0.2353
Batch 270, Loss: 0.2685
Batch 280, Loss: 0.2433
Batch 290, Loss: 0.2499
Batch 300, Loss: 0.2698
Batch 310, Loss: 0.2274
Batch 320, Loss: 0.2453
Batch 330, Loss: 0.2307
Batch 340, Loss: 0.2150
Batch 350, Loss: 0.2556
Batch 360, Loss: 0.2458
Batch 370, Loss: 0.2482
Batch 380, Loss: 0.2163
Batch 390, Loss: 0.2365
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.377981185913086 seconds
Epoch 191 accuracy: 80.3%
Batch 10, Loss: 0.2612
Batch 20, Loss: 0.2643
Batch 30, Loss: 0.2505
Batch 40, Loss: 0.2494
Batch 50, Loss: 0.2303
Batch 60, Loss: 0.2429
Batch 70, Loss: 0.2378
Batch 80, Loss: 0.2515
Batch 90, Loss: 0.2499
Batch 100, Loss: 0.2403
Batch 110, Loss: 0.2558
Batch 120, Loss: 0.2072
Batch 130, Loss: 0.2511
Batch 140, Loss: 0.2027
Batch 150, Loss: 0.2679
Batch 160, Loss: 0.2467
Batch 170, Loss: 0.2400
Batch 180, Loss: 0.2294
Batch 190, Loss: 0.2578
Batch 200, Loss: 0.2245
Batch 210, Loss: 0.2562
Batch 220, Loss: 0.2265
Batch 230, Loss: 0.2532
Batch 240, Loss: 0.2547
Batch 250, Loss: 0.2562
Batch 260, Loss: 0.2342
Batch 270, Loss: 0.2356
Batch 280, Loss: 0.2307
Batch 290, Loss: 0.2377
Batch 300, Loss: 0.2286
Batch 310, Loss: 0.2183
Batch 320, Loss: 0.2525
Batch 330, Loss: 0.2569
Batch 340, Loss: 0.2383
Batch 350, Loss: 0.2406
Batch 360, Loss: 0.2365
Batch 370, Loss: 0.2372
Batch 380, Loss: 0.2469
Batch 390, Loss: 0.2588
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.418250799179077 seconds
Epoch 192 accuracy: 80.35%
Batch 10, Loss: 0.2273
Batch 20, Loss: 0.2743
Batch 30, Loss: 0.2221
Batch 40, Loss: 0.2422
Batch 50, Loss: 0.2364
Batch 60, Loss: 0.2337
Batch 70, Loss: 0.2590
Batch 80, Loss: 0.2291
Batch 90, Loss: 0.2266
Batch 100, Loss: 0.2507
Batch 110, Loss: 0.2567
Batch 120, Loss: 0.2460
Batch 130, Loss: 0.2797
Batch 140, Loss: 0.2316
Batch 150, Loss: 0.2578
Batch 160, Loss: 0.2375
Batch 170, Loss: 0.2535
Batch 180, Loss: 0.2154
Batch 190, Loss: 0.2466
Batch 200, Loss: 0.2404
Batch 210, Loss: 0.2209
Batch 220, Loss: 0.2687
Batch 230, Loss: 0.2398
Batch 240, Loss: 0.2478
Batch 250, Loss: 0.2485
Batch 260, Loss: 0.2584
Batch 270, Loss: 0.2753
Batch 280, Loss: 0.2224
Batch 290, Loss: 0.2351
Batch 300, Loss: 0.2552
Batch 310, Loss: 0.2405
Batch 320, Loss: 0.2277
Batch 330, Loss: 0.2276
Batch 340, Loss: 0.2245
Batch 350, Loss: 0.2427
Batch 360, Loss: 0.2366
Batch 370, Loss: 0.2585
Batch 380, Loss: 0.2389
Batch 390, Loss: 0.2309
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.346826791763306 seconds
Epoch 193 accuracy: 80.34%
Batch 10, Loss: 0.2279
Batch 20, Loss: 0.2029
Batch 30, Loss: 0.2122
Batch 40, Loss: 0.2471
Batch 50, Loss: 0.2613
Batch 60, Loss: 0.2266
Batch 70, Loss: 0.2463
Batch 80, Loss: 0.2502
Batch 90, Loss: 0.2306
Batch 100, Loss: 0.2350
Batch 110, Loss: 0.2117
Batch 120, Loss: 0.2317
Batch 130, Loss: 0.1991
Batch 140, Loss: 0.2251
Batch 150, Loss: 0.2447
Batch 160, Loss: 0.2120
Batch 170, Loss: 0.2399
Batch 180, Loss: 0.2539
Batch 190, Loss: 0.2111
Batch 200, Loss: 0.2341
Batch 210, Loss: 0.2189
Batch 220, Loss: 0.2270
Batch 230, Loss: 0.2582
Batch 240, Loss: 0.2379
Batch 250, Loss: 0.2163
Batch 260, Loss: 0.2209
Batch 270, Loss: 0.2341
Batch 280, Loss: 0.2468
Batch 290, Loss: 0.2284
Batch 300, Loss: 0.2149
Batch 310, Loss: 0.2540
Batch 320, Loss: 0.2603
Batch 330, Loss: 0.2572
Batch 340, Loss: 0.2532
Batch 350, Loss: 0.2532
Batch 360, Loss: 0.2240
Batch 370, Loss: 0.2269
Batch 380, Loss: 0.2413
Batch 390, Loss: 0.2302
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.295734167099 seconds
Epoch 194 accuracy: 80.52%
Batch 10, Loss: 0.2443
Batch 20, Loss: 0.2324
Batch 30, Loss: 0.2360
Batch 40, Loss: 0.2620
Batch 50, Loss: 0.2332
Batch 60, Loss: 0.2358
Batch 70, Loss: 0.2257
Batch 80, Loss: 0.2504
Batch 90, Loss: 0.2214
Batch 100, Loss: 0.2398
Batch 110, Loss: 0.2617
Batch 120, Loss: 0.2528
Batch 130, Loss: 0.2195
Batch 140, Loss: 0.2617
Batch 150, Loss: 0.2805
Batch 160, Loss: 0.2130
Batch 170, Loss: 0.2273
Batch 180, Loss: 0.2152
Batch 190, Loss: 0.2228
Batch 200, Loss: 0.2225
Batch 210, Loss: 0.2466
Batch 220, Loss: 0.2077
Batch 230, Loss: 0.2423
Batch 240, Loss: 0.2371
Batch 250, Loss: 0.2202
Batch 260, Loss: 0.2379
Batch 270, Loss: 0.2149
Batch 280, Loss: 0.2282
Batch 290, Loss: 0.2469
Batch 300, Loss: 0.2253
Batch 310, Loss: 0.2223
Batch 320, Loss: 0.2319
Batch 330, Loss: 0.2349
Batch 340, Loss: 0.2192
Batch 350, Loss: 0.2267
Batch 360, Loss: 0.2272
Batch 370, Loss: 0.2505
Batch 380, Loss: 0.2564
Batch 390, Loss: 0.2325
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.289700508117676 seconds
Epoch 195 accuracy: 80.46%
Batch 10, Loss: 0.2470
Batch 20, Loss: 0.2590
Batch 30, Loss: 0.2598
Batch 40, Loss: 0.2300
Batch 50, Loss: 0.2255
Batch 60, Loss: 0.2619
Batch 70, Loss: 0.2098
Batch 80, Loss: 0.2496
Batch 90, Loss: 0.2227
Batch 100, Loss: 0.2390
Batch 110, Loss: 0.2415
Batch 120, Loss: 0.2201
Batch 130, Loss: 0.2224
Batch 140, Loss: 0.2665
Batch 150, Loss: 0.1952
Batch 160, Loss: 0.2549
Batch 170, Loss: 0.2275
Batch 180, Loss: 0.2094
Batch 190, Loss: 0.2376
Batch 200, Loss: 0.2431
Batch 210, Loss: 0.2577
Batch 220, Loss: 0.2301
Batch 230, Loss: 0.2418
Batch 240, Loss: 0.2532
Batch 250, Loss: 0.2380
Batch 260, Loss: 0.2092
Batch 270, Loss: 0.2516
Batch 280, Loss: 0.2321
Batch 290, Loss: 0.2346
Batch 300, Loss: 0.2337
Batch 310, Loss: 0.2412
Batch 320, Loss: 0.2301
Batch 330, Loss: 0.2371
Batch 340, Loss: 0.2170
Batch 350, Loss: 0.2058
Batch 360, Loss: 0.2458
Batch 370, Loss: 0.2355
Batch 380, Loss: 0.2566
Batch 390, Loss: 0.2719
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.319566249847412 seconds
Epoch 196 accuracy: 80.42%
Batch 10, Loss: 0.2394
Batch 20, Loss: 0.2002
Batch 30, Loss: 0.2351
Batch 40, Loss: 0.2549
Batch 50, Loss: 0.2223
Batch 60, Loss: 0.2237
Batch 70, Loss: 0.2345
Batch 80, Loss: 0.2666
Batch 90, Loss: 0.2226
Batch 100, Loss: 0.2563
Batch 110, Loss: 0.2240
Batch 120, Loss: 0.2449
Batch 130, Loss: 0.2303
Batch 140, Loss: 0.2285
Batch 150, Loss: 0.2315
Batch 160, Loss: 0.2467
Batch 170, Loss: 0.2464
Batch 180, Loss: 0.2367
Batch 190, Loss: 0.2468
Batch 200, Loss: 0.2129
Batch 210, Loss: 0.2613
Batch 220, Loss: 0.2381
Batch 230, Loss: 0.2374
Batch 240, Loss: 0.2121
Batch 250, Loss: 0.2487
Batch 260, Loss: 0.2286
Batch 270, Loss: 0.2650
Batch 280, Loss: 0.2492
Batch 290, Loss: 0.2598
Batch 300, Loss: 0.2273
Batch 310, Loss: 0.2574
Batch 320, Loss: 0.2667
Batch 330, Loss: 0.2320
Batch 340, Loss: 0.2396
Batch 350, Loss: 0.2162
Batch 360, Loss: 0.2706
Batch 370, Loss: 0.2431
Batch 380, Loss: 0.2676
Batch 390, Loss: 0.2470
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.307885885238647 seconds
Epoch 197 accuracy: 80.68%
Batch 10, Loss: 0.2693
Batch 20, Loss: 0.2207
Batch 30, Loss: 0.2387
Batch 40, Loss: 0.2463
Batch 50, Loss: 0.2259
Batch 60, Loss: 0.2309
Batch 70, Loss: 0.2502
Batch 80, Loss: 0.2416
Batch 90, Loss: 0.2506
Batch 100, Loss: 0.2340
Batch 110, Loss: 0.2287
Batch 120, Loss: 0.2432
Batch 130, Loss: 0.2340
Batch 140, Loss: 0.2189
Batch 150, Loss: 0.2232
Batch 160, Loss: 0.2643
Batch 170, Loss: 0.2659
Batch 180, Loss: 0.2451
Batch 190, Loss: 0.2430
Batch 200, Loss: 0.2328
Batch 210, Loss: 0.2275
Batch 220, Loss: 0.2411
Batch 230, Loss: 0.2351
Batch 240, Loss: 0.1909
Batch 250, Loss: 0.2428
Batch 260, Loss: 0.2590
Batch 270, Loss: 0.2163
Batch 280, Loss: 0.2360
Batch 290, Loss: 0.2455
Batch 300, Loss: 0.2264
Batch 310, Loss: 0.2226
Batch 320, Loss: 0.2443
Batch 330, Loss: 0.2460
Batch 340, Loss: 0.2449
Batch 350, Loss: 0.2193
Batch 360, Loss: 0.2210
Batch 370, Loss: 0.2411
Batch 380, Loss: 0.2218
Batch 390, Loss: 0.2464
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.269174098968506 seconds
Epoch 198 accuracy: 80.51%
Batch 10, Loss: 0.2407
Batch 20, Loss: 0.2028
Batch 30, Loss: 0.2530
Batch 40, Loss: 0.2247
Batch 50, Loss: 0.2556
Batch 60, Loss: 0.2335
Batch 70, Loss: 0.2333
Batch 80, Loss: 0.2424
Batch 90, Loss: 0.2363
Batch 100, Loss: 0.2271
Batch 110, Loss: 0.2063
Batch 120, Loss: 0.2413
Batch 130, Loss: 0.2243
Batch 140, Loss: 0.2342
Batch 150, Loss: 0.2504
Batch 160, Loss: 0.1983
Batch 170, Loss: 0.2844
Batch 180, Loss: 0.2300
Batch 190, Loss: 0.2156
Batch 200, Loss: 0.2446
Batch 210, Loss: 0.2381
Batch 220, Loss: 0.2225
Batch 230, Loss: 0.2438
Batch 240, Loss: 0.2248
Batch 250, Loss: 0.2407
Batch 260, Loss: 0.2211
Batch 270, Loss: 0.2225
Batch 280, Loss: 0.2441
Batch 290, Loss: 0.2520
Batch 300, Loss: 0.2178
Batch 310, Loss: 0.2559
Batch 320, Loss: 0.2082
Batch 330, Loss: 0.2475
Batch 340, Loss: 0.2552
Batch 350, Loss: 0.2502
Batch 360, Loss: 0.2244
Batch 370, Loss: 0.2468
Batch 380, Loss: 0.2412
Batch 390, Loss: 0.1888
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.209117889404297 seconds
Epoch 199 accuracy: 80.44%
Batch 10, Loss: 0.2387
Batch 20, Loss: 0.2304
Batch 30, Loss: 0.2254
Batch 40, Loss: 0.2205
Batch 50, Loss: 0.2560
Batch 60, Loss: 0.2497
Batch 70, Loss: 0.2535
Batch 80, Loss: 0.2390
Batch 90, Loss: 0.2275
Batch 100, Loss: 0.2166
Batch 110, Loss: 0.2346
Batch 120, Loss: 0.2678
Batch 130, Loss: 0.2074
Batch 140, Loss: 0.2790
Batch 150, Loss: 0.2279
Batch 160, Loss: 0.2446
Batch 170, Loss: 0.2292
Batch 180, Loss: 0.2256
Batch 190, Loss: 0.2443
Batch 200, Loss: 0.2450
Batch 210, Loss: 0.2462
Batch 220, Loss: 0.2327
Batch 230, Loss: 0.2619
Batch 240, Loss: 0.2023
Batch 250, Loss: 0.2454
Batch 260, Loss: 0.2279
Batch 270, Loss: 0.2300
Batch 280, Loss: 0.2198
Batch 290, Loss: 0.2444
Batch 300, Loss: 0.2350
Batch 310, Loss: 0.2360
Batch 320, Loss: 0.2760
Batch 330, Loss: 0.2336
Batch 340, Loss: 0.2267
Batch 350, Loss: 0.2400
Batch 360, Loss: 0.2298
Batch 370, Loss: 0.2229
Batch 380, Loss: 0.2610
Batch 390, Loss: 0.2506
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.19145679473877 seconds
Epoch 200 accuracy: 80.46%
Total training time: 5072.081106424332 seconds
