The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 3.2352
Batch 20, Loss: 2.3608
Batch 30, Loss: 1.9639
Batch 40, Loss: 1.8679
Batch 50, Loss: 1.8096
Batch 60, Loss: 1.7478
Batch 70, Loss: 1.6931
Batch 80, Loss: 1.6844
Batch 90, Loss: 1.6566
Batch 100, Loss: 1.6433
Batch 110, Loss: 1.6135
Batch 120, Loss: 1.6205
Batch 130, Loss: 1.6180
Batch 140, Loss: 1.5808
Batch 150, Loss: 1.5937
Batch 160, Loss: 1.5916
Batch 170, Loss: 1.5557
Batch 180, Loss: 1.5979
Batch 190, Loss: 1.5769
Batch 200, Loss: 1.5798
Batch 210, Loss: 1.5897
Batch 220, Loss: 1.5734
Batch 230, Loss: 1.5707
Batch 240, Loss: 1.5754
Batch 250, Loss: 1.5626
Batch 260, Loss: 1.5702
Batch 270, Loss: 1.5240
Batch 280, Loss: 1.5285
Batch 290, Loss: 1.5618
Batch 300, Loss: 1.5065
Batch 310, Loss: 1.5022
Batch 320, Loss: 1.5128
Batch 330, Loss: 1.5066
Batch 340, Loss: 1.5145
Batch 350, Loss: 1.4662
Batch 360, Loss: 1.4933
Batch 370, Loss: 1.5101
Batch 380, Loss: 1.4895
Batch 390, Loss: 1.4753
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.861319303512573 seconds
Epoch 1 accuracy: 34.01%
Batch 10, Loss: 1.4681
Batch 20, Loss: 1.4466
Batch 30, Loss: 1.4682
Batch 40, Loss: 1.4723
Batch 50, Loss: 1.4502
Batch 60, Loss: 1.4857
Batch 70, Loss: 1.4447
Batch 80, Loss: 1.4384
Batch 90, Loss: 1.4238
Batch 100, Loss: 1.4328
Batch 110, Loss: 1.4637
Batch 120, Loss: 1.4829
Batch 130, Loss: 1.4540
Batch 140, Loss: 1.4435
Batch 150, Loss: 1.4431
Batch 160, Loss: 1.4463
Batch 170, Loss: 1.4405
Batch 180, Loss: 1.4170
Batch 190, Loss: 1.3888
Batch 200, Loss: 1.4282
Batch 210, Loss: 1.3958
Batch 220, Loss: 1.3809
Batch 230, Loss: 1.4320
Batch 240, Loss: 1.4160
Batch 250, Loss: 1.3960
Batch 260, Loss: 1.3567
Batch 270, Loss: 1.3850
Batch 280, Loss: 1.3748
Batch 290, Loss: 1.3949
Batch 300, Loss: 1.3481
Batch 310, Loss: 1.3764
Batch 320, Loss: 1.3483
Batch 330, Loss: 1.3525
Batch 340, Loss: 1.3873
Batch 350, Loss: 1.3281
Batch 360, Loss: 1.3598
Batch 370, Loss: 1.3936
Batch 380, Loss: 1.3176
Batch 390, Loss: 1.3939
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.434701204299927 seconds
Epoch 2 accuracy: 40.41%
Batch 10, Loss: 1.3514
Batch 20, Loss: 1.2881
Batch 30, Loss: 1.2941
Batch 40, Loss: 1.3132
Batch 50, Loss: 1.2743
Batch 60, Loss: 1.2765
Batch 70, Loss: 1.3408
Batch 80, Loss: 1.2971
Batch 90, Loss: 1.2999
Batch 100, Loss: 1.2716
Batch 110, Loss: 1.2990
Batch 120, Loss: 1.2542
Batch 130, Loss: 1.2836
Batch 140, Loss: 1.2640
Batch 150, Loss: 1.2815
Batch 160, Loss: 1.2983
Batch 170, Loss: 1.2373
Batch 180, Loss: 1.2861
Batch 190, Loss: 1.2814
Batch 200, Loss: 1.2508
Batch 210, Loss: 1.2915
Batch 220, Loss: 1.2651
Batch 230, Loss: 1.2212
Batch 240, Loss: 1.2318
Batch 250, Loss: 1.2058
Batch 260, Loss: 1.2257
Batch 270, Loss: 1.2464
Batch 280, Loss: 1.2785
Batch 290, Loss: 1.2413
Batch 300, Loss: 1.2333
Batch 310, Loss: 1.2423
Batch 320, Loss: 1.2470
Batch 330, Loss: 1.2184
Batch 340, Loss: 1.1850
Batch 350, Loss: 1.2492
Batch 360, Loss: 1.2193
Batch 370, Loss: 1.2303
Batch 380, Loss: 1.2244
Batch 390, Loss: 1.2253
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.483840465545654 seconds
Epoch 3 accuracy: 49.25%
Batch 10, Loss: 1.1675
Batch 20, Loss: 1.2176
Batch 30, Loss: 1.1881
Batch 40, Loss: 1.1782
Batch 50, Loss: 1.1893
Batch 60, Loss: 1.1668
Batch 70, Loss: 1.1761
Batch 80, Loss: 1.1704
Batch 90, Loss: 1.1779
Batch 100, Loss: 1.1452
Batch 110, Loss: 1.1550
Batch 120, Loss: 1.1577
Batch 130, Loss: 1.1633
Batch 140, Loss: 1.1927
Batch 150, Loss: 1.1887
Batch 160, Loss: 1.1757
Batch 170, Loss: 1.1591
Batch 180, Loss: 1.1730
Batch 190, Loss: 1.1024
Batch 200, Loss: 1.1428
Batch 210, Loss: 1.1249
Batch 220, Loss: 1.1448
Batch 230, Loss: 1.1370
Batch 240, Loss: 1.0977
Batch 250, Loss: 1.1191
Batch 260, Loss: 1.1260
Batch 270, Loss: 1.1153
Batch 280, Loss: 1.1487
Batch 290, Loss: 1.1586
Batch 300, Loss: 1.1084
Batch 310, Loss: 1.0965
Batch 320, Loss: 1.1323
Batch 330, Loss: 1.0994
Batch 340, Loss: 1.1337
Batch 350, Loss: 1.1169
Batch 360, Loss: 1.1278
Batch 370, Loss: 1.1391
Batch 380, Loss: 1.1133
Batch 390, Loss: 1.1065
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.76209545135498 seconds
Epoch 4 accuracy: 52.83%
Batch 10, Loss: 1.0842
Batch 20, Loss: 1.0920
Batch 30, Loss: 1.0857
Batch 40, Loss: 1.0895
Batch 50, Loss: 1.0758
Batch 60, Loss: 1.1476
Batch 70, Loss: 1.0358
Batch 80, Loss: 1.0881
Batch 90, Loss: 1.1141
Batch 100, Loss: 1.0830
Batch 110, Loss: 1.0828
Batch 120, Loss: 1.1135
Batch 130, Loss: 1.0235
Batch 140, Loss: 1.0911
Batch 150, Loss: 1.0719
Batch 160, Loss: 1.0652
Batch 170, Loss: 1.1104
Batch 180, Loss: 1.1597
Batch 190, Loss: 1.0980
Batch 200, Loss: 1.0932
Batch 210, Loss: 1.0639
Batch 220, Loss: 1.0792
Batch 230, Loss: 1.0505
Batch 240, Loss: 1.1098
Batch 250, Loss: 1.0253
Batch 260, Loss: 1.0501
Batch 270, Loss: 1.0736
Batch 280, Loss: 1.0418
Batch 290, Loss: 1.0336
Batch 300, Loss: 1.0661
Batch 310, Loss: 1.0099
Batch 320, Loss: 1.0468
Batch 330, Loss: 1.0226
Batch 340, Loss: 1.0494
Batch 350, Loss: 1.0343
Batch 360, Loss: 1.0174
Batch 370, Loss: 1.0432
Batch 380, Loss: 0.9833
Batch 390, Loss: 1.0246
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.781020164489746 seconds
Epoch 5 accuracy: 62.82%
Batch 10, Loss: 0.9876
Batch 20, Loss: 1.0079
Batch 30, Loss: 1.0311
Batch 40, Loss: 0.9880
Batch 50, Loss: 1.0019
Batch 60, Loss: 1.0033
Batch 70, Loss: 1.0271
Batch 80, Loss: 0.9806
Batch 90, Loss: 1.0011
Batch 100, Loss: 0.9873
Batch 110, Loss: 1.0062
Batch 120, Loss: 0.9584
Batch 130, Loss: 0.9810
Batch 140, Loss: 1.0313
Batch 150, Loss: 1.0273
Batch 160, Loss: 0.9913
Batch 170, Loss: 0.9695
Batch 180, Loss: 0.9257
Batch 190, Loss: 0.9852
Batch 200, Loss: 0.9550
Batch 210, Loss: 0.9751
Batch 220, Loss: 1.0158
Batch 230, Loss: 0.9468
Batch 240, Loss: 0.9666
Batch 250, Loss: 0.9810
Batch 260, Loss: 0.9861
Batch 270, Loss: 0.9751
Batch 280, Loss: 0.9954
Batch 290, Loss: 1.0040
Batch 300, Loss: 0.9716
Batch 310, Loss: 0.9594
Batch 320, Loss: 0.9412
Batch 330, Loss: 0.9683
Batch 340, Loss: 0.9346
Batch 350, Loss: 0.9575
Batch 360, Loss: 0.9987
Batch 370, Loss: 1.0073
Batch 380, Loss: 0.9169
Batch 390, Loss: 0.9551
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.82744598388672 seconds
Epoch 6 accuracy: 66.78%
Batch 10, Loss: 0.9569
Batch 20, Loss: 0.9782
Batch 30, Loss: 0.9582
Batch 40, Loss: 0.9559
Batch 50, Loss: 0.9051
Batch 60, Loss: 0.9307
Batch 70, Loss: 0.8816
Batch 80, Loss: 0.9454
Batch 90, Loss: 0.8803
Batch 100, Loss: 0.9285
Batch 110, Loss: 0.9202
Batch 120, Loss: 0.9244
Batch 130, Loss: 0.8787
Batch 140, Loss: 0.8893
Batch 150, Loss: 0.9466
Batch 160, Loss: 0.9217
Batch 170, Loss: 0.9481
Batch 180, Loss: 0.9565
Batch 190, Loss: 0.9414
Batch 200, Loss: 0.8687
Batch 210, Loss: 0.8671
Batch 220, Loss: 0.9026
Batch 230, Loss: 0.9061
Batch 240, Loss: 0.8917
Batch 250, Loss: 0.9233
Batch 260, Loss: 0.9340
Batch 270, Loss: 0.9187
Batch 280, Loss: 0.9148
Batch 290, Loss: 0.9411
Batch 300, Loss: 0.8904
Batch 310, Loss: 0.8755
Batch 320, Loss: 0.8859
Batch 330, Loss: 0.8835
Batch 340, Loss: 0.8709
Batch 350, Loss: 0.8704
Batch 360, Loss: 0.8635
Batch 370, Loss: 0.8613
Batch 380, Loss: 0.8386
Batch 390, Loss: 0.8892
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.527109622955322 seconds
Epoch 7 accuracy: 68.35%
Batch 10, Loss: 0.8402
Batch 20, Loss: 0.8396
Batch 30, Loss: 0.8516
Batch 40, Loss: 0.8669
Batch 50, Loss: 0.8644
Batch 60, Loss: 0.8493
Batch 70, Loss: 0.8436
Batch 80, Loss: 0.8721
Batch 90, Loss: 0.8809
Batch 100, Loss: 0.8768
Batch 110, Loss: 0.8225
Batch 120, Loss: 0.8454
Batch 130, Loss: 0.8693
Batch 140, Loss: 0.8404
Batch 150, Loss: 0.8510
Batch 160, Loss: 0.8250
Batch 170, Loss: 0.8581
Batch 180, Loss: 0.8919
Batch 190, Loss: 0.8491
Batch 200, Loss: 0.8757
Batch 210, Loss: 0.8727
Batch 220, Loss: 0.8545
Batch 230, Loss: 0.8042
Batch 240, Loss: 0.8351
Batch 250, Loss: 0.7914
Batch 260, Loss: 0.8220
Batch 270, Loss: 0.8365
Batch 280, Loss: 0.8440
Batch 290, Loss: 0.8070
Batch 300, Loss: 0.8111
Batch 310, Loss: 0.8191
Batch 320, Loss: 0.7902
Batch 330, Loss: 0.8025
Batch 340, Loss: 0.7935
Batch 350, Loss: 0.8326
Batch 360, Loss: 0.8534
Batch 370, Loss: 0.8367
Batch 380, Loss: 0.8361
Batch 390, Loss: 0.8413
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.639892101287842 seconds
Epoch 8 accuracy: 64.76%
Batch 10, Loss: 0.8099
Batch 20, Loss: 0.7618
Batch 30, Loss: 0.7947
Batch 40, Loss: 0.8179
Batch 50, Loss: 0.8264
Batch 60, Loss: 0.8199
Batch 70, Loss: 0.7880
Batch 80, Loss: 0.7870
Batch 90, Loss: 0.8003
Batch 100, Loss: 0.8213
Batch 110, Loss: 0.8148
Batch 120, Loss: 0.8321
Batch 130, Loss: 0.8041
Batch 140, Loss: 0.8105
Batch 150, Loss: 0.7645
Batch 160, Loss: 0.8406
Batch 170, Loss: 0.8177
Batch 180, Loss: 0.7578
Batch 190, Loss: 0.7675
Batch 200, Loss: 0.7938
Batch 210, Loss: 0.8216
Batch 220, Loss: 0.7427
Batch 230, Loss: 0.7723
Batch 240, Loss: 0.7740
Batch 250, Loss: 0.8309
Batch 260, Loss: 0.7898
Batch 270, Loss: 0.8224
Batch 280, Loss: 0.7888
Batch 290, Loss: 0.7838
Batch 300, Loss: 0.7621
Batch 310, Loss: 0.8074
Batch 320, Loss: 0.7707
Batch 330, Loss: 0.7620
Batch 340, Loss: 0.7566
Batch 350, Loss: 0.7780
Batch 360, Loss: 0.7539
Batch 370, Loss: 0.7566
Batch 380, Loss: 0.8166
Batch 390, Loss: 0.7494
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.592511415481567 seconds
Epoch 9 accuracy: 72.47%
Batch 10, Loss: 0.8249
Batch 20, Loss: 0.8307
Batch 30, Loss: 0.7737
Batch 40, Loss: 0.8178
Batch 50, Loss: 0.7737
Batch 60, Loss: 0.8016
Batch 70, Loss: 0.7544
Batch 80, Loss: 0.7957
Batch 90, Loss: 0.7586
Batch 100, Loss: 0.8119
Batch 110, Loss: 0.7555
Batch 120, Loss: 0.7491
Batch 130, Loss: 0.7604
Batch 140, Loss: 0.8215
Batch 150, Loss: 0.8277
Batch 160, Loss: 0.8292
Batch 170, Loss: 0.7800
Batch 180, Loss: 0.7619
Batch 190, Loss: 0.7204
Batch 200, Loss: 0.7716
Batch 210, Loss: 0.7887
Batch 220, Loss: 0.7210
Batch 230, Loss: 0.7379
Batch 240, Loss: 0.7315
Batch 250, Loss: 0.7576
Batch 260, Loss: 0.7297
Batch 270, Loss: 0.7189
Batch 280, Loss: 0.7455
Batch 290, Loss: 0.7652
Batch 300, Loss: 0.7577
Batch 310, Loss: 0.7316
Batch 320, Loss: 0.7600
Batch 330, Loss: 0.7712
Batch 340, Loss: 0.7273
Batch 350, Loss: 0.7130
Batch 360, Loss: 0.7379
Batch 370, Loss: 0.8187
Batch 380, Loss: 0.7341
Batch 390, Loss: 0.8068
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.62149667739868 seconds
Epoch 10 accuracy: 69.76%
Batch 10, Loss: 0.7499
Batch 20, Loss: 0.7222
Batch 30, Loss: 0.7452
Batch 40, Loss: 0.7471
Batch 50, Loss: 0.7593
Batch 60, Loss: 0.7424
Batch 70, Loss: 0.7944
Batch 80, Loss: 0.7541
Batch 90, Loss: 0.7691
Batch 100, Loss: 0.7515
Batch 110, Loss: 0.7271
Batch 120, Loss: 0.7170
Batch 130, Loss: 0.7668
Batch 140, Loss: 0.7052
Batch 150, Loss: 0.7053
Batch 160, Loss: 0.7165
Batch 170, Loss: 0.7524
Batch 180, Loss: 0.7514
Batch 190, Loss: 0.7179
Batch 200, Loss: 0.7075
Batch 210, Loss: 0.7684
Batch 220, Loss: 0.7234
Batch 230, Loss: 0.7474
Batch 240, Loss: 0.7305
Batch 250, Loss: 0.7301
Batch 260, Loss: 0.7143
Batch 270, Loss: 0.7518
Batch 280, Loss: 0.7460
Batch 290, Loss: 0.7318
Batch 300, Loss: 0.7160
Batch 310, Loss: 0.7672
Batch 320, Loss: 0.7201
Batch 330, Loss: 0.7373
Batch 340, Loss: 0.7393
Batch 350, Loss: 0.7420
Batch 360, Loss: 0.7392
Batch 370, Loss: 0.7576
Batch 380, Loss: 0.7337
Batch 390, Loss: 0.7097
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.706014394760132 seconds
Epoch 11 accuracy: 75.7%
Batch 10, Loss: 0.7407
Batch 20, Loss: 0.7440
Batch 30, Loss: 0.7258
Batch 40, Loss: 0.7372
Batch 50, Loss: 0.7170
Batch 60, Loss: 0.7197
Batch 70, Loss: 0.7359
Batch 80, Loss: 0.7563
Batch 90, Loss: 0.7626
Batch 100, Loss: 0.7127
Batch 110, Loss: 0.7369
Batch 120, Loss: 0.6781
Batch 130, Loss: 0.6903
Batch 140, Loss: 0.7227
Batch 150, Loss: 0.7099
Batch 160, Loss: 0.7587
Batch 170, Loss: 0.7330
Batch 180, Loss: 0.7516
Batch 190, Loss: 0.7280
Batch 200, Loss: 0.7379
Batch 210, Loss: 0.6985
Batch 220, Loss: 0.6876
Batch 230, Loss: 0.6876
Batch 240, Loss: 0.7491
Batch 250, Loss: 0.7335
Batch 260, Loss: 0.6710
Batch 270, Loss: 0.6750
Batch 280, Loss: 0.7296
Batch 290, Loss: 0.7213
Batch 300, Loss: 0.7398
Batch 310, Loss: 0.6984
Batch 320, Loss: 0.7081
Batch 330, Loss: 0.7265
Batch 340, Loss: 0.6760
Batch 350, Loss: 0.6916
Batch 360, Loss: 0.7367
Batch 370, Loss: 0.7048
Batch 380, Loss: 0.7214
Batch 390, Loss: 0.7417
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.72402048110962 seconds
Epoch 12 accuracy: 78.52%
Batch 10, Loss: 0.7117
Batch 20, Loss: 0.7107
Batch 30, Loss: 0.6966
Batch 40, Loss: 0.6979
Batch 50, Loss: 0.6971
Batch 60, Loss: 0.7338
Batch 70, Loss: 0.7097
Batch 80, Loss: 0.6801
Batch 90, Loss: 0.6827
Batch 100, Loss: 0.6737
Batch 110, Loss: 0.7092
Batch 120, Loss: 0.6844
Batch 130, Loss: 0.6923
Batch 140, Loss: 0.6882
Batch 150, Loss: 0.7044
Batch 160, Loss: 0.6757
Batch 170, Loss: 0.7006
Batch 180, Loss: 0.6753
Batch 190, Loss: 0.7285
Batch 200, Loss: 0.7369
Batch 210, Loss: 0.6911
Batch 220, Loss: 0.6976
Batch 230, Loss: 0.7033
Batch 240, Loss: 0.6921
Batch 250, Loss: 0.6692
Batch 260, Loss: 0.7085
Batch 270, Loss: 0.7033
Batch 280, Loss: 0.7172
Batch 290, Loss: 0.6949
Batch 300, Loss: 0.7042
Batch 310, Loss: 0.6892
Batch 320, Loss: 0.6539
Batch 330, Loss: 0.7251
Batch 340, Loss: 0.7292
Batch 350, Loss: 0.6986
Batch 360, Loss: 0.7121
Batch 370, Loss: 0.6613
Batch 380, Loss: 0.6575
Batch 390, Loss: 0.6922
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.805405855178833 seconds
Epoch 13 accuracy: 75.27%
Batch 10, Loss: 0.7262
Batch 20, Loss: 0.7038
Batch 30, Loss: 0.6816
Batch 40, Loss: 0.6814
Batch 50, Loss: 0.6747
Batch 60, Loss: 0.6888
Batch 70, Loss: 0.7070
Batch 80, Loss: 0.6557
Batch 90, Loss: 0.6785
Batch 100, Loss: 0.6987
Batch 110, Loss: 0.6963
Batch 120, Loss: 0.6485
Batch 130, Loss: 0.6977
Batch 140, Loss: 0.6522
Batch 150, Loss: 0.6818
Batch 160, Loss: 0.6726
Batch 170, Loss: 0.6984
Batch 180, Loss: 0.6740
Batch 190, Loss: 0.6473
Batch 200, Loss: 0.6451
Batch 210, Loss: 0.6852
Batch 220, Loss: 0.7281
Batch 230, Loss: 0.6991
Batch 240, Loss: 0.6519
Batch 250, Loss: 0.6878
Batch 260, Loss: 0.7140
Batch 270, Loss: 0.6593
Batch 280, Loss: 0.7065
Batch 290, Loss: 0.7443
Batch 300, Loss: 0.6708
Batch 310, Loss: 0.6731
Batch 320, Loss: 0.6992
Batch 330, Loss: 0.7069
Batch 340, Loss: 0.6853
Batch 350, Loss: 0.6509
Batch 360, Loss: 0.6368
Batch 370, Loss: 0.6910
Batch 380, Loss: 0.6605
Batch 390, Loss: 0.7030
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.656697750091553 seconds
Epoch 14 accuracy: 79.17%
Batch 10, Loss: 0.6652
Batch 20, Loss: 0.6560
Batch 30, Loss: 0.6823
Batch 40, Loss: 0.6588
Batch 50, Loss: 0.6775
Batch 60, Loss: 0.6713
Batch 70, Loss: 0.6516
Batch 80, Loss: 0.6728
Batch 90, Loss: 0.6618
Batch 100, Loss: 0.6964
Batch 110, Loss: 0.6923
Batch 120, Loss: 0.7120
Batch 130, Loss: 0.6490
Batch 140, Loss: 0.6649
Batch 150, Loss: 0.6674
Batch 160, Loss: 0.6523
Batch 170, Loss: 0.7324
Batch 180, Loss: 0.7179
Batch 190, Loss: 0.7028
Batch 200, Loss: 0.7259
Batch 210, Loss: 0.6503
Batch 220, Loss: 0.6548
Batch 230, Loss: 0.6545
Batch 240, Loss: 0.6987
Batch 250, Loss: 0.7167
Batch 260, Loss: 0.6866
Batch 270, Loss: 0.6684
Batch 280, Loss: 0.6711
Batch 290, Loss: 0.6297
Batch 300, Loss: 0.6564
Batch 310, Loss: 0.6703
Batch 320, Loss: 0.6571
Batch 330, Loss: 0.6497
Batch 340, Loss: 0.6627
Batch 350, Loss: 0.6648
Batch 360, Loss: 0.6859
Batch 370, Loss: 0.6721
Batch 380, Loss: 0.6484
Batch 390, Loss: 0.6837
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.62808084487915 seconds
Epoch 15 accuracy: 79.7%
Batch 10, Loss: 0.6876
Batch 20, Loss: 0.6727
Batch 30, Loss: 0.6304
Batch 40, Loss: 0.6397
Batch 50, Loss: 0.6702
Batch 60, Loss: 0.6697
Batch 70, Loss: 0.6480
Batch 80, Loss: 0.6634
Batch 90, Loss: 0.6775
Batch 100, Loss: 0.7126
Batch 110, Loss: 0.6438
Batch 120, Loss: 0.6749
Batch 130, Loss: 0.6519
Batch 140, Loss: 0.6400
Batch 150, Loss: 0.6605
Batch 160, Loss: 0.6427
Batch 170, Loss: 0.6386
Batch 180, Loss: 0.6530
Batch 190, Loss: 0.6947
Batch 200, Loss: 0.6522
Batch 210, Loss: 0.6266
Batch 220, Loss: 0.6416
Batch 230, Loss: 0.7006
Batch 240, Loss: 0.6800
Batch 250, Loss: 0.6455
Batch 260, Loss: 0.6937
Batch 270, Loss: 0.6607
Batch 280, Loss: 0.6625
Batch 290, Loss: 0.6484
Batch 300, Loss: 0.6859
Batch 310, Loss: 0.6630
Batch 320, Loss: 0.6695
Batch 330, Loss: 0.6218
Batch 340, Loss: 0.6292
Batch 350, Loss: 0.6168
Batch 360, Loss: 0.6635
Batch 370, Loss: 0.6992
Batch 380, Loss: 0.6446
Batch 390, Loss: 0.7082
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.699059009552002 seconds
Epoch 16 accuracy: 77.34%
Batch 10, Loss: 0.6822
Batch 20, Loss: 0.7017
Batch 30, Loss: 0.6866
Batch 40, Loss: 0.6930
Batch 50, Loss: 0.6505
Batch 60, Loss: 0.6217
Batch 70, Loss: 0.6529
Batch 80, Loss: 0.6677
Batch 90, Loss: 0.6376
Batch 100, Loss: 0.6706
Batch 110, Loss: 0.6501
Batch 120, Loss: 0.6356
Batch 130, Loss: 0.5951
Batch 140, Loss: 0.6505
Batch 150, Loss: 0.6246
Batch 160, Loss: 0.6151
Batch 170, Loss: 0.6739
Batch 180, Loss: 0.6568
Batch 190, Loss: 0.6339
Batch 200, Loss: 0.6739
Batch 210, Loss: 0.6606
Batch 220, Loss: 0.6772
Batch 230, Loss: 0.6482
Batch 240, Loss: 0.6862
Batch 250, Loss: 0.6511
Batch 260, Loss: 0.6651
Batch 270, Loss: 0.6420
Batch 280, Loss: 0.6654
Batch 290, Loss: 0.7035
Batch 300, Loss: 0.6482
Batch 310, Loss: 0.6795
Batch 320, Loss: 0.6257
Batch 330, Loss: 0.6291
Batch 340, Loss: 0.6615
Batch 350, Loss: 0.6648
Batch 360, Loss: 0.6319
Batch 370, Loss: 0.6365
Batch 380, Loss: 0.6523
Batch 390, Loss: 0.6231
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.544008255004883 seconds
Epoch 17 accuracy: 80.43%
Batch 10, Loss: 0.6366
Batch 20, Loss: 0.6298
Batch 30, Loss: 0.6858
Batch 40, Loss: 0.6905
Batch 50, Loss: 0.6549
Batch 60, Loss: 0.6376
Batch 70, Loss: 0.6592
Batch 80, Loss: 0.6310
Batch 90, Loss: 0.6339
Batch 100, Loss: 0.6586
Batch 110, Loss: 0.6524
Batch 120, Loss: 0.6279
Batch 130, Loss: 0.6690
Batch 140, Loss: 0.6688
Batch 150, Loss: 0.6601
Batch 160, Loss: 0.6463
Batch 170, Loss: 0.6182
Batch 180, Loss: 0.6197
Batch 190, Loss: 0.6226
Batch 200, Loss: 0.6195
Batch 210, Loss: 0.6889
Batch 220, Loss: 0.6533
Batch 230, Loss: 0.6282
Batch 240, Loss: 0.6083
Batch 250, Loss: 0.6403
Batch 260, Loss: 0.6654
Batch 270, Loss: 0.6434
Batch 280, Loss: 0.6551
Batch 290, Loss: 0.6473
Batch 300, Loss: 0.6347
Batch 310, Loss: 0.6187
Batch 320, Loss: 0.6153
Batch 330, Loss: 0.7002
Batch 340, Loss: 0.7179
Batch 350, Loss: 0.6490
Batch 360, Loss: 0.6689
Batch 370, Loss: 0.6914
Batch 380, Loss: 0.6433
Batch 390, Loss: 0.6619
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.262324571609497 seconds
Epoch 18 accuracy: 77.09%
Batch 10, Loss: 0.5913
Batch 20, Loss: 0.6427
Batch 30, Loss: 0.6489
Batch 40, Loss: 0.6589
Batch 50, Loss: 0.6845
Batch 60, Loss: 0.6555
Batch 70, Loss: 0.6173
Batch 80, Loss: 0.6328
Batch 90, Loss: 0.6168
Batch 100, Loss: 0.6212
Batch 110, Loss: 0.6265
Batch 120, Loss: 0.6188
Batch 130, Loss: 0.6251
Batch 140, Loss: 0.6359
Batch 150, Loss: 0.6324
Batch 160, Loss: 0.6610
Batch 170, Loss: 0.6638
Batch 180, Loss: 0.6714
Batch 190, Loss: 0.6283
Batch 200, Loss: 0.6193
Batch 210, Loss: 0.5902
Batch 220, Loss: 0.6475
Batch 230, Loss: 0.6343
Batch 240, Loss: 0.6355
Batch 250, Loss: 0.6337
Batch 260, Loss: 0.6140
Batch 270, Loss: 0.5978
Batch 280, Loss: 0.6272
Batch 290, Loss: 0.6502
Batch 300, Loss: 0.6715
Batch 310, Loss: 0.6411
Batch 320, Loss: 0.6249
Batch 330, Loss: 0.6297
Batch 340, Loss: 0.5919
Batch 350, Loss: 0.6344
Batch 360, Loss: 0.6130
Batch 370, Loss: 0.6428
Batch 380, Loss: 0.6178
Batch 390, Loss: 0.6544
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.195104598999023 seconds
Epoch 19 accuracy: 80.59%
Batch 10, Loss: 0.5885
Batch 20, Loss: 0.5940
Batch 30, Loss: 0.6727
Batch 40, Loss: 0.6413
Batch 50, Loss: 0.6101
Batch 60, Loss: 0.6476
Batch 70, Loss: 0.6041
Batch 80, Loss: 0.6289
Batch 90, Loss: 0.6266
Batch 100, Loss: 0.6224
Batch 110, Loss: 0.6337
Batch 120, Loss: 0.6527
Batch 130, Loss: 0.6512
Batch 140, Loss: 0.6054
Batch 150, Loss: 0.6420
Batch 160, Loss: 0.6537
Batch 170, Loss: 0.6021
Batch 180, Loss: 0.6420
Batch 190, Loss: 0.6433
Batch 200, Loss: 0.5768
Batch 210, Loss: 0.6148
Batch 220, Loss: 0.6641
Batch 230, Loss: 0.6408
Batch 240, Loss: 0.6354
Batch 250, Loss: 0.6225
Batch 260, Loss: 0.6476
Batch 270, Loss: 0.6536
Batch 280, Loss: 0.6488
Batch 290, Loss: 0.6552
Batch 300, Loss: 0.6416
Batch 310, Loss: 0.6376
Batch 320, Loss: 0.6352
Batch 330, Loss: 0.6240
Batch 340, Loss: 0.5894
Batch 350, Loss: 0.6479
Batch 360, Loss: 0.6008
Batch 370, Loss: 0.6554
Batch 380, Loss: 0.6396
Batch 390, Loss: 0.6306
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.381947994232178 seconds
Epoch 20 accuracy: 78.58%
Batch 10, Loss: 0.6342
Batch 20, Loss: 0.6191
Batch 30, Loss: 0.6317
Batch 40, Loss: 0.6005
Batch 50, Loss: 0.6261
Batch 60, Loss: 0.6436
Batch 70, Loss: 0.6016
Batch 80, Loss: 0.6774
Batch 90, Loss: 0.6130
Batch 100, Loss: 0.6488
Batch 110, Loss: 0.6348
Batch 120, Loss: 0.6390
Batch 130, Loss: 0.6560
Batch 140, Loss: 0.6721
Batch 150, Loss: 0.6521
Batch 160, Loss: 0.6291
Batch 170, Loss: 0.6018
Batch 180, Loss: 0.5966
Batch 190, Loss: 0.6279
Batch 200, Loss: 0.6225
Batch 210, Loss: 0.6075
Batch 220, Loss: 0.6018
Batch 230, Loss: 0.6512
Batch 240, Loss: 0.6059
Batch 250, Loss: 0.6403
Batch 260, Loss: 0.6255
Batch 270, Loss: 0.6284
Batch 280, Loss: 0.6224
Batch 290, Loss: 0.6458
Batch 300, Loss: 0.6182
Batch 310, Loss: 0.6401
Batch 320, Loss: 0.6302
Batch 330, Loss: 0.6588
Batch 340, Loss: 0.6263
Batch 350, Loss: 0.6250
Batch 360, Loss: 0.6511
Batch 370, Loss: 0.6467
Batch 380, Loss: 0.6276
Batch 390, Loss: 0.6421
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.244548082351685 seconds
Epoch 21 accuracy: 81.86%
Batch 10, Loss: 0.6220
Batch 20, Loss: 0.5974
Batch 30, Loss: 0.5778
Batch 40, Loss: 0.6092
Batch 50, Loss: 0.6220
Batch 60, Loss: 0.5686
Batch 70, Loss: 0.6043
Batch 80, Loss: 0.5812
Batch 90, Loss: 0.6652
Batch 100, Loss: 0.6121
Batch 110, Loss: 0.6032
Batch 120, Loss: 0.6010
Batch 130, Loss: 0.5888
Batch 140, Loss: 0.5983
Batch 150, Loss: 0.6232
Batch 160, Loss: 0.6153
Batch 170, Loss: 0.6256
Batch 180, Loss: 0.6169
Batch 190, Loss: 0.6189
Batch 200, Loss: 0.5620
Batch 210, Loss: 0.6076
Batch 220, Loss: 0.6123
Batch 230, Loss: 0.6304
Batch 240, Loss: 0.6159
Batch 250, Loss: 0.6237
Batch 260, Loss: 0.6284
Batch 270, Loss: 0.6535
Batch 280, Loss: 0.5979
Batch 290, Loss: 0.6213
Batch 300, Loss: 0.6522
Batch 310, Loss: 0.6178
Batch 320, Loss: 0.5845
Batch 330, Loss: 0.6267
Batch 340, Loss: 0.6089
Batch 350, Loss: 0.6268
Batch 360, Loss: 0.5912
Batch 370, Loss: 0.6040
Batch 380, Loss: 0.6243
Batch 390, Loss: 0.6160
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.1955144405365 seconds
Epoch 22 accuracy: 76.65%
Batch 10, Loss: 0.6095
Batch 20, Loss: 0.5794
Batch 30, Loss: 0.5904
Batch 40, Loss: 0.5960
Batch 50, Loss: 0.6190
Batch 60, Loss: 0.5937
Batch 70, Loss: 0.5832
Batch 80, Loss: 0.5642
Batch 90, Loss: 0.6520
Batch 100, Loss: 0.6838
Batch 110, Loss: 0.6507
Batch 120, Loss: 0.6392
Batch 130, Loss: 0.6214
Batch 140, Loss: 0.5994
Batch 150, Loss: 0.5959
Batch 160, Loss: 0.6186
Batch 170, Loss: 0.5806
Batch 180, Loss: 0.6094
Batch 190, Loss: 0.6249
Batch 200, Loss: 0.6223
Batch 210, Loss: 0.6208
Batch 220, Loss: 0.5888
Batch 230, Loss: 0.5864
Batch 240, Loss: 0.5972
Batch 250, Loss: 0.6003
Batch 260, Loss: 0.6067
Batch 270, Loss: 0.6135
Batch 280, Loss: 0.6163
Batch 290, Loss: 0.6079
Batch 300, Loss: 0.6264
Batch 310, Loss: 0.5956
Batch 320, Loss: 0.6493
Batch 330, Loss: 0.6004
Batch 340, Loss: 0.5822
Batch 350, Loss: 0.5633
Batch 360, Loss: 0.6284
Batch 370, Loss: 0.6112
Batch 380, Loss: 0.6032
Batch 390, Loss: 0.5929
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.204901456832886 seconds
Epoch 23 accuracy: 80.07%
Batch 10, Loss: 0.5624
Batch 20, Loss: 0.5800
Batch 30, Loss: 0.6020
Batch 40, Loss: 0.6092
Batch 50, Loss: 0.5862
Batch 60, Loss: 0.6718
Batch 70, Loss: 0.6301
Batch 80, Loss: 0.6420
Batch 90, Loss: 0.6100
Batch 100, Loss: 0.5815
Batch 110, Loss: 0.6165
Batch 120, Loss: 0.6493
Batch 130, Loss: 0.6163
Batch 140, Loss: 0.6168
Batch 150, Loss: 0.6387
Batch 160, Loss: 0.5974
Batch 170, Loss: 0.6177
Batch 180, Loss: 0.6694
Batch 190, Loss: 0.5909
Batch 200, Loss: 0.5829
Batch 210, Loss: 0.6145
Batch 220, Loss: 0.6180
Batch 230, Loss: 0.5788
Batch 240, Loss: 0.6441
Batch 250, Loss: 0.6710
Batch 260, Loss: 0.6294
Batch 270, Loss: 0.6264
Batch 280, Loss: 0.6504
Batch 290, Loss: 0.5810
Batch 300, Loss: 0.6016
Batch 310, Loss: 0.5656
Batch 320, Loss: 0.6231
Batch 330, Loss: 0.6056
Batch 340, Loss: 0.5891
Batch 350, Loss: 0.5925
Batch 360, Loss: 0.6078
Batch 370, Loss: 0.6488
Batch 380, Loss: 0.6143
Batch 390, Loss: 0.6321
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.244478225708008 seconds
Epoch 24 accuracy: 82.05%
Batch 10, Loss: 0.5918
Batch 20, Loss: 0.5841
Batch 30, Loss: 0.5510
Batch 40, Loss: 0.5686
Batch 50, Loss: 0.5946
Batch 60, Loss: 0.5813
Batch 70, Loss: 0.6183
Batch 80, Loss: 0.5614
Batch 90, Loss: 0.5743
Batch 100, Loss: 0.6049
Batch 110, Loss: 0.6108
Batch 120, Loss: 0.6110
Batch 130, Loss: 0.6263
Batch 140, Loss: 0.6324
Batch 150, Loss: 0.6250
Batch 160, Loss: 0.6469
Batch 170, Loss: 0.6197
Batch 180, Loss: 0.6171
Batch 190, Loss: 0.6163
Batch 200, Loss: 0.6162
Batch 210, Loss: 0.5654
Batch 220, Loss: 0.6296
Batch 230, Loss: 0.6130
Batch 240, Loss: 0.5762
Batch 250, Loss: 0.6210
Batch 260, Loss: 0.5967
Batch 270, Loss: 0.6570
Batch 280, Loss: 0.6371
Batch 290, Loss: 0.6261
Batch 300, Loss: 0.6291
Batch 310, Loss: 0.5333
Batch 320, Loss: 0.5862
Batch 330, Loss: 0.5587
Batch 340, Loss: 0.5781
Batch 350, Loss: 0.6440
Batch 360, Loss: 0.6157
Batch 370, Loss: 0.6442
Batch 380, Loss: 0.6322
Batch 390, Loss: 0.6205
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.27632451057434 seconds
Epoch 25 accuracy: 83.89%
Batch 10, Loss: 0.5645
Batch 20, Loss: 0.6381
Batch 30, Loss: 0.5858
Batch 40, Loss: 0.5963
Batch 50, Loss: 0.6161
Batch 60, Loss: 0.5585
Batch 70, Loss: 0.5775
Batch 80, Loss: 0.5915
Batch 90, Loss: 0.5881
Batch 100, Loss: 0.5841
Batch 110, Loss: 0.6096
Batch 120, Loss: 0.5570
Batch 130, Loss: 0.5968
Batch 140, Loss: 0.6276
Batch 150, Loss: 0.5907
Batch 160, Loss: 0.5706
Batch 170, Loss: 0.5813
Batch 180, Loss: 0.6434
Batch 190, Loss: 0.6012
Batch 200, Loss: 0.6005
Batch 210, Loss: 0.5440
Batch 220, Loss: 0.5481
Batch 230, Loss: 0.6030
Batch 240, Loss: 0.6176
Batch 250, Loss: 0.6331
Batch 260, Loss: 0.5928
Batch 270, Loss: 0.5967
Batch 280, Loss: 0.5570
Batch 290, Loss: 0.5966
Batch 300, Loss: 0.5884
Batch 310, Loss: 0.6267
Batch 320, Loss: 0.5841
Batch 330, Loss: 0.6074
Batch 340, Loss: 0.6317
Batch 350, Loss: 0.6602
Batch 360, Loss: 0.5768
Batch 370, Loss: 0.5940
Batch 380, Loss: 0.6442
Batch 390, Loss: 0.6138
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.332579135894775 seconds
Epoch 26 accuracy: 83.17%
Batch 10, Loss: 0.5571
Batch 20, Loss: 0.5981
Batch 30, Loss: 0.5668
Batch 40, Loss: 0.6238
Batch 50, Loss: 0.5655
Batch 60, Loss: 0.5810
Batch 70, Loss: 0.6031
Batch 80, Loss: 0.6146
Batch 90, Loss: 0.6276
Batch 100, Loss: 0.6171
Batch 110, Loss: 0.5939
Batch 120, Loss: 0.6389
Batch 130, Loss: 0.5673
Batch 140, Loss: 0.5967
Batch 150, Loss: 0.6196
Batch 160, Loss: 0.6371
Batch 170, Loss: 0.5923
Batch 180, Loss: 0.6048
Batch 190, Loss: 0.5617
Batch 200, Loss: 0.5790
Batch 210, Loss: 0.5889
Batch 220, Loss: 0.6046
Batch 230, Loss: 0.6180
Batch 240, Loss: 0.5982
Batch 250, Loss: 0.5371
Batch 260, Loss: 0.5794
Batch 270, Loss: 0.6167
Batch 280, Loss: 0.5849
Batch 290, Loss: 0.5830
Batch 300, Loss: 0.5876
Batch 310, Loss: 0.5816
Batch 320, Loss: 0.5790
Batch 330, Loss: 0.5716
Batch 340, Loss: 0.6139
Batch 350, Loss: 0.6117
Batch 360, Loss: 0.6092
Batch 370, Loss: 0.6259
Batch 380, Loss: 0.6108
Batch 390, Loss: 0.6276
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.48522114753723 seconds
Epoch 27 accuracy: 72.22%
Batch 10, Loss: 0.6099
Batch 20, Loss: 0.5878
Batch 30, Loss: 0.5608
Batch 40, Loss: 0.5963
Batch 50, Loss: 0.6126
Batch 60, Loss: 0.5549
Batch 70, Loss: 0.5468
Batch 80, Loss: 0.5943
Batch 90, Loss: 0.5746
Batch 100, Loss: 0.6483
Batch 110, Loss: 0.5985
Batch 120, Loss: 0.5634
Batch 130, Loss: 0.6390
Batch 140, Loss: 0.6225
Batch 150, Loss: 0.5965
Batch 160, Loss: 0.5818
Batch 170, Loss: 0.5754
Batch 180, Loss: 0.5841
Batch 190, Loss: 0.6047
Batch 200, Loss: 0.5689
Batch 210, Loss: 0.5831
Batch 220, Loss: 0.6057
Batch 230, Loss: 0.6181
Batch 240, Loss: 0.5952
Batch 250, Loss: 0.5823
Batch 260, Loss: 0.5787
Batch 270, Loss: 0.5843
Batch 280, Loss: 0.5814
Batch 290, Loss: 0.5826
Batch 300, Loss: 0.6237
Batch 310, Loss: 0.5848
Batch 320, Loss: 0.5784
Batch 330, Loss: 0.6257
Batch 340, Loss: 0.6249
Batch 350, Loss: 0.5872
Batch 360, Loss: 0.6182
Batch 370, Loss: 0.5886
Batch 380, Loss: 0.5975
Batch 390, Loss: 0.5952
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.810600996017456 seconds
Epoch 28 accuracy: 84.47%
Batch 10, Loss: 0.5706
Batch 20, Loss: 0.5766
Batch 30, Loss: 0.6134
Batch 40, Loss: 0.6395
Batch 50, Loss: 0.5811
Batch 60, Loss: 0.5965
Batch 70, Loss: 0.6004
Batch 80, Loss: 0.5603
Batch 90, Loss: 0.5515
Batch 100, Loss: 0.6208
Batch 110, Loss: 0.6190
Batch 120, Loss: 0.5855
Batch 130, Loss: 0.5893
Batch 140, Loss: 0.5959
Batch 150, Loss: 0.5742
Batch 160, Loss: 0.5716
Batch 170, Loss: 0.5509
Batch 180, Loss: 0.6260
Batch 190, Loss: 0.6005
Batch 200, Loss: 0.6119
Batch 210, Loss: 0.5707
Batch 220, Loss: 0.5619
Batch 230, Loss: 0.5930
Batch 240, Loss: 0.5662
Batch 250, Loss: 0.6097
Batch 260, Loss: 0.5887
Batch 270, Loss: 0.5760
Batch 280, Loss: 0.6126
Batch 290, Loss: 0.6002
Batch 300, Loss: 0.6057
Batch 310, Loss: 0.5993
Batch 320, Loss: 0.5679
Batch 330, Loss: 0.6306
Batch 340, Loss: 0.5707
Batch 350, Loss: 0.5735
Batch 360, Loss: 0.5727
Batch 370, Loss: 0.5900
Batch 380, Loss: 0.6111
Batch 390, Loss: 0.6055
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.619250297546387 seconds
Epoch 29 accuracy: 80.39%
Batch 10, Loss: 0.5783
Batch 20, Loss: 0.5745
Batch 30, Loss: 0.5318
Batch 40, Loss: 0.5955
Batch 50, Loss: 0.5839
Batch 60, Loss: 0.5675
Batch 70, Loss: 0.6014
Batch 80, Loss: 0.5821
Batch 90, Loss: 0.5990
Batch 100, Loss: 0.5613
Batch 110, Loss: 0.5674
Batch 120, Loss: 0.5602
Batch 130, Loss: 0.5795
Batch 140, Loss: 0.5808
Batch 150, Loss: 0.5886
Batch 160, Loss: 0.6055
Batch 170, Loss: 0.5979
Batch 180, Loss: 0.5802
Batch 190, Loss: 0.5817
Batch 200, Loss: 0.5708
Batch 210, Loss: 0.6192
Batch 220, Loss: 0.5767
Batch 230, Loss: 0.5844
Batch 240, Loss: 0.5883
Batch 250, Loss: 0.5657
Batch 260, Loss: 0.6280
Batch 270, Loss: 0.5878
Batch 280, Loss: 0.6143
Batch 290, Loss: 0.6343
Batch 300, Loss: 0.5773
Batch 310, Loss: 0.5961
Batch 320, Loss: 0.5858
Batch 330, Loss: 0.5679
Batch 340, Loss: 0.5897
Batch 350, Loss: 0.5623
Batch 360, Loss: 0.5733
Batch 370, Loss: 0.5644
Batch 380, Loss: 0.5384
Batch 390, Loss: 0.6171
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.53112554550171 seconds
Epoch 30 accuracy: 80.5%
Batch 10, Loss: 0.5655
Batch 20, Loss: 0.5656
Batch 30, Loss: 0.6287
Batch 40, Loss: 0.5813
Batch 50, Loss: 0.5411
Batch 60, Loss: 0.5873
Batch 70, Loss: 0.5544
Batch 80, Loss: 0.5786
Batch 90, Loss: 0.5864
Batch 100, Loss: 0.5781
Batch 110, Loss: 0.6051
Batch 120, Loss: 0.5764
Batch 130, Loss: 0.5874
Batch 140, Loss: 0.5608
Batch 150, Loss: 0.5658
Batch 160, Loss: 0.5756
Batch 170, Loss: 0.5868
Batch 180, Loss: 0.5714
Batch 190, Loss: 0.5910
Batch 200, Loss: 0.5541
Batch 210, Loss: 0.5769
Batch 220, Loss: 0.5981
Batch 230, Loss: 0.5846
Batch 240, Loss: 0.5914
Batch 250, Loss: 0.6164
Batch 260, Loss: 0.5417
Batch 270, Loss: 0.6156
Batch 280, Loss: 0.6166
Batch 290, Loss: 0.6268
Batch 300, Loss: 0.5809
Batch 310, Loss: 0.5525
Batch 320, Loss: 0.5186
Batch 330, Loss: 0.5774
Batch 340, Loss: 0.5887
Batch 350, Loss: 0.5824
Batch 360, Loss: 0.5737
Batch 370, Loss: 0.5626
Batch 380, Loss: 0.5714
Batch 390, Loss: 0.5801
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.578022718429565 seconds
Epoch 31 accuracy: 79.85%
Batch 10, Loss: 0.6040
Batch 20, Loss: 0.5950
Batch 30, Loss: 0.6004
Batch 40, Loss: 0.5441
Batch 50, Loss: 0.5601
Batch 60, Loss: 0.5905
Batch 70, Loss: 0.5813
Batch 80, Loss: 0.5825
Batch 90, Loss: 0.5509
Batch 100, Loss: 0.5591
Batch 110, Loss: 0.5780
Batch 120, Loss: 0.5732
Batch 130, Loss: 0.5759
Batch 140, Loss: 0.5799
Batch 150, Loss: 0.5869
Batch 160, Loss: 0.5502
Batch 170, Loss: 0.5707
Batch 180, Loss: 0.5796
Batch 190, Loss: 0.5796
Batch 200, Loss: 0.5724
Batch 210, Loss: 0.6327
Batch 220, Loss: 0.5512
Batch 230, Loss: 0.5379
Batch 240, Loss: 0.5560
Batch 250, Loss: 0.5691
Batch 260, Loss: 0.6048
Batch 270, Loss: 0.5869
Batch 280, Loss: 0.5502
Batch 290, Loss: 0.5417
Batch 300, Loss: 0.6070
Batch 310, Loss: 0.5859
Batch 320, Loss: 0.5523
Batch 330, Loss: 0.5561
Batch 340, Loss: 0.5564
Batch 350, Loss: 0.5803
Batch 360, Loss: 0.5814
Batch 370, Loss: 0.5671
Batch 380, Loss: 0.5732
Batch 390, Loss: 0.5811
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.539995908737183 seconds
Epoch 32 accuracy: 83.35%
Batch 10, Loss: 0.5489
Batch 20, Loss: 0.5750
Batch 30, Loss: 0.5355
Batch 40, Loss: 0.5257
Batch 50, Loss: 0.5870
Batch 60, Loss: 0.5655
Batch 70, Loss: 0.5724
Batch 80, Loss: 0.5480
Batch 90, Loss: 0.5451
Batch 100, Loss: 0.5621
Batch 110, Loss: 0.5625
Batch 120, Loss: 0.5959
Batch 130, Loss: 0.5762
Batch 140, Loss: 0.5443
Batch 150, Loss: 0.5621
Batch 160, Loss: 0.5596
Batch 170, Loss: 0.6176
Batch 180, Loss: 0.6116
Batch 190, Loss: 0.6224
Batch 200, Loss: 0.5344
Batch 210, Loss: 0.5465
Batch 220, Loss: 0.5684
Batch 230, Loss: 0.5675
Batch 240, Loss: 0.5969
Batch 250, Loss: 0.6006
Batch 260, Loss: 0.6180
Batch 270, Loss: 0.5513
Batch 280, Loss: 0.5622
Batch 290, Loss: 0.5890
Batch 300, Loss: 0.5596
Batch 310, Loss: 0.5858
Batch 320, Loss: 0.6187
Batch 330, Loss: 0.5685
Batch 340, Loss: 0.6199
Batch 350, Loss: 0.5731
Batch 360, Loss: 0.5831
Batch 370, Loss: 0.6117
Batch 380, Loss: 0.6106
Batch 390, Loss: 0.5709
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.67111110687256 seconds
Epoch 33 accuracy: 81.91%
Batch 10, Loss: 0.5511
Batch 20, Loss: 0.5990
Batch 30, Loss: 0.5364
Batch 40, Loss: 0.5575
Batch 50, Loss: 0.5717
Batch 60, Loss: 0.5163
Batch 70, Loss: 0.5649
Batch 80, Loss: 0.5615
Batch 90, Loss: 0.5569
Batch 100, Loss: 0.5611
Batch 110, Loss: 0.5511
Batch 120, Loss: 0.5309
Batch 130, Loss: 0.6097
Batch 140, Loss: 0.5767
Batch 150, Loss: 0.5576
Batch 160, Loss: 0.5860
Batch 170, Loss: 0.5781
Batch 180, Loss: 0.5746
Batch 190, Loss: 0.5612
Batch 200, Loss: 0.5812
Batch 210, Loss: 0.5271
Batch 220, Loss: 0.5279
Batch 230, Loss: 0.5533
Batch 240, Loss: 0.5907
Batch 250, Loss: 0.5676
Batch 260, Loss: 0.5547
Batch 270, Loss: 0.5871
Batch 280, Loss: 0.5402
Batch 290, Loss: 0.5879
Batch 300, Loss: 0.5852
Batch 310, Loss: 0.5783
Batch 320, Loss: 0.5933
Batch 330, Loss: 0.5961
Batch 340, Loss: 0.5686
Batch 350, Loss: 0.5792
Batch 360, Loss: 0.5784
Batch 370, Loss: 0.5453
Batch 380, Loss: 0.5735
Batch 390, Loss: 0.6180
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.76728868484497 seconds
Epoch 34 accuracy: 74.44%
Batch 10, Loss: 0.5890
Batch 20, Loss: 0.5601
Batch 30, Loss: 0.5707
Batch 40, Loss: 0.5552
Batch 50, Loss: 0.5604
Batch 60, Loss: 0.5668
Batch 70, Loss: 0.5582
Batch 80, Loss: 0.5809
Batch 90, Loss: 0.5627
Batch 100, Loss: 0.5867
Batch 110, Loss: 0.6091
Batch 120, Loss: 0.5974
Batch 130, Loss: 0.5704
Batch 140, Loss: 0.5576
Batch 150, Loss: 0.5574
Batch 160, Loss: 0.5466
Batch 170, Loss: 0.6367
Batch 180, Loss: 0.6113
Batch 190, Loss: 0.5543
Batch 200, Loss: 0.5541
Batch 210, Loss: 0.5801
Batch 220, Loss: 0.6001
Batch 230, Loss: 0.5571
Batch 240, Loss: 0.5643
Batch 250, Loss: 0.5798
Batch 260, Loss: 0.5739
Batch 270, Loss: 0.5519
Batch 280, Loss: 0.5680
Batch 290, Loss: 0.5697
Batch 300, Loss: 0.5950
Batch 310, Loss: 0.5626
Batch 320, Loss: 0.5501
Batch 330, Loss: 0.5316
Batch 340, Loss: 0.5870
Batch 350, Loss: 0.6339
Batch 360, Loss: 0.5335
Batch 370, Loss: 0.5681
Batch 380, Loss: 0.5911
Batch 390, Loss: 0.5882
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.5846905708313 seconds
Epoch 35 accuracy: 81.93%
Batch 10, Loss: 0.5908
Batch 20, Loss: 0.5488
Batch 30, Loss: 0.5437
Batch 40, Loss: 0.5392
Batch 50, Loss: 0.5826
Batch 60, Loss: 0.5519
Batch 70, Loss: 0.5721
Batch 80, Loss: 0.5714
Batch 90, Loss: 0.5515
Batch 100, Loss: 0.5719
Batch 110, Loss: 0.5773
Batch 120, Loss: 0.5801
Batch 130, Loss: 0.5986
Batch 140, Loss: 0.5867
Batch 150, Loss: 0.6103
Batch 160, Loss: 0.5892
Batch 170, Loss: 0.5811
Batch 180, Loss: 0.5434
Batch 190, Loss: 0.5195
Batch 200, Loss: 0.5700
Batch 210, Loss: 0.5529
Batch 220, Loss: 0.5702
Batch 230, Loss: 0.5669
Batch 240, Loss: 0.5655
Batch 250, Loss: 0.5420
Batch 260, Loss: 0.5768
Batch 270, Loss: 0.5592
Batch 280, Loss: 0.5844
Batch 290, Loss: 0.5862
Batch 300, Loss: 0.5527
Batch 310, Loss: 0.5613
Batch 320, Loss: 0.5932
Batch 330, Loss: 0.5719
Batch 340, Loss: 0.6155
Batch 350, Loss: 0.5449
Batch 360, Loss: 0.5486
Batch 370, Loss: 0.5440
Batch 380, Loss: 0.5436
Batch 390, Loss: 0.5602
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.640724897384644 seconds
Epoch 36 accuracy: 79.95%
Batch 10, Loss: 0.5600
Batch 20, Loss: 0.5620
Batch 30, Loss: 0.6199
Batch 40, Loss: 0.5815
Batch 50, Loss: 0.5770
Batch 60, Loss: 0.5501
Batch 70, Loss: 0.5782
Batch 80, Loss: 0.5484
Batch 90, Loss: 0.5627
Batch 100, Loss: 0.5323
Batch 110, Loss: 0.5432
Batch 120, Loss: 0.5541
Batch 130, Loss: 0.5548
Batch 140, Loss: 0.5872
Batch 150, Loss: 0.5843
Batch 160, Loss: 0.5631
Batch 170, Loss: 0.5317
Batch 180, Loss: 0.5527
Batch 190, Loss: 0.5804
Batch 200, Loss: 0.5617
Batch 210, Loss: 0.5522
Batch 220, Loss: 0.5729
Batch 230, Loss: 0.5694
Batch 240, Loss: 0.6147
Batch 250, Loss: 0.5786
Batch 260, Loss: 0.5987
Batch 270, Loss: 0.5551
Batch 280, Loss: 0.5657
Batch 290, Loss: 0.5801
Batch 300, Loss: 0.5659
Batch 310, Loss: 0.5727
Batch 320, Loss: 0.6019
Batch 330, Loss: 0.5918
Batch 340, Loss: 0.5374
Batch 350, Loss: 0.5385
Batch 360, Loss: 0.5911
Batch 370, Loss: 0.5655
Batch 380, Loss: 0.5896
Batch 390, Loss: 0.5711
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.821365118026733 seconds
Epoch 37 accuracy: 76.96%
Batch 10, Loss: 0.5504
Batch 20, Loss: 0.6202
Batch 30, Loss: 0.5938
Batch 40, Loss: 0.6017
Batch 50, Loss: 0.5405
Batch 60, Loss: 0.5459
Batch 70, Loss: 0.5958
Batch 80, Loss: 0.5543
Batch 90, Loss: 0.5626
Batch 100, Loss: 0.5828
Batch 110, Loss: 0.5519
Batch 120, Loss: 0.5716
Batch 130, Loss: 0.5452
Batch 140, Loss: 0.6322
Batch 150, Loss: 0.5557
Batch 160, Loss: 0.5827
Batch 170, Loss: 0.5686
Batch 180, Loss: 0.5464
Batch 190, Loss: 0.5642
Batch 200, Loss: 0.5198
Batch 210, Loss: 0.5211
Batch 220, Loss: 0.5395
Batch 230, Loss: 0.5802
Batch 240, Loss: 0.5185
Batch 250, Loss: 0.5547
Batch 260, Loss: 0.5755
Batch 270, Loss: 0.5570
Batch 280, Loss: 0.5364
Batch 290, Loss: 0.5615
Batch 300, Loss: 0.5700
Batch 310, Loss: 0.6146
Batch 320, Loss: 0.5855
Batch 330, Loss: 0.5707
Batch 340, Loss: 0.5277
Batch 350, Loss: 0.4918
Batch 360, Loss: 0.5927
Batch 370, Loss: 0.5499
Batch 380, Loss: 0.5449
Batch 390, Loss: 0.5658
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.507789373397827 seconds
Epoch 38 accuracy: 79.53%
Batch 10, Loss: 0.5651
Batch 20, Loss: 0.6006
Batch 30, Loss: 0.5567
Batch 40, Loss: 0.5634
Batch 50, Loss: 0.5516
Batch 60, Loss: 0.5814
Batch 70, Loss: 0.5910
Batch 80, Loss: 0.5836
Batch 90, Loss: 0.6021
Batch 100, Loss: 0.5570
Batch 110, Loss: 0.6173
Batch 120, Loss: 0.5322
Batch 130, Loss: 0.5614
Batch 140, Loss: 0.5616
Batch 150, Loss: 0.5563
Batch 160, Loss: 0.5477
Batch 170, Loss: 0.5535
Batch 180, Loss: 0.5684
Batch 190, Loss: 0.5471
Batch 200, Loss: 0.5688
Batch 210, Loss: 0.5391
Batch 220, Loss: 0.6100
Batch 230, Loss: 0.5908
Batch 240, Loss: 0.5617
Batch 250, Loss: 0.5768
Batch 260, Loss: 0.5755
Batch 270, Loss: 0.5359
Batch 280, Loss: 0.5186
Batch 290, Loss: 0.5343
Batch 300, Loss: 0.5414
Batch 310, Loss: 0.5907
Batch 320, Loss: 0.6191
Batch 330, Loss: 0.5814
Batch 340, Loss: 0.5869
Batch 350, Loss: 0.5660
Batch 360, Loss: 0.5842
Batch 370, Loss: 0.5730
Batch 380, Loss: 0.5626
Batch 390, Loss: 0.5588
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.601189851760864 seconds
Epoch 39 accuracy: 80.97%
Batch 10, Loss: 0.5802
Batch 20, Loss: 0.5558
Batch 30, Loss: 0.5751
Batch 40, Loss: 0.5102
Batch 50, Loss: 0.5347
Batch 60, Loss: 0.5761
Batch 70, Loss: 0.5624
Batch 80, Loss: 0.5891
Batch 90, Loss: 0.5768
Batch 100, Loss: 0.5732
Batch 110, Loss: 0.5435
Batch 120, Loss: 0.5731
Batch 130, Loss: 0.5243
Batch 140, Loss: 0.5350
Batch 150, Loss: 0.5496
Batch 160, Loss: 0.5364
Batch 170, Loss: 0.5938
Batch 180, Loss: 0.5952
Batch 190, Loss: 0.5884
Batch 200, Loss: 0.5672
Batch 210, Loss: 0.5548
Batch 220, Loss: 0.5876
Batch 230, Loss: 0.5266
Batch 240, Loss: 0.5414
Batch 250, Loss: 0.5871
Batch 260, Loss: 0.6029
Batch 270, Loss: 0.5603
Batch 280, Loss: 0.5699
Batch 290, Loss: 0.5666
Batch 300, Loss: 0.5319
Batch 310, Loss: 0.5764
Batch 320, Loss: 0.5758
Batch 330, Loss: 0.5752
Batch 340, Loss: 0.5431
Batch 350, Loss: 0.5667
Batch 360, Loss: 0.5595
Batch 370, Loss: 0.5717
Batch 380, Loss: 0.5317
Batch 390, Loss: 0.5636
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.683228492736816 seconds
Epoch 40 accuracy: 76.17%
Batch 10, Loss: 0.5196
Batch 20, Loss: 0.5576
Batch 30, Loss: 0.5478
Batch 40, Loss: 0.5272
Batch 50, Loss: 0.5470
Batch 60, Loss: 0.5785
Batch 70, Loss: 0.5084
Batch 80, Loss: 0.5581
Batch 90, Loss: 0.5348
Batch 100, Loss: 0.5869
Batch 110, Loss: 0.5343
Batch 120, Loss: 0.5610
Batch 130, Loss: 0.5793
Batch 140, Loss: 0.5632
Batch 150, Loss: 0.5475
Batch 160, Loss: 0.5466
Batch 170, Loss: 0.5529
Batch 180, Loss: 0.5485
Batch 190, Loss: 0.5710
Batch 200, Loss: 0.5678
Batch 210, Loss: 0.5419
Batch 220, Loss: 0.5974
Batch 230, Loss: 0.5410
Batch 240, Loss: 0.5380
Batch 250, Loss: 0.5665
Batch 260, Loss: 0.5643
Batch 270, Loss: 0.5515
Batch 280, Loss: 0.5683
Batch 290, Loss: 0.5810
Batch 300, Loss: 0.5885
Batch 310, Loss: 0.6195
Batch 320, Loss: 0.5759
Batch 330, Loss: 0.5790
Batch 340, Loss: 0.5679
Batch 350, Loss: 0.5429
Batch 360, Loss: 0.5522
Batch 370, Loss: 0.5308
Batch 380, Loss: 0.5619
Batch 390, Loss: 0.5594
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.526456117630005 seconds
Epoch 41 accuracy: 83.86%
Batch 10, Loss: 0.5034
Batch 20, Loss: 0.5612
Batch 30, Loss: 0.5447
Batch 40, Loss: 0.5899
Batch 50, Loss: 0.5475
Batch 60, Loss: 0.5385
Batch 70, Loss: 0.5471
Batch 80, Loss: 0.5170
Batch 90, Loss: 0.5508
Batch 100, Loss: 0.5711
Batch 110, Loss: 0.5433
Batch 120, Loss: 0.5405
Batch 130, Loss: 0.5604
Batch 140, Loss: 0.5942
Batch 150, Loss: 0.5346
Batch 160, Loss: 0.5302
Batch 170, Loss: 0.5482
Batch 180, Loss: 0.5186
Batch 190, Loss: 0.5691
Batch 200, Loss: 0.5454
Batch 210, Loss: 0.5732
Batch 220, Loss: 0.5784
Batch 230, Loss: 0.5846
Batch 240, Loss: 0.6064
Batch 250, Loss: 0.5441
Batch 260, Loss: 0.5578
Batch 270, Loss: 0.5319
Batch 280, Loss: 0.5595
Batch 290, Loss: 0.5716
Batch 300, Loss: 0.5387
Batch 310, Loss: 0.5403
Batch 320, Loss: 0.6017
Batch 330, Loss: 0.5707
Batch 340, Loss: 0.5772
Batch 350, Loss: 0.6039
Batch 360, Loss: 0.5358
Batch 370, Loss: 0.5400
Batch 380, Loss: 0.5093
Batch 390, Loss: 0.5292
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.73811984062195 seconds
Epoch 42 accuracy: 80.25%
Batch 10, Loss: 0.5722
Batch 20, Loss: 0.5397
Batch 30, Loss: 0.5446
Batch 40, Loss: 0.5718
Batch 50, Loss: 0.5845
Batch 60, Loss: 0.5767
Batch 70, Loss: 0.5414
Batch 80, Loss: 0.5265
Batch 90, Loss: 0.5465
Batch 100, Loss: 0.5476
Batch 110, Loss: 0.4651
Batch 120, Loss: 0.5759
Batch 130, Loss: 0.5518
Batch 140, Loss: 0.5679
Batch 150, Loss: 0.5467
Batch 160, Loss: 0.5707
Batch 170, Loss: 0.5483
Batch 180, Loss: 0.5901
Batch 190, Loss: 0.5682
Batch 200, Loss: 0.5187
Batch 210, Loss: 0.5469
Batch 220, Loss: 0.5512
Batch 230, Loss: 0.5556
Batch 240, Loss: 0.5426
Batch 250, Loss: 0.5645
Batch 260, Loss: 0.5547
Batch 270, Loss: 0.5793
Batch 280, Loss: 0.5659
Batch 290, Loss: 0.5591
Batch 300, Loss: 0.5404
Batch 310, Loss: 0.5792
Batch 320, Loss: 0.5450
Batch 330, Loss: 0.5423
Batch 340, Loss: 0.5698
Batch 350, Loss: 0.5813
Batch 360, Loss: 0.5471
Batch 370, Loss: 0.5573
Batch 380, Loss: 0.5339
Batch 390, Loss: 0.5607
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.572420835494995 seconds
Epoch 43 accuracy: 81.56%
Batch 10, Loss: 0.5594
Batch 20, Loss: 0.5523
Batch 30, Loss: 0.5704
Batch 40, Loss: 0.5826
Batch 50, Loss: 0.5268
Batch 60, Loss: 0.5764
Batch 70, Loss: 0.5719
Batch 80, Loss: 0.5779
Batch 90, Loss: 0.5500
Batch 100, Loss: 0.5357
Batch 110, Loss: 0.5493
Batch 120, Loss: 0.5493
Batch 130, Loss: 0.5780
Batch 140, Loss: 0.5498
Batch 150, Loss: 0.5391
Batch 160, Loss: 0.5658
Batch 170, Loss: 0.5575
Batch 180, Loss: 0.5660
Batch 190, Loss: 0.5634
Batch 200, Loss: 0.5629
Batch 210, Loss: 0.5583
Batch 220, Loss: 0.5378
Batch 230, Loss: 0.5475
Batch 240, Loss: 0.5459
Batch 250, Loss: 0.5523
Batch 260, Loss: 0.5686
Batch 270, Loss: 0.5656
Batch 280, Loss: 0.5097
Batch 290, Loss: 0.6098
Batch 300, Loss: 0.5554
Batch 310, Loss: 0.5560
Batch 320, Loss: 0.5644
Batch 330, Loss: 0.5573
Batch 340, Loss: 0.5019
Batch 350, Loss: 0.5567
Batch 360, Loss: 0.5288
Batch 370, Loss: 0.5441
Batch 380, Loss: 0.4989
Batch 390, Loss: 0.5263
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.637084245681763 seconds
Epoch 44 accuracy: 80.41%
Batch 10, Loss: 0.5585
Batch 20, Loss: 0.5571
Batch 30, Loss: 0.5069
Batch 40, Loss: 0.5335
Batch 50, Loss: 0.5501
Batch 60, Loss: 0.5167
Batch 70, Loss: 0.5475
Batch 80, Loss: 0.5503
Batch 90, Loss: 0.5523
Batch 100, Loss: 0.5455
Batch 110, Loss: 0.5467
Batch 120, Loss: 0.5029
Batch 130, Loss: 0.5726
Batch 140, Loss: 0.5632
Batch 150, Loss: 0.5619
Batch 160, Loss: 0.5584
Batch 170, Loss: 0.5455
Batch 180, Loss: 0.5533
Batch 190, Loss: 0.5456
Batch 200, Loss: 0.5363
Batch 210, Loss: 0.5242
Batch 220, Loss: 0.5310
Batch 230, Loss: 0.5765
Batch 240, Loss: 0.5576
Batch 250, Loss: 0.5839
Batch 260, Loss: 0.5615
Batch 270, Loss: 0.5307
Batch 280, Loss: 0.5487
Batch 290, Loss: 0.5746
Batch 300, Loss: 0.5259
Batch 310, Loss: 0.5560
Batch 320, Loss: 0.5614
Batch 330, Loss: 0.5539
Batch 340, Loss: 0.5623
Batch 350, Loss: 0.5033
Batch 360, Loss: 0.5227
Batch 370, Loss: 0.5493
Batch 380, Loss: 0.5072
Batch 390, Loss: 0.5818
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.54624605178833 seconds
Epoch 45 accuracy: 85.48%
Batch 10, Loss: 0.5534
Batch 20, Loss: 0.5576
Batch 30, Loss: 0.5665
Batch 40, Loss: 0.5401
Batch 50, Loss: 0.5588
Batch 60, Loss: 0.5376
Batch 70, Loss: 0.5236
Batch 80, Loss: 0.5096
Batch 90, Loss: 0.5894
Batch 100, Loss: 0.5201
Batch 110, Loss: 0.5406
Batch 120, Loss: 0.5586
Batch 130, Loss: 0.5753
Batch 140, Loss: 0.5298
Batch 150, Loss: 0.5782
Batch 160, Loss: 0.5217
Batch 170, Loss: 0.5156
Batch 180, Loss: 0.5457
Batch 190, Loss: 0.5403
Batch 200, Loss: 0.5366
Batch 210, Loss: 0.5485
Batch 220, Loss: 0.5513
Batch 230, Loss: 0.5455
Batch 240, Loss: 0.5408
Batch 250, Loss: 0.5625
Batch 260, Loss: 0.5333
Batch 270, Loss: 0.5452
Batch 280, Loss: 0.5455
Batch 290, Loss: 0.5387
Batch 300, Loss: 0.5130
Batch 310, Loss: 0.5224
Batch 320, Loss: 0.5577
Batch 330, Loss: 0.5770
Batch 340, Loss: 0.5525
Batch 350, Loss: 0.5370
Batch 360, Loss: 0.5676
Batch 370, Loss: 0.5551
Batch 380, Loss: 0.5684
Batch 390, Loss: 0.5560
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.535077810287476 seconds
Epoch 46 accuracy: 84.37%
Batch 10, Loss: 0.5267
Batch 20, Loss: 0.5260
Batch 30, Loss: 0.5483
Batch 40, Loss: 0.5396
Batch 50, Loss: 0.5338
Batch 60, Loss: 0.5273
Batch 70, Loss: 0.5226
Batch 80, Loss: 0.5433
Batch 90, Loss: 0.5104
Batch 100, Loss: 0.5707
Batch 110, Loss: 0.5872
Batch 120, Loss: 0.5516
Batch 130, Loss: 0.4926
Batch 140, Loss: 0.5328
Batch 150, Loss: 0.5256
Batch 160, Loss: 0.5560
Batch 170, Loss: 0.5630
Batch 180, Loss: 0.5460
Batch 190, Loss: 0.5146
Batch 200, Loss: 0.5113
Batch 210, Loss: 0.5546
Batch 220, Loss: 0.5832
Batch 230, Loss: 0.4870
Batch 240, Loss: 0.5667
Batch 250, Loss: 0.5738
Batch 260, Loss: 0.5742
Batch 270, Loss: 0.5492
Batch 280, Loss: 0.5327
Batch 290, Loss: 0.5443
Batch 300, Loss: 0.5691
Batch 310, Loss: 0.5286
Batch 320, Loss: 0.5759
Batch 330, Loss: 0.5597
Batch 340, Loss: 0.5320
Batch 350, Loss: 0.5409
Batch 360, Loss: 0.5684
Batch 370, Loss: 0.4932
Batch 380, Loss: 0.5348
Batch 390, Loss: 0.5364
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.611319065093994 seconds
Epoch 47 accuracy: 83.95%
Batch 10, Loss: 0.5764
Batch 20, Loss: 0.5473
Batch 30, Loss: 0.5412
Batch 40, Loss: 0.5349
Batch 50, Loss: 0.5284
Batch 60, Loss: 0.5414
Batch 70, Loss: 0.5120
Batch 80, Loss: 0.5517
Batch 90, Loss: 0.5257
Batch 100, Loss: 0.5560
Batch 110, Loss: 0.5714
Batch 120, Loss: 0.5288
Batch 130, Loss: 0.5422
Batch 140, Loss: 0.5041
Batch 150, Loss: 0.5590
Batch 160, Loss: 0.5391
Batch 170, Loss: 0.4993
Batch 180, Loss: 0.5342
Batch 190, Loss: 0.5598
Batch 200, Loss: 0.5167
Batch 210, Loss: 0.5429
Batch 220, Loss: 0.5459
Batch 230, Loss: 0.5343
Batch 240, Loss: 0.5461
Batch 250, Loss: 0.5200
Batch 260, Loss: 0.5553
Batch 270, Loss: 0.5342
Batch 280, Loss: 0.5261
Batch 290, Loss: 0.5460
Batch 300, Loss: 0.5597
Batch 310, Loss: 0.5410
Batch 320, Loss: 0.5872
Batch 330, Loss: 0.5506
Batch 340, Loss: 0.5632
Batch 350, Loss: 0.5674
Batch 360, Loss: 0.5751
Batch 370, Loss: 0.5231
Batch 380, Loss: 0.5275
Batch 390, Loss: 0.5740
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.620540618896484 seconds
Epoch 48 accuracy: 77.67%
Batch 10, Loss: 0.5268
Batch 20, Loss: 0.5428
Batch 30, Loss: 0.5076
Batch 40, Loss: 0.5371
Batch 50, Loss: 0.5688
Batch 60, Loss: 0.5473
Batch 70, Loss: 0.5143
Batch 80, Loss: 0.5870
Batch 90, Loss: 0.5900
Batch 100, Loss: 0.5551
Batch 110, Loss: 0.5245
Batch 120, Loss: 0.5371
Batch 130, Loss: 0.5169
Batch 140, Loss: 0.5235
Batch 150, Loss: 0.5616
Batch 160, Loss: 0.5595
Batch 170, Loss: 0.5401
Batch 180, Loss: 0.5594
Batch 190, Loss: 0.5385
Batch 200, Loss: 0.5560
Batch 210, Loss: 0.5263
Batch 220, Loss: 0.5147
Batch 230, Loss: 0.5542
Batch 240, Loss: 0.5488
Batch 250, Loss: 0.5791
Batch 260, Loss: 0.5282
Batch 270, Loss: 0.5535
Batch 280, Loss: 0.5104
Batch 290, Loss: 0.5317
Batch 300, Loss: 0.5595
Batch 310, Loss: 0.5274
Batch 320, Loss: 0.5577
Batch 330, Loss: 0.5767
Batch 340, Loss: 0.5547
Batch 350, Loss: 0.5360
Batch 360, Loss: 0.5638
Batch 370, Loss: 0.5657
Batch 380, Loss: 0.5203
Batch 390, Loss: 0.5617
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.4666166305542 seconds
Epoch 49 accuracy: 83.12%
Batch 10, Loss: 0.4942
Batch 20, Loss: 0.5265
Batch 30, Loss: 0.5663
Batch 40, Loss: 0.4951
Batch 50, Loss: 0.5238
Batch 60, Loss: 0.5625
Batch 70, Loss: 0.5520
Batch 80, Loss: 0.5416
Batch 90, Loss: 0.5431
Batch 100, Loss: 0.5793
Batch 110, Loss: 0.6097
Batch 120, Loss: 0.5232
Batch 130, Loss: 0.5456
Batch 140, Loss: 0.5480
Batch 150, Loss: 0.5093
Batch 160, Loss: 0.5130
Batch 170, Loss: 0.5437
Batch 180, Loss: 0.5775
Batch 190, Loss: 0.5468
Batch 200, Loss: 0.5589
Batch 210, Loss: 0.5306
Batch 220, Loss: 0.5297
Batch 230, Loss: 0.5539
Batch 240, Loss: 0.5543
Batch 250, Loss: 0.5179
Batch 260, Loss: 0.5542
Batch 270, Loss: 0.5300
Batch 280, Loss: 0.5150
Batch 290, Loss: 0.5217
Batch 300, Loss: 0.5510
Batch 310, Loss: 0.5235
Batch 320, Loss: 0.5434
Batch 330, Loss: 0.5434
Batch 340, Loss: 0.5338
Batch 350, Loss: 0.4994
Batch 360, Loss: 0.5357
Batch 370, Loss: 0.5807
Batch 380, Loss: 0.5305
Batch 390, Loss: 0.5385
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.577527046203613 seconds
Epoch 50 accuracy: 85.64%
Batch 10, Loss: 0.5061
Batch 20, Loss: 0.5156
Batch 30, Loss: 0.5389
Batch 40, Loss: 0.5293
Batch 50, Loss: 0.5491
Batch 60, Loss: 0.5199
Batch 70, Loss: 0.5402
Batch 80, Loss: 0.5620
Batch 90, Loss: 0.4849
Batch 100, Loss: 0.5893
Batch 110, Loss: 0.5263
Batch 120, Loss: 0.5529
Batch 130, Loss: 0.5843
Batch 140, Loss: 0.5546
Batch 150, Loss: 0.5599
Batch 160, Loss: 0.5315
Batch 170, Loss: 0.5416
Batch 180, Loss: 0.5704
Batch 190, Loss: 0.5165
Batch 200, Loss: 0.5744
Batch 210, Loss: 0.5167
Batch 220, Loss: 0.5599
Batch 230, Loss: 0.5489
Batch 240, Loss: 0.5460
Batch 250, Loss: 0.5536
Batch 260, Loss: 0.5306
Batch 270, Loss: 0.5485
Batch 280, Loss: 0.5393
Batch 290, Loss: 0.5693
Batch 300, Loss: 0.5407
Batch 310, Loss: 0.5997
Batch 320, Loss: 0.5378
Batch 330, Loss: 0.5704
Batch 340, Loss: 0.5269
Batch 350, Loss: 0.5208
Batch 360, Loss: 0.5354
Batch 370, Loss: 0.5140
Batch 380, Loss: 0.5281
Batch 390, Loss: 0.5383
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.536902904510498 seconds
Epoch 51 accuracy: 83.67%
Batch 10, Loss: 0.5596
Batch 20, Loss: 0.6054
Batch 30, Loss: 0.5481
Batch 40, Loss: 0.5523
Batch 50, Loss: 0.5162
Batch 60, Loss: 0.5279
Batch 70, Loss: 0.5449
Batch 80, Loss: 0.5109
Batch 90, Loss: 0.5475
Batch 100, Loss: 0.5171
Batch 110, Loss: 0.5063
Batch 120, Loss: 0.4784
Batch 130, Loss: 0.5569
Batch 140, Loss: 0.5004
Batch 150, Loss: 0.5559
Batch 160, Loss: 0.5043
Batch 170, Loss: 0.5338
Batch 180, Loss: 0.5231
Batch 190, Loss: 0.5607
Batch 200, Loss: 0.5264
Batch 210, Loss: 0.5073
Batch 220, Loss: 0.5277
Batch 230, Loss: 0.5279
Batch 240, Loss: 0.5605
Batch 250, Loss: 0.5425
Batch 260, Loss: 0.5380
Batch 270, Loss: 0.5431
Batch 280, Loss: 0.5574
Batch 290, Loss: 0.5201
Batch 300, Loss: 0.5517
Batch 310, Loss: 0.5143
Batch 320, Loss: 0.5721
Batch 330, Loss: 0.5364
Batch 340, Loss: 0.5323
Batch 350, Loss: 0.5370
Batch 360, Loss: 0.5271
Batch 370, Loss: 0.5440
Batch 380, Loss: 0.5507
Batch 390, Loss: 0.5323
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.57935619354248 seconds
Epoch 52 accuracy: 82.55%
Batch 10, Loss: 0.5402
Batch 20, Loss: 0.4949
Batch 30, Loss: 0.5485
Batch 40, Loss: 0.5370
Batch 50, Loss: 0.5753
Batch 60, Loss: 0.5347
Batch 70, Loss: 0.5125
Batch 80, Loss: 0.4961
Batch 90, Loss: 0.5507
Batch 100, Loss: 0.4760
Batch 110, Loss: 0.5412
Batch 120, Loss: 0.5030
Batch 130, Loss: 0.5073
Batch 140, Loss: 0.5493
Batch 150, Loss: 0.5559
Batch 160, Loss: 0.5497
Batch 170, Loss: 0.5726
Batch 180, Loss: 0.5193
Batch 190, Loss: 0.5371
Batch 200, Loss: 0.5294
Batch 210, Loss: 0.5322
Batch 220, Loss: 0.5456
Batch 230, Loss: 0.5907
Batch 240, Loss: 0.5510
Batch 250, Loss: 0.5686
Batch 260, Loss: 0.5229
Batch 270, Loss: 0.5422
Batch 280, Loss: 0.5420
Batch 290, Loss: 0.5684
Batch 300, Loss: 0.5434
Batch 310, Loss: 0.5222
Batch 320, Loss: 0.5223
Batch 330, Loss: 0.5038
Batch 340, Loss: 0.5241
Batch 350, Loss: 0.5099
Batch 360, Loss: 0.5206
Batch 370, Loss: 0.5254
Batch 380, Loss: 0.5582
Batch 390, Loss: 0.5246
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.282591581344604 seconds
Epoch 53 accuracy: 84.04%
Batch 10, Loss: 0.5229
Batch 20, Loss: 0.5452
Batch 30, Loss: 0.5300
Batch 40, Loss: 0.4712
Batch 50, Loss: 0.5360
Batch 60, Loss: 0.5159
Batch 70, Loss: 0.4825
Batch 80, Loss: 0.5425
Batch 90, Loss: 0.5229
Batch 100, Loss: 0.5455
Batch 110, Loss: 0.5391
Batch 120, Loss: 0.5413
Batch 130, Loss: 0.5054
Batch 140, Loss: 0.4941
Batch 150, Loss: 0.4961
Batch 160, Loss: 0.5423
Batch 170, Loss: 0.5378
Batch 180, Loss: 0.5576
Batch 190, Loss: 0.5739
Batch 200, Loss: 0.5010
Batch 210, Loss: 0.5561
Batch 220, Loss: 0.5039
Batch 230, Loss: 0.5315
Batch 240, Loss: 0.5346
Batch 250, Loss: 0.4900
Batch 260, Loss: 0.5387
Batch 270, Loss: 0.5051
Batch 280, Loss: 0.5540
Batch 290, Loss: 0.5308
Batch 300, Loss: 0.5352
Batch 310, Loss: 0.5384
Batch 320, Loss: 0.5329
Batch 330, Loss: 0.5741
Batch 340, Loss: 0.5366
Batch 350, Loss: 0.5251
Batch 360, Loss: 0.5391
Batch 370, Loss: 0.5507
Batch 380, Loss: 0.5345
Batch 390, Loss: 0.5166
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.574018001556396 seconds
Epoch 54 accuracy: 82.78%
Batch 10, Loss: 0.5091
Batch 20, Loss: 0.5171
Batch 30, Loss: 0.5265
Batch 40, Loss: 0.5069
Batch 50, Loss: 0.5424
Batch 60, Loss: 0.5337
Batch 70, Loss: 0.5352
Batch 80, Loss: 0.5578
Batch 90, Loss: 0.5081
Batch 100, Loss: 0.5100
Batch 110, Loss: 0.5025
Batch 120, Loss: 0.5310
Batch 130, Loss: 0.5511
Batch 140, Loss: 0.5383
Batch 150, Loss: 0.5393
Batch 160, Loss: 0.4934
Batch 170, Loss: 0.5229
Batch 180, Loss: 0.5606
Batch 190, Loss: 0.5219
Batch 200, Loss: 0.5307
Batch 210, Loss: 0.5331
Batch 220, Loss: 0.5276
Batch 230, Loss: 0.5440
Batch 240, Loss: 0.5654
Batch 250, Loss: 0.5309
Batch 260, Loss: 0.5189
Batch 270, Loss: 0.5628
Batch 280, Loss: 0.5172
Batch 290, Loss: 0.5262
Batch 300, Loss: 0.5529
Batch 310, Loss: 0.5349
Batch 320, Loss: 0.5018
Batch 330, Loss: 0.5244
Batch 340, Loss: 0.5660
Batch 350, Loss: 0.5319
Batch 360, Loss: 0.5161
Batch 370, Loss: 0.5024
Batch 380, Loss: 0.5577
Batch 390, Loss: 0.5223
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.631898880004883 seconds
Epoch 55 accuracy: 81.76%
Batch 10, Loss: 0.5174
Batch 20, Loss: 0.5351
Batch 30, Loss: 0.5381
Batch 40, Loss: 0.4987
Batch 50, Loss: 0.5211
Batch 60, Loss: 0.5317
Batch 70, Loss: 0.5112
Batch 80, Loss: 0.5174
Batch 90, Loss: 0.5240
Batch 100, Loss: 0.5354
Batch 110, Loss: 0.5327
Batch 120, Loss: 0.5165
Batch 130, Loss: 0.5269
Batch 140, Loss: 0.5248
Batch 150, Loss: 0.5494
Batch 160, Loss: 0.5300
Batch 170, Loss: 0.5276
Batch 180, Loss: 0.5029
Batch 190, Loss: 0.5589
Batch 200, Loss: 0.5336
Batch 210, Loss: 0.5462
Batch 220, Loss: 0.5362
Batch 230, Loss: 0.5334
Batch 240, Loss: 0.5127
Batch 250, Loss: 0.5228
Batch 260, Loss: 0.5423
Batch 270, Loss: 0.5266
Batch 280, Loss: 0.5561
Batch 290, Loss: 0.5087
Batch 300, Loss: 0.5410
Batch 310, Loss: 0.5316
Batch 320, Loss: 0.5105
Batch 330, Loss: 0.5309
Batch 340, Loss: 0.5338
Batch 350, Loss: 0.5242
Batch 360, Loss: 0.5071
Batch 370, Loss: 0.4914
Batch 380, Loss: 0.4938
Batch 390, Loss: 0.5689
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.71796441078186 seconds
Epoch 56 accuracy: 80.35%
Batch 10, Loss: 0.5236
Batch 20, Loss: 0.5494
Batch 30, Loss: 0.5295
Batch 40, Loss: 0.5528
Batch 50, Loss: 0.5219
Batch 60, Loss: 0.5104
Batch 70, Loss: 0.5475
Batch 80, Loss: 0.5212
Batch 90, Loss: 0.5226
Batch 100, Loss: 0.5043
Batch 110, Loss: 0.5281
Batch 120, Loss: 0.5097
Batch 130, Loss: 0.5335
Batch 140, Loss: 0.4737
Batch 150, Loss: 0.5507
Batch 160, Loss: 0.5413
Batch 170, Loss: 0.5363
Batch 180, Loss: 0.5406
Batch 190, Loss: 0.5406
Batch 200, Loss: 0.5466
Batch 210, Loss: 0.5525
Batch 220, Loss: 0.4958
Batch 230, Loss: 0.5205
Batch 240, Loss: 0.5241
Batch 250, Loss: 0.5460
Batch 260, Loss: 0.5029
Batch 270, Loss: 0.5333
Batch 280, Loss: 0.4962
Batch 290, Loss: 0.5349
Batch 300, Loss: 0.4990
Batch 310, Loss: 0.5352
Batch 320, Loss: 0.5640
Batch 330, Loss: 0.5361
Batch 340, Loss: 0.5603
Batch 350, Loss: 0.5069
Batch 360, Loss: 0.5878
Batch 370, Loss: 0.5205
Batch 380, Loss: 0.5449
Batch 390, Loss: 0.4980
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.53767204284668 seconds
Epoch 57 accuracy: 83.29%
Batch 10, Loss: 0.5304
Batch 20, Loss: 0.5358
Batch 30, Loss: 0.5361
Batch 40, Loss: 0.5082
Batch 50, Loss: 0.5018
Batch 60, Loss: 0.5125
Batch 70, Loss: 0.4860
Batch 80, Loss: 0.5346
Batch 90, Loss: 0.5537
Batch 100, Loss: 0.5044
Batch 110, Loss: 0.4930
Batch 120, Loss: 0.5382
Batch 130, Loss: 0.5318
Batch 140, Loss: 0.5576
Batch 150, Loss: 0.4780
Batch 160, Loss: 0.5383
Batch 170, Loss: 0.5013
Batch 180, Loss: 0.5045
Batch 190, Loss: 0.5323
Batch 200, Loss: 0.5522
Batch 210, Loss: 0.5238
Batch 220, Loss: 0.5399
Batch 230, Loss: 0.5737
Batch 240, Loss: 0.5658
Batch 250, Loss: 0.5049
Batch 260, Loss: 0.5124
Batch 270, Loss: 0.5099
Batch 280, Loss: 0.4880
Batch 290, Loss: 0.5115
Batch 300, Loss: 0.5391
Batch 310, Loss: 0.5355
Batch 320, Loss: 0.5364
Batch 330, Loss: 0.5291
Batch 340, Loss: 0.5120
Batch 350, Loss: 0.5183
Batch 360, Loss: 0.5331
Batch 370, Loss: 0.5075
Batch 380, Loss: 0.5149
Batch 390, Loss: 0.5501
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.590535402297974 seconds
Epoch 58 accuracy: 82.71%
Batch 10, Loss: 0.4950
Batch 20, Loss: 0.5224
Batch 30, Loss: 0.5466
Batch 40, Loss: 0.4920
Batch 50, Loss: 0.5487
Batch 60, Loss: 0.5410
Batch 70, Loss: 0.5019
Batch 80, Loss: 0.5020
Batch 90, Loss: 0.5173
Batch 100, Loss: 0.5572
Batch 110, Loss: 0.5248
Batch 120, Loss: 0.5502
Batch 130, Loss: 0.5190
Batch 140, Loss: 0.5325
Batch 150, Loss: 0.5512
Batch 160, Loss: 0.5222
Batch 170, Loss: 0.5154
Batch 180, Loss: 0.5154
Batch 190, Loss: 0.5080
Batch 200, Loss: 0.5100
Batch 210, Loss: 0.4902
Batch 220, Loss: 0.5163
Batch 230, Loss: 0.5034
Batch 240, Loss: 0.5695
Batch 250, Loss: 0.5116
Batch 260, Loss: 0.5212
Batch 270, Loss: 0.5374
Batch 280, Loss: 0.4911
Batch 290, Loss: 0.5182
Batch 300, Loss: 0.5434
Batch 310, Loss: 0.5349
Batch 320, Loss: 0.4986
Batch 330, Loss: 0.5340
Batch 340, Loss: 0.4915
Batch 350, Loss: 0.5318
Batch 360, Loss: 0.5573
Batch 370, Loss: 0.5194
Batch 380, Loss: 0.5660
Batch 390, Loss: 0.5376
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.53042769432068 seconds
Epoch 59 accuracy: 82.85%
Batch 10, Loss: 0.5334
Batch 20, Loss: 0.5017
Batch 30, Loss: 0.5071
Batch 40, Loss: 0.5395
Batch 50, Loss: 0.4976
Batch 60, Loss: 0.5365
Batch 70, Loss: 0.4699
Batch 80, Loss: 0.5240
Batch 90, Loss: 0.5291
Batch 100, Loss: 0.5136
Batch 110, Loss: 0.4967
Batch 120, Loss: 0.5182
Batch 130, Loss: 0.4846
Batch 140, Loss: 0.5406
Batch 150, Loss: 0.5318
Batch 160, Loss: 0.5158
Batch 170, Loss: 0.5047
Batch 180, Loss: 0.5624
Batch 190, Loss: 0.4907
Batch 200, Loss: 0.5288
Batch 210, Loss: 0.5612
Batch 220, Loss: 0.5270
Batch 230, Loss: 0.4967
Batch 240, Loss: 0.5520
Batch 250, Loss: 0.5243
Batch 260, Loss: 0.5166
Batch 270, Loss: 0.5757
Batch 280, Loss: 0.5545
Batch 290, Loss: 0.4887
Batch 300, Loss: 0.4391
Batch 310, Loss: 0.5287
Batch 320, Loss: 0.5405
Batch 330, Loss: 0.5163
Batch 340, Loss: 0.4849
Batch 350, Loss: 0.5143
Batch 360, Loss: 0.5455
Batch 370, Loss: 0.5256
Batch 380, Loss: 0.4927
Batch 390, Loss: 0.5503
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.65843176841736 seconds
Epoch 60 accuracy: 85.38%
Batch 10, Loss: 0.5110
Batch 20, Loss: 0.5086
Batch 30, Loss: 0.5433
Batch 40, Loss: 0.5272
Batch 50, Loss: 0.5499
Batch 60, Loss: 0.4888
Batch 70, Loss: 0.4931
Batch 80, Loss: 0.5185
Batch 90, Loss: 0.4902
Batch 100, Loss: 0.5081
Batch 110, Loss: 0.5209
Batch 120, Loss: 0.5513
Batch 130, Loss: 0.5207
Batch 140, Loss: 0.5544
Batch 150, Loss: 0.5473
Batch 160, Loss: 0.4725
Batch 170, Loss: 0.5024
Batch 180, Loss: 0.5081
Batch 190, Loss: 0.5074
Batch 200, Loss: 0.5205
Batch 210, Loss: 0.5252
Batch 220, Loss: 0.5302
Batch 230, Loss: 0.5136
Batch 240, Loss: 0.5284
Batch 250, Loss: 0.5100
Batch 260, Loss: 0.5057
Batch 270, Loss: 0.5103
Batch 280, Loss: 0.5115
Batch 290, Loss: 0.5011
Batch 300, Loss: 0.5458
Batch 310, Loss: 0.5205
Batch 320, Loss: 0.5283
Batch 330, Loss: 0.5740
Batch 340, Loss: 0.4997
Batch 350, Loss: 0.5390
Batch 360, Loss: 0.5165
Batch 370, Loss: 0.4959
Batch 380, Loss: 0.5655
Batch 390, Loss: 0.5008
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.5291166305542 seconds
Epoch 61 accuracy: 85.95%
Batch 10, Loss: 0.5268
Batch 20, Loss: 0.5256
Batch 30, Loss: 0.5119
Batch 40, Loss: 0.5196
Batch 50, Loss: 0.5146
Batch 60, Loss: 0.4687
Batch 70, Loss: 0.5234
Batch 80, Loss: 0.5140
Batch 90, Loss: 0.4984
Batch 100, Loss: 0.5230
Batch 110, Loss: 0.5758
Batch 120, Loss: 0.4979
Batch 130, Loss: 0.4980
Batch 140, Loss: 0.5174
Batch 150, Loss: 0.5085
Batch 160, Loss: 0.5099
Batch 170, Loss: 0.5741
Batch 180, Loss: 0.5267
Batch 190, Loss: 0.5114
Batch 200, Loss: 0.5289
Batch 210, Loss: 0.5377
Batch 220, Loss: 0.5514
Batch 230, Loss: 0.5250
Batch 240, Loss: 0.4854
Batch 250, Loss: 0.5127
Batch 260, Loss: 0.4897
Batch 270, Loss: 0.5216
Batch 280, Loss: 0.5221
Batch 290, Loss: 0.4950
Batch 300, Loss: 0.4983
Batch 310, Loss: 0.5589
Batch 320, Loss: 0.4995
Batch 330, Loss: 0.5065
Batch 340, Loss: 0.5269
Batch 350, Loss: 0.5770
Batch 360, Loss: 0.5167
Batch 370, Loss: 0.5327
Batch 380, Loss: 0.5285
Batch 390, Loss: 0.5088
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.686723947525024 seconds
Epoch 62 accuracy: 85.65%
Batch 10, Loss: 0.4654
Batch 20, Loss: 0.4904
Batch 30, Loss: 0.5005
Batch 40, Loss: 0.4851
Batch 50, Loss: 0.4916
Batch 60, Loss: 0.5157
Batch 70, Loss: 0.4642
Batch 80, Loss: 0.4899
Batch 90, Loss: 0.5163
Batch 100, Loss: 0.5362
Batch 110, Loss: 0.5470
Batch 120, Loss: 0.5104
Batch 130, Loss: 0.5183
Batch 140, Loss: 0.4729
Batch 150, Loss: 0.5563
Batch 160, Loss: 0.5415
Batch 170, Loss: 0.5053
Batch 180, Loss: 0.5130
Batch 190, Loss: 0.5127
Batch 200, Loss: 0.5248
Batch 210, Loss: 0.5054
Batch 220, Loss: 0.5158
Batch 230, Loss: 0.5237
Batch 240, Loss: 0.4912
Batch 250, Loss: 0.4914
Batch 260, Loss: 0.5115
Batch 270, Loss: 0.4967
Batch 280, Loss: 0.5073
Batch 290, Loss: 0.5206
Batch 300, Loss: 0.5703
Batch 310, Loss: 0.5385
Batch 320, Loss: 0.5222
Batch 330, Loss: 0.4806
Batch 340, Loss: 0.5028
Batch 350, Loss: 0.5132
Batch 360, Loss: 0.4935
Batch 370, Loss: 0.5437
Batch 380, Loss: 0.5132
Batch 390, Loss: 0.5031
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.44794225692749 seconds
Epoch 63 accuracy: 83.48%
Batch 10, Loss: 0.5151
Batch 20, Loss: 0.5172
Batch 30, Loss: 0.5158
Batch 40, Loss: 0.5008
Batch 50, Loss: 0.5448
Batch 60, Loss: 0.5170
Batch 70, Loss: 0.5130
Batch 80, Loss: 0.4944
Batch 90, Loss: 0.4778
Batch 100, Loss: 0.4662
Batch 110, Loss: 0.5029
Batch 120, Loss: 0.5260
Batch 130, Loss: 0.4789
Batch 140, Loss: 0.5179
Batch 150, Loss: 0.5454
Batch 160, Loss: 0.4756
Batch 170, Loss: 0.5218
Batch 180, Loss: 0.5001
Batch 190, Loss: 0.4840
Batch 200, Loss: 0.5145
Batch 210, Loss: 0.5100
Batch 220, Loss: 0.4954
Batch 230, Loss: 0.5219
Batch 240, Loss: 0.5456
Batch 250, Loss: 0.5409
Batch 260, Loss: 0.5041
Batch 270, Loss: 0.4900
Batch 280, Loss: 0.4913
Batch 290, Loss: 0.5168
Batch 300, Loss: 0.5292
Batch 310, Loss: 0.5084
Batch 320, Loss: 0.5216
Batch 330, Loss: 0.5169
Batch 340, Loss: 0.5632
Batch 350, Loss: 0.5209
Batch 360, Loss: 0.4782
Batch 370, Loss: 0.4999
Batch 380, Loss: 0.5241
Batch 390, Loss: 0.4854
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.613784074783325 seconds
Epoch 64 accuracy: 88.18%
Batch 10, Loss: 0.4774
Batch 20, Loss: 0.4529
Batch 30, Loss: 0.4888
Batch 40, Loss: 0.5104
Batch 50, Loss: 0.5342
Batch 60, Loss: 0.5389
Batch 70, Loss: 0.5332
Batch 80, Loss: 0.5283
Batch 90, Loss: 0.4952
Batch 100, Loss: 0.4683
Batch 110, Loss: 0.4965
Batch 120, Loss: 0.5075
Batch 130, Loss: 0.5341
Batch 140, Loss: 0.5220
Batch 150, Loss: 0.5177
Batch 160, Loss: 0.5037
Batch 170, Loss: 0.5351
Batch 180, Loss: 0.4882
Batch 190, Loss: 0.5538
Batch 200, Loss: 0.5219
Batch 210, Loss: 0.4845
Batch 220, Loss: 0.4724
Batch 230, Loss: 0.5121
Batch 240, Loss: 0.4765
Batch 250, Loss: 0.5521
Batch 260, Loss: 0.5166
Batch 270, Loss: 0.5148
Batch 280, Loss: 0.5028
Batch 290, Loss: 0.5189
Batch 300, Loss: 0.4788
Batch 310, Loss: 0.5168
Batch 320, Loss: 0.5009
Batch 330, Loss: 0.5373
Batch 340, Loss: 0.4847
Batch 350, Loss: 0.5236
Batch 360, Loss: 0.5567
Batch 370, Loss: 0.5127
Batch 380, Loss: 0.4908
Batch 390, Loss: 0.4988
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.579351663589478 seconds
Epoch 65 accuracy: 86.6%
Batch 10, Loss: 0.5263
Batch 20, Loss: 0.5135
Batch 30, Loss: 0.4924
Batch 40, Loss: 0.5222
Batch 50, Loss: 0.4873
Batch 60, Loss: 0.5321
Batch 70, Loss: 0.4888
Batch 80, Loss: 0.5227
Batch 90, Loss: 0.4892
Batch 100, Loss: 0.5197
Batch 110, Loss: 0.5220
Batch 120, Loss: 0.5476
Batch 130, Loss: 0.4868
Batch 140, Loss: 0.4704
Batch 150, Loss: 0.5380
Batch 160, Loss: 0.4905
Batch 170, Loss: 0.4996
Batch 180, Loss: 0.5049
Batch 190, Loss: 0.5411
Batch 200, Loss: 0.4922
Batch 210, Loss: 0.5186
Batch 220, Loss: 0.5166
Batch 230, Loss: 0.5452
Batch 240, Loss: 0.5268
Batch 250, Loss: 0.5111
Batch 260, Loss: 0.5274
Batch 270, Loss: 0.5601
Batch 280, Loss: 0.5361
Batch 290, Loss: 0.5606
Batch 300, Loss: 0.5186
Batch 310, Loss: 0.4889
Batch 320, Loss: 0.4774
Batch 330, Loss: 0.4795
Batch 340, Loss: 0.5343
Batch 350, Loss: 0.5007
Batch 360, Loss: 0.4873
Batch 370, Loss: 0.5155
Batch 380, Loss: 0.4930
Batch 390, Loss: 0.5474
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.502516269683838 seconds
Epoch 66 accuracy: 84.48%
Batch 10, Loss: 0.4846
Batch 20, Loss: 0.5171
Batch 30, Loss: 0.5328
Batch 40, Loss: 0.5213
Batch 50, Loss: 0.5315
Batch 60, Loss: 0.5178
Batch 70, Loss: 0.4992
Batch 80, Loss: 0.5457
Batch 90, Loss: 0.5219
Batch 100, Loss: 0.4519
Batch 110, Loss: 0.4604
Batch 120, Loss: 0.4711
Batch 130, Loss: 0.4757
Batch 140, Loss: 0.4975
Batch 150, Loss: 0.4906
Batch 160, Loss: 0.5378
Batch 170, Loss: 0.5171
Batch 180, Loss: 0.5173
Batch 190, Loss: 0.5007
Batch 200, Loss: 0.4934
Batch 210, Loss: 0.4874
Batch 220, Loss: 0.4964
Batch 230, Loss: 0.5104
Batch 240, Loss: 0.4993
Batch 250, Loss: 0.4860
Batch 260, Loss: 0.5122
Batch 270, Loss: 0.5165
Batch 280, Loss: 0.4538
Batch 290, Loss: 0.5340
Batch 300, Loss: 0.5031
Batch 310, Loss: 0.4792
Batch 320, Loss: 0.5464
Batch 330, Loss: 0.4886
Batch 340, Loss: 0.5246
Batch 350, Loss: 0.5226
Batch 360, Loss: 0.5146
Batch 370, Loss: 0.5069
Batch 380, Loss: 0.5013
Batch 390, Loss: 0.4828
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.509397506713867 seconds
Epoch 67 accuracy: 82.92%
Batch 10, Loss: 0.4991
Batch 20, Loss: 0.4933
Batch 30, Loss: 0.5461
Batch 40, Loss: 0.5191
Batch 50, Loss: 0.4948
Batch 60, Loss: 0.4785
Batch 70, Loss: 0.5406
Batch 80, Loss: 0.4873
Batch 90, Loss: 0.5211
Batch 100, Loss: 0.4797
Batch 110, Loss: 0.4997
Batch 120, Loss: 0.5253
Batch 130, Loss: 0.5200
Batch 140, Loss: 0.4683
Batch 150, Loss: 0.5082
Batch 160, Loss: 0.4932
Batch 170, Loss: 0.5134
Batch 180, Loss: 0.5181
Batch 190, Loss: 0.5135
Batch 200, Loss: 0.4923
Batch 210, Loss: 0.5159
Batch 220, Loss: 0.5139
Batch 230, Loss: 0.4838
Batch 240, Loss: 0.5164
Batch 250, Loss: 0.4974
Batch 260, Loss: 0.4709
Batch 270, Loss: 0.5125
Batch 280, Loss: 0.5259
Batch 290, Loss: 0.5075
Batch 300, Loss: 0.5074
Batch 310, Loss: 0.5004
Batch 320, Loss: 0.4842
Batch 330, Loss: 0.5206
Batch 340, Loss: 0.5053
Batch 350, Loss: 0.5320
Batch 360, Loss: 0.5479
Batch 370, Loss: 0.5335
Batch 380, Loss: 0.4992
Batch 390, Loss: 0.5109
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.74297332763672 seconds
Epoch 68 accuracy: 85.75%
Batch 10, Loss: 0.5317
Batch 20, Loss: 0.5020
Batch 30, Loss: 0.4552
Batch 40, Loss: 0.5191
Batch 50, Loss: 0.4868
Batch 60, Loss: 0.4996
Batch 70, Loss: 0.5045
Batch 80, Loss: 0.4904
Batch 90, Loss: 0.4914
Batch 100, Loss: 0.4680
Batch 110, Loss: 0.5382
Batch 120, Loss: 0.5468
Batch 130, Loss: 0.5381
Batch 140, Loss: 0.5080
Batch 150, Loss: 0.4976
Batch 160, Loss: 0.4963
Batch 170, Loss: 0.5094
Batch 180, Loss: 0.5155
Batch 190, Loss: 0.5487
Batch 200, Loss: 0.5041
Batch 210, Loss: 0.5195
Batch 220, Loss: 0.4957
Batch 230, Loss: 0.5780
Batch 240, Loss: 0.5044
Batch 250, Loss: 0.5027
Batch 260, Loss: 0.5033
Batch 270, Loss: 0.5602
Batch 280, Loss: 0.4912
Batch 290, Loss: 0.5239
Batch 300, Loss: 0.5019
Batch 310, Loss: 0.4710
Batch 320, Loss: 0.5217
Batch 330, Loss: 0.5538
Batch 340, Loss: 0.5322
Batch 350, Loss: 0.4931
Batch 360, Loss: 0.5252
Batch 370, Loss: 0.5112
Batch 380, Loss: 0.5228
Batch 390, Loss: 0.5346
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.649136304855347 seconds
Epoch 69 accuracy: 81.53%
Batch 10, Loss: 0.5332
Batch 20, Loss: 0.5231
Batch 30, Loss: 0.5164
Batch 40, Loss: 0.4779
Batch 50, Loss: 0.4849
Batch 60, Loss: 0.4629
Batch 70, Loss: 0.4926
Batch 80, Loss: 0.5355
Batch 90, Loss: 0.5077
Batch 100, Loss: 0.4816
Batch 110, Loss: 0.5014
Batch 120, Loss: 0.5115
Batch 130, Loss: 0.5228
Batch 140, Loss: 0.5242
Batch 150, Loss: 0.5334
Batch 160, Loss: 0.5283
Batch 170, Loss: 0.5379
Batch 180, Loss: 0.5514
Batch 190, Loss: 0.5251
Batch 200, Loss: 0.4864
Batch 210, Loss: 0.4920
Batch 220, Loss: 0.5284
Batch 230, Loss: 0.5015
Batch 240, Loss: 0.5003
Batch 250, Loss: 0.5236
Batch 260, Loss: 0.4922
Batch 270, Loss: 0.4679
Batch 280, Loss: 0.5165
Batch 290, Loss: 0.4914
Batch 300, Loss: 0.5058
Batch 310, Loss: 0.4785
Batch 320, Loss: 0.5014
Batch 330, Loss: 0.5007
Batch 340, Loss: 0.5504
Batch 350, Loss: 0.5022
Batch 360, Loss: 0.5386
Batch 370, Loss: 0.5237
Batch 380, Loss: 0.4862
Batch 390, Loss: 0.4866
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.654781341552734 seconds
Epoch 70 accuracy: 83.98%
Batch 10, Loss: 0.4952
Batch 20, Loss: 0.5237
Batch 30, Loss: 0.5139
Batch 40, Loss: 0.4840
Batch 50, Loss: 0.4998
Batch 60, Loss: 0.4856
Batch 70, Loss: 0.4823
Batch 80, Loss: 0.4800
Batch 90, Loss: 0.4533
Batch 100, Loss: 0.5091
Batch 110, Loss: 0.4820
Batch 120, Loss: 0.4994
Batch 130, Loss: 0.5181
Batch 140, Loss: 0.4815
Batch 150, Loss: 0.5381
Batch 160, Loss: 0.4967
Batch 170, Loss: 0.5110
Batch 180, Loss: 0.5278
Batch 190, Loss: 0.5066
Batch 200, Loss: 0.5290
Batch 210, Loss: 0.4879
Batch 220, Loss: 0.5053
Batch 230, Loss: 0.4731
Batch 240, Loss: 0.5167
Batch 250, Loss: 0.5335
Batch 260, Loss: 0.4879
Batch 270, Loss: 0.5158
Batch 280, Loss: 0.4964
Batch 290, Loss: 0.4823
Batch 300, Loss: 0.4919
Batch 310, Loss: 0.5095
Batch 320, Loss: 0.5507
Batch 330, Loss: 0.4936
Batch 340, Loss: 0.5040
Batch 350, Loss: 0.4722
Batch 360, Loss: 0.5211
Batch 370, Loss: 0.5074
Batch 380, Loss: 0.4636
Batch 390, Loss: 0.5230
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.642847776412964 seconds
Epoch 71 accuracy: 87.31%
Batch 10, Loss: 0.4924
Batch 20, Loss: 0.4394
Batch 30, Loss: 0.4978
Batch 40, Loss: 0.4647
Batch 50, Loss: 0.4928
Batch 60, Loss: 0.4739
Batch 70, Loss: 0.4756
Batch 80, Loss: 0.5186
Batch 90, Loss: 0.5087
Batch 100, Loss: 0.5010
Batch 110, Loss: 0.5291
Batch 120, Loss: 0.5016
Batch 130, Loss: 0.5035
Batch 140, Loss: 0.4834
Batch 150, Loss: 0.5241
Batch 160, Loss: 0.4804
Batch 170, Loss: 0.5145
Batch 180, Loss: 0.4648
Batch 190, Loss: 0.5009
Batch 200, Loss: 0.4777
Batch 210, Loss: 0.4976
Batch 220, Loss: 0.5079
Batch 230, Loss: 0.4727
Batch 240, Loss: 0.5032
Batch 250, Loss: 0.4920
Batch 260, Loss: 0.4938
Batch 270, Loss: 0.4865
Batch 280, Loss: 0.4926
Batch 290, Loss: 0.5302
Batch 300, Loss: 0.4826
Batch 310, Loss: 0.5628
Batch 320, Loss: 0.5411
Batch 330, Loss: 0.5226
Batch 340, Loss: 0.4713
Batch 350, Loss: 0.5118
Batch 360, Loss: 0.4753
Batch 370, Loss: 0.5168
Batch 380, Loss: 0.4772
Batch 390, Loss: 0.5295
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.62198567390442 seconds
Epoch 72 accuracy: 85.71%
Batch 10, Loss: 0.5015
Batch 20, Loss: 0.4926
Batch 30, Loss: 0.5053
Batch 40, Loss: 0.4880
Batch 50, Loss: 0.5023
Batch 60, Loss: 0.4974
Batch 70, Loss: 0.5395
Batch 80, Loss: 0.5447
Batch 90, Loss: 0.5248
Batch 100, Loss: 0.5005
Batch 110, Loss: 0.4835
Batch 120, Loss: 0.5174
Batch 130, Loss: 0.5216
Batch 140, Loss: 0.4669
Batch 150, Loss: 0.5105
Batch 160, Loss: 0.5080
Batch 170, Loss: 0.4718
Batch 180, Loss: 0.4702
Batch 190, Loss: 0.5316
Batch 200, Loss: 0.4884
Batch 210, Loss: 0.4650
Batch 220, Loss: 0.5089
Batch 230, Loss: 0.4721
Batch 240, Loss: 0.4917
Batch 250, Loss: 0.5257
Batch 260, Loss: 0.4831
Batch 270, Loss: 0.4531
Batch 280, Loss: 0.5043
Batch 290, Loss: 0.4995
Batch 300, Loss: 0.5077
Batch 310, Loss: 0.4902
Batch 320, Loss: 0.5423
Batch 330, Loss: 0.5072
Batch 340, Loss: 0.4753
Batch 350, Loss: 0.4808
Batch 360, Loss: 0.4946
Batch 370, Loss: 0.4650
Batch 380, Loss: 0.4653
Batch 390, Loss: 0.4842
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.657762050628662 seconds
Epoch 73 accuracy: 86.45%
Batch 10, Loss: 0.5123
Batch 20, Loss: 0.4952
Batch 30, Loss: 0.4913
Batch 40, Loss: 0.4799
Batch 50, Loss: 0.4993
Batch 60, Loss: 0.4849
Batch 70, Loss: 0.4287
Batch 80, Loss: 0.5215
Batch 90, Loss: 0.5023
Batch 100, Loss: 0.5525
Batch 110, Loss: 0.4776
Batch 120, Loss: 0.5071
Batch 130, Loss: 0.4909
Batch 140, Loss: 0.4555
Batch 150, Loss: 0.4433
Batch 160, Loss: 0.5037
Batch 170, Loss: 0.4839
Batch 180, Loss: 0.4783
Batch 190, Loss: 0.4932
Batch 200, Loss: 0.4914
Batch 210, Loss: 0.4957
Batch 220, Loss: 0.5111
Batch 230, Loss: 0.5011
Batch 240, Loss: 0.4860
Batch 250, Loss: 0.5280
Batch 260, Loss: 0.5018
Batch 270, Loss: 0.4790
Batch 280, Loss: 0.4885
Batch 290, Loss: 0.4991
Batch 300, Loss: 0.4693
Batch 310, Loss: 0.5129
Batch 320, Loss: 0.5017
Batch 330, Loss: 0.4443
Batch 340, Loss: 0.4601
Batch 350, Loss: 0.4766
Batch 360, Loss: 0.5015
Batch 370, Loss: 0.4701
Batch 380, Loss: 0.4629
Batch 390, Loss: 0.4830
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.734970569610596 seconds
Epoch 74 accuracy: 85.84%
Batch 10, Loss: 0.5388
Batch 20, Loss: 0.5118
Batch 30, Loss: 0.4951
Batch 40, Loss: 0.4713
Batch 50, Loss: 0.4999
Batch 60, Loss: 0.4744
Batch 70, Loss: 0.5095
Batch 80, Loss: 0.5060
Batch 90, Loss: 0.5195
Batch 100, Loss: 0.5064
Batch 110, Loss: 0.4856
Batch 120, Loss: 0.4692
Batch 130, Loss: 0.4867
Batch 140, Loss: 0.4844
Batch 150, Loss: 0.5087
Batch 160, Loss: 0.4876
Batch 170, Loss: 0.4930
Batch 180, Loss: 0.4959
Batch 190, Loss: 0.4868
Batch 200, Loss: 0.4455
Batch 210, Loss: 0.5142
Batch 220, Loss: 0.4919
Batch 230, Loss: 0.4846
Batch 240, Loss: 0.5002
Batch 250, Loss: 0.4929
Batch 260, Loss: 0.4888
Batch 270, Loss: 0.5119
Batch 280, Loss: 0.5009
Batch 290, Loss: 0.4412
Batch 300, Loss: 0.4540
Batch 310, Loss: 0.4700
Batch 320, Loss: 0.4878
Batch 330, Loss: 0.5020
Batch 340, Loss: 0.5225
Batch 350, Loss: 0.4904
Batch 360, Loss: 0.5033
Batch 370, Loss: 0.4909
Batch 380, Loss: 0.5025
Batch 390, Loss: 0.4929
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 26.07461428642273 seconds
Epoch 75 accuracy: 83.31%
Batch 10, Loss: 0.4865
Batch 20, Loss: 0.4821
Batch 30, Loss: 0.5207
Batch 40, Loss: 0.5089
Batch 50, Loss: 0.5085
Batch 60, Loss: 0.4602
Batch 70, Loss: 0.4671
Batch 80, Loss: 0.5024
Batch 90, Loss: 0.5129
Batch 100, Loss: 0.5009
Batch 110, Loss: 0.4727
Batch 120, Loss: 0.5055
Batch 130, Loss: 0.5236
Batch 140, Loss: 0.4996
Batch 150, Loss: 0.5277
Batch 160, Loss: 0.4701
Batch 170, Loss: 0.4905
Batch 180, Loss: 0.5100
Batch 190, Loss: 0.5024
Batch 200, Loss: 0.4572
Batch 210, Loss: 0.5287
Batch 220, Loss: 0.4954
Batch 230, Loss: 0.5192
Batch 240, Loss: 0.4633
Batch 250, Loss: 0.5103
Batch 260, Loss: 0.5139
Batch 270, Loss: 0.5068
Batch 280, Loss: 0.5020
Batch 290, Loss: 0.4841
Batch 300, Loss: 0.4796
Batch 310, Loss: 0.4962
Batch 320, Loss: 0.4647
Batch 330, Loss: 0.4633
Batch 340, Loss: 0.5189
Batch 350, Loss: 0.4874
Batch 360, Loss: 0.4882
Batch 370, Loss: 0.5199
Batch 380, Loss: 0.5133
Batch 390, Loss: 0.5246
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.492255210876465 seconds
Epoch 76 accuracy: 83.68%
Batch 10, Loss: 0.4818
Batch 20, Loss: 0.4412
Batch 30, Loss: 0.4553
Batch 40, Loss: 0.4757
Batch 50, Loss: 0.4763
Batch 60, Loss: 0.5529
Batch 70, Loss: 0.4790
Batch 80, Loss: 0.4891
Batch 90, Loss: 0.4562
Batch 100, Loss: 0.5167
Batch 110, Loss: 0.4895
Batch 120, Loss: 0.4743
Batch 130, Loss: 0.4969
Batch 140, Loss: 0.5326
Batch 150, Loss: 0.5110
Batch 160, Loss: 0.4956
Batch 170, Loss: 0.4918
Batch 180, Loss: 0.4795
Batch 190, Loss: 0.4632
Batch 200, Loss: 0.4585
Batch 210, Loss: 0.4410
Batch 220, Loss: 0.4833
Batch 230, Loss: 0.5050
Batch 240, Loss: 0.4863
Batch 250, Loss: 0.4922
Batch 260, Loss: 0.4740
Batch 270, Loss: 0.4549
Batch 280, Loss: 0.4822
Batch 290, Loss: 0.4829
Batch 300, Loss: 0.5361
Batch 310, Loss: 0.4982
Batch 320, Loss: 0.4975
Batch 330, Loss: 0.5093
Batch 340, Loss: 0.5488
Batch 350, Loss: 0.4647
Batch 360, Loss: 0.5276
Batch 370, Loss: 0.5041
Batch 380, Loss: 0.4580
Batch 390, Loss: 0.5037
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.571407556533813 seconds
Epoch 77 accuracy: 87.44%
Batch 10, Loss: 0.4835
Batch 20, Loss: 0.4630
Batch 30, Loss: 0.4894
Batch 40, Loss: 0.4684
Batch 50, Loss: 0.4960
Batch 60, Loss: 0.4813
Batch 70, Loss: 0.4628
Batch 80, Loss: 0.4776
Batch 90, Loss: 0.4886
Batch 100, Loss: 0.5090
Batch 110, Loss: 0.4763
Batch 120, Loss: 0.4886
Batch 130, Loss: 0.4833
Batch 140, Loss: 0.5025
Batch 150, Loss: 0.5075
Batch 160, Loss: 0.4474
Batch 170, Loss: 0.4965
Batch 180, Loss: 0.5166
Batch 190, Loss: 0.4538
Batch 200, Loss: 0.4808
Batch 210, Loss: 0.4702
Batch 220, Loss: 0.4955
Batch 230, Loss: 0.4728
Batch 240, Loss: 0.4956
Batch 250, Loss: 0.4919
Batch 260, Loss: 0.4839
Batch 270, Loss: 0.4519
Batch 280, Loss: 0.4875
Batch 290, Loss: 0.4464
Batch 300, Loss: 0.4925
Batch 310, Loss: 0.4729
Batch 320, Loss: 0.4903
Batch 330, Loss: 0.4702
Batch 340, Loss: 0.4773
Batch 350, Loss: 0.5046
Batch 360, Loss: 0.4751
Batch 370, Loss: 0.5014
Batch 380, Loss: 0.4916
Batch 390, Loss: 0.5238
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.676140546798706 seconds
Epoch 78 accuracy: 87.22%
Batch 10, Loss: 0.4611
Batch 20, Loss: 0.4378
Batch 30, Loss: 0.4879
Batch 40, Loss: 0.5024
Batch 50, Loss: 0.4901
Batch 60, Loss: 0.4721
Batch 70, Loss: 0.4721
Batch 80, Loss: 0.4818
Batch 90, Loss: 0.4699
Batch 100, Loss: 0.5206
Batch 110, Loss: 0.4602
Batch 120, Loss: 0.5161
Batch 130, Loss: 0.4713
Batch 140, Loss: 0.5065
Batch 150, Loss: 0.5050
Batch 160, Loss: 0.4705
Batch 170, Loss: 0.4549
Batch 180, Loss: 0.4876
Batch 190, Loss: 0.4622
Batch 200, Loss: 0.4792
Batch 210, Loss: 0.5105
Batch 220, Loss: 0.5119
Batch 230, Loss: 0.4763
Batch 240, Loss: 0.4894
Batch 250, Loss: 0.5195
Batch 260, Loss: 0.4991
Batch 270, Loss: 0.4753
Batch 280, Loss: 0.4564
Batch 290, Loss: 0.4620
Batch 300, Loss: 0.4506
Batch 310, Loss: 0.4814
Batch 320, Loss: 0.4588
Batch 330, Loss: 0.5121
Batch 340, Loss: 0.4900
Batch 350, Loss: 0.4734
Batch 360, Loss: 0.4710
Batch 370, Loss: 0.4982
Batch 380, Loss: 0.4667
Batch 390, Loss: 0.4899
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.62332844734192 seconds
Epoch 79 accuracy: 86.17%
Batch 10, Loss: 0.4806
Batch 20, Loss: 0.4594
Batch 30, Loss: 0.4387
Batch 40, Loss: 0.4774
Batch 50, Loss: 0.4509
Batch 60, Loss: 0.4815
Batch 70, Loss: 0.5081
Batch 80, Loss: 0.5298
Batch 90, Loss: 0.4854
Batch 100, Loss: 0.4581
Batch 110, Loss: 0.4945
Batch 120, Loss: 0.4930
Batch 130, Loss: 0.4525
Batch 140, Loss: 0.5221
Batch 150, Loss: 0.4857
Batch 160, Loss: 0.4750
Batch 170, Loss: 0.4957
Batch 180, Loss: 0.4891
Batch 190, Loss: 0.4965
Batch 200, Loss: 0.5152
Batch 210, Loss: 0.4783
Batch 220, Loss: 0.4676
Batch 230, Loss: 0.4822
Batch 240, Loss: 0.4723
Batch 250, Loss: 0.4905
Batch 260, Loss: 0.4812
Batch 270, Loss: 0.4904
Batch 280, Loss: 0.4890
Batch 290, Loss: 0.4722
Batch 300, Loss: 0.4881
Batch 310, Loss: 0.4608
Batch 320, Loss: 0.4725
Batch 330, Loss: 0.4891
Batch 340, Loss: 0.4765
Batch 350, Loss: 0.5018
Batch 360, Loss: 0.4845
Batch 370, Loss: 0.4800
Batch 380, Loss: 0.4850
Batch 390, Loss: 0.4894
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.652334451675415 seconds
Epoch 80 accuracy: 83.87%
Batch 10, Loss: 0.4974
Batch 20, Loss: 0.4780
Batch 30, Loss: 0.4903
Batch 40, Loss: 0.4810
Batch 50, Loss: 0.4553
Batch 60, Loss: 0.4668
Batch 70, Loss: 0.4461
Batch 80, Loss: 0.4844
Batch 90, Loss: 0.4668
Batch 100, Loss: 0.4730
Batch 110, Loss: 0.4807
Batch 120, Loss: 0.5234
Batch 130, Loss: 0.4712
Batch 140, Loss: 0.4935
Batch 150, Loss: 0.4562
Batch 160, Loss: 0.4696
Batch 170, Loss: 0.4719
Batch 180, Loss: 0.4670
Batch 190, Loss: 0.4670
Batch 200, Loss: 0.4790
Batch 210, Loss: 0.4822
Batch 220, Loss: 0.4617
Batch 230, Loss: 0.4977
Batch 240, Loss: 0.5028
Batch 250, Loss: 0.4816
Batch 260, Loss: 0.4924
Batch 270, Loss: 0.4695
Batch 280, Loss: 0.4891
Batch 290, Loss: 0.4817
Batch 300, Loss: 0.4529
Batch 310, Loss: 0.4671
Batch 320, Loss: 0.4830
Batch 330, Loss: 0.5060
Batch 340, Loss: 0.4590
Batch 350, Loss: 0.4646
Batch 360, Loss: 0.5205
Batch 370, Loss: 0.4827
Batch 380, Loss: 0.4575
Batch 390, Loss: 0.4560
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.46176052093506 seconds
Epoch 81 accuracy: 85.7%
Batch 10, Loss: 0.4774
Batch 20, Loss: 0.5302
Batch 30, Loss: 0.4747
Batch 40, Loss: 0.4751
Batch 50, Loss: 0.4606
Batch 60, Loss: 0.4726
Batch 70, Loss: 0.4447
Batch 80, Loss: 0.5023
Batch 90, Loss: 0.4417
Batch 100, Loss: 0.4729
Batch 110, Loss: 0.4742
Batch 120, Loss: 0.4911
Batch 130, Loss: 0.4330
Batch 140, Loss: 0.4484
Batch 150, Loss: 0.4839
Batch 160, Loss: 0.4622
Batch 170, Loss: 0.4520
Batch 180, Loss: 0.4337
Batch 190, Loss: 0.4882
Batch 200, Loss: 0.4365
Batch 210, Loss: 0.4655
Batch 220, Loss: 0.4800
Batch 230, Loss: 0.5044
Batch 240, Loss: 0.5061
Batch 250, Loss: 0.5189
Batch 260, Loss: 0.4800
Batch 270, Loss: 0.4749
Batch 280, Loss: 0.4373
Batch 290, Loss: 0.4904
Batch 300, Loss: 0.4518
Batch 310, Loss: 0.4757
Batch 320, Loss: 0.4720
Batch 330, Loss: 0.5011
Batch 340, Loss: 0.4835
Batch 350, Loss: 0.4798
Batch 360, Loss: 0.4967
Batch 370, Loss: 0.4590
Batch 380, Loss: 0.4897
Batch 390, Loss: 0.4758
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.67867875099182 seconds
Epoch 82 accuracy: 86.69%
Batch 10, Loss: 0.4497
Batch 20, Loss: 0.4816
Batch 30, Loss: 0.4721
Batch 40, Loss: 0.4497
Batch 50, Loss: 0.4744
Batch 60, Loss: 0.4418
Batch 70, Loss: 0.4310
Batch 80, Loss: 0.4767
Batch 90, Loss: 0.4835
Batch 100, Loss: 0.5133
Batch 110, Loss: 0.4564
Batch 120, Loss: 0.4333
Batch 130, Loss: 0.4989
Batch 140, Loss: 0.5005
Batch 150, Loss: 0.4627
Batch 160, Loss: 0.4485
Batch 170, Loss: 0.4858
Batch 180, Loss: 0.4937
Batch 190, Loss: 0.5187
Batch 200, Loss: 0.4035
Batch 210, Loss: 0.4688
Batch 220, Loss: 0.4792
Batch 230, Loss: 0.4460
Batch 240, Loss: 0.4465
Batch 250, Loss: 0.5019
Batch 260, Loss: 0.4294
Batch 270, Loss: 0.4644
Batch 280, Loss: 0.4730
Batch 290, Loss: 0.4499
Batch 300, Loss: 0.4746
Batch 310, Loss: 0.4826
Batch 320, Loss: 0.4578
Batch 330, Loss: 0.4616
Batch 340, Loss: 0.4950
Batch 350, Loss: 0.5069
Batch 360, Loss: 0.4447
Batch 370, Loss: 0.5058
Batch 380, Loss: 0.4872
Batch 390, Loss: 0.4864
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.605127811431885 seconds
Epoch 83 accuracy: 84.85%
Batch 10, Loss: 0.4644
Batch 20, Loss: 0.4714
Batch 30, Loss: 0.5017
Batch 40, Loss: 0.4824
Batch 50, Loss: 0.4698
Batch 60, Loss: 0.4925
Batch 70, Loss: 0.4625
Batch 80, Loss: 0.5055
Batch 90, Loss: 0.4409
Batch 100, Loss: 0.4636
Batch 110, Loss: 0.4634
Batch 120, Loss: 0.4665
Batch 130, Loss: 0.4752
Batch 140, Loss: 0.4734
Batch 150, Loss: 0.4446
Batch 160, Loss: 0.4847
Batch 170, Loss: 0.4812
Batch 180, Loss: 0.4784
Batch 190, Loss: 0.4376
Batch 200, Loss: 0.4232
Batch 210, Loss: 0.4563
Batch 220, Loss: 0.4267
Batch 230, Loss: 0.4653
Batch 240, Loss: 0.4912
Batch 250, Loss: 0.4904
Batch 260, Loss: 0.4796
Batch 270, Loss: 0.4908
Batch 280, Loss: 0.5034
Batch 290, Loss: 0.4258
Batch 300, Loss: 0.4503
Batch 310, Loss: 0.4699
Batch 320, Loss: 0.5304
Batch 330, Loss: 0.4590
Batch 340, Loss: 0.4737
Batch 350, Loss: 0.4777
Batch 360, Loss: 0.4854
Batch 370, Loss: 0.4988
Batch 380, Loss: 0.4878
Batch 390, Loss: 0.4945
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.515169620513916 seconds
Epoch 84 accuracy: 88.37%
Batch 10, Loss: 0.4082
Batch 20, Loss: 0.5022
Batch 30, Loss: 0.4542
Batch 40, Loss: 0.4672
Batch 50, Loss: 0.4650
Batch 60, Loss: 0.4441
Batch 70, Loss: 0.4804
Batch 80, Loss: 0.4747
Batch 90, Loss: 0.4772
Batch 100, Loss: 0.4707
Batch 110, Loss: 0.5038
Batch 120, Loss: 0.4760
Batch 130, Loss: 0.4796
Batch 140, Loss: 0.4584
Batch 150, Loss: 0.4994
Batch 160, Loss: 0.4805
Batch 170, Loss: 0.4991
Batch 180, Loss: 0.4251
Batch 190, Loss: 0.4614
Batch 200, Loss: 0.4637
Batch 210, Loss: 0.4878
Batch 220, Loss: 0.4927
Batch 230, Loss: 0.4482
Batch 240, Loss: 0.4495
Batch 250, Loss: 0.4962
Batch 260, Loss: 0.4678
Batch 270, Loss: 0.4502
Batch 280, Loss: 0.4367
Batch 290, Loss: 0.4955
Batch 300, Loss: 0.4829
Batch 310, Loss: 0.4758
Batch 320, Loss: 0.5045
Batch 330, Loss: 0.4383
Batch 340, Loss: 0.4183
Batch 350, Loss: 0.4391
Batch 360, Loss: 0.5062
Batch 370, Loss: 0.4724
Batch 380, Loss: 0.4378
Batch 390, Loss: 0.4577
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.48950982093811 seconds
Epoch 85 accuracy: 83.51%
Batch 10, Loss: 0.4406
Batch 20, Loss: 0.4556
Batch 30, Loss: 0.4528
Batch 40, Loss: 0.5044
Batch 50, Loss: 0.4399
Batch 60, Loss: 0.4973
Batch 70, Loss: 0.4706
Batch 80, Loss: 0.4726
Batch 90, Loss: 0.4710
Batch 100, Loss: 0.4488
Batch 110, Loss: 0.4730
Batch 120, Loss: 0.4630
Batch 130, Loss: 0.4468
Batch 140, Loss: 0.4621
Batch 150, Loss: 0.4709
Batch 160, Loss: 0.5074
Batch 170, Loss: 0.4735
Batch 180, Loss: 0.4887
Batch 190, Loss: 0.4659
Batch 200, Loss: 0.4317
Batch 210, Loss: 0.4399
Batch 220, Loss: 0.4764
Batch 230, Loss: 0.4577
Batch 240, Loss: 0.4817
Batch 250, Loss: 0.5034
Batch 260, Loss: 0.4612
Batch 270, Loss: 0.4796
Batch 280, Loss: 0.4524
Batch 290, Loss: 0.5066
Batch 300, Loss: 0.4957
Batch 310, Loss: 0.5071
Batch 320, Loss: 0.4700
Batch 330, Loss: 0.4547
Batch 340, Loss: 0.4291
Batch 350, Loss: 0.4565
Batch 360, Loss: 0.4902
Batch 370, Loss: 0.4610
Batch 380, Loss: 0.4802
Batch 390, Loss: 0.5162
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.585460424423218 seconds
Epoch 86 accuracy: 87.78%
Batch 10, Loss: 0.4799
Batch 20, Loss: 0.4575
Batch 30, Loss: 0.4502
Batch 40, Loss: 0.4788
Batch 50, Loss: 0.4762
Batch 60, Loss: 0.4797
Batch 70, Loss: 0.4284
Batch 80, Loss: 0.4197
Batch 90, Loss: 0.4786
Batch 100, Loss: 0.4499
Batch 110, Loss: 0.4749
Batch 120, Loss: 0.4794
Batch 130, Loss: 0.4458
Batch 140, Loss: 0.4462
Batch 150, Loss: 0.4518
Batch 160, Loss: 0.4855
Batch 170, Loss: 0.4813
Batch 180, Loss: 0.4592
Batch 190, Loss: 0.4894
Batch 200, Loss: 0.4481
Batch 210, Loss: 0.4673
Batch 220, Loss: 0.4803
Batch 230, Loss: 0.4667
Batch 240, Loss: 0.4569
Batch 250, Loss: 0.4627
Batch 260, Loss: 0.4942
Batch 270, Loss: 0.4717
Batch 280, Loss: 0.4563
Batch 290, Loss: 0.4630
Batch 300, Loss: 0.4418
Batch 310, Loss: 0.4883
Batch 320, Loss: 0.4869
Batch 330, Loss: 0.4423
Batch 340, Loss: 0.4805
Batch 350, Loss: 0.4818
Batch 360, Loss: 0.4638
Batch 370, Loss: 0.4619
Batch 380, Loss: 0.4347
Batch 390, Loss: 0.4478
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.479730129241943 seconds
Epoch 87 accuracy: 86.43%
Batch 10, Loss: 0.4516
Batch 20, Loss: 0.5108
Batch 30, Loss: 0.4472
Batch 40, Loss: 0.4366
Batch 50, Loss: 0.4549
Batch 60, Loss: 0.4668
Batch 70, Loss: 0.4726
Batch 80, Loss: 0.4615
Batch 90, Loss: 0.4581
Batch 100, Loss: 0.4464
Batch 110, Loss: 0.4377
Batch 120, Loss: 0.4188
Batch 130, Loss: 0.4773
Batch 140, Loss: 0.4681
Batch 150, Loss: 0.4455
Batch 160, Loss: 0.4404
Batch 170, Loss: 0.4662
Batch 180, Loss: 0.4573
Batch 190, Loss: 0.4947
Batch 200, Loss: 0.4304
Batch 210, Loss: 0.4524
Batch 220, Loss: 0.4427
Batch 230, Loss: 0.4363
Batch 240, Loss: 0.4400
Batch 250, Loss: 0.4421
Batch 260, Loss: 0.4866
Batch 270, Loss: 0.4411
Batch 280, Loss: 0.4394
Batch 290, Loss: 0.4399
Batch 300, Loss: 0.4797
Batch 310, Loss: 0.4914
Batch 320, Loss: 0.5244
Batch 330, Loss: 0.4932
Batch 340, Loss: 0.4660
Batch 350, Loss: 0.4561
Batch 360, Loss: 0.4821
Batch 370, Loss: 0.4516
Batch 380, Loss: 0.4743
Batch 390, Loss: 0.4780
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.27797794342041 seconds
Epoch 88 accuracy: 86.05%
Batch 10, Loss: 0.4461
Batch 20, Loss: 0.4878
Batch 30, Loss: 0.4545
Batch 40, Loss: 0.4555
Batch 50, Loss: 0.4645
Batch 60, Loss: 0.4739
Batch 70, Loss: 0.4728
Batch 80, Loss: 0.4532
Batch 90, Loss: 0.4653
Batch 100, Loss: 0.4524
Batch 110, Loss: 0.4417
Batch 120, Loss: 0.4057
Batch 130, Loss: 0.4612
Batch 140, Loss: 0.4572
Batch 150, Loss: 0.4540
Batch 160, Loss: 0.4274
Batch 170, Loss: 0.5002
Batch 180, Loss: 0.4685
Batch 190, Loss: 0.4913
Batch 200, Loss: 0.4669
Batch 210, Loss: 0.4674
Batch 220, Loss: 0.4826
Batch 230, Loss: 0.4432
Batch 240, Loss: 0.4642
Batch 250, Loss: 0.4458
Batch 260, Loss: 0.4459
Batch 270, Loss: 0.4681
Batch 280, Loss: 0.4994
Batch 290, Loss: 0.4478
Batch 300, Loss: 0.4654
Batch 310, Loss: 0.4494
Batch 320, Loss: 0.4543
Batch 330, Loss: 0.4516
Batch 340, Loss: 0.4665
Batch 350, Loss: 0.4876
Batch 360, Loss: 0.4641
Batch 370, Loss: 0.4808
Batch 380, Loss: 0.4433
Batch 390, Loss: 0.4941
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.430903434753418 seconds
Epoch 89 accuracy: 85.92%
Batch 10, Loss: 0.4178
Batch 20, Loss: 0.4675
Batch 30, Loss: 0.4501
Batch 40, Loss: 0.4423
Batch 50, Loss: 0.4191
Batch 60, Loss: 0.4505
Batch 70, Loss: 0.4615
Batch 80, Loss: 0.4719
Batch 90, Loss: 0.4732
Batch 100, Loss: 0.4165
Batch 110, Loss: 0.4339
Batch 120, Loss: 0.4700
Batch 130, Loss: 0.4854
Batch 140, Loss: 0.4818
Batch 150, Loss: 0.4765
Batch 160, Loss: 0.4225
Batch 170, Loss: 0.4571
Batch 180, Loss: 0.4454
Batch 190, Loss: 0.4352
Batch 200, Loss: 0.4502
Batch 210, Loss: 0.4425
Batch 220, Loss: 0.4497
Batch 230, Loss: 0.4472
Batch 240, Loss: 0.4816
Batch 250, Loss: 0.4748
Batch 260, Loss: 0.4756
Batch 270, Loss: 0.4850
Batch 280, Loss: 0.4939
Batch 290, Loss: 0.4605
Batch 300, Loss: 0.4741
Batch 310, Loss: 0.4307
Batch 320, Loss: 0.4408
Batch 330, Loss: 0.4542
Batch 340, Loss: 0.4464
Batch 350, Loss: 0.4475
Batch 360, Loss: 0.4642
Batch 370, Loss: 0.4584
Batch 380, Loss: 0.4524
Batch 390, Loss: 0.4071
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.553947925567627 seconds
Epoch 90 accuracy: 86.38%
Batch 10, Loss: 0.4611
Batch 20, Loss: 0.4642
Batch 30, Loss: 0.4823
Batch 40, Loss: 0.4791
Batch 50, Loss: 0.4335
Batch 60, Loss: 0.4544
Batch 70, Loss: 0.4694
Batch 80, Loss: 0.4579
Batch 90, Loss: 0.4676
Batch 100, Loss: 0.4231
Batch 110, Loss: 0.4465
Batch 120, Loss: 0.4856
Batch 130, Loss: 0.4550
Batch 140, Loss: 0.4273
Batch 150, Loss: 0.4723
Batch 160, Loss: 0.4520
Batch 170, Loss: 0.4275
Batch 180, Loss: 0.4731
Batch 190, Loss: 0.4481
Batch 200, Loss: 0.4416
Batch 210, Loss: 0.4523
Batch 220, Loss: 0.4874
Batch 230, Loss: 0.4783
Batch 240, Loss: 0.4297
Batch 250, Loss: 0.4582
Batch 260, Loss: 0.4540
Batch 270, Loss: 0.4816
Batch 280, Loss: 0.4935
Batch 290, Loss: 0.4406
Batch 300, Loss: 0.4744
Batch 310, Loss: 0.4284
Batch 320, Loss: 0.4738
Batch 330, Loss: 0.4488
Batch 340, Loss: 0.4708
Batch 350, Loss: 0.4273
Batch 360, Loss: 0.4738
Batch 370, Loss: 0.4740
Batch 380, Loss: 0.4226
Batch 390, Loss: 0.4241
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.608150959014893 seconds
Epoch 91 accuracy: 86.46%
Batch 10, Loss: 0.4255
Batch 20, Loss: 0.4725
Batch 30, Loss: 0.4449
Batch 40, Loss: 0.4297
Batch 50, Loss: 0.4523
Batch 60, Loss: 0.4894
Batch 70, Loss: 0.4510
Batch 80, Loss: 0.4760
Batch 90, Loss: 0.4416
Batch 100, Loss: 0.4216
Batch 110, Loss: 0.4777
Batch 120, Loss: 0.4476
Batch 130, Loss: 0.4682
Batch 140, Loss: 0.4906
Batch 150, Loss: 0.4509
Batch 160, Loss: 0.4194
Batch 170, Loss: 0.4290
Batch 180, Loss: 0.4479
Batch 190, Loss: 0.4371
Batch 200, Loss: 0.4641
Batch 210, Loss: 0.4433
Batch 220, Loss: 0.4557
Batch 230, Loss: 0.4738
Batch 240, Loss: 0.4643
Batch 250, Loss: 0.4559
Batch 260, Loss: 0.4628
Batch 270, Loss: 0.4497
Batch 280, Loss: 0.4384
Batch 290, Loss: 0.4336
Batch 300, Loss: 0.4537
Batch 310, Loss: 0.4336
Batch 320, Loss: 0.4577
Batch 330, Loss: 0.4323
Batch 340, Loss: 0.4835
Batch 350, Loss: 0.4783
Batch 360, Loss: 0.4746
Batch 370, Loss: 0.4617
Batch 380, Loss: 0.4224
Batch 390, Loss: 0.4647
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.47110390663147 seconds
Epoch 92 accuracy: 85.89%
Batch 10, Loss: 0.4477
Batch 20, Loss: 0.4428
Batch 30, Loss: 0.4531
Batch 40, Loss: 0.4451
Batch 50, Loss: 0.4284
Batch 60, Loss: 0.4378
Batch 70, Loss: 0.4717
Batch 80, Loss: 0.4639
Batch 90, Loss: 0.4645
Batch 100, Loss: 0.4586
Batch 110, Loss: 0.4232
Batch 120, Loss: 0.4047
Batch 130, Loss: 0.4567
Batch 140, Loss: 0.4315
Batch 150, Loss: 0.4663
Batch 160, Loss: 0.4806
Batch 170, Loss: 0.4430
Batch 180, Loss: 0.4482
Batch 190, Loss: 0.4793
Batch 200, Loss: 0.5153
Batch 210, Loss: 0.4546
Batch 220, Loss: 0.4734
Batch 230, Loss: 0.4532
Batch 240, Loss: 0.4661
Batch 250, Loss: 0.4741
Batch 260, Loss: 0.4482
Batch 270, Loss: 0.4862
Batch 280, Loss: 0.4779
Batch 290, Loss: 0.4248
Batch 300, Loss: 0.4472
Batch 310, Loss: 0.4878
Batch 320, Loss: 0.4796
Batch 330, Loss: 0.4067
Batch 340, Loss: 0.4380
Batch 350, Loss: 0.4838
Batch 360, Loss: 0.4442
Batch 370, Loss: 0.4455
Batch 380, Loss: 0.4389
Batch 390, Loss: 0.4623
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.58378505706787 seconds
Epoch 93 accuracy: 87.91%
Batch 10, Loss: 0.4660
Batch 20, Loss: 0.4435
Batch 30, Loss: 0.4665
Batch 40, Loss: 0.4215
Batch 50, Loss: 0.4308
Batch 60, Loss: 0.4366
Batch 70, Loss: 0.5208
Batch 80, Loss: 0.4599
Batch 90, Loss: 0.4493
Batch 100, Loss: 0.4278
Batch 110, Loss: 0.4172
Batch 120, Loss: 0.4781
Batch 130, Loss: 0.4442
Batch 140, Loss: 0.4518
Batch 150, Loss: 0.4158
Batch 160, Loss: 0.4655
Batch 170, Loss: 0.4708
Batch 180, Loss: 0.4466
Batch 190, Loss: 0.4173
Batch 200, Loss: 0.4382
Batch 210, Loss: 0.4561
Batch 220, Loss: 0.4143
Batch 230, Loss: 0.4335
Batch 240, Loss: 0.4312
Batch 250, Loss: 0.4465
Batch 260, Loss: 0.4802
Batch 270, Loss: 0.4403
Batch 280, Loss: 0.4720
Batch 290, Loss: 0.4283
Batch 300, Loss: 0.4465
Batch 310, Loss: 0.4110
Batch 320, Loss: 0.4175
Batch 330, Loss: 0.4093
Batch 340, Loss: 0.4362
Batch 350, Loss: 0.4645
Batch 360, Loss: 0.4317
Batch 370, Loss: 0.4486
Batch 380, Loss: 0.4764
Batch 390, Loss: 0.4632
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.57217764854431 seconds
Epoch 94 accuracy: 88.28%
Batch 10, Loss: 0.4942
Batch 20, Loss: 0.4341
Batch 30, Loss: 0.4762
Batch 40, Loss: 0.4141
Batch 50, Loss: 0.4525
Batch 60, Loss: 0.4661
Batch 70, Loss: 0.4622
Batch 80, Loss: 0.4331
Batch 90, Loss: 0.4114
Batch 100, Loss: 0.4511
Batch 110, Loss: 0.3887
Batch 120, Loss: 0.4155
Batch 130, Loss: 0.4837
Batch 140, Loss: 0.4552
Batch 150, Loss: 0.4299
Batch 160, Loss: 0.4671
Batch 170, Loss: 0.4171
Batch 180, Loss: 0.4366
Batch 190, Loss: 0.4249
Batch 200, Loss: 0.4644
Batch 210, Loss: 0.4767
Batch 220, Loss: 0.4555
Batch 230, Loss: 0.4841
Batch 240, Loss: 0.4572
Batch 250, Loss: 0.4607
Batch 260, Loss: 0.4268
Batch 270, Loss: 0.3941
Batch 280, Loss: 0.4622
Batch 290, Loss: 0.4397
Batch 300, Loss: 0.4394
Batch 310, Loss: 0.4568
Batch 320, Loss: 0.4329
Batch 330, Loss: 0.4514
Batch 340, Loss: 0.4568
Batch 350, Loss: 0.4648
Batch 360, Loss: 0.4769
Batch 370, Loss: 0.4819
Batch 380, Loss: 0.4020
Batch 390, Loss: 0.4227
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.686989545822144 seconds
Epoch 95 accuracy: 87.28%
Batch 10, Loss: 0.4525
Batch 20, Loss: 0.4703
Batch 30, Loss: 0.4547
Batch 40, Loss: 0.4102
Batch 50, Loss: 0.4263
Batch 60, Loss: 0.4570
Batch 70, Loss: 0.4472
Batch 80, Loss: 0.4420
Batch 90, Loss: 0.4453
Batch 100, Loss: 0.4623
Batch 110, Loss: 0.4391
Batch 120, Loss: 0.4453
Batch 130, Loss: 0.4640
Batch 140, Loss: 0.4267
Batch 150, Loss: 0.4173
Batch 160, Loss: 0.4315
Batch 170, Loss: 0.4263
Batch 180, Loss: 0.4218
Batch 190, Loss: 0.4415
Batch 200, Loss: 0.4435
Batch 210, Loss: 0.4311
Batch 220, Loss: 0.4160
Batch 230, Loss: 0.4524
Batch 240, Loss: 0.4952
Batch 250, Loss: 0.4348
Batch 260, Loss: 0.4314
Batch 270, Loss: 0.4443
Batch 280, Loss: 0.4289
Batch 290, Loss: 0.4449
Batch 300, Loss: 0.4716
Batch 310, Loss: 0.4728
Batch 320, Loss: 0.4364
Batch 330, Loss: 0.4108
Batch 340, Loss: 0.4567
Batch 350, Loss: 0.4496
Batch 360, Loss: 0.4248
Batch 370, Loss: 0.4481
Batch 380, Loss: 0.4304
Batch 390, Loss: 0.4716
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.715433835983276 seconds
Epoch 96 accuracy: 86.14%
Batch 10, Loss: 0.4428
Batch 20, Loss: 0.4441
Batch 30, Loss: 0.4574
Batch 40, Loss: 0.4197
Batch 50, Loss: 0.4367
Batch 60, Loss: 0.4203
Batch 70, Loss: 0.4599
Batch 80, Loss: 0.4635
Batch 90, Loss: 0.4114
Batch 100, Loss: 0.4180
Batch 110, Loss: 0.4360
Batch 120, Loss: 0.4513
Batch 130, Loss: 0.4492
Batch 140, Loss: 0.4239
Batch 150, Loss: 0.4226
Batch 160, Loss: 0.4336
Batch 170, Loss: 0.4236
Batch 180, Loss: 0.4508
Batch 190, Loss: 0.4349
Batch 200, Loss: 0.4492
Batch 210, Loss: 0.4931
Batch 220, Loss: 0.4442
Batch 230, Loss: 0.4486
Batch 240, Loss: 0.4715
Batch 250, Loss: 0.4374
Batch 260, Loss: 0.4296
Batch 270, Loss: 0.4218
Batch 280, Loss: 0.4367
Batch 290, Loss: 0.3982
Batch 300, Loss: 0.4556
Batch 310, Loss: 0.4144
Batch 320, Loss: 0.4462
Batch 330, Loss: 0.4538
Batch 340, Loss: 0.4418
Batch 350, Loss: 0.4529
Batch 360, Loss: 0.4292
Batch 370, Loss: 0.4588
Batch 380, Loss: 0.4517
Batch 390, Loss: 0.4456
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.512434720993042 seconds
Epoch 97 accuracy: 86.71%
Batch 10, Loss: 0.4499
Batch 20, Loss: 0.4551
Batch 30, Loss: 0.4167
Batch 40, Loss: 0.4603
Batch 50, Loss: 0.4093
Batch 60, Loss: 0.4307
Batch 70, Loss: 0.4141
Batch 80, Loss: 0.4541
Batch 90, Loss: 0.4327
Batch 100, Loss: 0.4244
Batch 110, Loss: 0.4690
Batch 120, Loss: 0.4792
Batch 130, Loss: 0.3957
Batch 140, Loss: 0.4444
Batch 150, Loss: 0.4205
Batch 160, Loss: 0.4576
Batch 170, Loss: 0.4391
Batch 180, Loss: 0.3792
Batch 190, Loss: 0.4490
Batch 200, Loss: 0.4504
Batch 210, Loss: 0.4629
Batch 220, Loss: 0.4632
Batch 230, Loss: 0.4531
Batch 240, Loss: 0.5112
Batch 250, Loss: 0.4681
Batch 260, Loss: 0.4737
Batch 270, Loss: 0.4497
Batch 280, Loss: 0.4516
Batch 290, Loss: 0.4050
Batch 300, Loss: 0.4605
Batch 310, Loss: 0.4139
Batch 320, Loss: 0.4653
Batch 330, Loss: 0.4388
Batch 340, Loss: 0.4057
Batch 350, Loss: 0.4746
Batch 360, Loss: 0.4420
Batch 370, Loss: 0.4309
Batch 380, Loss: 0.4306
Batch 390, Loss: 0.4336
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.553098440170288 seconds
Epoch 98 accuracy: 89.2%
Batch 10, Loss: 0.4310
Batch 20, Loss: 0.4381
Batch 30, Loss: 0.4130
Batch 40, Loss: 0.4135
Batch 50, Loss: 0.4387
Batch 60, Loss: 0.4480
Batch 70, Loss: 0.4304
Batch 80, Loss: 0.4439
Batch 90, Loss: 0.4178
Batch 100, Loss: 0.4301
Batch 110, Loss: 0.4310
Batch 120, Loss: 0.4480
Batch 130, Loss: 0.4345
Batch 140, Loss: 0.4351
Batch 150, Loss: 0.4442
Batch 160, Loss: 0.4209
Batch 170, Loss: 0.4708
Batch 180, Loss: 0.4266
Batch 190, Loss: 0.4199
Batch 200, Loss: 0.4100
Batch 210, Loss: 0.4437
Batch 220, Loss: 0.4362
Batch 230, Loss: 0.4221
Batch 240, Loss: 0.4137
Batch 250, Loss: 0.4362
Batch 260, Loss: 0.4507
Batch 270, Loss: 0.4743
Batch 280, Loss: 0.4898
Batch 290, Loss: 0.4521
Batch 300, Loss: 0.4309
Batch 310, Loss: 0.4237
Batch 320, Loss: 0.4336
Batch 330, Loss: 0.4413
Batch 340, Loss: 0.4378
Batch 350, Loss: 0.4434
Batch 360, Loss: 0.4086
Batch 370, Loss: 0.4611
Batch 380, Loss: 0.4561
Batch 390, Loss: 0.4140
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.610373735427856 seconds
Epoch 99 accuracy: 86.41%
Batch 10, Loss: 0.4493
Batch 20, Loss: 0.4305
Batch 30, Loss: 0.4231
Batch 40, Loss: 0.4131
Batch 50, Loss: 0.4322
Batch 60, Loss: 0.4630
Batch 70, Loss: 0.4330
Batch 80, Loss: 0.4231
Batch 90, Loss: 0.4521
Batch 100, Loss: 0.4216
Batch 110, Loss: 0.4389
Batch 120, Loss: 0.3897
Batch 130, Loss: 0.4362
Batch 140, Loss: 0.4499
Batch 150, Loss: 0.3940
Batch 160, Loss: 0.4458
Batch 170, Loss: 0.4386
Batch 180, Loss: 0.4330
Batch 190, Loss: 0.4171
Batch 200, Loss: 0.4433
Batch 210, Loss: 0.4485
Batch 220, Loss: 0.3805
Batch 230, Loss: 0.4623
Batch 240, Loss: 0.4678
Batch 250, Loss: 0.4470
Batch 260, Loss: 0.4413
Batch 270, Loss: 0.4942
Batch 280, Loss: 0.4255
Batch 290, Loss: 0.4454
Batch 300, Loss: 0.4620
Batch 310, Loss: 0.4092
Batch 320, Loss: 0.4392
Batch 330, Loss: 0.4506
Batch 340, Loss: 0.4325
Batch 350, Loss: 0.4296
Batch 360, Loss: 0.4701
Batch 370, Loss: 0.4364
Batch 380, Loss: 0.4247
Batch 390, Loss: 0.4707
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.60182237625122 seconds
Epoch 100 accuracy: 85.42%
Batch 10, Loss: 0.4176
Batch 20, Loss: 0.4232
Batch 30, Loss: 0.4033
Batch 40, Loss: 0.4445
Batch 50, Loss: 0.3935
Batch 60, Loss: 0.4071
Batch 70, Loss: 0.4518
Batch 80, Loss: 0.4318
Batch 90, Loss: 0.4314
Batch 100, Loss: 0.4360
Batch 110, Loss: 0.4510
Batch 120, Loss: 0.4240
Batch 130, Loss: 0.4272
Batch 140, Loss: 0.4175
Batch 150, Loss: 0.4517
Batch 160, Loss: 0.4141
Batch 170, Loss: 0.4413
Batch 180, Loss: 0.4334
Batch 190, Loss: 0.4383
Batch 200, Loss: 0.4438
Batch 210, Loss: 0.4248
Batch 220, Loss: 0.4108
Batch 230, Loss: 0.4112
Batch 240, Loss: 0.4261
Batch 250, Loss: 0.4159
Batch 260, Loss: 0.4384
Batch 270, Loss: 0.4493
Batch 280, Loss: 0.4496
Batch 290, Loss: 0.4412
Batch 300, Loss: 0.4464
Batch 310, Loss: 0.4134
Batch 320, Loss: 0.4268
Batch 330, Loss: 0.4448
Batch 340, Loss: 0.4139
Batch 350, Loss: 0.4175
Batch 360, Loss: 0.4146
Batch 370, Loss: 0.4309
Batch 380, Loss: 0.4702
Batch 390, Loss: 0.4469
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.627122402191162 seconds
Epoch 101 accuracy: 87.82%
Batch 10, Loss: 0.4432
Batch 20, Loss: 0.4391
Batch 30, Loss: 0.4590
Batch 40, Loss: 0.4463
Batch 50, Loss: 0.4002
Batch 60, Loss: 0.4354
Batch 70, Loss: 0.4410
Batch 80, Loss: 0.4705
Batch 90, Loss: 0.4022
Batch 100, Loss: 0.4058
Batch 110, Loss: 0.4068
Batch 120, Loss: 0.3847
Batch 130, Loss: 0.4318
Batch 140, Loss: 0.4132
Batch 150, Loss: 0.4190
Batch 160, Loss: 0.4434
Batch 170, Loss: 0.4309
Batch 180, Loss: 0.4526
Batch 190, Loss: 0.4200
Batch 200, Loss: 0.4423
Batch 210, Loss: 0.4220
Batch 220, Loss: 0.4376
Batch 230, Loss: 0.4266
Batch 240, Loss: 0.4210
Batch 250, Loss: 0.4193
Batch 260, Loss: 0.4143
Batch 270, Loss: 0.4465
Batch 280, Loss: 0.4328
Batch 290, Loss: 0.4264
Batch 300, Loss: 0.4947
Batch 310, Loss: 0.4437
Batch 320, Loss: 0.4163
Batch 330, Loss: 0.4097
Batch 340, Loss: 0.4587
Batch 350, Loss: 0.4284
Batch 360, Loss: 0.3935
Batch 370, Loss: 0.4041
Batch 380, Loss: 0.4133
Batch 390, Loss: 0.4504
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.55500102043152 seconds
Epoch 102 accuracy: 88.22%
Batch 10, Loss: 0.4304
Batch 20, Loss: 0.4254
Batch 30, Loss: 0.4053
Batch 40, Loss: 0.3985
Batch 50, Loss: 0.4206
Batch 60, Loss: 0.4354
Batch 70, Loss: 0.4308
Batch 80, Loss: 0.4443
Batch 90, Loss: 0.4296
Batch 100, Loss: 0.4646
Batch 110, Loss: 0.4609
Batch 120, Loss: 0.4238
Batch 130, Loss: 0.4539
Batch 140, Loss: 0.3844
Batch 150, Loss: 0.4224
Batch 160, Loss: 0.4384
Batch 170, Loss: 0.4156
Batch 180, Loss: 0.4385
Batch 190, Loss: 0.4232
Batch 200, Loss: 0.4135
Batch 210, Loss: 0.4418
Batch 220, Loss: 0.4709
Batch 230, Loss: 0.4119
Batch 240, Loss: 0.4211
Batch 250, Loss: 0.4252
Batch 260, Loss: 0.4251
Batch 270, Loss: 0.3981
Batch 280, Loss: 0.4399
Batch 290, Loss: 0.4331
Batch 300, Loss: 0.4466
Batch 310, Loss: 0.4292
Batch 320, Loss: 0.4050
Batch 330, Loss: 0.4029
Batch 340, Loss: 0.3978
Batch 350, Loss: 0.4287
Batch 360, Loss: 0.3841
Batch 370, Loss: 0.4471
Batch 380, Loss: 0.4292
Batch 390, Loss: 0.4329
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.632739543914795 seconds
Epoch 103 accuracy: 87.86%
Batch 10, Loss: 0.4202
Batch 20, Loss: 0.4004
Batch 30, Loss: 0.3835
Batch 40, Loss: 0.4478
Batch 50, Loss: 0.3984
Batch 60, Loss: 0.4224
Batch 70, Loss: 0.4043
Batch 80, Loss: 0.4150
Batch 90, Loss: 0.3973
Batch 100, Loss: 0.4296
Batch 110, Loss: 0.4016
Batch 120, Loss: 0.4597
Batch 130, Loss: 0.4166
Batch 140, Loss: 0.4134
Batch 150, Loss: 0.4374
Batch 160, Loss: 0.4748
Batch 170, Loss: 0.4075
Batch 180, Loss: 0.3978
Batch 190, Loss: 0.4358
Batch 200, Loss: 0.4324
Batch 210, Loss: 0.4162
Batch 220, Loss: 0.4246
Batch 230, Loss: 0.4521
Batch 240, Loss: 0.4008
Batch 250, Loss: 0.4358
Batch 260, Loss: 0.4351
Batch 270, Loss: 0.4240
Batch 280, Loss: 0.4152
Batch 290, Loss: 0.4455
Batch 300, Loss: 0.4471
Batch 310, Loss: 0.4901
Batch 320, Loss: 0.3910
Batch 330, Loss: 0.3853
Batch 340, Loss: 0.4145
Batch 350, Loss: 0.4449
Batch 360, Loss: 0.4285
Batch 370, Loss: 0.4413
Batch 380, Loss: 0.4230
Batch 390, Loss: 0.4506
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.774940967559814 seconds
Epoch 104 accuracy: 90.1%
Batch 10, Loss: 0.4368
Batch 20, Loss: 0.3895
Batch 30, Loss: 0.3854
Batch 40, Loss: 0.4132
Batch 50, Loss: 0.3898
Batch 60, Loss: 0.4407
Batch 70, Loss: 0.4262
Batch 80, Loss: 0.4123
Batch 90, Loss: 0.4581
Batch 100, Loss: 0.4152
Batch 110, Loss: 0.4199
Batch 120, Loss: 0.4098
Batch 130, Loss: 0.4501
Batch 140, Loss: 0.4031
Batch 150, Loss: 0.4156
Batch 160, Loss: 0.4640
Batch 170, Loss: 0.4274
Batch 180, Loss: 0.4500
Batch 190, Loss: 0.4517
Batch 200, Loss: 0.4297
Batch 210, Loss: 0.4439
Batch 220, Loss: 0.4271
Batch 230, Loss: 0.4075
Batch 240, Loss: 0.4280
Batch 250, Loss: 0.4283
Batch 260, Loss: 0.4081
Batch 270, Loss: 0.4236
Batch 280, Loss: 0.4264
Batch 290, Loss: 0.4188
Batch 300, Loss: 0.4037
Batch 310, Loss: 0.4349
Batch 320, Loss: 0.4432
Batch 330, Loss: 0.4073
Batch 340, Loss: 0.4090
Batch 350, Loss: 0.4027
Batch 360, Loss: 0.3974
Batch 370, Loss: 0.3925
Batch 380, Loss: 0.4259
Batch 390, Loss: 0.4252
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.64884638786316 seconds
Epoch 105 accuracy: 89.37%
Batch 10, Loss: 0.4238
Batch 20, Loss: 0.4145
Batch 30, Loss: 0.4210
Batch 40, Loss: 0.3737
Batch 50, Loss: 0.4070
Batch 60, Loss: 0.4655
Batch 70, Loss: 0.4594
Batch 80, Loss: 0.4132
Batch 90, Loss: 0.3773
Batch 100, Loss: 0.4485
Batch 110, Loss: 0.4129
Batch 120, Loss: 0.4131
Batch 130, Loss: 0.3920
Batch 140, Loss: 0.4145
Batch 150, Loss: 0.3951
Batch 160, Loss: 0.4217
Batch 170, Loss: 0.4381
Batch 180, Loss: 0.4241
Batch 190, Loss: 0.4276
Batch 200, Loss: 0.3921
Batch 210, Loss: 0.4410
Batch 220, Loss: 0.4220
Batch 230, Loss: 0.4161
Batch 240, Loss: 0.4116
Batch 250, Loss: 0.4083
Batch 260, Loss: 0.4274
Batch 270, Loss: 0.4050
Batch 280, Loss: 0.3958
Batch 290, Loss: 0.4308
Batch 300, Loss: 0.4224
Batch 310, Loss: 0.4347
Batch 320, Loss: 0.4278
Batch 330, Loss: 0.4391
Batch 340, Loss: 0.4249
Batch 350, Loss: 0.4150
Batch 360, Loss: 0.4260
Batch 370, Loss: 0.4057
Batch 380, Loss: 0.3973
Batch 390, Loss: 0.4506
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.62431025505066 seconds
Epoch 106 accuracy: 89.9%
Batch 10, Loss: 0.4063
Batch 20, Loss: 0.4128
Batch 30, Loss: 0.3799
Batch 40, Loss: 0.3750
Batch 50, Loss: 0.4292
Batch 60, Loss: 0.4197
Batch 70, Loss: 0.4187
Batch 80, Loss: 0.4073
Batch 90, Loss: 0.4003
Batch 100, Loss: 0.4284
Batch 110, Loss: 0.4100
Batch 120, Loss: 0.3939
Batch 130, Loss: 0.4214
Batch 140, Loss: 0.4154
Batch 150, Loss: 0.4016
Batch 160, Loss: 0.4125
Batch 170, Loss: 0.4018
Batch 180, Loss: 0.4149
Batch 190, Loss: 0.4170
Batch 200, Loss: 0.4340
Batch 210, Loss: 0.4135
Batch 220, Loss: 0.3923
Batch 230, Loss: 0.4460
Batch 240, Loss: 0.4272
Batch 250, Loss: 0.3692
Batch 260, Loss: 0.4328
Batch 270, Loss: 0.4422
Batch 280, Loss: 0.4376
Batch 290, Loss: 0.4105
Batch 300, Loss: 0.4243
Batch 310, Loss: 0.4600
Batch 320, Loss: 0.4474
Batch 330, Loss: 0.4261
Batch 340, Loss: 0.4207
Batch 350, Loss: 0.4583
Batch 360, Loss: 0.4413
Batch 370, Loss: 0.3876
Batch 380, Loss: 0.4543
Batch 390, Loss: 0.3751
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.486700296401978 seconds
Epoch 107 accuracy: 90.13%
Batch 10, Loss: 0.3852
Batch 20, Loss: 0.3974
Batch 30, Loss: 0.4548
Batch 40, Loss: 0.3986
Batch 50, Loss: 0.4244
Batch 60, Loss: 0.3927
Batch 70, Loss: 0.4241
Batch 80, Loss: 0.4078
Batch 90, Loss: 0.3825
Batch 100, Loss: 0.4208
Batch 110, Loss: 0.3918
Batch 120, Loss: 0.4355
Batch 130, Loss: 0.4125
Batch 140, Loss: 0.4207
Batch 150, Loss: 0.4082
Batch 160, Loss: 0.4060
Batch 170, Loss: 0.3807
Batch 180, Loss: 0.4188
Batch 190, Loss: 0.4053
Batch 200, Loss: 0.4477
Batch 210, Loss: 0.4114
Batch 220, Loss: 0.3893
Batch 230, Loss: 0.4337
Batch 240, Loss: 0.4067
Batch 250, Loss: 0.4210
Batch 260, Loss: 0.4080
Batch 270, Loss: 0.4339
Batch 280, Loss: 0.4304
Batch 290, Loss: 0.4105
Batch 300, Loss: 0.3989
Batch 310, Loss: 0.3994
Batch 320, Loss: 0.4476
Batch 330, Loss: 0.4101
Batch 340, Loss: 0.4177
Batch 350, Loss: 0.4203
Batch 360, Loss: 0.4214
Batch 370, Loss: 0.4123
Batch 380, Loss: 0.4021
Batch 390, Loss: 0.4271
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.628148555755615 seconds
Epoch 108 accuracy: 89.27%
Batch 10, Loss: 0.4220
Batch 20, Loss: 0.4207
Batch 30, Loss: 0.3830
Batch 40, Loss: 0.4112
Batch 50, Loss: 0.3919
Batch 60, Loss: 0.3980
Batch 70, Loss: 0.3993
Batch 80, Loss: 0.4072
Batch 90, Loss: 0.4453
Batch 100, Loss: 0.3931
Batch 110, Loss: 0.4016
Batch 120, Loss: 0.4133
Batch 130, Loss: 0.4367
Batch 140, Loss: 0.4146
Batch 150, Loss: 0.3811
Batch 160, Loss: 0.3949
Batch 170, Loss: 0.4459
Batch 180, Loss: 0.4058
Batch 190, Loss: 0.4018
Batch 200, Loss: 0.4276
Batch 210, Loss: 0.4135
Batch 220, Loss: 0.4400
Batch 230, Loss: 0.4436
Batch 240, Loss: 0.4177
Batch 250, Loss: 0.4341
Batch 260, Loss: 0.4330
Batch 270, Loss: 0.4321
Batch 280, Loss: 0.4072
Batch 290, Loss: 0.4162
Batch 300, Loss: 0.4296
Batch 310, Loss: 0.4201
Batch 320, Loss: 0.3957
Batch 330, Loss: 0.4003
Batch 340, Loss: 0.3997
Batch 350, Loss: 0.4263
Batch 360, Loss: 0.4115
Batch 370, Loss: 0.4065
Batch 380, Loss: 0.3960
Batch 390, Loss: 0.4075
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.594953060150146 seconds
Epoch 109 accuracy: 88.91%
Batch 10, Loss: 0.3923
Batch 20, Loss: 0.3701
Batch 30, Loss: 0.3986
Batch 40, Loss: 0.3852
Batch 50, Loss: 0.4464
Batch 60, Loss: 0.4379
Batch 70, Loss: 0.3995
Batch 80, Loss: 0.4421
Batch 90, Loss: 0.3941
Batch 100, Loss: 0.3779
Batch 110, Loss: 0.3766
Batch 120, Loss: 0.4457
Batch 130, Loss: 0.4023
Batch 140, Loss: 0.3950
Batch 150, Loss: 0.4533
Batch 160, Loss: 0.3919
Batch 170, Loss: 0.4231
Batch 180, Loss: 0.4112
Batch 190, Loss: 0.3761
Batch 200, Loss: 0.3882
Batch 210, Loss: 0.3931
Batch 220, Loss: 0.4136
Batch 230, Loss: 0.4021
Batch 240, Loss: 0.4432
Batch 250, Loss: 0.3819
Batch 260, Loss: 0.3941
Batch 270, Loss: 0.4010
Batch 280, Loss: 0.4267
Batch 290, Loss: 0.4158
Batch 300, Loss: 0.4338
Batch 310, Loss: 0.4317
Batch 320, Loss: 0.4663
Batch 330, Loss: 0.4379
Batch 340, Loss: 0.3770
Batch 350, Loss: 0.4305
Batch 360, Loss: 0.3999
Batch 370, Loss: 0.4000
Batch 380, Loss: 0.3905
Batch 390, Loss: 0.4202
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.499205112457275 seconds
Epoch 110 accuracy: 89.93%
Batch 10, Loss: 0.3955
Batch 20, Loss: 0.3905
Batch 30, Loss: 0.4365
Batch 40, Loss: 0.4238
Batch 50, Loss: 0.3983
Batch 60, Loss: 0.3939
Batch 70, Loss: 0.4283
Batch 80, Loss: 0.3603
Batch 90, Loss: 0.3995
Batch 100, Loss: 0.4145
Batch 110, Loss: 0.4385
Batch 120, Loss: 0.3822
Batch 130, Loss: 0.4239
Batch 140, Loss: 0.3825
Batch 150, Loss: 0.4124
Batch 160, Loss: 0.3548
Batch 170, Loss: 0.4351
Batch 180, Loss: 0.4092
Batch 190, Loss: 0.4066
Batch 200, Loss: 0.4350
Batch 210, Loss: 0.4325
Batch 220, Loss: 0.3885
Batch 230, Loss: 0.3954
Batch 240, Loss: 0.4331
Batch 250, Loss: 0.3968
Batch 260, Loss: 0.3882
Batch 270, Loss: 0.4192
Batch 280, Loss: 0.4143
Batch 290, Loss: 0.3928
Batch 300, Loss: 0.4175
Batch 310, Loss: 0.4286
Batch 320, Loss: 0.4189
Batch 330, Loss: 0.4170
Batch 340, Loss: 0.3926
Batch 350, Loss: 0.4181
Batch 360, Loss: 0.3934
Batch 370, Loss: 0.4194
Batch 380, Loss: 0.3961
Batch 390, Loss: 0.3939
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.51506543159485 seconds
Epoch 111 accuracy: 90.22%
Batch 10, Loss: 0.4309
Batch 20, Loss: 0.4354
Batch 30, Loss: 0.3949
Batch 40, Loss: 0.4082
Batch 50, Loss: 0.3789
Batch 60, Loss: 0.3894
Batch 70, Loss: 0.4104
Batch 80, Loss: 0.3973
Batch 90, Loss: 0.3756
Batch 100, Loss: 0.4451
Batch 110, Loss: 0.3953
Batch 120, Loss: 0.4104
Batch 130, Loss: 0.3634
Batch 140, Loss: 0.4106
Batch 150, Loss: 0.4181
Batch 160, Loss: 0.4315
Batch 170, Loss: 0.4228
Batch 180, Loss: 0.3738
Batch 190, Loss: 0.4086
Batch 200, Loss: 0.3851
Batch 210, Loss: 0.3918
Batch 220, Loss: 0.4144
Batch 230, Loss: 0.4297
Batch 240, Loss: 0.3918
Batch 250, Loss: 0.4026
Batch 260, Loss: 0.3804
Batch 270, Loss: 0.3816
Batch 280, Loss: 0.3944
Batch 290, Loss: 0.3878
Batch 300, Loss: 0.3915
Batch 310, Loss: 0.3802
Batch 320, Loss: 0.4097
Batch 330, Loss: 0.3823
Batch 340, Loss: 0.3993
Batch 350, Loss: 0.4022
Batch 360, Loss: 0.3930
Batch 370, Loss: 0.4196
Batch 380, Loss: 0.4051
Batch 390, Loss: 0.4178
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.70244002342224 seconds
Epoch 112 accuracy: 88.99%
Batch 10, Loss: 0.4103
Batch 20, Loss: 0.4032
Batch 30, Loss: 0.4152
Batch 40, Loss: 0.4045
Batch 50, Loss: 0.3689
Batch 60, Loss: 0.3780
Batch 70, Loss: 0.4353
Batch 80, Loss: 0.3949
Batch 90, Loss: 0.4313
Batch 100, Loss: 0.4016
Batch 110, Loss: 0.3969
Batch 120, Loss: 0.4412
Batch 130, Loss: 0.4034
Batch 140, Loss: 0.3919
Batch 150, Loss: 0.3949
Batch 160, Loss: 0.4208
Batch 170, Loss: 0.3791
Batch 180, Loss: 0.3976
Batch 190, Loss: 0.3977
Batch 200, Loss: 0.4302
Batch 210, Loss: 0.4484
Batch 220, Loss: 0.4061
Batch 230, Loss: 0.3730
Batch 240, Loss: 0.4112
Batch 250, Loss: 0.4020
Batch 260, Loss: 0.4274
Batch 270, Loss: 0.3973
Batch 280, Loss: 0.4062
Batch 290, Loss: 0.3933
Batch 300, Loss: 0.4038
Batch 310, Loss: 0.3777
Batch 320, Loss: 0.4498
Batch 330, Loss: 0.4094
Batch 340, Loss: 0.3759
Batch 350, Loss: 0.4281
Batch 360, Loss: 0.4226
Batch 370, Loss: 0.3732
Batch 380, Loss: 0.3686
Batch 390, Loss: 0.4144
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.70891523361206 seconds
Epoch 113 accuracy: 89.85%
Batch 10, Loss: 0.3978
Batch 20, Loss: 0.4068
Batch 30, Loss: 0.3855
Batch 40, Loss: 0.3810
Batch 50, Loss: 0.3935
Batch 60, Loss: 0.4010
Batch 70, Loss: 0.4225
Batch 80, Loss: 0.4059
Batch 90, Loss: 0.3705
Batch 100, Loss: 0.4246
Batch 110, Loss: 0.4381
Batch 120, Loss: 0.4214
Batch 130, Loss: 0.4002
Batch 140, Loss: 0.4190
Batch 150, Loss: 0.3816
Batch 160, Loss: 0.4023
Batch 170, Loss: 0.3830
Batch 180, Loss: 0.4369
Batch 190, Loss: 0.3546
Batch 200, Loss: 0.4036
Batch 210, Loss: 0.3992
Batch 220, Loss: 0.4512
Batch 230, Loss: 0.3878
Batch 240, Loss: 0.4330
Batch 250, Loss: 0.3724
Batch 260, Loss: 0.4360
Batch 270, Loss: 0.3820
Batch 280, Loss: 0.3701
Batch 290, Loss: 0.3822
Batch 300, Loss: 0.4349
Batch 310, Loss: 0.3996
Batch 320, Loss: 0.3982
Batch 330, Loss: 0.4132
Batch 340, Loss: 0.4134
Batch 350, Loss: 0.4125
Batch 360, Loss: 0.4115
Batch 370, Loss: 0.4103
Batch 380, Loss: 0.3694
Batch 390, Loss: 0.3992
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.52258849143982 seconds
Epoch 114 accuracy: 89.18%
Batch 10, Loss: 0.3920
Batch 20, Loss: 0.4025
Batch 30, Loss: 0.4054
Batch 40, Loss: 0.3884
Batch 50, Loss: 0.3847
Batch 60, Loss: 0.3794
Batch 70, Loss: 0.4201
Batch 80, Loss: 0.3926
Batch 90, Loss: 0.3672
Batch 100, Loss: 0.3827
Batch 110, Loss: 0.3875
Batch 120, Loss: 0.4180
Batch 130, Loss: 0.3796
Batch 140, Loss: 0.3862
Batch 150, Loss: 0.4015
Batch 160, Loss: 0.3878
Batch 170, Loss: 0.3899
Batch 180, Loss: 0.3827
Batch 190, Loss: 0.4129
Batch 200, Loss: 0.3471
Batch 210, Loss: 0.4171
Batch 220, Loss: 0.3551
Batch 230, Loss: 0.3647
Batch 240, Loss: 0.3713
Batch 250, Loss: 0.3942
Batch 260, Loss: 0.3957
Batch 270, Loss: 0.3889
Batch 280, Loss: 0.3901
Batch 290, Loss: 0.4053
Batch 300, Loss: 0.4074
Batch 310, Loss: 0.3845
Batch 320, Loss: 0.3766
Batch 330, Loss: 0.4027
Batch 340, Loss: 0.3884
Batch 350, Loss: 0.3727
Batch 360, Loss: 0.3780
Batch 370, Loss: 0.3849
Batch 380, Loss: 0.4094
Batch 390, Loss: 0.3862
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.52310085296631 seconds
Epoch 115 accuracy: 90.7%
Batch 10, Loss: 0.4039
Batch 20, Loss: 0.4161
Batch 30, Loss: 0.4234
Batch 40, Loss: 0.3857
Batch 50, Loss: 0.4413
Batch 60, Loss: 0.3945
Batch 70, Loss: 0.3921
Batch 80, Loss: 0.4031
Batch 90, Loss: 0.3898
Batch 100, Loss: 0.3895
Batch 110, Loss: 0.3644
Batch 120, Loss: 0.3912
Batch 130, Loss: 0.3760
Batch 140, Loss: 0.3483
Batch 150, Loss: 0.3851
Batch 160, Loss: 0.3612
Batch 170, Loss: 0.3745
Batch 180, Loss: 0.4134
Batch 190, Loss: 0.3911
Batch 200, Loss: 0.4049
Batch 210, Loss: 0.3893
Batch 220, Loss: 0.3477
Batch 230, Loss: 0.3934
Batch 240, Loss: 0.4144
Batch 250, Loss: 0.4406
Batch 260, Loss: 0.3890
Batch 270, Loss: 0.3678
Batch 280, Loss: 0.3903
Batch 290, Loss: 0.3797
Batch 300, Loss: 0.3781
Batch 310, Loss: 0.4119
Batch 320, Loss: 0.3719
Batch 330, Loss: 0.4345
Batch 340, Loss: 0.4362
Batch 350, Loss: 0.3710
Batch 360, Loss: 0.3933
Batch 370, Loss: 0.4175
Batch 380, Loss: 0.4094
Batch 390, Loss: 0.3902
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.59360122680664 seconds
Epoch 116 accuracy: 90.92%
Batch 10, Loss: 0.3785
Batch 20, Loss: 0.3959
Batch 30, Loss: 0.3812
Batch 40, Loss: 0.3610
Batch 50, Loss: 0.4002
Batch 60, Loss: 0.3774
Batch 70, Loss: 0.3758
Batch 80, Loss: 0.3674
Batch 90, Loss: 0.4252
Batch 100, Loss: 0.3846
Batch 110, Loss: 0.4036
Batch 120, Loss: 0.3936
Batch 130, Loss: 0.4167
Batch 140, Loss: 0.4068
Batch 150, Loss: 0.4140
Batch 160, Loss: 0.3788
Batch 170, Loss: 0.3669
Batch 180, Loss: 0.3929
Batch 190, Loss: 0.3834
Batch 200, Loss: 0.3782
Batch 210, Loss: 0.4057
Batch 220, Loss: 0.3988
Batch 230, Loss: 0.4180
Batch 240, Loss: 0.4047
Batch 250, Loss: 0.3626
Batch 260, Loss: 0.3848
Batch 270, Loss: 0.3818
Batch 280, Loss: 0.4104
Batch 290, Loss: 0.3733
Batch 300, Loss: 0.3966
Batch 310, Loss: 0.3910
Batch 320, Loss: 0.4224
Batch 330, Loss: 0.3846
Batch 340, Loss: 0.3952
Batch 350, Loss: 0.3984
Batch 360, Loss: 0.3892
Batch 370, Loss: 0.4040
Batch 380, Loss: 0.4298
Batch 390, Loss: 0.4031
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.554232597351074 seconds
Epoch 117 accuracy: 90.83%
Batch 10, Loss: 0.3816
Batch 20, Loss: 0.3693
Batch 30, Loss: 0.4019
Batch 40, Loss: 0.3658
Batch 50, Loss: 0.4155
Batch 60, Loss: 0.4041
Batch 70, Loss: 0.3411
Batch 80, Loss: 0.3602
Batch 90, Loss: 0.4062
Batch 100, Loss: 0.3602
Batch 110, Loss: 0.3781
Batch 120, Loss: 0.3769
Batch 130, Loss: 0.3981
Batch 140, Loss: 0.3548
Batch 150, Loss: 0.3922
Batch 160, Loss: 0.3968
Batch 170, Loss: 0.4006
Batch 180, Loss: 0.4253
Batch 190, Loss: 0.3999
Batch 200, Loss: 0.4217
Batch 210, Loss: 0.4280
Batch 220, Loss: 0.4110
Batch 230, Loss: 0.4102
Batch 240, Loss: 0.4268
Batch 250, Loss: 0.4224
Batch 260, Loss: 0.3706
Batch 270, Loss: 0.3990
Batch 280, Loss: 0.3916
Batch 290, Loss: 0.3540
Batch 300, Loss: 0.3648
Batch 310, Loss: 0.3871
Batch 320, Loss: 0.3652
Batch 330, Loss: 0.3710
Batch 340, Loss: 0.3955
Batch 350, Loss: 0.3802
Batch 360, Loss: 0.3972
Batch 370, Loss: 0.3985
Batch 380, Loss: 0.3840
Batch 390, Loss: 0.3906
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.43155860900879 seconds
Epoch 118 accuracy: 89.88%
Batch 10, Loss: 0.3915
Batch 20, Loss: 0.3872
Batch 30, Loss: 0.3619
Batch 40, Loss: 0.3708
Batch 50, Loss: 0.3974
Batch 60, Loss: 0.3663
Batch 70, Loss: 0.3638
Batch 80, Loss: 0.3332
Batch 90, Loss: 0.4154
Batch 100, Loss: 0.4075
Batch 110, Loss: 0.3429
Batch 120, Loss: 0.3526
Batch 130, Loss: 0.3666
Batch 140, Loss: 0.3650
Batch 150, Loss: 0.4178
Batch 160, Loss: 0.4059
Batch 170, Loss: 0.4062
Batch 180, Loss: 0.3758
Batch 190, Loss: 0.3976
Batch 200, Loss: 0.3927
Batch 210, Loss: 0.3968
Batch 220, Loss: 0.3809
Batch 230, Loss: 0.3395
Batch 240, Loss: 0.3830
Batch 250, Loss: 0.3989
Batch 260, Loss: 0.3917
Batch 270, Loss: 0.4275
Batch 280, Loss: 0.4051
Batch 290, Loss: 0.3942
Batch 300, Loss: 0.3427
Batch 310, Loss: 0.3699
Batch 320, Loss: 0.3757
Batch 330, Loss: 0.3909
Batch 340, Loss: 0.3638
Batch 350, Loss: 0.3712
Batch 360, Loss: 0.3820
Batch 370, Loss: 0.4000
Batch 380, Loss: 0.3575
Batch 390, Loss: 0.3811
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.512750387191772 seconds
Epoch 119 accuracy: 89.64%
Batch 10, Loss: 0.3935
Batch 20, Loss: 0.3801
Batch 30, Loss: 0.3972
Batch 40, Loss: 0.3900
Batch 50, Loss: 0.3872
Batch 60, Loss: 0.3816
Batch 70, Loss: 0.3689
Batch 80, Loss: 0.3818
Batch 90, Loss: 0.3686
Batch 100, Loss: 0.3733
Batch 110, Loss: 0.3575
Batch 120, Loss: 0.4018
Batch 130, Loss: 0.3909
Batch 140, Loss: 0.3704
Batch 150, Loss: 0.3771
Batch 160, Loss: 0.3401
Batch 170, Loss: 0.3680
Batch 180, Loss: 0.3940
Batch 190, Loss: 0.3748
Batch 200, Loss: 0.3452
Batch 210, Loss: 0.3867
Batch 220, Loss: 0.4001
Batch 230, Loss: 0.3999
Batch 240, Loss: 0.3903
Batch 250, Loss: 0.3507
Batch 260, Loss: 0.3513
Batch 270, Loss: 0.3838
Batch 280, Loss: 0.3740
Batch 290, Loss: 0.3685
Batch 300, Loss: 0.3537
Batch 310, Loss: 0.3842
Batch 320, Loss: 0.3933
Batch 330, Loss: 0.4302
Batch 340, Loss: 0.4236
Batch 350, Loss: 0.3643
Batch 360, Loss: 0.3749
Batch 370, Loss: 0.3586
Batch 380, Loss: 0.3805
Batch 390, Loss: 0.3621
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.572009801864624 seconds
Epoch 120 accuracy: 88.76%
Batch 10, Loss: 0.3860
Batch 20, Loss: 0.3518
Batch 30, Loss: 0.3661
Batch 40, Loss: 0.4004
Batch 50, Loss: 0.3629
Batch 60, Loss: 0.3464
Batch 70, Loss: 0.3837
Batch 80, Loss: 0.3720
Batch 90, Loss: 0.3359
Batch 100, Loss: 0.3825
Batch 110, Loss: 0.3568
Batch 120, Loss: 0.3890
Batch 130, Loss: 0.3772
Batch 140, Loss: 0.3559
Batch 150, Loss: 0.3710
Batch 160, Loss: 0.3805
Batch 170, Loss: 0.3573
Batch 180, Loss: 0.3872
Batch 190, Loss: 0.3820
Batch 200, Loss: 0.3841
Batch 210, Loss: 0.3851
Batch 220, Loss: 0.3615
Batch 230, Loss: 0.3794
Batch 240, Loss: 0.3712
Batch 250, Loss: 0.3409
Batch 260, Loss: 0.3749
Batch 270, Loss: 0.3704
Batch 280, Loss: 0.3756
Batch 290, Loss: 0.3776
Batch 300, Loss: 0.3670
Batch 310, Loss: 0.3586
Batch 320, Loss: 0.3608
Batch 330, Loss: 0.3775
Batch 340, Loss: 0.3714
Batch 350, Loss: 0.3661
Batch 360, Loss: 0.3973
Batch 370, Loss: 0.3888
Batch 380, Loss: 0.4048
Batch 390, Loss: 0.3880
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.562857151031494 seconds
Epoch 121 accuracy: 88.38%
Batch 10, Loss: 0.3775
Batch 20, Loss: 0.3640
Batch 30, Loss: 0.3795
Batch 40, Loss: 0.3787
Batch 50, Loss: 0.3933
Batch 60, Loss: 0.4120
Batch 70, Loss: 0.3497
Batch 80, Loss: 0.3684
Batch 90, Loss: 0.3883
Batch 100, Loss: 0.3824
Batch 110, Loss: 0.3867
Batch 120, Loss: 0.3857
Batch 130, Loss: 0.3698
Batch 140, Loss: 0.3943
Batch 150, Loss: 0.3696
Batch 160, Loss: 0.3403
Batch 170, Loss: 0.3471
Batch 180, Loss: 0.3582
Batch 190, Loss: 0.3697
Batch 200, Loss: 0.3588
Batch 210, Loss: 0.4109
Batch 220, Loss: 0.3573
Batch 230, Loss: 0.3855
Batch 240, Loss: 0.3490
Batch 250, Loss: 0.3621
Batch 260, Loss: 0.4002
Batch 270, Loss: 0.3413
Batch 280, Loss: 0.4096
Batch 290, Loss: 0.3729
Batch 300, Loss: 0.3672
Batch 310, Loss: 0.3901
Batch 320, Loss: 0.3628
Batch 330, Loss: 0.3592
Batch 340, Loss: 0.3507
Batch 350, Loss: 0.3963
Batch 360, Loss: 0.3647
Batch 370, Loss: 0.4082
Batch 380, Loss: 0.3742
Batch 390, Loss: 0.3931
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.503766536712646 seconds
Epoch 122 accuracy: 91.0%
Batch 10, Loss: 0.3947
Batch 20, Loss: 0.3744
Batch 30, Loss: 0.3634
Batch 40, Loss: 0.3610
Batch 50, Loss: 0.3742
Batch 60, Loss: 0.3718
Batch 70, Loss: 0.3738
Batch 80, Loss: 0.4182
Batch 90, Loss: 0.3777
Batch 100, Loss: 0.3744
Batch 110, Loss: 0.3408
Batch 120, Loss: 0.3767
Batch 130, Loss: 0.3706
Batch 140, Loss: 0.3676
Batch 150, Loss: 0.3753
Batch 160, Loss: 0.3962
Batch 170, Loss: 0.3902
Batch 180, Loss: 0.3851
Batch 190, Loss: 0.3464
Batch 200, Loss: 0.3493
Batch 210, Loss: 0.3449
Batch 220, Loss: 0.3831
Batch 230, Loss: 0.3792
Batch 240, Loss: 0.3653
Batch 250, Loss: 0.3873
Batch 260, Loss: 0.3426
Batch 270, Loss: 0.3902
Batch 280, Loss: 0.3590
Batch 290, Loss: 0.3431
Batch 300, Loss: 0.3675
Batch 310, Loss: 0.3464
Batch 320, Loss: 0.3933
Batch 330, Loss: 0.3512
Batch 340, Loss: 0.4031
Batch 350, Loss: 0.3972
Batch 360, Loss: 0.3715
Batch 370, Loss: 0.3751
Batch 380, Loss: 0.3820
Batch 390, Loss: 0.3806
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.306705951690674 seconds
Epoch 123 accuracy: 90.84%
Batch 10, Loss: 0.4069
Batch 20, Loss: 0.3891
Batch 30, Loss: 0.4149
Batch 40, Loss: 0.3376
Batch 50, Loss: 0.3560
Batch 60, Loss: 0.3483
Batch 70, Loss: 0.3733
Batch 80, Loss: 0.3801
Batch 90, Loss: 0.3676
Batch 100, Loss: 0.3562
Batch 110, Loss: 0.3385
Batch 120, Loss: 0.3874
Batch 130, Loss: 0.3464
Batch 140, Loss: 0.3546
Batch 150, Loss: 0.3132
Batch 160, Loss: 0.3692
Batch 170, Loss: 0.3873
Batch 180, Loss: 0.3592
Batch 190, Loss: 0.3952
Batch 200, Loss: 0.3580
Batch 210, Loss: 0.3506
Batch 220, Loss: 0.3347
Batch 230, Loss: 0.3831
Batch 240, Loss: 0.3801
Batch 250, Loss: 0.3502
Batch 260, Loss: 0.4119
Batch 270, Loss: 0.3701
Batch 280, Loss: 0.3649
Batch 290, Loss: 0.3951
Batch 300, Loss: 0.3544
Batch 310, Loss: 0.3813
Batch 320, Loss: 0.3548
Batch 330, Loss: 0.3764
Batch 340, Loss: 0.3895
Batch 350, Loss: 0.3979
Batch 360, Loss: 0.3669
Batch 370, Loss: 0.3553
Batch 380, Loss: 0.3726
Batch 390, Loss: 0.3898
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.211454391479492 seconds
Epoch 124 accuracy: 90.98%
Batch 10, Loss: 0.3498
Batch 20, Loss: 0.3314
Batch 30, Loss: 0.3616
Batch 40, Loss: 0.3351
Batch 50, Loss: 0.3568
Batch 60, Loss: 0.3218
Batch 70, Loss: 0.3475
Batch 80, Loss: 0.3669
Batch 90, Loss: 0.3950
Batch 100, Loss: 0.3485
Batch 110, Loss: 0.3659
Batch 120, Loss: 0.3781
Batch 130, Loss: 0.3599
Batch 140, Loss: 0.3932
Batch 150, Loss: 0.3622
Batch 160, Loss: 0.3708
Batch 170, Loss: 0.3516
Batch 180, Loss: 0.3774
Batch 190, Loss: 0.3940
Batch 200, Loss: 0.3837
Batch 210, Loss: 0.3488
Batch 220, Loss: 0.3663
Batch 230, Loss: 0.3521
Batch 240, Loss: 0.3595
Batch 250, Loss: 0.3384
Batch 260, Loss: 0.3609
Batch 270, Loss: 0.3651
Batch 280, Loss: 0.3891
Batch 290, Loss: 0.3615
Batch 300, Loss: 0.3471
Batch 310, Loss: 0.3764
Batch 320, Loss: 0.3603
Batch 330, Loss: 0.3567
Batch 340, Loss: 0.3749
Batch 350, Loss: 0.3472
Batch 360, Loss: 0.3411
Batch 370, Loss: 0.3523
Batch 380, Loss: 0.3458
Batch 390, Loss: 0.3580
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.23560905456543 seconds
Epoch 125 accuracy: 90.83%
Batch 10, Loss: 0.3631
Batch 20, Loss: 0.3682
Batch 30, Loss: 0.3552
Batch 40, Loss: 0.3553
Batch 50, Loss: 0.3577
Batch 60, Loss: 0.3738
Batch 70, Loss: 0.3714
Batch 80, Loss: 0.3608
Batch 90, Loss: 0.3541
Batch 100, Loss: 0.3679
Batch 110, Loss: 0.3516
Batch 120, Loss: 0.3637
Batch 130, Loss: 0.3570
Batch 140, Loss: 0.3480
Batch 150, Loss: 0.3889
Batch 160, Loss: 0.3470
Batch 170, Loss: 0.4135
Batch 180, Loss: 0.3832
Batch 190, Loss: 0.3671
Batch 200, Loss: 0.3684
Batch 210, Loss: 0.3975
Batch 220, Loss: 0.3621
Batch 230, Loss: 0.3403
Batch 240, Loss: 0.3423
Batch 250, Loss: 0.3544
Batch 260, Loss: 0.3744
Batch 270, Loss: 0.3718
Batch 280, Loss: 0.3623
Batch 290, Loss: 0.3511
Batch 300, Loss: 0.3554
Batch 310, Loss: 0.3481
Batch 320, Loss: 0.3596
Batch 330, Loss: 0.3463
Batch 340, Loss: 0.3730
Batch 350, Loss: 0.3687
Batch 360, Loss: 0.3418
Batch 370, Loss: 0.3490
Batch 380, Loss: 0.3409
Batch 390, Loss: 0.3739
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.231891870498657 seconds
Epoch 126 accuracy: 89.86%
Batch 10, Loss: 0.3681
Batch 20, Loss: 0.3373
Batch 30, Loss: 0.3564
Batch 40, Loss: 0.3351
Batch 50, Loss: 0.3155
Batch 60, Loss: 0.3420
Batch 70, Loss: 0.3269
Batch 80, Loss: 0.3375
Batch 90, Loss: 0.3508
Batch 100, Loss: 0.3760
Batch 110, Loss: 0.3659
Batch 120, Loss: 0.3593
Batch 130, Loss: 0.3672
Batch 140, Loss: 0.3774
Batch 150, Loss: 0.3418
Batch 160, Loss: 0.3495
Batch 170, Loss: 0.3612
Batch 180, Loss: 0.3678
Batch 190, Loss: 0.3467
Batch 200, Loss: 0.3629
Batch 210, Loss: 0.3804
Batch 220, Loss: 0.3242
Batch 230, Loss: 0.3891
Batch 240, Loss: 0.3667
Batch 250, Loss: 0.3511
Batch 260, Loss: 0.3764
Batch 270, Loss: 0.3676
Batch 280, Loss: 0.3605
Batch 290, Loss: 0.3627
Batch 300, Loss: 0.3611
Batch 310, Loss: 0.3800
Batch 320, Loss: 0.3679
Batch 330, Loss: 0.3506
Batch 340, Loss: 0.3682
Batch 350, Loss: 0.3453
Batch 360, Loss: 0.3809
Batch 370, Loss: 0.3566
Batch 380, Loss: 0.3926
Batch 390, Loss: 0.3698
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.203941345214844 seconds
Epoch 127 accuracy: 91.05%
Batch 10, Loss: 0.3631
Batch 20, Loss: 0.3643
Batch 30, Loss: 0.3659
Batch 40, Loss: 0.3259
Batch 50, Loss: 0.3691
Batch 60, Loss: 0.3703
Batch 70, Loss: 0.4040
Batch 80, Loss: 0.3371
Batch 90, Loss: 0.3642
Batch 100, Loss: 0.3384
Batch 110, Loss: 0.3552
Batch 120, Loss: 0.3682
Batch 130, Loss: 0.3843
Batch 140, Loss: 0.3633
Batch 150, Loss: 0.3451
Batch 160, Loss: 0.3285
Batch 170, Loss: 0.3304
Batch 180, Loss: 0.3672
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.3604
Batch 210, Loss: 0.3509
Batch 220, Loss: 0.3545
Batch 230, Loss: 0.3691
Batch 240, Loss: 0.3329
Batch 250, Loss: 0.3717
Batch 260, Loss: 0.3369
Batch 270, Loss: 0.3714
Batch 280, Loss: 0.3898
Batch 290, Loss: 0.3908
Batch 300, Loss: 0.3829
Batch 310, Loss: 0.3338
Batch 320, Loss: 0.3518
Batch 330, Loss: 0.3472
Batch 340, Loss: 0.3509
Batch 350, Loss: 0.3523
Batch 360, Loss: 0.3411
Batch 370, Loss: 0.3520
Batch 380, Loss: 0.3995
Batch 390, Loss: 0.3525
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.179213523864746 seconds
Epoch 128 accuracy: 91.1%
Batch 10, Loss: 0.3609
Batch 20, Loss: 0.3694
Batch 30, Loss: 0.3123
Batch 40, Loss: 0.3328
Batch 50, Loss: 0.3095
Batch 60, Loss: 0.3379
Batch 70, Loss: 0.3611
Batch 80, Loss: 0.3533
Batch 90, Loss: 0.3572
Batch 100, Loss: 0.3507
Batch 110, Loss: 0.3640
Batch 120, Loss: 0.3495
Batch 130, Loss: 0.3551
Batch 140, Loss: 0.3224
Batch 150, Loss: 0.3357
Batch 160, Loss: 0.3235
Batch 170, Loss: 0.3420
Batch 180, Loss: 0.3705
Batch 190, Loss: 0.3437
Batch 200, Loss: 0.3496
Batch 210, Loss: 0.3312
Batch 220, Loss: 0.3710
Batch 230, Loss: 0.3325
Batch 240, Loss: 0.3033
Batch 250, Loss: 0.3769
Batch 260, Loss: 0.3163
Batch 270, Loss: 0.3264
Batch 280, Loss: 0.3595
Batch 290, Loss: 0.3607
Batch 300, Loss: 0.3563
Batch 310, Loss: 0.3402
Batch 320, Loss: 0.3944
Batch 330, Loss: 0.3388
Batch 340, Loss: 0.3492
Batch 350, Loss: 0.3477
Batch 360, Loss: 0.3720
Batch 370, Loss: 0.3763
Batch 380, Loss: 0.3839
Batch 390, Loss: 0.3618
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.14694309234619 seconds
Epoch 129 accuracy: 91.16%
Batch 10, Loss: 0.3760
Batch 20, Loss: 0.3344
Batch 30, Loss: 0.3420
Batch 40, Loss: 0.3540
Batch 50, Loss: 0.3432
Batch 60, Loss: 0.3310
Batch 70, Loss: 0.3622
Batch 80, Loss: 0.3485
Batch 90, Loss: 0.3405
Batch 100, Loss: 0.3276
Batch 110, Loss: 0.3613
Batch 120, Loss: 0.3388
Batch 130, Loss: 0.3579
Batch 140, Loss: 0.3302
Batch 150, Loss: 0.3425
Batch 160, Loss: 0.3669
Batch 170, Loss: 0.3463
Batch 180, Loss: 0.3768
Batch 190, Loss: 0.2953
Batch 200, Loss: 0.3581
Batch 210, Loss: 0.3717
Batch 220, Loss: 0.3299
Batch 230, Loss: 0.3485
Batch 240, Loss: 0.3748
Batch 250, Loss: 0.3521
Batch 260, Loss: 0.3188
Batch 270, Loss: 0.3306
Batch 280, Loss: 0.3537
Batch 290, Loss: 0.3594
Batch 300, Loss: 0.3655
Batch 310, Loss: 0.3390
Batch 320, Loss: 0.3621
Batch 330, Loss: 0.3414
Batch 340, Loss: 0.3646
Batch 350, Loss: 0.3474
Batch 360, Loss: 0.3396
Batch 370, Loss: 0.3578
Batch 380, Loss: 0.3794
Batch 390, Loss: 0.3605
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.238413095474243 seconds
Epoch 130 accuracy: 91.22%
Batch 10, Loss: 0.3219
Batch 20, Loss: 0.3528
Batch 30, Loss: 0.3392
Batch 40, Loss: 0.2979
Batch 50, Loss: 0.3298
Batch 60, Loss: 0.3851
Batch 70, Loss: 0.3158
Batch 80, Loss: 0.3373
Batch 90, Loss: 0.3510
Batch 100, Loss: 0.3514
Batch 110, Loss: 0.3216
Batch 120, Loss: 0.3501
Batch 130, Loss: 0.3489
Batch 140, Loss: 0.3586
Batch 150, Loss: 0.3470
Batch 160, Loss: 0.3487
Batch 170, Loss: 0.3519
Batch 180, Loss: 0.3512
Batch 190, Loss: 0.3216
Batch 200, Loss: 0.3909
Batch 210, Loss: 0.3173
Batch 220, Loss: 0.3595
Batch 230, Loss: 0.3455
Batch 240, Loss: 0.3412
Batch 250, Loss: 0.3773
Batch 260, Loss: 0.3355
Batch 270, Loss: 0.3282
Batch 280, Loss: 0.3696
Batch 290, Loss: 0.3653
Batch 300, Loss: 0.3021
Batch 310, Loss: 0.3583
Batch 320, Loss: 0.3373
Batch 330, Loss: 0.3293
Batch 340, Loss: 0.3416
Batch 350, Loss: 0.3492
Batch 360, Loss: 0.3029
Batch 370, Loss: 0.3327
Batch 380, Loss: 0.3479
Batch 390, Loss: 0.3454
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.242058515548706 seconds
Epoch 131 accuracy: 91.05%
Batch 10, Loss: 0.3480
Batch 20, Loss: 0.3691
Batch 30, Loss: 0.3505
Batch 40, Loss: 0.3442
Batch 50, Loss: 0.3821
Batch 60, Loss: 0.3526
Batch 70, Loss: 0.3265
Batch 80, Loss: 0.3265
Batch 90, Loss: 0.3309
Batch 100, Loss: 0.3550
Batch 110, Loss: 0.3652
Batch 120, Loss: 0.3084
Batch 130, Loss: 0.3351
Batch 140, Loss: 0.3427
Batch 150, Loss: 0.3561
Batch 160, Loss: 0.3519
Batch 170, Loss: 0.3698
Batch 180, Loss: 0.3237
Batch 190, Loss: 0.3822
Batch 200, Loss: 0.3272
Batch 210, Loss: 0.3164
Batch 220, Loss: 0.3385
Batch 230, Loss: 0.3522
Batch 240, Loss: 0.3640
Batch 250, Loss: 0.3655
Batch 260, Loss: 0.3559
Batch 270, Loss: 0.3348
Batch 280, Loss: 0.3443
Batch 290, Loss: 0.3754
Batch 300, Loss: 0.3436
Batch 310, Loss: 0.3462
Batch 320, Loss: 0.3590
Batch 330, Loss: 0.3465
Batch 340, Loss: 0.3228
Batch 350, Loss: 0.3307
Batch 360, Loss: 0.3585
Batch 370, Loss: 0.3542
Batch 380, Loss: 0.3757
Batch 390, Loss: 0.3389
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.24045705795288 seconds
Epoch 132 accuracy: 90.73%
Batch 10, Loss: 0.3698
Batch 20, Loss: 0.3460
Batch 30, Loss: 0.3554
Batch 40, Loss: 0.3661
Batch 50, Loss: 0.3106
Batch 60, Loss: 0.3239
Batch 70, Loss: 0.3774
Batch 80, Loss: 0.3296
Batch 90, Loss: 0.3118
Batch 100, Loss: 0.3370
Batch 110, Loss: 0.3649
Batch 120, Loss: 0.3777
Batch 130, Loss: 0.3443
Batch 140, Loss: 0.3175
Batch 150, Loss: 0.3655
Batch 160, Loss: 0.3730
Batch 170, Loss: 0.3399
Batch 180, Loss: 0.3515
Batch 190, Loss: 0.3384
Batch 200, Loss: 0.3450
Batch 210, Loss: 0.3422
Batch 220, Loss: 0.3139
Batch 230, Loss: 0.3052
Batch 240, Loss: 0.3501
Batch 250, Loss: 0.3444
Batch 260, Loss: 0.3460
Batch 270, Loss: 0.3542
Batch 280, Loss: 0.3465
Batch 290, Loss: 0.3306
Batch 300, Loss: 0.3233
Batch 310, Loss: 0.3528
Batch 320, Loss: 0.3414
Batch 330, Loss: 0.3698
Batch 340, Loss: 0.3549
Batch 350, Loss: 0.3567
Batch 360, Loss: 0.3670
Batch 370, Loss: 0.3487
Batch 380, Loss: 0.3650
Batch 390, Loss: 0.3747
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.12225031852722 seconds
Epoch 133 accuracy: 92.88%
Batch 10, Loss: 0.3256
Batch 20, Loss: 0.3085
Batch 30, Loss: 0.3326
Batch 40, Loss: 0.3452
Batch 50, Loss: 0.3324
Batch 60, Loss: 0.3693
Batch 70, Loss: 0.3335
Batch 80, Loss: 0.3078
Batch 90, Loss: 0.3368
Batch 100, Loss: 0.3394
Batch 110, Loss: 0.3336
Batch 120, Loss: 0.3532
Batch 130, Loss: 0.3393
Batch 140, Loss: 0.3574
Batch 150, Loss: 0.3201
Batch 160, Loss: 0.3084
Batch 170, Loss: 0.3434
Batch 180, Loss: 0.3376
Batch 190, Loss: 0.3615
Batch 200, Loss: 0.3089
Batch 210, Loss: 0.3437
Batch 220, Loss: 0.3274
Batch 230, Loss: 0.3284
Batch 240, Loss: 0.3138
Batch 250, Loss: 0.3574
Batch 260, Loss: 0.3150
Batch 270, Loss: 0.3767
Batch 280, Loss: 0.3400
Batch 290, Loss: 0.3599
Batch 300, Loss: 0.3546
Batch 310, Loss: 0.3373
Batch 320, Loss: 0.3456
Batch 330, Loss: 0.3366
Batch 340, Loss: 0.3367
Batch 350, Loss: 0.3517
Batch 360, Loss: 0.2943
Batch 370, Loss: 0.3042
Batch 380, Loss: 0.3009
Batch 390, Loss: 0.3276
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.202129364013672 seconds
Epoch 134 accuracy: 92.4%
Batch 10, Loss: 0.3293
Batch 20, Loss: 0.3408
Batch 30, Loss: 0.3450
Batch 40, Loss: 0.2946
Batch 50, Loss: 0.3445
Batch 60, Loss: 0.3206
Batch 70, Loss: 0.3450
Batch 80, Loss: 0.3297
Batch 90, Loss: 0.3125
Batch 100, Loss: 0.3643
Batch 110, Loss: 0.3493
Batch 120, Loss: 0.3427
Batch 130, Loss: 0.3562
Batch 140, Loss: 0.3400
Batch 150, Loss: 0.3434
Batch 160, Loss: 0.3144
Batch 170, Loss: 0.3091
Batch 180, Loss: 0.3390
Batch 190, Loss: 0.3384
Batch 200, Loss: 0.3501
Batch 210, Loss: 0.3283
Batch 220, Loss: 0.3170
Batch 230, Loss: 0.2999
Batch 240, Loss: 0.3513
Batch 250, Loss: 0.3441
Batch 260, Loss: 0.3383
Batch 270, Loss: 0.3140
Batch 280, Loss: 0.3563
Batch 290, Loss: 0.3207
Batch 300, Loss: 0.3432
Batch 310, Loss: 0.3197
Batch 320, Loss: 0.3101
Batch 330, Loss: 0.3721
Batch 340, Loss: 0.3438
Batch 350, Loss: 0.3164
Batch 360, Loss: 0.3631
Batch 370, Loss: 0.3617
Batch 380, Loss: 0.3601
Batch 390, Loss: 0.3130
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.18936252593994 seconds
Epoch 135 accuracy: 92.47%
Batch 10, Loss: 0.3072
Batch 20, Loss: 0.3046
Batch 30, Loss: 0.3632
Batch 40, Loss: 0.3187
Batch 50, Loss: 0.3211
Batch 60, Loss: 0.3134
Batch 70, Loss: 0.3263
Batch 80, Loss: 0.3294
Batch 90, Loss: 0.3399
Batch 100, Loss: 0.3247
Batch 110, Loss: 0.3471
Batch 120, Loss: 0.3166
Batch 130, Loss: 0.3308
Batch 140, Loss: 0.3172
Batch 150, Loss: 0.3266
Batch 160, Loss: 0.3445
Batch 170, Loss: 0.3450
Batch 180, Loss: 0.3563
Batch 190, Loss: 0.3202
Batch 200, Loss: 0.3120
Batch 210, Loss: 0.3216
Batch 220, Loss: 0.3093
Batch 230, Loss: 0.3474
Batch 240, Loss: 0.3479
Batch 250, Loss: 0.3185
Batch 260, Loss: 0.3600
Batch 270, Loss: 0.3136
Batch 280, Loss: 0.3212
Batch 290, Loss: 0.2986
Batch 300, Loss: 0.3357
Batch 310, Loss: 0.3436
Batch 320, Loss: 0.3262
Batch 330, Loss: 0.3457
Batch 340, Loss: 0.3124
Batch 350, Loss: 0.3457
Batch 360, Loss: 0.3258
Batch 370, Loss: 0.3274
Batch 380, Loss: 0.3612
Batch 390, Loss: 0.3373
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.20571255683899 seconds
Epoch 136 accuracy: 91.03%
Batch 10, Loss: 0.2945
Batch 20, Loss: 0.2784
Batch 30, Loss: 0.3226
Batch 40, Loss: 0.3369
Batch 50, Loss: 0.3333
Batch 60, Loss: 0.3351
Batch 70, Loss: 0.3284
Batch 80, Loss: 0.3052
Batch 90, Loss: 0.3121
Batch 100, Loss: 0.3335
Batch 110, Loss: 0.3335
Batch 120, Loss: 0.3335
Batch 130, Loss: 0.3223
Batch 140, Loss: 0.3224
Batch 150, Loss: 0.3590
Batch 160, Loss: 0.3089
Batch 170, Loss: 0.3854
Batch 180, Loss: 0.3591
Batch 190, Loss: 0.3315
Batch 200, Loss: 0.3586
Batch 210, Loss: 0.3459
Batch 220, Loss: 0.3298
Batch 230, Loss: 0.3204
Batch 240, Loss: 0.3495
Batch 250, Loss: 0.3256
Batch 260, Loss: 0.3387
Batch 270, Loss: 0.3278
Batch 280, Loss: 0.3209
Batch 290, Loss: 0.3255
Batch 300, Loss: 0.2985
Batch 310, Loss: 0.3261
Batch 320, Loss: 0.3750
Batch 330, Loss: 0.3166
Batch 340, Loss: 0.3128
Batch 350, Loss: 0.3277
Batch 360, Loss: 0.3066
Batch 370, Loss: 0.3011
Batch 380, Loss: 0.3251
Batch 390, Loss: 0.3700
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.26904821395874 seconds
Epoch 137 accuracy: 92.51%
Batch 10, Loss: 0.2913
Batch 20, Loss: 0.3159
Batch 30, Loss: 0.3197
Batch 40, Loss: 0.3267
Batch 50, Loss: 0.2990
Batch 60, Loss: 0.3239
Batch 70, Loss: 0.3208
Batch 80, Loss: 0.3044
Batch 90, Loss: 0.3455
Batch 100, Loss: 0.3392
Batch 110, Loss: 0.3278
Batch 120, Loss: 0.3549
Batch 130, Loss: 0.3380
Batch 140, Loss: 0.3296
Batch 150, Loss: 0.3279
Batch 160, Loss: 0.2853
Batch 170, Loss: 0.3343
Batch 180, Loss: 0.3345
Batch 190, Loss: 0.3320
Batch 200, Loss: 0.3267
Batch 210, Loss: 0.3126
Batch 220, Loss: 0.2894
Batch 230, Loss: 0.3278
Batch 240, Loss: 0.3068
Batch 250, Loss: 0.2946
Batch 260, Loss: 0.3267
Batch 270, Loss: 0.3370
Batch 280, Loss: 0.3214
Batch 290, Loss: 0.3047
Batch 300, Loss: 0.2914
Batch 310, Loss: 0.3266
Batch 320, Loss: 0.3084
Batch 330, Loss: 0.3147
Batch 340, Loss: 0.3250
Batch 350, Loss: 0.3637
Batch 360, Loss: 0.3531
Batch 370, Loss: 0.3140
Batch 380, Loss: 0.3562
Batch 390, Loss: 0.3398
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.23655652999878 seconds
Epoch 138 accuracy: 92.3%
Batch 10, Loss: 0.3371
Batch 20, Loss: 0.3233
Batch 30, Loss: 0.3156
Batch 40, Loss: 0.3000
Batch 50, Loss: 0.3013
Batch 60, Loss: 0.2969
Batch 70, Loss: 0.3322
Batch 80, Loss: 0.2820
Batch 90, Loss: 0.2849
Batch 100, Loss: 0.2792
Batch 110, Loss: 0.3122
Batch 120, Loss: 0.3517
Batch 130, Loss: 0.3092
Batch 140, Loss: 0.3342
Batch 150, Loss: 0.3452
Batch 160, Loss: 0.3092
Batch 170, Loss: 0.3535
Batch 180, Loss: 0.3132
Batch 190, Loss: 0.3365
Batch 200, Loss: 0.3499
Batch 210, Loss: 0.3244
Batch 220, Loss: 0.2985
Batch 230, Loss: 0.3479
Batch 240, Loss: 0.3207
Batch 250, Loss: 0.3229
Batch 260, Loss: 0.3370
Batch 270, Loss: 0.2935
Batch 280, Loss: 0.3337
Batch 290, Loss: 0.3096
Batch 300, Loss: 0.3103
Batch 310, Loss: 0.3304
Batch 320, Loss: 0.2987
Batch 330, Loss: 0.3146
Batch 340, Loss: 0.3694
Batch 350, Loss: 0.3074
Batch 360, Loss: 0.3220
Batch 370, Loss: 0.3273
Batch 380, Loss: 0.3443
Batch 390, Loss: 0.3193
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.14702582359314 seconds
Epoch 139 accuracy: 91.64%
Batch 10, Loss: 0.3122
Batch 20, Loss: 0.3012
Batch 30, Loss: 0.3128
Batch 40, Loss: 0.3363
Batch 50, Loss: 0.3279
Batch 60, Loss: 0.3093
Batch 70, Loss: 0.3165
Batch 80, Loss: 0.3070
Batch 90, Loss: 0.3269
Batch 100, Loss: 0.2956
Batch 110, Loss: 0.3338
Batch 120, Loss: 0.3083
Batch 130, Loss: 0.3257
Batch 140, Loss: 0.3372
Batch 150, Loss: 0.3025
Batch 160, Loss: 0.3394
Batch 170, Loss: 0.3360
Batch 180, Loss: 0.2962
Batch 190, Loss: 0.3436
Batch 200, Loss: 0.3089
Batch 210, Loss: 0.3176
Batch 220, Loss: 0.3061
Batch 230, Loss: 0.3261
Batch 240, Loss: 0.3201
Batch 250, Loss: 0.3063
Batch 260, Loss: 0.3043
Batch 270, Loss: 0.3394
Batch 280, Loss: 0.3188
Batch 290, Loss: 0.3477
Batch 300, Loss: 0.3426
Batch 310, Loss: 0.3170
Batch 320, Loss: 0.3028
Batch 330, Loss: 0.3472
Batch 340, Loss: 0.3134
Batch 350, Loss: 0.3094
Batch 360, Loss: 0.3095
Batch 370, Loss: 0.3093
Batch 380, Loss: 0.3164
Batch 390, Loss: 0.3053
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.23319149017334 seconds
Epoch 140 accuracy: 92.62%
Batch 10, Loss: 0.3122
Batch 20, Loss: 0.3133
Batch 30, Loss: 0.2965
Batch 40, Loss: 0.2935
Batch 50, Loss: 0.2892
Batch 60, Loss: 0.3351
Batch 70, Loss: 0.2936
Batch 80, Loss: 0.2866
Batch 90, Loss: 0.3088
Batch 100, Loss: 0.2999
Batch 110, Loss: 0.3179
Batch 120, Loss: 0.3098
Batch 130, Loss: 0.3096
Batch 140, Loss: 0.3391
Batch 150, Loss: 0.3457
Batch 160, Loss: 0.2844
Batch 170, Loss: 0.2960
Batch 180, Loss: 0.2837
Batch 190, Loss: 0.2824
Batch 200, Loss: 0.2979
Batch 210, Loss: 0.3153
Batch 220, Loss: 0.3213
Batch 230, Loss: 0.2923
Batch 240, Loss: 0.3293
Batch 250, Loss: 0.2933
Batch 260, Loss: 0.3308
Batch 270, Loss: 0.3130
Batch 280, Loss: 0.3251
Batch 290, Loss: 0.3097
Batch 300, Loss: 0.3334
Batch 310, Loss: 0.3090
Batch 320, Loss: 0.2985
Batch 330, Loss: 0.3594
Batch 340, Loss: 0.3346
Batch 350, Loss: 0.2793
Batch 360, Loss: 0.3131
Batch 370, Loss: 0.2916
Batch 380, Loss: 0.3165
Batch 390, Loss: 0.3452
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.207964658737183 seconds
Epoch 141 accuracy: 92.77%
Batch 10, Loss: 0.2724
Batch 20, Loss: 0.3271
Batch 30, Loss: 0.3083
Batch 40, Loss: 0.3186
Batch 50, Loss: 0.2886
Batch 60, Loss: 0.3322
Batch 70, Loss: 0.3294
Batch 80, Loss: 0.2923
Batch 90, Loss: 0.3212
Batch 100, Loss: 0.3216
Batch 110, Loss: 0.3204
Batch 120, Loss: 0.3180
Batch 130, Loss: 0.2589
Batch 140, Loss: 0.3203
Batch 150, Loss: 0.3217
Batch 160, Loss: 0.3282
Batch 170, Loss: 0.3350
Batch 180, Loss: 0.2968
Batch 190, Loss: 0.2943
Batch 200, Loss: 0.3175
Batch 210, Loss: 0.3391
Batch 220, Loss: 0.3187
Batch 230, Loss: 0.2850
Batch 240, Loss: 0.3292
Batch 250, Loss: 0.3124
Batch 260, Loss: 0.3306
Batch 270, Loss: 0.3280
Batch 280, Loss: 0.3255
Batch 290, Loss: 0.3072
Batch 300, Loss: 0.3036
Batch 310, Loss: 0.3079
Batch 320, Loss: 0.3146
Batch 330, Loss: 0.3177
Batch 340, Loss: 0.3338
Batch 350, Loss: 0.3068
Batch 360, Loss: 0.2910
Batch 370, Loss: 0.3036
Batch 380, Loss: 0.3056
Batch 390, Loss: 0.3040
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.214586973190308 seconds
Epoch 142 accuracy: 92.73%
Batch 10, Loss: 0.3013
Batch 20, Loss: 0.3040
Batch 30, Loss: 0.2926
Batch 40, Loss: 0.3013
Batch 50, Loss: 0.2742
Batch 60, Loss: 0.2977
Batch 70, Loss: 0.2849
Batch 80, Loss: 0.2985
Batch 90, Loss: 0.2785
Batch 100, Loss: 0.2979
Batch 110, Loss: 0.2850
Batch 120, Loss: 0.2877
Batch 130, Loss: 0.3026
Batch 140, Loss: 0.3098
Batch 150, Loss: 0.3025
Batch 160, Loss: 0.3296
Batch 170, Loss: 0.3193
Batch 180, Loss: 0.2609
Batch 190, Loss: 0.2778
Batch 200, Loss: 0.3161
Batch 210, Loss: 0.3181
Batch 220, Loss: 0.3142
Batch 230, Loss: 0.3181
Batch 240, Loss: 0.3169
Batch 250, Loss: 0.3112
Batch 260, Loss: 0.3122
Batch 270, Loss: 0.3372
Batch 280, Loss: 0.3268
Batch 290, Loss: 0.3275
Batch 300, Loss: 0.3197
Batch 310, Loss: 0.3276
Batch 320, Loss: 0.3109
Batch 330, Loss: 0.3199
Batch 340, Loss: 0.3385
Batch 350, Loss: 0.2871
Batch 360, Loss: 0.3379
Batch 370, Loss: 0.3049
Batch 380, Loss: 0.3184
Batch 390, Loss: 0.3114
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.265379428863525 seconds
Epoch 143 accuracy: 93.26%
Batch 10, Loss: 0.3089
Batch 20, Loss: 0.2906
Batch 30, Loss: 0.2910
Batch 40, Loss: 0.2690
Batch 50, Loss: 0.2981
Batch 60, Loss: 0.3020
Batch 70, Loss: 0.2949
Batch 80, Loss: 0.2832
Batch 90, Loss: 0.3227
Batch 100, Loss: 0.3009
Batch 110, Loss: 0.2918
Batch 120, Loss: 0.2808
Batch 130, Loss: 0.2944
Batch 140, Loss: 0.2890
Batch 150, Loss: 0.2878
Batch 160, Loss: 0.2992
Batch 170, Loss: 0.3149
Batch 180, Loss: 0.2987
Batch 190, Loss: 0.2901
Batch 200, Loss: 0.2877
Batch 210, Loss: 0.2999
Batch 220, Loss: 0.3049
Batch 230, Loss: 0.3126
Batch 240, Loss: 0.2971
Batch 250, Loss: 0.2791
Batch 260, Loss: 0.2609
Batch 270, Loss: 0.2745
Batch 280, Loss: 0.3167
Batch 290, Loss: 0.2908
Batch 300, Loss: 0.3023
Batch 310, Loss: 0.3091
Batch 320, Loss: 0.3242
Batch 330, Loss: 0.3041
Batch 340, Loss: 0.3090
Batch 350, Loss: 0.2708
Batch 360, Loss: 0.3052
Batch 370, Loss: 0.3337
Batch 380, Loss: 0.2719
Batch 390, Loss: 0.3005
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.209500074386597 seconds
Epoch 144 accuracy: 93.03%
Batch 10, Loss: 0.2692
Batch 20, Loss: 0.2647
Batch 30, Loss: 0.3066
Batch 40, Loss: 0.3177
Batch 50, Loss: 0.2982
Batch 60, Loss: 0.3025
Batch 70, Loss: 0.2969
Batch 80, Loss: 0.3208
Batch 90, Loss: 0.2673
Batch 100, Loss: 0.2798
Batch 110, Loss: 0.2693
Batch 120, Loss: 0.3096
Batch 130, Loss: 0.2914
Batch 140, Loss: 0.3278
Batch 150, Loss: 0.3161
Batch 160, Loss: 0.3002
Batch 170, Loss: 0.2779
Batch 180, Loss: 0.2665
Batch 190, Loss: 0.2728
Batch 200, Loss: 0.2828
Batch 210, Loss: 0.2824
Batch 220, Loss: 0.2966
Batch 230, Loss: 0.2818
Batch 240, Loss: 0.3089
Batch 250, Loss: 0.2982
Batch 260, Loss: 0.2958
Batch 270, Loss: 0.2896
Batch 280, Loss: 0.3218
Batch 290, Loss: 0.2732
Batch 300, Loss: 0.3338
Batch 310, Loss: 0.3250
Batch 320, Loss: 0.2883
Batch 330, Loss: 0.3146
Batch 340, Loss: 0.2894
Batch 350, Loss: 0.3132
Batch 360, Loss: 0.3116
Batch 370, Loss: 0.3039
Batch 380, Loss: 0.3021
Batch 390, Loss: 0.3138
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.230470657348633 seconds
Epoch 145 accuracy: 93.37%
Batch 10, Loss: 0.2732
Batch 20, Loss: 0.3023
Batch 30, Loss: 0.3062
Batch 40, Loss: 0.3174
Batch 50, Loss: 0.3027
Batch 60, Loss: 0.2767
Batch 70, Loss: 0.2900
Batch 80, Loss: 0.3106
Batch 90, Loss: 0.3095
Batch 100, Loss: 0.2769
Batch 110, Loss: 0.2875
Batch 120, Loss: 0.2697
Batch 130, Loss: 0.3068
Batch 140, Loss: 0.3042
Batch 150, Loss: 0.2656
Batch 160, Loss: 0.2746
Batch 170, Loss: 0.2731
Batch 180, Loss: 0.2999
Batch 190, Loss: 0.3275
Batch 200, Loss: 0.3082
Batch 210, Loss: 0.2692
Batch 220, Loss: 0.2977
Batch 230, Loss: 0.2919
Batch 240, Loss: 0.2898
Batch 250, Loss: 0.2853
Batch 260, Loss: 0.2518
Batch 270, Loss: 0.2995
Batch 280, Loss: 0.2881
Batch 290, Loss: 0.2589
Batch 300, Loss: 0.3142
Batch 310, Loss: 0.2980
Batch 320, Loss: 0.2736
Batch 330, Loss: 0.2763
Batch 340, Loss: 0.2850
Batch 350, Loss: 0.2854
Batch 360, Loss: 0.3282
Batch 370, Loss: 0.2930
Batch 380, Loss: 0.3163
Batch 390, Loss: 0.3040
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.174310207366943 seconds
Epoch 146 accuracy: 92.71%
Batch 10, Loss: 0.2924
Batch 20, Loss: 0.2867
Batch 30, Loss: 0.2959
Batch 40, Loss: 0.2925
Batch 50, Loss: 0.2953
Batch 60, Loss: 0.3057
Batch 70, Loss: 0.2783
Batch 80, Loss: 0.2901
Batch 90, Loss: 0.3227
Batch 100, Loss: 0.3182
Batch 110, Loss: 0.2971
Batch 120, Loss: 0.2628
Batch 130, Loss: 0.2821
Batch 140, Loss: 0.3215
Batch 150, Loss: 0.2783
Batch 160, Loss: 0.3226
Batch 170, Loss: 0.3015
Batch 180, Loss: 0.2801
Batch 190, Loss: 0.2734
Batch 200, Loss: 0.2880
Batch 210, Loss: 0.2869
Batch 220, Loss: 0.2705
Batch 230, Loss: 0.2821
Batch 240, Loss: 0.2779
Batch 250, Loss: 0.2817
Batch 260, Loss: 0.2914
Batch 270, Loss: 0.3168
Batch 280, Loss: 0.3062
Batch 290, Loss: 0.3052
Batch 300, Loss: 0.2959
Batch 310, Loss: 0.2952
Batch 320, Loss: 0.3139
Batch 330, Loss: 0.2993
Batch 340, Loss: 0.3102
Batch 350, Loss: 0.2814
Batch 360, Loss: 0.2667
Batch 370, Loss: 0.2849
Batch 380, Loss: 0.2844
Batch 390, Loss: 0.2994
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.2673397064209 seconds
Epoch 147 accuracy: 93.33%
Batch 10, Loss: 0.3104
Batch 20, Loss: 0.3008
Batch 30, Loss: 0.3069
Batch 40, Loss: 0.3051
Batch 50, Loss: 0.2823
Batch 60, Loss: 0.2736
Batch 70, Loss: 0.2582
Batch 80, Loss: 0.2824
Batch 90, Loss: 0.2916
Batch 100, Loss: 0.3078
Batch 110, Loss: 0.2896
Batch 120, Loss: 0.2811
Batch 130, Loss: 0.2803
Batch 140, Loss: 0.2962
Batch 150, Loss: 0.2994
Batch 160, Loss: 0.3112
Batch 170, Loss: 0.2881
Batch 180, Loss: 0.2815
Batch 190, Loss: 0.2629
Batch 200, Loss: 0.2440
Batch 210, Loss: 0.2535
Batch 220, Loss: 0.3013
Batch 230, Loss: 0.2639
Batch 240, Loss: 0.2920
Batch 250, Loss: 0.2915
Batch 260, Loss: 0.2902
Batch 270, Loss: 0.2697
Batch 280, Loss: 0.2758
Batch 290, Loss: 0.3212
Batch 300, Loss: 0.2802
Batch 310, Loss: 0.2599
Batch 320, Loss: 0.3219
Batch 330, Loss: 0.2822
Batch 340, Loss: 0.2798
Batch 350, Loss: 0.3065
Batch 360, Loss: 0.2964
Batch 370, Loss: 0.2698
Batch 380, Loss: 0.3273
Batch 390, Loss: 0.2847
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.21431851387024 seconds
Epoch 148 accuracy: 91.33%
Batch 10, Loss: 0.3161
Batch 20, Loss: 0.2641
Batch 30, Loss: 0.2717
Batch 40, Loss: 0.3068
Batch 50, Loss: 0.2800
Batch 60, Loss: 0.2510
Batch 70, Loss: 0.3125
Batch 80, Loss: 0.2875
Batch 90, Loss: 0.2764
Batch 100, Loss: 0.2973
Batch 110, Loss: 0.2734
Batch 120, Loss: 0.2721
Batch 130, Loss: 0.2657
Batch 140, Loss: 0.2715
Batch 150, Loss: 0.2694
Batch 160, Loss: 0.3105
Batch 170, Loss: 0.2903
Batch 180, Loss: 0.3081
Batch 190, Loss: 0.2768
Batch 200, Loss: 0.2916
Batch 210, Loss: 0.2744
Batch 220, Loss: 0.2682
Batch 230, Loss: 0.2748
Batch 240, Loss: 0.2793
Batch 250, Loss: 0.2563
Batch 260, Loss: 0.2672
Batch 270, Loss: 0.3107
Batch 280, Loss: 0.2727
Batch 290, Loss: 0.2730
Batch 300, Loss: 0.2943
Batch 310, Loss: 0.2638
Batch 320, Loss: 0.2937
Batch 330, Loss: 0.3059
Batch 340, Loss: 0.2860
Batch 350, Loss: 0.3140
Batch 360, Loss: 0.2652
Batch 370, Loss: 0.2759
Batch 380, Loss: 0.2993
Batch 390, Loss: 0.2988
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.31204652786255 seconds
Epoch 149 accuracy: 93.34%
Batch 10, Loss: 0.2674
Batch 20, Loss: 0.2987
Batch 30, Loss: 0.2853
Batch 40, Loss: 0.2584
Batch 50, Loss: 0.2800
Batch 60, Loss: 0.2561
Batch 70, Loss: 0.2725
Batch 80, Loss: 0.2755
Batch 90, Loss: 0.2730
Batch 100, Loss: 0.2901
Batch 110, Loss: 0.2625
Batch 120, Loss: 0.2468
Batch 130, Loss: 0.2942
Batch 140, Loss: 0.2683
Batch 150, Loss: 0.2976
Batch 160, Loss: 0.3291
Batch 170, Loss: 0.3023
Batch 180, Loss: 0.2588
Batch 190, Loss: 0.2734
Batch 200, Loss: 0.2967
Batch 210, Loss: 0.2633
Batch 220, Loss: 0.2698
Batch 230, Loss: 0.2900
Batch 240, Loss: 0.3047
Batch 250, Loss: 0.2899
Batch 260, Loss: 0.2686
Batch 270, Loss: 0.3182
Batch 280, Loss: 0.2992
Batch 290, Loss: 0.3063
Batch 300, Loss: 0.2810
Batch 310, Loss: 0.2715
Batch 320, Loss: 0.2760
Batch 330, Loss: 0.2857
Batch 340, Loss: 0.2753
Batch 350, Loss: 0.2724
Batch 360, Loss: 0.2799
Batch 370, Loss: 0.2824
Batch 380, Loss: 0.2847
Batch 390, Loss: 0.2688
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.2763671875 seconds
Epoch 150 accuracy: 93.37%
Batch 10, Loss: 0.2789
Batch 20, Loss: 0.3054
Batch 30, Loss: 0.2597
Batch 40, Loss: 0.2674
Batch 50, Loss: 0.2643
Batch 60, Loss: 0.2437
Batch 70, Loss: 0.2540
Batch 80, Loss: 0.2736
Batch 90, Loss: 0.2910
Batch 100, Loss: 0.2695
Batch 110, Loss: 0.2479
Batch 120, Loss: 0.2642
Batch 130, Loss: 0.3044
Batch 140, Loss: 0.2797
Batch 150, Loss: 0.2940
Batch 160, Loss: 0.2824
Batch 170, Loss: 0.3048
Batch 180, Loss: 0.2840
Batch 190, Loss: 0.2747
Batch 200, Loss: 0.2755
Batch 210, Loss: 0.2862
Batch 220, Loss: 0.2748
Batch 230, Loss: 0.2781
Batch 240, Loss: 0.2691
Batch 250, Loss: 0.2667
Batch 260, Loss: 0.2964
Batch 270, Loss: 0.2997
Batch 280, Loss: 0.3185
Batch 290, Loss: 0.2796
Batch 300, Loss: 0.2747
Batch 310, Loss: 0.2777
Batch 320, Loss: 0.2689
Batch 330, Loss: 0.2923
Batch 340, Loss: 0.2737
Batch 350, Loss: 0.2729
Batch 360, Loss: 0.2975
Batch 370, Loss: 0.2877
Batch 380, Loss: 0.2822
Batch 390, Loss: 0.2939
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.25446915626526 seconds
Epoch 151 accuracy: 93.3%
Batch 10, Loss: 0.2876
Batch 20, Loss: 0.2600
Batch 30, Loss: 0.2684
Batch 40, Loss: 0.2982
Batch 50, Loss: 0.2656
Batch 60, Loss: 0.2630
Batch 70, Loss: 0.2529
Batch 80, Loss: 0.2714
Batch 90, Loss: 0.2562
Batch 100, Loss: 0.2856
Batch 110, Loss: 0.2297
Batch 120, Loss: 0.2710
Batch 130, Loss: 0.2704
Batch 140, Loss: 0.2595
Batch 150, Loss: 0.2681
Batch 160, Loss: 0.2991
Batch 170, Loss: 0.2641
Batch 180, Loss: 0.2748
Batch 190, Loss: 0.2693
Batch 200, Loss: 0.2690
Batch 210, Loss: 0.2844
Batch 220, Loss: 0.2739
Batch 230, Loss: 0.2895
Batch 240, Loss: 0.2398
Batch 250, Loss: 0.2862
Batch 260, Loss: 0.2447
Batch 270, Loss: 0.2521
Batch 280, Loss: 0.2531
Batch 290, Loss: 0.2840
Batch 300, Loss: 0.2681
Batch 310, Loss: 0.2649
Batch 320, Loss: 0.2648
Batch 330, Loss: 0.2759
Batch 340, Loss: 0.2716
Batch 350, Loss: 0.2707
Batch 360, Loss: 0.2842
Batch 370, Loss: 0.2707
Batch 380, Loss: 0.2849
Batch 390, Loss: 0.2645
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.20034170150757 seconds
Epoch 152 accuracy: 93.9%
Batch 10, Loss: 0.2812
Batch 20, Loss: 0.2304
Batch 30, Loss: 0.2817
Batch 40, Loss: 0.2929
Batch 50, Loss: 0.2669
Batch 60, Loss: 0.2883
Batch 70, Loss: 0.2721
Batch 80, Loss: 0.2431
Batch 90, Loss: 0.2414
Batch 100, Loss: 0.2643
Batch 110, Loss: 0.2707
Batch 120, Loss: 0.2760
Batch 130, Loss: 0.2566
Batch 140, Loss: 0.2579
Batch 150, Loss: 0.2426
Batch 160, Loss: 0.2744
Batch 170, Loss: 0.2728
Batch 180, Loss: 0.2630
Batch 190, Loss: 0.2833
Batch 200, Loss: 0.2747
Batch 210, Loss: 0.2779
Batch 220, Loss: 0.3080
Batch 230, Loss: 0.2753
Batch 240, Loss: 0.2426
Batch 250, Loss: 0.2793
Batch 260, Loss: 0.2657
Batch 270, Loss: 0.2375
Batch 280, Loss: 0.2577
Batch 290, Loss: 0.2545
Batch 300, Loss: 0.2707
Batch 310, Loss: 0.2590
Batch 320, Loss: 0.2495
Batch 330, Loss: 0.2519
Batch 340, Loss: 0.2967
Batch 350, Loss: 0.2542
Batch 360, Loss: 0.2732
Batch 370, Loss: 0.2894
Batch 380, Loss: 0.2638
Batch 390, Loss: 0.2496
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.30517315864563 seconds
Epoch 153 accuracy: 92.87%
Batch 10, Loss: 0.2737
Batch 20, Loss: 0.2413
Batch 30, Loss: 0.2486
Batch 40, Loss: 0.2825
Batch 50, Loss: 0.2520
Batch 60, Loss: 0.2684
Batch 70, Loss: 0.2724
Batch 80, Loss: 0.2452
Batch 90, Loss: 0.2488
Batch 100, Loss: 0.2233
Batch 110, Loss: 0.2676
Batch 120, Loss: 0.2713
Batch 130, Loss: 0.2584
Batch 140, Loss: 0.2779
Batch 150, Loss: 0.2712
Batch 160, Loss: 0.2577
Batch 170, Loss: 0.2468
Batch 180, Loss: 0.2657
Batch 190, Loss: 0.2598
Batch 200, Loss: 0.2599
Batch 210, Loss: 0.2801
Batch 220, Loss: 0.2741
Batch 230, Loss: 0.2495
Batch 240, Loss: 0.2560
Batch 250, Loss: 0.2695
Batch 260, Loss: 0.2971
Batch 270, Loss: 0.2631
Batch 280, Loss: 0.2843
Batch 290, Loss: 0.2769
Batch 300, Loss: 0.2568
Batch 310, Loss: 0.2677
Batch 320, Loss: 0.2925
Batch 330, Loss: 0.2681
Batch 340, Loss: 0.2880
Batch 350, Loss: 0.2528
Batch 360, Loss: 0.2499
Batch 370, Loss: 0.2837
Batch 380, Loss: 0.2687
Batch 390, Loss: 0.2771
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.265053272247314 seconds
Epoch 154 accuracy: 93.38%
Batch 10, Loss: 0.2300
Batch 20, Loss: 0.2410
Batch 30, Loss: 0.2523
Batch 40, Loss: 0.2639
Batch 50, Loss: 0.2403
Batch 60, Loss: 0.2326
Batch 70, Loss: 0.2460
Batch 80, Loss: 0.2857
Batch 90, Loss: 0.2614
Batch 100, Loss: 0.2382
Batch 110, Loss: 0.2612
Batch 120, Loss: 0.2612
Batch 130, Loss: 0.2500
Batch 140, Loss: 0.2406
Batch 150, Loss: 0.2607
Batch 160, Loss: 0.2745
Batch 170, Loss: 0.2476
Batch 180, Loss: 0.2677
Batch 190, Loss: 0.2473
Batch 200, Loss: 0.2505
Batch 210, Loss: 0.2606
Batch 220, Loss: 0.2686
Batch 230, Loss: 0.2473
Batch 240, Loss: 0.2666
Batch 250, Loss: 0.2609
Batch 260, Loss: 0.2563
Batch 270, Loss: 0.2531
Batch 280, Loss: 0.2833
Batch 290, Loss: 0.2472
Batch 300, Loss: 0.2555
Batch 310, Loss: 0.2736
Batch 320, Loss: 0.2595
Batch 330, Loss: 0.2364
Batch 340, Loss: 0.2402
Batch 350, Loss: 0.2475
Batch 360, Loss: 0.2717
Batch 370, Loss: 0.2406
Batch 380, Loss: 0.2611
Batch 390, Loss: 0.2636
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.2640860080719 seconds
Epoch 155 accuracy: 93.99%
Batch 10, Loss: 0.2241
Batch 20, Loss: 0.2546
Batch 30, Loss: 0.2671
Batch 40, Loss: 0.2557
Batch 50, Loss: 0.2472
Batch 60, Loss: 0.2752
Batch 70, Loss: 0.2379
Batch 80, Loss: 0.2380
Batch 90, Loss: 0.2679
Batch 100, Loss: 0.2618
Batch 110, Loss: 0.2639
Batch 120, Loss: 0.2455
Batch 130, Loss: 0.2447
Batch 140, Loss: 0.2350
Batch 150, Loss: 0.2631
Batch 160, Loss: 0.2696
Batch 170, Loss: 0.2579
Batch 180, Loss: 0.2725
Batch 190, Loss: 0.2366
Batch 200, Loss: 0.2788
Batch 210, Loss: 0.2438
Batch 220, Loss: 0.2682
Batch 230, Loss: 0.2285
Batch 240, Loss: 0.2476
Batch 250, Loss: 0.2877
Batch 260, Loss: 0.2399
Batch 270, Loss: 0.2732
Batch 280, Loss: 0.2798
Batch 290, Loss: 0.2469
Batch 300, Loss: 0.2767
Batch 310, Loss: 0.2431
Batch 320, Loss: 0.2470
Batch 330, Loss: 0.2666
Batch 340, Loss: 0.2513
Batch 350, Loss: 0.2750
Batch 360, Loss: 0.2835
Batch 370, Loss: 0.2693
Batch 380, Loss: 0.2652
Batch 390, Loss: 0.2512
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.242005348205566 seconds
Epoch 156 accuracy: 94.12%
Batch 10, Loss: 0.2305
Batch 20, Loss: 0.2436
Batch 30, Loss: 0.2290
Batch 40, Loss: 0.2404
Batch 50, Loss: 0.2266
Batch 60, Loss: 0.2695
Batch 70, Loss: 0.2574
Batch 80, Loss: 0.2521
Batch 90, Loss: 0.2432
Batch 100, Loss: 0.2484
Batch 110, Loss: 0.2725
Batch 120, Loss: 0.2582
Batch 130, Loss: 0.2869
Batch 140, Loss: 0.2305
Batch 150, Loss: 0.2683
Batch 160, Loss: 0.2364
Batch 170, Loss: 0.2896
Batch 180, Loss: 0.2440
Batch 190, Loss: 0.2305
Batch 200, Loss: 0.2406
Batch 210, Loss: 0.2483
Batch 220, Loss: 0.2697
Batch 230, Loss: 0.2474
Batch 240, Loss: 0.2589
Batch 250, Loss: 0.2436
Batch 260, Loss: 0.2377
Batch 270, Loss: 0.2655
Batch 280, Loss: 0.2820
Batch 290, Loss: 0.2611
Batch 300, Loss: 0.2571
Batch 310, Loss: 0.2401
Batch 320, Loss: 0.2502
Batch 330, Loss: 0.2630
Batch 340, Loss: 0.2729
Batch 350, Loss: 0.2308
Batch 360, Loss: 0.2649
Batch 370, Loss: 0.2398
Batch 380, Loss: 0.2868
Batch 390, Loss: 0.2415
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.22867751121521 seconds
Epoch 157 accuracy: 94.06%
Batch 10, Loss: 0.2610
Batch 20, Loss: 0.2533
Batch 30, Loss: 0.2303
Batch 40, Loss: 0.2521
Batch 50, Loss: 0.2678
Batch 60, Loss: 0.1928
Batch 70, Loss: 0.2519
Batch 80, Loss: 0.2374
Batch 90, Loss: 0.2683
Batch 100, Loss: 0.2328
Batch 110, Loss: 0.2449
Batch 120, Loss: 0.2654
Batch 130, Loss: 0.2357
Batch 140, Loss: 0.2528
Batch 150, Loss: 0.2468
Batch 160, Loss: 0.2523
Batch 170, Loss: 0.2303
Batch 180, Loss: 0.2644
Batch 190, Loss: 0.2472
Batch 200, Loss: 0.2589
Batch 210, Loss: 0.2346
Batch 220, Loss: 0.2477
Batch 230, Loss: 0.2592
Batch 240, Loss: 0.2372
Batch 250, Loss: 0.2882
Batch 260, Loss: 0.2527
Batch 270, Loss: 0.2560
Batch 280, Loss: 0.2464
Batch 290, Loss: 0.2679
Batch 300, Loss: 0.2559
Batch 310, Loss: 0.2476
Batch 320, Loss: 0.2332
Batch 330, Loss: 0.2552
Batch 340, Loss: 0.2390
Batch 350, Loss: 0.2460
Batch 360, Loss: 0.2670
Batch 370, Loss: 0.2410
Batch 380, Loss: 0.2518
Batch 390, Loss: 0.2374
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.148391485214233 seconds
Epoch 158 accuracy: 94.37%
Batch 10, Loss: 0.2227
Batch 20, Loss: 0.2329
Batch 30, Loss: 0.2545
Batch 40, Loss: 0.2409
Batch 50, Loss: 0.2481
Batch 60, Loss: 0.2351
Batch 70, Loss: 0.2545
Batch 80, Loss: 0.2259
Batch 90, Loss: 0.2415
Batch 100, Loss: 0.2487
Batch 110, Loss: 0.2783
Batch 120, Loss: 0.2684
Batch 130, Loss: 0.2438
Batch 140, Loss: 0.2353
Batch 150, Loss: 0.2601
Batch 160, Loss: 0.2382
Batch 170, Loss: 0.2607
Batch 180, Loss: 0.2338
Batch 190, Loss: 0.2541
Batch 200, Loss: 0.2515
Batch 210, Loss: 0.2529
Batch 220, Loss: 0.2630
Batch 230, Loss: 0.2547
Batch 240, Loss: 0.2336
Batch 250, Loss: 0.2424
Batch 260, Loss: 0.2501
Batch 270, Loss: 0.2409
Batch 280, Loss: 0.2292
Batch 290, Loss: 0.2595
Batch 300, Loss: 0.2960
Batch 310, Loss: 0.2658
Batch 320, Loss: 0.2406
Batch 330, Loss: 0.2468
Batch 340, Loss: 0.2644
Batch 350, Loss: 0.2428
Batch 360, Loss: 0.2374
Batch 370, Loss: 0.2828
Batch 380, Loss: 0.2630
Batch 390, Loss: 0.2370
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.168294429779053 seconds
Epoch 159 accuracy: 94.41%
Batch 10, Loss: 0.2198
Batch 20, Loss: 0.2435
Batch 30, Loss: 0.2375
Batch 40, Loss: 0.2105
Batch 50, Loss: 0.2286
Batch 60, Loss: 0.2363
Batch 70, Loss: 0.2479
Batch 80, Loss: 0.2356
Batch 90, Loss: 0.2186
Batch 100, Loss: 0.2534
Batch 110, Loss: 0.2194
Batch 120, Loss: 0.2492
Batch 130, Loss: 0.2364
Batch 140, Loss: 0.2245
Batch 150, Loss: 0.2318
Batch 160, Loss: 0.2570
Batch 170, Loss: 0.2383
Batch 180, Loss: 0.2305
Batch 190, Loss: 0.2560
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2534
Batch 220, Loss: 0.2291
Batch 230, Loss: 0.2554
Batch 240, Loss: 0.2502
Batch 250, Loss: 0.1906
Batch 260, Loss: 0.2458
Batch 270, Loss: 0.2140
Batch 280, Loss: 0.2358
Batch 290, Loss: 0.2272
Batch 300, Loss: 0.2282
Batch 310, Loss: 0.2468
Batch 320, Loss: 0.2431
Batch 330, Loss: 0.2346
Batch 340, Loss: 0.2259
Batch 350, Loss: 0.2665
Batch 360, Loss: 0.2356
Batch 370, Loss: 0.2545
Batch 380, Loss: 0.2966
Batch 390, Loss: 0.2517
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.221657514572144 seconds
Epoch 160 accuracy: 94.87%
Batch 10, Loss: 0.2621
Batch 20, Loss: 0.2451
Batch 30, Loss: 0.2301
Batch 40, Loss: 0.2329
Batch 50, Loss: 0.2119
Batch 60, Loss: 0.2347
Batch 70, Loss: 0.2234
Batch 80, Loss: 0.2068
Batch 90, Loss: 0.1971
Batch 100, Loss: 0.2313
Batch 110, Loss: 0.2064
Batch 120, Loss: 0.2356
Batch 130, Loss: 0.2387
Batch 140, Loss: 0.2336
Batch 150, Loss: 0.2388
Batch 160, Loss: 0.2188
Batch 170, Loss: 0.2334
Batch 180, Loss: 0.2091
Batch 190, Loss: 0.2418
Batch 200, Loss: 0.2225
Batch 210, Loss: 0.2365
Batch 220, Loss: 0.2502
Batch 230, Loss: 0.2204
Batch 240, Loss: 0.2303
Batch 250, Loss: 0.2437
Batch 260, Loss: 0.2505
Batch 270, Loss: 0.2486
Batch 280, Loss: 0.2439
Batch 290, Loss: 0.2406
Batch 300, Loss: 0.2147
Batch 310, Loss: 0.2525
Batch 320, Loss: 0.2583
Batch 330, Loss: 0.2162
Batch 340, Loss: 0.2405
Batch 350, Loss: 0.2309
Batch 360, Loss: 0.2456
Batch 370, Loss: 0.2542
Batch 380, Loss: 0.2146
Batch 390, Loss: 0.2333
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.24252486228943 seconds
Epoch 161 accuracy: 94.52%
Batch 10, Loss: 0.2350
Batch 20, Loss: 0.2317
Batch 30, Loss: 0.2438
Batch 40, Loss: 0.2385
Batch 50, Loss: 0.2475
Batch 60, Loss: 0.2260
Batch 70, Loss: 0.2509
Batch 80, Loss: 0.2442
Batch 90, Loss: 0.2264
Batch 100, Loss: 0.2339
Batch 110, Loss: 0.2095
Batch 120, Loss: 0.2193
Batch 130, Loss: 0.2291
Batch 140, Loss: 0.2342
Batch 150, Loss: 0.2403
Batch 160, Loss: 0.2387
Batch 170, Loss: 0.2067
Batch 180, Loss: 0.2517
Batch 190, Loss: 0.1985
Batch 200, Loss: 0.2379
Batch 210, Loss: 0.2153
Batch 220, Loss: 0.2349
Batch 230, Loss: 0.2201
Batch 240, Loss: 0.2178
Batch 250, Loss: 0.2413
Batch 260, Loss: 0.2117
Batch 270, Loss: 0.2438
Batch 280, Loss: 0.2060
Batch 290, Loss: 0.2087
Batch 300, Loss: 0.2302
Batch 310, Loss: 0.2419
Batch 320, Loss: 0.2289
Batch 330, Loss: 0.2383
Batch 340, Loss: 0.2202
Batch 350, Loss: 0.2242
Batch 360, Loss: 0.2211
Batch 370, Loss: 0.2407
Batch 380, Loss: 0.2590
Batch 390, Loss: 0.2428
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.192406177520752 seconds
Epoch 162 accuracy: 94.58%
Batch 10, Loss: 0.2308
Batch 20, Loss: 0.2370
Batch 30, Loss: 0.2205
Batch 40, Loss: 0.2123
Batch 50, Loss: 0.2147
Batch 60, Loss: 0.2222
Batch 70, Loss: 0.2056
Batch 80, Loss: 0.2446
Batch 90, Loss: 0.2374
Batch 100, Loss: 0.2323
Batch 110, Loss: 0.2160
Batch 120, Loss: 0.2043
Batch 130, Loss: 0.2266
Batch 140, Loss: 0.2396
Batch 150, Loss: 0.2146
Batch 160, Loss: 0.1919
Batch 170, Loss: 0.2437
Batch 180, Loss: 0.2374
Batch 190, Loss: 0.2340
Batch 200, Loss: 0.2073
Batch 210, Loss: 0.2320
Batch 220, Loss: 0.1988
Batch 230, Loss: 0.2405
Batch 240, Loss: 0.2306
Batch 250, Loss: 0.2236
Batch 260, Loss: 0.2050
Batch 270, Loss: 0.2215
Batch 280, Loss: 0.2285
Batch 290, Loss: 0.2194
Batch 300, Loss: 0.2266
Batch 310, Loss: 0.2176
Batch 320, Loss: 0.2308
Batch 330, Loss: 0.2085
Batch 340, Loss: 0.2260
Batch 350, Loss: 0.2404
Batch 360, Loss: 0.2431
Batch 370, Loss: 0.2476
Batch 380, Loss: 0.2153
Batch 390, Loss: 0.2352
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.21804904937744 seconds
Epoch 163 accuracy: 94.92%
Batch 10, Loss: 0.2355
Batch 20, Loss: 0.2186
Batch 30, Loss: 0.1910
Batch 40, Loss: 0.2323
Batch 50, Loss: 0.1780
Batch 60, Loss: 0.1995
Batch 70, Loss: 0.2147
Batch 80, Loss: 0.2304
Batch 90, Loss: 0.2357
Batch 100, Loss: 0.2167
Batch 110, Loss: 0.2369
Batch 120, Loss: 0.2356
Batch 130, Loss: 0.2331
Batch 140, Loss: 0.2188
Batch 150, Loss: 0.2177
Batch 160, Loss: 0.2656
Batch 170, Loss: 0.2443
Batch 180, Loss: 0.2186
Batch 190, Loss: 0.2314
Batch 200, Loss: 0.2067
Batch 210, Loss: 0.2095
Batch 220, Loss: 0.2234
Batch 230, Loss: 0.2150
Batch 240, Loss: 0.2094
Batch 250, Loss: 0.2115
Batch 260, Loss: 0.2104
Batch 270, Loss: 0.2304
Batch 280, Loss: 0.2272
Batch 290, Loss: 0.2506
Batch 300, Loss: 0.2180
Batch 310, Loss: 0.2218
Batch 320, Loss: 0.2194
Batch 330, Loss: 0.2228
Batch 340, Loss: 0.2354
Batch 350, Loss: 0.2025
Batch 360, Loss: 0.1963
Batch 370, Loss: 0.2459
Batch 380, Loss: 0.2205
Batch 390, Loss: 0.2201
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.216199159622192 seconds
Epoch 164 accuracy: 94.98%
Batch 10, Loss: 0.2183
Batch 20, Loss: 0.2300
Batch 30, Loss: 0.2155
Batch 40, Loss: 0.2163
Batch 50, Loss: 0.2273
Batch 60, Loss: 0.2336
Batch 70, Loss: 0.2088
Batch 80, Loss: 0.2140
Batch 90, Loss: 0.2288
Batch 100, Loss: 0.2537
Batch 110, Loss: 0.2138
Batch 120, Loss: 0.1938
Batch 130, Loss: 0.2020
Batch 140, Loss: 0.2155
Batch 150, Loss: 0.2106
Batch 160, Loss: 0.2086
Batch 170, Loss: 0.2448
Batch 180, Loss: 0.2060
Batch 190, Loss: 0.2173
Batch 200, Loss: 0.1965
Batch 210, Loss: 0.2197
Batch 220, Loss: 0.2121
Batch 230, Loss: 0.2145
Batch 240, Loss: 0.1912
Batch 250, Loss: 0.2049
Batch 260, Loss: 0.2306
Batch 270, Loss: 0.2001
Batch 280, Loss: 0.2062
Batch 290, Loss: 0.2227
Batch 300, Loss: 0.2335
Batch 310, Loss: 0.2458
Batch 320, Loss: 0.2096
Batch 330, Loss: 0.2425
Batch 340, Loss: 0.2152
Batch 350, Loss: 0.2216
Batch 360, Loss: 0.2291
Batch 370, Loss: 0.2222
Batch 380, Loss: 0.1916
Batch 390, Loss: 0.2319
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.20388698577881 seconds
Epoch 165 accuracy: 95.01%
Batch 10, Loss: 0.2233
Batch 20, Loss: 0.1917
Batch 30, Loss: 0.1950
Batch 40, Loss: 0.2115
Batch 50, Loss: 0.2109
Batch 60, Loss: 0.2225
Batch 70, Loss: 0.2218
Batch 80, Loss: 0.2121
Batch 90, Loss: 0.1910
Batch 100, Loss: 0.1929
Batch 110, Loss: 0.2099
Batch 120, Loss: 0.2015
Batch 130, Loss: 0.2227
Batch 140, Loss: 0.2055
Batch 150, Loss: 0.2264
Batch 160, Loss: 0.2403
Batch 170, Loss: 0.2475
Batch 180, Loss: 0.1989
Batch 190, Loss: 0.2045
Batch 200, Loss: 0.2120
Batch 210, Loss: 0.2055
Batch 220, Loss: 0.1892
Batch 230, Loss: 0.2077
Batch 240, Loss: 0.2132
Batch 250, Loss: 0.2178
Batch 260, Loss: 0.1957
Batch 270, Loss: 0.2383
Batch 280, Loss: 0.2151
Batch 290, Loss: 0.1980
Batch 300, Loss: 0.1917
Batch 310, Loss: 0.2274
Batch 320, Loss: 0.1997
Batch 330, Loss: 0.2147
Batch 340, Loss: 0.1809
Batch 350, Loss: 0.2176
Batch 360, Loss: 0.2333
Batch 370, Loss: 0.2314
Batch 380, Loss: 0.2154
Batch 390, Loss: 0.2105
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.229257106781006 seconds
Epoch 166 accuracy: 95.15%
Batch 10, Loss: 0.1915
Batch 20, Loss: 0.2048
Batch 30, Loss: 0.1916
Batch 40, Loss: 0.1994
Batch 50, Loss: 0.2092
Batch 60, Loss: 0.1984
Batch 70, Loss: 0.2406
Batch 80, Loss: 0.2249
Batch 90, Loss: 0.1915
Batch 100, Loss: 0.2174
Batch 110, Loss: 0.2089
Batch 120, Loss: 0.2189
Batch 130, Loss: 0.2189
Batch 140, Loss: 0.1945
Batch 150, Loss: 0.1910
Batch 160, Loss: 0.2302
Batch 170, Loss: 0.2148
Batch 180, Loss: 0.2270
Batch 190, Loss: 0.2144
Batch 200, Loss: 0.1961
Batch 210, Loss: 0.2215
Batch 220, Loss: 0.2019
Batch 230, Loss: 0.2080
Batch 240, Loss: 0.2135
Batch 250, Loss: 0.2374
Batch 260, Loss: 0.2118
Batch 270, Loss: 0.1990
Batch 280, Loss: 0.2272
Batch 290, Loss: 0.1971
Batch 300, Loss: 0.2012
Batch 310, Loss: 0.1853
Batch 320, Loss: 0.2037
Batch 330, Loss: 0.1953
Batch 340, Loss: 0.2331
Batch 350, Loss: 0.2349
Batch 360, Loss: 0.2129
Batch 370, Loss: 0.2146
Batch 380, Loss: 0.2122
Batch 390, Loss: 0.2535
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.210582733154297 seconds
Epoch 167 accuracy: 95.25%
Batch 10, Loss: 0.2205
Batch 20, Loss: 0.1952
Batch 30, Loss: 0.1963
Batch 40, Loss: 0.2082
Batch 50, Loss: 0.2027
Batch 60, Loss: 0.1778
Batch 70, Loss: 0.2452
Batch 80, Loss: 0.2356
Batch 90, Loss: 0.2027
Batch 100, Loss: 0.2084
Batch 110, Loss: 0.2193
Batch 120, Loss: 0.2127
Batch 130, Loss: 0.1992
Batch 140, Loss: 0.1804
Batch 150, Loss: 0.1805
Batch 160, Loss: 0.2262
Batch 170, Loss: 0.2107
Batch 180, Loss: 0.2128
Batch 190, Loss: 0.1986
Batch 200, Loss: 0.2203
Batch 210, Loss: 0.2172
Batch 220, Loss: 0.2005
Batch 230, Loss: 0.2030
Batch 240, Loss: 0.1866
Batch 250, Loss: 0.2030
Batch 260, Loss: 0.1930
Batch 270, Loss: 0.2161
Batch 280, Loss: 0.1921
Batch 290, Loss: 0.1992
Batch 300, Loss: 0.1940
Batch 310, Loss: 0.2012
Batch 320, Loss: 0.2112
Batch 330, Loss: 0.2136
Batch 340, Loss: 0.2284
Batch 350, Loss: 0.1871
Batch 360, Loss: 0.2102
Batch 370, Loss: 0.2055
Batch 380, Loss: 0.2177
Batch 390, Loss: 0.2007
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.225639820098877 seconds
Epoch 168 accuracy: 94.6%
Batch 10, Loss: 0.2031
Batch 20, Loss: 0.1811
Batch 30, Loss: 0.1851
Batch 40, Loss: 0.2020
Batch 50, Loss: 0.1810
Batch 60, Loss: 0.2121
Batch 70, Loss: 0.1921
Batch 80, Loss: 0.2364
Batch 90, Loss: 0.2030
Batch 100, Loss: 0.1918
Batch 110, Loss: 0.1945
Batch 120, Loss: 0.2162
Batch 130, Loss: 0.2163
Batch 140, Loss: 0.1857
Batch 150, Loss: 0.1830
Batch 160, Loss: 0.2021
Batch 170, Loss: 0.1914
Batch 180, Loss: 0.1919
Batch 190, Loss: 0.2081
Batch 200, Loss: 0.1941
Batch 210, Loss: 0.2162
Batch 220, Loss: 0.1966
Batch 230, Loss: 0.1988
Batch 240, Loss: 0.1924
Batch 250, Loss: 0.2043
Batch 260, Loss: 0.2186
Batch 270, Loss: 0.1997
Batch 280, Loss: 0.2074
Batch 290, Loss: 0.1926
Batch 300, Loss: 0.2069
Batch 310, Loss: 0.1868
Batch 320, Loss: 0.2237
Batch 330, Loss: 0.2023
Batch 340, Loss: 0.2038
Batch 350, Loss: 0.1762
Batch 360, Loss: 0.2131
Batch 370, Loss: 0.1877
Batch 380, Loss: 0.1996
Batch 390, Loss: 0.1994
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.32438325881958 seconds
Epoch 169 accuracy: 95.13%
Batch 10, Loss: 0.2024
Batch 20, Loss: 0.1881
Batch 30, Loss: 0.2189
Batch 40, Loss: 0.1875
Batch 50, Loss: 0.2135
Batch 60, Loss: 0.2092
Batch 70, Loss: 0.1922
Batch 80, Loss: 0.1984
Batch 90, Loss: 0.2169
Batch 100, Loss: 0.1807
Batch 110, Loss: 0.2065
Batch 120, Loss: 0.1831
Batch 130, Loss: 0.2092
Batch 140, Loss: 0.2291
Batch 150, Loss: 0.1796
Batch 160, Loss: 0.1814
Batch 170, Loss: 0.2088
Batch 180, Loss: 0.2040
Batch 190, Loss: 0.2129
Batch 200, Loss: 0.2070
Batch 210, Loss: 0.2079
Batch 220, Loss: 0.2116
Batch 230, Loss: 0.1927
Batch 240, Loss: 0.1844
Batch 250, Loss: 0.2024
Batch 260, Loss: 0.1869
Batch 270, Loss: 0.1977
Batch 280, Loss: 0.1884
Batch 290, Loss: 0.2083
Batch 300, Loss: 0.2150
Batch 310, Loss: 0.1979
Batch 320, Loss: 0.2307
Batch 330, Loss: 0.1897
Batch 340, Loss: 0.2130
Batch 350, Loss: 0.1829
Batch 360, Loss: 0.2142
Batch 370, Loss: 0.1926
Batch 380, Loss: 0.2252
Batch 390, Loss: 0.1845
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.298327445983887 seconds
Epoch 170 accuracy: 95.06%
Batch 10, Loss: 0.1865
Batch 20, Loss: 0.1911
Batch 30, Loss: 0.1909
Batch 40, Loss: 0.2116
Batch 50, Loss: 0.1986
Batch 60, Loss: 0.1918
Batch 70, Loss: 0.2001
Batch 80, Loss: 0.1879
Batch 90, Loss: 0.1787
Batch 100, Loss: 0.1920
Batch 110, Loss: 0.1847
Batch 120, Loss: 0.1953
Batch 130, Loss: 0.2092
Batch 140, Loss: 0.1963
Batch 150, Loss: 0.1774
Batch 160, Loss: 0.1767
Batch 170, Loss: 0.1730
Batch 180, Loss: 0.1953
Batch 190, Loss: 0.2107
Batch 200, Loss: 0.1890
Batch 210, Loss: 0.1780
Batch 220, Loss: 0.1979
Batch 230, Loss: 0.1933
Batch 240, Loss: 0.1777
Batch 250, Loss: 0.1855
Batch 260, Loss: 0.2062
Batch 270, Loss: 0.2214
Batch 280, Loss: 0.1770
Batch 290, Loss: 0.1801
Batch 300, Loss: 0.1750
Batch 310, Loss: 0.1842
Batch 320, Loss: 0.1840
Batch 330, Loss: 0.2107
Batch 340, Loss: 0.1875
Batch 350, Loss: 0.1701
Batch 360, Loss: 0.2039
Batch 370, Loss: 0.2010
Batch 380, Loss: 0.1929
Batch 390, Loss: 0.2074
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.258588314056396 seconds
Epoch 171 accuracy: 95.41%
Batch 10, Loss: 0.1910
Batch 20, Loss: 0.1793
Batch 30, Loss: 0.1872
Batch 40, Loss: 0.1835
Batch 50, Loss: 0.2100
Batch 60, Loss: 0.1966
Batch 70, Loss: 0.2039
Batch 80, Loss: 0.1792
Batch 90, Loss: 0.1968
Batch 100, Loss: 0.2134
Batch 110, Loss: 0.1740
Batch 120, Loss: 0.1942
Batch 130, Loss: 0.1835
Batch 140, Loss: 0.1702
Batch 150, Loss: 0.1755
Batch 160, Loss: 0.1853
Batch 170, Loss: 0.1851
Batch 180, Loss: 0.1907
Batch 190, Loss: 0.1778
Batch 200, Loss: 0.2102
Batch 210, Loss: 0.1931
Batch 220, Loss: 0.2054
Batch 230, Loss: 0.1797
Batch 240, Loss: 0.1712
Batch 250, Loss: 0.2050
Batch 260, Loss: 0.1839
Batch 270, Loss: 0.2122
Batch 280, Loss: 0.1881
Batch 290, Loss: 0.1726
Batch 300, Loss: 0.2022
Batch 310, Loss: 0.2025
Batch 320, Loss: 0.1787
Batch 330, Loss: 0.2254
Batch 340, Loss: 0.1792
Batch 350, Loss: 0.1797
Batch 360, Loss: 0.1696
Batch 370, Loss: 0.1803
Batch 380, Loss: 0.1831
Batch 390, Loss: 0.2141
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.23097515106201 seconds
Epoch 172 accuracy: 95.55%
Batch 10, Loss: 0.2111
Batch 20, Loss: 0.1832
Batch 30, Loss: 0.1996
Batch 40, Loss: 0.1812
Batch 50, Loss: 0.1878
Batch 60, Loss: 0.2198
Batch 70, Loss: 0.1976
Batch 80, Loss: 0.2016
Batch 90, Loss: 0.2113
Batch 100, Loss: 0.1947
Batch 110, Loss: 0.2043
Batch 120, Loss: 0.1887
Batch 130, Loss: 0.1696
Batch 140, Loss: 0.1647
Batch 150, Loss: 0.1901
Batch 160, Loss: 0.1651
Batch 170, Loss: 0.1591
Batch 180, Loss: 0.1798
Batch 190, Loss: 0.1980
Batch 200, Loss: 0.1918
Batch 210, Loss: 0.1718
Batch 220, Loss: 0.1895
Batch 230, Loss: 0.2056
Batch 240, Loss: 0.1975
Batch 250, Loss: 0.1934
Batch 260, Loss: 0.1905
Batch 270, Loss: 0.2072
Batch 280, Loss: 0.1748
Batch 290, Loss: 0.1917
Batch 300, Loss: 0.1596
Batch 310, Loss: 0.1865
Batch 320, Loss: 0.2018
Batch 330, Loss: 0.1780
Batch 340, Loss: 0.1740
Batch 350, Loss: 0.1633
Batch 360, Loss: 0.1882
Batch 370, Loss: 0.1806
Batch 380, Loss: 0.1633
Batch 390, Loss: 0.1716
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.248214721679688 seconds
Epoch 173 accuracy: 95.67%
Batch 10, Loss: 0.1792
Batch 20, Loss: 0.1822
Batch 30, Loss: 0.1766
Batch 40, Loss: 0.1796
Batch 50, Loss: 0.1699
Batch 60, Loss: 0.1611
Batch 70, Loss: 0.1883
Batch 80, Loss: 0.1710
Batch 90, Loss: 0.1791
Batch 100, Loss: 0.1649
Batch 110, Loss: 0.1870
Batch 120, Loss: 0.1626
Batch 130, Loss: 0.2077
Batch 140, Loss: 0.1917
Batch 150, Loss: 0.1575
Batch 160, Loss: 0.1791
Batch 170, Loss: 0.1866
Batch 180, Loss: 0.1703
Batch 190, Loss: 0.1679
Batch 200, Loss: 0.1966
Batch 210, Loss: 0.2027
Batch 220, Loss: 0.1872
Batch 230, Loss: 0.1886
Batch 240, Loss: 0.2020
Batch 250, Loss: 0.2031
Batch 260, Loss: 0.1907
Batch 270, Loss: 0.1943
Batch 280, Loss: 0.1755
Batch 290, Loss: 0.1655
Batch 300, Loss: 0.1501
Batch 310, Loss: 0.2057
Batch 320, Loss: 0.1956
Batch 330, Loss: 0.1917
Batch 340, Loss: 0.1731
Batch 350, Loss: 0.1856
Batch 360, Loss: 0.1590
Batch 370, Loss: 0.1694
Batch 380, Loss: 0.1663
Batch 390, Loss: 0.1792
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.243833541870117 seconds
Epoch 174 accuracy: 95.72%
Batch 10, Loss: 0.1655
Batch 20, Loss: 0.1684
Batch 30, Loss: 0.1626
Batch 40, Loss: 0.1874
Batch 50, Loss: 0.1477
Batch 60, Loss: 0.1733
Batch 70, Loss: 0.1945
Batch 80, Loss: 0.1772
Batch 90, Loss: 0.1742
Batch 100, Loss: 0.1897
Batch 110, Loss: 0.1840
Batch 120, Loss: 0.1927
Batch 130, Loss: 0.1874
Batch 140, Loss: 0.1664
Batch 150, Loss: 0.1767
Batch 160, Loss: 0.1609
Batch 170, Loss: 0.1791
Batch 180, Loss: 0.1613
Batch 190, Loss: 0.1947
Batch 200, Loss: 0.1828
Batch 210, Loss: 0.1798
Batch 220, Loss: 0.1759
Batch 230, Loss: 0.1765
Batch 240, Loss: 0.1656
Batch 250, Loss: 0.1562
Batch 260, Loss: 0.1680
Batch 270, Loss: 0.1813
Batch 280, Loss: 0.2008
Batch 290, Loss: 0.1748
Batch 300, Loss: 0.1730
Batch 310, Loss: 0.1635
Batch 320, Loss: 0.1758
Batch 330, Loss: 0.1820
Batch 340, Loss: 0.1790
Batch 350, Loss: 0.1741
Batch 360, Loss: 0.1803
Batch 370, Loss: 0.1754
Batch 380, Loss: 0.1987
Batch 390, Loss: 0.1968
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.256961584091187 seconds
Epoch 175 accuracy: 95.69%
Batch 10, Loss: 0.1582
Batch 20, Loss: 0.1807
Batch 30, Loss: 0.1576
Batch 40, Loss: 0.1447
Batch 50, Loss: 0.1827
Batch 60, Loss: 0.1690
Batch 70, Loss: 0.1862
Batch 80, Loss: 0.1620
Batch 90, Loss: 0.1825
Batch 100, Loss: 0.1519
Batch 110, Loss: 0.1688
Batch 120, Loss: 0.1510
Batch 130, Loss: 0.1678
Batch 140, Loss: 0.1688
Batch 150, Loss: 0.1772
Batch 160, Loss: 0.1368
Batch 170, Loss: 0.1557
Batch 180, Loss: 0.1903
Batch 190, Loss: 0.1801
Batch 200, Loss: 0.1922
Batch 210, Loss: 0.1784
Batch 220, Loss: 0.1699
Batch 230, Loss: 0.1565
Batch 240, Loss: 0.1866
Batch 250, Loss: 0.1767
Batch 260, Loss: 0.1750
Batch 270, Loss: 0.1716
Batch 280, Loss: 0.1507
Batch 290, Loss: 0.1656
Batch 300, Loss: 0.1832
Batch 310, Loss: 0.1754
Batch 320, Loss: 0.1888
Batch 330, Loss: 0.1753
Batch 340, Loss: 0.1787
Batch 350, Loss: 0.1930
Batch 360, Loss: 0.1594
Batch 370, Loss: 0.1713
Batch 380, Loss: 0.1733
Batch 390, Loss: 0.1629
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.25374937057495 seconds
Epoch 176 accuracy: 95.71%
Batch 10, Loss: 0.1913
Batch 20, Loss: 0.1671
Batch 30, Loss: 0.1821
Batch 40, Loss: 0.1810
Batch 50, Loss: 0.1727
Batch 60, Loss: 0.1578
Batch 70, Loss: 0.1423
Batch 80, Loss: 0.1619
Batch 90, Loss: 0.1620
Batch 100, Loss: 0.1874
Batch 110, Loss: 0.1645
Batch 120, Loss: 0.1573
Batch 130, Loss: 0.1876
Batch 140, Loss: 0.1723
Batch 150, Loss: 0.1783
Batch 160, Loss: 0.1760
Batch 170, Loss: 0.1661
Batch 180, Loss: 0.1675
Batch 190, Loss: 0.1656
Batch 200, Loss: 0.1515
Batch 210, Loss: 0.1605
Batch 220, Loss: 0.1740
Batch 230, Loss: 0.1578
Batch 240, Loss: 0.1621
Batch 250, Loss: 0.1747
Batch 260, Loss: 0.1892
Batch 270, Loss: 0.1533
Batch 280, Loss: 0.1506
Batch 290, Loss: 0.1930
Batch 300, Loss: 0.1574
Batch 310, Loss: 0.1623
Batch 320, Loss: 0.1739
Batch 330, Loss: 0.1968
Batch 340, Loss: 0.1582
Batch 350, Loss: 0.1685
Batch 360, Loss: 0.1705
Batch 370, Loss: 0.1804
Batch 380, Loss: 0.1958
Batch 390, Loss: 0.1713
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.22046732902527 seconds
Epoch 177 accuracy: 95.9%
Batch 10, Loss: 0.1672
Batch 20, Loss: 0.1768
Batch 30, Loss: 0.1714
Batch 40, Loss: 0.1875
Batch 50, Loss: 0.1792
Batch 60, Loss: 0.1608
Batch 70, Loss: 0.1701
Batch 80, Loss: 0.1979
Batch 90, Loss: 0.1624
Batch 100, Loss: 0.1518
Batch 110, Loss: 0.1945
Batch 120, Loss: 0.1586
Batch 130, Loss: 0.1740
Batch 140, Loss: 0.1645
Batch 150, Loss: 0.1685
Batch 160, Loss: 0.1680
Batch 170, Loss: 0.1554
Batch 180, Loss: 0.1731
Batch 190, Loss: 0.1746
Batch 200, Loss: 0.1859
Batch 210, Loss: 0.1744
Batch 220, Loss: 0.1553
Batch 230, Loss: 0.1716
Batch 240, Loss: 0.1573
Batch 250, Loss: 0.1733
Batch 260, Loss: 0.1707
Batch 270, Loss: 0.1469
Batch 280, Loss: 0.1633
Batch 290, Loss: 0.1498
Batch 300, Loss: 0.1681
Batch 310, Loss: 0.1608
Batch 320, Loss: 0.1821
Batch 330, Loss: 0.1651
Batch 340, Loss: 0.1643
Batch 350, Loss: 0.1578
Batch 360, Loss: 0.1641
Batch 370, Loss: 0.1507
Batch 380, Loss: 0.1650
Batch 390, Loss: 0.1957
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.19580841064453 seconds
Epoch 178 accuracy: 96.02%
Batch 10, Loss: 0.1937
Batch 20, Loss: 0.1485
Batch 30, Loss: 0.1575
Batch 40, Loss: 0.1578
Batch 50, Loss: 0.1504
Batch 60, Loss: 0.1572
Batch 70, Loss: 0.1699
Batch 80, Loss: 0.1748
Batch 90, Loss: 0.1654
Batch 100, Loss: 0.1850
Batch 110, Loss: 0.1639
Batch 120, Loss: 0.1749
Batch 130, Loss: 0.1669
Batch 140, Loss: 0.1656
Batch 150, Loss: 0.1843
Batch 160, Loss: 0.1430
Batch 170, Loss: 0.1566
Batch 180, Loss: 0.1886
Batch 190, Loss: 0.1779
Batch 200, Loss: 0.1682
Batch 210, Loss: 0.1649
Batch 220, Loss: 0.1395
Batch 230, Loss: 0.1647
Batch 240, Loss: 0.1685
Batch 250, Loss: 0.1572
Batch 260, Loss: 0.1698
Batch 270, Loss: 0.1487
Batch 280, Loss: 0.1580
Batch 290, Loss: 0.1628
Batch 300, Loss: 0.1583
Batch 310, Loss: 0.1700
Batch 320, Loss: 0.1795
Batch 330, Loss: 0.1606
Batch 340, Loss: 0.1662
Batch 350, Loss: 0.1595
Batch 360, Loss: 0.1417
Batch 370, Loss: 0.1568
Batch 380, Loss: 0.1691
Batch 390, Loss: 0.1829
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.21722912788391 seconds
Epoch 179 accuracy: 95.86%
Batch 10, Loss: 0.1521
Batch 20, Loss: 0.1531
Batch 30, Loss: 0.1564
Batch 40, Loss: 0.1460
Batch 50, Loss: 0.1801
Batch 60, Loss: 0.1669
Batch 70, Loss: 0.1700
Batch 80, Loss: 0.1538
Batch 90, Loss: 0.1787
Batch 100, Loss: 0.1481
Batch 110, Loss: 0.1653
Batch 120, Loss: 0.1665
Batch 130, Loss: 0.1476
Batch 140, Loss: 0.1618
Batch 150, Loss: 0.1508
Batch 160, Loss: 0.1458
Batch 170, Loss: 0.1629
Batch 180, Loss: 0.1538
Batch 190, Loss: 0.1422
Batch 200, Loss: 0.1613
Batch 210, Loss: 0.1663
Batch 220, Loss: 0.1638
Batch 230, Loss: 0.1415
Batch 240, Loss: 0.1491
Batch 250, Loss: 0.1963
Batch 260, Loss: 0.1485
Batch 270, Loss: 0.1543
Batch 280, Loss: 0.1727
Batch 290, Loss: 0.1554
Batch 300, Loss: 0.1414
Batch 310, Loss: 0.1246
Batch 320, Loss: 0.1433
Batch 330, Loss: 0.1563
Batch 340, Loss: 0.1384
Batch 350, Loss: 0.1570
Batch 360, Loss: 0.1654
Batch 370, Loss: 0.1446
Batch 380, Loss: 0.1672
Batch 390, Loss: 0.1656
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.25799560546875 seconds
Epoch 180 accuracy: 96.11%
Batch 10, Loss: 0.1604
Batch 20, Loss: 0.1365
Batch 30, Loss: 0.1625
Batch 40, Loss: 0.1479
Batch 50, Loss: 0.1407
Batch 60, Loss: 0.1214
Batch 70, Loss: 0.1729
Batch 80, Loss: 0.1567
Batch 90, Loss: 0.1854
Batch 100, Loss: 0.1715
Batch 110, Loss: 0.1547
Batch 120, Loss: 0.1448
Batch 130, Loss: 0.1705
Batch 140, Loss: 0.1276
Batch 150, Loss: 0.1466
Batch 160, Loss: 0.1598
Batch 170, Loss: 0.1311
Batch 180, Loss: 0.1629
Batch 190, Loss: 0.1430
Batch 200, Loss: 0.1610
Batch 210, Loss: 0.1321
Batch 220, Loss: 0.1386
Batch 230, Loss: 0.1466
Batch 240, Loss: 0.1462
Batch 250, Loss: 0.1504
Batch 260, Loss: 0.1584
Batch 270, Loss: 0.1928
Batch 280, Loss: 0.1544
Batch 290, Loss: 0.1685
Batch 300, Loss: 0.1490
Batch 310, Loss: 0.1364
Batch 320, Loss: 0.1692
Batch 330, Loss: 0.1485
Batch 340, Loss: 0.1489
Batch 350, Loss: 0.1682
Batch 360, Loss: 0.1375
Batch 370, Loss: 0.1520
Batch 380, Loss: 0.1230
Batch 390, Loss: 0.1296
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.2150981426239 seconds
Epoch 181 accuracy: 96.06%
Batch 10, Loss: 0.1401
Batch 20, Loss: 0.1457
Batch 30, Loss: 0.1433
Batch 40, Loss: 0.1377
Batch 50, Loss: 0.1442
Batch 60, Loss: 0.1462
Batch 70, Loss: 0.1639
Batch 80, Loss: 0.1575
Batch 90, Loss: 0.1495
Batch 100, Loss: 0.1429
Batch 110, Loss: 0.1510
Batch 120, Loss: 0.1557
Batch 130, Loss: 0.1392
Batch 140, Loss: 0.1488
Batch 150, Loss: 0.1651
Batch 160, Loss: 0.1315
Batch 170, Loss: 0.1616
Batch 180, Loss: 0.1335
Batch 190, Loss: 0.1424
Batch 200, Loss: 0.1562
Batch 210, Loss: 0.1750
Batch 220, Loss: 0.1439
Batch 230, Loss: 0.1337
Batch 240, Loss: 0.1587
Batch 250, Loss: 0.1797
Batch 260, Loss: 0.1603
Batch 270, Loss: 0.1720
Batch 280, Loss: 0.1586
Batch 290, Loss: 0.1366
Batch 300, Loss: 0.1753
Batch 310, Loss: 0.1379
Batch 320, Loss: 0.1734
Batch 330, Loss: 0.1426
Batch 340, Loss: 0.1601
Batch 350, Loss: 0.1415
Batch 360, Loss: 0.1264
Batch 370, Loss: 0.1448
Batch 380, Loss: 0.1403
Batch 390, Loss: 0.1482
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.20257568359375 seconds
Epoch 182 accuracy: 96.0%
Batch 10, Loss: 0.1590
Batch 20, Loss: 0.1416
Batch 30, Loss: 0.1512
Batch 40, Loss: 0.1282
Batch 50, Loss: 0.1617
Batch 60, Loss: 0.1505
Batch 70, Loss: 0.1308
Batch 80, Loss: 0.1552
Batch 90, Loss: 0.1513
Batch 100, Loss: 0.1637
Batch 110, Loss: 0.1624
Batch 120, Loss: 0.1422
Batch 130, Loss: 0.1703
Batch 140, Loss: 0.1522
Batch 150, Loss: 0.1400
Batch 160, Loss: 0.1813
Batch 170, Loss: 0.1410
Batch 180, Loss: 0.1391
Batch 190, Loss: 0.1408
Batch 200, Loss: 0.1366
Batch 210, Loss: 0.1522
Batch 220, Loss: 0.1504
Batch 230, Loss: 0.1473
Batch 240, Loss: 0.1538
Batch 250, Loss: 0.1462
Batch 260, Loss: 0.1357
Batch 270, Loss: 0.1380
Batch 280, Loss: 0.1308
Batch 290, Loss: 0.1445
Batch 300, Loss: 0.1321
Batch 310, Loss: 0.1367
Batch 320, Loss: 0.1545
Batch 330, Loss: 0.1385
Batch 340, Loss: 0.1676
Batch 350, Loss: 0.1417
Batch 360, Loss: 0.1244
Batch 370, Loss: 0.1633
Batch 380, Loss: 0.1616
Batch 390, Loss: 0.1613
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.240885019302368 seconds
Epoch 183 accuracy: 96.07%
Batch 10, Loss: 0.1517
Batch 20, Loss: 0.1249
Batch 30, Loss: 0.1621
Batch 40, Loss: 0.1305
Batch 50, Loss: 0.1528
Batch 60, Loss: 0.1314
Batch 70, Loss: 0.1492
Batch 80, Loss: 0.1375
Batch 90, Loss: 0.1429
Batch 100, Loss: 0.1399
Batch 110, Loss: 0.1345
Batch 120, Loss: 0.1740
Batch 130, Loss: 0.1690
Batch 140, Loss: 0.1513
Batch 150, Loss: 0.1473
Batch 160, Loss: 0.1445
Batch 170, Loss: 0.1509
Batch 180, Loss: 0.1635
Batch 190, Loss: 0.1383
Batch 200, Loss: 0.1536
Batch 210, Loss: 0.1396
Batch 220, Loss: 0.1408
Batch 230, Loss: 0.1283
Batch 240, Loss: 0.1339
Batch 250, Loss: 0.1420
Batch 260, Loss: 0.1286
Batch 270, Loss: 0.1407
Batch 280, Loss: 0.1486
Batch 290, Loss: 0.1651
Batch 300, Loss: 0.1371
Batch 310, Loss: 0.1298
Batch 320, Loss: 0.1547
Batch 330, Loss: 0.1382
Batch 340, Loss: 0.1347
Batch 350, Loss: 0.1383
Batch 360, Loss: 0.1334
Batch 370, Loss: 0.1423
Batch 380, Loss: 0.1529
Batch 390, Loss: 0.1343
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.254998683929443 seconds
Epoch 184 accuracy: 95.92%
Batch 10, Loss: 0.1217
Batch 20, Loss: 0.1378
Batch 30, Loss: 0.1429
Batch 40, Loss: 0.1326
Batch 50, Loss: 0.1465
Batch 60, Loss: 0.1399
Batch 70, Loss: 0.1284
Batch 80, Loss: 0.1431
Batch 90, Loss: 0.1621
Batch 100, Loss: 0.1391
Batch 110, Loss: 0.1626
Batch 120, Loss: 0.1456
Batch 130, Loss: 0.1288
Batch 140, Loss: 0.1519
Batch 150, Loss: 0.1469
Batch 160, Loss: 0.1158
Batch 170, Loss: 0.1327
Batch 180, Loss: 0.1229
Batch 190, Loss: 0.1160
Batch 200, Loss: 0.1446
Batch 210, Loss: 0.1240
Batch 220, Loss: 0.1303
Batch 230, Loss: 0.1359
Batch 240, Loss: 0.1303
Batch 250, Loss: 0.1402
Batch 260, Loss: 0.1496
Batch 270, Loss: 0.1510
Batch 280, Loss: 0.1409
Batch 290, Loss: 0.1577
Batch 300, Loss: 0.1468
Batch 310, Loss: 0.1592
Batch 320, Loss: 0.1400
Batch 330, Loss: 0.1514
Batch 340, Loss: 0.1567
Batch 350, Loss: 0.1404
Batch 360, Loss: 0.1643
Batch 370, Loss: 0.1518
Batch 380, Loss: 0.1373
Batch 390, Loss: 0.1294
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.297176599502563 seconds
Epoch 185 accuracy: 96.11%
Batch 10, Loss: 0.1539
Batch 20, Loss: 0.1586
Batch 30, Loss: 0.1351
Batch 40, Loss: 0.1212
Batch 50, Loss: 0.1197
Batch 60, Loss: 0.1350
Batch 70, Loss: 0.1493
Batch 80, Loss: 0.1382
Batch 90, Loss: 0.1681
Batch 100, Loss: 0.1510
Batch 110, Loss: 0.1467
Batch 120, Loss: 0.1519
Batch 130, Loss: 0.1380
Batch 140, Loss: 0.1372
Batch 150, Loss: 0.1465
Batch 160, Loss: 0.1367
Batch 170, Loss: 0.1376
Batch 180, Loss: 0.1318
Batch 190, Loss: 0.1387
Batch 200, Loss: 0.1350
Batch 210, Loss: 0.1288
Batch 220, Loss: 0.1292
Batch 230, Loss: 0.1343
Batch 240, Loss: 0.1453
Batch 250, Loss: 0.1313
Batch 260, Loss: 0.1484
Batch 270, Loss: 0.1507
Batch 280, Loss: 0.1474
Batch 290, Loss: 0.1238
Batch 300, Loss: 0.1172
Batch 310, Loss: 0.1552
Batch 320, Loss: 0.1376
Batch 330, Loss: 0.1246
Batch 340, Loss: 0.1368
Batch 350, Loss: 0.1264
Batch 360, Loss: 0.1552
Batch 370, Loss: 0.1667
Batch 380, Loss: 0.1456
Batch 390, Loss: 0.1228
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.2392635345459 seconds
Epoch 186 accuracy: 96.32%
Batch 10, Loss: 0.1399
Batch 20, Loss: 0.1425
Batch 30, Loss: 0.1411
Batch 40, Loss: 0.1460
Batch 50, Loss: 0.1480
Batch 60, Loss: 0.1570
Batch 70, Loss: 0.1315
Batch 80, Loss: 0.1448
Batch 90, Loss: 0.1464
Batch 100, Loss: 0.1535
Batch 110, Loss: 0.1540
Batch 120, Loss: 0.1463
Batch 130, Loss: 0.1393
Batch 140, Loss: 0.1175
Batch 150, Loss: 0.1357
Batch 160, Loss: 0.1238
Batch 170, Loss: 0.1552
Batch 180, Loss: 0.1308
Batch 190, Loss: 0.1300
Batch 200, Loss: 0.1165
Batch 210, Loss: 0.1294
Batch 220, Loss: 0.1398
Batch 230, Loss: 0.1281
Batch 240, Loss: 0.1484
Batch 250, Loss: 0.1404
Batch 260, Loss: 0.1389
Batch 270, Loss: 0.1480
Batch 280, Loss: 0.1468
Batch 290, Loss: 0.1465
Batch 300, Loss: 0.1348
Batch 310, Loss: 0.1437
Batch 320, Loss: 0.1601
Batch 330, Loss: 0.1424
Batch 340, Loss: 0.1390
Batch 350, Loss: 0.1426
Batch 360, Loss: 0.1620
Batch 370, Loss: 0.1465
Batch 380, Loss: 0.1127
Batch 390, Loss: 0.1644
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.150684595108032 seconds
Epoch 187 accuracy: 96.36%
Batch 10, Loss: 0.1407
Batch 20, Loss: 0.1408
Batch 30, Loss: 0.1348
Batch 40, Loss: 0.1249
Batch 50, Loss: 0.1504
Batch 60, Loss: 0.1354
Batch 70, Loss: 0.1233
Batch 80, Loss: 0.1304
Batch 90, Loss: 0.1525
Batch 100, Loss: 0.1486
Batch 110, Loss: 0.1369
Batch 120, Loss: 0.1479
Batch 130, Loss: 0.1496
Batch 140, Loss: 0.1347
Batch 150, Loss: 0.1264
Batch 160, Loss: 0.1227
Batch 170, Loss: 0.1232
Batch 180, Loss: 0.1256
Batch 190, Loss: 0.1260
Batch 200, Loss: 0.1260
Batch 210, Loss: 0.1216
Batch 220, Loss: 0.1341
Batch 230, Loss: 0.1269
Batch 240, Loss: 0.1244
Batch 250, Loss: 0.1349
Batch 260, Loss: 0.1363
Batch 270, Loss: 0.1463
Batch 280, Loss: 0.1311
Batch 290, Loss: 0.1445
Batch 300, Loss: 0.1559
Batch 310, Loss: 0.1248
Batch 320, Loss: 0.1353
Batch 330, Loss: 0.1427
Batch 340, Loss: 0.1508
Batch 350, Loss: 0.1249
Batch 360, Loss: 0.1248
Batch 370, Loss: 0.1198
Batch 380, Loss: 0.1190
Batch 390, Loss: 0.1427
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.29033088684082 seconds
Epoch 188 accuracy: 96.49%
Batch 10, Loss: 0.1296
Batch 20, Loss: 0.1386
Batch 30, Loss: 0.1462
Batch 40, Loss: 0.1336
Batch 50, Loss: 0.1448
Batch 60, Loss: 0.1392
Batch 70, Loss: 0.1264
Batch 80, Loss: 0.1233
Batch 90, Loss: 0.1253
Batch 100, Loss: 0.1417
Batch 110, Loss: 0.1468
Batch 120, Loss: 0.1251
Batch 130, Loss: 0.1316
Batch 140, Loss: 0.1407
Batch 150, Loss: 0.1217
Batch 160, Loss: 0.1095
Batch 170, Loss: 0.1382
Batch 180, Loss: 0.1256
Batch 190, Loss: 0.1371
Batch 200, Loss: 0.1015
Batch 210, Loss: 0.1561
Batch 220, Loss: 0.1287
Batch 230, Loss: 0.1494
Batch 240, Loss: 0.1555
Batch 250, Loss: 0.1339
Batch 260, Loss: 0.1250
Batch 270, Loss: 0.1306
Batch 280, Loss: 0.1367
Batch 290, Loss: 0.1510
Batch 300, Loss: 0.1305
Batch 310, Loss: 0.1472
Batch 320, Loss: 0.1336
Batch 330, Loss: 0.1304
Batch 340, Loss: 0.1327
Batch 350, Loss: 0.1389
Batch 360, Loss: 0.1054
Batch 370, Loss: 0.1405
Batch 380, Loss: 0.1159
Batch 390, Loss: 0.1327
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.234472274780273 seconds
Epoch 189 accuracy: 96.44%
Batch 10, Loss: 0.1372
Batch 20, Loss: 0.1238
Batch 30, Loss: 0.1364
Batch 40, Loss: 0.1425
Batch 50, Loss: 0.1327
Batch 60, Loss: 0.1597
Batch 70, Loss: 0.1229
Batch 80, Loss: 0.1227
Batch 90, Loss: 0.1169
Batch 100, Loss: 0.1342
Batch 110, Loss: 0.1432
Batch 120, Loss: 0.1330
Batch 130, Loss: 0.1290
Batch 140, Loss: 0.1346
Batch 150, Loss: 0.1396
Batch 160, Loss: 0.1117
Batch 170, Loss: 0.1450
Batch 180, Loss: 0.1203
Batch 190, Loss: 0.1289
Batch 200, Loss: 0.1237
Batch 210, Loss: 0.1311
Batch 220, Loss: 0.1502
Batch 230, Loss: 0.1260
Batch 240, Loss: 0.1360
Batch 250, Loss: 0.1397
Batch 260, Loss: 0.1424
Batch 270, Loss: 0.1267
Batch 280, Loss: 0.1191
Batch 290, Loss: 0.1447
Batch 300, Loss: 0.1330
Batch 310, Loss: 0.1412
Batch 320, Loss: 0.1339
Batch 330, Loss: 0.1267
Batch 340, Loss: 0.1281
Batch 350, Loss: 0.1217
Batch 360, Loss: 0.1386
Batch 370, Loss: 0.1407
Batch 380, Loss: 0.1348
Batch 390, Loss: 0.1371
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.154422521591187 seconds
Epoch 190 accuracy: 96.34%
Batch 10, Loss: 0.0994
Batch 20, Loss: 0.1373
Batch 30, Loss: 0.1239
Batch 40, Loss: 0.1161
Batch 50, Loss: 0.1336
Batch 60, Loss: 0.1131
Batch 70, Loss: 0.1295
Batch 80, Loss: 0.1546
Batch 90, Loss: 0.1283
Batch 100, Loss: 0.1445
Batch 110, Loss: 0.1281
Batch 120, Loss: 0.1406
Batch 130, Loss: 0.1224
Batch 140, Loss: 0.1094
Batch 150, Loss: 0.1183
Batch 160, Loss: 0.1234
Batch 170, Loss: 0.1570
Batch 180, Loss: 0.1323
Batch 190, Loss: 0.1288
Batch 200, Loss: 0.1209
Batch 210, Loss: 0.1162
Batch 220, Loss: 0.1187
Batch 230, Loss: 0.1188
Batch 240, Loss: 0.1338
Batch 250, Loss: 0.1534
Batch 260, Loss: 0.1286
Batch 270, Loss: 0.1325
Batch 280, Loss: 0.1445
Batch 290, Loss: 0.1028
Batch 300, Loss: 0.1321
Batch 310, Loss: 0.1543
Batch 320, Loss: 0.1319
Batch 330, Loss: 0.1277
Batch 340, Loss: 0.1202
Batch 350, Loss: 0.1238
Batch 360, Loss: 0.1260
Batch 370, Loss: 0.1202
Batch 380, Loss: 0.1434
Batch 390, Loss: 0.1463
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.213052988052368 seconds
Epoch 191 accuracy: 96.5%
Batch 10, Loss: 0.1511
Batch 20, Loss: 0.1207
Batch 30, Loss: 0.1373
Batch 40, Loss: 0.1396
Batch 50, Loss: 0.1272
Batch 60, Loss: 0.1181
Batch 70, Loss: 0.1173
Batch 80, Loss: 0.1457
Batch 90, Loss: 0.1351
Batch 100, Loss: 0.1137
Batch 110, Loss: 0.1345
Batch 120, Loss: 0.1435
Batch 130, Loss: 0.1303
Batch 140, Loss: 0.0982
Batch 150, Loss: 0.1417
Batch 160, Loss: 0.1432
Batch 170, Loss: 0.1601
Batch 180, Loss: 0.1252
Batch 190, Loss: 0.1178
Batch 200, Loss: 0.1165
Batch 210, Loss: 0.1218
Batch 220, Loss: 0.1493
Batch 230, Loss: 0.1235
Batch 240, Loss: 0.1370
Batch 250, Loss: 0.1290
Batch 260, Loss: 0.1284
Batch 270, Loss: 0.1439
Batch 280, Loss: 0.1458
Batch 290, Loss: 0.1414
Batch 300, Loss: 0.1340
Batch 310, Loss: 0.1174
Batch 320, Loss: 0.1172
Batch 330, Loss: 0.1038
Batch 340, Loss: 0.1168
Batch 350, Loss: 0.1153
Batch 360, Loss: 0.1204
Batch 370, Loss: 0.1250
Batch 380, Loss: 0.1405
Batch 390, Loss: 0.1295
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.20332932472229 seconds
Epoch 192 accuracy: 96.29%
Batch 10, Loss: 0.1353
Batch 20, Loss: 0.1270
Batch 30, Loss: 0.1143
Batch 40, Loss: 0.1332
Batch 50, Loss: 0.1438
Batch 60, Loss: 0.1204
Batch 70, Loss: 0.1296
Batch 80, Loss: 0.1438
Batch 90, Loss: 0.1084
Batch 100, Loss: 0.1214
Batch 110, Loss: 0.1292
Batch 120, Loss: 0.1466
Batch 130, Loss: 0.1305
Batch 140, Loss: 0.1369
Batch 150, Loss: 0.1174
Batch 160, Loss: 0.1322
Batch 170, Loss: 0.1186
Batch 180, Loss: 0.1306
Batch 190, Loss: 0.1312
Batch 200, Loss: 0.1084
Batch 210, Loss: 0.1205
Batch 220, Loss: 0.1454
Batch 230, Loss: 0.1335
Batch 240, Loss: 0.1293
Batch 250, Loss: 0.1356
Batch 260, Loss: 0.1299
Batch 270, Loss: 0.1264
Batch 280, Loss: 0.1155
Batch 290, Loss: 0.1255
Batch 300, Loss: 0.1369
Batch 310, Loss: 0.1423
Batch 320, Loss: 0.1161
Batch 330, Loss: 0.1224
Batch 340, Loss: 0.1213
Batch 350, Loss: 0.1290
Batch 360, Loss: 0.1278
Batch 370, Loss: 0.1538
Batch 380, Loss: 0.1167
Batch 390, Loss: 0.1504
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.37236261367798 seconds
Epoch 193 accuracy: 96.38%
Batch 10, Loss: 0.1201
Batch 20, Loss: 0.1231
Batch 30, Loss: 0.1355
Batch 40, Loss: 0.1116
Batch 50, Loss: 0.1282
Batch 60, Loss: 0.1310
Batch 70, Loss: 0.1383
Batch 80, Loss: 0.1288
Batch 90, Loss: 0.1282
Batch 100, Loss: 0.1302
Batch 110, Loss: 0.1269
Batch 120, Loss: 0.1223
Batch 130, Loss: 0.1424
Batch 140, Loss: 0.1153
Batch 150, Loss: 0.1404
Batch 160, Loss: 0.1286
Batch 170, Loss: 0.1207
Batch 180, Loss: 0.1182
Batch 190, Loss: 0.1315
Batch 200, Loss: 0.1310
Batch 210, Loss: 0.1156
Batch 220, Loss: 0.1147
Batch 230, Loss: 0.1412
Batch 240, Loss: 0.1264
Batch 250, Loss: 0.1115
Batch 260, Loss: 0.1378
Batch 270, Loss: 0.1201
Batch 280, Loss: 0.1041
Batch 290, Loss: 0.1288
Batch 300, Loss: 0.1450
Batch 310, Loss: 0.1111
Batch 320, Loss: 0.1038
Batch 330, Loss: 0.1337
Batch 340, Loss: 0.1254
Batch 350, Loss: 0.1164
Batch 360, Loss: 0.1100
Batch 370, Loss: 0.1077
Batch 380, Loss: 0.1154
Batch 390, Loss: 0.1183
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.50702214241028 seconds
Epoch 194 accuracy: 96.39%
Batch 10, Loss: 0.1374
Batch 20, Loss: 0.1163
Batch 30, Loss: 0.1310
Batch 40, Loss: 0.1377
Batch 50, Loss: 0.1134
Batch 60, Loss: 0.1239
Batch 70, Loss: 0.1211
Batch 80, Loss: 0.1396
Batch 90, Loss: 0.1433
Batch 100, Loss: 0.1278
Batch 110, Loss: 0.1274
Batch 120, Loss: 0.1222
Batch 130, Loss: 0.1370
Batch 140, Loss: 0.1142
Batch 150, Loss: 0.1349
Batch 160, Loss: 0.1317
Batch 170, Loss: 0.1328
Batch 180, Loss: 0.1220
Batch 190, Loss: 0.1220
Batch 200, Loss: 0.1284
Batch 210, Loss: 0.1233
Batch 220, Loss: 0.1291
Batch 230, Loss: 0.1236
Batch 240, Loss: 0.1517
Batch 250, Loss: 0.1216
Batch 260, Loss: 0.1374
Batch 270, Loss: 0.1389
Batch 280, Loss: 0.1096
Batch 290, Loss: 0.1100
Batch 300, Loss: 0.1170
Batch 310, Loss: 0.1327
Batch 320, Loss: 0.1211
Batch 330, Loss: 0.1063
Batch 340, Loss: 0.1253
Batch 350, Loss: 0.1103
Batch 360, Loss: 0.1176
Batch 370, Loss: 0.1382
Batch 380, Loss: 0.1136
Batch 390, Loss: 0.1278
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.453756093978882 seconds
Epoch 195 accuracy: 96.44%
Batch 10, Loss: 0.1094
Batch 20, Loss: 0.1231
Batch 30, Loss: 0.1129
Batch 40, Loss: 0.1419
Batch 50, Loss: 0.1341
Batch 60, Loss: 0.1249
Batch 70, Loss: 0.1071
Batch 80, Loss: 0.1388
Batch 90, Loss: 0.1102
Batch 100, Loss: 0.1251
Batch 110, Loss: 0.1276
Batch 120, Loss: 0.1357
Batch 130, Loss: 0.1429
Batch 140, Loss: 0.1301
Batch 150, Loss: 0.1249
Batch 160, Loss: 0.1064
Batch 170, Loss: 0.1157
Batch 180, Loss: 0.1329
Batch 190, Loss: 0.1412
Batch 200, Loss: 0.1211
Batch 210, Loss: 0.1445
Batch 220, Loss: 0.1279
Batch 230, Loss: 0.1367
Batch 240, Loss: 0.1229
Batch 250, Loss: 0.1226
Batch 260, Loss: 0.1391
Batch 270, Loss: 0.1561
Batch 280, Loss: 0.1315
Batch 290, Loss: 0.1314
Batch 300, Loss: 0.1341
Batch 310, Loss: 0.1340
Batch 320, Loss: 0.1105
Batch 330, Loss: 0.1177
Batch 340, Loss: 0.1081
Batch 350, Loss: 0.1537
Batch 360, Loss: 0.1223
Batch 370, Loss: 0.1272
Batch 380, Loss: 0.1075
Batch 390, Loss: 0.1181
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.522857427597046 seconds
Epoch 196 accuracy: 96.4%
Batch 10, Loss: 0.1008
Batch 20, Loss: 0.1189
Batch 30, Loss: 0.1144
Batch 40, Loss: 0.1220
Batch 50, Loss: 0.1382
Batch 60, Loss: 0.1202
Batch 70, Loss: 0.1202
Batch 80, Loss: 0.1327
Batch 90, Loss: 0.1281
Batch 100, Loss: 0.1216
Batch 110, Loss: 0.1261
Batch 120, Loss: 0.1209
Batch 130, Loss: 0.1416
Batch 140, Loss: 0.1256
Batch 150, Loss: 0.1216
Batch 160, Loss: 0.1235
Batch 170, Loss: 0.1394
Batch 180, Loss: 0.1479
Batch 190, Loss: 0.1253
Batch 200, Loss: 0.1120
Batch 210, Loss: 0.1289
Batch 220, Loss: 0.1156
Batch 230, Loss: 0.1165
Batch 240, Loss: 0.1218
Batch 250, Loss: 0.1242
Batch 260, Loss: 0.1093
Batch 270, Loss: 0.1110
Batch 280, Loss: 0.1293
Batch 290, Loss: 0.1373
Batch 300, Loss: 0.1142
Batch 310, Loss: 0.1115
Batch 320, Loss: 0.1198
Batch 330, Loss: 0.1046
Batch 340, Loss: 0.1370
Batch 350, Loss: 0.1312
Batch 360, Loss: 0.1241
Batch 370, Loss: 0.1088
Batch 380, Loss: 0.1051
Batch 390, Loss: 0.1234
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.562418699264526 seconds
Epoch 197 accuracy: 96.49%
Batch 10, Loss: 0.1052
Batch 20, Loss: 0.1212
Batch 30, Loss: 0.1385
Batch 40, Loss: 0.1430
Batch 50, Loss: 0.1111
Batch 60, Loss: 0.1322
Batch 70, Loss: 0.1094
Batch 80, Loss: 0.1315
Batch 90, Loss: 0.1273
Batch 100, Loss: 0.1219
Batch 110, Loss: 0.1285
Batch 120, Loss: 0.1227
Batch 130, Loss: 0.1188
Batch 140, Loss: 0.1081
Batch 150, Loss: 0.1228
Batch 160, Loss: 0.1470
Batch 170, Loss: 0.1368
Batch 180, Loss: 0.1323
Batch 190, Loss: 0.1126
Batch 200, Loss: 0.1201
Batch 210, Loss: 0.1240
Batch 220, Loss: 0.1057
Batch 230, Loss: 0.1253
Batch 240, Loss: 0.1122
Batch 250, Loss: 0.1300
Batch 260, Loss: 0.1328
Batch 270, Loss: 0.1253
Batch 280, Loss: 0.1287
Batch 290, Loss: 0.1349
Batch 300, Loss: 0.1030
Batch 310, Loss: 0.1122
Batch 320, Loss: 0.1305
Batch 330, Loss: 0.1401
Batch 340, Loss: 0.1324
Batch 350, Loss: 0.0880
Batch 360, Loss: 0.1133
Batch 370, Loss: 0.1262
Batch 380, Loss: 0.1191
Batch 390, Loss: 0.1097
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.63906693458557 seconds
Epoch 198 accuracy: 96.44%
Batch 10, Loss: 0.1348
Batch 20, Loss: 0.1095
Batch 30, Loss: 0.1299
Batch 40, Loss: 0.1369
Batch 50, Loss: 0.1252
Batch 60, Loss: 0.1186
Batch 70, Loss: 0.1430
Batch 80, Loss: 0.1207
Batch 90, Loss: 0.1295
Batch 100, Loss: 0.1353
Batch 110, Loss: 0.1340
Batch 120, Loss: 0.1219
Batch 130, Loss: 0.1229
Batch 140, Loss: 0.1291
Batch 150, Loss: 0.1174
Batch 160, Loss: 0.1211
Batch 170, Loss: 0.1295
Batch 180, Loss: 0.1210
Batch 190, Loss: 0.1075
Batch 200, Loss: 0.1379
Batch 210, Loss: 0.1250
Batch 220, Loss: 0.1324
Batch 230, Loss: 0.1173
Batch 240, Loss: 0.1108
Batch 250, Loss: 0.1401
Batch 260, Loss: 0.1227
Batch 270, Loss: 0.1149
Batch 280, Loss: 0.1312
Batch 290, Loss: 0.1327
Batch 300, Loss: 0.1119
Batch 310, Loss: 0.1328
Batch 320, Loss: 0.1124
Batch 330, Loss: 0.1302
Batch 340, Loss: 0.1409
Batch 350, Loss: 0.1343
Batch 360, Loss: 0.1062
Batch 370, Loss: 0.1040
Batch 380, Loss: 0.1194
Batch 390, Loss: 0.1349
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.700907230377197 seconds
Epoch 199 accuracy: 96.44%
Batch 10, Loss: 0.1089
Batch 20, Loss: 0.1108
Batch 30, Loss: 0.1301
Batch 40, Loss: 0.1136
Batch 50, Loss: 0.1262
Batch 60, Loss: 0.1410
Batch 70, Loss: 0.1072
Batch 80, Loss: 0.1374
Batch 90, Loss: 0.1258
Batch 100, Loss: 0.1114
Batch 110, Loss: 0.1162
Batch 120, Loss: 0.1021
Batch 130, Loss: 0.1038
Batch 140, Loss: 0.1296
Batch 150, Loss: 0.1211
Batch 160, Loss: 0.1070
Batch 170, Loss: 0.1300
Batch 180, Loss: 0.1172
Batch 190, Loss: 0.1272
Batch 200, Loss: 0.1188
Batch 210, Loss: 0.1084
Batch 220, Loss: 0.1203
Batch 230, Loss: 0.1263
Batch 240, Loss: 0.1272
Batch 250, Loss: 0.1253
Batch 260, Loss: 0.1356
Batch 270, Loss: 0.1233
Batch 280, Loss: 0.1071
Batch 290, Loss: 0.1372
Batch 300, Loss: 0.1125
Batch 310, Loss: 0.1045
Batch 320, Loss: 0.1242
Batch 330, Loss: 0.1102
Batch 340, Loss: 0.1315
Batch 350, Loss: 0.1182
Batch 360, Loss: 0.1316
Batch 370, Loss: 0.1268
Batch 380, Loss: 0.1358
Batch 390, Loss: 0.1171
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.594080448150635 seconds
Epoch 200 accuracy: 96.51%
Total training time: 5096.855805397034 seconds
