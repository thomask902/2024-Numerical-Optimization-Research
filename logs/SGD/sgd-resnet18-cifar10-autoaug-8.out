The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 3.4780
Batch 20, Loss: 2.6119
Batch 30, Loss: 1.8570
Batch 40, Loss: 1.8244
Batch 50, Loss: 1.7699
Batch 60, Loss: 1.7862
Batch 70, Loss: 1.7487
Batch 80, Loss: 1.7427
Batch 90, Loss: 1.7153
Batch 100, Loss: 1.6920
Batch 110, Loss: 1.6897
Batch 120, Loss: 1.6623
Batch 130, Loss: 1.6586
Batch 140, Loss: 1.6512
Batch 150, Loss: 1.6170
Batch 160, Loss: 1.6145
Batch 170, Loss: 1.6058
Batch 180, Loss: 1.6305
Batch 190, Loss: 1.6370
Batch 200, Loss: 1.6035
Batch 210, Loss: 1.6124
Batch 220, Loss: 1.6115
Batch 230, Loss: 1.5724
Batch 240, Loss: 1.6362
Batch 250, Loss: 1.5629
Batch 260, Loss: 1.5691
Batch 270, Loss: 1.5534
Batch 280, Loss: 1.5865
Batch 290, Loss: 1.5323
Batch 300, Loss: 1.5424
Batch 310, Loss: 1.5214
Batch 320, Loss: 1.5570
Batch 330, Loss: 1.5227
Batch 340, Loss: 1.5651
Batch 350, Loss: 1.5125
Batch 360, Loss: 1.5180
Batch 370, Loss: 1.4998
Batch 380, Loss: 1.4976
Batch 390, Loss: 1.5122
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.859081268310547 seconds
Epoch 1 accuracy: 32.11%
Batch 10, Loss: 1.5110
Batch 20, Loss: 1.4911
Batch 30, Loss: 1.5040
Batch 40, Loss: 1.5179
Batch 50, Loss: 1.4729
Batch 60, Loss: 1.4927
Batch 70, Loss: 1.4608
Batch 80, Loss: 1.4786
Batch 90, Loss: 1.4748
Batch 100, Loss: 1.4199
Batch 110, Loss: 1.4427
Batch 120, Loss: 1.4598
Batch 130, Loss: 1.4521
Batch 140, Loss: 1.4425
Batch 150, Loss: 1.4490
Batch 160, Loss: 1.4276
Batch 170, Loss: 1.4386
Batch 180, Loss: 1.4292
Batch 190, Loss: 1.4512
Batch 200, Loss: 1.4333
Batch 210, Loss: 1.4268
Batch 220, Loss: 1.4147
Batch 230, Loss: 1.4365
Batch 240, Loss: 1.4044
Batch 250, Loss: 1.4100
Batch 260, Loss: 1.4134
Batch 270, Loss: 1.4154
Batch 280, Loss: 1.3772
Batch 290, Loss: 1.3813
Batch 300, Loss: 1.3793
Batch 310, Loss: 1.3788
Batch 320, Loss: 1.4178
Batch 330, Loss: 1.3464
Batch 340, Loss: 1.3390
Batch 350, Loss: 1.3502
Batch 360, Loss: 1.3467
Batch 370, Loss: 1.3120
Batch 380, Loss: 1.3478
Batch 390, Loss: 1.3275
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.60255527496338 seconds
Epoch 2 accuracy: 45.01%
Batch 10, Loss: 1.3315
Batch 20, Loss: 1.3385
Batch 30, Loss: 1.3594
Batch 40, Loss: 1.3209
Batch 50, Loss: 1.3434
Batch 60, Loss: 1.3239
Batch 70, Loss: 1.3492
Batch 80, Loss: 1.3239
Batch 90, Loss: 1.3424
Batch 100, Loss: 1.3086
Batch 110, Loss: 1.2895
Batch 120, Loss: 1.3016
Batch 130, Loss: 1.2925
Batch 140, Loss: 1.3039
Batch 150, Loss: 1.3030
Batch 160, Loss: 1.2880
Batch 170, Loss: 1.2956
Batch 180, Loss: 1.2778
Batch 190, Loss: 1.3090
Batch 200, Loss: 1.3382
Batch 210, Loss: 1.2937
Batch 220, Loss: 1.2604
Batch 230, Loss: 1.2999
Batch 240, Loss: 1.2613
Batch 250, Loss: 1.2826
Batch 260, Loss: 1.2203
Batch 270, Loss: 1.2341
Batch 280, Loss: 1.2686
Batch 290, Loss: 1.2391
Batch 300, Loss: 1.2267
Batch 310, Loss: 1.2794
Batch 320, Loss: 1.2509
Batch 330, Loss: 1.2552
Batch 340, Loss: 1.2339
Batch 350, Loss: 1.2645
Batch 360, Loss: 1.1965
Batch 370, Loss: 1.2744
Batch 380, Loss: 1.2125
Batch 390, Loss: 1.2284
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.58564281463623 seconds
Epoch 3 accuracy: 50.08%
Batch 10, Loss: 1.1775
Batch 20, Loss: 1.2007
Batch 30, Loss: 1.2216
Batch 40, Loss: 1.2107
Batch 50, Loss: 1.2167
Batch 60, Loss: 1.2090
Batch 70, Loss: 1.1698
Batch 80, Loss: 1.1629
Batch 90, Loss: 1.1933
Batch 100, Loss: 1.1499
Batch 110, Loss: 1.1802
Batch 120, Loss: 1.1527
Batch 130, Loss: 1.1686
Batch 140, Loss: 1.1461
Batch 150, Loss: 1.1993
Batch 160, Loss: 1.1355
Batch 170, Loss: 1.1491
Batch 180, Loss: 1.1562
Batch 190, Loss: 1.1583
Batch 200, Loss: 1.2180
Batch 210, Loss: 1.1333
Batch 220, Loss: 1.1343
Batch 230, Loss: 1.1242
Batch 240, Loss: 1.2006
Batch 250, Loss: 1.1740
Batch 260, Loss: 1.1788
Batch 270, Loss: 1.2303
Batch 280, Loss: 1.1786
Batch 290, Loss: 1.1799
Batch 300, Loss: 1.1083
Batch 310, Loss: 1.1625
Batch 320, Loss: 1.1661
Batch 330, Loss: 1.1021
Batch 340, Loss: 1.1485
Batch 350, Loss: 1.0901
Batch 360, Loss: 1.1085
Batch 370, Loss: 1.1042
Batch 380, Loss: 1.1151
Batch 390, Loss: 1.0992
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.619748830795288 seconds
Epoch 4 accuracy: 56.78%
Batch 10, Loss: 1.0617
Batch 20, Loss: 1.1205
Batch 30, Loss: 1.0610
Batch 40, Loss: 1.0808
Batch 50, Loss: 1.1515
Batch 60, Loss: 1.1033
Batch 70, Loss: 1.1086
Batch 80, Loss: 1.0653
Batch 90, Loss: 1.0865
Batch 100, Loss: 1.1230
Batch 110, Loss: 1.1178
Batch 120, Loss: 1.0878
Batch 130, Loss: 1.0971
Batch 140, Loss: 1.0953
Batch 150, Loss: 1.0561
Batch 160, Loss: 1.0498
Batch 170, Loss: 1.0921
Batch 180, Loss: 1.0892
Batch 190, Loss: 1.0577
Batch 200, Loss: 1.0616
Batch 210, Loss: 1.0796
Batch 220, Loss: 1.0827
Batch 230, Loss: 1.0338
Batch 240, Loss: 1.0688
Batch 250, Loss: 1.0550
Batch 260, Loss: 1.0453
Batch 270, Loss: 1.0609
Batch 280, Loss: 1.0401
Batch 290, Loss: 1.0121
Batch 300, Loss: 1.0471
Batch 310, Loss: 0.9886
Batch 320, Loss: 1.0133
Batch 330, Loss: 1.0482
Batch 340, Loss: 1.0905
Batch 350, Loss: 1.0411
Batch 360, Loss: 1.0290
Batch 370, Loss: 0.9938
Batch 380, Loss: 1.0235
Batch 390, Loss: 0.9861
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.594345331192017 seconds
Epoch 5 accuracy: 60.8%
Batch 10, Loss: 1.0033
Batch 20, Loss: 1.0381
Batch 30, Loss: 0.9828
Batch 40, Loss: 0.9504
Batch 50, Loss: 0.9609
Batch 60, Loss: 1.0212
Batch 70, Loss: 1.0323
Batch 80, Loss: 1.0194
Batch 90, Loss: 0.9627
Batch 100, Loss: 1.0090
Batch 110, Loss: 1.0342
Batch 120, Loss: 0.9539
Batch 130, Loss: 1.0092
Batch 140, Loss: 1.0030
Batch 150, Loss: 0.9482
Batch 160, Loss: 0.9311
Batch 170, Loss: 0.9853
Batch 180, Loss: 0.9751
Batch 190, Loss: 0.9458
Batch 200, Loss: 0.9802
Batch 210, Loss: 0.9517
Batch 220, Loss: 0.9663
Batch 230, Loss: 0.9753
Batch 240, Loss: 0.9387
Batch 250, Loss: 0.9588
Batch 260, Loss: 1.0000
Batch 270, Loss: 0.9942
Batch 280, Loss: 0.9982
Batch 290, Loss: 0.9776
Batch 300, Loss: 0.9350
Batch 310, Loss: 0.9162
Batch 320, Loss: 0.9358
Batch 330, Loss: 0.9794
Batch 340, Loss: 0.9687
Batch 350, Loss: 0.9719
Batch 360, Loss: 0.9832
Batch 370, Loss: 0.9595
Batch 380, Loss: 0.9585
Batch 390, Loss: 0.9664
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.49983048439026 seconds
Epoch 6 accuracy: 57.81%
Batch 10, Loss: 0.9074
Batch 20, Loss: 0.9965
Batch 30, Loss: 0.9305
Batch 40, Loss: 0.9322
Batch 50, Loss: 0.9691
Batch 60, Loss: 0.9332
Batch 70, Loss: 0.8939
Batch 80, Loss: 0.9370
Batch 90, Loss: 0.9300
Batch 100, Loss: 0.8910
Batch 110, Loss: 0.9244
Batch 120, Loss: 0.9162
Batch 130, Loss: 0.9203
Batch 140, Loss: 0.9030
Batch 150, Loss: 0.9609
Batch 160, Loss: 0.9494
Batch 170, Loss: 0.9459
Batch 180, Loss: 0.9308
Batch 190, Loss: 0.9412
Batch 200, Loss: 0.9217
Batch 210, Loss: 0.8766
Batch 220, Loss: 0.8751
Batch 230, Loss: 0.9147
Batch 240, Loss: 0.9026
Batch 250, Loss: 0.9047
Batch 260, Loss: 0.9021
Batch 270, Loss: 0.9049
Batch 280, Loss: 0.8498
Batch 290, Loss: 0.8711
Batch 300, Loss: 0.9169
Batch 310, Loss: 0.8924
Batch 320, Loss: 0.8963
Batch 330, Loss: 0.9273
Batch 340, Loss: 0.8331
Batch 350, Loss: 0.8964
Batch 360, Loss: 0.8814
Batch 370, Loss: 0.8769
Batch 380, Loss: 0.8589
Batch 390, Loss: 0.8934
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.684189081192017 seconds
Epoch 7 accuracy: 68.92%
Batch 10, Loss: 0.8580
Batch 20, Loss: 0.8645
Batch 30, Loss: 0.8085
Batch 40, Loss: 0.8309
Batch 50, Loss: 0.8571
Batch 60, Loss: 0.8648
Batch 70, Loss: 0.8750
Batch 80, Loss: 0.8438
Batch 90, Loss: 0.8787
Batch 100, Loss: 0.8391
Batch 110, Loss: 0.8829
Batch 120, Loss: 0.8784
Batch 130, Loss: 0.8369
Batch 140, Loss: 0.8481
Batch 150, Loss: 0.8222
Batch 160, Loss: 0.8334
Batch 170, Loss: 0.8796
Batch 180, Loss: 0.8694
Batch 190, Loss: 0.8512
Batch 200, Loss: 0.8359
Batch 210, Loss: 0.8398
Batch 220, Loss: 0.8356
Batch 230, Loss: 0.8013
Batch 240, Loss: 0.8448
Batch 250, Loss: 0.8205
Batch 260, Loss: 0.8142
Batch 270, Loss: 0.8048
Batch 280, Loss: 0.8052
Batch 290, Loss: 0.7904
Batch 300, Loss: 0.8645
Batch 310, Loss: 0.7821
Batch 320, Loss: 0.8561
Batch 330, Loss: 0.8077
Batch 340, Loss: 0.8504
Batch 350, Loss: 0.8344
Batch 360, Loss: 0.8073
Batch 370, Loss: 0.8131
Batch 380, Loss: 0.8986
Batch 390, Loss: 0.7820
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.531718492507935 seconds
Epoch 8 accuracy: 69.14%
Batch 10, Loss: 0.8191
Batch 20, Loss: 0.8256
Batch 30, Loss: 0.7875
Batch 40, Loss: 0.8245
Batch 50, Loss: 0.7968
Batch 60, Loss: 0.8159
Batch 70, Loss: 0.8241
Batch 80, Loss: 0.8092
Batch 90, Loss: 0.7988
Batch 100, Loss: 0.8091
Batch 110, Loss: 0.8216
Batch 120, Loss: 0.7678
Batch 130, Loss: 0.8151
Batch 140, Loss: 0.8103
Batch 150, Loss: 0.8290
Batch 160, Loss: 0.7847
Batch 170, Loss: 0.8328
Batch 180, Loss: 0.8398
Batch 190, Loss: 0.7756
Batch 200, Loss: 0.8430
Batch 210, Loss: 0.8191
Batch 220, Loss: 0.8273
Batch 230, Loss: 0.7394
Batch 240, Loss: 0.7877
Batch 250, Loss: 0.8060
Batch 260, Loss: 0.8110
Batch 270, Loss: 0.8275
Batch 280, Loss: 0.7821
Batch 290, Loss: 0.7496
Batch 300, Loss: 0.7617
Batch 310, Loss: 0.8257
Batch 320, Loss: 0.8113
Batch 330, Loss: 0.7710
Batch 340, Loss: 0.7725
Batch 350, Loss: 0.7738
Batch 360, Loss: 0.7989
Batch 370, Loss: 0.7647
Batch 380, Loss: 0.7627
Batch 390, Loss: 0.7325
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.370548486709595 seconds
Epoch 9 accuracy: 73.17%
Batch 10, Loss: 0.7655
Batch 20, Loss: 0.8431
Batch 30, Loss: 0.7433
Batch 40, Loss: 0.7629
Batch 50, Loss: 0.7766
Batch 60, Loss: 0.7375
Batch 70, Loss: 0.7689
Batch 80, Loss: 0.7766
Batch 90, Loss: 0.7813
Batch 100, Loss: 0.7597
Batch 110, Loss: 0.7815
Batch 120, Loss: 0.7517
Batch 130, Loss: 0.7556
Batch 140, Loss: 0.7613
Batch 150, Loss: 0.7445
Batch 160, Loss: 0.7249
Batch 170, Loss: 0.7572
Batch 180, Loss: 0.7972
Batch 190, Loss: 0.7468
Batch 200, Loss: 0.7512
Batch 210, Loss: 0.7798
Batch 220, Loss: 0.7831
Batch 230, Loss: 0.7240
Batch 240, Loss: 0.7319
Batch 250, Loss: 0.7731
Batch 260, Loss: 0.7749
Batch 270, Loss: 0.7988
Batch 280, Loss: 0.7401
Batch 290, Loss: 0.7446
Batch 300, Loss: 0.7179
Batch 310, Loss: 0.7317
Batch 320, Loss: 0.7783
Batch 330, Loss: 0.7376
Batch 340, Loss: 0.7948
Batch 350, Loss: 0.7920
Batch 360, Loss: 0.7741
Batch 370, Loss: 0.7467
Batch 380, Loss: 0.7006
Batch 390, Loss: 0.7517
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.363104343414307 seconds
Epoch 10 accuracy: 73.36%
Batch 10, Loss: 0.7444
Batch 20, Loss: 0.7314
Batch 30, Loss: 0.7198
Batch 40, Loss: 0.7150
Batch 50, Loss: 0.7662
Batch 60, Loss: 0.7633
Batch 70, Loss: 0.7238
Batch 80, Loss: 0.7182
Batch 90, Loss: 0.6918
Batch 100, Loss: 0.7027
Batch 110, Loss: 0.7471
Batch 120, Loss: 0.8082
Batch 130, Loss: 0.7659
Batch 140, Loss: 0.7261
Batch 150, Loss: 0.7467
Batch 160, Loss: 0.7506
Batch 170, Loss: 0.7328
Batch 180, Loss: 0.7541
Batch 190, Loss: 0.7554
Batch 200, Loss: 0.7891
Batch 210, Loss: 0.7289
Batch 220, Loss: 0.7429
Batch 230, Loss: 0.7557
Batch 240, Loss: 0.7113
Batch 250, Loss: 0.7277
Batch 260, Loss: 0.7236
Batch 270, Loss: 0.7428
Batch 280, Loss: 0.7733
Batch 290, Loss: 0.7419
Batch 300, Loss: 0.7326
Batch 310, Loss: 0.7153
Batch 320, Loss: 0.7186
Batch 330, Loss: 0.7548
Batch 340, Loss: 0.7713
Batch 350, Loss: 0.7144
Batch 360, Loss: 0.7040
Batch 370, Loss: 0.7021
Batch 380, Loss: 0.7273
Batch 390, Loss: 0.7053
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.424490690231323 seconds
Epoch 11 accuracy: 73.87%
Batch 10, Loss: 0.7171
Batch 20, Loss: 0.7152
Batch 30, Loss: 0.7329
Batch 40, Loss: 0.7491
Batch 50, Loss: 0.7246
Batch 60, Loss: 0.6851
Batch 70, Loss: 0.6929
Batch 80, Loss: 0.7219
Batch 90, Loss: 0.7432
Batch 100, Loss: 0.7526
Batch 110, Loss: 0.7288
Batch 120, Loss: 0.7209
Batch 130, Loss: 0.7009
Batch 140, Loss: 0.7149
Batch 150, Loss: 0.7568
Batch 160, Loss: 0.7110
Batch 170, Loss: 0.7419
Batch 180, Loss: 0.7224
Batch 190, Loss: 0.7347
Batch 200, Loss: 0.7735
Batch 210, Loss: 0.7373
Batch 220, Loss: 0.7565
Batch 230, Loss: 0.7023
Batch 240, Loss: 0.6588
Batch 250, Loss: 0.6858
Batch 260, Loss: 0.7233
Batch 270, Loss: 0.7179
Batch 280, Loss: 0.7291
Batch 290, Loss: 0.7621
Batch 300, Loss: 0.7248
Batch 310, Loss: 0.7064
Batch 320, Loss: 0.7247
Batch 330, Loss: 0.7500
Batch 340, Loss: 0.7181
Batch 350, Loss: 0.6599
Batch 360, Loss: 0.7537
Batch 370, Loss: 0.7125
Batch 380, Loss: 0.7592
Batch 390, Loss: 0.6998
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.401148080825806 seconds
Epoch 12 accuracy: 77.14%
Batch 10, Loss: 0.7140
Batch 20, Loss: 0.7052
Batch 30, Loss: 0.7552
Batch 40, Loss: 0.7402
Batch 50, Loss: 0.6920
Batch 60, Loss: 0.6838
Batch 70, Loss: 0.7361
Batch 80, Loss: 0.7100
Batch 90, Loss: 0.7148
Batch 100, Loss: 0.6919
Batch 110, Loss: 0.7106
Batch 120, Loss: 0.7218
Batch 130, Loss: 0.6760
Batch 140, Loss: 0.7301
Batch 150, Loss: 0.7339
Batch 160, Loss: 0.7330
Batch 170, Loss: 0.6783
Batch 180, Loss: 0.6710
Batch 190, Loss: 0.7341
Batch 200, Loss: 0.6921
Batch 210, Loss: 0.7032
Batch 220, Loss: 0.6998
Batch 230, Loss: 0.7053
Batch 240, Loss: 0.7344
Batch 250, Loss: 0.6919
Batch 260, Loss: 0.6997
Batch 270, Loss: 0.7065
Batch 280, Loss: 0.7289
Batch 290, Loss: 0.6743
Batch 300, Loss: 0.6931
Batch 310, Loss: 0.7091
Batch 320, Loss: 0.7365
Batch 330, Loss: 0.6979
Batch 340, Loss: 0.6762
Batch 350, Loss: 0.7180
Batch 360, Loss: 0.6989
Batch 370, Loss: 0.7219
Batch 380, Loss: 0.7560
Batch 390, Loss: 0.7680
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.316920042037964 seconds
Epoch 13 accuracy: 77.26%
Batch 10, Loss: 0.6486
Batch 20, Loss: 0.7230
Batch 30, Loss: 0.7015
Batch 40, Loss: 0.7267
Batch 50, Loss: 0.6703
Batch 60, Loss: 0.7042
Batch 70, Loss: 0.6920
Batch 80, Loss: 0.6910
Batch 90, Loss: 0.6715
Batch 100, Loss: 0.7007
Batch 110, Loss: 0.7091
Batch 120, Loss: 0.6674
Batch 130, Loss: 0.6780
Batch 140, Loss: 0.7309
Batch 150, Loss: 0.7380
Batch 160, Loss: 0.6618
Batch 170, Loss: 0.6630
Batch 180, Loss: 0.7032
Batch 190, Loss: 0.6874
Batch 200, Loss: 0.7098
Batch 210, Loss: 0.6957
Batch 220, Loss: 0.6757
Batch 230, Loss: 0.6823
Batch 240, Loss: 0.6912
Batch 250, Loss: 0.6583
Batch 260, Loss: 0.6658
Batch 270, Loss: 0.6683
Batch 280, Loss: 0.7207
Batch 290, Loss: 0.7077
Batch 300, Loss: 0.6820
Batch 310, Loss: 0.7542
Batch 320, Loss: 0.6819
Batch 330, Loss: 0.6766
Batch 340, Loss: 0.7074
Batch 350, Loss: 0.7020
Batch 360, Loss: 0.6811
Batch 370, Loss: 0.6524
Batch 380, Loss: 0.7007
Batch 390, Loss: 0.6552
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.351827383041382 seconds
Epoch 14 accuracy: 79.01%
Batch 10, Loss: 0.6175
Batch 20, Loss: 0.6626
Batch 30, Loss: 0.6364
Batch 40, Loss: 0.6832
Batch 50, Loss: 0.6893
Batch 60, Loss: 0.6917
Batch 70, Loss: 0.7256
Batch 80, Loss: 0.7216
Batch 90, Loss: 0.6786
Batch 100, Loss: 0.6163
Batch 110, Loss: 0.6545
Batch 120, Loss: 0.6756
Batch 130, Loss: 0.6544
Batch 140, Loss: 0.6755
Batch 150, Loss: 0.6890
Batch 160, Loss: 0.7058
Batch 170, Loss: 0.7078
Batch 180, Loss: 0.6911
Batch 190, Loss: 0.6613
Batch 200, Loss: 0.6543
Batch 210, Loss: 0.6790
Batch 220, Loss: 0.6602
Batch 230, Loss: 0.6612
Batch 240, Loss: 0.6919
Batch 250, Loss: 0.6704
Batch 260, Loss: 0.6612
Batch 270, Loss: 0.6453
Batch 280, Loss: 0.6734
Batch 290, Loss: 0.6463
Batch 300, Loss: 0.6702
Batch 310, Loss: 0.6560
Batch 320, Loss: 0.6392
Batch 330, Loss: 0.6549
Batch 340, Loss: 0.6996
Batch 350, Loss: 0.6714
Batch 360, Loss: 0.6335
Batch 370, Loss: 0.6723
Batch 380, Loss: 0.6653
Batch 390, Loss: 0.6536
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.330448389053345 seconds
Epoch 15 accuracy: 77.7%
Batch 10, Loss: 0.7306
Batch 20, Loss: 0.6599
Batch 30, Loss: 0.6585
Batch 40, Loss: 0.6737
Batch 50, Loss: 0.6197
Batch 60, Loss: 0.6590
Batch 70, Loss: 0.6678
Batch 80, Loss: 0.6821
Batch 90, Loss: 0.6144
Batch 100, Loss: 0.6668
Batch 110, Loss: 0.7033
Batch 120, Loss: 0.6540
Batch 130, Loss: 0.6709
Batch 140, Loss: 0.6587
Batch 150, Loss: 0.6264
Batch 160, Loss: 0.6624
Batch 170, Loss: 0.6377
Batch 180, Loss: 0.6239
Batch 190, Loss: 0.6670
Batch 200, Loss: 0.6462
Batch 210, Loss: 0.6483
Batch 220, Loss: 0.6987
Batch 230, Loss: 0.6545
Batch 240, Loss: 0.7125
Batch 250, Loss: 0.6801
Batch 260, Loss: 0.6255
Batch 270, Loss: 0.6471
Batch 280, Loss: 0.6395
Batch 290, Loss: 0.6343
Batch 300, Loss: 0.6561
Batch 310, Loss: 0.6541
Batch 320, Loss: 0.6381
Batch 330, Loss: 0.6324
Batch 340, Loss: 0.6514
Batch 350, Loss: 0.6982
Batch 360, Loss: 0.7170
Batch 370, Loss: 0.6656
Batch 380, Loss: 0.6877
Batch 390, Loss: 0.6704
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.302429914474487 seconds
Epoch 16 accuracy: 77.4%
Batch 10, Loss: 0.6601
Batch 20, Loss: 0.6236
Batch 30, Loss: 0.6874
Batch 40, Loss: 0.7021
Batch 50, Loss: 0.6433
Batch 60, Loss: 0.6567
Batch 70, Loss: 0.6062
Batch 80, Loss: 0.6602
Batch 90, Loss: 0.7080
Batch 100, Loss: 0.6475
Batch 110, Loss: 0.6303
Batch 120, Loss: 0.6455
Batch 130, Loss: 0.6571
Batch 140, Loss: 0.5932
Batch 150, Loss: 0.6789
Batch 160, Loss: 0.6550
Batch 170, Loss: 0.6593
Batch 180, Loss: 0.6818
Batch 190, Loss: 0.6640
Batch 200, Loss: 0.6134
Batch 210, Loss: 0.6220
Batch 220, Loss: 0.6409
Batch 230, Loss: 0.6191
Batch 240, Loss: 0.6626
Batch 250, Loss: 0.6530
Batch 260, Loss: 0.6193
Batch 270, Loss: 0.6356
Batch 280, Loss: 0.6380
Batch 290, Loss: 0.6783
Batch 300, Loss: 0.6928
Batch 310, Loss: 0.5997
Batch 320, Loss: 0.6235
Batch 330, Loss: 0.5998
Batch 340, Loss: 0.6201
Batch 350, Loss: 0.6822
Batch 360, Loss: 0.6912
Batch 370, Loss: 0.6898
Batch 380, Loss: 0.6174
Batch 390, Loss: 0.6823
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.326746463775635 seconds
Epoch 17 accuracy: 76.18%
Batch 10, Loss: 0.6300
Batch 20, Loss: 0.6359
Batch 30, Loss: 0.6430
Batch 40, Loss: 0.5984
Batch 50, Loss: 0.6593
Batch 60, Loss: 0.6708
Batch 70, Loss: 0.6677
Batch 80, Loss: 0.6879
Batch 90, Loss: 0.6807
Batch 100, Loss: 0.6395
Batch 110, Loss: 0.6350
Batch 120, Loss: 0.6463
Batch 130, Loss: 0.6366
Batch 140, Loss: 0.6260
Batch 150, Loss: 0.6857
Batch 160, Loss: 0.6564
Batch 170, Loss: 0.6540
Batch 180, Loss: 0.6538
Batch 190, Loss: 0.6515
Batch 200, Loss: 0.6573
Batch 210, Loss: 0.6520
Batch 220, Loss: 0.6720
Batch 230, Loss: 0.6599
Batch 240, Loss: 0.6323
Batch 250, Loss: 0.6290
Batch 260, Loss: 0.6492
Batch 270, Loss: 0.6877
Batch 280, Loss: 0.6303
Batch 290, Loss: 0.6557
Batch 300, Loss: 0.6174
Batch 310, Loss: 0.6109
Batch 320, Loss: 0.6435
Batch 330, Loss: 0.6597
Batch 340, Loss: 0.6359
Batch 350, Loss: 0.6791
Batch 360, Loss: 0.6624
Batch 370, Loss: 0.6683
Batch 380, Loss: 0.6618
Batch 390, Loss: 0.6404
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.371477365493774 seconds
Epoch 18 accuracy: 81.65%
Batch 10, Loss: 0.6460
Batch 20, Loss: 0.6341
Batch 30, Loss: 0.6326
Batch 40, Loss: 0.6120
Batch 50, Loss: 0.5973
Batch 60, Loss: 0.6563
Batch 70, Loss: 0.6544
Batch 80, Loss: 0.5755
Batch 90, Loss: 0.6162
Batch 100, Loss: 0.6551
Batch 110, Loss: 0.6253
Batch 120, Loss: 0.6694
Batch 130, Loss: 0.6845
Batch 140, Loss: 0.6661
Batch 150, Loss: 0.6148
Batch 160, Loss: 0.6386
Batch 170, Loss: 0.6234
Batch 180, Loss: 0.6219
Batch 190, Loss: 0.5912
Batch 200, Loss: 0.6364
Batch 210, Loss: 0.6767
Batch 220, Loss: 0.6863
Batch 230, Loss: 0.6301
Batch 240, Loss: 0.6576
Batch 250, Loss: 0.6372
Batch 260, Loss: 0.6516
Batch 270, Loss: 0.6285
Batch 280, Loss: 0.6517
Batch 290, Loss: 0.6113
Batch 300, Loss: 0.6540
Batch 310, Loss: 0.6148
Batch 320, Loss: 0.5966
Batch 330, Loss: 0.6276
Batch 340, Loss: 0.6450
Batch 350, Loss: 0.6198
Batch 360, Loss: 0.6229
Batch 370, Loss: 0.6380
Batch 380, Loss: 0.6151
Batch 390, Loss: 0.5970
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.375300645828247 seconds
Epoch 19 accuracy: 81.45%
Batch 10, Loss: 0.6334
Batch 20, Loss: 0.5824
Batch 30, Loss: 0.6320
Batch 40, Loss: 0.6147
Batch 50, Loss: 0.6118
Batch 60, Loss: 0.6144
Batch 70, Loss: 0.5974
Batch 80, Loss: 0.5995
Batch 90, Loss: 0.6224
Batch 100, Loss: 0.6132
Batch 110, Loss: 0.6674
Batch 120, Loss: 0.6273
Batch 130, Loss: 0.6020
Batch 140, Loss: 0.5956
Batch 150, Loss: 0.6304
Batch 160, Loss: 0.6506
Batch 170, Loss: 0.6005
Batch 180, Loss: 0.6333
Batch 190, Loss: 0.6363
Batch 200, Loss: 0.6663
Batch 210, Loss: 0.6168
Batch 220, Loss: 0.6497
Batch 230, Loss: 0.6203
Batch 240, Loss: 0.6318
Batch 250, Loss: 0.6640
Batch 260, Loss: 0.6004
Batch 270, Loss: 0.5689
Batch 280, Loss: 0.6283
Batch 290, Loss: 0.6324
Batch 300, Loss: 0.5595
Batch 310, Loss: 0.6375
Batch 320, Loss: 0.6112
Batch 330, Loss: 0.6385
Batch 340, Loss: 0.6148
Batch 350, Loss: 0.6760
Batch 360, Loss: 0.6564
Batch 370, Loss: 0.6409
Batch 380, Loss: 0.6278
Batch 390, Loss: 0.6216
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.30147433280945 seconds
Epoch 20 accuracy: 81.05%
Batch 10, Loss: 0.6071
Batch 20, Loss: 0.6264
Batch 30, Loss: 0.5800
Batch 40, Loss: 0.6449
Batch 50, Loss: 0.5816
Batch 60, Loss: 0.6636
Batch 70, Loss: 0.6318
Batch 80, Loss: 0.5840
Batch 90, Loss: 0.6113
Batch 100, Loss: 0.5823
Batch 110, Loss: 0.6341
Batch 120, Loss: 0.6930
Batch 130, Loss: 0.6048
Batch 140, Loss: 0.6275
Batch 150, Loss: 0.6587
Batch 160, Loss: 0.6638
Batch 170, Loss: 0.6120
Batch 180, Loss: 0.5878
Batch 190, Loss: 0.6215
Batch 200, Loss: 0.6300
Batch 210, Loss: 0.6237
Batch 220, Loss: 0.6395
Batch 230, Loss: 0.6404
Batch 240, Loss: 0.6081
Batch 250, Loss: 0.6558
Batch 260, Loss: 0.6421
Batch 270, Loss: 0.6342
Batch 280, Loss: 0.6429
Batch 290, Loss: 0.6393
Batch 300, Loss: 0.6138
Batch 310, Loss: 0.5995
Batch 320, Loss: 0.6241
Batch 330, Loss: 0.6409
Batch 340, Loss: 0.6263
Batch 350, Loss: 0.6193
Batch 360, Loss: 0.6525
Batch 370, Loss: 0.6288
Batch 380, Loss: 0.6291
Batch 390, Loss: 0.5962
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.34831976890564 seconds
Epoch 21 accuracy: 80.55%
Batch 10, Loss: 0.6439
Batch 20, Loss: 0.6046
Batch 30, Loss: 0.6409
Batch 40, Loss: 0.6164
Batch 50, Loss: 0.6411
Batch 60, Loss: 0.6193
Batch 70, Loss: 0.6216
Batch 80, Loss: 0.6034
Batch 90, Loss: 0.6104
Batch 100, Loss: 0.5899
Batch 110, Loss: 0.6590
Batch 120, Loss: 0.5930
Batch 130, Loss: 0.5942
Batch 140, Loss: 0.5997
Batch 150, Loss: 0.6132
Batch 160, Loss: 0.6047
Batch 170, Loss: 0.6455
Batch 180, Loss: 0.6065
Batch 190, Loss: 0.6427
Batch 200, Loss: 0.6340
Batch 210, Loss: 0.6366
Batch 220, Loss: 0.6104
Batch 230, Loss: 0.6135
Batch 240, Loss: 0.6299
Batch 250, Loss: 0.6217
Batch 260, Loss: 0.6160
Batch 270, Loss: 0.6396
Batch 280, Loss: 0.6069
Batch 290, Loss: 0.6221
Batch 300, Loss: 0.6029
Batch 310, Loss: 0.5839
Batch 320, Loss: 0.5872
Batch 330, Loss: 0.6394
Batch 340, Loss: 0.6347
Batch 350, Loss: 0.5830
Batch 360, Loss: 0.6143
Batch 370, Loss: 0.6009
Batch 380, Loss: 0.5686
Batch 390, Loss: 0.6250
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.270626544952393 seconds
Epoch 22 accuracy: 77.57%
Batch 10, Loss: 0.6359
Batch 20, Loss: 0.6162
Batch 30, Loss: 0.6354
Batch 40, Loss: 0.5687
Batch 50, Loss: 0.6077
Batch 60, Loss: 0.6112
Batch 70, Loss: 0.6573
Batch 80, Loss: 0.5932
Batch 90, Loss: 0.5968
Batch 100, Loss: 0.6154
Batch 110, Loss: 0.6054
Batch 120, Loss: 0.7188
Batch 130, Loss: 0.6780
Batch 140, Loss: 0.6462
Batch 150, Loss: 0.6263
Batch 160, Loss: 0.6424
Batch 170, Loss: 0.5993
Batch 180, Loss: 0.5950
Batch 190, Loss: 0.5983
Batch 200, Loss: 0.6133
Batch 210, Loss: 0.5910
Batch 220, Loss: 0.5892
Batch 230, Loss: 0.5709
Batch 240, Loss: 0.6140
Batch 250, Loss: 0.6162
Batch 260, Loss: 0.6278
Batch 270, Loss: 0.6203
Batch 280, Loss: 0.6449
Batch 290, Loss: 0.6111
Batch 300, Loss: 0.6338
Batch 310, Loss: 0.5963
Batch 320, Loss: 0.6051
Batch 330, Loss: 0.6455
Batch 340, Loss: 0.6327
Batch 350, Loss: 0.5865
Batch 360, Loss: 0.5749
Batch 370, Loss: 0.6279
Batch 380, Loss: 0.6028
Batch 390, Loss: 0.6262
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.35342502593994 seconds
Epoch 23 accuracy: 75.34%
Batch 10, Loss: 0.6043
Batch 20, Loss: 0.6172
Batch 30, Loss: 0.6097
Batch 40, Loss: 0.5588
Batch 50, Loss: 0.5996
Batch 60, Loss: 0.5676
Batch 70, Loss: 0.6054
Batch 80, Loss: 0.6046
Batch 90, Loss: 0.6199
Batch 100, Loss: 0.6623
Batch 110, Loss: 0.6215
Batch 120, Loss: 0.5860
Batch 130, Loss: 0.5751
Batch 140, Loss: 0.6005
Batch 150, Loss: 0.6401
Batch 160, Loss: 0.6160
Batch 170, Loss: 0.6389
Batch 180, Loss: 0.6031
Batch 190, Loss: 0.6118
Batch 200, Loss: 0.5768
Batch 210, Loss: 0.5669
Batch 220, Loss: 0.6097
Batch 230, Loss: 0.5779
Batch 240, Loss: 0.5969
Batch 250, Loss: 0.6101
Batch 260, Loss: 0.5716
Batch 270, Loss: 0.6185
Batch 280, Loss: 0.6346
Batch 290, Loss: 0.6149
Batch 300, Loss: 0.6457
Batch 310, Loss: 0.5737
Batch 320, Loss: 0.5861
Batch 330, Loss: 0.6240
Batch 340, Loss: 0.5671
Batch 350, Loss: 0.6147
Batch 360, Loss: 0.6354
Batch 370, Loss: 0.6399
Batch 380, Loss: 0.5639
Batch 390, Loss: 0.6048
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.309099197387695 seconds
Epoch 24 accuracy: 81.01%
Batch 10, Loss: 0.5921
Batch 20, Loss: 0.5898
Batch 30, Loss: 0.6036
Batch 40, Loss: 0.5839
Batch 50, Loss: 0.5546
Batch 60, Loss: 0.5843
Batch 70, Loss: 0.5741
Batch 80, Loss: 0.6179
Batch 90, Loss: 0.6291
Batch 100, Loss: 0.5832
Batch 110, Loss: 0.5896
Batch 120, Loss: 0.5945
Batch 130, Loss: 0.6330
Batch 140, Loss: 0.5868
Batch 150, Loss: 0.6159
Batch 160, Loss: 0.6072
Batch 170, Loss: 0.6082
Batch 180, Loss: 0.6421
Batch 190, Loss: 0.5695
Batch 200, Loss: 0.5971
Batch 210, Loss: 0.6104
Batch 220, Loss: 0.5941
Batch 230, Loss: 0.5903
Batch 240, Loss: 0.6058
Batch 250, Loss: 0.5795
Batch 260, Loss: 0.6115
Batch 270, Loss: 0.5984
Batch 280, Loss: 0.5723
Batch 290, Loss: 0.5963
Batch 300, Loss: 0.6003
Batch 310, Loss: 0.6032
Batch 320, Loss: 0.6053
Batch 330, Loss: 0.6209
Batch 340, Loss: 0.6011
Batch 350, Loss: 0.6007
Batch 360, Loss: 0.6022
Batch 370, Loss: 0.5932
Batch 380, Loss: 0.6134
Batch 390, Loss: 0.6015
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.330426931381226 seconds
Epoch 25 accuracy: 79.54%
Batch 10, Loss: 0.5429
Batch 20, Loss: 0.5992
Batch 30, Loss: 0.5834
Batch 40, Loss: 0.6252
Batch 50, Loss: 0.6000
Batch 60, Loss: 0.5991
Batch 70, Loss: 0.6169
Batch 80, Loss: 0.6429
Batch 90, Loss: 0.5880
Batch 100, Loss: 0.6165
Batch 110, Loss: 0.5719
Batch 120, Loss: 0.5630
Batch 130, Loss: 0.5944
Batch 140, Loss: 0.6154
Batch 150, Loss: 0.6038
Batch 160, Loss: 0.6177
Batch 170, Loss: 0.5891
Batch 180, Loss: 0.6012
Batch 190, Loss: 0.5785
Batch 200, Loss: 0.5882
Batch 210, Loss: 0.5815
Batch 220, Loss: 0.5804
Batch 230, Loss: 0.6055
Batch 240, Loss: 0.6025
Batch 250, Loss: 0.5819
Batch 260, Loss: 0.5797
Batch 270, Loss: 0.6014
Batch 280, Loss: 0.5678
Batch 290, Loss: 0.5772
Batch 300, Loss: 0.6015
Batch 310, Loss: 0.6379
Batch 320, Loss: 0.6050
Batch 330, Loss: 0.5946
Batch 340, Loss: 0.6235
Batch 350, Loss: 0.5665
Batch 360, Loss: 0.5934
Batch 370, Loss: 0.5874
Batch 380, Loss: 0.6161
Batch 390, Loss: 0.6523
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.255935668945312 seconds
Epoch 26 accuracy: 78.12%
Batch 10, Loss: 0.5888
Batch 20, Loss: 0.6209
Batch 30, Loss: 0.5875
Batch 40, Loss: 0.6024
Batch 50, Loss: 0.6308
Batch 60, Loss: 0.6001
Batch 70, Loss: 0.5599
Batch 80, Loss: 0.5712
Batch 90, Loss: 0.5639
Batch 100, Loss: 0.5810
Batch 110, Loss: 0.5643
Batch 120, Loss: 0.5921
Batch 130, Loss: 0.6283
Batch 140, Loss: 0.5924
Batch 150, Loss: 0.5776
Batch 160, Loss: 0.5749
Batch 170, Loss: 0.6158
Batch 180, Loss: 0.5832
Batch 190, Loss: 0.5870
Batch 200, Loss: 0.5732
Batch 210, Loss: 0.5864
Batch 220, Loss: 0.5642
Batch 230, Loss: 0.5893
Batch 240, Loss: 0.5543
Batch 250, Loss: 0.5530
Batch 260, Loss: 0.6103
Batch 270, Loss: 0.6166
Batch 280, Loss: 0.6047
Batch 290, Loss: 0.5957
Batch 300, Loss: 0.5809
Batch 310, Loss: 0.5748
Batch 320, Loss: 0.5925
Batch 330, Loss: 0.5990
Batch 340, Loss: 0.6003
Batch 350, Loss: 0.6118
Batch 360, Loss: 0.6007
Batch 370, Loss: 0.5688
Batch 380, Loss: 0.6058
Batch 390, Loss: 0.5743
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.281866788864136 seconds
Epoch 27 accuracy: 81.39%
Batch 10, Loss: 0.6035
Batch 20, Loss: 0.5746
Batch 30, Loss: 0.6028
Batch 40, Loss: 0.5995
Batch 50, Loss: 0.6146
Batch 60, Loss: 0.5775
Batch 70, Loss: 0.5887
Batch 80, Loss: 0.6088
Batch 90, Loss: 0.5908
Batch 100, Loss: 0.6238
Batch 110, Loss: 0.5692
Batch 120, Loss: 0.6084
Batch 130, Loss: 0.5783
Batch 140, Loss: 0.5867
Batch 150, Loss: 0.5619
Batch 160, Loss: 0.5850
Batch 170, Loss: 0.5788
Batch 180, Loss: 0.5947
Batch 190, Loss: 0.5608
Batch 200, Loss: 0.6008
Batch 210, Loss: 0.6212
Batch 220, Loss: 0.5870
Batch 230, Loss: 0.6064
Batch 240, Loss: 0.5823
Batch 250, Loss: 0.5742
Batch 260, Loss: 0.5716
Batch 270, Loss: 0.6151
Batch 280, Loss: 0.5911
Batch 290, Loss: 0.5642
Batch 300, Loss: 0.6322
Batch 310, Loss: 0.5711
Batch 320, Loss: 0.5731
Batch 330, Loss: 0.6177
Batch 340, Loss: 0.5478
Batch 350, Loss: 0.5802
Batch 360, Loss: 0.6405
Batch 370, Loss: 0.5869
Batch 380, Loss: 0.5542
Batch 390, Loss: 0.6291
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.319580793380737 seconds
Epoch 28 accuracy: 83.35%
Batch 10, Loss: 0.5953
Batch 20, Loss: 0.5848
Batch 30, Loss: 0.5970
Batch 40, Loss: 0.5780
Batch 50, Loss: 0.5356
Batch 60, Loss: 0.5825
Batch 70, Loss: 0.5961
Batch 80, Loss: 0.5974
Batch 90, Loss: 0.5847
Batch 100, Loss: 0.5612
Batch 110, Loss: 0.5875
Batch 120, Loss: 0.6517
Batch 130, Loss: 0.6035
Batch 140, Loss: 0.5537
Batch 150, Loss: 0.5811
Batch 160, Loss: 0.5391
Batch 170, Loss: 0.5783
Batch 180, Loss: 0.5683
Batch 190, Loss: 0.5904
Batch 200, Loss: 0.5894
Batch 210, Loss: 0.6012
Batch 220, Loss: 0.5976
Batch 230, Loss: 0.6179
Batch 240, Loss: 0.6087
Batch 250, Loss: 0.6155
Batch 260, Loss: 0.6086
Batch 270, Loss: 0.6078
Batch 280, Loss: 0.5878
Batch 290, Loss: 0.5564
Batch 300, Loss: 0.6028
Batch 310, Loss: 0.6083
Batch 320, Loss: 0.6158
Batch 330, Loss: 0.5785
Batch 340, Loss: 0.5969
Batch 350, Loss: 0.5965
Batch 360, Loss: 0.5945
Batch 370, Loss: 0.5893
Batch 380, Loss: 0.6219
Batch 390, Loss: 0.5677
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.400306940078735 seconds
Epoch 29 accuracy: 80.28%
Batch 10, Loss: 0.5820
Batch 20, Loss: 0.6077
Batch 30, Loss: 0.5809
Batch 40, Loss: 0.5886
Batch 50, Loss: 0.5522
Batch 60, Loss: 0.5904
Batch 70, Loss: 0.5962
Batch 80, Loss: 0.5772
Batch 90, Loss: 0.5871
Batch 100, Loss: 0.5796
Batch 110, Loss: 0.5913
Batch 120, Loss: 0.6152
Batch 130, Loss: 0.5635
Batch 140, Loss: 0.5931
Batch 150, Loss: 0.5994
Batch 160, Loss: 0.5837
Batch 170, Loss: 0.5715
Batch 180, Loss: 0.6148
Batch 190, Loss: 0.6243
Batch 200, Loss: 0.5923
Batch 210, Loss: 0.5987
Batch 220, Loss: 0.5649
Batch 230, Loss: 0.5713
Batch 240, Loss: 0.5704
Batch 250, Loss: 0.5881
Batch 260, Loss: 0.6134
Batch 270, Loss: 0.6038
Batch 280, Loss: 0.6418
Batch 290, Loss: 0.5959
Batch 300, Loss: 0.5642
Batch 310, Loss: 0.6118
Batch 320, Loss: 0.6174
Batch 330, Loss: 0.5423
Batch 340, Loss: 0.5481
Batch 350, Loss: 0.5746
Batch 360, Loss: 0.5986
Batch 370, Loss: 0.5649
Batch 380, Loss: 0.5584
Batch 390, Loss: 0.5952
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.350533485412598 seconds
Epoch 30 accuracy: 79.3%
Batch 10, Loss: 0.5683
Batch 20, Loss: 0.5947
Batch 30, Loss: 0.5651
Batch 40, Loss: 0.5864
Batch 50, Loss: 0.5823
Batch 60, Loss: 0.5447
Batch 70, Loss: 0.5687
Batch 80, Loss: 0.5922
Batch 90, Loss: 0.5970
Batch 100, Loss: 0.5291
Batch 110, Loss: 0.5984
Batch 120, Loss: 0.6156
Batch 130, Loss: 0.5700
Batch 140, Loss: 0.6047
Batch 150, Loss: 0.5887
Batch 160, Loss: 0.6084
Batch 170, Loss: 0.5910
Batch 180, Loss: 0.5811
Batch 190, Loss: 0.5779
Batch 200, Loss: 0.5815
Batch 210, Loss: 0.5738
Batch 220, Loss: 0.5758
Batch 230, Loss: 0.5780
Batch 240, Loss: 0.5691
Batch 250, Loss: 0.6172
Batch 260, Loss: 0.5222
Batch 270, Loss: 0.5952
Batch 280, Loss: 0.5741
Batch 290, Loss: 0.6042
Batch 300, Loss: 0.5629
Batch 310, Loss: 0.5633
Batch 320, Loss: 0.6051
Batch 330, Loss: 0.5448
Batch 340, Loss: 0.5213
Batch 350, Loss: 0.5425
Batch 360, Loss: 0.5718
Batch 370, Loss: 0.6140
Batch 380, Loss: 0.5977
Batch 390, Loss: 0.5760
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.294170379638672 seconds
Epoch 31 accuracy: 79.63%
Batch 10, Loss: 0.5713
Batch 20, Loss: 0.5632
Batch 30, Loss: 0.5839
Batch 40, Loss: 0.5798
Batch 50, Loss: 0.5884
Batch 60, Loss: 0.5500
Batch 70, Loss: 0.6278
Batch 80, Loss: 0.5857
Batch 90, Loss: 0.5902
Batch 100, Loss: 0.6152
Batch 110, Loss: 0.6293
Batch 120, Loss: 0.6061
Batch 130, Loss: 0.5859
Batch 140, Loss: 0.5730
Batch 150, Loss: 0.5713
Batch 160, Loss: 0.5653
Batch 170, Loss: 0.6120
Batch 180, Loss: 0.5915
Batch 190, Loss: 0.5613
Batch 200, Loss: 0.5947
Batch 210, Loss: 0.5979
Batch 220, Loss: 0.5767
Batch 230, Loss: 0.5584
Batch 240, Loss: 0.5839
Batch 250, Loss: 0.5911
Batch 260, Loss: 0.5827
Batch 270, Loss: 0.5684
Batch 280, Loss: 0.5669
Batch 290, Loss: 0.5469
Batch 300, Loss: 0.5578
Batch 310, Loss: 0.6236
Batch 320, Loss: 0.5748
Batch 330, Loss: 0.5653
Batch 340, Loss: 0.5815
Batch 350, Loss: 0.5514
Batch 360, Loss: 0.6215
Batch 370, Loss: 0.5963
Batch 380, Loss: 0.5957
Batch 390, Loss: 0.5750
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.35379123687744 seconds
Epoch 32 accuracy: 83.57%
Batch 10, Loss: 0.5655
Batch 20, Loss: 0.5513
Batch 30, Loss: 0.5641
Batch 40, Loss: 0.6025
Batch 50, Loss: 0.5620
Batch 60, Loss: 0.6388
Batch 70, Loss: 0.5784
Batch 80, Loss: 0.5672
Batch 90, Loss: 0.5683
Batch 100, Loss: 0.5478
Batch 110, Loss: 0.5776
Batch 120, Loss: 0.5931
Batch 130, Loss: 0.5542
Batch 140, Loss: 0.5494
Batch 150, Loss: 0.5533
Batch 160, Loss: 0.5918
Batch 170, Loss: 0.6233
Batch 180, Loss: 0.5882
Batch 190, Loss: 0.5698
Batch 200, Loss: 0.5634
Batch 210, Loss: 0.5490
Batch 220, Loss: 0.5548
Batch 230, Loss: 0.5813
Batch 240, Loss: 0.5661
Batch 250, Loss: 0.5571
Batch 260, Loss: 0.5881
Batch 270, Loss: 0.5424
Batch 280, Loss: 0.5810
Batch 290, Loss: 0.5969
Batch 300, Loss: 0.5784
Batch 310, Loss: 0.5549
Batch 320, Loss: 0.5576
Batch 330, Loss: 0.5224
Batch 340, Loss: 0.6183
Batch 350, Loss: 0.5822
Batch 360, Loss: 0.6023
Batch 370, Loss: 0.5850
Batch 380, Loss: 0.5680
Batch 390, Loss: 0.5662
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.202462911605835 seconds
Epoch 33 accuracy: 83.63%
Batch 10, Loss: 0.5380
Batch 20, Loss: 0.5489
Batch 30, Loss: 0.5471
Batch 40, Loss: 0.5645
Batch 50, Loss: 0.5790
Batch 60, Loss: 0.5657
Batch 70, Loss: 0.5514
Batch 80, Loss: 0.5828
Batch 90, Loss: 0.5518
Batch 100, Loss: 0.5711
Batch 110, Loss: 0.6262
Batch 120, Loss: 0.5860
Batch 130, Loss: 0.5457
Batch 140, Loss: 0.5228
Batch 150, Loss: 0.5841
Batch 160, Loss: 0.5450
Batch 170, Loss: 0.5686
Batch 180, Loss: 0.5994
Batch 190, Loss: 0.5622
Batch 200, Loss: 0.6094
Batch 210, Loss: 0.5876
Batch 220, Loss: 0.5402
Batch 230, Loss: 0.5511
Batch 240, Loss: 0.5696
Batch 250, Loss: 0.5362
Batch 260, Loss: 0.5639
Batch 270, Loss: 0.5469
Batch 280, Loss: 0.5413
Batch 290, Loss: 0.5759
Batch 300, Loss: 0.5274
Batch 310, Loss: 0.5725
Batch 320, Loss: 0.5313
Batch 330, Loss: 0.5827
Batch 340, Loss: 0.5787
Batch 350, Loss: 0.5507
Batch 360, Loss: 0.6215
Batch 370, Loss: 0.5942
Batch 380, Loss: 0.6119
Batch 390, Loss: 0.5902
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.235260486602783 seconds
Epoch 34 accuracy: 79.24%
Batch 10, Loss: 0.6045
Batch 20, Loss: 0.5841
Batch 30, Loss: 0.5692
Batch 40, Loss: 0.5870
Batch 50, Loss: 0.5996
Batch 60, Loss: 0.5491
Batch 70, Loss: 0.5501
Batch 80, Loss: 0.5608
Batch 90, Loss: 0.5679
Batch 100, Loss: 0.5503
Batch 110, Loss: 0.5633
Batch 120, Loss: 0.5892
Batch 130, Loss: 0.5460
Batch 140, Loss: 0.5793
Batch 150, Loss: 0.5812
Batch 160, Loss: 0.5973
Batch 170, Loss: 0.5590
Batch 180, Loss: 0.5506
Batch 190, Loss: 0.5796
Batch 200, Loss: 0.5380
Batch 210, Loss: 0.5871
Batch 220, Loss: 0.5354
Batch 230, Loss: 0.5514
Batch 240, Loss: 0.5679
Batch 250, Loss: 0.5838
Batch 260, Loss: 0.5641
Batch 270, Loss: 0.6102
Batch 280, Loss: 0.5856
Batch 290, Loss: 0.5464
Batch 300, Loss: 0.5400
Batch 310, Loss: 0.5900
Batch 320, Loss: 0.5565
Batch 330, Loss: 0.5501
Batch 340, Loss: 0.5684
Batch 350, Loss: 0.5259
Batch 360, Loss: 0.6219
Batch 370, Loss: 0.5478
Batch 380, Loss: 0.5920
Batch 390, Loss: 0.5652
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.24468684196472 seconds
Epoch 35 accuracy: 81.94%
Batch 10, Loss: 0.5718
Batch 20, Loss: 0.5807
Batch 30, Loss: 0.5543
Batch 40, Loss: 0.5505
Batch 50, Loss: 0.5917
Batch 60, Loss: 0.5287
Batch 70, Loss: 0.5343
Batch 80, Loss: 0.5704
Batch 90, Loss: 0.5571
Batch 100, Loss: 0.5498
Batch 110, Loss: 0.5636
Batch 120, Loss: 0.5626
Batch 130, Loss: 0.6038
Batch 140, Loss: 0.5714
Batch 150, Loss: 0.6090
Batch 160, Loss: 0.5465
Batch 170, Loss: 0.5700
Batch 180, Loss: 0.5901
Batch 190, Loss: 0.5525
Batch 200, Loss: 0.6016
Batch 210, Loss: 0.5773
Batch 220, Loss: 0.5981
Batch 230, Loss: 0.5708
Batch 240, Loss: 0.5883
Batch 250, Loss: 0.5754
Batch 260, Loss: 0.5535
Batch 270, Loss: 0.5878
Batch 280, Loss: 0.5370
Batch 290, Loss: 0.5526
Batch 300, Loss: 0.5935
Batch 310, Loss: 0.5628
Batch 320, Loss: 0.5563
Batch 330, Loss: 0.5314
Batch 340, Loss: 0.5882
Batch 350, Loss: 0.5547
Batch 360, Loss: 0.6035
Batch 370, Loss: 0.5722
Batch 380, Loss: 0.5660
Batch 390, Loss: 0.5854
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.226674556732178 seconds
Epoch 36 accuracy: 83.81%
Batch 10, Loss: 0.5659
Batch 20, Loss: 0.5180
Batch 30, Loss: 0.5759
Batch 40, Loss: 0.5306
Batch 50, Loss: 0.5676
Batch 60, Loss: 0.5574
Batch 70, Loss: 0.5190
Batch 80, Loss: 0.5624
Batch 90, Loss: 0.5607
Batch 100, Loss: 0.5778
Batch 110, Loss: 0.5564
Batch 120, Loss: 0.5749
Batch 130, Loss: 0.5633
Batch 140, Loss: 0.5752
Batch 150, Loss: 0.5998
Batch 160, Loss: 0.5823
Batch 170, Loss: 0.5438
Batch 180, Loss: 0.5512
Batch 190, Loss: 0.5310
Batch 200, Loss: 0.5780
Batch 210, Loss: 0.5663
Batch 220, Loss: 0.5949
Batch 230, Loss: 0.6038
Batch 240, Loss: 0.6102
Batch 250, Loss: 0.5599
Batch 260, Loss: 0.5595
Batch 270, Loss: 0.5378
Batch 280, Loss: 0.5624
Batch 290, Loss: 0.5481
Batch 300, Loss: 0.5524
Batch 310, Loss: 0.5866
Batch 320, Loss: 0.5721
Batch 330, Loss: 0.5322
Batch 340, Loss: 0.5615
Batch 350, Loss: 0.5559
Batch 360, Loss: 0.5395
Batch 370, Loss: 0.5952
Batch 380, Loss: 0.5889
Batch 390, Loss: 0.5850
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.21434712409973 seconds
Epoch 37 accuracy: 83.68%
Batch 10, Loss: 0.5697
Batch 20, Loss: 0.5583
Batch 30, Loss: 0.5677
Batch 40, Loss: 0.5687
Batch 50, Loss: 0.5583
Batch 60, Loss: 0.5740
Batch 70, Loss: 0.5594
Batch 80, Loss: 0.5625
Batch 90, Loss: 0.5764
Batch 100, Loss: 0.5389
Batch 110, Loss: 0.5583
Batch 120, Loss: 0.5726
Batch 130, Loss: 0.5586
Batch 140, Loss: 0.5660
Batch 150, Loss: 0.5744
Batch 160, Loss: 0.5680
Batch 170, Loss: 0.5611
Batch 180, Loss: 0.5781
Batch 190, Loss: 0.6069
Batch 200, Loss: 0.5647
Batch 210, Loss: 0.5692
Batch 220, Loss: 0.5523
Batch 230, Loss: 0.5468
Batch 240, Loss: 0.5599
Batch 250, Loss: 0.5244
Batch 260, Loss: 0.5213
Batch 270, Loss: 0.5646
Batch 280, Loss: 0.5484
Batch 290, Loss: 0.5757
Batch 300, Loss: 0.5600
Batch 310, Loss: 0.6151
Batch 320, Loss: 0.5530
Batch 330, Loss: 0.5778
Batch 340, Loss: 0.5601
Batch 350, Loss: 0.5912
Batch 360, Loss: 0.5483
Batch 370, Loss: 0.5674
Batch 380, Loss: 0.5946
Batch 390, Loss: 0.5287
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.2200448513031 seconds
Epoch 38 accuracy: 80.47%
Batch 10, Loss: 0.5878
Batch 20, Loss: 0.5352
Batch 30, Loss: 0.5448
Batch 40, Loss: 0.5860
Batch 50, Loss: 0.5990
Batch 60, Loss: 0.5705
Batch 70, Loss: 0.5627
Batch 80, Loss: 0.5802
Batch 90, Loss: 0.5350
Batch 100, Loss: 0.5593
Batch 110, Loss: 0.5647
Batch 120, Loss: 0.5713
Batch 130, Loss: 0.5561
Batch 140, Loss: 0.5198
Batch 150, Loss: 0.5779
Batch 160, Loss: 0.5769
Batch 170, Loss: 0.5541
Batch 180, Loss: 0.5512
Batch 190, Loss: 0.6038
Batch 200, Loss: 0.5407
Batch 210, Loss: 0.5323
Batch 220, Loss: 0.5430
Batch 230, Loss: 0.5707
Batch 240, Loss: 0.5567
Batch 250, Loss: 0.5742
Batch 260, Loss: 0.5238
Batch 270, Loss: 0.5658
Batch 280, Loss: 0.5375
Batch 290, Loss: 0.5537
Batch 300, Loss: 0.5561
Batch 310, Loss: 0.5895
Batch 320, Loss: 0.5544
Batch 330, Loss: 0.5639
Batch 340, Loss: 0.5747
Batch 350, Loss: 0.5578
Batch 360, Loss: 0.5898
Batch 370, Loss: 0.5445
Batch 380, Loss: 0.5914
Batch 390, Loss: 0.5451
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.277429580688477 seconds
Epoch 39 accuracy: 83.73%
Batch 10, Loss: 0.5671
Batch 20, Loss: 0.5598
Batch 30, Loss: 0.5698
Batch 40, Loss: 0.5566
Batch 50, Loss: 0.5487
Batch 60, Loss: 0.5442
Batch 70, Loss: 0.5396
Batch 80, Loss: 0.5680
Batch 90, Loss: 0.5999
Batch 100, Loss: 0.5388
Batch 110, Loss: 0.5713
Batch 120, Loss: 0.5868
Batch 130, Loss: 0.5824
Batch 140, Loss: 0.5589
Batch 150, Loss: 0.5631
Batch 160, Loss: 0.6020
Batch 170, Loss: 0.5675
Batch 180, Loss: 0.5389
Batch 190, Loss: 0.5526
Batch 200, Loss: 0.5683
Batch 210, Loss: 0.5733
Batch 220, Loss: 0.5484
Batch 230, Loss: 0.4975
Batch 240, Loss: 0.5783
Batch 250, Loss: 0.5904
Batch 260, Loss: 0.5559
Batch 270, Loss: 0.5545
Batch 280, Loss: 0.5358
Batch 290, Loss: 0.5682
Batch 300, Loss: 0.5474
Batch 310, Loss: 0.5599
Batch 320, Loss: 0.5650
Batch 330, Loss: 0.5301
Batch 340, Loss: 0.5602
Batch 350, Loss: 0.5378
Batch 360, Loss: 0.5238
Batch 370, Loss: 0.5928
Batch 380, Loss: 0.5410
Batch 390, Loss: 0.5507
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.290175676345825 seconds
Epoch 40 accuracy: 84.05%
Batch 10, Loss: 0.5323
Batch 20, Loss: 0.5367
Batch 30, Loss: 0.5533
Batch 40, Loss: 0.5370
Batch 50, Loss: 0.5429
Batch 60, Loss: 0.6106
Batch 70, Loss: 0.6003
Batch 80, Loss: 0.5583
Batch 90, Loss: 0.5680
Batch 100, Loss: 0.5439
Batch 110, Loss: 0.5713
Batch 120, Loss: 0.5564
Batch 130, Loss: 0.5657
Batch 140, Loss: 0.5794
Batch 150, Loss: 0.5903
Batch 160, Loss: 0.5798
Batch 170, Loss: 0.5536
Batch 180, Loss: 0.5369
Batch 190, Loss: 0.5512
Batch 200, Loss: 0.5383
Batch 210, Loss: 0.5348
Batch 220, Loss: 0.5911
Batch 230, Loss: 0.5791
Batch 240, Loss: 0.5624
Batch 250, Loss: 0.5347
Batch 260, Loss: 0.5328
Batch 270, Loss: 0.5798
Batch 280, Loss: 0.5495
Batch 290, Loss: 0.5769
Batch 300, Loss: 0.5405
Batch 310, Loss: 0.5352
Batch 320, Loss: 0.5660
Batch 330, Loss: 0.5328
Batch 340, Loss: 0.5769
Batch 350, Loss: 0.5792
Batch 360, Loss: 0.5885
Batch 370, Loss: 0.5530
Batch 380, Loss: 0.5357
Batch 390, Loss: 0.5730
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.212952613830566 seconds
Epoch 41 accuracy: 81.89%
Batch 10, Loss: 0.5342
Batch 20, Loss: 0.5243
Batch 30, Loss: 0.5556
Batch 40, Loss: 0.5691
Batch 50, Loss: 0.5313
Batch 60, Loss: 0.5278
Batch 70, Loss: 0.5322
Batch 80, Loss: 0.5685
Batch 90, Loss: 0.5536
Batch 100, Loss: 0.5522
Batch 110, Loss: 0.5505
Batch 120, Loss: 0.5312
Batch 130, Loss: 0.5385
Batch 140, Loss: 0.5682
Batch 150, Loss: 0.5732
Batch 160, Loss: 0.5772
Batch 170, Loss: 0.5647
Batch 180, Loss: 0.5621
Batch 190, Loss: 0.5657
Batch 200, Loss: 0.5612
Batch 210, Loss: 0.5571
Batch 220, Loss: 0.5399
Batch 230, Loss: 0.5234
Batch 240, Loss: 0.5631
Batch 250, Loss: 0.5634
Batch 260, Loss: 0.5965
Batch 270, Loss: 0.5571
Batch 280, Loss: 0.5482
Batch 290, Loss: 0.5249
Batch 300, Loss: 0.5253
Batch 310, Loss: 0.5777
Batch 320, Loss: 0.5568
Batch 330, Loss: 0.5191
Batch 340, Loss: 0.5080
Batch 350, Loss: 0.5507
Batch 360, Loss: 0.5859
Batch 370, Loss: 0.5779
Batch 380, Loss: 0.5541
Batch 390, Loss: 0.5593
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.328226566314697 seconds
Epoch 42 accuracy: 82.39%
Batch 10, Loss: 0.5271
Batch 20, Loss: 0.5418
Batch 30, Loss: 0.5432
Batch 40, Loss: 0.5844
Batch 50, Loss: 0.5899
Batch 60, Loss: 0.5550
Batch 70, Loss: 0.5697
Batch 80, Loss: 0.5484
Batch 90, Loss: 0.5804
Batch 100, Loss: 0.5291
Batch 110, Loss: 0.5333
Batch 120, Loss: 0.5645
Batch 130, Loss: 0.5545
Batch 140, Loss: 0.5529
Batch 150, Loss: 0.5827
Batch 160, Loss: 0.5511
Batch 170, Loss: 0.5970
Batch 180, Loss: 0.5713
Batch 190, Loss: 0.5388
Batch 200, Loss: 0.5708
Batch 210, Loss: 0.5529
Batch 220, Loss: 0.5391
Batch 230, Loss: 0.5232
Batch 240, Loss: 0.5356
Batch 250, Loss: 0.5385
Batch 260, Loss: 0.5391
Batch 270, Loss: 0.5815
Batch 280, Loss: 0.5513
Batch 290, Loss: 0.5900
Batch 300, Loss: 0.5800
Batch 310, Loss: 0.5531
Batch 320, Loss: 0.5615
Batch 330, Loss: 0.5578
Batch 340, Loss: 0.5568
Batch 350, Loss: 0.5252
Batch 360, Loss: 0.5893
Batch 370, Loss: 0.5164
Batch 380, Loss: 0.5432
Batch 390, Loss: 0.5604
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.34973168373108 seconds
Epoch 43 accuracy: 81.75%
Batch 10, Loss: 0.5595
Batch 20, Loss: 0.5637
Batch 30, Loss: 0.5456
Batch 40, Loss: 0.6052
Batch 50, Loss: 0.5886
Batch 60, Loss: 0.5718
Batch 70, Loss: 0.5505
Batch 80, Loss: 0.6016
Batch 90, Loss: 0.5928
Batch 100, Loss: 0.5502
Batch 110, Loss: 0.5270
Batch 120, Loss: 0.5460
Batch 130, Loss: 0.5677
Batch 140, Loss: 0.5378
Batch 150, Loss: 0.5858
Batch 160, Loss: 0.5377
Batch 170, Loss: 0.5403
Batch 180, Loss: 0.5401
Batch 190, Loss: 0.5470
Batch 200, Loss: 0.5499
Batch 210, Loss: 0.5169
Batch 220, Loss: 0.5447
Batch 230, Loss: 0.5328
Batch 240, Loss: 0.5536
Batch 250, Loss: 0.5424
Batch 260, Loss: 0.5470
Batch 270, Loss: 0.5357
Batch 280, Loss: 0.5661
Batch 290, Loss: 0.5494
Batch 300, Loss: 0.5220
Batch 310, Loss: 0.5743
Batch 320, Loss: 0.5590
Batch 330, Loss: 0.5404
Batch 340, Loss: 0.5486
Batch 350, Loss: 0.5736
Batch 360, Loss: 0.5932
Batch 370, Loss: 0.5327
Batch 380, Loss: 0.5388
Batch 390, Loss: 0.5290
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.311167240142822 seconds
Epoch 44 accuracy: 80.98%
Batch 10, Loss: 0.5421
Batch 20, Loss: 0.5258
Batch 30, Loss: 0.4936
Batch 40, Loss: 0.5579
Batch 50, Loss: 0.5415
Batch 60, Loss: 0.4995
Batch 70, Loss: 0.5151
Batch 80, Loss: 0.5294
Batch 90, Loss: 0.6033
Batch 100, Loss: 0.5376
Batch 110, Loss: 0.5545
Batch 120, Loss: 0.5500
Batch 130, Loss: 0.5393
Batch 140, Loss: 0.5715
Batch 150, Loss: 0.5593
Batch 160, Loss: 0.5640
Batch 170, Loss: 0.5794
Batch 180, Loss: 0.5516
Batch 190, Loss: 0.5884
Batch 200, Loss: 0.5310
Batch 210, Loss: 0.5682
Batch 220, Loss: 0.5737
Batch 230, Loss: 0.5279
Batch 240, Loss: 0.5396
Batch 250, Loss: 0.6065
Batch 260, Loss: 0.5309
Batch 270, Loss: 0.5250
Batch 280, Loss: 0.5472
Batch 290, Loss: 0.5697
Batch 300, Loss: 0.5510
Batch 310, Loss: 0.5457
Batch 320, Loss: 0.5726
Batch 330, Loss: 0.5504
Batch 340, Loss: 0.5479
Batch 350, Loss: 0.5504
Batch 360, Loss: 0.5534
Batch 370, Loss: 0.5593
Batch 380, Loss: 0.6098
Batch 390, Loss: 0.5326
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.296685218811035 seconds
Epoch 45 accuracy: 81.85%
Batch 10, Loss: 0.5306
Batch 20, Loss: 0.5294
Batch 30, Loss: 0.5403
Batch 40, Loss: 0.5549
Batch 50, Loss: 0.5219
Batch 60, Loss: 0.5459
Batch 70, Loss: 0.5625
Batch 80, Loss: 0.5393
Batch 90, Loss: 0.5599
Batch 100, Loss: 0.5468
Batch 110, Loss: 0.5328
Batch 120, Loss: 0.5013
Batch 130, Loss: 0.5488
Batch 140, Loss: 0.5307
Batch 150, Loss: 0.5627
Batch 160, Loss: 0.5785
Batch 170, Loss: 0.5368
Batch 180, Loss: 0.5386
Batch 190, Loss: 0.5408
Batch 200, Loss: 0.5197
Batch 210, Loss: 0.5560
Batch 220, Loss: 0.5259
Batch 230, Loss: 0.5474
Batch 240, Loss: 0.5657
Batch 250, Loss: 0.5637
Batch 260, Loss: 0.5247
Batch 270, Loss: 0.5344
Batch 280, Loss: 0.5549
Batch 290, Loss: 0.5098
Batch 300, Loss: 0.6044
Batch 310, Loss: 0.5936
Batch 320, Loss: 0.5401
Batch 330, Loss: 0.5213
Batch 340, Loss: 0.5518
Batch 350, Loss: 0.5374
Batch 360, Loss: 0.5781
Batch 370, Loss: 0.5600
Batch 380, Loss: 0.5660
Batch 390, Loss: 0.5431
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.271013975143433 seconds
Epoch 46 accuracy: 84.13%
Batch 10, Loss: 0.5698
Batch 20, Loss: 0.5176
Batch 30, Loss: 0.5287
Batch 40, Loss: 0.5901
Batch 50, Loss: 0.5711
Batch 60, Loss: 0.5309
Batch 70, Loss: 0.5144
Batch 80, Loss: 0.5472
Batch 90, Loss: 0.5495
Batch 100, Loss: 0.5203
Batch 110, Loss: 0.5564
Batch 120, Loss: 0.5698
Batch 130, Loss: 0.5371
Batch 140, Loss: 0.5743
Batch 150, Loss: 0.5538
Batch 160, Loss: 0.5393
Batch 170, Loss: 0.5222
Batch 180, Loss: 0.5688
Batch 190, Loss: 0.5563
Batch 200, Loss: 0.5476
Batch 210, Loss: 0.5979
Batch 220, Loss: 0.5500
Batch 230, Loss: 0.5442
Batch 240, Loss: 0.5298
Batch 250, Loss: 0.5292
Batch 260, Loss: 0.5254
Batch 270, Loss: 0.5167
Batch 280, Loss: 0.5273
Batch 290, Loss: 0.5196
Batch 300, Loss: 0.5072
Batch 310, Loss: 0.5244
Batch 320, Loss: 0.5099
Batch 330, Loss: 0.5827
Batch 340, Loss: 0.5535
Batch 350, Loss: 0.5408
Batch 360, Loss: 0.5252
Batch 370, Loss: 0.5607
Batch 380, Loss: 0.5607
Batch 390, Loss: 0.5087
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.396604537963867 seconds
Epoch 47 accuracy: 81.26%
Batch 10, Loss: 0.5389
Batch 20, Loss: 0.5425
Batch 30, Loss: 0.5039
Batch 40, Loss: 0.5641
Batch 50, Loss: 0.5936
Batch 60, Loss: 0.5432
Batch 70, Loss: 0.5455
Batch 80, Loss: 0.5447
Batch 90, Loss: 0.5134
Batch 100, Loss: 0.5166
Batch 110, Loss: 0.5342
Batch 120, Loss: 0.5539
Batch 130, Loss: 0.5578
Batch 140, Loss: 0.5741
Batch 150, Loss: 0.5338
Batch 160, Loss: 0.5777
Batch 170, Loss: 0.5477
Batch 180, Loss: 0.5250
Batch 190, Loss: 0.4955
Batch 200, Loss: 0.5159
Batch 210, Loss: 0.5307
Batch 220, Loss: 0.5573
Batch 230, Loss: 0.5329
Batch 240, Loss: 0.5348
Batch 250, Loss: 0.5386
Batch 260, Loss: 0.5286
Batch 270, Loss: 0.5160
Batch 280, Loss: 0.5109
Batch 290, Loss: 0.5225
Batch 300, Loss: 0.5519
Batch 310, Loss: 0.5543
Batch 320, Loss: 0.5432
Batch 330, Loss: 0.5504
Batch 340, Loss: 0.5590
Batch 350, Loss: 0.5230
Batch 360, Loss: 0.4992
Batch 370, Loss: 0.5740
Batch 380, Loss: 0.5689
Batch 390, Loss: 0.5525
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.287752151489258 seconds
Epoch 48 accuracy: 82.38%
Batch 10, Loss: 0.5242
Batch 20, Loss: 0.5438
Batch 30, Loss: 0.5017
Batch 40, Loss: 0.5585
Batch 50, Loss: 0.5199
Batch 60, Loss: 0.5146
Batch 70, Loss: 0.5557
Batch 80, Loss: 0.5169
Batch 90, Loss: 0.5676
Batch 100, Loss: 0.5069
Batch 110, Loss: 0.5471
Batch 120, Loss: 0.5352
Batch 130, Loss: 0.5327
Batch 140, Loss: 0.5357
Batch 150, Loss: 0.5298
Batch 160, Loss: 0.5191
Batch 170, Loss: 0.5548
Batch 180, Loss: 0.5355
Batch 190, Loss: 0.5364
Batch 200, Loss: 0.5598
Batch 210, Loss: 0.5821
Batch 220, Loss: 0.5404
Batch 230, Loss: 0.5226
Batch 240, Loss: 0.5746
Batch 250, Loss: 0.5596
Batch 260, Loss: 0.5336
Batch 270, Loss: 0.5212
Batch 280, Loss: 0.4893
Batch 290, Loss: 0.5280
Batch 300, Loss: 0.5601
Batch 310, Loss: 0.5146
Batch 320, Loss: 0.5150
Batch 330, Loss: 0.5249
Batch 340, Loss: 0.5572
Batch 350, Loss: 0.5460
Batch 360, Loss: 0.5269
Batch 370, Loss: 0.5762
Batch 380, Loss: 0.6058
Batch 390, Loss: 0.5775
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.291337490081787 seconds
Epoch 49 accuracy: 83.32%
Batch 10, Loss: 0.5542
Batch 20, Loss: 0.5165
Batch 30, Loss: 0.5248
Batch 40, Loss: 0.5111
Batch 50, Loss: 0.5227
Batch 60, Loss: 0.5131
Batch 70, Loss: 0.5128
Batch 80, Loss: 0.5239
Batch 90, Loss: 0.5021
Batch 100, Loss: 0.5147
Batch 110, Loss: 0.5028
Batch 120, Loss: 0.5088
Batch 130, Loss: 0.5322
Batch 140, Loss: 0.5274
Batch 150, Loss: 0.5286
Batch 160, Loss: 0.5685
Batch 170, Loss: 0.5394
Batch 180, Loss: 0.5508
Batch 190, Loss: 0.5700
Batch 200, Loss: 0.5270
Batch 210, Loss: 0.5379
Batch 220, Loss: 0.5494
Batch 230, Loss: 0.5701
Batch 240, Loss: 0.5767
Batch 250, Loss: 0.5768
Batch 260, Loss: 0.5470
Batch 270, Loss: 0.5401
Batch 280, Loss: 0.5403
Batch 290, Loss: 0.5206
Batch 300, Loss: 0.5492
Batch 310, Loss: 0.5073
Batch 320, Loss: 0.5417
Batch 330, Loss: 0.5495
Batch 340, Loss: 0.5401
Batch 350, Loss: 0.5545
Batch 360, Loss: 0.5532
Batch 370, Loss: 0.5354
Batch 380, Loss: 0.5686
Batch 390, Loss: 0.5427
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.29470729827881 seconds
Epoch 50 accuracy: 80.93%
Batch 10, Loss: 0.5561
Batch 20, Loss: 0.5242
Batch 30, Loss: 0.5283
Batch 40, Loss: 0.5111
Batch 50, Loss: 0.5185
Batch 60, Loss: 0.5236
Batch 70, Loss: 0.5489
Batch 80, Loss: 0.5419
Batch 90, Loss: 0.5515
Batch 100, Loss: 0.5775
Batch 110, Loss: 0.5410
Batch 120, Loss: 0.4975
Batch 130, Loss: 0.5380
Batch 140, Loss: 0.5126
Batch 150, Loss: 0.5410
Batch 160, Loss: 0.5409
Batch 170, Loss: 0.5503
Batch 180, Loss: 0.5425
Batch 190, Loss: 0.5355
Batch 200, Loss: 0.5337
Batch 210, Loss: 0.5712
Batch 220, Loss: 0.5643
Batch 230, Loss: 0.5838
Batch 240, Loss: 0.5766
Batch 250, Loss: 0.5220
Batch 260, Loss: 0.5349
Batch 270, Loss: 0.5521
Batch 280, Loss: 0.5345
Batch 290, Loss: 0.5401
Batch 300, Loss: 0.5196
Batch 310, Loss: 0.5136
Batch 320, Loss: 0.4905
Batch 330, Loss: 0.5231
Batch 340, Loss: 0.5527
Batch 350, Loss: 0.5174
Batch 360, Loss: 0.5777
Batch 370, Loss: 0.5334
Batch 380, Loss: 0.5237
Batch 390, Loss: 0.4954
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.24835753440857 seconds
Epoch 51 accuracy: 86.07%
Batch 10, Loss: 0.5391
Batch 20, Loss: 0.5293
Batch 30, Loss: 0.5083
Batch 40, Loss: 0.5291
Batch 50, Loss: 0.5039
Batch 60, Loss: 0.5057
Batch 70, Loss: 0.5130
Batch 80, Loss: 0.5416
Batch 90, Loss: 0.5118
Batch 100, Loss: 0.5445
Batch 110, Loss: 0.5370
Batch 120, Loss: 0.5556
Batch 130, Loss: 0.5133
Batch 140, Loss: 0.5249
Batch 150, Loss: 0.5175
Batch 160, Loss: 0.5596
Batch 170, Loss: 0.5392
Batch 180, Loss: 0.5592
Batch 190, Loss: 0.5643
Batch 200, Loss: 0.5144
Batch 210, Loss: 0.5107
Batch 220, Loss: 0.5194
Batch 230, Loss: 0.5555
Batch 240, Loss: 0.5430
Batch 250, Loss: 0.5251
Batch 260, Loss: 0.5482
Batch 270, Loss: 0.5176
Batch 280, Loss: 0.5324
Batch 290, Loss: 0.5233
Batch 300, Loss: 0.5248
Batch 310, Loss: 0.5551
Batch 320, Loss: 0.5262
Batch 330, Loss: 0.5292
Batch 340, Loss: 0.5345
Batch 350, Loss: 0.5487
Batch 360, Loss: 0.5334
Batch 370, Loss: 0.5686
Batch 380, Loss: 0.5912
Batch 390, Loss: 0.5658
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.2934308052063 seconds
Epoch 52 accuracy: 82.4%
Batch 10, Loss: 0.5394
Batch 20, Loss: 0.5113
Batch 30, Loss: 0.4688
Batch 40, Loss: 0.5236
Batch 50, Loss: 0.5530
Batch 60, Loss: 0.5624
Batch 70, Loss: 0.4778
Batch 80, Loss: 0.5154
Batch 90, Loss: 0.5506
Batch 100, Loss: 0.5614
Batch 110, Loss: 0.5721
Batch 120, Loss: 0.5625
Batch 130, Loss: 0.5500
Batch 140, Loss: 0.5161
Batch 150, Loss: 0.5317
Batch 160, Loss: 0.5086
Batch 170, Loss: 0.5257
Batch 180, Loss: 0.5141
Batch 190, Loss: 0.5216
Batch 200, Loss: 0.4989
Batch 210, Loss: 0.5503
Batch 220, Loss: 0.5420
Batch 230, Loss: 0.5238
Batch 240, Loss: 0.5444
Batch 250, Loss: 0.4867
Batch 260, Loss: 0.4857
Batch 270, Loss: 0.5246
Batch 280, Loss: 0.5352
Batch 290, Loss: 0.5732
Batch 300, Loss: 0.5453
Batch 310, Loss: 0.5262
Batch 320, Loss: 0.5365
Batch 330, Loss: 0.5711
Batch 340, Loss: 0.5688
Batch 350, Loss: 0.5593
Batch 360, Loss: 0.4979
Batch 370, Loss: 0.5490
Batch 380, Loss: 0.5126
Batch 390, Loss: 0.5521
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.326330184936523 seconds
Epoch 53 accuracy: 85.11%
Batch 10, Loss: 0.5237
Batch 20, Loss: 0.5659
Batch 30, Loss: 0.5384
Batch 40, Loss: 0.5401
Batch 50, Loss: 0.5223
Batch 60, Loss: 0.5230
Batch 70, Loss: 0.5281
Batch 80, Loss: 0.5245
Batch 90, Loss: 0.5238
Batch 100, Loss: 0.5200
Batch 110, Loss: 0.5416
Batch 120, Loss: 0.4983
Batch 130, Loss: 0.5162
Batch 140, Loss: 0.5500
Batch 150, Loss: 0.5572
Batch 160, Loss: 0.5264
Batch 170, Loss: 0.5265
Batch 180, Loss: 0.5322
Batch 190, Loss: 0.5033
Batch 200, Loss: 0.4856
Batch 210, Loss: 0.5013
Batch 220, Loss: 0.5492
Batch 230, Loss: 0.5612
Batch 240, Loss: 0.5147
Batch 250, Loss: 0.5626
Batch 260, Loss: 0.5539
Batch 270, Loss: 0.4709
Batch 280, Loss: 0.5542
Batch 290, Loss: 0.4904
Batch 300, Loss: 0.5274
Batch 310, Loss: 0.5151
Batch 320, Loss: 0.5328
Batch 330, Loss: 0.5565
Batch 340, Loss: 0.5237
Batch 350, Loss: 0.5467
Batch 360, Loss: 0.5605
Batch 370, Loss: 0.5625
Batch 380, Loss: 0.5340
Batch 390, Loss: 0.5494
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.34309220314026 seconds
Epoch 54 accuracy: 84.33%
Batch 10, Loss: 0.5798
Batch 20, Loss: 0.5345
Batch 30, Loss: 0.4800
Batch 40, Loss: 0.4937
Batch 50, Loss: 0.5099
Batch 60, Loss: 0.5650
Batch 70, Loss: 0.5215
Batch 80, Loss: 0.5037
Batch 90, Loss: 0.5073
Batch 100, Loss: 0.5437
Batch 110, Loss: 0.5404
Batch 120, Loss: 0.5753
Batch 130, Loss: 0.5373
Batch 140, Loss: 0.5100
Batch 150, Loss: 0.5577
Batch 160, Loss: 0.5584
Batch 170, Loss: 0.5434
Batch 180, Loss: 0.5324
Batch 190, Loss: 0.5202
Batch 200, Loss: 0.4699
Batch 210, Loss: 0.5072
Batch 220, Loss: 0.5848
Batch 230, Loss: 0.5594
Batch 240, Loss: 0.5232
Batch 250, Loss: 0.5332
Batch 260, Loss: 0.5267
Batch 270, Loss: 0.5245
Batch 280, Loss: 0.5571
Batch 290, Loss: 0.5804
Batch 300, Loss: 0.5304
Batch 310, Loss: 0.4953
Batch 320, Loss: 0.5396
Batch 330, Loss: 0.5265
Batch 340, Loss: 0.5281
Batch 350, Loss: 0.5333
Batch 360, Loss: 0.5293
Batch 370, Loss: 0.5455
Batch 380, Loss: 0.4998
Batch 390, Loss: 0.5246
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.268908262252808 seconds
Epoch 55 accuracy: 84.5%
Batch 10, Loss: 0.5562
Batch 20, Loss: 0.5263
Batch 30, Loss: 0.5097
Batch 40, Loss: 0.5341
Batch 50, Loss: 0.4958
Batch 60, Loss: 0.5268
Batch 70, Loss: 0.5300
Batch 80, Loss: 0.5138
Batch 90, Loss: 0.5387
Batch 100, Loss: 0.5101
Batch 110, Loss: 0.5451
Batch 120, Loss: 0.5422
Batch 130, Loss: 0.5101
Batch 140, Loss: 0.5279
Batch 150, Loss: 0.5380
Batch 160, Loss: 0.5313
Batch 170, Loss: 0.5373
Batch 180, Loss: 0.5353
Batch 190, Loss: 0.4997
Batch 200, Loss: 0.5472
Batch 210, Loss: 0.5188
Batch 220, Loss: 0.5163
Batch 230, Loss: 0.5385
Batch 240, Loss: 0.5531
Batch 250, Loss: 0.5495
Batch 260, Loss: 0.5228
Batch 270, Loss: 0.4858
Batch 280, Loss: 0.5563
Batch 290, Loss: 0.4927
Batch 300, Loss: 0.4925
Batch 310, Loss: 0.5051
Batch 320, Loss: 0.5432
Batch 330, Loss: 0.4898
Batch 340, Loss: 0.5460
Batch 350, Loss: 0.5532
Batch 360, Loss: 0.5470
Batch 370, Loss: 0.5231
Batch 380, Loss: 0.5544
Batch 390, Loss: 0.5591
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.357935428619385 seconds
Epoch 56 accuracy: 85.47%
Batch 10, Loss: 0.5158
Batch 20, Loss: 0.5093
Batch 30, Loss: 0.5303
Batch 40, Loss: 0.5016
Batch 50, Loss: 0.5453
Batch 60, Loss: 0.5331
Batch 70, Loss: 0.5268
Batch 80, Loss: 0.4883
Batch 90, Loss: 0.4950
Batch 100, Loss: 0.5341
Batch 110, Loss: 0.5613
Batch 120, Loss: 0.5108
Batch 130, Loss: 0.5247
Batch 140, Loss: 0.5447
Batch 150, Loss: 0.5054
Batch 160, Loss: 0.5087
Batch 170, Loss: 0.5315
Batch 180, Loss: 0.4825
Batch 190, Loss: 0.5488
Batch 200, Loss: 0.5170
Batch 210, Loss: 0.5335
Batch 220, Loss: 0.5354
Batch 230, Loss: 0.5040
Batch 240, Loss: 0.5353
Batch 250, Loss: 0.5323
Batch 260, Loss: 0.5605
Batch 270, Loss: 0.5231
Batch 280, Loss: 0.5398
Batch 290, Loss: 0.5141
Batch 300, Loss: 0.5264
Batch 310, Loss: 0.5384
Batch 320, Loss: 0.5200
Batch 330, Loss: 0.5059
Batch 340, Loss: 0.5024
Batch 350, Loss: 0.5156
Batch 360, Loss: 0.5119
Batch 370, Loss: 0.5093
Batch 380, Loss: 0.6037
Batch 390, Loss: 0.5445
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.14123272895813 seconds
Epoch 57 accuracy: 80.54%
Batch 10, Loss: 0.5082
Batch 20, Loss: 0.5401
Batch 30, Loss: 0.4928
Batch 40, Loss: 0.5654
Batch 50, Loss: 0.5227
Batch 60, Loss: 0.5312
Batch 70, Loss: 0.5381
Batch 80, Loss: 0.5138
Batch 90, Loss: 0.5424
Batch 100, Loss: 0.5401
Batch 110, Loss: 0.5454
Batch 120, Loss: 0.5173
Batch 130, Loss: 0.5016
Batch 140, Loss: 0.5240
Batch 150, Loss: 0.5051
Batch 160, Loss: 0.5258
Batch 170, Loss: 0.5235
Batch 180, Loss: 0.5257
Batch 190, Loss: 0.4992
Batch 200, Loss: 0.5208
Batch 210, Loss: 0.4809
Batch 220, Loss: 0.5277
Batch 230, Loss: 0.5522
Batch 240, Loss: 0.5693
Batch 250, Loss: 0.5081
Batch 260, Loss: 0.4948
Batch 270, Loss: 0.5319
Batch 280, Loss: 0.5340
Batch 290, Loss: 0.5526
Batch 300, Loss: 0.5418
Batch 310, Loss: 0.5703
Batch 320, Loss: 0.4891
Batch 330, Loss: 0.5225
Batch 340, Loss: 0.5153
Batch 350, Loss: 0.5198
Batch 360, Loss: 0.4870
Batch 370, Loss: 0.4950
Batch 380, Loss: 0.5054
Batch 390, Loss: 0.5221
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.341440677642822 seconds
Epoch 58 accuracy: 85.67%
Batch 10, Loss: 0.5036
Batch 20, Loss: 0.5110
Batch 30, Loss: 0.5348
Batch 40, Loss: 0.5218
Batch 50, Loss: 0.5178
Batch 60, Loss: 0.5244
Batch 70, Loss: 0.5264
Batch 80, Loss: 0.5226
Batch 90, Loss: 0.4844
Batch 100, Loss: 0.5133
Batch 110, Loss: 0.5461
Batch 120, Loss: 0.4916
Batch 130, Loss: 0.5213
Batch 140, Loss: 0.5376
Batch 150, Loss: 0.5322
Batch 160, Loss: 0.5400
Batch 170, Loss: 0.5272
Batch 180, Loss: 0.5193
Batch 190, Loss: 0.5032
Batch 200, Loss: 0.5256
Batch 210, Loss: 0.5153
Batch 220, Loss: 0.5525
Batch 230, Loss: 0.5331
Batch 240, Loss: 0.5123
Batch 250, Loss: 0.5349
Batch 260, Loss: 0.5593
Batch 270, Loss: 0.5146
Batch 280, Loss: 0.5077
Batch 290, Loss: 0.5085
Batch 300, Loss: 0.5160
Batch 310, Loss: 0.5364
Batch 320, Loss: 0.5200
Batch 330, Loss: 0.5248
Batch 340, Loss: 0.5211
Batch 350, Loss: 0.5388
Batch 360, Loss: 0.5274
Batch 370, Loss: 0.5047
Batch 380, Loss: 0.5339
Batch 390, Loss: 0.5066
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.401886463165283 seconds
Epoch 59 accuracy: 83.59%
Batch 10, Loss: 0.5128
Batch 20, Loss: 0.5503
Batch 30, Loss: 0.4990
Batch 40, Loss: 0.4826
Batch 50, Loss: 0.5580
Batch 60, Loss: 0.4556
Batch 70, Loss: 0.5164
Batch 80, Loss: 0.5363
Batch 90, Loss: 0.5091
Batch 100, Loss: 0.5230
Batch 110, Loss: 0.5280
Batch 120, Loss: 0.5008
Batch 130, Loss: 0.5403
Batch 140, Loss: 0.5195
Batch 150, Loss: 0.5099
Batch 160, Loss: 0.4875
Batch 170, Loss: 0.5165
Batch 180, Loss: 0.5016
Batch 190, Loss: 0.5190
Batch 200, Loss: 0.5062
Batch 210, Loss: 0.5431
Batch 220, Loss: 0.4604
Batch 230, Loss: 0.4950
Batch 240, Loss: 0.5092
Batch 250, Loss: 0.4919
Batch 260, Loss: 0.5509
Batch 270, Loss: 0.5350
Batch 280, Loss: 0.5254
Batch 290, Loss: 0.5049
Batch 300, Loss: 0.4890
Batch 310, Loss: 0.5431
Batch 320, Loss: 0.5073
Batch 330, Loss: 0.5121
Batch 340, Loss: 0.5251
Batch 350, Loss: 0.5571
Batch 360, Loss: 0.5287
Batch 370, Loss: 0.5096
Batch 380, Loss: 0.5309
Batch 390, Loss: 0.5371
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.25910210609436 seconds
Epoch 60 accuracy: 80.5%
Batch 10, Loss: 0.5101
Batch 20, Loss: 0.5139
Batch 30, Loss: 0.4623
Batch 40, Loss: 0.5059
Batch 50, Loss: 0.4804
Batch 60, Loss: 0.5362
Batch 70, Loss: 0.5173
Batch 80, Loss: 0.4988
Batch 90, Loss: 0.4918
Batch 100, Loss: 0.5048
Batch 110, Loss: 0.4762
Batch 120, Loss: 0.5162
Batch 130, Loss: 0.4842
Batch 140, Loss: 0.4903
Batch 150, Loss: 0.5426
Batch 160, Loss: 0.5202
Batch 170, Loss: 0.5107
Batch 180, Loss: 0.5267
Batch 190, Loss: 0.5141
Batch 200, Loss: 0.5328
Batch 210, Loss: 0.5056
Batch 220, Loss: 0.4999
Batch 230, Loss: 0.5010
Batch 240, Loss: 0.5364
Batch 250, Loss: 0.5088
Batch 260, Loss: 0.5363
Batch 270, Loss: 0.5185
Batch 280, Loss: 0.5259
Batch 290, Loss: 0.5285
Batch 300, Loss: 0.5479
Batch 310, Loss: 0.5122
Batch 320, Loss: 0.4980
Batch 330, Loss: 0.4884
Batch 340, Loss: 0.5273
Batch 350, Loss: 0.5264
Batch 360, Loss: 0.5005
Batch 370, Loss: 0.5018
Batch 380, Loss: 0.5551
Batch 390, Loss: 0.5150
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.207239627838135 seconds
Epoch 61 accuracy: 85.33%
Batch 10, Loss: 0.5109
Batch 20, Loss: 0.5300
Batch 30, Loss: 0.5587
Batch 40, Loss: 0.5044
Batch 50, Loss: 0.5269
Batch 60, Loss: 0.5286
Batch 70, Loss: 0.5197
Batch 80, Loss: 0.4737
Batch 90, Loss: 0.5279
Batch 100, Loss: 0.5225
Batch 110, Loss: 0.5345
Batch 120, Loss: 0.5636
Batch 130, Loss: 0.5103
Batch 140, Loss: 0.5226
Batch 150, Loss: 0.4941
Batch 160, Loss: 0.5267
Batch 170, Loss: 0.5462
Batch 180, Loss: 0.5315
Batch 190, Loss: 0.5322
Batch 200, Loss: 0.4846
Batch 210, Loss: 0.4968
Batch 220, Loss: 0.5239
Batch 230, Loss: 0.5253
Batch 240, Loss: 0.5385
Batch 250, Loss: 0.5292
Batch 260, Loss: 0.4981
Batch 270, Loss: 0.5071
Batch 280, Loss: 0.5096
Batch 290, Loss: 0.5132
Batch 300, Loss: 0.5270
Batch 310, Loss: 0.5400
Batch 320, Loss: 0.5374
Batch 330, Loss: 0.5530
Batch 340, Loss: 0.5319
Batch 350, Loss: 0.5064
Batch 360, Loss: 0.5035
Batch 370, Loss: 0.5130
Batch 380, Loss: 0.5287
Batch 390, Loss: 0.4911
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.249096393585205 seconds
Epoch 62 accuracy: 84.67%
Batch 10, Loss: 0.4917
Batch 20, Loss: 0.5091
Batch 30, Loss: 0.5059
Batch 40, Loss: 0.5002
Batch 50, Loss: 0.4662
Batch 60, Loss: 0.5035
Batch 70, Loss: 0.5003
Batch 80, Loss: 0.5296
Batch 90, Loss: 0.5228
Batch 100, Loss: 0.5440
Batch 110, Loss: 0.4741
Batch 120, Loss: 0.5262
Batch 130, Loss: 0.5103
Batch 140, Loss: 0.4941
Batch 150, Loss: 0.5528
Batch 160, Loss: 0.5340
Batch 170, Loss: 0.5406
Batch 180, Loss: 0.5617
Batch 190, Loss: 0.4982
Batch 200, Loss: 0.5315
Batch 210, Loss: 0.5200
Batch 220, Loss: 0.5145
Batch 230, Loss: 0.5147
Batch 240, Loss: 0.5222
Batch 250, Loss: 0.5175
Batch 260, Loss: 0.5387
Batch 270, Loss: 0.5291
Batch 280, Loss: 0.5245
Batch 290, Loss: 0.5255
Batch 300, Loss: 0.5379
Batch 310, Loss: 0.5352
Batch 320, Loss: 0.5486
Batch 330, Loss: 0.5105
Batch 340, Loss: 0.5314
Batch 350, Loss: 0.5262
Batch 360, Loss: 0.5033
Batch 370, Loss: 0.5055
Batch 380, Loss: 0.4844
Batch 390, Loss: 0.5204
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.235259771347046 seconds
Epoch 63 accuracy: 86.41%
Batch 10, Loss: 0.4925
Batch 20, Loss: 0.5173
Batch 30, Loss: 0.5447
Batch 40, Loss: 0.5045
Batch 50, Loss: 0.4962
Batch 60, Loss: 0.5481
Batch 70, Loss: 0.4920
Batch 80, Loss: 0.5132
Batch 90, Loss: 0.4947
Batch 100, Loss: 0.4678
Batch 110, Loss: 0.4776
Batch 120, Loss: 0.5131
Batch 130, Loss: 0.4959
Batch 140, Loss: 0.5208
Batch 150, Loss: 0.5209
Batch 160, Loss: 0.5137
Batch 170, Loss: 0.5165
Batch 180, Loss: 0.4870
Batch 190, Loss: 0.5009
Batch 200, Loss: 0.4787
Batch 210, Loss: 0.5222
Batch 220, Loss: 0.4943
Batch 230, Loss: 0.5420
Batch 240, Loss: 0.5081
Batch 250, Loss: 0.5465
Batch 260, Loss: 0.4846
Batch 270, Loss: 0.4864
Batch 280, Loss: 0.4921
Batch 290, Loss: 0.4735
Batch 300, Loss: 0.5156
Batch 310, Loss: 0.4973
Batch 320, Loss: 0.5060
Batch 330, Loss: 0.4974
Batch 340, Loss: 0.4872
Batch 350, Loss: 0.4903
Batch 360, Loss: 0.5408
Batch 370, Loss: 0.5541
Batch 380, Loss: 0.5348
Batch 390, Loss: 0.5462
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.223037481307983 seconds
Epoch 64 accuracy: 81.23%
Batch 10, Loss: 0.4726
Batch 20, Loss: 0.5119
Batch 30, Loss: 0.4633
Batch 40, Loss: 0.4985
Batch 50, Loss: 0.5202
Batch 60, Loss: 0.4756
Batch 70, Loss: 0.4706
Batch 80, Loss: 0.5157
Batch 90, Loss: 0.4553
Batch 100, Loss: 0.5549
Batch 110, Loss: 0.5399
Batch 120, Loss: 0.5229
Batch 130, Loss: 0.5267
Batch 140, Loss: 0.5641
Batch 150, Loss: 0.5137
Batch 160, Loss: 0.4902
Batch 170, Loss: 0.5001
Batch 180, Loss: 0.5243
Batch 190, Loss: 0.5287
Batch 200, Loss: 0.4812
Batch 210, Loss: 0.4590
Batch 220, Loss: 0.4999
Batch 230, Loss: 0.4765
Batch 240, Loss: 0.4702
Batch 250, Loss: 0.5042
Batch 260, Loss: 0.5042
Batch 270, Loss: 0.5624
Batch 280, Loss: 0.5185
Batch 290, Loss: 0.5043
Batch 300, Loss: 0.4933
Batch 310, Loss: 0.5294
Batch 320, Loss: 0.5076
Batch 330, Loss: 0.4642
Batch 340, Loss: 0.5258
Batch 350, Loss: 0.5025
Batch 360, Loss: 0.5067
Batch 370, Loss: 0.5012
Batch 380, Loss: 0.5010
Batch 390, Loss: 0.5061
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.350745677947998 seconds
Epoch 65 accuracy: 80.61%
Batch 10, Loss: 0.5158
Batch 20, Loss: 0.5033
Batch 30, Loss: 0.4788
Batch 40, Loss: 0.5200
Batch 50, Loss: 0.4884
Batch 60, Loss: 0.5283
Batch 70, Loss: 0.5004
Batch 80, Loss: 0.5228
Batch 90, Loss: 0.5095
Batch 100, Loss: 0.4896
Batch 110, Loss: 0.4881
Batch 120, Loss: 0.5133
Batch 130, Loss: 0.5117
Batch 140, Loss: 0.4866
Batch 150, Loss: 0.4844
Batch 160, Loss: 0.5010
Batch 170, Loss: 0.5293
Batch 180, Loss: 0.5019
Batch 190, Loss: 0.4841
Batch 200, Loss: 0.4892
Batch 210, Loss: 0.5013
Batch 220, Loss: 0.5005
Batch 230, Loss: 0.5027
Batch 240, Loss: 0.5056
Batch 250, Loss: 0.5098
Batch 260, Loss: 0.4822
Batch 270, Loss: 0.5428
Batch 280, Loss: 0.5056
Batch 290, Loss: 0.4925
Batch 300, Loss: 0.5428
Batch 310, Loss: 0.5228
Batch 320, Loss: 0.4785
Batch 330, Loss: 0.5134
Batch 340, Loss: 0.5063
Batch 350, Loss: 0.5642
Batch 360, Loss: 0.5208
Batch 370, Loss: 0.5336
Batch 380, Loss: 0.4937
Batch 390, Loss: 0.5215
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.314188241958618 seconds
Epoch 66 accuracy: 84.68%
Batch 10, Loss: 0.5013
Batch 20, Loss: 0.4525
Batch 30, Loss: 0.5275
Batch 40, Loss: 0.5252
Batch 50, Loss: 0.5187
Batch 60, Loss: 0.5185
Batch 70, Loss: 0.4947
Batch 80, Loss: 0.5157
Batch 90, Loss: 0.4632
Batch 100, Loss: 0.4755
Batch 110, Loss: 0.5027
Batch 120, Loss: 0.5318
Batch 130, Loss: 0.5085
Batch 140, Loss: 0.5325
Batch 150, Loss: 0.4950
Batch 160, Loss: 0.5055
Batch 170, Loss: 0.4975
Batch 180, Loss: 0.4878
Batch 190, Loss: 0.5365
Batch 200, Loss: 0.5051
Batch 210, Loss: 0.5147
Batch 220, Loss: 0.5224
Batch 230, Loss: 0.5164
Batch 240, Loss: 0.4931
Batch 250, Loss: 0.5373
Batch 260, Loss: 0.5103
Batch 270, Loss: 0.5253
Batch 280, Loss: 0.5018
Batch 290, Loss: 0.4764
Batch 300, Loss: 0.5126
Batch 310, Loss: 0.5188
Batch 320, Loss: 0.4905
Batch 330, Loss: 0.5107
Batch 340, Loss: 0.4806
Batch 350, Loss: 0.4827
Batch 360, Loss: 0.5047
Batch 370, Loss: 0.5153
Batch 380, Loss: 0.5018
Batch 390, Loss: 0.4839
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.354074954986572 seconds
Epoch 67 accuracy: 85.35%
Batch 10, Loss: 0.5530
Batch 20, Loss: 0.4940
Batch 30, Loss: 0.4880
Batch 40, Loss: 0.4889
Batch 50, Loss: 0.5196
Batch 60, Loss: 0.5069
Batch 70, Loss: 0.4573
Batch 80, Loss: 0.4550
Batch 90, Loss: 0.5115
Batch 100, Loss: 0.4998
Batch 110, Loss: 0.5212
Batch 120, Loss: 0.5286
Batch 130, Loss: 0.4951
Batch 140, Loss: 0.5031
Batch 150, Loss: 0.5145
Batch 160, Loss: 0.5086
Batch 170, Loss: 0.4947
Batch 180, Loss: 0.5048
Batch 190, Loss: 0.5100
Batch 200, Loss: 0.5052
Batch 210, Loss: 0.5051
Batch 220, Loss: 0.4969
Batch 230, Loss: 0.4845
Batch 240, Loss: 0.4993
Batch 250, Loss: 0.5058
Batch 260, Loss: 0.4682
Batch 270, Loss: 0.4946
Batch 280, Loss: 0.5017
Batch 290, Loss: 0.4928
Batch 300, Loss: 0.4846
Batch 310, Loss: 0.5046
Batch 320, Loss: 0.4817
Batch 330, Loss: 0.5030
Batch 340, Loss: 0.5086
Batch 350, Loss: 0.5223
Batch 360, Loss: 0.5268
Batch 370, Loss: 0.5129
Batch 380, Loss: 0.5206
Batch 390, Loss: 0.5132
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.225281715393066 seconds
Epoch 68 accuracy: 87.24%
Batch 10, Loss: 0.4966
Batch 20, Loss: 0.4952
Batch 30, Loss: 0.5056
Batch 40, Loss: 0.4967
Batch 50, Loss: 0.4857
Batch 60, Loss: 0.5084
Batch 70, Loss: 0.5116
Batch 80, Loss: 0.4887
Batch 90, Loss: 0.4521
Batch 100, Loss: 0.5018
Batch 110, Loss: 0.4781
Batch 120, Loss: 0.5006
Batch 130, Loss: 0.4744
Batch 140, Loss: 0.4851
Batch 150, Loss: 0.4851
Batch 160, Loss: 0.5027
Batch 170, Loss: 0.4694
Batch 180, Loss: 0.5066
Batch 190, Loss: 0.4937
Batch 200, Loss: 0.4994
Batch 210, Loss: 0.4536
Batch 220, Loss: 0.5120
Batch 230, Loss: 0.5451
Batch 240, Loss: 0.5040
Batch 250, Loss: 0.4717
Batch 260, Loss: 0.5310
Batch 270, Loss: 0.5205
Batch 280, Loss: 0.4972
Batch 290, Loss: 0.5222
Batch 300, Loss: 0.4979
Batch 310, Loss: 0.4693
Batch 320, Loss: 0.4836
Batch 330, Loss: 0.5343
Batch 340, Loss: 0.5371
Batch 350, Loss: 0.4963
Batch 360, Loss: 0.5341
Batch 370, Loss: 0.5281
Batch 380, Loss: 0.5356
Batch 390, Loss: 0.4915
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.246458768844604 seconds
Epoch 69 accuracy: 85.24%
Batch 10, Loss: 0.4964
Batch 20, Loss: 0.4955
Batch 30, Loss: 0.4650
Batch 40, Loss: 0.4873
Batch 50, Loss: 0.5119
Batch 60, Loss: 0.5020
Batch 70, Loss: 0.4706
Batch 80, Loss: 0.4918
Batch 90, Loss: 0.4928
Batch 100, Loss: 0.5237
Batch 110, Loss: 0.4719
Batch 120, Loss: 0.5027
Batch 130, Loss: 0.5121
Batch 140, Loss: 0.5095
Batch 150, Loss: 0.5101
Batch 160, Loss: 0.5126
Batch 170, Loss: 0.4928
Batch 180, Loss: 0.5228
Batch 190, Loss: 0.4842
Batch 200, Loss: 0.5119
Batch 210, Loss: 0.5044
Batch 220, Loss: 0.5308
Batch 230, Loss: 0.5243
Batch 240, Loss: 0.5104
Batch 250, Loss: 0.4692
Batch 260, Loss: 0.5436
Batch 270, Loss: 0.4823
Batch 280, Loss: 0.4621
Batch 290, Loss: 0.5065
Batch 300, Loss: 0.4702
Batch 310, Loss: 0.5173
Batch 320, Loss: 0.5006
Batch 330, Loss: 0.5125
Batch 340, Loss: 0.4846
Batch 350, Loss: 0.4702
Batch 360, Loss: 0.4991
Batch 370, Loss: 0.5491
Batch 380, Loss: 0.4872
Batch 390, Loss: 0.5028
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.318937063217163 seconds
Epoch 70 accuracy: 84.66%
Batch 10, Loss: 0.5041
Batch 20, Loss: 0.4895
Batch 30, Loss: 0.4683
Batch 40, Loss: 0.5177
Batch 50, Loss: 0.4742
Batch 60, Loss: 0.4883
Batch 70, Loss: 0.5090
Batch 80, Loss: 0.5296
Batch 90, Loss: 0.4911
Batch 100, Loss: 0.4706
Batch 110, Loss: 0.4796
Batch 120, Loss: 0.5042
Batch 130, Loss: 0.5462
Batch 140, Loss: 0.4758
Batch 150, Loss: 0.4452
Batch 160, Loss: 0.5341
Batch 170, Loss: 0.4714
Batch 180, Loss: 0.5198
Batch 190, Loss: 0.4698
Batch 200, Loss: 0.5172
Batch 210, Loss: 0.5220
Batch 220, Loss: 0.4847
Batch 230, Loss: 0.4949
Batch 240, Loss: 0.4825
Batch 250, Loss: 0.5032
Batch 260, Loss: 0.5297
Batch 270, Loss: 0.4820
Batch 280, Loss: 0.4556
Batch 290, Loss: 0.4862
Batch 300, Loss: 0.4951
Batch 310, Loss: 0.4824
Batch 320, Loss: 0.5198
Batch 330, Loss: 0.5006
Batch 340, Loss: 0.5222
Batch 350, Loss: 0.5232
Batch 360, Loss: 0.5335
Batch 370, Loss: 0.5512
Batch 380, Loss: 0.4984
Batch 390, Loss: 0.4871
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.229512214660645 seconds
Epoch 71 accuracy: 88.05%
Batch 10, Loss: 0.5145
Batch 20, Loss: 0.4775
Batch 30, Loss: 0.4910
Batch 40, Loss: 0.4558
Batch 50, Loss: 0.4798
Batch 60, Loss: 0.4912
Batch 70, Loss: 0.4983
Batch 80, Loss: 0.5127
Batch 90, Loss: 0.4705
Batch 100, Loss: 0.4949
Batch 110, Loss: 0.4801
Batch 120, Loss: 0.5074
Batch 130, Loss: 0.5164
Batch 140, Loss: 0.4712
Batch 150, Loss: 0.5136
Batch 160, Loss: 0.5212
Batch 170, Loss: 0.5066
Batch 180, Loss: 0.5010
Batch 190, Loss: 0.4596
Batch 200, Loss: 0.4736
Batch 210, Loss: 0.5261
Batch 220, Loss: 0.4984
Batch 230, Loss: 0.5106
Batch 240, Loss: 0.4915
Batch 250, Loss: 0.4631
Batch 260, Loss: 0.4712
Batch 270, Loss: 0.4784
Batch 280, Loss: 0.4946
Batch 290, Loss: 0.4832
Batch 300, Loss: 0.5057
Batch 310, Loss: 0.4944
Batch 320, Loss: 0.4780
Batch 330, Loss: 0.5058
Batch 340, Loss: 0.5285
Batch 350, Loss: 0.5203
Batch 360, Loss: 0.4792
Batch 370, Loss: 0.4656
Batch 380, Loss: 0.4750
Batch 390, Loss: 0.5053
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.24641227722168 seconds
Epoch 72 accuracy: 84.99%
Batch 10, Loss: 0.4836
Batch 20, Loss: 0.4569
Batch 30, Loss: 0.4796
Batch 40, Loss: 0.4998
Batch 50, Loss: 0.4974
Batch 60, Loss: 0.4711
Batch 70, Loss: 0.5284
Batch 80, Loss: 0.4264
Batch 90, Loss: 0.4708
Batch 100, Loss: 0.4822
Batch 110, Loss: 0.4948
Batch 120, Loss: 0.4535
Batch 130, Loss: 0.4706
Batch 140, Loss: 0.4985
Batch 150, Loss: 0.4771
Batch 160, Loss: 0.4865
Batch 170, Loss: 0.5290
Batch 180, Loss: 0.5026
Batch 190, Loss: 0.4924
Batch 200, Loss: 0.5026
Batch 210, Loss: 0.5084
Batch 220, Loss: 0.5399
Batch 230, Loss: 0.5017
Batch 240, Loss: 0.4916
Batch 250, Loss: 0.4436
Batch 260, Loss: 0.5125
Batch 270, Loss: 0.4975
Batch 280, Loss: 0.4739
Batch 290, Loss: 0.4874
Batch 300, Loss: 0.4934
Batch 310, Loss: 0.4887
Batch 320, Loss: 0.5286
Batch 330, Loss: 0.4954
Batch 340, Loss: 0.5249
Batch 350, Loss: 0.5662
Batch 360, Loss: 0.5517
Batch 370, Loss: 0.4965
Batch 380, Loss: 0.5058
Batch 390, Loss: 0.4790
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.317965745925903 seconds
Epoch 73 accuracy: 84.92%
Batch 10, Loss: 0.4782
Batch 20, Loss: 0.5042
Batch 30, Loss: 0.4862
Batch 40, Loss: 0.4627
Batch 50, Loss: 0.4930
Batch 60, Loss: 0.4535
Batch 70, Loss: 0.5260
Batch 80, Loss: 0.4820
Batch 90, Loss: 0.5239
Batch 100, Loss: 0.5145
Batch 110, Loss: 0.5254
Batch 120, Loss: 0.5064
Batch 130, Loss: 0.5167
Batch 140, Loss: 0.5023
Batch 150, Loss: 0.4799
Batch 160, Loss: 0.5215
Batch 170, Loss: 0.4697
Batch 180, Loss: 0.5049
Batch 190, Loss: 0.5008
Batch 200, Loss: 0.4255
Batch 210, Loss: 0.4671
Batch 220, Loss: 0.4821
Batch 230, Loss: 0.5029
Batch 240, Loss: 0.5155
Batch 250, Loss: 0.4978
Batch 260, Loss: 0.5263
Batch 270, Loss: 0.5001
Batch 280, Loss: 0.4861
Batch 290, Loss: 0.4843
Batch 300, Loss: 0.5063
Batch 310, Loss: 0.4949
Batch 320, Loss: 0.5058
Batch 330, Loss: 0.4826
Batch 340, Loss: 0.4931
Batch 350, Loss: 0.5009
Batch 360, Loss: 0.5162
Batch 370, Loss: 0.4842
Batch 380, Loss: 0.4878
Batch 390, Loss: 0.4556
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.368226528167725 seconds
Epoch 74 accuracy: 88.2%
Batch 10, Loss: 0.4532
Batch 20, Loss: 0.5077
Batch 30, Loss: 0.4727
Batch 40, Loss: 0.4599
Batch 50, Loss: 0.5222
Batch 60, Loss: 0.4921
Batch 70, Loss: 0.4801
Batch 80, Loss: 0.4973
Batch 90, Loss: 0.4686
Batch 100, Loss: 0.4802
Batch 110, Loss: 0.4816
Batch 120, Loss: 0.4958
Batch 130, Loss: 0.4772
Batch 140, Loss: 0.4938
Batch 150, Loss: 0.4938
Batch 160, Loss: 0.4969
Batch 170, Loss: 0.5251
Batch 180, Loss: 0.4643
Batch 190, Loss: 0.4426
Batch 200, Loss: 0.5339
Batch 210, Loss: 0.4788
Batch 220, Loss: 0.5425
Batch 230, Loss: 0.5435
Batch 240, Loss: 0.5142
Batch 250, Loss: 0.5070
Batch 260, Loss: 0.5052
Batch 270, Loss: 0.4751
Batch 280, Loss: 0.5061
Batch 290, Loss: 0.4886
Batch 300, Loss: 0.4858
Batch 310, Loss: 0.4655
Batch 320, Loss: 0.4338
Batch 330, Loss: 0.4717
Batch 340, Loss: 0.4953
Batch 350, Loss: 0.5262
Batch 360, Loss: 0.4649
Batch 370, Loss: 0.4497
Batch 380, Loss: 0.4931
Batch 390, Loss: 0.4812
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.8149893283844 seconds
Epoch 75 accuracy: 82.41%
Batch 10, Loss: 0.4646
Batch 20, Loss: 0.4732
Batch 30, Loss: 0.4951
Batch 40, Loss: 0.4672
Batch 50, Loss: 0.4846
Batch 60, Loss: 0.4828
Batch 70, Loss: 0.5130
Batch 80, Loss: 0.5076
Batch 90, Loss: 0.4927
Batch 100, Loss: 0.5161
Batch 110, Loss: 0.4732
Batch 120, Loss: 0.5062
Batch 130, Loss: 0.4921
Batch 140, Loss: 0.4866
Batch 150, Loss: 0.4870
Batch 160, Loss: 0.5042
Batch 170, Loss: 0.4858
Batch 180, Loss: 0.4731
Batch 190, Loss: 0.4819
Batch 200, Loss: 0.4992
Batch 210, Loss: 0.5299
Batch 220, Loss: 0.4978
Batch 230, Loss: 0.4872
Batch 240, Loss: 0.4571
Batch 250, Loss: 0.4551
Batch 260, Loss: 0.4970
Batch 270, Loss: 0.4721
Batch 280, Loss: 0.4917
Batch 290, Loss: 0.5186
Batch 300, Loss: 0.5127
Batch 310, Loss: 0.4799
Batch 320, Loss: 0.4757
Batch 330, Loss: 0.5027
Batch 340, Loss: 0.4588
Batch 350, Loss: 0.5051
Batch 360, Loss: 0.4958
Batch 370, Loss: 0.4999
Batch 380, Loss: 0.4974
Batch 390, Loss: 0.5085
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.248405933380127 seconds
Epoch 76 accuracy: 84.49%
Batch 10, Loss: 0.4849
Batch 20, Loss: 0.4618
Batch 30, Loss: 0.4895
Batch 40, Loss: 0.5223
Batch 50, Loss: 0.4643
Batch 60, Loss: 0.4854
Batch 70, Loss: 0.4837
Batch 80, Loss: 0.5198
Batch 90, Loss: 0.4620
Batch 100, Loss: 0.4528
Batch 110, Loss: 0.4750
Batch 120, Loss: 0.4568
Batch 130, Loss: 0.4630
Batch 140, Loss: 0.4986
Batch 150, Loss: 0.4625
Batch 160, Loss: 0.4837
Batch 170, Loss: 0.5130
Batch 180, Loss: 0.4560
Batch 190, Loss: 0.4581
Batch 200, Loss: 0.5056
Batch 210, Loss: 0.4923
Batch 220, Loss: 0.4905
Batch 230, Loss: 0.5183
Batch 240, Loss: 0.4588
Batch 250, Loss: 0.5092
Batch 260, Loss: 0.5058
Batch 270, Loss: 0.4617
Batch 280, Loss: 0.5115
Batch 290, Loss: 0.4837
Batch 300, Loss: 0.5306
Batch 310, Loss: 0.4947
Batch 320, Loss: 0.4327
Batch 330, Loss: 0.4701
Batch 340, Loss: 0.4951
Batch 350, Loss: 0.4767
Batch 360, Loss: 0.4405
Batch 370, Loss: 0.4744
Batch 380, Loss: 0.4734
Batch 390, Loss: 0.5046
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.374308347702026 seconds
Epoch 77 accuracy: 86.49%
Batch 10, Loss: 0.4734
Batch 20, Loss: 0.4513
Batch 30, Loss: 0.4765
Batch 40, Loss: 0.5078
Batch 50, Loss: 0.4622
Batch 60, Loss: 0.4769
Batch 70, Loss: 0.4633
Batch 80, Loss: 0.4874
Batch 90, Loss: 0.5008
Batch 100, Loss: 0.4866
Batch 110, Loss: 0.4973
Batch 120, Loss: 0.5211
Batch 130, Loss: 0.4901
Batch 140, Loss: 0.4689
Batch 150, Loss: 0.4628
Batch 160, Loss: 0.4523
Batch 170, Loss: 0.4984
Batch 180, Loss: 0.4800
Batch 190, Loss: 0.4963
Batch 200, Loss: 0.5078
Batch 210, Loss: 0.4508
Batch 220, Loss: 0.4869
Batch 230, Loss: 0.5047
Batch 240, Loss: 0.5034
Batch 250, Loss: 0.5053
Batch 260, Loss: 0.4307
Batch 270, Loss: 0.4853
Batch 280, Loss: 0.5136
Batch 290, Loss: 0.5145
Batch 300, Loss: 0.4853
Batch 310, Loss: 0.5172
Batch 320, Loss: 0.4764
Batch 330, Loss: 0.4959
Batch 340, Loss: 0.5196
Batch 350, Loss: 0.4798
Batch 360, Loss: 0.4530
Batch 370, Loss: 0.4771
Batch 380, Loss: 0.4369
Batch 390, Loss: 0.4979
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.35345959663391 seconds
Epoch 78 accuracy: 86.79%
Batch 10, Loss: 0.4859
Batch 20, Loss: 0.5295
Batch 30, Loss: 0.4985
Batch 40, Loss: 0.4921
Batch 50, Loss: 0.5108
Batch 60, Loss: 0.4913
Batch 70, Loss: 0.4846
Batch 80, Loss: 0.4859
Batch 90, Loss: 0.4498
Batch 100, Loss: 0.4445
Batch 110, Loss: 0.4329
Batch 120, Loss: 0.4692
Batch 130, Loss: 0.4626
Batch 140, Loss: 0.4667
Batch 150, Loss: 0.4710
Batch 160, Loss: 0.5015
Batch 170, Loss: 0.4805
Batch 180, Loss: 0.4529
Batch 190, Loss: 0.4802
Batch 200, Loss: 0.5025
Batch 210, Loss: 0.4820
Batch 220, Loss: 0.4979
Batch 230, Loss: 0.5033
Batch 240, Loss: 0.4869
Batch 250, Loss: 0.4892
Batch 260, Loss: 0.5001
Batch 270, Loss: 0.4934
Batch 280, Loss: 0.4703
Batch 290, Loss: 0.5018
Batch 300, Loss: 0.4709
Batch 310, Loss: 0.4925
Batch 320, Loss: 0.5306
Batch 330, Loss: 0.4845
Batch 340, Loss: 0.4717
Batch 350, Loss: 0.5153
Batch 360, Loss: 0.4802
Batch 370, Loss: 0.4749
Batch 380, Loss: 0.4805
Batch 390, Loss: 0.5207
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.276976585388184 seconds
Epoch 79 accuracy: 85.95%
Batch 10, Loss: 0.5321
Batch 20, Loss: 0.4514
Batch 30, Loss: 0.4613
Batch 40, Loss: 0.4600
Batch 50, Loss: 0.4616
Batch 60, Loss: 0.4829
Batch 70, Loss: 0.4688
Batch 80, Loss: 0.4650
Batch 90, Loss: 0.4906
Batch 100, Loss: 0.4556
Batch 110, Loss: 0.4694
Batch 120, Loss: 0.5067
Batch 130, Loss: 0.4449
Batch 140, Loss: 0.5165
Batch 150, Loss: 0.4666
Batch 160, Loss: 0.4688
Batch 170, Loss: 0.5012
Batch 180, Loss: 0.4676
Batch 190, Loss: 0.4490
Batch 200, Loss: 0.4313
Batch 210, Loss: 0.4445
Batch 220, Loss: 0.5217
Batch 230, Loss: 0.5056
Batch 240, Loss: 0.4859
Batch 250, Loss: 0.5094
Batch 260, Loss: 0.4681
Batch 270, Loss: 0.4830
Batch 280, Loss: 0.4648
Batch 290, Loss: 0.4333
Batch 300, Loss: 0.4881
Batch 310, Loss: 0.4702
Batch 320, Loss: 0.4742
Batch 330, Loss: 0.4544
Batch 340, Loss: 0.4957
Batch 350, Loss: 0.4657
Batch 360, Loss: 0.5055
Batch 370, Loss: 0.4802
Batch 380, Loss: 0.4852
Batch 390, Loss: 0.5117
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.425010204315186 seconds
Epoch 80 accuracy: 84.67%
Batch 10, Loss: 0.4917
Batch 20, Loss: 0.4681
Batch 30, Loss: 0.5115
Batch 40, Loss: 0.4793
Batch 50, Loss: 0.4739
Batch 60, Loss: 0.5153
Batch 70, Loss: 0.4435
Batch 80, Loss: 0.4456
Batch 90, Loss: 0.4790
Batch 100, Loss: 0.4526
Batch 110, Loss: 0.4729
Batch 120, Loss: 0.4503
Batch 130, Loss: 0.5148
Batch 140, Loss: 0.5022
Batch 150, Loss: 0.5109
Batch 160, Loss: 0.4608
Batch 170, Loss: 0.4187
Batch 180, Loss: 0.4685
Batch 190, Loss: 0.4632
Batch 200, Loss: 0.4422
Batch 210, Loss: 0.4430
Batch 220, Loss: 0.4673
Batch 230, Loss: 0.4868
Batch 240, Loss: 0.4773
Batch 250, Loss: 0.4904
Batch 260, Loss: 0.5002
Batch 270, Loss: 0.4865
Batch 280, Loss: 0.4756
Batch 290, Loss: 0.4665
Batch 300, Loss: 0.4721
Batch 310, Loss: 0.4539
Batch 320, Loss: 0.4731
Batch 330, Loss: 0.4913
Batch 340, Loss: 0.4822
Batch 350, Loss: 0.4846
Batch 360, Loss: 0.4783
Batch 370, Loss: 0.4847
Batch 380, Loss: 0.4625
Batch 390, Loss: 0.4631
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.31933045387268 seconds
Epoch 81 accuracy: 88.33%
Batch 10, Loss: 0.4916
Batch 20, Loss: 0.3994
Batch 30, Loss: 0.4598
Batch 40, Loss: 0.4269
Batch 50, Loss: 0.4739
Batch 60, Loss: 0.4631
Batch 70, Loss: 0.4492
Batch 80, Loss: 0.4493
Batch 90, Loss: 0.4667
Batch 100, Loss: 0.4974
Batch 110, Loss: 0.4657
Batch 120, Loss: 0.4968
Batch 130, Loss: 0.5001
Batch 140, Loss: 0.4997
Batch 150, Loss: 0.4621
Batch 160, Loss: 0.4759
Batch 170, Loss: 0.4629
Batch 180, Loss: 0.5069
Batch 190, Loss: 0.4811
Batch 200, Loss: 0.4525
Batch 210, Loss: 0.4893
Batch 220, Loss: 0.4341
Batch 230, Loss: 0.4642
Batch 240, Loss: 0.5100
Batch 250, Loss: 0.5042
Batch 260, Loss: 0.5213
Batch 270, Loss: 0.4551
Batch 280, Loss: 0.4893
Batch 290, Loss: 0.4756
Batch 300, Loss: 0.4851
Batch 310, Loss: 0.4700
Batch 320, Loss: 0.4845
Batch 330, Loss: 0.4688
Batch 340, Loss: 0.4600
Batch 350, Loss: 0.4369
Batch 360, Loss: 0.4787
Batch 370, Loss: 0.4999
Batch 380, Loss: 0.4943
Batch 390, Loss: 0.5234
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.367488145828247 seconds
Epoch 82 accuracy: 85.46%
Batch 10, Loss: 0.4569
Batch 20, Loss: 0.4603
Batch 30, Loss: 0.4900
Batch 40, Loss: 0.4573
Batch 50, Loss: 0.4834
Batch 60, Loss: 0.4591
Batch 70, Loss: 0.4512
Batch 80, Loss: 0.4804
Batch 90, Loss: 0.4407
Batch 100, Loss: 0.4621
Batch 110, Loss: 0.4567
Batch 120, Loss: 0.4715
Batch 130, Loss: 0.4818
Batch 140, Loss: 0.4644
Batch 150, Loss: 0.4991
Batch 160, Loss: 0.5245
Batch 170, Loss: 0.4964
Batch 180, Loss: 0.5104
Batch 190, Loss: 0.4467
Batch 200, Loss: 0.4709
Batch 210, Loss: 0.5158
Batch 220, Loss: 0.4890
Batch 230, Loss: 0.4806
Batch 240, Loss: 0.4850
Batch 250, Loss: 0.4805
Batch 260, Loss: 0.4748
Batch 270, Loss: 0.4752
Batch 280, Loss: 0.4941
Batch 290, Loss: 0.4734
Batch 300, Loss: 0.4739
Batch 310, Loss: 0.4969
Batch 320, Loss: 0.4374
Batch 330, Loss: 0.4641
Batch 340, Loss: 0.4939
Batch 350, Loss: 0.4373
Batch 360, Loss: 0.4088
Batch 370, Loss: 0.4674
Batch 380, Loss: 0.5077
Batch 390, Loss: 0.4713
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.298732042312622 seconds
Epoch 83 accuracy: 86.39%
Batch 10, Loss: 0.4514
Batch 20, Loss: 0.4300
Batch 30, Loss: 0.4606
Batch 40, Loss: 0.4881
Batch 50, Loss: 0.4883
Batch 60, Loss: 0.4682
Batch 70, Loss: 0.4552
Batch 80, Loss: 0.4364
Batch 90, Loss: 0.4895
Batch 100, Loss: 0.4643
Batch 110, Loss: 0.4843
Batch 120, Loss: 0.4687
Batch 130, Loss: 0.4751
Batch 140, Loss: 0.4508
Batch 150, Loss: 0.4975
Batch 160, Loss: 0.4635
Batch 170, Loss: 0.4861
Batch 180, Loss: 0.4875
Batch 190, Loss: 0.4246
Batch 200, Loss: 0.4849
Batch 210, Loss: 0.4686
Batch 220, Loss: 0.5035
Batch 230, Loss: 0.4801
Batch 240, Loss: 0.4603
Batch 250, Loss: 0.4933
Batch 260, Loss: 0.4678
Batch 270, Loss: 0.4611
Batch 280, Loss: 0.4972
Batch 290, Loss: 0.4903
Batch 300, Loss: 0.4924
Batch 310, Loss: 0.4715
Batch 320, Loss: 0.4925
Batch 330, Loss: 0.4529
Batch 340, Loss: 0.4792
Batch 350, Loss: 0.5064
Batch 360, Loss: 0.4608
Batch 370, Loss: 0.4885
Batch 380, Loss: 0.4727
Batch 390, Loss: 0.4787
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.336901426315308 seconds
Epoch 84 accuracy: 86.81%
Batch 10, Loss: 0.4429
Batch 20, Loss: 0.4480
Batch 30, Loss: 0.4345
Batch 40, Loss: 0.4915
Batch 50, Loss: 0.4739
Batch 60, Loss: 0.4588
Batch 70, Loss: 0.4641
Batch 80, Loss: 0.4600
Batch 90, Loss: 0.3956
Batch 100, Loss: 0.4311
Batch 110, Loss: 0.4612
Batch 120, Loss: 0.4743
Batch 130, Loss: 0.4857
Batch 140, Loss: 0.4945
Batch 150, Loss: 0.4636
Batch 160, Loss: 0.4862
Batch 170, Loss: 0.4620
Batch 180, Loss: 0.4668
Batch 190, Loss: 0.4519
Batch 200, Loss: 0.4579
Batch 210, Loss: 0.5323
Batch 220, Loss: 0.4625
Batch 230, Loss: 0.4475
Batch 240, Loss: 0.4820
Batch 250, Loss: 0.4234
Batch 260, Loss: 0.5025
Batch 270, Loss: 0.4617
Batch 280, Loss: 0.4332
Batch 290, Loss: 0.4493
Batch 300, Loss: 0.4423
Batch 310, Loss: 0.4874
Batch 320, Loss: 0.4535
Batch 330, Loss: 0.4725
Batch 340, Loss: 0.4874
Batch 350, Loss: 0.4888
Batch 360, Loss: 0.4604
Batch 370, Loss: 0.4707
Batch 380, Loss: 0.4850
Batch 390, Loss: 0.4380
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.287466287612915 seconds
Epoch 85 accuracy: 87.18%
Batch 10, Loss: 0.5098
Batch 20, Loss: 0.5137
Batch 30, Loss: 0.4422
Batch 40, Loss: 0.4566
Batch 50, Loss: 0.4679
Batch 60, Loss: 0.4466
Batch 70, Loss: 0.4582
Batch 80, Loss: 0.5129
Batch 90, Loss: 0.5005
Batch 100, Loss: 0.4865
Batch 110, Loss: 0.4327
Batch 120, Loss: 0.4744
Batch 130, Loss: 0.4438
Batch 140, Loss: 0.4311
Batch 150, Loss: 0.4987
Batch 160, Loss: 0.4356
Batch 170, Loss: 0.4519
Batch 180, Loss: 0.4598
Batch 190, Loss: 0.4801
Batch 200, Loss: 0.5036
Batch 210, Loss: 0.4803
Batch 220, Loss: 0.4690
Batch 230, Loss: 0.4259
Batch 240, Loss: 0.4275
Batch 250, Loss: 0.4507
Batch 260, Loss: 0.4916
Batch 270, Loss: 0.5019
Batch 280, Loss: 0.5264
Batch 290, Loss: 0.5060
Batch 300, Loss: 0.4851
Batch 310, Loss: 0.4490
Batch 320, Loss: 0.4866
Batch 330, Loss: 0.4381
Batch 340, Loss: 0.4673
Batch 350, Loss: 0.4266
Batch 360, Loss: 0.4526
Batch 370, Loss: 0.4516
Batch 380, Loss: 0.4853
Batch 390, Loss: 0.4730
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.33574342727661 seconds
Epoch 86 accuracy: 88.08%
Batch 10, Loss: 0.4784
Batch 20, Loss: 0.4262
Batch 30, Loss: 0.4711
Batch 40, Loss: 0.4424
Batch 50, Loss: 0.4614
Batch 60, Loss: 0.4758
Batch 70, Loss: 0.4566
Batch 80, Loss: 0.4696
Batch 90, Loss: 0.4782
Batch 100, Loss: 0.4559
Batch 110, Loss: 0.4553
Batch 120, Loss: 0.4507
Batch 130, Loss: 0.4394
Batch 140, Loss: 0.4810
Batch 150, Loss: 0.4613
Batch 160, Loss: 0.4694
Batch 170, Loss: 0.4532
Batch 180, Loss: 0.4449
Batch 190, Loss: 0.4777
Batch 200, Loss: 0.4899
Batch 210, Loss: 0.4676
Batch 220, Loss: 0.4729
Batch 230, Loss: 0.4266
Batch 240, Loss: 0.4486
Batch 250, Loss: 0.4795
Batch 260, Loss: 0.4749
Batch 270, Loss: 0.4586
Batch 280, Loss: 0.4537
Batch 290, Loss: 0.4393
Batch 300, Loss: 0.4855
Batch 310, Loss: 0.4460
Batch 320, Loss: 0.4362
Batch 330, Loss: 0.4595
Batch 340, Loss: 0.4121
Batch 350, Loss: 0.4394
Batch 360, Loss: 0.4659
Batch 370, Loss: 0.4708
Batch 380, Loss: 0.4927
Batch 390, Loss: 0.4865
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.185814380645752 seconds
Epoch 87 accuracy: 83.38%
Batch 10, Loss: 0.4372
Batch 20, Loss: 0.4523
Batch 30, Loss: 0.4658
Batch 40, Loss: 0.4695
Batch 50, Loss: 0.4436
Batch 60, Loss: 0.4331
Batch 70, Loss: 0.4376
Batch 80, Loss: 0.4583
Batch 90, Loss: 0.4445
Batch 100, Loss: 0.4614
Batch 110, Loss: 0.4815
Batch 120, Loss: 0.4314
Batch 130, Loss: 0.4538
Batch 140, Loss: 0.4876
Batch 150, Loss: 0.4879
Batch 160, Loss: 0.4247
Batch 170, Loss: 0.4632
Batch 180, Loss: 0.4420
Batch 190, Loss: 0.4670
Batch 200, Loss: 0.4721
Batch 210, Loss: 0.4397
Batch 220, Loss: 0.4405
Batch 230, Loss: 0.4565
Batch 240, Loss: 0.4140
Batch 250, Loss: 0.4287
Batch 260, Loss: 0.4585
Batch 270, Loss: 0.4834
Batch 280, Loss: 0.4474
Batch 290, Loss: 0.4783
Batch 300, Loss: 0.4564
Batch 310, Loss: 0.4501
Batch 320, Loss: 0.4473
Batch 330, Loss: 0.4559
Batch 340, Loss: 0.4545
Batch 350, Loss: 0.4798
Batch 360, Loss: 0.5161
Batch 370, Loss: 0.4536
Batch 380, Loss: 0.4673
Batch 390, Loss: 0.4473
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.234703063964844 seconds
Epoch 88 accuracy: 86.54%
Batch 10, Loss: 0.4517
Batch 20, Loss: 0.4542
Batch 30, Loss: 0.4612
Batch 40, Loss: 0.4576
Batch 50, Loss: 0.4360
Batch 60, Loss: 0.4251
Batch 70, Loss: 0.4554
Batch 80, Loss: 0.5149
Batch 90, Loss: 0.4635
Batch 100, Loss: 0.4702
Batch 110, Loss: 0.4457
Batch 120, Loss: 0.4787
Batch 130, Loss: 0.4820
Batch 140, Loss: 0.5032
Batch 150, Loss: 0.4242
Batch 160, Loss: 0.4049
Batch 170, Loss: 0.4554
Batch 180, Loss: 0.4664
Batch 190, Loss: 0.4689
Batch 200, Loss: 0.4749
Batch 210, Loss: 0.4383
Batch 220, Loss: 0.4873
Batch 230, Loss: 0.4532
Batch 240, Loss: 0.4248
Batch 250, Loss: 0.4509
Batch 260, Loss: 0.4399
Batch 270, Loss: 0.4603
Batch 280, Loss: 0.4664
Batch 290, Loss: 0.4437
Batch 300, Loss: 0.5190
Batch 310, Loss: 0.5231
Batch 320, Loss: 0.4860
Batch 330, Loss: 0.4521
Batch 340, Loss: 0.4551
Batch 350, Loss: 0.4337
Batch 360, Loss: 0.4827
Batch 370, Loss: 0.4341
Batch 380, Loss: 0.4641
Batch 390, Loss: 0.4729
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.213231563568115 seconds
Epoch 89 accuracy: 87.38%
Batch 10, Loss: 0.4506
Batch 20, Loss: 0.4515
Batch 30, Loss: 0.4272
Batch 40, Loss: 0.4595
Batch 50, Loss: 0.4741
Batch 60, Loss: 0.4460
Batch 70, Loss: 0.4628
Batch 80, Loss: 0.4440
Batch 90, Loss: 0.4775
Batch 100, Loss: 0.4310
Batch 110, Loss: 0.4484
Batch 120, Loss: 0.4169
Batch 130, Loss: 0.4463
Batch 140, Loss: 0.4654
Batch 150, Loss: 0.4605
Batch 160, Loss: 0.4733
Batch 170, Loss: 0.4398
Batch 180, Loss: 0.4458
Batch 190, Loss: 0.4141
Batch 200, Loss: 0.4748
Batch 210, Loss: 0.4284
Batch 220, Loss: 0.4883
Batch 230, Loss: 0.4770
Batch 240, Loss: 0.4514
Batch 250, Loss: 0.4561
Batch 260, Loss: 0.4896
Batch 270, Loss: 0.4662
Batch 280, Loss: 0.4836
Batch 290, Loss: 0.4772
Batch 300, Loss: 0.4450
Batch 310, Loss: 0.4579
Batch 320, Loss: 0.4746
Batch 330, Loss: 0.4844
Batch 340, Loss: 0.4807
Batch 350, Loss: 0.4989
Batch 360, Loss: 0.4555
Batch 370, Loss: 0.4825
Batch 380, Loss: 0.4542
Batch 390, Loss: 0.4436
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.267103910446167 seconds
Epoch 90 accuracy: 86.17%
Batch 10, Loss: 0.4557
Batch 20, Loss: 0.4289
Batch 30, Loss: 0.4536
Batch 40, Loss: 0.4792
Batch 50, Loss: 0.4101
Batch 60, Loss: 0.4516
Batch 70, Loss: 0.4322
Batch 80, Loss: 0.4495
Batch 90, Loss: 0.4464
Batch 100, Loss: 0.4438
Batch 110, Loss: 0.4713
Batch 120, Loss: 0.4325
Batch 130, Loss: 0.4716
Batch 140, Loss: 0.4928
Batch 150, Loss: 0.4348
Batch 160, Loss: 0.4795
Batch 170, Loss: 0.4492
Batch 180, Loss: 0.4152
Batch 190, Loss: 0.4771
Batch 200, Loss: 0.4776
Batch 210, Loss: 0.4876
Batch 220, Loss: 0.4642
Batch 230, Loss: 0.4349
Batch 240, Loss: 0.4554
Batch 250, Loss: 0.4664
Batch 260, Loss: 0.4926
Batch 270, Loss: 0.4739
Batch 280, Loss: 0.4736
Batch 290, Loss: 0.4188
Batch 300, Loss: 0.4700
Batch 310, Loss: 0.4635
Batch 320, Loss: 0.4616
Batch 330, Loss: 0.4020
Batch 340, Loss: 0.4666
Batch 350, Loss: 0.4374
Batch 360, Loss: 0.4572
Batch 370, Loss: 0.4509
Batch 380, Loss: 0.4849
Batch 390, Loss: 0.4525
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.244091033935547 seconds
Epoch 91 accuracy: 86.3%
Batch 10, Loss: 0.4637
Batch 20, Loss: 0.4475
Batch 30, Loss: 0.4760
Batch 40, Loss: 0.4848
Batch 50, Loss: 0.4944
Batch 60, Loss: 0.4298
Batch 70, Loss: 0.4583
Batch 80, Loss: 0.4412
Batch 90, Loss: 0.4184
Batch 100, Loss: 0.4602
Batch 110, Loss: 0.4478
Batch 120, Loss: 0.4709
Batch 130, Loss: 0.4494
Batch 140, Loss: 0.4951
Batch 150, Loss: 0.4311
Batch 160, Loss: 0.4084
Batch 170, Loss: 0.4347
Batch 180, Loss: 0.4748
Batch 190, Loss: 0.4641
Batch 200, Loss: 0.4796
Batch 210, Loss: 0.4743
Batch 220, Loss: 0.4564
Batch 230, Loss: 0.4354
Batch 240, Loss: 0.4312
Batch 250, Loss: 0.4395
Batch 260, Loss: 0.4842
Batch 270, Loss: 0.4555
Batch 280, Loss: 0.4658
Batch 290, Loss: 0.4588
Batch 300, Loss: 0.4642
Batch 310, Loss: 0.4743
Batch 320, Loss: 0.4471
Batch 330, Loss: 0.4719
Batch 340, Loss: 0.4647
Batch 350, Loss: 0.4373
Batch 360, Loss: 0.3991
Batch 370, Loss: 0.4657
Batch 380, Loss: 0.5226
Batch 390, Loss: 0.4713
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.429316759109497 seconds
Epoch 92 accuracy: 87.26%
Batch 10, Loss: 0.4370
Batch 20, Loss: 0.3761
Batch 30, Loss: 0.4591
Batch 40, Loss: 0.4350
Batch 50, Loss: 0.4394
Batch 60, Loss: 0.4552
Batch 70, Loss: 0.4438
Batch 80, Loss: 0.4646
Batch 90, Loss: 0.5011
Batch 100, Loss: 0.4625
Batch 110, Loss: 0.4531
Batch 120, Loss: 0.4325
Batch 130, Loss: 0.4366
Batch 140, Loss: 0.4089
Batch 150, Loss: 0.4260
Batch 160, Loss: 0.4262
Batch 170, Loss: 0.4490
Batch 180, Loss: 0.4152
Batch 190, Loss: 0.4540
Batch 200, Loss: 0.4115
Batch 210, Loss: 0.4292
Batch 220, Loss: 0.4680
Batch 230, Loss: 0.5118
Batch 240, Loss: 0.4836
Batch 250, Loss: 0.4333
Batch 260, Loss: 0.4051
Batch 270, Loss: 0.4484
Batch 280, Loss: 0.4501
Batch 290, Loss: 0.4545
Batch 300, Loss: 0.4983
Batch 310, Loss: 0.4589
Batch 320, Loss: 0.4275
Batch 330, Loss: 0.4332
Batch 340, Loss: 0.4371
Batch 350, Loss: 0.4556
Batch 360, Loss: 0.4620
Batch 370, Loss: 0.4615
Batch 380, Loss: 0.4827
Batch 390, Loss: 0.4721
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.416011333465576 seconds
Epoch 93 accuracy: 86.27%
Batch 10, Loss: 0.4353
Batch 20, Loss: 0.4552
Batch 30, Loss: 0.4454
Batch 40, Loss: 0.4293
Batch 50, Loss: 0.4074
Batch 60, Loss: 0.4365
Batch 70, Loss: 0.4462
Batch 80, Loss: 0.4074
Batch 90, Loss: 0.4325
Batch 100, Loss: 0.4204
Batch 110, Loss: 0.4138
Batch 120, Loss: 0.4237
Batch 130, Loss: 0.4679
Batch 140, Loss: 0.4338
Batch 150, Loss: 0.4501
Batch 160, Loss: 0.4699
Batch 170, Loss: 0.4427
Batch 180, Loss: 0.4335
Batch 190, Loss: 0.4002
Batch 200, Loss: 0.4480
Batch 210, Loss: 0.4819
Batch 220, Loss: 0.4121
Batch 230, Loss: 0.4666
Batch 240, Loss: 0.4371
Batch 250, Loss: 0.4540
Batch 260, Loss: 0.4499
Batch 270, Loss: 0.4454
Batch 280, Loss: 0.4590
Batch 290, Loss: 0.4358
Batch 300, Loss: 0.4137
Batch 310, Loss: 0.4464
Batch 320, Loss: 0.4597
Batch 330, Loss: 0.4390
Batch 340, Loss: 0.4227
Batch 350, Loss: 0.4331
Batch 360, Loss: 0.4458
Batch 370, Loss: 0.4652
Batch 380, Loss: 0.4572
Batch 390, Loss: 0.4755
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.288103818893433 seconds
Epoch 94 accuracy: 88.72%
Batch 10, Loss: 0.4254
Batch 20, Loss: 0.4243
Batch 30, Loss: 0.4464
Batch 40, Loss: 0.4426
Batch 50, Loss: 0.4130
Batch 60, Loss: 0.4407
Batch 70, Loss: 0.4590
Batch 80, Loss: 0.4721
Batch 90, Loss: 0.4167
Batch 100, Loss: 0.4280
Batch 110, Loss: 0.4602
Batch 120, Loss: 0.4414
Batch 130, Loss: 0.4833
Batch 140, Loss: 0.4672
Batch 150, Loss: 0.4210
Batch 160, Loss: 0.3971
Batch 170, Loss: 0.4484
Batch 180, Loss: 0.4289
Batch 190, Loss: 0.4152
Batch 200, Loss: 0.4637
Batch 210, Loss: 0.4779
Batch 220, Loss: 0.4489
Batch 230, Loss: 0.4583
Batch 240, Loss: 0.4365
Batch 250, Loss: 0.4314
Batch 260, Loss: 0.4600
Batch 270, Loss: 0.4901
Batch 280, Loss: 0.4606
Batch 290, Loss: 0.4592
Batch 300, Loss: 0.4838
Batch 310, Loss: 0.4710
Batch 320, Loss: 0.4482
Batch 330, Loss: 0.4785
Batch 340, Loss: 0.4467
Batch 350, Loss: 0.4513
Batch 360, Loss: 0.4341
Batch 370, Loss: 0.4784
Batch 380, Loss: 0.4357
Batch 390, Loss: 0.4436
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.389543294906616 seconds
Epoch 95 accuracy: 87.65%
Batch 10, Loss: 0.4831
Batch 20, Loss: 0.4192
Batch 30, Loss: 0.4705
Batch 40, Loss: 0.4375
Batch 50, Loss: 0.4273
Batch 60, Loss: 0.4940
Batch 70, Loss: 0.4649
Batch 80, Loss: 0.4577
Batch 90, Loss: 0.4264
Batch 100, Loss: 0.4056
Batch 110, Loss: 0.4159
Batch 120, Loss: 0.4314
Batch 130, Loss: 0.4330
Batch 140, Loss: 0.4290
Batch 150, Loss: 0.4151
Batch 160, Loss: 0.4209
Batch 170, Loss: 0.4542
Batch 180, Loss: 0.4489
Batch 190, Loss: 0.4472
Batch 200, Loss: 0.4412
Batch 210, Loss: 0.4369
Batch 220, Loss: 0.4463
Batch 230, Loss: 0.4573
Batch 240, Loss: 0.4624
Batch 250, Loss: 0.4331
Batch 260, Loss: 0.4748
Batch 270, Loss: 0.4741
Batch 280, Loss: 0.4091
Batch 290, Loss: 0.4284
Batch 300, Loss: 0.4214
Batch 310, Loss: 0.4655
Batch 320, Loss: 0.4567
Batch 330, Loss: 0.4406
Batch 340, Loss: 0.4585
Batch 350, Loss: 0.4444
Batch 360, Loss: 0.4319
Batch 370, Loss: 0.4445
Batch 380, Loss: 0.4746
Batch 390, Loss: 0.4496
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.32012367248535 seconds
Epoch 96 accuracy: 87.32%
Batch 10, Loss: 0.4679
Batch 20, Loss: 0.4653
Batch 30, Loss: 0.3916
Batch 40, Loss: 0.4061
Batch 50, Loss: 0.4474
Batch 60, Loss: 0.4523
Batch 70, Loss: 0.4159
Batch 80, Loss: 0.4512
Batch 90, Loss: 0.4001
Batch 100, Loss: 0.4507
Batch 110, Loss: 0.4059
Batch 120, Loss: 0.4408
Batch 130, Loss: 0.4304
Batch 140, Loss: 0.4694
Batch 150, Loss: 0.5144
Batch 160, Loss: 0.4679
Batch 170, Loss: 0.4502
Batch 180, Loss: 0.4353
Batch 190, Loss: 0.4476
Batch 200, Loss: 0.4140
Batch 210, Loss: 0.4324
Batch 220, Loss: 0.4472
Batch 230, Loss: 0.4185
Batch 240, Loss: 0.3975
Batch 250, Loss: 0.4345
Batch 260, Loss: 0.4302
Batch 270, Loss: 0.4649
Batch 280, Loss: 0.4653
Batch 290, Loss: 0.4399
Batch 300, Loss: 0.4562
Batch 310, Loss: 0.4531
Batch 320, Loss: 0.4350
Batch 330, Loss: 0.4546
Batch 340, Loss: 0.4520
Batch 350, Loss: 0.4418
Batch 360, Loss: 0.4443
Batch 370, Loss: 0.4801
Batch 380, Loss: 0.4347
Batch 390, Loss: 0.4420
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.360756397247314 seconds
Epoch 97 accuracy: 88.65%
Batch 10, Loss: 0.4363
Batch 20, Loss: 0.3898
Batch 30, Loss: 0.4445
Batch 40, Loss: 0.4284
Batch 50, Loss: 0.4410
Batch 60, Loss: 0.4402
Batch 70, Loss: 0.4348
Batch 80, Loss: 0.4605
Batch 90, Loss: 0.4439
Batch 100, Loss: 0.3838
Batch 110, Loss: 0.4279
Batch 120, Loss: 0.4239
Batch 130, Loss: 0.4496
Batch 140, Loss: 0.4354
Batch 150, Loss: 0.4691
Batch 160, Loss: 0.4570
Batch 170, Loss: 0.4306
Batch 180, Loss: 0.4434
Batch 190, Loss: 0.4336
Batch 200, Loss: 0.4427
Batch 210, Loss: 0.4136
Batch 220, Loss: 0.4346
Batch 230, Loss: 0.4474
Batch 240, Loss: 0.4171
Batch 250, Loss: 0.4062
Batch 260, Loss: 0.4324
Batch 270, Loss: 0.4373
Batch 280, Loss: 0.4764
Batch 290, Loss: 0.4527
Batch 300, Loss: 0.4498
Batch 310, Loss: 0.4469
Batch 320, Loss: 0.4441
Batch 330, Loss: 0.4468
Batch 340, Loss: 0.4302
Batch 350, Loss: 0.4617
Batch 360, Loss: 0.4786
Batch 370, Loss: 0.4294
Batch 380, Loss: 0.4489
Batch 390, Loss: 0.4500
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.385398149490356 seconds
Epoch 98 accuracy: 89.42%
Batch 10, Loss: 0.4240
Batch 20, Loss: 0.3935
Batch 30, Loss: 0.4803
Batch 40, Loss: 0.4248
Batch 50, Loss: 0.4285
Batch 60, Loss: 0.4077
Batch 70, Loss: 0.4402
Batch 80, Loss: 0.4322
Batch 90, Loss: 0.4214
Batch 100, Loss: 0.4267
Batch 110, Loss: 0.4624
Batch 120, Loss: 0.4472
Batch 130, Loss: 0.4045
Batch 140, Loss: 0.4234
Batch 150, Loss: 0.4161
Batch 160, Loss: 0.3988
Batch 170, Loss: 0.4328
Batch 180, Loss: 0.4033
Batch 190, Loss: 0.4503
Batch 200, Loss: 0.4328
Batch 210, Loss: 0.4533
Batch 220, Loss: 0.4072
Batch 230, Loss: 0.4269
Batch 240, Loss: 0.4146
Batch 250, Loss: 0.4605
Batch 260, Loss: 0.4643
Batch 270, Loss: 0.4578
Batch 280, Loss: 0.4539
Batch 290, Loss: 0.4101
Batch 300, Loss: 0.4192
Batch 310, Loss: 0.4419
Batch 320, Loss: 0.4429
Batch 330, Loss: 0.4545
Batch 340, Loss: 0.4348
Batch 350, Loss: 0.4627
Batch 360, Loss: 0.4342
Batch 370, Loss: 0.4250
Batch 380, Loss: 0.4716
Batch 390, Loss: 0.4442
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.193443775177002 seconds
Epoch 99 accuracy: 87.85%
Batch 10, Loss: 0.3860
Batch 20, Loss: 0.4247
Batch 30, Loss: 0.4380
Batch 40, Loss: 0.4311
Batch 50, Loss: 0.4612
Batch 60, Loss: 0.4449
Batch 70, Loss: 0.4339
Batch 80, Loss: 0.4318
Batch 90, Loss: 0.4131
Batch 100, Loss: 0.4504
Batch 110, Loss: 0.4304
Batch 120, Loss: 0.4397
Batch 130, Loss: 0.4097
Batch 140, Loss: 0.4669
Batch 150, Loss: 0.4541
Batch 160, Loss: 0.4105
Batch 170, Loss: 0.4351
Batch 180, Loss: 0.4336
Batch 190, Loss: 0.4365
Batch 200, Loss: 0.4348
Batch 210, Loss: 0.4445
Batch 220, Loss: 0.4591
Batch 230, Loss: 0.4087
Batch 240, Loss: 0.4360
Batch 250, Loss: 0.4310
Batch 260, Loss: 0.4128
Batch 270, Loss: 0.4244
Batch 280, Loss: 0.4500
Batch 290, Loss: 0.4474
Batch 300, Loss: 0.4176
Batch 310, Loss: 0.4490
Batch 320, Loss: 0.4337
Batch 330, Loss: 0.4169
Batch 340, Loss: 0.4445
Batch 350, Loss: 0.4245
Batch 360, Loss: 0.4323
Batch 370, Loss: 0.4521
Batch 380, Loss: 0.4168
Batch 390, Loss: 0.4449
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.386871576309204 seconds
Epoch 100 accuracy: 88.06%
Batch 10, Loss: 0.4439
Batch 20, Loss: 0.4449
Batch 30, Loss: 0.4394
Batch 40, Loss: 0.4809
Batch 50, Loss: 0.4547
Batch 60, Loss: 0.4445
Batch 70, Loss: 0.4192
Batch 80, Loss: 0.4150
Batch 90, Loss: 0.4012
Batch 100, Loss: 0.3972
Batch 110, Loss: 0.4396
Batch 120, Loss: 0.4147
Batch 130, Loss: 0.4107
Batch 140, Loss: 0.4361
Batch 150, Loss: 0.4688
Batch 160, Loss: 0.4270
Batch 170, Loss: 0.4124
Batch 180, Loss: 0.4921
Batch 190, Loss: 0.4270
Batch 200, Loss: 0.3945
Batch 210, Loss: 0.4799
Batch 220, Loss: 0.4241
Batch 230, Loss: 0.4237
Batch 240, Loss: 0.4142
Batch 250, Loss: 0.4542
Batch 260, Loss: 0.4208
Batch 270, Loss: 0.4439
Batch 280, Loss: 0.4360
Batch 290, Loss: 0.4307
Batch 300, Loss: 0.4298
Batch 310, Loss: 0.4396
Batch 320, Loss: 0.4409
Batch 330, Loss: 0.3976
Batch 340, Loss: 0.4780
Batch 350, Loss: 0.4183
Batch 360, Loss: 0.3998
Batch 370, Loss: 0.4189
Batch 380, Loss: 0.4534
Batch 390, Loss: 0.4313
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.269203901290894 seconds
Epoch 101 accuracy: 89.58%
Batch 10, Loss: 0.4440
Batch 20, Loss: 0.4159
Batch 30, Loss: 0.4143
Batch 40, Loss: 0.3928
Batch 50, Loss: 0.4157
Batch 60, Loss: 0.4332
Batch 70, Loss: 0.4432
Batch 80, Loss: 0.4370
Batch 90, Loss: 0.4500
Batch 100, Loss: 0.4095
Batch 110, Loss: 0.4089
Batch 120, Loss: 0.4167
Batch 130, Loss: 0.4640
Batch 140, Loss: 0.4294
Batch 150, Loss: 0.4288
Batch 160, Loss: 0.4096
Batch 170, Loss: 0.4156
Batch 180, Loss: 0.4446
Batch 190, Loss: 0.4273
Batch 200, Loss: 0.4293
Batch 210, Loss: 0.3987
Batch 220, Loss: 0.4479
Batch 230, Loss: 0.4460
Batch 240, Loss: 0.4062
Batch 250, Loss: 0.4342
Batch 260, Loss: 0.4290
Batch 270, Loss: 0.4336
Batch 280, Loss: 0.4327
Batch 290, Loss: 0.4038
Batch 300, Loss: 0.4377
Batch 310, Loss: 0.4193
Batch 320, Loss: 0.4992
Batch 330, Loss: 0.4349
Batch 340, Loss: 0.4019
Batch 350, Loss: 0.4273
Batch 360, Loss: 0.4185
Batch 370, Loss: 0.4519
Batch 380, Loss: 0.4643
Batch 390, Loss: 0.4609
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.369213581085205 seconds
Epoch 102 accuracy: 88.75%
Batch 10, Loss: 0.3999
Batch 20, Loss: 0.4051
Batch 30, Loss: 0.4501
Batch 40, Loss: 0.4077
Batch 50, Loss: 0.4395
Batch 60, Loss: 0.4285
Batch 70, Loss: 0.4382
Batch 80, Loss: 0.4253
Batch 90, Loss: 0.4616
Batch 100, Loss: 0.4042
Batch 110, Loss: 0.4108
Batch 120, Loss: 0.4443
Batch 130, Loss: 0.4525
Batch 140, Loss: 0.4333
Batch 150, Loss: 0.4018
Batch 160, Loss: 0.4062
Batch 170, Loss: 0.4011
Batch 180, Loss: 0.4602
Batch 190, Loss: 0.4306
Batch 200, Loss: 0.4007
Batch 210, Loss: 0.4156
Batch 220, Loss: 0.4314
Batch 230, Loss: 0.4341
Batch 240, Loss: 0.4078
Batch 250, Loss: 0.4569
Batch 260, Loss: 0.4305
Batch 270, Loss: 0.4409
Batch 280, Loss: 0.4225
Batch 290, Loss: 0.4243
Batch 300, Loss: 0.4519
Batch 310, Loss: 0.4096
Batch 320, Loss: 0.4106
Batch 330, Loss: 0.3908
Batch 340, Loss: 0.4558
Batch 350, Loss: 0.4270
Batch 360, Loss: 0.4383
Batch 370, Loss: 0.4139
Batch 380, Loss: 0.4145
Batch 390, Loss: 0.3925
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.33102583885193 seconds
Epoch 103 accuracy: 87.45%
Batch 10, Loss: 0.4609
Batch 20, Loss: 0.4594
Batch 30, Loss: 0.4009
Batch 40, Loss: 0.4278
Batch 50, Loss: 0.4126
Batch 60, Loss: 0.4535
Batch 70, Loss: 0.4476
Batch 80, Loss: 0.4115
Batch 90, Loss: 0.4160
Batch 100, Loss: 0.4452
Batch 110, Loss: 0.4072
Batch 120, Loss: 0.4205
Batch 130, Loss: 0.4155
Batch 140, Loss: 0.4058
Batch 150, Loss: 0.3979
Batch 160, Loss: 0.3747
Batch 170, Loss: 0.4404
Batch 180, Loss: 0.4365
Batch 190, Loss: 0.4023
Batch 200, Loss: 0.4271
Batch 210, Loss: 0.4294
Batch 220, Loss: 0.4357
Batch 230, Loss: 0.4383
Batch 240, Loss: 0.3945
Batch 250, Loss: 0.4012
Batch 260, Loss: 0.4087
Batch 270, Loss: 0.4397
Batch 280, Loss: 0.4444
Batch 290, Loss: 0.4859
Batch 300, Loss: 0.4585
Batch 310, Loss: 0.4219
Batch 320, Loss: 0.4139
Batch 330, Loss: 0.4189
Batch 340, Loss: 0.4272
Batch 350, Loss: 0.4157
Batch 360, Loss: 0.4391
Batch 370, Loss: 0.4045
Batch 380, Loss: 0.4226
Batch 390, Loss: 0.4326
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.269179582595825 seconds
Epoch 104 accuracy: 89.11%
Batch 10, Loss: 0.3950
Batch 20, Loss: 0.4181
Batch 30, Loss: 0.4555
Batch 40, Loss: 0.3898
Batch 50, Loss: 0.4048
Batch 60, Loss: 0.3998
Batch 70, Loss: 0.3859
Batch 80, Loss: 0.4150
Batch 90, Loss: 0.4329
Batch 100, Loss: 0.4518
Batch 110, Loss: 0.3883
Batch 120, Loss: 0.4454
Batch 130, Loss: 0.4007
Batch 140, Loss: 0.4561
Batch 150, Loss: 0.4275
Batch 160, Loss: 0.4310
Batch 170, Loss: 0.4111
Batch 180, Loss: 0.4040
Batch 190, Loss: 0.4030
Batch 200, Loss: 0.4152
Batch 210, Loss: 0.4031
Batch 220, Loss: 0.4112
Batch 230, Loss: 0.4160
Batch 240, Loss: 0.4563
Batch 250, Loss: 0.3994
Batch 260, Loss: 0.4285
Batch 270, Loss: 0.4432
Batch 280, Loss: 0.4088
Batch 290, Loss: 0.3934
Batch 300, Loss: 0.4112
Batch 310, Loss: 0.4309
Batch 320, Loss: 0.4331
Batch 330, Loss: 0.4122
Batch 340, Loss: 0.4083
Batch 350, Loss: 0.3821
Batch 360, Loss: 0.4365
Batch 370, Loss: 0.4591
Batch 380, Loss: 0.4047
Batch 390, Loss: 0.4026
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.233052015304565 seconds
Epoch 105 accuracy: 87.47%
Batch 10, Loss: 0.4578
Batch 20, Loss: 0.4161
Batch 30, Loss: 0.4360
Batch 40, Loss: 0.4303
Batch 50, Loss: 0.3837
Batch 60, Loss: 0.4341
Batch 70, Loss: 0.4259
Batch 80, Loss: 0.3990
Batch 90, Loss: 0.4182
Batch 100, Loss: 0.4165
Batch 110, Loss: 0.4213
Batch 120, Loss: 0.4121
Batch 130, Loss: 0.4260
Batch 140, Loss: 0.3749
Batch 150, Loss: 0.4237
Batch 160, Loss: 0.4178
Batch 170, Loss: 0.3830
Batch 180, Loss: 0.4345
Batch 190, Loss: 0.4095
Batch 200, Loss: 0.3996
Batch 210, Loss: 0.3746
Batch 220, Loss: 0.4309
Batch 230, Loss: 0.4196
Batch 240, Loss: 0.4348
Batch 250, Loss: 0.4384
Batch 260, Loss: 0.4362
Batch 270, Loss: 0.4447
Batch 280, Loss: 0.3941
Batch 290, Loss: 0.4250
Batch 300, Loss: 0.4062
Batch 310, Loss: 0.4280
Batch 320, Loss: 0.4097
Batch 330, Loss: 0.4505
Batch 340, Loss: 0.4168
Batch 350, Loss: 0.4276
Batch 360, Loss: 0.4327
Batch 370, Loss: 0.4301
Batch 380, Loss: 0.4440
Batch 390, Loss: 0.4447
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.201584815979004 seconds
Epoch 106 accuracy: 89.24%
Batch 10, Loss: 0.4114
Batch 20, Loss: 0.4147
Batch 30, Loss: 0.4060
Batch 40, Loss: 0.4204
Batch 50, Loss: 0.3998
Batch 60, Loss: 0.4327
Batch 70, Loss: 0.3676
Batch 80, Loss: 0.3825
Batch 90, Loss: 0.4345
Batch 100, Loss: 0.4282
Batch 110, Loss: 0.3908
Batch 120, Loss: 0.3931
Batch 130, Loss: 0.4458
Batch 140, Loss: 0.4068
Batch 150, Loss: 0.3816
Batch 160, Loss: 0.4037
Batch 170, Loss: 0.3789
Batch 180, Loss: 0.3690
Batch 190, Loss: 0.4241
Batch 200, Loss: 0.4314
Batch 210, Loss: 0.4327
Batch 220, Loss: 0.4088
Batch 230, Loss: 0.3551
Batch 240, Loss: 0.4360
Batch 250, Loss: 0.3984
Batch 260, Loss: 0.4319
Batch 270, Loss: 0.4629
Batch 280, Loss: 0.4179
Batch 290, Loss: 0.4014
Batch 300, Loss: 0.4460
Batch 310, Loss: 0.4281
Batch 320, Loss: 0.4251
Batch 330, Loss: 0.3950
Batch 340, Loss: 0.4300
Batch 350, Loss: 0.4281
Batch 360, Loss: 0.4269
Batch 370, Loss: 0.4267
Batch 380, Loss: 0.4207
Batch 390, Loss: 0.4270
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.224449634552002 seconds
Epoch 107 accuracy: 89.57%
Batch 10, Loss: 0.4504
Batch 20, Loss: 0.4146
Batch 30, Loss: 0.4174
Batch 40, Loss: 0.3866
Batch 50, Loss: 0.4136
Batch 60, Loss: 0.4089
Batch 70, Loss: 0.4245
Batch 80, Loss: 0.3890
Batch 90, Loss: 0.4147
Batch 100, Loss: 0.4282
Batch 110, Loss: 0.4348
Batch 120, Loss: 0.4318
Batch 130, Loss: 0.4272
Batch 140, Loss: 0.4321
Batch 150, Loss: 0.3848
Batch 160, Loss: 0.3883
Batch 170, Loss: 0.3920
Batch 180, Loss: 0.3971
Batch 190, Loss: 0.4103
Batch 200, Loss: 0.4208
Batch 210, Loss: 0.3712
Batch 220, Loss: 0.4554
Batch 230, Loss: 0.4026
Batch 240, Loss: 0.3943
Batch 250, Loss: 0.3908
Batch 260, Loss: 0.4536
Batch 270, Loss: 0.3863
Batch 280, Loss: 0.4123
Batch 290, Loss: 0.4300
Batch 300, Loss: 0.4064
Batch 310, Loss: 0.4588
Batch 320, Loss: 0.4405
Batch 330, Loss: 0.4335
Batch 340, Loss: 0.4422
Batch 350, Loss: 0.4035
Batch 360, Loss: 0.4283
Batch 370, Loss: 0.4132
Batch 380, Loss: 0.4417
Batch 390, Loss: 0.4349
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.375214338302612 seconds
Epoch 108 accuracy: 90.49%
Batch 10, Loss: 0.4045
Batch 20, Loss: 0.3916
Batch 30, Loss: 0.4019
Batch 40, Loss: 0.4146
Batch 50, Loss: 0.4449
Batch 60, Loss: 0.4153
Batch 70, Loss: 0.3884
Batch 80, Loss: 0.4188
Batch 90, Loss: 0.4075
Batch 100, Loss: 0.4146
Batch 110, Loss: 0.3944
Batch 120, Loss: 0.4211
Batch 130, Loss: 0.3885
Batch 140, Loss: 0.4186
Batch 150, Loss: 0.3879
Batch 160, Loss: 0.4072
Batch 170, Loss: 0.3925
Batch 180, Loss: 0.4266
Batch 190, Loss: 0.4144
Batch 200, Loss: 0.3751
Batch 210, Loss: 0.3925
Batch 220, Loss: 0.4149
Batch 230, Loss: 0.4003
Batch 240, Loss: 0.4531
Batch 250, Loss: 0.4000
Batch 260, Loss: 0.4104
Batch 270, Loss: 0.4247
Batch 280, Loss: 0.4265
Batch 290, Loss: 0.4384
Batch 300, Loss: 0.4091
Batch 310, Loss: 0.4162
Batch 320, Loss: 0.4068
Batch 330, Loss: 0.4242
Batch 340, Loss: 0.4449
Batch 350, Loss: 0.3979
Batch 360, Loss: 0.4274
Batch 370, Loss: 0.4516
Batch 380, Loss: 0.4177
Batch 390, Loss: 0.4192
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.18834400177002 seconds
Epoch 109 accuracy: 90.09%
Batch 10, Loss: 0.4320
Batch 20, Loss: 0.4296
Batch 30, Loss: 0.3965
Batch 40, Loss: 0.3901
Batch 50, Loss: 0.4139
Batch 60, Loss: 0.4382
Batch 70, Loss: 0.4211
Batch 80, Loss: 0.4030
Batch 90, Loss: 0.3866
Batch 100, Loss: 0.3948
Batch 110, Loss: 0.3977
Batch 120, Loss: 0.4419
Batch 130, Loss: 0.3910
Batch 140, Loss: 0.3926
Batch 150, Loss: 0.4141
Batch 160, Loss: 0.4122
Batch 170, Loss: 0.3846
Batch 180, Loss: 0.4031
Batch 190, Loss: 0.3789
Batch 200, Loss: 0.4149
Batch 210, Loss: 0.4204
Batch 220, Loss: 0.4446
Batch 230, Loss: 0.3776
Batch 240, Loss: 0.4387
Batch 250, Loss: 0.3991
Batch 260, Loss: 0.4073
Batch 270, Loss: 0.4035
Batch 280, Loss: 0.4535
Batch 290, Loss: 0.4404
Batch 300, Loss: 0.3906
Batch 310, Loss: 0.4332
Batch 320, Loss: 0.3867
Batch 330, Loss: 0.4232
Batch 340, Loss: 0.4098
Batch 350, Loss: 0.4230
Batch 360, Loss: 0.4185
Batch 370, Loss: 0.3861
Batch 380, Loss: 0.4033
Batch 390, Loss: 0.4408
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.180652379989624 seconds
Epoch 110 accuracy: 89.42%
Batch 10, Loss: 0.3713
Batch 20, Loss: 0.4219
Batch 30, Loss: 0.4270
Batch 40, Loss: 0.4031
Batch 50, Loss: 0.4397
Batch 60, Loss: 0.4121
Batch 70, Loss: 0.3923
Batch 80, Loss: 0.3634
Batch 90, Loss: 0.3991
Batch 100, Loss: 0.3828
Batch 110, Loss: 0.4138
Batch 120, Loss: 0.3954
Batch 130, Loss: 0.4203
Batch 140, Loss: 0.4221
Batch 150, Loss: 0.3930
Batch 160, Loss: 0.4273
Batch 170, Loss: 0.4245
Batch 180, Loss: 0.4053
Batch 190, Loss: 0.4259
Batch 200, Loss: 0.4034
Batch 210, Loss: 0.4230
Batch 220, Loss: 0.4315
Batch 230, Loss: 0.4059
Batch 240, Loss: 0.4326
Batch 250, Loss: 0.4126
Batch 260, Loss: 0.3949
Batch 270, Loss: 0.3638
Batch 280, Loss: 0.4068
Batch 290, Loss: 0.4271
Batch 300, Loss: 0.3957
Batch 310, Loss: 0.4188
Batch 320, Loss: 0.4067
Batch 330, Loss: 0.4157
Batch 340, Loss: 0.4005
Batch 350, Loss: 0.4277
Batch 360, Loss: 0.4313
Batch 370, Loss: 0.3853
Batch 380, Loss: 0.4141
Batch 390, Loss: 0.3990
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.239550590515137 seconds
Epoch 111 accuracy: 88.41%
Batch 10, Loss: 0.4073
Batch 20, Loss: 0.3765
Batch 30, Loss: 0.3752
Batch 40, Loss: 0.3645
Batch 50, Loss: 0.4185
Batch 60, Loss: 0.4098
Batch 70, Loss: 0.3863
Batch 80, Loss: 0.3836
Batch 90, Loss: 0.4031
Batch 100, Loss: 0.3965
Batch 110, Loss: 0.3414
Batch 120, Loss: 0.4146
Batch 130, Loss: 0.4204
Batch 140, Loss: 0.4077
Batch 150, Loss: 0.4279
Batch 160, Loss: 0.4040
Batch 170, Loss: 0.3879
Batch 180, Loss: 0.3933
Batch 190, Loss: 0.3715
Batch 200, Loss: 0.4130
Batch 210, Loss: 0.3815
Batch 220, Loss: 0.4136
Batch 230, Loss: 0.4220
Batch 240, Loss: 0.3673
Batch 250, Loss: 0.3775
Batch 260, Loss: 0.4080
Batch 270, Loss: 0.4525
Batch 280, Loss: 0.4003
Batch 290, Loss: 0.4221
Batch 300, Loss: 0.4109
Batch 310, Loss: 0.3911
Batch 320, Loss: 0.3764
Batch 330, Loss: 0.3967
Batch 340, Loss: 0.4096
Batch 350, Loss: 0.4132
Batch 360, Loss: 0.3928
Batch 370, Loss: 0.3568
Batch 380, Loss: 0.4016
Batch 390, Loss: 0.4415
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.233250379562378 seconds
Epoch 112 accuracy: 90.38%
Batch 10, Loss: 0.3935
Batch 20, Loss: 0.4081
Batch 30, Loss: 0.3845
Batch 40, Loss: 0.4047
Batch 50, Loss: 0.4039
Batch 60, Loss: 0.4230
Batch 70, Loss: 0.3837
Batch 80, Loss: 0.3817
Batch 90, Loss: 0.3843
Batch 100, Loss: 0.4073
Batch 110, Loss: 0.3994
Batch 120, Loss: 0.3887
Batch 130, Loss: 0.3907
Batch 140, Loss: 0.3865
Batch 150, Loss: 0.4221
Batch 160, Loss: 0.3988
Batch 170, Loss: 0.3997
Batch 180, Loss: 0.3909
Batch 190, Loss: 0.3990
Batch 200, Loss: 0.4103
Batch 210, Loss: 0.3804
Batch 220, Loss: 0.4101
Batch 230, Loss: 0.3998
Batch 240, Loss: 0.3733
Batch 250, Loss: 0.3745
Batch 260, Loss: 0.3811
Batch 270, Loss: 0.3873
Batch 280, Loss: 0.4486
Batch 290, Loss: 0.3997
Batch 300, Loss: 0.4121
Batch 310, Loss: 0.3950
Batch 320, Loss: 0.4092
Batch 330, Loss: 0.4077
Batch 340, Loss: 0.4104
Batch 350, Loss: 0.3988
Batch 360, Loss: 0.3950
Batch 370, Loss: 0.4050
Batch 380, Loss: 0.3581
Batch 390, Loss: 0.4133
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.151424407958984 seconds
Epoch 113 accuracy: 89.33%
Batch 10, Loss: 0.3788
Batch 20, Loss: 0.4074
Batch 30, Loss: 0.3568
Batch 40, Loss: 0.3897
Batch 50, Loss: 0.4101
Batch 60, Loss: 0.3817
Batch 70, Loss: 0.3978
Batch 80, Loss: 0.4047
Batch 90, Loss: 0.3994
Batch 100, Loss: 0.4107
Batch 110, Loss: 0.4060
Batch 120, Loss: 0.3826
Batch 130, Loss: 0.3544
Batch 140, Loss: 0.3930
Batch 150, Loss: 0.3894
Batch 160, Loss: 0.3880
Batch 170, Loss: 0.3996
Batch 180, Loss: 0.3702
Batch 190, Loss: 0.3929
Batch 200, Loss: 0.3666
Batch 210, Loss: 0.3922
Batch 220, Loss: 0.3991
Batch 230, Loss: 0.3877
Batch 240, Loss: 0.4081
Batch 250, Loss: 0.3938
Batch 260, Loss: 0.3947
Batch 270, Loss: 0.4294
Batch 280, Loss: 0.3980
Batch 290, Loss: 0.4096
Batch 300, Loss: 0.3795
Batch 310, Loss: 0.4069
Batch 320, Loss: 0.4393
Batch 330, Loss: 0.4049
Batch 340, Loss: 0.3825
Batch 350, Loss: 0.4007
Batch 360, Loss: 0.4063
Batch 370, Loss: 0.3900
Batch 380, Loss: 0.4129
Batch 390, Loss: 0.4063
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.26800513267517 seconds
Epoch 114 accuracy: 90.12%
Batch 10, Loss: 0.3794
Batch 20, Loss: 0.4096
Batch 30, Loss: 0.3763
Batch 40, Loss: 0.4308
Batch 50, Loss: 0.4077
Batch 60, Loss: 0.4054
Batch 70, Loss: 0.3990
Batch 80, Loss: 0.3895
Batch 90, Loss: 0.4133
Batch 100, Loss: 0.3794
Batch 110, Loss: 0.3611
Batch 120, Loss: 0.3828
Batch 130, Loss: 0.3649
Batch 140, Loss: 0.3868
Batch 150, Loss: 0.4003
Batch 160, Loss: 0.4155
Batch 170, Loss: 0.3976
Batch 180, Loss: 0.4071
Batch 190, Loss: 0.3873
Batch 200, Loss: 0.3970
Batch 210, Loss: 0.4125
Batch 220, Loss: 0.4038
Batch 230, Loss: 0.4179
Batch 240, Loss: 0.4393
Batch 250, Loss: 0.4114
Batch 260, Loss: 0.4310
Batch 270, Loss: 0.4007
Batch 280, Loss: 0.3845
Batch 290, Loss: 0.4231
Batch 300, Loss: 0.3491
Batch 310, Loss: 0.3822
Batch 320, Loss: 0.4039
Batch 330, Loss: 0.3813
Batch 340, Loss: 0.3890
Batch 350, Loss: 0.3813
Batch 360, Loss: 0.4017
Batch 370, Loss: 0.3988
Batch 380, Loss: 0.4035
Batch 390, Loss: 0.3874
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.266841173171997 seconds
Epoch 115 accuracy: 89.12%
Batch 10, Loss: 0.4019
Batch 20, Loss: 0.3732
Batch 30, Loss: 0.3632
Batch 40, Loss: 0.3992
Batch 50, Loss: 0.3354
Batch 60, Loss: 0.3642
Batch 70, Loss: 0.3901
Batch 80, Loss: 0.3898
Batch 90, Loss: 0.3881
Batch 100, Loss: 0.4134
Batch 110, Loss: 0.4016
Batch 120, Loss: 0.3882
Batch 130, Loss: 0.3470
Batch 140, Loss: 0.3913
Batch 150, Loss: 0.3877
Batch 160, Loss: 0.3742
Batch 170, Loss: 0.3617
Batch 180, Loss: 0.3945
Batch 190, Loss: 0.3821
Batch 200, Loss: 0.4318
Batch 210, Loss: 0.4032
Batch 220, Loss: 0.4121
Batch 230, Loss: 0.3721
Batch 240, Loss: 0.3900
Batch 250, Loss: 0.4068
Batch 260, Loss: 0.3829
Batch 270, Loss: 0.3613
Batch 280, Loss: 0.4375
Batch 290, Loss: 0.4250
Batch 300, Loss: 0.3942
Batch 310, Loss: 0.4185
Batch 320, Loss: 0.3913
Batch 330, Loss: 0.3811
Batch 340, Loss: 0.3821
Batch 350, Loss: 0.3937
Batch 360, Loss: 0.4013
Batch 370, Loss: 0.4111
Batch 380, Loss: 0.3600
Batch 390, Loss: 0.3854
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.4408061504364 seconds
Epoch 116 accuracy: 89.52%
Batch 10, Loss: 0.4155
Batch 20, Loss: 0.3712
Batch 30, Loss: 0.3828
Batch 40, Loss: 0.4293
Batch 50, Loss: 0.3966
Batch 60, Loss: 0.4330
Batch 70, Loss: 0.3722
Batch 80, Loss: 0.3961
Batch 90, Loss: 0.3826
Batch 100, Loss: 0.4157
Batch 110, Loss: 0.4270
Batch 120, Loss: 0.3850
Batch 130, Loss: 0.4249
Batch 140, Loss: 0.3946
Batch 150, Loss: 0.3725
Batch 160, Loss: 0.3448
Batch 170, Loss: 0.4080
Batch 180, Loss: 0.3663
Batch 190, Loss: 0.3956
Batch 200, Loss: 0.4061
Batch 210, Loss: 0.4269
Batch 220, Loss: 0.3768
Batch 230, Loss: 0.3741
Batch 240, Loss: 0.3949
Batch 250, Loss: 0.3779
Batch 260, Loss: 0.3615
Batch 270, Loss: 0.3414
Batch 280, Loss: 0.3801
Batch 290, Loss: 0.3805
Batch 300, Loss: 0.3596
Batch 310, Loss: 0.3920
Batch 320, Loss: 0.4231
Batch 330, Loss: 0.3961
Batch 340, Loss: 0.3561
Batch 350, Loss: 0.3915
Batch 360, Loss: 0.4052
Batch 370, Loss: 0.3742
Batch 380, Loss: 0.3769
Batch 390, Loss: 0.3826
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.248070001602173 seconds
Epoch 117 accuracy: 88.27%
Batch 10, Loss: 0.4092
Batch 20, Loss: 0.3490
Batch 30, Loss: 0.3906
Batch 40, Loss: 0.3980
Batch 50, Loss: 0.3804
Batch 60, Loss: 0.4306
Batch 70, Loss: 0.3824
Batch 80, Loss: 0.3913
Batch 90, Loss: 0.3705
Batch 100, Loss: 0.3822
Batch 110, Loss: 0.3847
Batch 120, Loss: 0.3822
Batch 130, Loss: 0.3608
Batch 140, Loss: 0.4065
Batch 150, Loss: 0.3968
Batch 160, Loss: 0.3663
Batch 170, Loss: 0.4043
Batch 180, Loss: 0.4000
Batch 190, Loss: 0.3586
Batch 200, Loss: 0.3590
Batch 210, Loss: 0.3805
Batch 220, Loss: 0.3953
Batch 230, Loss: 0.3716
Batch 240, Loss: 0.3785
Batch 250, Loss: 0.3898
Batch 260, Loss: 0.3730
Batch 270, Loss: 0.3488
Batch 280, Loss: 0.4034
Batch 290, Loss: 0.4021
Batch 300, Loss: 0.3912
Batch 310, Loss: 0.3777
Batch 320, Loss: 0.3936
Batch 330, Loss: 0.3939
Batch 340, Loss: 0.3760
Batch 350, Loss: 0.3683
Batch 360, Loss: 0.3701
Batch 370, Loss: 0.4137
Batch 380, Loss: 0.4043
Batch 390, Loss: 0.4104
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.137938261032104 seconds
Epoch 118 accuracy: 87.4%
Batch 10, Loss: 0.3933
Batch 20, Loss: 0.3542
Batch 30, Loss: 0.3336
Batch 40, Loss: 0.3809
Batch 50, Loss: 0.3700
Batch 60, Loss: 0.3890
Batch 70, Loss: 0.3970
Batch 80, Loss: 0.3506
Batch 90, Loss: 0.3664
Batch 100, Loss: 0.3890
Batch 110, Loss: 0.3508
Batch 120, Loss: 0.3864
Batch 130, Loss: 0.3997
Batch 140, Loss: 0.3932
Batch 150, Loss: 0.3902
Batch 160, Loss: 0.3852
Batch 170, Loss: 0.3964
Batch 180, Loss: 0.4032
Batch 190, Loss: 0.4040
Batch 200, Loss: 0.3671
Batch 210, Loss: 0.3879
Batch 220, Loss: 0.3611
Batch 230, Loss: 0.3995
Batch 240, Loss: 0.4210
Batch 250, Loss: 0.3747
Batch 260, Loss: 0.3865
Batch 270, Loss: 0.3939
Batch 280, Loss: 0.3594
Batch 290, Loss: 0.3759
Batch 300, Loss: 0.4205
Batch 310, Loss: 0.3949
Batch 320, Loss: 0.3336
Batch 330, Loss: 0.3842
Batch 340, Loss: 0.3897
Batch 350, Loss: 0.3822
Batch 360, Loss: 0.3808
Batch 370, Loss: 0.3619
Batch 380, Loss: 0.3610
Batch 390, Loss: 0.3663
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.32365322113037 seconds
Epoch 119 accuracy: 90.12%
Batch 10, Loss: 0.3855
Batch 20, Loss: 0.3730
Batch 30, Loss: 0.3644
Batch 40, Loss: 0.3457
Batch 50, Loss: 0.3487
Batch 60, Loss: 0.3712
Batch 70, Loss: 0.3784
Batch 80, Loss: 0.3901
Batch 90, Loss: 0.3932
Batch 100, Loss: 0.3611
Batch 110, Loss: 0.3623
Batch 120, Loss: 0.3932
Batch 130, Loss: 0.3756
Batch 140, Loss: 0.4077
Batch 150, Loss: 0.3652
Batch 160, Loss: 0.3775
Batch 170, Loss: 0.4095
Batch 180, Loss: 0.3557
Batch 190, Loss: 0.3717
Batch 200, Loss: 0.4169
Batch 210, Loss: 0.3891
Batch 220, Loss: 0.4507
Batch 230, Loss: 0.3718
Batch 240, Loss: 0.3828
Batch 250, Loss: 0.4201
Batch 260, Loss: 0.3996
Batch 270, Loss: 0.3614
Batch 280, Loss: 0.4201
Batch 290, Loss: 0.3995
Batch 300, Loss: 0.3982
Batch 310, Loss: 0.3506
Batch 320, Loss: 0.3943
Batch 330, Loss: 0.3645
Batch 340, Loss: 0.3944
Batch 350, Loss: 0.4006
Batch 360, Loss: 0.3890
Batch 370, Loss: 0.4029
Batch 380, Loss: 0.3756
Batch 390, Loss: 0.3600
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.34680199623108 seconds
Epoch 120 accuracy: 90.65%
Batch 10, Loss: 0.3913
Batch 20, Loss: 0.3667
Batch 30, Loss: 0.3620
Batch 40, Loss: 0.3647
Batch 50, Loss: 0.3549
Batch 60, Loss: 0.3660
Batch 70, Loss: 0.3627
Batch 80, Loss: 0.3873
Batch 90, Loss: 0.4074
Batch 100, Loss: 0.3505
Batch 110, Loss: 0.3691
Batch 120, Loss: 0.3419
Batch 130, Loss: 0.3562
Batch 140, Loss: 0.3814
Batch 150, Loss: 0.3884
Batch 160, Loss: 0.3896
Batch 170, Loss: 0.3965
Batch 180, Loss: 0.3761
Batch 190, Loss: 0.3551
Batch 200, Loss: 0.3480
Batch 210, Loss: 0.3868
Batch 220, Loss: 0.3450
Batch 230, Loss: 0.3836
Batch 240, Loss: 0.3470
Batch 250, Loss: 0.3769
Batch 260, Loss: 0.4142
Batch 270, Loss: 0.4063
Batch 280, Loss: 0.3677
Batch 290, Loss: 0.3681
Batch 300, Loss: 0.3176
Batch 310, Loss: 0.3919
Batch 320, Loss: 0.3375
Batch 330, Loss: 0.3718
Batch 340, Loss: 0.3915
Batch 350, Loss: 0.3824
Batch 360, Loss: 0.3878
Batch 370, Loss: 0.3908
Batch 380, Loss: 0.3920
Batch 390, Loss: 0.4004
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.373133897781372 seconds
Epoch 121 accuracy: 90.58%
Batch 10, Loss: 0.3682
Batch 20, Loss: 0.3765
Batch 30, Loss: 0.3734
Batch 40, Loss: 0.3726
Batch 50, Loss: 0.3745
Batch 60, Loss: 0.3943
Batch 70, Loss: 0.3962
Batch 80, Loss: 0.3869
Batch 90, Loss: 0.3532
Batch 100, Loss: 0.3822
Batch 110, Loss: 0.3845
Batch 120, Loss: 0.3545
Batch 130, Loss: 0.3907
Batch 140, Loss: 0.3647
Batch 150, Loss: 0.3702
Batch 160, Loss: 0.3547
Batch 170, Loss: 0.3405
Batch 180, Loss: 0.3845
Batch 190, Loss: 0.3813
Batch 200, Loss: 0.3518
Batch 210, Loss: 0.4013
Batch 220, Loss: 0.4051
Batch 230, Loss: 0.3879
Batch 240, Loss: 0.3416
Batch 250, Loss: 0.3821
Batch 260, Loss: 0.3687
Batch 270, Loss: 0.3641
Batch 280, Loss: 0.3847
Batch 290, Loss: 0.3740
Batch 300, Loss: 0.3710
Batch 310, Loss: 0.3733
Batch 320, Loss: 0.3975
Batch 330, Loss: 0.3639
Batch 340, Loss: 0.3724
Batch 350, Loss: 0.3823
Batch 360, Loss: 0.4003
Batch 370, Loss: 0.3615
Batch 380, Loss: 0.3982
Batch 390, Loss: 0.3582
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.36392378807068 seconds
Epoch 122 accuracy: 91.25%
Batch 10, Loss: 0.3817
Batch 20, Loss: 0.3865
Batch 30, Loss: 0.3847
Batch 40, Loss: 0.3476
Batch 50, Loss: 0.3601
Batch 60, Loss: 0.3390
Batch 70, Loss: 0.3422
Batch 80, Loss: 0.3586
Batch 90, Loss: 0.3405
Batch 100, Loss: 0.3720
Batch 110, Loss: 0.3637
Batch 120, Loss: 0.3809
Batch 130, Loss: 0.3359
Batch 140, Loss: 0.3852
Batch 150, Loss: 0.3363
Batch 160, Loss: 0.3952
Batch 170, Loss: 0.3643
Batch 180, Loss: 0.3902
Batch 190, Loss: 0.3525
Batch 200, Loss: 0.3845
Batch 210, Loss: 0.3816
Batch 220, Loss: 0.3586
Batch 230, Loss: 0.4033
Batch 240, Loss: 0.4087
Batch 250, Loss: 0.3651
Batch 260, Loss: 0.3356
Batch 270, Loss: 0.3550
Batch 280, Loss: 0.3972
Batch 290, Loss: 0.3719
Batch 300, Loss: 0.3512
Batch 310, Loss: 0.3924
Batch 320, Loss: 0.3653
Batch 330, Loss: 0.3754
Batch 340, Loss: 0.3923
Batch 350, Loss: 0.3786
Batch 360, Loss: 0.3864
Batch 370, Loss: 0.4135
Batch 380, Loss: 0.3917
Batch 390, Loss: 0.3415
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.249567985534668 seconds
Epoch 123 accuracy: 91.23%
Batch 10, Loss: 0.3452
Batch 20, Loss: 0.3542
Batch 30, Loss: 0.3348
Batch 40, Loss: 0.3559
Batch 50, Loss: 0.3858
Batch 60, Loss: 0.3793
Batch 70, Loss: 0.3494
Batch 80, Loss: 0.3659
Batch 90, Loss: 0.3758
Batch 100, Loss: 0.3807
Batch 110, Loss: 0.3475
Batch 120, Loss: 0.3575
Batch 130, Loss: 0.3637
Batch 140, Loss: 0.3900
Batch 150, Loss: 0.3599
Batch 160, Loss: 0.3515
Batch 170, Loss: 0.3442
Batch 180, Loss: 0.3421
Batch 190, Loss: 0.3498
Batch 200, Loss: 0.3649
Batch 210, Loss: 0.3441
Batch 220, Loss: 0.3569
Batch 230, Loss: 0.3605
Batch 240, Loss: 0.3844
Batch 250, Loss: 0.3801
Batch 260, Loss: 0.3877
Batch 270, Loss: 0.3900
Batch 280, Loss: 0.3322
Batch 290, Loss: 0.3807
Batch 300, Loss: 0.3640
Batch 310, Loss: 0.3924
Batch 320, Loss: 0.3745
Batch 330, Loss: 0.3621
Batch 340, Loss: 0.3913
Batch 350, Loss: 0.3962
Batch 360, Loss: 0.4057
Batch 370, Loss: 0.3313
Batch 380, Loss: 0.3548
Batch 390, Loss: 0.3767
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.255550861358643 seconds
Epoch 124 accuracy: 89.49%
Batch 10, Loss: 0.3616
Batch 20, Loss: 0.3643
Batch 30, Loss: 0.3510
Batch 40, Loss: 0.3703
Batch 50, Loss: 0.3699
Batch 60, Loss: 0.3684
Batch 70, Loss: 0.3771
Batch 80, Loss: 0.3426
Batch 90, Loss: 0.3534
Batch 100, Loss: 0.3654
Batch 110, Loss: 0.3566
Batch 120, Loss: 0.3731
Batch 130, Loss: 0.3559
Batch 140, Loss: 0.3574
Batch 150, Loss: 0.3278
Batch 160, Loss: 0.3681
Batch 170, Loss: 0.3919
Batch 180, Loss: 0.3791
Batch 190, Loss: 0.3324
Batch 200, Loss: 0.3330
Batch 210, Loss: 0.3543
Batch 220, Loss: 0.3447
Batch 230, Loss: 0.3451
Batch 240, Loss: 0.3772
Batch 250, Loss: 0.3543
Batch 260, Loss: 0.3920
Batch 270, Loss: 0.3733
Batch 280, Loss: 0.3521
Batch 290, Loss: 0.3380
Batch 300, Loss: 0.3834
Batch 310, Loss: 0.3766
Batch 320, Loss: 0.3417
Batch 330, Loss: 0.3801
Batch 340, Loss: 0.3430
Batch 350, Loss: 0.3685
Batch 360, Loss: 0.3702
Batch 370, Loss: 0.3525
Batch 380, Loss: 0.3592
Batch 390, Loss: 0.3872
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.270568132400513 seconds
Epoch 125 accuracy: 89.1%
Batch 10, Loss: 0.3724
Batch 20, Loss: 0.3720
Batch 30, Loss: 0.3633
Batch 40, Loss: 0.3279
Batch 50, Loss: 0.3945
Batch 60, Loss: 0.3491
Batch 70, Loss: 0.3634
Batch 80, Loss: 0.3333
Batch 90, Loss: 0.3502
Batch 100, Loss: 0.3703
Batch 110, Loss: 0.3295
Batch 120, Loss: 0.3825
Batch 130, Loss: 0.3615
Batch 140, Loss: 0.3881
Batch 150, Loss: 0.3851
Batch 160, Loss: 0.3397
Batch 170, Loss: 0.3653
Batch 180, Loss: 0.3646
Batch 190, Loss: 0.3380
Batch 200, Loss: 0.3578
Batch 210, Loss: 0.3548
Batch 220, Loss: 0.3577
Batch 230, Loss: 0.3805
Batch 240, Loss: 0.3521
Batch 250, Loss: 0.3894
Batch 260, Loss: 0.3683
Batch 270, Loss: 0.3993
Batch 280, Loss: 0.3636
Batch 290, Loss: 0.3643
Batch 300, Loss: 0.3552
Batch 310, Loss: 0.3810
Batch 320, Loss: 0.3259
Batch 330, Loss: 0.3450
Batch 340, Loss: 0.3702
Batch 350, Loss: 0.3532
Batch 360, Loss: 0.3647
Batch 370, Loss: 0.3818
Batch 380, Loss: 0.3644
Batch 390, Loss: 0.3685
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.360356092453003 seconds
Epoch 126 accuracy: 90.71%
Batch 10, Loss: 0.4011
Batch 20, Loss: 0.3577
Batch 30, Loss: 0.3879
Batch 40, Loss: 0.3589
Batch 50, Loss: 0.3507
Batch 60, Loss: 0.3502
Batch 70, Loss: 0.3563
Batch 80, Loss: 0.3497
Batch 90, Loss: 0.3573
Batch 100, Loss: 0.3743
Batch 110, Loss: 0.3409
Batch 120, Loss: 0.3063
Batch 130, Loss: 0.3533
Batch 140, Loss: 0.3562
Batch 150, Loss: 0.3477
Batch 160, Loss: 0.3869
Batch 170, Loss: 0.3647
Batch 180, Loss: 0.3588
Batch 190, Loss: 0.3383
Batch 200, Loss: 0.3668
Batch 210, Loss: 0.3521
Batch 220, Loss: 0.3601
Batch 230, Loss: 0.3127
Batch 240, Loss: 0.3340
Batch 250, Loss: 0.3544
Batch 260, Loss: 0.3569
Batch 270, Loss: 0.3678
Batch 280, Loss: 0.3258
Batch 290, Loss: 0.3751
Batch 300, Loss: 0.3345
Batch 310, Loss: 0.3868
Batch 320, Loss: 0.3829
Batch 330, Loss: 0.3608
Batch 340, Loss: 0.3638
Batch 350, Loss: 0.3609
Batch 360, Loss: 0.3913
Batch 370, Loss: 0.3714
Batch 380, Loss: 0.3508
Batch 390, Loss: 0.3823
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.106228590011597 seconds
Epoch 127 accuracy: 91.72%
Batch 10, Loss: 0.3849
Batch 20, Loss: 0.3536
Batch 30, Loss: 0.3617
Batch 40, Loss: 0.3925
Batch 50, Loss: 0.3635
Batch 60, Loss: 0.3587
Batch 70, Loss: 0.3254
Batch 80, Loss: 0.3483
Batch 90, Loss: 0.3249
Batch 100, Loss: 0.3680
Batch 110, Loss: 0.3656
Batch 120, Loss: 0.3458
Batch 130, Loss: 0.3559
Batch 140, Loss: 0.3556
Batch 150, Loss: 0.3307
Batch 160, Loss: 0.3298
Batch 170, Loss: 0.3704
Batch 180, Loss: 0.3666
Batch 190, Loss: 0.3499
Batch 200, Loss: 0.3687
Batch 210, Loss: 0.3341
Batch 220, Loss: 0.3630
Batch 230, Loss: 0.3707
Batch 240, Loss: 0.3541
Batch 250, Loss: 0.3487
Batch 260, Loss: 0.3525
Batch 270, Loss: 0.3957
Batch 280, Loss: 0.3452
Batch 290, Loss: 0.3576
Batch 300, Loss: 0.3666
Batch 310, Loss: 0.3534
Batch 320, Loss: 0.3482
Batch 330, Loss: 0.3433
Batch 340, Loss: 0.3913
Batch 350, Loss: 0.3444
Batch 360, Loss: 0.3662
Batch 370, Loss: 0.3537
Batch 380, Loss: 0.3482
Batch 390, Loss: 0.3482
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.2568781375885 seconds
Epoch 128 accuracy: 90.63%
Batch 10, Loss: 0.3346
Batch 20, Loss: 0.3592
Batch 30, Loss: 0.3755
Batch 40, Loss: 0.3529
Batch 50, Loss: 0.3433
Batch 60, Loss: 0.3547
Batch 70, Loss: 0.3629
Batch 80, Loss: 0.3887
Batch 90, Loss: 0.3578
Batch 100, Loss: 0.3646
Batch 110, Loss: 0.3621
Batch 120, Loss: 0.3603
Batch 130, Loss: 0.3723
Batch 140, Loss: 0.3586
Batch 150, Loss: 0.3707
Batch 160, Loss: 0.3567
Batch 170, Loss: 0.3500
Batch 180, Loss: 0.3428
Batch 190, Loss: 0.3422
Batch 200, Loss: 0.3477
Batch 210, Loss: 0.3493
Batch 220, Loss: 0.3408
Batch 230, Loss: 0.3591
Batch 240, Loss: 0.3497
Batch 250, Loss: 0.3700
Batch 260, Loss: 0.3351
Batch 270, Loss: 0.3349
Batch 280, Loss: 0.3543
Batch 290, Loss: 0.3574
Batch 300, Loss: 0.3437
Batch 310, Loss: 0.3778
Batch 320, Loss: 0.3684
Batch 330, Loss: 0.3426
Batch 340, Loss: 0.3402
Batch 350, Loss: 0.3444
Batch 360, Loss: 0.3481
Batch 370, Loss: 0.3111
Batch 380, Loss: 0.3637
Batch 390, Loss: 0.4154
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.177237033843994 seconds
Epoch 129 accuracy: 91.38%
Batch 10, Loss: 0.3290
Batch 20, Loss: 0.3099
Batch 30, Loss: 0.3450
Batch 40, Loss: 0.3278
Batch 50, Loss: 0.3587
Batch 60, Loss: 0.3416
Batch 70, Loss: 0.3301
Batch 80, Loss: 0.3634
Batch 90, Loss: 0.3387
Batch 100, Loss: 0.3227
Batch 110, Loss: 0.3308
Batch 120, Loss: 0.3234
Batch 130, Loss: 0.3650
Batch 140, Loss: 0.3397
Batch 150, Loss: 0.3227
Batch 160, Loss: 0.3537
Batch 170, Loss: 0.3678
Batch 180, Loss: 0.3529
Batch 190, Loss: 0.3523
Batch 200, Loss: 0.3660
Batch 210, Loss: 0.3554
Batch 220, Loss: 0.3596
Batch 230, Loss: 0.3912
Batch 240, Loss: 0.3786
Batch 250, Loss: 0.3559
Batch 260, Loss: 0.3929
Batch 270, Loss: 0.3718
Batch 280, Loss: 0.3523
Batch 290, Loss: 0.3538
Batch 300, Loss: 0.3283
Batch 310, Loss: 0.3362
Batch 320, Loss: 0.3385
Batch 330, Loss: 0.3603
Batch 340, Loss: 0.3556
Batch 350, Loss: 0.4011
Batch 360, Loss: 0.3682
Batch 370, Loss: 0.3650
Batch 380, Loss: 0.3220
Batch 390, Loss: 0.3769
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.35343337059021 seconds
Epoch 130 accuracy: 90.85%
Batch 10, Loss: 0.3881
Batch 20, Loss: 0.3624
Batch 30, Loss: 0.3588
Batch 40, Loss: 0.3591
Batch 50, Loss: 0.3827
Batch 60, Loss: 0.3650
Batch 70, Loss: 0.3776
Batch 80, Loss: 0.3664
Batch 90, Loss: 0.3586
Batch 100, Loss: 0.3585
Batch 110, Loss: 0.3407
Batch 120, Loss: 0.3346
Batch 130, Loss: 0.3524
Batch 140, Loss: 0.3430
Batch 150, Loss: 0.3149
Batch 160, Loss: 0.3655
Batch 170, Loss: 0.4009
Batch 180, Loss: 0.3369
Batch 190, Loss: 0.3038
Batch 200, Loss: 0.3327
Batch 210, Loss: 0.3422
Batch 220, Loss: 0.3301
Batch 230, Loss: 0.3484
Batch 240, Loss: 0.3509
Batch 250, Loss: 0.3352
Batch 260, Loss: 0.3551
Batch 270, Loss: 0.3799
Batch 280, Loss: 0.3027
Batch 290, Loss: 0.3573
Batch 300, Loss: 0.3500
Batch 310, Loss: 0.3436
Batch 320, Loss: 0.3417
Batch 330, Loss: 0.3280
Batch 340, Loss: 0.3343
Batch 350, Loss: 0.3740
Batch 360, Loss: 0.3439
Batch 370, Loss: 0.3285
Batch 380, Loss: 0.3459
Batch 390, Loss: 0.3730
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.29438853263855 seconds
Epoch 131 accuracy: 91.0%
Batch 10, Loss: 0.3179
Batch 20, Loss: 0.3605
Batch 30, Loss: 0.3478
Batch 40, Loss: 0.3364
Batch 50, Loss: 0.3545
Batch 60, Loss: 0.3232
Batch 70, Loss: 0.3211
Batch 80, Loss: 0.3524
Batch 90, Loss: 0.3771
Batch 100, Loss: 0.3309
Batch 110, Loss: 0.3091
Batch 120, Loss: 0.3529
Batch 130, Loss: 0.3547
Batch 140, Loss: 0.3108
Batch 150, Loss: 0.3563
Batch 160, Loss: 0.3877
Batch 170, Loss: 0.3370
Batch 180, Loss: 0.3395
Batch 190, Loss: 0.3295
Batch 200, Loss: 0.3566
Batch 210, Loss: 0.3253
Batch 220, Loss: 0.3639
Batch 230, Loss: 0.2982
Batch 240, Loss: 0.3463
Batch 250, Loss: 0.3558
Batch 260, Loss: 0.3616
Batch 270, Loss: 0.3569
Batch 280, Loss: 0.2998
Batch 290, Loss: 0.3270
Batch 300, Loss: 0.3326
Batch 310, Loss: 0.3557
Batch 320, Loss: 0.3785
Batch 330, Loss: 0.3455
Batch 340, Loss: 0.3398
Batch 350, Loss: 0.3401
Batch 360, Loss: 0.3894
Batch 370, Loss: 0.3458
Batch 380, Loss: 0.3729
Batch 390, Loss: 0.3592
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.17420506477356 seconds
Epoch 132 accuracy: 91.72%
Batch 10, Loss: 0.3396
Batch 20, Loss: 0.3187
Batch 30, Loss: 0.3175
Batch 40, Loss: 0.3354
Batch 50, Loss: 0.3512
Batch 60, Loss: 0.3037
Batch 70, Loss: 0.3264
Batch 80, Loss: 0.3644
Batch 90, Loss: 0.3183
Batch 100, Loss: 0.3380
Batch 110, Loss: 0.3430
Batch 120, Loss: 0.3333
Batch 130, Loss: 0.3431
Batch 140, Loss: 0.3427
Batch 150, Loss: 0.3702
Batch 160, Loss: 0.3266
Batch 170, Loss: 0.3355
Batch 180, Loss: 0.3349
Batch 190, Loss: 0.3530
Batch 200, Loss: 0.3080
Batch 210, Loss: 0.3139
Batch 220, Loss: 0.3385
Batch 230, Loss: 0.3358
Batch 240, Loss: 0.3223
Batch 250, Loss: 0.3575
Batch 260, Loss: 0.3279
Batch 270, Loss: 0.3405
Batch 280, Loss: 0.3564
Batch 290, Loss: 0.3552
Batch 300, Loss: 0.3266
Batch 310, Loss: 0.3392
Batch 320, Loss: 0.3542
Batch 330, Loss: 0.3667
Batch 340, Loss: 0.3667
Batch 350, Loss: 0.3166
Batch 360, Loss: 0.3453
Batch 370, Loss: 0.2907
Batch 380, Loss: 0.3631
Batch 390, Loss: 0.3164
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.304713249206543 seconds
Epoch 133 accuracy: 90.38%
Batch 10, Loss: 0.3331
Batch 20, Loss: 0.3270
Batch 30, Loss: 0.3634
Batch 40, Loss: 0.3109
Batch 50, Loss: 0.3154
Batch 60, Loss: 0.3346
Batch 70, Loss: 0.3218
Batch 80, Loss: 0.2959
Batch 90, Loss: 0.3377
Batch 100, Loss: 0.3253
Batch 110, Loss: 0.3361
Batch 120, Loss: 0.3130
Batch 130, Loss: 0.3354
Batch 140, Loss: 0.3422
Batch 150, Loss: 0.3259
Batch 160, Loss: 0.3242
Batch 170, Loss: 0.3680
Batch 180, Loss: 0.2989
Batch 190, Loss: 0.3165
Batch 200, Loss: 0.3548
Batch 210, Loss: 0.3545
Batch 220, Loss: 0.3505
Batch 230, Loss: 0.3576
Batch 240, Loss: 0.3258
Batch 250, Loss: 0.3697
Batch 260, Loss: 0.3127
Batch 270, Loss: 0.3486
Batch 280, Loss: 0.3540
Batch 290, Loss: 0.3373
Batch 300, Loss: 0.3180
Batch 310, Loss: 0.3305
Batch 320, Loss: 0.3655
Batch 330, Loss: 0.3207
Batch 340, Loss: 0.3323
Batch 350, Loss: 0.3209
Batch 360, Loss: 0.3229
Batch 370, Loss: 0.3398
Batch 380, Loss: 0.3606
Batch 390, Loss: 0.3449
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.22477102279663 seconds
Epoch 134 accuracy: 92.29%
Batch 10, Loss: 0.3306
Batch 20, Loss: 0.3216
Batch 30, Loss: 0.3276
Batch 40, Loss: 0.3393
Batch 50, Loss: 0.3027
Batch 60, Loss: 0.3366
Batch 70, Loss: 0.3235
Batch 80, Loss: 0.3076
Batch 90, Loss: 0.3207
Batch 100, Loss: 0.3237
Batch 110, Loss: 0.3342
Batch 120, Loss: 0.3392
Batch 130, Loss: 0.3239
Batch 140, Loss: 0.3642
Batch 150, Loss: 0.3237
Batch 160, Loss: 0.3109
Batch 170, Loss: 0.3379
Batch 180, Loss: 0.3142
Batch 190, Loss: 0.3154
Batch 200, Loss: 0.3406
Batch 210, Loss: 0.3302
Batch 220, Loss: 0.3562
Batch 230, Loss: 0.2985
Batch 240, Loss: 0.3577
Batch 250, Loss: 0.3121
Batch 260, Loss: 0.3161
Batch 270, Loss: 0.3080
Batch 280, Loss: 0.3632
Batch 290, Loss: 0.3478
Batch 300, Loss: 0.3464
Batch 310, Loss: 0.3144
Batch 320, Loss: 0.3193
Batch 330, Loss: 0.3128
Batch 340, Loss: 0.3641
Batch 350, Loss: 0.3427
Batch 360, Loss: 0.3472
Batch 370, Loss: 0.3706
Batch 380, Loss: 0.3551
Batch 390, Loss: 0.3626
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.408455848693848 seconds
Epoch 135 accuracy: 91.88%
Batch 10, Loss: 0.3486
Batch 20, Loss: 0.3195
Batch 30, Loss: 0.3394
Batch 40, Loss: 0.3226
Batch 50, Loss: 0.3007
Batch 60, Loss: 0.3253
Batch 70, Loss: 0.3483
Batch 80, Loss: 0.3391
Batch 90, Loss: 0.2933
Batch 100, Loss: 0.3216
Batch 110, Loss: 0.3378
Batch 120, Loss: 0.3148
Batch 130, Loss: 0.3192
Batch 140, Loss: 0.3506
Batch 150, Loss: 0.3495
Batch 160, Loss: 0.3173
Batch 170, Loss: 0.3067
Batch 180, Loss: 0.3379
Batch 190, Loss: 0.3027
Batch 200, Loss: 0.3401
Batch 210, Loss: 0.3405
Batch 220, Loss: 0.3355
Batch 230, Loss: 0.3214
Batch 240, Loss: 0.3441
Batch 250, Loss: 0.3353
Batch 260, Loss: 0.3138
Batch 270, Loss: 0.3638
Batch 280, Loss: 0.3306
Batch 290, Loss: 0.3210
Batch 300, Loss: 0.3356
Batch 310, Loss: 0.3335
Batch 320, Loss: 0.2976
Batch 330, Loss: 0.3512
Batch 340, Loss: 0.3423
Batch 350, Loss: 0.3413
Batch 360, Loss: 0.3191
Batch 370, Loss: 0.3397
Batch 380, Loss: 0.3137
Batch 390, Loss: 0.3438
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.28126835823059 seconds
Epoch 136 accuracy: 92.29%
Batch 10, Loss: 0.3100
Batch 20, Loss: 0.3286
Batch 30, Loss: 0.3145
Batch 40, Loss: 0.3170
Batch 50, Loss: 0.3163
Batch 60, Loss: 0.3159
Batch 70, Loss: 0.3280
Batch 80, Loss: 0.3341
Batch 90, Loss: 0.3374
Batch 100, Loss: 0.3480
Batch 110, Loss: 0.3421
Batch 120, Loss: 0.3169
Batch 130, Loss: 0.3337
Batch 140, Loss: 0.3277
Batch 150, Loss: 0.3048
Batch 160, Loss: 0.3204
Batch 170, Loss: 0.3187
Batch 180, Loss: 0.3021
Batch 190, Loss: 0.3491
Batch 200, Loss: 0.3516
Batch 210, Loss: 0.3140
Batch 220, Loss: 0.3391
Batch 230, Loss: 0.3649
Batch 240, Loss: 0.3437
Batch 250, Loss: 0.3151
Batch 260, Loss: 0.3317
Batch 270, Loss: 0.3243
Batch 280, Loss: 0.3162
Batch 290, Loss: 0.3068
Batch 300, Loss: 0.3463
Batch 310, Loss: 0.3333
Batch 320, Loss: 0.3115
Batch 330, Loss: 0.3314
Batch 340, Loss: 0.3493
Batch 350, Loss: 0.3054
Batch 360, Loss: 0.3229
Batch 370, Loss: 0.3211
Batch 380, Loss: 0.3387
Batch 390, Loss: 0.3107
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.08917784690857 seconds
Epoch 137 accuracy: 92.11%
Batch 10, Loss: 0.2945
Batch 20, Loss: 0.2971
Batch 30, Loss: 0.3394
Batch 40, Loss: 0.3451
Batch 50, Loss: 0.3064
Batch 60, Loss: 0.3176
Batch 70, Loss: 0.2994
Batch 80, Loss: 0.3241
Batch 90, Loss: 0.3375
Batch 100, Loss: 0.3069
Batch 110, Loss: 0.3072
Batch 120, Loss: 0.3284
Batch 130, Loss: 0.2965
Batch 140, Loss: 0.2842
Batch 150, Loss: 0.3195
Batch 160, Loss: 0.3306
Batch 170, Loss: 0.2951
Batch 180, Loss: 0.3607
Batch 190, Loss: 0.3546
Batch 200, Loss: 0.3272
Batch 210, Loss: 0.3123
Batch 220, Loss: 0.3074
Batch 230, Loss: 0.3241
Batch 240, Loss: 0.3341
Batch 250, Loss: 0.3261
Batch 260, Loss: 0.3270
Batch 270, Loss: 0.3256
Batch 280, Loss: 0.3264
Batch 290, Loss: 0.3268
Batch 300, Loss: 0.3379
Batch 310, Loss: 0.3107
Batch 320, Loss: 0.2972
Batch 330, Loss: 0.3295
Batch 340, Loss: 0.2972
Batch 350, Loss: 0.3052
Batch 360, Loss: 0.3413
Batch 370, Loss: 0.2799
Batch 380, Loss: 0.3043
Batch 390, Loss: 0.3444
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.173670053482056 seconds
Epoch 138 accuracy: 92.02%
Batch 10, Loss: 0.3074
Batch 20, Loss: 0.3002
Batch 30, Loss: 0.3160
Batch 40, Loss: 0.3143
Batch 50, Loss: 0.3175
Batch 60, Loss: 0.3216
Batch 70, Loss: 0.3350
Batch 80, Loss: 0.3024
Batch 90, Loss: 0.3021
Batch 100, Loss: 0.3172
Batch 110, Loss: 0.2934
Batch 120, Loss: 0.3162
Batch 130, Loss: 0.3234
Batch 140, Loss: 0.3381
Batch 150, Loss: 0.3000
Batch 160, Loss: 0.3259
Batch 170, Loss: 0.3359
Batch 180, Loss: 0.3476
Batch 190, Loss: 0.3524
Batch 200, Loss: 0.3036
Batch 210, Loss: 0.3035
Batch 220, Loss: 0.3295
Batch 230, Loss: 0.3285
Batch 240, Loss: 0.3235
Batch 250, Loss: 0.3226
Batch 260, Loss: 0.3210
Batch 270, Loss: 0.3103
Batch 280, Loss: 0.2988
Batch 290, Loss: 0.3241
Batch 300, Loss: 0.3197
Batch 310, Loss: 0.3205
Batch 320, Loss: 0.3203
Batch 330, Loss: 0.3349
Batch 340, Loss: 0.3169
Batch 350, Loss: 0.3344
Batch 360, Loss: 0.3036
Batch 370, Loss: 0.3101
Batch 380, Loss: 0.3202
Batch 390, Loss: 0.3211
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.313191175460815 seconds
Epoch 139 accuracy: 92.21%
Batch 10, Loss: 0.3182
Batch 20, Loss: 0.3119
Batch 30, Loss: 0.3197
Batch 40, Loss: 0.3166
Batch 50, Loss: 0.3017
Batch 60, Loss: 0.3078
Batch 70, Loss: 0.3146
Batch 80, Loss: 0.2900
Batch 90, Loss: 0.2673
Batch 100, Loss: 0.3248
Batch 110, Loss: 0.3262
Batch 120, Loss: 0.3005
Batch 130, Loss: 0.2995
Batch 140, Loss: 0.3156
Batch 150, Loss: 0.3276
Batch 160, Loss: 0.3129
Batch 170, Loss: 0.2982
Batch 180, Loss: 0.2946
Batch 190, Loss: 0.3099
Batch 200, Loss: 0.2940
Batch 210, Loss: 0.3240
Batch 220, Loss: 0.2896
Batch 230, Loss: 0.3148
Batch 240, Loss: 0.3299
Batch 250, Loss: 0.2919
Batch 260, Loss: 0.3121
Batch 270, Loss: 0.2939
Batch 280, Loss: 0.3154
Batch 290, Loss: 0.3134
Batch 300, Loss: 0.3320
Batch 310, Loss: 0.3051
Batch 320, Loss: 0.3370
Batch 330, Loss: 0.3588
Batch 340, Loss: 0.3142
Batch 350, Loss: 0.3354
Batch 360, Loss: 0.3342
Batch 370, Loss: 0.3264
Batch 380, Loss: 0.2956
Batch 390, Loss: 0.3503
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.399052143096924 seconds
Epoch 140 accuracy: 92.7%
Batch 10, Loss: 0.3014
Batch 20, Loss: 0.3200
Batch 30, Loss: 0.3231
Batch 40, Loss: 0.3179
Batch 50, Loss: 0.2972
Batch 60, Loss: 0.3329
Batch 70, Loss: 0.3090
Batch 80, Loss: 0.3178
Batch 90, Loss: 0.2758
Batch 100, Loss: 0.2922
Batch 110, Loss: 0.3033
Batch 120, Loss: 0.3225
Batch 130, Loss: 0.2884
Batch 140, Loss: 0.3161
Batch 150, Loss: 0.3185
Batch 160, Loss: 0.3191
Batch 170, Loss: 0.3336
Batch 180, Loss: 0.2863
Batch 190, Loss: 0.3290
Batch 200, Loss: 0.3114
Batch 210, Loss: 0.3323
Batch 220, Loss: 0.3171
Batch 230, Loss: 0.2692
Batch 240, Loss: 0.3004
Batch 250, Loss: 0.3228
Batch 260, Loss: 0.3036
Batch 270, Loss: 0.3213
Batch 280, Loss: 0.2926
Batch 290, Loss: 0.3198
Batch 300, Loss: 0.2972
Batch 310, Loss: 0.3165
Batch 320, Loss: 0.3388
Batch 330, Loss: 0.2934
Batch 340, Loss: 0.3277
Batch 350, Loss: 0.3222
Batch 360, Loss: 0.3279
Batch 370, Loss: 0.3270
Batch 380, Loss: 0.3120
Batch 390, Loss: 0.3002
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.287604808807373 seconds
Epoch 141 accuracy: 93.04%
Batch 10, Loss: 0.2859
Batch 20, Loss: 0.3078
Batch 30, Loss: 0.3289
Batch 40, Loss: 0.3235
Batch 50, Loss: 0.3239
Batch 60, Loss: 0.2952
Batch 70, Loss: 0.3252
Batch 80, Loss: 0.3106
Batch 90, Loss: 0.3244
Batch 100, Loss: 0.3325
Batch 110, Loss: 0.2987
Batch 120, Loss: 0.3130
Batch 130, Loss: 0.2906
Batch 140, Loss: 0.3086
Batch 150, Loss: 0.2876
Batch 160, Loss: 0.2795
Batch 170, Loss: 0.3037
Batch 180, Loss: 0.2951
Batch 190, Loss: 0.2929
Batch 200, Loss: 0.3259
Batch 210, Loss: 0.2944
Batch 220, Loss: 0.3147
Batch 230, Loss: 0.3230
Batch 240, Loss: 0.2805
Batch 250, Loss: 0.3324
Batch 260, Loss: 0.2976
Batch 270, Loss: 0.3220
Batch 280, Loss: 0.2790
Batch 290, Loss: 0.3031
Batch 300, Loss: 0.3292
Batch 310, Loss: 0.3105
Batch 320, Loss: 0.3353
Batch 330, Loss: 0.2924
Batch 340, Loss: 0.3110
Batch 350, Loss: 0.3412
Batch 360, Loss: 0.2872
Batch 370, Loss: 0.2866
Batch 380, Loss: 0.2748
Batch 390, Loss: 0.3040
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.477224349975586 seconds
Epoch 142 accuracy: 93.33%
Batch 10, Loss: 0.2966
Batch 20, Loss: 0.3020
Batch 30, Loss: 0.3073
Batch 40, Loss: 0.3011
Batch 50, Loss: 0.2974
Batch 60, Loss: 0.2865
Batch 70, Loss: 0.2753
Batch 80, Loss: 0.3042
Batch 90, Loss: 0.3199
Batch 100, Loss: 0.3205
Batch 110, Loss: 0.2819
Batch 120, Loss: 0.3158
Batch 130, Loss: 0.3084
Batch 140, Loss: 0.2942
Batch 150, Loss: 0.3075
Batch 160, Loss: 0.3285
Batch 170, Loss: 0.2886
Batch 180, Loss: 0.3235
Batch 190, Loss: 0.3231
Batch 200, Loss: 0.3018
Batch 210, Loss: 0.3038
Batch 220, Loss: 0.2916
Batch 230, Loss: 0.2743
Batch 240, Loss: 0.3027
Batch 250, Loss: 0.3074
Batch 260, Loss: 0.3030
Batch 270, Loss: 0.2973
Batch 280, Loss: 0.3186
Batch 290, Loss: 0.2689
Batch 300, Loss: 0.3144
Batch 310, Loss: 0.3080
Batch 320, Loss: 0.3058
Batch 330, Loss: 0.3002
Batch 340, Loss: 0.3405
Batch 350, Loss: 0.3362
Batch 360, Loss: 0.2750
Batch 370, Loss: 0.3245
Batch 380, Loss: 0.2993
Batch 390, Loss: 0.2809
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.195396900177002 seconds
Epoch 143 accuracy: 93.51%
Batch 10, Loss: 0.2956
Batch 20, Loss: 0.2738
Batch 30, Loss: 0.2927
Batch 40, Loss: 0.3100
Batch 50, Loss: 0.2926
Batch 60, Loss: 0.2959
Batch 70, Loss: 0.3008
Batch 80, Loss: 0.2933
Batch 90, Loss: 0.3021
Batch 100, Loss: 0.3323
Batch 110, Loss: 0.3140
Batch 120, Loss: 0.2874
Batch 130, Loss: 0.2956
Batch 140, Loss: 0.3156
Batch 150, Loss: 0.3128
Batch 160, Loss: 0.3102
Batch 170, Loss: 0.2701
Batch 180, Loss: 0.2789
Batch 190, Loss: 0.2684
Batch 200, Loss: 0.2784
Batch 210, Loss: 0.2870
Batch 220, Loss: 0.3173
Batch 230, Loss: 0.3366
Batch 240, Loss: 0.3205
Batch 250, Loss: 0.2967
Batch 260, Loss: 0.3112
Batch 270, Loss: 0.2821
Batch 280, Loss: 0.2810
Batch 290, Loss: 0.2940
Batch 300, Loss: 0.3151
Batch 310, Loss: 0.3056
Batch 320, Loss: 0.3025
Batch 330, Loss: 0.2913
Batch 340, Loss: 0.3131
Batch 350, Loss: 0.3225
Batch 360, Loss: 0.3406
Batch 370, Loss: 0.2838
Batch 380, Loss: 0.3096
Batch 390, Loss: 0.2921
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.286333084106445 seconds
Epoch 144 accuracy: 92.96%
Batch 10, Loss: 0.3184
Batch 20, Loss: 0.2815
Batch 30, Loss: 0.3090
Batch 40, Loss: 0.2833
Batch 50, Loss: 0.3339
Batch 60, Loss: 0.3131
Batch 70, Loss: 0.2978
Batch 80, Loss: 0.2822
Batch 90, Loss: 0.2672
Batch 100, Loss: 0.3212
Batch 110, Loss: 0.2765
Batch 120, Loss: 0.2896
Batch 130, Loss: 0.3020
Batch 140, Loss: 0.2857
Batch 150, Loss: 0.2920
Batch 160, Loss: 0.2978
Batch 170, Loss: 0.3194
Batch 180, Loss: 0.3064
Batch 190, Loss: 0.2938
Batch 200, Loss: 0.2722
Batch 210, Loss: 0.3037
Batch 220, Loss: 0.2868
Batch 230, Loss: 0.2750
Batch 240, Loss: 0.3133
Batch 250, Loss: 0.3014
Batch 260, Loss: 0.3042
Batch 270, Loss: 0.2954
Batch 280, Loss: 0.2908
Batch 290, Loss: 0.3242
Batch 300, Loss: 0.3159
Batch 310, Loss: 0.3240
Batch 320, Loss: 0.2758
Batch 330, Loss: 0.2999
Batch 340, Loss: 0.2957
Batch 350, Loss: 0.2798
Batch 360, Loss: 0.2913
Batch 370, Loss: 0.2817
Batch 380, Loss: 0.2960
Batch 390, Loss: 0.2881
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.207818269729614 seconds
Epoch 145 accuracy: 93.08%
Batch 10, Loss: 0.2860
Batch 20, Loss: 0.2934
Batch 30, Loss: 0.2802
Batch 40, Loss: 0.3057
Batch 50, Loss: 0.2874
Batch 60, Loss: 0.2780
Batch 70, Loss: 0.2927
Batch 80, Loss: 0.3065
Batch 90, Loss: 0.3172
Batch 100, Loss: 0.2889
Batch 110, Loss: 0.2988
Batch 120, Loss: 0.2966
Batch 130, Loss: 0.3025
Batch 140, Loss: 0.2555
Batch 150, Loss: 0.2927
Batch 160, Loss: 0.2875
Batch 170, Loss: 0.2637
Batch 180, Loss: 0.2800
Batch 190, Loss: 0.2932
Batch 200, Loss: 0.2987
Batch 210, Loss: 0.2971
Batch 220, Loss: 0.3122
Batch 230, Loss: 0.3030
Batch 240, Loss: 0.2992
Batch 250, Loss: 0.2759
Batch 260, Loss: 0.2689
Batch 270, Loss: 0.2473
Batch 280, Loss: 0.2767
Batch 290, Loss: 0.2723
Batch 300, Loss: 0.2835
Batch 310, Loss: 0.3047
Batch 320, Loss: 0.3058
Batch 330, Loss: 0.2866
Batch 340, Loss: 0.3062
Batch 350, Loss: 0.3069
Batch 360, Loss: 0.2727
Batch 370, Loss: 0.2961
Batch 380, Loss: 0.3255
Batch 390, Loss: 0.3108
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.22760796546936 seconds
Epoch 146 accuracy: 92.79%
Batch 10, Loss: 0.2864
Batch 20, Loss: 0.2957
Batch 30, Loss: 0.2477
Batch 40, Loss: 0.2891
Batch 50, Loss: 0.3256
Batch 60, Loss: 0.2824
Batch 70, Loss: 0.2765
Batch 80, Loss: 0.2714
Batch 90, Loss: 0.2980
Batch 100, Loss: 0.2752
Batch 110, Loss: 0.2744
Batch 120, Loss: 0.2997
Batch 130, Loss: 0.3022
Batch 140, Loss: 0.2953
Batch 150, Loss: 0.2899
Batch 160, Loss: 0.2779
Batch 170, Loss: 0.2543
Batch 180, Loss: 0.2757
Batch 190, Loss: 0.3057
Batch 200, Loss: 0.2549
Batch 210, Loss: 0.2882
Batch 220, Loss: 0.3431
Batch 230, Loss: 0.2905
Batch 240, Loss: 0.2850
Batch 250, Loss: 0.2792
Batch 260, Loss: 0.3223
Batch 270, Loss: 0.2885
Batch 280, Loss: 0.3151
Batch 290, Loss: 0.2886
Batch 300, Loss: 0.2932
Batch 310, Loss: 0.2871
Batch 320, Loss: 0.3043
Batch 330, Loss: 0.2844
Batch 340, Loss: 0.2971
Batch 350, Loss: 0.2942
Batch 360, Loss: 0.3155
Batch 370, Loss: 0.2837
Batch 380, Loss: 0.2592
Batch 390, Loss: 0.2893
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.353848218917847 seconds
Epoch 147 accuracy: 93.06%
Batch 10, Loss: 0.3128
Batch 20, Loss: 0.2884
Batch 30, Loss: 0.2873
Batch 40, Loss: 0.2694
Batch 50, Loss: 0.2865
Batch 60, Loss: 0.2910
Batch 70, Loss: 0.2647
Batch 80, Loss: 0.2993
Batch 90, Loss: 0.3141
Batch 100, Loss: 0.2863
Batch 110, Loss: 0.2849
Batch 120, Loss: 0.2938
Batch 130, Loss: 0.2774
Batch 140, Loss: 0.3248
Batch 150, Loss: 0.2969
Batch 160, Loss: 0.2952
Batch 170, Loss: 0.2888
Batch 180, Loss: 0.2903
Batch 190, Loss: 0.2625
Batch 200, Loss: 0.2668
Batch 210, Loss: 0.2803
Batch 220, Loss: 0.2872
Batch 230, Loss: 0.2991
Batch 240, Loss: 0.2991
Batch 250, Loss: 0.2945
Batch 260, Loss: 0.2637
Batch 270, Loss: 0.2726
Batch 280, Loss: 0.3113
Batch 290, Loss: 0.2948
Batch 300, Loss: 0.2952
Batch 310, Loss: 0.2668
Batch 320, Loss: 0.2748
Batch 330, Loss: 0.2860
Batch 340, Loss: 0.2674
Batch 350, Loss: 0.3186
Batch 360, Loss: 0.2850
Batch 370, Loss: 0.2750
Batch 380, Loss: 0.2782
Batch 390, Loss: 0.2935
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.314430236816406 seconds
Epoch 148 accuracy: 93.52%
Batch 10, Loss: 0.2612
Batch 20, Loss: 0.2525
Batch 30, Loss: 0.2659
Batch 40, Loss: 0.2813
Batch 50, Loss: 0.2661
Batch 60, Loss: 0.2737
Batch 70, Loss: 0.3119
Batch 80, Loss: 0.2797
Batch 90, Loss: 0.2798
Batch 100, Loss: 0.2777
Batch 110, Loss: 0.2766
Batch 120, Loss: 0.2716
Batch 130, Loss: 0.2710
Batch 140, Loss: 0.2966
Batch 150, Loss: 0.2454
Batch 160, Loss: 0.2956
Batch 170, Loss: 0.2816
Batch 180, Loss: 0.2774
Batch 190, Loss: 0.2732
Batch 200, Loss: 0.2956
Batch 210, Loss: 0.2742
Batch 220, Loss: 0.3057
Batch 230, Loss: 0.3024
Batch 240, Loss: 0.2877
Batch 250, Loss: 0.3063
Batch 260, Loss: 0.2717
Batch 270, Loss: 0.2879
Batch 280, Loss: 0.2909
Batch 290, Loss: 0.2695
Batch 300, Loss: 0.3637
Batch 310, Loss: 0.2746
Batch 320, Loss: 0.2777
Batch 330, Loss: 0.3002
Batch 340, Loss: 0.2949
Batch 350, Loss: 0.2735
Batch 360, Loss: 0.3164
Batch 370, Loss: 0.2961
Batch 380, Loss: 0.2702
Batch 390, Loss: 0.2684
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.385688304901123 seconds
Epoch 149 accuracy: 93.77%
Batch 10, Loss: 0.2625
Batch 20, Loss: 0.2691
Batch 30, Loss: 0.2635
Batch 40, Loss: 0.2891
Batch 50, Loss: 0.2704
Batch 60, Loss: 0.2348
Batch 70, Loss: 0.2681
Batch 80, Loss: 0.2738
Batch 90, Loss: 0.2598
Batch 100, Loss: 0.2478
Batch 110, Loss: 0.2985
Batch 120, Loss: 0.2819
Batch 130, Loss: 0.2656
Batch 140, Loss: 0.2713
Batch 150, Loss: 0.2933
Batch 160, Loss: 0.2903
Batch 170, Loss: 0.2615
Batch 180, Loss: 0.2799
Batch 190, Loss: 0.2962
Batch 200, Loss: 0.2743
Batch 210, Loss: 0.2806
Batch 220, Loss: 0.2744
Batch 230, Loss: 0.2776
Batch 240, Loss: 0.2964
Batch 250, Loss: 0.2743
Batch 260, Loss: 0.2827
Batch 270, Loss: 0.2407
Batch 280, Loss: 0.2665
Batch 290, Loss: 0.2391
Batch 300, Loss: 0.3091
Batch 310, Loss: 0.2693
Batch 320, Loss: 0.2714
Batch 330, Loss: 0.2788
Batch 340, Loss: 0.2901
Batch 350, Loss: 0.2677
Batch 360, Loss: 0.2869
Batch 370, Loss: 0.3147
Batch 380, Loss: 0.2695
Batch 390, Loss: 0.3063
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.27146553993225 seconds
Epoch 150 accuracy: 93.83%
Batch 10, Loss: 0.2683
Batch 20, Loss: 0.2686
Batch 30, Loss: 0.2845
Batch 40, Loss: 0.2927
Batch 50, Loss: 0.2957
Batch 60, Loss: 0.2953
Batch 70, Loss: 0.2789
Batch 80, Loss: 0.3086
Batch 90, Loss: 0.3100
Batch 100, Loss: 0.2679
Batch 110, Loss: 0.2831
Batch 120, Loss: 0.2547
Batch 130, Loss: 0.2674
Batch 140, Loss: 0.3115
Batch 150, Loss: 0.2648
Batch 160, Loss: 0.2507
Batch 170, Loss: 0.2706
Batch 180, Loss: 0.2763
Batch 190, Loss: 0.2599
Batch 200, Loss: 0.2696
Batch 210, Loss: 0.2751
Batch 220, Loss: 0.2867
Batch 230, Loss: 0.2698
Batch 240, Loss: 0.2761
Batch 250, Loss: 0.2767
Batch 260, Loss: 0.2772
Batch 270, Loss: 0.2926
Batch 280, Loss: 0.2393
Batch 290, Loss: 0.2858
Batch 300, Loss: 0.2238
Batch 310, Loss: 0.2727
Batch 320, Loss: 0.2685
Batch 330, Loss: 0.2730
Batch 340, Loss: 0.2833
Batch 350, Loss: 0.3236
Batch 360, Loss: 0.3058
Batch 370, Loss: 0.2984
Batch 380, Loss: 0.2864
Batch 390, Loss: 0.2974
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.323928833007812 seconds
Epoch 151 accuracy: 93.04%
Batch 10, Loss: 0.2752
Batch 20, Loss: 0.2535
Batch 30, Loss: 0.2978
Batch 40, Loss: 0.2881
Batch 50, Loss: 0.2559
Batch 60, Loss: 0.2462
Batch 70, Loss: 0.2775
Batch 80, Loss: 0.2521
Batch 90, Loss: 0.2540
Batch 100, Loss: 0.2673
Batch 110, Loss: 0.2573
Batch 120, Loss: 0.2644
Batch 130, Loss: 0.2881
Batch 140, Loss: 0.2566
Batch 150, Loss: 0.2759
Batch 160, Loss: 0.2800
Batch 170, Loss: 0.2917
Batch 180, Loss: 0.2939
Batch 190, Loss: 0.2884
Batch 200, Loss: 0.2622
Batch 210, Loss: 0.2740
Batch 220, Loss: 0.2819
Batch 230, Loss: 0.2747
Batch 240, Loss: 0.2699
Batch 250, Loss: 0.2853
Batch 260, Loss: 0.2518
Batch 270, Loss: 0.2762
Batch 280, Loss: 0.2809
Batch 290, Loss: 0.2682
Batch 300, Loss: 0.2692
Batch 310, Loss: 0.2682
Batch 320, Loss: 0.2832
Batch 330, Loss: 0.2659
Batch 340, Loss: 0.2719
Batch 350, Loss: 0.2557
Batch 360, Loss: 0.2787
Batch 370, Loss: 0.2992
Batch 380, Loss: 0.2570
Batch 390, Loss: 0.2963
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.21614646911621 seconds
Epoch 152 accuracy: 93.29%
Batch 10, Loss: 0.2566
Batch 20, Loss: 0.2469
Batch 30, Loss: 0.2564
Batch 40, Loss: 0.2455
Batch 50, Loss: 0.2649
Batch 60, Loss: 0.2640
Batch 70, Loss: 0.2418
Batch 80, Loss: 0.2910
Batch 90, Loss: 0.2440
Batch 100, Loss: 0.2578
Batch 110, Loss: 0.2511
Batch 120, Loss: 0.2868
Batch 130, Loss: 0.2581
Batch 140, Loss: 0.2697
Batch 150, Loss: 0.2782
Batch 160, Loss: 0.2662
Batch 170, Loss: 0.2827
Batch 180, Loss: 0.2530
Batch 190, Loss: 0.2472
Batch 200, Loss: 0.2794
Batch 210, Loss: 0.2319
Batch 220, Loss: 0.2829
Batch 230, Loss: 0.2540
Batch 240, Loss: 0.2487
Batch 250, Loss: 0.2480
Batch 260, Loss: 0.2699
Batch 270, Loss: 0.2547
Batch 280, Loss: 0.2541
Batch 290, Loss: 0.2572
Batch 300, Loss: 0.2614
Batch 310, Loss: 0.2702
Batch 320, Loss: 0.2720
Batch 330, Loss: 0.2813
Batch 340, Loss: 0.2566
Batch 350, Loss: 0.2752
Batch 360, Loss: 0.2853
Batch 370, Loss: 0.2583
Batch 380, Loss: 0.2796
Batch 390, Loss: 0.2773
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.247785568237305 seconds
Epoch 153 accuracy: 93.8%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2136
Batch 30, Loss: 0.2671
Batch 40, Loss: 0.2583
Batch 50, Loss: 0.2709
Batch 60, Loss: 0.2708
Batch 70, Loss: 0.2822
Batch 80, Loss: 0.2619
Batch 90, Loss: 0.2931
Batch 100, Loss: 0.2510
Batch 110, Loss: 0.2833
Batch 120, Loss: 0.2742
Batch 130, Loss: 0.2657
Batch 140, Loss: 0.2163
Batch 150, Loss: 0.2461
Batch 160, Loss: 0.2931
Batch 170, Loss: 0.2535
Batch 180, Loss: 0.2521
Batch 190, Loss: 0.2551
Batch 200, Loss: 0.2700
Batch 210, Loss: 0.2825
Batch 220, Loss: 0.2481
Batch 230, Loss: 0.2654
Batch 240, Loss: 0.2698
Batch 250, Loss: 0.2670
Batch 260, Loss: 0.2821
Batch 270, Loss: 0.2605
Batch 280, Loss: 0.2609
Batch 290, Loss: 0.2614
Batch 300, Loss: 0.2747
Batch 310, Loss: 0.2621
Batch 320, Loss: 0.2686
Batch 330, Loss: 0.2622
Batch 340, Loss: 0.2572
Batch 350, Loss: 0.2704
Batch 360, Loss: 0.2544
Batch 370, Loss: 0.2672
Batch 380, Loss: 0.2256
Batch 390, Loss: 0.2741
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.264974355697632 seconds
Epoch 154 accuracy: 94.36%
Batch 10, Loss: 0.2728
Batch 20, Loss: 0.2704
Batch 30, Loss: 0.2985
Batch 40, Loss: 0.2537
Batch 50, Loss: 0.2610
Batch 60, Loss: 0.2588
Batch 70, Loss: 0.2615
Batch 80, Loss: 0.2572
Batch 90, Loss: 0.2719
Batch 100, Loss: 0.2451
Batch 110, Loss: 0.2490
Batch 120, Loss: 0.2225
Batch 130, Loss: 0.2809
Batch 140, Loss: 0.2377
Batch 150, Loss: 0.2545
Batch 160, Loss: 0.2599
Batch 170, Loss: 0.2844
Batch 180, Loss: 0.2814
Batch 190, Loss: 0.2463
Batch 200, Loss: 0.2637
Batch 210, Loss: 0.2585
Batch 220, Loss: 0.2541
Batch 230, Loss: 0.2582
Batch 240, Loss: 0.2575
Batch 250, Loss: 0.2561
Batch 260, Loss: 0.2287
Batch 270, Loss: 0.2637
Batch 280, Loss: 0.2612
Batch 290, Loss: 0.2738
Batch 300, Loss: 0.2203
Batch 310, Loss: 0.2726
Batch 320, Loss: 0.2421
Batch 330, Loss: 0.2780
Batch 340, Loss: 0.2277
Batch 350, Loss: 0.2599
Batch 360, Loss: 0.2531
Batch 370, Loss: 0.2880
Batch 380, Loss: 0.2434
Batch 390, Loss: 0.2490
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.380295276641846 seconds
Epoch 155 accuracy: 94.35%
Batch 10, Loss: 0.2796
Batch 20, Loss: 0.2532
Batch 30, Loss: 0.2535
Batch 40, Loss: 0.2283
Batch 50, Loss: 0.3019
Batch 60, Loss: 0.2616
Batch 70, Loss: 0.2412
Batch 80, Loss: 0.2632
Batch 90, Loss: 0.2542
Batch 100, Loss: 0.2556
Batch 110, Loss: 0.2480
Batch 120, Loss: 0.2674
Batch 130, Loss: 0.2406
Batch 140, Loss: 0.2686
Batch 150, Loss: 0.2540
Batch 160, Loss: 0.2615
Batch 170, Loss: 0.2632
Batch 180, Loss: 0.2838
Batch 190, Loss: 0.2858
Batch 200, Loss: 0.2543
Batch 210, Loss: 0.2468
Batch 220, Loss: 0.2725
Batch 230, Loss: 0.2301
Batch 240, Loss: 0.2409
Batch 250, Loss: 0.2299
Batch 260, Loss: 0.2330
Batch 270, Loss: 0.2612
Batch 280, Loss: 0.2466
Batch 290, Loss: 0.2248
Batch 300, Loss: 0.2285
Batch 310, Loss: 0.2239
Batch 320, Loss: 0.2851
Batch 330, Loss: 0.2493
Batch 340, Loss: 0.2658
Batch 350, Loss: 0.2830
Batch 360, Loss: 0.2602
Batch 370, Loss: 0.2320
Batch 380, Loss: 0.2391
Batch 390, Loss: 0.2459
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.380168914794922 seconds
Epoch 156 accuracy: 94.5%
Batch 10, Loss: 0.2579
Batch 20, Loss: 0.2406
Batch 30, Loss: 0.2451
Batch 40, Loss: 0.2517
Batch 50, Loss: 0.2483
Batch 60, Loss: 0.2532
Batch 70, Loss: 0.2650
Batch 80, Loss: 0.2541
Batch 90, Loss: 0.2536
Batch 100, Loss: 0.2557
Batch 110, Loss: 0.2541
Batch 120, Loss: 0.2466
Batch 130, Loss: 0.2651
Batch 140, Loss: 0.2447
Batch 150, Loss: 0.2536
Batch 160, Loss: 0.2752
Batch 170, Loss: 0.2355
Batch 180, Loss: 0.2538
Batch 190, Loss: 0.2604
Batch 200, Loss: 0.2782
Batch 210, Loss: 0.2631
Batch 220, Loss: 0.2549
Batch 230, Loss: 0.2443
Batch 240, Loss: 0.2724
Batch 250, Loss: 0.2560
Batch 260, Loss: 0.2593
Batch 270, Loss: 0.2489
Batch 280, Loss: 0.2454
Batch 290, Loss: 0.2380
Batch 300, Loss: 0.2552
Batch 310, Loss: 0.2667
Batch 320, Loss: 0.2470
Batch 330, Loss: 0.2372
Batch 340, Loss: 0.2461
Batch 350, Loss: 0.2463
Batch 360, Loss: 0.2382
Batch 370, Loss: 0.2526
Batch 380, Loss: 0.2465
Batch 390, Loss: 0.2603
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.345741271972656 seconds
Epoch 157 accuracy: 94.43%
Batch 10, Loss: 0.2548
Batch 20, Loss: 0.2567
Batch 30, Loss: 0.2673
Batch 40, Loss: 0.2706
Batch 50, Loss: 0.2307
Batch 60, Loss: 0.2786
Batch 70, Loss: 0.2431
Batch 80, Loss: 0.2616
Batch 90, Loss: 0.2734
Batch 100, Loss: 0.2572
Batch 110, Loss: 0.2123
Batch 120, Loss: 0.2541
Batch 130, Loss: 0.2232
Batch 140, Loss: 0.2283
Batch 150, Loss: 0.2340
Batch 160, Loss: 0.2665
Batch 170, Loss: 0.2596
Batch 180, Loss: 0.2217
Batch 190, Loss: 0.2401
Batch 200, Loss: 0.2547
Batch 210, Loss: 0.2602
Batch 220, Loss: 0.2392
Batch 230, Loss: 0.2373
Batch 240, Loss: 0.2150
Batch 250, Loss: 0.2359
Batch 260, Loss: 0.2503
Batch 270, Loss: 0.2329
Batch 280, Loss: 0.2809
Batch 290, Loss: 0.2637
Batch 300, Loss: 0.2571
Batch 310, Loss: 0.2307
Batch 320, Loss: 0.2313
Batch 330, Loss: 0.2619
Batch 340, Loss: 0.2485
Batch 350, Loss: 0.2327
Batch 360, Loss: 0.2602
Batch 370, Loss: 0.2493
Batch 380, Loss: 0.2635
Batch 390, Loss: 0.2587
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.175281763076782 seconds
Epoch 158 accuracy: 94.51%
Batch 10, Loss: 0.2551
Batch 20, Loss: 0.2581
Batch 30, Loss: 0.2238
Batch 40, Loss: 0.2655
Batch 50, Loss: 0.2504
Batch 60, Loss: 0.2547
Batch 70, Loss: 0.2455
Batch 80, Loss: 0.2532
Batch 90, Loss: 0.2494
Batch 100, Loss: 0.2521
Batch 110, Loss: 0.2318
Batch 120, Loss: 0.2509
Batch 130, Loss: 0.2307
Batch 140, Loss: 0.2721
Batch 150, Loss: 0.2390
Batch 160, Loss: 0.2412
Batch 170, Loss: 0.2522
Batch 180, Loss: 0.2676
Batch 190, Loss: 0.2533
Batch 200, Loss: 0.2380
Batch 210, Loss: 0.2425
Batch 220, Loss: 0.1925
Batch 230, Loss: 0.2633
Batch 240, Loss: 0.2445
Batch 250, Loss: 0.2538
Batch 260, Loss: 0.2425
Batch 270, Loss: 0.2362
Batch 280, Loss: 0.2287
Batch 290, Loss: 0.2353
Batch 300, Loss: 0.2316
Batch 310, Loss: 0.2483
Batch 320, Loss: 0.2606
Batch 330, Loss: 0.2420
Batch 340, Loss: 0.2269
Batch 350, Loss: 0.2443
Batch 360, Loss: 0.2308
Batch 370, Loss: 0.2221
Batch 380, Loss: 0.2369
Batch 390, Loss: 0.2657
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.252650499343872 seconds
Epoch 159 accuracy: 94.65%
Batch 10, Loss: 0.2414
Batch 20, Loss: 0.2502
Batch 30, Loss: 0.2281
Batch 40, Loss: 0.2351
Batch 50, Loss: 0.2448
Batch 60, Loss: 0.2499
Batch 70, Loss: 0.2520
Batch 80, Loss: 0.2469
Batch 90, Loss: 0.2309
Batch 100, Loss: 0.2659
Batch 110, Loss: 0.2392
Batch 120, Loss: 0.2490
Batch 130, Loss: 0.2267
Batch 140, Loss: 0.2215
Batch 150, Loss: 0.2332
Batch 160, Loss: 0.2322
Batch 170, Loss: 0.2437
Batch 180, Loss: 0.2377
Batch 190, Loss: 0.2329
Batch 200, Loss: 0.2633
Batch 210, Loss: 0.2150
Batch 220, Loss: 0.2239
Batch 230, Loss: 0.2353
Batch 240, Loss: 0.2304
Batch 250, Loss: 0.2308
Batch 260, Loss: 0.2712
Batch 270, Loss: 0.2202
Batch 280, Loss: 0.2347
Batch 290, Loss: 0.2413
Batch 300, Loss: 0.2186
Batch 310, Loss: 0.2241
Batch 320, Loss: 0.2418
Batch 330, Loss: 0.2641
Batch 340, Loss: 0.2315
Batch 350, Loss: 0.2803
Batch 360, Loss: 0.2358
Batch 370, Loss: 0.2567
Batch 380, Loss: 0.2618
Batch 390, Loss: 0.2167
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.24681067466736 seconds
Epoch 160 accuracy: 94.5%
Batch 10, Loss: 0.2340
Batch 20, Loss: 0.2506
Batch 30, Loss: 0.2112
Batch 40, Loss: 0.2520
Batch 50, Loss: 0.2446
Batch 60, Loss: 0.2298
Batch 70, Loss: 0.2370
Batch 80, Loss: 0.2021
Batch 90, Loss: 0.2275
Batch 100, Loss: 0.2340
Batch 110, Loss: 0.2395
Batch 120, Loss: 0.2240
Batch 130, Loss: 0.2638
Batch 140, Loss: 0.2232
Batch 150, Loss: 0.2222
Batch 160, Loss: 0.2370
Batch 170, Loss: 0.2299
Batch 180, Loss: 0.2306
Batch 190, Loss: 0.2219
Batch 200, Loss: 0.2479
Batch 210, Loss: 0.2426
Batch 220, Loss: 0.2300
Batch 230, Loss: 0.2469
Batch 240, Loss: 0.2356
Batch 250, Loss: 0.2338
Batch 260, Loss: 0.2438
Batch 270, Loss: 0.2182
Batch 280, Loss: 0.2259
Batch 290, Loss: 0.2376
Batch 300, Loss: 0.2383
Batch 310, Loss: 0.2190
Batch 320, Loss: 0.2435
Batch 330, Loss: 0.2248
Batch 340, Loss: 0.2479
Batch 350, Loss: 0.2558
Batch 360, Loss: 0.2269
Batch 370, Loss: 0.2463
Batch 380, Loss: 0.2460
Batch 390, Loss: 0.2511
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.317652463912964 seconds
Epoch 161 accuracy: 94.91%
Batch 10, Loss: 0.2106
Batch 20, Loss: 0.2446
Batch 30, Loss: 0.2244
Batch 40, Loss: 0.2399
Batch 50, Loss: 0.2433
Batch 60, Loss: 0.2449
Batch 70, Loss: 0.2266
Batch 80, Loss: 0.2261
Batch 90, Loss: 0.2350
Batch 100, Loss: 0.2275
Batch 110, Loss: 0.2370
Batch 120, Loss: 0.2094
Batch 130, Loss: 0.2255
Batch 140, Loss: 0.2507
Batch 150, Loss: 0.2460
Batch 160, Loss: 0.2239
Batch 170, Loss: 0.2295
Batch 180, Loss: 0.2345
Batch 190, Loss: 0.2320
Batch 200, Loss: 0.2323
Batch 210, Loss: 0.2301
Batch 220, Loss: 0.1928
Batch 230, Loss: 0.2211
Batch 240, Loss: 0.2365
Batch 250, Loss: 0.2459
Batch 260, Loss: 0.2488
Batch 270, Loss: 0.2400
Batch 280, Loss: 0.2241
Batch 290, Loss: 0.2213
Batch 300, Loss: 0.2246
Batch 310, Loss: 0.2344
Batch 320, Loss: 0.2582
Batch 330, Loss: 0.2211
Batch 340, Loss: 0.2627
Batch 350, Loss: 0.2505
Batch 360, Loss: 0.2369
Batch 370, Loss: 0.2466
Batch 380, Loss: 0.2117
Batch 390, Loss: 0.2252
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.318198919296265 seconds
Epoch 162 accuracy: 94.71%
Batch 10, Loss: 0.2059
Batch 20, Loss: 0.2220
Batch 30, Loss: 0.2079
Batch 40, Loss: 0.2257
Batch 50, Loss: 0.1876
Batch 60, Loss: 0.2344
Batch 70, Loss: 0.2393
Batch 80, Loss: 0.2296
Batch 90, Loss: 0.2483
Batch 100, Loss: 0.2355
Batch 110, Loss: 0.2153
Batch 120, Loss: 0.2365
Batch 130, Loss: 0.2239
Batch 140, Loss: 0.2383
Batch 150, Loss: 0.2153
Batch 160, Loss: 0.2514
Batch 170, Loss: 0.2015
Batch 180, Loss: 0.2226
Batch 190, Loss: 0.2378
Batch 200, Loss: 0.2350
Batch 210, Loss: 0.2272
Batch 220, Loss: 0.2430
Batch 230, Loss: 0.2302
Batch 240, Loss: 0.2375
Batch 250, Loss: 0.2187
Batch 260, Loss: 0.2225
Batch 270, Loss: 0.2011
Batch 280, Loss: 0.2582
Batch 290, Loss: 0.2270
Batch 300, Loss: 0.2308
Batch 310, Loss: 0.2266
Batch 320, Loss: 0.2139
Batch 330, Loss: 0.2461
Batch 340, Loss: 0.2268
Batch 350, Loss: 0.2195
Batch 360, Loss: 0.2363
Batch 370, Loss: 0.2293
Batch 380, Loss: 0.2211
Batch 390, Loss: 0.2288
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.267221927642822 seconds
Epoch 163 accuracy: 95.16%
Batch 10, Loss: 0.2218
Batch 20, Loss: 0.2478
Batch 30, Loss: 0.2083
Batch 40, Loss: 0.2082
Batch 50, Loss: 0.2175
Batch 60, Loss: 0.2083
Batch 70, Loss: 0.2439
Batch 80, Loss: 0.2378
Batch 90, Loss: 0.2412
Batch 100, Loss: 0.2296
Batch 110, Loss: 0.2105
Batch 120, Loss: 0.2308
Batch 130, Loss: 0.2042
Batch 140, Loss: 0.2200
Batch 150, Loss: 0.1857
Batch 160, Loss: 0.2073
Batch 170, Loss: 0.2128
Batch 180, Loss: 0.2170
Batch 190, Loss: 0.2331
Batch 200, Loss: 0.2323
Batch 210, Loss: 0.2297
Batch 220, Loss: 0.2355
Batch 230, Loss: 0.2569
Batch 240, Loss: 0.2185
Batch 250, Loss: 0.2389
Batch 260, Loss: 0.2093
Batch 270, Loss: 0.2009
Batch 280, Loss: 0.2333
Batch 290, Loss: 0.2459
Batch 300, Loss: 0.2027
Batch 310, Loss: 0.2372
Batch 320, Loss: 0.2170
Batch 330, Loss: 0.2239
Batch 340, Loss: 0.2057
Batch 350, Loss: 0.2205
Batch 360, Loss: 0.2190
Batch 370, Loss: 0.2053
Batch 380, Loss: 0.2389
Batch 390, Loss: 0.2518
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.36550736427307 seconds
Epoch 164 accuracy: 94.79%
Batch 10, Loss: 0.2292
Batch 20, Loss: 0.2056
Batch 30, Loss: 0.2316
Batch 40, Loss: 0.2220
Batch 50, Loss: 0.2035
Batch 60, Loss: 0.2297
Batch 70, Loss: 0.1793
Batch 80, Loss: 0.2152
Batch 90, Loss: 0.2334
Batch 100, Loss: 0.1999
Batch 110, Loss: 0.1843
Batch 120, Loss: 0.2136
Batch 130, Loss: 0.2164
Batch 140, Loss: 0.2156
Batch 150, Loss: 0.2337
Batch 160, Loss: 0.2261
Batch 170, Loss: 0.2346
Batch 180, Loss: 0.2313
Batch 190, Loss: 0.2104
Batch 200, Loss: 0.2113
Batch 210, Loss: 0.2247
Batch 220, Loss: 0.2148
Batch 230, Loss: 0.2180
Batch 240, Loss: 0.2124
Batch 250, Loss: 0.2359
Batch 260, Loss: 0.2326
Batch 270, Loss: 0.2364
Batch 280, Loss: 0.1962
Batch 290, Loss: 0.2153
Batch 300, Loss: 0.2307
Batch 310, Loss: 0.2131
Batch 320, Loss: 0.2418
Batch 330, Loss: 0.2001
Batch 340, Loss: 0.2163
Batch 350, Loss: 0.2229
Batch 360, Loss: 0.2190
Batch 370, Loss: 0.2249
Batch 380, Loss: 0.2123
Batch 390, Loss: 0.2311
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.315649032592773 seconds
Epoch 165 accuracy: 94.41%
Batch 10, Loss: 0.2067
Batch 20, Loss: 0.2108
Batch 30, Loss: 0.2206
Batch 40, Loss: 0.2121
Batch 50, Loss: 0.2025
Batch 60, Loss: 0.2022
Batch 70, Loss: 0.2162
Batch 80, Loss: 0.2061
Batch 90, Loss: 0.2070
Batch 100, Loss: 0.2213
Batch 110, Loss: 0.2148
Batch 120, Loss: 0.2162
Batch 130, Loss: 0.2049
Batch 140, Loss: 0.2118
Batch 150, Loss: 0.1984
Batch 160, Loss: 0.1870
Batch 170, Loss: 0.2131
Batch 180, Loss: 0.2164
Batch 190, Loss: 0.2124
Batch 200, Loss: 0.1989
Batch 210, Loss: 0.2103
Batch 220, Loss: 0.2285
Batch 230, Loss: 0.2175
Batch 240, Loss: 0.1976
Batch 250, Loss: 0.2279
Batch 260, Loss: 0.2459
Batch 270, Loss: 0.2199
Batch 280, Loss: 0.2112
Batch 290, Loss: 0.2068
Batch 300, Loss: 0.1927
Batch 310, Loss: 0.2296
Batch 320, Loss: 0.2174
Batch 330, Loss: 0.2036
Batch 340, Loss: 0.2304
Batch 350, Loss: 0.2267
Batch 360, Loss: 0.2167
Batch 370, Loss: 0.2263
Batch 380, Loss: 0.2071
Batch 390, Loss: 0.2189
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.275933027267456 seconds
Epoch 166 accuracy: 95.3%
Batch 10, Loss: 0.2092
Batch 20, Loss: 0.2167
Batch 30, Loss: 0.2160
Batch 40, Loss: 0.2153
Batch 50, Loss: 0.2034
Batch 60, Loss: 0.2112
Batch 70, Loss: 0.2075
Batch 80, Loss: 0.2237
Batch 90, Loss: 0.2082
Batch 100, Loss: 0.2067
Batch 110, Loss: 0.1953
Batch 120, Loss: 0.2049
Batch 130, Loss: 0.1975
Batch 140, Loss: 0.1861
Batch 150, Loss: 0.2002
Batch 160, Loss: 0.1917
Batch 170, Loss: 0.2073
Batch 180, Loss: 0.2144
Batch 190, Loss: 0.2025
Batch 200, Loss: 0.2261
Batch 210, Loss: 0.2115
Batch 220, Loss: 0.1915
Batch 230, Loss: 0.1929
Batch 240, Loss: 0.2252
Batch 250, Loss: 0.2078
Batch 260, Loss: 0.2595
Batch 270, Loss: 0.1959
Batch 280, Loss: 0.1995
Batch 290, Loss: 0.1844
Batch 300, Loss: 0.2348
Batch 310, Loss: 0.2414
Batch 320, Loss: 0.2121
Batch 330, Loss: 0.2257
Batch 340, Loss: 0.2117
Batch 350, Loss: 0.2128
Batch 360, Loss: 0.2017
Batch 370, Loss: 0.2173
Batch 380, Loss: 0.2074
Batch 390, Loss: 0.1927
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.375877141952515 seconds
Epoch 167 accuracy: 94.78%
Batch 10, Loss: 0.2178
Batch 20, Loss: 0.1986
Batch 30, Loss: 0.2071
Batch 40, Loss: 0.1947
Batch 50, Loss: 0.1888
Batch 60, Loss: 0.2098
Batch 70, Loss: 0.1873
Batch 80, Loss: 0.2146
Batch 90, Loss: 0.1990
Batch 100, Loss: 0.1977
Batch 110, Loss: 0.2024
Batch 120, Loss: 0.2229
Batch 130, Loss: 0.2108
Batch 140, Loss: 0.2111
Batch 150, Loss: 0.2314
Batch 160, Loss: 0.2175
Batch 170, Loss: 0.2245
Batch 180, Loss: 0.1865
Batch 190, Loss: 0.1824
Batch 200, Loss: 0.2093
Batch 210, Loss: 0.1910
Batch 220, Loss: 0.2200
Batch 230, Loss: 0.2094
Batch 240, Loss: 0.2217
Batch 250, Loss: 0.2302
Batch 260, Loss: 0.1862
Batch 270, Loss: 0.2112
Batch 280, Loss: 0.1935
Batch 290, Loss: 0.2024
Batch 300, Loss: 0.2123
Batch 310, Loss: 0.1712
Batch 320, Loss: 0.2096
Batch 330, Loss: 0.2140
Batch 340, Loss: 0.2406
Batch 350, Loss: 0.2021
Batch 360, Loss: 0.2122
Batch 370, Loss: 0.1792
Batch 380, Loss: 0.1956
Batch 390, Loss: 0.1938
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.325439929962158 seconds
Epoch 168 accuracy: 95.07%
Batch 10, Loss: 0.2119
Batch 20, Loss: 0.2139
Batch 30, Loss: 0.2134
Batch 40, Loss: 0.1899
Batch 50, Loss: 0.1973
Batch 60, Loss: 0.1841
Batch 70, Loss: 0.2169
Batch 80, Loss: 0.1779
Batch 90, Loss: 0.1832
Batch 100, Loss: 0.1991
Batch 110, Loss: 0.1804
Batch 120, Loss: 0.1965
Batch 130, Loss: 0.2191
Batch 140, Loss: 0.2046
Batch 150, Loss: 0.1782
Batch 160, Loss: 0.1930
Batch 170, Loss: 0.2217
Batch 180, Loss: 0.2027
Batch 190, Loss: 0.1892
Batch 200, Loss: 0.2088
Batch 210, Loss: 0.1921
Batch 220, Loss: 0.1732
Batch 230, Loss: 0.1580
Batch 240, Loss: 0.2040
Batch 250, Loss: 0.1939
Batch 260, Loss: 0.1769
Batch 270, Loss: 0.1963
Batch 280, Loss: 0.1700
Batch 290, Loss: 0.1862
Batch 300, Loss: 0.1933
Batch 310, Loss: 0.2165
Batch 320, Loss: 0.2091
Batch 330, Loss: 0.2187
Batch 340, Loss: 0.1977
Batch 350, Loss: 0.1988
Batch 360, Loss: 0.1965
Batch 370, Loss: 0.1926
Batch 380, Loss: 0.2083
Batch 390, Loss: 0.2228
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.272425174713135 seconds
Epoch 169 accuracy: 95.32%
Batch 10, Loss: 0.1857
Batch 20, Loss: 0.2046
Batch 30, Loss: 0.1920
Batch 40, Loss: 0.2091
Batch 50, Loss: 0.1965
Batch 60, Loss: 0.1805
Batch 70, Loss: 0.1900
Batch 80, Loss: 0.2063
Batch 90, Loss: 0.1858
Batch 100, Loss: 0.1981
Batch 110, Loss: 0.2079
Batch 120, Loss: 0.2137
Batch 130, Loss: 0.1748
Batch 140, Loss: 0.1774
Batch 150, Loss: 0.1919
Batch 160, Loss: 0.2054
Batch 170, Loss: 0.2075
Batch 180, Loss: 0.1898
Batch 190, Loss: 0.2136
Batch 200, Loss: 0.2202
Batch 210, Loss: 0.2159
Batch 220, Loss: 0.2022
Batch 230, Loss: 0.2001
Batch 240, Loss: 0.1819
Batch 250, Loss: 0.2105
Batch 260, Loss: 0.1692
Batch 270, Loss: 0.1764
Batch 280, Loss: 0.2067
Batch 290, Loss: 0.2120
Batch 300, Loss: 0.2057
Batch 310, Loss: 0.2109
Batch 320, Loss: 0.2045
Batch 330, Loss: 0.2103
Batch 340, Loss: 0.1798
Batch 350, Loss: 0.2012
Batch 360, Loss: 0.1822
Batch 370, Loss: 0.1762
Batch 380, Loss: 0.1811
Batch 390, Loss: 0.2110
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.179077625274658 seconds
Epoch 170 accuracy: 95.17%
Batch 10, Loss: 0.1881
Batch 20, Loss: 0.1747
Batch 30, Loss: 0.2003
Batch 40, Loss: 0.1778
Batch 50, Loss: 0.2193
Batch 60, Loss: 0.1874
Batch 70, Loss: 0.2054
Batch 80, Loss: 0.1832
Batch 90, Loss: 0.2055
Batch 100, Loss: 0.1796
Batch 110, Loss: 0.1771
Batch 120, Loss: 0.1947
Batch 130, Loss: 0.1553
Batch 140, Loss: 0.2151
Batch 150, Loss: 0.2007
Batch 160, Loss: 0.1944
Batch 170, Loss: 0.1838
Batch 180, Loss: 0.2040
Batch 190, Loss: 0.2353
Batch 200, Loss: 0.2072
Batch 210, Loss: 0.1878
Batch 220, Loss: 0.1789
Batch 230, Loss: 0.1691
Batch 240, Loss: 0.2198
Batch 250, Loss: 0.2187
Batch 260, Loss: 0.1987
Batch 270, Loss: 0.2040
Batch 280, Loss: 0.1627
Batch 290, Loss: 0.1983
Batch 300, Loss: 0.2050
Batch 310, Loss: 0.2049
Batch 320, Loss: 0.2031
Batch 330, Loss: 0.1559
Batch 340, Loss: 0.1852
Batch 350, Loss: 0.1762
Batch 360, Loss: 0.1868
Batch 370, Loss: 0.1818
Batch 380, Loss: 0.1778
Batch 390, Loss: 0.2124
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.409170389175415 seconds
Epoch 171 accuracy: 95.18%
Batch 10, Loss: 0.1880
Batch 20, Loss: 0.1812
Batch 30, Loss: 0.2210
Batch 40, Loss: 0.2001
Batch 50, Loss: 0.2012
Batch 60, Loss: 0.1964
Batch 70, Loss: 0.2053
Batch 80, Loss: 0.1850
Batch 90, Loss: 0.2101
Batch 100, Loss: 0.1826
Batch 110, Loss: 0.1993
Batch 120, Loss: 0.1640
Batch 130, Loss: 0.1920
Batch 140, Loss: 0.1761
Batch 150, Loss: 0.1780
Batch 160, Loss: 0.1930
Batch 170, Loss: 0.1865
Batch 180, Loss: 0.1857
Batch 190, Loss: 0.1859
Batch 200, Loss: 0.1980
Batch 210, Loss: 0.1560
Batch 220, Loss: 0.2055
Batch 230, Loss: 0.1890
Batch 240, Loss: 0.1700
Batch 250, Loss: 0.1850
Batch 260, Loss: 0.1872
Batch 270, Loss: 0.1991
Batch 280, Loss: 0.2041
Batch 290, Loss: 0.1712
Batch 300, Loss: 0.1674
Batch 310, Loss: 0.1966
Batch 320, Loss: 0.1810
Batch 330, Loss: 0.2001
Batch 340, Loss: 0.1839
Batch 350, Loss: 0.1763
Batch 360, Loss: 0.1874
Batch 370, Loss: 0.1846
Batch 380, Loss: 0.2001
Batch 390, Loss: 0.1727
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.19998526573181 seconds
Epoch 172 accuracy: 95.37%
Batch 10, Loss: 0.1968
Batch 20, Loss: 0.1857
Batch 30, Loss: 0.1686
Batch 40, Loss: 0.1865
Batch 50, Loss: 0.1933
Batch 60, Loss: 0.1746
Batch 70, Loss: 0.1890
Batch 80, Loss: 0.1602
Batch 90, Loss: 0.1756
Batch 100, Loss: 0.1749
Batch 110, Loss: 0.1807
Batch 120, Loss: 0.1863
Batch 130, Loss: 0.1762
Batch 140, Loss: 0.1841
Batch 150, Loss: 0.1856
Batch 160, Loss: 0.2040
Batch 170, Loss: 0.2024
Batch 180, Loss: 0.1795
Batch 190, Loss: 0.1875
Batch 200, Loss: 0.1872
Batch 210, Loss: 0.1795
Batch 220, Loss: 0.1764
Batch 230, Loss: 0.1888
Batch 240, Loss: 0.1735
Batch 250, Loss: 0.1652
Batch 260, Loss: 0.1978
Batch 270, Loss: 0.1843
Batch 280, Loss: 0.2037
Batch 290, Loss: 0.1977
Batch 300, Loss: 0.1800
Batch 310, Loss: 0.1859
Batch 320, Loss: 0.1795
Batch 330, Loss: 0.1865
Batch 340, Loss: 0.1732
Batch 350, Loss: 0.1841
Batch 360, Loss: 0.1886
Batch 370, Loss: 0.1940
Batch 380, Loss: 0.2156
Batch 390, Loss: 0.1871
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.245675325393677 seconds
Epoch 173 accuracy: 95.5%
Batch 10, Loss: 0.1773
Batch 20, Loss: 0.2001
Batch 30, Loss: 0.1823
Batch 40, Loss: 0.2233
Batch 50, Loss: 0.1562
Batch 60, Loss: 0.1812
Batch 70, Loss: 0.1867
Batch 80, Loss: 0.1612
Batch 90, Loss: 0.1944
Batch 100, Loss: 0.1555
Batch 110, Loss: 0.1885
Batch 120, Loss: 0.1762
Batch 130, Loss: 0.1749
Batch 140, Loss: 0.2127
Batch 150, Loss: 0.1827
Batch 160, Loss: 0.2013
Batch 170, Loss: 0.1711
Batch 180, Loss: 0.1784
Batch 190, Loss: 0.2011
Batch 200, Loss: 0.1758
Batch 210, Loss: 0.1799
Batch 220, Loss: 0.1856
Batch 230, Loss: 0.2043
Batch 240, Loss: 0.1805
Batch 250, Loss: 0.1800
Batch 260, Loss: 0.1892
Batch 270, Loss: 0.1722
Batch 280, Loss: 0.1940
Batch 290, Loss: 0.1894
Batch 300, Loss: 0.1770
Batch 310, Loss: 0.1839
Batch 320, Loss: 0.1790
Batch 330, Loss: 0.1794
Batch 340, Loss: 0.1816
Batch 350, Loss: 0.1871
Batch 360, Loss: 0.1870
Batch 370, Loss: 0.2028
Batch 380, Loss: 0.1615
Batch 390, Loss: 0.1771
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.27422285079956 seconds
Epoch 174 accuracy: 95.51%
Batch 10, Loss: 0.1542
Batch 20, Loss: 0.1681
Batch 30, Loss: 0.1835
Batch 40, Loss: 0.1527
Batch 50, Loss: 0.1959
Batch 60, Loss: 0.1918
Batch 70, Loss: 0.1869
Batch 80, Loss: 0.1818
Batch 90, Loss: 0.2066
Batch 100, Loss: 0.1865
Batch 110, Loss: 0.1944
Batch 120, Loss: 0.1919
Batch 130, Loss: 0.1879
Batch 140, Loss: 0.1841
Batch 150, Loss: 0.1850
Batch 160, Loss: 0.1913
Batch 170, Loss: 0.1661
Batch 180, Loss: 0.2104
Batch 190, Loss: 0.1906
Batch 200, Loss: 0.1769
Batch 210, Loss: 0.1643
Batch 220, Loss: 0.1600
Batch 230, Loss: 0.1708
Batch 240, Loss: 0.1796
Batch 250, Loss: 0.1701
Batch 260, Loss: 0.1962
Batch 270, Loss: 0.1902
Batch 280, Loss: 0.1953
Batch 290, Loss: 0.1828
Batch 300, Loss: 0.2084
Batch 310, Loss: 0.1610
Batch 320, Loss: 0.1833
Batch 330, Loss: 0.1901
Batch 340, Loss: 0.1648
Batch 350, Loss: 0.1935
Batch 360, Loss: 0.1512
Batch 370, Loss: 0.1790
Batch 380, Loss: 0.1930
Batch 390, Loss: 0.2062
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.250972747802734 seconds
Epoch 175 accuracy: 95.58%
Batch 10, Loss: 0.1913
Batch 20, Loss: 0.1788
Batch 30, Loss: 0.1829
Batch 40, Loss: 0.1748
Batch 50, Loss: 0.1615
Batch 60, Loss: 0.1776
Batch 70, Loss: 0.1862
Batch 80, Loss: 0.1881
Batch 90, Loss: 0.1670
Batch 100, Loss: 0.1775
Batch 110, Loss: 0.1758
Batch 120, Loss: 0.1746
Batch 130, Loss: 0.1652
Batch 140, Loss: 0.1650
Batch 150, Loss: 0.1702
Batch 160, Loss: 0.1783
Batch 170, Loss: 0.1645
Batch 180, Loss: 0.1881
Batch 190, Loss: 0.1589
Batch 200, Loss: 0.1751
Batch 210, Loss: 0.1829
Batch 220, Loss: 0.1600
Batch 230, Loss: 0.1667
Batch 240, Loss: 0.1626
Batch 250, Loss: 0.1639
Batch 260, Loss: 0.1593
Batch 270, Loss: 0.1757
Batch 280, Loss: 0.1707
Batch 290, Loss: 0.1735
Batch 300, Loss: 0.1558
Batch 310, Loss: 0.1511
Batch 320, Loss: 0.1982
Batch 330, Loss: 0.1931
Batch 340, Loss: 0.1774
Batch 350, Loss: 0.1581
Batch 360, Loss: 0.1705
Batch 370, Loss: 0.1600
Batch 380, Loss: 0.1692
Batch 390, Loss: 0.1769
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.318803548812866 seconds
Epoch 176 accuracy: 95.86%
Batch 10, Loss: 0.1821
Batch 20, Loss: 0.1496
Batch 30, Loss: 0.1735
Batch 40, Loss: 0.1735
Batch 50, Loss: 0.1712
Batch 60, Loss: 0.1954
Batch 70, Loss: 0.1535
Batch 80, Loss: 0.1712
Batch 90, Loss: 0.1767
Batch 100, Loss: 0.1976
Batch 110, Loss: 0.1648
Batch 120, Loss: 0.1326
Batch 130, Loss: 0.1702
Batch 140, Loss: 0.1887
Batch 150, Loss: 0.1767
Batch 160, Loss: 0.1768
Batch 170, Loss: 0.1553
Batch 180, Loss: 0.1748
Batch 190, Loss: 0.1605
Batch 200, Loss: 0.1675
Batch 210, Loss: 0.1586
Batch 220, Loss: 0.1575
Batch 230, Loss: 0.1942
Batch 240, Loss: 0.1832
Batch 250, Loss: 0.1855
Batch 260, Loss: 0.1576
Batch 270, Loss: 0.1814
Batch 280, Loss: 0.1610
Batch 290, Loss: 0.1633
Batch 300, Loss: 0.1701
Batch 310, Loss: 0.1780
Batch 320, Loss: 0.1696
Batch 330, Loss: 0.1552
Batch 340, Loss: 0.1785
Batch 350, Loss: 0.1488
Batch 360, Loss: 0.1770
Batch 370, Loss: 0.1634
Batch 380, Loss: 0.1591
Batch 390, Loss: 0.1736
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.333698511123657 seconds
Epoch 177 accuracy: 95.89%
Batch 10, Loss: 0.1832
Batch 20, Loss: 0.1716
Batch 30, Loss: 0.1768
Batch 40, Loss: 0.1670
Batch 50, Loss: 0.1840
Batch 60, Loss: 0.1691
Batch 70, Loss: 0.1653
Batch 80, Loss: 0.1542
Batch 90, Loss: 0.1590
Batch 100, Loss: 0.1634
Batch 110, Loss: 0.1669
Batch 120, Loss: 0.1702
Batch 130, Loss: 0.1292
Batch 140, Loss: 0.1791
Batch 150, Loss: 0.1550
Batch 160, Loss: 0.1688
Batch 170, Loss: 0.1552
Batch 180, Loss: 0.1602
Batch 190, Loss: 0.1709
Batch 200, Loss: 0.1640
Batch 210, Loss: 0.1793
Batch 220, Loss: 0.1613
Batch 230, Loss: 0.1945
Batch 240, Loss: 0.1507
Batch 250, Loss: 0.1699
Batch 260, Loss: 0.2122
Batch 270, Loss: 0.1874
Batch 280, Loss: 0.1362
Batch 290, Loss: 0.1429
Batch 300, Loss: 0.1734
Batch 310, Loss: 0.1591
Batch 320, Loss: 0.1849
Batch 330, Loss: 0.1895
Batch 340, Loss: 0.1668
Batch 350, Loss: 0.1615
Batch 360, Loss: 0.1710
Batch 370, Loss: 0.1745
Batch 380, Loss: 0.1751
Batch 390, Loss: 0.1664
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.211090564727783 seconds
Epoch 178 accuracy: 96.03%
Batch 10, Loss: 0.1537
Batch 20, Loss: 0.1448
Batch 30, Loss: 0.1616
Batch 40, Loss: 0.1496
Batch 50, Loss: 0.1635
Batch 60, Loss: 0.1688
Batch 70, Loss: 0.1769
Batch 80, Loss: 0.1431
Batch 90, Loss: 0.1810
Batch 100, Loss: 0.1761
Batch 110, Loss: 0.1550
Batch 120, Loss: 0.1836
Batch 130, Loss: 0.1664
Batch 140, Loss: 0.1531
Batch 150, Loss: 0.1634
Batch 160, Loss: 0.1808
Batch 170, Loss: 0.1578
Batch 180, Loss: 0.1776
Batch 190, Loss: 0.1580
Batch 200, Loss: 0.1508
Batch 210, Loss: 0.1613
Batch 220, Loss: 0.1694
Batch 230, Loss: 0.1550
Batch 240, Loss: 0.1601
Batch 250, Loss: 0.1565
Batch 260, Loss: 0.1484
Batch 270, Loss: 0.1423
Batch 280, Loss: 0.1546
Batch 290, Loss: 0.1564
Batch 300, Loss: 0.1635
Batch 310, Loss: 0.1483
Batch 320, Loss: 0.1646
Batch 330, Loss: 0.1646
Batch 340, Loss: 0.1601
Batch 350, Loss: 0.1557
Batch 360, Loss: 0.1751
Batch 370, Loss: 0.1897
Batch 380, Loss: 0.1558
Batch 390, Loss: 0.1464
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.266925573349 seconds
Epoch 179 accuracy: 95.76%
Batch 10, Loss: 0.1598
Batch 20, Loss: 0.1436
Batch 30, Loss: 0.1424
Batch 40, Loss: 0.1569
Batch 50, Loss: 0.1827
Batch 60, Loss: 0.1827
Batch 70, Loss: 0.1545
Batch 80, Loss: 0.1638
Batch 90, Loss: 0.1520
Batch 100, Loss: 0.1910
Batch 110, Loss: 0.1566
Batch 120, Loss: 0.1603
Batch 130, Loss: 0.1640
Batch 140, Loss: 0.1406
Batch 150, Loss: 0.1670
Batch 160, Loss: 0.1569
Batch 170, Loss: 0.1399
Batch 180, Loss: 0.1652
Batch 190, Loss: 0.1908
Batch 200, Loss: 0.1613
Batch 210, Loss: 0.1456
Batch 220, Loss: 0.1601
Batch 230, Loss: 0.1537
Batch 240, Loss: 0.1396
Batch 250, Loss: 0.1593
Batch 260, Loss: 0.1597
Batch 270, Loss: 0.1678
Batch 280, Loss: 0.1625
Batch 290, Loss: 0.1414
Batch 300, Loss: 0.1430
Batch 310, Loss: 0.1566
Batch 320, Loss: 0.1738
Batch 330, Loss: 0.1487
Batch 340, Loss: 0.1634
Batch 350, Loss: 0.1349
Batch 360, Loss: 0.1352
Batch 370, Loss: 0.1720
Batch 380, Loss: 0.1527
Batch 390, Loss: 0.1662
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.272082328796387 seconds
Epoch 180 accuracy: 96.14%
Batch 10, Loss: 0.1629
Batch 20, Loss: 0.1525
Batch 30, Loss: 0.1489
Batch 40, Loss: 0.1584
Batch 50, Loss: 0.1601
Batch 60, Loss: 0.1655
Batch 70, Loss: 0.1588
Batch 80, Loss: 0.1697
Batch 90, Loss: 0.1568
Batch 100, Loss: 0.1654
Batch 110, Loss: 0.1552
Batch 120, Loss: 0.1632
Batch 130, Loss: 0.1485
Batch 140, Loss: 0.1647
Batch 150, Loss: 0.1511
Batch 160, Loss: 0.1623
Batch 170, Loss: 0.1611
Batch 180, Loss: 0.1736
Batch 190, Loss: 0.1716
Batch 200, Loss: 0.1583
Batch 210, Loss: 0.1405
Batch 220, Loss: 0.1477
Batch 230, Loss: 0.1708
Batch 240, Loss: 0.1389
Batch 250, Loss: 0.1568
Batch 260, Loss: 0.1600
Batch 270, Loss: 0.1454
Batch 280, Loss: 0.1521
Batch 290, Loss: 0.1542
Batch 300, Loss: 0.1597
Batch 310, Loss: 0.1850
Batch 320, Loss: 0.1547
Batch 330, Loss: 0.1651
Batch 340, Loss: 0.1791
Batch 350, Loss: 0.1687
Batch 360, Loss: 0.1532
Batch 370, Loss: 0.1388
Batch 380, Loss: 0.1424
Batch 390, Loss: 0.1581
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.311886072158813 seconds
Epoch 181 accuracy: 96.05%
Batch 10, Loss: 0.1387
Batch 20, Loss: 0.1698
Batch 30, Loss: 0.1706
Batch 40, Loss: 0.1179
Batch 50, Loss: 0.1496
Batch 60, Loss: 0.1588
Batch 70, Loss: 0.1455
Batch 80, Loss: 0.1669
Batch 90, Loss: 0.1359
Batch 100, Loss: 0.1584
Batch 110, Loss: 0.1496
Batch 120, Loss: 0.1671
Batch 130, Loss: 0.1533
Batch 140, Loss: 0.1638
Batch 150, Loss: 0.1490
Batch 160, Loss: 0.1570
Batch 170, Loss: 0.1452
Batch 180, Loss: 0.1453
Batch 190, Loss: 0.1648
Batch 200, Loss: 0.1540
Batch 210, Loss: 0.1482
Batch 220, Loss: 0.1551
Batch 230, Loss: 0.1412
Batch 240, Loss: 0.1505
Batch 250, Loss: 0.1581
Batch 260, Loss: 0.1742
Batch 270, Loss: 0.1496
Batch 280, Loss: 0.1420
Batch 290, Loss: 0.1718
Batch 300, Loss: 0.1360
Batch 310, Loss: 0.1610
Batch 320, Loss: 0.1402
Batch 330, Loss: 0.1390
Batch 340, Loss: 0.1574
Batch 350, Loss: 0.1553
Batch 360, Loss: 0.1652
Batch 370, Loss: 0.1356
Batch 380, Loss: 0.1565
Batch 390, Loss: 0.1510
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.36060357093811 seconds
Epoch 182 accuracy: 96.27%
Batch 10, Loss: 0.1546
Batch 20, Loss: 0.1445
Batch 30, Loss: 0.1523
Batch 40, Loss: 0.1294
Batch 50, Loss: 0.1497
Batch 60, Loss: 0.1524
Batch 70, Loss: 0.1616
Batch 80, Loss: 0.1693
Batch 90, Loss: 0.1424
Batch 100, Loss: 0.1526
Batch 110, Loss: 0.1428
Batch 120, Loss: 0.1270
Batch 130, Loss: 0.1585
Batch 140, Loss: 0.1514
Batch 150, Loss: 0.1356
Batch 160, Loss: 0.1416
Batch 170, Loss: 0.1583
Batch 180, Loss: 0.1603
Batch 190, Loss: 0.1796
Batch 200, Loss: 0.1232
Batch 210, Loss: 0.1525
Batch 220, Loss: 0.1627
Batch 230, Loss: 0.1706
Batch 240, Loss: 0.1448
Batch 250, Loss: 0.1680
Batch 260, Loss: 0.1257
Batch 270, Loss: 0.1492
Batch 280, Loss: 0.1586
Batch 290, Loss: 0.1496
Batch 300, Loss: 0.1263
Batch 310, Loss: 0.1405
Batch 320, Loss: 0.1454
Batch 330, Loss: 0.1289
Batch 340, Loss: 0.1350
Batch 350, Loss: 0.1675
Batch 360, Loss: 0.1624
Batch 370, Loss: 0.1611
Batch 380, Loss: 0.1775
Batch 390, Loss: 0.1437
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.297659397125244 seconds
Epoch 183 accuracy: 96.47%
Batch 10, Loss: 0.1437
Batch 20, Loss: 0.1460
Batch 30, Loss: 0.1608
Batch 40, Loss: 0.1569
Batch 50, Loss: 0.1225
Batch 60, Loss: 0.1368
Batch 70, Loss: 0.1361
Batch 80, Loss: 0.1600
Batch 90, Loss: 0.1401
Batch 100, Loss: 0.1388
Batch 110, Loss: 0.1594
Batch 120, Loss: 0.1544
Batch 130, Loss: 0.1462
Batch 140, Loss: 0.1454
Batch 150, Loss: 0.1461
Batch 160, Loss: 0.1523
Batch 170, Loss: 0.1550
Batch 180, Loss: 0.1487
Batch 190, Loss: 0.1487
Batch 200, Loss: 0.1518
Batch 210, Loss: 0.1368
Batch 220, Loss: 0.1410
Batch 230, Loss: 0.1409
Batch 240, Loss: 0.1609
Batch 250, Loss: 0.1438
Batch 260, Loss: 0.1451
Batch 270, Loss: 0.1348
Batch 280, Loss: 0.1365
Batch 290, Loss: 0.1530
Batch 300, Loss: 0.1531
Batch 310, Loss: 0.1488
Batch 320, Loss: 0.1460
Batch 330, Loss: 0.1563
Batch 340, Loss: 0.1485
Batch 350, Loss: 0.1390
Batch 360, Loss: 0.1405
Batch 370, Loss: 0.1646
Batch 380, Loss: 0.1472
Batch 390, Loss: 0.1673
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.299678802490234 seconds
Epoch 184 accuracy: 96.2%
Batch 10, Loss: 0.1435
Batch 20, Loss: 0.1246
Batch 30, Loss: 0.1603
Batch 40, Loss: 0.1402
Batch 50, Loss: 0.1587
Batch 60, Loss: 0.1378
Batch 70, Loss: 0.1447
Batch 80, Loss: 0.1442
Batch 90, Loss: 0.1429
Batch 100, Loss: 0.1571
Batch 110, Loss: 0.1569
Batch 120, Loss: 0.1549
Batch 130, Loss: 0.1558
Batch 140, Loss: 0.1463
Batch 150, Loss: 0.1474
Batch 160, Loss: 0.1383
Batch 170, Loss: 0.1611
Batch 180, Loss: 0.1227
Batch 190, Loss: 0.1458
Batch 200, Loss: 0.1620
Batch 210, Loss: 0.1662
Batch 220, Loss: 0.1478
Batch 230, Loss: 0.1388
Batch 240, Loss: 0.1343
Batch 250, Loss: 0.1346
Batch 260, Loss: 0.1581
Batch 270, Loss: 0.1555
Batch 280, Loss: 0.1492
Batch 290, Loss: 0.1336
Batch 300, Loss: 0.1287
Batch 310, Loss: 0.1224
Batch 320, Loss: 0.1474
Batch 330, Loss: 0.1445
Batch 340, Loss: 0.1552
Batch 350, Loss: 0.1488
Batch 360, Loss: 0.1468
Batch 370, Loss: 0.1682
Batch 380, Loss: 0.1021
Batch 390, Loss: 0.1249
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.272260904312134 seconds
Epoch 185 accuracy: 96.39%
Batch 10, Loss: 0.1629
Batch 20, Loss: 0.1492
Batch 30, Loss: 0.1651
Batch 40, Loss: 0.1449
Batch 50, Loss: 0.1393
Batch 60, Loss: 0.1266
Batch 70, Loss: 0.1406
Batch 80, Loss: 0.1340
Batch 90, Loss: 0.1321
Batch 100, Loss: 0.1484
Batch 110, Loss: 0.1340
Batch 120, Loss: 0.1383
Batch 130, Loss: 0.1426
Batch 140, Loss: 0.1255
Batch 150, Loss: 0.1505
Batch 160, Loss: 0.1473
Batch 170, Loss: 0.1516
Batch 180, Loss: 0.1298
Batch 190, Loss: 0.1286
Batch 200, Loss: 0.1546
Batch 210, Loss: 0.1320
Batch 220, Loss: 0.1646
Batch 230, Loss: 0.1200
Batch 240, Loss: 0.1493
Batch 250, Loss: 0.1582
Batch 260, Loss: 0.1683
Batch 270, Loss: 0.1219
Batch 280, Loss: 0.1358
Batch 290, Loss: 0.1416
Batch 300, Loss: 0.1445
Batch 310, Loss: 0.1560
Batch 320, Loss: 0.1304
Batch 330, Loss: 0.1555
Batch 340, Loss: 0.1386
Batch 350, Loss: 0.1479
Batch 360, Loss: 0.1528
Batch 370, Loss: 0.1352
Batch 380, Loss: 0.1350
Batch 390, Loss: 0.1569
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.25362205505371 seconds
Epoch 186 accuracy: 96.41%
Batch 10, Loss: 0.1142
Batch 20, Loss: 0.1467
Batch 30, Loss: 0.1379
Batch 40, Loss: 0.1269
Batch 50, Loss: 0.1625
Batch 60, Loss: 0.1451
Batch 70, Loss: 0.1421
Batch 80, Loss: 0.1461
Batch 90, Loss: 0.1335
Batch 100, Loss: 0.1394
Batch 110, Loss: 0.1405
Batch 120, Loss: 0.1422
Batch 130, Loss: 0.1324
Batch 140, Loss: 0.1441
Batch 150, Loss: 0.1399
Batch 160, Loss: 0.1620
Batch 170, Loss: 0.1334
Batch 180, Loss: 0.1234
Batch 190, Loss: 0.1416
Batch 200, Loss: 0.1282
Batch 210, Loss: 0.1390
Batch 220, Loss: 0.1415
Batch 230, Loss: 0.1198
Batch 240, Loss: 0.1537
Batch 250, Loss: 0.1246
Batch 260, Loss: 0.1220
Batch 270, Loss: 0.1467
Batch 280, Loss: 0.1609
Batch 290, Loss: 0.1423
Batch 300, Loss: 0.1270
Batch 310, Loss: 0.1376
Batch 320, Loss: 0.1272
Batch 330, Loss: 0.1253
Batch 340, Loss: 0.1518
Batch 350, Loss: 0.1293
Batch 360, Loss: 0.1502
Batch 370, Loss: 0.1501
Batch 380, Loss: 0.1133
Batch 390, Loss: 0.1474
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.336267948150635 seconds
Epoch 187 accuracy: 96.48%
Batch 10, Loss: 0.1383
Batch 20, Loss: 0.1359
Batch 30, Loss: 0.1379
Batch 40, Loss: 0.1384
Batch 50, Loss: 0.1011
Batch 60, Loss: 0.1480
Batch 70, Loss: 0.1507
Batch 80, Loss: 0.1093
Batch 90, Loss: 0.1401
Batch 100, Loss: 0.1409
Batch 110, Loss: 0.1174
Batch 120, Loss: 0.1392
Batch 130, Loss: 0.1398
Batch 140, Loss: 0.1376
Batch 150, Loss: 0.1356
Batch 160, Loss: 0.1320
Batch 170, Loss: 0.1401
Batch 180, Loss: 0.1365
Batch 190, Loss: 0.1300
Batch 200, Loss: 0.1315
Batch 210, Loss: 0.1247
Batch 220, Loss: 0.1410
Batch 230, Loss: 0.1613
Batch 240, Loss: 0.1214
Batch 250, Loss: 0.1477
Batch 260, Loss: 0.1378
Batch 270, Loss: 0.1299
Batch 280, Loss: 0.1378
Batch 290, Loss: 0.1439
Batch 300, Loss: 0.1356
Batch 310, Loss: 0.0993
Batch 320, Loss: 0.1416
Batch 330, Loss: 0.1477
Batch 340, Loss: 0.1417
Batch 350, Loss: 0.1556
Batch 360, Loss: 0.1363
Batch 370, Loss: 0.1156
Batch 380, Loss: 0.1308
Batch 390, Loss: 0.1426
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.51926064491272 seconds
Epoch 188 accuracy: 96.54%
Batch 10, Loss: 0.1365
Batch 20, Loss: 0.1150
Batch 30, Loss: 0.1511
Batch 40, Loss: 0.1446
Batch 50, Loss: 0.1479
Batch 60, Loss: 0.1501
Batch 70, Loss: 0.1593
Batch 80, Loss: 0.1405
Batch 90, Loss: 0.1455
Batch 100, Loss: 0.1338
Batch 110, Loss: 0.1242
Batch 120, Loss: 0.1312
Batch 130, Loss: 0.1312
Batch 140, Loss: 0.1273
Batch 150, Loss: 0.1224
Batch 160, Loss: 0.1415
Batch 170, Loss: 0.1279
Batch 180, Loss: 0.1304
Batch 190, Loss: 0.1347
Batch 200, Loss: 0.1263
Batch 210, Loss: 0.1567
Batch 220, Loss: 0.1381
Batch 230, Loss: 0.1443
Batch 240, Loss: 0.1478
Batch 250, Loss: 0.1394
Batch 260, Loss: 0.1432
Batch 270, Loss: 0.1564
Batch 280, Loss: 0.1232
Batch 290, Loss: 0.1311
Batch 300, Loss: 0.1302
Batch 310, Loss: 0.1430
Batch 320, Loss: 0.1071
Batch 330, Loss: 0.1432
Batch 340, Loss: 0.1224
Batch 350, Loss: 0.1199
Batch 360, Loss: 0.1603
Batch 370, Loss: 0.1179
Batch 380, Loss: 0.1092
Batch 390, Loss: 0.1127
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.269445419311523 seconds
Epoch 189 accuracy: 96.52%
Batch 10, Loss: 0.1320
Batch 20, Loss: 0.1449
Batch 30, Loss: 0.1438
Batch 40, Loss: 0.1327
Batch 50, Loss: 0.1340
Batch 60, Loss: 0.1083
Batch 70, Loss: 0.1314
Batch 80, Loss: 0.1125
Batch 90, Loss: 0.1295
Batch 100, Loss: 0.1215
Batch 110, Loss: 0.1334
Batch 120, Loss: 0.1105
Batch 130, Loss: 0.1460
Batch 140, Loss: 0.1342
Batch 150, Loss: 0.1415
Batch 160, Loss: 0.1424
Batch 170, Loss: 0.1259
Batch 180, Loss: 0.1420
Batch 190, Loss: 0.1399
Batch 200, Loss: 0.1133
Batch 210, Loss: 0.1192
Batch 220, Loss: 0.1533
Batch 230, Loss: 0.1225
Batch 240, Loss: 0.1518
Batch 250, Loss: 0.1368
Batch 260, Loss: 0.1322
Batch 270, Loss: 0.1287
Batch 280, Loss: 0.1342
Batch 290, Loss: 0.1432
Batch 300, Loss: 0.1457
Batch 310, Loss: 0.1342
Batch 320, Loss: 0.1254
Batch 330, Loss: 0.1359
Batch 340, Loss: 0.1259
Batch 350, Loss: 0.1413
Batch 360, Loss: 0.1400
Batch 370, Loss: 0.1352
Batch 380, Loss: 0.1369
Batch 390, Loss: 0.1146
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.216084718704224 seconds
Epoch 190 accuracy: 96.58%
Batch 10, Loss: 0.1254
Batch 20, Loss: 0.1288
Batch 30, Loss: 0.1140
Batch 40, Loss: 0.1212
Batch 50, Loss: 0.1296
Batch 60, Loss: 0.1332
Batch 70, Loss: 0.1406
Batch 80, Loss: 0.1467
Batch 90, Loss: 0.1242
Batch 100, Loss: 0.1287
Batch 110, Loss: 0.1386
Batch 120, Loss: 0.1263
Batch 130, Loss: 0.1278
Batch 140, Loss: 0.1269
Batch 150, Loss: 0.1172
Batch 160, Loss: 0.1423
Batch 170, Loss: 0.1377
Batch 180, Loss: 0.1371
Batch 190, Loss: 0.1427
Batch 200, Loss: 0.1336
Batch 210, Loss: 0.1064
Batch 220, Loss: 0.1408
Batch 230, Loss: 0.1264
Batch 240, Loss: 0.1349
Batch 250, Loss: 0.1288
Batch 260, Loss: 0.1252
Batch 270, Loss: 0.1231
Batch 280, Loss: 0.1102
Batch 290, Loss: 0.1218
Batch 300, Loss: 0.1284
Batch 310, Loss: 0.1276
Batch 320, Loss: 0.1374
Batch 330, Loss: 0.1336
Batch 340, Loss: 0.1516
Batch 350, Loss: 0.1182
Batch 360, Loss: 0.1331
Batch 370, Loss: 0.1378
Batch 380, Loss: 0.1114
Batch 390, Loss: 0.1311
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.16655158996582 seconds
Epoch 191 accuracy: 96.64%
Batch 10, Loss: 0.1312
Batch 20, Loss: 0.1389
Batch 30, Loss: 0.1338
Batch 40, Loss: 0.1248
Batch 50, Loss: 0.1303
Batch 60, Loss: 0.1359
Batch 70, Loss: 0.1423
Batch 80, Loss: 0.1226
Batch 90, Loss: 0.1161
Batch 100, Loss: 0.1374
Batch 110, Loss: 0.1388
Batch 120, Loss: 0.1358
Batch 130, Loss: 0.1339
Batch 140, Loss: 0.1409
Batch 150, Loss: 0.1175
Batch 160, Loss: 0.1436
Batch 170, Loss: 0.1189
Batch 180, Loss: 0.1247
Batch 190, Loss: 0.1276
Batch 200, Loss: 0.1197
Batch 210, Loss: 0.1198
Batch 220, Loss: 0.1411
Batch 230, Loss: 0.1101
Batch 240, Loss: 0.1070
Batch 250, Loss: 0.1183
Batch 260, Loss: 0.1254
Batch 270, Loss: 0.1308
Batch 280, Loss: 0.1385
Batch 290, Loss: 0.1160
Batch 300, Loss: 0.1099
Batch 310, Loss: 0.1407
Batch 320, Loss: 0.1338
Batch 330, Loss: 0.1180
Batch 340, Loss: 0.1247
Batch 350, Loss: 0.1368
Batch 360, Loss: 0.1332
Batch 370, Loss: 0.1242
Batch 380, Loss: 0.1449
Batch 390, Loss: 0.1386
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.258157968521118 seconds
Epoch 192 accuracy: 96.6%
Batch 10, Loss: 0.1430
Batch 20, Loss: 0.1214
Batch 30, Loss: 0.1108
Batch 40, Loss: 0.1056
Batch 50, Loss: 0.1276
Batch 60, Loss: 0.1357
Batch 70, Loss: 0.1116
Batch 80, Loss: 0.1365
Batch 90, Loss: 0.1199
Batch 100, Loss: 0.1218
Batch 110, Loss: 0.1341
Batch 120, Loss: 0.1102
Batch 130, Loss: 0.1483
Batch 140, Loss: 0.1277
Batch 150, Loss: 0.1377
Batch 160, Loss: 0.1228
Batch 170, Loss: 0.1257
Batch 180, Loss: 0.1219
Batch 190, Loss: 0.1264
Batch 200, Loss: 0.1411
Batch 210, Loss: 0.0943
Batch 220, Loss: 0.1100
Batch 230, Loss: 0.1353
Batch 240, Loss: 0.1184
Batch 250, Loss: 0.1457
Batch 260, Loss: 0.1311
Batch 270, Loss: 0.1284
Batch 280, Loss: 0.1229
Batch 290, Loss: 0.1222
Batch 300, Loss: 0.1363
Batch 310, Loss: 0.1409
Batch 320, Loss: 0.1300
Batch 330, Loss: 0.1262
Batch 340, Loss: 0.1165
Batch 350, Loss: 0.1200
Batch 360, Loss: 0.0946
Batch 370, Loss: 0.1313
Batch 380, Loss: 0.1253
Batch 390, Loss: 0.1279
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.204270362854004 seconds
Epoch 193 accuracy: 96.6%
Batch 10, Loss: 0.1332
Batch 20, Loss: 0.1136
Batch 30, Loss: 0.1533
Batch 40, Loss: 0.1565
Batch 50, Loss: 0.1208
Batch 60, Loss: 0.1329
Batch 70, Loss: 0.1089
Batch 80, Loss: 0.1222
Batch 90, Loss: 0.1187
Batch 100, Loss: 0.1228
Batch 110, Loss: 0.1135
Batch 120, Loss: 0.1277
Batch 130, Loss: 0.1118
Batch 140, Loss: 0.1346
Batch 150, Loss: 0.1111
Batch 160, Loss: 0.1144
Batch 170, Loss: 0.1312
Batch 180, Loss: 0.1115
Batch 190, Loss: 0.1215
Batch 200, Loss: 0.1261
Batch 210, Loss: 0.1340
Batch 220, Loss: 0.1255
Batch 230, Loss: 0.1490
Batch 240, Loss: 0.1142
Batch 250, Loss: 0.1219
Batch 260, Loss: 0.1176
Batch 270, Loss: 0.1181
Batch 280, Loss: 0.1596
Batch 290, Loss: 0.1153
Batch 300, Loss: 0.1236
Batch 310, Loss: 0.1349
Batch 320, Loss: 0.1402
Batch 330, Loss: 0.1332
Batch 340, Loss: 0.1346
Batch 350, Loss: 0.1204
Batch 360, Loss: 0.1335
Batch 370, Loss: 0.1121
Batch 380, Loss: 0.1403
Batch 390, Loss: 0.1182
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.329187393188477 seconds
Epoch 194 accuracy: 96.59%
Batch 10, Loss: 0.1330
Batch 20, Loss: 0.1205
Batch 30, Loss: 0.1407
Batch 40, Loss: 0.1531
Batch 50, Loss: 0.1242
Batch 60, Loss: 0.1273
Batch 70, Loss: 0.1206
Batch 80, Loss: 0.1235
Batch 90, Loss: 0.1269
Batch 100, Loss: 0.1208
Batch 110, Loss: 0.1232
Batch 120, Loss: 0.1281
Batch 130, Loss: 0.1233
Batch 140, Loss: 0.1351
Batch 150, Loss: 0.1336
Batch 160, Loss: 0.1328
Batch 170, Loss: 0.1290
Batch 180, Loss: 0.1488
Batch 190, Loss: 0.1204
Batch 200, Loss: 0.1276
Batch 210, Loss: 0.1337
Batch 220, Loss: 0.1145
Batch 230, Loss: 0.1132
Batch 240, Loss: 0.1277
Batch 250, Loss: 0.1269
Batch 260, Loss: 0.1346
Batch 270, Loss: 0.1485
Batch 280, Loss: 0.1260
Batch 290, Loss: 0.1298
Batch 300, Loss: 0.1039
Batch 310, Loss: 0.1189
Batch 320, Loss: 0.1350
Batch 330, Loss: 0.1247
Batch 340, Loss: 0.1335
Batch 350, Loss: 0.1202
Batch 360, Loss: 0.1174
Batch 370, Loss: 0.1276
Batch 380, Loss: 0.1317
Batch 390, Loss: 0.1369
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.305400848388672 seconds
Epoch 195 accuracy: 96.68%
Batch 10, Loss: 0.1301
Batch 20, Loss: 0.1385
Batch 30, Loss: 0.1092
Batch 40, Loss: 0.1228
Batch 50, Loss: 0.1389
Batch 60, Loss: 0.1249
Batch 70, Loss: 0.1130
Batch 80, Loss: 0.1091
Batch 90, Loss: 0.1133
Batch 100, Loss: 0.1087
Batch 110, Loss: 0.1248
Batch 120, Loss: 0.1203
Batch 130, Loss: 0.1410
Batch 140, Loss: 0.1260
Batch 150, Loss: 0.1256
Batch 160, Loss: 0.1419
Batch 170, Loss: 0.1421
Batch 180, Loss: 0.1337
Batch 190, Loss: 0.1244
Batch 200, Loss: 0.1279
Batch 210, Loss: 0.1231
Batch 220, Loss: 0.1281
Batch 230, Loss: 0.1234
Batch 240, Loss: 0.1149
Batch 250, Loss: 0.1344
Batch 260, Loss: 0.1433
Batch 270, Loss: 0.1231
Batch 280, Loss: 0.1191
Batch 290, Loss: 0.1397
Batch 300, Loss: 0.1190
Batch 310, Loss: 0.1261
Batch 320, Loss: 0.1202
Batch 330, Loss: 0.1168
Batch 340, Loss: 0.1239
Batch 350, Loss: 0.1096
Batch 360, Loss: 0.1192
Batch 370, Loss: 0.1295
Batch 380, Loss: 0.1351
Batch 390, Loss: 0.1224
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.313941955566406 seconds
Epoch 196 accuracy: 96.74%
Batch 10, Loss: 0.1226
Batch 20, Loss: 0.1302
Batch 30, Loss: 0.1193
Batch 40, Loss: 0.1383
Batch 50, Loss: 0.1172
Batch 60, Loss: 0.1167
Batch 70, Loss: 0.1224
Batch 80, Loss: 0.1371
Batch 90, Loss: 0.1371
Batch 100, Loss: 0.1307
Batch 110, Loss: 0.1312
Batch 120, Loss: 0.1232
Batch 130, Loss: 0.1093
Batch 140, Loss: 0.1261
Batch 150, Loss: 0.1187
Batch 160, Loss: 0.1279
Batch 170, Loss: 0.1300
Batch 180, Loss: 0.1278
Batch 190, Loss: 0.1112
Batch 200, Loss: 0.1232
Batch 210, Loss: 0.1128
Batch 220, Loss: 0.1180
Batch 230, Loss: 0.1107
Batch 240, Loss: 0.1209
Batch 250, Loss: 0.1120
Batch 260, Loss: 0.1013
Batch 270, Loss: 0.1117
Batch 280, Loss: 0.1186
Batch 290, Loss: 0.1128
Batch 300, Loss: 0.1242
Batch 310, Loss: 0.1165
Batch 320, Loss: 0.1277
Batch 330, Loss: 0.1482
Batch 340, Loss: 0.1257
Batch 350, Loss: 0.1212
Batch 360, Loss: 0.1221
Batch 370, Loss: 0.1361
Batch 380, Loss: 0.1277
Batch 390, Loss: 0.1228
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.414538860321045 seconds
Epoch 197 accuracy: 96.71%
Batch 10, Loss: 0.1380
Batch 20, Loss: 0.1183
Batch 30, Loss: 0.1438
Batch 40, Loss: 0.1170
Batch 50, Loss: 0.1348
Batch 60, Loss: 0.1298
Batch 70, Loss: 0.1251
Batch 80, Loss: 0.1284
Batch 90, Loss: 0.1131
Batch 100, Loss: 0.1290
Batch 110, Loss: 0.1303
Batch 120, Loss: 0.1125
Batch 130, Loss: 0.1306
Batch 140, Loss: 0.1225
Batch 150, Loss: 0.1504
Batch 160, Loss: 0.1297
Batch 170, Loss: 0.1318
Batch 180, Loss: 0.1266
Batch 190, Loss: 0.1145
Batch 200, Loss: 0.1210
Batch 210, Loss: 0.1287
Batch 220, Loss: 0.1176
Batch 230, Loss: 0.1202
Batch 240, Loss: 0.1256
Batch 250, Loss: 0.1133
Batch 260, Loss: 0.1365
Batch 270, Loss: 0.1197
Batch 280, Loss: 0.1213
Batch 290, Loss: 0.1319
Batch 300, Loss: 0.1365
Batch 310, Loss: 0.1196
Batch 320, Loss: 0.1327
Batch 330, Loss: 0.1145
Batch 340, Loss: 0.1382
Batch 350, Loss: 0.1222
Batch 360, Loss: 0.1034
Batch 370, Loss: 0.1480
Batch 380, Loss: 0.1341
Batch 390, Loss: 0.1448
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.244856357574463 seconds
Epoch 198 accuracy: 96.71%
Batch 10, Loss: 0.1376
Batch 20, Loss: 0.1158
Batch 30, Loss: 0.1343
Batch 40, Loss: 0.0993
Batch 50, Loss: 0.1030
Batch 60, Loss: 0.1079
Batch 70, Loss: 0.1144
Batch 80, Loss: 0.1010
Batch 90, Loss: 0.1350
Batch 100, Loss: 0.1148
Batch 110, Loss: 0.1230
Batch 120, Loss: 0.1203
Batch 130, Loss: 0.0998
Batch 140, Loss: 0.1090
Batch 150, Loss: 0.1265
Batch 160, Loss: 0.1223
Batch 170, Loss: 0.1293
Batch 180, Loss: 0.1299
Batch 190, Loss: 0.1320
Batch 200, Loss: 0.1276
Batch 210, Loss: 0.1335
Batch 220, Loss: 0.1324
Batch 230, Loss: 0.1175
Batch 240, Loss: 0.1298
Batch 250, Loss: 0.1369
Batch 260, Loss: 0.1169
Batch 270, Loss: 0.1098
Batch 280, Loss: 0.1086
Batch 290, Loss: 0.1151
Batch 300, Loss: 0.1257
Batch 310, Loss: 0.1057
Batch 320, Loss: 0.1356
Batch 330, Loss: 0.1336
Batch 340, Loss: 0.1271
Batch 350, Loss: 0.1169
Batch 360, Loss: 0.0990
Batch 370, Loss: 0.1270
Batch 380, Loss: 0.1243
Batch 390, Loss: 0.1323
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.269316911697388 seconds
Epoch 199 accuracy: 96.67%
Batch 10, Loss: 0.1373
Batch 20, Loss: 0.1237
Batch 30, Loss: 0.1240
Batch 40, Loss: 0.1071
Batch 50, Loss: 0.1114
Batch 60, Loss: 0.1456
Batch 70, Loss: 0.1016
Batch 80, Loss: 0.1019
Batch 90, Loss: 0.1404
Batch 100, Loss: 0.1095
Batch 110, Loss: 0.1159
Batch 120, Loss: 0.1089
Batch 130, Loss: 0.1224
Batch 140, Loss: 0.1093
Batch 150, Loss: 0.1400
Batch 160, Loss: 0.1315
Batch 170, Loss: 0.1296
Batch 180, Loss: 0.1119
Batch 190, Loss: 0.1343
Batch 200, Loss: 0.1344
Batch 210, Loss: 0.1308
Batch 220, Loss: 0.1313
Batch 230, Loss: 0.1129
Batch 240, Loss: 0.1348
Batch 250, Loss: 0.1169
Batch 260, Loss: 0.1123
Batch 270, Loss: 0.1262
Batch 280, Loss: 0.1207
Batch 290, Loss: 0.1034
Batch 300, Loss: 0.1223
Batch 310, Loss: 0.1225
Batch 320, Loss: 0.1334
Batch 330, Loss: 0.1316
Batch 340, Loss: 0.1287
Batch 350, Loss: 0.1238
Batch 360, Loss: 0.1213
Batch 370, Loss: 0.1287
Batch 380, Loss: 0.1194
Batch 390, Loss: 0.1223
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.232282876968384 seconds
Epoch 200 accuracy: 96.7%
Total training time: 5068.051979541779 seconds
