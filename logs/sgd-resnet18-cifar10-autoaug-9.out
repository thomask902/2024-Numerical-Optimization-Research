The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 3.1003
Batch 20, Loss: 2.9438
Batch 30, Loss: 2.2214
Batch 40, Loss: 1.9257
Batch 50, Loss: 1.9228
Batch 60, Loss: 1.8263
Batch 70, Loss: 1.8366
Batch 80, Loss: 1.7422
Batch 90, Loss: 1.7307
Batch 100, Loss: 1.7145
Batch 110, Loss: 1.6992
Batch 120, Loss: 1.6669
Batch 130, Loss: 1.6297
Batch 140, Loss: 1.6637
Batch 150, Loss: 1.6396
Batch 160, Loss: 1.6303
Batch 170, Loss: 1.6169
Batch 180, Loss: 1.6350
Batch 190, Loss: 1.5865
Batch 200, Loss: 1.6091
Batch 210, Loss: 1.5947
Batch 220, Loss: 1.6038
Batch 230, Loss: 1.6266
Batch 240, Loss: 1.5885
Batch 250, Loss: 1.5938
Batch 260, Loss: 1.5755
Batch 270, Loss: 1.5838
Batch 280, Loss: 1.5714
Batch 290, Loss: 1.5746
Batch 300, Loss: 1.5488
Batch 310, Loss: 1.5424
Batch 320, Loss: 1.5754
Batch 330, Loss: 1.5463
Batch 340, Loss: 1.4981
Batch 350, Loss: 1.5028
Batch 360, Loss: 1.5396
Batch 370, Loss: 1.5046
Batch 380, Loss: 1.4886
Batch 390, Loss: 1.4931
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 30.946775436401367 seconds
Epoch 1 accuracy: 35.03%
Batch 10, Loss: 1.5123
Batch 20, Loss: 1.5034
Batch 30, Loss: 1.4964
Batch 40, Loss: 1.4918
Batch 50, Loss: 1.5218
Batch 60, Loss: 1.4999
Batch 70, Loss: 1.4640
Batch 80, Loss: 1.4631
Batch 90, Loss: 1.4623
Batch 100, Loss: 1.4795
Batch 110, Loss: 1.4670
Batch 120, Loss: 1.4255
Batch 130, Loss: 1.4559
Batch 140, Loss: 1.4784
Batch 150, Loss: 1.4889
Batch 160, Loss: 1.4399
Batch 170, Loss: 1.4426
Batch 180, Loss: 1.4109
Batch 190, Loss: 1.4282
Batch 200, Loss: 1.4109
Batch 210, Loss: 1.4281
Batch 220, Loss: 1.4005
Batch 230, Loss: 1.4194
Batch 240, Loss: 1.4519
Batch 250, Loss: 1.4183
Batch 260, Loss: 1.4355
Batch 270, Loss: 1.4225
Batch 280, Loss: 1.3835
Batch 290, Loss: 1.4139
Batch 300, Loss: 1.4185
Batch 310, Loss: 1.3939
Batch 320, Loss: 1.3932
Batch 330, Loss: 1.3793
Batch 340, Loss: 1.4004
Batch 350, Loss: 1.3792
Batch 360, Loss: 1.3756
Batch 370, Loss: 1.4120
Batch 380, Loss: 1.3642
Batch 390, Loss: 1.3800
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 24.9251492023468 seconds
Epoch 2 accuracy: 42.34%
Batch 10, Loss: 1.3631
Batch 20, Loss: 1.3349
Batch 30, Loss: 1.3967
Batch 40, Loss: 1.3618
Batch 50, Loss: 1.3961
Batch 60, Loss: 1.3656
Batch 70, Loss: 1.3647
Batch 80, Loss: 1.3374
Batch 90, Loss: 1.3425
Batch 100, Loss: 1.3175
Batch 110, Loss: 1.3243
Batch 120, Loss: 1.3381
Batch 130, Loss: 1.3335
Batch 140, Loss: 1.3179
Batch 150, Loss: 1.2793
Batch 160, Loss: 1.3372
Batch 170, Loss: 1.3215
Batch 180, Loss: 1.2933
Batch 190, Loss: 1.2928
Batch 200, Loss: 1.2963
Batch 210, Loss: 1.2467
Batch 220, Loss: 1.3010
Batch 230, Loss: 1.3212
Batch 240, Loss: 1.2897
Batch 250, Loss: 1.2796
Batch 260, Loss: 1.3013
Batch 270, Loss: 1.2803
Batch 280, Loss: 1.2902
Batch 290, Loss: 1.2521
Batch 300, Loss: 1.2800
Batch 310, Loss: 1.2537
Batch 320, Loss: 1.2297
Batch 330, Loss: 1.2466
Batch 340, Loss: 1.2573
Batch 350, Loss: 1.2241
Batch 360, Loss: 1.2487
Batch 370, Loss: 1.2227
Batch 380, Loss: 1.2294
Batch 390, Loss: 1.2427
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 24.90149688720703 seconds
Epoch 3 accuracy: 46.3%
Batch 10, Loss: 1.2629
Batch 20, Loss: 1.1911
Batch 30, Loss: 1.1900
Batch 40, Loss: 1.2155
Batch 50, Loss: 1.2091
Batch 60, Loss: 1.1639
Batch 70, Loss: 1.2119
Batch 80, Loss: 1.1974
Batch 90, Loss: 1.2211
Batch 100, Loss: 1.1811
Batch 110, Loss: 1.1434
Batch 120, Loss: 1.1589
Batch 130, Loss: 1.2202
Batch 140, Loss: 1.1376
Batch 150, Loss: 1.1603
Batch 160, Loss: 1.1187
Batch 170, Loss: 1.1725
Batch 180, Loss: 1.1425
Batch 190, Loss: 1.1650
Batch 200, Loss: 1.1148
Batch 210, Loss: 1.1898
Batch 220, Loss: 1.1641
Batch 230, Loss: 1.1667
Batch 240, Loss: 1.1654
Batch 250, Loss: 1.1316
Batch 260, Loss: 1.1439
Batch 270, Loss: 1.1497
Batch 280, Loss: 1.1237
Batch 290, Loss: 1.1546
Batch 300, Loss: 1.1117
Batch 310, Loss: 1.1663
Batch 320, Loss: 1.1471
Batch 330, Loss: 1.1308
Batch 340, Loss: 1.1004
Batch 350, Loss: 1.1289
Batch 360, Loss: 1.1184
Batch 370, Loss: 1.1298
Batch 380, Loss: 1.1386
Batch 390, Loss: 1.1013
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 24.870906114578247 seconds
Epoch 4 accuracy: 52.58%
Batch 10, Loss: 1.1195
Batch 20, Loss: 1.1017
Batch 30, Loss: 1.1007
Batch 40, Loss: 1.1050
Batch 50, Loss: 1.0658
Batch 60, Loss: 1.0813
Batch 70, Loss: 1.1272
Batch 80, Loss: 1.0637
Batch 90, Loss: 1.0207
Batch 100, Loss: 1.0840
Batch 110, Loss: 1.0788
Batch 120, Loss: 1.1156
Batch 130, Loss: 1.0866
Batch 140, Loss: 1.0650
Batch 150, Loss: 1.0066
Batch 160, Loss: 1.0830
Batch 170, Loss: 1.0971
Batch 180, Loss: 1.0088
Batch 190, Loss: 1.0791
Batch 200, Loss: 1.0731
Batch 210, Loss: 1.0658
Batch 220, Loss: 1.0713
Batch 230, Loss: 1.0414
Batch 240, Loss: 1.0582
Batch 250, Loss: 1.0743
Batch 260, Loss: 1.0083
Batch 270, Loss: 1.0177
Batch 280, Loss: 1.0556
Batch 290, Loss: 1.0284
Batch 300, Loss: 1.0310
Batch 310, Loss: 1.0330
Batch 320, Loss: 1.0452
Batch 330, Loss: 1.0259
Batch 340, Loss: 0.9985
Batch 350, Loss: 0.9869
Batch 360, Loss: 1.0198
Batch 370, Loss: 1.0247
Batch 380, Loss: 1.0125
Batch 390, Loss: 1.0372
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 24.904438257217407 seconds
Epoch 5 accuracy: 60.88%
Batch 10, Loss: 1.0316
Batch 20, Loss: 0.9846
Batch 30, Loss: 0.9933
Batch 40, Loss: 0.9978
Batch 50, Loss: 0.9986
Batch 60, Loss: 1.0052
Batch 70, Loss: 1.0090
Batch 80, Loss: 0.9864
Batch 90, Loss: 0.9861
Batch 100, Loss: 0.9773
Batch 110, Loss: 0.9822
Batch 120, Loss: 0.9224
Batch 130, Loss: 0.9948
Batch 140, Loss: 1.0058
Batch 150, Loss: 0.9985
Batch 160, Loss: 0.9819
Batch 170, Loss: 0.9618
Batch 180, Loss: 0.9788
Batch 190, Loss: 0.9640
Batch 200, Loss: 0.9775
Batch 210, Loss: 0.9736
Batch 220, Loss: 0.9791
Batch 230, Loss: 0.9404
Batch 240, Loss: 0.9338
Batch 250, Loss: 0.9194
Batch 260, Loss: 0.9480
Batch 270, Loss: 0.9508
Batch 280, Loss: 0.9766
Batch 290, Loss: 0.9624
Batch 300, Loss: 0.9954
Batch 310, Loss: 0.9476
Batch 320, Loss: 0.9321
Batch 330, Loss: 0.9642
Batch 340, Loss: 0.9307
Batch 350, Loss: 0.9319
Batch 360, Loss: 0.9212
Batch 370, Loss: 0.8944
Batch 380, Loss: 0.9943
Batch 390, Loss: 0.9375
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 24.918110370635986 seconds
Epoch 6 accuracy: 60.3%
Batch 10, Loss: 0.8755
Batch 20, Loss: 0.9055
Batch 30, Loss: 0.9420
Batch 40, Loss: 0.9041
Batch 50, Loss: 0.8996
Batch 60, Loss: 0.8987
Batch 70, Loss: 0.9277
Batch 80, Loss: 0.9668
Batch 90, Loss: 0.9455
Batch 100, Loss: 0.8905
Batch 110, Loss: 0.8950
Batch 120, Loss: 0.9251
Batch 130, Loss: 0.9358
Batch 140, Loss: 0.9536
Batch 150, Loss: 0.9135
Batch 160, Loss: 0.8707
Batch 170, Loss: 0.9216
Batch 180, Loss: 0.8882
Batch 190, Loss: 0.8417
Batch 200, Loss: 0.8731
Batch 210, Loss: 0.9093
Batch 220, Loss: 0.8696
Batch 230, Loss: 0.9097
Batch 240, Loss: 0.8857
Batch 250, Loss: 0.8583
Batch 260, Loss: 0.8791
Batch 270, Loss: 0.9216
Batch 280, Loss: 0.9148
Batch 290, Loss: 0.8847
Batch 300, Loss: 0.9498
Batch 310, Loss: 0.8589
Batch 320, Loss: 0.8827
Batch 330, Loss: 0.9213
Batch 340, Loss: 0.9096
Batch 350, Loss: 0.8855
Batch 360, Loss: 0.8468
Batch 370, Loss: 0.8813
Batch 380, Loss: 0.8752
Batch 390, Loss: 0.8605
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 24.933593273162842 seconds
Epoch 7 accuracy: 70.22%
Batch 10, Loss: 0.8509
Batch 20, Loss: 0.8676
Batch 30, Loss: 0.8713
Batch 40, Loss: 0.8936
Batch 50, Loss: 0.8555
Batch 60, Loss: 0.8227
Batch 70, Loss: 0.8242
Batch 80, Loss: 0.8317
Batch 90, Loss: 0.8571
Batch 100, Loss: 0.8161
Batch 110, Loss: 0.8648
Batch 120, Loss: 0.7987
Batch 130, Loss: 0.8902
Batch 140, Loss: 0.8686
Batch 150, Loss: 0.8548
Batch 160, Loss: 0.8761
Batch 170, Loss: 0.8038
Batch 180, Loss: 0.8694
Batch 190, Loss: 0.8489
Batch 200, Loss: 0.8260
Batch 210, Loss: 0.8103
Batch 220, Loss: 0.8239
Batch 230, Loss: 0.8856
Batch 240, Loss: 0.8798
Batch 250, Loss: 0.8577
Batch 260, Loss: 0.8475
Batch 270, Loss: 0.8082
Batch 280, Loss: 0.8067
Batch 290, Loss: 0.8120
Batch 300, Loss: 0.8143
Batch 310, Loss: 0.8069
Batch 320, Loss: 0.8418
Batch 330, Loss: 0.8561
Batch 340, Loss: 0.8135
Batch 350, Loss: 0.8171
Batch 360, Loss: 0.8295
Batch 370, Loss: 0.8138
Batch 380, Loss: 0.7860
Batch 390, Loss: 0.8196
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 24.942453145980835 seconds
Epoch 8 accuracy: 72.85%
Batch 10, Loss: 0.8462
Batch 20, Loss: 0.7924
Batch 30, Loss: 0.8112
Batch 40, Loss: 0.7871
Batch 50, Loss: 0.8260
Batch 60, Loss: 0.8136
Batch 70, Loss: 0.7908
Batch 80, Loss: 0.7761
Batch 90, Loss: 0.8794
Batch 100, Loss: 0.8083
Batch 110, Loss: 0.7963
Batch 120, Loss: 0.7776
Batch 130, Loss: 0.7917
Batch 140, Loss: 0.8266
Batch 150, Loss: 0.7917
Batch 160, Loss: 0.7931
Batch 170, Loss: 0.7954
Batch 180, Loss: 0.7628
Batch 190, Loss: 0.8401
Batch 200, Loss: 0.7921
Batch 210, Loss: 0.7975
Batch 220, Loss: 0.7885
Batch 230, Loss: 0.7588
Batch 240, Loss: 0.8462
Batch 250, Loss: 0.8336
Batch 260, Loss: 0.7740
Batch 270, Loss: 0.7823
Batch 280, Loss: 0.7914
Batch 290, Loss: 0.7918
Batch 300, Loss: 0.8097
Batch 310, Loss: 0.7979
Batch 320, Loss: 0.7928
Batch 330, Loss: 0.7899
Batch 340, Loss: 0.7783
Batch 350, Loss: 0.7948
Batch 360, Loss: 0.7948
Batch 370, Loss: 0.7867
Batch 380, Loss: 0.7690
Batch 390, Loss: 0.7876
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 24.994755029678345 seconds
Epoch 9 accuracy: 72.67%
Batch 10, Loss: 0.7899
Batch 20, Loss: 0.7547
Batch 30, Loss: 0.8245
Batch 40, Loss: 0.7787
Batch 50, Loss: 0.7755
Batch 60, Loss: 0.8117
Batch 70, Loss: 0.7794
Batch 80, Loss: 0.7750
Batch 90, Loss: 0.7441
Batch 100, Loss: 0.8351
Batch 110, Loss: 0.7818
Batch 120, Loss: 0.7699
Batch 130, Loss: 0.7264
Batch 140, Loss: 0.7646
Batch 150, Loss: 0.7854
Batch 160, Loss: 0.7590
Batch 170, Loss: 0.7595
Batch 180, Loss: 0.7280
Batch 190, Loss: 0.7822
Batch 200, Loss: 0.8260
Batch 210, Loss: 0.7322
Batch 220, Loss: 0.7798
Batch 230, Loss: 0.7435
Batch 240, Loss: 0.7102
Batch 250, Loss: 0.8063
Batch 260, Loss: 0.8108
Batch 270, Loss: 0.7618
Batch 280, Loss: 0.7852
Batch 290, Loss: 0.7333
Batch 300, Loss: 0.8150
Batch 310, Loss: 0.7779
Batch 320, Loss: 0.7200
Batch 330, Loss: 0.7432
Batch 340, Loss: 0.7332
Batch 350, Loss: 0.7215
Batch 360, Loss: 0.7764
Batch 370, Loss: 0.7751
Batch 380, Loss: 0.7459
Batch 390, Loss: 0.7510
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 24.973772764205933 seconds
Epoch 10 accuracy: 73.56%
Batch 10, Loss: 0.7655
Batch 20, Loss: 0.7804
Batch 30, Loss: 0.7242
Batch 40, Loss: 0.7433
Batch 50, Loss: 0.7686
Batch 60, Loss: 0.7395
Batch 70, Loss: 0.7671
Batch 80, Loss: 0.7835
Batch 90, Loss: 0.7183
Batch 100, Loss: 0.7559
Batch 110, Loss: 0.7497
Batch 120, Loss: 0.7450
Batch 130, Loss: 0.7339
Batch 140, Loss: 0.7475
Batch 150, Loss: 0.7385
Batch 160, Loss: 0.7290
Batch 170, Loss: 0.7779
Batch 180, Loss: 0.7857
Batch 190, Loss: 0.7947
Batch 200, Loss: 0.7655
Batch 210, Loss: 0.7578
Batch 220, Loss: 0.7640
Batch 230, Loss: 0.7092
Batch 240, Loss: 0.7180
Batch 250, Loss: 0.7694
Batch 260, Loss: 0.7796
Batch 270, Loss: 0.7070
Batch 280, Loss: 0.7256
Batch 290, Loss: 0.7269
Batch 300, Loss: 0.8000
Batch 310, Loss: 0.7694
Batch 320, Loss: 0.7251
Batch 330, Loss: 0.7390
Batch 340, Loss: 0.7302
Batch 350, Loss: 0.7606
Batch 360, Loss: 0.7784
Batch 370, Loss: 0.7487
Batch 380, Loss: 0.7584
Batch 390, Loss: 0.7578
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 24.9246346950531 seconds
Epoch 11 accuracy: 68.06%
Batch 10, Loss: 0.7005
Batch 20, Loss: 0.7484
Batch 30, Loss: 0.7333
Batch 40, Loss: 0.7001
Batch 50, Loss: 0.7393
Batch 60, Loss: 0.7403
Batch 70, Loss: 0.7413
Batch 80, Loss: 0.7322
Batch 90, Loss: 0.7273
Batch 100, Loss: 0.7342
Batch 110, Loss: 0.7216
Batch 120, Loss: 0.7263
Batch 130, Loss: 0.7280
Batch 140, Loss: 0.7144
Batch 150, Loss: 0.6722
Batch 160, Loss: 0.7068
Batch 170, Loss: 0.7063
Batch 180, Loss: 0.7028
Batch 190, Loss: 0.6916
Batch 200, Loss: 0.7547
Batch 210, Loss: 0.7348
Batch 220, Loss: 0.7377
Batch 230, Loss: 0.7316
Batch 240, Loss: 0.7156
Batch 250, Loss: 0.7196
Batch 260, Loss: 0.7064
Batch 270, Loss: 0.7078
Batch 280, Loss: 0.7135
Batch 290, Loss: 0.7014
Batch 300, Loss: 0.7691
Batch 310, Loss: 0.7009
Batch 320, Loss: 0.7222
Batch 330, Loss: 0.7252
Batch 340, Loss: 0.7179
Batch 350, Loss: 0.7388
Batch 360, Loss: 0.6856
Batch 370, Loss: 0.6991
Batch 380, Loss: 0.6872
Batch 390, Loss: 0.7263
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 24.900781631469727 seconds
Epoch 12 accuracy: 76.08%
Batch 10, Loss: 0.6863
Batch 20, Loss: 0.7050
Batch 30, Loss: 0.7401
Batch 40, Loss: 0.7076
Batch 50, Loss: 0.7144
Batch 60, Loss: 0.7131
Batch 70, Loss: 0.7087
Batch 80, Loss: 0.6847
Batch 90, Loss: 0.6620
Batch 100, Loss: 0.7111
Batch 110, Loss: 0.7260
Batch 120, Loss: 0.6927
Batch 130, Loss: 0.7269
Batch 140, Loss: 0.7480
Batch 150, Loss: 0.7397
Batch 160, Loss: 0.7081
Batch 170, Loss: 0.7118
Batch 180, Loss: 0.7353
Batch 190, Loss: 0.6850
Batch 200, Loss: 0.7224
Batch 210, Loss: 0.7214
Batch 220, Loss: 0.7182
Batch 230, Loss: 0.6805
Batch 240, Loss: 0.7039
Batch 250, Loss: 0.6980
Batch 260, Loss: 0.6729
Batch 270, Loss: 0.7390
Batch 280, Loss: 0.7320
Batch 290, Loss: 0.6971
Batch 300, Loss: 0.7151
Batch 310, Loss: 0.6465
Batch 320, Loss: 0.6767
Batch 330, Loss: 0.7330
Batch 340, Loss: 0.7374
Batch 350, Loss: 0.7034
Batch 360, Loss: 0.6874
Batch 370, Loss: 0.6791
Batch 380, Loss: 0.6833
Batch 390, Loss: 0.6810
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 24.91906237602234 seconds
Epoch 13 accuracy: 75.49%
Batch 10, Loss: 0.7005
Batch 20, Loss: 0.7107
Batch 30, Loss: 0.7297
Batch 40, Loss: 0.6773
Batch 50, Loss: 0.7109
Batch 60, Loss: 0.7165
Batch 70, Loss: 0.6874
Batch 80, Loss: 0.7181
Batch 90, Loss: 0.6547
Batch 100, Loss: 0.7123
Batch 110, Loss: 0.6668
Batch 120, Loss: 0.6701
Batch 130, Loss: 0.7295
Batch 140, Loss: 0.7278
Batch 150, Loss: 0.6673
Batch 160, Loss: 0.6883
Batch 170, Loss: 0.6784
Batch 180, Loss: 0.6920
Batch 190, Loss: 0.6807
Batch 200, Loss: 0.7021
Batch 210, Loss: 0.6718
Batch 220, Loss: 0.6763
Batch 230, Loss: 0.7006
Batch 240, Loss: 0.7002
Batch 250, Loss: 0.6836
Batch 260, Loss: 0.6964
Batch 270, Loss: 0.6844
Batch 280, Loss: 0.6478
Batch 290, Loss: 0.6904
Batch 300, Loss: 0.7013
Batch 310, Loss: 0.7151
Batch 320, Loss: 0.7079
Batch 330, Loss: 0.6997
Batch 340, Loss: 0.7082
Batch 350, Loss: 0.6999
Batch 360, Loss: 0.6765
Batch 370, Loss: 0.7190
Batch 380, Loss: 0.6945
Batch 390, Loss: 0.7196
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 24.928935766220093 seconds
Epoch 14 accuracy: 73.22%
Batch 10, Loss: 0.7249
Batch 20, Loss: 0.7027
Batch 30, Loss: 0.6905
Batch 40, Loss: 0.6925
Batch 50, Loss: 0.6523
Batch 60, Loss: 0.6815
Batch 70, Loss: 0.7528
Batch 80, Loss: 0.6454
Batch 90, Loss: 0.6983
Batch 100, Loss: 0.6501
Batch 110, Loss: 0.6625
Batch 120, Loss: 0.6685
Batch 130, Loss: 0.6994
Batch 140, Loss: 0.6573
Batch 150, Loss: 0.6772
Batch 160, Loss: 0.6917
Batch 170, Loss: 0.6574
Batch 180, Loss: 0.6532
Batch 190, Loss: 0.6986
Batch 200, Loss: 0.6737
Batch 210, Loss: 0.6700
Batch 220, Loss: 0.6942
Batch 230, Loss: 0.6898
Batch 240, Loss: 0.6929
Batch 250, Loss: 0.6401
Batch 260, Loss: 0.6850
Batch 270, Loss: 0.6568
Batch 280, Loss: 0.6975
Batch 290, Loss: 0.6899
Batch 300, Loss: 0.6627
Batch 310, Loss: 0.6838
Batch 320, Loss: 0.6918
Batch 330, Loss: 0.6530
Batch 340, Loss: 0.6871
Batch 350, Loss: 0.6650
Batch 360, Loss: 0.7401
Batch 370, Loss: 0.7001
Batch 380, Loss: 0.6920
Batch 390, Loss: 0.6767
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.002444982528687 seconds
Epoch 15 accuracy: 77.17%
Batch 10, Loss: 0.6416
Batch 20, Loss: 0.6845
Batch 30, Loss: 0.6431
Batch 40, Loss: 0.6733
Batch 50, Loss: 0.7026
Batch 60, Loss: 0.6563
Batch 70, Loss: 0.6908
Batch 80, Loss: 0.6776
Batch 90, Loss: 0.6551
Batch 100, Loss: 0.6481
Batch 110, Loss: 0.6196
Batch 120, Loss: 0.6485
Batch 130, Loss: 0.6423
Batch 140, Loss: 0.7056
Batch 150, Loss: 0.6485
Batch 160, Loss: 0.6838
Batch 170, Loss: 0.6826
Batch 180, Loss: 0.7296
Batch 190, Loss: 0.6874
Batch 200, Loss: 0.6543
Batch 210, Loss: 0.6840
Batch 220, Loss: 0.6613
Batch 230, Loss: 0.6686
Batch 240, Loss: 0.6550
Batch 250, Loss: 0.6708
Batch 260, Loss: 0.6732
Batch 270, Loss: 0.6912
Batch 280, Loss: 0.6666
Batch 290, Loss: 0.6905
Batch 300, Loss: 0.6912
Batch 310, Loss: 0.6904
Batch 320, Loss: 0.6642
Batch 330, Loss: 0.6376
Batch 340, Loss: 0.6614
Batch 350, Loss: 0.6519
Batch 360, Loss: 0.6359
Batch 370, Loss: 0.7034
Batch 380, Loss: 0.6538
Batch 390, Loss: 0.6523
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 24.974165201187134 seconds
Epoch 16 accuracy: 77.87%
Batch 10, Loss: 0.6624
Batch 20, Loss: 0.6574
Batch 30, Loss: 0.6619
Batch 40, Loss: 0.6333
Batch 50, Loss: 0.6832
Batch 60, Loss: 0.6222
Batch 70, Loss: 0.6991
Batch 80, Loss: 0.6169
Batch 90, Loss: 0.6910
Batch 100, Loss: 0.6527
Batch 110, Loss: 0.6536
Batch 120, Loss: 0.6572
Batch 130, Loss: 0.6653
Batch 140, Loss: 0.6559
Batch 150, Loss: 0.6872
Batch 160, Loss: 0.6987
Batch 170, Loss: 0.7059
Batch 180, Loss: 0.6522
Batch 190, Loss: 0.6390
Batch 200, Loss: 0.6703
Batch 210, Loss: 0.6936
Batch 220, Loss: 0.6688
Batch 230, Loss: 0.6672
Batch 240, Loss: 0.5965
Batch 250, Loss: 0.6378
Batch 260, Loss: 0.7060
Batch 270, Loss: 0.6295
Batch 280, Loss: 0.6934
Batch 290, Loss: 0.6902
Batch 300, Loss: 0.6080
Batch 310, Loss: 0.7148
Batch 320, Loss: 0.6456
Batch 330, Loss: 0.6581
Batch 340, Loss: 0.6552
Batch 350, Loss: 0.6740
Batch 360, Loss: 0.6462
Batch 370, Loss: 0.6596
Batch 380, Loss: 0.6462
Batch 390, Loss: 0.6557
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 24.907960653305054 seconds
Epoch 17 accuracy: 74.46%
Batch 10, Loss: 0.6482
Batch 20, Loss: 0.6437
Batch 30, Loss: 0.6720
Batch 40, Loss: 0.6577
Batch 50, Loss: 0.6370
Batch 60, Loss: 0.6470
Batch 70, Loss: 0.6405
Batch 80, Loss: 0.6673
Batch 90, Loss: 0.6174
Batch 100, Loss: 0.6520
Batch 110, Loss: 0.6661
Batch 120, Loss: 0.6167
Batch 130, Loss: 0.6570
Batch 140, Loss: 0.6423
Batch 150, Loss: 0.6811
Batch 160, Loss: 0.6846
Batch 170, Loss: 0.6688
Batch 180, Loss: 0.6426
Batch 190, Loss: 0.6346
Batch 200, Loss: 0.6358
Batch 210, Loss: 0.6591
Batch 220, Loss: 0.6713
Batch 230, Loss: 0.6349
Batch 240, Loss: 0.6357
Batch 250, Loss: 0.6102
Batch 260, Loss: 0.6839
Batch 270, Loss: 0.6178
Batch 280, Loss: 0.6463
Batch 290, Loss: 0.6676
Batch 300, Loss: 0.6148
Batch 310, Loss: 0.6450
Batch 320, Loss: 0.6558
Batch 330, Loss: 0.6749
Batch 340, Loss: 0.6574
Batch 350, Loss: 0.7110
Batch 360, Loss: 0.6580
Batch 370, Loss: 0.6505
Batch 380, Loss: 0.6200
Batch 390, Loss: 0.6422
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 24.908126831054688 seconds
Epoch 18 accuracy: 78.38%
Batch 10, Loss: 0.6336
Batch 20, Loss: 0.6217
Batch 30, Loss: 0.6266
Batch 40, Loss: 0.6523
Batch 50, Loss: 0.6260
Batch 60, Loss: 0.6224
Batch 70, Loss: 0.6592
Batch 80, Loss: 0.6454
Batch 90, Loss: 0.6485
Batch 100, Loss: 0.6437
Batch 110, Loss: 0.6513
Batch 120, Loss: 0.6416
Batch 130, Loss: 0.6381
Batch 140, Loss: 0.6203
Batch 150, Loss: 0.6287
Batch 160, Loss: 0.7052
Batch 170, Loss: 0.6277
Batch 180, Loss: 0.6643
Batch 190, Loss: 0.6123
Batch 200, Loss: 0.6140
Batch 210, Loss: 0.6085
Batch 220, Loss: 0.6998
Batch 230, Loss: 0.7030
Batch 240, Loss: 0.6418
Batch 250, Loss: 0.6346
Batch 260, Loss: 0.6507
Batch 270, Loss: 0.6125
Batch 280, Loss: 0.6313
Batch 290, Loss: 0.6363
Batch 300, Loss: 0.6584
Batch 310, Loss: 0.6371
Batch 320, Loss: 0.6614
Batch 330, Loss: 0.6405
Batch 340, Loss: 0.6507
Batch 350, Loss: 0.6329
Batch 360, Loss: 0.6406
Batch 370, Loss: 0.6371
Batch 380, Loss: 0.6632
Batch 390, Loss: 0.6057
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 24.975136041641235 seconds
Epoch 19 accuracy: 82.54%
Batch 10, Loss: 0.6303
Batch 20, Loss: 0.6524
Batch 30, Loss: 0.6591
Batch 40, Loss: 0.6415
Batch 50, Loss: 0.6196
Batch 60, Loss: 0.6385
Batch 70, Loss: 0.6445
Batch 80, Loss: 0.6301
Batch 90, Loss: 0.6541
Batch 100, Loss: 0.6570
Batch 110, Loss: 0.6212
Batch 120, Loss: 0.6447
Batch 130, Loss: 0.6536
Batch 140, Loss: 0.6477
Batch 150, Loss: 0.6431
Batch 160, Loss: 0.5971
Batch 170, Loss: 0.6123
Batch 180, Loss: 0.6060
Batch 190, Loss: 0.6241
Batch 200, Loss: 0.6608
Batch 210, Loss: 0.6376
Batch 220, Loss: 0.6264
Batch 230, Loss: 0.6325
Batch 240, Loss: 0.5977
Batch 250, Loss: 0.6524
Batch 260, Loss: 0.6220
Batch 270, Loss: 0.6430
Batch 280, Loss: 0.6179
Batch 290, Loss: 0.6008
Batch 300, Loss: 0.6459
Batch 310, Loss: 0.6306
Batch 320, Loss: 0.6696
Batch 330, Loss: 0.6623
Batch 340, Loss: 0.6512
Batch 350, Loss: 0.6601
Batch 360, Loss: 0.6153
Batch 370, Loss: 0.6239
Batch 380, Loss: 0.6508
Batch 390, Loss: 0.6158
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 24.94534468650818 seconds
Epoch 20 accuracy: 77.32%
Batch 10, Loss: 0.5659
Batch 20, Loss: 0.6385
Batch 30, Loss: 0.6430
Batch 40, Loss: 0.6516
Batch 50, Loss: 0.6589
Batch 60, Loss: 0.6176
Batch 70, Loss: 0.6376
Batch 80, Loss: 0.6258
Batch 90, Loss: 0.6239
Batch 100, Loss: 0.6217
Batch 110, Loss: 0.6076
Batch 120, Loss: 0.5978
Batch 130, Loss: 0.6497
Batch 140, Loss: 0.6336
Batch 150, Loss: 0.6337
Batch 160, Loss: 0.6198
Batch 170, Loss: 0.6385
Batch 180, Loss: 0.6239
Batch 190, Loss: 0.6595
Batch 200, Loss: 0.5808
Batch 210, Loss: 0.6036
Batch 220, Loss: 0.5702
Batch 230, Loss: 0.6638
Batch 240, Loss: 0.6613
Batch 250, Loss: 0.6184
Batch 260, Loss: 0.6441
Batch 270, Loss: 0.5949
Batch 280, Loss: 0.6633
Batch 290, Loss: 0.6147
Batch 300, Loss: 0.6445
Batch 310, Loss: 0.5989
Batch 320, Loss: 0.6316
Batch 330, Loss: 0.6972
Batch 340, Loss: 0.6010
Batch 350, Loss: 0.6483
Batch 360, Loss: 0.6201
Batch 370, Loss: 0.6432
Batch 380, Loss: 0.6084
Batch 390, Loss: 0.6279
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 24.927747011184692 seconds
Epoch 21 accuracy: 71.38%
Batch 10, Loss: 0.6275
Batch 20, Loss: 0.6042
Batch 30, Loss: 0.6406
Batch 40, Loss: 0.5885
Batch 50, Loss: 0.6458
Batch 60, Loss: 0.6065
Batch 70, Loss: 0.6436
Batch 80, Loss: 0.6231
Batch 90, Loss: 0.5955
Batch 100, Loss: 0.6490
Batch 110, Loss: 0.6223
Batch 120, Loss: 0.6099
Batch 130, Loss: 0.6535
Batch 140, Loss: 0.6178
Batch 150, Loss: 0.6166
Batch 160, Loss: 0.6534
Batch 170, Loss: 0.6085
Batch 180, Loss: 0.6048
Batch 190, Loss: 0.6006
Batch 200, Loss: 0.6055
Batch 210, Loss: 0.6314
Batch 220, Loss: 0.6297
Batch 230, Loss: 0.6050
Batch 240, Loss: 0.5852
Batch 250, Loss: 0.6155
Batch 260, Loss: 0.6342
Batch 270, Loss: 0.6534
Batch 280, Loss: 0.6460
Batch 290, Loss: 0.6097
Batch 300, Loss: 0.6422
Batch 310, Loss: 0.6147
Batch 320, Loss: 0.6580
Batch 330, Loss: 0.5907
Batch 340, Loss: 0.5966
Batch 350, Loss: 0.5969
Batch 360, Loss: 0.6282
Batch 370, Loss: 0.6451
Batch 380, Loss: 0.6567
Batch 390, Loss: 0.6329
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 24.951819896697998 seconds
Epoch 22 accuracy: 81.33%
Batch 10, Loss: 0.5937
Batch 20, Loss: 0.5757
Batch 30, Loss: 0.6164
Batch 40, Loss: 0.6271
Batch 50, Loss: 0.6113
Batch 60, Loss: 0.6244
Batch 70, Loss: 0.6140
Batch 80, Loss: 0.6564
Batch 90, Loss: 0.6058
Batch 100, Loss: 0.6153
Batch 110, Loss: 0.5951
Batch 120, Loss: 0.6199
Batch 130, Loss: 0.6259
Batch 140, Loss: 0.6306
Batch 150, Loss: 0.6613
Batch 160, Loss: 0.6010
Batch 170, Loss: 0.6442
Batch 180, Loss: 0.6068
Batch 190, Loss: 0.6301
Batch 200, Loss: 0.6364
Batch 210, Loss: 0.6609
Batch 220, Loss: 0.6049
Batch 230, Loss: 0.6242
Batch 240, Loss: 0.6026
Batch 250, Loss: 0.6183
Batch 260, Loss: 0.6411
Batch 270, Loss: 0.6418
Batch 280, Loss: 0.6294
Batch 290, Loss: 0.6231
Batch 300, Loss: 0.6075
Batch 310, Loss: 0.5934
Batch 320, Loss: 0.6533
Batch 330, Loss: 0.6483
Batch 340, Loss: 0.6123
Batch 350, Loss: 0.6137
Batch 360, Loss: 0.6178
Batch 370, Loss: 0.5886
Batch 380, Loss: 0.6517
Batch 390, Loss: 0.6319
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 24.921515941619873 seconds
Epoch 23 accuracy: 82.22%
Batch 10, Loss: 0.6386
Batch 20, Loss: 0.5911
Batch 30, Loss: 0.5841
Batch 40, Loss: 0.6115
Batch 50, Loss: 0.6148
Batch 60, Loss: 0.6079
Batch 70, Loss: 0.5938
Batch 80, Loss: 0.6259
Batch 90, Loss: 0.6203
Batch 100, Loss: 0.6436
Batch 110, Loss: 0.6606
Batch 120, Loss: 0.6281
Batch 130, Loss: 0.6046
Batch 140, Loss: 0.6533
Batch 150, Loss: 0.6035
Batch 160, Loss: 0.6125
Batch 170, Loss: 0.6110
Batch 180, Loss: 0.6185
Batch 190, Loss: 0.6088
Batch 200, Loss: 0.6238
Batch 210, Loss: 0.6329
Batch 220, Loss: 0.6376
Batch 230, Loss: 0.6001
Batch 240, Loss: 0.6142
Batch 250, Loss: 0.5929
Batch 260, Loss: 0.5850
Batch 270, Loss: 0.6187
Batch 280, Loss: 0.6599
Batch 290, Loss: 0.5975
Batch 300, Loss: 0.6029
Batch 310, Loss: 0.5699
Batch 320, Loss: 0.6247
Batch 330, Loss: 0.5858
Batch 340, Loss: 0.6696
Batch 350, Loss: 0.6448
Batch 360, Loss: 0.6479
Batch 370, Loss: 0.6400
Batch 380, Loss: 0.5700
Batch 390, Loss: 0.6002
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 24.94183039665222 seconds
Epoch 24 accuracy: 76.62%
Batch 10, Loss: 0.6279
Batch 20, Loss: 0.5930
Batch 30, Loss: 0.5914
Batch 40, Loss: 0.6411
Batch 50, Loss: 0.6348
Batch 60, Loss: 0.6096
Batch 70, Loss: 0.5851
Batch 80, Loss: 0.6308
Batch 90, Loss: 0.5801
Batch 100, Loss: 0.6439
Batch 110, Loss: 0.5918
Batch 120, Loss: 0.5815
Batch 130, Loss: 0.6243
Batch 140, Loss: 0.5987
Batch 150, Loss: 0.6184
Batch 160, Loss: 0.6155
Batch 170, Loss: 0.6195
Batch 180, Loss: 0.5805
Batch 190, Loss: 0.5923
Batch 200, Loss: 0.6069
Batch 210, Loss: 0.5775
Batch 220, Loss: 0.6045
Batch 230, Loss: 0.5936
Batch 240, Loss: 0.6442
Batch 250, Loss: 0.6177
Batch 260, Loss: 0.5269
Batch 270, Loss: 0.6039
Batch 280, Loss: 0.5880
Batch 290, Loss: 0.5967
Batch 300, Loss: 0.6414
Batch 310, Loss: 0.6374
Batch 320, Loss: 0.6119
Batch 330, Loss: 0.6494
Batch 340, Loss: 0.6200
Batch 350, Loss: 0.6093
Batch 360, Loss: 0.6065
Batch 370, Loss: 0.6376
Batch 380, Loss: 0.6133
Batch 390, Loss: 0.6026
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 24.90799069404602 seconds
Epoch 25 accuracy: 81.48%
Batch 10, Loss: 0.5820
Batch 20, Loss: 0.6015
Batch 30, Loss: 0.5991
Batch 40, Loss: 0.5807
Batch 50, Loss: 0.6070
Batch 60, Loss: 0.6120
Batch 70, Loss: 0.5956
Batch 80, Loss: 0.6365
Batch 90, Loss: 0.6258
Batch 100, Loss: 0.5984
Batch 110, Loss: 0.6102
Batch 120, Loss: 0.5757
Batch 130, Loss: 0.5887
Batch 140, Loss: 0.6222
Batch 150, Loss: 0.5802
Batch 160, Loss: 0.6001
Batch 170, Loss: 0.5526
Batch 180, Loss: 0.5942
Batch 190, Loss: 0.6713
Batch 200, Loss: 0.6579
Batch 210, Loss: 0.5818
Batch 220, Loss: 0.6204
Batch 230, Loss: 0.5902
Batch 240, Loss: 0.6175
Batch 250, Loss: 0.6028
Batch 260, Loss: 0.5785
Batch 270, Loss: 0.6100
Batch 280, Loss: 0.5839
Batch 290, Loss: 0.5980
Batch 300, Loss: 0.6338
Batch 310, Loss: 0.5688
Batch 320, Loss: 0.6342
Batch 330, Loss: 0.5982
Batch 340, Loss: 0.5931
Batch 350, Loss: 0.5935
Batch 360, Loss: 0.5786
Batch 370, Loss: 0.5842
Batch 380, Loss: 0.5793
Batch 390, Loss: 0.6562
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 24.945764541625977 seconds
Epoch 26 accuracy: 69.08%
Batch 10, Loss: 0.6582
Batch 20, Loss: 0.6215
Batch 30, Loss: 0.5888
Batch 40, Loss: 0.5761
Batch 50, Loss: 0.6267
Batch 60, Loss: 0.6003
Batch 70, Loss: 0.6148
Batch 80, Loss: 0.5888
Batch 90, Loss: 0.5786
Batch 100, Loss: 0.6084
Batch 110, Loss: 0.5863
Batch 120, Loss: 0.5996
Batch 130, Loss: 0.6125
Batch 140, Loss: 0.6256
Batch 150, Loss: 0.5985
Batch 160, Loss: 0.6440
Batch 170, Loss: 0.6267
Batch 180, Loss: 0.6045
Batch 190, Loss: 0.6069
Batch 200, Loss: 0.5821
Batch 210, Loss: 0.6119
Batch 220, Loss: 0.5866
Batch 230, Loss: 0.5833
Batch 240, Loss: 0.6075
Batch 250, Loss: 0.5847
Batch 260, Loss: 0.5860
Batch 270, Loss: 0.5442
Batch 280, Loss: 0.5653
Batch 290, Loss: 0.5446
Batch 300, Loss: 0.5930
Batch 310, Loss: 0.6219
Batch 320, Loss: 0.5859
Batch 330, Loss: 0.6135
Batch 340, Loss: 0.6016
Batch 350, Loss: 0.6457
Batch 360, Loss: 0.6018
Batch 370, Loss: 0.6125
Batch 380, Loss: 0.5874
Batch 390, Loss: 0.6224
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 24.976340293884277 seconds
Epoch 27 accuracy: 83.52%
Batch 10, Loss: 0.5822
Batch 20, Loss: 0.5692
Batch 30, Loss: 0.6362
Batch 40, Loss: 0.6029
Batch 50, Loss: 0.5984
Batch 60, Loss: 0.5518
Batch 70, Loss: 0.5824
Batch 80, Loss: 0.6098
Batch 90, Loss: 0.5690
Batch 100, Loss: 0.5600
Batch 110, Loss: 0.5522
Batch 120, Loss: 0.5719
Batch 130, Loss: 0.5555
Batch 140, Loss: 0.6230
Batch 150, Loss: 0.6069
Batch 160, Loss: 0.5930
Batch 170, Loss: 0.6467
Batch 180, Loss: 0.6187
Batch 190, Loss: 0.5912
Batch 200, Loss: 0.5998
Batch 210, Loss: 0.5618
Batch 220, Loss: 0.5909
Batch 230, Loss: 0.5652
Batch 240, Loss: 0.5755
Batch 250, Loss: 0.6284
Batch 260, Loss: 0.6168
Batch 270, Loss: 0.6166
Batch 280, Loss: 0.6361
Batch 290, Loss: 0.6544
Batch 300, Loss: 0.5795
Batch 310, Loss: 0.5900
Batch 320, Loss: 0.6083
Batch 330, Loss: 0.5883
Batch 340, Loss: 0.5659
Batch 350, Loss: 0.6080
Batch 360, Loss: 0.5897
Batch 370, Loss: 0.6028
Batch 380, Loss: 0.6060
Batch 390, Loss: 0.5886
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 24.945448875427246 seconds
Epoch 28 accuracy: 82.48%
Batch 10, Loss: 0.5649
Batch 20, Loss: 0.5399
Batch 30, Loss: 0.5701
Batch 40, Loss: 0.6070
Batch 50, Loss: 0.5745
Batch 60, Loss: 0.5721
Batch 70, Loss: 0.5770
Batch 80, Loss: 0.5932
Batch 90, Loss: 0.5549
Batch 100, Loss: 0.6008
Batch 110, Loss: 0.5915
Batch 120, Loss: 0.5821
Batch 130, Loss: 0.6026
Batch 140, Loss: 0.5745
Batch 150, Loss: 0.6112
Batch 160, Loss: 0.5885
Batch 170, Loss: 0.5732
Batch 180, Loss: 0.5653
Batch 190, Loss: 0.6107
Batch 200, Loss: 0.6000
Batch 210, Loss: 0.6463
Batch 220, Loss: 0.6252
Batch 230, Loss: 0.5846
Batch 240, Loss: 0.6123
Batch 250, Loss: 0.6077
Batch 260, Loss: 0.5508
Batch 270, Loss: 0.6013
Batch 280, Loss: 0.5864
Batch 290, Loss: 0.5970
Batch 300, Loss: 0.6075
Batch 310, Loss: 0.5936
Batch 320, Loss: 0.6252
Batch 330, Loss: 0.6074
Batch 340, Loss: 0.5905
Batch 350, Loss: 0.6003
Batch 360, Loss: 0.5885
Batch 370, Loss: 0.5993
Batch 380, Loss: 0.6002
Batch 390, Loss: 0.5532
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 24.97735333442688 seconds
Epoch 29 accuracy: 82.73%
Batch 10, Loss: 0.6177
Batch 20, Loss: 0.6149
Batch 30, Loss: 0.6132
Batch 40, Loss: 0.5933
Batch 50, Loss: 0.5972
Batch 60, Loss: 0.6191
Batch 70, Loss: 0.5350
Batch 80, Loss: 0.5755
Batch 90, Loss: 0.5692
Batch 100, Loss: 0.5850
Batch 110, Loss: 0.5730
Batch 120, Loss: 0.5672
Batch 130, Loss: 0.5706
Batch 140, Loss: 0.5749
Batch 150, Loss: 0.5815
Batch 160, Loss: 0.6157
Batch 170, Loss: 0.6168
Batch 180, Loss: 0.6068
Batch 190, Loss: 0.6026
Batch 200, Loss: 0.5882
Batch 210, Loss: 0.5856
Batch 220, Loss: 0.6263
Batch 230, Loss: 0.5914
Batch 240, Loss: 0.6131
Batch 250, Loss: 0.6130
Batch 260, Loss: 0.5553
Batch 270, Loss: 0.5989
Batch 280, Loss: 0.6138
Batch 290, Loss: 0.6057
Batch 300, Loss: 0.5880
Batch 310, Loss: 0.6045
Batch 320, Loss: 0.6022
Batch 330, Loss: 0.5876
Batch 340, Loss: 0.6084
Batch 350, Loss: 0.5680
Batch 360, Loss: 0.6044
Batch 370, Loss: 0.6058
Batch 380, Loss: 0.5936
Batch 390, Loss: 0.6096
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 24.94794797897339 seconds
Epoch 30 accuracy: 79.69%
Batch 10, Loss: 0.6028
Batch 20, Loss: 0.5905
Batch 30, Loss: 0.6176
Batch 40, Loss: 0.6022
Batch 50, Loss: 0.5765
Batch 60, Loss: 0.5769
Batch 70, Loss: 0.6164
Batch 80, Loss: 0.5905
Batch 90, Loss: 0.6092
Batch 100, Loss: 0.5958
Batch 110, Loss: 0.5842
Batch 120, Loss: 0.5595
Batch 130, Loss: 0.6102
Batch 140, Loss: 0.5706
Batch 150, Loss: 0.6012
Batch 160, Loss: 0.5418
Batch 170, Loss: 0.5650
Batch 180, Loss: 0.5925
Batch 190, Loss: 0.5548
Batch 200, Loss: 0.5515
Batch 210, Loss: 0.5443
Batch 220, Loss: 0.5929
Batch 230, Loss: 0.5791
Batch 240, Loss: 0.5910
Batch 250, Loss: 0.6029
Batch 260, Loss: 0.6247
Batch 270, Loss: 0.5759
Batch 280, Loss: 0.5965
Batch 290, Loss: 0.5732
Batch 300, Loss: 0.5747
Batch 310, Loss: 0.5725
Batch 320, Loss: 0.6101
Batch 330, Loss: 0.6085
Batch 340, Loss: 0.5545
Batch 350, Loss: 0.5957
Batch 360, Loss: 0.5739
Batch 370, Loss: 0.5914
Batch 380, Loss: 0.5949
Batch 390, Loss: 0.5510
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 24.930757761001587 seconds
Epoch 31 accuracy: 79.79%
Batch 10, Loss: 0.5980
Batch 20, Loss: 0.5878
Batch 30, Loss: 0.5823
Batch 40, Loss: 0.5646
Batch 50, Loss: 0.5978
Batch 60, Loss: 0.6231
Batch 70, Loss: 0.6026
Batch 80, Loss: 0.6029
Batch 90, Loss: 0.5635
Batch 100, Loss: 0.5791
Batch 110, Loss: 0.5131
Batch 120, Loss: 0.5834
Batch 130, Loss: 0.5731
Batch 140, Loss: 0.5703
Batch 150, Loss: 0.5219
Batch 160, Loss: 0.6035
Batch 170, Loss: 0.6167
Batch 180, Loss: 0.5740
Batch 190, Loss: 0.5611
Batch 200, Loss: 0.5516
Batch 210, Loss: 0.5139
Batch 220, Loss: 0.5778
Batch 230, Loss: 0.5999
Batch 240, Loss: 0.6020
Batch 250, Loss: 0.5819
Batch 260, Loss: 0.5650
Batch 270, Loss: 0.5835
Batch 280, Loss: 0.5544
Batch 290, Loss: 0.6223
Batch 300, Loss: 0.5750
Batch 310, Loss: 0.5628
Batch 320, Loss: 0.6260
Batch 330, Loss: 0.6003
Batch 340, Loss: 0.5651
Batch 350, Loss: 0.5797
Batch 360, Loss: 0.6036
Batch 370, Loss: 0.5871
Batch 380, Loss: 0.6013
Batch 390, Loss: 0.5777
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 24.887052297592163 seconds
Epoch 32 accuracy: 78.29%
Batch 10, Loss: 0.5703
Batch 20, Loss: 0.5329
Batch 30, Loss: 0.5736
Batch 40, Loss: 0.5338
Batch 50, Loss: 0.6171
Batch 60, Loss: 0.5778
Batch 70, Loss: 0.6144
Batch 80, Loss: 0.5883
Batch 90, Loss: 0.5526
Batch 100, Loss: 0.5915
Batch 110, Loss: 0.5759
Batch 120, Loss: 0.6122
Batch 130, Loss: 0.6006
Batch 140, Loss: 0.5760
Batch 150, Loss: 0.6011
Batch 160, Loss: 0.5601
Batch 170, Loss: 0.5614
Batch 180, Loss: 0.5893
Batch 190, Loss: 0.5605
Batch 200, Loss: 0.6295
Batch 210, Loss: 0.5750
Batch 220, Loss: 0.5711
Batch 230, Loss: 0.5623
Batch 240, Loss: 0.5473
Batch 250, Loss: 0.5354
Batch 260, Loss: 0.5695
Batch 270, Loss: 0.6204
Batch 280, Loss: 0.5986
Batch 290, Loss: 0.5784
Batch 300, Loss: 0.5552
Batch 310, Loss: 0.5602
Batch 320, Loss: 0.5860
Batch 330, Loss: 0.5747
Batch 340, Loss: 0.5802
Batch 350, Loss: 0.5848
Batch 360, Loss: 0.5875
Batch 370, Loss: 0.5884
Batch 380, Loss: 0.6014
Batch 390, Loss: 0.5702
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 24.928666830062866 seconds
Epoch 33 accuracy: 82.11%
Batch 10, Loss: 0.5476
Batch 20, Loss: 0.5452
Batch 30, Loss: 0.6133
Batch 40, Loss: 0.6203
Batch 50, Loss: 0.5710
Batch 60, Loss: 0.5827
Batch 70, Loss: 0.5557
Batch 80, Loss: 0.5500
Batch 90, Loss: 0.5717
Batch 100, Loss: 0.5657
Batch 110, Loss: 0.5618
Batch 120, Loss: 0.5879
Batch 130, Loss: 0.6053
Batch 140, Loss: 0.5988
Batch 150, Loss: 0.6060
Batch 160, Loss: 0.6065
Batch 170, Loss: 0.5614
Batch 180, Loss: 0.5389
Batch 190, Loss: 0.5708
Batch 200, Loss: 0.5812
Batch 210, Loss: 0.6030
Batch 220, Loss: 0.5569
Batch 230, Loss: 0.6022
Batch 240, Loss: 0.5537
Batch 250, Loss: 0.5327
Batch 260, Loss: 0.5559
Batch 270, Loss: 0.5601
Batch 280, Loss: 0.5871
Batch 290, Loss: 0.5758
Batch 300, Loss: 0.5878
Batch 310, Loss: 0.5612
Batch 320, Loss: 0.5564
Batch 330, Loss: 0.5701
Batch 340, Loss: 0.6095
Batch 350, Loss: 0.6066
Batch 360, Loss: 0.6010
Batch 370, Loss: 0.5738
Batch 380, Loss: 0.5971
Batch 390, Loss: 0.5709
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 24.89025855064392 seconds
Epoch 34 accuracy: 82.31%
Batch 10, Loss: 0.5726
Batch 20, Loss: 0.5902
Batch 30, Loss: 0.5574
Batch 40, Loss: 0.5667
Batch 50, Loss: 0.5814
Batch 60, Loss: 0.5595
Batch 70, Loss: 0.5562
Batch 80, Loss: 0.5832
Batch 90, Loss: 0.5523
Batch 100, Loss: 0.5684
Batch 110, Loss: 0.5603
Batch 120, Loss: 0.6236
Batch 130, Loss: 0.5929
Batch 140, Loss: 0.5627
Batch 150, Loss: 0.5258
Batch 160, Loss: 0.5689
Batch 170, Loss: 0.5795
Batch 180, Loss: 0.5593
Batch 190, Loss: 0.5872
Batch 200, Loss: 0.5241
Batch 210, Loss: 0.5451
Batch 220, Loss: 0.5729
Batch 230, Loss: 0.5755
Batch 240, Loss: 0.5556
Batch 250, Loss: 0.6108
Batch 260, Loss: 0.5776
Batch 270, Loss: 0.5824
Batch 280, Loss: 0.5436
Batch 290, Loss: 0.5868
Batch 300, Loss: 0.5335
Batch 310, Loss: 0.5483
Batch 320, Loss: 0.5769
Batch 330, Loss: 0.5837
Batch 340, Loss: 0.5926
Batch 350, Loss: 0.5992
Batch 360, Loss: 0.5685
Batch 370, Loss: 0.5705
Batch 380, Loss: 0.5611
Batch 390, Loss: 0.5746
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 24.89403462409973 seconds
Epoch 35 accuracy: 82.16%
Batch 10, Loss: 0.5754
Batch 20, Loss: 0.5929
Batch 30, Loss: 0.5645
Batch 40, Loss: 0.5271
Batch 50, Loss: 0.5647
Batch 60, Loss: 0.6065
Batch 70, Loss: 0.5926
Batch 80, Loss: 0.5207
Batch 90, Loss: 0.5706
Batch 100, Loss: 0.5439
Batch 110, Loss: 0.5823
Batch 120, Loss: 0.5610
Batch 130, Loss: 0.5609
Batch 140, Loss: 0.5577
Batch 150, Loss: 0.5949
Batch 160, Loss: 0.5935
Batch 170, Loss: 0.6142
Batch 180, Loss: 0.5663
Batch 190, Loss: 0.5559
Batch 200, Loss: 0.5188
Batch 210, Loss: 0.5568
Batch 220, Loss: 0.5436
Batch 230, Loss: 0.5686
Batch 240, Loss: 0.5667
Batch 250, Loss: 0.5939
Batch 260, Loss: 0.5765
Batch 270, Loss: 0.6039
Batch 280, Loss: 0.5378
Batch 290, Loss: 0.5947
Batch 300, Loss: 0.5839
Batch 310, Loss: 0.6045
Batch 320, Loss: 0.5644
Batch 330, Loss: 0.5840
Batch 340, Loss: 0.5730
Batch 350, Loss: 0.5807
Batch 360, Loss: 0.5912
Batch 370, Loss: 0.5408
Batch 380, Loss: 0.5855
Batch 390, Loss: 0.5841
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 24.92117214202881 seconds
Epoch 36 accuracy: 82.44%
Batch 10, Loss: 0.5731
Batch 20, Loss: 0.5444
Batch 30, Loss: 0.5567
Batch 40, Loss: 0.5443
Batch 50, Loss: 0.5756
Batch 60, Loss: 0.5553
Batch 70, Loss: 0.5244
Batch 80, Loss: 0.5475
Batch 90, Loss: 0.5514
Batch 100, Loss: 0.5524
Batch 110, Loss: 0.6314
Batch 120, Loss: 0.5827
Batch 130, Loss: 0.5704
Batch 140, Loss: 0.5333
Batch 150, Loss: 0.5812
Batch 160, Loss: 0.5890
Batch 170, Loss: 0.5974
Batch 180, Loss: 0.5632
Batch 190, Loss: 0.5926
Batch 200, Loss: 0.5849
Batch 210, Loss: 0.5157
Batch 220, Loss: 0.5623
Batch 230, Loss: 0.6063
Batch 240, Loss: 0.5779
Batch 250, Loss: 0.5650
Batch 260, Loss: 0.6088
Batch 270, Loss: 0.5940
Batch 280, Loss: 0.6011
Batch 290, Loss: 0.5488
Batch 300, Loss: 0.5892
Batch 310, Loss: 0.5910
Batch 320, Loss: 0.5684
Batch 330, Loss: 0.5648
Batch 340, Loss: 0.5338
Batch 350, Loss: 0.5446
Batch 360, Loss: 0.5642
Batch 370, Loss: 0.5851
Batch 380, Loss: 0.5638
Batch 390, Loss: 0.5853
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 24.9235680103302 seconds
Epoch 37 accuracy: 81.75%
Batch 10, Loss: 0.5607
Batch 20, Loss: 0.5514
Batch 30, Loss: 0.5762
Batch 40, Loss: 0.5161
Batch 50, Loss: 0.6025
Batch 60, Loss: 0.5786
Batch 70, Loss: 0.5820
Batch 80, Loss: 0.5867
Batch 90, Loss: 0.5361
Batch 100, Loss: 0.5464
Batch 110, Loss: 0.5744
Batch 120, Loss: 0.5571
Batch 130, Loss: 0.6002
Batch 140, Loss: 0.5308
Batch 150, Loss: 0.5541
Batch 160, Loss: 0.5253
Batch 170, Loss: 0.5826
Batch 180, Loss: 0.5382
Batch 190, Loss: 0.5907
Batch 200, Loss: 0.6017
Batch 210, Loss: 0.5561
Batch 220, Loss: 0.5563
Batch 230, Loss: 0.5422
Batch 240, Loss: 0.5627
Batch 250, Loss: 0.5819
Batch 260, Loss: 0.5651
Batch 270, Loss: 0.5733
Batch 280, Loss: 0.5998
Batch 290, Loss: 0.5700
Batch 300, Loss: 0.5681
Batch 310, Loss: 0.5799
Batch 320, Loss: 0.5401
Batch 330, Loss: 0.5859
Batch 340, Loss: 0.5834
Batch 350, Loss: 0.5950
Batch 360, Loss: 0.5266
Batch 370, Loss: 0.5311
Batch 380, Loss: 0.5843
Batch 390, Loss: 0.5523
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 24.988367557525635 seconds
Epoch 38 accuracy: 82.82%
Batch 10, Loss: 0.5520
Batch 20, Loss: 0.5375
Batch 30, Loss: 0.5544
Batch 40, Loss: 0.5491
Batch 50, Loss: 0.5642
Batch 60, Loss: 0.5572
Batch 70, Loss: 0.5657
Batch 80, Loss: 0.5127
Batch 90, Loss: 0.5633
Batch 100, Loss: 0.5555
Batch 110, Loss: 0.5465
Batch 120, Loss: 0.6181
Batch 130, Loss: 0.5649
Batch 140, Loss: 0.5427
Batch 150, Loss: 0.5532
Batch 160, Loss: 0.5805
Batch 170, Loss: 0.5659
Batch 180, Loss: 0.5803
Batch 190, Loss: 0.5905
Batch 200, Loss: 0.5845
Batch 210, Loss: 0.6042
Batch 220, Loss: 0.5819
Batch 230, Loss: 0.5351
Batch 240, Loss: 0.5683
Batch 250, Loss: 0.5589
Batch 260, Loss: 0.5823
Batch 270, Loss: 0.5782
Batch 280, Loss: 0.5689
Batch 290, Loss: 0.6275
Batch 300, Loss: 0.5059
Batch 310, Loss: 0.5546
Batch 320, Loss: 0.5609
Batch 330, Loss: 0.5203
Batch 340, Loss: 0.5587
Batch 350, Loss: 0.5538
Batch 360, Loss: 0.5232
Batch 370, Loss: 0.5435
Batch 380, Loss: 0.5626
Batch 390, Loss: 0.5640
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 24.916411638259888 seconds
Epoch 39 accuracy: 80.82%
Batch 10, Loss: 0.5259
Batch 20, Loss: 0.5430
Batch 30, Loss: 0.5742
Batch 40, Loss: 0.5473
Batch 50, Loss: 0.5520
Batch 60, Loss: 0.5420
Batch 70, Loss: 0.5569
Batch 80, Loss: 0.5842
Batch 90, Loss: 0.5141
Batch 100, Loss: 0.5732
Batch 110, Loss: 0.5580
Batch 120, Loss: 0.5307
Batch 130, Loss: 0.5311
Batch 140, Loss: 0.5684
Batch 150, Loss: 0.5590
Batch 160, Loss: 0.5322
Batch 170, Loss: 0.6021
Batch 180, Loss: 0.5800
Batch 190, Loss: 0.5714
Batch 200, Loss: 0.6210
Batch 210, Loss: 0.5596
Batch 220, Loss: 0.5233
Batch 230, Loss: 0.5659
Batch 240, Loss: 0.5748
Batch 250, Loss: 0.6000
Batch 260, Loss: 0.5805
Batch 270, Loss: 0.5507
Batch 280, Loss: 0.5407
Batch 290, Loss: 0.5440
Batch 300, Loss: 0.5732
Batch 310, Loss: 0.5917
Batch 320, Loss: 0.5658
Batch 330, Loss: 0.5689
Batch 340, Loss: 0.5272
Batch 350, Loss: 0.5866
Batch 360, Loss: 0.5475
Batch 370, Loss: 0.5811
Batch 380, Loss: 0.5406
Batch 390, Loss: 0.5702
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 24.95220923423767 seconds
Epoch 40 accuracy: 82.37%
Batch 10, Loss: 0.5321
Batch 20, Loss: 0.5507
Batch 30, Loss: 0.5128
Batch 40, Loss: 0.5661
Batch 50, Loss: 0.5556
Batch 60, Loss: 0.5258
Batch 70, Loss: 0.5703
Batch 80, Loss: 0.5939
Batch 90, Loss: 0.5448
Batch 100, Loss: 0.5464
Batch 110, Loss: 0.5792
Batch 120, Loss: 0.5468
Batch 130, Loss: 0.5696
Batch 140, Loss: 0.5540
Batch 150, Loss: 0.5605
Batch 160, Loss: 0.5206
Batch 170, Loss: 0.5361
Batch 180, Loss: 0.6211
Batch 190, Loss: 0.5734
Batch 200, Loss: 0.5892
Batch 210, Loss: 0.5582
Batch 220, Loss: 0.5790
Batch 230, Loss: 0.5657
Batch 240, Loss: 0.5746
Batch 250, Loss: 0.5864
Batch 260, Loss: 0.5546
Batch 270, Loss: 0.5303
Batch 280, Loss: 0.5475
Batch 290, Loss: 0.5857
Batch 300, Loss: 0.5726
Batch 310, Loss: 0.5838
Batch 320, Loss: 0.5370
Batch 330, Loss: 0.5741
Batch 340, Loss: 0.5667
Batch 350, Loss: 0.5593
Batch 360, Loss: 0.5382
Batch 370, Loss: 0.5454
Batch 380, Loss: 0.5550
Batch 390, Loss: 0.5300
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 24.967514038085938 seconds
Epoch 41 accuracy: 79.68%
Batch 10, Loss: 0.5305
Batch 20, Loss: 0.5558
Batch 30, Loss: 0.5321
Batch 40, Loss: 0.5523
Batch 50, Loss: 0.5481
Batch 60, Loss: 0.5275
Batch 70, Loss: 0.5576
Batch 80, Loss: 0.5832
Batch 90, Loss: 0.5519
Batch 100, Loss: 0.5651
Batch 110, Loss: 0.5462
Batch 120, Loss: 0.5519
Batch 130, Loss: 0.5779
Batch 140, Loss: 0.5601
Batch 150, Loss: 0.5837
Batch 160, Loss: 0.5771
Batch 170, Loss: 0.5427
Batch 180, Loss: 0.5715
Batch 190, Loss: 0.5529
Batch 200, Loss: 0.5478
Batch 210, Loss: 0.5726
Batch 220, Loss: 0.5197
Batch 230, Loss: 0.5787
Batch 240, Loss: 0.5736
Batch 250, Loss: 0.5690
Batch 260, Loss: 0.5518
Batch 270, Loss: 0.5934
Batch 280, Loss: 0.5490
Batch 290, Loss: 0.6246
Batch 300, Loss: 0.5679
Batch 310, Loss: 0.5173
Batch 320, Loss: 0.5677
Batch 330, Loss: 0.5280
Batch 340, Loss: 0.6065
Batch 350, Loss: 0.5896
Batch 360, Loss: 0.5668
Batch 370, Loss: 0.5666
Batch 380, Loss: 0.5323
Batch 390, Loss: 0.5745
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 24.9130277633667 seconds
Epoch 42 accuracy: 82.38%
Batch 10, Loss: 0.5006
Batch 20, Loss: 0.5029
Batch 30, Loss: 0.5094
Batch 40, Loss: 0.5719
Batch 50, Loss: 0.5609
Batch 60, Loss: 0.6108
Batch 70, Loss: 0.5186
Batch 80, Loss: 0.5271
Batch 90, Loss: 0.5422
Batch 100, Loss: 0.5617
Batch 110, Loss: 0.5299
Batch 120, Loss: 0.5378
Batch 130, Loss: 0.5621
Batch 140, Loss: 0.5386
Batch 150, Loss: 0.5713
Batch 160, Loss: 0.5650
Batch 170, Loss: 0.5100
Batch 180, Loss: 0.5969
Batch 190, Loss: 0.5625
Batch 200, Loss: 0.5853
Batch 210, Loss: 0.5611
Batch 220, Loss: 0.5775
Batch 230, Loss: 0.5676
Batch 240, Loss: 0.5750
Batch 250, Loss: 0.5411
Batch 260, Loss: 0.5176
Batch 270, Loss: 0.5596
Batch 280, Loss: 0.5628
Batch 290, Loss: 0.5433
Batch 300, Loss: 0.5506
Batch 310, Loss: 0.5559
Batch 320, Loss: 0.5519
Batch 330, Loss: 0.6012
Batch 340, Loss: 0.5642
Batch 350, Loss: 0.5392
Batch 360, Loss: 0.5070
Batch 370, Loss: 0.5526
Batch 380, Loss: 0.5525
Batch 390, Loss: 0.5582
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 24.922391414642334 seconds
Epoch 43 accuracy: 83.6%
Batch 10, Loss: 0.5634
Batch 20, Loss: 0.5400
Batch 30, Loss: 0.5550
Batch 40, Loss: 0.5503
Batch 50, Loss: 0.5138
Batch 60, Loss: 0.5297
Batch 70, Loss: 0.5486
Batch 80, Loss: 0.5452
Batch 90, Loss: 0.5234
Batch 100, Loss: 0.5787
Batch 110, Loss: 0.5445
Batch 120, Loss: 0.5447
Batch 130, Loss: 0.5678
Batch 140, Loss: 0.5286
Batch 150, Loss: 0.5527
Batch 160, Loss: 0.5418
Batch 170, Loss: 0.5000
Batch 180, Loss: 0.5320
Batch 190, Loss: 0.5860
Batch 200, Loss: 0.5958
Batch 210, Loss: 0.5724
Batch 220, Loss: 0.5606
Batch 230, Loss: 0.5636
Batch 240, Loss: 0.5524
Batch 250, Loss: 0.5285
Batch 260, Loss: 0.5556
Batch 270, Loss: 0.5800
Batch 280, Loss: 0.5178
Batch 290, Loss: 0.5463
Batch 300, Loss: 0.4978
Batch 310, Loss: 0.5552
Batch 320, Loss: 0.5683
Batch 330, Loss: 0.5489
Batch 340, Loss: 0.5330
Batch 350, Loss: 0.5390
Batch 360, Loss: 0.5816
Batch 370, Loss: 0.5873
Batch 380, Loss: 0.5710
Batch 390, Loss: 0.5424
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 24.950929164886475 seconds
Epoch 44 accuracy: 84.02%
Batch 10, Loss: 0.5385
Batch 20, Loss: 0.5303
Batch 30, Loss: 0.5800
Batch 40, Loss: 0.5512
Batch 50, Loss: 0.5257
Batch 60, Loss: 0.5208
Batch 70, Loss: 0.5124
Batch 80, Loss: 0.5343
Batch 90, Loss: 0.5491
Batch 100, Loss: 0.5646
Batch 110, Loss: 0.5865
Batch 120, Loss: 0.5282
Batch 130, Loss: 0.5329
Batch 140, Loss: 0.5199
Batch 150, Loss: 0.5427
Batch 160, Loss: 0.5570
Batch 170, Loss: 0.5335
Batch 180, Loss: 0.5418
Batch 190, Loss: 0.5436
Batch 200, Loss: 0.5677
Batch 210, Loss: 0.5340
Batch 220, Loss: 0.5421
Batch 230, Loss: 0.5631
Batch 240, Loss: 0.5451
Batch 250, Loss: 0.5500
Batch 260, Loss: 0.5571
Batch 270, Loss: 0.5963
Batch 280, Loss: 0.5447
Batch 290, Loss: 0.5547
Batch 300, Loss: 0.5706
Batch 310, Loss: 0.5447
Batch 320, Loss: 0.5616
Batch 330, Loss: 0.6129
Batch 340, Loss: 0.5915
Batch 350, Loss: 0.5720
Batch 360, Loss: 0.5689
Batch 370, Loss: 0.5364
Batch 380, Loss: 0.5549
Batch 390, Loss: 0.4885
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 24.93788504600525 seconds
Epoch 45 accuracy: 83.36%
Batch 10, Loss: 0.5635
Batch 20, Loss: 0.5384
Batch 30, Loss: 0.5563
Batch 40, Loss: 0.5456
Batch 50, Loss: 0.5364
Batch 60, Loss: 0.5380
Batch 70, Loss: 0.5315
Batch 80, Loss: 0.5420
Batch 90, Loss: 0.5644
Batch 100, Loss: 0.5654
Batch 110, Loss: 0.5484
Batch 120, Loss: 0.5115
Batch 130, Loss: 0.5515
Batch 140, Loss: 0.5453
Batch 150, Loss: 0.5461
Batch 160, Loss: 0.5355
Batch 170, Loss: 0.5758
Batch 180, Loss: 0.5359
Batch 190, Loss: 0.5493
Batch 200, Loss: 0.5281
Batch 210, Loss: 0.5673
Batch 220, Loss: 0.5007
Batch 230, Loss: 0.5435
Batch 240, Loss: 0.5624
Batch 250, Loss: 0.5837
Batch 260, Loss: 0.6013
Batch 270, Loss: 0.5792
Batch 280, Loss: 0.5691
Batch 290, Loss: 0.5614
Batch 300, Loss: 0.5282
Batch 310, Loss: 0.5665
Batch 320, Loss: 0.5818
Batch 330, Loss: 0.5716
Batch 340, Loss: 0.5306
Batch 350, Loss: 0.5342
Batch 360, Loss: 0.5502
Batch 370, Loss: 0.5511
Batch 380, Loss: 0.5839
Batch 390, Loss: 0.5439
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 24.881000757217407 seconds
Epoch 46 accuracy: 83.12%
Batch 10, Loss: 0.5406
Batch 20, Loss: 0.5073
Batch 30, Loss: 0.5618
Batch 40, Loss: 0.5686
Batch 50, Loss: 0.5667
Batch 60, Loss: 0.5496
Batch 70, Loss: 0.5769
Batch 80, Loss: 0.5593
Batch 90, Loss: 0.5875
Batch 100, Loss: 0.5172
Batch 110, Loss: 0.5278
Batch 120, Loss: 0.5805
Batch 130, Loss: 0.5864
Batch 140, Loss: 0.5332
Batch 150, Loss: 0.5182
Batch 160, Loss: 0.5580
Batch 170, Loss: 0.5359
Batch 180, Loss: 0.5544
Batch 190, Loss: 0.5570
Batch 200, Loss: 0.5534
Batch 210, Loss: 0.4962
Batch 220, Loss: 0.5334
Batch 230, Loss: 0.5656
Batch 240, Loss: 0.5214
Batch 250, Loss: 0.5347
Batch 260, Loss: 0.5418
Batch 270, Loss: 0.5725
Batch 280, Loss: 0.5288
Batch 290, Loss: 0.5280
Batch 300, Loss: 0.5556
Batch 310, Loss: 0.6024
Batch 320, Loss: 0.5101
Batch 330, Loss: 0.5682
Batch 340, Loss: 0.5469
Batch 350, Loss: 0.5660
Batch 360, Loss: 0.5302
Batch 370, Loss: 0.5293
Batch 380, Loss: 0.5912
Batch 390, Loss: 0.5518
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 24.89772129058838 seconds
Epoch 47 accuracy: 83.68%
Batch 10, Loss: 0.5426
Batch 20, Loss: 0.5318
Batch 30, Loss: 0.5525
Batch 40, Loss: 0.5560
Batch 50, Loss: 0.5392
Batch 60, Loss: 0.5314
Batch 70, Loss: 0.5135
Batch 80, Loss: 0.5522
Batch 90, Loss: 0.5111
Batch 100, Loss: 0.5512
Batch 110, Loss: 0.5449
Batch 120, Loss: 0.5813
Batch 130, Loss: 0.5158
Batch 140, Loss: 0.5353
Batch 150, Loss: 0.5819
Batch 160, Loss: 0.5557
Batch 170, Loss: 0.5446
Batch 180, Loss: 0.5701
Batch 190, Loss: 0.5694
Batch 200, Loss: 0.5498
Batch 210, Loss: 0.5457
Batch 220, Loss: 0.5238
Batch 230, Loss: 0.5664
Batch 240, Loss: 0.5788
Batch 250, Loss: 0.5452
Batch 260, Loss: 0.5399
Batch 270, Loss: 0.5594
Batch 280, Loss: 0.5474
Batch 290, Loss: 0.5418
Batch 300, Loss: 0.5400
Batch 310, Loss: 0.5693
Batch 320, Loss: 0.5298
Batch 330, Loss: 0.5161
Batch 340, Loss: 0.5910
Batch 350, Loss: 0.5472
Batch 360, Loss: 0.5846
Batch 370, Loss: 0.5671
Batch 380, Loss: 0.4855
Batch 390, Loss: 0.5163
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 24.96766471862793 seconds
Epoch 48 accuracy: 82.08%
Batch 10, Loss: 0.5756
Batch 20, Loss: 0.5408
Batch 30, Loss: 0.5409
Batch 40, Loss: 0.5303
Batch 50, Loss: 0.5529
Batch 60, Loss: 0.5185
Batch 70, Loss: 0.4846
Batch 80, Loss: 0.5323
Batch 90, Loss: 0.5527
Batch 100, Loss: 0.5098
Batch 110, Loss: 0.5363
Batch 120, Loss: 0.5857
Batch 130, Loss: 0.5539
Batch 140, Loss: 0.5453
Batch 150, Loss: 0.5358
Batch 160, Loss: 0.5321
Batch 170, Loss: 0.5379
Batch 180, Loss: 0.5341
Batch 190, Loss: 0.5663
Batch 200, Loss: 0.5403
Batch 210, Loss: 0.5888
Batch 220, Loss: 0.5229
Batch 230, Loss: 0.5463
Batch 240, Loss: 0.5329
Batch 250, Loss: 0.5349
Batch 260, Loss: 0.5859
Batch 270, Loss: 0.5627
Batch 280, Loss: 0.5312
Batch 290, Loss: 0.5057
Batch 300, Loss: 0.5427
Batch 310, Loss: 0.5383
Batch 320, Loss: 0.5586
Batch 330, Loss: 0.5168
Batch 340, Loss: 0.5440
Batch 350, Loss: 0.5381
Batch 360, Loss: 0.5193
Batch 370, Loss: 0.5580
Batch 380, Loss: 0.5752
Batch 390, Loss: 0.5463
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 24.88076877593994 seconds
Epoch 49 accuracy: 81.98%
Batch 10, Loss: 0.5726
Batch 20, Loss: 0.5434
Batch 30, Loss: 0.5387
Batch 40, Loss: 0.5289
Batch 50, Loss: 0.5092
Batch 60, Loss: 0.4987
Batch 70, Loss: 0.5590
Batch 80, Loss: 0.5556
Batch 90, Loss: 0.5615
Batch 100, Loss: 0.5223
Batch 110, Loss: 0.5620
Batch 120, Loss: 0.5305
Batch 130, Loss: 0.5368
Batch 140, Loss: 0.5058
Batch 150, Loss: 0.5572
Batch 160, Loss: 0.5417
Batch 170, Loss: 0.5437
Batch 180, Loss: 0.5414
Batch 190, Loss: 0.5638
Batch 200, Loss: 0.5483
Batch 210, Loss: 0.5426
Batch 220, Loss: 0.5135
Batch 230, Loss: 0.5366
Batch 240, Loss: 0.5344
Batch 250, Loss: 0.5501
Batch 260, Loss: 0.5158
Batch 270, Loss: 0.5535
Batch 280, Loss: 0.5677
Batch 290, Loss: 0.5248
Batch 300, Loss: 0.5594
Batch 310, Loss: 0.5587
Batch 320, Loss: 0.5465
Batch 330, Loss: 0.5304
Batch 340, Loss: 0.5127
Batch 350, Loss: 0.4962
Batch 360, Loss: 0.5231
Batch 370, Loss: 0.5646
Batch 380, Loss: 0.5138
Batch 390, Loss: 0.5496
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 24.87407684326172 seconds
Epoch 50 accuracy: 82.53%
Batch 10, Loss: 0.4983
Batch 20, Loss: 0.5118
Batch 30, Loss: 0.5702
Batch 40, Loss: 0.5503
Batch 50, Loss: 0.6058
Batch 60, Loss: 0.5462
Batch 70, Loss: 0.5157
Batch 80, Loss: 0.5377
Batch 90, Loss: 0.5733
Batch 100, Loss: 0.5242
Batch 110, Loss: 0.5021
Batch 120, Loss: 0.5146
Batch 130, Loss: 0.5011
Batch 140, Loss: 0.5563
Batch 150, Loss: 0.5415
Batch 160, Loss: 0.4958
Batch 170, Loss: 0.5490
Batch 180, Loss: 0.5516
Batch 190, Loss: 0.5268
Batch 200, Loss: 0.5194
Batch 210, Loss: 0.5019
Batch 220, Loss: 0.5436
Batch 230, Loss: 0.5592
Batch 240, Loss: 0.5453
Batch 250, Loss: 0.5651
Batch 260, Loss: 0.5134
Batch 270, Loss: 0.5177
Batch 280, Loss: 0.5638
Batch 290, Loss: 0.5624
Batch 300, Loss: 0.5086
Batch 310, Loss: 0.5823
Batch 320, Loss: 0.5686
Batch 330, Loss: 0.5615
Batch 340, Loss: 0.5526
Batch 350, Loss: 0.5636
Batch 360, Loss: 0.5365
Batch 370, Loss: 0.5361
Batch 380, Loss: 0.5446
Batch 390, Loss: 0.5353
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 24.930301666259766 seconds
Epoch 51 accuracy: 80.35%
Batch 10, Loss: 0.5126
Batch 20, Loss: 0.5121
Batch 30, Loss: 0.5145
Batch 40, Loss: 0.5393
Batch 50, Loss: 0.5430
Batch 60, Loss: 0.5192
Batch 70, Loss: 0.5609
Batch 80, Loss: 0.5339
Batch 90, Loss: 0.5467
Batch 100, Loss: 0.5062
Batch 110, Loss: 0.5889
Batch 120, Loss: 0.5638
Batch 130, Loss: 0.5570
Batch 140, Loss: 0.5262
Batch 150, Loss: 0.5315
Batch 160, Loss: 0.5359
Batch 170, Loss: 0.5521
Batch 180, Loss: 0.5466
Batch 190, Loss: 0.5448
Batch 200, Loss: 0.5756
Batch 210, Loss: 0.5528
Batch 220, Loss: 0.5371
Batch 230, Loss: 0.4765
Batch 240, Loss: 0.5470
Batch 250, Loss: 0.5354
Batch 260, Loss: 0.5426
Batch 270, Loss: 0.5123
Batch 280, Loss: 0.5415
Batch 290, Loss: 0.5501
Batch 300, Loss: 0.5409
Batch 310, Loss: 0.5822
Batch 320, Loss: 0.5390
Batch 330, Loss: 0.5100
Batch 340, Loss: 0.5528
Batch 350, Loss: 0.5371
Batch 360, Loss: 0.5355
Batch 370, Loss: 0.5394
Batch 380, Loss: 0.5692
Batch 390, Loss: 0.5299
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 24.93978714942932 seconds
Epoch 52 accuracy: 84.73%
Batch 10, Loss: 0.5352
Batch 20, Loss: 0.5452
Batch 30, Loss: 0.5259
Batch 40, Loss: 0.4775
Batch 50, Loss: 0.4931
Batch 60, Loss: 0.5711
Batch 70, Loss: 0.5578
Batch 80, Loss: 0.4963
Batch 90, Loss: 0.4673
Batch 100, Loss: 0.5230
Batch 110, Loss: 0.5268
Batch 120, Loss: 0.5853
Batch 130, Loss: 0.5278
Batch 140, Loss: 0.5128
Batch 150, Loss: 0.5027
Batch 160, Loss: 0.5328
Batch 170, Loss: 0.5137
Batch 180, Loss: 0.5358
Batch 190, Loss: 0.5501
Batch 200, Loss: 0.5276
Batch 210, Loss: 0.5364
Batch 220, Loss: 0.5374
Batch 230, Loss: 0.5338
Batch 240, Loss: 0.5805
Batch 250, Loss: 0.5281
Batch 260, Loss: 0.4908
Batch 270, Loss: 0.5677
Batch 280, Loss: 0.5204
Batch 290, Loss: 0.5253
Batch 300, Loss: 0.5539
Batch 310, Loss: 0.5227
Batch 320, Loss: 0.5593
Batch 330, Loss: 0.5325
Batch 340, Loss: 0.4976
Batch 350, Loss: 0.5227
Batch 360, Loss: 0.5450
Batch 370, Loss: 0.5430
Batch 380, Loss: 0.5478
Batch 390, Loss: 0.5231
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 24.90958571434021 seconds
Epoch 53 accuracy: 83.67%
Batch 10, Loss: 0.5495
Batch 20, Loss: 0.5420
Batch 30, Loss: 0.5381
Batch 40, Loss: 0.5106
Batch 50, Loss: 0.5807
Batch 60, Loss: 0.5257
Batch 70, Loss: 0.5311
Batch 80, Loss: 0.5380
Batch 90, Loss: 0.4942
Batch 100, Loss: 0.4918
Batch 110, Loss: 0.5262
Batch 120, Loss: 0.5345
Batch 130, Loss: 0.5809
Batch 140, Loss: 0.5603
Batch 150, Loss: 0.5608
Batch 160, Loss: 0.5511
Batch 170, Loss: 0.5117
Batch 180, Loss: 0.5119
Batch 190, Loss: 0.5849
Batch 200, Loss: 0.4990
Batch 210, Loss: 0.5385
Batch 220, Loss: 0.5383
Batch 230, Loss: 0.5273
Batch 240, Loss: 0.5312
Batch 250, Loss: 0.5465
Batch 260, Loss: 0.5136
Batch 270, Loss: 0.5305
Batch 280, Loss: 0.4764
Batch 290, Loss: 0.5497
Batch 300, Loss: 0.5474
Batch 310, Loss: 0.5690
Batch 320, Loss: 0.5245
Batch 330, Loss: 0.5095
Batch 340, Loss: 0.5668
Batch 350, Loss: 0.5526
Batch 360, Loss: 0.5649
Batch 370, Loss: 0.5421
Batch 380, Loss: 0.5450
Batch 390, Loss: 0.5173
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 24.96659517288208 seconds
Epoch 54 accuracy: 81.61%
Batch 10, Loss: 0.5085
Batch 20, Loss: 0.5362
Batch 30, Loss: 0.5288
Batch 40, Loss: 0.5078
Batch 50, Loss: 0.5409
Batch 60, Loss: 0.5390
Batch 70, Loss: 0.5387
Batch 80, Loss: 0.5154
Batch 90, Loss: 0.5486
Batch 100, Loss: 0.5172
Batch 110, Loss: 0.5009
Batch 120, Loss: 0.5529
Batch 130, Loss: 0.5509
Batch 140, Loss: 0.4976
Batch 150, Loss: 0.5572
Batch 160, Loss: 0.5000
Batch 170, Loss: 0.4978
Batch 180, Loss: 0.5371
Batch 190, Loss: 0.5389
Batch 200, Loss: 0.5089
Batch 210, Loss: 0.5152
Batch 220, Loss: 0.5571
Batch 230, Loss: 0.5319
Batch 240, Loss: 0.5058
Batch 250, Loss: 0.5180
Batch 260, Loss: 0.5628
Batch 270, Loss: 0.5448
Batch 280, Loss: 0.5310
Batch 290, Loss: 0.5373
Batch 300, Loss: 0.5683
Batch 310, Loss: 0.5367
Batch 320, Loss: 0.5431
Batch 330, Loss: 0.5196
Batch 340, Loss: 0.5175
Batch 350, Loss: 0.5431
Batch 360, Loss: 0.4988
Batch 370, Loss: 0.5465
Batch 380, Loss: 0.5018
Batch 390, Loss: 0.5203
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 24.92351269721985 seconds
Epoch 55 accuracy: 80.51%
Batch 10, Loss: 0.5209
Batch 20, Loss: 0.5766
Batch 30, Loss: 0.5442
Batch 40, Loss: 0.5197
Batch 50, Loss: 0.5062
Batch 60, Loss: 0.5118
Batch 70, Loss: 0.5540
Batch 80, Loss: 0.5538
Batch 90, Loss: 0.5024
Batch 100, Loss: 0.5287
Batch 110, Loss: 0.5198
Batch 120, Loss: 0.5114
Batch 130, Loss: 0.4850
Batch 140, Loss: 0.5176
Batch 150, Loss: 0.5601
Batch 160, Loss: 0.5522
Batch 170, Loss: 0.5795
Batch 180, Loss: 0.5258
Batch 190, Loss: 0.5224
Batch 200, Loss: 0.5273
Batch 210, Loss: 0.5219
Batch 220, Loss: 0.5385
Batch 230, Loss: 0.5554
Batch 240, Loss: 0.5370
Batch 250, Loss: 0.5110
Batch 260, Loss: 0.5452
Batch 270, Loss: 0.5040
Batch 280, Loss: 0.5536
Batch 290, Loss: 0.5174
Batch 300, Loss: 0.5529
Batch 310, Loss: 0.4808
Batch 320, Loss: 0.5166
Batch 330, Loss: 0.5193
Batch 340, Loss: 0.5474
Batch 350, Loss: 0.5719
Batch 360, Loss: 0.5362
Batch 370, Loss: 0.5227
Batch 380, Loss: 0.5279
Batch 390, Loss: 0.5487
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 24.95030641555786 seconds
Epoch 56 accuracy: 77.5%
Batch 10, Loss: 0.5403
Batch 20, Loss: 0.4959
Batch 30, Loss: 0.5528
Batch 40, Loss: 0.5195
Batch 50, Loss: 0.5027
Batch 60, Loss: 0.5304
Batch 70, Loss: 0.5111
Batch 80, Loss: 0.5605
Batch 90, Loss: 0.5116
Batch 100, Loss: 0.5512
Batch 110, Loss: 0.5044
Batch 120, Loss: 0.4921
Batch 130, Loss: 0.5343
Batch 140, Loss: 0.5212
Batch 150, Loss: 0.5440
Batch 160, Loss: 0.5234
Batch 170, Loss: 0.5183
Batch 180, Loss: 0.5448
Batch 190, Loss: 0.5088
Batch 200, Loss: 0.5026
Batch 210, Loss: 0.5127
Batch 220, Loss: 0.5352
Batch 230, Loss: 0.5322
Batch 240, Loss: 0.5448
Batch 250, Loss: 0.5314
Batch 260, Loss: 0.5303
Batch 270, Loss: 0.5404
Batch 280, Loss: 0.5350
Batch 290, Loss: 0.5413
Batch 300, Loss: 0.5172
Batch 310, Loss: 0.5122
Batch 320, Loss: 0.4998
Batch 330, Loss: 0.5368
Batch 340, Loss: 0.5809
Batch 350, Loss: 0.5366
Batch 360, Loss: 0.5532
Batch 370, Loss: 0.5544
Batch 380, Loss: 0.5356
Batch 390, Loss: 0.5283
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 24.932898998260498 seconds
Epoch 57 accuracy: 84.09%
Batch 10, Loss: 0.5280
Batch 20, Loss: 0.4995
Batch 30, Loss: 0.5148
Batch 40, Loss: 0.5390
Batch 50, Loss: 0.5823
Batch 60, Loss: 0.5374
Batch 70, Loss: 0.4559
Batch 80, Loss: 0.5395
Batch 90, Loss: 0.5210
Batch 100, Loss: 0.5114
Batch 110, Loss: 0.5143
Batch 120, Loss: 0.5143
Batch 130, Loss: 0.5074
Batch 140, Loss: 0.5031
Batch 150, Loss: 0.5123
Batch 160, Loss: 0.5026
Batch 170, Loss: 0.5414
Batch 180, Loss: 0.5392
Batch 190, Loss: 0.5349
Batch 200, Loss: 0.5366
Batch 210, Loss: 0.5673
Batch 220, Loss: 0.5226
Batch 230, Loss: 0.5570
Batch 240, Loss: 0.5382
Batch 250, Loss: 0.5434
Batch 260, Loss: 0.5438
Batch 270, Loss: 0.5358
Batch 280, Loss: 0.5217
Batch 290, Loss: 0.5480
Batch 300, Loss: 0.5357
Batch 310, Loss: 0.5268
Batch 320, Loss: 0.5350
Batch 330, Loss: 0.5311
Batch 340, Loss: 0.5413
Batch 350, Loss: 0.5500
Batch 360, Loss: 0.5274
Batch 370, Loss: 0.4899
Batch 380, Loss: 0.4961
Batch 390, Loss: 0.5449
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.001432418823242 seconds
Epoch 58 accuracy: 79.11%
Batch 10, Loss: 0.5380
Batch 20, Loss: 0.5307
Batch 30, Loss: 0.5213
Batch 40, Loss: 0.5180
Batch 50, Loss: 0.4762
Batch 60, Loss: 0.5227
Batch 70, Loss: 0.5299
Batch 80, Loss: 0.5300
Batch 90, Loss: 0.5497
Batch 100, Loss: 0.5431
Batch 110, Loss: 0.5250
Batch 120, Loss: 0.5005
Batch 130, Loss: 0.5041
Batch 140, Loss: 0.5507
Batch 150, Loss: 0.5271
Batch 160, Loss: 0.5040
Batch 170, Loss: 0.5248
Batch 180, Loss: 0.4955
Batch 190, Loss: 0.4962
Batch 200, Loss: 0.5438
Batch 210, Loss: 0.5145
Batch 220, Loss: 0.5505
Batch 230, Loss: 0.4957
Batch 240, Loss: 0.5406
Batch 250, Loss: 0.5095
Batch 260, Loss: 0.5353
Batch 270, Loss: 0.5123
Batch 280, Loss: 0.5384
Batch 290, Loss: 0.5506
Batch 300, Loss: 0.5285
Batch 310, Loss: 0.5333
Batch 320, Loss: 0.5488
Batch 330, Loss: 0.5093
Batch 340, Loss: 0.5356
Batch 350, Loss: 0.5031
Batch 360, Loss: 0.4849
Batch 370, Loss: 0.5164
Batch 380, Loss: 0.5478
Batch 390, Loss: 0.5154
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 24.995651721954346 seconds
Epoch 59 accuracy: 79.15%
Batch 10, Loss: 0.5084
Batch 20, Loss: 0.4836
Batch 30, Loss: 0.5178
Batch 40, Loss: 0.5201
Batch 50, Loss: 0.5193
Batch 60, Loss: 0.5111
Batch 70, Loss: 0.4690
Batch 80, Loss: 0.5330
Batch 90, Loss: 0.5367
Batch 100, Loss: 0.5094
Batch 110, Loss: 0.5502
Batch 120, Loss: 0.5571
Batch 130, Loss: 0.5243
Batch 140, Loss: 0.5518
Batch 150, Loss: 0.5205
Batch 160, Loss: 0.5343
Batch 170, Loss: 0.5351
Batch 180, Loss: 0.5026
Batch 190, Loss: 0.5092
Batch 200, Loss: 0.5219
Batch 210, Loss: 0.4991
Batch 220, Loss: 0.5210
Batch 230, Loss: 0.5086
Batch 240, Loss: 0.5492
Batch 250, Loss: 0.5671
Batch 260, Loss: 0.5083
Batch 270, Loss: 0.5397
Batch 280, Loss: 0.5386
Batch 290, Loss: 0.5521
Batch 300, Loss: 0.5182
Batch 310, Loss: 0.5293
Batch 320, Loss: 0.5273
Batch 330, Loss: 0.5462
Batch 340, Loss: 0.4826
Batch 350, Loss: 0.5103
Batch 360, Loss: 0.5325
Batch 370, Loss: 0.5088
Batch 380, Loss: 0.4959
Batch 390, Loss: 0.4906
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 24.929192304611206 seconds
Epoch 60 accuracy: 82.7%
Batch 10, Loss: 0.5393
Batch 20, Loss: 0.5188
Batch 30, Loss: 0.5653
Batch 40, Loss: 0.5300
Batch 50, Loss: 0.5191
Batch 60, Loss: 0.5238
Batch 70, Loss: 0.5066
Batch 80, Loss: 0.5526
Batch 90, Loss: 0.5598
Batch 100, Loss: 0.5586
Batch 110, Loss: 0.5256
Batch 120, Loss: 0.5343
Batch 130, Loss: 0.5106
Batch 140, Loss: 0.5219
Batch 150, Loss: 0.5201
Batch 160, Loss: 0.4908
Batch 170, Loss: 0.5344
Batch 180, Loss: 0.5361
Batch 190, Loss: 0.5051
Batch 200, Loss: 0.4790
Batch 210, Loss: 0.5499
Batch 220, Loss: 0.5248
Batch 230, Loss: 0.4972
Batch 240, Loss: 0.4964
Batch 250, Loss: 0.4792
Batch 260, Loss: 0.5448
Batch 270, Loss: 0.5597
Batch 280, Loss: 0.5194
Batch 290, Loss: 0.5200
Batch 300, Loss: 0.5499
Batch 310, Loss: 0.5345
Batch 320, Loss: 0.5243
Batch 330, Loss: 0.5060
Batch 340, Loss: 0.4847
Batch 350, Loss: 0.5311
Batch 360, Loss: 0.5033
Batch 370, Loss: 0.5143
Batch 380, Loss: 0.5181
Batch 390, Loss: 0.5137
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 24.938050031661987 seconds
Epoch 61 accuracy: 82.98%
Batch 10, Loss: 0.5365
Batch 20, Loss: 0.5058
Batch 30, Loss: 0.5172
Batch 40, Loss: 0.5142
Batch 50, Loss: 0.5384
Batch 60, Loss: 0.5067
Batch 70, Loss: 0.5508
Batch 80, Loss: 0.5016
Batch 90, Loss: 0.5167
Batch 100, Loss: 0.4836
Batch 110, Loss: 0.4948
Batch 120, Loss: 0.5534
Batch 130, Loss: 0.5184
Batch 140, Loss: 0.4992
Batch 150, Loss: 0.5280
Batch 160, Loss: 0.5124
Batch 170, Loss: 0.5035
Batch 180, Loss: 0.5040
Batch 190, Loss: 0.5232
Batch 200, Loss: 0.5229
Batch 210, Loss: 0.5598
Batch 220, Loss: 0.5242
Batch 230, Loss: 0.5414
Batch 240, Loss: 0.5517
Batch 250, Loss: 0.5215
Batch 260, Loss: 0.5028
Batch 270, Loss: 0.4836
Batch 280, Loss: 0.5312
Batch 290, Loss: 0.5351
Batch 300, Loss: 0.5405
Batch 310, Loss: 0.5133
Batch 320, Loss: 0.5755
Batch 330, Loss: 0.5118
Batch 340, Loss: 0.5134
Batch 350, Loss: 0.5059
Batch 360, Loss: 0.5438
Batch 370, Loss: 0.4876
Batch 380, Loss: 0.4992
Batch 390, Loss: 0.5314
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 24.869725942611694 seconds
Epoch 62 accuracy: 85.65%
Batch 10, Loss: 0.4931
Batch 20, Loss: 0.5073
Batch 30, Loss: 0.5403
Batch 40, Loss: 0.5237
Batch 50, Loss: 0.5259
Batch 60, Loss: 0.5038
Batch 70, Loss: 0.5135
Batch 80, Loss: 0.4915
Batch 90, Loss: 0.5113
Batch 100, Loss: 0.4867
Batch 110, Loss: 0.4991
Batch 120, Loss: 0.5322
Batch 130, Loss: 0.5034
Batch 140, Loss: 0.5422
Batch 150, Loss: 0.5054
Batch 160, Loss: 0.4950
Batch 170, Loss: 0.5357
Batch 180, Loss: 0.5387
Batch 190, Loss: 0.5245
Batch 200, Loss: 0.5689
Batch 210, Loss: 0.5216
Batch 220, Loss: 0.5550
Batch 230, Loss: 0.5156
Batch 240, Loss: 0.5348
Batch 250, Loss: 0.5104
Batch 260, Loss: 0.5126
Batch 270, Loss: 0.4951
Batch 280, Loss: 0.4869
Batch 290, Loss: 0.4943
Batch 300, Loss: 0.5072
Batch 310, Loss: 0.5395
Batch 320, Loss: 0.5200
Batch 330, Loss: 0.4967
Batch 340, Loss: 0.5403
Batch 350, Loss: 0.5209
Batch 360, Loss: 0.5112
Batch 370, Loss: 0.5702
Batch 380, Loss: 0.5482
Batch 390, Loss: 0.4948
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 24.930502891540527 seconds
Epoch 63 accuracy: 86.29%
Batch 10, Loss: 0.5063
Batch 20, Loss: 0.5097
Batch 30, Loss: 0.4731
Batch 40, Loss: 0.4912
Batch 50, Loss: 0.4988
Batch 60, Loss: 0.5508
Batch 70, Loss: 0.5079
Batch 80, Loss: 0.5107
Batch 90, Loss: 0.5329
Batch 100, Loss: 0.5174
Batch 110, Loss: 0.5389
Batch 120, Loss: 0.4894
Batch 130, Loss: 0.4787
Batch 140, Loss: 0.5079
Batch 150, Loss: 0.4895
Batch 160, Loss: 0.5294
Batch 170, Loss: 0.5250
Batch 180, Loss: 0.5026
Batch 190, Loss: 0.5256
Batch 200, Loss: 0.4810
Batch 210, Loss: 0.5105
Batch 220, Loss: 0.5111
Batch 230, Loss: 0.5266
Batch 240, Loss: 0.5272
Batch 250, Loss: 0.5123
Batch 260, Loss: 0.4995
Batch 270, Loss: 0.5040
Batch 280, Loss: 0.5250
Batch 290, Loss: 0.5282
Batch 300, Loss: 0.4990
Batch 310, Loss: 0.5171
Batch 320, Loss: 0.4818
Batch 330, Loss: 0.5481
Batch 340, Loss: 0.5143
Batch 350, Loss: 0.5659
Batch 360, Loss: 0.5302
Batch 370, Loss: 0.4963
Batch 380, Loss: 0.4495
Batch 390, Loss: 0.4745
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 24.87821340560913 seconds
Epoch 64 accuracy: 87.02%
Batch 10, Loss: 0.5085
Batch 20, Loss: 0.5291
Batch 30, Loss: 0.5654
Batch 40, Loss: 0.5407
Batch 50, Loss: 0.5105
Batch 60, Loss: 0.5355
Batch 70, Loss: 0.5185
Batch 80, Loss: 0.5272
Batch 90, Loss: 0.4783
Batch 100, Loss: 0.5183
Batch 110, Loss: 0.4899
Batch 120, Loss: 0.4879
Batch 130, Loss: 0.5392
Batch 140, Loss: 0.5353
Batch 150, Loss: 0.5025
Batch 160, Loss: 0.5078
Batch 170, Loss: 0.5099
Batch 180, Loss: 0.4744
Batch 190, Loss: 0.4745
Batch 200, Loss: 0.5230
Batch 210, Loss: 0.5016
Batch 220, Loss: 0.5307
Batch 230, Loss: 0.5246
Batch 240, Loss: 0.4691
Batch 250, Loss: 0.4763
Batch 260, Loss: 0.5132
Batch 270, Loss: 0.5259
Batch 280, Loss: 0.5146
Batch 290, Loss: 0.5112
Batch 300, Loss: 0.5269
Batch 310, Loss: 0.5341
Batch 320, Loss: 0.5258
Batch 330, Loss: 0.5027
Batch 340, Loss: 0.5093
Batch 350, Loss: 0.5496
Batch 360, Loss: 0.4868
Batch 370, Loss: 0.4952
Batch 380, Loss: 0.5152
Batch 390, Loss: 0.4884
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 24.945319652557373 seconds
Epoch 65 accuracy: 83.31%
Batch 10, Loss: 0.5334
Batch 20, Loss: 0.4671
Batch 30, Loss: 0.4913
Batch 40, Loss: 0.5131
Batch 50, Loss: 0.5188
Batch 60, Loss: 0.5017
Batch 70, Loss: 0.4973
Batch 80, Loss: 0.4916
Batch 90, Loss: 0.5072
Batch 100, Loss: 0.5162
Batch 110, Loss: 0.4640
Batch 120, Loss: 0.4950
Batch 130, Loss: 0.4924
Batch 140, Loss: 0.4765
Batch 150, Loss: 0.4859
Batch 160, Loss: 0.5181
Batch 170, Loss: 0.5235
Batch 180, Loss: 0.4925
Batch 190, Loss: 0.5174
Batch 200, Loss: 0.5100
Batch 210, Loss: 0.5139
Batch 220, Loss: 0.4518
Batch 230, Loss: 0.4498
Batch 240, Loss: 0.4976
Batch 250, Loss: 0.4939
Batch 260, Loss: 0.5042
Batch 270, Loss: 0.5685
Batch 280, Loss: 0.5300
Batch 290, Loss: 0.5206
Batch 300, Loss: 0.5541
Batch 310, Loss: 0.5604
Batch 320, Loss: 0.5298
Batch 330, Loss: 0.5158
Batch 340, Loss: 0.5450
Batch 350, Loss: 0.5064
Batch 360, Loss: 0.5352
Batch 370, Loss: 0.5140
Batch 380, Loss: 0.5216
Batch 390, Loss: 0.5126
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 24.880686044692993 seconds
Epoch 66 accuracy: 85.2%
Batch 10, Loss: 0.5144
Batch 20, Loss: 0.4960
Batch 30, Loss: 0.4993
Batch 40, Loss: 0.4790
Batch 50, Loss: 0.5047
Batch 60, Loss: 0.5343
Batch 70, Loss: 0.5036
Batch 80, Loss: 0.5156
Batch 90, Loss: 0.4488
Batch 100, Loss: 0.5213
Batch 110, Loss: 0.5135
Batch 120, Loss: 0.5183
Batch 130, Loss: 0.5738
Batch 140, Loss: 0.5035
Batch 150, Loss: 0.5036
Batch 160, Loss: 0.4830
Batch 170, Loss: 0.5023
Batch 180, Loss: 0.4840
Batch 190, Loss: 0.5361
Batch 200, Loss: 0.4954
Batch 210, Loss: 0.5060
Batch 220, Loss: 0.4864
Batch 230, Loss: 0.4793
Batch 240, Loss: 0.5133
Batch 250, Loss: 0.5505
Batch 260, Loss: 0.4948
Batch 270, Loss: 0.4942
Batch 280, Loss: 0.4992
Batch 290, Loss: 0.5166
Batch 300, Loss: 0.4826
Batch 310, Loss: 0.5598
Batch 320, Loss: 0.4930
Batch 330, Loss: 0.4628
Batch 340, Loss: 0.5086
Batch 350, Loss: 0.5415
Batch 360, Loss: 0.5030
Batch 370, Loss: 0.5011
Batch 380, Loss: 0.5295
Batch 390, Loss: 0.5196
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 24.955792903900146 seconds
Epoch 67 accuracy: 85.11%
Batch 10, Loss: 0.5197
Batch 20, Loss: 0.4903
Batch 30, Loss: 0.5068
Batch 40, Loss: 0.4968
Batch 50, Loss: 0.5129
Batch 60, Loss: 0.4838
Batch 70, Loss: 0.5156
Batch 80, Loss: 0.5323
Batch 90, Loss: 0.4815
Batch 100, Loss: 0.4994
Batch 110, Loss: 0.4752
Batch 120, Loss: 0.4936
Batch 130, Loss: 0.5394
Batch 140, Loss: 0.5098
Batch 150, Loss: 0.5224
Batch 160, Loss: 0.4719
Batch 170, Loss: 0.4998
Batch 180, Loss: 0.4887
Batch 190, Loss: 0.5467
Batch 200, Loss: 0.4764
Batch 210, Loss: 0.5281
Batch 220, Loss: 0.4982
Batch 230, Loss: 0.4484
Batch 240, Loss: 0.5090
Batch 250, Loss: 0.5030
Batch 260, Loss: 0.4649
Batch 270, Loss: 0.5390
Batch 280, Loss: 0.5564
Batch 290, Loss: 0.4842
Batch 300, Loss: 0.5582
Batch 310, Loss: 0.5145
Batch 320, Loss: 0.4910
Batch 330, Loss: 0.5284
Batch 340, Loss: 0.4931
Batch 350, Loss: 0.4687
Batch 360, Loss: 0.5121
Batch 370, Loss: 0.5013
Batch 380, Loss: 0.4929
Batch 390, Loss: 0.4898
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.1072518825531 seconds
Epoch 68 accuracy: 82.5%
Batch 10, Loss: 0.4858
Batch 20, Loss: 0.5118
Batch 30, Loss: 0.4871
Batch 40, Loss: 0.4849
Batch 50, Loss: 0.4728
Batch 60, Loss: 0.4920
Batch 70, Loss: 0.5047
Batch 80, Loss: 0.5425
Batch 90, Loss: 0.4989
Batch 100, Loss: 0.4787
Batch 110, Loss: 0.4903
Batch 120, Loss: 0.4941
Batch 130, Loss: 0.4785
Batch 140, Loss: 0.5143
Batch 150, Loss: 0.4439
Batch 160, Loss: 0.4870
Batch 170, Loss: 0.5033
Batch 180, Loss: 0.5068
Batch 190, Loss: 0.5368
Batch 200, Loss: 0.4973
Batch 210, Loss: 0.5127
Batch 220, Loss: 0.4723
Batch 230, Loss: 0.5047
Batch 240, Loss: 0.5040
Batch 250, Loss: 0.4942
Batch 260, Loss: 0.5140
Batch 270, Loss: 0.4825
Batch 280, Loss: 0.4904
Batch 290, Loss: 0.5117
Batch 300, Loss: 0.5191
Batch 310, Loss: 0.5270
Batch 320, Loss: 0.5507
Batch 330, Loss: 0.4892
Batch 340, Loss: 0.4921
Batch 350, Loss: 0.4663
Batch 360, Loss: 0.5001
Batch 370, Loss: 0.5300
Batch 380, Loss: 0.4758
Batch 390, Loss: 0.5134
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 24.925593852996826 seconds
Epoch 69 accuracy: 85.23%
Batch 10, Loss: 0.4835
Batch 20, Loss: 0.5345
Batch 30, Loss: 0.5217
Batch 40, Loss: 0.5357
Batch 50, Loss: 0.4991
Batch 60, Loss: 0.4634
Batch 70, Loss: 0.5485
Batch 80, Loss: 0.5269
Batch 90, Loss: 0.5183
Batch 100, Loss: 0.4980
Batch 110, Loss: 0.4879
Batch 120, Loss: 0.4891
Batch 130, Loss: 0.4918
Batch 140, Loss: 0.5166
Batch 150, Loss: 0.5078
Batch 160, Loss: 0.4875
Batch 170, Loss: 0.4997
Batch 180, Loss: 0.5070
Batch 190, Loss: 0.5219
Batch 200, Loss: 0.5411
Batch 210, Loss: 0.4966
Batch 220, Loss: 0.5319
Batch 230, Loss: 0.4998
Batch 240, Loss: 0.4785
Batch 250, Loss: 0.4630
Batch 260, Loss: 0.4809
Batch 270, Loss: 0.4760
Batch 280, Loss: 0.5211
Batch 290, Loss: 0.4616
Batch 300, Loss: 0.5122
Batch 310, Loss: 0.5485
Batch 320, Loss: 0.4927
Batch 330, Loss: 0.4982
Batch 340, Loss: 0.5345
Batch 350, Loss: 0.4802
Batch 360, Loss: 0.4983
Batch 370, Loss: 0.5237
Batch 380, Loss: 0.5031
Batch 390, Loss: 0.5126
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.016445875167847 seconds
Epoch 70 accuracy: 84.15%
Batch 10, Loss: 0.5306
Batch 20, Loss: 0.4708
Batch 30, Loss: 0.5074
Batch 40, Loss: 0.4936
Batch 50, Loss: 0.5302
Batch 60, Loss: 0.5310
Batch 70, Loss: 0.5173
Batch 80, Loss: 0.5108
Batch 90, Loss: 0.4735
Batch 100, Loss: 0.4709
Batch 110, Loss: 0.4909
Batch 120, Loss: 0.5116
Batch 130, Loss: 0.4987
Batch 140, Loss: 0.4585
Batch 150, Loss: 0.4933
Batch 160, Loss: 0.5087
Batch 170, Loss: 0.4917
Batch 180, Loss: 0.5238
Batch 190, Loss: 0.4981
Batch 200, Loss: 0.5365
Batch 210, Loss: 0.4871
Batch 220, Loss: 0.4903
Batch 230, Loss: 0.4700
Batch 240, Loss: 0.5221
Batch 250, Loss: 0.5644
Batch 260, Loss: 0.5385
Batch 270, Loss: 0.5265
Batch 280, Loss: 0.4794
Batch 290, Loss: 0.5084
Batch 300, Loss: 0.5145
Batch 310, Loss: 0.5037
Batch 320, Loss: 0.5281
Batch 330, Loss: 0.5300
Batch 340, Loss: 0.5215
Batch 350, Loss: 0.5207
Batch 360, Loss: 0.4857
Batch 370, Loss: 0.4571
Batch 380, Loss: 0.5433
Batch 390, Loss: 0.5191
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 24.87681746482849 seconds
Epoch 71 accuracy: 86.71%
Batch 10, Loss: 0.5061
Batch 20, Loss: 0.5053
Batch 30, Loss: 0.4847
Batch 40, Loss: 0.5006
Batch 50, Loss: 0.5156
Batch 60, Loss: 0.5274
Batch 70, Loss: 0.5106
Batch 80, Loss: 0.4874
Batch 90, Loss: 0.4750
Batch 100, Loss: 0.5138
Batch 110, Loss: 0.5012
Batch 120, Loss: 0.4802
Batch 130, Loss: 0.5131
Batch 140, Loss: 0.4484
Batch 150, Loss: 0.4644
Batch 160, Loss: 0.4765
Batch 170, Loss: 0.5328
Batch 180, Loss: 0.5166
Batch 190, Loss: 0.5050
Batch 200, Loss: 0.4878
Batch 210, Loss: 0.4618
Batch 220, Loss: 0.5281
Batch 230, Loss: 0.4858
Batch 240, Loss: 0.4994
Batch 250, Loss: 0.5432
Batch 260, Loss: 0.5574
Batch 270, Loss: 0.5351
Batch 280, Loss: 0.5013
Batch 290, Loss: 0.4880
Batch 300, Loss: 0.5138
Batch 310, Loss: 0.4696
Batch 320, Loss: 0.5007
Batch 330, Loss: 0.4728
Batch 340, Loss: 0.5150
Batch 350, Loss: 0.5291
Batch 360, Loss: 0.4996
Batch 370, Loss: 0.5011
Batch 380, Loss: 0.4782
Batch 390, Loss: 0.5070
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 24.88884401321411 seconds
Epoch 72 accuracy: 85.62%
Batch 10, Loss: 0.4728
Batch 20, Loss: 0.4846
Batch 30, Loss: 0.5086
Batch 40, Loss: 0.4936
Batch 50, Loss: 0.5008
Batch 60, Loss: 0.4971
Batch 70, Loss: 0.4828
Batch 80, Loss: 0.4728
Batch 90, Loss: 0.5021
Batch 100, Loss: 0.5252
Batch 110, Loss: 0.4915
Batch 120, Loss: 0.5120
Batch 130, Loss: 0.5168
Batch 140, Loss: 0.4656
Batch 150, Loss: 0.5117
Batch 160, Loss: 0.4884
Batch 170, Loss: 0.4987
Batch 180, Loss: 0.5145
Batch 190, Loss: 0.4954
Batch 200, Loss: 0.4894
Batch 210, Loss: 0.4651
Batch 220, Loss: 0.4653
Batch 230, Loss: 0.4961
Batch 240, Loss: 0.4775
Batch 250, Loss: 0.4986
Batch 260, Loss: 0.4817
Batch 270, Loss: 0.4894
Batch 280, Loss: 0.4746
Batch 290, Loss: 0.5011
Batch 300, Loss: 0.4955
Batch 310, Loss: 0.5232
Batch 320, Loss: 0.5254
Batch 330, Loss: 0.4745
Batch 340, Loss: 0.4974
Batch 350, Loss: 0.5103
Batch 360, Loss: 0.4848
Batch 370, Loss: 0.4574
Batch 380, Loss: 0.5121
Batch 390, Loss: 0.4803
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 24.9614474773407 seconds
Epoch 73 accuracy: 85.59%
Batch 10, Loss: 0.4833
Batch 20, Loss: 0.4890
Batch 30, Loss: 0.4905
Batch 40, Loss: 0.4759
Batch 50, Loss: 0.5123
Batch 60, Loss: 0.4860
Batch 70, Loss: 0.5255
Batch 80, Loss: 0.4820
Batch 90, Loss: 0.4802
Batch 100, Loss: 0.5417
Batch 110, Loss: 0.5054
Batch 120, Loss: 0.4986
Batch 130, Loss: 0.5045
Batch 140, Loss: 0.5119
Batch 150, Loss: 0.4792
Batch 160, Loss: 0.4945
Batch 170, Loss: 0.4813
Batch 180, Loss: 0.5285
Batch 190, Loss: 0.5015
Batch 200, Loss: 0.4737
Batch 210, Loss: 0.4810
Batch 220, Loss: 0.5285
Batch 230, Loss: 0.4683
Batch 240, Loss: 0.5000
Batch 250, Loss: 0.4839
Batch 260, Loss: 0.4056
Batch 270, Loss: 0.4925
Batch 280, Loss: 0.4897
Batch 290, Loss: 0.4813
Batch 300, Loss: 0.5164
Batch 310, Loss: 0.5354
Batch 320, Loss: 0.4822
Batch 330, Loss: 0.4946
Batch 340, Loss: 0.4651
Batch 350, Loss: 0.4848
Batch 360, Loss: 0.4880
Batch 370, Loss: 0.5263
Batch 380, Loss: 0.4998
Batch 390, Loss: 0.4839
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 24.887975692749023 seconds
Epoch 74 accuracy: 86.66%
Batch 10, Loss: 0.4558
Batch 20, Loss: 0.4815
Batch 30, Loss: 0.4555
Batch 40, Loss: 0.4509
Batch 50, Loss: 0.4765
Batch 60, Loss: 0.4489
Batch 70, Loss: 0.5006
Batch 80, Loss: 0.4923
Batch 90, Loss: 0.4643
Batch 100, Loss: 0.4986
Batch 110, Loss: 0.5092
Batch 120, Loss: 0.4885
Batch 130, Loss: 0.4838
Batch 140, Loss: 0.4745
Batch 150, Loss: 0.5198
Batch 160, Loss: 0.5200
Batch 170, Loss: 0.5484
Batch 180, Loss: 0.5216
Batch 190, Loss: 0.4830
Batch 200, Loss: 0.5342
Batch 210, Loss: 0.4508
Batch 220, Loss: 0.5033
Batch 230, Loss: 0.5045
Batch 240, Loss: 0.5073
Batch 250, Loss: 0.5031
Batch 260, Loss: 0.5214
Batch 270, Loss: 0.5031
Batch 280, Loss: 0.5260
Batch 290, Loss: 0.4820
Batch 300, Loss: 0.4735
Batch 310, Loss: 0.4760
Batch 320, Loss: 0.5298
Batch 330, Loss: 0.4774
Batch 340, Loss: 0.4826
Batch 350, Loss: 0.4930
Batch 360, Loss: 0.5016
Batch 370, Loss: 0.5060
Batch 380, Loss: 0.5027
Batch 390, Loss: 0.5296
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 24.910773277282715 seconds
Epoch 75 accuracy: 86.07%
Batch 10, Loss: 0.4460
Batch 20, Loss: 0.4676
Batch 30, Loss: 0.5154
Batch 40, Loss: 0.4848
Batch 50, Loss: 0.4921
Batch 60, Loss: 0.5039
Batch 70, Loss: 0.5192
Batch 80, Loss: 0.5009
Batch 90, Loss: 0.4813
Batch 100, Loss: 0.5255
Batch 110, Loss: 0.4726
Batch 120, Loss: 0.5074
Batch 130, Loss: 0.5348
Batch 140, Loss: 0.5093
Batch 150, Loss: 0.4838
Batch 160, Loss: 0.4956
Batch 170, Loss: 0.4580
Batch 180, Loss: 0.5000
Batch 190, Loss: 0.4913
Batch 200, Loss: 0.4827
Batch 210, Loss: 0.4926
Batch 220, Loss: 0.5322
Batch 230, Loss: 0.4848
Batch 240, Loss: 0.4891
Batch 250, Loss: 0.4956
Batch 260, Loss: 0.5297
Batch 270, Loss: 0.4483
Batch 280, Loss: 0.4921
Batch 290, Loss: 0.4940
Batch 300, Loss: 0.4926
Batch 310, Loss: 0.4811
Batch 320, Loss: 0.4731
Batch 330, Loss: 0.5183
Batch 340, Loss: 0.4744
Batch 350, Loss: 0.4718
Batch 360, Loss: 0.4859
Batch 370, Loss: 0.5039
Batch 380, Loss: 0.5162
Batch 390, Loss: 0.4662
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 24.88691782951355 seconds
Epoch 76 accuracy: 86.35%
Batch 10, Loss: 0.4804
Batch 20, Loss: 0.4848
Batch 30, Loss: 0.5226
Batch 40, Loss: 0.4642
Batch 50, Loss: 0.4524
Batch 60, Loss: 0.4637
Batch 70, Loss: 0.4481
Batch 80, Loss: 0.4840
Batch 90, Loss: 0.4727
Batch 100, Loss: 0.4919
Batch 110, Loss: 0.4857
Batch 120, Loss: 0.4848
Batch 130, Loss: 0.5251
Batch 140, Loss: 0.4944
Batch 150, Loss: 0.4368
Batch 160, Loss: 0.4436
Batch 170, Loss: 0.5514
Batch 180, Loss: 0.4835
Batch 190, Loss: 0.4836
Batch 200, Loss: 0.4533
Batch 210, Loss: 0.5023
Batch 220, Loss: 0.4532
Batch 230, Loss: 0.4746
Batch 240, Loss: 0.4783
Batch 250, Loss: 0.5078
Batch 260, Loss: 0.5456
Batch 270, Loss: 0.5165
Batch 280, Loss: 0.4890
Batch 290, Loss: 0.4263
Batch 300, Loss: 0.4997
Batch 310, Loss: 0.5137
Batch 320, Loss: 0.5416
Batch 330, Loss: 0.4972
Batch 340, Loss: 0.5243
Batch 350, Loss: 0.4999
Batch 360, Loss: 0.4922
Batch 370, Loss: 0.4839
Batch 380, Loss: 0.4915
Batch 390, Loss: 0.4863
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 24.886937379837036 seconds
Epoch 77 accuracy: 86.6%
Batch 10, Loss: 0.4629
Batch 20, Loss: 0.4876
Batch 30, Loss: 0.4355
Batch 40, Loss: 0.4625
Batch 50, Loss: 0.4762
Batch 60, Loss: 0.5045
Batch 70, Loss: 0.4600
Batch 80, Loss: 0.4941
Batch 90, Loss: 0.4742
Batch 100, Loss: 0.4851
Batch 110, Loss: 0.5165
Batch 120, Loss: 0.4688
Batch 130, Loss: 0.5140
Batch 140, Loss: 0.4776
Batch 150, Loss: 0.4980
Batch 160, Loss: 0.4691
Batch 170, Loss: 0.4679
Batch 180, Loss: 0.4760
Batch 190, Loss: 0.5009
Batch 200, Loss: 0.4581
Batch 210, Loss: 0.4930
Batch 220, Loss: 0.4739
Batch 230, Loss: 0.4839
Batch 240, Loss: 0.5068
Batch 250, Loss: 0.5228
Batch 260, Loss: 0.5108
Batch 270, Loss: 0.4661
Batch 280, Loss: 0.4995
Batch 290, Loss: 0.4712
Batch 300, Loss: 0.4625
Batch 310, Loss: 0.4884
Batch 320, Loss: 0.4853
Batch 330, Loss: 0.5025
Batch 340, Loss: 0.4933
Batch 350, Loss: 0.4772
Batch 360, Loss: 0.4686
Batch 370, Loss: 0.4996
Batch 380, Loss: 0.4844
Batch 390, Loss: 0.4952
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 24.852513790130615 seconds
Epoch 78 accuracy: 82.5%
Batch 10, Loss: 0.4512
Batch 20, Loss: 0.4681
Batch 30, Loss: 0.4466
Batch 40, Loss: 0.4773
Batch 50, Loss: 0.4575
Batch 60, Loss: 0.5094
Batch 70, Loss: 0.4671
Batch 80, Loss: 0.4733
Batch 90, Loss: 0.4845
Batch 100, Loss: 0.4920
Batch 110, Loss: 0.4633
Batch 120, Loss: 0.4678
Batch 130, Loss: 0.4947
Batch 140, Loss: 0.5241
Batch 150, Loss: 0.5015
Batch 160, Loss: 0.5272
Batch 170, Loss: 0.4847
Batch 180, Loss: 0.5076
Batch 190, Loss: 0.4590
Batch 200, Loss: 0.4960
Batch 210, Loss: 0.4652
Batch 220, Loss: 0.4897
Batch 230, Loss: 0.4896
Batch 240, Loss: 0.5252
Batch 250, Loss: 0.5065
Batch 260, Loss: 0.4709
Batch 270, Loss: 0.4813
Batch 280, Loss: 0.4491
Batch 290, Loss: 0.4728
Batch 300, Loss: 0.5031
Batch 310, Loss: 0.5153
Batch 320, Loss: 0.4881
Batch 330, Loss: 0.5116
Batch 340, Loss: 0.5017
Batch 350, Loss: 0.4906
Batch 360, Loss: 0.4796
Batch 370, Loss: 0.5227
Batch 380, Loss: 0.4882
Batch 390, Loss: 0.5167
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 24.882877588272095 seconds
Epoch 79 accuracy: 86.43%
Batch 10, Loss: 0.5083
Batch 20, Loss: 0.5124
Batch 30, Loss: 0.5136
Batch 40, Loss: 0.5115
Batch 50, Loss: 0.5112
Batch 60, Loss: 0.4570
Batch 70, Loss: 0.4859
Batch 80, Loss: 0.4948
Batch 90, Loss: 0.4862
Batch 100, Loss: 0.4778
Batch 110, Loss: 0.4465
Batch 120, Loss: 0.5442
Batch 130, Loss: 0.4654
Batch 140, Loss: 0.4407
Batch 150, Loss: 0.4723
Batch 160, Loss: 0.4478
Batch 170, Loss: 0.4741
Batch 180, Loss: 0.4700
Batch 190, Loss: 0.4528
Batch 200, Loss: 0.4824
Batch 210, Loss: 0.4698
Batch 220, Loss: 0.4858
Batch 230, Loss: 0.4474
Batch 240, Loss: 0.4724
Batch 250, Loss: 0.4466
Batch 260, Loss: 0.4788
Batch 270, Loss: 0.4489
Batch 280, Loss: 0.4932
Batch 290, Loss: 0.4791
Batch 300, Loss: 0.5037
Batch 310, Loss: 0.5089
Batch 320, Loss: 0.4715
Batch 330, Loss: 0.4336
Batch 340, Loss: 0.4854
Batch 350, Loss: 0.4912
Batch 360, Loss: 0.4858
Batch 370, Loss: 0.4935
Batch 380, Loss: 0.5193
Batch 390, Loss: 0.4445
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 24.882206201553345 seconds
Epoch 80 accuracy: 86.64%
Batch 10, Loss: 0.4509
Batch 20, Loss: 0.4834
Batch 30, Loss: 0.5003
Batch 40, Loss: 0.4536
Batch 50, Loss: 0.4484
Batch 60, Loss: 0.5119
Batch 70, Loss: 0.4864
Batch 80, Loss: 0.5460
Batch 90, Loss: 0.4884
Batch 100, Loss: 0.4786
Batch 110, Loss: 0.4788
Batch 120, Loss: 0.4825
Batch 130, Loss: 0.4784
Batch 140, Loss: 0.4960
Batch 150, Loss: 0.5064
Batch 160, Loss: 0.5112
Batch 170, Loss: 0.4816
Batch 180, Loss: 0.4751
Batch 190, Loss: 0.4982
Batch 200, Loss: 0.4719
Batch 210, Loss: 0.4850
Batch 220, Loss: 0.4541
Batch 230, Loss: 0.4676
Batch 240, Loss: 0.4830
Batch 250, Loss: 0.5016
Batch 260, Loss: 0.4291
Batch 270, Loss: 0.4739
Batch 280, Loss: 0.5246
Batch 290, Loss: 0.5341
Batch 300, Loss: 0.4969
Batch 310, Loss: 0.5049
Batch 320, Loss: 0.4801
Batch 330, Loss: 0.4778
Batch 340, Loss: 0.4750
Batch 350, Loss: 0.4951
Batch 360, Loss: 0.4648
Batch 370, Loss: 0.4958
Batch 380, Loss: 0.4486
Batch 390, Loss: 0.4754
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 24.942294120788574 seconds
Epoch 81 accuracy: 87.52%
Batch 10, Loss: 0.4471
Batch 20, Loss: 0.4625
Batch 30, Loss: 0.4762
Batch 40, Loss: 0.4752
Batch 50, Loss: 0.4838
Batch 60, Loss: 0.4674
Batch 70, Loss: 0.5189
Batch 80, Loss: 0.4853
Batch 90, Loss: 0.4788
Batch 100, Loss: 0.4723
Batch 110, Loss: 0.4786
Batch 120, Loss: 0.4879
Batch 130, Loss: 0.4477
Batch 140, Loss: 0.4570
Batch 150, Loss: 0.4836
Batch 160, Loss: 0.4484
Batch 170, Loss: 0.4607
Batch 180, Loss: 0.4557
Batch 190, Loss: 0.4735
Batch 200, Loss: 0.4680
Batch 210, Loss: 0.4724
Batch 220, Loss: 0.4676
Batch 230, Loss: 0.4891
Batch 240, Loss: 0.4822
Batch 250, Loss: 0.4745
Batch 260, Loss: 0.4824
Batch 270, Loss: 0.4967
Batch 280, Loss: 0.5104
Batch 290, Loss: 0.4731
Batch 300, Loss: 0.4544
Batch 310, Loss: 0.5155
Batch 320, Loss: 0.5101
Batch 330, Loss: 0.4845
Batch 340, Loss: 0.4731
Batch 350, Loss: 0.4758
Batch 360, Loss: 0.4997
Batch 370, Loss: 0.4772
Batch 380, Loss: 0.4909
Batch 390, Loss: 0.4372
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 24.906273365020752 seconds
Epoch 82 accuracy: 85.44%
Batch 10, Loss: 0.4770
Batch 20, Loss: 0.4496
Batch 30, Loss: 0.4744
Batch 40, Loss: 0.4797
Batch 50, Loss: 0.4613
Batch 60, Loss: 0.4500
Batch 70, Loss: 0.4470
Batch 80, Loss: 0.4899
Batch 90, Loss: 0.4412
Batch 100, Loss: 0.4736
Batch 110, Loss: 0.4624
Batch 120, Loss: 0.4690
Batch 130, Loss: 0.4556
Batch 140, Loss: 0.4733
Batch 150, Loss: 0.5001
Batch 160, Loss: 0.4752
Batch 170, Loss: 0.4702
Batch 180, Loss: 0.4795
Batch 190, Loss: 0.5330
Batch 200, Loss: 0.4713
Batch 210, Loss: 0.4638
Batch 220, Loss: 0.4758
Batch 230, Loss: 0.4823
Batch 240, Loss: 0.5089
Batch 250, Loss: 0.5017
Batch 260, Loss: 0.4515
Batch 270, Loss: 0.4892
Batch 280, Loss: 0.4723
Batch 290, Loss: 0.4367
Batch 300, Loss: 0.5140
Batch 310, Loss: 0.4463
Batch 320, Loss: 0.4922
Batch 330, Loss: 0.4277
Batch 340, Loss: 0.4682
Batch 350, Loss: 0.4968
Batch 360, Loss: 0.4848
Batch 370, Loss: 0.4574
Batch 380, Loss: 0.4578
Batch 390, Loss: 0.4988
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 24.89933729171753 seconds
Epoch 83 accuracy: 85.43%
Batch 10, Loss: 0.4685
Batch 20, Loss: 0.4584
Batch 30, Loss: 0.4820
Batch 40, Loss: 0.4766
Batch 50, Loss: 0.4446
Batch 60, Loss: 0.4470
Batch 70, Loss: 0.4723
Batch 80, Loss: 0.4736
Batch 90, Loss: 0.5159
Batch 100, Loss: 0.4482
Batch 110, Loss: 0.4806
Batch 120, Loss: 0.4739
Batch 130, Loss: 0.4545
Batch 140, Loss: 0.4626
Batch 150, Loss: 0.4510
Batch 160, Loss: 0.4583
Batch 170, Loss: 0.4830
Batch 180, Loss: 0.4960
Batch 190, Loss: 0.4744
Batch 200, Loss: 0.4922
Batch 210, Loss: 0.4799
Batch 220, Loss: 0.4818
Batch 230, Loss: 0.4850
Batch 240, Loss: 0.5149
Batch 250, Loss: 0.4966
Batch 260, Loss: 0.4728
Batch 270, Loss: 0.4507
Batch 280, Loss: 0.4531
Batch 290, Loss: 0.4562
Batch 300, Loss: 0.4810
Batch 310, Loss: 0.5194
Batch 320, Loss: 0.4391
Batch 330, Loss: 0.4863
Batch 340, Loss: 0.4575
Batch 350, Loss: 0.5001
Batch 360, Loss: 0.4746
Batch 370, Loss: 0.4803
Batch 380, Loss: 0.4599
Batch 390, Loss: 0.4887
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 24.88231635093689 seconds
Epoch 84 accuracy: 87.96%
Batch 10, Loss: 0.4708
Batch 20, Loss: 0.4669
Batch 30, Loss: 0.4422
Batch 40, Loss: 0.4752
Batch 50, Loss: 0.4759
Batch 60, Loss: 0.4362
Batch 70, Loss: 0.4464
Batch 80, Loss: 0.4851
Batch 90, Loss: 0.4770
Batch 100, Loss: 0.4961
Batch 110, Loss: 0.4260
Batch 120, Loss: 0.4354
Batch 130, Loss: 0.4629
Batch 140, Loss: 0.4373
Batch 150, Loss: 0.4777
Batch 160, Loss: 0.4944
Batch 170, Loss: 0.5132
Batch 180, Loss: 0.4628
Batch 190, Loss: 0.4824
Batch 200, Loss: 0.4938
Batch 210, Loss: 0.4959
Batch 220, Loss: 0.5024
Batch 230, Loss: 0.4712
Batch 240, Loss: 0.5034
Batch 250, Loss: 0.4989
Batch 260, Loss: 0.4136
Batch 270, Loss: 0.4622
Batch 280, Loss: 0.4824
Batch 290, Loss: 0.4368
Batch 300, Loss: 0.4818
Batch 310, Loss: 0.4780
Batch 320, Loss: 0.4864
Batch 330, Loss: 0.4889
Batch 340, Loss: 0.4798
Batch 350, Loss: 0.4923
Batch 360, Loss: 0.4358
Batch 370, Loss: 0.4875
Batch 380, Loss: 0.4746
Batch 390, Loss: 0.5112
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 24.89409589767456 seconds
Epoch 85 accuracy: 87.29%
Batch 10, Loss: 0.4795
Batch 20, Loss: 0.4607
Batch 30, Loss: 0.4405
Batch 40, Loss: 0.4486
Batch 50, Loss: 0.4703
Batch 60, Loss: 0.4527
Batch 70, Loss: 0.4545
Batch 80, Loss: 0.4486
Batch 90, Loss: 0.4663
Batch 100, Loss: 0.4501
Batch 110, Loss: 0.4746
Batch 120, Loss: 0.4876
Batch 130, Loss: 0.4714
Batch 140, Loss: 0.4958
Batch 150, Loss: 0.4645
Batch 160, Loss: 0.4483
Batch 170, Loss: 0.4993
Batch 180, Loss: 0.4353
Batch 190, Loss: 0.4863
Batch 200, Loss: 0.5086
Batch 210, Loss: 0.4851
Batch 220, Loss: 0.4764
Batch 230, Loss: 0.4637
Batch 240, Loss: 0.4374
Batch 250, Loss: 0.4324
Batch 260, Loss: 0.4418
Batch 270, Loss: 0.4476
Batch 280, Loss: 0.4687
Batch 290, Loss: 0.4651
Batch 300, Loss: 0.4773
Batch 310, Loss: 0.4624
Batch 320, Loss: 0.4499
Batch 330, Loss: 0.4688
Batch 340, Loss: 0.5003
Batch 350, Loss: 0.4534
Batch 360, Loss: 0.5056
Batch 370, Loss: 0.4720
Batch 380, Loss: 0.4582
Batch 390, Loss: 0.4656
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 24.89512324333191 seconds
Epoch 86 accuracy: 83.99%
Batch 10, Loss: 0.4677
Batch 20, Loss: 0.4463
Batch 30, Loss: 0.4682
Batch 40, Loss: 0.4716
Batch 50, Loss: 0.5191
Batch 60, Loss: 0.5057
Batch 70, Loss: 0.4550
Batch 80, Loss: 0.4684
Batch 90, Loss: 0.4699
Batch 100, Loss: 0.4556
Batch 110, Loss: 0.4878
Batch 120, Loss: 0.4136
Batch 130, Loss: 0.4564
Batch 140, Loss: 0.4703
Batch 150, Loss: 0.4874
Batch 160, Loss: 0.4426
Batch 170, Loss: 0.4764
Batch 180, Loss: 0.4771
Batch 190, Loss: 0.4825
Batch 200, Loss: 0.4541
Batch 210, Loss: 0.4718
Batch 220, Loss: 0.4434
Batch 230, Loss: 0.4612
Batch 240, Loss: 0.4271
Batch 250, Loss: 0.4598
Batch 260, Loss: 0.4921
Batch 270, Loss: 0.4567
Batch 280, Loss: 0.4913
Batch 290, Loss: 0.4326
Batch 300, Loss: 0.4452
Batch 310, Loss: 0.4235
Batch 320, Loss: 0.5056
Batch 330, Loss: 0.4674
Batch 340, Loss: 0.4291
Batch 350, Loss: 0.4507
Batch 360, Loss: 0.4798
Batch 370, Loss: 0.4707
Batch 380, Loss: 0.4700
Batch 390, Loss: 0.4546
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 24.90028166770935 seconds
Epoch 87 accuracy: 86.61%
Batch 10, Loss: 0.4577
Batch 20, Loss: 0.4554
Batch 30, Loss: 0.4770
Batch 40, Loss: 0.4372
Batch 50, Loss: 0.4479
Batch 60, Loss: 0.4549
Batch 70, Loss: 0.4607
Batch 80, Loss: 0.4732
Batch 90, Loss: 0.4272
Batch 100, Loss: 0.4494
Batch 110, Loss: 0.4432
Batch 120, Loss: 0.4870
Batch 130, Loss: 0.4461
Batch 140, Loss: 0.4651
Batch 150, Loss: 0.4219
Batch 160, Loss: 0.4736
Batch 170, Loss: 0.4710
Batch 180, Loss: 0.4821
Batch 190, Loss: 0.4455
Batch 200, Loss: 0.4527
Batch 210, Loss: 0.4534
Batch 220, Loss: 0.4533
Batch 230, Loss: 0.4365
Batch 240, Loss: 0.4762
Batch 250, Loss: 0.4401
Batch 260, Loss: 0.4601
Batch 270, Loss: 0.5223
Batch 280, Loss: 0.4960
Batch 290, Loss: 0.4809
Batch 300, Loss: 0.4667
Batch 310, Loss: 0.4847
Batch 320, Loss: 0.4414
Batch 330, Loss: 0.4910
Batch 340, Loss: 0.4279
Batch 350, Loss: 0.4480
Batch 360, Loss: 0.4948
Batch 370, Loss: 0.4743
Batch 380, Loss: 0.4687
Batch 390, Loss: 0.5002
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 24.924325466156006 seconds
Epoch 88 accuracy: 88.33%
Batch 10, Loss: 0.4701
Batch 20, Loss: 0.4915
Batch 30, Loss: 0.4556
Batch 40, Loss: 0.4608
Batch 50, Loss: 0.4445
Batch 60, Loss: 0.4394
Batch 70, Loss: 0.4597
Batch 80, Loss: 0.4725
Batch 90, Loss: 0.4560
Batch 100, Loss: 0.4575
Batch 110, Loss: 0.4825
Batch 120, Loss: 0.4812
Batch 130, Loss: 0.4726
Batch 140, Loss: 0.4364
Batch 150, Loss: 0.4676
Batch 160, Loss: 0.4755
Batch 170, Loss: 0.4365
Batch 180, Loss: 0.4456
Batch 190, Loss: 0.4325
Batch 200, Loss: 0.4583
Batch 210, Loss: 0.5014
Batch 220, Loss: 0.4739
Batch 230, Loss: 0.4819
Batch 240, Loss: 0.4902
Batch 250, Loss: 0.4729
Batch 260, Loss: 0.4902
Batch 270, Loss: 0.4810
Batch 280, Loss: 0.4346
Batch 290, Loss: 0.4843
Batch 300, Loss: 0.4656
Batch 310, Loss: 0.4619
Batch 320, Loss: 0.4729
Batch 330, Loss: 0.4002
Batch 340, Loss: 0.4711
Batch 350, Loss: 0.4617
Batch 360, Loss: 0.4773
Batch 370, Loss: 0.4480
Batch 380, Loss: 0.4557
Batch 390, Loss: 0.4580
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 24.92325520515442 seconds
Epoch 89 accuracy: 83.06%
Batch 10, Loss: 0.4562
Batch 20, Loss: 0.4639
Batch 30, Loss: 0.4398
Batch 40, Loss: 0.4644
Batch 50, Loss: 0.4537
Batch 60, Loss: 0.4388
Batch 70, Loss: 0.4622
Batch 80, Loss: 0.4841
Batch 90, Loss: 0.4379
Batch 100, Loss: 0.4805
Batch 110, Loss: 0.4316
Batch 120, Loss: 0.4365
Batch 130, Loss: 0.4830
Batch 140, Loss: 0.4855
Batch 150, Loss: 0.4395
Batch 160, Loss: 0.4339
Batch 170, Loss: 0.4843
Batch 180, Loss: 0.4409
Batch 190, Loss: 0.4844
Batch 200, Loss: 0.4595
Batch 210, Loss: 0.4479
Batch 220, Loss: 0.4623
Batch 230, Loss: 0.4825
Batch 240, Loss: 0.4630
Batch 250, Loss: 0.4706
Batch 260, Loss: 0.4476
Batch 270, Loss: 0.4959
Batch 280, Loss: 0.4518
Batch 290, Loss: 0.4682
Batch 300, Loss: 0.5252
Batch 310, Loss: 0.4277
Batch 320, Loss: 0.5006
Batch 330, Loss: 0.4771
Batch 340, Loss: 0.4547
Batch 350, Loss: 0.4816
Batch 360, Loss: 0.5301
Batch 370, Loss: 0.4667
Batch 380, Loss: 0.4870
Batch 390, Loss: 0.4837
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 24.893971920013428 seconds
Epoch 90 accuracy: 83.8%
Batch 10, Loss: 0.4279
Batch 20, Loss: 0.4793
Batch 30, Loss: 0.4684
Batch 40, Loss: 0.4343
Batch 50, Loss: 0.4165
Batch 60, Loss: 0.4345
Batch 70, Loss: 0.4453
Batch 80, Loss: 0.4374
Batch 90, Loss: 0.4594
Batch 100, Loss: 0.4376
Batch 110, Loss: 0.4458
Batch 120, Loss: 0.4651
Batch 130, Loss: 0.4813
Batch 140, Loss: 0.5043
Batch 150, Loss: 0.4674
Batch 160, Loss: 0.4744
Batch 170, Loss: 0.4152
Batch 180, Loss: 0.4501
Batch 190, Loss: 0.4354
Batch 200, Loss: 0.4524
Batch 210, Loss: 0.4660
Batch 220, Loss: 0.4650
Batch 230, Loss: 0.5323
Batch 240, Loss: 0.4432
Batch 250, Loss: 0.4652
Batch 260, Loss: 0.4672
Batch 270, Loss: 0.4304
Batch 280, Loss: 0.4616
Batch 290, Loss: 0.4550
Batch 300, Loss: 0.4837
Batch 310, Loss: 0.4413
Batch 320, Loss: 0.4662
Batch 330, Loss: 0.4400
Batch 340, Loss: 0.4766
Batch 350, Loss: 0.4445
Batch 360, Loss: 0.4952
Batch 370, Loss: 0.4645
Batch 380, Loss: 0.4658
Batch 390, Loss: 0.4552
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 24.8980815410614 seconds
Epoch 91 accuracy: 86.17%
Batch 10, Loss: 0.4374
Batch 20, Loss: 0.4601
Batch 30, Loss: 0.4347
Batch 40, Loss: 0.4240
Batch 50, Loss: 0.4247
Batch 60, Loss: 0.4675
Batch 70, Loss: 0.4738
Batch 80, Loss: 0.4508
Batch 90, Loss: 0.4650
Batch 100, Loss: 0.4519
Batch 110, Loss: 0.4457
Batch 120, Loss: 0.4868
Batch 130, Loss: 0.4572
Batch 140, Loss: 0.4710
Batch 150, Loss: 0.4390
Batch 160, Loss: 0.4803
Batch 170, Loss: 0.4469
Batch 180, Loss: 0.4404
Batch 190, Loss: 0.4256
Batch 200, Loss: 0.4268
Batch 210, Loss: 0.4750
Batch 220, Loss: 0.4602
Batch 230, Loss: 0.4524
Batch 240, Loss: 0.4630
Batch 250, Loss: 0.4692
Batch 260, Loss: 0.4273
Batch 270, Loss: 0.4322
Batch 280, Loss: 0.4486
Batch 290, Loss: 0.4096
Batch 300, Loss: 0.4564
Batch 310, Loss: 0.4607
Batch 320, Loss: 0.4887
Batch 330, Loss: 0.4652
Batch 340, Loss: 0.4500
Batch 350, Loss: 0.4611
Batch 360, Loss: 0.4414
Batch 370, Loss: 0.5014
Batch 380, Loss: 0.4337
Batch 390, Loss: 0.4343
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 24.909433126449585 seconds
Epoch 92 accuracy: 87.71%
Batch 10, Loss: 0.4466
Batch 20, Loss: 0.4646
Batch 30, Loss: 0.4551
Batch 40, Loss: 0.4559
Batch 50, Loss: 0.4680
Batch 60, Loss: 0.4958
Batch 70, Loss: 0.4579
Batch 80, Loss: 0.4463
Batch 90, Loss: 0.4414
Batch 100, Loss: 0.4336
Batch 110, Loss: 0.4420
Batch 120, Loss: 0.4414
Batch 130, Loss: 0.4599
Batch 140, Loss: 0.4495
Batch 150, Loss: 0.4446
Batch 160, Loss: 0.4403
Batch 170, Loss: 0.4299
Batch 180, Loss: 0.4409
Batch 190, Loss: 0.4638
Batch 200, Loss: 0.4754
Batch 210, Loss: 0.4184
Batch 220, Loss: 0.4271
Batch 230, Loss: 0.4628
Batch 240, Loss: 0.4146
Batch 250, Loss: 0.4350
Batch 260, Loss: 0.4800
Batch 270, Loss: 0.4228
Batch 280, Loss: 0.4700
Batch 290, Loss: 0.4302
Batch 300, Loss: 0.4227
Batch 310, Loss: 0.4397
Batch 320, Loss: 0.4858
Batch 330, Loss: 0.4216
Batch 340, Loss: 0.4547
Batch 350, Loss: 0.4703
Batch 360, Loss: 0.4596
Batch 370, Loss: 0.4409
Batch 380, Loss: 0.4774
Batch 390, Loss: 0.4287
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 24.9447238445282 seconds
Epoch 93 accuracy: 85.81%
Batch 10, Loss: 0.4435
Batch 20, Loss: 0.4090
Batch 30, Loss: 0.4481
Batch 40, Loss: 0.4578
Batch 50, Loss: 0.4186
Batch 60, Loss: 0.4822
Batch 70, Loss: 0.5008
Batch 80, Loss: 0.4243
Batch 90, Loss: 0.4766
Batch 100, Loss: 0.4515
Batch 110, Loss: 0.4356
Batch 120, Loss: 0.4137
Batch 130, Loss: 0.4211
Batch 140, Loss: 0.4106
Batch 150, Loss: 0.4095
Batch 160, Loss: 0.4366
Batch 170, Loss: 0.4535
Batch 180, Loss: 0.4069
Batch 190, Loss: 0.4722
Batch 200, Loss: 0.4679
Batch 210, Loss: 0.4244
Batch 220, Loss: 0.4301
Batch 230, Loss: 0.4576
Batch 240, Loss: 0.4445
Batch 250, Loss: 0.4688
Batch 260, Loss: 0.4708
Batch 270, Loss: 0.4764
Batch 280, Loss: 0.5003
Batch 290, Loss: 0.4416
Batch 300, Loss: 0.4423
Batch 310, Loss: 0.4721
Batch 320, Loss: 0.4748
Batch 330, Loss: 0.4529
Batch 340, Loss: 0.4896
Batch 350, Loss: 0.5149
Batch 360, Loss: 0.4955
Batch 370, Loss: 0.4982
Batch 380, Loss: 0.4542
Batch 390, Loss: 0.4525
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 24.93397307395935 seconds
Epoch 94 accuracy: 86.57%
Batch 10, Loss: 0.4276
Batch 20, Loss: 0.4377
Batch 30, Loss: 0.4306
Batch 40, Loss: 0.4269
Batch 50, Loss: 0.4515
Batch 60, Loss: 0.4318
Batch 70, Loss: 0.4819
Batch 80, Loss: 0.4811
Batch 90, Loss: 0.4837
Batch 100, Loss: 0.4273
Batch 110, Loss: 0.4543
Batch 120, Loss: 0.4907
Batch 130, Loss: 0.4417
Batch 140, Loss: 0.4863
Batch 150, Loss: 0.4355
Batch 160, Loss: 0.4218
Batch 170, Loss: 0.4302
Batch 180, Loss: 0.4454
Batch 190, Loss: 0.4374
Batch 200, Loss: 0.4829
Batch 210, Loss: 0.4541
Batch 220, Loss: 0.4539
Batch 230, Loss: 0.4919
Batch 240, Loss: 0.4510
Batch 250, Loss: 0.4511
Batch 260, Loss: 0.4202
Batch 270, Loss: 0.4607
Batch 280, Loss: 0.4262
Batch 290, Loss: 0.4392
Batch 300, Loss: 0.4391
Batch 310, Loss: 0.4346
Batch 320, Loss: 0.4074
Batch 330, Loss: 0.4686
Batch 340, Loss: 0.4423
Batch 350, Loss: 0.4567
Batch 360, Loss: 0.4130
Batch 370, Loss: 0.4077
Batch 380, Loss: 0.4874
Batch 390, Loss: 0.4424
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 24.84888458251953 seconds
Epoch 95 accuracy: 87.92%
Batch 10, Loss: 0.4621
Batch 20, Loss: 0.4742
Batch 30, Loss: 0.4464
Batch 40, Loss: 0.4831
Batch 50, Loss: 0.4533
Batch 60, Loss: 0.4209
Batch 70, Loss: 0.4694
Batch 80, Loss: 0.4762
Batch 90, Loss: 0.4472
Batch 100, Loss: 0.3991
Batch 110, Loss: 0.4529
Batch 120, Loss: 0.4277
Batch 130, Loss: 0.4344
Batch 140, Loss: 0.4398
Batch 150, Loss: 0.4137
Batch 160, Loss: 0.4019
Batch 170, Loss: 0.4102
Batch 180, Loss: 0.4586
Batch 190, Loss: 0.4543
Batch 200, Loss: 0.4370
Batch 210, Loss: 0.4624
Batch 220, Loss: 0.4419
Batch 230, Loss: 0.4490
Batch 240, Loss: 0.4533
Batch 250, Loss: 0.4006
Batch 260, Loss: 0.4208
Batch 270, Loss: 0.4340
Batch 280, Loss: 0.4639
Batch 290, Loss: 0.4218
Batch 300, Loss: 0.4746
Batch 310, Loss: 0.4131
Batch 320, Loss: 0.4378
Batch 330, Loss: 0.4206
Batch 340, Loss: 0.5046
Batch 350, Loss: 0.4709
Batch 360, Loss: 0.4536
Batch 370, Loss: 0.4333
Batch 380, Loss: 0.4368
Batch 390, Loss: 0.4437
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 24.96894145011902 seconds
Epoch 96 accuracy: 87.21%
Batch 10, Loss: 0.4541
Batch 20, Loss: 0.3880
Batch 30, Loss: 0.4444
Batch 40, Loss: 0.4516
Batch 50, Loss: 0.4637
Batch 60, Loss: 0.4003
Batch 70, Loss: 0.4609
Batch 80, Loss: 0.4322
Batch 90, Loss: 0.4058
Batch 100, Loss: 0.4287
Batch 110, Loss: 0.4483
Batch 120, Loss: 0.4313
Batch 130, Loss: 0.4201
Batch 140, Loss: 0.4529
Batch 150, Loss: 0.4200
Batch 160, Loss: 0.4701
Batch 170, Loss: 0.4481
Batch 180, Loss: 0.4689
Batch 190, Loss: 0.4668
Batch 200, Loss: 0.4477
Batch 210, Loss: 0.4522
Batch 220, Loss: 0.4779
Batch 230, Loss: 0.4258
Batch 240, Loss: 0.4339
Batch 250, Loss: 0.4562
Batch 260, Loss: 0.4801
Batch 270, Loss: 0.4061
Batch 280, Loss: 0.4246
Batch 290, Loss: 0.4300
Batch 300, Loss: 0.4261
Batch 310, Loss: 0.4776
Batch 320, Loss: 0.4385
Batch 330, Loss: 0.4364
Batch 340, Loss: 0.4385
Batch 350, Loss: 0.4290
Batch 360, Loss: 0.4404
Batch 370, Loss: 0.4258
Batch 380, Loss: 0.4383
Batch 390, Loss: 0.4423
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 24.888389825820923 seconds
Epoch 97 accuracy: 87.72%
Batch 10, Loss: 0.4235
Batch 20, Loss: 0.4316
Batch 30, Loss: 0.4154
Batch 40, Loss: 0.4830
Batch 50, Loss: 0.4394
Batch 60, Loss: 0.4494
Batch 70, Loss: 0.4173
Batch 80, Loss: 0.4371
Batch 90, Loss: 0.4337
Batch 100, Loss: 0.4249
Batch 110, Loss: 0.4249
Batch 120, Loss: 0.4836
Batch 130, Loss: 0.4658
Batch 140, Loss: 0.4371
Batch 150, Loss: 0.4002
Batch 160, Loss: 0.4646
Batch 170, Loss: 0.4722
Batch 180, Loss: 0.4049
Batch 190, Loss: 0.4197
Batch 200, Loss: 0.5174
Batch 210, Loss: 0.4509
Batch 220, Loss: 0.4166
Batch 230, Loss: 0.4265
Batch 240, Loss: 0.4373
Batch 250, Loss: 0.4358
Batch 260, Loss: 0.4209
Batch 270, Loss: 0.4147
Batch 280, Loss: 0.4198
Batch 290, Loss: 0.4411
Batch 300, Loss: 0.4354
Batch 310, Loss: 0.4478
Batch 320, Loss: 0.4348
Batch 330, Loss: 0.4282
Batch 340, Loss: 0.4631
Batch 350, Loss: 0.4514
Batch 360, Loss: 0.4266
Batch 370, Loss: 0.4145
Batch 380, Loss: 0.4473
Batch 390, Loss: 0.4634
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 24.95450258255005 seconds
Epoch 98 accuracy: 87.48%
Batch 10, Loss: 0.4310
Batch 20, Loss: 0.4725
Batch 30, Loss: 0.4511
Batch 40, Loss: 0.4423
Batch 50, Loss: 0.4315
Batch 60, Loss: 0.4399
Batch 70, Loss: 0.4204
Batch 80, Loss: 0.4336
Batch 90, Loss: 0.4219
Batch 100, Loss: 0.4320
Batch 110, Loss: 0.4511
Batch 120, Loss: 0.4646
Batch 130, Loss: 0.4507
Batch 140, Loss: 0.4313
Batch 150, Loss: 0.4287
Batch 160, Loss: 0.4139
Batch 170, Loss: 0.4640
Batch 180, Loss: 0.4854
Batch 190, Loss: 0.4420
Batch 200, Loss: 0.4441
Batch 210, Loss: 0.3765
Batch 220, Loss: 0.4429
Batch 230, Loss: 0.4514
Batch 240, Loss: 0.4360
Batch 250, Loss: 0.4164
Batch 260, Loss: 0.4160
Batch 270, Loss: 0.4344
Batch 280, Loss: 0.4388
Batch 290, Loss: 0.4036
Batch 300, Loss: 0.4189
Batch 310, Loss: 0.3841
Batch 320, Loss: 0.4230
Batch 330, Loss: 0.4130
Batch 340, Loss: 0.4586
Batch 350, Loss: 0.4463
Batch 360, Loss: 0.4505
Batch 370, Loss: 0.4635
Batch 380, Loss: 0.4379
Batch 390, Loss: 0.4683
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 24.910544633865356 seconds
Epoch 99 accuracy: 86.93%
Batch 10, Loss: 0.4988
Batch 20, Loss: 0.4296
Batch 30, Loss: 0.3986
Batch 40, Loss: 0.4438
Batch 50, Loss: 0.4300
Batch 60, Loss: 0.4510
Batch 70, Loss: 0.4144
Batch 80, Loss: 0.4323
Batch 90, Loss: 0.4376
Batch 100, Loss: 0.4554
Batch 110, Loss: 0.4486
Batch 120, Loss: 0.4251
Batch 130, Loss: 0.4544
Batch 140, Loss: 0.4061
Batch 150, Loss: 0.4405
Batch 160, Loss: 0.4349
Batch 170, Loss: 0.4700
Batch 180, Loss: 0.4447
Batch 190, Loss: 0.3942
Batch 200, Loss: 0.4091
Batch 210, Loss: 0.4172
Batch 220, Loss: 0.4533
Batch 230, Loss: 0.4766
Batch 240, Loss: 0.3979
Batch 250, Loss: 0.4383
Batch 260, Loss: 0.4482
Batch 270, Loss: 0.4502
Batch 280, Loss: 0.4223
Batch 290, Loss: 0.4556
Batch 300, Loss: 0.4835
Batch 310, Loss: 0.4536
Batch 320, Loss: 0.4081
Batch 330, Loss: 0.4416
Batch 340, Loss: 0.4196
Batch 350, Loss: 0.4121
Batch 360, Loss: 0.4279
Batch 370, Loss: 0.4212
Batch 380, Loss: 0.4528
Batch 390, Loss: 0.4521
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 24.91855812072754 seconds
Epoch 100 accuracy: 87.56%
Batch 10, Loss: 0.4196
Batch 20, Loss: 0.4277
Batch 30, Loss: 0.4372
Batch 40, Loss: 0.4366
Batch 50, Loss: 0.4228
Batch 60, Loss: 0.4964
Batch 70, Loss: 0.4230
Batch 80, Loss: 0.4275
Batch 90, Loss: 0.4075
Batch 100, Loss: 0.3977
Batch 110, Loss: 0.4270
Batch 120, Loss: 0.4677
Batch 130, Loss: 0.4566
Batch 140, Loss: 0.4231
Batch 150, Loss: 0.4017
Batch 160, Loss: 0.4681
Batch 170, Loss: 0.4499
Batch 180, Loss: 0.4524
Batch 190, Loss: 0.4205
Batch 200, Loss: 0.4554
Batch 210, Loss: 0.4080
Batch 220, Loss: 0.4467
Batch 230, Loss: 0.4482
Batch 240, Loss: 0.4534
Batch 250, Loss: 0.4355
Batch 260, Loss: 0.4662
Batch 270, Loss: 0.4097
Batch 280, Loss: 0.4191
Batch 290, Loss: 0.4123
Batch 300, Loss: 0.4478
Batch 310, Loss: 0.3904
Batch 320, Loss: 0.4435
Batch 330, Loss: 0.4604
Batch 340, Loss: 0.4715
Batch 350, Loss: 0.4623
Batch 360, Loss: 0.4665
Batch 370, Loss: 0.4645
Batch 380, Loss: 0.4255
Batch 390, Loss: 0.4316
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 24.86192798614502 seconds
Epoch 101 accuracy: 89.31%
Batch 10, Loss: 0.3800
Batch 20, Loss: 0.4008
Batch 30, Loss: 0.4409
Batch 40, Loss: 0.4226
Batch 50, Loss: 0.4190
Batch 60, Loss: 0.4014
Batch 70, Loss: 0.3968
Batch 80, Loss: 0.4346
Batch 90, Loss: 0.4055
Batch 100, Loss: 0.4203
Batch 110, Loss: 0.3782
Batch 120, Loss: 0.4390
Batch 130, Loss: 0.4356
Batch 140, Loss: 0.4382
Batch 150, Loss: 0.4620
Batch 160, Loss: 0.4414
Batch 170, Loss: 0.4042
Batch 180, Loss: 0.4486
Batch 190, Loss: 0.4114
Batch 200, Loss: 0.4478
Batch 210, Loss: 0.4296
Batch 220, Loss: 0.4115
Batch 230, Loss: 0.4069
Batch 240, Loss: 0.3867
Batch 250, Loss: 0.4066
Batch 260, Loss: 0.4402
Batch 270, Loss: 0.4473
Batch 280, Loss: 0.4178
Batch 290, Loss: 0.4354
Batch 300, Loss: 0.4395
Batch 310, Loss: 0.4738
Batch 320, Loss: 0.4762
Batch 330, Loss: 0.4443
Batch 340, Loss: 0.4364
Batch 350, Loss: 0.4624
Batch 360, Loss: 0.4405
Batch 370, Loss: 0.4410
Batch 380, Loss: 0.4214
Batch 390, Loss: 0.4259
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 24.884921073913574 seconds
Epoch 102 accuracy: 88.33%
Batch 10, Loss: 0.4024
Batch 20, Loss: 0.4003
Batch 30, Loss: 0.4061
Batch 40, Loss: 0.4028
Batch 50, Loss: 0.3990
Batch 60, Loss: 0.4306
Batch 70, Loss: 0.4264
Batch 80, Loss: 0.4587
Batch 90, Loss: 0.4096
Batch 100, Loss: 0.4254
Batch 110, Loss: 0.4321
Batch 120, Loss: 0.4365
Batch 130, Loss: 0.4103
Batch 140, Loss: 0.4233
Batch 150, Loss: 0.4659
Batch 160, Loss: 0.4267
Batch 170, Loss: 0.4482
Batch 180, Loss: 0.4365
Batch 190, Loss: 0.4016
Batch 200, Loss: 0.3995
Batch 210, Loss: 0.4153
Batch 220, Loss: 0.4108
Batch 230, Loss: 0.4367
Batch 240, Loss: 0.4201
Batch 250, Loss: 0.4503
Batch 260, Loss: 0.4308
Batch 270, Loss: 0.4337
Batch 280, Loss: 0.4171
Batch 290, Loss: 0.4515
Batch 300, Loss: 0.4046
Batch 310, Loss: 0.4127
Batch 320, Loss: 0.4344
Batch 330, Loss: 0.4208
Batch 340, Loss: 0.4281
Batch 350, Loss: 0.4370
Batch 360, Loss: 0.4256
Batch 370, Loss: 0.4529
Batch 380, Loss: 0.4748
Batch 390, Loss: 0.4007
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 24.866593599319458 seconds
Epoch 103 accuracy: 86.6%
Batch 10, Loss: 0.4582
Batch 20, Loss: 0.4418
Batch 30, Loss: 0.3832
Batch 40, Loss: 0.4230
Batch 50, Loss: 0.4465
Batch 60, Loss: 0.4397
Batch 70, Loss: 0.4083
Batch 80, Loss: 0.4059
Batch 90, Loss: 0.4058
Batch 100, Loss: 0.4432
Batch 110, Loss: 0.4150
Batch 120, Loss: 0.4246
Batch 130, Loss: 0.4172
Batch 140, Loss: 0.4308
Batch 150, Loss: 0.3790
Batch 160, Loss: 0.4116
Batch 170, Loss: 0.4160
Batch 180, Loss: 0.4466
Batch 190, Loss: 0.4187
Batch 200, Loss: 0.4422
Batch 210, Loss: 0.4373
Batch 220, Loss: 0.4331
Batch 230, Loss: 0.4165
Batch 240, Loss: 0.3956
Batch 250, Loss: 0.4416
Batch 260, Loss: 0.4063
Batch 270, Loss: 0.4671
Batch 280, Loss: 0.4227
Batch 290, Loss: 0.4352
Batch 300, Loss: 0.4278
Batch 310, Loss: 0.3978
Batch 320, Loss: 0.4496
Batch 330, Loss: 0.4446
Batch 340, Loss: 0.4169
Batch 350, Loss: 0.4225
Batch 360, Loss: 0.4143
Batch 370, Loss: 0.4354
Batch 380, Loss: 0.4146
Batch 390, Loss: 0.4114
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 24.893115520477295 seconds
Epoch 104 accuracy: 89.39%
Batch 10, Loss: 0.4604
Batch 20, Loss: 0.3901
Batch 30, Loss: 0.4147
Batch 40, Loss: 0.4151
Batch 50, Loss: 0.4112
Batch 60, Loss: 0.4469
Batch 70, Loss: 0.3945
Batch 80, Loss: 0.4176
Batch 90, Loss: 0.4119
Batch 100, Loss: 0.4345
Batch 110, Loss: 0.3968
Batch 120, Loss: 0.4034
Batch 130, Loss: 0.3855
Batch 140, Loss: 0.4217
Batch 150, Loss: 0.4379
Batch 160, Loss: 0.4339
Batch 170, Loss: 0.4028
Batch 180, Loss: 0.4178
Batch 190, Loss: 0.4208
Batch 200, Loss: 0.4195
Batch 210, Loss: 0.4105
Batch 220, Loss: 0.4211
Batch 230, Loss: 0.4306
Batch 240, Loss: 0.4354
Batch 250, Loss: 0.4410
Batch 260, Loss: 0.4114
Batch 270, Loss: 0.4426
Batch 280, Loss: 0.4202
Batch 290, Loss: 0.4398
Batch 300, Loss: 0.4226
Batch 310, Loss: 0.4454
Batch 320, Loss: 0.4349
Batch 330, Loss: 0.4274
Batch 340, Loss: 0.4397
Batch 350, Loss: 0.4155
Batch 360, Loss: 0.4540
Batch 370, Loss: 0.4214
Batch 380, Loss: 0.3875
Batch 390, Loss: 0.4369
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 24.927881956100464 seconds
Epoch 105 accuracy: 88.37%
Batch 10, Loss: 0.4131
Batch 20, Loss: 0.4184
Batch 30, Loss: 0.4325
Batch 40, Loss: 0.4563
Batch 50, Loss: 0.4123
Batch 60, Loss: 0.4316
Batch 70, Loss: 0.4317
Batch 80, Loss: 0.4329
Batch 90, Loss: 0.4165
Batch 100, Loss: 0.4457
Batch 110, Loss: 0.4151
Batch 120, Loss: 0.3853
Batch 130, Loss: 0.4242
Batch 140, Loss: 0.3809
Batch 150, Loss: 0.4276
Batch 160, Loss: 0.4470
Batch 170, Loss: 0.3946
Batch 180, Loss: 0.3926
Batch 190, Loss: 0.4334
Batch 200, Loss: 0.4092
Batch 210, Loss: 0.4088
Batch 220, Loss: 0.4164
Batch 230, Loss: 0.3896
Batch 240, Loss: 0.4323
Batch 250, Loss: 0.4229
Batch 260, Loss: 0.3773
Batch 270, Loss: 0.4209
Batch 280, Loss: 0.4338
Batch 290, Loss: 0.4216
Batch 300, Loss: 0.3981
Batch 310, Loss: 0.4410
Batch 320, Loss: 0.4224
Batch 330, Loss: 0.4357
Batch 340, Loss: 0.4271
Batch 350, Loss: 0.4024
Batch 360, Loss: 0.4538
Batch 370, Loss: 0.4032
Batch 380, Loss: 0.4673
Batch 390, Loss: 0.4132
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 24.81966543197632 seconds
Epoch 106 accuracy: 88.1%
Batch 10, Loss: 0.4384
Batch 20, Loss: 0.3856
Batch 30, Loss: 0.4361
Batch 40, Loss: 0.4058
Batch 50, Loss: 0.3903
Batch 60, Loss: 0.4283
Batch 70, Loss: 0.4098
Batch 80, Loss: 0.4087
Batch 90, Loss: 0.4196
Batch 100, Loss: 0.4071
Batch 110, Loss: 0.4183
Batch 120, Loss: 0.3806
Batch 130, Loss: 0.4042
Batch 140, Loss: 0.4114
Batch 150, Loss: 0.4443
Batch 160, Loss: 0.4520
Batch 170, Loss: 0.4422
Batch 180, Loss: 0.4204
Batch 190, Loss: 0.4054
Batch 200, Loss: 0.4379
Batch 210, Loss: 0.4434
Batch 220, Loss: 0.4261
Batch 230, Loss: 0.4295
Batch 240, Loss: 0.4245
Batch 250, Loss: 0.4048
Batch 260, Loss: 0.4251
Batch 270, Loss: 0.4381
Batch 280, Loss: 0.4189
Batch 290, Loss: 0.4522
Batch 300, Loss: 0.4026
Batch 310, Loss: 0.4241
Batch 320, Loss: 0.4136
Batch 330, Loss: 0.4368
Batch 340, Loss: 0.4132
Batch 350, Loss: 0.4259
Batch 360, Loss: 0.4421
Batch 370, Loss: 0.4493
Batch 380, Loss: 0.4184
Batch 390, Loss: 0.4132
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 24.928789377212524 seconds
Epoch 107 accuracy: 89.0%
Batch 10, Loss: 0.4172
Batch 20, Loss: 0.4310
Batch 30, Loss: 0.4125
Batch 40, Loss: 0.4141
Batch 50, Loss: 0.4204
Batch 60, Loss: 0.4231
Batch 70, Loss: 0.4165
Batch 80, Loss: 0.4288
Batch 90, Loss: 0.4084
Batch 100, Loss: 0.4073
Batch 110, Loss: 0.4048
Batch 120, Loss: 0.4111
Batch 130, Loss: 0.4048
Batch 140, Loss: 0.4444
Batch 150, Loss: 0.4304
Batch 160, Loss: 0.4103
Batch 170, Loss: 0.3984
Batch 180, Loss: 0.4007
Batch 190, Loss: 0.3995
Batch 200, Loss: 0.4034
Batch 210, Loss: 0.3963
Batch 220, Loss: 0.4022
Batch 230, Loss: 0.4011
Batch 240, Loss: 0.4032
Batch 250, Loss: 0.4438
Batch 260, Loss: 0.3823
Batch 270, Loss: 0.4136
Batch 280, Loss: 0.4328
Batch 290, Loss: 0.4170
Batch 300, Loss: 0.4541
Batch 310, Loss: 0.4362
Batch 320, Loss: 0.4578
Batch 330, Loss: 0.3992
Batch 340, Loss: 0.4345
Batch 350, Loss: 0.4325
Batch 360, Loss: 0.4071
Batch 370, Loss: 0.4185
Batch 380, Loss: 0.4014
Batch 390, Loss: 0.4158
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 24.81699800491333 seconds
Epoch 108 accuracy: 88.53%
Batch 10, Loss: 0.3823
Batch 20, Loss: 0.4085
Batch 30, Loss: 0.4250
Batch 40, Loss: 0.4245
Batch 50, Loss: 0.3863
Batch 60, Loss: 0.3934
Batch 70, Loss: 0.4426
Batch 80, Loss: 0.3869
Batch 90, Loss: 0.4107
Batch 100, Loss: 0.4176
Batch 110, Loss: 0.3677
Batch 120, Loss: 0.3924
Batch 130, Loss: 0.4030
Batch 140, Loss: 0.4414
Batch 150, Loss: 0.4181
Batch 160, Loss: 0.4438
Batch 170, Loss: 0.4369
Batch 180, Loss: 0.4176
Batch 190, Loss: 0.3946
Batch 200, Loss: 0.4279
Batch 210, Loss: 0.4698
Batch 220, Loss: 0.4513
Batch 230, Loss: 0.4169
Batch 240, Loss: 0.4377
Batch 250, Loss: 0.4200
Batch 260, Loss: 0.3794
Batch 270, Loss: 0.4057
Batch 280, Loss: 0.3946
Batch 290, Loss: 0.4153
Batch 300, Loss: 0.3844
Batch 310, Loss: 0.3809
Batch 320, Loss: 0.4074
Batch 330, Loss: 0.4111
Batch 340, Loss: 0.4379
Batch 350, Loss: 0.4105
Batch 360, Loss: 0.4370
Batch 370, Loss: 0.4259
Batch 380, Loss: 0.4045
Batch 390, Loss: 0.4139
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 24.90325951576233 seconds
Epoch 109 accuracy: 88.25%
Batch 10, Loss: 0.4239
Batch 20, Loss: 0.3720
Batch 30, Loss: 0.3850
Batch 40, Loss: 0.3971
Batch 50, Loss: 0.3867
Batch 60, Loss: 0.4302
Batch 70, Loss: 0.3974
Batch 80, Loss: 0.4205
Batch 90, Loss: 0.4109
Batch 100, Loss: 0.4126
Batch 110, Loss: 0.4225
Batch 120, Loss: 0.4225
Batch 130, Loss: 0.4523
Batch 140, Loss: 0.4377
Batch 150, Loss: 0.4088
Batch 160, Loss: 0.3887
Batch 170, Loss: 0.4444
Batch 180, Loss: 0.4086
Batch 190, Loss: 0.4022
Batch 200, Loss: 0.4055
Batch 210, Loss: 0.3835
Batch 220, Loss: 0.3964
Batch 230, Loss: 0.4296
Batch 240, Loss: 0.3924
Batch 250, Loss: 0.4532
Batch 260, Loss: 0.4247
Batch 270, Loss: 0.4186
Batch 280, Loss: 0.4131
Batch 290, Loss: 0.4293
Batch 300, Loss: 0.3944
Batch 310, Loss: 0.3950
Batch 320, Loss: 0.4007
Batch 330, Loss: 0.4101
Batch 340, Loss: 0.3865
Batch 350, Loss: 0.4085
Batch 360, Loss: 0.4161
Batch 370, Loss: 0.4157
Batch 380, Loss: 0.4227
Batch 390, Loss: 0.4205
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 24.899842977523804 seconds
Epoch 110 accuracy: 88.64%
Batch 10, Loss: 0.3669
Batch 20, Loss: 0.3849
Batch 30, Loss: 0.3984
Batch 40, Loss: 0.4176
Batch 50, Loss: 0.3996
Batch 60, Loss: 0.3894
Batch 70, Loss: 0.3693
Batch 80, Loss: 0.4050
Batch 90, Loss: 0.4100
Batch 100, Loss: 0.3698
Batch 110, Loss: 0.4493
Batch 120, Loss: 0.4152
Batch 130, Loss: 0.4239
Batch 140, Loss: 0.3951
Batch 150, Loss: 0.4159
Batch 160, Loss: 0.4074
Batch 170, Loss: 0.4089
Batch 180, Loss: 0.3836
Batch 190, Loss: 0.4000
Batch 200, Loss: 0.4347
Batch 210, Loss: 0.4255
Batch 220, Loss: 0.4581
Batch 230, Loss: 0.4132
Batch 240, Loss: 0.4148
Batch 250, Loss: 0.4141
Batch 260, Loss: 0.4035
Batch 270, Loss: 0.3938
Batch 280, Loss: 0.4247
Batch 290, Loss: 0.3754
Batch 300, Loss: 0.4297
Batch 310, Loss: 0.3884
Batch 320, Loss: 0.3785
Batch 330, Loss: 0.3905
Batch 340, Loss: 0.3992
Batch 350, Loss: 0.4360
Batch 360, Loss: 0.4381
Batch 370, Loss: 0.3912
Batch 380, Loss: 0.4116
Batch 390, Loss: 0.4041
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.867816925048828 seconds
Epoch 111 accuracy: 90.49%
Batch 10, Loss: 0.4009
Batch 20, Loss: 0.4205
Batch 30, Loss: 0.3847
Batch 40, Loss: 0.3330
Batch 50, Loss: 0.4114
Batch 60, Loss: 0.3870
Batch 70, Loss: 0.4060
Batch 80, Loss: 0.3892
Batch 90, Loss: 0.4033
Batch 100, Loss: 0.4320
Batch 110, Loss: 0.3840
Batch 120, Loss: 0.3773
Batch 130, Loss: 0.3993
Batch 140, Loss: 0.4054
Batch 150, Loss: 0.4031
Batch 160, Loss: 0.3947
Batch 170, Loss: 0.4472
Batch 180, Loss: 0.4288
Batch 190, Loss: 0.4212
Batch 200, Loss: 0.3224
Batch 210, Loss: 0.4207
Batch 220, Loss: 0.4267
Batch 230, Loss: 0.4017
Batch 240, Loss: 0.4174
Batch 250, Loss: 0.4332
Batch 260, Loss: 0.4074
Batch 270, Loss: 0.4327
Batch 280, Loss: 0.3921
Batch 290, Loss: 0.4215
Batch 300, Loss: 0.3702
Batch 310, Loss: 0.3853
Batch 320, Loss: 0.4041
Batch 330, Loss: 0.4040
Batch 340, Loss: 0.3952
Batch 350, Loss: 0.4022
Batch 360, Loss: 0.3986
Batch 370, Loss: 0.4257
Batch 380, Loss: 0.3961
Batch 390, Loss: 0.4194
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 24.899577379226685 seconds
Epoch 112 accuracy: 89.14%
Batch 10, Loss: 0.3751
Batch 20, Loss: 0.3826
Batch 30, Loss: 0.4237
Batch 40, Loss: 0.3852
Batch 50, Loss: 0.3989
Batch 60, Loss: 0.3716
Batch 70, Loss: 0.4239
Batch 80, Loss: 0.3890
Batch 90, Loss: 0.4063
Batch 100, Loss: 0.3914
Batch 110, Loss: 0.3891
Batch 120, Loss: 0.3956
Batch 130, Loss: 0.4255
Batch 140, Loss: 0.4272
Batch 150, Loss: 0.4190
Batch 160, Loss: 0.3847
Batch 170, Loss: 0.3859
Batch 180, Loss: 0.4088
Batch 190, Loss: 0.4341
Batch 200, Loss: 0.3974
Batch 210, Loss: 0.3784
Batch 220, Loss: 0.3958
Batch 230, Loss: 0.3734
Batch 240, Loss: 0.3827
Batch 250, Loss: 0.4042
Batch 260, Loss: 0.4295
Batch 270, Loss: 0.4055
Batch 280, Loss: 0.3917
Batch 290, Loss: 0.3897
Batch 300, Loss: 0.3876
Batch 310, Loss: 0.4089
Batch 320, Loss: 0.3815
Batch 330, Loss: 0.4047
Batch 340, Loss: 0.4071
Batch 350, Loss: 0.4278
Batch 360, Loss: 0.4026
Batch 370, Loss: 0.4392
Batch 380, Loss: 0.3765
Batch 390, Loss: 0.3818
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 24.891507625579834 seconds
Epoch 113 accuracy: 88.26%
Batch 10, Loss: 0.3511
Batch 20, Loss: 0.4362
Batch 30, Loss: 0.4166
Batch 40, Loss: 0.4186
Batch 50, Loss: 0.4141
Batch 60, Loss: 0.4582
Batch 70, Loss: 0.3835
Batch 80, Loss: 0.4002
Batch 90, Loss: 0.3719
Batch 100, Loss: 0.3801
Batch 110, Loss: 0.3869
Batch 120, Loss: 0.3889
Batch 130, Loss: 0.4068
Batch 140, Loss: 0.3641
Batch 150, Loss: 0.3927
Batch 160, Loss: 0.3881
Batch 170, Loss: 0.4026
Batch 180, Loss: 0.4041
Batch 190, Loss: 0.4268
Batch 200, Loss: 0.4228
Batch 210, Loss: 0.3903
Batch 220, Loss: 0.4051
Batch 230, Loss: 0.4206
Batch 240, Loss: 0.4007
Batch 250, Loss: 0.4174
Batch 260, Loss: 0.4123
Batch 270, Loss: 0.3724
Batch 280, Loss: 0.4038
Batch 290, Loss: 0.3731
Batch 300, Loss: 0.3858
Batch 310, Loss: 0.4058
Batch 320, Loss: 0.3895
Batch 330, Loss: 0.4108
Batch 340, Loss: 0.4000
Batch 350, Loss: 0.4570
Batch 360, Loss: 0.4195
Batch 370, Loss: 0.3999
Batch 380, Loss: 0.4049
Batch 390, Loss: 0.3891
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 24.893552780151367 seconds
Epoch 114 accuracy: 89.03%
Batch 10, Loss: 0.4095
Batch 20, Loss: 0.4125
Batch 30, Loss: 0.4291
Batch 40, Loss: 0.3716
Batch 50, Loss: 0.3920
Batch 60, Loss: 0.4096
Batch 70, Loss: 0.4025
Batch 80, Loss: 0.4115
Batch 90, Loss: 0.4272
Batch 100, Loss: 0.3840
Batch 110, Loss: 0.3967
Batch 120, Loss: 0.4023
Batch 130, Loss: 0.3844
Batch 140, Loss: 0.4176
Batch 150, Loss: 0.3716
Batch 160, Loss: 0.3989
Batch 170, Loss: 0.3622
Batch 180, Loss: 0.3512
Batch 190, Loss: 0.3663
Batch 200, Loss: 0.3698
Batch 210, Loss: 0.4062
Batch 220, Loss: 0.3941
Batch 230, Loss: 0.3900
Batch 240, Loss: 0.3736
Batch 250, Loss: 0.4213
Batch 260, Loss: 0.3926
Batch 270, Loss: 0.3877
Batch 280, Loss: 0.4114
Batch 290, Loss: 0.4041
Batch 300, Loss: 0.3887
Batch 310, Loss: 0.4383
Batch 320, Loss: 0.4249
Batch 330, Loss: 0.3948
Batch 340, Loss: 0.4123
Batch 350, Loss: 0.3767
Batch 360, Loss: 0.3872
Batch 370, Loss: 0.3808
Batch 380, Loss: 0.3610
Batch 390, Loss: 0.4120
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 24.904000997543335 seconds
Epoch 115 accuracy: 90.18%
Batch 10, Loss: 0.3927
Batch 20, Loss: 0.4419
Batch 30, Loss: 0.3888
Batch 40, Loss: 0.3948
Batch 50, Loss: 0.3806
Batch 60, Loss: 0.3617
Batch 70, Loss: 0.3756
Batch 80, Loss: 0.4114
Batch 90, Loss: 0.3707
Batch 100, Loss: 0.3821
Batch 110, Loss: 0.3999
Batch 120, Loss: 0.3767
Batch 130, Loss: 0.3636
Batch 140, Loss: 0.3753
Batch 150, Loss: 0.4228
Batch 160, Loss: 0.3628
Batch 170, Loss: 0.3627
Batch 180, Loss: 0.3594
Batch 190, Loss: 0.3924
Batch 200, Loss: 0.3960
Batch 210, Loss: 0.3999
Batch 220, Loss: 0.3836
Batch 230, Loss: 0.4370
Batch 240, Loss: 0.4305
Batch 250, Loss: 0.3941
Batch 260, Loss: 0.3760
Batch 270, Loss: 0.3992
Batch 280, Loss: 0.4043
Batch 290, Loss: 0.4131
Batch 300, Loss: 0.3984
Batch 310, Loss: 0.4327
Batch 320, Loss: 0.3901
Batch 330, Loss: 0.4056
Batch 340, Loss: 0.4109
Batch 350, Loss: 0.4087
Batch 360, Loss: 0.3871
Batch 370, Loss: 0.3981
Batch 380, Loss: 0.3927
Batch 390, Loss: 0.3752
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 24.89436101913452 seconds
Epoch 116 accuracy: 89.33%
Batch 10, Loss: 0.4113
Batch 20, Loss: 0.3960
Batch 30, Loss: 0.3690
Batch 40, Loss: 0.3736
Batch 50, Loss: 0.3998
Batch 60, Loss: 0.3808
Batch 70, Loss: 0.3919
Batch 80, Loss: 0.4101
Batch 90, Loss: 0.3749
Batch 100, Loss: 0.4030
Batch 110, Loss: 0.3573
Batch 120, Loss: 0.3458
Batch 130, Loss: 0.4194
Batch 140, Loss: 0.3772
Batch 150, Loss: 0.4153
Batch 160, Loss: 0.3785
Batch 170, Loss: 0.4016
Batch 180, Loss: 0.3964
Batch 190, Loss: 0.3927
Batch 200, Loss: 0.3717
Batch 210, Loss: 0.4018
Batch 220, Loss: 0.3703
Batch 230, Loss: 0.3985
Batch 240, Loss: 0.3935
Batch 250, Loss: 0.3901
Batch 260, Loss: 0.4021
Batch 270, Loss: 0.4049
Batch 280, Loss: 0.3917
Batch 290, Loss: 0.3977
Batch 300, Loss: 0.3814
Batch 310, Loss: 0.3484
Batch 320, Loss: 0.3823
Batch 330, Loss: 0.4141
Batch 340, Loss: 0.3821
Batch 350, Loss: 0.3926
Batch 360, Loss: 0.3810
Batch 370, Loss: 0.3955
Batch 380, Loss: 0.4180
Batch 390, Loss: 0.4171
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 24.863981008529663 seconds
Epoch 117 accuracy: 89.63%
Batch 10, Loss: 0.4137
Batch 20, Loss: 0.3626
Batch 30, Loss: 0.3826
Batch 40, Loss: 0.3760
Batch 50, Loss: 0.3867
Batch 60, Loss: 0.3810
Batch 70, Loss: 0.3933
Batch 80, Loss: 0.4135
Batch 90, Loss: 0.3669
Batch 100, Loss: 0.3700
Batch 110, Loss: 0.3653
Batch 120, Loss: 0.4072
Batch 130, Loss: 0.3687
Batch 140, Loss: 0.4119
Batch 150, Loss: 0.3906
Batch 160, Loss: 0.3724
Batch 170, Loss: 0.3417
Batch 180, Loss: 0.3641
Batch 190, Loss: 0.3716
Batch 200, Loss: 0.3834
Batch 210, Loss: 0.3804
Batch 220, Loss: 0.3776
Batch 230, Loss: 0.4156
Batch 240, Loss: 0.3749
Batch 250, Loss: 0.3996
Batch 260, Loss: 0.3927
Batch 270, Loss: 0.4083
Batch 280, Loss: 0.4071
Batch 290, Loss: 0.4216
Batch 300, Loss: 0.3956
Batch 310, Loss: 0.3688
Batch 320, Loss: 0.3792
Batch 330, Loss: 0.3808
Batch 340, Loss: 0.4129
Batch 350, Loss: 0.3823
Batch 360, Loss: 0.3541
Batch 370, Loss: 0.3925
Batch 380, Loss: 0.4201
Batch 390, Loss: 0.4032
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 24.91390061378479 seconds
Epoch 118 accuracy: 90.71%
Batch 10, Loss: 0.3768
Batch 20, Loss: 0.3589
Batch 30, Loss: 0.3846
Batch 40, Loss: 0.4206
Batch 50, Loss: 0.3756
Batch 60, Loss: 0.3781
Batch 70, Loss: 0.4506
Batch 80, Loss: 0.4034
Batch 90, Loss: 0.3692
Batch 100, Loss: 0.3909
Batch 110, Loss: 0.3853
Batch 120, Loss: 0.3617
Batch 130, Loss: 0.3621
Batch 140, Loss: 0.3969
Batch 150, Loss: 0.3935
Batch 160, Loss: 0.3525
Batch 170, Loss: 0.3890
Batch 180, Loss: 0.3551
Batch 190, Loss: 0.3811
Batch 200, Loss: 0.4095
Batch 210, Loss: 0.3973
Batch 220, Loss: 0.3915
Batch 230, Loss: 0.3874
Batch 240, Loss: 0.3990
Batch 250, Loss: 0.4085
Batch 260, Loss: 0.4123
Batch 270, Loss: 0.3833
Batch 280, Loss: 0.3764
Batch 290, Loss: 0.3694
Batch 300, Loss: 0.3931
Batch 310, Loss: 0.3692
Batch 320, Loss: 0.3846
Batch 330, Loss: 0.3808
Batch 340, Loss: 0.4037
Batch 350, Loss: 0.3896
Batch 360, Loss: 0.3985
Batch 370, Loss: 0.4180
Batch 380, Loss: 0.4015
Batch 390, Loss: 0.3724
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 24.902021408081055 seconds
Epoch 119 accuracy: 89.37%
Batch 10, Loss: 0.3666
Batch 20, Loss: 0.4078
Batch 30, Loss: 0.3720
Batch 40, Loss: 0.3320
Batch 50, Loss: 0.3825
Batch 60, Loss: 0.3717
Batch 70, Loss: 0.3737
Batch 80, Loss: 0.3594
Batch 90, Loss: 0.4470
Batch 100, Loss: 0.3841
Batch 110, Loss: 0.4074
Batch 120, Loss: 0.3927
Batch 130, Loss: 0.3871
Batch 140, Loss: 0.3572
Batch 150, Loss: 0.3710
Batch 160, Loss: 0.3984
Batch 170, Loss: 0.3675
Batch 180, Loss: 0.3579
Batch 190, Loss: 0.3609
Batch 200, Loss: 0.3953
Batch 210, Loss: 0.3734
Batch 220, Loss: 0.3838
Batch 230, Loss: 0.3687
Batch 240, Loss: 0.3954
Batch 250, Loss: 0.3890
Batch 260, Loss: 0.3939
Batch 270, Loss: 0.3896
Batch 280, Loss: 0.3923
Batch 290, Loss: 0.3828
Batch 300, Loss: 0.4418
Batch 310, Loss: 0.3685
Batch 320, Loss: 0.3755
Batch 330, Loss: 0.3803
Batch 340, Loss: 0.3624
Batch 350, Loss: 0.3940
Batch 360, Loss: 0.3981
Batch 370, Loss: 0.3789
Batch 380, Loss: 0.3815
Batch 390, Loss: 0.4140
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 24.910099983215332 seconds
Epoch 120 accuracy: 88.65%
Batch 10, Loss: 0.3683
Batch 20, Loss: 0.3819
Batch 30, Loss: 0.3419
Batch 40, Loss: 0.3778
Batch 50, Loss: 0.3734
Batch 60, Loss: 0.3942
Batch 70, Loss: 0.3804
Batch 80, Loss: 0.4009
Batch 90, Loss: 0.3604
Batch 100, Loss: 0.3701
Batch 110, Loss: 0.4050
Batch 120, Loss: 0.3799
Batch 130, Loss: 0.3638
Batch 140, Loss: 0.3612
Batch 150, Loss: 0.3863
Batch 160, Loss: 0.3703
Batch 170, Loss: 0.3364
Batch 180, Loss: 0.4013
Batch 190, Loss: 0.4066
Batch 200, Loss: 0.4034
Batch 210, Loss: 0.4046
Batch 220, Loss: 0.4110
Batch 230, Loss: 0.3903
Batch 240, Loss: 0.4186
Batch 250, Loss: 0.3476
Batch 260, Loss: 0.4047
Batch 270, Loss: 0.3625
Batch 280, Loss: 0.3648
Batch 290, Loss: 0.3666
Batch 300, Loss: 0.3680
Batch 310, Loss: 0.3875
Batch 320, Loss: 0.3867
Batch 330, Loss: 0.3548
Batch 340, Loss: 0.3457
Batch 350, Loss: 0.3836
Batch 360, Loss: 0.3803
Batch 370, Loss: 0.3891
Batch 380, Loss: 0.3631
Batch 390, Loss: 0.3457
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 24.88156533241272 seconds
Epoch 121 accuracy: 91.43%
Batch 10, Loss: 0.3457
Batch 20, Loss: 0.3532
Batch 30, Loss: 0.3504
Batch 40, Loss: 0.3643
Batch 50, Loss: 0.3698
Batch 60, Loss: 0.3910
Batch 70, Loss: 0.3786
Batch 80, Loss: 0.3524
Batch 90, Loss: 0.3908
Batch 100, Loss: 0.3461
Batch 110, Loss: 0.3624
Batch 120, Loss: 0.3496
Batch 130, Loss: 0.3450
Batch 140, Loss: 0.4035
Batch 150, Loss: 0.3517
Batch 160, Loss: 0.3731
Batch 170, Loss: 0.3787
Batch 180, Loss: 0.3617
Batch 190, Loss: 0.3540
Batch 200, Loss: 0.3752
Batch 210, Loss: 0.3450
Batch 220, Loss: 0.3532
Batch 230, Loss: 0.3694
Batch 240, Loss: 0.3952
Batch 250, Loss: 0.3913
Batch 260, Loss: 0.3782
Batch 270, Loss: 0.3517
Batch 280, Loss: 0.3746
Batch 290, Loss: 0.3649
Batch 300, Loss: 0.3948
Batch 310, Loss: 0.4063
Batch 320, Loss: 0.3949
Batch 330, Loss: 0.3617
Batch 340, Loss: 0.3857
Batch 350, Loss: 0.3501
Batch 360, Loss: 0.4120
Batch 370, Loss: 0.3802
Batch 380, Loss: 0.3930
Batch 390, Loss: 0.3525
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 24.936219215393066 seconds
Epoch 122 accuracy: 90.11%
Batch 10, Loss: 0.3549
Batch 20, Loss: 0.3726
Batch 30, Loss: 0.3737
Batch 40, Loss: 0.3681
Batch 50, Loss: 0.3761
Batch 60, Loss: 0.3646
Batch 70, Loss: 0.3739
Batch 80, Loss: 0.3525
Batch 90, Loss: 0.3819
Batch 100, Loss: 0.3747
Batch 110, Loss: 0.3794
Batch 120, Loss: 0.3806
Batch 130, Loss: 0.3714
Batch 140, Loss: 0.3630
Batch 150, Loss: 0.3959
Batch 160, Loss: 0.3534
Batch 170, Loss: 0.3859
Batch 180, Loss: 0.3555
Batch 190, Loss: 0.3718
Batch 200, Loss: 0.3282
Batch 210, Loss: 0.3836
Batch 220, Loss: 0.3799
Batch 230, Loss: 0.3447
Batch 240, Loss: 0.3720
Batch 250, Loss: 0.3697
Batch 260, Loss: 0.3561
Batch 270, Loss: 0.3652
Batch 280, Loss: 0.4320
Batch 290, Loss: 0.3752
Batch 300, Loss: 0.3625
Batch 310, Loss: 0.3782
Batch 320, Loss: 0.3695
Batch 330, Loss: 0.3710
Batch 340, Loss: 0.3735
Batch 350, Loss: 0.3960
Batch 360, Loss: 0.4031
Batch 370, Loss: 0.4240
Batch 380, Loss: 0.3911
Batch 390, Loss: 0.3587
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 24.90806770324707 seconds
Epoch 123 accuracy: 91.12%
Batch 10, Loss: 0.3849
Batch 20, Loss: 0.3665
Batch 30, Loss: 0.3433
Batch 40, Loss: 0.3357
Batch 50, Loss: 0.3710
Batch 60, Loss: 0.3436
Batch 70, Loss: 0.3695
Batch 80, Loss: 0.3680
Batch 90, Loss: 0.3541
Batch 100, Loss: 0.4111
Batch 110, Loss: 0.3568
Batch 120, Loss: 0.3650
Batch 130, Loss: 0.3723
Batch 140, Loss: 0.3720
Batch 150, Loss: 0.3522
Batch 160, Loss: 0.3771
Batch 170, Loss: 0.3616
Batch 180, Loss: 0.3859
Batch 190, Loss: 0.3535
Batch 200, Loss: 0.3467
Batch 210, Loss: 0.3404
Batch 220, Loss: 0.3469
Batch 230, Loss: 0.3955
Batch 240, Loss: 0.3742
Batch 250, Loss: 0.3975
Batch 260, Loss: 0.3658
Batch 270, Loss: 0.3751
Batch 280, Loss: 0.3500
Batch 290, Loss: 0.3506
Batch 300, Loss: 0.3359
Batch 310, Loss: 0.3843
Batch 320, Loss: 0.3548
Batch 330, Loss: 0.3527
Batch 340, Loss: 0.3698
Batch 350, Loss: 0.3809
Batch 360, Loss: 0.3795
Batch 370, Loss: 0.3961
Batch 380, Loss: 0.3798
Batch 390, Loss: 0.3690
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 24.939030408859253 seconds
Epoch 124 accuracy: 89.48%
Batch 10, Loss: 0.3512
Batch 20, Loss: 0.3743
Batch 30, Loss: 0.3754
Batch 40, Loss: 0.3220
Batch 50, Loss: 0.3253
Batch 60, Loss: 0.3761
Batch 70, Loss: 0.3805
Batch 80, Loss: 0.3528
Batch 90, Loss: 0.4006
Batch 100, Loss: 0.3690
Batch 110, Loss: 0.3746
Batch 120, Loss: 0.3858
Batch 130, Loss: 0.4004
Batch 140, Loss: 0.3510
Batch 150, Loss: 0.3758
Batch 160, Loss: 0.3851
Batch 170, Loss: 0.3940
Batch 180, Loss: 0.3964
Batch 190, Loss: 0.3885
Batch 200, Loss: 0.3598
Batch 210, Loss: 0.3336
Batch 220, Loss: 0.3583
Batch 230, Loss: 0.3665
Batch 240, Loss: 0.3557
Batch 250, Loss: 0.3408
Batch 260, Loss: 0.3676
Batch 270, Loss: 0.3779
Batch 280, Loss: 0.3665
Batch 290, Loss: 0.3570
Batch 300, Loss: 0.3659
Batch 310, Loss: 0.3628
Batch 320, Loss: 0.3586
Batch 330, Loss: 0.3641
Batch 340, Loss: 0.3622
Batch 350, Loss: 0.3943
Batch 360, Loss: 0.3680
Batch 370, Loss: 0.3565
Batch 380, Loss: 0.3711
Batch 390, Loss: 0.3907
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 24.847567081451416 seconds
Epoch 125 accuracy: 90.4%
Batch 10, Loss: 0.4073
Batch 20, Loss: 0.3367
Batch 30, Loss: 0.3495
Batch 40, Loss: 0.3429
Batch 50, Loss: 0.3311
Batch 60, Loss: 0.3383
Batch 70, Loss: 0.3500
Batch 80, Loss: 0.3635
Batch 90, Loss: 0.3377
Batch 100, Loss: 0.3380
Batch 110, Loss: 0.3648
Batch 120, Loss: 0.3783
Batch 130, Loss: 0.3716
Batch 140, Loss: 0.3702
Batch 150, Loss: 0.3473
Batch 160, Loss: 0.3821
Batch 170, Loss: 0.3578
Batch 180, Loss: 0.3750
Batch 190, Loss: 0.3911
Batch 200, Loss: 0.3781
Batch 210, Loss: 0.3876
Batch 220, Loss: 0.3697
Batch 230, Loss: 0.3366
Batch 240, Loss: 0.3609
Batch 250, Loss: 0.3607
Batch 260, Loss: 0.3456
Batch 270, Loss: 0.3690
Batch 280, Loss: 0.3666
Batch 290, Loss: 0.3859
Batch 300, Loss: 0.3497
Batch 310, Loss: 0.3636
Batch 320, Loss: 0.3492
Batch 330, Loss: 0.3725
Batch 340, Loss: 0.3609
Batch 350, Loss: 0.3588
Batch 360, Loss: 0.3577
Batch 370, Loss: 0.3607
Batch 380, Loss: 0.3717
Batch 390, Loss: 0.3370
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 24.890740871429443 seconds
Epoch 126 accuracy: 90.42%
Batch 10, Loss: 0.3458
Batch 20, Loss: 0.3462
Batch 30, Loss: 0.3677
Batch 40, Loss: 0.3739
Batch 50, Loss: 0.3364
Batch 60, Loss: 0.3773
Batch 70, Loss: 0.3481
Batch 80, Loss: 0.3765
Batch 90, Loss: 0.3573
Batch 100, Loss: 0.3427
Batch 110, Loss: 0.3852
Batch 120, Loss: 0.3581
Batch 130, Loss: 0.3343
Batch 140, Loss: 0.3346
Batch 150, Loss: 0.3361
Batch 160, Loss: 0.3478
Batch 170, Loss: 0.3771
Batch 180, Loss: 0.3498
Batch 190, Loss: 0.3435
Batch 200, Loss: 0.3986
Batch 210, Loss: 0.3469
Batch 220, Loss: 0.3777
Batch 230, Loss: 0.3622
Batch 240, Loss: 0.3339
Batch 250, Loss: 0.3459
Batch 260, Loss: 0.3678
Batch 270, Loss: 0.3653
Batch 280, Loss: 0.3409
Batch 290, Loss: 0.3691
Batch 300, Loss: 0.3514
Batch 310, Loss: 0.4203
Batch 320, Loss: 0.3809
Batch 330, Loss: 0.3603
Batch 340, Loss: 0.3810
Batch 350, Loss: 0.3842
Batch 360, Loss: 0.3735
Batch 370, Loss: 0.3392
Batch 380, Loss: 0.3460
Batch 390, Loss: 0.3354
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 24.86666250228882 seconds
Epoch 127 accuracy: 90.91%
Batch 10, Loss: 0.3623
Batch 20, Loss: 0.3341
Batch 30, Loss: 0.3348
Batch 40, Loss: 0.3681
Batch 50, Loss: 0.3847
Batch 60, Loss: 0.3301
Batch 70, Loss: 0.3964
Batch 80, Loss: 0.3643
Batch 90, Loss: 0.3524
Batch 100, Loss: 0.3724
Batch 110, Loss: 0.3665
Batch 120, Loss: 0.3686
Batch 130, Loss: 0.3560
Batch 140, Loss: 0.3659
Batch 150, Loss: 0.3378
Batch 160, Loss: 0.3638
Batch 170, Loss: 0.3203
Batch 180, Loss: 0.3325
Batch 190, Loss: 0.3499
Batch 200, Loss: 0.3893
Batch 210, Loss: 0.3932
Batch 220, Loss: 0.4211
Batch 230, Loss: 0.3323
Batch 240, Loss: 0.3536
Batch 250, Loss: 0.3673
Batch 260, Loss: 0.3759
Batch 270, Loss: 0.3860
Batch 280, Loss: 0.3560
Batch 290, Loss: 0.3540
Batch 300, Loss: 0.3464
Batch 310, Loss: 0.3718
Batch 320, Loss: 0.3603
Batch 330, Loss: 0.3462
Batch 340, Loss: 0.3473
Batch 350, Loss: 0.3590
Batch 360, Loss: 0.3917
Batch 370, Loss: 0.3678
Batch 380, Loss: 0.3523
Batch 390, Loss: 0.3761
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 24.85794734954834 seconds
Epoch 128 accuracy: 91.82%
Batch 10, Loss: 0.3552
Batch 20, Loss: 0.3430
Batch 30, Loss: 0.3898
Batch 40, Loss: 0.3529
Batch 50, Loss: 0.3736
Batch 60, Loss: 0.3297
Batch 70, Loss: 0.3750
Batch 80, Loss: 0.3207
Batch 90, Loss: 0.3481
Batch 100, Loss: 0.3379
Batch 110, Loss: 0.3532
Batch 120, Loss: 0.3373
Batch 130, Loss: 0.3607
Batch 140, Loss: 0.3405
Batch 150, Loss: 0.3718
Batch 160, Loss: 0.3685
Batch 170, Loss: 0.3626
Batch 180, Loss: 0.3167
Batch 190, Loss: 0.3658
Batch 200, Loss: 0.3176
Batch 210, Loss: 0.3539
Batch 220, Loss: 0.3671
Batch 230, Loss: 0.3718
Batch 240, Loss: 0.3711
Batch 250, Loss: 0.3287
Batch 260, Loss: 0.3455
Batch 270, Loss: 0.3226
Batch 280, Loss: 0.3506
Batch 290, Loss: 0.3688
Batch 300, Loss: 0.3576
Batch 310, Loss: 0.3823
Batch 320, Loss: 0.3629
Batch 330, Loss: 0.3516
Batch 340, Loss: 0.3719
Batch 350, Loss: 0.3131
Batch 360, Loss: 0.3183
Batch 370, Loss: 0.3546
Batch 380, Loss: 0.3282
Batch 390, Loss: 0.3337
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 24.876522302627563 seconds
Epoch 129 accuracy: 91.41%
Batch 10, Loss: 0.3340
Batch 20, Loss: 0.3670
Batch 30, Loss: 0.3640
Batch 40, Loss: 0.3192
Batch 50, Loss: 0.3615
Batch 60, Loss: 0.3587
Batch 70, Loss: 0.3609
Batch 80, Loss: 0.3714
Batch 90, Loss: 0.3391
Batch 100, Loss: 0.3612
Batch 110, Loss: 0.3582
Batch 120, Loss: 0.3355
Batch 130, Loss: 0.3507
Batch 140, Loss: 0.3808
Batch 150, Loss: 0.3766
Batch 160, Loss: 0.3540
Batch 170, Loss: 0.3531
Batch 180, Loss: 0.3187
Batch 190, Loss: 0.3535
Batch 200, Loss: 0.3109
Batch 210, Loss: 0.3268
Batch 220, Loss: 0.3757
Batch 230, Loss: 0.3286
Batch 240, Loss: 0.3326
Batch 250, Loss: 0.3413
Batch 260, Loss: 0.3521
Batch 270, Loss: 0.3250
Batch 280, Loss: 0.3233
Batch 290, Loss: 0.3593
Batch 300, Loss: 0.3595
Batch 310, Loss: 0.3602
Batch 320, Loss: 0.3626
Batch 330, Loss: 0.3402
Batch 340, Loss: 0.3548
Batch 350, Loss: 0.3626
Batch 360, Loss: 0.3658
Batch 370, Loss: 0.3619
Batch 380, Loss: 0.3564
Batch 390, Loss: 0.3523
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 24.926779747009277 seconds
Epoch 130 accuracy: 91.51%
Batch 10, Loss: 0.3322
Batch 20, Loss: 0.3421
Batch 30, Loss: 0.3147
Batch 40, Loss: 0.3155
Batch 50, Loss: 0.3139
Batch 60, Loss: 0.3381
Batch 70, Loss: 0.3225
Batch 80, Loss: 0.3324
Batch 90, Loss: 0.3634
Batch 100, Loss: 0.3213
Batch 110, Loss: 0.3586
Batch 120, Loss: 0.3556
Batch 130, Loss: 0.3109
Batch 140, Loss: 0.3299
Batch 150, Loss: 0.3752
Batch 160, Loss: 0.3429
Batch 170, Loss: 0.3252
Batch 180, Loss: 0.3340
Batch 190, Loss: 0.3483
Batch 200, Loss: 0.3130
Batch 210, Loss: 0.3717
Batch 220, Loss: 0.3401
Batch 230, Loss: 0.3671
Batch 240, Loss: 0.3297
Batch 250, Loss: 0.3257
Batch 260, Loss: 0.3330
Batch 270, Loss: 0.3473
Batch 280, Loss: 0.3858
Batch 290, Loss: 0.3301
Batch 300, Loss: 0.3444
Batch 310, Loss: 0.3483
Batch 320, Loss: 0.4391
Batch 330, Loss: 0.3829
Batch 340, Loss: 0.3510
Batch 350, Loss: 0.3558
Batch 360, Loss: 0.3613
Batch 370, Loss: 0.3551
Batch 380, Loss: 0.3265
Batch 390, Loss: 0.3532
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 24.836869955062866 seconds
Epoch 131 accuracy: 91.65%
Batch 10, Loss: 0.3499
Batch 20, Loss: 0.3360
Batch 30, Loss: 0.3441
Batch 40, Loss: 0.3285
Batch 50, Loss: 0.3537
Batch 60, Loss: 0.3574
Batch 70, Loss: 0.3378
Batch 80, Loss: 0.3616
Batch 90, Loss: 0.3581
Batch 100, Loss: 0.3276
Batch 110, Loss: 0.3202
Batch 120, Loss: 0.3593
Batch 130, Loss: 0.3489
Batch 140, Loss: 0.3578
Batch 150, Loss: 0.3309
Batch 160, Loss: 0.3754
Batch 170, Loss: 0.3276
Batch 180, Loss: 0.3536
Batch 190, Loss: 0.3739
Batch 200, Loss: 0.3317
Batch 210, Loss: 0.3534
Batch 220, Loss: 0.3324
Batch 230, Loss: 0.3304
Batch 240, Loss: 0.3064
Batch 250, Loss: 0.3582
Batch 260, Loss: 0.3616
Batch 270, Loss: 0.3431
Batch 280, Loss: 0.3194
Batch 290, Loss: 0.3488
Batch 300, Loss: 0.3497
Batch 310, Loss: 0.3110
Batch 320, Loss: 0.3675
Batch 330, Loss: 0.3434
Batch 340, Loss: 0.3418
Batch 350, Loss: 0.3696
Batch 360, Loss: 0.3351
Batch 370, Loss: 0.3149
Batch 380, Loss: 0.3187
Batch 390, Loss: 0.3679
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 24.848790168762207 seconds
Epoch 132 accuracy: 91.71%
Batch 10, Loss: 0.3572
Batch 20, Loss: 0.3359
Batch 30, Loss: 0.3498
Batch 40, Loss: 0.3143
Batch 50, Loss: 0.3442
Batch 60, Loss: 0.3504
Batch 70, Loss: 0.3719
Batch 80, Loss: 0.3273
Batch 90, Loss: 0.3453
Batch 100, Loss: 0.3387
Batch 110, Loss: 0.3614
Batch 120, Loss: 0.3285
Batch 130, Loss: 0.2919
Batch 140, Loss: 0.3635
Batch 150, Loss: 0.3472
Batch 160, Loss: 0.3644
Batch 170, Loss: 0.3170
Batch 180, Loss: 0.3207
Batch 190, Loss: 0.3295
Batch 200, Loss: 0.3411
Batch 210, Loss: 0.3441
Batch 220, Loss: 0.3415
Batch 230, Loss: 0.3338
Batch 240, Loss: 0.3675
Batch 250, Loss: 0.3608
Batch 260, Loss: 0.3170
Batch 270, Loss: 0.3501
Batch 280, Loss: 0.3403
Batch 290, Loss: 0.3606
Batch 300, Loss: 0.3561
Batch 310, Loss: 0.3491
Batch 320, Loss: 0.3294
Batch 330, Loss: 0.3582
Batch 340, Loss: 0.3585
Batch 350, Loss: 0.3432
Batch 360, Loss: 0.2889
Batch 370, Loss: 0.3649
Batch 380, Loss: 0.3460
Batch 390, Loss: 0.3400
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 24.87369465827942 seconds
Epoch 133 accuracy: 91.66%
Batch 10, Loss: 0.3487
Batch 20, Loss: 0.3000
Batch 30, Loss: 0.3301
Batch 40, Loss: 0.3541
Batch 50, Loss: 0.3236
Batch 60, Loss: 0.3595
Batch 70, Loss: 0.3333
Batch 80, Loss: 0.3451
Batch 90, Loss: 0.3322
Batch 100, Loss: 0.3131
Batch 110, Loss: 0.3195
Batch 120, Loss: 0.3093
Batch 130, Loss: 0.3207
Batch 140, Loss: 0.3740
Batch 150, Loss: 0.3360
Batch 160, Loss: 0.3501
Batch 170, Loss: 0.3312
Batch 180, Loss: 0.3436
Batch 190, Loss: 0.3493
Batch 200, Loss: 0.3479
Batch 210, Loss: 0.3438
Batch 220, Loss: 0.3591
Batch 230, Loss: 0.3618
Batch 240, Loss: 0.3463
Batch 250, Loss: 0.3557
Batch 260, Loss: 0.3360
Batch 270, Loss: 0.3465
Batch 280, Loss: 0.3263
Batch 290, Loss: 0.3214
Batch 300, Loss: 0.3076
Batch 310, Loss: 0.2771
Batch 320, Loss: 0.3321
Batch 330, Loss: 0.3168
Batch 340, Loss: 0.3590
Batch 350, Loss: 0.3459
Batch 360, Loss: 0.3269
Batch 370, Loss: 0.3769
Batch 380, Loss: 0.3562
Batch 390, Loss: 0.3578
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 24.908989906311035 seconds
Epoch 134 accuracy: 92.5%
Batch 10, Loss: 0.3431
Batch 20, Loss: 0.3566
Batch 30, Loss: 0.3440
Batch 40, Loss: 0.3398
Batch 50, Loss: 0.3444
Batch 60, Loss: 0.3237
Batch 70, Loss: 0.3105
Batch 80, Loss: 0.3347
Batch 90, Loss: 0.3201
Batch 100, Loss: 0.3396
Batch 110, Loss: 0.3187
Batch 120, Loss: 0.3275
Batch 130, Loss: 0.3342
Batch 140, Loss: 0.3291
Batch 150, Loss: 0.3402
Batch 160, Loss: 0.3596
Batch 170, Loss: 0.3016
Batch 180, Loss: 0.3502
Batch 190, Loss: 0.3273
Batch 200, Loss: 0.3449
Batch 210, Loss: 0.3198
Batch 220, Loss: 0.3308
Batch 230, Loss: 0.3024
Batch 240, Loss: 0.3206
Batch 250, Loss: 0.3250
Batch 260, Loss: 0.3416
Batch 270, Loss: 0.3022
Batch 280, Loss: 0.3621
Batch 290, Loss: 0.3568
Batch 300, Loss: 0.3567
Batch 310, Loss: 0.3568
Batch 320, Loss: 0.3495
Batch 330, Loss: 0.3383
Batch 340, Loss: 0.3430
Batch 350, Loss: 0.3603
Batch 360, Loss: 0.3095
Batch 370, Loss: 0.2959
Batch 380, Loss: 0.3323
Batch 390, Loss: 0.3642
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 24.853853702545166 seconds
Epoch 135 accuracy: 92.0%
Batch 10, Loss: 0.3024
Batch 20, Loss: 0.3119
Batch 30, Loss: 0.3238
Batch 40, Loss: 0.3064
Batch 50, Loss: 0.3357
Batch 60, Loss: 0.3167
Batch 70, Loss: 0.3589
Batch 80, Loss: 0.3486
Batch 90, Loss: 0.3336
Batch 100, Loss: 0.3250
Batch 110, Loss: 0.3276
Batch 120, Loss: 0.3316
Batch 130, Loss: 0.3559
Batch 140, Loss: 0.3431
Batch 150, Loss: 0.3434
Batch 160, Loss: 0.3340
Batch 170, Loss: 0.3328
Batch 180, Loss: 0.3645
Batch 190, Loss: 0.3580
Batch 200, Loss: 0.3247
Batch 210, Loss: 0.3394
Batch 220, Loss: 0.3233
Batch 230, Loss: 0.3170
Batch 240, Loss: 0.3222
Batch 250, Loss: 0.3328
Batch 260, Loss: 0.3332
Batch 270, Loss: 0.3228
Batch 280, Loss: 0.3288
Batch 290, Loss: 0.3658
Batch 300, Loss: 0.3102
Batch 310, Loss: 0.3278
Batch 320, Loss: 0.3291
Batch 330, Loss: 0.2865
Batch 340, Loss: 0.3438
Batch 350, Loss: 0.3272
Batch 360, Loss: 0.3432
Batch 370, Loss: 0.3439
Batch 380, Loss: 0.3464
Batch 390, Loss: 0.3306
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 24.896793603897095 seconds
Epoch 136 accuracy: 91.98%
Batch 10, Loss: 0.3453
Batch 20, Loss: 0.3173
Batch 30, Loss: 0.3462
Batch 40, Loss: 0.3221
Batch 50, Loss: 0.3151
Batch 60, Loss: 0.3184
Batch 70, Loss: 0.2784
Batch 80, Loss: 0.3203
Batch 90, Loss: 0.3340
Batch 100, Loss: 0.3245
Batch 110, Loss: 0.2924
Batch 120, Loss: 0.3164
Batch 130, Loss: 0.2977
Batch 140, Loss: 0.2928
Batch 150, Loss: 0.3267
Batch 160, Loss: 0.3113
Batch 170, Loss: 0.3475
Batch 180, Loss: 0.3129
Batch 190, Loss: 0.2854
Batch 200, Loss: 0.3160
Batch 210, Loss: 0.3127
Batch 220, Loss: 0.3658
Batch 230, Loss: 0.3480
Batch 240, Loss: 0.3397
Batch 250, Loss: 0.3274
Batch 260, Loss: 0.3349
Batch 270, Loss: 0.3317
Batch 280, Loss: 0.3449
Batch 290, Loss: 0.3490
Batch 300, Loss: 0.3140
Batch 310, Loss: 0.3311
Batch 320, Loss: 0.3019
Batch 330, Loss: 0.3765
Batch 340, Loss: 0.3201
Batch 350, Loss: 0.3184
Batch 360, Loss: 0.3154
Batch 370, Loss: 0.3727
Batch 380, Loss: 0.3419
Batch 390, Loss: 0.3617
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 24.911911010742188 seconds
Epoch 137 accuracy: 91.62%
Batch 10, Loss: 0.3336
Batch 20, Loss: 0.3547
Batch 30, Loss: 0.3107
Batch 40, Loss: 0.3230
Batch 50, Loss: 0.3089
Batch 60, Loss: 0.3279
Batch 70, Loss: 0.3275
Batch 80, Loss: 0.3008
Batch 90, Loss: 0.3544
Batch 100, Loss: 0.3382
Batch 110, Loss: 0.3187
Batch 120, Loss: 0.2872
Batch 130, Loss: 0.3247
Batch 140, Loss: 0.3196
Batch 150, Loss: 0.3412
Batch 160, Loss: 0.3117
Batch 170, Loss: 0.2952
Batch 180, Loss: 0.3235
Batch 190, Loss: 0.2970
Batch 200, Loss: 0.3258
Batch 210, Loss: 0.3353
Batch 220, Loss: 0.3454
Batch 230, Loss: 0.3583
Batch 240, Loss: 0.3275
Batch 250, Loss: 0.3150
Batch 260, Loss: 0.3192
Batch 270, Loss: 0.2951
Batch 280, Loss: 0.3465
Batch 290, Loss: 0.3557
Batch 300, Loss: 0.3296
Batch 310, Loss: 0.3362
Batch 320, Loss: 0.3345
Batch 330, Loss: 0.3189
Batch 340, Loss: 0.3290
Batch 350, Loss: 0.3277
Batch 360, Loss: 0.3103
Batch 370, Loss: 0.3156
Batch 380, Loss: 0.3333
Batch 390, Loss: 0.3369
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 24.8939790725708 seconds
Epoch 138 accuracy: 92.2%
Batch 10, Loss: 0.3174
Batch 20, Loss: 0.3257
Batch 30, Loss: 0.3236
Batch 40, Loss: 0.2751
Batch 50, Loss: 0.3024
Batch 60, Loss: 0.2797
Batch 70, Loss: 0.3276
Batch 80, Loss: 0.3017
Batch 90, Loss: 0.3337
Batch 100, Loss: 0.3146
Batch 110, Loss: 0.2737
Batch 120, Loss: 0.3090
Batch 130, Loss: 0.3210
Batch 140, Loss: 0.3072
Batch 150, Loss: 0.2923
Batch 160, Loss: 0.3462
Batch 170, Loss: 0.3175
Batch 180, Loss: 0.3181
Batch 190, Loss: 0.2852
Batch 200, Loss: 0.3209
Batch 210, Loss: 0.3021
Batch 220, Loss: 0.3250
Batch 230, Loss: 0.3162
Batch 240, Loss: 0.3463
Batch 250, Loss: 0.3480
Batch 260, Loss: 0.3073
Batch 270, Loss: 0.3279
Batch 280, Loss: 0.3490
Batch 290, Loss: 0.3439
Batch 300, Loss: 0.3209
Batch 310, Loss: 0.3436
Batch 320, Loss: 0.3360
Batch 330, Loss: 0.3538
Batch 340, Loss: 0.3319
Batch 350, Loss: 0.3497
Batch 360, Loss: 0.3315
Batch 370, Loss: 0.3443
Batch 380, Loss: 0.3199
Batch 390, Loss: 0.3621
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 24.89949131011963 seconds
Epoch 139 accuracy: 92.08%
Batch 10, Loss: 0.3138
Batch 20, Loss: 0.3386
Batch 30, Loss: 0.3463
Batch 40, Loss: 0.3181
Batch 50, Loss: 0.2852
Batch 60, Loss: 0.3031
Batch 70, Loss: 0.3077
Batch 80, Loss: 0.3060
Batch 90, Loss: 0.3371
Batch 100, Loss: 0.3104
Batch 110, Loss: 0.3152
Batch 120, Loss: 0.3284
Batch 130, Loss: 0.3262
Batch 140, Loss: 0.3127
Batch 150, Loss: 0.3251
Batch 160, Loss: 0.3309
Batch 170, Loss: 0.2965
Batch 180, Loss: 0.3179
Batch 190, Loss: 0.2961
Batch 200, Loss: 0.2842
Batch 210, Loss: 0.3199
Batch 220, Loss: 0.3477
Batch 230, Loss: 0.3407
Batch 240, Loss: 0.3176
Batch 250, Loss: 0.3145
Batch 260, Loss: 0.3470
Batch 270, Loss: 0.3208
Batch 280, Loss: 0.3317
Batch 290, Loss: 0.3209
Batch 300, Loss: 0.3013
Batch 310, Loss: 0.3195
Batch 320, Loss: 0.3064
Batch 330, Loss: 0.3060
Batch 340, Loss: 0.3136
Batch 350, Loss: 0.3223
Batch 360, Loss: 0.3233
Batch 370, Loss: 0.3454
Batch 380, Loss: 0.3194
Batch 390, Loss: 0.2865
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 24.99631357192993 seconds
Epoch 140 accuracy: 92.53%
Batch 10, Loss: 0.3300
Batch 20, Loss: 0.3413
Batch 30, Loss: 0.3056
Batch 40, Loss: 0.3104
Batch 50, Loss: 0.3375
Batch 60, Loss: 0.3073
Batch 70, Loss: 0.3179
Batch 80, Loss: 0.3049
Batch 90, Loss: 0.2994
Batch 100, Loss: 0.2848
Batch 110, Loss: 0.3123
Batch 120, Loss: 0.3126
Batch 130, Loss: 0.3061
Batch 140, Loss: 0.3002
Batch 150, Loss: 0.3352
Batch 160, Loss: 0.3086
Batch 170, Loss: 0.3075
Batch 180, Loss: 0.2848
Batch 190, Loss: 0.2864
Batch 200, Loss: 0.3032
Batch 210, Loss: 0.3043
Batch 220, Loss: 0.2962
Batch 230, Loss: 0.3261
Batch 240, Loss: 0.3150
Batch 250, Loss: 0.3309
Batch 260, Loss: 0.3276
Batch 270, Loss: 0.3292
Batch 280, Loss: 0.3242
Batch 290, Loss: 0.2917
Batch 300, Loss: 0.3142
Batch 310, Loss: 0.3168
Batch 320, Loss: 0.2921
Batch 330, Loss: 0.3074
Batch 340, Loss: 0.3091
Batch 350, Loss: 0.3433
Batch 360, Loss: 0.3190
Batch 370, Loss: 0.3157
Batch 380, Loss: 0.3279
Batch 390, Loss: 0.3184
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 24.911763668060303 seconds
Epoch 141 accuracy: 92.06%
Batch 10, Loss: 0.3099
Batch 20, Loss: 0.3230
Batch 30, Loss: 0.2903
Batch 40, Loss: 0.3188
Batch 50, Loss: 0.2843
Batch 60, Loss: 0.3032
Batch 70, Loss: 0.2818
Batch 80, Loss: 0.3181
Batch 90, Loss: 0.2931
Batch 100, Loss: 0.3187
Batch 110, Loss: 0.3289
Batch 120, Loss: 0.3058
Batch 130, Loss: 0.3185
Batch 140, Loss: 0.3148
Batch 150, Loss: 0.2976
Batch 160, Loss: 0.2998
Batch 170, Loss: 0.3060
Batch 180, Loss: 0.3223
Batch 190, Loss: 0.3037
Batch 200, Loss: 0.3294
Batch 210, Loss: 0.3440
Batch 220, Loss: 0.3104
Batch 230, Loss: 0.3343
Batch 240, Loss: 0.2953
Batch 250, Loss: 0.3060
Batch 260, Loss: 0.2903
Batch 270, Loss: 0.3206
Batch 280, Loss: 0.2935
Batch 290, Loss: 0.3150
Batch 300, Loss: 0.2939
Batch 310, Loss: 0.2899
Batch 320, Loss: 0.2918
Batch 330, Loss: 0.3054
Batch 340, Loss: 0.2905
Batch 350, Loss: 0.3616
Batch 360, Loss: 0.3096
Batch 370, Loss: 0.3321
Batch 380, Loss: 0.3114
Batch 390, Loss: 0.2773
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 24.836188554763794 seconds
Epoch 142 accuracy: 92.54%
Batch 10, Loss: 0.2964
Batch 20, Loss: 0.2821
Batch 30, Loss: 0.3003
Batch 40, Loss: 0.3072
Batch 50, Loss: 0.2702
Batch 60, Loss: 0.3003
Batch 70, Loss: 0.2961
Batch 80, Loss: 0.3126
Batch 90, Loss: 0.3058
Batch 100, Loss: 0.2897
Batch 110, Loss: 0.2879
Batch 120, Loss: 0.2973
Batch 130, Loss: 0.3018
Batch 140, Loss: 0.2793
Batch 150, Loss: 0.2962
Batch 160, Loss: 0.2832
Batch 170, Loss: 0.3324
Batch 180, Loss: 0.3097
Batch 190, Loss: 0.3307
Batch 200, Loss: 0.3497
Batch 210, Loss: 0.2929
Batch 220, Loss: 0.3326
Batch 230, Loss: 0.3129
Batch 240, Loss: 0.2741
Batch 250, Loss: 0.2895
Batch 260, Loss: 0.3395
Batch 270, Loss: 0.3157
Batch 280, Loss: 0.3021
Batch 290, Loss: 0.2649
Batch 300, Loss: 0.3038
Batch 310, Loss: 0.3296
Batch 320, Loss: 0.2976
Batch 330, Loss: 0.2992
Batch 340, Loss: 0.3538
Batch 350, Loss: 0.3053
Batch 360, Loss: 0.3212
Batch 370, Loss: 0.3082
Batch 380, Loss: 0.3376
Batch 390, Loss: 0.3083
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 24.83085799217224 seconds
Epoch 143 accuracy: 93.08%
Batch 10, Loss: 0.2893
Batch 20, Loss: 0.3159
Batch 30, Loss: 0.2871
Batch 40, Loss: 0.3062
Batch 50, Loss: 0.2806
Batch 60, Loss: 0.2734
Batch 70, Loss: 0.3038
Batch 80, Loss: 0.3035
Batch 90, Loss: 0.2830
Batch 100, Loss: 0.3015
Batch 110, Loss: 0.2955
Batch 120, Loss: 0.3014
Batch 130, Loss: 0.2975
Batch 140, Loss: 0.3162
Batch 150, Loss: 0.3388
Batch 160, Loss: 0.3454
Batch 170, Loss: 0.3368
Batch 180, Loss: 0.2977
Batch 190, Loss: 0.2841
Batch 200, Loss: 0.3033
Batch 210, Loss: 0.3241
Batch 220, Loss: 0.2725
Batch 230, Loss: 0.3091
Batch 240, Loss: 0.2899
Batch 250, Loss: 0.3196
Batch 260, Loss: 0.3313
Batch 270, Loss: 0.3056
Batch 280, Loss: 0.2779
Batch 290, Loss: 0.2899
Batch 300, Loss: 0.3011
Batch 310, Loss: 0.2584
Batch 320, Loss: 0.3032
Batch 330, Loss: 0.3264
Batch 340, Loss: 0.3497
Batch 350, Loss: 0.3446
Batch 360, Loss: 0.2926
Batch 370, Loss: 0.2926
Batch 380, Loss: 0.2910
Batch 390, Loss: 0.2942
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 24.923990488052368 seconds
Epoch 144 accuracy: 92.51%
Batch 10, Loss: 0.3123
Batch 20, Loss: 0.3018
Batch 30, Loss: 0.3193
Batch 40, Loss: 0.3073
Batch 50, Loss: 0.2907
Batch 60, Loss: 0.2656
Batch 70, Loss: 0.2856
Batch 80, Loss: 0.3089
Batch 90, Loss: 0.2722
Batch 100, Loss: 0.2767
Batch 110, Loss: 0.3018
Batch 120, Loss: 0.2770
Batch 130, Loss: 0.3063
Batch 140, Loss: 0.2883
Batch 150, Loss: 0.2794
Batch 160, Loss: 0.2855
Batch 170, Loss: 0.3183
Batch 180, Loss: 0.3117
Batch 190, Loss: 0.2920
Batch 200, Loss: 0.2749
Batch 210, Loss: 0.2820
Batch 220, Loss: 0.2884
Batch 230, Loss: 0.2850
Batch 240, Loss: 0.3089
Batch 250, Loss: 0.2936
Batch 260, Loss: 0.2841
Batch 270, Loss: 0.3065
Batch 280, Loss: 0.2854
Batch 290, Loss: 0.3007
Batch 300, Loss: 0.2636
Batch 310, Loss: 0.2871
Batch 320, Loss: 0.2870
Batch 330, Loss: 0.2761
Batch 340, Loss: 0.3240
Batch 350, Loss: 0.2902
Batch 360, Loss: 0.3349
Batch 370, Loss: 0.3075
Batch 380, Loss: 0.3378
Batch 390, Loss: 0.3097
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 24.902645587921143 seconds
Epoch 145 accuracy: 92.51%
Batch 10, Loss: 0.3344
Batch 20, Loss: 0.2844
Batch 30, Loss: 0.3064
Batch 40, Loss: 0.3011
Batch 50, Loss: 0.3070
Batch 60, Loss: 0.2865
Batch 70, Loss: 0.3072
Batch 80, Loss: 0.3096
Batch 90, Loss: 0.2885
Batch 100, Loss: 0.3332
Batch 110, Loss: 0.3115
Batch 120, Loss: 0.3028
Batch 130, Loss: 0.3070
Batch 140, Loss: 0.3216
Batch 150, Loss: 0.3076
Batch 160, Loss: 0.2933
Batch 170, Loss: 0.2868
Batch 180, Loss: 0.2632
Batch 190, Loss: 0.2583
Batch 200, Loss: 0.3054
Batch 210, Loss: 0.2875
Batch 220, Loss: 0.2843
Batch 230, Loss: 0.3039
Batch 240, Loss: 0.2979
Batch 250, Loss: 0.3109
Batch 260, Loss: 0.2894
Batch 270, Loss: 0.3175
Batch 280, Loss: 0.3009
Batch 290, Loss: 0.3173
Batch 300, Loss: 0.2979
Batch 310, Loss: 0.3023
Batch 320, Loss: 0.3290
Batch 330, Loss: 0.2958
Batch 340, Loss: 0.2716
Batch 350, Loss: 0.2839
Batch 360, Loss: 0.3006
Batch 370, Loss: 0.3059
Batch 380, Loss: 0.2855
Batch 390, Loss: 0.3074
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 24.8804132938385 seconds
Epoch 146 accuracy: 92.88%
Batch 10, Loss: 0.2907
Batch 20, Loss: 0.2682
Batch 30, Loss: 0.3119
Batch 40, Loss: 0.2583
Batch 50, Loss: 0.3006
Batch 60, Loss: 0.3101
Batch 70, Loss: 0.2987
Batch 80, Loss: 0.2688
Batch 90, Loss: 0.3158
Batch 100, Loss: 0.2770
Batch 110, Loss: 0.2807
Batch 120, Loss: 0.2867
Batch 130, Loss: 0.3066
Batch 140, Loss: 0.2883
Batch 150, Loss: 0.3029
Batch 160, Loss: 0.2746
Batch 170, Loss: 0.3117
Batch 180, Loss: 0.2910
Batch 190, Loss: 0.2998
Batch 200, Loss: 0.2809
Batch 210, Loss: 0.3033
Batch 220, Loss: 0.2690
Batch 230, Loss: 0.2811
Batch 240, Loss: 0.2763
Batch 250, Loss: 0.2794
Batch 260, Loss: 0.3007
Batch 270, Loss: 0.2587
Batch 280, Loss: 0.3158
Batch 290, Loss: 0.3054
Batch 300, Loss: 0.3006
Batch 310, Loss: 0.2998
Batch 320, Loss: 0.3100
Batch 330, Loss: 0.3006
Batch 340, Loss: 0.2897
Batch 350, Loss: 0.2994
Batch 360, Loss: 0.3282
Batch 370, Loss: 0.3269
Batch 380, Loss: 0.2643
Batch 390, Loss: 0.2811
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 24.887387990951538 seconds
Epoch 147 accuracy: 93.07%
Batch 10, Loss: 0.2589
Batch 20, Loss: 0.2893
Batch 30, Loss: 0.2654
Batch 40, Loss: 0.2932
Batch 50, Loss: 0.2450
Batch 60, Loss: 0.2691
Batch 70, Loss: 0.2954
Batch 80, Loss: 0.2849
Batch 90, Loss: 0.3119
Batch 100, Loss: 0.2821
Batch 110, Loss: 0.3029
Batch 120, Loss: 0.2832
Batch 130, Loss: 0.2898
Batch 140, Loss: 0.2916
Batch 150, Loss: 0.2770
Batch 160, Loss: 0.2837
Batch 170, Loss: 0.2851
Batch 180, Loss: 0.2787
Batch 190, Loss: 0.3136
Batch 200, Loss: 0.2832
Batch 210, Loss: 0.2846
Batch 220, Loss: 0.2617
Batch 230, Loss: 0.3028
Batch 240, Loss: 0.2637
Batch 250, Loss: 0.2715
Batch 260, Loss: 0.2782
Batch 270, Loss: 0.2918
Batch 280, Loss: 0.2736
Batch 290, Loss: 0.2824
Batch 300, Loss: 0.2951
Batch 310, Loss: 0.2742
Batch 320, Loss: 0.2931
Batch 330, Loss: 0.2781
Batch 340, Loss: 0.2940
Batch 350, Loss: 0.3106
Batch 360, Loss: 0.3105
Batch 370, Loss: 0.2811
Batch 380, Loss: 0.2545
Batch 390, Loss: 0.2685
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 24.902907848358154 seconds
Epoch 148 accuracy: 93.25%
Batch 10, Loss: 0.3298
Batch 20, Loss: 0.2868
Batch 30, Loss: 0.2611
Batch 40, Loss: 0.2787
Batch 50, Loss: 0.3020
Batch 60, Loss: 0.2703
Batch 70, Loss: 0.2968
Batch 80, Loss: 0.2775
Batch 90, Loss: 0.2839
Batch 100, Loss: 0.2971
Batch 110, Loss: 0.2727
Batch 120, Loss: 0.2916
Batch 130, Loss: 0.2623
Batch 140, Loss: 0.2697
Batch 150, Loss: 0.2567
Batch 160, Loss: 0.2790
Batch 170, Loss: 0.2742
Batch 180, Loss: 0.2719
Batch 190, Loss: 0.2896
Batch 200, Loss: 0.2864
Batch 210, Loss: 0.2853
Batch 220, Loss: 0.2638
Batch 230, Loss: 0.2862
Batch 240, Loss: 0.2774
Batch 250, Loss: 0.2807
Batch 260, Loss: 0.2809
Batch 270, Loss: 0.2580
Batch 280, Loss: 0.2844
Batch 290, Loss: 0.2859
Batch 300, Loss: 0.2955
Batch 310, Loss: 0.2583
Batch 320, Loss: 0.2517
Batch 330, Loss: 0.2815
Batch 340, Loss: 0.2954
Batch 350, Loss: 0.2759
Batch 360, Loss: 0.3000
Batch 370, Loss: 0.3146
Batch 380, Loss: 0.2850
Batch 390, Loss: 0.2918
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 24.896780252456665 seconds
Epoch 149 accuracy: 93.37%
Batch 10, Loss: 0.2963
Batch 20, Loss: 0.2788
Batch 30, Loss: 0.2736
Batch 40, Loss: 0.2747
Batch 50, Loss: 0.2748
Batch 60, Loss: 0.2807
Batch 70, Loss: 0.2975
Batch 80, Loss: 0.3049
Batch 90, Loss: 0.2812
Batch 100, Loss: 0.2874
Batch 110, Loss: 0.2822
Batch 120, Loss: 0.3064
Batch 130, Loss: 0.2966
Batch 140, Loss: 0.2785
Batch 150, Loss: 0.2534
Batch 160, Loss: 0.3091
Batch 170, Loss: 0.3121
Batch 180, Loss: 0.2662
Batch 190, Loss: 0.2858
Batch 200, Loss: 0.2592
Batch 210, Loss: 0.3102
Batch 220, Loss: 0.2886
Batch 230, Loss: 0.2919
Batch 240, Loss: 0.3049
Batch 250, Loss: 0.2736
Batch 260, Loss: 0.2748
Batch 270, Loss: 0.2798
Batch 280, Loss: 0.2844
Batch 290, Loss: 0.2975
Batch 300, Loss: 0.2991
Batch 310, Loss: 0.2840
Batch 320, Loss: 0.2825
Batch 330, Loss: 0.2718
Batch 340, Loss: 0.2701
Batch 350, Loss: 0.2633
Batch 360, Loss: 0.2713
Batch 370, Loss: 0.2918
Batch 380, Loss: 0.2539
Batch 390, Loss: 0.2778
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 24.950310945510864 seconds
Epoch 150 accuracy: 93.07%
Batch 10, Loss: 0.2887
Batch 20, Loss: 0.2701
Batch 30, Loss: 0.2876
Batch 40, Loss: 0.2571
Batch 50, Loss: 0.2959
Batch 60, Loss: 0.2828
Batch 70, Loss: 0.2916
Batch 80, Loss: 0.2527
Batch 90, Loss: 0.3087
Batch 100, Loss: 0.2597
Batch 110, Loss: 0.2501
Batch 120, Loss: 0.2644
Batch 130, Loss: 0.3052
Batch 140, Loss: 0.2760
Batch 150, Loss: 0.3004
Batch 160, Loss: 0.2467
Batch 170, Loss: 0.2964
Batch 180, Loss: 0.2885
Batch 190, Loss: 0.2783
Batch 200, Loss: 0.2607
Batch 210, Loss: 0.2980
Batch 220, Loss: 0.2692
Batch 230, Loss: 0.2599
Batch 240, Loss: 0.2815
Batch 250, Loss: 0.2701
Batch 260, Loss: 0.2717
Batch 270, Loss: 0.2727
Batch 280, Loss: 0.2619
Batch 290, Loss: 0.2757
Batch 300, Loss: 0.2825
Batch 310, Loss: 0.2631
Batch 320, Loss: 0.2531
Batch 330, Loss: 0.3280
Batch 340, Loss: 0.2958
Batch 350, Loss: 0.2957
Batch 360, Loss: 0.3000
Batch 370, Loss: 0.2622
Batch 380, Loss: 0.2749
Batch 390, Loss: 0.2724
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 24.939908981323242 seconds
Epoch 151 accuracy: 93.96%
Batch 10, Loss: 0.2640
Batch 20, Loss: 0.2763
Batch 30, Loss: 0.2603
Batch 40, Loss: 0.2669
Batch 50, Loss: 0.2387
Batch 60, Loss: 0.2484
Batch 70, Loss: 0.2622
Batch 80, Loss: 0.2544
Batch 90, Loss: 0.2840
Batch 100, Loss: 0.2847
Batch 110, Loss: 0.2717
Batch 120, Loss: 0.2678
Batch 130, Loss: 0.2668
Batch 140, Loss: 0.2643
Batch 150, Loss: 0.2641
Batch 160, Loss: 0.2683
Batch 170, Loss: 0.2790
Batch 180, Loss: 0.2818
Batch 190, Loss: 0.2623
Batch 200, Loss: 0.2934
Batch 210, Loss: 0.2753
Batch 220, Loss: 0.2877
Batch 230, Loss: 0.2801
Batch 240, Loss: 0.2885
Batch 250, Loss: 0.2729
Batch 260, Loss: 0.2576
Batch 270, Loss: 0.2885
Batch 280, Loss: 0.2712
Batch 290, Loss: 0.2706
Batch 300, Loss: 0.2719
Batch 310, Loss: 0.2480
Batch 320, Loss: 0.2674
Batch 330, Loss: 0.2832
Batch 340, Loss: 0.2879
Batch 350, Loss: 0.2485
Batch 360, Loss: 0.3242
Batch 370, Loss: 0.2595
Batch 380, Loss: 0.2651
Batch 390, Loss: 0.2782
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 24.903531312942505 seconds
Epoch 152 accuracy: 93.97%
Batch 10, Loss: 0.2535
Batch 20, Loss: 0.2486
Batch 30, Loss: 0.2755
Batch 40, Loss: 0.2342
Batch 50, Loss: 0.2689
Batch 60, Loss: 0.2699
Batch 70, Loss: 0.2703
Batch 80, Loss: 0.2695
Batch 90, Loss: 0.2712
Batch 100, Loss: 0.2724
Batch 110, Loss: 0.2550
Batch 120, Loss: 0.2640
Batch 130, Loss: 0.2597
Batch 140, Loss: 0.2698
Batch 150, Loss: 0.2632
Batch 160, Loss: 0.2451
Batch 170, Loss: 0.2711
Batch 180, Loss: 0.2381
Batch 190, Loss: 0.2731
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2691
Batch 220, Loss: 0.2766
Batch 230, Loss: 0.2750
Batch 240, Loss: 0.2973
Batch 250, Loss: 0.2984
Batch 260, Loss: 0.2945
Batch 270, Loss: 0.2776
Batch 280, Loss: 0.2784
Batch 290, Loss: 0.2690
Batch 300, Loss: 0.2728
Batch 310, Loss: 0.2638
Batch 320, Loss: 0.2767
Batch 330, Loss: 0.2563
Batch 340, Loss: 0.2895
Batch 350, Loss: 0.2604
Batch 360, Loss: 0.3044
Batch 370, Loss: 0.2916
Batch 380, Loss: 0.2690
Batch 390, Loss: 0.2971
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 24.875832080841064 seconds
Epoch 153 accuracy: 93.61%
Batch 10, Loss: 0.2622
Batch 20, Loss: 0.2686
Batch 30, Loss: 0.2308
Batch 40, Loss: 0.2521
Batch 50, Loss: 0.2642
Batch 60, Loss: 0.2626
Batch 70, Loss: 0.2732
Batch 80, Loss: 0.2153
Batch 90, Loss: 0.2756
Batch 100, Loss: 0.2502
Batch 110, Loss: 0.2588
Batch 120, Loss: 0.2299
Batch 130, Loss: 0.2732
Batch 140, Loss: 0.2481
Batch 150, Loss: 0.2522
Batch 160, Loss: 0.2616
Batch 170, Loss: 0.2544
Batch 180, Loss: 0.2458
Batch 190, Loss: 0.2751
Batch 200, Loss: 0.2623
Batch 210, Loss: 0.2994
Batch 220, Loss: 0.2521
Batch 230, Loss: 0.2454
Batch 240, Loss: 0.2757
Batch 250, Loss: 0.2690
Batch 260, Loss: 0.2549
Batch 270, Loss: 0.2857
Batch 280, Loss: 0.2873
Batch 290, Loss: 0.2541
Batch 300, Loss: 0.2750
Batch 310, Loss: 0.2688
Batch 320, Loss: 0.2815
Batch 330, Loss: 0.2810
Batch 340, Loss: 0.2552
Batch 350, Loss: 0.2804
Batch 360, Loss: 0.2580
Batch 370, Loss: 0.2924
Batch 380, Loss: 0.2291
Batch 390, Loss: 0.2444
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 24.9008526802063 seconds
Epoch 154 accuracy: 93.64%
Batch 10, Loss: 0.3056
Batch 20, Loss: 0.2523
Batch 30, Loss: 0.2594
Batch 40, Loss: 0.2256
Batch 50, Loss: 0.2801
Batch 60, Loss: 0.2499
Batch 70, Loss: 0.2679
Batch 80, Loss: 0.2699
Batch 90, Loss: 0.2567
Batch 100, Loss: 0.2425
Batch 110, Loss: 0.2546
Batch 120, Loss: 0.2603
Batch 130, Loss: 0.2495
Batch 140, Loss: 0.2446
Batch 150, Loss: 0.2987
Batch 160, Loss: 0.2562
Batch 170, Loss: 0.2459
Batch 180, Loss: 0.2811
Batch 190, Loss: 0.2695
Batch 200, Loss: 0.2636
Batch 210, Loss: 0.2751
Batch 220, Loss: 0.2445
Batch 230, Loss: 0.2549
Batch 240, Loss: 0.2583
Batch 250, Loss: 0.2548
Batch 260, Loss: 0.2615
Batch 270, Loss: 0.2610
Batch 280, Loss: 0.2577
Batch 290, Loss: 0.2534
Batch 300, Loss: 0.2606
Batch 310, Loss: 0.2838
Batch 320, Loss: 0.2707
Batch 330, Loss: 0.2379
Batch 340, Loss: 0.2484
Batch 350, Loss: 0.2659
Batch 360, Loss: 0.2779
Batch 370, Loss: 0.2346
Batch 380, Loss: 0.2517
Batch 390, Loss: 0.2442
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 24.907499313354492 seconds
Epoch 155 accuracy: 93.9%
Batch 10, Loss: 0.2615
Batch 20, Loss: 0.2461
Batch 30, Loss: 0.2545
Batch 40, Loss: 0.2497
Batch 50, Loss: 0.2562
Batch 60, Loss: 0.2287
Batch 70, Loss: 0.2761
Batch 80, Loss: 0.2607
Batch 90, Loss: 0.2799
Batch 100, Loss: 0.2584
Batch 110, Loss: 0.2481
Batch 120, Loss: 0.2603
Batch 130, Loss: 0.2493
Batch 140, Loss: 0.2471
Batch 150, Loss: 0.2560
Batch 160, Loss: 0.2795
Batch 170, Loss: 0.2252
Batch 180, Loss: 0.2320
Batch 190, Loss: 0.2395
Batch 200, Loss: 0.2342
Batch 210, Loss: 0.2431
Batch 220, Loss: 0.2425
Batch 230, Loss: 0.2478
Batch 240, Loss: 0.2472
Batch 250, Loss: 0.2714
Batch 260, Loss: 0.2606
Batch 270, Loss: 0.2667
Batch 280, Loss: 0.2697
Batch 290, Loss: 0.2778
Batch 300, Loss: 0.2851
Batch 310, Loss: 0.2773
Batch 320, Loss: 0.2726
Batch 330, Loss: 0.2520
Batch 340, Loss: 0.2786
Batch 350, Loss: 0.2614
Batch 360, Loss: 0.2816
Batch 370, Loss: 0.2612
Batch 380, Loss: 0.2556
Batch 390, Loss: 0.2332
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 24.85215926170349 seconds
Epoch 156 accuracy: 94.08%
Batch 10, Loss: 0.2459
Batch 20, Loss: 0.2615
Batch 30, Loss: 0.2546
Batch 40, Loss: 0.2758
Batch 50, Loss: 0.2469
Batch 60, Loss: 0.2546
Batch 70, Loss: 0.2767
Batch 80, Loss: 0.2146
Batch 90, Loss: 0.2603
Batch 100, Loss: 0.2539
Batch 110, Loss: 0.2562
Batch 120, Loss: 0.2516
Batch 130, Loss: 0.2509
Batch 140, Loss: 0.2590
Batch 150, Loss: 0.2395
Batch 160, Loss: 0.2620
Batch 170, Loss: 0.2465
Batch 180, Loss: 0.2602
Batch 190, Loss: 0.2418
Batch 200, Loss: 0.2678
Batch 210, Loss: 0.2670
Batch 220, Loss: 0.2509
Batch 230, Loss: 0.2474
Batch 240, Loss: 0.2451
Batch 250, Loss: 0.2623
Batch 260, Loss: 0.2555
Batch 270, Loss: 0.2394
Batch 280, Loss: 0.2898
Batch 290, Loss: 0.2599
Batch 300, Loss: 0.2535
Batch 310, Loss: 0.2383
Batch 320, Loss: 0.2557
Batch 330, Loss: 0.2524
Batch 340, Loss: 0.2551
Batch 350, Loss: 0.2544
Batch 360, Loss: 0.2857
Batch 370, Loss: 0.2508
Batch 380, Loss: 0.2475
Batch 390, Loss: 0.2324
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 24.956825971603394 seconds
Epoch 157 accuracy: 94.05%
Batch 10, Loss: 0.2656
Batch 20, Loss: 0.2300
Batch 30, Loss: 0.2719
Batch 40, Loss: 0.2435
Batch 50, Loss: 0.2539
Batch 60, Loss: 0.2595
Batch 70, Loss: 0.2210
Batch 80, Loss: 0.2461
Batch 90, Loss: 0.2160
Batch 100, Loss: 0.2510
Batch 110, Loss: 0.2454
Batch 120, Loss: 0.2789
Batch 130, Loss: 0.2461
Batch 140, Loss: 0.2587
Batch 150, Loss: 0.2445
Batch 160, Loss: 0.2267
Batch 170, Loss: 0.2241
Batch 180, Loss: 0.2314
Batch 190, Loss: 0.2489
Batch 200, Loss: 0.2324
Batch 210, Loss: 0.2365
Batch 220, Loss: 0.2701
Batch 230, Loss: 0.2514
Batch 240, Loss: 0.2548
Batch 250, Loss: 0.2491
Batch 260, Loss: 0.2467
Batch 270, Loss: 0.2595
Batch 280, Loss: 0.2583
Batch 290, Loss: 0.2410
Batch 300, Loss: 0.2701
Batch 310, Loss: 0.2295
Batch 320, Loss: 0.2375
Batch 330, Loss: 0.2623
Batch 340, Loss: 0.2305
Batch 350, Loss: 0.2386
Batch 360, Loss: 0.2286
Batch 370, Loss: 0.2050
Batch 380, Loss: 0.2534
Batch 390, Loss: 0.2663
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 24.876752138137817 seconds
Epoch 158 accuracy: 94.03%
Batch 10, Loss: 0.2344
Batch 20, Loss: 0.2273
Batch 30, Loss: 0.2251
Batch 40, Loss: 0.2429
Batch 50, Loss: 0.2685
Batch 60, Loss: 0.2596
Batch 70, Loss: 0.2268
Batch 80, Loss: 0.2712
Batch 90, Loss: 0.2356
Batch 100, Loss: 0.2463
Batch 110, Loss: 0.2493
Batch 120, Loss: 0.2516
Batch 130, Loss: 0.2351
Batch 140, Loss: 0.2698
Batch 150, Loss: 0.2565
Batch 160, Loss: 0.2691
Batch 170, Loss: 0.2517
Batch 180, Loss: 0.2418
Batch 190, Loss: 0.2346
Batch 200, Loss: 0.2394
Batch 210, Loss: 0.2620
Batch 220, Loss: 0.2427
Batch 230, Loss: 0.2221
Batch 240, Loss: 0.2414
Batch 250, Loss: 0.2301
Batch 260, Loss: 0.2639
Batch 270, Loss: 0.2529
Batch 280, Loss: 0.2681
Batch 290, Loss: 0.2323
Batch 300, Loss: 0.2535
Batch 310, Loss: 0.2144
Batch 320, Loss: 0.2348
Batch 330, Loss: 0.2206
Batch 340, Loss: 0.2288
Batch 350, Loss: 0.2581
Batch 360, Loss: 0.2370
Batch 370, Loss: 0.2484
Batch 380, Loss: 0.2332
Batch 390, Loss: 0.2698
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 24.90272879600525 seconds
Epoch 159 accuracy: 94.11%
Batch 10, Loss: 0.2621
Batch 20, Loss: 0.2314
Batch 30, Loss: 0.2450
Batch 40, Loss: 0.2435
Batch 50, Loss: 0.2376
Batch 60, Loss: 0.2402
Batch 70, Loss: 0.2313
Batch 80, Loss: 0.2333
Batch 90, Loss: 0.2357
Batch 100, Loss: 0.2606
Batch 110, Loss: 0.2171
Batch 120, Loss: 0.2173
Batch 130, Loss: 0.2391
Batch 140, Loss: 0.2162
Batch 150, Loss: 0.2369
Batch 160, Loss: 0.2057
Batch 170, Loss: 0.2660
Batch 180, Loss: 0.2461
Batch 190, Loss: 0.2467
Batch 200, Loss: 0.2525
Batch 210, Loss: 0.2443
Batch 220, Loss: 0.2405
Batch 230, Loss: 0.2284
Batch 240, Loss: 0.2299
Batch 250, Loss: 0.2644
Batch 260, Loss: 0.2260
Batch 270, Loss: 0.2418
Batch 280, Loss: 0.2465
Batch 290, Loss: 0.2754
Batch 300, Loss: 0.2417
Batch 310, Loss: 0.2160
Batch 320, Loss: 0.2575
Batch 330, Loss: 0.2353
Batch 340, Loss: 0.2516
Batch 350, Loss: 0.2249
Batch 360, Loss: 0.2348
Batch 370, Loss: 0.2256
Batch 380, Loss: 0.2612
Batch 390, Loss: 0.2346
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 24.87440323829651 seconds
Epoch 160 accuracy: 93.75%
Batch 10, Loss: 0.2481
Batch 20, Loss: 0.2500
Batch 30, Loss: 0.2490
Batch 40, Loss: 0.2459
Batch 50, Loss: 0.2424
Batch 60, Loss: 0.2313
Batch 70, Loss: 0.2270
Batch 80, Loss: 0.2490
Batch 90, Loss: 0.2308
Batch 100, Loss: 0.2498
Batch 110, Loss: 0.2283
Batch 120, Loss: 0.2392
Batch 130, Loss: 0.2427
Batch 140, Loss: 0.2424
Batch 150, Loss: 0.2235
Batch 160, Loss: 0.2476
Batch 170, Loss: 0.2306
Batch 180, Loss: 0.2448
Batch 190, Loss: 0.2433
Batch 200, Loss: 0.2547
Batch 210, Loss: 0.2092
Batch 220, Loss: 0.2296
Batch 230, Loss: 0.1995
Batch 240, Loss: 0.2173
Batch 250, Loss: 0.2148
Batch 260, Loss: 0.2478
Batch 270, Loss: 0.2343
Batch 280, Loss: 0.2385
Batch 290, Loss: 0.2396
Batch 300, Loss: 0.2083
Batch 310, Loss: 0.2395
Batch 320, Loss: 0.2495
Batch 330, Loss: 0.2511
Batch 340, Loss: 0.2480
Batch 350, Loss: 0.2528
Batch 360, Loss: 0.2585
Batch 370, Loss: 0.2420
Batch 380, Loss: 0.2333
Batch 390, Loss: 0.2365
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 24.897745609283447 seconds
Epoch 161 accuracy: 94.56%
Batch 10, Loss: 0.2318
Batch 20, Loss: 0.2265
Batch 30, Loss: 0.2264
Batch 40, Loss: 0.2150
Batch 50, Loss: 0.2230
Batch 60, Loss: 0.2322
Batch 70, Loss: 0.2561
Batch 80, Loss: 0.2321
Batch 90, Loss: 0.2419
Batch 100, Loss: 0.2167
Batch 110, Loss: 0.2211
Batch 120, Loss: 0.2461
Batch 130, Loss: 0.2254
Batch 140, Loss: 0.2486
Batch 150, Loss: 0.2201
Batch 160, Loss: 0.2197
Batch 170, Loss: 0.2113
Batch 180, Loss: 0.2177
Batch 190, Loss: 0.2152
Batch 200, Loss: 0.2419
Batch 210, Loss: 0.2372
Batch 220, Loss: 0.2255
Batch 230, Loss: 0.2163
Batch 240, Loss: 0.2093
Batch 250, Loss: 0.2357
Batch 260, Loss: 0.2063
Batch 270, Loss: 0.2058
Batch 280, Loss: 0.2510
Batch 290, Loss: 0.2423
Batch 300, Loss: 0.2566
Batch 310, Loss: 0.2530
Batch 320, Loss: 0.2378
Batch 330, Loss: 0.2543
Batch 340, Loss: 0.2471
Batch 350, Loss: 0.2591
Batch 360, Loss: 0.2324
Batch 370, Loss: 0.2246
Batch 380, Loss: 0.2223
Batch 390, Loss: 0.2401
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 24.87375497817993 seconds
Epoch 162 accuracy: 94.14%
Batch 10, Loss: 0.2269
Batch 20, Loss: 0.2302
Batch 30, Loss: 0.2004
Batch 40, Loss: 0.2274
Batch 50, Loss: 0.2316
Batch 60, Loss: 0.2192
Batch 70, Loss: 0.2289
Batch 80, Loss: 0.2384
Batch 90, Loss: 0.2410
Batch 100, Loss: 0.2310
Batch 110, Loss: 0.2114
Batch 120, Loss: 0.2612
Batch 130, Loss: 0.2025
Batch 140, Loss: 0.2338
Batch 150, Loss: 0.2276
Batch 160, Loss: 0.2406
Batch 170, Loss: 0.2462
Batch 180, Loss: 0.2277
Batch 190, Loss: 0.2164
Batch 200, Loss: 0.2245
Batch 210, Loss: 0.2322
Batch 220, Loss: 0.2521
Batch 230, Loss: 0.2162
Batch 240, Loss: 0.2225
Batch 250, Loss: 0.2385
Batch 260, Loss: 0.2026
Batch 270, Loss: 0.2182
Batch 280, Loss: 0.2413
Batch 290, Loss: 0.2147
Batch 300, Loss: 0.2355
Batch 310, Loss: 0.2387
Batch 320, Loss: 0.2090
Batch 330, Loss: 0.2315
Batch 340, Loss: 0.2390
Batch 350, Loss: 0.2313
Batch 360, Loss: 0.2224
Batch 370, Loss: 0.2391
Batch 380, Loss: 0.2439
Batch 390, Loss: 0.2662
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 24.85123085975647 seconds
Epoch 163 accuracy: 94.45%
Batch 10, Loss: 0.2220
Batch 20, Loss: 0.2120
Batch 30, Loss: 0.2321
Batch 40, Loss: 0.2428
Batch 50, Loss: 0.2181
Batch 60, Loss: 0.1934
Batch 70, Loss: 0.2307
Batch 80, Loss: 0.2396
Batch 90, Loss: 0.2267
Batch 100, Loss: 0.2466
Batch 110, Loss: 0.2488
Batch 120, Loss: 0.2191
Batch 130, Loss: 0.2229
Batch 140, Loss: 0.2391
Batch 150, Loss: 0.2124
Batch 160, Loss: 0.2188
Batch 170, Loss: 0.2092
Batch 180, Loss: 0.2316
Batch 190, Loss: 0.2673
Batch 200, Loss: 0.2264
Batch 210, Loss: 0.2090
Batch 220, Loss: 0.1916
Batch 230, Loss: 0.2355
Batch 240, Loss: 0.2046
Batch 250, Loss: 0.2377
Batch 260, Loss: 0.2196
Batch 270, Loss: 0.2345
Batch 280, Loss: 0.2017
Batch 290, Loss: 0.2180
Batch 300, Loss: 0.2120
Batch 310, Loss: 0.2338
Batch 320, Loss: 0.2392
Batch 330, Loss: 0.2108
Batch 340, Loss: 0.2335
Batch 350, Loss: 0.2026
Batch 360, Loss: 0.2464
Batch 370, Loss: 0.2136
Batch 380, Loss: 0.2069
Batch 390, Loss: 0.2242
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 24.957119941711426 seconds
Epoch 164 accuracy: 94.36%
Batch 10, Loss: 0.2338
Batch 20, Loss: 0.2095
Batch 30, Loss: 0.2139
Batch 40, Loss: 0.1880
Batch 50, Loss: 0.2025
Batch 60, Loss: 0.2482
Batch 70, Loss: 0.2384
Batch 80, Loss: 0.2264
Batch 90, Loss: 0.2234
Batch 100, Loss: 0.2232
Batch 110, Loss: 0.2599
Batch 120, Loss: 0.2094
Batch 130, Loss: 0.2103
Batch 140, Loss: 0.2181
Batch 150, Loss: 0.2438
Batch 160, Loss: 0.2175
Batch 170, Loss: 0.2097
Batch 180, Loss: 0.2164
Batch 190, Loss: 0.2312
Batch 200, Loss: 0.2289
Batch 210, Loss: 0.2218
Batch 220, Loss: 0.2236
Batch 230, Loss: 0.2524
Batch 240, Loss: 0.2176
Batch 250, Loss: 0.2188
Batch 260, Loss: 0.2077
Batch 270, Loss: 0.2236
Batch 280, Loss: 0.1877
Batch 290, Loss: 0.2064
Batch 300, Loss: 0.2072
Batch 310, Loss: 0.2037
Batch 320, Loss: 0.2025
Batch 330, Loss: 0.2031
Batch 340, Loss: 0.2391
Batch 350, Loss: 0.1998
Batch 360, Loss: 0.2261
Batch 370, Loss: 0.2169
Batch 380, Loss: 0.2222
Batch 390, Loss: 0.2290
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 24.930779695510864 seconds
Epoch 165 accuracy: 94.52%
Batch 10, Loss: 0.2021
Batch 20, Loss: 0.1852
Batch 30, Loss: 0.2028
Batch 40, Loss: 0.1749
Batch 50, Loss: 0.2391
Batch 60, Loss: 0.2189
Batch 70, Loss: 0.2285
Batch 80, Loss: 0.2300
Batch 90, Loss: 0.2434
Batch 100, Loss: 0.2232
Batch 110, Loss: 0.2060
Batch 120, Loss: 0.2026
Batch 130, Loss: 0.2065
Batch 140, Loss: 0.2184
Batch 150, Loss: 0.1935
Batch 160, Loss: 0.2279
Batch 170, Loss: 0.2225
Batch 180, Loss: 0.2089
Batch 190, Loss: 0.2086
Batch 200, Loss: 0.1940
Batch 210, Loss: 0.2340
Batch 220, Loss: 0.2322
Batch 230, Loss: 0.1973
Batch 240, Loss: 0.2129
Batch 250, Loss: 0.2187
Batch 260, Loss: 0.2273
Batch 270, Loss: 0.2300
Batch 280, Loss: 0.2200
Batch 290, Loss: 0.2017
Batch 300, Loss: 0.2176
Batch 310, Loss: 0.2220
Batch 320, Loss: 0.2236
Batch 330, Loss: 0.2170
Batch 340, Loss: 0.2134
Batch 350, Loss: 0.2037
Batch 360, Loss: 0.2204
Batch 370, Loss: 0.2134
Batch 380, Loss: 0.2181
Batch 390, Loss: 0.2113
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 24.884259700775146 seconds
Epoch 166 accuracy: 94.69%
Batch 10, Loss: 0.1939
Batch 20, Loss: 0.1966
Batch 30, Loss: 0.2009
Batch 40, Loss: 0.2043
Batch 50, Loss: 0.1932
Batch 60, Loss: 0.2292
Batch 70, Loss: 0.2123
Batch 80, Loss: 0.1899
Batch 90, Loss: 0.1821
Batch 100, Loss: 0.1876
Batch 110, Loss: 0.1918
Batch 120, Loss: 0.1962
Batch 130, Loss: 0.2167
Batch 140, Loss: 0.1837
Batch 150, Loss: 0.1981
Batch 160, Loss: 0.1995
Batch 170, Loss: 0.1976
Batch 180, Loss: 0.2174
Batch 190, Loss: 0.1953
Batch 200, Loss: 0.1854
Batch 210, Loss: 0.1819
Batch 220, Loss: 0.1946
Batch 230, Loss: 0.1870
Batch 240, Loss: 0.2129
Batch 250, Loss: 0.2317
Batch 260, Loss: 0.1791
Batch 270, Loss: 0.2013
Batch 280, Loss: 0.2452
Batch 290, Loss: 0.2253
Batch 300, Loss: 0.1944
Batch 310, Loss: 0.2092
Batch 320, Loss: 0.2090
Batch 330, Loss: 0.2122
Batch 340, Loss: 0.2252
Batch 350, Loss: 0.2045
Batch 360, Loss: 0.1975
Batch 370, Loss: 0.1955
Batch 380, Loss: 0.1968
Batch 390, Loss: 0.2412
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 24.922234058380127 seconds
Epoch 167 accuracy: 95.22%
Batch 10, Loss: 0.2153
Batch 20, Loss: 0.2104
Batch 30, Loss: 0.2060
Batch 40, Loss: 0.2090
Batch 50, Loss: 0.1822
Batch 60, Loss: 0.1961
Batch 70, Loss: 0.2316
Batch 80, Loss: 0.1970
Batch 90, Loss: 0.1945
Batch 100, Loss: 0.1935
Batch 110, Loss: 0.2026
Batch 120, Loss: 0.2398
Batch 130, Loss: 0.2069
Batch 140, Loss: 0.2448
Batch 150, Loss: 0.2240
Batch 160, Loss: 0.2190
Batch 170, Loss: 0.1969
Batch 180, Loss: 0.1832
Batch 190, Loss: 0.1977
Batch 200, Loss: 0.1916
Batch 210, Loss: 0.2003
Batch 220, Loss: 0.2025
Batch 230, Loss: 0.2114
Batch 240, Loss: 0.2037
Batch 250, Loss: 0.2059
Batch 260, Loss: 0.2201
Batch 270, Loss: 0.2092
Batch 280, Loss: 0.1994
Batch 290, Loss: 0.2154
Batch 300, Loss: 0.1933
Batch 310, Loss: 0.2128
Batch 320, Loss: 0.1853
Batch 330, Loss: 0.2098
Batch 340, Loss: 0.2160
Batch 350, Loss: 0.1998
Batch 360, Loss: 0.2114
Batch 370, Loss: 0.1914
Batch 380, Loss: 0.1931
Batch 390, Loss: 0.1949
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 24.917620182037354 seconds
Epoch 168 accuracy: 94.76%
Batch 10, Loss: 0.1948
Batch 20, Loss: 0.1820
Batch 30, Loss: 0.2279
Batch 40, Loss: 0.2057
Batch 50, Loss: 0.1985
Batch 60, Loss: 0.2286
Batch 70, Loss: 0.2133
Batch 80, Loss: 0.2082
Batch 90, Loss: 0.2099
Batch 100, Loss: 0.1762
Batch 110, Loss: 0.1983
Batch 120, Loss: 0.2016
Batch 130, Loss: 0.1744
Batch 140, Loss: 0.1854
Batch 150, Loss: 0.2071
Batch 160, Loss: 0.2043
Batch 170, Loss: 0.2031
Batch 180, Loss: 0.1913
Batch 190, Loss: 0.1825
Batch 200, Loss: 0.2083
Batch 210, Loss: 0.2032
Batch 220, Loss: 0.2156
Batch 230, Loss: 0.2183
Batch 240, Loss: 0.2189
Batch 250, Loss: 0.2072
Batch 260, Loss: 0.2032
Batch 270, Loss: 0.1793
Batch 280, Loss: 0.2216
Batch 290, Loss: 0.2097
Batch 300, Loss: 0.1920
Batch 310, Loss: 0.1886
Batch 320, Loss: 0.1881
Batch 330, Loss: 0.2182
Batch 340, Loss: 0.2011
Batch 350, Loss: 0.1940
Batch 360, Loss: 0.1819
Batch 370, Loss: 0.1965
Batch 380, Loss: 0.2103
Batch 390, Loss: 0.2179
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 24.902846097946167 seconds
Epoch 169 accuracy: 94.69%
Batch 10, Loss: 0.2146
Batch 20, Loss: 0.2076
Batch 30, Loss: 0.1901
Batch 40, Loss: 0.1854
Batch 50, Loss: 0.1931
Batch 60, Loss: 0.2111
Batch 70, Loss: 0.2064
Batch 80, Loss: 0.1803
Batch 90, Loss: 0.2122
Batch 100, Loss: 0.1748
Batch 110, Loss: 0.1901
Batch 120, Loss: 0.2085
Batch 130, Loss: 0.2133
Batch 140, Loss: 0.2015
Batch 150, Loss: 0.2112
Batch 160, Loss: 0.1886
Batch 170, Loss: 0.2180
Batch 180, Loss: 0.1810
Batch 190, Loss: 0.2084
Batch 200, Loss: 0.1914
Batch 210, Loss: 0.2176
Batch 220, Loss: 0.1899
Batch 230, Loss: 0.1689
Batch 240, Loss: 0.1997
Batch 250, Loss: 0.2019
Batch 260, Loss: 0.1943
Batch 270, Loss: 0.2063
Batch 280, Loss: 0.2024
Batch 290, Loss: 0.1918
Batch 300, Loss: 0.1905
Batch 310, Loss: 0.1680
Batch 320, Loss: 0.2121
Batch 330, Loss: 0.1954
Batch 340, Loss: 0.1901
Batch 350, Loss: 0.2075
Batch 360, Loss: 0.2021
Batch 370, Loss: 0.2128
Batch 380, Loss: 0.2029
Batch 390, Loss: 0.1963
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 24.92989420890808 seconds
Epoch 170 accuracy: 95.13%
Batch 10, Loss: 0.2062
Batch 20, Loss: 0.1683
Batch 30, Loss: 0.2154
Batch 40, Loss: 0.2025
Batch 50, Loss: 0.1919
Batch 60, Loss: 0.2055
Batch 70, Loss: 0.1551
Batch 80, Loss: 0.1734
Batch 90, Loss: 0.2069
Batch 100, Loss: 0.2107
Batch 110, Loss: 0.1769
Batch 120, Loss: 0.1689
Batch 130, Loss: 0.2044
Batch 140, Loss: 0.2112
Batch 150, Loss: 0.1699
Batch 160, Loss: 0.1921
Batch 170, Loss: 0.1774
Batch 180, Loss: 0.1768
Batch 190, Loss: 0.1568
Batch 200, Loss: 0.1961
Batch 210, Loss: 0.1780
Batch 220, Loss: 0.1995
Batch 230, Loss: 0.1866
Batch 240, Loss: 0.2089
Batch 250, Loss: 0.1998
Batch 260, Loss: 0.1821
Batch 270, Loss: 0.1942
Batch 280, Loss: 0.1905
Batch 290, Loss: 0.2009
Batch 300, Loss: 0.2226
Batch 310, Loss: 0.1759
Batch 320, Loss: 0.2006
Batch 330, Loss: 0.2136
Batch 340, Loss: 0.1750
Batch 350, Loss: 0.2093
Batch 360, Loss: 0.1725
Batch 370, Loss: 0.1904
Batch 380, Loss: 0.2097
Batch 390, Loss: 0.2247
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 24.89760684967041 seconds
Epoch 171 accuracy: 95.12%
Batch 10, Loss: 0.2021
Batch 20, Loss: 0.1867
Batch 30, Loss: 0.1796
Batch 40, Loss: 0.1789
Batch 50, Loss: 0.2077
Batch 60, Loss: 0.1804
Batch 70, Loss: 0.2306
Batch 80, Loss: 0.1783
Batch 90, Loss: 0.2089
Batch 100, Loss: 0.1875
Batch 110, Loss: 0.1776
Batch 120, Loss: 0.1867
Batch 130, Loss: 0.1755
Batch 140, Loss: 0.2059
Batch 150, Loss: 0.1811
Batch 160, Loss: 0.1978
Batch 170, Loss: 0.2100
Batch 180, Loss: 0.1697
Batch 190, Loss: 0.1887
Batch 200, Loss: 0.1824
Batch 210, Loss: 0.1769
Batch 220, Loss: 0.1780
Batch 230, Loss: 0.1827
Batch 240, Loss: 0.1793
Batch 250, Loss: 0.1754
Batch 260, Loss: 0.1900
Batch 270, Loss: 0.2023
Batch 280, Loss: 0.2000
Batch 290, Loss: 0.1874
Batch 300, Loss: 0.2053
Batch 310, Loss: 0.1975
Batch 320, Loss: 0.1797
Batch 330, Loss: 0.1923
Batch 340, Loss: 0.1993
Batch 350, Loss: 0.1909
Batch 360, Loss: 0.1719
Batch 370, Loss: 0.1990
Batch 380, Loss: 0.1756
Batch 390, Loss: 0.1955
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 24.90557336807251 seconds
Epoch 172 accuracy: 95.18%
Batch 10, Loss: 0.1953
Batch 20, Loss: 0.2019
Batch 30, Loss: 0.1615
Batch 40, Loss: 0.1931
Batch 50, Loss: 0.1949
Batch 60, Loss: 0.1961
Batch 70, Loss: 0.1659
Batch 80, Loss: 0.1710
Batch 90, Loss: 0.1646
Batch 100, Loss: 0.1772
Batch 110, Loss: 0.1725
Batch 120, Loss: 0.1664
Batch 130, Loss: 0.2001
Batch 140, Loss: 0.1893
Batch 150, Loss: 0.1831
Batch 160, Loss: 0.1920
Batch 170, Loss: 0.1859
Batch 180, Loss: 0.1762
Batch 190, Loss: 0.1707
Batch 200, Loss: 0.2061
Batch 210, Loss: 0.1903
Batch 220, Loss: 0.1973
Batch 230, Loss: 0.2114
Batch 240, Loss: 0.1466
Batch 250, Loss: 0.1940
Batch 260, Loss: 0.1807
Batch 270, Loss: 0.1737
Batch 280, Loss: 0.1875
Batch 290, Loss: 0.1651
Batch 300, Loss: 0.1979
Batch 310, Loss: 0.1820
Batch 320, Loss: 0.1912
Batch 330, Loss: 0.1782
Batch 340, Loss: 0.1904
Batch 350, Loss: 0.2001
Batch 360, Loss: 0.1703
Batch 370, Loss: 0.1786
Batch 380, Loss: 0.2077
Batch 390, Loss: 0.2155
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 24.955369472503662 seconds
Epoch 173 accuracy: 95.41%
Batch 10, Loss: 0.1834
Batch 20, Loss: 0.1589
Batch 30, Loss: 0.1751
Batch 40, Loss: 0.1722
Batch 50, Loss: 0.1894
Batch 60, Loss: 0.1666
Batch 70, Loss: 0.1878
Batch 80, Loss: 0.2001
Batch 90, Loss: 0.1907
Batch 100, Loss: 0.1995
Batch 110, Loss: 0.1763
Batch 120, Loss: 0.2076
Batch 130, Loss: 0.1694
Batch 140, Loss: 0.1731
Batch 150, Loss: 0.1725
Batch 160, Loss: 0.1656
Batch 170, Loss: 0.1901
Batch 180, Loss: 0.2271
Batch 190, Loss: 0.1748
Batch 200, Loss: 0.1935
Batch 210, Loss: 0.1956
Batch 220, Loss: 0.1560
Batch 230, Loss: 0.2047
Batch 240, Loss: 0.2174
Batch 250, Loss: 0.1796
Batch 260, Loss: 0.1769
Batch 270, Loss: 0.1646
Batch 280, Loss: 0.1507
Batch 290, Loss: 0.2091
Batch 300, Loss: 0.1753
Batch 310, Loss: 0.2108
Batch 320, Loss: 0.1974
Batch 330, Loss: 0.1827
Batch 340, Loss: 0.1790
Batch 350, Loss: 0.1835
Batch 360, Loss: 0.1741
Batch 370, Loss: 0.1967
Batch 380, Loss: 0.1754
Batch 390, Loss: 0.1842
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 24.8534197807312 seconds
Epoch 174 accuracy: 95.22%
Batch 10, Loss: 0.1743
Batch 20, Loss: 0.1826
Batch 30, Loss: 0.1870
Batch 40, Loss: 0.1719
Batch 50, Loss: 0.1848
Batch 60, Loss: 0.1802
Batch 70, Loss: 0.1708
Batch 80, Loss: 0.1500
Batch 90, Loss: 0.1768
Batch 100, Loss: 0.1565
Batch 110, Loss: 0.2108
Batch 120, Loss: 0.1742
Batch 130, Loss: 0.1879
Batch 140, Loss: 0.1861
Batch 150, Loss: 0.1883
Batch 160, Loss: 0.1725
Batch 170, Loss: 0.1465
Batch 180, Loss: 0.1735
Batch 190, Loss: 0.1943
Batch 200, Loss: 0.1722
Batch 210, Loss: 0.1774
Batch 220, Loss: 0.2008
Batch 230, Loss: 0.1715
Batch 240, Loss: 0.1780
Batch 250, Loss: 0.1770
Batch 260, Loss: 0.1541
Batch 270, Loss: 0.1678
Batch 280, Loss: 0.1687
Batch 290, Loss: 0.1901
Batch 300, Loss: 0.1617
Batch 310, Loss: 0.1654
Batch 320, Loss: 0.1596
Batch 330, Loss: 0.1678
Batch 340, Loss: 0.1669
Batch 350, Loss: 0.1734
Batch 360, Loss: 0.2118
Batch 370, Loss: 0.1813
Batch 380, Loss: 0.1956
Batch 390, Loss: 0.1775
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 24.900391101837158 seconds
Epoch 175 accuracy: 95.74%
Batch 10, Loss: 0.1858
Batch 20, Loss: 0.1717
Batch 30, Loss: 0.1505
Batch 40, Loss: 0.1504
Batch 50, Loss: 0.1712
Batch 60, Loss: 0.1753
Batch 70, Loss: 0.1729
Batch 80, Loss: 0.1657
Batch 90, Loss: 0.1775
Batch 100, Loss: 0.1598
Batch 110, Loss: 0.1777
Batch 120, Loss: 0.1730
Batch 130, Loss: 0.1499
Batch 140, Loss: 0.1743
Batch 150, Loss: 0.1671
Batch 160, Loss: 0.1566
Batch 170, Loss: 0.1647
Batch 180, Loss: 0.1573
Batch 190, Loss: 0.1652
Batch 200, Loss: 0.1595
Batch 210, Loss: 0.1698
Batch 220, Loss: 0.1546
Batch 230, Loss: 0.1328
Batch 240, Loss: 0.1805
Batch 250, Loss: 0.1749
Batch 260, Loss: 0.1870
Batch 270, Loss: 0.1760
Batch 280, Loss: 0.1831
Batch 290, Loss: 0.1638
Batch 300, Loss: 0.1725
Batch 310, Loss: 0.1889
Batch 320, Loss: 0.1816
Batch 330, Loss: 0.1800
Batch 340, Loss: 0.1808
Batch 350, Loss: 0.1832
Batch 360, Loss: 0.1898
Batch 370, Loss: 0.1677
Batch 380, Loss: 0.1711
Batch 390, Loss: 0.1734
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 24.958774089813232 seconds
Epoch 176 accuracy: 95.53%
Batch 10, Loss: 0.1829
Batch 20, Loss: 0.1657
Batch 30, Loss: 0.1792
Batch 40, Loss: 0.1665
Batch 50, Loss: 0.1606
Batch 60, Loss: 0.1570
Batch 70, Loss: 0.1503
Batch 80, Loss: 0.1635
Batch 90, Loss: 0.1787
Batch 100, Loss: 0.1947
Batch 110, Loss: 0.1843
Batch 120, Loss: 0.1683
Batch 130, Loss: 0.1918
Batch 140, Loss: 0.1752
Batch 150, Loss: 0.1400
Batch 160, Loss: 0.1620
Batch 170, Loss: 0.1571
Batch 180, Loss: 0.1582
Batch 190, Loss: 0.1424
Batch 200, Loss: 0.1871
Batch 210, Loss: 0.1879
Batch 220, Loss: 0.2028
Batch 230, Loss: 0.1879
Batch 240, Loss: 0.1736
Batch 250, Loss: 0.1471
Batch 260, Loss: 0.1710
Batch 270, Loss: 0.1583
Batch 280, Loss: 0.1695
Batch 290, Loss: 0.1760
Batch 300, Loss: 0.1911
Batch 310, Loss: 0.1834
Batch 320, Loss: 0.1677
Batch 330, Loss: 0.1906
Batch 340, Loss: 0.1619
Batch 350, Loss: 0.1765
Batch 360, Loss: 0.1642
Batch 370, Loss: 0.1685
Batch 380, Loss: 0.1971
Batch 390, Loss: 0.1732
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 24.883861541748047 seconds
Epoch 177 accuracy: 95.48%
Batch 10, Loss: 0.1727
Batch 20, Loss: 0.1567
Batch 30, Loss: 0.1834
Batch 40, Loss: 0.1759
Batch 50, Loss: 0.1826
Batch 60, Loss: 0.1610
Batch 70, Loss: 0.1524
Batch 80, Loss: 0.1515
Batch 90, Loss: 0.1603
Batch 100, Loss: 0.1711
Batch 110, Loss: 0.1544
Batch 120, Loss: 0.1736
Batch 130, Loss: 0.1592
Batch 140, Loss: 0.2006
Batch 150, Loss: 0.1736
Batch 160, Loss: 0.1587
Batch 170, Loss: 0.1569
Batch 180, Loss: 0.1921
Batch 190, Loss: 0.1612
Batch 200, Loss: 0.1622
Batch 210, Loss: 0.1523
Batch 220, Loss: 0.1683
Batch 230, Loss: 0.1463
Batch 240, Loss: 0.1680
Batch 250, Loss: 0.1537
Batch 260, Loss: 0.1691
Batch 270, Loss: 0.1580
Batch 280, Loss: 0.1718
Batch 290, Loss: 0.1585
Batch 300, Loss: 0.1715
Batch 310, Loss: 0.1672
Batch 320, Loss: 0.1349
Batch 330, Loss: 0.2008
Batch 340, Loss: 0.1537
Batch 350, Loss: 0.1596
Batch 360, Loss: 0.1732
Batch 370, Loss: 0.1594
Batch 380, Loss: 0.1547
Batch 390, Loss: 0.1457
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 24.943885326385498 seconds
Epoch 178 accuracy: 95.76%
Batch 10, Loss: 0.1591
Batch 20, Loss: 0.1593
Batch 30, Loss: 0.1867
Batch 40, Loss: 0.1561
Batch 50, Loss: 0.1686
Batch 60, Loss: 0.1569
Batch 70, Loss: 0.1701
Batch 80, Loss: 0.1668
Batch 90, Loss: 0.1558
Batch 100, Loss: 0.1532
Batch 110, Loss: 0.1500
Batch 120, Loss: 0.1729
Batch 130, Loss: 0.1707
Batch 140, Loss: 0.1775
Batch 150, Loss: 0.1719
Batch 160, Loss: 0.1346
Batch 170, Loss: 0.1628
Batch 180, Loss: 0.1502
Batch 190, Loss: 0.1482
Batch 200, Loss: 0.1755
Batch 210, Loss: 0.1478
Batch 220, Loss: 0.1689
Batch 230, Loss: 0.1667
Batch 240, Loss: 0.1824
Batch 250, Loss: 0.1301
Batch 260, Loss: 0.1473
Batch 270, Loss: 0.1839
Batch 280, Loss: 0.1515
Batch 290, Loss: 0.1710
Batch 300, Loss: 0.1733
Batch 310, Loss: 0.1855
Batch 320, Loss: 0.1687
Batch 330, Loss: 0.1925
Batch 340, Loss: 0.1545
Batch 350, Loss: 0.1830
Batch 360, Loss: 0.1830
Batch 370, Loss: 0.1702
Batch 380, Loss: 0.1757
Batch 390, Loss: 0.1705
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 24.88040041923523 seconds
Epoch 179 accuracy: 95.63%
Batch 10, Loss: 0.1483
Batch 20, Loss: 0.1408
Batch 30, Loss: 0.1647
Batch 40, Loss: 0.1539
Batch 50, Loss: 0.1660
Batch 60, Loss: 0.1511
Batch 70, Loss: 0.1742
Batch 80, Loss: 0.1749
Batch 90, Loss: 0.1583
Batch 100, Loss: 0.1586
Batch 110, Loss: 0.1519
Batch 120, Loss: 0.1750
Batch 130, Loss: 0.1480
Batch 140, Loss: 0.1655
Batch 150, Loss: 0.1538
Batch 160, Loss: 0.1428
Batch 170, Loss: 0.1717
Batch 180, Loss: 0.1554
Batch 190, Loss: 0.1589
Batch 200, Loss: 0.1418
Batch 210, Loss: 0.1641
Batch 220, Loss: 0.1690
Batch 230, Loss: 0.1659
Batch 240, Loss: 0.1782
Batch 250, Loss: 0.1401
Batch 260, Loss: 0.1518
Batch 270, Loss: 0.1824
Batch 280, Loss: 0.1605
Batch 290, Loss: 0.1719
Batch 300, Loss: 0.1499
Batch 310, Loss: 0.1473
Batch 320, Loss: 0.1944
Batch 330, Loss: 0.1554
Batch 340, Loss: 0.1464
Batch 350, Loss: 0.1674
Batch 360, Loss: 0.1687
Batch 370, Loss: 0.1604
Batch 380, Loss: 0.1506
Batch 390, Loss: 0.1583
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 24.891473531723022 seconds
Epoch 180 accuracy: 95.71%
Batch 10, Loss: 0.1355
Batch 20, Loss: 0.1410
Batch 30, Loss: 0.1497
Batch 40, Loss: 0.1546
Batch 50, Loss: 0.1579
Batch 60, Loss: 0.1655
Batch 70, Loss: 0.1599
Batch 80, Loss: 0.1465
Batch 90, Loss: 0.1691
Batch 100, Loss: 0.1618
Batch 110, Loss: 0.1726
Batch 120, Loss: 0.1724
Batch 130, Loss: 0.1623
Batch 140, Loss: 0.1587
Batch 150, Loss: 0.1234
Batch 160, Loss: 0.1789
Batch 170, Loss: 0.1369
Batch 180, Loss: 0.1686
Batch 190, Loss: 0.1758
Batch 200, Loss: 0.1381
Batch 210, Loss: 0.1640
Batch 220, Loss: 0.1617
Batch 230, Loss: 0.1463
Batch 240, Loss: 0.1781
Batch 250, Loss: 0.1572
Batch 260, Loss: 0.1417
Batch 270, Loss: 0.1523
Batch 280, Loss: 0.1390
Batch 290, Loss: 0.1451
Batch 300, Loss: 0.1491
Batch 310, Loss: 0.1722
Batch 320, Loss: 0.1511
Batch 330, Loss: 0.1438
Batch 340, Loss: 0.1720
Batch 350, Loss: 0.1736
Batch 360, Loss: 0.1898
Batch 370, Loss: 0.1678
Batch 380, Loss: 0.1634
Batch 390, Loss: 0.1473
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 24.942677974700928 seconds
Epoch 181 accuracy: 95.81%
Batch 10, Loss: 0.1677
Batch 20, Loss: 0.1693
Batch 30, Loss: 0.1458
Batch 40, Loss: 0.1457
Batch 50, Loss: 0.1438
Batch 60, Loss: 0.1841
Batch 70, Loss: 0.1597
Batch 80, Loss: 0.1311
Batch 90, Loss: 0.1466
Batch 100, Loss: 0.1561
Batch 110, Loss: 0.1638
Batch 120, Loss: 0.1532
Batch 130, Loss: 0.1588
Batch 140, Loss: 0.1511
Batch 150, Loss: 0.1605
Batch 160, Loss: 0.1598
Batch 170, Loss: 0.1527
Batch 180, Loss: 0.1692
Batch 190, Loss: 0.1570
Batch 200, Loss: 0.1740
Batch 210, Loss: 0.1521
Batch 220, Loss: 0.1642
Batch 230, Loss: 0.1155
Batch 240, Loss: 0.1672
Batch 250, Loss: 0.1686
Batch 260, Loss: 0.1602
Batch 270, Loss: 0.1496
Batch 280, Loss: 0.1515
Batch 290, Loss: 0.1367
Batch 300, Loss: 0.1577
Batch 310, Loss: 0.1412
Batch 320, Loss: 0.1765
Batch 330, Loss: 0.1638
Batch 340, Loss: 0.1602
Batch 350, Loss: 0.1456
Batch 360, Loss: 0.1567
Batch 370, Loss: 0.1462
Batch 380, Loss: 0.1577
Batch 390, Loss: 0.1452
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 24.90913224220276 seconds
Epoch 182 accuracy: 95.79%
Batch 10, Loss: 0.1457
Batch 20, Loss: 0.1308
Batch 30, Loss: 0.1518
Batch 40, Loss: 0.1355
Batch 50, Loss: 0.1436
Batch 60, Loss: 0.1459
Batch 70, Loss: 0.1368
Batch 80, Loss: 0.1651
Batch 90, Loss: 0.1621
Batch 100, Loss: 0.1393
Batch 110, Loss: 0.1663
Batch 120, Loss: 0.1605
Batch 130, Loss: 0.1497
Batch 140, Loss: 0.1650
Batch 150, Loss: 0.1583
Batch 160, Loss: 0.1408
Batch 170, Loss: 0.1441
Batch 180, Loss: 0.1596
Batch 190, Loss: 0.1385
Batch 200, Loss: 0.1662
Batch 210, Loss: 0.1545
Batch 220, Loss: 0.1453
Batch 230, Loss: 0.1446
Batch 240, Loss: 0.1415
Batch 250, Loss: 0.1561
Batch 260, Loss: 0.1388
Batch 270, Loss: 0.1522
Batch 280, Loss: 0.1575
Batch 290, Loss: 0.1294
Batch 300, Loss: 0.1424
Batch 310, Loss: 0.1414
Batch 320, Loss: 0.1287
Batch 330, Loss: 0.1487
Batch 340, Loss: 0.1247
Batch 350, Loss: 0.1485
Batch 360, Loss: 0.1590
Batch 370, Loss: 0.1476
Batch 380, Loss: 0.1430
Batch 390, Loss: 0.1411
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 24.937097787857056 seconds
Epoch 183 accuracy: 95.9%
Batch 10, Loss: 0.1560
Batch 20, Loss: 0.1573
Batch 30, Loss: 0.1374
Batch 40, Loss: 0.1355
Batch 50, Loss: 0.1566
Batch 60, Loss: 0.1442
Batch 70, Loss: 0.1318
Batch 80, Loss: 0.1449
Batch 90, Loss: 0.1503
Batch 100, Loss: 0.1649
Batch 110, Loss: 0.1412
Batch 120, Loss: 0.1564
Batch 130, Loss: 0.1430
Batch 140, Loss: 0.1587
Batch 150, Loss: 0.1379
Batch 160, Loss: 0.1527
Batch 170, Loss: 0.1387
Batch 180, Loss: 0.1266
Batch 190, Loss: 0.1420
Batch 200, Loss: 0.1461
Batch 210, Loss: 0.1335
Batch 220, Loss: 0.1446
Batch 230, Loss: 0.1224
Batch 240, Loss: 0.1449
Batch 250, Loss: 0.1581
Batch 260, Loss: 0.1440
Batch 270, Loss: 0.1310
Batch 280, Loss: 0.1506
Batch 290, Loss: 0.1699
Batch 300, Loss: 0.1424
Batch 310, Loss: 0.1630
Batch 320, Loss: 0.1521
Batch 330, Loss: 0.1462
Batch 340, Loss: 0.1452
Batch 350, Loss: 0.1527
Batch 360, Loss: 0.1640
Batch 370, Loss: 0.1411
Batch 380, Loss: 0.1454
Batch 390, Loss: 0.1462
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 24.941380500793457 seconds
Epoch 184 accuracy: 96.0%
Batch 10, Loss: 0.1457
Batch 20, Loss: 0.1552
Batch 30, Loss: 0.1325
Batch 40, Loss: 0.1639
Batch 50, Loss: 0.1460
Batch 60, Loss: 0.1443
Batch 70, Loss: 0.1499
Batch 80, Loss: 0.1529
Batch 90, Loss: 0.1406
Batch 100, Loss: 0.0996
Batch 110, Loss: 0.1589
Batch 120, Loss: 0.1599
Batch 130, Loss: 0.1499
Batch 140, Loss: 0.1399
Batch 150, Loss: 0.1374
Batch 160, Loss: 0.1328
Batch 170, Loss: 0.1467
Batch 180, Loss: 0.1466
Batch 190, Loss: 0.1390
Batch 200, Loss: 0.1589
Batch 210, Loss: 0.1497
Batch 220, Loss: 0.1311
Batch 230, Loss: 0.1434
Batch 240, Loss: 0.1658
Batch 250, Loss: 0.1319
Batch 260, Loss: 0.1373
Batch 270, Loss: 0.1488
Batch 280, Loss: 0.1520
Batch 290, Loss: 0.1502
Batch 300, Loss: 0.1574
Batch 310, Loss: 0.1574
Batch 320, Loss: 0.1520
Batch 330, Loss: 0.1513
Batch 340, Loss: 0.1769
Batch 350, Loss: 0.1477
Batch 360, Loss: 0.1246
Batch 370, Loss: 0.1493
Batch 380, Loss: 0.1438
Batch 390, Loss: 0.1539
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 24.953911542892456 seconds
Epoch 185 accuracy: 96.13%
Batch 10, Loss: 0.1138
Batch 20, Loss: 0.1568
Batch 30, Loss: 0.1582
Batch 40, Loss: 0.1193
Batch 50, Loss: 0.1510
Batch 60, Loss: 0.1389
Batch 70, Loss: 0.1321
Batch 80, Loss: 0.1304
Batch 90, Loss: 0.1283
Batch 100, Loss: 0.1433
Batch 110, Loss: 0.1404
Batch 120, Loss: 0.1598
Batch 130, Loss: 0.1564
Batch 140, Loss: 0.1402
Batch 150, Loss: 0.1507
Batch 160, Loss: 0.1366
Batch 170, Loss: 0.1234
Batch 180, Loss: 0.1426
Batch 190, Loss: 0.1538
Batch 200, Loss: 0.1660
Batch 210, Loss: 0.1364
Batch 220, Loss: 0.1521
Batch 230, Loss: 0.1310
Batch 240, Loss: 0.1370
Batch 250, Loss: 0.1300
Batch 260, Loss: 0.1410
Batch 270, Loss: 0.1460
Batch 280, Loss: 0.1578
Batch 290, Loss: 0.1723
Batch 300, Loss: 0.1308
Batch 310, Loss: 0.1397
Batch 320, Loss: 0.1270
Batch 330, Loss: 0.1535
Batch 340, Loss: 0.1366
Batch 350, Loss: 0.1403
Batch 360, Loss: 0.1430
Batch 370, Loss: 0.1518
Batch 380, Loss: 0.1365
Batch 390, Loss: 0.1218
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 24.94562029838562 seconds
Epoch 186 accuracy: 96.06%
Batch 10, Loss: 0.1382
Batch 20, Loss: 0.1548
Batch 30, Loss: 0.1288
Batch 40, Loss: 0.1284
Batch 50, Loss: 0.1182
Batch 60, Loss: 0.1343
Batch 70, Loss: 0.1519
Batch 80, Loss: 0.1475
Batch 90, Loss: 0.1292
Batch 100, Loss: 0.1362
Batch 110, Loss: 0.1425
Batch 120, Loss: 0.1409
Batch 130, Loss: 0.1485
Batch 140, Loss: 0.1414
Batch 150, Loss: 0.1362
Batch 160, Loss: 0.1265
Batch 170, Loss: 0.1599
Batch 180, Loss: 0.1355
Batch 190, Loss: 0.1315
Batch 200, Loss: 0.1366
Batch 210, Loss: 0.1484
Batch 220, Loss: 0.1361
Batch 230, Loss: 0.1283
Batch 240, Loss: 0.1265
Batch 250, Loss: 0.1343
Batch 260, Loss: 0.1333
Batch 270, Loss: 0.1481
Batch 280, Loss: 0.1226
Batch 290, Loss: 0.1396
Batch 300, Loss: 0.1565
Batch 310, Loss: 0.1241
Batch 320, Loss: 0.1332
Batch 330, Loss: 0.1494
Batch 340, Loss: 0.1301
Batch 350, Loss: 0.1273
Batch 360, Loss: 0.1426
Batch 370, Loss: 0.1551
Batch 380, Loss: 0.1494
Batch 390, Loss: 0.1515
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 24.928352117538452 seconds
Epoch 187 accuracy: 95.87%
Batch 10, Loss: 0.1427
Batch 20, Loss: 0.1331
Batch 30, Loss: 0.1273
Batch 40, Loss: 0.1437
Batch 50, Loss: 0.1215
Batch 60, Loss: 0.1552
Batch 70, Loss: 0.1226
Batch 80, Loss: 0.1443
Batch 90, Loss: 0.1249
Batch 100, Loss: 0.1218
Batch 110, Loss: 0.1242
Batch 120, Loss: 0.1158
Batch 130, Loss: 0.1254
Batch 140, Loss: 0.1400
Batch 150, Loss: 0.1285
Batch 160, Loss: 0.1426
Batch 170, Loss: 0.1330
Batch 180, Loss: 0.1500
Batch 190, Loss: 0.1417
Batch 200, Loss: 0.1231
Batch 210, Loss: 0.1221
Batch 220, Loss: 0.1300
Batch 230, Loss: 0.1276
Batch 240, Loss: 0.1227
Batch 250, Loss: 0.1493
Batch 260, Loss: 0.1233
Batch 270, Loss: 0.1316
Batch 280, Loss: 0.1264
Batch 290, Loss: 0.1325
Batch 300, Loss: 0.1594
Batch 310, Loss: 0.1434
Batch 320, Loss: 0.1319
Batch 330, Loss: 0.1179
Batch 340, Loss: 0.1446
Batch 350, Loss: 0.1425
Batch 360, Loss: 0.1410
Batch 370, Loss: 0.1389
Batch 380, Loss: 0.1469
Batch 390, Loss: 0.1309
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 24.928614139556885 seconds
Epoch 188 accuracy: 96.06%
Batch 10, Loss: 0.1352
Batch 20, Loss: 0.1449
Batch 30, Loss: 0.1371
Batch 40, Loss: 0.1083
Batch 50, Loss: 0.1249
Batch 60, Loss: 0.1348
Batch 70, Loss: 0.1273
Batch 80, Loss: 0.1287
Batch 90, Loss: 0.1213
Batch 100, Loss: 0.1318
Batch 110, Loss: 0.1271
Batch 120, Loss: 0.1349
Batch 130, Loss: 0.1442
Batch 140, Loss: 0.1516
Batch 150, Loss: 0.1361
Batch 160, Loss: 0.1431
Batch 170, Loss: 0.1430
Batch 180, Loss: 0.1236
Batch 190, Loss: 0.1399
Batch 200, Loss: 0.1273
Batch 210, Loss: 0.1475
Batch 220, Loss: 0.1188
Batch 230, Loss: 0.1420
Batch 240, Loss: 0.1411
Batch 250, Loss: 0.1426
Batch 260, Loss: 0.1298
Batch 270, Loss: 0.1316
Batch 280, Loss: 0.1595
Batch 290, Loss: 0.1291
Batch 300, Loss: 0.1377
Batch 310, Loss: 0.1289
Batch 320, Loss: 0.1412
Batch 330, Loss: 0.1412
Batch 340, Loss: 0.1414
Batch 350, Loss: 0.1230
Batch 360, Loss: 0.1252
Batch 370, Loss: 0.1206
Batch 380, Loss: 0.1359
Batch 390, Loss: 0.1378
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 24.910595417022705 seconds
Epoch 189 accuracy: 96.35%
Batch 10, Loss: 0.1302
Batch 20, Loss: 0.1262
Batch 30, Loss: 0.1320
Batch 40, Loss: 0.1320
Batch 50, Loss: 0.1320
Batch 60, Loss: 0.1477
Batch 70, Loss: 0.1332
Batch 80, Loss: 0.1326
Batch 90, Loss: 0.1114
Batch 100, Loss: 0.1330
Batch 110, Loss: 0.1363
Batch 120, Loss: 0.1338
Batch 130, Loss: 0.1335
Batch 140, Loss: 0.1431
Batch 150, Loss: 0.1218
Batch 160, Loss: 0.1409
Batch 170, Loss: 0.1282
Batch 180, Loss: 0.1251
Batch 190, Loss: 0.1365
Batch 200, Loss: 0.0997
Batch 210, Loss: 0.1434
Batch 220, Loss: 0.1277
Batch 230, Loss: 0.1448
Batch 240, Loss: 0.1093
Batch 250, Loss: 0.1457
Batch 260, Loss: 0.1343
Batch 270, Loss: 0.1222
Batch 280, Loss: 0.1430
Batch 290, Loss: 0.1303
Batch 300, Loss: 0.1556
Batch 310, Loss: 0.1075
Batch 320, Loss: 0.1282
Batch 330, Loss: 0.1187
Batch 340, Loss: 0.1295
Batch 350, Loss: 0.1419
Batch 360, Loss: 0.1270
Batch 370, Loss: 0.1165
Batch 380, Loss: 0.1167
Batch 390, Loss: 0.1462
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 24.85733437538147 seconds
Epoch 190 accuracy: 96.3%
Batch 10, Loss: 0.1192
Batch 20, Loss: 0.1183
Batch 30, Loss: 0.1403
Batch 40, Loss: 0.1292
Batch 50, Loss: 0.1309
Batch 60, Loss: 0.1123
Batch 70, Loss: 0.1436
Batch 80, Loss: 0.1280
Batch 90, Loss: 0.1278
Batch 100, Loss: 0.1159
Batch 110, Loss: 0.1335
Batch 120, Loss: 0.1206
Batch 130, Loss: 0.1158
Batch 140, Loss: 0.1389
Batch 150, Loss: 0.1207
Batch 160, Loss: 0.1561
Batch 170, Loss: 0.1378
Batch 180, Loss: 0.1414
Batch 190, Loss: 0.1578
Batch 200, Loss: 0.1323
Batch 210, Loss: 0.1173
Batch 220, Loss: 0.1453
Batch 230, Loss: 0.1456
Batch 240, Loss: 0.1511
Batch 250, Loss: 0.1338
Batch 260, Loss: 0.1276
Batch 270, Loss: 0.1411
Batch 280, Loss: 0.1274
Batch 290, Loss: 0.1361
Batch 300, Loss: 0.1415
Batch 310, Loss: 0.1593
Batch 320, Loss: 0.1339
Batch 330, Loss: 0.1281
Batch 340, Loss: 0.1359
Batch 350, Loss: 0.1391
Batch 360, Loss: 0.1378
Batch 370, Loss: 0.1368
Batch 380, Loss: 0.1472
Batch 390, Loss: 0.1369
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 24.86450505256653 seconds
Epoch 191 accuracy: 96.35%
Batch 10, Loss: 0.1363
Batch 20, Loss: 0.1151
Batch 30, Loss: 0.1137
Batch 40, Loss: 0.1124
Batch 50, Loss: 0.1172
Batch 60, Loss: 0.1467
Batch 70, Loss: 0.1250
Batch 80, Loss: 0.1381
Batch 90, Loss: 0.1292
Batch 100, Loss: 0.1226
Batch 110, Loss: 0.1476
Batch 120, Loss: 0.1285
Batch 130, Loss: 0.1344
Batch 140, Loss: 0.1400
Batch 150, Loss: 0.1145
Batch 160, Loss: 0.1376
Batch 170, Loss: 0.1375
Batch 180, Loss: 0.1359
Batch 190, Loss: 0.1282
Batch 200, Loss: 0.1348
Batch 210, Loss: 0.1364
Batch 220, Loss: 0.1419
Batch 230, Loss: 0.1411
Batch 240, Loss: 0.1210
Batch 250, Loss: 0.1229
Batch 260, Loss: 0.1378
Batch 270, Loss: 0.1207
Batch 280, Loss: 0.1295
Batch 290, Loss: 0.1222
Batch 300, Loss: 0.1198
Batch 310, Loss: 0.1120
Batch 320, Loss: 0.1131
Batch 330, Loss: 0.1294
Batch 340, Loss: 0.1376
Batch 350, Loss: 0.1194
Batch 360, Loss: 0.1304
Batch 370, Loss: 0.1366
Batch 380, Loss: 0.1208
Batch 390, Loss: 0.1349
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 24.878722190856934 seconds
Epoch 192 accuracy: 96.33%
Batch 10, Loss: 0.1483
Batch 20, Loss: 0.1013
Batch 30, Loss: 0.1234
Batch 40, Loss: 0.1300
Batch 50, Loss: 0.1319
Batch 60, Loss: 0.1121
Batch 70, Loss: 0.1375
Batch 80, Loss: 0.1372
Batch 90, Loss: 0.1358
Batch 100, Loss: 0.1220
Batch 110, Loss: 0.1333
Batch 120, Loss: 0.1411
Batch 130, Loss: 0.1202
Batch 140, Loss: 0.1320
Batch 150, Loss: 0.1438
Batch 160, Loss: 0.1228
Batch 170, Loss: 0.1324
Batch 180, Loss: 0.1203
Batch 190, Loss: 0.1323
Batch 200, Loss: 0.1483
Batch 210, Loss: 0.1282
Batch 220, Loss: 0.1062
Batch 230, Loss: 0.1241
Batch 240, Loss: 0.1174
Batch 250, Loss: 0.1296
Batch 260, Loss: 0.1296
Batch 270, Loss: 0.1354
Batch 280, Loss: 0.1181
Batch 290, Loss: 0.1096
Batch 300, Loss: 0.1491
Batch 310, Loss: 0.1170
Batch 320, Loss: 0.1348
Batch 330, Loss: 0.1137
Batch 340, Loss: 0.1310
Batch 350, Loss: 0.1372
Batch 360, Loss: 0.1283
Batch 370, Loss: 0.1259
Batch 380, Loss: 0.1275
Batch 390, Loss: 0.1183
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 24.922183752059937 seconds
Epoch 193 accuracy: 96.24%
Batch 10, Loss: 0.1367
Batch 20, Loss: 0.1380
Batch 30, Loss: 0.1319
Batch 40, Loss: 0.0955
Batch 50, Loss: 0.1068
Batch 60, Loss: 0.1243
Batch 70, Loss: 0.1234
Batch 80, Loss: 0.1209
Batch 90, Loss: 0.1098
Batch 100, Loss: 0.1453
Batch 110, Loss: 0.1282
Batch 120, Loss: 0.1133
Batch 130, Loss: 0.1148
Batch 140, Loss: 0.1304
Batch 150, Loss: 0.1217
Batch 160, Loss: 0.1313
Batch 170, Loss: 0.1184
Batch 180, Loss: 0.1262
Batch 190, Loss: 0.1210
Batch 200, Loss: 0.1286
Batch 210, Loss: 0.1314
Batch 220, Loss: 0.1334
Batch 230, Loss: 0.1352
Batch 240, Loss: 0.1409
Batch 250, Loss: 0.0993
Batch 260, Loss: 0.1219
Batch 270, Loss: 0.1191
Batch 280, Loss: 0.1325
Batch 290, Loss: 0.1257
Batch 300, Loss: 0.1304
Batch 310, Loss: 0.1027
Batch 320, Loss: 0.1149
Batch 330, Loss: 0.1282
Batch 340, Loss: 0.1254
Batch 350, Loss: 0.1269
Batch 360, Loss: 0.1342
Batch 370, Loss: 0.1435
Batch 380, Loss: 0.1161
Batch 390, Loss: 0.1328
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 24.88271927833557 seconds
Epoch 194 accuracy: 96.43%
Batch 10, Loss: 0.1224
Batch 20, Loss: 0.1306
Batch 30, Loss: 0.1157
Batch 40, Loss: 0.1238
Batch 50, Loss: 0.1272
Batch 60, Loss: 0.1137
Batch 70, Loss: 0.1186
Batch 80, Loss: 0.1294
Batch 90, Loss: 0.1369
Batch 100, Loss: 0.1139
Batch 110, Loss: 0.1500
Batch 120, Loss: 0.1417
Batch 130, Loss: 0.1464
Batch 140, Loss: 0.1172
Batch 150, Loss: 0.1330
Batch 160, Loss: 0.1273
Batch 170, Loss: 0.1407
Batch 180, Loss: 0.1431
Batch 190, Loss: 0.1363
Batch 200, Loss: 0.1386
Batch 210, Loss: 0.1513
Batch 220, Loss: 0.1148
Batch 230, Loss: 0.1204
Batch 240, Loss: 0.1336
Batch 250, Loss: 0.1385
Batch 260, Loss: 0.1359
Batch 270, Loss: 0.1375
Batch 280, Loss: 0.1414
Batch 290, Loss: 0.1427
Batch 300, Loss: 0.1408
Batch 310, Loss: 0.1446
Batch 320, Loss: 0.1203
Batch 330, Loss: 0.1409
Batch 340, Loss: 0.1196
Batch 350, Loss: 0.1418
Batch 360, Loss: 0.1216
Batch 370, Loss: 0.1211
Batch 380, Loss: 0.1208
Batch 390, Loss: 0.1199
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 24.957569360733032 seconds
Epoch 195 accuracy: 96.28%
Batch 10, Loss: 0.1388
Batch 20, Loss: 0.1103
Batch 30, Loss: 0.1310
Batch 40, Loss: 0.1169
Batch 50, Loss: 0.1289
Batch 60, Loss: 0.1241
Batch 70, Loss: 0.1226
Batch 80, Loss: 0.1403
Batch 90, Loss: 0.1207
Batch 100, Loss: 0.1253
Batch 110, Loss: 0.1270
Batch 120, Loss: 0.1200
Batch 130, Loss: 0.1217
Batch 140, Loss: 0.1131
Batch 150, Loss: 0.1073
Batch 160, Loss: 0.1182
Batch 170, Loss: 0.1514
Batch 180, Loss: 0.1355
Batch 190, Loss: 0.1354
Batch 200, Loss: 0.1229
Batch 210, Loss: 0.1256
Batch 220, Loss: 0.1153
Batch 230, Loss: 0.1230
Batch 240, Loss: 0.1287
Batch 250, Loss: 0.1193
Batch 260, Loss: 0.1619
Batch 270, Loss: 0.1378
Batch 280, Loss: 0.1294
Batch 290, Loss: 0.1378
Batch 300, Loss: 0.1191
Batch 310, Loss: 0.1141
Batch 320, Loss: 0.1240
Batch 330, Loss: 0.1399
Batch 340, Loss: 0.1220
Batch 350, Loss: 0.1266
Batch 360, Loss: 0.1221
Batch 370, Loss: 0.1198
Batch 380, Loss: 0.1310
Batch 390, Loss: 0.1206
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 24.939440488815308 seconds
Epoch 196 accuracy: 96.29%
Batch 10, Loss: 0.1234
Batch 20, Loss: 0.1299
Batch 30, Loss: 0.1455
Batch 40, Loss: 0.1230
Batch 50, Loss: 0.1319
Batch 60, Loss: 0.1129
Batch 70, Loss: 0.1419
Batch 80, Loss: 0.1241
Batch 90, Loss: 0.1396
Batch 100, Loss: 0.1304
Batch 110, Loss: 0.1148
Batch 120, Loss: 0.1246
Batch 130, Loss: 0.1307
Batch 140, Loss: 0.1266
Batch 150, Loss: 0.1267
Batch 160, Loss: 0.1306
Batch 170, Loss: 0.1344
Batch 180, Loss: 0.1212
Batch 190, Loss: 0.1241
Batch 200, Loss: 0.1324
Batch 210, Loss: 0.1203
Batch 220, Loss: 0.1334
Batch 230, Loss: 0.1248
Batch 240, Loss: 0.1178
Batch 250, Loss: 0.1332
Batch 260, Loss: 0.1162
Batch 270, Loss: 0.1352
Batch 280, Loss: 0.1430
Batch 290, Loss: 0.1341
Batch 300, Loss: 0.1197
Batch 310, Loss: 0.1181
Batch 320, Loss: 0.1136
Batch 330, Loss: 0.1123
Batch 340, Loss: 0.1358
Batch 350, Loss: 0.1190
Batch 360, Loss: 0.1161
Batch 370, Loss: 0.0982
Batch 380, Loss: 0.1091
Batch 390, Loss: 0.1240
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 24.90571141242981 seconds
Epoch 197 accuracy: 96.46%
Batch 10, Loss: 0.1419
Batch 20, Loss: 0.1271
Batch 30, Loss: 0.1442
Batch 40, Loss: 0.1207
Batch 50, Loss: 0.1256
Batch 60, Loss: 0.1102
Batch 70, Loss: 0.1492
Batch 80, Loss: 0.1402
Batch 90, Loss: 0.1463
Batch 100, Loss: 0.1129
Batch 110, Loss: 0.1232
Batch 120, Loss: 0.1281
Batch 130, Loss: 0.1169
Batch 140, Loss: 0.1256
Batch 150, Loss: 0.1259
Batch 160, Loss: 0.1306
Batch 170, Loss: 0.1438
Batch 180, Loss: 0.1265
Batch 190, Loss: 0.1060
Batch 200, Loss: 0.1295
Batch 210, Loss: 0.1309
Batch 220, Loss: 0.1320
Batch 230, Loss: 0.1200
Batch 240, Loss: 0.0932
Batch 250, Loss: 0.1396
Batch 260, Loss: 0.1321
Batch 270, Loss: 0.1149
Batch 280, Loss: 0.1378
Batch 290, Loss: 0.1156
Batch 300, Loss: 0.1098
Batch 310, Loss: 0.1362
Batch 320, Loss: 0.1125
Batch 330, Loss: 0.1261
Batch 340, Loss: 0.1165
Batch 350, Loss: 0.1243
Batch 360, Loss: 0.1309
Batch 370, Loss: 0.1356
Batch 380, Loss: 0.1129
Batch 390, Loss: 0.1271
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 24.888867139816284 seconds
Epoch 198 accuracy: 96.32%
Batch 10, Loss: 0.1257
Batch 20, Loss: 0.1130
Batch 30, Loss: 0.1117
Batch 40, Loss: 0.1081
Batch 50, Loss: 0.1063
Batch 60, Loss: 0.1164
Batch 70, Loss: 0.1154
Batch 80, Loss: 0.1155
Batch 90, Loss: 0.1340
Batch 100, Loss: 0.1220
Batch 110, Loss: 0.1242
Batch 120, Loss: 0.1149
Batch 130, Loss: 0.1415
Batch 140, Loss: 0.1130
Batch 150, Loss: 0.1278
Batch 160, Loss: 0.1398
Batch 170, Loss: 0.1161
Batch 180, Loss: 0.1081
Batch 190, Loss: 0.1180
Batch 200, Loss: 0.1387
Batch 210, Loss: 0.1326
Batch 220, Loss: 0.1299
Batch 230, Loss: 0.1130
Batch 240, Loss: 0.1250
Batch 250, Loss: 0.1402
Batch 260, Loss: 0.1288
Batch 270, Loss: 0.1177
Batch 280, Loss: 0.1356
Batch 290, Loss: 0.1546
Batch 300, Loss: 0.1210
Batch 310, Loss: 0.1355
Batch 320, Loss: 0.0961
Batch 330, Loss: 0.1409
Batch 340, Loss: 0.1403
Batch 350, Loss: 0.1330
Batch 360, Loss: 0.1367
Batch 370, Loss: 0.1107
Batch 380, Loss: 0.1042
Batch 390, Loss: 0.1296
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 24.991058349609375 seconds
Epoch 199 accuracy: 96.26%
Batch 10, Loss: 0.1190
Batch 20, Loss: 0.1325
Batch 30, Loss: 0.1416
Batch 40, Loss: 0.1442
Batch 50, Loss: 0.1202
Batch 60, Loss: 0.1026
Batch 70, Loss: 0.1025
Batch 80, Loss: 0.1029
Batch 90, Loss: 0.1226
Batch 100, Loss: 0.1282
Batch 110, Loss: 0.1210
Batch 120, Loss: 0.1177
Batch 130, Loss: 0.1346
Batch 140, Loss: 0.1279
Batch 150, Loss: 0.1278
Batch 160, Loss: 0.1099
Batch 170, Loss: 0.1250
Batch 180, Loss: 0.1123
Batch 190, Loss: 0.1310
Batch 200, Loss: 0.1107
Batch 210, Loss: 0.1064
Batch 220, Loss: 0.1273
Batch 230, Loss: 0.1067
Batch 240, Loss: 0.1476
Batch 250, Loss: 0.1154
Batch 260, Loss: 0.1419
Batch 270, Loss: 0.1366
Batch 280, Loss: 0.1465
Batch 290, Loss: 0.1196
Batch 300, Loss: 0.1319
Batch 310, Loss: 0.1418
Batch 320, Loss: 0.1330
Batch 330, Loss: 0.1278
Batch 340, Loss: 0.1190
Batch 350, Loss: 0.1223
Batch 360, Loss: 0.1134
Batch 370, Loss: 0.1274
Batch 380, Loss: 0.1283
Batch 390, Loss: 0.1314
Epoch 200 learning rate: 0.0
Epoch 200 time: 24.880662441253662 seconds
Epoch 200 accuracy: 96.33%
Total training time: 4988.759603977203 seconds
