The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:215: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM/basicaug/lr-0.1/batchsize-128/2024-08-03-18:47:54
Batch 100, Loss: 2.2641
Batch 200, Loss: 1.5800
Batch 300, Loss: 1.4632
Epoch 1 learning rate: 0.05
Epoch 1 time: 140.4061508178711 seconds
Epoch 1 accuracy: 30.9%
Batch 100, Loss: 1.3277
Batch 200, Loss: 1.2636
Batch 300, Loss: 1.2237
Epoch 2 learning rate: 0.0
Epoch 2 time: 99.63564395904541 seconds
Epoch 2 accuracy: 42.91%
rho:  0.04 , alpha:  0.3
Total training time: 240.04280161857605 seconds
/home/tkleinkn/GAMtest/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /home/coulombc/wheels_builder/tmp.2617/python-3.11/torch/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
The top Hessian eigenvalue of this model is 22.6187
Traceback (most recent call last):
  File "/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py", line 469, in <module>
    main()
  File "/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py", line 228, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py", line 455, in main_worker
    grad_norm = hessian_comp.get_gradient_norm()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/6070520/tkleinkn/Vanilla-GAM/utils/pyhessian/hessian.py", line 276, in get_gradient_norm
    norm += torch.sum(grad ** 2)
    ^^^^
UnboundLocalError: cannot access local variable 'norm' where it is not associated with a value
