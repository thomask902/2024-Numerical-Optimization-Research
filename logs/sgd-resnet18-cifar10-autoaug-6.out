The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 4.2074
Batch 20, Loss: 2.4445
Batch 30, Loss: 1.9356
Batch 40, Loss: 1.8392
Batch 50, Loss: 1.7945
Batch 60, Loss: 1.7753
Batch 70, Loss: 1.7361
Batch 80, Loss: 1.6855
Batch 90, Loss: 1.6911
Batch 100, Loss: 1.6708
Batch 110, Loss: 1.6700
Batch 120, Loss: 1.6890
Batch 130, Loss: 1.6648
Batch 140, Loss: 1.6493
Batch 150, Loss: 1.6453
Batch 160, Loss: 1.6334
Batch 170, Loss: 1.6268
Batch 180, Loss: 1.6462
Batch 190, Loss: 1.6426
Batch 200, Loss: 1.5991
Batch 210, Loss: 1.6247
Batch 220, Loss: 1.6062
Batch 230, Loss: 1.6031
Batch 240, Loss: 1.6037
Batch 250, Loss: 1.6174
Batch 260, Loss: 1.5874
Batch 270, Loss: 1.5909
Batch 280, Loss: 1.5915
Batch 290, Loss: 1.5983
Batch 300, Loss: 1.6215
Batch 310, Loss: 1.5994
Batch 320, Loss: 1.5930
Batch 330, Loss: 1.5760
Batch 340, Loss: 1.5883
Batch 350, Loss: 1.5635
Batch 360, Loss: 1.5700
Batch 370, Loss: 1.5744
Batch 380, Loss: 1.5627
Batch 390, Loss: 1.5538
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.74171257019043 seconds
Epoch 1 accuracy: 28.63%
Batch 10, Loss: 1.5154
Batch 20, Loss: 1.5146
Batch 30, Loss: 1.5241
Batch 40, Loss: 1.5326
Batch 50, Loss: 1.5185
Batch 60, Loss: 1.5421
Batch 70, Loss: 1.5238
Batch 80, Loss: 1.5133
Batch 90, Loss: 1.4941
Batch 100, Loss: 1.5039
Batch 110, Loss: 1.4939
Batch 120, Loss: 1.5025
Batch 130, Loss: 1.4866
Batch 140, Loss: 1.4849
Batch 150, Loss: 1.4731
Batch 160, Loss: 1.4831
Batch 170, Loss: 1.4983
Batch 180, Loss: 1.4703
Batch 190, Loss: 1.4664
Batch 200, Loss: 1.4605
Batch 210, Loss: 1.4495
Batch 220, Loss: 1.4817
Batch 230, Loss: 1.4571
Batch 240, Loss: 1.4591
Batch 250, Loss: 1.4679
Batch 260, Loss: 1.4590
Batch 270, Loss: 1.4093
Batch 280, Loss: 1.4422
Batch 290, Loss: 1.4422
Batch 300, Loss: 1.4324
Batch 310, Loss: 1.4354
Batch 320, Loss: 1.4338
Batch 330, Loss: 1.4658
Batch 340, Loss: 1.4204
Batch 350, Loss: 1.4801
Batch 360, Loss: 1.4208
Batch 370, Loss: 1.4494
Batch 380, Loss: 1.4301
Batch 390, Loss: 1.3772
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.49820828437805 seconds
Epoch 2 accuracy: 39.91%
Batch 10, Loss: 1.4132
Batch 20, Loss: 1.4170
Batch 30, Loss: 1.4024
Batch 40, Loss: 1.4306
Batch 50, Loss: 1.3941
Batch 60, Loss: 1.3728
Batch 70, Loss: 1.3678
Batch 80, Loss: 1.4032
Batch 90, Loss: 1.3914
Batch 100, Loss: 1.3668
Batch 110, Loss: 1.3911
Batch 120, Loss: 1.3965
Batch 130, Loss: 1.3380
Batch 140, Loss: 1.3639
Batch 150, Loss: 1.3741
Batch 160, Loss: 1.3336
Batch 170, Loss: 1.3764
Batch 180, Loss: 1.3390
Batch 190, Loss: 1.3193
Batch 200, Loss: 1.3122
Batch 210, Loss: 1.3381
Batch 220, Loss: 1.3794
Batch 230, Loss: 1.3131
Batch 240, Loss: 1.3211
Batch 250, Loss: 1.3039
Batch 260, Loss: 1.3221
Batch 270, Loss: 1.3292
Batch 280, Loss: 1.3319
Batch 290, Loss: 1.3008
Batch 300, Loss: 1.2922
Batch 310, Loss: 1.2904
Batch 320, Loss: 1.3390
Batch 330, Loss: 1.2637
Batch 340, Loss: 1.3334
Batch 350, Loss: 1.2772
Batch 360, Loss: 1.3047
Batch 370, Loss: 1.2487
Batch 380, Loss: 1.2822
Batch 390, Loss: 1.2726
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.497963428497314 seconds
Epoch 3 accuracy: 49.56%
Batch 10, Loss: 1.2863
Batch 20, Loss: 1.2546
Batch 30, Loss: 1.2467
Batch 40, Loss: 1.2556
Batch 50, Loss: 1.2476
Batch 60, Loss: 1.2237
Batch 70, Loss: 1.2508
Batch 80, Loss: 1.2262
Batch 90, Loss: 1.2518
Batch 100, Loss: 1.2380
Batch 110, Loss: 1.2631
Batch 120, Loss: 1.2488
Batch 130, Loss: 1.2771
Batch 140, Loss: 1.3213
Batch 150, Loss: 1.2342
Batch 160, Loss: 1.2304
Batch 170, Loss: 1.2310
Batch 180, Loss: 1.2144
Batch 190, Loss: 1.2121
Batch 200, Loss: 1.1765
Batch 210, Loss: 1.1910
Batch 220, Loss: 1.1855
Batch 230, Loss: 1.2227
Batch 240, Loss: 1.1469
Batch 250, Loss: 1.1791
Batch 260, Loss: 1.1761
Batch 270, Loss: 1.2036
Batch 280, Loss: 1.1831
Batch 290, Loss: 1.1624
Batch 300, Loss: 1.1289
Batch 310, Loss: 1.1476
Batch 320, Loss: 1.1583
Batch 330, Loss: 1.1670
Batch 340, Loss: 1.1312
Batch 350, Loss: 1.1089
Batch 360, Loss: 1.1682
Batch 370, Loss: 1.1882
Batch 380, Loss: 1.1557
Batch 390, Loss: 1.1661
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.55208730697632 seconds
Epoch 4 accuracy: 53.25%
Batch 10, Loss: 1.1490
Batch 20, Loss: 1.1587
Batch 30, Loss: 1.1714
Batch 40, Loss: 1.1182
Batch 50, Loss: 1.1291
Batch 60, Loss: 1.1128
Batch 70, Loss: 1.1242
Batch 80, Loss: 1.0949
Batch 90, Loss: 1.1630
Batch 100, Loss: 1.1108
Batch 110, Loss: 1.1083
Batch 120, Loss: 1.1335
Batch 130, Loss: 1.1032
Batch 140, Loss: 1.1102
Batch 150, Loss: 1.1195
Batch 160, Loss: 1.0719
Batch 170, Loss: 1.0819
Batch 180, Loss: 1.0658
Batch 190, Loss: 1.0676
Batch 200, Loss: 1.1029
Batch 210, Loss: 1.0986
Batch 220, Loss: 1.0573
Batch 230, Loss: 1.0859
Batch 240, Loss: 1.0422
Batch 250, Loss: 1.0548
Batch 260, Loss: 1.1260
Batch 270, Loss: 1.1089
Batch 280, Loss: 1.0155
Batch 290, Loss: 1.0744
Batch 300, Loss: 1.1279
Batch 310, Loss: 1.0808
Batch 320, Loss: 1.0579
Batch 330, Loss: 1.0867
Batch 340, Loss: 1.0981
Batch 350, Loss: 1.0491
Batch 360, Loss: 1.0646
Batch 370, Loss: 1.0730
Batch 380, Loss: 1.0392
Batch 390, Loss: 1.0377
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.48592472076416 seconds
Epoch 5 accuracy: 50.35%
Batch 10, Loss: 1.1019
Batch 20, Loss: 1.0413
Batch 30, Loss: 1.0578
Batch 40, Loss: 1.0439
Batch 50, Loss: 1.0627
Batch 60, Loss: 1.0617
Batch 70, Loss: 1.0663
Batch 80, Loss: 1.0457
Batch 90, Loss: 1.0875
Batch 100, Loss: 1.0673
Batch 110, Loss: 1.0089
Batch 120, Loss: 1.0599
Batch 130, Loss: 1.0163
Batch 140, Loss: 1.0609
Batch 150, Loss: 1.0684
Batch 160, Loss: 1.0251
Batch 170, Loss: 1.0367
Batch 180, Loss: 0.9952
Batch 190, Loss: 1.0082
Batch 200, Loss: 1.0060
Batch 210, Loss: 1.0320
Batch 220, Loss: 1.0249
Batch 230, Loss: 0.9987
Batch 240, Loss: 1.0476
Batch 250, Loss: 1.0182
Batch 260, Loss: 0.9851
Batch 270, Loss: 1.0166
Batch 280, Loss: 0.9652
Batch 290, Loss: 1.0390
Batch 300, Loss: 1.0218
Batch 310, Loss: 0.9870
Batch 320, Loss: 1.0039
Batch 330, Loss: 0.9553
Batch 340, Loss: 0.9415
Batch 350, Loss: 0.9816
Batch 360, Loss: 1.0101
Batch 370, Loss: 1.0146
Batch 380, Loss: 0.9684
Batch 390, Loss: 1.0294
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.519814014434814 seconds
Epoch 6 accuracy: 62.19%
Batch 10, Loss: 0.9851
Batch 20, Loss: 0.9354
Batch 30, Loss: 0.9568
Batch 40, Loss: 0.9297
Batch 50, Loss: 0.9975
Batch 60, Loss: 0.9872
Batch 70, Loss: 0.9610
Batch 80, Loss: 0.9574
Batch 90, Loss: 0.9436
Batch 100, Loss: 1.0005
Batch 110, Loss: 0.9483
Batch 120, Loss: 0.9209
Batch 130, Loss: 0.9985
Batch 140, Loss: 0.9610
Batch 150, Loss: 0.9644
Batch 160, Loss: 0.9624
Batch 170, Loss: 0.9972
Batch 180, Loss: 0.9200
Batch 190, Loss: 0.9173
Batch 200, Loss: 0.9317
Batch 210, Loss: 0.8967
Batch 220, Loss: 0.9078
Batch 230, Loss: 0.9250
Batch 240, Loss: 0.9308
Batch 250, Loss: 0.9641
Batch 260, Loss: 0.9491
Batch 270, Loss: 0.9388
Batch 280, Loss: 0.9607
Batch 290, Loss: 0.9557
Batch 300, Loss: 0.8971
Batch 310, Loss: 0.9288
Batch 320, Loss: 0.8695
Batch 330, Loss: 0.9125
Batch 340, Loss: 0.9315
Batch 350, Loss: 0.9285
Batch 360, Loss: 0.9540
Batch 370, Loss: 0.9085
Batch 380, Loss: 0.9385
Batch 390, Loss: 0.9491
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.473012447357178 seconds
Epoch 7 accuracy: 68.77%
Batch 10, Loss: 0.9178
Batch 20, Loss: 0.8668
Batch 30, Loss: 0.8974
Batch 40, Loss: 0.9080
Batch 50, Loss: 0.9169
Batch 60, Loss: 0.8724
Batch 70, Loss: 0.8990
Batch 80, Loss: 0.8701
Batch 90, Loss: 0.8640
Batch 100, Loss: 0.8827
Batch 110, Loss: 0.9294
Batch 120, Loss: 0.8542
Batch 130, Loss: 0.8743
Batch 140, Loss: 0.9057
Batch 150, Loss: 0.8822
Batch 160, Loss: 0.8964
Batch 170, Loss: 0.8625
Batch 180, Loss: 0.8821
Batch 190, Loss: 0.8585
Batch 200, Loss: 0.8362
Batch 210, Loss: 0.8767
Batch 220, Loss: 0.9050
Batch 230, Loss: 0.8594
Batch 240, Loss: 0.9138
Batch 250, Loss: 0.9159
Batch 260, Loss: 0.8754
Batch 270, Loss: 0.8435
Batch 280, Loss: 0.8095
Batch 290, Loss: 0.8354
Batch 300, Loss: 0.8753
Batch 310, Loss: 0.8479
Batch 320, Loss: 0.8568
Batch 330, Loss: 0.8275
Batch 340, Loss: 0.8651
Batch 350, Loss: 0.8613
Batch 360, Loss: 0.8701
Batch 370, Loss: 0.8251
Batch 380, Loss: 0.8203
Batch 390, Loss: 0.8803
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.452202320098877 seconds
Epoch 8 accuracy: 69.56%
Batch 10, Loss: 0.8443
Batch 20, Loss: 0.8277
Batch 30, Loss: 0.8265
Batch 40, Loss: 0.8371
Batch 50, Loss: 0.8372
Batch 60, Loss: 0.8657
Batch 70, Loss: 0.8894
Batch 80, Loss: 0.8406
Batch 90, Loss: 0.8566
Batch 100, Loss: 0.8788
Batch 110, Loss: 0.7844
Batch 120, Loss: 0.7933
Batch 130, Loss: 0.8465
Batch 140, Loss: 0.8362
Batch 150, Loss: 0.8122
Batch 160, Loss: 0.8607
Batch 170, Loss: 0.8291
Batch 180, Loss: 0.7933
Batch 190, Loss: 0.8348
Batch 200, Loss: 0.8818
Batch 210, Loss: 0.8525
Batch 220, Loss: 0.8352
Batch 230, Loss: 0.8272
Batch 240, Loss: 0.8364
Batch 250, Loss: 0.8320
Batch 260, Loss: 0.7980
Batch 270, Loss: 0.7774
Batch 280, Loss: 0.7863
Batch 290, Loss: 0.7920
Batch 300, Loss: 0.7635
Batch 310, Loss: 0.7892
Batch 320, Loss: 0.7920
Batch 330, Loss: 0.7989
Batch 340, Loss: 0.8074
Batch 350, Loss: 0.8409
Batch 360, Loss: 0.8295
Batch 370, Loss: 0.8041
Batch 380, Loss: 0.8097
Batch 390, Loss: 0.7773
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.374837398529053 seconds
Epoch 9 accuracy: 71.13%
Batch 10, Loss: 0.8130
Batch 20, Loss: 0.8433
Batch 30, Loss: 0.8034
Batch 40, Loss: 0.7683
Batch 50, Loss: 0.7994
Batch 60, Loss: 0.7764
Batch 70, Loss: 0.7982
Batch 80, Loss: 0.7575
Batch 90, Loss: 0.8151
Batch 100, Loss: 0.8262
Batch 110, Loss: 0.7868
Batch 120, Loss: 0.8221
Batch 130, Loss: 0.8380
Batch 140, Loss: 0.8059
Batch 150, Loss: 0.8144
Batch 160, Loss: 0.8164
Batch 170, Loss: 0.7784
Batch 180, Loss: 0.7707
Batch 190, Loss: 0.7887
Batch 200, Loss: 0.7908
Batch 210, Loss: 0.7468
Batch 220, Loss: 0.8529
Batch 230, Loss: 0.7325
Batch 240, Loss: 0.8153
Batch 250, Loss: 0.7956
Batch 260, Loss: 0.7675
Batch 270, Loss: 0.7576
Batch 280, Loss: 0.7758
Batch 290, Loss: 0.7825
Batch 300, Loss: 0.8065
Batch 310, Loss: 0.7454
Batch 320, Loss: 0.7529
Batch 330, Loss: 0.7733
Batch 340, Loss: 0.8067
Batch 350, Loss: 0.7255
Batch 360, Loss: 0.7998
Batch 370, Loss: 0.7374
Batch 380, Loss: 0.7961
Batch 390, Loss: 0.7523
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.415557622909546 seconds
Epoch 10 accuracy: 72.76%
Batch 10, Loss: 0.7889
Batch 20, Loss: 0.8285
Batch 30, Loss: 0.7852
Batch 40, Loss: 0.7651
Batch 50, Loss: 0.7801
Batch 60, Loss: 0.7838
Batch 70, Loss: 0.7572
Batch 80, Loss: 0.7561
Batch 90, Loss: 0.7732
Batch 100, Loss: 0.7432
Batch 110, Loss: 0.7768
Batch 120, Loss: 0.7426
Batch 130, Loss: 0.8028
Batch 140, Loss: 0.7445
Batch 150, Loss: 0.7770
Batch 160, Loss: 0.7496
Batch 170, Loss: 0.7968
Batch 180, Loss: 0.7398
Batch 190, Loss: 0.7555
Batch 200, Loss: 0.7314
Batch 210, Loss: 0.7786
Batch 220, Loss: 0.7814
Batch 230, Loss: 0.7373
Batch 240, Loss: 0.7550
Batch 250, Loss: 0.7689
Batch 260, Loss: 0.7609
Batch 270, Loss: 0.7484
Batch 280, Loss: 0.7527
Batch 290, Loss: 0.7152
Batch 300, Loss: 0.6956
Batch 310, Loss: 0.7205
Batch 320, Loss: 0.7526
Batch 330, Loss: 0.7584
Batch 340, Loss: 0.7578
Batch 350, Loss: 0.7329
Batch 360, Loss: 0.7360
Batch 370, Loss: 0.7105
Batch 380, Loss: 0.7672
Batch 390, Loss: 0.7335
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.399933576583862 seconds
Epoch 11 accuracy: 73.83%
Batch 10, Loss: 0.7897
Batch 20, Loss: 0.7830
Batch 30, Loss: 0.7694
Batch 40, Loss: 0.7950
Batch 50, Loss: 0.7441
Batch 60, Loss: 0.7229
Batch 70, Loss: 0.7261
Batch 80, Loss: 0.7252
Batch 90, Loss: 0.7544
Batch 100, Loss: 0.7555
Batch 110, Loss: 0.7206
Batch 120, Loss: 0.7210
Batch 130, Loss: 0.7293
Batch 140, Loss: 0.7105
Batch 150, Loss: 0.7333
Batch 160, Loss: 0.7101
Batch 170, Loss: 0.7368
Batch 180, Loss: 0.7534
Batch 190, Loss: 0.7478
Batch 200, Loss: 0.7511
Batch 210, Loss: 0.7325
Batch 220, Loss: 0.7546
Batch 230, Loss: 0.7874
Batch 240, Loss: 0.7302
Batch 250, Loss: 0.7377
Batch 260, Loss: 0.7380
Batch 270, Loss: 0.7189
Batch 280, Loss: 0.6987
Batch 290, Loss: 0.7443
Batch 300, Loss: 0.7307
Batch 310, Loss: 0.7323
Batch 320, Loss: 0.7738
Batch 330, Loss: 0.7050
Batch 340, Loss: 0.7430
Batch 350, Loss: 0.7152
Batch 360, Loss: 0.7221
Batch 370, Loss: 0.7346
Batch 380, Loss: 0.7703
Batch 390, Loss: 0.7227
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.418692111968994 seconds
Epoch 12 accuracy: 71.79%
Batch 10, Loss: 0.7149
Batch 20, Loss: 0.7637
Batch 30, Loss: 0.7416
Batch 40, Loss: 0.7145
Batch 50, Loss: 0.7646
Batch 60, Loss: 0.6903
Batch 70, Loss: 0.7609
Batch 80, Loss: 0.7008
Batch 90, Loss: 0.7260
Batch 100, Loss: 0.7258
Batch 110, Loss: 0.7343
Batch 120, Loss: 0.7218
Batch 130, Loss: 0.7605
Batch 140, Loss: 0.7091
Batch 150, Loss: 0.7159
Batch 160, Loss: 0.6776
Batch 170, Loss: 0.7207
Batch 180, Loss: 0.6914
Batch 190, Loss: 0.7172
Batch 200, Loss: 0.7265
Batch 210, Loss: 0.7028
Batch 220, Loss: 0.6923
Batch 230, Loss: 0.6719
Batch 240, Loss: 0.7182
Batch 250, Loss: 0.7233
Batch 260, Loss: 0.7117
Batch 270, Loss: 0.7293
Batch 280, Loss: 0.7571
Batch 290, Loss: 0.7327
Batch 300, Loss: 0.7011
Batch 310, Loss: 0.7525
Batch 320, Loss: 0.7094
Batch 330, Loss: 0.7012
Batch 340, Loss: 0.7112
Batch 350, Loss: 0.7379
Batch 360, Loss: 0.7582
Batch 370, Loss: 0.7168
Batch 380, Loss: 0.7552
Batch 390, Loss: 0.7151
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.54337501525879 seconds
Epoch 13 accuracy: 78.89%
Batch 10, Loss: 0.7498
Batch 20, Loss: 0.6846
Batch 30, Loss: 0.6940
Batch 40, Loss: 0.6525
Batch 50, Loss: 0.7350
Batch 60, Loss: 0.6920
Batch 70, Loss: 0.7127
Batch 80, Loss: 0.7498
Batch 90, Loss: 0.7108
Batch 100, Loss: 0.6719
Batch 110, Loss: 0.7419
Batch 120, Loss: 0.6779
Batch 130, Loss: 0.6962
Batch 140, Loss: 0.7379
Batch 150, Loss: 0.6583
Batch 160, Loss: 0.7202
Batch 170, Loss: 0.6896
Batch 180, Loss: 0.6853
Batch 190, Loss: 0.6903
Batch 200, Loss: 0.7039
Batch 210, Loss: 0.7063
Batch 220, Loss: 0.6820
Batch 230, Loss: 0.6899
Batch 240, Loss: 0.7100
Batch 250, Loss: 0.6600
Batch 260, Loss: 0.6581
Batch 270, Loss: 0.7177
Batch 280, Loss: 0.7061
Batch 290, Loss: 0.7025
Batch 300, Loss: 0.7064
Batch 310, Loss: 0.6940
Batch 320, Loss: 0.7124
Batch 330, Loss: 0.7136
Batch 340, Loss: 0.7091
Batch 350, Loss: 0.6642
Batch 360, Loss: 0.6337
Batch 370, Loss: 0.6529
Batch 380, Loss: 0.6996
Batch 390, Loss: 0.7241
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.541369915008545 seconds
Epoch 14 accuracy: 76.59%
Batch 10, Loss: 0.7351
Batch 20, Loss: 0.6800
Batch 30, Loss: 0.7410
Batch 40, Loss: 0.6842
Batch 50, Loss: 0.6382
Batch 60, Loss: 0.6894
Batch 70, Loss: 0.6954
Batch 80, Loss: 0.7219
Batch 90, Loss: 0.7078
Batch 100, Loss: 0.6842
Batch 110, Loss: 0.6423
Batch 120, Loss: 0.6443
Batch 130, Loss: 0.6930
Batch 140, Loss: 0.6797
Batch 150, Loss: 0.7305
Batch 160, Loss: 0.6743
Batch 170, Loss: 0.7089
Batch 180, Loss: 0.7355
Batch 190, Loss: 0.7343
Batch 200, Loss: 0.6765
Batch 210, Loss: 0.6418
Batch 220, Loss: 0.6679
Batch 230, Loss: 0.6732
Batch 240, Loss: 0.7027
Batch 250, Loss: 0.6600
Batch 260, Loss: 0.6335
Batch 270, Loss: 0.7695
Batch 280, Loss: 0.6899
Batch 290, Loss: 0.7131
Batch 300, Loss: 0.6578
Batch 310, Loss: 0.6940
Batch 320, Loss: 0.7239
Batch 330, Loss: 0.6871
Batch 340, Loss: 0.6523
Batch 350, Loss: 0.6721
Batch 360, Loss: 0.6785
Batch 370, Loss: 0.6907
Batch 380, Loss: 0.6933
Batch 390, Loss: 0.6677
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.616319179534912 seconds
Epoch 15 accuracy: 78.75%
Batch 10, Loss: 0.6382
Batch 20, Loss: 0.7061
Batch 30, Loss: 0.6880
Batch 40, Loss: 0.7398
Batch 50, Loss: 0.6904
Batch 60, Loss: 0.6907
Batch 70, Loss: 0.7142
Batch 80, Loss: 0.6651
Batch 90, Loss: 0.6892
Batch 100, Loss: 0.6393
Batch 110, Loss: 0.6528
Batch 120, Loss: 0.6614
Batch 130, Loss: 0.7050
Batch 140, Loss: 0.6906
Batch 150, Loss: 0.7102
Batch 160, Loss: 0.6888
Batch 170, Loss: 0.7105
Batch 180, Loss: 0.6804
Batch 190, Loss: 0.6679
Batch 200, Loss: 0.6900
Batch 210, Loss: 0.7255
Batch 220, Loss: 0.6860
Batch 230, Loss: 0.6708
Batch 240, Loss: 0.6838
Batch 250, Loss: 0.6971
Batch 260, Loss: 0.7122
Batch 270, Loss: 0.6964
Batch 280, Loss: 0.6632
Batch 290, Loss: 0.6715
Batch 300, Loss: 0.6557
Batch 310, Loss: 0.6624
Batch 320, Loss: 0.6637
Batch 330, Loss: 0.6189
Batch 340, Loss: 0.6278
Batch 350, Loss: 0.6748
Batch 360, Loss: 0.6800
Batch 370, Loss: 0.6603
Batch 380, Loss: 0.6127
Batch 390, Loss: 0.6562
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.56208896636963 seconds
Epoch 16 accuracy: 77.59%
Batch 10, Loss: 0.6246
Batch 20, Loss: 0.7012
Batch 30, Loss: 0.6700
Batch 40, Loss: 0.6704
Batch 50, Loss: 0.6973
Batch 60, Loss: 0.6828
Batch 70, Loss: 0.6244
Batch 80, Loss: 0.6778
Batch 90, Loss: 0.7033
Batch 100, Loss: 0.6705
Batch 110, Loss: 0.6761
Batch 120, Loss: 0.6490
Batch 130, Loss: 0.6979
Batch 140, Loss: 0.6425
Batch 150, Loss: 0.6626
Batch 160, Loss: 0.6781
Batch 170, Loss: 0.6600
Batch 180, Loss: 0.6315
Batch 190, Loss: 0.6353
Batch 200, Loss: 0.6778
Batch 210, Loss: 0.6840
Batch 220, Loss: 0.6829
Batch 230, Loss: 0.6730
Batch 240, Loss: 0.6302
Batch 250, Loss: 0.6601
Batch 260, Loss: 0.6527
Batch 270, Loss: 0.6590
Batch 280, Loss: 0.6789
Batch 290, Loss: 0.6837
Batch 300, Loss: 0.6968
Batch 310, Loss: 0.6740
Batch 320, Loss: 0.6596
Batch 330, Loss: 0.6917
Batch 340, Loss: 0.6765
Batch 350, Loss: 0.6513
Batch 360, Loss: 0.6707
Batch 370, Loss: 0.6907
Batch 380, Loss: 0.6729
Batch 390, Loss: 0.6817
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.540333032608032 seconds
Epoch 17 accuracy: 79.39%
Batch 10, Loss: 0.6984
Batch 20, Loss: 0.6423
Batch 30, Loss: 0.6462
Batch 40, Loss: 0.6600
Batch 50, Loss: 0.6601
Batch 60, Loss: 0.6927
Batch 70, Loss: 0.6717
Batch 80, Loss: 0.6690
Batch 90, Loss: 0.6831
Batch 100, Loss: 0.6963
Batch 110, Loss: 0.6658
Batch 120, Loss: 0.6382
Batch 130, Loss: 0.6514
Batch 140, Loss: 0.7049
Batch 150, Loss: 0.6356
Batch 160, Loss: 0.6273
Batch 170, Loss: 0.6751
Batch 180, Loss: 0.6330
Batch 190, Loss: 0.6467
Batch 200, Loss: 0.6450
Batch 210, Loss: 0.6506
Batch 220, Loss: 0.7038
Batch 230, Loss: 0.6430
Batch 240, Loss: 0.6611
Batch 250, Loss: 0.6624
Batch 260, Loss: 0.6249
Batch 270, Loss: 0.5964
Batch 280, Loss: 0.5964
Batch 290, Loss: 0.6985
Batch 300, Loss: 0.7055
Batch 310, Loss: 0.6526
Batch 320, Loss: 0.6201
Batch 330, Loss: 0.6479
Batch 340, Loss: 0.6263
Batch 350, Loss: 0.6791
Batch 360, Loss: 0.6546
Batch 370, Loss: 0.6595
Batch 380, Loss: 0.6542
Batch 390, Loss: 0.6519
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.440881729125977 seconds
Epoch 18 accuracy: 80.28%
Batch 10, Loss: 0.6479
Batch 20, Loss: 0.6758
Batch 30, Loss: 0.6488
Batch 40, Loss: 0.6535
Batch 50, Loss: 0.7123
Batch 60, Loss: 0.6828
Batch 70, Loss: 0.6758
Batch 80, Loss: 0.6459
Batch 90, Loss: 0.6291
Batch 100, Loss: 0.6791
Batch 110, Loss: 0.6812
Batch 120, Loss: 0.6436
Batch 130, Loss: 0.6579
Batch 140, Loss: 0.6485
Batch 150, Loss: 0.6507
Batch 160, Loss: 0.6170
Batch 170, Loss: 0.6417
Batch 180, Loss: 0.6732
Batch 190, Loss: 0.6584
Batch 200, Loss: 0.6306
Batch 210, Loss: 0.6195
Batch 220, Loss: 0.6487
Batch 230, Loss: 0.6150
Batch 240, Loss: 0.6471
Batch 250, Loss: 0.6657
Batch 260, Loss: 0.6712
Batch 270, Loss: 0.6562
Batch 280, Loss: 0.6402
Batch 290, Loss: 0.6491
Batch 300, Loss: 0.6522
Batch 310, Loss: 0.6650
Batch 320, Loss: 0.6771
Batch 330, Loss: 0.6649
Batch 340, Loss: 0.6187
Batch 350, Loss: 0.6626
Batch 360, Loss: 0.6029
Batch 370, Loss: 0.6930
Batch 380, Loss: 0.6596
Batch 390, Loss: 0.6264
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.428142309188843 seconds
Epoch 19 accuracy: 78.01%
Batch 10, Loss: 0.6351
Batch 20, Loss: 0.6370
Batch 30, Loss: 0.6313
Batch 40, Loss: 0.6480
Batch 50, Loss: 0.6791
Batch 60, Loss: 0.6402
Batch 70, Loss: 0.6501
Batch 80, Loss: 0.6429
Batch 90, Loss: 0.6780
Batch 100, Loss: 0.6302
Batch 110, Loss: 0.6369
Batch 120, Loss: 0.6261
Batch 130, Loss: 0.6695
Batch 140, Loss: 0.6716
Batch 150, Loss: 0.6318
Batch 160, Loss: 0.6533
Batch 170, Loss: 0.6318
Batch 180, Loss: 0.6535
Batch 190, Loss: 0.6149
Batch 200, Loss: 0.6227
Batch 210, Loss: 0.6531
Batch 220, Loss: 0.6696
Batch 230, Loss: 0.6330
Batch 240, Loss: 0.6125
Batch 250, Loss: 0.6084
Batch 260, Loss: 0.6697
Batch 270, Loss: 0.6560
Batch 280, Loss: 0.5761
Batch 290, Loss: 0.6572
Batch 300, Loss: 0.6073
Batch 310, Loss: 0.6511
Batch 320, Loss: 0.6658
Batch 330, Loss: 0.6603
Batch 340, Loss: 0.6653
Batch 350, Loss: 0.6551
Batch 360, Loss: 0.6209
Batch 370, Loss: 0.6473
Batch 380, Loss: 0.6653
Batch 390, Loss: 0.6673
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.51195454597473 seconds
Epoch 20 accuracy: 79.99%
Batch 10, Loss: 0.6664
Batch 20, Loss: 0.6444
Batch 30, Loss: 0.6205
Batch 40, Loss: 0.6332
Batch 50, Loss: 0.6458
Batch 60, Loss: 0.6173
Batch 70, Loss: 0.6042
Batch 80, Loss: 0.6204
Batch 90, Loss: 0.6355
Batch 100, Loss: 0.5995
Batch 110, Loss: 0.6145
Batch 120, Loss: 0.6504
Batch 130, Loss: 0.6601
Batch 140, Loss: 0.6386
Batch 150, Loss: 0.6291
Batch 160, Loss: 0.6284
Batch 170, Loss: 0.5865
Batch 180, Loss: 0.6389
Batch 190, Loss: 0.6289
Batch 200, Loss: 0.6188
Batch 210, Loss: 0.6513
Batch 220, Loss: 0.6690
Batch 230, Loss: 0.6146
Batch 240, Loss: 0.6243
Batch 250, Loss: 0.6314
Batch 260, Loss: 0.6545
Batch 270, Loss: 0.6536
Batch 280, Loss: 0.6523
Batch 290, Loss: 0.6505
Batch 300, Loss: 0.6181
Batch 310, Loss: 0.6325
Batch 320, Loss: 0.6512
Batch 330, Loss: 0.6469
Batch 340, Loss: 0.5909
Batch 350, Loss: 0.6267
Batch 360, Loss: 0.6580
Batch 370, Loss: 0.6282
Batch 380, Loss: 0.6446
Batch 390, Loss: 0.6201
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.44189429283142 seconds
Epoch 21 accuracy: 77.17%
Batch 10, Loss: 0.6071
Batch 20, Loss: 0.6460
Batch 30, Loss: 0.5913
Batch 40, Loss: 0.6444
Batch 50, Loss: 0.6131
Batch 60, Loss: 0.6286
Batch 70, Loss: 0.6516
Batch 80, Loss: 0.5782
Batch 90, Loss: 0.6384
Batch 100, Loss: 0.6243
Batch 110, Loss: 0.6318
Batch 120, Loss: 0.6419
Batch 130, Loss: 0.6579
Batch 140, Loss: 0.6391
Batch 150, Loss: 0.6629
Batch 160, Loss: 0.6120
Batch 170, Loss: 0.6680
Batch 180, Loss: 0.6334
Batch 190, Loss: 0.5748
Batch 200, Loss: 0.6086
Batch 210, Loss: 0.6440
Batch 220, Loss: 0.6299
Batch 230, Loss: 0.6449
Batch 240, Loss: 0.6474
Batch 250, Loss: 0.6379
Batch 260, Loss: 0.6123
Batch 270, Loss: 0.6267
Batch 280, Loss: 0.6140
Batch 290, Loss: 0.6141
Batch 300, Loss: 0.6218
Batch 310, Loss: 0.5894
Batch 320, Loss: 0.6134
Batch 330, Loss: 0.6241
Batch 340, Loss: 0.6899
Batch 350, Loss: 0.6449
Batch 360, Loss: 0.6528
Batch 370, Loss: 0.6079
Batch 380, Loss: 0.6213
Batch 390, Loss: 0.5943
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.393715381622314 seconds
Epoch 22 accuracy: 78.95%
Batch 10, Loss: 0.6084
Batch 20, Loss: 0.6259
Batch 30, Loss: 0.6486
Batch 40, Loss: 0.6110
Batch 50, Loss: 0.6451
Batch 60, Loss: 0.6321
Batch 70, Loss: 0.6093
Batch 80, Loss: 0.6002
Batch 90, Loss: 0.5941
Batch 100, Loss: 0.5953
Batch 110, Loss: 0.5943
Batch 120, Loss: 0.6215
Batch 130, Loss: 0.6435
Batch 140, Loss: 0.5532
Batch 150, Loss: 0.5806
Batch 160, Loss: 0.6639
Batch 170, Loss: 0.6666
Batch 180, Loss: 0.6365
Batch 190, Loss: 0.6203
Batch 200, Loss: 0.6264
Batch 210, Loss: 0.6474
Batch 220, Loss: 0.6509
Batch 230, Loss: 0.6272
Batch 240, Loss: 0.6212
Batch 250, Loss: 0.6240
Batch 260, Loss: 0.6010
Batch 270, Loss: 0.6375
Batch 280, Loss: 0.6626
Batch 290, Loss: 0.5950
Batch 300, Loss: 0.5950
Batch 310, Loss: 0.6158
Batch 320, Loss: 0.6286
Batch 330, Loss: 0.6322
Batch 340, Loss: 0.6068
Batch 350, Loss: 0.6194
Batch 360, Loss: 0.6457
Batch 370, Loss: 0.5937
Batch 380, Loss: 0.6271
Batch 390, Loss: 0.5757
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.508994340896606 seconds
Epoch 23 accuracy: 82.45%
Batch 10, Loss: 0.6247
Batch 20, Loss: 0.5927
Batch 30, Loss: 0.5652
Batch 40, Loss: 0.6039
Batch 50, Loss: 0.6152
Batch 60, Loss: 0.6548
Batch 70, Loss: 0.6337
Batch 80, Loss: 0.6175
Batch 90, Loss: 0.6195
Batch 100, Loss: 0.5745
Batch 110, Loss: 0.5939
Batch 120, Loss: 0.6049
Batch 130, Loss: 0.5976
Batch 140, Loss: 0.6020
Batch 150, Loss: 0.5985
Batch 160, Loss: 0.6081
Batch 170, Loss: 0.6333
Batch 180, Loss: 0.6299
Batch 190, Loss: 0.6112
Batch 200, Loss: 0.6323
Batch 210, Loss: 0.6208
Batch 220, Loss: 0.6154
Batch 230, Loss: 0.6001
Batch 240, Loss: 0.6133
Batch 250, Loss: 0.6166
Batch 260, Loss: 0.6210
Batch 270, Loss: 0.6458
Batch 280, Loss: 0.6124
Batch 290, Loss: 0.6321
Batch 300, Loss: 0.6135
Batch 310, Loss: 0.6566
Batch 320, Loss: 0.6295
Batch 330, Loss: 0.5912
Batch 340, Loss: 0.6034
Batch 350, Loss: 0.6184
Batch 360, Loss: 0.6534
Batch 370, Loss: 0.6244
Batch 380, Loss: 0.5625
Batch 390, Loss: 0.6475
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.518858194351196 seconds
Epoch 24 accuracy: 81.36%
Batch 10, Loss: 0.6198
Batch 20, Loss: 0.6193
Batch 30, Loss: 0.5566
Batch 40, Loss: 0.6499
Batch 50, Loss: 0.6069
Batch 60, Loss: 0.6101
Batch 70, Loss: 0.6297
Batch 80, Loss: 0.6021
Batch 90, Loss: 0.5796
Batch 100, Loss: 0.5684
Batch 110, Loss: 0.6554
Batch 120, Loss: 0.5934
Batch 130, Loss: 0.5799
Batch 140, Loss: 0.6190
Batch 150, Loss: 0.6116
Batch 160, Loss: 0.6281
Batch 170, Loss: 0.6192
Batch 180, Loss: 0.5788
Batch 190, Loss: 0.5963
Batch 200, Loss: 0.5969
Batch 210, Loss: 0.5800
Batch 220, Loss: 0.6110
Batch 230, Loss: 0.6173
Batch 240, Loss: 0.6448
Batch 250, Loss: 0.5890
Batch 260, Loss: 0.6108
Batch 270, Loss: 0.6027
Batch 280, Loss: 0.6543
Batch 290, Loss: 0.6047
Batch 300, Loss: 0.6067
Batch 310, Loss: 0.6375
Batch 320, Loss: 0.6047
Batch 330, Loss: 0.6179
Batch 340, Loss: 0.5928
Batch 350, Loss: 0.5658
Batch 360, Loss: 0.6003
Batch 370, Loss: 0.6488
Batch 380, Loss: 0.5938
Batch 390, Loss: 0.6021
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.374884366989136 seconds
Epoch 25 accuracy: 81.42%
Batch 10, Loss: 0.6050
Batch 20, Loss: 0.6213
Batch 30, Loss: 0.6085
Batch 40, Loss: 0.5866
Batch 50, Loss: 0.5684
Batch 60, Loss: 0.5898
Batch 70, Loss: 0.6032
Batch 80, Loss: 0.6019
Batch 90, Loss: 0.5746
Batch 100, Loss: 0.6633
Batch 110, Loss: 0.5848
Batch 120, Loss: 0.6417
Batch 130, Loss: 0.5913
Batch 140, Loss: 0.5746
Batch 150, Loss: 0.5933
Batch 160, Loss: 0.5423
Batch 170, Loss: 0.6358
Batch 180, Loss: 0.6112
Batch 190, Loss: 0.6221
Batch 200, Loss: 0.6210
Batch 210, Loss: 0.5653
Batch 220, Loss: 0.6279
Batch 230, Loss: 0.6037
Batch 240, Loss: 0.6387
Batch 250, Loss: 0.5971
Batch 260, Loss: 0.6342
Batch 270, Loss: 0.6056
Batch 280, Loss: 0.5866
Batch 290, Loss: 0.5618
Batch 300, Loss: 0.6354
Batch 310, Loss: 0.6008
Batch 320, Loss: 0.5815
Batch 330, Loss: 0.6077
Batch 340, Loss: 0.6037
Batch 350, Loss: 0.6328
Batch 360, Loss: 0.5822
Batch 370, Loss: 0.6322
Batch 380, Loss: 0.6369
Batch 390, Loss: 0.6008
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.37824296951294 seconds
Epoch 26 accuracy: 80.84%
Batch 10, Loss: 0.6060
Batch 20, Loss: 0.5591
Batch 30, Loss: 0.6403
Batch 40, Loss: 0.5794
Batch 50, Loss: 0.5844
Batch 60, Loss: 0.5650
Batch 70, Loss: 0.5850
Batch 80, Loss: 0.6240
Batch 90, Loss: 0.6338
Batch 100, Loss: 0.6031
Batch 110, Loss: 0.6259
Batch 120, Loss: 0.5784
Batch 130, Loss: 0.6246
Batch 140, Loss: 0.6258
Batch 150, Loss: 0.6113
Batch 160, Loss: 0.6031
Batch 170, Loss: 0.6016
Batch 180, Loss: 0.5677
Batch 190, Loss: 0.5925
Batch 200, Loss: 0.6238
Batch 210, Loss: 0.5928
Batch 220, Loss: 0.6080
Batch 230, Loss: 0.6267
Batch 240, Loss: 0.6263
Batch 250, Loss: 0.5807
Batch 260, Loss: 0.5783
Batch 270, Loss: 0.6052
Batch 280, Loss: 0.6158
Batch 290, Loss: 0.6054
Batch 300, Loss: 0.5788
Batch 310, Loss: 0.5310
Batch 320, Loss: 0.5506
Batch 330, Loss: 0.6158
Batch 340, Loss: 0.5612
Batch 350, Loss: 0.5951
Batch 360, Loss: 0.5935
Batch 370, Loss: 0.6315
Batch 380, Loss: 0.6140
Batch 390, Loss: 0.6204
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.430011749267578 seconds
Epoch 27 accuracy: 78.27%
Batch 10, Loss: 0.5674
Batch 20, Loss: 0.5796
Batch 30, Loss: 0.6099
Batch 40, Loss: 0.5820
Batch 50, Loss: 0.6084
Batch 60, Loss: 0.6608
Batch 70, Loss: 0.6312
Batch 80, Loss: 0.5737
Batch 90, Loss: 0.5920
Batch 100, Loss: 0.5886
Batch 110, Loss: 0.5848
Batch 120, Loss: 0.5754
Batch 130, Loss: 0.5956
Batch 140, Loss: 0.6093
Batch 150, Loss: 0.6124
Batch 160, Loss: 0.6020
Batch 170, Loss: 0.5512
Batch 180, Loss: 0.5609
Batch 190, Loss: 0.6049
Batch 200, Loss: 0.5985
Batch 210, Loss: 0.6094
Batch 220, Loss: 0.6141
Batch 230, Loss: 0.6068
Batch 240, Loss: 0.6125
Batch 250, Loss: 0.6425
Batch 260, Loss: 0.6118
Batch 270, Loss: 0.5690
Batch 280, Loss: 0.5731
Batch 290, Loss: 0.5989
Batch 300, Loss: 0.6396
Batch 310, Loss: 0.6308
Batch 320, Loss: 0.5843
Batch 330, Loss: 0.5737
Batch 340, Loss: 0.6555
Batch 350, Loss: 0.5968
Batch 360, Loss: 0.6119
Batch 370, Loss: 0.6020
Batch 380, Loss: 0.5882
Batch 390, Loss: 0.6279
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.491832971572876 seconds
Epoch 28 accuracy: 82.9%
Batch 10, Loss: 0.5970
Batch 20, Loss: 0.5944
Batch 30, Loss: 0.6288
Batch 40, Loss: 0.6218
Batch 50, Loss: 0.6082
Batch 60, Loss: 0.6009
Batch 70, Loss: 0.6012
Batch 80, Loss: 0.5839
Batch 90, Loss: 0.5966
Batch 100, Loss: 0.5796
Batch 110, Loss: 0.6245
Batch 120, Loss: 0.5513
Batch 130, Loss: 0.6053
Batch 140, Loss: 0.6149
Batch 150, Loss: 0.6020
Batch 160, Loss: 0.6118
Batch 170, Loss: 0.5499
Batch 180, Loss: 0.5555
Batch 190, Loss: 0.5695
Batch 200, Loss: 0.6296
Batch 210, Loss: 0.6385
Batch 220, Loss: 0.5763
Batch 230, Loss: 0.5848
Batch 240, Loss: 0.5781
Batch 250, Loss: 0.6252
Batch 260, Loss: 0.5981
Batch 270, Loss: 0.6434
Batch 280, Loss: 0.5641
Batch 290, Loss: 0.5515
Batch 300, Loss: 0.5994
Batch 310, Loss: 0.6183
Batch 320, Loss: 0.5961
Batch 330, Loss: 0.5845
Batch 340, Loss: 0.6114
Batch 350, Loss: 0.5877
Batch 360, Loss: 0.5781
Batch 370, Loss: 0.5789
Batch 380, Loss: 0.5582
Batch 390, Loss: 0.5724
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.41347336769104 seconds
Epoch 29 accuracy: 83.08%
Batch 10, Loss: 0.5899
Batch 20, Loss: 0.6299
Batch 30, Loss: 0.5516
Batch 40, Loss: 0.5734
Batch 50, Loss: 0.5877
Batch 60, Loss: 0.5591
Batch 70, Loss: 0.5866
Batch 80, Loss: 0.6165
Batch 90, Loss: 0.6272
Batch 100, Loss: 0.6006
Batch 110, Loss: 0.5899
Batch 120, Loss: 0.5886
Batch 130, Loss: 0.6122
Batch 140, Loss: 0.5759
Batch 150, Loss: 0.6563
Batch 160, Loss: 0.5741
Batch 170, Loss: 0.5721
Batch 180, Loss: 0.5540
Batch 190, Loss: 0.6001
Batch 200, Loss: 0.5897
Batch 210, Loss: 0.5859
Batch 220, Loss: 0.5909
Batch 230, Loss: 0.5997
Batch 240, Loss: 0.5886
Batch 250, Loss: 0.5701
Batch 260, Loss: 0.6242
Batch 270, Loss: 0.5532
Batch 280, Loss: 0.5887
Batch 290, Loss: 0.5629
Batch 300, Loss: 0.5814
Batch 310, Loss: 0.5684
Batch 320, Loss: 0.5756
Batch 330, Loss: 0.5981
Batch 340, Loss: 0.6319
Batch 350, Loss: 0.6073
Batch 360, Loss: 0.6026
Batch 370, Loss: 0.5794
Batch 380, Loss: 0.5660
Batch 390, Loss: 0.6131
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.450473308563232 seconds
Epoch 30 accuracy: 78.81%
Batch 10, Loss: 0.5704
Batch 20, Loss: 0.5879
Batch 30, Loss: 0.5720
Batch 40, Loss: 0.5878
Batch 50, Loss: 0.6062
Batch 60, Loss: 0.5616
Batch 70, Loss: 0.6215
Batch 80, Loss: 0.5543
Batch 90, Loss: 0.5429
Batch 100, Loss: 0.5243
Batch 110, Loss: 0.5601
Batch 120, Loss: 0.5841
Batch 130, Loss: 0.5667
Batch 140, Loss: 0.5815
Batch 150, Loss: 0.5785
Batch 160, Loss: 0.5861
Batch 170, Loss: 0.6139
Batch 180, Loss: 0.5832
Batch 190, Loss: 0.5916
Batch 200, Loss: 0.5596
Batch 210, Loss: 0.5793
Batch 220, Loss: 0.5598
Batch 230, Loss: 0.5929
Batch 240, Loss: 0.5657
Batch 250, Loss: 0.6072
Batch 260, Loss: 0.6139
Batch 270, Loss: 0.5798
Batch 280, Loss: 0.5347
Batch 290, Loss: 0.5779
Batch 300, Loss: 0.5386
Batch 310, Loss: 0.5906
Batch 320, Loss: 0.5618
Batch 330, Loss: 0.6071
Batch 340, Loss: 0.5615
Batch 350, Loss: 0.5869
Batch 360, Loss: 0.6036
Batch 370, Loss: 0.5592
Batch 380, Loss: 0.5672
Batch 390, Loss: 0.5837
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.397913694381714 seconds
Epoch 31 accuracy: 74.99%
Batch 10, Loss: 0.5466
Batch 20, Loss: 0.5685
Batch 30, Loss: 0.5624
Batch 40, Loss: 0.5775
Batch 50, Loss: 0.5797
Batch 60, Loss: 0.5734
Batch 70, Loss: 0.5530
Batch 80, Loss: 0.5910
Batch 90, Loss: 0.5981
Batch 100, Loss: 0.6172
Batch 110, Loss: 0.6057
Batch 120, Loss: 0.6047
Batch 130, Loss: 0.5891
Batch 140, Loss: 0.5891
Batch 150, Loss: 0.6112
Batch 160, Loss: 0.5810
Batch 170, Loss: 0.6027
Batch 180, Loss: 0.5751
Batch 190, Loss: 0.5652
Batch 200, Loss: 0.5537
Batch 210, Loss: 0.5757
Batch 220, Loss: 0.6369
Batch 230, Loss: 0.5821
Batch 240, Loss: 0.5903
Batch 250, Loss: 0.5754
Batch 260, Loss: 0.5849
Batch 270, Loss: 0.5491
Batch 280, Loss: 0.6580
Batch 290, Loss: 0.5875
Batch 300, Loss: 0.6043
Batch 310, Loss: 0.5789
Batch 320, Loss: 0.5940
Batch 330, Loss: 0.5686
Batch 340, Loss: 0.6003
Batch 350, Loss: 0.5982
Batch 360, Loss: 0.5752
Batch 370, Loss: 0.5931
Batch 380, Loss: 0.6496
Batch 390, Loss: 0.5864
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.495171785354614 seconds
Epoch 32 accuracy: 80.39%
Batch 10, Loss: 0.5865
Batch 20, Loss: 0.5971
Batch 30, Loss: 0.5500
Batch 40, Loss: 0.5568
Batch 50, Loss: 0.5837
Batch 60, Loss: 0.5717
Batch 70, Loss: 0.5546
Batch 80, Loss: 0.5828
Batch 90, Loss: 0.5692
Batch 100, Loss: 0.5941
Batch 110, Loss: 0.5665
Batch 120, Loss: 0.5495
Batch 130, Loss: 0.5448
Batch 140, Loss: 0.5537
Batch 150, Loss: 0.6044
Batch 160, Loss: 0.5762
Batch 170, Loss: 0.6262
Batch 180, Loss: 0.5663
Batch 190, Loss: 0.5710
Batch 200, Loss: 0.5368
Batch 210, Loss: 0.5613
Batch 220, Loss: 0.5589
Batch 230, Loss: 0.6055
Batch 240, Loss: 0.6030
Batch 250, Loss: 0.5768
Batch 260, Loss: 0.5400
Batch 270, Loss: 0.5884
Batch 280, Loss: 0.6114
Batch 290, Loss: 0.5748
Batch 300, Loss: 0.5922
Batch 310, Loss: 0.5921
Batch 320, Loss: 0.6124
Batch 330, Loss: 0.5727
Batch 340, Loss: 0.5553
Batch 350, Loss: 0.6141
Batch 360, Loss: 0.5752
Batch 370, Loss: 0.5992
Batch 380, Loss: 0.6328
Batch 390, Loss: 0.5602
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.54345679283142 seconds
Epoch 33 accuracy: 80.87%
Batch 10, Loss: 0.6045
Batch 20, Loss: 0.5908
Batch 30, Loss: 0.5701
Batch 40, Loss: 0.5900
Batch 50, Loss: 0.5871
Batch 60, Loss: 0.5786
Batch 70, Loss: 0.6214
Batch 80, Loss: 0.5477
Batch 90, Loss: 0.5662
Batch 100, Loss: 0.5613
Batch 110, Loss: 0.5512
Batch 120, Loss: 0.5805
Batch 130, Loss: 0.6093
Batch 140, Loss: 0.6141
Batch 150, Loss: 0.5956
Batch 160, Loss: 0.5586
Batch 170, Loss: 0.5001
Batch 180, Loss: 0.5804
Batch 190, Loss: 0.5717
Batch 200, Loss: 0.5924
Batch 210, Loss: 0.5702
Batch 220, Loss: 0.5595
Batch 230, Loss: 0.5737
Batch 240, Loss: 0.6300
Batch 250, Loss: 0.5901
Batch 260, Loss: 0.5698
Batch 270, Loss: 0.6037
Batch 280, Loss: 0.5959
Batch 290, Loss: 0.5625
Batch 300, Loss: 0.5550
Batch 310, Loss: 0.5679
Batch 320, Loss: 0.5515
Batch 330, Loss: 0.5844
Batch 340, Loss: 0.6273
Batch 350, Loss: 0.5988
Batch 360, Loss: 0.5990
Batch 370, Loss: 0.5699
Batch 380, Loss: 0.5857
Batch 390, Loss: 0.5779
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.390557289123535 seconds
Epoch 34 accuracy: 82.98%
Batch 10, Loss: 0.5929
Batch 20, Loss: 0.5507
Batch 30, Loss: 0.5752
Batch 40, Loss: 0.5926
Batch 50, Loss: 0.5741
Batch 60, Loss: 0.5579
Batch 70, Loss: 0.6217
Batch 80, Loss: 0.6401
Batch 90, Loss: 0.5756
Batch 100, Loss: 0.6043
Batch 110, Loss: 0.6161
Batch 120, Loss: 0.5962
Batch 130, Loss: 0.5985
Batch 140, Loss: 0.5995
Batch 150, Loss: 0.5247
Batch 160, Loss: 0.5538
Batch 170, Loss: 0.5993
Batch 180, Loss: 0.5734
Batch 190, Loss: 0.5694
Batch 200, Loss: 0.5538
Batch 210, Loss: 0.5581
Batch 220, Loss: 0.5430
Batch 230, Loss: 0.5530
Batch 240, Loss: 0.5776
Batch 250, Loss: 0.6243
Batch 260, Loss: 0.6052
Batch 270, Loss: 0.5788
Batch 280, Loss: 0.5690
Batch 290, Loss: 0.5912
Batch 300, Loss: 0.5532
Batch 310, Loss: 0.5595
Batch 320, Loss: 0.6116
Batch 330, Loss: 0.5906
Batch 340, Loss: 0.6101
Batch 350, Loss: 0.5940
Batch 360, Loss: 0.5887
Batch 370, Loss: 0.5528
Batch 380, Loss: 0.5570
Batch 390, Loss: 0.5517
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.36987566947937 seconds
Epoch 35 accuracy: 84.26%
Batch 10, Loss: 0.5708
Batch 20, Loss: 0.5646
Batch 30, Loss: 0.5423
Batch 40, Loss: 0.5712
Batch 50, Loss: 0.5700
Batch 60, Loss: 0.5860
Batch 70, Loss: 0.5713
Batch 80, Loss: 0.5813
Batch 90, Loss: 0.5986
Batch 100, Loss: 0.5714
Batch 110, Loss: 0.5194
Batch 120, Loss: 0.6066
Batch 130, Loss: 0.6133
Batch 140, Loss: 0.5847
Batch 150, Loss: 0.5407
Batch 160, Loss: 0.5755
Batch 170, Loss: 0.5399
Batch 180, Loss: 0.5706
Batch 190, Loss: 0.5752
Batch 200, Loss: 0.5805
Batch 210, Loss: 0.5574
Batch 220, Loss: 0.5369
Batch 230, Loss: 0.6180
Batch 240, Loss: 0.5917
Batch 250, Loss: 0.5894
Batch 260, Loss: 0.5678
Batch 270, Loss: 0.5566
Batch 280, Loss: 0.5544
Batch 290, Loss: 0.5702
Batch 300, Loss: 0.5955
Batch 310, Loss: 0.5598
Batch 320, Loss: 0.5139
Batch 330, Loss: 0.5554
Batch 340, Loss: 0.5713
Batch 350, Loss: 0.5649
Batch 360, Loss: 0.5865
Batch 370, Loss: 0.5778
Batch 380, Loss: 0.5767
Batch 390, Loss: 0.5419
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.50175666809082 seconds
Epoch 36 accuracy: 82.6%
Batch 10, Loss: 0.5832
Batch 20, Loss: 0.5550
Batch 30, Loss: 0.5858
Batch 40, Loss: 0.5704
Batch 50, Loss: 0.5443
Batch 60, Loss: 0.5841
Batch 70, Loss: 0.5417
Batch 80, Loss: 0.5549
Batch 90, Loss: 0.5395
Batch 100, Loss: 0.5373
Batch 110, Loss: 0.5261
Batch 120, Loss: 0.5440
Batch 130, Loss: 0.5576
Batch 140, Loss: 0.5746
Batch 150, Loss: 0.5781
Batch 160, Loss: 0.5434
Batch 170, Loss: 0.5467
Batch 180, Loss: 0.5445
Batch 190, Loss: 0.5857
Batch 200, Loss: 0.5782
Batch 210, Loss: 0.5585
Batch 220, Loss: 0.5674
Batch 230, Loss: 0.5622
Batch 240, Loss: 0.5784
Batch 250, Loss: 0.5733
Batch 260, Loss: 0.5839
Batch 270, Loss: 0.5866
Batch 280, Loss: 0.5569
Batch 290, Loss: 0.6036
Batch 300, Loss: 0.5700
Batch 310, Loss: 0.5672
Batch 320, Loss: 0.5847
Batch 330, Loss: 0.5919
Batch 340, Loss: 0.6112
Batch 350, Loss: 0.5874
Batch 360, Loss: 0.5410
Batch 370, Loss: 0.5773
Batch 380, Loss: 0.5671
Batch 390, Loss: 0.5816
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.53240203857422 seconds
Epoch 37 accuracy: 79.19%
Batch 10, Loss: 0.5594
Batch 20, Loss: 0.5413
Batch 30, Loss: 0.5475
Batch 40, Loss: 0.5581
Batch 50, Loss: 0.5481
Batch 60, Loss: 0.5408
Batch 70, Loss: 0.5541
Batch 80, Loss: 0.5285
Batch 90, Loss: 0.5771
Batch 100, Loss: 0.5988
Batch 110, Loss: 0.5928
Batch 120, Loss: 0.5698
Batch 130, Loss: 0.5787
Batch 140, Loss: 0.6050
Batch 150, Loss: 0.5600
Batch 160, Loss: 0.5788
Batch 170, Loss: 0.5498
Batch 180, Loss: 0.5583
Batch 190, Loss: 0.5556
Batch 200, Loss: 0.5570
Batch 210, Loss: 0.5984
Batch 220, Loss: 0.5509
Batch 230, Loss: 0.5773
Batch 240, Loss: 0.5201
Batch 250, Loss: 0.5425
Batch 260, Loss: 0.5839
Batch 270, Loss: 0.5820
Batch 280, Loss: 0.5815
Batch 290, Loss: 0.5860
Batch 300, Loss: 0.5981
Batch 310, Loss: 0.5891
Batch 320, Loss: 0.5796
Batch 330, Loss: 0.5857
Batch 340, Loss: 0.5813
Batch 350, Loss: 0.5645
Batch 360, Loss: 0.5747
Batch 370, Loss: 0.5571
Batch 380, Loss: 0.5985
Batch 390, Loss: 0.5710
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.443532943725586 seconds
Epoch 38 accuracy: 83.06%
Batch 10, Loss: 0.6032
Batch 20, Loss: 0.5639
Batch 30, Loss: 0.5655
Batch 40, Loss: 0.5330
Batch 50, Loss: 0.5845
Batch 60, Loss: 0.5722
Batch 70, Loss: 0.5889
Batch 80, Loss: 0.5407
Batch 90, Loss: 0.5961
Batch 100, Loss: 0.5993
Batch 110, Loss: 0.5315
Batch 120, Loss: 0.5896
Batch 130, Loss: 0.6214
Batch 140, Loss: 0.5660
Batch 150, Loss: 0.5431
Batch 160, Loss: 0.5498
Batch 170, Loss: 0.5760
Batch 180, Loss: 0.5375
Batch 190, Loss: 0.5650
Batch 200, Loss: 0.6151
Batch 210, Loss: 0.5663
Batch 220, Loss: 0.5757
Batch 230, Loss: 0.5354
Batch 240, Loss: 0.5650
Batch 250, Loss: 0.5954
Batch 260, Loss: 0.6121
Batch 270, Loss: 0.5990
Batch 280, Loss: 0.5445
Batch 290, Loss: 0.6012
Batch 300, Loss: 0.5658
Batch 310, Loss: 0.5467
Batch 320, Loss: 0.5611
Batch 330, Loss: 0.5705
Batch 340, Loss: 0.6210
Batch 350, Loss: 0.5715
Batch 360, Loss: 0.5707
Batch 370, Loss: 0.5771
Batch 380, Loss: 0.5805
Batch 390, Loss: 0.5879
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.481972217559814 seconds
Epoch 39 accuracy: 81.31%
Batch 10, Loss: 0.5543
Batch 20, Loss: 0.5849
Batch 30, Loss: 0.5512
Batch 40, Loss: 0.5464
Batch 50, Loss: 0.5461
Batch 60, Loss: 0.5609
Batch 70, Loss: 0.5541
Batch 80, Loss: 0.5715
Batch 90, Loss: 0.5354
Batch 100, Loss: 0.5797
Batch 110, Loss: 0.5535
Batch 120, Loss: 0.5511
Batch 130, Loss: 0.6059
Batch 140, Loss: 0.5643
Batch 150, Loss: 0.5804
Batch 160, Loss: 0.6036
Batch 170, Loss: 0.5377
Batch 180, Loss: 0.5568
Batch 190, Loss: 0.5372
Batch 200, Loss: 0.5740
Batch 210, Loss: 0.5560
Batch 220, Loss: 0.5579
Batch 230, Loss: 0.5497
Batch 240, Loss: 0.5963
Batch 250, Loss: 0.5648
Batch 260, Loss: 0.5703
Batch 270, Loss: 0.5321
Batch 280, Loss: 0.5481
Batch 290, Loss: 0.5724
Batch 300, Loss: 0.5557
Batch 310, Loss: 0.5138
Batch 320, Loss: 0.5395
Batch 330, Loss: 0.5024
Batch 340, Loss: 0.5796
Batch 350, Loss: 0.5326
Batch 360, Loss: 0.5800
Batch 370, Loss: 0.5724
Batch 380, Loss: 0.5715
Batch 390, Loss: 0.5662
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.43677043914795 seconds
Epoch 40 accuracy: 82.04%
Batch 10, Loss: 0.5799
Batch 20, Loss: 0.5847
Batch 30, Loss: 0.5817
Batch 40, Loss: 0.5640
Batch 50, Loss: 0.5744
Batch 60, Loss: 0.5294
Batch 70, Loss: 0.5461
Batch 80, Loss: 0.5561
Batch 90, Loss: 0.5508
Batch 100, Loss: 0.5433
Batch 110, Loss: 0.5453
Batch 120, Loss: 0.5747
Batch 130, Loss: 0.5462
Batch 140, Loss: 0.5599
Batch 150, Loss: 0.5659
Batch 160, Loss: 0.5515
Batch 170, Loss: 0.5648
Batch 180, Loss: 0.5935
Batch 190, Loss: 0.5786
Batch 200, Loss: 0.5546
Batch 210, Loss: 0.5553
Batch 220, Loss: 0.5742
Batch 230, Loss: 0.5830
Batch 240, Loss: 0.5623
Batch 250, Loss: 0.5884
Batch 260, Loss: 0.5820
Batch 270, Loss: 0.5489
Batch 280, Loss: 0.5745
Batch 290, Loss: 0.6028
Batch 300, Loss: 0.5611
Batch 310, Loss: 0.5435
Batch 320, Loss: 0.5796
Batch 330, Loss: 0.5676
Batch 340, Loss: 0.5957
Batch 350, Loss: 0.5596
Batch 360, Loss: 0.5528
Batch 370, Loss: 0.5465
Batch 380, Loss: 0.5649
Batch 390, Loss: 0.5571
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.401196718215942 seconds
Epoch 41 accuracy: 83.65%
Batch 10, Loss: 0.5422
Batch 20, Loss: 0.5540
Batch 30, Loss: 0.5783
Batch 40, Loss: 0.5489
Batch 50, Loss: 0.5582
Batch 60, Loss: 0.5751
Batch 70, Loss: 0.5701
Batch 80, Loss: 0.5680
Batch 90, Loss: 0.5502
Batch 100, Loss: 0.5410
Batch 110, Loss: 0.5388
Batch 120, Loss: 0.6091
Batch 130, Loss: 0.5368
Batch 140, Loss: 0.5741
Batch 150, Loss: 0.5475
Batch 160, Loss: 0.6221
Batch 170, Loss: 0.5671
Batch 180, Loss: 0.6024
Batch 190, Loss: 0.5720
Batch 200, Loss: 0.5372
Batch 210, Loss: 0.5697
Batch 220, Loss: 0.5266
Batch 230, Loss: 0.5899
Batch 240, Loss: 0.5267
Batch 250, Loss: 0.5510
Batch 260, Loss: 0.5523
Batch 270, Loss: 0.5284
Batch 280, Loss: 0.5469
Batch 290, Loss: 0.5749
Batch 300, Loss: 0.5573
Batch 310, Loss: 0.6136
Batch 320, Loss: 0.5770
Batch 330, Loss: 0.6091
Batch 340, Loss: 0.5680
Batch 350, Loss: 0.5840
Batch 360, Loss: 0.5846
Batch 370, Loss: 0.5958
Batch 380, Loss: 0.5426
Batch 390, Loss: 0.5559
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.452325582504272 seconds
Epoch 42 accuracy: 82.76%
Batch 10, Loss: 0.5325
Batch 20, Loss: 0.5224
Batch 30, Loss: 0.5645
Batch 40, Loss: 0.5223
Batch 50, Loss: 0.5529
Batch 60, Loss: 0.5541
Batch 70, Loss: 0.5360
Batch 80, Loss: 0.6005
Batch 90, Loss: 0.5004
Batch 100, Loss: 0.5908
Batch 110, Loss: 0.5548
Batch 120, Loss: 0.5581
Batch 130, Loss: 0.5717
Batch 140, Loss: 0.5669
Batch 150, Loss: 0.5745
Batch 160, Loss: 0.5419
Batch 170, Loss: 0.5134
Batch 180, Loss: 0.5483
Batch 190, Loss: 0.5807
Batch 200, Loss: 0.5709
Batch 210, Loss: 0.5541
Batch 220, Loss: 0.5490
Batch 230, Loss: 0.5249
Batch 240, Loss: 0.5362
Batch 250, Loss: 0.5126
Batch 260, Loss: 0.5623
Batch 270, Loss: 0.5514
Batch 280, Loss: 0.5507
Batch 290, Loss: 0.5674
Batch 300, Loss: 0.5981
Batch 310, Loss: 0.5563
Batch 320, Loss: 0.5294
Batch 330, Loss: 0.5710
Batch 340, Loss: 0.5674
Batch 350, Loss: 0.5977
Batch 360, Loss: 0.5615
Batch 370, Loss: 0.5675
Batch 380, Loss: 0.5573
Batch 390, Loss: 0.5648
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.393860816955566 seconds
Epoch 43 accuracy: 82.63%
Batch 10, Loss: 0.5982
Batch 20, Loss: 0.5700
Batch 30, Loss: 0.5125
Batch 40, Loss: 0.5157
Batch 50, Loss: 0.5327
Batch 60, Loss: 0.5411
Batch 70, Loss: 0.5367
Batch 80, Loss: 0.5765
Batch 90, Loss: 0.6047
Batch 100, Loss: 0.5674
Batch 110, Loss: 0.5631
Batch 120, Loss: 0.5597
Batch 130, Loss: 0.5624
Batch 140, Loss: 0.5548
Batch 150, Loss: 0.5730
Batch 160, Loss: 0.5595
Batch 170, Loss: 0.5783
Batch 180, Loss: 0.5410
Batch 190, Loss: 0.5551
Batch 200, Loss: 0.5555
Batch 210, Loss: 0.5691
Batch 220, Loss: 0.5674
Batch 230, Loss: 0.5680
Batch 240, Loss: 0.5800
Batch 250, Loss: 0.5190
Batch 260, Loss: 0.5901
Batch 270, Loss: 0.5317
Batch 280, Loss: 0.5414
Batch 290, Loss: 0.5219
Batch 300, Loss: 0.5551
Batch 310, Loss: 0.5723
Batch 320, Loss: 0.5899
Batch 330, Loss: 0.5396
Batch 340, Loss: 0.5143
Batch 350, Loss: 0.5561
Batch 360, Loss: 0.5233
Batch 370, Loss: 0.5603
Batch 380, Loss: 0.5933
Batch 390, Loss: 0.5752
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.52134132385254 seconds
Epoch 44 accuracy: 80.5%
Batch 10, Loss: 0.5493
Batch 20, Loss: 0.5285
Batch 30, Loss: 0.5495
Batch 40, Loss: 0.5444
Batch 50, Loss: 0.5225
Batch 60, Loss: 0.4732
Batch 70, Loss: 0.5659
Batch 80, Loss: 0.5559
Batch 90, Loss: 0.5588
Batch 100, Loss: 0.5635
Batch 110, Loss: 0.5770
Batch 120, Loss: 0.5452
Batch 130, Loss: 0.5420
Batch 140, Loss: 0.5670
Batch 150, Loss: 0.5439
Batch 160, Loss: 0.5290
Batch 170, Loss: 0.5193
Batch 180, Loss: 0.5306
Batch 190, Loss: 0.5347
Batch 200, Loss: 0.5739
Batch 210, Loss: 0.5624
Batch 220, Loss: 0.5627
Batch 230, Loss: 0.5461
Batch 240, Loss: 0.5090
Batch 250, Loss: 0.5677
Batch 260, Loss: 0.5407
Batch 270, Loss: 0.5439
Batch 280, Loss: 0.5506
Batch 290, Loss: 0.5359
Batch 300, Loss: 0.5701
Batch 310, Loss: 0.5740
Batch 320, Loss: 0.5495
Batch 330, Loss: 0.5603
Batch 340, Loss: 0.5463
Batch 350, Loss: 0.5738
Batch 360, Loss: 0.5633
Batch 370, Loss: 0.5365
Batch 380, Loss: 0.5778
Batch 390, Loss: 0.5802
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.586121559143066 seconds
Epoch 45 accuracy: 82.63%
Batch 10, Loss: 0.5776
Batch 20, Loss: 0.5553
Batch 30, Loss: 0.5817
Batch 40, Loss: 0.5904
Batch 50, Loss: 0.5197
Batch 60, Loss: 0.5442
Batch 70, Loss: 0.5396
Batch 80, Loss: 0.5210
Batch 90, Loss: 0.5474
Batch 100, Loss: 0.5393
Batch 110, Loss: 0.5058
Batch 120, Loss: 0.5739
Batch 130, Loss: 0.5273
Batch 140, Loss: 0.5249
Batch 150, Loss: 0.5269
Batch 160, Loss: 0.5226
Batch 170, Loss: 0.5345
Batch 180, Loss: 0.5721
Batch 190, Loss: 0.5193
Batch 200, Loss: 0.5565
Batch 210, Loss: 0.5853
Batch 220, Loss: 0.5575
Batch 230, Loss: 0.5473
Batch 240, Loss: 0.5814
Batch 250, Loss: 0.5429
Batch 260, Loss: 0.5523
Batch 270, Loss: 0.5683
Batch 280, Loss: 0.5412
Batch 290, Loss: 0.5480
Batch 300, Loss: 0.5241
Batch 310, Loss: 0.5455
Batch 320, Loss: 0.5582
Batch 330, Loss: 0.5671
Batch 340, Loss: 0.5184
Batch 350, Loss: 0.5596
Batch 360, Loss: 0.5562
Batch 370, Loss: 0.5801
Batch 380, Loss: 0.5931
Batch 390, Loss: 0.5591
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.429381132125854 seconds
Epoch 46 accuracy: 83.35%
Batch 10, Loss: 0.5627
Batch 20, Loss: 0.5689
Batch 30, Loss: 0.5871
Batch 40, Loss: 0.5863
Batch 50, Loss: 0.5412
Batch 60, Loss: 0.5398
Batch 70, Loss: 0.5255
Batch 80, Loss: 0.5713
Batch 90, Loss: 0.5104
Batch 100, Loss: 0.5458
Batch 110, Loss: 0.5736
Batch 120, Loss: 0.5615
Batch 130, Loss: 0.5421
Batch 140, Loss: 0.5287
Batch 150, Loss: 0.5775
Batch 160, Loss: 0.5507
Batch 170, Loss: 0.5569
Batch 180, Loss: 0.5494
Batch 190, Loss: 0.5934
Batch 200, Loss: 0.5521
Batch 210, Loss: 0.5670
Batch 220, Loss: 0.5375
Batch 230, Loss: 0.5347
Batch 240, Loss: 0.5442
Batch 250, Loss: 0.5803
Batch 260, Loss: 0.5369
Batch 270, Loss: 0.5089
Batch 280, Loss: 0.5386
Batch 290, Loss: 0.5349
Batch 300, Loss: 0.5491
Batch 310, Loss: 0.4830
Batch 320, Loss: 0.5393
Batch 330, Loss: 0.5618
Batch 340, Loss: 0.5108
Batch 350, Loss: 0.5517
Batch 360, Loss: 0.5309
Batch 370, Loss: 0.5606
Batch 380, Loss: 0.6103
Batch 390, Loss: 0.5615
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.542901515960693 seconds
Epoch 47 accuracy: 83.36%
Batch 10, Loss: 0.5297
Batch 20, Loss: 0.5437
Batch 30, Loss: 0.5476
Batch 40, Loss: 0.5273
Batch 50, Loss: 0.5149
Batch 60, Loss: 0.5453
Batch 70, Loss: 0.5314
Batch 80, Loss: 0.5407
Batch 90, Loss: 0.5517
Batch 100, Loss: 0.5482
Batch 110, Loss: 0.5616
Batch 120, Loss: 0.5948
Batch 130, Loss: 0.5677
Batch 140, Loss: 0.5739
Batch 150, Loss: 0.5502
Batch 160, Loss: 0.5620
Batch 170, Loss: 0.5281
Batch 180, Loss: 0.5303
Batch 190, Loss: 0.5184
Batch 200, Loss: 0.5453
Batch 210, Loss: 0.5285
Batch 220, Loss: 0.5616
Batch 230, Loss: 0.5388
Batch 240, Loss: 0.4889
Batch 250, Loss: 0.5707
Batch 260, Loss: 0.5653
Batch 270, Loss: 0.5339
Batch 280, Loss: 0.5587
Batch 290, Loss: 0.5821
Batch 300, Loss: 0.5359
Batch 310, Loss: 0.5441
Batch 320, Loss: 0.5079
Batch 330, Loss: 0.5931
Batch 340, Loss: 0.5718
Batch 350, Loss: 0.5677
Batch 360, Loss: 0.5680
Batch 370, Loss: 0.5410
Batch 380, Loss: 0.5344
Batch 390, Loss: 0.5375
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.481638431549072 seconds
Epoch 48 accuracy: 75.46%
Batch 10, Loss: 0.5293
Batch 20, Loss: 0.5370
Batch 30, Loss: 0.5423
Batch 40, Loss: 0.5368
Batch 50, Loss: 0.4918
Batch 60, Loss: 0.5584
Batch 70, Loss: 0.5887
Batch 80, Loss: 0.5264
Batch 90, Loss: 0.4982
Batch 100, Loss: 0.5184
Batch 110, Loss: 0.5334
Batch 120, Loss: 0.5633
Batch 130, Loss: 0.5251
Batch 140, Loss: 0.5452
Batch 150, Loss: 0.5388
Batch 160, Loss: 0.5374
Batch 170, Loss: 0.5210
Batch 180, Loss: 0.5863
Batch 190, Loss: 0.5644
Batch 200, Loss: 0.6199
Batch 210, Loss: 0.5995
Batch 220, Loss: 0.5809
Batch 230, Loss: 0.5516
Batch 240, Loss: 0.5368
Batch 250, Loss: 0.5674
Batch 260, Loss: 0.5569
Batch 270, Loss: 0.5065
Batch 280, Loss: 0.5448
Batch 290, Loss: 0.4964
Batch 300, Loss: 0.5772
Batch 310, Loss: 0.5893
Batch 320, Loss: 0.5508
Batch 330, Loss: 0.5516
Batch 340, Loss: 0.5050
Batch 350, Loss: 0.5228
Batch 360, Loss: 0.5189
Batch 370, Loss: 0.5596
Batch 380, Loss: 0.5886
Batch 390, Loss: 0.5427
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.55157780647278 seconds
Epoch 49 accuracy: 84.7%
Batch 10, Loss: 0.5178
Batch 20, Loss: 0.5523
Batch 30, Loss: 0.5654
Batch 40, Loss: 0.5032
Batch 50, Loss: 0.5979
Batch 60, Loss: 0.5456
Batch 70, Loss: 0.5113
Batch 80, Loss: 0.5332
Batch 90, Loss: 0.5085
Batch 100, Loss: 0.6254
Batch 110, Loss: 0.5633
Batch 120, Loss: 0.5216
Batch 130, Loss: 0.5447
Batch 140, Loss: 0.5348
Batch 150, Loss: 0.5681
Batch 160, Loss: 0.5353
Batch 170, Loss: 0.5248
Batch 180, Loss: 0.5389
Batch 190, Loss: 0.5383
Batch 200, Loss: 0.5702
Batch 210, Loss: 0.5341
Batch 220, Loss: 0.5252
Batch 230, Loss: 0.5259
Batch 240, Loss: 0.5305
Batch 250, Loss: 0.5594
Batch 260, Loss: 0.5266
Batch 270, Loss: 0.5727
Batch 280, Loss: 0.5490
Batch 290, Loss: 0.5506
Batch 300, Loss: 0.5273
Batch 310, Loss: 0.5211
Batch 320, Loss: 0.5745
Batch 330, Loss: 0.5571
Batch 340, Loss: 0.5524
Batch 350, Loss: 0.5697
Batch 360, Loss: 0.5249
Batch 370, Loss: 0.5260
Batch 380, Loss: 0.5508
Batch 390, Loss: 0.5437
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.511877298355103 seconds
Epoch 50 accuracy: 83.69%
Batch 10, Loss: 0.5359
Batch 20, Loss: 0.5731
Batch 30, Loss: 0.5579
Batch 40, Loss: 0.5757
Batch 50, Loss: 0.4951
Batch 60, Loss: 0.5377
Batch 70, Loss: 0.5369
Batch 80, Loss: 0.5109
Batch 90, Loss: 0.5464
Batch 100, Loss: 0.5460
Batch 110, Loss: 0.5378
Batch 120, Loss: 0.5515
Batch 130, Loss: 0.5609
Batch 140, Loss: 0.5740
Batch 150, Loss: 0.5511
Batch 160, Loss: 0.5227
Batch 170, Loss: 0.5083
Batch 180, Loss: 0.5516
Batch 190, Loss: 0.5376
Batch 200, Loss: 0.5870
Batch 210, Loss: 0.5354
Batch 220, Loss: 0.5725
Batch 230, Loss: 0.5415
Batch 240, Loss: 0.5224
Batch 250, Loss: 0.5226
Batch 260, Loss: 0.5679
Batch 270, Loss: 0.5893
Batch 280, Loss: 0.5349
Batch 290, Loss: 0.5168
Batch 300, Loss: 0.5157
Batch 310, Loss: 0.4951
Batch 320, Loss: 0.5162
Batch 330, Loss: 0.5565
Batch 340, Loss: 0.5729
Batch 350, Loss: 0.5301
Batch 360, Loss: 0.5266
Batch 370, Loss: 0.5235
Batch 380, Loss: 0.5812
Batch 390, Loss: 0.5870
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.48724365234375 seconds
Epoch 51 accuracy: 81.89%
Batch 10, Loss: 0.5236
Batch 20, Loss: 0.5433
Batch 30, Loss: 0.5678
Batch 40, Loss: 0.5391
Batch 50, Loss: 0.5567
Batch 60, Loss: 0.5375
Batch 70, Loss: 0.5195
Batch 80, Loss: 0.5307
Batch 90, Loss: 0.5576
Batch 100, Loss: 0.5602
Batch 110, Loss: 0.5404
Batch 120, Loss: 0.5593
Batch 130, Loss: 0.5206
Batch 140, Loss: 0.5194
Batch 150, Loss: 0.5793
Batch 160, Loss: 0.5327
Batch 170, Loss: 0.5582
Batch 180, Loss: 0.5430
Batch 190, Loss: 0.5256
Batch 200, Loss: 0.5430
Batch 210, Loss: 0.5101
Batch 220, Loss: 0.5288
Batch 230, Loss: 0.5088
Batch 240, Loss: 0.5505
Batch 250, Loss: 0.5538
Batch 260, Loss: 0.5386
Batch 270, Loss: 0.4970
Batch 280, Loss: 0.5393
Batch 290, Loss: 0.5409
Batch 300, Loss: 0.5567
Batch 310, Loss: 0.5369
Batch 320, Loss: 0.5663
Batch 330, Loss: 0.5436
Batch 340, Loss: 0.5189
Batch 350, Loss: 0.5572
Batch 360, Loss: 0.5284
Batch 370, Loss: 0.5503
Batch 380, Loss: 0.5277
Batch 390, Loss: 0.5165
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.500633001327515 seconds
Epoch 52 accuracy: 85.23%
Batch 10, Loss: 0.5380
Batch 20, Loss: 0.5488
Batch 30, Loss: 0.5117
Batch 40, Loss: 0.5095
Batch 50, Loss: 0.5307
Batch 60, Loss: 0.5329
Batch 70, Loss: 0.5334
Batch 80, Loss: 0.5940
Batch 90, Loss: 0.5433
Batch 100, Loss: 0.5174
Batch 110, Loss: 0.5234
Batch 120, Loss: 0.5189
Batch 130, Loss: 0.5658
Batch 140, Loss: 0.5539
Batch 150, Loss: 0.5509
Batch 160, Loss: 0.5539
Batch 170, Loss: 0.5365
Batch 180, Loss: 0.5234
Batch 190, Loss: 0.5087
Batch 200, Loss: 0.5497
Batch 210, Loss: 0.5457
Batch 220, Loss: 0.5635
Batch 230, Loss: 0.5642
Batch 240, Loss: 0.5455
Batch 250, Loss: 0.5449
Batch 260, Loss: 0.5212
Batch 270, Loss: 0.5177
Batch 280, Loss: 0.5397
Batch 290, Loss: 0.5674
Batch 300, Loss: 0.5069
Batch 310, Loss: 0.5244
Batch 320, Loss: 0.5163
Batch 330, Loss: 0.5611
Batch 340, Loss: 0.5836
Batch 350, Loss: 0.6022
Batch 360, Loss: 0.5425
Batch 370, Loss: 0.5558
Batch 380, Loss: 0.5307
Batch 390, Loss: 0.5314
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.522226810455322 seconds
Epoch 53 accuracy: 85.45%
Batch 10, Loss: 0.5258
Batch 20, Loss: 0.5129
Batch 30, Loss: 0.5558
Batch 40, Loss: 0.5131
Batch 50, Loss: 0.5054
Batch 60, Loss: 0.5529
Batch 70, Loss: 0.5496
Batch 80, Loss: 0.5028
Batch 90, Loss: 0.5135
Batch 100, Loss: 0.5183
Batch 110, Loss: 0.5516
Batch 120, Loss: 0.5471
Batch 130, Loss: 0.4994
Batch 140, Loss: 0.4993
Batch 150, Loss: 0.5382
Batch 160, Loss: 0.4971
Batch 170, Loss: 0.5283
Batch 180, Loss: 0.5747
Batch 190, Loss: 0.5600
Batch 200, Loss: 0.5421
Batch 210, Loss: 0.5069
Batch 220, Loss: 0.4977
Batch 230, Loss: 0.4869
Batch 240, Loss: 0.5650
Batch 250, Loss: 0.5320
Batch 260, Loss: 0.5680
Batch 270, Loss: 0.5410
Batch 280, Loss: 0.4872
Batch 290, Loss: 0.5334
Batch 300, Loss: 0.5356
Batch 310, Loss: 0.5513
Batch 320, Loss: 0.4985
Batch 330, Loss: 0.5444
Batch 340, Loss: 0.5118
Batch 350, Loss: 0.5489
Batch 360, Loss: 0.5749
Batch 370, Loss: 0.5627
Batch 380, Loss: 0.5286
Batch 390, Loss: 0.5245
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.50397300720215 seconds
Epoch 54 accuracy: 86.62%
Batch 10, Loss: 0.4990
Batch 20, Loss: 0.5207
Batch 30, Loss: 0.4942
Batch 40, Loss: 0.5188
Batch 50, Loss: 0.5126
Batch 60, Loss: 0.4933
Batch 70, Loss: 0.5119
Batch 80, Loss: 0.5289
Batch 90, Loss: 0.5083
Batch 100, Loss: 0.5228
Batch 110, Loss: 0.4821
Batch 120, Loss: 0.5247
Batch 130, Loss: 0.5169
Batch 140, Loss: 0.5322
Batch 150, Loss: 0.5520
Batch 160, Loss: 0.5298
Batch 170, Loss: 0.5389
Batch 180, Loss: 0.4928
Batch 190, Loss: 0.5291
Batch 200, Loss: 0.5536
Batch 210, Loss: 0.5511
Batch 220, Loss: 0.5759
Batch 230, Loss: 0.5221
Batch 240, Loss: 0.5364
Batch 250, Loss: 0.5779
Batch 260, Loss: 0.5171
Batch 270, Loss: 0.5219
Batch 280, Loss: 0.5419
Batch 290, Loss: 0.5130
Batch 300, Loss: 0.5499
Batch 310, Loss: 0.5643
Batch 320, Loss: 0.5051
Batch 330, Loss: 0.5378
Batch 340, Loss: 0.5791
Batch 350, Loss: 0.5013
Batch 360, Loss: 0.5313
Batch 370, Loss: 0.5489
Batch 380, Loss: 0.5477
Batch 390, Loss: 0.5329
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.46220827102661 seconds
Epoch 55 accuracy: 76.97%
Batch 10, Loss: 0.5696
Batch 20, Loss: 0.5215
Batch 30, Loss: 0.5434
Batch 40, Loss: 0.5778
Batch 50, Loss: 0.5417
Batch 60, Loss: 0.5072
Batch 70, Loss: 0.5143
Batch 80, Loss: 0.5243
Batch 90, Loss: 0.5092
Batch 100, Loss: 0.5354
Batch 110, Loss: 0.5263
Batch 120, Loss: 0.5309
Batch 130, Loss: 0.5328
Batch 140, Loss: 0.5655
Batch 150, Loss: 0.4921
Batch 160, Loss: 0.5314
Batch 170, Loss: 0.5590
Batch 180, Loss: 0.5537
Batch 190, Loss: 0.5079
Batch 200, Loss: 0.5038
Batch 210, Loss: 0.5369
Batch 220, Loss: 0.5250
Batch 230, Loss: 0.5327
Batch 240, Loss: 0.5322
Batch 250, Loss: 0.5202
Batch 260, Loss: 0.5173
Batch 270, Loss: 0.5095
Batch 280, Loss: 0.5319
Batch 290, Loss: 0.5420
Batch 300, Loss: 0.5031
Batch 310, Loss: 0.5665
Batch 320, Loss: 0.5492
Batch 330, Loss: 0.5277
Batch 340, Loss: 0.5246
Batch 350, Loss: 0.5024
Batch 360, Loss: 0.5554
Batch 370, Loss: 0.5372
Batch 380, Loss: 0.5515
Batch 390, Loss: 0.5255
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.47109317779541 seconds
Epoch 56 accuracy: 84.89%
Batch 10, Loss: 0.5032
Batch 20, Loss: 0.4740
Batch 30, Loss: 0.5542
Batch 40, Loss: 0.5360
Batch 50, Loss: 0.5331
Batch 60, Loss: 0.5072
Batch 70, Loss: 0.5110
Batch 80, Loss: 0.5371
Batch 90, Loss: 0.5191
Batch 100, Loss: 0.5137
Batch 110, Loss: 0.5181
Batch 120, Loss: 0.5092
Batch 130, Loss: 0.5157
Batch 140, Loss: 0.5168
Batch 150, Loss: 0.5327
Batch 160, Loss: 0.5052
Batch 170, Loss: 0.4989
Batch 180, Loss: 0.5255
Batch 190, Loss: 0.5846
Batch 200, Loss: 0.5516
Batch 210, Loss: 0.5237
Batch 220, Loss: 0.5700
Batch 230, Loss: 0.5414
Batch 240, Loss: 0.5200
Batch 250, Loss: 0.5106
Batch 260, Loss: 0.4941
Batch 270, Loss: 0.5491
Batch 280, Loss: 0.5456
Batch 290, Loss: 0.5598
Batch 300, Loss: 0.5174
Batch 310, Loss: 0.5287
Batch 320, Loss: 0.5415
Batch 330, Loss: 0.5383
Batch 340, Loss: 0.5051
Batch 350, Loss: 0.5353
Batch 360, Loss: 0.5461
Batch 370, Loss: 0.4932
Batch 380, Loss: 0.5080
Batch 390, Loss: 0.5490
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.370584964752197 seconds
Epoch 57 accuracy: 84.11%
Batch 10, Loss: 0.5214
Batch 20, Loss: 0.5287
Batch 30, Loss: 0.5408
Batch 40, Loss: 0.5470
Batch 50, Loss: 0.5151
Batch 60, Loss: 0.5010
Batch 70, Loss: 0.5189
Batch 80, Loss: 0.5104
Batch 90, Loss: 0.5252
Batch 100, Loss: 0.5233
Batch 110, Loss: 0.5199
Batch 120, Loss: 0.5300
Batch 130, Loss: 0.4845
Batch 140, Loss: 0.5393
Batch 150, Loss: 0.5744
Batch 160, Loss: 0.5449
Batch 170, Loss: 0.5412
Batch 180, Loss: 0.5126
Batch 190, Loss: 0.5005
Batch 200, Loss: 0.4877
Batch 210, Loss: 0.5191
Batch 220, Loss: 0.5745
Batch 230, Loss: 0.5245
Batch 240, Loss: 0.5511
Batch 250, Loss: 0.5742
Batch 260, Loss: 0.5422
Batch 270, Loss: 0.4954
Batch 280, Loss: 0.5123
Batch 290, Loss: 0.5690
Batch 300, Loss: 0.5486
Batch 310, Loss: 0.5564
Batch 320, Loss: 0.4973
Batch 330, Loss: 0.5121
Batch 340, Loss: 0.4945
Batch 350, Loss: 0.5139
Batch 360, Loss: 0.5464
Batch 370, Loss: 0.5399
Batch 380, Loss: 0.5543
Batch 390, Loss: 0.4890
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.585217237472534 seconds
Epoch 58 accuracy: 84.48%
Batch 10, Loss: 0.5222
Batch 20, Loss: 0.5300
Batch 30, Loss: 0.5338
Batch 40, Loss: 0.5251
Batch 50, Loss: 0.4967
Batch 60, Loss: 0.4722
Batch 70, Loss: 0.4891
Batch 80, Loss: 0.5399
Batch 90, Loss: 0.5279
Batch 100, Loss: 0.5461
Batch 110, Loss: 0.5455
Batch 120, Loss: 0.4917
Batch 130, Loss: 0.4991
Batch 140, Loss: 0.5285
Batch 150, Loss: 0.5147
Batch 160, Loss: 0.5522
Batch 170, Loss: 0.5141
Batch 180, Loss: 0.4957
Batch 190, Loss: 0.5138
Batch 200, Loss: 0.5511
Batch 210, Loss: 0.5187
Batch 220, Loss: 0.5160
Batch 230, Loss: 0.5053
Batch 240, Loss: 0.5205
Batch 250, Loss: 0.5316
Batch 260, Loss: 0.5698
Batch 270, Loss: 0.5256
Batch 280, Loss: 0.5199
Batch 290, Loss: 0.5386
Batch 300, Loss: 0.5340
Batch 310, Loss: 0.4921
Batch 320, Loss: 0.5259
Batch 330, Loss: 0.5337
Batch 340, Loss: 0.5114
Batch 350, Loss: 0.5076
Batch 360, Loss: 0.5363
Batch 370, Loss: 0.5402
Batch 380, Loss: 0.5645
Batch 390, Loss: 0.5426
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.48393487930298 seconds
Epoch 59 accuracy: 84.26%
Batch 10, Loss: 0.5314
Batch 20, Loss: 0.5261
Batch 30, Loss: 0.5143
Batch 40, Loss: 0.4910
Batch 50, Loss: 0.5363
Batch 60, Loss: 0.5058
Batch 70, Loss: 0.5208
Batch 80, Loss: 0.5240
Batch 90, Loss: 0.5235
Batch 100, Loss: 0.4998
Batch 110, Loss: 0.5404
Batch 120, Loss: 0.5279
Batch 130, Loss: 0.4938
Batch 140, Loss: 0.5486
Batch 150, Loss: 0.4999
Batch 160, Loss: 0.5293
Batch 170, Loss: 0.4844
Batch 180, Loss: 0.5203
Batch 190, Loss: 0.5163
Batch 200, Loss: 0.5444
Batch 210, Loss: 0.4983
Batch 220, Loss: 0.5413
Batch 230, Loss: 0.5087
Batch 240, Loss: 0.5269
Batch 250, Loss: 0.5212
Batch 260, Loss: 0.5082
Batch 270, Loss: 0.5321
Batch 280, Loss: 0.5334
Batch 290, Loss: 0.5145
Batch 300, Loss: 0.5308
Batch 310, Loss: 0.5458
Batch 320, Loss: 0.5505
Batch 330, Loss: 0.5096
Batch 340, Loss: 0.5239
Batch 350, Loss: 0.5380
Batch 360, Loss: 0.5069
Batch 370, Loss: 0.5408
Batch 380, Loss: 0.5455
Batch 390, Loss: 0.5536
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.34137773513794 seconds
Epoch 60 accuracy: 86.1%
Batch 10, Loss: 0.5580
Batch 20, Loss: 0.5149
Batch 30, Loss: 0.5139
Batch 40, Loss: 0.5036
Batch 50, Loss: 0.5239
Batch 60, Loss: 0.5515
Batch 70, Loss: 0.5290
Batch 80, Loss: 0.5803
Batch 90, Loss: 0.5282
Batch 100, Loss: 0.5071
Batch 110, Loss: 0.5206
Batch 120, Loss: 0.5042
Batch 130, Loss: 0.5231
Batch 140, Loss: 0.5464
Batch 150, Loss: 0.4769
Batch 160, Loss: 0.4658
Batch 170, Loss: 0.5078
Batch 180, Loss: 0.5122
Batch 190, Loss: 0.5418
Batch 200, Loss: 0.5219
Batch 210, Loss: 0.5256
Batch 220, Loss: 0.5146
Batch 230, Loss: 0.5309
Batch 240, Loss: 0.5314
Batch 250, Loss: 0.5159
Batch 260, Loss: 0.5292
Batch 270, Loss: 0.5207
Batch 280, Loss: 0.5118
Batch 290, Loss: 0.5133
Batch 300, Loss: 0.5513
Batch 310, Loss: 0.5170
Batch 320, Loss: 0.5296
Batch 330, Loss: 0.5236
Batch 340, Loss: 0.5363
Batch 350, Loss: 0.5161
Batch 360, Loss: 0.5199
Batch 370, Loss: 0.5370
Batch 380, Loss: 0.5109
Batch 390, Loss: 0.5454
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.707751750946045 seconds
Epoch 61 accuracy: 85.24%
Batch 10, Loss: 0.4919
Batch 20, Loss: 0.5162
Batch 30, Loss: 0.5352
Batch 40, Loss: 0.5092
Batch 50, Loss: 0.5627
Batch 60, Loss: 0.4718
Batch 70, Loss: 0.4991
Batch 80, Loss: 0.5114
Batch 90, Loss: 0.5113
Batch 100, Loss: 0.5210
Batch 110, Loss: 0.5022
Batch 120, Loss: 0.4689
Batch 130, Loss: 0.5698
Batch 140, Loss: 0.5481
Batch 150, Loss: 0.4896
Batch 160, Loss: 0.5551
Batch 170, Loss: 0.5497
Batch 180, Loss: 0.5126
Batch 190, Loss: 0.5486
Batch 200, Loss: 0.5125
Batch 210, Loss: 0.5056
Batch 220, Loss: 0.4852
Batch 230, Loss: 0.5823
Batch 240, Loss: 0.4870
Batch 250, Loss: 0.5213
Batch 260, Loss: 0.5565
Batch 270, Loss: 0.5038
Batch 280, Loss: 0.4819
Batch 290, Loss: 0.5688
Batch 300, Loss: 0.5391
Batch 310, Loss: 0.5510
Batch 320, Loss: 0.5513
Batch 330, Loss: 0.5318
Batch 340, Loss: 0.5387
Batch 350, Loss: 0.5126
Batch 360, Loss: 0.5109
Batch 370, Loss: 0.4869
Batch 380, Loss: 0.4855
Batch 390, Loss: 0.5435
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.567975759506226 seconds
Epoch 62 accuracy: 86.81%
Batch 10, Loss: 0.5062
Batch 20, Loss: 0.5499
Batch 30, Loss: 0.5056
Batch 40, Loss: 0.4904
Batch 50, Loss: 0.5195
Batch 60, Loss: 0.4982
Batch 70, Loss: 0.5402
Batch 80, Loss: 0.5102
Batch 90, Loss: 0.5140
Batch 100, Loss: 0.5451
Batch 110, Loss: 0.5117
Batch 120, Loss: 0.5113
Batch 130, Loss: 0.5293
Batch 140, Loss: 0.5134
Batch 150, Loss: 0.4627
Batch 160, Loss: 0.5349
Batch 170, Loss: 0.5131
Batch 180, Loss: 0.5677
Batch 190, Loss: 0.5279
Batch 200, Loss: 0.5018
Batch 210, Loss: 0.5244
Batch 220, Loss: 0.5365
Batch 230, Loss: 0.5214
Batch 240, Loss: 0.5576
Batch 250, Loss: 0.5178
Batch 260, Loss: 0.5171
Batch 270, Loss: 0.5216
Batch 280, Loss: 0.5120
Batch 290, Loss: 0.5467
Batch 300, Loss: 0.4984
Batch 310, Loss: 0.4968
Batch 320, Loss: 0.4903
Batch 330, Loss: 0.5162
Batch 340, Loss: 0.5000
Batch 350, Loss: 0.5190
Batch 360, Loss: 0.4889
Batch 370, Loss: 0.5226
Batch 380, Loss: 0.5035
Batch 390, Loss: 0.5146
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.50625705718994 seconds
Epoch 63 accuracy: 82.99%
Batch 10, Loss: 0.5652
Batch 20, Loss: 0.5075
Batch 30, Loss: 0.4882
Batch 40, Loss: 0.4802
Batch 50, Loss: 0.5480
Batch 60, Loss: 0.4798
Batch 70, Loss: 0.5210
Batch 80, Loss: 0.5281
Batch 90, Loss: 0.5050
Batch 100, Loss: 0.4898
Batch 110, Loss: 0.5150
Batch 120, Loss: 0.5140
Batch 130, Loss: 0.5051
Batch 140, Loss: 0.4798
Batch 150, Loss: 0.5448
Batch 160, Loss: 0.5426
Batch 170, Loss: 0.5338
Batch 180, Loss: 0.4885
Batch 190, Loss: 0.5176
Batch 200, Loss: 0.5231
Batch 210, Loss: 0.4899
Batch 220, Loss: 0.4950
Batch 230, Loss: 0.4880
Batch 240, Loss: 0.5526
Batch 250, Loss: 0.5324
Batch 260, Loss: 0.4979
Batch 270, Loss: 0.4809
Batch 280, Loss: 0.4897
Batch 290, Loss: 0.5365
Batch 300, Loss: 0.5154
Batch 310, Loss: 0.4968
Batch 320, Loss: 0.5390
Batch 330, Loss: 0.5247
Batch 340, Loss: 0.5599
Batch 350, Loss: 0.5620
Batch 360, Loss: 0.5260
Batch 370, Loss: 0.4819
Batch 380, Loss: 0.5058
Batch 390, Loss: 0.5126
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.477386236190796 seconds
Epoch 64 accuracy: 82.7%
Batch 10, Loss: 0.5016
Batch 20, Loss: 0.5288
Batch 30, Loss: 0.5115
Batch 40, Loss: 0.4556
Batch 50, Loss: 0.4777
Batch 60, Loss: 0.5037
Batch 70, Loss: 0.4677
Batch 80, Loss: 0.5510
Batch 90, Loss: 0.5173
Batch 100, Loss: 0.5429
Batch 110, Loss: 0.4961
Batch 120, Loss: 0.5008
Batch 130, Loss: 0.4796
Batch 140, Loss: 0.4993
Batch 150, Loss: 0.5248
Batch 160, Loss: 0.5306
Batch 170, Loss: 0.5065
Batch 180, Loss: 0.5105
Batch 190, Loss: 0.5360
Batch 200, Loss: 0.5025
Batch 210, Loss: 0.5476
Batch 220, Loss: 0.5508
Batch 230, Loss: 0.5094
Batch 240, Loss: 0.5291
Batch 250, Loss: 0.5163
Batch 260, Loss: 0.5107
Batch 270, Loss: 0.4942
Batch 280, Loss: 0.5526
Batch 290, Loss: 0.5243
Batch 300, Loss: 0.4922
Batch 310, Loss: 0.4992
Batch 320, Loss: 0.4787
Batch 330, Loss: 0.5222
Batch 340, Loss: 0.4996
Batch 350, Loss: 0.4875
Batch 360, Loss: 0.5324
Batch 370, Loss: 0.5456
Batch 380, Loss: 0.4895
Batch 390, Loss: 0.5199
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.59419536590576 seconds
Epoch 65 accuracy: 84.52%
Batch 10, Loss: 0.5181
Batch 20, Loss: 0.4841
Batch 30, Loss: 0.4933
Batch 40, Loss: 0.5268
Batch 50, Loss: 0.5262
Batch 60, Loss: 0.4936
Batch 70, Loss: 0.5321
Batch 80, Loss: 0.4938
Batch 90, Loss: 0.4860
Batch 100, Loss: 0.5378
Batch 110, Loss: 0.5032
Batch 120, Loss: 0.5110
Batch 130, Loss: 0.5387
Batch 140, Loss: 0.5329
Batch 150, Loss: 0.4885
Batch 160, Loss: 0.4950
Batch 170, Loss: 0.5416
Batch 180, Loss: 0.5053
Batch 190, Loss: 0.4850
Batch 200, Loss: 0.5059
Batch 210, Loss: 0.5150
Batch 220, Loss: 0.4978
Batch 230, Loss: 0.5193
Batch 240, Loss: 0.5392
Batch 250, Loss: 0.5241
Batch 260, Loss: 0.4658
Batch 270, Loss: 0.5526
Batch 280, Loss: 0.5370
Batch 290, Loss: 0.5061
Batch 300, Loss: 0.5139
Batch 310, Loss: 0.4964
Batch 320, Loss: 0.4997
Batch 330, Loss: 0.5261
Batch 340, Loss: 0.5115
Batch 350, Loss: 0.5287
Batch 360, Loss: 0.5038
Batch 370, Loss: 0.4972
Batch 380, Loss: 0.5378
Batch 390, Loss: 0.5051
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.47157311439514 seconds
Epoch 66 accuracy: 87.87%
Batch 10, Loss: 0.4777
Batch 20, Loss: 0.5194
Batch 30, Loss: 0.4914
Batch 40, Loss: 0.5094
Batch 50, Loss: 0.4878
Batch 60, Loss: 0.4926
Batch 70, Loss: 0.4636
Batch 80, Loss: 0.4854
Batch 90, Loss: 0.5075
Batch 100, Loss: 0.4890
Batch 110, Loss: 0.5360
Batch 120, Loss: 0.5200
Batch 130, Loss: 0.4648
Batch 140, Loss: 0.5301
Batch 150, Loss: 0.4733
Batch 160, Loss: 0.4730
Batch 170, Loss: 0.5045
Batch 180, Loss: 0.5286
Batch 190, Loss: 0.5244
Batch 200, Loss: 0.5249
Batch 210, Loss: 0.4936
Batch 220, Loss: 0.5099
Batch 230, Loss: 0.4826
Batch 240, Loss: 0.5073
Batch 250, Loss: 0.5313
Batch 260, Loss: 0.4709
Batch 270, Loss: 0.5211
Batch 280, Loss: 0.5334
Batch 290, Loss: 0.5082
Batch 300, Loss: 0.5365
Batch 310, Loss: 0.4717
Batch 320, Loss: 0.5574
Batch 330, Loss: 0.4765
Batch 340, Loss: 0.4976
Batch 350, Loss: 0.5298
Batch 360, Loss: 0.5429
Batch 370, Loss: 0.5171
Batch 380, Loss: 0.4940
Batch 390, Loss: 0.5030
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.529742002487183 seconds
Epoch 67 accuracy: 86.57%
Batch 10, Loss: 0.5018
Batch 20, Loss: 0.5095
Batch 30, Loss: 0.5156
Batch 40, Loss: 0.4997
Batch 50, Loss: 0.4907
Batch 60, Loss: 0.5133
Batch 70, Loss: 0.5090
Batch 80, Loss: 0.5211
Batch 90, Loss: 0.5094
Batch 100, Loss: 0.4940
Batch 110, Loss: 0.5178
Batch 120, Loss: 0.5172
Batch 130, Loss: 0.5339
Batch 140, Loss: 0.5031
Batch 150, Loss: 0.5087
Batch 160, Loss: 0.4880
Batch 170, Loss: 0.4686
Batch 180, Loss: 0.5079
Batch 190, Loss: 0.4573
Batch 200, Loss: 0.4955
Batch 210, Loss: 0.5103
Batch 220, Loss: 0.5070
Batch 230, Loss: 0.5132
Batch 240, Loss: 0.5042
Batch 250, Loss: 0.5556
Batch 260, Loss: 0.5249
Batch 270, Loss: 0.5102
Batch 280, Loss: 0.4654
Batch 290, Loss: 0.4991
Batch 300, Loss: 0.5138
Batch 310, Loss: 0.5236
Batch 320, Loss: 0.4631
Batch 330, Loss: 0.5080
Batch 340, Loss: 0.5484
Batch 350, Loss: 0.5267
Batch 360, Loss: 0.4844
Batch 370, Loss: 0.5425
Batch 380, Loss: 0.5571
Batch 390, Loss: 0.5215
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.456398725509644 seconds
Epoch 68 accuracy: 85.45%
Batch 10, Loss: 0.4850
Batch 20, Loss: 0.4702
Batch 30, Loss: 0.4708
Batch 40, Loss: 0.5415
Batch 50, Loss: 0.4815
Batch 60, Loss: 0.4780
Batch 70, Loss: 0.4806
Batch 80, Loss: 0.4706
Batch 90, Loss: 0.4735
Batch 100, Loss: 0.5167
Batch 110, Loss: 0.5000
Batch 120, Loss: 0.4991
Batch 130, Loss: 0.5253
Batch 140, Loss: 0.5016
Batch 150, Loss: 0.4996
Batch 160, Loss: 0.5067
Batch 170, Loss: 0.4792
Batch 180, Loss: 0.4743
Batch 190, Loss: 0.4947
Batch 200, Loss: 0.5024
Batch 210, Loss: 0.5217
Batch 220, Loss: 0.5185
Batch 230, Loss: 0.5453
Batch 240, Loss: 0.4977
Batch 250, Loss: 0.4928
Batch 260, Loss: 0.5402
Batch 270, Loss: 0.5284
Batch 280, Loss: 0.5215
Batch 290, Loss: 0.5254
Batch 300, Loss: 0.5320
Batch 310, Loss: 0.4480
Batch 320, Loss: 0.4832
Batch 330, Loss: 0.4944
Batch 340, Loss: 0.4857
Batch 350, Loss: 0.4984
Batch 360, Loss: 0.5292
Batch 370, Loss: 0.5039
Batch 380, Loss: 0.4944
Batch 390, Loss: 0.5296
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.578152179718018 seconds
Epoch 69 accuracy: 83.98%
Batch 10, Loss: 0.5322
Batch 20, Loss: 0.4973
Batch 30, Loss: 0.5010
Batch 40, Loss: 0.5224
Batch 50, Loss: 0.4734
Batch 60, Loss: 0.5008
Batch 70, Loss: 0.4676
Batch 80, Loss: 0.4774
Batch 90, Loss: 0.5183
Batch 100, Loss: 0.4691
Batch 110, Loss: 0.4946
Batch 120, Loss: 0.5179
Batch 130, Loss: 0.5237
Batch 140, Loss: 0.4935
Batch 150, Loss: 0.5301
Batch 160, Loss: 0.5370
Batch 170, Loss: 0.5027
Batch 180, Loss: 0.4935
Batch 190, Loss: 0.4498
Batch 200, Loss: 0.4718
Batch 210, Loss: 0.5142
Batch 220, Loss: 0.5235
Batch 230, Loss: 0.5185
Batch 240, Loss: 0.5239
Batch 250, Loss: 0.4983
Batch 260, Loss: 0.5056
Batch 270, Loss: 0.5171
Batch 280, Loss: 0.4827
Batch 290, Loss: 0.5163
Batch 300, Loss: 0.5089
Batch 310, Loss: 0.5163
Batch 320, Loss: 0.5185
Batch 330, Loss: 0.4894
Batch 340, Loss: 0.4986
Batch 350, Loss: 0.4809
Batch 360, Loss: 0.5112
Batch 370, Loss: 0.5173
Batch 380, Loss: 0.4979
Batch 390, Loss: 0.5216
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.396567821502686 seconds
Epoch 70 accuracy: 85.12%
Batch 10, Loss: 0.4590
Batch 20, Loss: 0.5162
Batch 30, Loss: 0.4624
Batch 40, Loss: 0.4964
Batch 50, Loss: 0.5098
Batch 60, Loss: 0.5272
Batch 70, Loss: 0.5325
Batch 80, Loss: 0.4906
Batch 90, Loss: 0.5006
Batch 100, Loss: 0.4759
Batch 110, Loss: 0.4757
Batch 120, Loss: 0.5205
Batch 130, Loss: 0.4966
Batch 140, Loss: 0.5098
Batch 150, Loss: 0.5464
Batch 160, Loss: 0.4748
Batch 170, Loss: 0.5140
Batch 180, Loss: 0.5029
Batch 190, Loss: 0.4436
Batch 200, Loss: 0.4887
Batch 210, Loss: 0.4645
Batch 220, Loss: 0.5008
Batch 230, Loss: 0.4937
Batch 240, Loss: 0.4670
Batch 250, Loss: 0.5044
Batch 260, Loss: 0.4798
Batch 270, Loss: 0.5161
Batch 280, Loss: 0.4931
Batch 290, Loss: 0.4878
Batch 300, Loss: 0.5059
Batch 310, Loss: 0.5025
Batch 320, Loss: 0.5007
Batch 330, Loss: 0.5426
Batch 340, Loss: 0.5041
Batch 350, Loss: 0.4946
Batch 360, Loss: 0.5268
Batch 370, Loss: 0.5101
Batch 380, Loss: 0.5254
Batch 390, Loss: 0.4909
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.483957290649414 seconds
Epoch 71 accuracy: 87.04%
Batch 10, Loss: 0.4296
Batch 20, Loss: 0.5325
Batch 30, Loss: 0.5199
Batch 40, Loss: 0.4591
Batch 50, Loss: 0.4861
Batch 60, Loss: 0.5235
Batch 70, Loss: 0.4915
Batch 80, Loss: 0.5002
Batch 90, Loss: 0.4868
Batch 100, Loss: 0.5325
Batch 110, Loss: 0.5105
Batch 120, Loss: 0.5059
Batch 130, Loss: 0.4807
Batch 140, Loss: 0.5128
Batch 150, Loss: 0.4485
Batch 160, Loss: 0.4935
Batch 170, Loss: 0.4970
Batch 180, Loss: 0.5587
Batch 190, Loss: 0.4800
Batch 200, Loss: 0.4575
Batch 210, Loss: 0.5248
Batch 220, Loss: 0.4966
Batch 230, Loss: 0.4698
Batch 240, Loss: 0.4628
Batch 250, Loss: 0.4873
Batch 260, Loss: 0.5014
Batch 270, Loss: 0.5092
Batch 280, Loss: 0.5090
Batch 290, Loss: 0.5302
Batch 300, Loss: 0.5061
Batch 310, Loss: 0.4747
Batch 320, Loss: 0.4623
Batch 330, Loss: 0.5317
Batch 340, Loss: 0.5641
Batch 350, Loss: 0.4916
Batch 360, Loss: 0.5299
Batch 370, Loss: 0.5212
Batch 380, Loss: 0.5054
Batch 390, Loss: 0.5088
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.629034519195557 seconds
Epoch 72 accuracy: 84.89%
Batch 10, Loss: 0.5188
Batch 20, Loss: 0.5188
Batch 30, Loss: 0.4886
Batch 40, Loss: 0.4806
Batch 50, Loss: 0.4668
Batch 60, Loss: 0.4724
Batch 70, Loss: 0.4979
Batch 80, Loss: 0.4692
Batch 90, Loss: 0.5357
Batch 100, Loss: 0.4950
Batch 110, Loss: 0.5055
Batch 120, Loss: 0.4406
Batch 130, Loss: 0.4556
Batch 140, Loss: 0.5122
Batch 150, Loss: 0.5413
Batch 160, Loss: 0.4937
Batch 170, Loss: 0.4884
Batch 180, Loss: 0.4691
Batch 190, Loss: 0.5171
Batch 200, Loss: 0.4847
Batch 210, Loss: 0.5227
Batch 220, Loss: 0.5022
Batch 230, Loss: 0.4691
Batch 240, Loss: 0.4889
Batch 250, Loss: 0.5104
Batch 260, Loss: 0.4617
Batch 270, Loss: 0.4843
Batch 280, Loss: 0.5414
Batch 290, Loss: 0.5111
Batch 300, Loss: 0.5218
Batch 310, Loss: 0.5353
Batch 320, Loss: 0.5121
Batch 330, Loss: 0.4951
Batch 340, Loss: 0.5025
Batch 350, Loss: 0.5026
Batch 360, Loss: 0.4993
Batch 370, Loss: 0.4790
Batch 380, Loss: 0.4764
Batch 390, Loss: 0.5153
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.480683088302612 seconds
Epoch 73 accuracy: 85.75%
Batch 10, Loss: 0.5048
Batch 20, Loss: 0.4812
Batch 30, Loss: 0.4867
Batch 40, Loss: 0.4914
Batch 50, Loss: 0.4826
Batch 60, Loss: 0.4873
Batch 70, Loss: 0.4658
Batch 80, Loss: 0.4934
Batch 90, Loss: 0.4553
Batch 100, Loss: 0.4893
Batch 110, Loss: 0.5288
Batch 120, Loss: 0.5101
Batch 130, Loss: 0.4754
Batch 140, Loss: 0.5186
Batch 150, Loss: 0.5416
Batch 160, Loss: 0.5202
Batch 170, Loss: 0.4944
Batch 180, Loss: 0.4826
Batch 190, Loss: 0.4785
Batch 200, Loss: 0.4785
Batch 210, Loss: 0.4656
Batch 220, Loss: 0.4726
Batch 230, Loss: 0.5181
Batch 240, Loss: 0.4629
Batch 250, Loss: 0.5150
Batch 260, Loss: 0.5214
Batch 270, Loss: 0.4888
Batch 280, Loss: 0.5251
Batch 290, Loss: 0.4681
Batch 300, Loss: 0.5139
Batch 310, Loss: 0.5438
Batch 320, Loss: 0.4965
Batch 330, Loss: 0.5327
Batch 340, Loss: 0.5164
Batch 350, Loss: 0.4790
Batch 360, Loss: 0.5184
Batch 370, Loss: 0.4720
Batch 380, Loss: 0.5021
Batch 390, Loss: 0.4986
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.47849416732788 seconds
Epoch 74 accuracy: 86.16%
Batch 10, Loss: 0.5247
Batch 20, Loss: 0.5051
Batch 30, Loss: 0.4568
Batch 40, Loss: 0.4997
Batch 50, Loss: 0.4935
Batch 60, Loss: 0.5060
Batch 70, Loss: 0.4619
Batch 80, Loss: 0.5055
Batch 90, Loss: 0.4653
Batch 100, Loss: 0.4744
Batch 110, Loss: 0.4671
Batch 120, Loss: 0.4639
Batch 130, Loss: 0.5175
Batch 140, Loss: 0.5241
Batch 150, Loss: 0.5148
Batch 160, Loss: 0.4970
Batch 170, Loss: 0.4475
Batch 180, Loss: 0.5042
Batch 190, Loss: 0.5174
Batch 200, Loss: 0.4730
Batch 210, Loss: 0.4762
Batch 220, Loss: 0.5060
Batch 230, Loss: 0.5102
Batch 240, Loss: 0.4715
Batch 250, Loss: 0.5392
Batch 260, Loss: 0.4735
Batch 270, Loss: 0.5010
Batch 280, Loss: 0.4900
Batch 290, Loss: 0.4867
Batch 300, Loss: 0.4996
Batch 310, Loss: 0.5074
Batch 320, Loss: 0.4239
Batch 330, Loss: 0.4802
Batch 340, Loss: 0.4875
Batch 350, Loss: 0.4772
Batch 360, Loss: 0.5223
Batch 370, Loss: 0.5053
Batch 380, Loss: 0.5181
Batch 390, Loss: 0.5367
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.939321756362915 seconds
Epoch 75 accuracy: 84.72%
Batch 10, Loss: 0.4782
Batch 20, Loss: 0.4899
Batch 30, Loss: 0.4678
Batch 40, Loss: 0.4824
Batch 50, Loss: 0.4510
Batch 60, Loss: 0.4679
Batch 70, Loss: 0.4949
Batch 80, Loss: 0.5028
Batch 90, Loss: 0.4692
Batch 100, Loss: 0.5218
Batch 110, Loss: 0.4737
Batch 120, Loss: 0.4688
Batch 130, Loss: 0.5143
Batch 140, Loss: 0.5256
Batch 150, Loss: 0.5150
Batch 160, Loss: 0.4847
Batch 170, Loss: 0.4703
Batch 180, Loss: 0.4948
Batch 190, Loss: 0.4416
Batch 200, Loss: 0.4705
Batch 210, Loss: 0.4773
Batch 220, Loss: 0.5341
Batch 230, Loss: 0.5046
Batch 240, Loss: 0.4957
Batch 250, Loss: 0.4953
Batch 260, Loss: 0.4972
Batch 270, Loss: 0.5071
Batch 280, Loss: 0.4810
Batch 290, Loss: 0.4899
Batch 300, Loss: 0.5161
Batch 310, Loss: 0.5069
Batch 320, Loss: 0.5088
Batch 330, Loss: 0.4866
Batch 340, Loss: 0.4537
Batch 350, Loss: 0.4553
Batch 360, Loss: 0.4801
Batch 370, Loss: 0.5190
Batch 380, Loss: 0.4874
Batch 390, Loss: 0.4689
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.612287282943726 seconds
Epoch 76 accuracy: 85.73%
Batch 10, Loss: 0.4216
Batch 20, Loss: 0.4750
Batch 30, Loss: 0.4735
Batch 40, Loss: 0.4795
Batch 50, Loss: 0.4988
Batch 60, Loss: 0.5131
Batch 70, Loss: 0.5100
Batch 80, Loss: 0.4861
Batch 90, Loss: 0.4620
Batch 100, Loss: 0.4975
Batch 110, Loss: 0.4826
Batch 120, Loss: 0.4911
Batch 130, Loss: 0.4495
Batch 140, Loss: 0.5214
Batch 150, Loss: 0.5259
Batch 160, Loss: 0.4784
Batch 170, Loss: 0.4745
Batch 180, Loss: 0.4913
Batch 190, Loss: 0.5057
Batch 200, Loss: 0.4902
Batch 210, Loss: 0.5035
Batch 220, Loss: 0.4966
Batch 230, Loss: 0.4687
Batch 240, Loss: 0.4814
Batch 250, Loss: 0.5056
Batch 260, Loss: 0.5183
Batch 270, Loss: 0.5181
Batch 280, Loss: 0.4905
Batch 290, Loss: 0.4858
Batch 300, Loss: 0.4709
Batch 310, Loss: 0.4627
Batch 320, Loss: 0.5165
Batch 330, Loss: 0.5034
Batch 340, Loss: 0.4886
Batch 350, Loss: 0.5341
Batch 360, Loss: 0.5079
Batch 370, Loss: 0.4781
Batch 380, Loss: 0.4832
Batch 390, Loss: 0.5091
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.55880117416382 seconds
Epoch 77 accuracy: 86.36%
Batch 10, Loss: 0.4788
Batch 20, Loss: 0.4877
Batch 30, Loss: 0.4532
Batch 40, Loss: 0.5221
Batch 50, Loss: 0.5121
Batch 60, Loss: 0.4346
Batch 70, Loss: 0.4841
Batch 80, Loss: 0.4748
Batch 90, Loss: 0.4937
Batch 100, Loss: 0.4828
Batch 110, Loss: 0.4713
Batch 120, Loss: 0.4817
Batch 130, Loss: 0.4893
Batch 140, Loss: 0.4569
Batch 150, Loss: 0.4865
Batch 160, Loss: 0.4580
Batch 170, Loss: 0.4628
Batch 180, Loss: 0.5020
Batch 190, Loss: 0.4857
Batch 200, Loss: 0.5063
Batch 210, Loss: 0.4899
Batch 220, Loss: 0.5015
Batch 230, Loss: 0.4768
Batch 240, Loss: 0.4557
Batch 250, Loss: 0.4822
Batch 260, Loss: 0.5096
Batch 270, Loss: 0.4674
Batch 280, Loss: 0.5182
Batch 290, Loss: 0.4701
Batch 300, Loss: 0.4756
Batch 310, Loss: 0.4947
Batch 320, Loss: 0.4693
Batch 330, Loss: 0.5014
Batch 340, Loss: 0.4713
Batch 350, Loss: 0.5192
Batch 360, Loss: 0.4523
Batch 370, Loss: 0.5044
Batch 380, Loss: 0.5190
Batch 390, Loss: 0.4820
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.416282892227173 seconds
Epoch 78 accuracy: 87.71%
Batch 10, Loss: 0.4929
Batch 20, Loss: 0.4523
Batch 30, Loss: 0.4615
Batch 40, Loss: 0.4605
Batch 50, Loss: 0.4250
Batch 60, Loss: 0.4819
Batch 70, Loss: 0.4878
Batch 80, Loss: 0.4552
Batch 90, Loss: 0.4816
Batch 100, Loss: 0.4986
Batch 110, Loss: 0.5047
Batch 120, Loss: 0.4728
Batch 130, Loss: 0.4979
Batch 140, Loss: 0.4783
Batch 150, Loss: 0.4798
Batch 160, Loss: 0.4930
Batch 170, Loss: 0.4692
Batch 180, Loss: 0.4948
Batch 190, Loss: 0.5003
Batch 200, Loss: 0.4785
Batch 210, Loss: 0.4700
Batch 220, Loss: 0.5011
Batch 230, Loss: 0.4926
Batch 240, Loss: 0.5227
Batch 250, Loss: 0.5314
Batch 260, Loss: 0.5008
Batch 270, Loss: 0.5099
Batch 280, Loss: 0.4922
Batch 290, Loss: 0.4921
Batch 300, Loss: 0.4636
Batch 310, Loss: 0.4697
Batch 320, Loss: 0.5183
Batch 330, Loss: 0.4788
Batch 340, Loss: 0.4786
Batch 350, Loss: 0.4605
Batch 360, Loss: 0.4905
Batch 370, Loss: 0.4953
Batch 380, Loss: 0.5170
Batch 390, Loss: 0.4851
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.478181838989258 seconds
Epoch 79 accuracy: 85.97%
Batch 10, Loss: 0.4802
Batch 20, Loss: 0.5414
Batch 30, Loss: 0.5098
Batch 40, Loss: 0.4841
Batch 50, Loss: 0.4618
Batch 60, Loss: 0.4656
Batch 70, Loss: 0.4662
Batch 80, Loss: 0.4780
Batch 90, Loss: 0.5045
Batch 100, Loss: 0.4771
Batch 110, Loss: 0.4863
Batch 120, Loss: 0.5006
Batch 130, Loss: 0.4903
Batch 140, Loss: 0.4739
Batch 150, Loss: 0.4809
Batch 160, Loss: 0.4762
Batch 170, Loss: 0.4747
Batch 180, Loss: 0.4780
Batch 190, Loss: 0.4852
Batch 200, Loss: 0.4801
Batch 210, Loss: 0.4949
Batch 220, Loss: 0.4728
Batch 230, Loss: 0.4771
Batch 240, Loss: 0.4702
Batch 250, Loss: 0.4535
Batch 260, Loss: 0.5053
Batch 270, Loss: 0.4988
Batch 280, Loss: 0.4975
Batch 290, Loss: 0.4803
Batch 300, Loss: 0.4739
Batch 310, Loss: 0.4679
Batch 320, Loss: 0.4814
Batch 330, Loss: 0.4967
Batch 340, Loss: 0.4820
Batch 350, Loss: 0.4787
Batch 360, Loss: 0.4683
Batch 370, Loss: 0.4774
Batch 380, Loss: 0.4651
Batch 390, Loss: 0.4873
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.505319118499756 seconds
Epoch 80 accuracy: 88.19%
Batch 10, Loss: 0.4749
Batch 20, Loss: 0.4715
Batch 30, Loss: 0.4520
Batch 40, Loss: 0.4496
Batch 50, Loss: 0.4557
Batch 60, Loss: 0.4847
Batch 70, Loss: 0.4663
Batch 80, Loss: 0.4750
Batch 90, Loss: 0.4649
Batch 100, Loss: 0.4858
Batch 110, Loss: 0.4410
Batch 120, Loss: 0.5264
Batch 130, Loss: 0.4752
Batch 140, Loss: 0.4965
Batch 150, Loss: 0.4764
Batch 160, Loss: 0.4804
Batch 170, Loss: 0.4893
Batch 180, Loss: 0.4499
Batch 190, Loss: 0.4894
Batch 200, Loss: 0.4742
Batch 210, Loss: 0.4482
Batch 220, Loss: 0.4503
Batch 230, Loss: 0.4683
Batch 240, Loss: 0.4470
Batch 250, Loss: 0.4708
Batch 260, Loss: 0.4384
Batch 270, Loss: 0.4881
Batch 280, Loss: 0.5123
Batch 290, Loss: 0.4866
Batch 300, Loss: 0.5244
Batch 310, Loss: 0.4891
Batch 320, Loss: 0.4653
Batch 330, Loss: 0.4966
Batch 340, Loss: 0.4892
Batch 350, Loss: 0.4805
Batch 360, Loss: 0.4890
Batch 370, Loss: 0.4578
Batch 380, Loss: 0.4882
Batch 390, Loss: 0.4578
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.51775574684143 seconds
Epoch 81 accuracy: 88.39%
Batch 10, Loss: 0.4845
Batch 20, Loss: 0.4404
Batch 30, Loss: 0.5107
Batch 40, Loss: 0.4875
Batch 50, Loss: 0.5049
Batch 60, Loss: 0.4675
Batch 70, Loss: 0.4745
Batch 80, Loss: 0.5055
Batch 90, Loss: 0.4600
Batch 100, Loss: 0.4906
Batch 110, Loss: 0.4893
Batch 120, Loss: 0.4653
Batch 130, Loss: 0.4592
Batch 140, Loss: 0.4717
Batch 150, Loss: 0.4697
Batch 160, Loss: 0.4986
Batch 170, Loss: 0.5350
Batch 180, Loss: 0.4765
Batch 190, Loss: 0.4419
Batch 200, Loss: 0.4699
Batch 210, Loss: 0.4831
Batch 220, Loss: 0.4946
Batch 230, Loss: 0.4894
Batch 240, Loss: 0.4527
Batch 250, Loss: 0.4810
Batch 260, Loss: 0.4813
Batch 270, Loss: 0.4879
Batch 280, Loss: 0.5079
Batch 290, Loss: 0.4618
Batch 300, Loss: 0.5169
Batch 310, Loss: 0.4547
Batch 320, Loss: 0.4583
Batch 330, Loss: 0.4878
Batch 340, Loss: 0.5045
Batch 350, Loss: 0.5052
Batch 360, Loss: 0.4937
Batch 370, Loss: 0.4825
Batch 380, Loss: 0.4893
Batch 390, Loss: 0.4644
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.51865577697754 seconds
Epoch 82 accuracy: 86.43%
Batch 10, Loss: 0.4463
Batch 20, Loss: 0.4309
Batch 30, Loss: 0.5157
Batch 40, Loss: 0.4950
Batch 50, Loss: 0.5080
Batch 60, Loss: 0.4475
Batch 70, Loss: 0.5309
Batch 80, Loss: 0.4852
Batch 90, Loss: 0.4840
Batch 100, Loss: 0.4795
Batch 110, Loss: 0.4481
Batch 120, Loss: 0.4723
Batch 130, Loss: 0.4680
Batch 140, Loss: 0.4702
Batch 150, Loss: 0.4498
Batch 160, Loss: 0.4461
Batch 170, Loss: 0.5028
Batch 180, Loss: 0.4611
Batch 190, Loss: 0.4792
Batch 200, Loss: 0.4533
Batch 210, Loss: 0.4694
Batch 220, Loss: 0.5042
Batch 230, Loss: 0.4909
Batch 240, Loss: 0.4863
Batch 250, Loss: 0.4814
Batch 260, Loss: 0.4861
Batch 270, Loss: 0.4678
Batch 280, Loss: 0.4742
Batch 290, Loss: 0.4863
Batch 300, Loss: 0.4497
Batch 310, Loss: 0.4758
Batch 320, Loss: 0.4828
Batch 330, Loss: 0.4579
Batch 340, Loss: 0.4923
Batch 350, Loss: 0.4947
Batch 360, Loss: 0.5073
Batch 370, Loss: 0.4833
Batch 380, Loss: 0.5033
Batch 390, Loss: 0.4961
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.421975135803223 seconds
Epoch 83 accuracy: 83.57%
Batch 10, Loss: 0.4943
Batch 20, Loss: 0.4755
Batch 30, Loss: 0.4695
Batch 40, Loss: 0.4404
Batch 50, Loss: 0.4636
Batch 60, Loss: 0.4148
Batch 70, Loss: 0.4853
Batch 80, Loss: 0.4513
Batch 90, Loss: 0.5109
Batch 100, Loss: 0.4797
Batch 110, Loss: 0.4432
Batch 120, Loss: 0.4902
Batch 130, Loss: 0.4715
Batch 140, Loss: 0.4738
Batch 150, Loss: 0.4990
Batch 160, Loss: 0.5079
Batch 170, Loss: 0.5064
Batch 180, Loss: 0.4972
Batch 190, Loss: 0.4503
Batch 200, Loss: 0.4584
Batch 210, Loss: 0.4583
Batch 220, Loss: 0.4915
Batch 230, Loss: 0.5346
Batch 240, Loss: 0.4863
Batch 250, Loss: 0.4580
Batch 260, Loss: 0.4326
Batch 270, Loss: 0.4479
Batch 280, Loss: 0.4555
Batch 290, Loss: 0.5173
Batch 300, Loss: 0.4632
Batch 310, Loss: 0.4508
Batch 320, Loss: 0.4818
Batch 330, Loss: 0.4553
Batch 340, Loss: 0.4742
Batch 350, Loss: 0.4601
Batch 360, Loss: 0.5168
Batch 370, Loss: 0.4877
Batch 380, Loss: 0.4547
Batch 390, Loss: 0.4759
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.516852855682373 seconds
Epoch 84 accuracy: 87.24%
Batch 10, Loss: 0.4074
Batch 20, Loss: 0.4744
Batch 30, Loss: 0.4519
Batch 40, Loss: 0.4649
Batch 50, Loss: 0.4849
Batch 60, Loss: 0.4889
Batch 70, Loss: 0.4995
Batch 80, Loss: 0.4935
Batch 90, Loss: 0.4475
Batch 100, Loss: 0.4590
Batch 110, Loss: 0.4778
Batch 120, Loss: 0.4622
Batch 130, Loss: 0.4527
Batch 140, Loss: 0.4792
Batch 150, Loss: 0.4907
Batch 160, Loss: 0.4699
Batch 170, Loss: 0.4777
Batch 180, Loss: 0.4613
Batch 190, Loss: 0.5041
Batch 200, Loss: 0.4927
Batch 210, Loss: 0.4640
Batch 220, Loss: 0.4569
Batch 230, Loss: 0.4699
Batch 240, Loss: 0.4186
Batch 250, Loss: 0.4547
Batch 260, Loss: 0.5060
Batch 270, Loss: 0.5119
Batch 280, Loss: 0.4751
Batch 290, Loss: 0.4682
Batch 300, Loss: 0.4938
Batch 310, Loss: 0.4780
Batch 320, Loss: 0.4735
Batch 330, Loss: 0.4678
Batch 340, Loss: 0.4412
Batch 350, Loss: 0.4693
Batch 360, Loss: 0.4582
Batch 370, Loss: 0.4769
Batch 380, Loss: 0.5054
Batch 390, Loss: 0.5031
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.530355215072632 seconds
Epoch 85 accuracy: 84.26%
Batch 10, Loss: 0.4427
Batch 20, Loss: 0.4156
Batch 30, Loss: 0.4597
Batch 40, Loss: 0.4665
Batch 50, Loss: 0.4901
Batch 60, Loss: 0.4633
Batch 70, Loss: 0.4940
Batch 80, Loss: 0.4794
Batch 90, Loss: 0.4758
Batch 100, Loss: 0.4481
Batch 110, Loss: 0.4641
Batch 120, Loss: 0.4874
Batch 130, Loss: 0.4817
Batch 140, Loss: 0.4293
Batch 150, Loss: 0.4604
Batch 160, Loss: 0.4422
Batch 170, Loss: 0.4761
Batch 180, Loss: 0.4270
Batch 190, Loss: 0.4795
Batch 200, Loss: 0.4915
Batch 210, Loss: 0.5087
Batch 220, Loss: 0.4980
Batch 230, Loss: 0.4674
Batch 240, Loss: 0.4858
Batch 250, Loss: 0.4751
Batch 260, Loss: 0.4835
Batch 270, Loss: 0.4725
Batch 280, Loss: 0.4800
Batch 290, Loss: 0.4523
Batch 300, Loss: 0.4623
Batch 310, Loss: 0.4772
Batch 320, Loss: 0.4467
Batch 330, Loss: 0.4700
Batch 340, Loss: 0.4244
Batch 350, Loss: 0.4819
Batch 360, Loss: 0.4555
Batch 370, Loss: 0.4953
Batch 380, Loss: 0.4886
Batch 390, Loss: 0.4690
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.638516664505005 seconds
Epoch 86 accuracy: 86.62%
Batch 10, Loss: 0.5053
Batch 20, Loss: 0.4400
Batch 30, Loss: 0.4315
Batch 40, Loss: 0.4622
Batch 50, Loss: 0.4076
Batch 60, Loss: 0.4289
Batch 70, Loss: 0.4487
Batch 80, Loss: 0.4419
Batch 90, Loss: 0.5189
Batch 100, Loss: 0.4431
Batch 110, Loss: 0.4657
Batch 120, Loss: 0.4821
Batch 130, Loss: 0.4357
Batch 140, Loss: 0.5002
Batch 150, Loss: 0.4573
Batch 160, Loss: 0.4919
Batch 170, Loss: 0.4674
Batch 180, Loss: 0.4781
Batch 190, Loss: 0.4261
Batch 200, Loss: 0.4597
Batch 210, Loss: 0.5054
Batch 220, Loss: 0.4587
Batch 230, Loss: 0.4939
Batch 240, Loss: 0.4698
Batch 250, Loss: 0.4715
Batch 260, Loss: 0.4960
Batch 270, Loss: 0.4962
Batch 280, Loss: 0.4736
Batch 290, Loss: 0.4810
Batch 300, Loss: 0.4472
Batch 310, Loss: 0.4607
Batch 320, Loss: 0.4335
Batch 330, Loss: 0.4849
Batch 340, Loss: 0.4611
Batch 350, Loss: 0.5142
Batch 360, Loss: 0.4944
Batch 370, Loss: 0.4301
Batch 380, Loss: 0.4619
Batch 390, Loss: 0.4321
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.448532819747925 seconds
Epoch 87 accuracy: 86.37%
Batch 10, Loss: 0.4449
Batch 20, Loss: 0.4430
Batch 30, Loss: 0.4276
Batch 40, Loss: 0.4620
Batch 50, Loss: 0.4610
Batch 60, Loss: 0.4532
Batch 70, Loss: 0.4624
Batch 80, Loss: 0.4808
Batch 90, Loss: 0.4612
Batch 100, Loss: 0.4447
Batch 110, Loss: 0.4824
Batch 120, Loss: 0.4574
Batch 130, Loss: 0.4512
Batch 140, Loss: 0.4588
Batch 150, Loss: 0.4593
Batch 160, Loss: 0.4395
Batch 170, Loss: 0.4613
Batch 180, Loss: 0.4486
Batch 190, Loss: 0.4713
Batch 200, Loss: 0.4595
Batch 210, Loss: 0.4433
Batch 220, Loss: 0.4541
Batch 230, Loss: 0.4845
Batch 240, Loss: 0.4929
Batch 250, Loss: 0.4680
Batch 260, Loss: 0.4713
Batch 270, Loss: 0.4697
Batch 280, Loss: 0.4643
Batch 290, Loss: 0.4433
Batch 300, Loss: 0.4756
Batch 310, Loss: 0.4794
Batch 320, Loss: 0.4830
Batch 330, Loss: 0.4661
Batch 340, Loss: 0.4866
Batch 350, Loss: 0.4676
Batch 360, Loss: 0.4498
Batch 370, Loss: 0.4697
Batch 380, Loss: 0.4882
Batch 390, Loss: 0.4547
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.576191425323486 seconds
Epoch 88 accuracy: 86.84%
Batch 10, Loss: 0.4958
Batch 20, Loss: 0.4826
Batch 30, Loss: 0.4243
Batch 40, Loss: 0.4199
Batch 50, Loss: 0.4462
Batch 60, Loss: 0.4527
Batch 70, Loss: 0.4679
Batch 80, Loss: 0.4104
Batch 90, Loss: 0.4736
Batch 100, Loss: 0.4565
Batch 110, Loss: 0.4614
Batch 120, Loss: 0.4780
Batch 130, Loss: 0.4728
Batch 140, Loss: 0.5034
Batch 150, Loss: 0.4548
Batch 160, Loss: 0.4717
Batch 170, Loss: 0.4854
Batch 180, Loss: 0.4184
Batch 190, Loss: 0.4690
Batch 200, Loss: 0.4408
Batch 210, Loss: 0.4347
Batch 220, Loss: 0.4213
Batch 230, Loss: 0.4476
Batch 240, Loss: 0.4716
Batch 250, Loss: 0.4275
Batch 260, Loss: 0.4715
Batch 270, Loss: 0.4578
Batch 280, Loss: 0.4638
Batch 290, Loss: 0.4602
Batch 300, Loss: 0.4230
Batch 310, Loss: 0.4271
Batch 320, Loss: 0.4624
Batch 330, Loss: 0.4837
Batch 340, Loss: 0.4507
Batch 350, Loss: 0.5174
Batch 360, Loss: 0.4936
Batch 370, Loss: 0.4505
Batch 380, Loss: 0.4681
Batch 390, Loss: 0.4031
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.38774347305298 seconds
Epoch 89 accuracy: 86.56%
Batch 10, Loss: 0.4577
Batch 20, Loss: 0.4580
Batch 30, Loss: 0.4480
Batch 40, Loss: 0.4745
Batch 50, Loss: 0.4181
Batch 60, Loss: 0.4434
Batch 70, Loss: 0.3958
Batch 80, Loss: 0.4444
Batch 90, Loss: 0.4442
Batch 100, Loss: 0.4440
Batch 110, Loss: 0.4499
Batch 120, Loss: 0.4502
Batch 130, Loss: 0.5061
Batch 140, Loss: 0.4354
Batch 150, Loss: 0.4375
Batch 160, Loss: 0.4899
Batch 170, Loss: 0.4399
Batch 180, Loss: 0.4549
Batch 190, Loss: 0.4547
Batch 200, Loss: 0.4871
Batch 210, Loss: 0.4306
Batch 220, Loss: 0.4487
Batch 230, Loss: 0.4638
Batch 240, Loss: 0.4387
Batch 250, Loss: 0.4287
Batch 260, Loss: 0.4720
Batch 270, Loss: 0.4666
Batch 280, Loss: 0.4451
Batch 290, Loss: 0.4517
Batch 300, Loss: 0.4573
Batch 310, Loss: 0.4814
Batch 320, Loss: 0.4769
Batch 330, Loss: 0.4633
Batch 340, Loss: 0.4621
Batch 350, Loss: 0.4648
Batch 360, Loss: 0.4765
Batch 370, Loss: 0.4290
Batch 380, Loss: 0.4636
Batch 390, Loss: 0.4852
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.509870529174805 seconds
Epoch 90 accuracy: 88.83%
Batch 10, Loss: 0.4408
Batch 20, Loss: 0.4356
Batch 30, Loss: 0.4498
Batch 40, Loss: 0.4284
Batch 50, Loss: 0.4348
Batch 60, Loss: 0.4543
Batch 70, Loss: 0.4730
Batch 80, Loss: 0.4619
Batch 90, Loss: 0.4716
Batch 100, Loss: 0.4892
Batch 110, Loss: 0.4735
Batch 120, Loss: 0.4385
Batch 130, Loss: 0.4701
Batch 140, Loss: 0.4611
Batch 150, Loss: 0.4401
Batch 160, Loss: 0.4632
Batch 170, Loss: 0.4774
Batch 180, Loss: 0.4105
Batch 190, Loss: 0.4756
Batch 200, Loss: 0.4683
Batch 210, Loss: 0.4735
Batch 220, Loss: 0.4367
Batch 230, Loss: 0.4862
Batch 240, Loss: 0.4474
Batch 250, Loss: 0.4987
Batch 260, Loss: 0.4766
Batch 270, Loss: 0.4360
Batch 280, Loss: 0.4594
Batch 290, Loss: 0.4737
Batch 300, Loss: 0.4525
Batch 310, Loss: 0.4568
Batch 320, Loss: 0.4601
Batch 330, Loss: 0.4573
Batch 340, Loss: 0.4947
Batch 350, Loss: 0.4275
Batch 360, Loss: 0.4566
Batch 370, Loss: 0.4629
Batch 380, Loss: 0.4687
Batch 390, Loss: 0.4190
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.585583209991455 seconds
Epoch 91 accuracy: 87.21%
Batch 10, Loss: 0.4212
Batch 20, Loss: 0.4442
Batch 30, Loss: 0.4478
Batch 40, Loss: 0.4118
Batch 50, Loss: 0.4008
Batch 60, Loss: 0.4735
Batch 70, Loss: 0.4619
Batch 80, Loss: 0.4993
Batch 90, Loss: 0.4540
Batch 100, Loss: 0.4852
Batch 110, Loss: 0.4659
Batch 120, Loss: 0.4341
Batch 130, Loss: 0.4448
Batch 140, Loss: 0.4400
Batch 150, Loss: 0.4585
Batch 160, Loss: 0.4577
Batch 170, Loss: 0.4685
Batch 180, Loss: 0.4787
Batch 190, Loss: 0.4672
Batch 200, Loss: 0.4873
Batch 210, Loss: 0.4837
Batch 220, Loss: 0.4795
Batch 230, Loss: 0.4623
Batch 240, Loss: 0.4699
Batch 250, Loss: 0.4256
Batch 260, Loss: 0.4365
Batch 270, Loss: 0.4675
Batch 280, Loss: 0.4406
Batch 290, Loss: 0.4713
Batch 300, Loss: 0.4509
Batch 310, Loss: 0.4501
Batch 320, Loss: 0.4632
Batch 330, Loss: 0.4701
Batch 340, Loss: 0.4702
Batch 350, Loss: 0.4460
Batch 360, Loss: 0.4949
Batch 370, Loss: 0.4293
Batch 380, Loss: 0.4341
Batch 390, Loss: 0.4440
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.572425365447998 seconds
Epoch 92 accuracy: 85.94%
Batch 10, Loss: 0.4200
Batch 20, Loss: 0.4651
Batch 30, Loss: 0.4251
Batch 40, Loss: 0.4367
Batch 50, Loss: 0.4396
Batch 60, Loss: 0.4382
Batch 70, Loss: 0.4649
Batch 80, Loss: 0.4836
Batch 90, Loss: 0.4489
Batch 100, Loss: 0.4438
Batch 110, Loss: 0.4276
Batch 120, Loss: 0.4500
Batch 130, Loss: 0.4243
Batch 140, Loss: 0.4603
Batch 150, Loss: 0.4629
Batch 160, Loss: 0.4876
Batch 170, Loss: 0.4354
Batch 180, Loss: 0.4574
Batch 190, Loss: 0.4547
Batch 200, Loss: 0.4266
Batch 210, Loss: 0.4558
Batch 220, Loss: 0.4449
Batch 230, Loss: 0.4430
Batch 240, Loss: 0.4873
Batch 250, Loss: 0.4127
Batch 260, Loss: 0.4105
Batch 270, Loss: 0.4768
Batch 280, Loss: 0.4507
Batch 290, Loss: 0.4390
Batch 300, Loss: 0.4634
Batch 310, Loss: 0.4389
Batch 320, Loss: 0.4858
Batch 330, Loss: 0.4369
Batch 340, Loss: 0.3989
Batch 350, Loss: 0.4568
Batch 360, Loss: 0.4440
Batch 370, Loss: 0.4254
Batch 380, Loss: 0.4419
Batch 390, Loss: 0.4418
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.55092978477478 seconds
Epoch 93 accuracy: 88.96%
Batch 10, Loss: 0.4423
Batch 20, Loss: 0.4210
Batch 30, Loss: 0.4244
Batch 40, Loss: 0.4723
Batch 50, Loss: 0.4624
Batch 60, Loss: 0.4382
Batch 70, Loss: 0.4524
Batch 80, Loss: 0.4384
Batch 90, Loss: 0.4401
Batch 100, Loss: 0.4382
Batch 110, Loss: 0.4355
Batch 120, Loss: 0.4369
Batch 130, Loss: 0.4664
Batch 140, Loss: 0.4390
Batch 150, Loss: 0.4308
Batch 160, Loss: 0.4832
Batch 170, Loss: 0.4690
Batch 180, Loss: 0.4755
Batch 190, Loss: 0.4281
Batch 200, Loss: 0.4390
Batch 210, Loss: 0.4492
Batch 220, Loss: 0.4550
Batch 230, Loss: 0.4501
Batch 240, Loss: 0.4286
Batch 250, Loss: 0.4479
Batch 260, Loss: 0.4640
Batch 270, Loss: 0.4389
Batch 280, Loss: 0.4903
Batch 290, Loss: 0.4250
Batch 300, Loss: 0.4415
Batch 310, Loss: 0.4800
Batch 320, Loss: 0.4525
Batch 330, Loss: 0.4567
Batch 340, Loss: 0.4467
Batch 350, Loss: 0.4682
Batch 360, Loss: 0.4192
Batch 370, Loss: 0.4914
Batch 380, Loss: 0.4638
Batch 390, Loss: 0.4430
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.556291103363037 seconds
Epoch 94 accuracy: 88.95%
Batch 10, Loss: 0.4640
Batch 20, Loss: 0.4220
Batch 30, Loss: 0.4396
Batch 40, Loss: 0.4518
Batch 50, Loss: 0.4485
Batch 60, Loss: 0.4323
Batch 70, Loss: 0.4223
Batch 80, Loss: 0.4474
Batch 90, Loss: 0.4336
Batch 100, Loss: 0.4514
Batch 110, Loss: 0.4549
Batch 120, Loss: 0.4373
Batch 130, Loss: 0.4666
Batch 140, Loss: 0.4009
Batch 150, Loss: 0.4592
Batch 160, Loss: 0.4091
Batch 170, Loss: 0.4433
Batch 180, Loss: 0.4110
Batch 190, Loss: 0.3987
Batch 200, Loss: 0.4691
Batch 210, Loss: 0.4480
Batch 220, Loss: 0.4833
Batch 230, Loss: 0.4582
Batch 240, Loss: 0.4032
Batch 250, Loss: 0.4503
Batch 260, Loss: 0.4439
Batch 270, Loss: 0.4325
Batch 280, Loss: 0.4849
Batch 290, Loss: 0.4745
Batch 300, Loss: 0.4761
Batch 310, Loss: 0.4374
Batch 320, Loss: 0.4393
Batch 330, Loss: 0.4206
Batch 340, Loss: 0.4261
Batch 350, Loss: 0.4695
Batch 360, Loss: 0.4546
Batch 370, Loss: 0.4591
Batch 380, Loss: 0.4552
Batch 390, Loss: 0.4977
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.630384922027588 seconds
Epoch 95 accuracy: 85.96%
Batch 10, Loss: 0.4326
Batch 20, Loss: 0.4326
Batch 30, Loss: 0.4514
Batch 40, Loss: 0.4360
Batch 50, Loss: 0.4455
Batch 60, Loss: 0.4557
Batch 70, Loss: 0.4444
Batch 80, Loss: 0.4381
Batch 90, Loss: 0.4372
Batch 100, Loss: 0.4387
Batch 110, Loss: 0.3954
Batch 120, Loss: 0.4862
Batch 130, Loss: 0.4227
Batch 140, Loss: 0.4397
Batch 150, Loss: 0.4170
Batch 160, Loss: 0.4731
Batch 170, Loss: 0.4471
Batch 180, Loss: 0.4894
Batch 190, Loss: 0.4025
Batch 200, Loss: 0.4389
Batch 210, Loss: 0.4420
Batch 220, Loss: 0.4294
Batch 230, Loss: 0.4156
Batch 240, Loss: 0.4904
Batch 250, Loss: 0.4692
Batch 260, Loss: 0.4754
Batch 270, Loss: 0.4307
Batch 280, Loss: 0.4375
Batch 290, Loss: 0.4502
Batch 300, Loss: 0.4239
Batch 310, Loss: 0.4476
Batch 320, Loss: 0.4066
Batch 330, Loss: 0.4493
Batch 340, Loss: 0.4354
Batch 350, Loss: 0.4502
Batch 360, Loss: 0.4537
Batch 370, Loss: 0.4277
Batch 380, Loss: 0.4638
Batch 390, Loss: 0.4137
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.45624303817749 seconds
Epoch 96 accuracy: 85.89%
Batch 10, Loss: 0.4529
Batch 20, Loss: 0.4174
Batch 30, Loss: 0.4745
Batch 40, Loss: 0.4808
Batch 50, Loss: 0.4521
Batch 60, Loss: 0.4553
Batch 70, Loss: 0.4471
Batch 80, Loss: 0.4513
Batch 90, Loss: 0.4290
Batch 100, Loss: 0.3936
Batch 110, Loss: 0.4475
Batch 120, Loss: 0.4735
Batch 130, Loss: 0.3957
Batch 140, Loss: 0.4544
Batch 150, Loss: 0.4559
Batch 160, Loss: 0.4556
Batch 170, Loss: 0.4071
Batch 180, Loss: 0.4299
Batch 190, Loss: 0.4349
Batch 200, Loss: 0.4662
Batch 210, Loss: 0.4549
Batch 220, Loss: 0.4117
Batch 230, Loss: 0.4883
Batch 240, Loss: 0.4150
Batch 250, Loss: 0.4518
Batch 260, Loss: 0.4375
Batch 270, Loss: 0.4560
Batch 280, Loss: 0.4328
Batch 290, Loss: 0.4790
Batch 300, Loss: 0.4332
Batch 310, Loss: 0.4271
Batch 320, Loss: 0.4428
Batch 330, Loss: 0.4396
Batch 340, Loss: 0.4529
Batch 350, Loss: 0.4225
Batch 360, Loss: 0.4297
Batch 370, Loss: 0.4464
Batch 380, Loss: 0.4763
Batch 390, Loss: 0.4881
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.514580965042114 seconds
Epoch 97 accuracy: 84.76%
Batch 10, Loss: 0.4693
Batch 20, Loss: 0.4486
Batch 30, Loss: 0.4185
Batch 40, Loss: 0.3990
Batch 50, Loss: 0.4391
Batch 60, Loss: 0.4573
Batch 70, Loss: 0.4469
Batch 80, Loss: 0.4564
Batch 90, Loss: 0.4563
Batch 100, Loss: 0.4299
Batch 110, Loss: 0.4627
Batch 120, Loss: 0.4205
Batch 130, Loss: 0.4869
Batch 140, Loss: 0.4375
Batch 150, Loss: 0.4075
Batch 160, Loss: 0.4367
Batch 170, Loss: 0.4656
Batch 180, Loss: 0.4501
Batch 190, Loss: 0.4526
Batch 200, Loss: 0.4676
Batch 210, Loss: 0.4288
Batch 220, Loss: 0.4745
Batch 230, Loss: 0.4205
Batch 240, Loss: 0.4238
Batch 250, Loss: 0.4507
Batch 260, Loss: 0.4797
Batch 270, Loss: 0.4117
Batch 280, Loss: 0.4397
Batch 290, Loss: 0.4628
Batch 300, Loss: 0.4456
Batch 310, Loss: 0.4919
Batch 320, Loss: 0.4430
Batch 330, Loss: 0.4786
Batch 340, Loss: 0.4378
Batch 350, Loss: 0.4543
Batch 360, Loss: 0.4355
Batch 370, Loss: 0.4041
Batch 380, Loss: 0.4142
Batch 390, Loss: 0.4502
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.51109790802002 seconds
Epoch 98 accuracy: 85.91%
Batch 10, Loss: 0.4216
Batch 20, Loss: 0.4569
Batch 30, Loss: 0.4254
Batch 40, Loss: 0.4004
Batch 50, Loss: 0.4466
Batch 60, Loss: 0.4270
Batch 70, Loss: 0.4241
Batch 80, Loss: 0.4841
Batch 90, Loss: 0.4730
Batch 100, Loss: 0.4846
Batch 110, Loss: 0.3781
Batch 120, Loss: 0.4343
Batch 130, Loss: 0.4037
Batch 140, Loss: 0.4648
Batch 150, Loss: 0.4176
Batch 160, Loss: 0.4367
Batch 170, Loss: 0.4195
Batch 180, Loss: 0.4086
Batch 190, Loss: 0.4410
Batch 200, Loss: 0.4698
Batch 210, Loss: 0.4340
Batch 220, Loss: 0.4985
Batch 230, Loss: 0.4471
Batch 240, Loss: 0.4564
Batch 250, Loss: 0.5071
Batch 260, Loss: 0.4235
Batch 270, Loss: 0.4212
Batch 280, Loss: 0.4114
Batch 290, Loss: 0.4015
Batch 300, Loss: 0.4427
Batch 310, Loss: 0.4325
Batch 320, Loss: 0.4326
Batch 330, Loss: 0.4671
Batch 340, Loss: 0.4489
Batch 350, Loss: 0.4322
Batch 360, Loss: 0.4251
Batch 370, Loss: 0.4422
Batch 380, Loss: 0.4321
Batch 390, Loss: 0.4627
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.400073528289795 seconds
Epoch 99 accuracy: 87.17%
Batch 10, Loss: 0.4013
Batch 20, Loss: 0.4499
Batch 30, Loss: 0.4077
Batch 40, Loss: 0.4393
Batch 50, Loss: 0.4133
Batch 60, Loss: 0.4335
Batch 70, Loss: 0.4190
Batch 80, Loss: 0.4093
Batch 90, Loss: 0.4686
Batch 100, Loss: 0.4196
Batch 110, Loss: 0.4291
Batch 120, Loss: 0.4260
Batch 130, Loss: 0.4246
Batch 140, Loss: 0.4254
Batch 150, Loss: 0.4304
Batch 160, Loss: 0.4359
Batch 170, Loss: 0.4541
Batch 180, Loss: 0.4350
Batch 190, Loss: 0.4406
Batch 200, Loss: 0.4092
Batch 210, Loss: 0.3940
Batch 220, Loss: 0.4548
Batch 230, Loss: 0.4185
Batch 240, Loss: 0.4741
Batch 250, Loss: 0.4950
Batch 260, Loss: 0.4636
Batch 270, Loss: 0.4454
Batch 280, Loss: 0.4252
Batch 290, Loss: 0.4600
Batch 300, Loss: 0.4274
Batch 310, Loss: 0.4630
Batch 320, Loss: 0.4529
Batch 330, Loss: 0.4886
Batch 340, Loss: 0.4317
Batch 350, Loss: 0.4551
Batch 360, Loss: 0.4180
Batch 370, Loss: 0.4012
Batch 380, Loss: 0.4101
Batch 390, Loss: 0.3848
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.38858723640442 seconds
Epoch 100 accuracy: 89.53%
Batch 10, Loss: 0.4140
Batch 20, Loss: 0.4331
Batch 30, Loss: 0.4182
Batch 40, Loss: 0.4370
Batch 50, Loss: 0.4362
Batch 60, Loss: 0.4151
Batch 70, Loss: 0.4301
Batch 80, Loss: 0.3904
Batch 90, Loss: 0.4052
Batch 100, Loss: 0.4576
Batch 110, Loss: 0.4341
Batch 120, Loss: 0.3953
Batch 130, Loss: 0.4342
Batch 140, Loss: 0.3957
Batch 150, Loss: 0.3795
Batch 160, Loss: 0.4217
Batch 170, Loss: 0.4049
Batch 180, Loss: 0.4611
Batch 190, Loss: 0.4928
Batch 200, Loss: 0.4084
Batch 210, Loss: 0.4487
Batch 220, Loss: 0.4281
Batch 230, Loss: 0.4472
Batch 240, Loss: 0.4274
Batch 250, Loss: 0.4213
Batch 260, Loss: 0.4528
Batch 270, Loss: 0.4606
Batch 280, Loss: 0.4388
Batch 290, Loss: 0.4442
Batch 300, Loss: 0.4728
Batch 310, Loss: 0.4607
Batch 320, Loss: 0.4157
Batch 330, Loss: 0.4490
Batch 340, Loss: 0.4286
Batch 350, Loss: 0.4153
Batch 360, Loss: 0.4033
Batch 370, Loss: 0.4169
Batch 380, Loss: 0.4575
Batch 390, Loss: 0.4364
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.583788871765137 seconds
Epoch 101 accuracy: 88.15%
Batch 10, Loss: 0.4371
Batch 20, Loss: 0.4052
Batch 30, Loss: 0.4260
Batch 40, Loss: 0.4297
Batch 50, Loss: 0.4270
Batch 60, Loss: 0.4495
Batch 70, Loss: 0.4345
Batch 80, Loss: 0.4234
Batch 90, Loss: 0.4152
Batch 100, Loss: 0.4380
Batch 110, Loss: 0.3835
Batch 120, Loss: 0.4075
Batch 130, Loss: 0.4465
Batch 140, Loss: 0.4325
Batch 150, Loss: 0.4136
Batch 160, Loss: 0.4194
Batch 170, Loss: 0.4276
Batch 180, Loss: 0.4408
Batch 190, Loss: 0.4573
Batch 200, Loss: 0.4158
Batch 210, Loss: 0.4345
Batch 220, Loss: 0.4412
Batch 230, Loss: 0.4494
Batch 240, Loss: 0.4084
Batch 250, Loss: 0.4656
Batch 260, Loss: 0.4023
Batch 270, Loss: 0.4375
Batch 280, Loss: 0.4607
Batch 290, Loss: 0.4200
Batch 300, Loss: 0.4388
Batch 310, Loss: 0.4249
Batch 320, Loss: 0.4223
Batch 330, Loss: 0.4071
Batch 340, Loss: 0.4269
Batch 350, Loss: 0.4713
Batch 360, Loss: 0.4270
Batch 370, Loss: 0.4360
Batch 380, Loss: 0.4375
Batch 390, Loss: 0.4615
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.66657519340515 seconds
Epoch 102 accuracy: 86.13%
Batch 10, Loss: 0.4143
Batch 20, Loss: 0.4374
Batch 30, Loss: 0.3998
Batch 40, Loss: 0.4106
Batch 50, Loss: 0.4540
Batch 60, Loss: 0.4291
Batch 70, Loss: 0.3978
Batch 80, Loss: 0.4194
Batch 90, Loss: 0.4429
Batch 100, Loss: 0.4269
Batch 110, Loss: 0.4328
Batch 120, Loss: 0.4291
Batch 130, Loss: 0.3957
Batch 140, Loss: 0.4214
Batch 150, Loss: 0.4351
Batch 160, Loss: 0.4190
Batch 170, Loss: 0.4260
Batch 180, Loss: 0.4647
Batch 190, Loss: 0.4074
Batch 200, Loss: 0.4242
Batch 210, Loss: 0.4015
Batch 220, Loss: 0.4128
Batch 230, Loss: 0.4251
Batch 240, Loss: 0.4335
Batch 250, Loss: 0.4059
Batch 260, Loss: 0.3980
Batch 270, Loss: 0.4198
Batch 280, Loss: 0.4664
Batch 290, Loss: 0.4522
Batch 300, Loss: 0.4704
Batch 310, Loss: 0.4067
Batch 320, Loss: 0.4111
Batch 330, Loss: 0.4062
Batch 340, Loss: 0.4342
Batch 350, Loss: 0.4020
Batch 360, Loss: 0.4304
Batch 370, Loss: 0.4271
Batch 380, Loss: 0.4538
Batch 390, Loss: 0.4336
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.45447587966919 seconds
Epoch 103 accuracy: 88.81%
Batch 10, Loss: 0.4769
Batch 20, Loss: 0.4133
Batch 30, Loss: 0.4134
Batch 40, Loss: 0.4084
Batch 50, Loss: 0.4132
Batch 60, Loss: 0.4326
Batch 70, Loss: 0.4090
Batch 80, Loss: 0.3979
Batch 90, Loss: 0.4154
Batch 100, Loss: 0.4286
Batch 110, Loss: 0.4478
Batch 120, Loss: 0.3993
Batch 130, Loss: 0.4643
Batch 140, Loss: 0.3770
Batch 150, Loss: 0.4130
Batch 160, Loss: 0.4342
Batch 170, Loss: 0.4135
Batch 180, Loss: 0.4686
Batch 190, Loss: 0.4250
Batch 200, Loss: 0.4384
Batch 210, Loss: 0.4194
Batch 220, Loss: 0.4062
Batch 230, Loss: 0.4289
Batch 240, Loss: 0.4432
Batch 250, Loss: 0.4890
Batch 260, Loss: 0.4477
Batch 270, Loss: 0.4397
Batch 280, Loss: 0.4316
Batch 290, Loss: 0.4505
Batch 300, Loss: 0.4184
Batch 310, Loss: 0.4377
Batch 320, Loss: 0.4635
Batch 330, Loss: 0.4134
Batch 340, Loss: 0.4221
Batch 350, Loss: 0.3690
Batch 360, Loss: 0.4105
Batch 370, Loss: 0.3869
Batch 380, Loss: 0.4076
Batch 390, Loss: 0.3951
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.506478309631348 seconds
Epoch 104 accuracy: 89.22%
Batch 10, Loss: 0.4177
Batch 20, Loss: 0.4164
Batch 30, Loss: 0.3963
Batch 40, Loss: 0.3743
Batch 50, Loss: 0.3864
Batch 60, Loss: 0.4266
Batch 70, Loss: 0.4240
Batch 80, Loss: 0.4295
Batch 90, Loss: 0.4153
Batch 100, Loss: 0.4653
Batch 110, Loss: 0.4178
Batch 120, Loss: 0.4105
Batch 130, Loss: 0.4066
Batch 140, Loss: 0.4109
Batch 150, Loss: 0.3781
Batch 160, Loss: 0.4088
Batch 170, Loss: 0.3929
Batch 180, Loss: 0.4139
Batch 190, Loss: 0.4339
Batch 200, Loss: 0.4175
Batch 210, Loss: 0.4489
Batch 220, Loss: 0.4224
Batch 230, Loss: 0.4219
Batch 240, Loss: 0.4208
Batch 250, Loss: 0.4108
Batch 260, Loss: 0.4348
Batch 270, Loss: 0.3990
Batch 280, Loss: 0.4542
Batch 290, Loss: 0.4238
Batch 300, Loss: 0.4472
Batch 310, Loss: 0.4400
Batch 320, Loss: 0.4318
Batch 330, Loss: 0.4043
Batch 340, Loss: 0.3911
Batch 350, Loss: 0.4588
Batch 360, Loss: 0.4474
Batch 370, Loss: 0.4592
Batch 380, Loss: 0.4364
Batch 390, Loss: 0.4302
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.60077977180481 seconds
Epoch 105 accuracy: 89.0%
Batch 10, Loss: 0.3981
Batch 20, Loss: 0.4126
Batch 30, Loss: 0.3808
Batch 40, Loss: 0.4114
Batch 50, Loss: 0.4186
Batch 60, Loss: 0.3927
Batch 70, Loss: 0.4405
Batch 80, Loss: 0.4669
Batch 90, Loss: 0.4571
Batch 100, Loss: 0.4005
Batch 110, Loss: 0.4047
Batch 120, Loss: 0.4269
Batch 130, Loss: 0.4495
Batch 140, Loss: 0.4074
Batch 150, Loss: 0.4082
Batch 160, Loss: 0.4254
Batch 170, Loss: 0.4347
Batch 180, Loss: 0.4164
Batch 190, Loss: 0.4110
Batch 200, Loss: 0.4010
Batch 210, Loss: 0.4515
Batch 220, Loss: 0.4196
Batch 230, Loss: 0.3917
Batch 240, Loss: 0.4051
Batch 250, Loss: 0.4466
Batch 260, Loss: 0.4329
Batch 270, Loss: 0.4290
Batch 280, Loss: 0.3839
Batch 290, Loss: 0.4015
Batch 300, Loss: 0.4246
Batch 310, Loss: 0.3768
Batch 320, Loss: 0.4114
Batch 330, Loss: 0.4708
Batch 340, Loss: 0.4216
Batch 350, Loss: 0.4290
Batch 360, Loss: 0.4155
Batch 370, Loss: 0.4188
Batch 380, Loss: 0.4224
Batch 390, Loss: 0.3938
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.440675020217896 seconds
Epoch 106 accuracy: 88.56%
Batch 10, Loss: 0.4095
Batch 20, Loss: 0.4091
Batch 30, Loss: 0.4104
Batch 40, Loss: 0.3887
Batch 50, Loss: 0.4235
Batch 60, Loss: 0.4365
Batch 70, Loss: 0.3872
Batch 80, Loss: 0.4107
Batch 90, Loss: 0.4128
Batch 100, Loss: 0.4441
Batch 110, Loss: 0.4378
Batch 120, Loss: 0.4528
Batch 130, Loss: 0.4187
Batch 140, Loss: 0.4310
Batch 150, Loss: 0.4236
Batch 160, Loss: 0.4143
Batch 170, Loss: 0.4059
Batch 180, Loss: 0.3904
Batch 190, Loss: 0.4041
Batch 200, Loss: 0.4002
Batch 210, Loss: 0.4281
Batch 220, Loss: 0.3970
Batch 230, Loss: 0.4555
Batch 240, Loss: 0.4403
Batch 250, Loss: 0.4077
Batch 260, Loss: 0.4352
Batch 270, Loss: 0.4185
Batch 280, Loss: 0.3758
Batch 290, Loss: 0.4265
Batch 300, Loss: 0.4104
Batch 310, Loss: 0.4075
Batch 320, Loss: 0.4152
Batch 330, Loss: 0.3848
Batch 340, Loss: 0.4102
Batch 350, Loss: 0.4294
Batch 360, Loss: 0.4150
Batch 370, Loss: 0.4340
Batch 380, Loss: 0.4200
Batch 390, Loss: 0.4357
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.47114610671997 seconds
Epoch 107 accuracy: 87.95%
Batch 10, Loss: 0.4231
Batch 20, Loss: 0.4266
Batch 30, Loss: 0.3924
Batch 40, Loss: 0.4284
Batch 50, Loss: 0.3816
Batch 60, Loss: 0.4042
Batch 70, Loss: 0.3967
Batch 80, Loss: 0.4184
Batch 90, Loss: 0.4139
Batch 100, Loss: 0.4112
Batch 110, Loss: 0.3834
Batch 120, Loss: 0.4101
Batch 130, Loss: 0.4232
Batch 140, Loss: 0.3904
Batch 150, Loss: 0.4199
Batch 160, Loss: 0.4139
Batch 170, Loss: 0.4020
Batch 180, Loss: 0.3835
Batch 190, Loss: 0.4245
Batch 200, Loss: 0.3974
Batch 210, Loss: 0.4116
Batch 220, Loss: 0.4190
Batch 230, Loss: 0.3988
Batch 240, Loss: 0.4111
Batch 250, Loss: 0.4026
Batch 260, Loss: 0.3854
Batch 270, Loss: 0.4111
Batch 280, Loss: 0.4061
Batch 290, Loss: 0.3956
Batch 300, Loss: 0.4476
Batch 310, Loss: 0.3876
Batch 320, Loss: 0.4032
Batch 330, Loss: 0.3656
Batch 340, Loss: 0.4353
Batch 350, Loss: 0.3927
Batch 360, Loss: 0.4140
Batch 370, Loss: 0.4439
Batch 380, Loss: 0.4130
Batch 390, Loss: 0.4431
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.484299182891846 seconds
Epoch 108 accuracy: 88.25%
Batch 10, Loss: 0.4077
Batch 20, Loss: 0.4180
Batch 30, Loss: 0.4106
Batch 40, Loss: 0.4015
Batch 50, Loss: 0.4265
Batch 60, Loss: 0.4104
Batch 70, Loss: 0.4077
Batch 80, Loss: 0.4154
Batch 90, Loss: 0.3856
Batch 100, Loss: 0.4294
Batch 110, Loss: 0.4232
Batch 120, Loss: 0.3877
Batch 130, Loss: 0.4217
Batch 140, Loss: 0.4280
Batch 150, Loss: 0.4103
Batch 160, Loss: 0.3756
Batch 170, Loss: 0.4078
Batch 180, Loss: 0.4040
Batch 190, Loss: 0.4135
Batch 200, Loss: 0.4454
Batch 210, Loss: 0.3920
Batch 220, Loss: 0.3958
Batch 230, Loss: 0.4553
Batch 240, Loss: 0.4397
Batch 250, Loss: 0.4587
Batch 260, Loss: 0.3858
Batch 270, Loss: 0.3896
Batch 280, Loss: 0.4011
Batch 290, Loss: 0.4031
Batch 300, Loss: 0.3880
Batch 310, Loss: 0.4380
Batch 320, Loss: 0.4053
Batch 330, Loss: 0.3885
Batch 340, Loss: 0.4030
Batch 350, Loss: 0.4215
Batch 360, Loss: 0.4414
Batch 370, Loss: 0.4303
Batch 380, Loss: 0.4045
Batch 390, Loss: 0.4262
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.62979793548584 seconds
Epoch 109 accuracy: 88.84%
Batch 10, Loss: 0.4059
Batch 20, Loss: 0.4177
Batch 30, Loss: 0.4019
Batch 40, Loss: 0.3907
Batch 50, Loss: 0.3573
Batch 60, Loss: 0.3950
Batch 70, Loss: 0.3930
Batch 80, Loss: 0.3717
Batch 90, Loss: 0.3911
Batch 100, Loss: 0.4111
Batch 110, Loss: 0.4066
Batch 120, Loss: 0.4086
Batch 130, Loss: 0.4010
Batch 140, Loss: 0.4199
Batch 150, Loss: 0.4137
Batch 160, Loss: 0.4334
Batch 170, Loss: 0.4472
Batch 180, Loss: 0.3812
Batch 190, Loss: 0.3896
Batch 200, Loss: 0.4329
Batch 210, Loss: 0.4082
Batch 220, Loss: 0.4504
Batch 230, Loss: 0.4262
Batch 240, Loss: 0.3835
Batch 250, Loss: 0.3959
Batch 260, Loss: 0.4349
Batch 270, Loss: 0.3933
Batch 280, Loss: 0.4476
Batch 290, Loss: 0.3834
Batch 300, Loss: 0.3948
Batch 310, Loss: 0.4280
Batch 320, Loss: 0.4371
Batch 330, Loss: 0.4134
Batch 340, Loss: 0.3949
Batch 350, Loss: 0.4161
Batch 360, Loss: 0.4009
Batch 370, Loss: 0.3927
Batch 380, Loss: 0.4097
Batch 390, Loss: 0.3830
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.59810185432434 seconds
Epoch 110 accuracy: 86.8%
Batch 10, Loss: 0.4587
Batch 20, Loss: 0.3822
Batch 30, Loss: 0.3787
Batch 40, Loss: 0.3974
Batch 50, Loss: 0.3881
Batch 60, Loss: 0.3725
Batch 70, Loss: 0.4118
Batch 80, Loss: 0.4284
Batch 90, Loss: 0.4309
Batch 100, Loss: 0.4164
Batch 110, Loss: 0.4108
Batch 120, Loss: 0.4505
Batch 130, Loss: 0.3943
Batch 140, Loss: 0.3991
Batch 150, Loss: 0.4521
Batch 160, Loss: 0.4241
Batch 170, Loss: 0.3975
Batch 180, Loss: 0.3710
Batch 190, Loss: 0.3961
Batch 200, Loss: 0.3651
Batch 210, Loss: 0.3672
Batch 220, Loss: 0.3788
Batch 230, Loss: 0.3775
Batch 240, Loss: 0.3797
Batch 250, Loss: 0.4354
Batch 260, Loss: 0.3935
Batch 270, Loss: 0.4241
Batch 280, Loss: 0.4339
Batch 290, Loss: 0.4122
Batch 300, Loss: 0.4012
Batch 310, Loss: 0.4164
Batch 320, Loss: 0.4343
Batch 330, Loss: 0.4394
Batch 340, Loss: 0.3855
Batch 350, Loss: 0.4207
Batch 360, Loss: 0.3772
Batch 370, Loss: 0.4213
Batch 380, Loss: 0.4508
Batch 390, Loss: 0.4332
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.481496810913086 seconds
Epoch 111 accuracy: 88.74%
Batch 10, Loss: 0.3966
Batch 20, Loss: 0.3915
Batch 30, Loss: 0.4159
Batch 40, Loss: 0.4168
Batch 50, Loss: 0.4032
Batch 60, Loss: 0.3951
Batch 70, Loss: 0.3958
Batch 80, Loss: 0.4305
Batch 90, Loss: 0.3732
Batch 100, Loss: 0.3456
Batch 110, Loss: 0.3734
Batch 120, Loss: 0.3890
Batch 130, Loss: 0.3754
Batch 140, Loss: 0.4072
Batch 150, Loss: 0.4245
Batch 160, Loss: 0.4287
Batch 170, Loss: 0.4100
Batch 180, Loss: 0.4114
Batch 190, Loss: 0.3959
Batch 200, Loss: 0.4119
Batch 210, Loss: 0.4096
Batch 220, Loss: 0.4072
Batch 230, Loss: 0.4387
Batch 240, Loss: 0.3766
Batch 250, Loss: 0.4001
Batch 260, Loss: 0.4272
Batch 270, Loss: 0.4052
Batch 280, Loss: 0.4601
Batch 290, Loss: 0.4153
Batch 300, Loss: 0.4128
Batch 310, Loss: 0.4253
Batch 320, Loss: 0.4082
Batch 330, Loss: 0.3633
Batch 340, Loss: 0.4171
Batch 350, Loss: 0.3591
Batch 360, Loss: 0.4254
Batch 370, Loss: 0.3904
Batch 380, Loss: 0.3838
Batch 390, Loss: 0.4414
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.556564807891846 seconds
Epoch 112 accuracy: 88.7%
Batch 10, Loss: 0.3958
Batch 20, Loss: 0.4052
Batch 30, Loss: 0.4151
Batch 40, Loss: 0.3721
Batch 50, Loss: 0.4050
Batch 60, Loss: 0.4298
Batch 70, Loss: 0.4187
Batch 80, Loss: 0.3993
Batch 90, Loss: 0.3774
Batch 100, Loss: 0.4065
Batch 110, Loss: 0.3922
Batch 120, Loss: 0.4305
Batch 130, Loss: 0.3974
Batch 140, Loss: 0.3924
Batch 150, Loss: 0.3892
Batch 160, Loss: 0.4096
Batch 170, Loss: 0.3915
Batch 180, Loss: 0.3944
Batch 190, Loss: 0.3999
Batch 200, Loss: 0.3673
Batch 210, Loss: 0.4108
Batch 220, Loss: 0.3894
Batch 230, Loss: 0.3811
Batch 240, Loss: 0.3731
Batch 250, Loss: 0.4375
Batch 260, Loss: 0.4262
Batch 270, Loss: 0.4094
Batch 280, Loss: 0.3905
Batch 290, Loss: 0.4356
Batch 300, Loss: 0.3654
Batch 310, Loss: 0.4303
Batch 320, Loss: 0.4436
Batch 330, Loss: 0.4357
Batch 340, Loss: 0.4241
Batch 350, Loss: 0.4023
Batch 360, Loss: 0.3947
Batch 370, Loss: 0.4037
Batch 380, Loss: 0.3931
Batch 390, Loss: 0.3597
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.45405340194702 seconds
Epoch 113 accuracy: 90.44%
Batch 10, Loss: 0.4180
Batch 20, Loss: 0.3736
Batch 30, Loss: 0.3952
Batch 40, Loss: 0.3962
Batch 50, Loss: 0.3934
Batch 60, Loss: 0.3835
Batch 70, Loss: 0.4464
Batch 80, Loss: 0.3854
Batch 90, Loss: 0.3940
Batch 100, Loss: 0.3768
Batch 110, Loss: 0.3752
Batch 120, Loss: 0.4149
Batch 130, Loss: 0.4127
Batch 140, Loss: 0.4241
Batch 150, Loss: 0.3814
Batch 160, Loss: 0.3790
Batch 170, Loss: 0.4157
Batch 180, Loss: 0.3688
Batch 190, Loss: 0.3863
Batch 200, Loss: 0.3973
Batch 210, Loss: 0.3797
Batch 220, Loss: 0.4006
Batch 230, Loss: 0.4260
Batch 240, Loss: 0.3878
Batch 250, Loss: 0.4165
Batch 260, Loss: 0.4189
Batch 270, Loss: 0.4168
Batch 280, Loss: 0.4098
Batch 290, Loss: 0.3890
Batch 300, Loss: 0.3872
Batch 310, Loss: 0.3943
Batch 320, Loss: 0.4145
Batch 330, Loss: 0.3763
Batch 340, Loss: 0.4126
Batch 350, Loss: 0.4109
Batch 360, Loss: 0.3670
Batch 370, Loss: 0.4269
Batch 380, Loss: 0.4256
Batch 390, Loss: 0.4343
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.480015754699707 seconds
Epoch 114 accuracy: 89.98%
Batch 10, Loss: 0.3994
Batch 20, Loss: 0.3843
Batch 30, Loss: 0.3829
Batch 40, Loss: 0.3840
Batch 50, Loss: 0.3869
Batch 60, Loss: 0.4120
Batch 70, Loss: 0.4186
Batch 80, Loss: 0.3775
Batch 90, Loss: 0.4173
Batch 100, Loss: 0.3956
Batch 110, Loss: 0.3988
Batch 120, Loss: 0.4270
Batch 130, Loss: 0.3841
Batch 140, Loss: 0.3951
Batch 150, Loss: 0.3912
Batch 160, Loss: 0.4046
Batch 170, Loss: 0.3948
Batch 180, Loss: 0.3784
Batch 190, Loss: 0.3781
Batch 200, Loss: 0.4021
Batch 210, Loss: 0.3891
Batch 220, Loss: 0.3811
Batch 230, Loss: 0.4128
Batch 240, Loss: 0.3825
Batch 250, Loss: 0.3718
Batch 260, Loss: 0.4006
Batch 270, Loss: 0.3897
Batch 280, Loss: 0.3713
Batch 290, Loss: 0.3976
Batch 300, Loss: 0.4286
Batch 310, Loss: 0.4234
Batch 320, Loss: 0.4169
Batch 330, Loss: 0.3763
Batch 340, Loss: 0.3647
Batch 350, Loss: 0.3978
Batch 360, Loss: 0.4176
Batch 370, Loss: 0.4044
Batch 380, Loss: 0.3845
Batch 390, Loss: 0.3870
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.425782442092896 seconds
Epoch 115 accuracy: 90.38%
Batch 10, Loss: 0.3554
Batch 20, Loss: 0.3820
Batch 30, Loss: 0.4390
Batch 40, Loss: 0.4128
Batch 50, Loss: 0.4051
Batch 60, Loss: 0.3976
Batch 70, Loss: 0.3780
Batch 80, Loss: 0.3719
Batch 90, Loss: 0.3774
Batch 100, Loss: 0.4175
Batch 110, Loss: 0.3820
Batch 120, Loss: 0.4242
Batch 130, Loss: 0.3718
Batch 140, Loss: 0.4429
Batch 150, Loss: 0.3458
Batch 160, Loss: 0.4046
Batch 170, Loss: 0.3947
Batch 180, Loss: 0.4112
Batch 190, Loss: 0.3607
Batch 200, Loss: 0.4359
Batch 210, Loss: 0.3931
Batch 220, Loss: 0.3657
Batch 230, Loss: 0.3779
Batch 240, Loss: 0.3651
Batch 250, Loss: 0.3628
Batch 260, Loss: 0.3826
Batch 270, Loss: 0.4132
Batch 280, Loss: 0.4321
Batch 290, Loss: 0.3924
Batch 300, Loss: 0.4036
Batch 310, Loss: 0.3865
Batch 320, Loss: 0.3806
Batch 330, Loss: 0.4078
Batch 340, Loss: 0.3887
Batch 350, Loss: 0.3804
Batch 360, Loss: 0.4067
Batch 370, Loss: 0.3981
Batch 380, Loss: 0.3795
Batch 390, Loss: 0.4042
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.489850282669067 seconds
Epoch 116 accuracy: 89.9%
Batch 10, Loss: 0.3855
Batch 20, Loss: 0.4024
Batch 30, Loss: 0.4234
Batch 40, Loss: 0.4106
Batch 50, Loss: 0.4043
Batch 60, Loss: 0.4027
Batch 70, Loss: 0.3723
Batch 80, Loss: 0.3764
Batch 90, Loss: 0.3921
Batch 100, Loss: 0.3945
Batch 110, Loss: 0.3641
Batch 120, Loss: 0.3629
Batch 130, Loss: 0.4083
Batch 140, Loss: 0.3959
Batch 150, Loss: 0.4461
Batch 160, Loss: 0.3932
Batch 170, Loss: 0.3887
Batch 180, Loss: 0.3853
Batch 190, Loss: 0.4220
Batch 200, Loss: 0.3811
Batch 210, Loss: 0.4025
Batch 220, Loss: 0.3926
Batch 230, Loss: 0.3821
Batch 240, Loss: 0.3628
Batch 250, Loss: 0.4167
Batch 260, Loss: 0.3675
Batch 270, Loss: 0.3854
Batch 280, Loss: 0.3829
Batch 290, Loss: 0.3823
Batch 300, Loss: 0.4085
Batch 310, Loss: 0.3954
Batch 320, Loss: 0.4052
Batch 330, Loss: 0.3574
Batch 340, Loss: 0.4019
Batch 350, Loss: 0.3655
Batch 360, Loss: 0.4171
Batch 370, Loss: 0.4040
Batch 380, Loss: 0.3973
Batch 390, Loss: 0.3640
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.484838724136353 seconds
Epoch 117 accuracy: 90.16%
Batch 10, Loss: 0.3680
Batch 20, Loss: 0.4021
Batch 30, Loss: 0.4192
Batch 40, Loss: 0.3967
Batch 50, Loss: 0.3916
Batch 60, Loss: 0.3757
Batch 70, Loss: 0.3455
Batch 80, Loss: 0.3859
Batch 90, Loss: 0.4108
Batch 100, Loss: 0.3822
Batch 110, Loss: 0.4041
Batch 120, Loss: 0.3741
Batch 130, Loss: 0.3499
Batch 140, Loss: 0.4072
Batch 150, Loss: 0.3590
Batch 160, Loss: 0.4125
Batch 170, Loss: 0.3800
Batch 180, Loss: 0.4164
Batch 190, Loss: 0.3630
Batch 200, Loss: 0.3734
Batch 210, Loss: 0.4080
Batch 220, Loss: 0.3887
Batch 230, Loss: 0.3575
Batch 240, Loss: 0.4094
Batch 250, Loss: 0.3699
Batch 260, Loss: 0.3741
Batch 270, Loss: 0.3875
Batch 280, Loss: 0.3366
Batch 290, Loss: 0.4121
Batch 300, Loss: 0.3795
Batch 310, Loss: 0.3928
Batch 320, Loss: 0.4039
Batch 330, Loss: 0.3758
Batch 340, Loss: 0.3726
Batch 350, Loss: 0.3474
Batch 360, Loss: 0.3766
Batch 370, Loss: 0.3744
Batch 380, Loss: 0.3727
Batch 390, Loss: 0.4003
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.537494897842407 seconds
Epoch 118 accuracy: 89.4%
Batch 10, Loss: 0.3514
Batch 20, Loss: 0.4056
Batch 30, Loss: 0.3657
Batch 40, Loss: 0.3713
Batch 50, Loss: 0.3809
Batch 60, Loss: 0.3869
Batch 70, Loss: 0.4018
Batch 80, Loss: 0.3529
Batch 90, Loss: 0.4144
Batch 100, Loss: 0.3864
Batch 110, Loss: 0.3835
Batch 120, Loss: 0.3839
Batch 130, Loss: 0.4093
Batch 140, Loss: 0.3597
Batch 150, Loss: 0.4173
Batch 160, Loss: 0.3828
Batch 170, Loss: 0.4082
Batch 180, Loss: 0.3903
Batch 190, Loss: 0.3927
Batch 200, Loss: 0.4102
Batch 210, Loss: 0.3892
Batch 220, Loss: 0.3686
Batch 230, Loss: 0.3953
Batch 240, Loss: 0.4102
Batch 250, Loss: 0.3625
Batch 260, Loss: 0.3673
Batch 270, Loss: 0.4044
Batch 280, Loss: 0.3906
Batch 290, Loss: 0.3563
Batch 300, Loss: 0.3996
Batch 310, Loss: 0.3697
Batch 320, Loss: 0.3712
Batch 330, Loss: 0.3929
Batch 340, Loss: 0.3772
Batch 350, Loss: 0.3414
Batch 360, Loss: 0.3754
Batch 370, Loss: 0.3801
Batch 380, Loss: 0.3513
Batch 390, Loss: 0.3788
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.57561755180359 seconds
Epoch 119 accuracy: 89.7%
Batch 10, Loss: 0.3779
Batch 20, Loss: 0.3669
Batch 30, Loss: 0.3705
Batch 40, Loss: 0.3617
Batch 50, Loss: 0.3592
Batch 60, Loss: 0.4099
Batch 70, Loss: 0.3828
Batch 80, Loss: 0.3738
Batch 90, Loss: 0.3540
Batch 100, Loss: 0.3913
Batch 110, Loss: 0.3676
Batch 120, Loss: 0.3608
Batch 130, Loss: 0.3675
Batch 140, Loss: 0.3923
Batch 150, Loss: 0.4033
Batch 160, Loss: 0.3879
Batch 170, Loss: 0.4037
Batch 180, Loss: 0.3885
Batch 190, Loss: 0.3827
Batch 200, Loss: 0.3981
Batch 210, Loss: 0.3716
Batch 220, Loss: 0.3584
Batch 230, Loss: 0.3617
Batch 240, Loss: 0.3671
Batch 250, Loss: 0.4149
Batch 260, Loss: 0.4245
Batch 270, Loss: 0.3782
Batch 280, Loss: 0.3580
Batch 290, Loss: 0.3658
Batch 300, Loss: 0.3635
Batch 310, Loss: 0.3949
Batch 320, Loss: 0.3967
Batch 330, Loss: 0.4054
Batch 340, Loss: 0.3988
Batch 350, Loss: 0.3950
Batch 360, Loss: 0.4021
Batch 370, Loss: 0.4076
Batch 380, Loss: 0.3935
Batch 390, Loss: 0.3684
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.63734459877014 seconds
Epoch 120 accuracy: 90.9%
Batch 10, Loss: 0.3770
Batch 20, Loss: 0.3675
Batch 30, Loss: 0.3516
Batch 40, Loss: 0.4028
Batch 50, Loss: 0.3730
Batch 60, Loss: 0.4031
Batch 70, Loss: 0.3860
Batch 80, Loss: 0.4016
Batch 90, Loss: 0.3551
Batch 100, Loss: 0.3956
Batch 110, Loss: 0.3586
Batch 120, Loss: 0.4296
Batch 130, Loss: 0.3794
Batch 140, Loss: 0.3545
Batch 150, Loss: 0.3608
Batch 160, Loss: 0.3781
Batch 170, Loss: 0.3812
Batch 180, Loss: 0.3478
Batch 190, Loss: 0.3311
Batch 200, Loss: 0.3479
Batch 210, Loss: 0.3839
Batch 220, Loss: 0.4003
Batch 230, Loss: 0.3801
Batch 240, Loss: 0.3886
Batch 250, Loss: 0.3594
Batch 260, Loss: 0.3355
Batch 270, Loss: 0.3568
Batch 280, Loss: 0.4127
Batch 290, Loss: 0.4179
Batch 300, Loss: 0.3434
Batch 310, Loss: 0.3638
Batch 320, Loss: 0.3877
Batch 330, Loss: 0.3821
Batch 340, Loss: 0.4047
Batch 350, Loss: 0.3938
Batch 360, Loss: 0.4081
Batch 370, Loss: 0.3967
Batch 380, Loss: 0.4164
Batch 390, Loss: 0.3968
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.62494707107544 seconds
Epoch 121 accuracy: 87.28%
Batch 10, Loss: 0.3840
Batch 20, Loss: 0.3564
Batch 30, Loss: 0.3900
Batch 40, Loss: 0.3662
Batch 50, Loss: 0.3677
Batch 60, Loss: 0.3536
Batch 70, Loss: 0.3715
Batch 80, Loss: 0.3936
Batch 90, Loss: 0.3687
Batch 100, Loss: 0.3884
Batch 110, Loss: 0.3668
Batch 120, Loss: 0.3748
Batch 130, Loss: 0.3377
Batch 140, Loss: 0.4026
Batch 150, Loss: 0.3592
Batch 160, Loss: 0.3893
Batch 170, Loss: 0.4088
Batch 180, Loss: 0.3864
Batch 190, Loss: 0.3740
Batch 200, Loss: 0.4020
Batch 210, Loss: 0.3764
Batch 220, Loss: 0.3679
Batch 230, Loss: 0.3782
Batch 240, Loss: 0.3628
Batch 250, Loss: 0.3759
Batch 260, Loss: 0.3496
Batch 270, Loss: 0.3983
Batch 280, Loss: 0.3823
Batch 290, Loss: 0.3874
Batch 300, Loss: 0.3659
Batch 310, Loss: 0.3830
Batch 320, Loss: 0.3897
Batch 330, Loss: 0.3354
Batch 340, Loss: 0.3753
Batch 350, Loss: 0.3852
Batch 360, Loss: 0.4037
Batch 370, Loss: 0.3770
Batch 380, Loss: 0.4086
Batch 390, Loss: 0.3927
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.56058692932129 seconds
Epoch 122 accuracy: 91.12%
Batch 10, Loss: 0.3533
Batch 20, Loss: 0.3423
Batch 30, Loss: 0.3867
Batch 40, Loss: 0.3739
Batch 50, Loss: 0.3684
Batch 60, Loss: 0.3214
Batch 70, Loss: 0.3741
Batch 80, Loss: 0.3764
Batch 90, Loss: 0.3721
Batch 100, Loss: 0.3690
Batch 110, Loss: 0.3471
Batch 120, Loss: 0.3706
Batch 130, Loss: 0.3837
Batch 140, Loss: 0.3529
Batch 150, Loss: 0.3799
Batch 160, Loss: 0.3933
Batch 170, Loss: 0.3688
Batch 180, Loss: 0.3779
Batch 190, Loss: 0.3937
Batch 200, Loss: 0.3705
Batch 210, Loss: 0.3824
Batch 220, Loss: 0.3831
Batch 230, Loss: 0.3893
Batch 240, Loss: 0.3900
Batch 250, Loss: 0.3639
Batch 260, Loss: 0.3800
Batch 270, Loss: 0.3857
Batch 280, Loss: 0.3606
Batch 290, Loss: 0.3499
Batch 300, Loss: 0.4183
Batch 310, Loss: 0.3412
Batch 320, Loss: 0.3726
Batch 330, Loss: 0.3514
Batch 340, Loss: 0.3446
Batch 350, Loss: 0.3719
Batch 360, Loss: 0.3787
Batch 370, Loss: 0.3926
Batch 380, Loss: 0.3494
Batch 390, Loss: 0.3798
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.29959988594055 seconds
Epoch 123 accuracy: 89.33%
Batch 10, Loss: 0.3512
Batch 20, Loss: 0.4058
Batch 30, Loss: 0.3834
Batch 40, Loss: 0.3495
Batch 50, Loss: 0.3948
Batch 60, Loss: 0.3762
Batch 70, Loss: 0.3532
Batch 80, Loss: 0.3647
Batch 90, Loss: 0.3390
Batch 100, Loss: 0.3895
Batch 110, Loss: 0.3611
Batch 120, Loss: 0.3869
Batch 130, Loss: 0.3447
Batch 140, Loss: 0.3802
Batch 150, Loss: 0.3480
Batch 160, Loss: 0.3611
Batch 170, Loss: 0.3889
Batch 180, Loss: 0.3817
Batch 190, Loss: 0.3831
Batch 200, Loss: 0.3676
Batch 210, Loss: 0.3653
Batch 220, Loss: 0.3640
Batch 230, Loss: 0.3532
Batch 240, Loss: 0.3649
Batch 250, Loss: 0.3872
Batch 260, Loss: 0.4018
Batch 270, Loss: 0.3892
Batch 280, Loss: 0.3519
Batch 290, Loss: 0.3493
Batch 300, Loss: 0.3218
Batch 310, Loss: 0.3348
Batch 320, Loss: 0.3603
Batch 330, Loss: 0.3896
Batch 340, Loss: 0.3719
Batch 350, Loss: 0.3829
Batch 360, Loss: 0.3682
Batch 370, Loss: 0.3804
Batch 380, Loss: 0.3867
Batch 390, Loss: 0.4114
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.40803551673889 seconds
Epoch 124 accuracy: 87.99%
Batch 10, Loss: 0.3455
Batch 20, Loss: 0.3390
Batch 30, Loss: 0.3661
Batch 40, Loss: 0.3594
Batch 50, Loss: 0.3569
Batch 60, Loss: 0.3653
Batch 70, Loss: 0.3788
Batch 80, Loss: 0.3336
Batch 90, Loss: 0.3642
Batch 100, Loss: 0.3474
Batch 110, Loss: 0.3795
Batch 120, Loss: 0.3700
Batch 130, Loss: 0.3229
Batch 140, Loss: 0.3818
Batch 150, Loss: 0.3699
Batch 160, Loss: 0.3693
Batch 170, Loss: 0.3672
Batch 180, Loss: 0.3777
Batch 190, Loss: 0.3688
Batch 200, Loss: 0.3395
Batch 210, Loss: 0.3352
Batch 220, Loss: 0.3608
Batch 230, Loss: 0.3968
Batch 240, Loss: 0.3855
Batch 250, Loss: 0.3863
Batch 260, Loss: 0.3820
Batch 270, Loss: 0.3679
Batch 280, Loss: 0.3935
Batch 290, Loss: 0.3861
Batch 300, Loss: 0.3769
Batch 310, Loss: 0.3706
Batch 320, Loss: 0.3791
Batch 330, Loss: 0.3270
Batch 340, Loss: 0.3638
Batch 350, Loss: 0.4096
Batch 360, Loss: 0.3814
Batch 370, Loss: 0.3951
Batch 380, Loss: 0.3668
Batch 390, Loss: 0.3811
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.39325737953186 seconds
Epoch 125 accuracy: 91.74%
Batch 10, Loss: 0.3544
Batch 20, Loss: 0.3623
Batch 30, Loss: 0.3369
Batch 40, Loss: 0.3378
Batch 50, Loss: 0.3220
Batch 60, Loss: 0.3453
Batch 70, Loss: 0.3279
Batch 80, Loss: 0.4048
Batch 90, Loss: 0.3152
Batch 100, Loss: 0.3695
Batch 110, Loss: 0.3487
Batch 120, Loss: 0.3844
Batch 130, Loss: 0.3629
Batch 140, Loss: 0.3878
Batch 150, Loss: 0.3396
Batch 160, Loss: 0.3631
Batch 170, Loss: 0.3699
Batch 180, Loss: 0.3714
Batch 190, Loss: 0.3595
Batch 200, Loss: 0.3599
Batch 210, Loss: 0.3253
Batch 220, Loss: 0.3329
Batch 230, Loss: 0.3656
Batch 240, Loss: 0.3497
Batch 250, Loss: 0.3678
Batch 260, Loss: 0.3442
Batch 270, Loss: 0.3478
Batch 280, Loss: 0.3649
Batch 290, Loss: 0.3751
Batch 300, Loss: 0.3723
Batch 310, Loss: 0.3771
Batch 320, Loss: 0.3538
Batch 330, Loss: 0.3665
Batch 340, Loss: 0.3761
Batch 350, Loss: 0.3672
Batch 360, Loss: 0.3818
Batch 370, Loss: 0.3675
Batch 380, Loss: 0.3569
Batch 390, Loss: 0.3736
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.326582193374634 seconds
Epoch 126 accuracy: 90.88%
Batch 10, Loss: 0.3522
Batch 20, Loss: 0.3369
Batch 30, Loss: 0.3451
Batch 40, Loss: 0.3426
Batch 50, Loss: 0.3360
Batch 60, Loss: 0.3468
Batch 70, Loss: 0.3791
Batch 80, Loss: 0.3547
Batch 90, Loss: 0.3482
Batch 100, Loss: 0.3693
Batch 110, Loss: 0.3497
Batch 120, Loss: 0.3829
Batch 130, Loss: 0.3833
Batch 140, Loss: 0.3683
Batch 150, Loss: 0.3629
Batch 160, Loss: 0.3390
Batch 170, Loss: 0.3426
Batch 180, Loss: 0.3684
Batch 190, Loss: 0.3587
Batch 200, Loss: 0.3583
Batch 210, Loss: 0.3494
Batch 220, Loss: 0.3683
Batch 230, Loss: 0.3582
Batch 240, Loss: 0.3630
Batch 250, Loss: 0.3613
Batch 260, Loss: 0.3489
Batch 270, Loss: 0.3610
Batch 280, Loss: 0.3411
Batch 290, Loss: 0.3734
Batch 300, Loss: 0.3863
Batch 310, Loss: 0.3443
Batch 320, Loss: 0.3749
Batch 330, Loss: 0.3625
Batch 340, Loss: 0.3732
Batch 350, Loss: 0.3716
Batch 360, Loss: 0.3338
Batch 370, Loss: 0.3554
Batch 380, Loss: 0.3608
Batch 390, Loss: 0.3698
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.601863622665405 seconds
Epoch 127 accuracy: 90.27%
Batch 10, Loss: 0.3540
Batch 20, Loss: 0.3741
Batch 30, Loss: 0.3845
Batch 40, Loss: 0.3182
Batch 50, Loss: 0.3363
Batch 60, Loss: 0.3584
Batch 70, Loss: 0.3717
Batch 80, Loss: 0.3413
Batch 90, Loss: 0.3193
Batch 100, Loss: 0.3640
Batch 110, Loss: 0.3778
Batch 120, Loss: 0.3489
Batch 130, Loss: 0.3544
Batch 140, Loss: 0.4034
Batch 150, Loss: 0.3663
Batch 160, Loss: 0.3352
Batch 170, Loss: 0.3233
Batch 180, Loss: 0.3713
Batch 190, Loss: 0.3271
Batch 200, Loss: 0.3276
Batch 210, Loss: 0.3568
Batch 220, Loss: 0.3401
Batch 230, Loss: 0.3104
Batch 240, Loss: 0.3842
Batch 250, Loss: 0.3979
Batch 260, Loss: 0.3546
Batch 270, Loss: 0.3829
Batch 280, Loss: 0.3451
Batch 290, Loss: 0.3292
Batch 300, Loss: 0.3416
Batch 310, Loss: 0.3502
Batch 320, Loss: 0.3614
Batch 330, Loss: 0.3579
Batch 340, Loss: 0.3654
Batch 350, Loss: 0.3434
Batch 360, Loss: 0.3687
Batch 370, Loss: 0.3518
Batch 380, Loss: 0.3923
Batch 390, Loss: 0.3504
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.597338676452637 seconds
Epoch 128 accuracy: 91.34%
Batch 10, Loss: 0.3492
Batch 20, Loss: 0.3368
Batch 30, Loss: 0.3509
Batch 40, Loss: 0.3175
Batch 50, Loss: 0.3576
Batch 60, Loss: 0.3589
Batch 70, Loss: 0.3213
Batch 80, Loss: 0.3282
Batch 90, Loss: 0.3564
Batch 100, Loss: 0.3432
Batch 110, Loss: 0.3726
Batch 120, Loss: 0.3952
Batch 130, Loss: 0.3775
Batch 140, Loss: 0.3555
Batch 150, Loss: 0.3363
Batch 160, Loss: 0.3284
Batch 170, Loss: 0.3661
Batch 180, Loss: 0.3509
Batch 190, Loss: 0.3583
Batch 200, Loss: 0.3502
Batch 210, Loss: 0.3793
Batch 220, Loss: 0.3591
Batch 230, Loss: 0.3692
Batch 240, Loss: 0.3645
Batch 250, Loss: 0.3555
Batch 260, Loss: 0.3688
Batch 270, Loss: 0.3726
Batch 280, Loss: 0.3538
Batch 290, Loss: 0.3474
Batch 300, Loss: 0.3542
Batch 310, Loss: 0.3635
Batch 320, Loss: 0.3592
Batch 330, Loss: 0.3681
Batch 340, Loss: 0.3753
Batch 350, Loss: 0.3828
Batch 360, Loss: 0.3592
Batch 370, Loss: 0.3256
Batch 380, Loss: 0.3640
Batch 390, Loss: 0.3528
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.52972388267517 seconds
Epoch 129 accuracy: 91.67%
Batch 10, Loss: 0.3203
Batch 20, Loss: 0.3323
Batch 30, Loss: 0.3162
Batch 40, Loss: 0.3072
Batch 50, Loss: 0.3322
Batch 60, Loss: 0.3688
Batch 70, Loss: 0.3637
Batch 80, Loss: 0.3626
Batch 90, Loss: 0.3446
Batch 100, Loss: 0.3551
Batch 110, Loss: 0.3312
Batch 120, Loss: 0.3511
Batch 130, Loss: 0.3670
Batch 140, Loss: 0.3571
Batch 150, Loss: 0.3092
Batch 160, Loss: 0.3566
Batch 170, Loss: 0.3566
Batch 180, Loss: 0.3690
Batch 190, Loss: 0.3657
Batch 200, Loss: 0.3683
Batch 210, Loss: 0.3712
Batch 220, Loss: 0.3636
Batch 230, Loss: 0.3520
Batch 240, Loss: 0.3355
Batch 250, Loss: 0.3159
Batch 260, Loss: 0.3365
Batch 270, Loss: 0.3393
Batch 280, Loss: 0.3404
Batch 290, Loss: 0.3585
Batch 300, Loss: 0.3443
Batch 310, Loss: 0.3401
Batch 320, Loss: 0.3847
Batch 330, Loss: 0.3569
Batch 340, Loss: 0.3487
Batch 350, Loss: 0.3290
Batch 360, Loss: 0.3411
Batch 370, Loss: 0.3218
Batch 380, Loss: 0.3581
Batch 390, Loss: 0.3646
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.52357840538025 seconds
Epoch 130 accuracy: 91.22%
Batch 10, Loss: 0.3550
Batch 20, Loss: 0.3533
Batch 30, Loss: 0.3494
Batch 40, Loss: 0.3312
Batch 50, Loss: 0.3556
Batch 60, Loss: 0.3641
Batch 70, Loss: 0.3381
Batch 80, Loss: 0.3583
Batch 90, Loss: 0.3512
Batch 100, Loss: 0.3279
Batch 110, Loss: 0.3549
Batch 120, Loss: 0.3290
Batch 130, Loss: 0.3371
Batch 140, Loss: 0.3303
Batch 150, Loss: 0.3561
Batch 160, Loss: 0.3519
Batch 170, Loss: 0.3666
Batch 180, Loss: 0.3412
Batch 190, Loss: 0.3386
Batch 200, Loss: 0.3237
Batch 210, Loss: 0.3278
Batch 220, Loss: 0.3322
Batch 230, Loss: 0.3353
Batch 240, Loss: 0.3750
Batch 250, Loss: 0.3472
Batch 260, Loss: 0.3435
Batch 270, Loss: 0.3703
Batch 280, Loss: 0.3437
Batch 290, Loss: 0.3929
Batch 300, Loss: 0.3320
Batch 310, Loss: 0.3402
Batch 320, Loss: 0.3450
Batch 330, Loss: 0.3128
Batch 340, Loss: 0.3505
Batch 350, Loss: 0.3570
Batch 360, Loss: 0.3556
Batch 370, Loss: 0.3772
Batch 380, Loss: 0.3369
Batch 390, Loss: 0.3719
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.522018432617188 seconds
Epoch 131 accuracy: 90.68%
Batch 10, Loss: 0.3719
Batch 20, Loss: 0.3639
Batch 30, Loss: 0.3448
Batch 40, Loss: 0.3368
Batch 50, Loss: 0.3373
Batch 60, Loss: 0.3204
Batch 70, Loss: 0.3275
Batch 80, Loss: 0.3387
Batch 90, Loss: 0.3532
Batch 100, Loss: 0.3506
Batch 110, Loss: 0.3046
Batch 120, Loss: 0.3273
Batch 130, Loss: 0.3083
Batch 140, Loss: 0.3393
Batch 150, Loss: 0.3397
Batch 160, Loss: 0.3489
Batch 170, Loss: 0.3506
Batch 180, Loss: 0.3318
Batch 190, Loss: 0.3480
Batch 200, Loss: 0.3150
Batch 210, Loss: 0.3686
Batch 220, Loss: 0.3558
Batch 230, Loss: 0.3378
Batch 240, Loss: 0.3069
Batch 250, Loss: 0.3309
Batch 260, Loss: 0.3193
Batch 270, Loss: 0.3282
Batch 280, Loss: 0.3691
Batch 290, Loss: 0.3381
Batch 300, Loss: 0.3488
Batch 310, Loss: 0.3345
Batch 320, Loss: 0.3636
Batch 330, Loss: 0.3391
Batch 340, Loss: 0.3403
Batch 350, Loss: 0.3545
Batch 360, Loss: 0.3714
Batch 370, Loss: 0.3183
Batch 380, Loss: 0.3332
Batch 390, Loss: 0.3356
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.40327787399292 seconds
Epoch 132 accuracy: 90.62%
Batch 10, Loss: 0.3289
Batch 20, Loss: 0.3644
Batch 30, Loss: 0.3571
Batch 40, Loss: 0.3293
Batch 50, Loss: 0.3080
Batch 60, Loss: 0.3266
Batch 70, Loss: 0.3561
Batch 80, Loss: 0.3547
Batch 90, Loss: 0.3362
Batch 100, Loss: 0.3426
Batch 110, Loss: 0.3810
Batch 120, Loss: 0.3565
Batch 130, Loss: 0.3478
Batch 140, Loss: 0.3571
Batch 150, Loss: 0.3476
Batch 160, Loss: 0.3423
Batch 170, Loss: 0.3338
Batch 180, Loss: 0.3608
Batch 190, Loss: 0.3264
Batch 200, Loss: 0.3612
Batch 210, Loss: 0.3540
Batch 220, Loss: 0.3111
Batch 230, Loss: 0.3050
Batch 240, Loss: 0.3743
Batch 250, Loss: 0.3343
Batch 260, Loss: 0.3495
Batch 270, Loss: 0.3295
Batch 280, Loss: 0.3372
Batch 290, Loss: 0.3301
Batch 300, Loss: 0.3429
Batch 310, Loss: 0.3282
Batch 320, Loss: 0.3264
Batch 330, Loss: 0.3277
Batch 340, Loss: 0.3527
Batch 350, Loss: 0.3451
Batch 360, Loss: 0.3337
Batch 370, Loss: 0.3372
Batch 380, Loss: 0.3691
Batch 390, Loss: 0.3566
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.490562915802002 seconds
Epoch 133 accuracy: 91.21%
Batch 10, Loss: 0.3064
Batch 20, Loss: 0.3200
Batch 30, Loss: 0.3103
Batch 40, Loss: 0.3064
Batch 50, Loss: 0.3180
Batch 60, Loss: 0.3807
Batch 70, Loss: 0.3251
Batch 80, Loss: 0.3323
Batch 90, Loss: 0.3413
Batch 100, Loss: 0.3239
Batch 110, Loss: 0.3225
Batch 120, Loss: 0.3301
Batch 130, Loss: 0.3357
Batch 140, Loss: 0.3180
Batch 150, Loss: 0.3323
Batch 160, Loss: 0.3658
Batch 170, Loss: 0.3128
Batch 180, Loss: 0.3617
Batch 190, Loss: 0.3277
Batch 200, Loss: 0.3081
Batch 210, Loss: 0.3416
Batch 220, Loss: 0.3393
Batch 230, Loss: 0.3362
Batch 240, Loss: 0.3595
Batch 250, Loss: 0.3741
Batch 260, Loss: 0.3621
Batch 270, Loss: 0.3121
Batch 280, Loss: 0.3748
Batch 290, Loss: 0.3176
Batch 300, Loss: 0.3356
Batch 310, Loss: 0.3534
Batch 320, Loss: 0.3665
Batch 330, Loss: 0.3595
Batch 340, Loss: 0.3422
Batch 350, Loss: 0.3601
Batch 360, Loss: 0.3222
Batch 370, Loss: 0.3639
Batch 380, Loss: 0.3386
Batch 390, Loss: 0.3491
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.427295684814453 seconds
Epoch 134 accuracy: 91.97%
Batch 10, Loss: 0.3352
Batch 20, Loss: 0.3120
Batch 30, Loss: 0.3077
Batch 40, Loss: 0.3106
Batch 50, Loss: 0.3323
Batch 60, Loss: 0.3649
Batch 70, Loss: 0.3194
Batch 80, Loss: 0.2772
Batch 90, Loss: 0.3377
Batch 100, Loss: 0.3610
Batch 110, Loss: 0.3332
Batch 120, Loss: 0.3389
Batch 130, Loss: 0.3419
Batch 140, Loss: 0.3458
Batch 150, Loss: 0.3301
Batch 160, Loss: 0.3206
Batch 170, Loss: 0.3256
Batch 180, Loss: 0.3328
Batch 190, Loss: 0.3337
Batch 200, Loss: 0.3243
Batch 210, Loss: 0.3197
Batch 220, Loss: 0.3701
Batch 230, Loss: 0.3609
Batch 240, Loss: 0.3327
Batch 250, Loss: 0.3543
Batch 260, Loss: 0.3042
Batch 270, Loss: 0.3074
Batch 280, Loss: 0.3275
Batch 290, Loss: 0.3533
Batch 300, Loss: 0.3607
Batch 310, Loss: 0.3458
Batch 320, Loss: 0.3182
Batch 330, Loss: 0.2970
Batch 340, Loss: 0.3419
Batch 350, Loss: 0.3387
Batch 360, Loss: 0.3733
Batch 370, Loss: 0.3170
Batch 380, Loss: 0.3700
Batch 390, Loss: 0.3457
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.551442623138428 seconds
Epoch 135 accuracy: 92.69%
Batch 10, Loss: 0.3097
Batch 20, Loss: 0.3291
Batch 30, Loss: 0.3268
Batch 40, Loss: 0.2950
Batch 50, Loss: 0.3629
Batch 60, Loss: 0.3469
Batch 70, Loss: 0.3517
Batch 80, Loss: 0.3386
Batch 90, Loss: 0.3322
Batch 100, Loss: 0.3165
Batch 110, Loss: 0.3309
Batch 120, Loss: 0.3107
Batch 130, Loss: 0.3452
Batch 140, Loss: 0.3352
Batch 150, Loss: 0.3038
Batch 160, Loss: 0.3200
Batch 170, Loss: 0.2948
Batch 180, Loss: 0.3241
Batch 190, Loss: 0.3671
Batch 200, Loss: 0.3219
Batch 210, Loss: 0.3324
Batch 220, Loss: 0.3435
Batch 230, Loss: 0.3140
Batch 240, Loss: 0.3102
Batch 250, Loss: 0.3371
Batch 260, Loss: 0.3474
Batch 270, Loss: 0.3325
Batch 280, Loss: 0.3239
Batch 290, Loss: 0.3158
Batch 300, Loss: 0.3113
Batch 310, Loss: 0.3423
Batch 320, Loss: 0.3249
Batch 330, Loss: 0.3169
Batch 340, Loss: 0.2826
Batch 350, Loss: 0.3361
Batch 360, Loss: 0.3192
Batch 370, Loss: 0.3203
Batch 380, Loss: 0.3629
Batch 390, Loss: 0.3619
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.30109453201294 seconds
Epoch 136 accuracy: 91.49%
Batch 10, Loss: 0.3509
Batch 20, Loss: 0.2808
Batch 30, Loss: 0.3230
Batch 40, Loss: 0.3155
Batch 50, Loss: 0.3191
Batch 60, Loss: 0.3032
Batch 70, Loss: 0.2972
Batch 80, Loss: 0.3090
Batch 90, Loss: 0.3170
Batch 100, Loss: 0.3133
Batch 110, Loss: 0.3037
Batch 120, Loss: 0.3256
Batch 130, Loss: 0.3195
Batch 140, Loss: 0.3261
Batch 150, Loss: 0.3200
Batch 160, Loss: 0.3066
Batch 170, Loss: 0.3265
Batch 180, Loss: 0.3445
Batch 190, Loss: 0.3087
Batch 200, Loss: 0.3337
Batch 210, Loss: 0.3603
Batch 220, Loss: 0.3465
Batch 230, Loss: 0.3339
Batch 240, Loss: 0.3102
Batch 250, Loss: 0.3187
Batch 260, Loss: 0.2980
Batch 270, Loss: 0.3148
Batch 280, Loss: 0.3328
Batch 290, Loss: 0.3135
Batch 300, Loss: 0.2736
Batch 310, Loss: 0.3244
Batch 320, Loss: 0.3071
Batch 330, Loss: 0.3578
Batch 340, Loss: 0.2995
Batch 350, Loss: 0.3526
Batch 360, Loss: 0.3215
Batch 370, Loss: 0.3662
Batch 380, Loss: 0.3338
Batch 390, Loss: 0.3336
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.451916456222534 seconds
Epoch 137 accuracy: 92.6%
Batch 10, Loss: 0.2899
Batch 20, Loss: 0.3284
Batch 30, Loss: 0.2905
Batch 40, Loss: 0.3392
Batch 50, Loss: 0.2969
Batch 60, Loss: 0.3029
Batch 70, Loss: 0.3261
Batch 80, Loss: 0.2885
Batch 90, Loss: 0.3206
Batch 100, Loss: 0.3400
Batch 110, Loss: 0.3257
Batch 120, Loss: 0.3071
Batch 130, Loss: 0.3212
Batch 140, Loss: 0.2983
Batch 150, Loss: 0.3042
Batch 160, Loss: 0.3282
Batch 170, Loss: 0.3422
Batch 180, Loss: 0.3282
Batch 190, Loss: 0.3495
Batch 200, Loss: 0.3292
Batch 210, Loss: 0.3493
Batch 220, Loss: 0.3093
Batch 230, Loss: 0.3139
Batch 240, Loss: 0.3032
Batch 250, Loss: 0.3187
Batch 260, Loss: 0.3322
Batch 270, Loss: 0.3037
Batch 280, Loss: 0.3224
Batch 290, Loss: 0.3182
Batch 300, Loss: 0.3332
Batch 310, Loss: 0.3576
Batch 320, Loss: 0.3362
Batch 330, Loss: 0.3364
Batch 340, Loss: 0.2550
Batch 350, Loss: 0.3237
Batch 360, Loss: 0.3344
Batch 370, Loss: 0.3375
Batch 380, Loss: 0.3273
Batch 390, Loss: 0.3206
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.468198537826538 seconds
Epoch 138 accuracy: 92.18%
Batch 10, Loss: 0.3273
Batch 20, Loss: 0.3363
Batch 30, Loss: 0.3326
Batch 40, Loss: 0.3333
Batch 50, Loss: 0.3360
Batch 60, Loss: 0.3262
Batch 70, Loss: 0.3297
Batch 80, Loss: 0.3223
Batch 90, Loss: 0.3064
Batch 100, Loss: 0.3037
Batch 110, Loss: 0.2989
Batch 120, Loss: 0.3100
Batch 130, Loss: 0.3591
Batch 140, Loss: 0.3112
Batch 150, Loss: 0.3171
Batch 160, Loss: 0.2874
Batch 170, Loss: 0.3272
Batch 180, Loss: 0.3526
Batch 190, Loss: 0.3190
Batch 200, Loss: 0.3246
Batch 210, Loss: 0.2944
Batch 220, Loss: 0.3149
Batch 230, Loss: 0.3040
Batch 240, Loss: 0.2954
Batch 250, Loss: 0.3179
Batch 260, Loss: 0.2980
Batch 270, Loss: 0.3206
Batch 280, Loss: 0.3406
Batch 290, Loss: 0.3326
Batch 300, Loss: 0.3004
Batch 310, Loss: 0.3694
Batch 320, Loss: 0.3097
Batch 330, Loss: 0.3120
Batch 340, Loss: 0.3054
Batch 350, Loss: 0.3370
Batch 360, Loss: 0.3514
Batch 370, Loss: 0.3317
Batch 380, Loss: 0.3265
Batch 390, Loss: 0.3130
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.454622507095337 seconds
Epoch 139 accuracy: 91.37%
Batch 10, Loss: 0.3211
Batch 20, Loss: 0.3164
Batch 30, Loss: 0.2801
Batch 40, Loss: 0.3162
Batch 50, Loss: 0.3249
Batch 60, Loss: 0.3371
Batch 70, Loss: 0.3320
Batch 80, Loss: 0.3272
Batch 90, Loss: 0.3340
Batch 100, Loss: 0.3137
Batch 110, Loss: 0.3181
Batch 120, Loss: 0.3092
Batch 130, Loss: 0.3176
Batch 140, Loss: 0.3417
Batch 150, Loss: 0.3255
Batch 160, Loss: 0.2811
Batch 170, Loss: 0.3170
Batch 180, Loss: 0.3174
Batch 190, Loss: 0.2923
Batch 200, Loss: 0.2593
Batch 210, Loss: 0.3123
Batch 220, Loss: 0.3150
Batch 230, Loss: 0.3180
Batch 240, Loss: 0.3171
Batch 250, Loss: 0.2800
Batch 260, Loss: 0.3311
Batch 270, Loss: 0.3273
Batch 280, Loss: 0.3414
Batch 290, Loss: 0.3014
Batch 300, Loss: 0.3361
Batch 310, Loss: 0.3396
Batch 320, Loss: 0.3139
Batch 330, Loss: 0.3156
Batch 340, Loss: 0.3176
Batch 350, Loss: 0.3097
Batch 360, Loss: 0.3331
Batch 370, Loss: 0.3412
Batch 380, Loss: 0.3142
Batch 390, Loss: 0.3255
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.354090929031372 seconds
Epoch 140 accuracy: 91.72%
Batch 10, Loss: 0.3318
Batch 20, Loss: 0.2950
Batch 30, Loss: 0.3141
Batch 40, Loss: 0.2973
Batch 50, Loss: 0.2730
Batch 60, Loss: 0.3104
Batch 70, Loss: 0.3137
Batch 80, Loss: 0.3259
Batch 90, Loss: 0.2812
Batch 100, Loss: 0.2954
Batch 110, Loss: 0.3297
Batch 120, Loss: 0.3008
Batch 130, Loss: 0.3088
Batch 140, Loss: 0.3138
Batch 150, Loss: 0.2986
Batch 160, Loss: 0.2779
Batch 170, Loss: 0.3215
Batch 180, Loss: 0.3338
Batch 190, Loss: 0.2966
Batch 200, Loss: 0.3117
Batch 210, Loss: 0.3087
Batch 220, Loss: 0.3085
Batch 230, Loss: 0.2937
Batch 240, Loss: 0.3099
Batch 250, Loss: 0.2985
Batch 260, Loss: 0.3111
Batch 270, Loss: 0.3104
Batch 280, Loss: 0.3339
Batch 290, Loss: 0.3349
Batch 300, Loss: 0.3233
Batch 310, Loss: 0.3120
Batch 320, Loss: 0.3090
Batch 330, Loss: 0.3224
Batch 340, Loss: 0.3115
Batch 350, Loss: 0.2976
Batch 360, Loss: 0.3232
Batch 370, Loss: 0.3135
Batch 380, Loss: 0.3330
Batch 390, Loss: 0.3020
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.349976778030396 seconds
Epoch 141 accuracy: 92.8%
Batch 10, Loss: 0.3032
Batch 20, Loss: 0.2904
Batch 30, Loss: 0.2932
Batch 40, Loss: 0.2984
Batch 50, Loss: 0.2947
Batch 60, Loss: 0.2838
Batch 70, Loss: 0.3208
Batch 80, Loss: 0.2926
Batch 90, Loss: 0.3215
Batch 100, Loss: 0.3146
Batch 110, Loss: 0.3294
Batch 120, Loss: 0.3193
Batch 130, Loss: 0.2918
Batch 140, Loss: 0.3022
Batch 150, Loss: 0.3093
Batch 160, Loss: 0.2845
Batch 170, Loss: 0.3420
Batch 180, Loss: 0.3152
Batch 190, Loss: 0.3079
Batch 200, Loss: 0.3204
Batch 210, Loss: 0.2996
Batch 220, Loss: 0.3191
Batch 230, Loss: 0.2891
Batch 240, Loss: 0.3185
Batch 250, Loss: 0.3142
Batch 260, Loss: 0.2909
Batch 270, Loss: 0.2722
Batch 280, Loss: 0.2795
Batch 290, Loss: 0.3060
Batch 300, Loss: 0.3159
Batch 310, Loss: 0.3019
Batch 320, Loss: 0.2854
Batch 330, Loss: 0.2777
Batch 340, Loss: 0.2870
Batch 350, Loss: 0.3035
Batch 360, Loss: 0.3028
Batch 370, Loss: 0.3351
Batch 380, Loss: 0.3084
Batch 390, Loss: 0.3335
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.439372539520264 seconds
Epoch 142 accuracy: 92.13%
Batch 10, Loss: 0.2973
Batch 20, Loss: 0.2843
Batch 30, Loss: 0.3536
Batch 40, Loss: 0.3129
Batch 50, Loss: 0.2872
Batch 60, Loss: 0.3249
Batch 70, Loss: 0.2927
Batch 80, Loss: 0.3076
Batch 90, Loss: 0.2932
Batch 100, Loss: 0.2973
Batch 110, Loss: 0.2863
Batch 120, Loss: 0.3254
Batch 130, Loss: 0.2983
Batch 140, Loss: 0.2857
Batch 150, Loss: 0.3061
Batch 160, Loss: 0.2994
Batch 170, Loss: 0.2986
Batch 180, Loss: 0.3169
Batch 190, Loss: 0.3210
Batch 200, Loss: 0.2772
Batch 210, Loss: 0.3070
Batch 220, Loss: 0.3326
Batch 230, Loss: 0.3300
Batch 240, Loss: 0.3114
Batch 250, Loss: 0.3173
Batch 260, Loss: 0.2741
Batch 270, Loss: 0.2860
Batch 280, Loss: 0.3113
Batch 290, Loss: 0.3095
Batch 300, Loss: 0.3080
Batch 310, Loss: 0.2862
Batch 320, Loss: 0.3221
Batch 330, Loss: 0.2938
Batch 340, Loss: 0.3038
Batch 350, Loss: 0.3008
Batch 360, Loss: 0.2888
Batch 370, Loss: 0.3114
Batch 380, Loss: 0.3030
Batch 390, Loss: 0.3213
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.511897087097168 seconds
Epoch 143 accuracy: 92.82%
Batch 10, Loss: 0.2944
Batch 20, Loss: 0.2879
Batch 30, Loss: 0.3049
Batch 40, Loss: 0.2844
Batch 50, Loss: 0.3016
Batch 60, Loss: 0.2696
Batch 70, Loss: 0.3081
Batch 80, Loss: 0.2851
Batch 90, Loss: 0.2722
Batch 100, Loss: 0.2989
Batch 110, Loss: 0.2797
Batch 120, Loss: 0.2890
Batch 130, Loss: 0.3187
Batch 140, Loss: 0.3082
Batch 150, Loss: 0.2881
Batch 160, Loss: 0.3231
Batch 170, Loss: 0.3089
Batch 180, Loss: 0.2900
Batch 190, Loss: 0.2828
Batch 200, Loss: 0.2991
Batch 210, Loss: 0.2785
Batch 220, Loss: 0.3173
Batch 230, Loss: 0.2910
Batch 240, Loss: 0.2991
Batch 250, Loss: 0.3101
Batch 260, Loss: 0.3056
Batch 270, Loss: 0.3291
Batch 280, Loss: 0.3156
Batch 290, Loss: 0.2682
Batch 300, Loss: 0.2766
Batch 310, Loss: 0.3220
Batch 320, Loss: 0.2887
Batch 330, Loss: 0.3001
Batch 340, Loss: 0.3293
Batch 350, Loss: 0.3039
Batch 360, Loss: 0.3215
Batch 370, Loss: 0.2908
Batch 380, Loss: 0.2858
Batch 390, Loss: 0.3143
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.37399458885193 seconds
Epoch 144 accuracy: 93.08%
Batch 10, Loss: 0.3194
Batch 20, Loss: 0.3034
Batch 30, Loss: 0.3056
Batch 40, Loss: 0.2782
Batch 50, Loss: 0.2896
Batch 60, Loss: 0.3301
Batch 70, Loss: 0.2950
Batch 80, Loss: 0.2810
Batch 90, Loss: 0.3102
Batch 100, Loss: 0.3258
Batch 110, Loss: 0.2848
Batch 120, Loss: 0.2625
Batch 130, Loss: 0.2894
Batch 140, Loss: 0.3001
Batch 150, Loss: 0.2913
Batch 160, Loss: 0.2912
Batch 170, Loss: 0.3040
Batch 180, Loss: 0.2808
Batch 190, Loss: 0.2995
Batch 200, Loss: 0.3096
Batch 210, Loss: 0.3200
Batch 220, Loss: 0.2986
Batch 230, Loss: 0.3101
Batch 240, Loss: 0.3136
Batch 250, Loss: 0.2937
Batch 260, Loss: 0.2894
Batch 270, Loss: 0.3106
Batch 280, Loss: 0.3080
Batch 290, Loss: 0.3035
Batch 300, Loss: 0.3086
Batch 310, Loss: 0.2916
Batch 320, Loss: 0.2627
Batch 330, Loss: 0.2948
Batch 340, Loss: 0.2845
Batch 350, Loss: 0.3007
Batch 360, Loss: 0.3433
Batch 370, Loss: 0.2810
Batch 380, Loss: 0.3145
Batch 390, Loss: 0.3031
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.413167715072632 seconds
Epoch 145 accuracy: 92.92%
Batch 10, Loss: 0.2683
Batch 20, Loss: 0.3194
Batch 30, Loss: 0.2697
Batch 40, Loss: 0.3000
Batch 50, Loss: 0.2961
Batch 60, Loss: 0.2996
Batch 70, Loss: 0.3145
Batch 80, Loss: 0.3151
Batch 90, Loss: 0.2868
Batch 100, Loss: 0.3205
Batch 110, Loss: 0.2622
Batch 120, Loss: 0.2870
Batch 130, Loss: 0.2750
Batch 140, Loss: 0.2989
Batch 150, Loss: 0.2799
Batch 160, Loss: 0.3191
Batch 170, Loss: 0.2966
Batch 180, Loss: 0.2803
Batch 190, Loss: 0.2948
Batch 200, Loss: 0.2871
Batch 210, Loss: 0.3179
Batch 220, Loss: 0.2846
Batch 230, Loss: 0.3067
Batch 240, Loss: 0.3073
Batch 250, Loss: 0.3267
Batch 260, Loss: 0.2682
Batch 270, Loss: 0.2973
Batch 280, Loss: 0.3128
Batch 290, Loss: 0.2767
Batch 300, Loss: 0.2642
Batch 310, Loss: 0.2833
Batch 320, Loss: 0.2920
Batch 330, Loss: 0.2878
Batch 340, Loss: 0.3021
Batch 350, Loss: 0.3162
Batch 360, Loss: 0.2900
Batch 370, Loss: 0.3051
Batch 380, Loss: 0.2962
Batch 390, Loss: 0.3193
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.48876976966858 seconds
Epoch 146 accuracy: 91.91%
Batch 10, Loss: 0.2973
Batch 20, Loss: 0.2887
Batch 30, Loss: 0.3067
Batch 40, Loss: 0.2830
Batch 50, Loss: 0.2990
Batch 60, Loss: 0.2967
Batch 70, Loss: 0.2576
Batch 80, Loss: 0.3228
Batch 90, Loss: 0.2775
Batch 100, Loss: 0.3132
Batch 110, Loss: 0.2911
Batch 120, Loss: 0.2835
Batch 130, Loss: 0.3182
Batch 140, Loss: 0.3145
Batch 150, Loss: 0.2980
Batch 160, Loss: 0.2800
Batch 170, Loss: 0.2975
Batch 180, Loss: 0.2727
Batch 190, Loss: 0.3032
Batch 200, Loss: 0.3006
Batch 210, Loss: 0.2772
Batch 220, Loss: 0.2703
Batch 230, Loss: 0.3081
Batch 240, Loss: 0.3112
Batch 250, Loss: 0.3030
Batch 260, Loss: 0.2946
Batch 270, Loss: 0.2910
Batch 280, Loss: 0.2980
Batch 290, Loss: 0.2989
Batch 300, Loss: 0.2893
Batch 310, Loss: 0.2732
Batch 320, Loss: 0.2956
Batch 330, Loss: 0.2953
Batch 340, Loss: 0.2949
Batch 350, Loss: 0.3111
Batch 360, Loss: 0.2918
Batch 370, Loss: 0.3032
Batch 380, Loss: 0.2788
Batch 390, Loss: 0.2913
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.34958577156067 seconds
Epoch 147 accuracy: 92.59%
Batch 10, Loss: 0.2917
Batch 20, Loss: 0.3098
Batch 30, Loss: 0.2918
Batch 40, Loss: 0.2851
Batch 50, Loss: 0.2644
Batch 60, Loss: 0.2788
Batch 70, Loss: 0.2787
Batch 80, Loss: 0.2849
Batch 90, Loss: 0.2984
Batch 100, Loss: 0.2852
Batch 110, Loss: 0.2899
Batch 120, Loss: 0.2793
Batch 130, Loss: 0.3078
Batch 140, Loss: 0.2708
Batch 150, Loss: 0.2637
Batch 160, Loss: 0.3158
Batch 170, Loss: 0.2668
Batch 180, Loss: 0.2692
Batch 190, Loss: 0.2910
Batch 200, Loss: 0.3080
Batch 210, Loss: 0.3179
Batch 220, Loss: 0.2878
Batch 230, Loss: 0.2930
Batch 240, Loss: 0.2608
Batch 250, Loss: 0.2600
Batch 260, Loss: 0.2815
Batch 270, Loss: 0.3047
Batch 280, Loss: 0.2767
Batch 290, Loss: 0.3079
Batch 300, Loss: 0.2953
Batch 310, Loss: 0.2897
Batch 320, Loss: 0.3083
Batch 330, Loss: 0.2688
Batch 340, Loss: 0.2959
Batch 350, Loss: 0.2943
Batch 360, Loss: 0.2764
Batch 370, Loss: 0.3075
Batch 380, Loss: 0.3029
Batch 390, Loss: 0.3219
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.36124539375305 seconds
Epoch 148 accuracy: 93.07%
Batch 10, Loss: 0.2670
Batch 20, Loss: 0.2742
Batch 30, Loss: 0.2664
Batch 40, Loss: 0.2764
Batch 50, Loss: 0.2924
Batch 60, Loss: 0.3010
Batch 70, Loss: 0.2958
Batch 80, Loss: 0.2798
Batch 90, Loss: 0.2735
Batch 100, Loss: 0.2654
Batch 110, Loss: 0.2617
Batch 120, Loss: 0.2416
Batch 130, Loss: 0.2756
Batch 140, Loss: 0.2844
Batch 150, Loss: 0.3062
Batch 160, Loss: 0.2458
Batch 170, Loss: 0.2789
Batch 180, Loss: 0.2857
Batch 190, Loss: 0.2818
Batch 200, Loss: 0.2753
Batch 210, Loss: 0.2595
Batch 220, Loss: 0.2703
Batch 230, Loss: 0.2923
Batch 240, Loss: 0.2872
Batch 250, Loss: 0.2949
Batch 260, Loss: 0.2742
Batch 270, Loss: 0.2615
Batch 280, Loss: 0.2854
Batch 290, Loss: 0.3020
Batch 300, Loss: 0.2909
Batch 310, Loss: 0.3084
Batch 320, Loss: 0.2826
Batch 330, Loss: 0.2921
Batch 340, Loss: 0.2827
Batch 350, Loss: 0.2827
Batch 360, Loss: 0.2913
Batch 370, Loss: 0.2958
Batch 380, Loss: 0.2839
Batch 390, Loss: 0.3361
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.373242616653442 seconds
Epoch 149 accuracy: 93.34%
Batch 10, Loss: 0.2820
Batch 20, Loss: 0.2705
Batch 30, Loss: 0.2560
Batch 40, Loss: 0.2567
Batch 50, Loss: 0.2643
Batch 60, Loss: 0.2619
Batch 70, Loss: 0.2732
Batch 80, Loss: 0.2943
Batch 90, Loss: 0.2732
Batch 100, Loss: 0.2609
Batch 110, Loss: 0.2880
Batch 120, Loss: 0.2796
Batch 130, Loss: 0.2844
Batch 140, Loss: 0.2887
Batch 150, Loss: 0.2763
Batch 160, Loss: 0.2698
Batch 170, Loss: 0.2694
Batch 180, Loss: 0.3035
Batch 190, Loss: 0.2805
Batch 200, Loss: 0.2498
Batch 210, Loss: 0.2809
Batch 220, Loss: 0.2680
Batch 230, Loss: 0.2636
Batch 240, Loss: 0.2656
Batch 250, Loss: 0.2662
Batch 260, Loss: 0.2438
Batch 270, Loss: 0.2962
Batch 280, Loss: 0.2824
Batch 290, Loss: 0.2590
Batch 300, Loss: 0.2715
Batch 310, Loss: 0.2905
Batch 320, Loss: 0.2836
Batch 330, Loss: 0.2712
Batch 340, Loss: 0.2970
Batch 350, Loss: 0.2916
Batch 360, Loss: 0.2422
Batch 370, Loss: 0.3078
Batch 380, Loss: 0.2962
Batch 390, Loss: 0.2721
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.47282314300537 seconds
Epoch 150 accuracy: 93.66%
Batch 10, Loss: 0.2754
Batch 20, Loss: 0.2606
Batch 30, Loss: 0.2458
Batch 40, Loss: 0.3019
Batch 50, Loss: 0.2657
Batch 60, Loss: 0.2722
Batch 70, Loss: 0.2676
Batch 80, Loss: 0.2727
Batch 90, Loss: 0.2488
Batch 100, Loss: 0.2633
Batch 110, Loss: 0.2547
Batch 120, Loss: 0.3023
Batch 130, Loss: 0.3135
Batch 140, Loss: 0.2683
Batch 150, Loss: 0.2717
Batch 160, Loss: 0.2857
Batch 170, Loss: 0.2926
Batch 180, Loss: 0.2866
Batch 190, Loss: 0.2537
Batch 200, Loss: 0.2692
Batch 210, Loss: 0.2584
Batch 220, Loss: 0.3029
Batch 230, Loss: 0.2747
Batch 240, Loss: 0.2755
Batch 250, Loss: 0.2685
Batch 260, Loss: 0.2733
Batch 270, Loss: 0.3004
Batch 280, Loss: 0.2766
Batch 290, Loss: 0.2736
Batch 300, Loss: 0.2903
Batch 310, Loss: 0.2748
Batch 320, Loss: 0.2727
Batch 330, Loss: 0.2903
Batch 340, Loss: 0.2587
Batch 350, Loss: 0.2878
Batch 360, Loss: 0.2814
Batch 370, Loss: 0.2928
Batch 380, Loss: 0.3085
Batch 390, Loss: 0.2770
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.410794258117676 seconds
Epoch 151 accuracy: 93.11%
Batch 10, Loss: 0.2651
Batch 20, Loss: 0.2723
Batch 30, Loss: 0.2918
Batch 40, Loss: 0.2581
Batch 50, Loss: 0.2315
Batch 60, Loss: 0.2738
Batch 70, Loss: 0.2804
Batch 80, Loss: 0.2790
Batch 90, Loss: 0.2700
Batch 100, Loss: 0.2495
Batch 110, Loss: 0.2289
Batch 120, Loss: 0.2482
Batch 130, Loss: 0.2636
Batch 140, Loss: 0.2816
Batch 150, Loss: 0.2790
Batch 160, Loss: 0.2685
Batch 170, Loss: 0.2804
Batch 180, Loss: 0.2871
Batch 190, Loss: 0.2777
Batch 200, Loss: 0.2672
Batch 210, Loss: 0.2716
Batch 220, Loss: 0.2711
Batch 230, Loss: 0.2878
Batch 240, Loss: 0.2728
Batch 250, Loss: 0.2812
Batch 260, Loss: 0.2633
Batch 270, Loss: 0.3011
Batch 280, Loss: 0.2630
Batch 290, Loss: 0.2898
Batch 300, Loss: 0.2656
Batch 310, Loss: 0.2519
Batch 320, Loss: 0.2850
Batch 330, Loss: 0.2765
Batch 340, Loss: 0.2933
Batch 350, Loss: 0.2708
Batch 360, Loss: 0.2833
Batch 370, Loss: 0.2530
Batch 380, Loss: 0.2930
Batch 390, Loss: 0.2962
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.307213306427002 seconds
Epoch 152 accuracy: 93.81%
Batch 10, Loss: 0.2628
Batch 20, Loss: 0.2562
Batch 30, Loss: 0.2608
Batch 40, Loss: 0.2626
Batch 50, Loss: 0.2590
Batch 60, Loss: 0.2558
Batch 70, Loss: 0.2563
Batch 80, Loss: 0.2830
Batch 90, Loss: 0.2855
Batch 100, Loss: 0.2899
Batch 110, Loss: 0.2788
Batch 120, Loss: 0.2632
Batch 130, Loss: 0.2505
Batch 140, Loss: 0.2306
Batch 150, Loss: 0.2576
Batch 160, Loss: 0.2870
Batch 170, Loss: 0.2443
Batch 180, Loss: 0.2737
Batch 190, Loss: 0.2646
Batch 200, Loss: 0.2726
Batch 210, Loss: 0.2844
Batch 220, Loss: 0.2637
Batch 230, Loss: 0.2862
Batch 240, Loss: 0.2229
Batch 250, Loss: 0.2744
Batch 260, Loss: 0.3003
Batch 270, Loss: 0.2766
Batch 280, Loss: 0.2641
Batch 290, Loss: 0.2476
Batch 300, Loss: 0.2707
Batch 310, Loss: 0.2516
Batch 320, Loss: 0.2656
Batch 330, Loss: 0.2772
Batch 340, Loss: 0.2762
Batch 350, Loss: 0.2871
Batch 360, Loss: 0.2631
Batch 370, Loss: 0.2543
Batch 380, Loss: 0.2761
Batch 390, Loss: 0.2591
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.46323275566101 seconds
Epoch 153 accuracy: 93.76%
Batch 10, Loss: 0.2646
Batch 20, Loss: 0.2363
Batch 30, Loss: 0.2710
Batch 40, Loss: 0.2740
Batch 50, Loss: 0.2568
Batch 60, Loss: 0.2878
Batch 70, Loss: 0.2365
Batch 80, Loss: 0.1979
Batch 90, Loss: 0.2685
Batch 100, Loss: 0.2851
Batch 110, Loss: 0.2805
Batch 120, Loss: 0.2598
Batch 130, Loss: 0.2582
Batch 140, Loss: 0.2616
Batch 150, Loss: 0.2722
Batch 160, Loss: 0.2487
Batch 170, Loss: 0.2415
Batch 180, Loss: 0.2506
Batch 190, Loss: 0.2920
Batch 200, Loss: 0.2586
Batch 210, Loss: 0.2755
Batch 220, Loss: 0.2435
Batch 230, Loss: 0.2477
Batch 240, Loss: 0.2774
Batch 250, Loss: 0.2716
Batch 260, Loss: 0.2494
Batch 270, Loss: 0.2970
Batch 280, Loss: 0.2798
Batch 290, Loss: 0.2674
Batch 300, Loss: 0.2504
Batch 310, Loss: 0.2348
Batch 320, Loss: 0.2632
Batch 330, Loss: 0.2802
Batch 340, Loss: 0.2563
Batch 350, Loss: 0.2575
Batch 360, Loss: 0.2626
Batch 370, Loss: 0.2745
Batch 380, Loss: 0.2279
Batch 390, Loss: 0.2934
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.36372423171997 seconds
Epoch 154 accuracy: 93.73%
Batch 10, Loss: 0.2391
Batch 20, Loss: 0.2712
Batch 30, Loss: 0.2603
Batch 40, Loss: 0.2700
Batch 50, Loss: 0.2679
Batch 60, Loss: 0.2635
Batch 70, Loss: 0.2504
Batch 80, Loss: 0.2561
Batch 90, Loss: 0.2567
Batch 100, Loss: 0.2646
Batch 110, Loss: 0.2742
Batch 120, Loss: 0.2459
Batch 130, Loss: 0.2956
Batch 140, Loss: 0.2679
Batch 150, Loss: 0.2461
Batch 160, Loss: 0.2460
Batch 170, Loss: 0.2504
Batch 180, Loss: 0.2346
Batch 190, Loss: 0.2477
Batch 200, Loss: 0.2623
Batch 210, Loss: 0.2297
Batch 220, Loss: 0.2372
Batch 230, Loss: 0.2580
Batch 240, Loss: 0.2676
Batch 250, Loss: 0.2410
Batch 260, Loss: 0.2830
Batch 270, Loss: 0.2699
Batch 280, Loss: 0.2668
Batch 290, Loss: 0.2271
Batch 300, Loss: 0.2435
Batch 310, Loss: 0.2805
Batch 320, Loss: 0.2363
Batch 330, Loss: 0.2602
Batch 340, Loss: 0.2527
Batch 350, Loss: 0.2401
Batch 360, Loss: 0.2598
Batch 370, Loss: 0.2446
Batch 380, Loss: 0.2709
Batch 390, Loss: 0.2814
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.564654111862183 seconds
Epoch 155 accuracy: 93.91%
Batch 10, Loss: 0.2568
Batch 20, Loss: 0.2760
Batch 30, Loss: 0.2626
Batch 40, Loss: 0.2389
Batch 50, Loss: 0.2520
Batch 60, Loss: 0.2412
Batch 70, Loss: 0.2526
Batch 80, Loss: 0.2989
Batch 90, Loss: 0.2808
Batch 100, Loss: 0.2855
Batch 110, Loss: 0.2595
Batch 120, Loss: 0.2836
Batch 130, Loss: 0.2457
Batch 140, Loss: 0.2553
Batch 150, Loss: 0.2483
Batch 160, Loss: 0.2603
Batch 170, Loss: 0.2447
Batch 180, Loss: 0.2617
Batch 190, Loss: 0.2309
Batch 200, Loss: 0.2624
Batch 210, Loss: 0.2385
Batch 220, Loss: 0.2581
Batch 230, Loss: 0.2532
Batch 240, Loss: 0.2537
Batch 250, Loss: 0.2719
Batch 260, Loss: 0.2523
Batch 270, Loss: 0.2464
Batch 280, Loss: 0.2599
Batch 290, Loss: 0.2631
Batch 300, Loss: 0.2376
Batch 310, Loss: 0.2612
Batch 320, Loss: 0.2509
Batch 330, Loss: 0.2141
Batch 340, Loss: 0.2714
Batch 350, Loss: 0.2443
Batch 360, Loss: 0.2147
Batch 370, Loss: 0.2461
Batch 380, Loss: 0.2353
Batch 390, Loss: 0.2744
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.508167266845703 seconds
Epoch 156 accuracy: 94.12%
Batch 10, Loss: 0.2511
Batch 20, Loss: 0.2577
Batch 30, Loss: 0.2481
Batch 40, Loss: 0.2684
Batch 50, Loss: 0.2876
Batch 60, Loss: 0.2833
Batch 70, Loss: 0.2521
Batch 80, Loss: 0.2690
Batch 90, Loss: 0.2487
Batch 100, Loss: 0.2703
Batch 110, Loss: 0.2502
Batch 120, Loss: 0.2600
Batch 130, Loss: 0.2321
Batch 140, Loss: 0.2685
Batch 150, Loss: 0.2468
Batch 160, Loss: 0.2479
Batch 170, Loss: 0.2292
Batch 180, Loss: 0.2463
Batch 190, Loss: 0.2685
Batch 200, Loss: 0.2456
Batch 210, Loss: 0.2717
Batch 220, Loss: 0.2667
Batch 230, Loss: 0.2567
Batch 240, Loss: 0.2355
Batch 250, Loss: 0.2753
Batch 260, Loss: 0.2540
Batch 270, Loss: 0.2743
Batch 280, Loss: 0.2686
Batch 290, Loss: 0.2492
Batch 300, Loss: 0.2775
Batch 310, Loss: 0.2497
Batch 320, Loss: 0.2644
Batch 330, Loss: 0.2447
Batch 340, Loss: 0.2842
Batch 350, Loss: 0.2500
Batch 360, Loss: 0.2410
Batch 370, Loss: 0.2527
Batch 380, Loss: 0.2263
Batch 390, Loss: 0.2481
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.39407968521118 seconds
Epoch 157 accuracy: 93.77%
Batch 10, Loss: 0.2523
Batch 20, Loss: 0.2525
Batch 30, Loss: 0.2698
Batch 40, Loss: 0.2565
Batch 50, Loss: 0.2795
Batch 60, Loss: 0.2632
Batch 70, Loss: 0.2391
Batch 80, Loss: 0.2464
Batch 90, Loss: 0.2517
Batch 100, Loss: 0.2364
Batch 110, Loss: 0.2325
Batch 120, Loss: 0.2508
Batch 130, Loss: 0.2489
Batch 140, Loss: 0.2484
Batch 150, Loss: 0.2525
Batch 160, Loss: 0.2560
Batch 170, Loss: 0.2474
Batch 180, Loss: 0.2483
Batch 190, Loss: 0.2336
Batch 200, Loss: 0.2314
Batch 210, Loss: 0.2562
Batch 220, Loss: 0.2294
Batch 230, Loss: 0.2486
Batch 240, Loss: 0.2422
Batch 250, Loss: 0.2171
Batch 260, Loss: 0.2535
Batch 270, Loss: 0.2887
Batch 280, Loss: 0.2484
Batch 290, Loss: 0.2347
Batch 300, Loss: 0.2632
Batch 310, Loss: 0.2466
Batch 320, Loss: 0.2443
Batch 330, Loss: 0.2437
Batch 340, Loss: 0.2517
Batch 350, Loss: 0.2547
Batch 360, Loss: 0.2402
Batch 370, Loss: 0.2722
Batch 380, Loss: 0.2514
Batch 390, Loss: 0.2451
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.436256647109985 seconds
Epoch 158 accuracy: 94.07%
Batch 10, Loss: 0.2634
Batch 20, Loss: 0.2251
Batch 30, Loss: 0.2255
Batch 40, Loss: 0.2306
Batch 50, Loss: 0.2279
Batch 60, Loss: 0.2378
Batch 70, Loss: 0.2470
Batch 80, Loss: 0.2150
Batch 90, Loss: 0.2559
Batch 100, Loss: 0.2548
Batch 110, Loss: 0.2346
Batch 120, Loss: 0.1867
Batch 130, Loss: 0.2474
Batch 140, Loss: 0.2231
Batch 150, Loss: 0.2104
Batch 160, Loss: 0.2263
Batch 170, Loss: 0.2524
Batch 180, Loss: 0.2429
Batch 190, Loss: 0.2427
Batch 200, Loss: 0.2525
Batch 210, Loss: 0.2673
Batch 220, Loss: 0.2340
Batch 230, Loss: 0.2517
Batch 240, Loss: 0.2346
Batch 250, Loss: 0.2455
Batch 260, Loss: 0.2681
Batch 270, Loss: 0.2741
Batch 280, Loss: 0.2735
Batch 290, Loss: 0.2477
Batch 300, Loss: 0.2585
Batch 310, Loss: 0.2430
Batch 320, Loss: 0.2355
Batch 330, Loss: 0.2295
Batch 340, Loss: 0.2180
Batch 350, Loss: 0.2408
Batch 360, Loss: 0.2396
Batch 370, Loss: 0.2187
Batch 380, Loss: 0.2586
Batch 390, Loss: 0.2787
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.42274785041809 seconds
Epoch 159 accuracy: 94.25%
Batch 10, Loss: 0.2131
Batch 20, Loss: 0.2193
Batch 30, Loss: 0.2431
Batch 40, Loss: 0.2235
Batch 50, Loss: 0.2116
Batch 60, Loss: 0.2188
Batch 70, Loss: 0.2531
Batch 80, Loss: 0.2582
Batch 90, Loss: 0.2852
Batch 100, Loss: 0.2286
Batch 110, Loss: 0.2499
Batch 120, Loss: 0.2166
Batch 130, Loss: 0.2531
Batch 140, Loss: 0.2261
Batch 150, Loss: 0.2377
Batch 160, Loss: 0.2274
Batch 170, Loss: 0.2206
Batch 180, Loss: 0.2364
Batch 190, Loss: 0.2383
Batch 200, Loss: 0.2181
Batch 210, Loss: 0.2272
Batch 220, Loss: 0.2345
Batch 230, Loss: 0.2823
Batch 240, Loss: 0.2276
Batch 250, Loss: 0.2497
Batch 260, Loss: 0.2322
Batch 270, Loss: 0.2433
Batch 280, Loss: 0.2230
Batch 290, Loss: 0.2554
Batch 300, Loss: 0.2286
Batch 310, Loss: 0.2173
Batch 320, Loss: 0.2444
Batch 330, Loss: 0.2301
Batch 340, Loss: 0.2648
Batch 350, Loss: 0.2368
Batch 360, Loss: 0.2402
Batch 370, Loss: 0.2531
Batch 380, Loss: 0.2415
Batch 390, Loss: 0.2608
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.328376054763794 seconds
Epoch 160 accuracy: 94.76%
Batch 10, Loss: 0.2129
Batch 20, Loss: 0.2173
Batch 30, Loss: 0.2644
Batch 40, Loss: 0.2435
Batch 50, Loss: 0.2089
Batch 60, Loss: 0.2236
Batch 70, Loss: 0.2314
Batch 80, Loss: 0.2110
Batch 90, Loss: 0.2192
Batch 100, Loss: 0.2288
Batch 110, Loss: 0.2485
Batch 120, Loss: 0.2052
Batch 130, Loss: 0.2437
Batch 140, Loss: 0.2450
Batch 150, Loss: 0.2395
Batch 160, Loss: 0.2385
Batch 170, Loss: 0.2382
Batch 180, Loss: 0.2237
Batch 190, Loss: 0.2306
Batch 200, Loss: 0.2304
Batch 210, Loss: 0.2272
Batch 220, Loss: 0.2721
Batch 230, Loss: 0.2357
Batch 240, Loss: 0.2472
Batch 250, Loss: 0.2385
Batch 260, Loss: 0.2419
Batch 270, Loss: 0.2610
Batch 280, Loss: 0.2327
Batch 290, Loss: 0.2295
Batch 300, Loss: 0.2304
Batch 310, Loss: 0.2107
Batch 320, Loss: 0.2372
Batch 330, Loss: 0.2215
Batch 340, Loss: 0.2172
Batch 350, Loss: 0.2414
Batch 360, Loss: 0.2322
Batch 370, Loss: 0.2267
Batch 380, Loss: 0.2337
Batch 390, Loss: 0.2532
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.356390237808228 seconds
Epoch 161 accuracy: 94.02%
Batch 10, Loss: 0.2083
Batch 20, Loss: 0.2316
Batch 30, Loss: 0.2338
Batch 40, Loss: 0.2275
Batch 50, Loss: 0.2255
Batch 60, Loss: 0.2229
Batch 70, Loss: 0.2293
Batch 80, Loss: 0.2470
Batch 90, Loss: 0.2329
Batch 100, Loss: 0.2107
Batch 110, Loss: 0.2161
Batch 120, Loss: 0.2172
Batch 130, Loss: 0.2501
Batch 140, Loss: 0.1990
Batch 150, Loss: 0.2615
Batch 160, Loss: 0.2313
Batch 170, Loss: 0.2564
Batch 180, Loss: 0.2341
Batch 190, Loss: 0.2174
Batch 200, Loss: 0.2365
Batch 210, Loss: 0.2227
Batch 220, Loss: 0.2228
Batch 230, Loss: 0.2408
Batch 240, Loss: 0.2132
Batch 250, Loss: 0.2430
Batch 260, Loss: 0.2578
Batch 270, Loss: 0.2365
Batch 280, Loss: 0.2217
Batch 290, Loss: 0.2175
Batch 300, Loss: 0.2519
Batch 310, Loss: 0.2310
Batch 320, Loss: 0.2013
Batch 330, Loss: 0.2163
Batch 340, Loss: 0.2287
Batch 350, Loss: 0.2239
Batch 360, Loss: 0.2331
Batch 370, Loss: 0.2373
Batch 380, Loss: 0.2497
Batch 390, Loss: 0.2237
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.455522775650024 seconds
Epoch 162 accuracy: 94.19%
Batch 10, Loss: 0.2334
Batch 20, Loss: 0.2074
Batch 30, Loss: 0.2365
Batch 40, Loss: 0.2127
Batch 50, Loss: 0.2018
Batch 60, Loss: 0.2436
Batch 70, Loss: 0.2269
Batch 80, Loss: 0.2396
Batch 90, Loss: 0.2361
Batch 100, Loss: 0.2177
Batch 110, Loss: 0.2567
Batch 120, Loss: 0.2289
Batch 130, Loss: 0.2378
Batch 140, Loss: 0.2105
Batch 150, Loss: 0.2100
Batch 160, Loss: 0.2203
Batch 170, Loss: 0.2523
Batch 180, Loss: 0.2635
Batch 190, Loss: 0.2089
Batch 200, Loss: 0.2483
Batch 210, Loss: 0.2348
Batch 220, Loss: 0.2317
Batch 230, Loss: 0.2269
Batch 240, Loss: 0.2403
Batch 250, Loss: 0.2237
Batch 260, Loss: 0.2243
Batch 270, Loss: 0.1858
Batch 280, Loss: 0.2123
Batch 290, Loss: 0.2446
Batch 300, Loss: 0.2170
Batch 310, Loss: 0.2098
Batch 320, Loss: 0.2084
Batch 330, Loss: 0.2371
Batch 340, Loss: 0.2260
Batch 350, Loss: 0.2364
Batch 360, Loss: 0.2351
Batch 370, Loss: 0.2491
Batch 380, Loss: 0.2413
Batch 390, Loss: 0.2467
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.538627862930298 seconds
Epoch 163 accuracy: 94.59%
Batch 10, Loss: 0.2160
Batch 20, Loss: 0.2476
Batch 30, Loss: 0.1871
Batch 40, Loss: 0.2264
Batch 50, Loss: 0.2035
Batch 60, Loss: 0.1949
Batch 70, Loss: 0.2396
Batch 80, Loss: 0.2107
Batch 90, Loss: 0.2193
Batch 100, Loss: 0.2301
Batch 110, Loss: 0.1941
Batch 120, Loss: 0.2219
Batch 130, Loss: 0.2050
Batch 140, Loss: 0.2336
Batch 150, Loss: 0.2337
Batch 160, Loss: 0.2152
Batch 170, Loss: 0.2163
Batch 180, Loss: 0.2002
Batch 190, Loss: 0.2210
Batch 200, Loss: 0.2304
Batch 210, Loss: 0.2007
Batch 220, Loss: 0.2329
Batch 230, Loss: 0.2107
Batch 240, Loss: 0.2312
Batch 250, Loss: 0.2254
Batch 260, Loss: 0.2092
Batch 270, Loss: 0.2236
Batch 280, Loss: 0.1942
Batch 290, Loss: 0.2316
Batch 300, Loss: 0.2426
Batch 310, Loss: 0.2371
Batch 320, Loss: 0.2419
Batch 330, Loss: 0.2109
Batch 340, Loss: 0.2279
Batch 350, Loss: 0.2182
Batch 360, Loss: 0.2367
Batch 370, Loss: 0.2279
Batch 380, Loss: 0.2418
Batch 390, Loss: 0.2303
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.47954487800598 seconds
Epoch 164 accuracy: 94.41%
Batch 10, Loss: 0.2029
Batch 20, Loss: 0.2174
Batch 30, Loss: 0.2425
Batch 40, Loss: 0.1909
Batch 50, Loss: 0.2149
Batch 60, Loss: 0.2109
Batch 70, Loss: 0.2376
Batch 80, Loss: 0.2294
Batch 90, Loss: 0.2294
Batch 100, Loss: 0.2121
Batch 110, Loss: 0.2310
Batch 120, Loss: 0.2254
Batch 130, Loss: 0.2335
Batch 140, Loss: 0.2263
Batch 150, Loss: 0.2196
Batch 160, Loss: 0.2236
Batch 170, Loss: 0.2178
Batch 180, Loss: 0.2217
Batch 190, Loss: 0.1962
Batch 200, Loss: 0.2191
Batch 210, Loss: 0.2324
Batch 220, Loss: 0.2389
Batch 230, Loss: 0.2206
Batch 240, Loss: 0.2124
Batch 250, Loss: 0.2245
Batch 260, Loss: 0.2126
Batch 270, Loss: 0.1987
Batch 280, Loss: 0.2299
Batch 290, Loss: 0.2310
Batch 300, Loss: 0.2158
Batch 310, Loss: 0.2261
Batch 320, Loss: 0.1827
Batch 330, Loss: 0.2339
Batch 340, Loss: 0.2428
Batch 350, Loss: 0.2140
Batch 360, Loss: 0.2135
Batch 370, Loss: 0.2178
Batch 380, Loss: 0.2197
Batch 390, Loss: 0.2115
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.52537965774536 seconds
Epoch 165 accuracy: 94.86%
Batch 10, Loss: 0.2182
Batch 20, Loss: 0.2183
Batch 30, Loss: 0.2099
Batch 40, Loss: 0.1929
Batch 50, Loss: 0.2039
Batch 60, Loss: 0.2068
Batch 70, Loss: 0.2050
Batch 80, Loss: 0.2113
Batch 90, Loss: 0.2184
Batch 100, Loss: 0.2115
Batch 110, Loss: 0.2325
Batch 120, Loss: 0.2037
Batch 130, Loss: 0.2380
Batch 140, Loss: 0.1985
Batch 150, Loss: 0.2236
Batch 160, Loss: 0.2162
Batch 170, Loss: 0.2215
Batch 180, Loss: 0.1904
Batch 190, Loss: 0.1922
Batch 200, Loss: 0.2185
Batch 210, Loss: 0.2221
Batch 220, Loss: 0.2078
Batch 230, Loss: 0.1912
Batch 240, Loss: 0.2038
Batch 250, Loss: 0.2200
Batch 260, Loss: 0.2032
Batch 270, Loss: 0.2220
Batch 280, Loss: 0.2043
Batch 290, Loss: 0.2186
Batch 300, Loss: 0.1979
Batch 310, Loss: 0.2107
Batch 320, Loss: 0.2044
Batch 330, Loss: 0.2349
Batch 340, Loss: 0.2256
Batch 350, Loss: 0.2257
Batch 360, Loss: 0.2187
Batch 370, Loss: 0.1891
Batch 380, Loss: 0.2133
Batch 390, Loss: 0.2024
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.42574691772461 seconds
Epoch 166 accuracy: 94.8%
Batch 10, Loss: 0.2296
Batch 20, Loss: 0.1964
Batch 30, Loss: 0.2307
Batch 40, Loss: 0.2212
Batch 50, Loss: 0.2140
Batch 60, Loss: 0.2025
Batch 70, Loss: 0.2020
Batch 80, Loss: 0.1822
Batch 90, Loss: 0.1919
Batch 100, Loss: 0.2031
Batch 110, Loss: 0.2123
Batch 120, Loss: 0.2142
Batch 130, Loss: 0.2033
Batch 140, Loss: 0.2289
Batch 150, Loss: 0.2300
Batch 160, Loss: 0.1949
Batch 170, Loss: 0.2254
Batch 180, Loss: 0.2056
Batch 190, Loss: 0.2128
Batch 200, Loss: 0.2027
Batch 210, Loss: 0.1963
Batch 220, Loss: 0.1942
Batch 230, Loss: 0.2190
Batch 240, Loss: 0.2072
Batch 250, Loss: 0.1851
Batch 260, Loss: 0.1980
Batch 270, Loss: 0.2087
Batch 280, Loss: 0.2008
Batch 290, Loss: 0.2162
Batch 300, Loss: 0.2145
Batch 310, Loss: 0.2187
Batch 320, Loss: 0.2195
Batch 330, Loss: 0.2195
Batch 340, Loss: 0.1884
Batch 350, Loss: 0.2219
Batch 360, Loss: 0.2187
Batch 370, Loss: 0.2073
Batch 380, Loss: 0.2143
Batch 390, Loss: 0.2107
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.48036503791809 seconds
Epoch 167 accuracy: 95.19%
Batch 10, Loss: 0.2083
Batch 20, Loss: 0.1991
Batch 30, Loss: 0.2059
Batch 40, Loss: 0.2098
Batch 50, Loss: 0.1953
Batch 60, Loss: 0.2007
Batch 70, Loss: 0.2058
Batch 80, Loss: 0.2224
Batch 90, Loss: 0.1896
Batch 100, Loss: 0.1954
Batch 110, Loss: 0.2020
Batch 120, Loss: 0.2253
Batch 130, Loss: 0.1956
Batch 140, Loss: 0.2048
Batch 150, Loss: 0.2045
Batch 160, Loss: 0.2121
Batch 170, Loss: 0.1985
Batch 180, Loss: 0.2050
Batch 190, Loss: 0.1886
Batch 200, Loss: 0.2056
Batch 210, Loss: 0.1881
Batch 220, Loss: 0.2000
Batch 230, Loss: 0.1986
Batch 240, Loss: 0.1921
Batch 250, Loss: 0.2071
Batch 260, Loss: 0.2138
Batch 270, Loss: 0.2382
Batch 280, Loss: 0.1960
Batch 290, Loss: 0.2077
Batch 300, Loss: 0.1798
Batch 310, Loss: 0.2029
Batch 320, Loss: 0.1887
Batch 330, Loss: 0.1970
Batch 340, Loss: 0.2206
Batch 350, Loss: 0.2294
Batch 360, Loss: 0.2068
Batch 370, Loss: 0.2080
Batch 380, Loss: 0.2292
Batch 390, Loss: 0.1993
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.466476678848267 seconds
Epoch 168 accuracy: 95.21%
Batch 10, Loss: 0.1850
Batch 20, Loss: 0.1817
Batch 30, Loss: 0.1912
Batch 40, Loss: 0.1908
Batch 50, Loss: 0.2034
Batch 60, Loss: 0.1862
Batch 70, Loss: 0.1732
Batch 80, Loss: 0.2050
Batch 90, Loss: 0.2042
Batch 100, Loss: 0.1661
Batch 110, Loss: 0.1968
Batch 120, Loss: 0.2013
Batch 130, Loss: 0.2308
Batch 140, Loss: 0.1952
Batch 150, Loss: 0.2210
Batch 160, Loss: 0.2402
Batch 170, Loss: 0.2319
Batch 180, Loss: 0.2272
Batch 190, Loss: 0.1986
Batch 200, Loss: 0.2063
Batch 210, Loss: 0.2048
Batch 220, Loss: 0.2145
Batch 230, Loss: 0.2120
Batch 240, Loss: 0.1953
Batch 250, Loss: 0.1869
Batch 260, Loss: 0.1894
Batch 270, Loss: 0.2139
Batch 280, Loss: 0.1932
Batch 290, Loss: 0.1811
Batch 300, Loss: 0.2145
Batch 310, Loss: 0.1770
Batch 320, Loss: 0.1977
Batch 330, Loss: 0.2033
Batch 340, Loss: 0.2021
Batch 350, Loss: 0.1969
Batch 360, Loss: 0.2038
Batch 370, Loss: 0.1733
Batch 380, Loss: 0.2051
Batch 390, Loss: 0.2089
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.434213161468506 seconds
Epoch 169 accuracy: 94.63%
Batch 10, Loss: 0.2093
Batch 20, Loss: 0.2180
Batch 30, Loss: 0.2113
Batch 40, Loss: 0.1749
Batch 50, Loss: 0.1982
Batch 60, Loss: 0.2109
Batch 70, Loss: 0.1788
Batch 80, Loss: 0.2043
Batch 90, Loss: 0.1816
Batch 100, Loss: 0.1542
Batch 110, Loss: 0.2003
Batch 120, Loss: 0.1904
Batch 130, Loss: 0.1962
Batch 140, Loss: 0.1939
Batch 150, Loss: 0.1968
Batch 160, Loss: 0.2017
Batch 170, Loss: 0.1962
Batch 180, Loss: 0.2012
Batch 190, Loss: 0.2052
Batch 200, Loss: 0.1964
Batch 210, Loss: 0.2062
Batch 220, Loss: 0.2050
Batch 230, Loss: 0.1837
Batch 240, Loss: 0.2117
Batch 250, Loss: 0.2015
Batch 260, Loss: 0.2209
Batch 270, Loss: 0.2105
Batch 280, Loss: 0.2294
Batch 290, Loss: 0.1948
Batch 300, Loss: 0.1826
Batch 310, Loss: 0.2081
Batch 320, Loss: 0.1977
Batch 330, Loss: 0.1785
Batch 340, Loss: 0.1804
Batch 350, Loss: 0.1869
Batch 360, Loss: 0.2015
Batch 370, Loss: 0.2114
Batch 380, Loss: 0.2023
Batch 390, Loss: 0.1880
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.386552572250366 seconds
Epoch 170 accuracy: 95.35%
Batch 10, Loss: 0.1913
Batch 20, Loss: 0.1874
Batch 30, Loss: 0.1962
Batch 40, Loss: 0.1994
Batch 50, Loss: 0.1578
Batch 60, Loss: 0.2053
Batch 70, Loss: 0.1835
Batch 80, Loss: 0.1678
Batch 90, Loss: 0.1828
Batch 100, Loss: 0.1891
Batch 110, Loss: 0.2122
Batch 120, Loss: 0.1668
Batch 130, Loss: 0.1556
Batch 140, Loss: 0.2019
Batch 150, Loss: 0.1895
Batch 160, Loss: 0.1973
Batch 170, Loss: 0.1970
Batch 180, Loss: 0.2100
Batch 190, Loss: 0.1980
Batch 200, Loss: 0.1814
Batch 210, Loss: 0.1744
Batch 220, Loss: 0.2028
Batch 230, Loss: 0.2113
Batch 240, Loss: 0.1974
Batch 250, Loss: 0.1981
Batch 260, Loss: 0.1668
Batch 270, Loss: 0.2071
Batch 280, Loss: 0.1888
Batch 290, Loss: 0.1851
Batch 300, Loss: 0.2056
Batch 310, Loss: 0.1977
Batch 320, Loss: 0.1819
Batch 330, Loss: 0.1682
Batch 340, Loss: 0.2003
Batch 350, Loss: 0.1990
Batch 360, Loss: 0.1859
Batch 370, Loss: 0.2076
Batch 380, Loss: 0.1789
Batch 390, Loss: 0.2121
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.363152503967285 seconds
Epoch 171 accuracy: 95.4%
Batch 10, Loss: 0.1706
Batch 20, Loss: 0.1974
Batch 30, Loss: 0.2039
Batch 40, Loss: 0.1646
Batch 50, Loss: 0.1808
Batch 60, Loss: 0.1765
Batch 70, Loss: 0.1881
Batch 80, Loss: 0.1554
Batch 90, Loss: 0.2095
Batch 100, Loss: 0.1796
Batch 110, Loss: 0.1916
Batch 120, Loss: 0.1996
Batch 130, Loss: 0.1806
Batch 140, Loss: 0.2144
Batch 150, Loss: 0.1717
Batch 160, Loss: 0.1783
Batch 170, Loss: 0.2091
Batch 180, Loss: 0.1651
Batch 190, Loss: 0.1740
Batch 200, Loss: 0.2065
Batch 210, Loss: 0.1723
Batch 220, Loss: 0.1817
Batch 230, Loss: 0.2094
Batch 240, Loss: 0.2142
Batch 250, Loss: 0.1982
Batch 260, Loss: 0.1972
Batch 270, Loss: 0.2099
Batch 280, Loss: 0.1918
Batch 290, Loss: 0.1631
Batch 300, Loss: 0.1679
Batch 310, Loss: 0.1648
Batch 320, Loss: 0.1837
Batch 330, Loss: 0.1751
Batch 340, Loss: 0.1955
Batch 350, Loss: 0.2021
Batch 360, Loss: 0.2138
Batch 370, Loss: 0.1687
Batch 380, Loss: 0.1990
Batch 390, Loss: 0.1590
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.474907636642456 seconds
Epoch 172 accuracy: 95.55%
Batch 10, Loss: 0.1787
Batch 20, Loss: 0.1725
Batch 30, Loss: 0.2076
Batch 40, Loss: 0.1911
Batch 50, Loss: 0.1621
Batch 60, Loss: 0.1996
Batch 70, Loss: 0.1744
Batch 80, Loss: 0.1983
Batch 90, Loss: 0.1992
Batch 100, Loss: 0.1964
Batch 110, Loss: 0.1635
Batch 120, Loss: 0.1765
Batch 130, Loss: 0.1762
Batch 140, Loss: 0.1832
Batch 150, Loss: 0.2003
Batch 160, Loss: 0.1826
Batch 170, Loss: 0.1944
Batch 180, Loss: 0.1801
Batch 190, Loss: 0.1501
Batch 200, Loss: 0.1601
Batch 210, Loss: 0.1706
Batch 220, Loss: 0.1732
Batch 230, Loss: 0.1733
Batch 240, Loss: 0.2149
Batch 250, Loss: 0.1745
Batch 260, Loss: 0.1620
Batch 270, Loss: 0.1816
Batch 280, Loss: 0.2088
Batch 290, Loss: 0.1964
Batch 300, Loss: 0.1628
Batch 310, Loss: 0.1887
Batch 320, Loss: 0.1997
Batch 330, Loss: 0.1760
Batch 340, Loss: 0.1952
Batch 350, Loss: 0.1590
Batch 360, Loss: 0.1991
Batch 370, Loss: 0.2121
Batch 380, Loss: 0.1535
Batch 390, Loss: 0.1678
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.342846393585205 seconds
Epoch 173 accuracy: 95.31%
Batch 10, Loss: 0.1838
Batch 20, Loss: 0.1977
Batch 30, Loss: 0.1698
Batch 40, Loss: 0.1802
Batch 50, Loss: 0.1650
Batch 60, Loss: 0.1818
Batch 70, Loss: 0.1716
Batch 80, Loss: 0.1743
Batch 90, Loss: 0.1938
Batch 100, Loss: 0.1867
Batch 110, Loss: 0.2164
Batch 120, Loss: 0.2069
Batch 130, Loss: 0.1837
Batch 140, Loss: 0.1654
Batch 150, Loss: 0.1982
Batch 160, Loss: 0.1999
Batch 170, Loss: 0.1852
Batch 180, Loss: 0.1758
Batch 190, Loss: 0.1978
Batch 200, Loss: 0.1692
Batch 210, Loss: 0.1804
Batch 220, Loss: 0.1889
Batch 230, Loss: 0.1941
Batch 240, Loss: 0.1773
Batch 250, Loss: 0.1665
Batch 260, Loss: 0.1850
Batch 270, Loss: 0.1460
Batch 280, Loss: 0.1793
Batch 290, Loss: 0.1837
Batch 300, Loss: 0.1957
Batch 310, Loss: 0.2086
Batch 320, Loss: 0.1748
Batch 330, Loss: 0.1945
Batch 340, Loss: 0.1850
Batch 350, Loss: 0.1777
Batch 360, Loss: 0.1791
Batch 370, Loss: 0.2038
Batch 380, Loss: 0.1578
Batch 390, Loss: 0.1758
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.41572618484497 seconds
Epoch 174 accuracy: 95.6%
Batch 10, Loss: 0.1549
Batch 20, Loss: 0.2006
Batch 30, Loss: 0.1723
Batch 40, Loss: 0.1671
Batch 50, Loss: 0.1738
Batch 60, Loss: 0.1942
Batch 70, Loss: 0.1890
Batch 80, Loss: 0.1684
Batch 90, Loss: 0.1838
Batch 100, Loss: 0.1656
Batch 110, Loss: 0.1747
Batch 120, Loss: 0.1655
Batch 130, Loss: 0.1702
Batch 140, Loss: 0.1878
Batch 150, Loss: 0.1810
Batch 160, Loss: 0.1728
Batch 170, Loss: 0.1937
Batch 180, Loss: 0.1981
Batch 190, Loss: 0.1871
Batch 200, Loss: 0.1526
Batch 210, Loss: 0.1638
Batch 220, Loss: 0.2033
Batch 230, Loss: 0.1700
Batch 240, Loss: 0.2049
Batch 250, Loss: 0.1860
Batch 260, Loss: 0.1642
Batch 270, Loss: 0.1348
Batch 280, Loss: 0.1656
Batch 290, Loss: 0.1651
Batch 300, Loss: 0.1479
Batch 310, Loss: 0.1767
Batch 320, Loss: 0.1591
Batch 330, Loss: 0.1803
Batch 340, Loss: 0.1822
Batch 350, Loss: 0.1822
Batch 360, Loss: 0.1930
Batch 370, Loss: 0.1937
Batch 380, Loss: 0.1692
Batch 390, Loss: 0.1894
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.47132635116577 seconds
Epoch 175 accuracy: 95.6%
Batch 10, Loss: 0.1728
Batch 20, Loss: 0.1789
Batch 30, Loss: 0.1782
Batch 40, Loss: 0.1692
Batch 50, Loss: 0.1941
Batch 60, Loss: 0.1891
Batch 70, Loss: 0.1541
Batch 80, Loss: 0.1728
Batch 90, Loss: 0.1690
Batch 100, Loss: 0.1837
Batch 110, Loss: 0.1749
Batch 120, Loss: 0.1558
Batch 130, Loss: 0.1635
Batch 140, Loss: 0.1757
Batch 150, Loss: 0.1602
Batch 160, Loss: 0.1691
Batch 170, Loss: 0.1611
Batch 180, Loss: 0.1471
Batch 190, Loss: 0.1530
Batch 200, Loss: 0.1685
Batch 210, Loss: 0.1588
Batch 220, Loss: 0.1697
Batch 230, Loss: 0.1823
Batch 240, Loss: 0.1965
Batch 250, Loss: 0.1619
Batch 260, Loss: 0.1964
Batch 270, Loss: 0.1749
Batch 280, Loss: 0.1618
Batch 290, Loss: 0.1757
Batch 300, Loss: 0.1717
Batch 310, Loss: 0.1930
Batch 320, Loss: 0.1466
Batch 330, Loss: 0.1741
Batch 340, Loss: 0.1634
Batch 350, Loss: 0.1575
Batch 360, Loss: 0.1817
Batch 370, Loss: 0.1715
Batch 380, Loss: 0.1612
Batch 390, Loss: 0.1717
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.49216365814209 seconds
Epoch 176 accuracy: 95.56%
Batch 10, Loss: 0.1649
Batch 20, Loss: 0.1773
Batch 30, Loss: 0.1999
Batch 40, Loss: 0.1622
Batch 50, Loss: 0.1700
Batch 60, Loss: 0.1928
Batch 70, Loss: 0.1790
Batch 80, Loss: 0.1880
Batch 90, Loss: 0.1885
Batch 100, Loss: 0.1485
Batch 110, Loss: 0.1844
Batch 120, Loss: 0.1686
Batch 130, Loss: 0.1679
Batch 140, Loss: 0.1772
Batch 150, Loss: 0.1596
Batch 160, Loss: 0.1571
Batch 170, Loss: 0.1491
Batch 180, Loss: 0.1850
Batch 190, Loss: 0.1834
Batch 200, Loss: 0.1912
Batch 210, Loss: 0.1774
Batch 220, Loss: 0.1596
Batch 230, Loss: 0.1780
Batch 240, Loss: 0.1656
Batch 250, Loss: 0.1424
Batch 260, Loss: 0.1651
Batch 270, Loss: 0.1701
Batch 280, Loss: 0.1622
Batch 290, Loss: 0.1873
Batch 300, Loss: 0.1716
Batch 310, Loss: 0.1671
Batch 320, Loss: 0.1610
Batch 330, Loss: 0.1923
Batch 340, Loss: 0.1409
Batch 350, Loss: 0.1911
Batch 360, Loss: 0.1789
Batch 370, Loss: 0.1660
Batch 380, Loss: 0.1709
Batch 390, Loss: 0.1496
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.375060319900513 seconds
Epoch 177 accuracy: 95.79%
Batch 10, Loss: 0.1612
Batch 20, Loss: 0.1692
Batch 30, Loss: 0.1454
Batch 40, Loss: 0.1754
Batch 50, Loss: 0.1573
Batch 60, Loss: 0.1527
Batch 70, Loss: 0.1576
Batch 80, Loss: 0.1548
Batch 90, Loss: 0.1809
Batch 100, Loss: 0.1729
Batch 110, Loss: 0.1654
Batch 120, Loss: 0.1667
Batch 130, Loss: 0.1574
Batch 140, Loss: 0.1660
Batch 150, Loss: 0.1555
Batch 160, Loss: 0.1709
Batch 170, Loss: 0.1336
Batch 180, Loss: 0.1822
Batch 190, Loss: 0.1794
Batch 200, Loss: 0.1671
Batch 210, Loss: 0.1769
Batch 220, Loss: 0.1554
Batch 230, Loss: 0.1448
Batch 240, Loss: 0.1817
Batch 250, Loss: 0.1610
Batch 260, Loss: 0.1427
Batch 270, Loss: 0.1644
Batch 280, Loss: 0.1617
Batch 290, Loss: 0.2033
Batch 300, Loss: 0.1851
Batch 310, Loss: 0.1578
Batch 320, Loss: 0.1629
Batch 330, Loss: 0.1625
Batch 340, Loss: 0.1701
Batch 350, Loss: 0.1622
Batch 360, Loss: 0.1804
Batch 370, Loss: 0.2037
Batch 380, Loss: 0.1645
Batch 390, Loss: 0.1677
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.472511291503906 seconds
Epoch 178 accuracy: 95.69%
Batch 10, Loss: 0.1607
Batch 20, Loss: 0.1567
Batch 30, Loss: 0.1334
Batch 40, Loss: 0.1600
Batch 50, Loss: 0.1611
Batch 60, Loss: 0.1605
Batch 70, Loss: 0.1435
Batch 80, Loss: 0.1723
Batch 90, Loss: 0.1518
Batch 100, Loss: 0.1663
Batch 110, Loss: 0.1421
Batch 120, Loss: 0.1885
Batch 130, Loss: 0.1762
Batch 140, Loss: 0.1774
Batch 150, Loss: 0.1852
Batch 160, Loss: 0.1817
Batch 170, Loss: 0.1554
Batch 180, Loss: 0.1465
Batch 190, Loss: 0.1450
Batch 200, Loss: 0.1615
Batch 210, Loss: 0.1673
Batch 220, Loss: 0.1803
Batch 230, Loss: 0.1560
Batch 240, Loss: 0.1502
Batch 250, Loss: 0.1410
Batch 260, Loss: 0.1639
Batch 270, Loss: 0.1741
Batch 280, Loss: 0.1531
Batch 290, Loss: 0.1782
Batch 300, Loss: 0.1598
Batch 310, Loss: 0.1568
Batch 320, Loss: 0.1756
Batch 330, Loss: 0.1868
Batch 340, Loss: 0.1585
Batch 350, Loss: 0.1679
Batch 360, Loss: 0.1720
Batch 370, Loss: 0.1577
Batch 380, Loss: 0.1444
Batch 390, Loss: 0.1745
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.380391359329224 seconds
Epoch 179 accuracy: 95.9%
Batch 10, Loss: 0.1666
Batch 20, Loss: 0.1478
Batch 30, Loss: 0.1393
Batch 40, Loss: 0.1485
Batch 50, Loss: 0.1595
Batch 60, Loss: 0.1491
Batch 70, Loss: 0.1522
Batch 80, Loss: 0.1442
Batch 90, Loss: 0.1550
Batch 100, Loss: 0.1408
Batch 110, Loss: 0.1673
Batch 120, Loss: 0.1678
Batch 130, Loss: 0.1624
Batch 140, Loss: 0.1659
Batch 150, Loss: 0.1513
Batch 160, Loss: 0.1851
Batch 170, Loss: 0.1666
Batch 180, Loss: 0.1574
Batch 190, Loss: 0.1559
Batch 200, Loss: 0.1582
Batch 210, Loss: 0.1577
Batch 220, Loss: 0.1691
Batch 230, Loss: 0.1491
Batch 240, Loss: 0.1475
Batch 250, Loss: 0.1664
Batch 260, Loss: 0.1650
Batch 270, Loss: 0.1311
Batch 280, Loss: 0.1675
Batch 290, Loss: 0.1885
Batch 300, Loss: 0.1501
Batch 310, Loss: 0.1561
Batch 320, Loss: 0.1618
Batch 330, Loss: 0.1484
Batch 340, Loss: 0.1476
Batch 350, Loss: 0.1679
Batch 360, Loss: 0.1587
Batch 370, Loss: 0.1657
Batch 380, Loss: 0.1666
Batch 390, Loss: 0.1758
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.403650045394897 seconds
Epoch 180 accuracy: 95.75%
Batch 10, Loss: 0.1402
Batch 20, Loss: 0.1416
Batch 30, Loss: 0.1510
Batch 40, Loss: 0.1504
Batch 50, Loss: 0.1845
Batch 60, Loss: 0.1534
Batch 70, Loss: 0.1425
Batch 80, Loss: 0.1406
Batch 90, Loss: 0.1476
Batch 100, Loss: 0.1497
Batch 110, Loss: 0.1668
Batch 120, Loss: 0.1429
Batch 130, Loss: 0.1493
Batch 140, Loss: 0.1439
Batch 150, Loss: 0.1645
Batch 160, Loss: 0.1370
Batch 170, Loss: 0.1612
Batch 180, Loss: 0.1491
Batch 190, Loss: 0.1409
Batch 200, Loss: 0.1647
Batch 210, Loss: 0.1568
Batch 220, Loss: 0.1454
Batch 230, Loss: 0.1583
Batch 240, Loss: 0.1571
Batch 250, Loss: 0.1453
Batch 260, Loss: 0.1651
Batch 270, Loss: 0.1345
Batch 280, Loss: 0.1433
Batch 290, Loss: 0.1560
Batch 300, Loss: 0.1532
Batch 310, Loss: 0.1298
Batch 320, Loss: 0.1635
Batch 330, Loss: 0.1494
Batch 340, Loss: 0.1566
Batch 350, Loss: 0.1527
Batch 360, Loss: 0.1689
Batch 370, Loss: 0.1596
Batch 380, Loss: 0.1413
Batch 390, Loss: 0.1573
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.435385704040527 seconds
Epoch 181 accuracy: 96.13%
Batch 10, Loss: 0.1572
Batch 20, Loss: 0.1473
Batch 30, Loss: 0.1809
Batch 40, Loss: 0.1456
Batch 50, Loss: 0.1487
Batch 60, Loss: 0.1419
Batch 70, Loss: 0.1313
Batch 80, Loss: 0.1419
Batch 90, Loss: 0.1317
Batch 100, Loss: 0.1666
Batch 110, Loss: 0.1325
Batch 120, Loss: 0.1352
Batch 130, Loss: 0.1549
Batch 140, Loss: 0.1632
Batch 150, Loss: 0.1520
Batch 160, Loss: 0.1431
Batch 170, Loss: 0.1500
Batch 180, Loss: 0.1534
Batch 190, Loss: 0.1179
Batch 200, Loss: 0.1512
Batch 210, Loss: 0.1540
Batch 220, Loss: 0.1479
Batch 230, Loss: 0.1574
Batch 240, Loss: 0.1645
Batch 250, Loss: 0.1638
Batch 260, Loss: 0.1539
Batch 270, Loss: 0.1502
Batch 280, Loss: 0.1529
Batch 290, Loss: 0.1472
Batch 300, Loss: 0.1756
Batch 310, Loss: 0.1492
Batch 320, Loss: 0.1499
Batch 330, Loss: 0.1518
Batch 340, Loss: 0.1613
Batch 350, Loss: 0.1779
Batch 360, Loss: 0.1685
Batch 370, Loss: 0.1311
Batch 380, Loss: 0.1556
Batch 390, Loss: 0.1512
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.55257749557495 seconds
Epoch 182 accuracy: 96.03%
Batch 10, Loss: 0.1495
Batch 20, Loss: 0.1395
Batch 30, Loss: 0.1365
Batch 40, Loss: 0.1512
Batch 50, Loss: 0.1470
Batch 60, Loss: 0.1578
Batch 70, Loss: 0.1453
Batch 80, Loss: 0.1428
Batch 90, Loss: 0.1355
Batch 100, Loss: 0.1616
Batch 110, Loss: 0.1420
Batch 120, Loss: 0.1446
Batch 130, Loss: 0.1401
Batch 140, Loss: 0.1495
Batch 150, Loss: 0.1526
Batch 160, Loss: 0.1338
Batch 170, Loss: 0.1408
Batch 180, Loss: 0.1465
Batch 190, Loss: 0.1398
Batch 200, Loss: 0.1340
Batch 210, Loss: 0.1580
Batch 220, Loss: 0.1505
Batch 230, Loss: 0.1456
Batch 240, Loss: 0.1146
Batch 250, Loss: 0.1516
Batch 260, Loss: 0.1424
Batch 270, Loss: 0.1592
Batch 280, Loss: 0.1580
Batch 290, Loss: 0.1508
Batch 300, Loss: 0.1527
Batch 310, Loss: 0.1811
Batch 320, Loss: 0.1524
Batch 330, Loss: 0.1486
Batch 340, Loss: 0.1626
Batch 350, Loss: 0.1511
Batch 360, Loss: 0.1556
Batch 370, Loss: 0.1719
Batch 380, Loss: 0.1421
Batch 390, Loss: 0.1452
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.496530294418335 seconds
Epoch 183 accuracy: 96.01%
Batch 10, Loss: 0.1467
Batch 20, Loss: 0.1557
Batch 30, Loss: 0.1550
Batch 40, Loss: 0.1820
Batch 50, Loss: 0.1649
Batch 60, Loss: 0.1451
Batch 70, Loss: 0.1551
Batch 80, Loss: 0.1351
Batch 90, Loss: 0.1363
Batch 100, Loss: 0.1362
Batch 110, Loss: 0.1368
Batch 120, Loss: 0.1374
Batch 130, Loss: 0.1384
Batch 140, Loss: 0.1534
Batch 150, Loss: 0.1431
Batch 160, Loss: 0.1347
Batch 170, Loss: 0.1320
Batch 180, Loss: 0.1233
Batch 190, Loss: 0.1333
Batch 200, Loss: 0.1193
Batch 210, Loss: 0.1386
Batch 220, Loss: 0.1566
Batch 230, Loss: 0.1504
Batch 240, Loss: 0.1560
Batch 250, Loss: 0.1499
Batch 260, Loss: 0.1345
Batch 270, Loss: 0.1574
Batch 280, Loss: 0.1396
Batch 290, Loss: 0.1336
Batch 300, Loss: 0.1336
Batch 310, Loss: 0.1365
Batch 320, Loss: 0.1374
Batch 330, Loss: 0.1508
Batch 340, Loss: 0.1306
Batch 350, Loss: 0.1364
Batch 360, Loss: 0.1653
Batch 370, Loss: 0.1298
Batch 380, Loss: 0.1426
Batch 390, Loss: 0.1528
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.295976877212524 seconds
Epoch 184 accuracy: 95.93%
Batch 10, Loss: 0.1246
Batch 20, Loss: 0.1335
Batch 30, Loss: 0.1475
Batch 40, Loss: 0.1530
Batch 50, Loss: 0.1305
Batch 60, Loss: 0.1559
Batch 70, Loss: 0.1490
Batch 80, Loss: 0.1559
Batch 90, Loss: 0.1527
Batch 100, Loss: 0.1386
Batch 110, Loss: 0.1421
Batch 120, Loss: 0.1213
Batch 130, Loss: 0.1295
Batch 140, Loss: 0.1559
Batch 150, Loss: 0.1302
Batch 160, Loss: 0.1281
Batch 170, Loss: 0.1521
Batch 180, Loss: 0.1444
Batch 190, Loss: 0.1502
Batch 200, Loss: 0.1470
Batch 210, Loss: 0.1369
Batch 220, Loss: 0.1467
Batch 230, Loss: 0.1506
Batch 240, Loss: 0.1308
Batch 250, Loss: 0.1505
Batch 260, Loss: 0.1292
Batch 270, Loss: 0.1278
Batch 280, Loss: 0.1469
Batch 290, Loss: 0.1701
Batch 300, Loss: 0.1400
Batch 310, Loss: 0.1367
Batch 320, Loss: 0.1477
Batch 330, Loss: 0.1529
Batch 340, Loss: 0.1442
Batch 350, Loss: 0.1282
Batch 360, Loss: 0.1352
Batch 370, Loss: 0.1233
Batch 380, Loss: 0.1361
Batch 390, Loss: 0.1502
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.334359169006348 seconds
Epoch 185 accuracy: 96.07%
Batch 10, Loss: 0.1412
Batch 20, Loss: 0.1387
Batch 30, Loss: 0.1406
Batch 40, Loss: 0.1520
Batch 50, Loss: 0.1324
Batch 60, Loss: 0.1443
Batch 70, Loss: 0.1649
Batch 80, Loss: 0.1447
Batch 90, Loss: 0.1263
Batch 100, Loss: 0.1498
Batch 110, Loss: 0.1370
Batch 120, Loss: 0.1380
Batch 130, Loss: 0.1509
Batch 140, Loss: 0.1406
Batch 150, Loss: 0.1191
Batch 160, Loss: 0.1178
Batch 170, Loss: 0.1334
Batch 180, Loss: 0.1154
Batch 190, Loss: 0.1451
Batch 200, Loss: 0.1391
Batch 210, Loss: 0.1573
Batch 220, Loss: 0.1279
Batch 230, Loss: 0.1257
Batch 240, Loss: 0.1331
Batch 250, Loss: 0.1379
Batch 260, Loss: 0.1474
Batch 270, Loss: 0.1511
Batch 280, Loss: 0.1291
Batch 290, Loss: 0.1382
Batch 300, Loss: 0.1493
Batch 310, Loss: 0.1474
Batch 320, Loss: 0.1398
Batch 330, Loss: 0.1633
Batch 340, Loss: 0.1283
Batch 350, Loss: 0.1669
Batch 360, Loss: 0.1558
Batch 370, Loss: 0.1351
Batch 380, Loss: 0.1465
Batch 390, Loss: 0.1202
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.35035538673401 seconds
Epoch 186 accuracy: 96.04%
Batch 10, Loss: 0.1430
Batch 20, Loss: 0.1320
Batch 30, Loss: 0.1487
Batch 40, Loss: 0.1306
Batch 50, Loss: 0.1489
Batch 60, Loss: 0.1490
Batch 70, Loss: 0.1544
Batch 80, Loss: 0.1196
Batch 90, Loss: 0.1162
Batch 100, Loss: 0.1377
Batch 110, Loss: 0.1366
Batch 120, Loss: 0.1279
Batch 130, Loss: 0.1554
Batch 140, Loss: 0.1179
Batch 150, Loss: 0.1172
Batch 160, Loss: 0.1548
Batch 170, Loss: 0.1474
Batch 180, Loss: 0.1625
Batch 190, Loss: 0.1567
Batch 200, Loss: 0.1364
Batch 210, Loss: 0.1459
Batch 220, Loss: 0.1226
Batch 230, Loss: 0.1444
Batch 240, Loss: 0.1166
Batch 250, Loss: 0.1358
Batch 260, Loss: 0.1315
Batch 270, Loss: 0.1262
Batch 280, Loss: 0.1539
Batch 290, Loss: 0.1633
Batch 300, Loss: 0.1363
Batch 310, Loss: 0.1507
Batch 320, Loss: 0.1363
Batch 330, Loss: 0.1414
Batch 340, Loss: 0.1460
Batch 350, Loss: 0.1397
Batch 360, Loss: 0.1199
Batch 370, Loss: 0.1415
Batch 380, Loss: 0.1420
Batch 390, Loss: 0.1363
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.33005452156067 seconds
Epoch 187 accuracy: 96.0%
Batch 10, Loss: 0.1268
Batch 20, Loss: 0.1182
Batch 30, Loss: 0.1220
Batch 40, Loss: 0.1432
Batch 50, Loss: 0.1188
Batch 60, Loss: 0.1316
Batch 70, Loss: 0.1279
Batch 80, Loss: 0.1326
Batch 90, Loss: 0.1607
Batch 100, Loss: 0.1405
Batch 110, Loss: 0.1073
Batch 120, Loss: 0.1156
Batch 130, Loss: 0.1416
Batch 140, Loss: 0.1223
Batch 150, Loss: 0.1277
Batch 160, Loss: 0.1589
Batch 170, Loss: 0.1416
Batch 180, Loss: 0.1351
Batch 190, Loss: 0.1378
Batch 200, Loss: 0.1271
Batch 210, Loss: 0.1475
Batch 220, Loss: 0.1402
Batch 230, Loss: 0.1245
Batch 240, Loss: 0.1340
Batch 250, Loss: 0.1437
Batch 260, Loss: 0.1221
Batch 270, Loss: 0.1445
Batch 280, Loss: 0.1388
Batch 290, Loss: 0.1366
Batch 300, Loss: 0.1308
Batch 310, Loss: 0.1312
Batch 320, Loss: 0.1194
Batch 330, Loss: 0.1484
Batch 340, Loss: 0.1226
Batch 350, Loss: 0.1353
Batch 360, Loss: 0.1428
Batch 370, Loss: 0.1067
Batch 380, Loss: 0.1506
Batch 390, Loss: 0.1307
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.250118732452393 seconds
Epoch 188 accuracy: 96.09%
Batch 10, Loss: 0.1287
Batch 20, Loss: 0.1319
Batch 30, Loss: 0.1362
Batch 40, Loss: 0.1302
Batch 50, Loss: 0.1359
Batch 60, Loss: 0.1278
Batch 70, Loss: 0.1433
Batch 80, Loss: 0.1470
Batch 90, Loss: 0.1163
Batch 100, Loss: 0.1077
Batch 110, Loss: 0.1146
Batch 120, Loss: 0.1208
Batch 130, Loss: 0.1245
Batch 140, Loss: 0.1135
Batch 150, Loss: 0.1188
Batch 160, Loss: 0.1376
Batch 170, Loss: 0.1373
Batch 180, Loss: 0.1465
Batch 190, Loss: 0.1272
Batch 200, Loss: 0.1391
Batch 210, Loss: 0.1421
Batch 220, Loss: 0.1575
Batch 230, Loss: 0.1483
Batch 240, Loss: 0.1504
Batch 250, Loss: 0.1445
Batch 260, Loss: 0.1288
Batch 270, Loss: 0.1398
Batch 280, Loss: 0.1208
Batch 290, Loss: 0.1459
Batch 300, Loss: 0.1297
Batch 310, Loss: 0.1301
Batch 320, Loss: 0.1211
Batch 330, Loss: 0.1305
Batch 340, Loss: 0.1332
Batch 350, Loss: 0.1267
Batch 360, Loss: 0.1389
Batch 370, Loss: 0.1227
Batch 380, Loss: 0.1325
Batch 390, Loss: 0.1262
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.402098178863525 seconds
Epoch 189 accuracy: 96.17%
Batch 10, Loss: 0.1166
Batch 20, Loss: 0.1668
Batch 30, Loss: 0.1288
Batch 40, Loss: 0.1295
Batch 50, Loss: 0.1218
Batch 60, Loss: 0.1259
Batch 70, Loss: 0.1387
Batch 80, Loss: 0.1400
Batch 90, Loss: 0.1519
Batch 100, Loss: 0.1475
Batch 110, Loss: 0.1357
Batch 120, Loss: 0.1186
Batch 130, Loss: 0.1338
Batch 140, Loss: 0.1330
Batch 150, Loss: 0.1391
Batch 160, Loss: 0.1158
Batch 170, Loss: 0.1343
Batch 180, Loss: 0.1328
Batch 190, Loss: 0.1164
Batch 200, Loss: 0.1264
Batch 210, Loss: 0.1372
Batch 220, Loss: 0.1224
Batch 230, Loss: 0.1215
Batch 240, Loss: 0.1424
Batch 250, Loss: 0.1290
Batch 260, Loss: 0.1082
Batch 270, Loss: 0.1252
Batch 280, Loss: 0.1316
Batch 290, Loss: 0.1131
Batch 300, Loss: 0.1217
Batch 310, Loss: 0.1212
Batch 320, Loss: 0.1265
Batch 330, Loss: 0.1399
Batch 340, Loss: 0.1337
Batch 350, Loss: 0.1299
Batch 360, Loss: 0.1471
Batch 370, Loss: 0.1312
Batch 380, Loss: 0.1294
Batch 390, Loss: 0.1326
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.6091365814209 seconds
Epoch 190 accuracy: 96.31%
Batch 10, Loss: 0.1405
Batch 20, Loss: 0.1311
Batch 30, Loss: 0.1371
Batch 40, Loss: 0.1213
Batch 50, Loss: 0.1567
Batch 60, Loss: 0.1273
Batch 70, Loss: 0.1362
Batch 80, Loss: 0.1261
Batch 90, Loss: 0.1219
Batch 100, Loss: 0.1499
Batch 110, Loss: 0.1261
Batch 120, Loss: 0.1393
Batch 130, Loss: 0.1304
Batch 140, Loss: 0.1395
Batch 150, Loss: 0.1163
Batch 160, Loss: 0.1352
Batch 170, Loss: 0.1330
Batch 180, Loss: 0.1603
Batch 190, Loss: 0.1323
Batch 200, Loss: 0.1426
Batch 210, Loss: 0.1064
Batch 220, Loss: 0.1353
Batch 230, Loss: 0.1461
Batch 240, Loss: 0.1412
Batch 250, Loss: 0.1458
Batch 260, Loss: 0.1231
Batch 270, Loss: 0.1418
Batch 280, Loss: 0.1575
Batch 290, Loss: 0.1245
Batch 300, Loss: 0.1275
Batch 310, Loss: 0.1132
Batch 320, Loss: 0.1175
Batch 330, Loss: 0.1298
Batch 340, Loss: 0.1325
Batch 350, Loss: 0.1381
Batch 360, Loss: 0.1075
Batch 370, Loss: 0.1489
Batch 380, Loss: 0.1239
Batch 390, Loss: 0.1227
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.561126470565796 seconds
Epoch 191 accuracy: 96.22%
Batch 10, Loss: 0.1524
Batch 20, Loss: 0.1228
Batch 30, Loss: 0.1150
Batch 40, Loss: 0.1440
Batch 50, Loss: 0.1168
Batch 60, Loss: 0.1253
Batch 70, Loss: 0.1351
Batch 80, Loss: 0.1149
Batch 90, Loss: 0.1126
Batch 100, Loss: 0.1162
Batch 110, Loss: 0.1222
Batch 120, Loss: 0.1176
Batch 130, Loss: 0.1336
Batch 140, Loss: 0.1352
Batch 150, Loss: 0.1343
Batch 160, Loss: 0.1174
Batch 170, Loss: 0.1405
Batch 180, Loss: 0.1235
Batch 190, Loss: 0.1132
Batch 200, Loss: 0.1342
Batch 210, Loss: 0.1462
Batch 220, Loss: 0.1363
Batch 230, Loss: 0.1402
Batch 240, Loss: 0.1481
Batch 250, Loss: 0.1058
Batch 260, Loss: 0.1347
Batch 270, Loss: 0.1367
Batch 280, Loss: 0.1225
Batch 290, Loss: 0.1512
Batch 300, Loss: 0.1419
Batch 310, Loss: 0.1487
Batch 320, Loss: 0.1217
Batch 330, Loss: 0.1423
Batch 340, Loss: 0.1351
Batch 350, Loss: 0.1455
Batch 360, Loss: 0.1510
Batch 370, Loss: 0.1318
Batch 380, Loss: 0.1380
Batch 390, Loss: 0.1455
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.456233978271484 seconds
Epoch 192 accuracy: 96.14%
Batch 10, Loss: 0.1347
Batch 20, Loss: 0.1416
Batch 30, Loss: 0.1224
Batch 40, Loss: 0.1241
Batch 50, Loss: 0.1340
Batch 60, Loss: 0.1347
Batch 70, Loss: 0.1456
Batch 80, Loss: 0.1336
Batch 90, Loss: 0.1080
Batch 100, Loss: 0.1169
Batch 110, Loss: 0.1294
Batch 120, Loss: 0.1341
Batch 130, Loss: 0.1175
Batch 140, Loss: 0.1369
Batch 150, Loss: 0.1231
Batch 160, Loss: 0.1391
Batch 170, Loss: 0.1455
Batch 180, Loss: 0.1310
Batch 190, Loss: 0.1231
Batch 200, Loss: 0.1395
Batch 210, Loss: 0.1352
Batch 220, Loss: 0.1345
Batch 230, Loss: 0.1142
Batch 240, Loss: 0.1192
Batch 250, Loss: 0.1189
Batch 260, Loss: 0.1218
Batch 270, Loss: 0.1308
Batch 280, Loss: 0.1097
Batch 290, Loss: 0.1355
Batch 300, Loss: 0.1267
Batch 310, Loss: 0.1139
Batch 320, Loss: 0.1386
Batch 330, Loss: 0.1313
Batch 340, Loss: 0.1293
Batch 350, Loss: 0.1414
Batch 360, Loss: 0.1298
Batch 370, Loss: 0.1350
Batch 380, Loss: 0.1321
Batch 390, Loss: 0.1205
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.487587690353394 seconds
Epoch 193 accuracy: 96.33%
Batch 10, Loss: 0.1277
Batch 20, Loss: 0.1284
Batch 30, Loss: 0.1309
Batch 40, Loss: 0.1286
Batch 50, Loss: 0.0974
Batch 60, Loss: 0.1288
Batch 70, Loss: 0.1043
Batch 80, Loss: 0.1382
Batch 90, Loss: 0.1336
Batch 100, Loss: 0.1375
Batch 110, Loss: 0.1347
Batch 120, Loss: 0.1355
Batch 130, Loss: 0.1327
Batch 140, Loss: 0.1203
Batch 150, Loss: 0.1394
Batch 160, Loss: 0.1179
Batch 170, Loss: 0.1307
Batch 180, Loss: 0.1151
Batch 190, Loss: 0.1104
Batch 200, Loss: 0.1433
Batch 210, Loss: 0.1314
Batch 220, Loss: 0.1226
Batch 230, Loss: 0.1251
Batch 240, Loss: 0.1566
Batch 250, Loss: 0.1573
Batch 260, Loss: 0.1469
Batch 270, Loss: 0.1270
Batch 280, Loss: 0.1379
Batch 290, Loss: 0.1073
Batch 300, Loss: 0.1240
Batch 310, Loss: 0.1319
Batch 320, Loss: 0.1376
Batch 330, Loss: 0.1075
Batch 340, Loss: 0.1395
Batch 350, Loss: 0.1358
Batch 360, Loss: 0.1116
Batch 370, Loss: 0.1421
Batch 380, Loss: 0.1395
Batch 390, Loss: 0.1194
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.40668034553528 seconds
Epoch 194 accuracy: 96.18%
Batch 10, Loss: 0.1231
Batch 20, Loss: 0.1189
Batch 30, Loss: 0.1168
Batch 40, Loss: 0.1418
Batch 50, Loss: 0.1146
Batch 60, Loss: 0.1310
Batch 70, Loss: 0.1375
Batch 80, Loss: 0.1258
Batch 90, Loss: 0.1445
Batch 100, Loss: 0.1157
Batch 110, Loss: 0.1144
Batch 120, Loss: 0.1240
Batch 130, Loss: 0.1168
Batch 140, Loss: 0.1178
Batch 150, Loss: 0.1240
Batch 160, Loss: 0.1350
Batch 170, Loss: 0.1339
Batch 180, Loss: 0.1452
Batch 190, Loss: 0.1243
Batch 200, Loss: 0.1315
Batch 210, Loss: 0.1232
Batch 220, Loss: 0.1299
Batch 230, Loss: 0.1294
Batch 240, Loss: 0.1314
Batch 250, Loss: 0.1252
Batch 260, Loss: 0.1238
Batch 270, Loss: 0.1243
Batch 280, Loss: 0.1054
Batch 290, Loss: 0.1136
Batch 300, Loss: 0.1274
Batch 310, Loss: 0.1501
Batch 320, Loss: 0.1232
Batch 330, Loss: 0.1286
Batch 340, Loss: 0.1274
Batch 350, Loss: 0.1235
Batch 360, Loss: 0.1294
Batch 370, Loss: 0.1374
Batch 380, Loss: 0.1262
Batch 390, Loss: 0.1100
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.480806350708008 seconds
Epoch 195 accuracy: 96.31%
Batch 10, Loss: 0.1201
Batch 20, Loss: 0.1154
Batch 30, Loss: 0.1286
Batch 40, Loss: 0.1218
Batch 50, Loss: 0.1381
Batch 60, Loss: 0.1332
Batch 70, Loss: 0.1098
Batch 80, Loss: 0.1188
Batch 90, Loss: 0.1325
Batch 100, Loss: 0.1248
Batch 110, Loss: 0.1311
Batch 120, Loss: 0.1246
Batch 130, Loss: 0.1416
Batch 140, Loss: 0.1338
Batch 150, Loss: 0.1287
Batch 160, Loss: 0.1178
Batch 170, Loss: 0.1087
Batch 180, Loss: 0.1239
Batch 190, Loss: 0.1324
Batch 200, Loss: 0.1045
Batch 210, Loss: 0.0996
Batch 220, Loss: 0.1245
Batch 230, Loss: 0.1072
Batch 240, Loss: 0.1273
Batch 250, Loss: 0.1337
Batch 260, Loss: 0.1270
Batch 270, Loss: 0.1431
Batch 280, Loss: 0.1200
Batch 290, Loss: 0.1320
Batch 300, Loss: 0.1181
Batch 310, Loss: 0.1286
Batch 320, Loss: 0.1221
Batch 330, Loss: 0.1318
Batch 340, Loss: 0.1143
Batch 350, Loss: 0.1187
Batch 360, Loss: 0.1283
Batch 370, Loss: 0.1212
Batch 380, Loss: 0.1322
Batch 390, Loss: 0.1326
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.51438593864441 seconds
Epoch 196 accuracy: 96.38%
Batch 10, Loss: 0.1038
Batch 20, Loss: 0.1050
Batch 30, Loss: 0.1441
Batch 40, Loss: 0.1317
Batch 50, Loss: 0.1342
Batch 60, Loss: 0.1050
Batch 70, Loss: 0.1518
Batch 80, Loss: 0.1443
Batch 90, Loss: 0.1222
Batch 100, Loss: 0.1166
Batch 110, Loss: 0.1235
Batch 120, Loss: 0.1427
Batch 130, Loss: 0.1153
Batch 140, Loss: 0.1284
Batch 150, Loss: 0.1348
Batch 160, Loss: 0.1524
Batch 170, Loss: 0.1301
Batch 180, Loss: 0.1450
Batch 190, Loss: 0.1403
Batch 200, Loss: 0.1255
Batch 210, Loss: 0.1015
Batch 220, Loss: 0.1125
Batch 230, Loss: 0.1115
Batch 240, Loss: 0.1254
Batch 250, Loss: 0.1442
Batch 260, Loss: 0.1200
Batch 270, Loss: 0.1397
Batch 280, Loss: 0.1290
Batch 290, Loss: 0.1187
Batch 300, Loss: 0.1089
Batch 310, Loss: 0.1236
Batch 320, Loss: 0.1357
Batch 330, Loss: 0.1272
Batch 340, Loss: 0.1207
Batch 350, Loss: 0.1221
Batch 360, Loss: 0.1001
Batch 370, Loss: 0.1157
Batch 380, Loss: 0.1171
Batch 390, Loss: 0.1134
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.443131685256958 seconds
Epoch 197 accuracy: 96.36%
Batch 10, Loss: 0.1396
Batch 20, Loss: 0.1589
Batch 30, Loss: 0.1184
Batch 40, Loss: 0.1319
Batch 50, Loss: 0.1369
Batch 60, Loss: 0.1168
Batch 70, Loss: 0.1268
Batch 80, Loss: 0.1472
Batch 90, Loss: 0.1209
Batch 100, Loss: 0.1050
Batch 110, Loss: 0.0995
Batch 120, Loss: 0.1315
Batch 130, Loss: 0.1362
Batch 140, Loss: 0.1198
Batch 150, Loss: 0.1154
Batch 160, Loss: 0.1211
Batch 170, Loss: 0.1220
Batch 180, Loss: 0.1251
Batch 190, Loss: 0.1235
Batch 200, Loss: 0.1418
Batch 210, Loss: 0.1341
Batch 220, Loss: 0.1075
Batch 230, Loss: 0.1484
Batch 240, Loss: 0.1293
Batch 250, Loss: 0.1215
Batch 260, Loss: 0.1180
Batch 270, Loss: 0.1253
Batch 280, Loss: 0.1146
Batch 290, Loss: 0.1172
Batch 300, Loss: 0.1247
Batch 310, Loss: 0.1232
Batch 320, Loss: 0.1098
Batch 330, Loss: 0.1480
Batch 340, Loss: 0.1258
Batch 350, Loss: 0.1045
Batch 360, Loss: 0.1230
Batch 370, Loss: 0.1356
Batch 380, Loss: 0.1297
Batch 390, Loss: 0.1337
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.37468981742859 seconds
Epoch 198 accuracy: 96.38%
Batch 10, Loss: 0.1281
Batch 20, Loss: 0.1307
Batch 30, Loss: 0.1359
Batch 40, Loss: 0.0925
Batch 50, Loss: 0.1367
Batch 60, Loss: 0.1053
Batch 70, Loss: 0.1327
Batch 80, Loss: 0.1106
Batch 90, Loss: 0.1133
Batch 100, Loss: 0.1246
Batch 110, Loss: 0.1245
Batch 120, Loss: 0.1311
Batch 130, Loss: 0.1291
Batch 140, Loss: 0.1310
Batch 150, Loss: 0.1367
Batch 160, Loss: 0.1166
Batch 170, Loss: 0.1153
Batch 180, Loss: 0.1340
Batch 190, Loss: 0.1312
Batch 200, Loss: 0.1247
Batch 210, Loss: 0.1360
Batch 220, Loss: 0.1240
Batch 230, Loss: 0.1259
Batch 240, Loss: 0.1204
Batch 250, Loss: 0.1149
Batch 260, Loss: 0.1212
Batch 270, Loss: 0.1336
Batch 280, Loss: 0.1286
Batch 290, Loss: 0.1216
Batch 300, Loss: 0.1338
Batch 310, Loss: 0.1082
Batch 320, Loss: 0.1327
Batch 330, Loss: 0.1297
Batch 340, Loss: 0.1157
Batch 350, Loss: 0.1215
Batch 360, Loss: 0.1247
Batch 370, Loss: 0.1260
Batch 380, Loss: 0.1336
Batch 390, Loss: 0.1144
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.653608083724976 seconds
Epoch 199 accuracy: 96.37%
Batch 10, Loss: 0.1269
Batch 20, Loss: 0.1269
Batch 30, Loss: 0.1233
Batch 40, Loss: 0.1104
Batch 50, Loss: 0.1271
Batch 60, Loss: 0.1378
Batch 70, Loss: 0.1370
Batch 80, Loss: 0.1077
Batch 90, Loss: 0.1253
Batch 100, Loss: 0.1289
Batch 110, Loss: 0.1345
Batch 120, Loss: 0.1299
Batch 130, Loss: 0.1228
Batch 140, Loss: 0.1084
Batch 150, Loss: 0.1083
Batch 160, Loss: 0.1269
Batch 170, Loss: 0.1304
Batch 180, Loss: 0.1382
Batch 190, Loss: 0.1377
Batch 200, Loss: 0.1188
Batch 210, Loss: 0.1189
Batch 220, Loss: 0.1186
Batch 230, Loss: 0.1156
Batch 240, Loss: 0.1006
Batch 250, Loss: 0.1290
Batch 260, Loss: 0.1094
Batch 270, Loss: 0.1207
Batch 280, Loss: 0.1321
Batch 290, Loss: 0.1351
Batch 300, Loss: 0.1136
Batch 310, Loss: 0.1143
Batch 320, Loss: 0.1156
Batch 330, Loss: 0.1351
Batch 340, Loss: 0.1245
Batch 350, Loss: 0.1448
Batch 360, Loss: 0.1078
Batch 370, Loss: 0.1159
Batch 380, Loss: 0.1478
Batch 390, Loss: 0.1173
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.557300329208374 seconds
Epoch 200 accuracy: 96.38%
Total training time: 5101.80371594429 seconds
