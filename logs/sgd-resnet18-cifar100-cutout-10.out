The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.4080
Batch 20, Loss: 4.3165
Batch 30, Loss: 3.9131
Batch 40, Loss: 3.7848
Batch 50, Loss: 3.5757
Batch 60, Loss: 3.5464
Batch 70, Loss: 3.4537
Batch 80, Loss: 3.4957
Batch 90, Loss: 3.4492
Batch 100, Loss: 3.4342
Batch 110, Loss: 3.3765
Batch 120, Loss: 3.3465
Batch 130, Loss: 3.3798
Batch 140, Loss: 3.2887
Batch 150, Loss: 3.3054
Batch 160, Loss: 3.3475
Batch 170, Loss: 3.3086
Batch 180, Loss: 3.2791
Batch 190, Loss: 3.2398
Batch 200, Loss: 3.2450
Batch 210, Loss: 3.2597
Batch 220, Loss: 3.2253
Batch 230, Loss: 3.2269
Batch 240, Loss: 3.2133
Batch 250, Loss: 3.1852
Batch 260, Loss: 3.2083
Batch 270, Loss: 3.1878
Batch 280, Loss: 3.1455
Batch 290, Loss: 3.1982
Batch 300, Loss: 3.1197
Batch 310, Loss: 3.2260
Batch 320, Loss: 3.1465
Batch 330, Loss: 3.1638
Batch 340, Loss: 3.1452
Batch 350, Loss: 3.1213
Batch 360, Loss: 3.0733
Batch 370, Loss: 3.1058
Batch 380, Loss: 3.1731
Batch 390, Loss: 3.0958
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.12871241569519 seconds
Epoch 1 accuracy: 12.99%
Batch 10, Loss: 3.0745
Batch 20, Loss: 3.0316
Batch 30, Loss: 3.0143
Batch 40, Loss: 3.0204
Batch 50, Loss: 3.0369
Batch 60, Loss: 3.0297
Batch 70, Loss: 3.0097
Batch 80, Loss: 2.9472
Batch 90, Loss: 2.9761
Batch 100, Loss: 3.0123
Batch 110, Loss: 3.0007
Batch 120, Loss: 3.0020
Batch 130, Loss: 2.9985
Batch 140, Loss: 2.9722
Batch 150, Loss: 2.9608
Batch 160, Loss: 2.9457
Batch 170, Loss: 2.9542
Batch 180, Loss: 2.9451
Batch 190, Loss: 2.8669
Batch 200, Loss: 2.9665
Batch 210, Loss: 2.8742
Batch 220, Loss: 2.8542
Batch 230, Loss: 2.8763
Batch 240, Loss: 2.7904
Batch 250, Loss: 2.8630
Batch 260, Loss: 2.8636
Batch 270, Loss: 2.8209
Batch 280, Loss: 2.8580
Batch 290, Loss: 2.8191
Batch 300, Loss: 2.8034
Batch 310, Loss: 2.8266
Batch 320, Loss: 2.8258
Batch 330, Loss: 2.7645
Batch 340, Loss: 2.7071
Batch 350, Loss: 2.7879
Batch 360, Loss: 2.7315
Batch 370, Loss: 2.7239
Batch 380, Loss: 2.7646
Batch 390, Loss: 2.7648
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.112530946731567 seconds
Epoch 2 accuracy: 19.28%
Batch 10, Loss: 2.7301
Batch 20, Loss: 2.7650
Batch 30, Loss: 2.7407
Batch 40, Loss: 2.6765
Batch 50, Loss: 2.7107
Batch 60, Loss: 2.6245
Batch 70, Loss: 2.6568
Batch 80, Loss: 2.6364
Batch 90, Loss: 2.5828
Batch 100, Loss: 2.7008
Batch 110, Loss: 2.6150
Batch 120, Loss: 2.6244
Batch 130, Loss: 2.6504
Batch 140, Loss: 2.6504
Batch 150, Loss: 2.5752
Batch 160, Loss: 2.5804
Batch 170, Loss: 2.5950
Batch 180, Loss: 2.4855
Batch 190, Loss: 2.5604
Batch 200, Loss: 2.6069
Batch 210, Loss: 2.6233
Batch 220, Loss: 2.5346
Batch 230, Loss: 2.5883
Batch 240, Loss: 2.5449
Batch 250, Loss: 2.5098
Batch 260, Loss: 2.5571
Batch 270, Loss: 2.5389
Batch 280, Loss: 2.4579
Batch 290, Loss: 2.4726
Batch 300, Loss: 2.4907
Batch 310, Loss: 2.4583
Batch 320, Loss: 2.4939
Batch 330, Loss: 2.4707
Batch 340, Loss: 2.4645
Batch 350, Loss: 2.5277
Batch 360, Loss: 2.4593
Batch 370, Loss: 2.4551
Batch 380, Loss: 2.4135
Batch 390, Loss: 2.4343
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.08971333503723 seconds
Epoch 3 accuracy: 25.92%
Batch 10, Loss: 2.3699
Batch 20, Loss: 2.3731
Batch 30, Loss: 2.3597
Batch 40, Loss: 2.3094
Batch 50, Loss: 2.4045
Batch 60, Loss: 2.2887
Batch 70, Loss: 2.3761
Batch 80, Loss: 2.2589
Batch 90, Loss: 2.2567
Batch 100, Loss: 2.2997
Batch 110, Loss: 2.3385
Batch 120, Loss: 2.3433
Batch 130, Loss: 2.3426
Batch 140, Loss: 2.2540
Batch 150, Loss: 2.3626
Batch 160, Loss: 2.2785
Batch 170, Loss: 2.3543
Batch 180, Loss: 2.2659
Batch 190, Loss: 2.2682
Batch 200, Loss: 2.3241
Batch 210, Loss: 2.2809
Batch 220, Loss: 2.2695
Batch 230, Loss: 2.2247
Batch 240, Loss: 2.1978
Batch 250, Loss: 2.1811
Batch 260, Loss: 2.3127
Batch 270, Loss: 2.2541
Batch 280, Loss: 2.2178
Batch 290, Loss: 2.1594
Batch 300, Loss: 2.2291
Batch 310, Loss: 2.1845
Batch 320, Loss: 2.1360
Batch 330, Loss: 2.1905
Batch 340, Loss: 2.2312
Batch 350, Loss: 2.2261
Batch 360, Loss: 2.1824
Batch 370, Loss: 2.1704
Batch 380, Loss: 2.1966
Batch 390, Loss: 2.2207
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.13638687133789 seconds
Epoch 4 accuracy: 29.21%
Batch 10, Loss: 2.0714
Batch 20, Loss: 2.1105
Batch 30, Loss: 2.0709
Batch 40, Loss: 2.1465
Batch 50, Loss: 2.0772
Batch 60, Loss: 2.1698
Batch 70, Loss: 2.0672
Batch 80, Loss: 2.1456
Batch 90, Loss: 2.1153
Batch 100, Loss: 2.0697
Batch 110, Loss: 2.0532
Batch 120, Loss: 2.1274
Batch 130, Loss: 2.0207
Batch 140, Loss: 2.1395
Batch 150, Loss: 2.0402
Batch 160, Loss: 1.9960
Batch 170, Loss: 1.9860
Batch 180, Loss: 2.0640
Batch 190, Loss: 2.0187
Batch 200, Loss: 1.9717
Batch 210, Loss: 2.0063
Batch 220, Loss: 1.9230
Batch 230, Loss: 2.0283
Batch 240, Loss: 1.9419
Batch 250, Loss: 1.9452
Batch 260, Loss: 2.0135
Batch 270, Loss: 2.0205
Batch 280, Loss: 2.0284
Batch 290, Loss: 2.0025
Batch 300, Loss: 1.9924
Batch 310, Loss: 2.0145
Batch 320, Loss: 1.9537
Batch 330, Loss: 1.9567
Batch 340, Loss: 1.9202
Batch 350, Loss: 1.9866
Batch 360, Loss: 1.9774
Batch 370, Loss: 2.0001
Batch 380, Loss: 2.0067
Batch 390, Loss: 1.8877
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.090961933135986 seconds
Epoch 5 accuracy: 37.77%
Batch 10, Loss: 1.8882
Batch 20, Loss: 1.9409
Batch 30, Loss: 1.9485
Batch 40, Loss: 1.8263
Batch 50, Loss: 1.8476
Batch 60, Loss: 1.8648
Batch 70, Loss: 1.8683
Batch 80, Loss: 1.8948
Batch 90, Loss: 1.8399
Batch 100, Loss: 1.8715
Batch 110, Loss: 1.9288
Batch 120, Loss: 1.8235
Batch 130, Loss: 1.9114
Batch 140, Loss: 1.8624
Batch 150, Loss: 1.8254
Batch 160, Loss: 1.8551
Batch 170, Loss: 1.8371
Batch 180, Loss: 1.8520
Batch 190, Loss: 1.8437
Batch 200, Loss: 1.8403
Batch 210, Loss: 1.8444
Batch 220, Loss: 1.8350
Batch 230, Loss: 1.8624
Batch 240, Loss: 1.8807
Batch 250, Loss: 1.8281
Batch 260, Loss: 1.8288
Batch 270, Loss: 1.8434
Batch 280, Loss: 1.8113
Batch 290, Loss: 1.8394
Batch 300, Loss: 1.8284
Batch 310, Loss: 1.7868
Batch 320, Loss: 1.8655
Batch 330, Loss: 1.8106
Batch 340, Loss: 1.7526
Batch 350, Loss: 1.7806
Batch 360, Loss: 1.8201
Batch 370, Loss: 1.7724
Batch 380, Loss: 1.7560
Batch 390, Loss: 1.7331
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.00305938720703 seconds
Epoch 6 accuracy: 44.36%
Batch 10, Loss: 1.7907
Batch 20, Loss: 1.6120
Batch 30, Loss: 1.7352
Batch 40, Loss: 1.7383
Batch 50, Loss: 1.7346
Batch 60, Loss: 1.7273
Batch 70, Loss: 1.6890
Batch 80, Loss: 1.7316
Batch 90, Loss: 1.6624
Batch 100, Loss: 1.7089
Batch 110, Loss: 1.6931
Batch 120, Loss: 1.6858
Batch 130, Loss: 1.7117
Batch 140, Loss: 1.7053
Batch 150, Loss: 1.7222
Batch 160, Loss: 1.7334
Batch 170, Loss: 1.6737
Batch 180, Loss: 1.6854
Batch 190, Loss: 1.7052
Batch 200, Loss: 1.7296
Batch 210, Loss: 1.6880
Batch 220, Loss: 1.7168
Batch 230, Loss: 1.7413
Batch 240, Loss: 1.6503
Batch 250, Loss: 1.7334
Batch 260, Loss: 1.6799
Batch 270, Loss: 1.6998
Batch 280, Loss: 1.6591
Batch 290, Loss: 1.6503
Batch 300, Loss: 1.6935
Batch 310, Loss: 1.6671
Batch 320, Loss: 1.6364
Batch 330, Loss: 1.6956
Batch 340, Loss: 1.6935
Batch 350, Loss: 1.6711
Batch 360, Loss: 1.7118
Batch 370, Loss: 1.6778
Batch 380, Loss: 1.6913
Batch 390, Loss: 1.6954
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.035603046417236 seconds
Epoch 7 accuracy: 46.25%
Batch 10, Loss: 1.5619
Batch 20, Loss: 1.5329
Batch 30, Loss: 1.6024
Batch 40, Loss: 1.6432
Batch 50, Loss: 1.5910
Batch 60, Loss: 1.6115
Batch 70, Loss: 1.6260
Batch 80, Loss: 1.5869
Batch 90, Loss: 1.5901
Batch 100, Loss: 1.5773
Batch 110, Loss: 1.6383
Batch 120, Loss: 1.5998
Batch 130, Loss: 1.5839
Batch 140, Loss: 1.5888
Batch 150, Loss: 1.5728
Batch 160, Loss: 1.6477
Batch 170, Loss: 1.6029
Batch 180, Loss: 1.6024
Batch 190, Loss: 1.5725
Batch 200, Loss: 1.5842
Batch 210, Loss: 1.6201
Batch 220, Loss: 1.5433
Batch 230, Loss: 1.6713
Batch 240, Loss: 1.5966
Batch 250, Loss: 1.5803
Batch 260, Loss: 1.5126
Batch 270, Loss: 1.5952
Batch 280, Loss: 1.6029
Batch 290, Loss: 1.6083
Batch 300, Loss: 1.5837
Batch 310, Loss: 1.5235
Batch 320, Loss: 1.5758
Batch 330, Loss: 1.5740
Batch 340, Loss: 1.5946
Batch 350, Loss: 1.5400
Batch 360, Loss: 1.5339
Batch 370, Loss: 1.5170
Batch 380, Loss: 1.5352
Batch 390, Loss: 1.6482
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.050737380981445 seconds
Epoch 8 accuracy: 48.54%
Batch 10, Loss: 1.4869
Batch 20, Loss: 1.3905
Batch 30, Loss: 1.4386
Batch 40, Loss: 1.5122
Batch 50, Loss: 1.5185
Batch 60, Loss: 1.4827
Batch 70, Loss: 1.4757
Batch 80, Loss: 1.4916
Batch 90, Loss: 1.5215
Batch 100, Loss: 1.6119
Batch 110, Loss: 1.4984
Batch 120, Loss: 1.5741
Batch 130, Loss: 1.4941
Batch 140, Loss: 1.4914
Batch 150, Loss: 1.5656
Batch 160, Loss: 1.4448
Batch 170, Loss: 1.5325
Batch 180, Loss: 1.4818
Batch 190, Loss: 1.5323
Batch 200, Loss: 1.4754
Batch 210, Loss: 1.4714
Batch 220, Loss: 1.4986
Batch 230, Loss: 1.5263
Batch 240, Loss: 1.4737
Batch 250, Loss: 1.5128
Batch 260, Loss: 1.5485
Batch 270, Loss: 1.5442
Batch 280, Loss: 1.5330
Batch 290, Loss: 1.4653
Batch 300, Loss: 1.4935
Batch 310, Loss: 1.4927
Batch 320, Loss: 1.4882
Batch 330, Loss: 1.5568
Batch 340, Loss: 1.5417
Batch 350, Loss: 1.5496
Batch 360, Loss: 1.5299
Batch 370, Loss: 1.5676
Batch 380, Loss: 1.4421
Batch 390, Loss: 1.5194
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 24.996456384658813 seconds
Epoch 9 accuracy: 51.85%
Batch 10, Loss: 1.4282
Batch 20, Loss: 1.4233
Batch 30, Loss: 1.4128
Batch 40, Loss: 1.3860
Batch 50, Loss: 1.4037
Batch 60, Loss: 1.4271
Batch 70, Loss: 1.4694
Batch 80, Loss: 1.4874
Batch 90, Loss: 1.4829
Batch 100, Loss: 1.4424
Batch 110, Loss: 1.5229
Batch 120, Loss: 1.4347
Batch 130, Loss: 1.4162
Batch 140, Loss: 1.4676
Batch 150, Loss: 1.4177
Batch 160, Loss: 1.4461
Batch 170, Loss: 1.4215
Batch 180, Loss: 1.4725
Batch 190, Loss: 1.4584
Batch 200, Loss: 1.4444
Batch 210, Loss: 1.4453
Batch 220, Loss: 1.5122
Batch 230, Loss: 1.4375
Batch 240, Loss: 1.4941
Batch 250, Loss: 1.5011
Batch 260, Loss: 1.4388
Batch 270, Loss: 1.3995
Batch 280, Loss: 1.4638
Batch 290, Loss: 1.4363
Batch 300, Loss: 1.4494
Batch 310, Loss: 1.4815
Batch 320, Loss: 1.4740
Batch 330, Loss: 1.4475
Batch 340, Loss: 1.4719
Batch 350, Loss: 1.4338
Batch 360, Loss: 1.4665
Batch 370, Loss: 1.3949
Batch 380, Loss: 1.4030
Batch 390, Loss: 1.4610
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 24.976150512695312 seconds
Epoch 10 accuracy: 48.88%
Batch 10, Loss: 1.4286
Batch 20, Loss: 1.3162
Batch 30, Loss: 1.3815
Batch 40, Loss: 1.3546
Batch 50, Loss: 1.3968
Batch 60, Loss: 1.3788
Batch 70, Loss: 1.4235
Batch 80, Loss: 1.3388
Batch 90, Loss: 1.3264
Batch 100, Loss: 1.4268
Batch 110, Loss: 1.3986
Batch 120, Loss: 1.4004
Batch 130, Loss: 1.3972
Batch 140, Loss: 1.3436
Batch 150, Loss: 1.3301
Batch 160, Loss: 1.3546
Batch 170, Loss: 1.4295
Batch 180, Loss: 1.3836
Batch 190, Loss: 1.3995
Batch 200, Loss: 1.4319
Batch 210, Loss: 1.4114
Batch 220, Loss: 1.3868
Batch 230, Loss: 1.4410
Batch 240, Loss: 1.3759
Batch 250, Loss: 1.4031
Batch 260, Loss: 1.3516
Batch 270, Loss: 1.4035
Batch 280, Loss: 1.3619
Batch 290, Loss: 1.3725
Batch 300, Loss: 1.3929
Batch 310, Loss: 1.4490
Batch 320, Loss: 1.3898
Batch 330, Loss: 1.4421
Batch 340, Loss: 1.4125
Batch 350, Loss: 1.4326
Batch 360, Loss: 1.4040
Batch 370, Loss: 1.3431
Batch 380, Loss: 1.4008
Batch 390, Loss: 1.4024
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 24.97429609298706 seconds
Epoch 11 accuracy: 50.03%
Batch 10, Loss: 1.3902
Batch 20, Loss: 1.3386
Batch 30, Loss: 1.2873
Batch 40, Loss: 1.3226
Batch 50, Loss: 1.2981
Batch 60, Loss: 1.3024
Batch 70, Loss: 1.2895
Batch 80, Loss: 1.2972
Batch 90, Loss: 1.3594
Batch 100, Loss: 1.2916
Batch 110, Loss: 1.3854
Batch 120, Loss: 1.3559
Batch 130, Loss: 1.3320
Batch 140, Loss: 1.3520
Batch 150, Loss: 1.2911
Batch 160, Loss: 1.3501
Batch 170, Loss: 1.3633
Batch 180, Loss: 1.3714
Batch 190, Loss: 1.3420
Batch 200, Loss: 1.3294
Batch 210, Loss: 1.3834
Batch 220, Loss: 1.3674
Batch 230, Loss: 1.3521
Batch 240, Loss: 1.3990
Batch 250, Loss: 1.3320
Batch 260, Loss: 1.3900
Batch 270, Loss: 1.3949
Batch 280, Loss: 1.4089
Batch 290, Loss: 1.3978
Batch 300, Loss: 1.3391
Batch 310, Loss: 1.3194
Batch 320, Loss: 1.3590
Batch 330, Loss: 1.3184
Batch 340, Loss: 1.3387
Batch 350, Loss: 1.3541
Batch 360, Loss: 1.3808
Batch 370, Loss: 1.3428
Batch 380, Loss: 1.3453
Batch 390, Loss: 1.3387
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.07848811149597 seconds
Epoch 12 accuracy: 51.18%
Batch 10, Loss: 1.2792
Batch 20, Loss: 1.3497
Batch 30, Loss: 1.3033
Batch 40, Loss: 1.2571
Batch 50, Loss: 1.3229
Batch 60, Loss: 1.3328
Batch 70, Loss: 1.2345
Batch 80, Loss: 1.2292
Batch 90, Loss: 1.2509
Batch 100, Loss: 1.2403
Batch 110, Loss: 1.2700
Batch 120, Loss: 1.2703
Batch 130, Loss: 1.3094
Batch 140, Loss: 1.3026
Batch 150, Loss: 1.3171
Batch 160, Loss: 1.2897
Batch 170, Loss: 1.3757
Batch 180, Loss: 1.2625
Batch 190, Loss: 1.2959
Batch 200, Loss: 1.3003
Batch 210, Loss: 1.3334
Batch 220, Loss: 1.3035
Batch 230, Loss: 1.3287
Batch 240, Loss: 1.3015
Batch 250, Loss: 1.3005
Batch 260, Loss: 1.3125
Batch 270, Loss: 1.3761
Batch 280, Loss: 1.2434
Batch 290, Loss: 1.3132
Batch 300, Loss: 1.4059
Batch 310, Loss: 1.3301
Batch 320, Loss: 1.3191
Batch 330, Loss: 1.3787
Batch 340, Loss: 1.3188
Batch 350, Loss: 1.3755
Batch 360, Loss: 1.2828
Batch 370, Loss: 1.2918
Batch 380, Loss: 1.3573
Batch 390, Loss: 1.3436
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.026195287704468 seconds
Epoch 13 accuracy: 53.91%
Batch 10, Loss: 1.1734
Batch 20, Loss: 1.3047
Batch 30, Loss: 1.2148
Batch 40, Loss: 1.2310
Batch 50, Loss: 1.2594
Batch 60, Loss: 1.2800
Batch 70, Loss: 1.2354
Batch 80, Loss: 1.2542
Batch 90, Loss: 1.2663
Batch 100, Loss: 1.2240
Batch 110, Loss: 1.2132
Batch 120, Loss: 1.2750
Batch 130, Loss: 1.1698
Batch 140, Loss: 1.2541
Batch 150, Loss: 1.2557
Batch 160, Loss: 1.2330
Batch 170, Loss: 1.2839
Batch 180, Loss: 1.2792
Batch 190, Loss: 1.2858
Batch 200, Loss: 1.2889
Batch 210, Loss: 1.2709
Batch 220, Loss: 1.2514
Batch 230, Loss: 1.2525
Batch 240, Loss: 1.2410
Batch 250, Loss: 1.3291
Batch 260, Loss: 1.3223
Batch 270, Loss: 1.2924
Batch 280, Loss: 1.2985
Batch 290, Loss: 1.3896
Batch 300, Loss: 1.3111
Batch 310, Loss: 1.3125
Batch 320, Loss: 1.2845
Batch 330, Loss: 1.2850
Batch 340, Loss: 1.3187
Batch 350, Loss: 1.2903
Batch 360, Loss: 1.2846
Batch 370, Loss: 1.2952
Batch 380, Loss: 1.3238
Batch 390, Loss: 1.3698
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.056538581848145 seconds
Epoch 14 accuracy: 54.26%
Batch 10, Loss: 1.1484
Batch 20, Loss: 1.2125
Batch 30, Loss: 1.1941
Batch 40, Loss: 1.2287
Batch 50, Loss: 1.1558
Batch 60, Loss: 1.1880
Batch 70, Loss: 1.1614
Batch 80, Loss: 1.2747
Batch 90, Loss: 1.1991
Batch 100, Loss: 1.2282
Batch 110, Loss: 1.1857
Batch 120, Loss: 1.2147
Batch 130, Loss: 1.2055
Batch 140, Loss: 1.3215
Batch 150, Loss: 1.2616
Batch 160, Loss: 1.1986
Batch 170, Loss: 1.2943
Batch 180, Loss: 1.2182
Batch 190, Loss: 1.3286
Batch 200, Loss: 1.2930
Batch 210, Loss: 1.2172
Batch 220, Loss: 1.2890
Batch 230, Loss: 1.2933
Batch 240, Loss: 1.2413
Batch 250, Loss: 1.2651
Batch 260, Loss: 1.2565
Batch 270, Loss: 1.2850
Batch 280, Loss: 1.2417
Batch 290, Loss: 1.2582
Batch 300, Loss: 1.2676
Batch 310, Loss: 1.2930
Batch 320, Loss: 1.3236
Batch 330, Loss: 1.2865
Batch 340, Loss: 1.2902
Batch 350, Loss: 1.2339
Batch 360, Loss: 1.2893
Batch 370, Loss: 1.2310
Batch 380, Loss: 1.2663
Batch 390, Loss: 1.2958
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 24.989360332489014 seconds
Epoch 15 accuracy: 56.65%
Batch 10, Loss: 1.1695
Batch 20, Loss: 1.1315
Batch 30, Loss: 1.1183
Batch 40, Loss: 1.1409
Batch 50, Loss: 1.1891
Batch 60, Loss: 1.2063
Batch 70, Loss: 1.1596
Batch 80, Loss: 1.2143
Batch 90, Loss: 1.1940
Batch 100, Loss: 1.1588
Batch 110, Loss: 1.1932
Batch 120, Loss: 1.2240
Batch 130, Loss: 1.2145
Batch 140, Loss: 1.2217
Batch 150, Loss: 1.2544
Batch 160, Loss: 1.1921
Batch 170, Loss: 1.2597
Batch 180, Loss: 1.2321
Batch 190, Loss: 1.2309
Batch 200, Loss: 1.1938
Batch 210, Loss: 1.1998
Batch 220, Loss: 1.2312
Batch 230, Loss: 1.2033
Batch 240, Loss: 1.2659
Batch 250, Loss: 1.2434
Batch 260, Loss: 1.2143
Batch 270, Loss: 1.2973
Batch 280, Loss: 1.2476
Batch 290, Loss: 1.2302
Batch 300, Loss: 1.2930
Batch 310, Loss: 1.2542
Batch 320, Loss: 1.3295
Batch 330, Loss: 1.2276
Batch 340, Loss: 1.2894
Batch 350, Loss: 1.2771
Batch 360, Loss: 1.2674
Batch 370, Loss: 1.3197
Batch 380, Loss: 1.2993
Batch 390, Loss: 1.2519
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.035328149795532 seconds
Epoch 16 accuracy: 53.49%
Batch 10, Loss: 1.0765
Batch 20, Loss: 1.1363
Batch 30, Loss: 1.1486
Batch 40, Loss: 1.1418
Batch 50, Loss: 1.1742
Batch 60, Loss: 1.1372
Batch 70, Loss: 1.1171
Batch 80, Loss: 1.1239
Batch 90, Loss: 1.1542
Batch 100, Loss: 1.2037
Batch 110, Loss: 1.1421
Batch 120, Loss: 1.1872
Batch 130, Loss: 1.1382
Batch 140, Loss: 1.1809
Batch 150, Loss: 1.1897
Batch 160, Loss: 1.1250
Batch 170, Loss: 1.2343
Batch 180, Loss: 1.2235
Batch 190, Loss: 1.2630
Batch 200, Loss: 1.2200
Batch 210, Loss: 1.2206
Batch 220, Loss: 1.1753
Batch 230, Loss: 1.2464
Batch 240, Loss: 1.2201
Batch 250, Loss: 1.2411
Batch 260, Loss: 1.1713
Batch 270, Loss: 1.2140
Batch 280, Loss: 1.1859
Batch 290, Loss: 1.2265
Batch 300, Loss: 1.2337
Batch 310, Loss: 1.2325
Batch 320, Loss: 1.2685
Batch 330, Loss: 1.2643
Batch 340, Loss: 1.2186
Batch 350, Loss: 1.2775
Batch 360, Loss: 1.1807
Batch 370, Loss: 1.3006
Batch 380, Loss: 1.2187
Batch 390, Loss: 1.2366
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.002867460250854 seconds
Epoch 17 accuracy: 56.32%
Batch 10, Loss: 1.1110
Batch 20, Loss: 1.0794
Batch 30, Loss: 1.1468
Batch 40, Loss: 1.1290
Batch 50, Loss: 1.1427
Batch 60, Loss: 1.1515
Batch 70, Loss: 1.1844
Batch 80, Loss: 1.2278
Batch 90, Loss: 1.1378
Batch 100, Loss: 1.2021
Batch 110, Loss: 1.1666
Batch 120, Loss: 1.1814
Batch 130, Loss: 1.1483
Batch 140, Loss: 1.1640
Batch 150, Loss: 1.1697
Batch 160, Loss: 1.1795
Batch 170, Loss: 1.1559
Batch 180, Loss: 1.1768
Batch 190, Loss: 1.1682
Batch 200, Loss: 1.2031
Batch 210, Loss: 1.1513
Batch 220, Loss: 1.2398
Batch 230, Loss: 1.1703
Batch 240, Loss: 1.2208
Batch 250, Loss: 1.2044
Batch 260, Loss: 1.2009
Batch 270, Loss: 1.1830
Batch 280, Loss: 1.1115
Batch 290, Loss: 1.2016
Batch 300, Loss: 1.2042
Batch 310, Loss: 1.2116
Batch 320, Loss: 1.1806
Batch 330, Loss: 1.1998
Batch 340, Loss: 1.1774
Batch 350, Loss: 1.1921
Batch 360, Loss: 1.2072
Batch 370, Loss: 1.1618
Batch 380, Loss: 1.1801
Batch 390, Loss: 1.2057
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.027181148529053 seconds
Epoch 18 accuracy: 53.85%
Batch 10, Loss: 1.1048
Batch 20, Loss: 1.0955
Batch 30, Loss: 1.0536
Batch 40, Loss: 1.1171
Batch 50, Loss: 1.0899
Batch 60, Loss: 1.1062
Batch 70, Loss: 1.1405
Batch 80, Loss: 1.1338
Batch 90, Loss: 1.1135
Batch 100, Loss: 1.1755
Batch 110, Loss: 1.1746
Batch 120, Loss: 1.1388
Batch 130, Loss: 1.2042
Batch 140, Loss: 1.1765
Batch 150, Loss: 1.1658
Batch 160, Loss: 1.2000
Batch 170, Loss: 1.1842
Batch 180, Loss: 1.1681
Batch 190, Loss: 1.1658
Batch 200, Loss: 1.1686
Batch 210, Loss: 1.1713
Batch 220, Loss: 1.1309
Batch 230, Loss: 1.2230
Batch 240, Loss: 1.1868
Batch 250, Loss: 1.1927
Batch 260, Loss: 1.1063
Batch 270, Loss: 1.0987
Batch 280, Loss: 1.1843
Batch 290, Loss: 1.2164
Batch 300, Loss: 1.2026
Batch 310, Loss: 1.1987
Batch 320, Loss: 1.2072
Batch 330, Loss: 1.1900
Batch 340, Loss: 1.1901
Batch 350, Loss: 1.1620
Batch 360, Loss: 1.1706
Batch 370, Loss: 1.2435
Batch 380, Loss: 1.1858
Batch 390, Loss: 1.2412
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.064714908599854 seconds
Epoch 19 accuracy: 56.59%
Batch 10, Loss: 1.0952
Batch 20, Loss: 1.0956
Batch 30, Loss: 1.0737
Batch 40, Loss: 1.0799
Batch 50, Loss: 1.1435
Batch 60, Loss: 1.1648
Batch 70, Loss: 1.1260
Batch 80, Loss: 1.1294
Batch 90, Loss: 1.0833
Batch 100, Loss: 1.1227
Batch 110, Loss: 1.0864
Batch 120, Loss: 1.0316
Batch 130, Loss: 1.0896
Batch 140, Loss: 1.1224
Batch 150, Loss: 1.1162
Batch 160, Loss: 1.1676
Batch 170, Loss: 1.1257
Batch 180, Loss: 1.2422
Batch 190, Loss: 1.1682
Batch 200, Loss: 1.1217
Batch 210, Loss: 1.1803
Batch 220, Loss: 1.1617
Batch 230, Loss: 1.1424
Batch 240, Loss: 1.1467
Batch 250, Loss: 1.1612
Batch 260, Loss: 1.1498
Batch 270, Loss: 1.1830
Batch 280, Loss: 1.1740
Batch 290, Loss: 1.1563
Batch 300, Loss: 1.1466
Batch 310, Loss: 1.1217
Batch 320, Loss: 1.1769
Batch 330, Loss: 1.1496
Batch 340, Loss: 1.1694
Batch 350, Loss: 1.1915
Batch 360, Loss: 1.1364
Batch 370, Loss: 1.1627
Batch 380, Loss: 1.2093
Batch 390, Loss: 1.1821
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.00402307510376 seconds
Epoch 20 accuracy: 50.22%
Batch 10, Loss: 1.0889
Batch 20, Loss: 1.0500
Batch 30, Loss: 1.0786
Batch 40, Loss: 1.0822
Batch 50, Loss: 1.0985
Batch 60, Loss: 1.1203
Batch 70, Loss: 1.1252
Batch 80, Loss: 1.1089
Batch 90, Loss: 1.1411
Batch 100, Loss: 1.1255
Batch 110, Loss: 1.0967
Batch 120, Loss: 1.1821
Batch 130, Loss: 1.1338
Batch 140, Loss: 1.1267
Batch 150, Loss: 1.1270
Batch 160, Loss: 1.1197
Batch 170, Loss: 1.1523
Batch 180, Loss: 1.0942
Batch 190, Loss: 1.0912
Batch 200, Loss: 1.1246
Batch 210, Loss: 1.1214
Batch 220, Loss: 1.1628
Batch 230, Loss: 1.1490
Batch 240, Loss: 1.1676
Batch 250, Loss: 1.1100
Batch 260, Loss: 1.1623
Batch 270, Loss: 1.1591
Batch 280, Loss: 1.1471
Batch 290, Loss: 1.1613
Batch 300, Loss: 1.1456
Batch 310, Loss: 1.1559
Batch 320, Loss: 1.1042
Batch 330, Loss: 1.1763
Batch 340, Loss: 1.1784
Batch 350, Loss: 1.1585
Batch 360, Loss: 1.1494
Batch 370, Loss: 1.2178
Batch 380, Loss: 1.1036
Batch 390, Loss: 1.1744
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.034188747406006 seconds
Epoch 21 accuracy: 59.05%
Batch 10, Loss: 1.0861
Batch 20, Loss: 1.0797
Batch 30, Loss: 1.0110
Batch 40, Loss: 1.0616
Batch 50, Loss: 1.0520
Batch 60, Loss: 1.0435
Batch 70, Loss: 1.0431
Batch 80, Loss: 1.0984
Batch 90, Loss: 1.0852
Batch 100, Loss: 1.1132
Batch 110, Loss: 1.0696
Batch 120, Loss: 1.1219
Batch 130, Loss: 1.1165
Batch 140, Loss: 1.0771
Batch 150, Loss: 1.1021
Batch 160, Loss: 1.0735
Batch 170, Loss: 1.1165
Batch 180, Loss: 1.0587
Batch 190, Loss: 1.0988
Batch 200, Loss: 1.1227
Batch 210, Loss: 1.1071
Batch 220, Loss: 1.1113
Batch 230, Loss: 1.1331
Batch 240, Loss: 1.0566
Batch 250, Loss: 1.1432
Batch 260, Loss: 1.1063
Batch 270, Loss: 1.0971
Batch 280, Loss: 1.1014
Batch 290, Loss: 1.1107
Batch 300, Loss: 1.1422
Batch 310, Loss: 1.1334
Batch 320, Loss: 1.0935
Batch 330, Loss: 1.1570
Batch 340, Loss: 1.2234
Batch 350, Loss: 1.1034
Batch 360, Loss: 1.1545
Batch 370, Loss: 1.1753
Batch 380, Loss: 1.1907
Batch 390, Loss: 1.1334
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.050358772277832 seconds
Epoch 22 accuracy: 57.86%
Batch 10, Loss: 1.0697
Batch 20, Loss: 1.0629
Batch 30, Loss: 1.0402
Batch 40, Loss: 1.0518
Batch 50, Loss: 1.0877
Batch 60, Loss: 1.1003
Batch 70, Loss: 1.0826
Batch 80, Loss: 1.0795
Batch 90, Loss: 1.1011
Batch 100, Loss: 1.0988
Batch 110, Loss: 1.0566
Batch 120, Loss: 1.1113
Batch 130, Loss: 1.0918
Batch 140, Loss: 1.1184
Batch 150, Loss: 1.1492
Batch 160, Loss: 1.0767
Batch 170, Loss: 1.0872
Batch 180, Loss: 1.0475
Batch 190, Loss: 1.1770
Batch 200, Loss: 1.0946
Batch 210, Loss: 1.0670
Batch 220, Loss: 1.1783
Batch 230, Loss: 1.1082
Batch 240, Loss: 1.0802
Batch 250, Loss: 1.0586
Batch 260, Loss: 1.0587
Batch 270, Loss: 1.0710
Batch 280, Loss: 1.1386
Batch 290, Loss: 1.1508
Batch 300, Loss: 1.1066
Batch 310, Loss: 1.0812
Batch 320, Loss: 1.1309
Batch 330, Loss: 1.0902
Batch 340, Loss: 1.1369
Batch 350, Loss: 1.0983
Batch 360, Loss: 1.0753
Batch 370, Loss: 1.1008
Batch 380, Loss: 1.1236
Batch 390, Loss: 1.1867
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.00442624092102 seconds
Epoch 23 accuracy: 51.82%
Batch 10, Loss: 1.0939
Batch 20, Loss: 0.9777
Batch 30, Loss: 1.0682
Batch 40, Loss: 1.0468
Batch 50, Loss: 1.0300
Batch 60, Loss: 1.0188
Batch 70, Loss: 1.0112
Batch 80, Loss: 1.0465
Batch 90, Loss: 1.0259
Batch 100, Loss: 1.0823
Batch 110, Loss: 1.0765
Batch 120, Loss: 1.0527
Batch 130, Loss: 1.0553
Batch 140, Loss: 1.1025
Batch 150, Loss: 1.0234
Batch 160, Loss: 1.0687
Batch 170, Loss: 1.1102
Batch 180, Loss: 1.0813
Batch 190, Loss: 1.1477
Batch 200, Loss: 1.0893
Batch 210, Loss: 1.1314
Batch 220, Loss: 1.0963
Batch 230, Loss: 1.1335
Batch 240, Loss: 1.0976
Batch 250, Loss: 1.0787
Batch 260, Loss: 1.1115
Batch 270, Loss: 1.1282
Batch 280, Loss: 1.1164
Batch 290, Loss: 1.1044
Batch 300, Loss: 1.1385
Batch 310, Loss: 1.0818
Batch 320, Loss: 1.0897
Batch 330, Loss: 1.1073
Batch 340, Loss: 1.0814
Batch 350, Loss: 1.1293
Batch 360, Loss: 1.1333
Batch 370, Loss: 1.0685
Batch 380, Loss: 1.1113
Batch 390, Loss: 1.0821
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 24.98426604270935 seconds
Epoch 24 accuracy: 56.65%
Batch 10, Loss: 0.9684
Batch 20, Loss: 1.0172
Batch 30, Loss: 1.0321
Batch 40, Loss: 0.9977
Batch 50, Loss: 0.9912
Batch 60, Loss: 1.0708
Batch 70, Loss: 1.0274
Batch 80, Loss: 0.9874
Batch 90, Loss: 1.0664
Batch 100, Loss: 0.9740
Batch 110, Loss: 1.0370
Batch 120, Loss: 1.1121
Batch 130, Loss: 1.1018
Batch 140, Loss: 1.0661
Batch 150, Loss: 1.0794
Batch 160, Loss: 1.0248
Batch 170, Loss: 1.0728
Batch 180, Loss: 1.1168
Batch 190, Loss: 1.0313
Batch 200, Loss: 1.1115
Batch 210, Loss: 1.0980
Batch 220, Loss: 1.1022
Batch 230, Loss: 1.1098
Batch 240, Loss: 1.0646
Batch 250, Loss: 1.0701
Batch 260, Loss: 1.1110
Batch 270, Loss: 1.0559
Batch 280, Loss: 1.0941
Batch 290, Loss: 1.1629
Batch 300, Loss: 1.1251
Batch 310, Loss: 1.1217
Batch 320, Loss: 1.1564
Batch 330, Loss: 1.2279
Batch 340, Loss: 1.1893
Batch 350, Loss: 1.0872
Batch 360, Loss: 1.1476
Batch 370, Loss: 1.1193
Batch 380, Loss: 1.0750
Batch 390, Loss: 1.1262
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.081121921539307 seconds
Epoch 25 accuracy: 58.9%
Batch 10, Loss: 1.0241
Batch 20, Loss: 0.9341
Batch 30, Loss: 0.9432
Batch 40, Loss: 1.0504
Batch 50, Loss: 1.0501
Batch 60, Loss: 0.9855
Batch 70, Loss: 1.0570
Batch 80, Loss: 1.0216
Batch 90, Loss: 1.0543
Batch 100, Loss: 1.0950
Batch 110, Loss: 1.0852
Batch 120, Loss: 1.0928
Batch 130, Loss: 1.0939
Batch 140, Loss: 1.0791
Batch 150, Loss: 1.0412
Batch 160, Loss: 1.0807
Batch 170, Loss: 1.0830
Batch 180, Loss: 1.0525
Batch 190, Loss: 1.0524
Batch 200, Loss: 1.0766
Batch 210, Loss: 1.1225
Batch 220, Loss: 1.0275
Batch 230, Loss: 1.0576
Batch 240, Loss: 1.0337
Batch 250, Loss: 1.0274
Batch 260, Loss: 1.0822
Batch 270, Loss: 1.0689
Batch 280, Loss: 1.0987
Batch 290, Loss: 1.1063
Batch 300, Loss: 1.1490
Batch 310, Loss: 1.1376
Batch 320, Loss: 1.0770
Batch 330, Loss: 1.0776
Batch 340, Loss: 1.1128
Batch 350, Loss: 1.1314
Batch 360, Loss: 1.1190
Batch 370, Loss: 1.0837
Batch 380, Loss: 1.0311
Batch 390, Loss: 1.0273
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.010892391204834 seconds
Epoch 26 accuracy: 58.11%
Batch 10, Loss: 1.0354
Batch 20, Loss: 0.9684
Batch 30, Loss: 0.9365
Batch 40, Loss: 1.0074
Batch 50, Loss: 0.9789
Batch 60, Loss: 1.0083
Batch 70, Loss: 0.9935
Batch 80, Loss: 1.0451
Batch 90, Loss: 1.0089
Batch 100, Loss: 1.0365
Batch 110, Loss: 1.0416
Batch 120, Loss: 1.0646
Batch 130, Loss: 1.0096
Batch 140, Loss: 1.0549
Batch 150, Loss: 1.0522
Batch 160, Loss: 1.0376
Batch 170, Loss: 1.0921
Batch 180, Loss: 1.1340
Batch 190, Loss: 1.0714
Batch 200, Loss: 1.0991
Batch 210, Loss: 1.0423
Batch 220, Loss: 1.0419
Batch 230, Loss: 1.0624
Batch 240, Loss: 1.0474
Batch 250, Loss: 1.0738
Batch 260, Loss: 1.0863
Batch 270, Loss: 1.0415
Batch 280, Loss: 1.1150
Batch 290, Loss: 1.1137
Batch 300, Loss: 1.0598
Batch 310, Loss: 1.0544
Batch 320, Loss: 1.1153
Batch 330, Loss: 1.0662
Batch 340, Loss: 1.1367
Batch 350, Loss: 1.0955
Batch 360, Loss: 1.0799
Batch 370, Loss: 1.0584
Batch 380, Loss: 1.1377
Batch 390, Loss: 1.0813
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.008978128433228 seconds
Epoch 27 accuracy: 57.04%
Batch 10, Loss: 0.9763
Batch 20, Loss: 1.0172
Batch 30, Loss: 1.0136
Batch 40, Loss: 1.0269
Batch 50, Loss: 0.9510
Batch 60, Loss: 1.0162
Batch 70, Loss: 0.9753
Batch 80, Loss: 0.9408
Batch 90, Loss: 0.9900
Batch 100, Loss: 1.0159
Batch 110, Loss: 1.0308
Batch 120, Loss: 0.9805
Batch 130, Loss: 1.0131
Batch 140, Loss: 1.0462
Batch 150, Loss: 1.0200
Batch 160, Loss: 1.0512
Batch 170, Loss: 1.0455
Batch 180, Loss: 1.0758
Batch 190, Loss: 1.0075
Batch 200, Loss: 1.0628
Batch 210, Loss: 1.0626
Batch 220, Loss: 1.0874
Batch 230, Loss: 1.0085
Batch 240, Loss: 1.0851
Batch 250, Loss: 1.0677
Batch 260, Loss: 1.0736
Batch 270, Loss: 1.1051
Batch 280, Loss: 1.0331
Batch 290, Loss: 1.0596
Batch 300, Loss: 1.1074
Batch 310, Loss: 1.0529
Batch 320, Loss: 1.0504
Batch 330, Loss: 1.0741
Batch 340, Loss: 1.0813
Batch 350, Loss: 1.1216
Batch 360, Loss: 1.1055
Batch 370, Loss: 1.1051
Batch 380, Loss: 1.0943
Batch 390, Loss: 1.0864
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.044520139694214 seconds
Epoch 28 accuracy: 57.76%
Batch 10, Loss: 0.9953
Batch 20, Loss: 1.0025
Batch 30, Loss: 0.9927
Batch 40, Loss: 0.9569
Batch 50, Loss: 1.0168
Batch 60, Loss: 0.9510
Batch 70, Loss: 1.0153
Batch 80, Loss: 1.0426
Batch 90, Loss: 1.0068
Batch 100, Loss: 1.0273
Batch 110, Loss: 0.9739
Batch 120, Loss: 1.0252
Batch 130, Loss: 1.0161
Batch 140, Loss: 1.0246
Batch 150, Loss: 1.0264
Batch 160, Loss: 1.0671
Batch 170, Loss: 1.0111
Batch 180, Loss: 1.0467
Batch 190, Loss: 1.0586
Batch 200, Loss: 1.0551
Batch 210, Loss: 1.1031
Batch 220, Loss: 1.0856
Batch 230, Loss: 1.0823
Batch 240, Loss: 1.0985
Batch 250, Loss: 1.0316
Batch 260, Loss: 1.0601
Batch 270, Loss: 1.0489
Batch 280, Loss: 1.0561
Batch 290, Loss: 1.0623
Batch 300, Loss: 1.0461
Batch 310, Loss: 1.0340
Batch 320, Loss: 1.0404
Batch 330, Loss: 1.0379
Batch 340, Loss: 1.1415
Batch 350, Loss: 1.0550
Batch 360, Loss: 1.0867
Batch 370, Loss: 1.0495
Batch 380, Loss: 1.0911
Batch 390, Loss: 1.1181
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 24.98214077949524 seconds
Epoch 29 accuracy: 58.83%
Batch 10, Loss: 0.9498
Batch 20, Loss: 0.9905
Batch 30, Loss: 0.9278
Batch 40, Loss: 0.9905
Batch 50, Loss: 0.9318
Batch 60, Loss: 0.9474
Batch 70, Loss: 0.9378
Batch 80, Loss: 0.9681
Batch 90, Loss: 0.9859
Batch 100, Loss: 0.9489
Batch 110, Loss: 1.0081
Batch 120, Loss: 0.9783
Batch 130, Loss: 1.0334
Batch 140, Loss: 0.9923
Batch 150, Loss: 1.0067
Batch 160, Loss: 1.0208
Batch 170, Loss: 0.9936
Batch 180, Loss: 1.0558
Batch 190, Loss: 1.0854
Batch 200, Loss: 1.0034
Batch 210, Loss: 1.0489
Batch 220, Loss: 1.0465
Batch 230, Loss: 1.0591
Batch 240, Loss: 1.0642
Batch 250, Loss: 1.1098
Batch 260, Loss: 1.0816
Batch 270, Loss: 1.1178
Batch 280, Loss: 1.0750
Batch 290, Loss: 1.0644
Batch 300, Loss: 1.0769
Batch 310, Loss: 0.9927
Batch 320, Loss: 1.0664
Batch 330, Loss: 1.0926
Batch 340, Loss: 1.0130
Batch 350, Loss: 1.0245
Batch 360, Loss: 1.0801
Batch 370, Loss: 1.0530
Batch 380, Loss: 1.0015
Batch 390, Loss: 1.0870
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 24.98659110069275 seconds
Epoch 30 accuracy: 55.61%
Batch 10, Loss: 0.9492
Batch 20, Loss: 0.9254
Batch 30, Loss: 0.9258
Batch 40, Loss: 0.9205
Batch 50, Loss: 0.9669
Batch 60, Loss: 0.9440
Batch 70, Loss: 0.9783
Batch 80, Loss: 0.9830
Batch 90, Loss: 0.9669
Batch 100, Loss: 1.0042
Batch 110, Loss: 1.0055
Batch 120, Loss: 0.9803
Batch 130, Loss: 0.9744
Batch 140, Loss: 1.0121
Batch 150, Loss: 0.9616
Batch 160, Loss: 1.0220
Batch 170, Loss: 1.0750
Batch 180, Loss: 1.0299
Batch 190, Loss: 1.0596
Batch 200, Loss: 1.0569
Batch 210, Loss: 1.0319
Batch 220, Loss: 1.0186
Batch 230, Loss: 1.0453
Batch 240, Loss: 1.0407
Batch 250, Loss: 1.0611
Batch 260, Loss: 1.0241
Batch 270, Loss: 1.0024
Batch 280, Loss: 1.0905
Batch 290, Loss: 1.0304
Batch 300, Loss: 1.0736
Batch 310, Loss: 1.0689
Batch 320, Loss: 1.1255
Batch 330, Loss: 1.0878
Batch 340, Loss: 1.0829
Batch 350, Loss: 1.0630
Batch 360, Loss: 1.0700
Batch 370, Loss: 1.0406
Batch 380, Loss: 1.0950
Batch 390, Loss: 1.0530
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 24.93715476989746 seconds
Epoch 31 accuracy: 55.71%
Batch 10, Loss: 0.9548
Batch 20, Loss: 0.9449
Batch 30, Loss: 0.9745
Batch 40, Loss: 0.9634
Batch 50, Loss: 0.9622
Batch 60, Loss: 1.0092
Batch 70, Loss: 0.9913
Batch 80, Loss: 0.9679
Batch 90, Loss: 0.9683
Batch 100, Loss: 0.9565
Batch 110, Loss: 1.0261
Batch 120, Loss: 0.9623
Batch 130, Loss: 0.9674
Batch 140, Loss: 1.0084
Batch 150, Loss: 0.9767
Batch 160, Loss: 1.0569
Batch 170, Loss: 1.0293
Batch 180, Loss: 0.9835
Batch 190, Loss: 1.0670
Batch 200, Loss: 1.0284
Batch 210, Loss: 0.9885
Batch 220, Loss: 1.0153
Batch 230, Loss: 1.0598
Batch 240, Loss: 1.0069
Batch 250, Loss: 1.0643
Batch 260, Loss: 1.0054
Batch 270, Loss: 1.0009
Batch 280, Loss: 1.0867
Batch 290, Loss: 1.0668
Batch 300, Loss: 1.0323
Batch 310, Loss: 1.1083
Batch 320, Loss: 1.0581
Batch 330, Loss: 1.1626
Batch 340, Loss: 1.0167
Batch 350, Loss: 1.0298
Batch 360, Loss: 1.0466
Batch 370, Loss: 1.0328
Batch 380, Loss: 1.0805
Batch 390, Loss: 1.0190
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 24.983933925628662 seconds
Epoch 32 accuracy: 59.9%
Batch 10, Loss: 0.9211
Batch 20, Loss: 0.9933
Batch 30, Loss: 0.9835
Batch 40, Loss: 0.9505
Batch 50, Loss: 0.9425
Batch 60, Loss: 0.9598
Batch 70, Loss: 0.9256
Batch 80, Loss: 0.9493
Batch 90, Loss: 0.9961
Batch 100, Loss: 0.9432
Batch 110, Loss: 0.9519
Batch 120, Loss: 0.9832
Batch 130, Loss: 0.9928
Batch 140, Loss: 0.9546
Batch 150, Loss: 1.0281
Batch 160, Loss: 1.0246
Batch 170, Loss: 0.9783
Batch 180, Loss: 1.0103
Batch 190, Loss: 0.9856
Batch 200, Loss: 1.0137
Batch 210, Loss: 1.0194
Batch 220, Loss: 1.0132
Batch 230, Loss: 1.0035
Batch 240, Loss: 1.0071
Batch 250, Loss: 1.0740
Batch 260, Loss: 1.0977
Batch 270, Loss: 1.0281
Batch 280, Loss: 1.0322
Batch 290, Loss: 1.0704
Batch 300, Loss: 1.0120
Batch 310, Loss: 1.0103
Batch 320, Loss: 0.9885
Batch 330, Loss: 1.0961
Batch 340, Loss: 1.0035
Batch 350, Loss: 1.0212
Batch 360, Loss: 1.0179
Batch 370, Loss: 0.9957
Batch 380, Loss: 1.0554
Batch 390, Loss: 1.0987
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.02403473854065 seconds
Epoch 33 accuracy: 55.48%
Batch 10, Loss: 0.9315
Batch 20, Loss: 0.9642
Batch 30, Loss: 0.9447
Batch 40, Loss: 0.8937
Batch 50, Loss: 0.8917
Batch 60, Loss: 0.9714
Batch 70, Loss: 0.9607
Batch 80, Loss: 0.9841
Batch 90, Loss: 0.9767
Batch 100, Loss: 0.9601
Batch 110, Loss: 0.9548
Batch 120, Loss: 0.9539
Batch 130, Loss: 1.0403
Batch 140, Loss: 0.9886
Batch 150, Loss: 0.9818
Batch 160, Loss: 1.0628
Batch 170, Loss: 0.9555
Batch 180, Loss: 0.9557
Batch 190, Loss: 1.0631
Batch 200, Loss: 1.0541
Batch 210, Loss: 1.0469
Batch 220, Loss: 1.0065
Batch 230, Loss: 1.0090
Batch 240, Loss: 1.0571
Batch 250, Loss: 1.0340
Batch 260, Loss: 1.0018
Batch 270, Loss: 1.0038
Batch 280, Loss: 1.0320
Batch 290, Loss: 1.0097
Batch 300, Loss: 1.0486
Batch 310, Loss: 1.0713
Batch 320, Loss: 0.9763
Batch 330, Loss: 0.9919
Batch 340, Loss: 1.0331
Batch 350, Loss: 1.0004
Batch 360, Loss: 1.0223
Batch 370, Loss: 1.0663
Batch 380, Loss: 1.0418
Batch 390, Loss: 1.0232
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 24.94804883003235 seconds
Epoch 34 accuracy: 56.3%
Batch 10, Loss: 0.9723
Batch 20, Loss: 0.9095
Batch 30, Loss: 0.8826
Batch 40, Loss: 0.8971
Batch 50, Loss: 0.9634
Batch 60, Loss: 0.9782
Batch 70, Loss: 0.9830
Batch 80, Loss: 0.9333
Batch 90, Loss: 0.8999
Batch 100, Loss: 0.9952
Batch 110, Loss: 0.9286
Batch 120, Loss: 0.9638
Batch 130, Loss: 0.9504
Batch 140, Loss: 0.9688
Batch 150, Loss: 0.9525
Batch 160, Loss: 0.9437
Batch 170, Loss: 0.9988
Batch 180, Loss: 0.9914
Batch 190, Loss: 0.9889
Batch 200, Loss: 1.0605
Batch 210, Loss: 1.0040
Batch 220, Loss: 0.9594
Batch 230, Loss: 1.0588
Batch 240, Loss: 0.9993
Batch 250, Loss: 0.9702
Batch 260, Loss: 1.0447
Batch 270, Loss: 1.0135
Batch 280, Loss: 0.9915
Batch 290, Loss: 0.9868
Batch 300, Loss: 1.0067
Batch 310, Loss: 1.0016
Batch 320, Loss: 1.0845
Batch 330, Loss: 1.0846
Batch 340, Loss: 1.0822
Batch 350, Loss: 1.0731
Batch 360, Loss: 0.9964
Batch 370, Loss: 1.0366
Batch 380, Loss: 1.0193
Batch 390, Loss: 1.0595
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 24.940184831619263 seconds
Epoch 35 accuracy: 59.77%
Batch 10, Loss: 0.8993
Batch 20, Loss: 0.9578
Batch 30, Loss: 0.9327
Batch 40, Loss: 0.9119
Batch 50, Loss: 0.9423
Batch 60, Loss: 0.9929
Batch 70, Loss: 0.9247
Batch 80, Loss: 0.9574
Batch 90, Loss: 0.9173
Batch 100, Loss: 0.9233
Batch 110, Loss: 0.9351
Batch 120, Loss: 0.9777
Batch 130, Loss: 0.9630
Batch 140, Loss: 1.0420
Batch 150, Loss: 0.9979
Batch 160, Loss: 0.9427
Batch 170, Loss: 0.9559
Batch 180, Loss: 0.9495
Batch 190, Loss: 0.9779
Batch 200, Loss: 1.0020
Batch 210, Loss: 1.0273
Batch 220, Loss: 1.0307
Batch 230, Loss: 1.0428
Batch 240, Loss: 1.0162
Batch 250, Loss: 0.9934
Batch 260, Loss: 1.0882
Batch 270, Loss: 1.0470
Batch 280, Loss: 1.0227
Batch 290, Loss: 0.9384
Batch 300, Loss: 1.0052
Batch 310, Loss: 1.0192
Batch 320, Loss: 1.0476
Batch 330, Loss: 1.0161
Batch 340, Loss: 1.0402
Batch 350, Loss: 1.0273
Batch 360, Loss: 1.0201
Batch 370, Loss: 1.0213
Batch 380, Loss: 1.0539
Batch 390, Loss: 1.0259
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 24.96908211708069 seconds
Epoch 36 accuracy: 53.49%
Batch 10, Loss: 0.9252
Batch 20, Loss: 0.9021
Batch 30, Loss: 0.9430
Batch 40, Loss: 0.9445
Batch 50, Loss: 0.9230
Batch 60, Loss: 0.9267
Batch 70, Loss: 0.9898
Batch 80, Loss: 0.9573
Batch 90, Loss: 0.9365
Batch 100, Loss: 0.9965
Batch 110, Loss: 0.9544
Batch 120, Loss: 0.9425
Batch 130, Loss: 0.9470
Batch 140, Loss: 1.0327
Batch 150, Loss: 0.9248
Batch 160, Loss: 0.9790
Batch 170, Loss: 1.0311
Batch 180, Loss: 0.9888
Batch 190, Loss: 1.0051
Batch 200, Loss: 0.9831
Batch 210, Loss: 0.9794
Batch 220, Loss: 0.9843
Batch 230, Loss: 0.9757
Batch 240, Loss: 0.9144
Batch 250, Loss: 1.0313
Batch 260, Loss: 0.9988
Batch 270, Loss: 1.0092
Batch 280, Loss: 1.0229
Batch 290, Loss: 0.9954
Batch 300, Loss: 0.9888
Batch 310, Loss: 0.9896
Batch 320, Loss: 0.9767
Batch 330, Loss: 1.0367
Batch 340, Loss: 1.0216
Batch 350, Loss: 1.0005
Batch 360, Loss: 1.0130
Batch 370, Loss: 0.9770
Batch 380, Loss: 1.0005
Batch 390, Loss: 1.0273
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.00405192375183 seconds
Epoch 37 accuracy: 59.14%
Batch 10, Loss: 0.9461
Batch 20, Loss: 0.9435
Batch 30, Loss: 0.8903
Batch 40, Loss: 0.8706
Batch 50, Loss: 0.9580
Batch 60, Loss: 0.9178
Batch 70, Loss: 0.9819
Batch 80, Loss: 0.9355
Batch 90, Loss: 0.9993
Batch 100, Loss: 0.8906
Batch 110, Loss: 0.9124
Batch 120, Loss: 1.0316
Batch 130, Loss: 0.9594
Batch 140, Loss: 0.9674
Batch 150, Loss: 0.8983
Batch 160, Loss: 0.9823
Batch 170, Loss: 0.9684
Batch 180, Loss: 0.9685
Batch 190, Loss: 0.8751
Batch 200, Loss: 0.9160
Batch 210, Loss: 1.0061
Batch 220, Loss: 0.9730
Batch 230, Loss: 1.0033
Batch 240, Loss: 0.9908
Batch 250, Loss: 1.0385
Batch 260, Loss: 1.0541
Batch 270, Loss: 0.9822
Batch 280, Loss: 1.0178
Batch 290, Loss: 1.0078
Batch 300, Loss: 0.9724
Batch 310, Loss: 0.9926
Batch 320, Loss: 0.9942
Batch 330, Loss: 1.0345
Batch 340, Loss: 1.0259
Batch 350, Loss: 0.9660
Batch 360, Loss: 0.9834
Batch 370, Loss: 0.9557
Batch 380, Loss: 0.9932
Batch 390, Loss: 0.9222
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 24.95835566520691 seconds
Epoch 38 accuracy: 57.44%
Batch 10, Loss: 0.9046
Batch 20, Loss: 0.8709
Batch 30, Loss: 0.8879
Batch 40, Loss: 0.8975
Batch 50, Loss: 0.9248
Batch 60, Loss: 0.9237
Batch 70, Loss: 0.9322
Batch 80, Loss: 0.9191
Batch 90, Loss: 0.9068
Batch 100, Loss: 0.9098
Batch 110, Loss: 0.9614
Batch 120, Loss: 0.9698
Batch 130, Loss: 1.0024
Batch 140, Loss: 0.9546
Batch 150, Loss: 0.9874
Batch 160, Loss: 0.9569
Batch 170, Loss: 0.9673
Batch 180, Loss: 0.9809
Batch 190, Loss: 0.9478
Batch 200, Loss: 0.9777
Batch 210, Loss: 0.9125
Batch 220, Loss: 1.0031
Batch 230, Loss: 0.9167
Batch 240, Loss: 0.9503
Batch 250, Loss: 0.9398
Batch 260, Loss: 0.9904
Batch 270, Loss: 0.9821
Batch 280, Loss: 0.9534
Batch 290, Loss: 1.0053
Batch 300, Loss: 1.0532
Batch 310, Loss: 1.0713
Batch 320, Loss: 1.0278
Batch 330, Loss: 1.0133
Batch 340, Loss: 0.9597
Batch 350, Loss: 0.9752
Batch 360, Loss: 1.0023
Batch 370, Loss: 1.0127
Batch 380, Loss: 0.9750
Batch 390, Loss: 0.9790
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.036251544952393 seconds
Epoch 39 accuracy: 61.45%
Batch 10, Loss: 0.9428
Batch 20, Loss: 0.9023
Batch 30, Loss: 0.9045
Batch 40, Loss: 0.9031
Batch 50, Loss: 0.9285
Batch 60, Loss: 0.8595
Batch 70, Loss: 0.9011
Batch 80, Loss: 0.9308
Batch 90, Loss: 0.8913
Batch 100, Loss: 0.9269
Batch 110, Loss: 0.9378
Batch 120, Loss: 0.9135
Batch 130, Loss: 0.9253
Batch 140, Loss: 0.9206
Batch 150, Loss: 0.9646
Batch 160, Loss: 0.9605
Batch 170, Loss: 0.9445
Batch 180, Loss: 0.9941
Batch 190, Loss: 0.9104
Batch 200, Loss: 1.0167
Batch 210, Loss: 1.0482
Batch 220, Loss: 0.9855
Batch 230, Loss: 1.0088
Batch 240, Loss: 0.9975
Batch 250, Loss: 0.9543
Batch 260, Loss: 1.0095
Batch 270, Loss: 0.9602
Batch 280, Loss: 0.9581
Batch 290, Loss: 0.9971
Batch 300, Loss: 0.9816
Batch 310, Loss: 1.0326
Batch 320, Loss: 0.9618
Batch 330, Loss: 1.0218
Batch 340, Loss: 0.9728
Batch 350, Loss: 0.9871
Batch 360, Loss: 0.9696
Batch 370, Loss: 1.0302
Batch 380, Loss: 0.9863
Batch 390, Loss: 1.0261
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.171202182769775 seconds
Epoch 40 accuracy: 61.21%
Batch 10, Loss: 0.9192
Batch 20, Loss: 0.8797
Batch 30, Loss: 0.9084
Batch 40, Loss: 0.8636
Batch 50, Loss: 0.9097
Batch 60, Loss: 0.8825
Batch 70, Loss: 0.9133
Batch 80, Loss: 0.9032
Batch 90, Loss: 0.8863
Batch 100, Loss: 0.9415
Batch 110, Loss: 0.9403
Batch 120, Loss: 0.8886
Batch 130, Loss: 0.9452
Batch 140, Loss: 0.9199
Batch 150, Loss: 0.9545
Batch 160, Loss: 0.9405
Batch 170, Loss: 0.9635
Batch 180, Loss: 0.9523
Batch 190, Loss: 0.9528
Batch 200, Loss: 0.9666
Batch 210, Loss: 1.0246
Batch 220, Loss: 0.9743
Batch 230, Loss: 0.9423
Batch 240, Loss: 0.9473
Batch 250, Loss: 0.9750
Batch 260, Loss: 0.9954
Batch 270, Loss: 0.9521
Batch 280, Loss: 0.9547
Batch 290, Loss: 0.9763
Batch 300, Loss: 1.0210
Batch 310, Loss: 0.9747
Batch 320, Loss: 0.9467
Batch 330, Loss: 0.9990
Batch 340, Loss: 0.9846
Batch 350, Loss: 1.0389
Batch 360, Loss: 0.9642
Batch 370, Loss: 1.0099
Batch 380, Loss: 0.9431
Batch 390, Loss: 0.9916
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.059056758880615 seconds
Epoch 41 accuracy: 58.54%
Batch 10, Loss: 0.8609
Batch 20, Loss: 0.8982
Batch 30, Loss: 0.8887
Batch 40, Loss: 0.8549
Batch 50, Loss: 0.8749
Batch 60, Loss: 0.8704
Batch 70, Loss: 0.8467
Batch 80, Loss: 0.9162
Batch 90, Loss: 0.9157
Batch 100, Loss: 0.9199
Batch 110, Loss: 0.9661
Batch 120, Loss: 0.9398
Batch 130, Loss: 0.9173
Batch 140, Loss: 0.9276
Batch 150, Loss: 0.9496
Batch 160, Loss: 0.9878
Batch 170, Loss: 0.9904
Batch 180, Loss: 0.9047
Batch 190, Loss: 0.9240
Batch 200, Loss: 0.9287
Batch 210, Loss: 0.9760
Batch 220, Loss: 0.9539
Batch 230, Loss: 1.0094
Batch 240, Loss: 0.9731
Batch 250, Loss: 0.9659
Batch 260, Loss: 0.9358
Batch 270, Loss: 0.9117
Batch 280, Loss: 0.9582
Batch 290, Loss: 0.9872
Batch 300, Loss: 0.9833
Batch 310, Loss: 0.9757
Batch 320, Loss: 1.0480
Batch 330, Loss: 0.9872
Batch 340, Loss: 0.9647
Batch 350, Loss: 0.9682
Batch 360, Loss: 0.9717
Batch 370, Loss: 1.0048
Batch 380, Loss: 1.0034
Batch 390, Loss: 1.0470
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.44510054588318 seconds
Epoch 42 accuracy: 59.89%
Batch 10, Loss: 0.9343
Batch 20, Loss: 0.8626
Batch 30, Loss: 0.8225
Batch 40, Loss: 0.8218
Batch 50, Loss: 0.8592
Batch 60, Loss: 0.8478
Batch 70, Loss: 0.9052
Batch 80, Loss: 0.8916
Batch 90, Loss: 0.9341
Batch 100, Loss: 0.9394
Batch 110, Loss: 0.8727
Batch 120, Loss: 0.9304
Batch 130, Loss: 0.9091
Batch 140, Loss: 0.9010
Batch 150, Loss: 0.9132
Batch 160, Loss: 0.9880
Batch 170, Loss: 0.9320
Batch 180, Loss: 0.9654
Batch 190, Loss: 0.9011
Batch 200, Loss: 0.9431
Batch 210, Loss: 1.0042
Batch 220, Loss: 0.9085
Batch 230, Loss: 0.9597
Batch 240, Loss: 0.9005
Batch 250, Loss: 0.9675
Batch 260, Loss: 0.8798
Batch 270, Loss: 0.9716
Batch 280, Loss: 0.9617
Batch 290, Loss: 0.9871
Batch 300, Loss: 0.9829
Batch 310, Loss: 1.0173
Batch 320, Loss: 0.9451
Batch 330, Loss: 1.0124
Batch 340, Loss: 0.9619
Batch 350, Loss: 0.9879
Batch 360, Loss: 0.9411
Batch 370, Loss: 0.9709
Batch 380, Loss: 0.9607
Batch 390, Loss: 1.0076
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.074059009552002 seconds
Epoch 43 accuracy: 58.3%
Batch 10, Loss: 0.8880
Batch 20, Loss: 0.8892
Batch 30, Loss: 0.8394
Batch 40, Loss: 0.8711
Batch 50, Loss: 0.8620
Batch 60, Loss: 0.8229
Batch 70, Loss: 0.8920
Batch 80, Loss: 0.9332
Batch 90, Loss: 0.9192
Batch 100, Loss: 0.9706
Batch 110, Loss: 0.9149
Batch 120, Loss: 0.9085
Batch 130, Loss: 0.8818
Batch 140, Loss: 0.8968
Batch 150, Loss: 0.9438
Batch 160, Loss: 0.9769
Batch 170, Loss: 1.0061
Batch 180, Loss: 0.9553
Batch 190, Loss: 0.9162
Batch 200, Loss: 0.9206
Batch 210, Loss: 0.9216
Batch 220, Loss: 0.8892
Batch 230, Loss: 0.9362
Batch 240, Loss: 0.9869
Batch 250, Loss: 0.9546
Batch 260, Loss: 0.9775
Batch 270, Loss: 0.9543
Batch 280, Loss: 0.9850
Batch 290, Loss: 0.9179
Batch 300, Loss: 0.9363
Batch 310, Loss: 0.9160
Batch 320, Loss: 0.9894
Batch 330, Loss: 0.9633
Batch 340, Loss: 0.9578
Batch 350, Loss: 0.9678
Batch 360, Loss: 1.0949
Batch 370, Loss: 1.0063
Batch 380, Loss: 0.9894
Batch 390, Loss: 0.9434
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.27013611793518 seconds
Epoch 44 accuracy: 59.33%
Batch 10, Loss: 0.9353
Batch 20, Loss: 0.8216
Batch 30, Loss: 0.8349
Batch 40, Loss: 0.7993
Batch 50, Loss: 0.8615
Batch 60, Loss: 0.8904
Batch 70, Loss: 0.8541
Batch 80, Loss: 0.8576
Batch 90, Loss: 0.8781
Batch 100, Loss: 0.8650
Batch 110, Loss: 0.8775
Batch 120, Loss: 0.9122
Batch 130, Loss: 0.9103
Batch 140, Loss: 0.9674
Batch 150, Loss: 0.9264
Batch 160, Loss: 0.9157
Batch 170, Loss: 0.9754
Batch 180, Loss: 0.9399
Batch 190, Loss: 0.9845
Batch 200, Loss: 0.9323
Batch 210, Loss: 0.9411
Batch 220, Loss: 0.9120
Batch 230, Loss: 0.9703
Batch 240, Loss: 0.9605
Batch 250, Loss: 0.9672
Batch 260, Loss: 0.9939
Batch 270, Loss: 0.9116
Batch 280, Loss: 0.9857
Batch 290, Loss: 0.9672
Batch 300, Loss: 0.9424
Batch 310, Loss: 1.0037
Batch 320, Loss: 0.9607
Batch 330, Loss: 0.9961
Batch 340, Loss: 0.9764
Batch 350, Loss: 1.0457
Batch 360, Loss: 0.9672
Batch 370, Loss: 1.0111
Batch 380, Loss: 0.9831
Batch 390, Loss: 0.9697
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.117809534072876 seconds
Epoch 45 accuracy: 59.06%
Batch 10, Loss: 0.8811
Batch 20, Loss: 0.8814
Batch 30, Loss: 0.9126
Batch 40, Loss: 0.8486
Batch 50, Loss: 0.8455
Batch 60, Loss: 0.8839
Batch 70, Loss: 0.8653
Batch 80, Loss: 0.9119
Batch 90, Loss: 0.8709
Batch 100, Loss: 0.8817
Batch 110, Loss: 0.9179
Batch 120, Loss: 0.8989
Batch 130, Loss: 0.9072
Batch 140, Loss: 0.9395
Batch 150, Loss: 0.9061
Batch 160, Loss: 0.9494
Batch 170, Loss: 0.9119
Batch 180, Loss: 0.9243
Batch 190, Loss: 0.8499
Batch 200, Loss: 0.9039
Batch 210, Loss: 0.9761
Batch 220, Loss: 0.9759
Batch 230, Loss: 0.9482
Batch 240, Loss: 0.9680
Batch 250, Loss: 0.9637
Batch 260, Loss: 0.9012
Batch 270, Loss: 0.9190
Batch 280, Loss: 0.9429
Batch 290, Loss: 0.9846
Batch 300, Loss: 0.9491
Batch 310, Loss: 1.0010
Batch 320, Loss: 0.9566
Batch 330, Loss: 0.9208
Batch 340, Loss: 0.9227
Batch 350, Loss: 1.0092
Batch 360, Loss: 0.9397
Batch 370, Loss: 0.9413
Batch 380, Loss: 0.9459
Batch 390, Loss: 0.9540
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.102093935012817 seconds
Epoch 46 accuracy: 61.11%
Batch 10, Loss: 0.8439
Batch 20, Loss: 0.7848
Batch 30, Loss: 0.9176
Batch 40, Loss: 0.8382
Batch 50, Loss: 0.8393
Batch 60, Loss: 0.8241
Batch 70, Loss: 0.9100
Batch 80, Loss: 0.8891
Batch 90, Loss: 0.8687
Batch 100, Loss: 0.9337
Batch 110, Loss: 0.9563
Batch 120, Loss: 0.9586
Batch 130, Loss: 0.9226
Batch 140, Loss: 0.8976
Batch 150, Loss: 0.9165
Batch 160, Loss: 0.9406
Batch 170, Loss: 0.9334
Batch 180, Loss: 0.9119
Batch 190, Loss: 0.9133
Batch 200, Loss: 0.9122
Batch 210, Loss: 0.9434
Batch 220, Loss: 0.9715
Batch 230, Loss: 0.9518
Batch 240, Loss: 0.9432
Batch 250, Loss: 0.9186
Batch 260, Loss: 0.9571
Batch 270, Loss: 0.9113
Batch 280, Loss: 0.9845
Batch 290, Loss: 0.9263
Batch 300, Loss: 0.9236
Batch 310, Loss: 0.9019
Batch 320, Loss: 0.9244
Batch 330, Loss: 0.8788
Batch 340, Loss: 0.9480
Batch 350, Loss: 0.9181
Batch 360, Loss: 0.9675
Batch 370, Loss: 0.9387
Batch 380, Loss: 0.9557
Batch 390, Loss: 0.9898
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.00220251083374 seconds
Epoch 47 accuracy: 58.63%
Batch 10, Loss: 0.9051
Batch 20, Loss: 0.8374
Batch 30, Loss: 0.8734
Batch 40, Loss: 0.8618
Batch 50, Loss: 0.8841
Batch 60, Loss: 0.8467
Batch 70, Loss: 0.8611
Batch 80, Loss: 0.7934
Batch 90, Loss: 0.8232
Batch 100, Loss: 0.8544
Batch 110, Loss: 0.8788
Batch 120, Loss: 0.8656
Batch 130, Loss: 0.8826
Batch 140, Loss: 0.8919
Batch 150, Loss: 0.8605
Batch 160, Loss: 0.9258
Batch 170, Loss: 0.8915
Batch 180, Loss: 0.8951
Batch 190, Loss: 0.9130
Batch 200, Loss: 0.9309
Batch 210, Loss: 0.9894
Batch 220, Loss: 0.9384
Batch 230, Loss: 0.9031
Batch 240, Loss: 0.9486
Batch 250, Loss: 0.8889
Batch 260, Loss: 0.9112
Batch 270, Loss: 0.9274
Batch 280, Loss: 0.9552
Batch 290, Loss: 0.9665
Batch 300, Loss: 0.9308
Batch 310, Loss: 0.9545
Batch 320, Loss: 0.9849
Batch 330, Loss: 0.9150
Batch 340, Loss: 0.9574
Batch 350, Loss: 0.9375
Batch 360, Loss: 0.9110
Batch 370, Loss: 0.8920
Batch 380, Loss: 0.9698
Batch 390, Loss: 0.9328
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.054064750671387 seconds
Epoch 48 accuracy: 59.5%
Batch 10, Loss: 0.8674
Batch 20, Loss: 0.8596
Batch 30, Loss: 0.8139
Batch 40, Loss: 0.7885
Batch 50, Loss: 0.7619
Batch 60, Loss: 0.8402
Batch 70, Loss: 0.8737
Batch 80, Loss: 0.8581
Batch 90, Loss: 0.9079
Batch 100, Loss: 0.8786
Batch 110, Loss: 0.8713
Batch 120, Loss: 0.8949
Batch 130, Loss: 0.8751
Batch 140, Loss: 0.8826
Batch 150, Loss: 0.9294
Batch 160, Loss: 0.8932
Batch 170, Loss: 0.9050
Batch 180, Loss: 0.8725
Batch 190, Loss: 0.9071
Batch 200, Loss: 0.9453
Batch 210, Loss: 0.9213
Batch 220, Loss: 0.9758
Batch 230, Loss: 0.8569
Batch 240, Loss: 0.9854
Batch 250, Loss: 0.9268
Batch 260, Loss: 0.9261
Batch 270, Loss: 0.9287
Batch 280, Loss: 0.9646
Batch 290, Loss: 0.9247
Batch 300, Loss: 0.9151
Batch 310, Loss: 0.9143
Batch 320, Loss: 0.9061
Batch 330, Loss: 0.9279
Batch 340, Loss: 0.9275
Batch 350, Loss: 0.9343
Batch 360, Loss: 0.9571
Batch 370, Loss: 0.9662
Batch 380, Loss: 1.0284
Batch 390, Loss: 1.0283
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.195719957351685 seconds
Epoch 49 accuracy: 57.09%
Batch 10, Loss: 0.8368
Batch 20, Loss: 0.8457
Batch 30, Loss: 0.8113
Batch 40, Loss: 0.8509
Batch 50, Loss: 0.8632
Batch 60, Loss: 0.9186
Batch 70, Loss: 0.8383
Batch 80, Loss: 0.8416
Batch 90, Loss: 0.8383
Batch 100, Loss: 0.8831
Batch 110, Loss: 0.8656
Batch 120, Loss: 0.8645
Batch 130, Loss: 0.8393
Batch 140, Loss: 0.9277
Batch 150, Loss: 0.9317
Batch 160, Loss: 0.9012
Batch 170, Loss: 0.8914
Batch 180, Loss: 0.8733
Batch 190, Loss: 0.9144
Batch 200, Loss: 0.9167
Batch 210, Loss: 0.9634
Batch 220, Loss: 0.9545
Batch 230, Loss: 0.9204
Batch 240, Loss: 0.9056
Batch 250, Loss: 0.9421
Batch 260, Loss: 0.9309
Batch 270, Loss: 0.9205
Batch 280, Loss: 0.9516
Batch 290, Loss: 0.9306
Batch 300, Loss: 0.9255
Batch 310, Loss: 0.9496
Batch 320, Loss: 0.9371
Batch 330, Loss: 0.9148
Batch 340, Loss: 0.8907
Batch 350, Loss: 0.9423
Batch 360, Loss: 0.9693
Batch 370, Loss: 0.8970
Batch 380, Loss: 0.9779
Batch 390, Loss: 0.9250
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 24.99416422843933 seconds
Epoch 50 accuracy: 63.18%
Batch 10, Loss: 0.8293
Batch 20, Loss: 0.8526
Batch 30, Loss: 0.8405
Batch 40, Loss: 0.8432
Batch 50, Loss: 0.8494
Batch 60, Loss: 0.7933
Batch 70, Loss: 0.8568
Batch 80, Loss: 0.8732
Batch 90, Loss: 0.8127
Batch 100, Loss: 0.9087
Batch 110, Loss: 0.8607
Batch 120, Loss: 0.8572
Batch 130, Loss: 0.8932
Batch 140, Loss: 0.8584
Batch 150, Loss: 0.8672
Batch 160, Loss: 0.8827
Batch 170, Loss: 0.8400
Batch 180, Loss: 0.8842
Batch 190, Loss: 0.8520
Batch 200, Loss: 0.9213
Batch 210, Loss: 0.9048
Batch 220, Loss: 0.9118
Batch 230, Loss: 0.8915
Batch 240, Loss: 0.8974
Batch 250, Loss: 0.8854
Batch 260, Loss: 0.9102
Batch 270, Loss: 0.8848
Batch 280, Loss: 0.8854
Batch 290, Loss: 0.9676
Batch 300, Loss: 0.9688
Batch 310, Loss: 0.9145
Batch 320, Loss: 0.8964
Batch 330, Loss: 0.9063
Batch 340, Loss: 0.9085
Batch 350, Loss: 1.0121
Batch 360, Loss: 0.9630
Batch 370, Loss: 1.0002
Batch 380, Loss: 0.9665
Batch 390, Loss: 0.9495
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.0218243598938 seconds
Epoch 51 accuracy: 61.65%
Batch 10, Loss: 0.8049
Batch 20, Loss: 0.8127
Batch 30, Loss: 0.8676
Batch 40, Loss: 0.8265
Batch 50, Loss: 0.8168
Batch 60, Loss: 0.8349
Batch 70, Loss: 0.8395
Batch 80, Loss: 0.8410
Batch 90, Loss: 0.8065
Batch 100, Loss: 0.8647
Batch 110, Loss: 0.8119
Batch 120, Loss: 0.8788
Batch 130, Loss: 0.7904
Batch 140, Loss: 0.7958
Batch 150, Loss: 0.8627
Batch 160, Loss: 0.8906
Batch 170, Loss: 0.8781
Batch 180, Loss: 0.8847
Batch 190, Loss: 0.8579
Batch 200, Loss: 0.9334
Batch 210, Loss: 0.9167
Batch 220, Loss: 0.8756
Batch 230, Loss: 0.9057
Batch 240, Loss: 0.8937
Batch 250, Loss: 0.8978
Batch 260, Loss: 0.9039
Batch 270, Loss: 0.9082
Batch 280, Loss: 0.9013
Batch 290, Loss: 0.9355
Batch 300, Loss: 0.9190
Batch 310, Loss: 0.9269
Batch 320, Loss: 0.9159
Batch 330, Loss: 0.9386
Batch 340, Loss: 0.9790
Batch 350, Loss: 0.9422
Batch 360, Loss: 0.9030
Batch 370, Loss: 0.9657
Batch 380, Loss: 0.9363
Batch 390, Loss: 0.9567
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.128568172454834 seconds
Epoch 52 accuracy: 60.71%
Batch 10, Loss: 0.8899
Batch 20, Loss: 0.8356
Batch 30, Loss: 0.8276
Batch 40, Loss: 0.7991
Batch 50, Loss: 0.8864
Batch 60, Loss: 0.8488
Batch 70, Loss: 0.8444
Batch 80, Loss: 0.8135
Batch 90, Loss: 0.8582
Batch 100, Loss: 0.8579
Batch 110, Loss: 0.8086
Batch 120, Loss: 0.7884
Batch 130, Loss: 0.8489
Batch 140, Loss: 0.8362
Batch 150, Loss: 0.9465
Batch 160, Loss: 0.8341
Batch 170, Loss: 0.9097
Batch 180, Loss: 0.8443
Batch 190, Loss: 0.8293
Batch 200, Loss: 0.8687
Batch 210, Loss: 0.9209
Batch 220, Loss: 0.8985
Batch 230, Loss: 0.9660
Batch 240, Loss: 0.9458
Batch 250, Loss: 0.8931
Batch 260, Loss: 0.8963
Batch 270, Loss: 0.8920
Batch 280, Loss: 0.8531
Batch 290, Loss: 0.9186
Batch 300, Loss: 0.8993
Batch 310, Loss: 0.8851
Batch 320, Loss: 0.8852
Batch 330, Loss: 0.8970
Batch 340, Loss: 0.9488
Batch 350, Loss: 0.9564
Batch 360, Loss: 0.9526
Batch 370, Loss: 0.9283
Batch 380, Loss: 0.9779
Batch 390, Loss: 0.9308
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.234662532806396 seconds
Epoch 53 accuracy: 58.0%
Batch 10, Loss: 0.8181
Batch 20, Loss: 0.8794
Batch 30, Loss: 0.8636
Batch 40, Loss: 0.8428
Batch 50, Loss: 0.8291
Batch 60, Loss: 0.8131
Batch 70, Loss: 0.8257
Batch 80, Loss: 0.8636
Batch 90, Loss: 0.9331
Batch 100, Loss: 0.8800
Batch 110, Loss: 0.8185
Batch 120, Loss: 0.8529
Batch 130, Loss: 0.8058
Batch 140, Loss: 0.8746
Batch 150, Loss: 0.8727
Batch 160, Loss: 0.8817
Batch 170, Loss: 0.8684
Batch 180, Loss: 0.8991
Batch 190, Loss: 0.9420
Batch 200, Loss: 0.8620
Batch 210, Loss: 0.9096
Batch 220, Loss: 0.9205
Batch 230, Loss: 0.8890
Batch 240, Loss: 0.8439
Batch 250, Loss: 0.8703
Batch 260, Loss: 0.8493
Batch 270, Loss: 0.9380
Batch 280, Loss: 0.9166
Batch 290, Loss: 0.9289
Batch 300, Loss: 0.8990
Batch 310, Loss: 0.9163
Batch 320, Loss: 0.8978
Batch 330, Loss: 0.8755
Batch 340, Loss: 0.8996
Batch 350, Loss: 0.9301
Batch 360, Loss: 0.8909
Batch 370, Loss: 0.9031
Batch 380, Loss: 0.9679
Batch 390, Loss: 0.9639
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.080118656158447 seconds
Epoch 54 accuracy: 59.35%
Batch 10, Loss: 0.8138
Batch 20, Loss: 0.8186
Batch 30, Loss: 0.8321
Batch 40, Loss: 0.7965
Batch 50, Loss: 0.8678
Batch 60, Loss: 0.7804
Batch 70, Loss: 0.8370
Batch 80, Loss: 0.8174
Batch 90, Loss: 0.7602
Batch 100, Loss: 0.8239
Batch 110, Loss: 0.8218
Batch 120, Loss: 0.8684
Batch 130, Loss: 0.8284
Batch 140, Loss: 0.8367
Batch 150, Loss: 0.8658
Batch 160, Loss: 0.8608
Batch 170, Loss: 0.8637
Batch 180, Loss: 0.8880
Batch 190, Loss: 0.8480
Batch 200, Loss: 0.9038
Batch 210, Loss: 0.8434
Batch 220, Loss: 0.9138
Batch 230, Loss: 0.9418
Batch 240, Loss: 0.8825
Batch 250, Loss: 0.8904
Batch 260, Loss: 0.9028
Batch 270, Loss: 0.9101
Batch 280, Loss: 0.8939
Batch 290, Loss: 0.9141
Batch 300, Loss: 0.9132
Batch 310, Loss: 0.9736
Batch 320, Loss: 0.8924
Batch 330, Loss: 0.8693
Batch 340, Loss: 0.9230
Batch 350, Loss: 0.8561
Batch 360, Loss: 0.8889
Batch 370, Loss: 0.9078
Batch 380, Loss: 0.9241
Batch 390, Loss: 0.9534
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.22038459777832 seconds
Epoch 55 accuracy: 63.33%
Batch 10, Loss: 0.7728
Batch 20, Loss: 0.7749
Batch 30, Loss: 0.7978
Batch 40, Loss: 0.7466
Batch 50, Loss: 0.8061
Batch 60, Loss: 0.8250
Batch 70, Loss: 0.8518
Batch 80, Loss: 0.7863
Batch 90, Loss: 0.8422
Batch 100, Loss: 0.8860
Batch 110, Loss: 0.8779
Batch 120, Loss: 0.8707
Batch 130, Loss: 0.8260
Batch 140, Loss: 0.8374
Batch 150, Loss: 0.8842
Batch 160, Loss: 0.8141
Batch 170, Loss: 0.9340
Batch 180, Loss: 0.8510
Batch 190, Loss: 0.9182
Batch 200, Loss: 0.8362
Batch 210, Loss: 0.9371
Batch 220, Loss: 0.8379
Batch 230, Loss: 0.8651
Batch 240, Loss: 0.8645
Batch 250, Loss: 0.8741
Batch 260, Loss: 0.8740
Batch 270, Loss: 0.8959
Batch 280, Loss: 0.9163
Batch 290, Loss: 0.8772
Batch 300, Loss: 0.8488
Batch 310, Loss: 0.9063
Batch 320, Loss: 0.8501
Batch 330, Loss: 0.8560
Batch 340, Loss: 0.8738
Batch 350, Loss: 0.9158
Batch 360, Loss: 0.9086
Batch 370, Loss: 0.8781
Batch 380, Loss: 0.8640
Batch 390, Loss: 0.8831
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.066192388534546 seconds
Epoch 56 accuracy: 60.45%
Batch 10, Loss: 0.7547
Batch 20, Loss: 0.8234
Batch 30, Loss: 0.8027
Batch 40, Loss: 0.7807
Batch 50, Loss: 0.8454
Batch 60, Loss: 0.8158
Batch 70, Loss: 0.8645
Batch 80, Loss: 0.8034
Batch 90, Loss: 0.8421
Batch 100, Loss: 0.8048
Batch 110, Loss: 0.8495
Batch 120, Loss: 0.8321
Batch 130, Loss: 0.8603
Batch 140, Loss: 0.7981
Batch 150, Loss: 0.8975
Batch 160, Loss: 0.8011
Batch 170, Loss: 0.8197
Batch 180, Loss: 0.8117
Batch 190, Loss: 0.8672
Batch 200, Loss: 0.9186
Batch 210, Loss: 0.8807
Batch 220, Loss: 0.9002
Batch 230, Loss: 0.8689
Batch 240, Loss: 0.9004
Batch 250, Loss: 0.8289
Batch 260, Loss: 0.8557
Batch 270, Loss: 0.8565
Batch 280, Loss: 0.8800
Batch 290, Loss: 0.8979
Batch 300, Loss: 0.9430
Batch 310, Loss: 0.8650
Batch 320, Loss: 0.8762
Batch 330, Loss: 0.8820
Batch 340, Loss: 0.9152
Batch 350, Loss: 0.8631
Batch 360, Loss: 0.8880
Batch 370, Loss: 0.9234
Batch 380, Loss: 0.8783
Batch 390, Loss: 0.9217
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.08992052078247 seconds
Epoch 57 accuracy: 59.73%
Batch 10, Loss: 0.7706
Batch 20, Loss: 0.7573
Batch 30, Loss: 0.8278
Batch 40, Loss: 0.8486
Batch 50, Loss: 0.7745
Batch 60, Loss: 0.8189
Batch 70, Loss: 0.7677
Batch 80, Loss: 0.7702
Batch 90, Loss: 0.7920
Batch 100, Loss: 0.7988
Batch 110, Loss: 0.8239
Batch 120, Loss: 0.8109
Batch 130, Loss: 0.7949
Batch 140, Loss: 0.8132
Batch 150, Loss: 0.8618
Batch 160, Loss: 0.8568
Batch 170, Loss: 0.8868
Batch 180, Loss: 0.8593
Batch 190, Loss: 0.8721
Batch 200, Loss: 0.9227
Batch 210, Loss: 0.8546
Batch 220, Loss: 0.8451
Batch 230, Loss: 0.8347
Batch 240, Loss: 0.8774
Batch 250, Loss: 0.9166
Batch 260, Loss: 0.9262
Batch 270, Loss: 0.8374
Batch 280, Loss: 0.8646
Batch 290, Loss: 0.9078
Batch 300, Loss: 0.8536
Batch 310, Loss: 0.9256
Batch 320, Loss: 0.8549
Batch 330, Loss: 0.8784
Batch 340, Loss: 0.9159
Batch 350, Loss: 0.8977
Batch 360, Loss: 0.9031
Batch 370, Loss: 0.8574
Batch 380, Loss: 0.8654
Batch 390, Loss: 0.9226
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 24.994937896728516 seconds
Epoch 58 accuracy: 61.92%
Batch 10, Loss: 0.8251
Batch 20, Loss: 0.7229
Batch 30, Loss: 0.8123
Batch 40, Loss: 0.7535
Batch 50, Loss: 0.7921
Batch 60, Loss: 0.8108
Batch 70, Loss: 0.8119
Batch 80, Loss: 0.8262
Batch 90, Loss: 0.8107
Batch 100, Loss: 0.8488
Batch 110, Loss: 0.7810
Batch 120, Loss: 0.8032
Batch 130, Loss: 0.7445
Batch 140, Loss: 0.8185
Batch 150, Loss: 0.8554
Batch 160, Loss: 0.8633
Batch 170, Loss: 0.8157
Batch 180, Loss: 0.8363
Batch 190, Loss: 0.7637
Batch 200, Loss: 0.8070
Batch 210, Loss: 0.8242
Batch 220, Loss: 0.8300
Batch 230, Loss: 0.8508
Batch 240, Loss: 0.8791
Batch 250, Loss: 0.8639
Batch 260, Loss: 0.8376
Batch 270, Loss: 0.8794
Batch 280, Loss: 0.8731
Batch 290, Loss: 0.8868
Batch 300, Loss: 0.8561
Batch 310, Loss: 0.8685
Batch 320, Loss: 0.9129
Batch 330, Loss: 0.9026
Batch 340, Loss: 0.8482
Batch 350, Loss: 0.9205
Batch 360, Loss: 0.9434
Batch 370, Loss: 0.9033
Batch 380, Loss: 0.8741
Batch 390, Loss: 0.9126
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.076401233673096 seconds
Epoch 59 accuracy: 59.49%
Batch 10, Loss: 0.8125
Batch 20, Loss: 0.7605
Batch 30, Loss: 0.7982
Batch 40, Loss: 0.7747
Batch 50, Loss: 0.8240
Batch 60, Loss: 0.7634
Batch 70, Loss: 0.8182
Batch 80, Loss: 0.7605
Batch 90, Loss: 0.8423
Batch 100, Loss: 0.7969
Batch 110, Loss: 0.7428
Batch 120, Loss: 0.8044
Batch 130, Loss: 0.8504
Batch 140, Loss: 0.8318
Batch 150, Loss: 0.7725
Batch 160, Loss: 0.8365
Batch 170, Loss: 0.7966
Batch 180, Loss: 0.8400
Batch 190, Loss: 0.7743
Batch 200, Loss: 0.8434
Batch 210, Loss: 0.8081
Batch 220, Loss: 0.8401
Batch 230, Loss: 0.8559
Batch 240, Loss: 0.8646
Batch 250, Loss: 0.8514
Batch 260, Loss: 0.8600
Batch 270, Loss: 0.9134
Batch 280, Loss: 0.9385
Batch 290, Loss: 0.9213
Batch 300, Loss: 0.9224
Batch 310, Loss: 0.8943
Batch 320, Loss: 0.8260
Batch 330, Loss: 0.8877
Batch 340, Loss: 0.8882
Batch 350, Loss: 0.8651
Batch 360, Loss: 0.8815
Batch 370, Loss: 0.8768
Batch 380, Loss: 0.9354
Batch 390, Loss: 0.9064
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.302513360977173 seconds
Epoch 60 accuracy: 60.8%
Batch 10, Loss: 0.7914
Batch 20, Loss: 0.7347
Batch 30, Loss: 0.6931
Batch 40, Loss: 0.7630
Batch 50, Loss: 0.7309
Batch 60, Loss: 0.7750
Batch 70, Loss: 0.8241
Batch 80, Loss: 0.7668
Batch 90, Loss: 0.7974
Batch 100, Loss: 0.8224
Batch 110, Loss: 0.8069
Batch 120, Loss: 0.7795
Batch 130, Loss: 0.8180
Batch 140, Loss: 0.7621
Batch 150, Loss: 0.7836
Batch 160, Loss: 0.8121
Batch 170, Loss: 0.8034
Batch 180, Loss: 0.7940
Batch 190, Loss: 0.8594
Batch 200, Loss: 0.8751
Batch 210, Loss: 0.8595
Batch 220, Loss: 0.8326
Batch 230, Loss: 0.8695
Batch 240, Loss: 0.8493
Batch 250, Loss: 0.8645
Batch 260, Loss: 0.8325
Batch 270, Loss: 0.8862
Batch 280, Loss: 0.8365
Batch 290, Loss: 0.8285
Batch 300, Loss: 0.9569
Batch 310, Loss: 0.9418
Batch 320, Loss: 0.8572
Batch 330, Loss: 0.8302
Batch 340, Loss: 0.8725
Batch 350, Loss: 0.9216
Batch 360, Loss: 0.8543
Batch 370, Loss: 0.8803
Batch 380, Loss: 0.9032
Batch 390, Loss: 0.9270
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.180249452590942 seconds
Epoch 61 accuracy: 60.03%
Batch 10, Loss: 0.7541
Batch 20, Loss: 0.7678
Batch 30, Loss: 0.7562
Batch 40, Loss: 0.7825
Batch 50, Loss: 0.7553
Batch 60, Loss: 0.7878
Batch 70, Loss: 0.7894
Batch 80, Loss: 0.7778
Batch 90, Loss: 0.8075
Batch 100, Loss: 0.8114
Batch 110, Loss: 0.7977
Batch 120, Loss: 0.7888
Batch 130, Loss: 0.7770
Batch 140, Loss: 0.7629
Batch 150, Loss: 0.8063
Batch 160, Loss: 0.8008
Batch 170, Loss: 0.8092
Batch 180, Loss: 0.8203
Batch 190, Loss: 0.8113
Batch 200, Loss: 0.8507
Batch 210, Loss: 0.8044
Batch 220, Loss: 0.8041
Batch 230, Loss: 0.8508
Batch 240, Loss: 0.7642
Batch 250, Loss: 0.8809
Batch 260, Loss: 0.8727
Batch 270, Loss: 0.8588
Batch 280, Loss: 0.8968
Batch 290, Loss: 0.8674
Batch 300, Loss: 0.8631
Batch 310, Loss: 0.8710
Batch 320, Loss: 0.8629
Batch 330, Loss: 0.8816
Batch 340, Loss: 0.9161
Batch 350, Loss: 0.8922
Batch 360, Loss: 0.8074
Batch 370, Loss: 0.8485
Batch 380, Loss: 0.7715
Batch 390, Loss: 0.9252
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.03282141685486 seconds
Epoch 62 accuracy: 62.68%
Batch 10, Loss: 0.7804
Batch 20, Loss: 0.7439
Batch 30, Loss: 0.7612
Batch 40, Loss: 0.7407
Batch 50, Loss: 0.7388
Batch 60, Loss: 0.7465
Batch 70, Loss: 0.8038
Batch 80, Loss: 0.7720
Batch 90, Loss: 0.7731
Batch 100, Loss: 0.7721
Batch 110, Loss: 0.8174
Batch 120, Loss: 0.7740
Batch 130, Loss: 0.7734
Batch 140, Loss: 0.8283
Batch 150, Loss: 0.8463
Batch 160, Loss: 0.8516
Batch 170, Loss: 0.8166
Batch 180, Loss: 0.8795
Batch 190, Loss: 0.8303
Batch 200, Loss: 0.8745
Batch 210, Loss: 0.8229
Batch 220, Loss: 0.8559
Batch 230, Loss: 0.8993
Batch 240, Loss: 0.8562
Batch 250, Loss: 0.8395
Batch 260, Loss: 0.7883
Batch 270, Loss: 0.8341
Batch 280, Loss: 0.8156
Batch 290, Loss: 0.9006
Batch 300, Loss: 0.8700
Batch 310, Loss: 0.8502
Batch 320, Loss: 0.8727
Batch 330, Loss: 0.9012
Batch 340, Loss: 0.8232
Batch 350, Loss: 0.9079
Batch 360, Loss: 0.8697
Batch 370, Loss: 0.8689
Batch 380, Loss: 0.8661
Batch 390, Loss: 0.8223
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.041404008865356 seconds
Epoch 63 accuracy: 64.43%
Batch 10, Loss: 0.7373
Batch 20, Loss: 0.7227
Batch 30, Loss: 0.7762
Batch 40, Loss: 0.7434
Batch 50, Loss: 0.7685
Batch 60, Loss: 0.7536
Batch 70, Loss: 0.7592
Batch 80, Loss: 0.8467
Batch 90, Loss: 0.7949
Batch 100, Loss: 0.7707
Batch 110, Loss: 0.7738
Batch 120, Loss: 0.8508
Batch 130, Loss: 0.7853
Batch 140, Loss: 0.7844
Batch 150, Loss: 0.8106
Batch 160, Loss: 0.8146
Batch 170, Loss: 0.8532
Batch 180, Loss: 0.8581
Batch 190, Loss: 0.8376
Batch 200, Loss: 0.8108
Batch 210, Loss: 0.8075
Batch 220, Loss: 0.8160
Batch 230, Loss: 0.8253
Batch 240, Loss: 0.8215
Batch 250, Loss: 0.9079
Batch 260, Loss: 0.8438
Batch 270, Loss: 0.8500
Batch 280, Loss: 0.8389
Batch 290, Loss: 0.8132
Batch 300, Loss: 0.8091
Batch 310, Loss: 0.8296
Batch 320, Loss: 0.8906
Batch 330, Loss: 0.8444
Batch 340, Loss: 0.8422
Batch 350, Loss: 0.8534
Batch 360, Loss: 0.8579
Batch 370, Loss: 0.8623
Batch 380, Loss: 0.8673
Batch 390, Loss: 0.8441
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 24.963046073913574 seconds
Epoch 64 accuracy: 61.64%
Batch 10, Loss: 0.7614
Batch 20, Loss: 0.7507
Batch 30, Loss: 0.7463
Batch 40, Loss: 0.7111
Batch 50, Loss: 0.6800
Batch 60, Loss: 0.7421
Batch 70, Loss: 0.8056
Batch 80, Loss: 0.8114
Batch 90, Loss: 0.7853
Batch 100, Loss: 0.7930
Batch 110, Loss: 0.7856
Batch 120, Loss: 0.7779
Batch 130, Loss: 0.7616
Batch 140, Loss: 0.8226
Batch 150, Loss: 0.7495
Batch 160, Loss: 0.8028
Batch 170, Loss: 0.8324
Batch 180, Loss: 0.7836
Batch 190, Loss: 0.7986
Batch 200, Loss: 0.8400
Batch 210, Loss: 0.8455
Batch 220, Loss: 0.8416
Batch 230, Loss: 0.7914
Batch 240, Loss: 0.8816
Batch 250, Loss: 0.7903
Batch 260, Loss: 0.8271
Batch 270, Loss: 0.9027
Batch 280, Loss: 0.9050
Batch 290, Loss: 0.8675
Batch 300, Loss: 0.8634
Batch 310, Loss: 0.8834
Batch 320, Loss: 0.8440
Batch 330, Loss: 0.8452
Batch 340, Loss: 0.8626
Batch 350, Loss: 0.8750
Batch 360, Loss: 0.8564
Batch 370, Loss: 0.8723
Batch 380, Loss: 0.8833
Batch 390, Loss: 0.8474
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.05575966835022 seconds
Epoch 65 accuracy: 62.58%
Batch 10, Loss: 0.7569
Batch 20, Loss: 0.6775
Batch 30, Loss: 0.7140
Batch 40, Loss: 0.7680
Batch 50, Loss: 0.7339
Batch 60, Loss: 0.7113
Batch 70, Loss: 0.7377
Batch 80, Loss: 0.7682
Batch 90, Loss: 0.7273
Batch 100, Loss: 0.8039
Batch 110, Loss: 0.7467
Batch 120, Loss: 0.7439
Batch 130, Loss: 0.7641
Batch 140, Loss: 0.8025
Batch 150, Loss: 0.8557
Batch 160, Loss: 0.7516
Batch 170, Loss: 0.8510
Batch 180, Loss: 0.8379
Batch 190, Loss: 0.8163
Batch 200, Loss: 0.8064
Batch 210, Loss: 0.7998
Batch 220, Loss: 0.8373
Batch 230, Loss: 0.8581
Batch 240, Loss: 0.7983
Batch 250, Loss: 0.8689
Batch 260, Loss: 0.8097
Batch 270, Loss: 0.8520
Batch 280, Loss: 0.8096
Batch 290, Loss: 0.8609
Batch 300, Loss: 0.7990
Batch 310, Loss: 0.8117
Batch 320, Loss: 0.8725
Batch 330, Loss: 0.8737
Batch 340, Loss: 0.8399
Batch 350, Loss: 0.8442
Batch 360, Loss: 0.8570
Batch 370, Loss: 0.8753
Batch 380, Loss: 0.8348
Batch 390, Loss: 0.8903
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.06935715675354 seconds
Epoch 66 accuracy: 63.23%
Batch 10, Loss: 0.7583
Batch 20, Loss: 0.6974
Batch 30, Loss: 0.7256
Batch 40, Loss: 0.7468
Batch 50, Loss: 0.7233
Batch 60, Loss: 0.7478
Batch 70, Loss: 0.7539
Batch 80, Loss: 0.7386
Batch 90, Loss: 0.7851
Batch 100, Loss: 0.7541
Batch 110, Loss: 0.7751
Batch 120, Loss: 0.7650
Batch 130, Loss: 0.7968
Batch 140, Loss: 0.7916
Batch 150, Loss: 0.7274
Batch 160, Loss: 0.8338
Batch 170, Loss: 0.8307
Batch 180, Loss: 0.8418
Batch 190, Loss: 0.8261
Batch 200, Loss: 0.7748
Batch 210, Loss: 0.8187
Batch 220, Loss: 0.7746
Batch 230, Loss: 0.8388
Batch 240, Loss: 0.7414
Batch 250, Loss: 0.7707
Batch 260, Loss: 0.7754
Batch 270, Loss: 0.7708
Batch 280, Loss: 0.8412
Batch 290, Loss: 0.7620
Batch 300, Loss: 0.7961
Batch 310, Loss: 0.8266
Batch 320, Loss: 0.8199
Batch 330, Loss: 0.8456
Batch 340, Loss: 0.8594
Batch 350, Loss: 0.8589
Batch 360, Loss: 0.8549
Batch 370, Loss: 0.8139
Batch 380, Loss: 0.8987
Batch 390, Loss: 0.8635
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.554110765457153 seconds
Epoch 67 accuracy: 61.26%
Batch 10, Loss: 0.6993
Batch 20, Loss: 0.6978
Batch 30, Loss: 0.7261
Batch 40, Loss: 0.7040
Batch 50, Loss: 0.7090
Batch 60, Loss: 0.7427
Batch 70, Loss: 0.7583
Batch 80, Loss: 0.7388
Batch 90, Loss: 0.7231
Batch 100, Loss: 0.7975
Batch 110, Loss: 0.7986
Batch 120, Loss: 0.7575
Batch 130, Loss: 0.8069
Batch 140, Loss: 0.7733
Batch 150, Loss: 0.7692
Batch 160, Loss: 0.7670
Batch 170, Loss: 0.8215
Batch 180, Loss: 0.8655
Batch 190, Loss: 0.8073
Batch 200, Loss: 0.7354
Batch 210, Loss: 0.7761
Batch 220, Loss: 0.7828
Batch 230, Loss: 0.8016
Batch 240, Loss: 0.8202
Batch 250, Loss: 0.7761
Batch 260, Loss: 0.8073
Batch 270, Loss: 0.8270
Batch 280, Loss: 0.8377
Batch 290, Loss: 0.8246
Batch 300, Loss: 0.8339
Batch 310, Loss: 0.8721
Batch 320, Loss: 0.8248
Batch 330, Loss: 0.8759
Batch 340, Loss: 0.8458
Batch 350, Loss: 0.8656
Batch 360, Loss: 0.8440
Batch 370, Loss: 0.8562
Batch 380, Loss: 0.8149
Batch 390, Loss: 0.8571
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 24.983131647109985 seconds
Epoch 68 accuracy: 64.89%
Batch 10, Loss: 0.7221
Batch 20, Loss: 0.7064
Batch 30, Loss: 0.7346
Batch 40, Loss: 0.7474
Batch 50, Loss: 0.7135
Batch 60, Loss: 0.7471
Batch 70, Loss: 0.7412
Batch 80, Loss: 0.7223
Batch 90, Loss: 0.7439
Batch 100, Loss: 0.7762
Batch 110, Loss: 0.7798
Batch 120, Loss: 0.7952
Batch 130, Loss: 0.7129
Batch 140, Loss: 0.7520
Batch 150, Loss: 0.7515
Batch 160, Loss: 0.7747
Batch 170, Loss: 0.8040
Batch 180, Loss: 0.7918
Batch 190, Loss: 0.8399
Batch 200, Loss: 0.8346
Batch 210, Loss: 0.7778
Batch 220, Loss: 0.8151
Batch 230, Loss: 0.8311
Batch 240, Loss: 0.7797
Batch 250, Loss: 0.8232
Batch 260, Loss: 0.7820
Batch 270, Loss: 0.8593
Batch 280, Loss: 0.8458
Batch 290, Loss: 0.8459
Batch 300, Loss: 0.7861
Batch 310, Loss: 0.7958
Batch 320, Loss: 0.8667
Batch 330, Loss: 0.8293
Batch 340, Loss: 0.8303
Batch 350, Loss: 0.8381
Batch 360, Loss: 0.8307
Batch 370, Loss: 0.7871
Batch 380, Loss: 0.8484
Batch 390, Loss: 0.8164
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.029751777648926 seconds
Epoch 69 accuracy: 61.75%
Batch 10, Loss: 0.7166
Batch 20, Loss: 0.7169
Batch 30, Loss: 0.7266
Batch 40, Loss: 0.7078
Batch 50, Loss: 0.6625
Batch 60, Loss: 0.7223
Batch 70, Loss: 0.7623
Batch 80, Loss: 0.7211
Batch 90, Loss: 0.6943
Batch 100, Loss: 0.7323
Batch 110, Loss: 0.7209
Batch 120, Loss: 0.7162
Batch 130, Loss: 0.7543
Batch 140, Loss: 0.7405
Batch 150, Loss: 0.7334
Batch 160, Loss: 0.7940
Batch 170, Loss: 0.7839
Batch 180, Loss: 0.7840
Batch 190, Loss: 0.8190
Batch 200, Loss: 0.8503
Batch 210, Loss: 0.8495
Batch 220, Loss: 0.8562
Batch 230, Loss: 0.8012
Batch 240, Loss: 0.8340
Batch 250, Loss: 0.8341
Batch 260, Loss: 0.8516
Batch 270, Loss: 0.8571
Batch 280, Loss: 0.7721
Batch 290, Loss: 0.8192
Batch 300, Loss: 0.7791
Batch 310, Loss: 0.7851
Batch 320, Loss: 0.7996
Batch 330, Loss: 0.7916
Batch 340, Loss: 0.8058
Batch 350, Loss: 0.8295
Batch 360, Loss: 0.8015
Batch 370, Loss: 0.8218
Batch 380, Loss: 0.8570
Batch 390, Loss: 0.7863
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.07379651069641 seconds
Epoch 70 accuracy: 64.82%
Batch 10, Loss: 0.7520
Batch 20, Loss: 0.6808
Batch 30, Loss: 0.7216
Batch 40, Loss: 0.7475
Batch 50, Loss: 0.7162
Batch 60, Loss: 0.7250
Batch 70, Loss: 0.7187
Batch 80, Loss: 0.7016
Batch 90, Loss: 0.7420
Batch 100, Loss: 0.7109
Batch 110, Loss: 0.7084
Batch 120, Loss: 0.7975
Batch 130, Loss: 0.7606
Batch 140, Loss: 0.7531
Batch 150, Loss: 0.7073
Batch 160, Loss: 0.7385
Batch 170, Loss: 0.7836
Batch 180, Loss: 0.7703
Batch 190, Loss: 0.7793
Batch 200, Loss: 0.7671
Batch 210, Loss: 0.7941
Batch 220, Loss: 0.8196
Batch 230, Loss: 0.7735
Batch 240, Loss: 0.8197
Batch 250, Loss: 0.7652
Batch 260, Loss: 0.7798
Batch 270, Loss: 0.7689
Batch 280, Loss: 0.8274
Batch 290, Loss: 0.7981
Batch 300, Loss: 0.7956
Batch 310, Loss: 0.8205
Batch 320, Loss: 0.8700
Batch 330, Loss: 0.8422
Batch 340, Loss: 0.8422
Batch 350, Loss: 0.8315
Batch 360, Loss: 0.8347
Batch 370, Loss: 0.8398
Batch 380, Loss: 0.8514
Batch 390, Loss: 0.7776
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.065587043762207 seconds
Epoch 71 accuracy: 61.07%
Batch 10, Loss: 0.6904
Batch 20, Loss: 0.6879
Batch 30, Loss: 0.7009
Batch 40, Loss: 0.7185
Batch 50, Loss: 0.6926
Batch 60, Loss: 0.7450
Batch 70, Loss: 0.7217
Batch 80, Loss: 0.7367
Batch 90, Loss: 0.7618
Batch 100, Loss: 0.7215
Batch 110, Loss: 0.7631
Batch 120, Loss: 0.7402
Batch 130, Loss: 0.7312
Batch 140, Loss: 0.7324
Batch 150, Loss: 0.7532
Batch 160, Loss: 0.7019
Batch 170, Loss: 0.7192
Batch 180, Loss: 0.7690
Batch 190, Loss: 0.7728
Batch 200, Loss: 0.7846
Batch 210, Loss: 0.7760
Batch 220, Loss: 0.8022
Batch 230, Loss: 0.7872
Batch 240, Loss: 0.7701
Batch 250, Loss: 0.7627
Batch 260, Loss: 0.8046
Batch 270, Loss: 0.8138
Batch 280, Loss: 0.8163
Batch 290, Loss: 0.8193
Batch 300, Loss: 0.8307
Batch 310, Loss: 0.7909
Batch 320, Loss: 0.8281
Batch 330, Loss: 0.7901
Batch 340, Loss: 0.7896
Batch 350, Loss: 0.7851
Batch 360, Loss: 0.8244
Batch 370, Loss: 0.8277
Batch 380, Loss: 0.7743
Batch 390, Loss: 0.8129
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.197898626327515 seconds
Epoch 72 accuracy: 61.24%
Batch 10, Loss: 0.6703
Batch 20, Loss: 0.6654
Batch 30, Loss: 0.6719
Batch 40, Loss: 0.6785
Batch 50, Loss: 0.6954
Batch 60, Loss: 0.7016
Batch 70, Loss: 0.7257
Batch 80, Loss: 0.7281
Batch 90, Loss: 0.7254
Batch 100, Loss: 0.7222
Batch 110, Loss: 0.7710
Batch 120, Loss: 0.7270
Batch 130, Loss: 0.7749
Batch 140, Loss: 0.7883
Batch 150, Loss: 0.6979
Batch 160, Loss: 0.7824
Batch 170, Loss: 0.7198
Batch 180, Loss: 0.7743
Batch 190, Loss: 0.7439
Batch 200, Loss: 0.7446
Batch 210, Loss: 0.7208
Batch 220, Loss: 0.7508
Batch 230, Loss: 0.7562
Batch 240, Loss: 0.8079
Batch 250, Loss: 0.7767
Batch 260, Loss: 0.7576
Batch 270, Loss: 0.8259
Batch 280, Loss: 0.7906
Batch 290, Loss: 0.7781
Batch 300, Loss: 0.7824
Batch 310, Loss: 0.8186
Batch 320, Loss: 0.7748
Batch 330, Loss: 0.7927
Batch 340, Loss: 0.8092
Batch 350, Loss: 0.7628
Batch 360, Loss: 0.8609
Batch 370, Loss: 0.7462
Batch 380, Loss: 0.7988
Batch 390, Loss: 0.7978
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 24.946072578430176 seconds
Epoch 73 accuracy: 61.91%
Batch 10, Loss: 0.7490
Batch 20, Loss: 0.7596
Batch 30, Loss: 0.6632
Batch 40, Loss: 0.6493
Batch 50, Loss: 0.6933
Batch 60, Loss: 0.6808
Batch 70, Loss: 0.6902
Batch 80, Loss: 0.7171
Batch 90, Loss: 0.7298
Batch 100, Loss: 0.7548
Batch 110, Loss: 0.7431
Batch 120, Loss: 0.7597
Batch 130, Loss: 0.7389
Batch 140, Loss: 0.7212
Batch 150, Loss: 0.7564
Batch 160, Loss: 0.7444
Batch 170, Loss: 0.7867
Batch 180, Loss: 0.7796
Batch 190, Loss: 0.8184
Batch 200, Loss: 0.7397
Batch 210, Loss: 0.7801
Batch 220, Loss: 0.7724
Batch 230, Loss: 0.7212
Batch 240, Loss: 0.7699
Batch 250, Loss: 0.7477
Batch 260, Loss: 0.8214
Batch 270, Loss: 0.7653
Batch 280, Loss: 0.7996
Batch 290, Loss: 0.7751
Batch 300, Loss: 0.7608
Batch 310, Loss: 0.7902
Batch 320, Loss: 0.8333
Batch 330, Loss: 0.8014
Batch 340, Loss: 0.7915
Batch 350, Loss: 0.7979
Batch 360, Loss: 0.7978
Batch 370, Loss: 0.7920
Batch 380, Loss: 0.7767
Batch 390, Loss: 0.8070
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.13347601890564 seconds
Epoch 74 accuracy: 64.12%
Batch 10, Loss: 0.6951
Batch 20, Loss: 0.6779
Batch 30, Loss: 0.7031
Batch 40, Loss: 0.6516
Batch 50, Loss: 0.6766
Batch 60, Loss: 0.7475
Batch 70, Loss: 0.6984
Batch 80, Loss: 0.6973
Batch 90, Loss: 0.7127
Batch 100, Loss: 0.6760
Batch 110, Loss: 0.7430
Batch 120, Loss: 0.6814
Batch 130, Loss: 0.6951
Batch 140, Loss: 0.7394
Batch 150, Loss: 0.7431
Batch 160, Loss: 0.6919
Batch 170, Loss: 0.6904
Batch 180, Loss: 0.7250
Batch 190, Loss: 0.7951
Batch 200, Loss: 0.7614
Batch 210, Loss: 0.7819
Batch 220, Loss: 0.7690
Batch 230, Loss: 0.7586
Batch 240, Loss: 0.7813
Batch 250, Loss: 0.8114
Batch 260, Loss: 0.7886
Batch 270, Loss: 0.7886
Batch 280, Loss: 0.7784
Batch 290, Loss: 0.7106
Batch 300, Loss: 0.7773
Batch 310, Loss: 0.8141
Batch 320, Loss: 0.7832
Batch 330, Loss: 0.7949
Batch 340, Loss: 0.8032
Batch 350, Loss: 0.7944
Batch 360, Loss: 0.8012
Batch 370, Loss: 0.7417
Batch 380, Loss: 0.8323
Batch 390, Loss: 0.8213
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.169298887252808 seconds
Epoch 75 accuracy: 61.04%
Batch 10, Loss: 0.7141
Batch 20, Loss: 0.7377
Batch 30, Loss: 0.6616
Batch 40, Loss: 0.6502
Batch 50, Loss: 0.6470
Batch 60, Loss: 0.6793
Batch 70, Loss: 0.6772
Batch 80, Loss: 0.7083
Batch 90, Loss: 0.6490
Batch 100, Loss: 0.6762
Batch 110, Loss: 0.6625
Batch 120, Loss: 0.7066
Batch 130, Loss: 0.7180
Batch 140, Loss: 0.7052
Batch 150, Loss: 0.7813
Batch 160, Loss: 0.6786
Batch 170, Loss: 0.7240
Batch 180, Loss: 0.7140
Batch 190, Loss: 0.7297
Batch 200, Loss: 0.7105
Batch 210, Loss: 0.8160
Batch 220, Loss: 0.7676
Batch 230, Loss: 0.7951
Batch 240, Loss: 0.7521
Batch 250, Loss: 0.7904
Batch 260, Loss: 0.7767
Batch 270, Loss: 0.7850
Batch 280, Loss: 0.7277
Batch 290, Loss: 0.7507
Batch 300, Loss: 0.7798
Batch 310, Loss: 0.7627
Batch 320, Loss: 0.8231
Batch 330, Loss: 0.7723
Batch 340, Loss: 0.8288
Batch 350, Loss: 0.7811
Batch 360, Loss: 0.7931
Batch 370, Loss: 0.7496
Batch 380, Loss: 0.7725
Batch 390, Loss: 0.7642
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.10164165496826 seconds
Epoch 76 accuracy: 65.72%
Batch 10, Loss: 0.6733
Batch 20, Loss: 0.6520
Batch 30, Loss: 0.6823
Batch 40, Loss: 0.6935
Batch 50, Loss: 0.6953
Batch 60, Loss: 0.6622
Batch 70, Loss: 0.6732
Batch 80, Loss: 0.6688
Batch 90, Loss: 0.6621
Batch 100, Loss: 0.7296
Batch 110, Loss: 0.7392
Batch 120, Loss: 0.7145
Batch 130, Loss: 0.7174
Batch 140, Loss: 0.7217
Batch 150, Loss: 0.7251
Batch 160, Loss: 0.7100
Batch 170, Loss: 0.7401
Batch 180, Loss: 0.7003
Batch 190, Loss: 0.7501
Batch 200, Loss: 0.7183
Batch 210, Loss: 0.7741
Batch 220, Loss: 0.7268
Batch 230, Loss: 0.7830
Batch 240, Loss: 0.7518
Batch 250, Loss: 0.7735
Batch 260, Loss: 0.7854
Batch 270, Loss: 0.7770
Batch 280, Loss: 0.7994
Batch 290, Loss: 0.7668
Batch 300, Loss: 0.7768
Batch 310, Loss: 0.7242
Batch 320, Loss: 0.7693
Batch 330, Loss: 0.7694
Batch 340, Loss: 0.7248
Batch 350, Loss: 0.7453
Batch 360, Loss: 0.7724
Batch 370, Loss: 0.8043
Batch 380, Loss: 0.7894
Batch 390, Loss: 0.7781
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.055684566497803 seconds
Epoch 77 accuracy: 62.56%
Batch 10, Loss: 0.6760
Batch 20, Loss: 0.6385
Batch 30, Loss: 0.6660
Batch 40, Loss: 0.6628
Batch 50, Loss: 0.6551
Batch 60, Loss: 0.6647
Batch 70, Loss: 0.7274
Batch 80, Loss: 0.6747
Batch 90, Loss: 0.6430
Batch 100, Loss: 0.7608
Batch 110, Loss: 0.6943
Batch 120, Loss: 0.7198
Batch 130, Loss: 0.7184
Batch 140, Loss: 0.7061
Batch 150, Loss: 0.6620
Batch 160, Loss: 0.7506
Batch 170, Loss: 0.7516
Batch 180, Loss: 0.7201
Batch 190, Loss: 0.7545
Batch 200, Loss: 0.7367
Batch 210, Loss: 0.7037
Batch 220, Loss: 0.6907
Batch 230, Loss: 0.8023
Batch 240, Loss: 0.7597
Batch 250, Loss: 0.7696
Batch 260, Loss: 0.7792
Batch 270, Loss: 0.7625
Batch 280, Loss: 0.7478
Batch 290, Loss: 0.8385
Batch 300, Loss: 0.7451
Batch 310, Loss: 0.7173
Batch 320, Loss: 0.7647
Batch 330, Loss: 0.7668
Batch 340, Loss: 0.7421
Batch 350, Loss: 0.7967
Batch 360, Loss: 0.8060
Batch 370, Loss: 0.7745
Batch 380, Loss: 0.7848
Batch 390, Loss: 0.8303
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 24.959912300109863 seconds
Epoch 78 accuracy: 63.57%
Batch 10, Loss: 0.7010
Batch 20, Loss: 0.6632
Batch 30, Loss: 0.6672
Batch 40, Loss: 0.6651
Batch 50, Loss: 0.6691
Batch 60, Loss: 0.6595
Batch 70, Loss: 0.6630
Batch 80, Loss: 0.6596
Batch 90, Loss: 0.6154
Batch 100, Loss: 0.7042
Batch 110, Loss: 0.6839
Batch 120, Loss: 0.6807
Batch 130, Loss: 0.6572
Batch 140, Loss: 0.7037
Batch 150, Loss: 0.7058
Batch 160, Loss: 0.6835
Batch 170, Loss: 0.7021
Batch 180, Loss: 0.7058
Batch 190, Loss: 0.6662
Batch 200, Loss: 0.6935
Batch 210, Loss: 0.7180
Batch 220, Loss: 0.7180
Batch 230, Loss: 0.7611
Batch 240, Loss: 0.7510
Batch 250, Loss: 0.7357
Batch 260, Loss: 0.7387
Batch 270, Loss: 0.7296
Batch 280, Loss: 0.7739
Batch 290, Loss: 0.7391
Batch 300, Loss: 0.7781
Batch 310, Loss: 0.7882
Batch 320, Loss: 0.7188
Batch 330, Loss: 0.7831
Batch 340, Loss: 0.7723
Batch 350, Loss: 0.7614
Batch 360, Loss: 0.7886
Batch 370, Loss: 0.8129
Batch 380, Loss: 0.7784
Batch 390, Loss: 0.8314
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 24.970665454864502 seconds
Epoch 79 accuracy: 59.66%
Batch 10, Loss: 0.7098
Batch 20, Loss: 0.6255
Batch 30, Loss: 0.6306
Batch 40, Loss: 0.6413
Batch 50, Loss: 0.6948
Batch 60, Loss: 0.6609
Batch 70, Loss: 0.6613
Batch 80, Loss: 0.6333
Batch 90, Loss: 0.6379
Batch 100, Loss: 0.6936
Batch 110, Loss: 0.6722
Batch 120, Loss: 0.7168
Batch 130, Loss: 0.6973
Batch 140, Loss: 0.6917
Batch 150, Loss: 0.7172
Batch 160, Loss: 0.7270
Batch 170, Loss: 0.7134
Batch 180, Loss: 0.7612
Batch 190, Loss: 0.7115
Batch 200, Loss: 0.7396
Batch 210, Loss: 0.7540
Batch 220, Loss: 0.7776
Batch 230, Loss: 0.7379
Batch 240, Loss: 0.7414
Batch 250, Loss: 0.7218
Batch 260, Loss: 0.7385
Batch 270, Loss: 0.7541
Batch 280, Loss: 0.7578
Batch 290, Loss: 0.7388
Batch 300, Loss: 0.7399
Batch 310, Loss: 0.8261
Batch 320, Loss: 0.7353
Batch 330, Loss: 0.7636
Batch 340, Loss: 0.7628
Batch 350, Loss: 0.7650
Batch 360, Loss: 0.7892
Batch 370, Loss: 0.7745
Batch 380, Loss: 0.7605
Batch 390, Loss: 0.8162
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.131380319595337 seconds
Epoch 80 accuracy: 62.59%
Batch 10, Loss: 0.6763
Batch 20, Loss: 0.6442
Batch 30, Loss: 0.6353
Batch 40, Loss: 0.7110
Batch 50, Loss: 0.6570
Batch 60, Loss: 0.6303
Batch 70, Loss: 0.6534
Batch 80, Loss: 0.6444
Batch 90, Loss: 0.6193
Batch 100, Loss: 0.6600
Batch 110, Loss: 0.6582
Batch 120, Loss: 0.6501
Batch 130, Loss: 0.6990
Batch 140, Loss: 0.7001
Batch 150, Loss: 0.6119
Batch 160, Loss: 0.7035
Batch 170, Loss: 0.6950
Batch 180, Loss: 0.7222
Batch 190, Loss: 0.7330
Batch 200, Loss: 0.6873
Batch 210, Loss: 0.7246
Batch 220, Loss: 0.6882
Batch 230, Loss: 0.7249
Batch 240, Loss: 0.7037
Batch 250, Loss: 0.7532
Batch 260, Loss: 0.7323
Batch 270, Loss: 0.7023
Batch 280, Loss: 0.8217
Batch 290, Loss: 0.8074
Batch 300, Loss: 0.7706
Batch 310, Loss: 0.7812
Batch 320, Loss: 0.7789
Batch 330, Loss: 0.7490
Batch 340, Loss: 0.7009
Batch 350, Loss: 0.7930
Batch 360, Loss: 0.7200
Batch 370, Loss: 0.7194
Batch 380, Loss: 0.7765
Batch 390, Loss: 0.7915
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 24.97461438179016 seconds
Epoch 81 accuracy: 65.83%
Batch 10, Loss: 0.6589
Batch 20, Loss: 0.6337
Batch 30, Loss: 0.6701
Batch 40, Loss: 0.5989
Batch 50, Loss: 0.6693
Batch 60, Loss: 0.6145
Batch 70, Loss: 0.6178
Batch 80, Loss: 0.6311
Batch 90, Loss: 0.6023
Batch 100, Loss: 0.6514
Batch 110, Loss: 0.6701
Batch 120, Loss: 0.6284
Batch 130, Loss: 0.6867
Batch 140, Loss: 0.6608
Batch 150, Loss: 0.7393
Batch 160, Loss: 0.6677
Batch 170, Loss: 0.7018
Batch 180, Loss: 0.6656
Batch 190, Loss: 0.6797
Batch 200, Loss: 0.6840
Batch 210, Loss: 0.6842
Batch 220, Loss: 0.7014
Batch 230, Loss: 0.7513
Batch 240, Loss: 0.6853
Batch 250, Loss: 0.7494
Batch 260, Loss: 0.6979
Batch 270, Loss: 0.7198
Batch 280, Loss: 0.7186
Batch 290, Loss: 0.6850
Batch 300, Loss: 0.7743
Batch 310, Loss: 0.7326
Batch 320, Loss: 0.7873
Batch 330, Loss: 0.7689
Batch 340, Loss: 0.7356
Batch 350, Loss: 0.8002
Batch 360, Loss: 0.7638
Batch 370, Loss: 0.7463
Batch 380, Loss: 0.7774
Batch 390, Loss: 0.7507
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 24.96045207977295 seconds
Epoch 82 accuracy: 61.52%
Batch 10, Loss: 0.6427
Batch 20, Loss: 0.6317
Batch 30, Loss: 0.6392
Batch 40, Loss: 0.6392
Batch 50, Loss: 0.6103
Batch 60, Loss: 0.5538
Batch 70, Loss: 0.6188
Batch 80, Loss: 0.6429
Batch 90, Loss: 0.6245
Batch 100, Loss: 0.6617
Batch 110, Loss: 0.6266
Batch 120, Loss: 0.6497
Batch 130, Loss: 0.6503
Batch 140, Loss: 0.7035
Batch 150, Loss: 0.7437
Batch 160, Loss: 0.6814
Batch 170, Loss: 0.6613
Batch 180, Loss: 0.6843
Batch 190, Loss: 0.6816
Batch 200, Loss: 0.7146
Batch 210, Loss: 0.6965
Batch 220, Loss: 0.6963
Batch 230, Loss: 0.6875
Batch 240, Loss: 0.7108
Batch 250, Loss: 0.7051
Batch 260, Loss: 0.7277
Batch 270, Loss: 0.7183
Batch 280, Loss: 0.7563
Batch 290, Loss: 0.7308
Batch 300, Loss: 0.7085
Batch 310, Loss: 0.7181
Batch 320, Loss: 0.7352
Batch 330, Loss: 0.7403
Batch 340, Loss: 0.7298
Batch 350, Loss: 0.7167
Batch 360, Loss: 0.7475
Batch 370, Loss: 0.7288
Batch 380, Loss: 0.7525
Batch 390, Loss: 0.7498
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 24.897157907485962 seconds
Epoch 83 accuracy: 63.05%
Batch 10, Loss: 0.6711
Batch 20, Loss: 0.6151
Batch 30, Loss: 0.6047
Batch 40, Loss: 0.6436
Batch 50, Loss: 0.6537
Batch 60, Loss: 0.5858
Batch 70, Loss: 0.6034
Batch 80, Loss: 0.6663
Batch 90, Loss: 0.6245
Batch 100, Loss: 0.5918
Batch 110, Loss: 0.6321
Batch 120, Loss: 0.6389
Batch 130, Loss: 0.6370
Batch 140, Loss: 0.6600
Batch 150, Loss: 0.6658
Batch 160, Loss: 0.6867
Batch 170, Loss: 0.7029
Batch 180, Loss: 0.6439
Batch 190, Loss: 0.6908
Batch 200, Loss: 0.7118
Batch 210, Loss: 0.6574
Batch 220, Loss: 0.6756
Batch 230, Loss: 0.7022
Batch 240, Loss: 0.7190
Batch 250, Loss: 0.6595
Batch 260, Loss: 0.7492
Batch 270, Loss: 0.7368
Batch 280, Loss: 0.7143
Batch 290, Loss: 0.7431
Batch 300, Loss: 0.7490
Batch 310, Loss: 0.6731
Batch 320, Loss: 0.6887
Batch 330, Loss: 0.7105
Batch 340, Loss: 0.7595
Batch 350, Loss: 0.7319
Batch 360, Loss: 0.7031
Batch 370, Loss: 0.6832
Batch 380, Loss: 0.7404
Batch 390, Loss: 0.7123
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.098064422607422 seconds
Epoch 84 accuracy: 65.24%
Batch 10, Loss: 0.6252
Batch 20, Loss: 0.5934
Batch 30, Loss: 0.6342
Batch 40, Loss: 0.5815
Batch 50, Loss: 0.6072
Batch 60, Loss: 0.6037
Batch 70, Loss: 0.6401
Batch 80, Loss: 0.5944
Batch 90, Loss: 0.6325
Batch 100, Loss: 0.6296
Batch 110, Loss: 0.6584
Batch 120, Loss: 0.6221
Batch 130, Loss: 0.6758
Batch 140, Loss: 0.6698
Batch 150, Loss: 0.6917
Batch 160, Loss: 0.6759
Batch 170, Loss: 0.6606
Batch 180, Loss: 0.6965
Batch 190, Loss: 0.6830
Batch 200, Loss: 0.6813
Batch 210, Loss: 0.6492
Batch 220, Loss: 0.7137
Batch 230, Loss: 0.6989
Batch 240, Loss: 0.7156
Batch 250, Loss: 0.6843
Batch 260, Loss: 0.7138
Batch 270, Loss: 0.6826
Batch 280, Loss: 0.7088
Batch 290, Loss: 0.6835
Batch 300, Loss: 0.7373
Batch 310, Loss: 0.6883
Batch 320, Loss: 0.7228
Batch 330, Loss: 0.7592
Batch 340, Loss: 0.7331
Batch 350, Loss: 0.7188
Batch 360, Loss: 0.7210
Batch 370, Loss: 0.7164
Batch 380, Loss: 0.7545
Batch 390, Loss: 0.7371
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.048890352249146 seconds
Epoch 85 accuracy: 62.07%
Batch 10, Loss: 0.5981
Batch 20, Loss: 0.6052
Batch 30, Loss: 0.6580
Batch 40, Loss: 0.6097
Batch 50, Loss: 0.6041
Batch 60, Loss: 0.6007
Batch 70, Loss: 0.6016
Batch 80, Loss: 0.6046
Batch 90, Loss: 0.6132
Batch 100, Loss: 0.6030
Batch 110, Loss: 0.6410
Batch 120, Loss: 0.6281
Batch 130, Loss: 0.6542
Batch 140, Loss: 0.6517
Batch 150, Loss: 0.6661
Batch 160, Loss: 0.6965
Batch 170, Loss: 0.6764
Batch 180, Loss: 0.7111
Batch 190, Loss: 0.6721
Batch 200, Loss: 0.6518
Batch 210, Loss: 0.6676
Batch 220, Loss: 0.6192
Batch 230, Loss: 0.6883
Batch 240, Loss: 0.6884
Batch 250, Loss: 0.7243
Batch 260, Loss: 0.6963
Batch 270, Loss: 0.7097
Batch 280, Loss: 0.7200
Batch 290, Loss: 0.7185
Batch 300, Loss: 0.7087
Batch 310, Loss: 0.7200
Batch 320, Loss: 0.7319
Batch 330, Loss: 0.7099
Batch 340, Loss: 0.7203
Batch 350, Loss: 0.7113
Batch 360, Loss: 0.6816
Batch 370, Loss: 0.7220
Batch 380, Loss: 0.7245
Batch 390, Loss: 0.7138
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 24.966636896133423 seconds
Epoch 86 accuracy: 64.25%
Batch 10, Loss: 0.6018
Batch 20, Loss: 0.6156
Batch 30, Loss: 0.5577
Batch 40, Loss: 0.6431
Batch 50, Loss: 0.6406
Batch 60, Loss: 0.5923
Batch 70, Loss: 0.5788
Batch 80, Loss: 0.5898
Batch 90, Loss: 0.6131
Batch 100, Loss: 0.6230
Batch 110, Loss: 0.6140
Batch 120, Loss: 0.6618
Batch 130, Loss: 0.6519
Batch 140, Loss: 0.6955
Batch 150, Loss: 0.6506
Batch 160, Loss: 0.6617
Batch 170, Loss: 0.6688
Batch 180, Loss: 0.6903
Batch 190, Loss: 0.6274
Batch 200, Loss: 0.6404
Batch 210, Loss: 0.6739
Batch 220, Loss: 0.6628
Batch 230, Loss: 0.6633
Batch 240, Loss: 0.6942
Batch 250, Loss: 0.6964
Batch 260, Loss: 0.7028
Batch 270, Loss: 0.6997
Batch 280, Loss: 0.6924
Batch 290, Loss: 0.6983
Batch 300, Loss: 0.7056
Batch 310, Loss: 0.6752
Batch 320, Loss: 0.7288
Batch 330, Loss: 0.7419
Batch 340, Loss: 0.7209
Batch 350, Loss: 0.6763
Batch 360, Loss: 0.7008
Batch 370, Loss: 0.6792
Batch 380, Loss: 0.7192
Batch 390, Loss: 0.7129
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.0282621383667 seconds
Epoch 87 accuracy: 67.23%
Batch 10, Loss: 0.6248
Batch 20, Loss: 0.6186
Batch 30, Loss: 0.6216
Batch 40, Loss: 0.6404
Batch 50, Loss: 0.6175
Batch 60, Loss: 0.5972
Batch 70, Loss: 0.6167
Batch 80, Loss: 0.6341
Batch 90, Loss: 0.5730
Batch 100, Loss: 0.6171
Batch 110, Loss: 0.6439
Batch 120, Loss: 0.6168
Batch 130, Loss: 0.6432
Batch 140, Loss: 0.6147
Batch 150, Loss: 0.6507
Batch 160, Loss: 0.6221
Batch 170, Loss: 0.6356
Batch 180, Loss: 0.6386
Batch 190, Loss: 0.6715
Batch 200, Loss: 0.6598
Batch 210, Loss: 0.6897
Batch 220, Loss: 0.7130
Batch 230, Loss: 0.7030
Batch 240, Loss: 0.6776
Batch 250, Loss: 0.6757
Batch 260, Loss: 0.6624
Batch 270, Loss: 0.6861
Batch 280, Loss: 0.6945
Batch 290, Loss: 0.6745
Batch 300, Loss: 0.7236
Batch 310, Loss: 0.6969
Batch 320, Loss: 0.7405
Batch 330, Loss: 0.7276
Batch 340, Loss: 0.7258
Batch 350, Loss: 0.6797
Batch 360, Loss: 0.6633
Batch 370, Loss: 0.6949
Batch 380, Loss: 0.6958
Batch 390, Loss: 0.7039
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.01227569580078 seconds
Epoch 88 accuracy: 65.6%
Batch 10, Loss: 0.5655
Batch 20, Loss: 0.5695
Batch 30, Loss: 0.5738
Batch 40, Loss: 0.6110
Batch 50, Loss: 0.5982
Batch 60, Loss: 0.5891
Batch 70, Loss: 0.6011
Batch 80, Loss: 0.6526
Batch 90, Loss: 0.6096
Batch 100, Loss: 0.6153
Batch 110, Loss: 0.6274
Batch 120, Loss: 0.6189
Batch 130, Loss: 0.6068
Batch 140, Loss: 0.6284
Batch 150, Loss: 0.5993
Batch 160, Loss: 0.6247
Batch 170, Loss: 0.6315
Batch 180, Loss: 0.6277
Batch 190, Loss: 0.5835
Batch 200, Loss: 0.6060
Batch 210, Loss: 0.6353
Batch 220, Loss: 0.7310
Batch 230, Loss: 0.6549
Batch 240, Loss: 0.6888
Batch 250, Loss: 0.6840
Batch 260, Loss: 0.6457
Batch 270, Loss: 0.6839
Batch 280, Loss: 0.6674
Batch 290, Loss: 0.6243
Batch 300, Loss: 0.7005
Batch 310, Loss: 0.6940
Batch 320, Loss: 0.7475
Batch 330, Loss: 0.6875
Batch 340, Loss: 0.6769
Batch 350, Loss: 0.6782
Batch 360, Loss: 0.7457
Batch 370, Loss: 0.7201
Batch 380, Loss: 0.6842
Batch 390, Loss: 0.7316
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 24.920180559158325 seconds
Epoch 89 accuracy: 62.67%
Batch 10, Loss: 0.5709
Batch 20, Loss: 0.5785
Batch 30, Loss: 0.5551
Batch 40, Loss: 0.5739
Batch 50, Loss: 0.5955
Batch 60, Loss: 0.5944
Batch 70, Loss: 0.6233
Batch 80, Loss: 0.5768
Batch 90, Loss: 0.6078
Batch 100, Loss: 0.6054
Batch 110, Loss: 0.5867
Batch 120, Loss: 0.5658
Batch 130, Loss: 0.6013
Batch 140, Loss: 0.6216
Batch 150, Loss: 0.6461
Batch 160, Loss: 0.5957
Batch 170, Loss: 0.6485
Batch 180, Loss: 0.6319
Batch 190, Loss: 0.5830
Batch 200, Loss: 0.6077
Batch 210, Loss: 0.6291
Batch 220, Loss: 0.6083
Batch 230, Loss: 0.6525
Batch 240, Loss: 0.6624
Batch 250, Loss: 0.6751
Batch 260, Loss: 0.6651
Batch 270, Loss: 0.6567
Batch 280, Loss: 0.6759
Batch 290, Loss: 0.6504
Batch 300, Loss: 0.6347
Batch 310, Loss: 0.6715
Batch 320, Loss: 0.6592
Batch 330, Loss: 0.7066
Batch 340, Loss: 0.7145
Batch 350, Loss: 0.7004
Batch 360, Loss: 0.6834
Batch 370, Loss: 0.6700
Batch 380, Loss: 0.7116
Batch 390, Loss: 0.7100
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.046584844589233 seconds
Epoch 90 accuracy: 63.92%
Batch 10, Loss: 0.6248
Batch 20, Loss: 0.6056
Batch 30, Loss: 0.5913
Batch 40, Loss: 0.5668
Batch 50, Loss: 0.6049
Batch 60, Loss: 0.5720
Batch 70, Loss: 0.5793
Batch 80, Loss: 0.5605
Batch 90, Loss: 0.6206
Batch 100, Loss: 0.6062
Batch 110, Loss: 0.5805
Batch 120, Loss: 0.5901
Batch 130, Loss: 0.5921
Batch 140, Loss: 0.6203
Batch 150, Loss: 0.6020
Batch 160, Loss: 0.6171
Batch 170, Loss: 0.6592
Batch 180, Loss: 0.6510
Batch 190, Loss: 0.6575
Batch 200, Loss: 0.6286
Batch 210, Loss: 0.6983
Batch 220, Loss: 0.5965
Batch 230, Loss: 0.6163
Batch 240, Loss: 0.6716
Batch 250, Loss: 0.6299
Batch 260, Loss: 0.6504
Batch 270, Loss: 0.6436
Batch 280, Loss: 0.6942
Batch 290, Loss: 0.6675
Batch 300, Loss: 0.6678
Batch 310, Loss: 0.6826
Batch 320, Loss: 0.7175
Batch 330, Loss: 0.6763
Batch 340, Loss: 0.6628
Batch 350, Loss: 0.7063
Batch 360, Loss: 0.6587
Batch 370, Loss: 0.6636
Batch 380, Loss: 0.6809
Batch 390, Loss: 0.6637
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.05922293663025 seconds
Epoch 91 accuracy: 65.76%
Batch 10, Loss: 0.5847
Batch 20, Loss: 0.5864
Batch 30, Loss: 0.5787
Batch 40, Loss: 0.5751
Batch 50, Loss: 0.5544
Batch 60, Loss: 0.5481
Batch 70, Loss: 0.5215
Batch 80, Loss: 0.5438
Batch 90, Loss: 0.5746
Batch 100, Loss: 0.5682
Batch 110, Loss: 0.5658
Batch 120, Loss: 0.6066
Batch 130, Loss: 0.5972
Batch 140, Loss: 0.6048
Batch 150, Loss: 0.6314
Batch 160, Loss: 0.6043
Batch 170, Loss: 0.6054
Batch 180, Loss: 0.6313
Batch 190, Loss: 0.6386
Batch 200, Loss: 0.6215
Batch 210, Loss: 0.6549
Batch 220, Loss: 0.6422
Batch 230, Loss: 0.6262
Batch 240, Loss: 0.5943
Batch 250, Loss: 0.6194
Batch 260, Loss: 0.6346
Batch 270, Loss: 0.6300
Batch 280, Loss: 0.6794
Batch 290, Loss: 0.6458
Batch 300, Loss: 0.6885
Batch 310, Loss: 0.6782
Batch 320, Loss: 0.6979
Batch 330, Loss: 0.6849
Batch 340, Loss: 0.6811
Batch 350, Loss: 0.6819
Batch 360, Loss: 0.7117
Batch 370, Loss: 0.6917
Batch 380, Loss: 0.6542
Batch 390, Loss: 0.6266
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 24.956589221954346 seconds
Epoch 92 accuracy: 66.01%
Batch 10, Loss: 0.5705
Batch 20, Loss: 0.6033
Batch 30, Loss: 0.5824
Batch 40, Loss: 0.5645
Batch 50, Loss: 0.5852
Batch 60, Loss: 0.5570
Batch 70, Loss: 0.5220
Batch 80, Loss: 0.5254
Batch 90, Loss: 0.5557
Batch 100, Loss: 0.6280
Batch 110, Loss: 0.5989
Batch 120, Loss: 0.6255
Batch 130, Loss: 0.5674
Batch 140, Loss: 0.6237
Batch 150, Loss: 0.6161
Batch 160, Loss: 0.5982
Batch 170, Loss: 0.5924
Batch 180, Loss: 0.6299
Batch 190, Loss: 0.6398
Batch 200, Loss: 0.6488
Batch 210, Loss: 0.6543
Batch 220, Loss: 0.5977
Batch 230, Loss: 0.6618
Batch 240, Loss: 0.6354
Batch 250, Loss: 0.6692
Batch 260, Loss: 0.6660
Batch 270, Loss: 0.6642
Batch 280, Loss: 0.6316
Batch 290, Loss: 0.6702
Batch 300, Loss: 0.6403
Batch 310, Loss: 0.6820
Batch 320, Loss: 0.6332
Batch 330, Loss: 0.6294
Batch 340, Loss: 0.6424
Batch 350, Loss: 0.6613
Batch 360, Loss: 0.6572
Batch 370, Loss: 0.6930
Batch 380, Loss: 0.7069
Batch 390, Loss: 0.6739
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.118135929107666 seconds
Epoch 93 accuracy: 64.79%
Batch 10, Loss: 0.5211
Batch 20, Loss: 0.5734
Batch 30, Loss: 0.5159
Batch 40, Loss: 0.5556
Batch 50, Loss: 0.5197
Batch 60, Loss: 0.5253
Batch 70, Loss: 0.5665
Batch 80, Loss: 0.5423
Batch 90, Loss: 0.5373
Batch 100, Loss: 0.5768
Batch 110, Loss: 0.5622
Batch 120, Loss: 0.5516
Batch 130, Loss: 0.5722
Batch 140, Loss: 0.6098
Batch 150, Loss: 0.5752
Batch 160, Loss: 0.5659
Batch 170, Loss: 0.6058
Batch 180, Loss: 0.6084
Batch 190, Loss: 0.6212
Batch 200, Loss: 0.5782
Batch 210, Loss: 0.5910
Batch 220, Loss: 0.6095
Batch 230, Loss: 0.6192
Batch 240, Loss: 0.6754
Batch 250, Loss: 0.5889
Batch 260, Loss: 0.6611
Batch 270, Loss: 0.6474
Batch 280, Loss: 0.6747
Batch 290, Loss: 0.6393
Batch 300, Loss: 0.6562
Batch 310, Loss: 0.6060
Batch 320, Loss: 0.6332
Batch 330, Loss: 0.6560
Batch 340, Loss: 0.6787
Batch 350, Loss: 0.6240
Batch 360, Loss: 0.6816
Batch 370, Loss: 0.6302
Batch 380, Loss: 0.6405
Batch 390, Loss: 0.6494
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.142510652542114 seconds
Epoch 94 accuracy: 63.35%
Batch 10, Loss: 0.5253
Batch 20, Loss: 0.5630
Batch 30, Loss: 0.5308
Batch 40, Loss: 0.5309
Batch 50, Loss: 0.5234
Batch 60, Loss: 0.5039
Batch 70, Loss: 0.5447
Batch 80, Loss: 0.5321
Batch 90, Loss: 0.5399
Batch 100, Loss: 0.5425
Batch 110, Loss: 0.6057
Batch 120, Loss: 0.5661
Batch 130, Loss: 0.5822
Batch 140, Loss: 0.5951
Batch 150, Loss: 0.5720
Batch 160, Loss: 0.5663
Batch 170, Loss: 0.5634
Batch 180, Loss: 0.5876
Batch 190, Loss: 0.5967
Batch 200, Loss: 0.6295
Batch 210, Loss: 0.6222
Batch 220, Loss: 0.6285
Batch 230, Loss: 0.6188
Batch 240, Loss: 0.6401
Batch 250, Loss: 0.6664
Batch 260, Loss: 0.6119
Batch 270, Loss: 0.6309
Batch 280, Loss: 0.6135
Batch 290, Loss: 0.6101
Batch 300, Loss: 0.6421
Batch 310, Loss: 0.6323
Batch 320, Loss: 0.6354
Batch 330, Loss: 0.6474
Batch 340, Loss: 0.6495
Batch 350, Loss: 0.6627
Batch 360, Loss: 0.6716
Batch 370, Loss: 0.6828
Batch 380, Loss: 0.6841
Batch 390, Loss: 0.6655
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.090928077697754 seconds
Epoch 95 accuracy: 66.05%
Batch 10, Loss: 0.5149
Batch 20, Loss: 0.5177
Batch 30, Loss: 0.5246
Batch 40, Loss: 0.5504
Batch 50, Loss: 0.5043
Batch 60, Loss: 0.5499
Batch 70, Loss: 0.5452
Batch 80, Loss: 0.5266
Batch 90, Loss: 0.5347
Batch 100, Loss: 0.5253
Batch 110, Loss: 0.5947
Batch 120, Loss: 0.5827
Batch 130, Loss: 0.5505
Batch 140, Loss: 0.5716
Batch 150, Loss: 0.5634
Batch 160, Loss: 0.5642
Batch 170, Loss: 0.5879
Batch 180, Loss: 0.5159
Batch 190, Loss: 0.5790
Batch 200, Loss: 0.5975
Batch 210, Loss: 0.5984
Batch 220, Loss: 0.6138
Batch 230, Loss: 0.5384
Batch 240, Loss: 0.6241
Batch 250, Loss: 0.6237
Batch 260, Loss: 0.5902
Batch 270, Loss: 0.6273
Batch 280, Loss: 0.6508
Batch 290, Loss: 0.6087
Batch 300, Loss: 0.5991
Batch 310, Loss: 0.6141
Batch 320, Loss: 0.6317
Batch 330, Loss: 0.6148
Batch 340, Loss: 0.6327
Batch 350, Loss: 0.6319
Batch 360, Loss: 0.6328
Batch 370, Loss: 0.6197
Batch 380, Loss: 0.6387
Batch 390, Loss: 0.6398
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.160000801086426 seconds
Epoch 96 accuracy: 64.41%
Batch 10, Loss: 0.5482
Batch 20, Loss: 0.5431
Batch 30, Loss: 0.5223
Batch 40, Loss: 0.5226
Batch 50, Loss: 0.5483
Batch 60, Loss: 0.5027
Batch 70, Loss: 0.5265
Batch 80, Loss: 0.5793
Batch 90, Loss: 0.5566
Batch 100, Loss: 0.5197
Batch 110, Loss: 0.5725
Batch 120, Loss: 0.5592
Batch 130, Loss: 0.5671
Batch 140, Loss: 0.5933
Batch 150, Loss: 0.5602
Batch 160, Loss: 0.5253
Batch 170, Loss: 0.5817
Batch 180, Loss: 0.5458
Batch 190, Loss: 0.5506
Batch 200, Loss: 0.5885
Batch 210, Loss: 0.5734
Batch 220, Loss: 0.6027
Batch 230, Loss: 0.6331
Batch 240, Loss: 0.5898
Batch 250, Loss: 0.5962
Batch 260, Loss: 0.6261
Batch 270, Loss: 0.5957
Batch 280, Loss: 0.6073
Batch 290, Loss: 0.6070
Batch 300, Loss: 0.6727
Batch 310, Loss: 0.6074
Batch 320, Loss: 0.6084
Batch 330, Loss: 0.6222
Batch 340, Loss: 0.6040
Batch 350, Loss: 0.6409
Batch 360, Loss: 0.6361
Batch 370, Loss: 0.6398
Batch 380, Loss: 0.6594
Batch 390, Loss: 0.6041
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.01999521255493 seconds
Epoch 97 accuracy: 65.14%
Batch 10, Loss: 0.5834
Batch 20, Loss: 0.5524
Batch 30, Loss: 0.5298
Batch 40, Loss: 0.5231
Batch 50, Loss: 0.5036
Batch 60, Loss: 0.5429
Batch 70, Loss: 0.4993
Batch 80, Loss: 0.5115
Batch 90, Loss: 0.5232
Batch 100, Loss: 0.5097
Batch 110, Loss: 0.5589
Batch 120, Loss: 0.4965
Batch 130, Loss: 0.5283
Batch 140, Loss: 0.5315
Batch 150, Loss: 0.5396
Batch 160, Loss: 0.5795
Batch 170, Loss: 0.5391
Batch 180, Loss: 0.6076
Batch 190, Loss: 0.5793
Batch 200, Loss: 0.5811
Batch 210, Loss: 0.6027
Batch 220, Loss: 0.5688
Batch 230, Loss: 0.5861
Batch 240, Loss: 0.6037
Batch 250, Loss: 0.5735
Batch 260, Loss: 0.5827
Batch 270, Loss: 0.5815
Batch 280, Loss: 0.5879
Batch 290, Loss: 0.6222
Batch 300, Loss: 0.6069
Batch 310, Loss: 0.5594
Batch 320, Loss: 0.6321
Batch 330, Loss: 0.5877
Batch 340, Loss: 0.5883
Batch 350, Loss: 0.6051
Batch 360, Loss: 0.5811
Batch 370, Loss: 0.6258
Batch 380, Loss: 0.5905
Batch 390, Loss: 0.6404
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 24.983930826187134 seconds
Epoch 98 accuracy: 67.11%
Batch 10, Loss: 0.5019
Batch 20, Loss: 0.5601
Batch 30, Loss: 0.4819
Batch 40, Loss: 0.5268
Batch 50, Loss: 0.5002
Batch 60, Loss: 0.5083
Batch 70, Loss: 0.4959
Batch 80, Loss: 0.4684
Batch 90, Loss: 0.5406
Batch 100, Loss: 0.4946
Batch 110, Loss: 0.4818
Batch 120, Loss: 0.5128
Batch 130, Loss: 0.5499
Batch 140, Loss: 0.5152
Batch 150, Loss: 0.5711
Batch 160, Loss: 0.5711
Batch 170, Loss: 0.5649
Batch 180, Loss: 0.5721
Batch 190, Loss: 0.5618
Batch 200, Loss: 0.5574
Batch 210, Loss: 0.5572
Batch 220, Loss: 0.5661
Batch 230, Loss: 0.6011
Batch 240, Loss: 0.5919
Batch 250, Loss: 0.5870
Batch 260, Loss: 0.5978
Batch 270, Loss: 0.5925
Batch 280, Loss: 0.5684
Batch 290, Loss: 0.5615
Batch 300, Loss: 0.6077
Batch 310, Loss: 0.5988
Batch 320, Loss: 0.5965
Batch 330, Loss: 0.6226
Batch 340, Loss: 0.5631
Batch 350, Loss: 0.6242
Batch 360, Loss: 0.5630
Batch 370, Loss: 0.5975
Batch 380, Loss: 0.5954
Batch 390, Loss: 0.6117
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.203989267349243 seconds
Epoch 99 accuracy: 66.49%
Batch 10, Loss: 0.5184
Batch 20, Loss: 0.5522
Batch 30, Loss: 0.5166
Batch 40, Loss: 0.5156
Batch 50, Loss: 0.4919
Batch 60, Loss: 0.5262
Batch 70, Loss: 0.5129
Batch 80, Loss: 0.4730
Batch 90, Loss: 0.4869
Batch 100, Loss: 0.5186
Batch 110, Loss: 0.4967
Batch 120, Loss: 0.5594
Batch 130, Loss: 0.5600
Batch 140, Loss: 0.5824
Batch 150, Loss: 0.5076
Batch 160, Loss: 0.5262
Batch 170, Loss: 0.5756
Batch 180, Loss: 0.5586
Batch 190, Loss: 0.5733
Batch 200, Loss: 0.5821
Batch 210, Loss: 0.5993
Batch 220, Loss: 0.6062
Batch 230, Loss: 0.6276
Batch 240, Loss: 0.5894
Batch 250, Loss: 0.5715
Batch 260, Loss: 0.5954
Batch 270, Loss: 0.5958
Batch 280, Loss: 0.6023
Batch 290, Loss: 0.6336
Batch 300, Loss: 0.5958
Batch 310, Loss: 0.5607
Batch 320, Loss: 0.6164
Batch 330, Loss: 0.6187
Batch 340, Loss: 0.5701
Batch 350, Loss: 0.5918
Batch 360, Loss: 0.6167
Batch 370, Loss: 0.6250
Batch 380, Loss: 0.6466
Batch 390, Loss: 0.6434
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.15870976448059 seconds
Epoch 100 accuracy: 64.89%
Batch 10, Loss: 0.5129
Batch 20, Loss: 0.5197
Batch 30, Loss: 0.5137
Batch 40, Loss: 0.5117
Batch 50, Loss: 0.4775
Batch 60, Loss: 0.4939
Batch 70, Loss: 0.5180
Batch 80, Loss: 0.5314
Batch 90, Loss: 0.5113
Batch 100, Loss: 0.4941
Batch 110, Loss: 0.5296
Batch 120, Loss: 0.5025
Batch 130, Loss: 0.5143
Batch 140, Loss: 0.5635
Batch 150, Loss: 0.5274
Batch 160, Loss: 0.5508
Batch 170, Loss: 0.5737
Batch 180, Loss: 0.5313
Batch 190, Loss: 0.5651
Batch 200, Loss: 0.5610
Batch 210, Loss: 0.5568
Batch 220, Loss: 0.5727
Batch 230, Loss: 0.5343
Batch 240, Loss: 0.5281
Batch 250, Loss: 0.5767
Batch 260, Loss: 0.5416
Batch 270, Loss: 0.6257
Batch 280, Loss: 0.5869
Batch 290, Loss: 0.5585
Batch 300, Loss: 0.5892
Batch 310, Loss: 0.5991
Batch 320, Loss: 0.5614
Batch 330, Loss: 0.5907
Batch 340, Loss: 0.5848
Batch 350, Loss: 0.5740
Batch 360, Loss: 0.5830
Batch 370, Loss: 0.5602
Batch 380, Loss: 0.5910
Batch 390, Loss: 0.5776
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.150118589401245 seconds
Epoch 101 accuracy: 65.79%
Batch 10, Loss: 0.4886
Batch 20, Loss: 0.4776
Batch 30, Loss: 0.4846
Batch 40, Loss: 0.4758
Batch 50, Loss: 0.4980
Batch 60, Loss: 0.5374
Batch 70, Loss: 0.4947
Batch 80, Loss: 0.5173
Batch 90, Loss: 0.5005
Batch 100, Loss: 0.5033
Batch 110, Loss: 0.5005
Batch 120, Loss: 0.5296
Batch 130, Loss: 0.5061
Batch 140, Loss: 0.5072
Batch 150, Loss: 0.5319
Batch 160, Loss: 0.5237
Batch 170, Loss: 0.4991
Batch 180, Loss: 0.5149
Batch 190, Loss: 0.5792
Batch 200, Loss: 0.5278
Batch 210, Loss: 0.5709
Batch 220, Loss: 0.5781
Batch 230, Loss: 0.5933
Batch 240, Loss: 0.5456
Batch 250, Loss: 0.5410
Batch 260, Loss: 0.5640
Batch 270, Loss: 0.5783
Batch 280, Loss: 0.5624
Batch 290, Loss: 0.5444
Batch 300, Loss: 0.5584
Batch 310, Loss: 0.5956
Batch 320, Loss: 0.6074
Batch 330, Loss: 0.5726
Batch 340, Loss: 0.5824
Batch 350, Loss: 0.5952
Batch 360, Loss: 0.5817
Batch 370, Loss: 0.5810
Batch 380, Loss: 0.5963
Batch 390, Loss: 0.5898
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.071381092071533 seconds
Epoch 102 accuracy: 66.8%
Batch 10, Loss: 0.4841
Batch 20, Loss: 0.5025
Batch 30, Loss: 0.4965
Batch 40, Loss: 0.4578
Batch 50, Loss: 0.4904
Batch 60, Loss: 0.4712
Batch 70, Loss: 0.4507
Batch 80, Loss: 0.4573
Batch 90, Loss: 0.4614
Batch 100, Loss: 0.4625
Batch 110, Loss: 0.4750
Batch 120, Loss: 0.4729
Batch 130, Loss: 0.4887
Batch 140, Loss: 0.4677
Batch 150, Loss: 0.4828
Batch 160, Loss: 0.5105
Batch 170, Loss: 0.5412
Batch 180, Loss: 0.5505
Batch 190, Loss: 0.5564
Batch 200, Loss: 0.5380
Batch 210, Loss: 0.5297
Batch 220, Loss: 0.5504
Batch 230, Loss: 0.5437
Batch 240, Loss: 0.5378
Batch 250, Loss: 0.5166
Batch 260, Loss: 0.5456
Batch 270, Loss: 0.5600
Batch 280, Loss: 0.5460
Batch 290, Loss: 0.5728
Batch 300, Loss: 0.5565
Batch 310, Loss: 0.5611
Batch 320, Loss: 0.5916
Batch 330, Loss: 0.5927
Batch 340, Loss: 0.6032
Batch 350, Loss: 0.5720
Batch 360, Loss: 0.5580
Batch 370, Loss: 0.6091
Batch 380, Loss: 0.6021
Batch 390, Loss: 0.5867
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.068342447280884 seconds
Epoch 103 accuracy: 64.31%
Batch 10, Loss: 0.4793
Batch 20, Loss: 0.4755
Batch 30, Loss: 0.4900
Batch 40, Loss: 0.4690
Batch 50, Loss: 0.4725
Batch 60, Loss: 0.4888
Batch 70, Loss: 0.5024
Batch 80, Loss: 0.5109
Batch 90, Loss: 0.4524
Batch 100, Loss: 0.4750
Batch 110, Loss: 0.4834
Batch 120, Loss: 0.5026
Batch 130, Loss: 0.5028
Batch 140, Loss: 0.5135
Batch 150, Loss: 0.5189
Batch 160, Loss: 0.5078
Batch 170, Loss: 0.5239
Batch 180, Loss: 0.4900
Batch 190, Loss: 0.4558
Batch 200, Loss: 0.5180
Batch 210, Loss: 0.5144
Batch 220, Loss: 0.4936
Batch 230, Loss: 0.5887
Batch 240, Loss: 0.4885
Batch 250, Loss: 0.5185
Batch 260, Loss: 0.5667
Batch 270, Loss: 0.5405
Batch 280, Loss: 0.5371
Batch 290, Loss: 0.5712
Batch 300, Loss: 0.5429
Batch 310, Loss: 0.5528
Batch 320, Loss: 0.5189
Batch 330, Loss: 0.5947
Batch 340, Loss: 0.6145
Batch 350, Loss: 0.5912
Batch 360, Loss: 0.5584
Batch 370, Loss: 0.6061
Batch 380, Loss: 0.5917
Batch 390, Loss: 0.5700
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.08804416656494 seconds
Epoch 104 accuracy: 66.34%
Batch 10, Loss: 0.4973
Batch 20, Loss: 0.4826
Batch 30, Loss: 0.4516
Batch 40, Loss: 0.4661
Batch 50, Loss: 0.4512
Batch 60, Loss: 0.4905
Batch 70, Loss: 0.4462
Batch 80, Loss: 0.4196
Batch 90, Loss: 0.5119
Batch 100, Loss: 0.4735
Batch 110, Loss: 0.5178
Batch 120, Loss: 0.4638
Batch 130, Loss: 0.4759
Batch 140, Loss: 0.4773
Batch 150, Loss: 0.5052
Batch 160, Loss: 0.5061
Batch 170, Loss: 0.5246
Batch 180, Loss: 0.5298
Batch 190, Loss: 0.5228
Batch 200, Loss: 0.4954
Batch 210, Loss: 0.5152
Batch 220, Loss: 0.5383
Batch 230, Loss: 0.5286
Batch 240, Loss: 0.5469
Batch 250, Loss: 0.5508
Batch 260, Loss: 0.5373
Batch 270, Loss: 0.5482
Batch 280, Loss: 0.5487
Batch 290, Loss: 0.5391
Batch 300, Loss: 0.5692
Batch 310, Loss: 0.5903
Batch 320, Loss: 0.5497
Batch 330, Loss: 0.5495
Batch 340, Loss: 0.5153
Batch 350, Loss: 0.5662
Batch 360, Loss: 0.5324
Batch 370, Loss: 0.5675
Batch 380, Loss: 0.5959
Batch 390, Loss: 0.5687
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.011327028274536 seconds
Epoch 105 accuracy: 64.34%
Batch 10, Loss: 0.4845
Batch 20, Loss: 0.4239
Batch 30, Loss: 0.4729
Batch 40, Loss: 0.4409
Batch 50, Loss: 0.5068
Batch 60, Loss: 0.4520
Batch 70, Loss: 0.4486
Batch 80, Loss: 0.4559
Batch 90, Loss: 0.4638
Batch 100, Loss: 0.4426
Batch 110, Loss: 0.5070
Batch 120, Loss: 0.4892
Batch 130, Loss: 0.5222
Batch 140, Loss: 0.4948
Batch 150, Loss: 0.4899
Batch 160, Loss: 0.4748
Batch 170, Loss: 0.5110
Batch 180, Loss: 0.5061
Batch 190, Loss: 0.5013
Batch 200, Loss: 0.4817
Batch 210, Loss: 0.5205
Batch 220, Loss: 0.5602
Batch 230, Loss: 0.4836
Batch 240, Loss: 0.5023
Batch 250, Loss: 0.5258
Batch 260, Loss: 0.5409
Batch 270, Loss: 0.5161
Batch 280, Loss: 0.5639
Batch 290, Loss: 0.5165
Batch 300, Loss: 0.5469
Batch 310, Loss: 0.5367
Batch 320, Loss: 0.5305
Batch 330, Loss: 0.5374
Batch 340, Loss: 0.5220
Batch 350, Loss: 0.5565
Batch 360, Loss: 0.5310
Batch 370, Loss: 0.5628
Batch 380, Loss: 0.5737
Batch 390, Loss: 0.5957
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 24.956462144851685 seconds
Epoch 106 accuracy: 66.44%
Batch 10, Loss: 0.4843
Batch 20, Loss: 0.4625
Batch 30, Loss: 0.4457
Batch 40, Loss: 0.4588
Batch 50, Loss: 0.4548
Batch 60, Loss: 0.4381
Batch 70, Loss: 0.4419
Batch 80, Loss: 0.4501
Batch 90, Loss: 0.4121
Batch 100, Loss: 0.4513
Batch 110, Loss: 0.4506
Batch 120, Loss: 0.4564
Batch 130, Loss: 0.4440
Batch 140, Loss: 0.4606
Batch 150, Loss: 0.4813
Batch 160, Loss: 0.4940
Batch 170, Loss: 0.4850
Batch 180, Loss: 0.5124
Batch 190, Loss: 0.4605
Batch 200, Loss: 0.4886
Batch 210, Loss: 0.4837
Batch 220, Loss: 0.4950
Batch 230, Loss: 0.5012
Batch 240, Loss: 0.5225
Batch 250, Loss: 0.5356
Batch 260, Loss: 0.4985
Batch 270, Loss: 0.5301
Batch 280, Loss: 0.4961
Batch 290, Loss: 0.4980
Batch 300, Loss: 0.5178
Batch 310, Loss: 0.5184
Batch 320, Loss: 0.5546
Batch 330, Loss: 0.5433
Batch 340, Loss: 0.5456
Batch 350, Loss: 0.5645
Batch 360, Loss: 0.5709
Batch 370, Loss: 0.5429
Batch 380, Loss: 0.5086
Batch 390, Loss: 0.5556
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 24.974565505981445 seconds
Epoch 107 accuracy: 66.58%
Batch 10, Loss: 0.4775
Batch 20, Loss: 0.4361
Batch 30, Loss: 0.4839
Batch 40, Loss: 0.4453
Batch 50, Loss: 0.4125
Batch 60, Loss: 0.4546
Batch 70, Loss: 0.4596
Batch 80, Loss: 0.4300
Batch 90, Loss: 0.4481
Batch 100, Loss: 0.4114
Batch 110, Loss: 0.4615
Batch 120, Loss: 0.4290
Batch 130, Loss: 0.4535
Batch 140, Loss: 0.4591
Batch 150, Loss: 0.4487
Batch 160, Loss: 0.5223
Batch 170, Loss: 0.4508
Batch 180, Loss: 0.5042
Batch 190, Loss: 0.4833
Batch 200, Loss: 0.4816
Batch 210, Loss: 0.4561
Batch 220, Loss: 0.5077
Batch 230, Loss: 0.4609
Batch 240, Loss: 0.4836
Batch 250, Loss: 0.4918
Batch 260, Loss: 0.4770
Batch 270, Loss: 0.5065
Batch 280, Loss: 0.5437
Batch 290, Loss: 0.4989
Batch 300, Loss: 0.4603
Batch 310, Loss: 0.4792
Batch 320, Loss: 0.5213
Batch 330, Loss: 0.4901
Batch 340, Loss: 0.5301
Batch 350, Loss: 0.5114
Batch 360, Loss: 0.5626
Batch 370, Loss: 0.5351
Batch 380, Loss: 0.4935
Batch 390, Loss: 0.4878
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 24.93129324913025 seconds
Epoch 108 accuracy: 66.97%
Batch 10, Loss: 0.4148
Batch 20, Loss: 0.4475
Batch 30, Loss: 0.4510
Batch 40, Loss: 0.3973
Batch 50, Loss: 0.4727
Batch 60, Loss: 0.4303
Batch 70, Loss: 0.4296
Batch 80, Loss: 0.4028
Batch 90, Loss: 0.4647
Batch 100, Loss: 0.4296
Batch 110, Loss: 0.4705
Batch 120, Loss: 0.4575
Batch 130, Loss: 0.4451
Batch 140, Loss: 0.4770
Batch 150, Loss: 0.4605
Batch 160, Loss: 0.4459
Batch 170, Loss: 0.4478
Batch 180, Loss: 0.4660
Batch 190, Loss: 0.4909
Batch 200, Loss: 0.4726
Batch 210, Loss: 0.5086
Batch 220, Loss: 0.4857
Batch 230, Loss: 0.5100
Batch 240, Loss: 0.5091
Batch 250, Loss: 0.4866
Batch 260, Loss: 0.5120
Batch 270, Loss: 0.5176
Batch 280, Loss: 0.4898
Batch 290, Loss: 0.5080
Batch 300, Loss: 0.5120
Batch 310, Loss: 0.4809
Batch 320, Loss: 0.5193
Batch 330, Loss: 0.5281
Batch 340, Loss: 0.5280
Batch 350, Loss: 0.5396
Batch 360, Loss: 0.4815
Batch 370, Loss: 0.5341
Batch 380, Loss: 0.5317
Batch 390, Loss: 0.5158
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 24.973835945129395 seconds
Epoch 109 accuracy: 68.22%
Batch 10, Loss: 0.4120
Batch 20, Loss: 0.4480
Batch 30, Loss: 0.4079
Batch 40, Loss: 0.4226
Batch 50, Loss: 0.4109
Batch 60, Loss: 0.4277
Batch 70, Loss: 0.4321
Batch 80, Loss: 0.4004
Batch 90, Loss: 0.4125
Batch 100, Loss: 0.4519
Batch 110, Loss: 0.4477
Batch 120, Loss: 0.4228
Batch 130, Loss: 0.4552
Batch 140, Loss: 0.4614
Batch 150, Loss: 0.4524
Batch 160, Loss: 0.4642
Batch 170, Loss: 0.4641
Batch 180, Loss: 0.4488
Batch 190, Loss: 0.4661
Batch 200, Loss: 0.4671
Batch 210, Loss: 0.4823
Batch 220, Loss: 0.5025
Batch 230, Loss: 0.4474
Batch 240, Loss: 0.4464
Batch 250, Loss: 0.5054
Batch 260, Loss: 0.5089
Batch 270, Loss: 0.5069
Batch 280, Loss: 0.4983
Batch 290, Loss: 0.4687
Batch 300, Loss: 0.5293
Batch 310, Loss: 0.5139
Batch 320, Loss: 0.5412
Batch 330, Loss: 0.5194
Batch 340, Loss: 0.5379
Batch 350, Loss: 0.5323
Batch 360, Loss: 0.5140
Batch 370, Loss: 0.5651
Batch 380, Loss: 0.5354
Batch 390, Loss: 0.5510
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.350024700164795 seconds
Epoch 110 accuracy: 67.42%
Batch 10, Loss: 0.4357
Batch 20, Loss: 0.4206
Batch 30, Loss: 0.4107
Batch 40, Loss: 0.4033
Batch 50, Loss: 0.4279
Batch 60, Loss: 0.4383
Batch 70, Loss: 0.4245
Batch 80, Loss: 0.3903
Batch 90, Loss: 0.4321
Batch 100, Loss: 0.3917
Batch 110, Loss: 0.3898
Batch 120, Loss: 0.4311
Batch 130, Loss: 0.4416
Batch 140, Loss: 0.4589
Batch 150, Loss: 0.4631
Batch 160, Loss: 0.4556
Batch 170, Loss: 0.4705
Batch 180, Loss: 0.4478
Batch 190, Loss: 0.4619
Batch 200, Loss: 0.4985
Batch 210, Loss: 0.4847
Batch 220, Loss: 0.4860
Batch 230, Loss: 0.4818
Batch 240, Loss: 0.4993
Batch 250, Loss: 0.4376
Batch 260, Loss: 0.4862
Batch 270, Loss: 0.4661
Batch 280, Loss: 0.4815
Batch 290, Loss: 0.4996
Batch 300, Loss: 0.4699
Batch 310, Loss: 0.4955
Batch 320, Loss: 0.4986
Batch 330, Loss: 0.5603
Batch 340, Loss: 0.5050
Batch 350, Loss: 0.5555
Batch 360, Loss: 0.4965
Batch 370, Loss: 0.5051
Batch 380, Loss: 0.5474
Batch 390, Loss: 0.4997
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.99682641029358 seconds
Epoch 111 accuracy: 65.24%
Batch 10, Loss: 0.4049
Batch 20, Loss: 0.4275
Batch 30, Loss: 0.3950
Batch 40, Loss: 0.4147
Batch 50, Loss: 0.4046
Batch 60, Loss: 0.4266
Batch 70, Loss: 0.4185
Batch 80, Loss: 0.4143
Batch 90, Loss: 0.4464
Batch 100, Loss: 0.4126
Batch 110, Loss: 0.4022
Batch 120, Loss: 0.4382
Batch 130, Loss: 0.4172
Batch 140, Loss: 0.4675
Batch 150, Loss: 0.4443
Batch 160, Loss: 0.4274
Batch 170, Loss: 0.4166
Batch 180, Loss: 0.4312
Batch 190, Loss: 0.4462
Batch 200, Loss: 0.4470
Batch 210, Loss: 0.4791
Batch 220, Loss: 0.4681
Batch 230, Loss: 0.4366
Batch 240, Loss: 0.4652
Batch 250, Loss: 0.4557
Batch 260, Loss: 0.4658
Batch 270, Loss: 0.4332
Batch 280, Loss: 0.4873
Batch 290, Loss: 0.4620
Batch 300, Loss: 0.4967
Batch 310, Loss: 0.4955
Batch 320, Loss: 0.4846
Batch 330, Loss: 0.4472
Batch 340, Loss: 0.5046
Batch 350, Loss: 0.4722
Batch 360, Loss: 0.5045
Batch 370, Loss: 0.5107
Batch 380, Loss: 0.4958
Batch 390, Loss: 0.4896
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.02623438835144 seconds
Epoch 112 accuracy: 66.25%
Batch 10, Loss: 0.4439
Batch 20, Loss: 0.4236
Batch 30, Loss: 0.4053
Batch 40, Loss: 0.3742
Batch 50, Loss: 0.4078
Batch 60, Loss: 0.3932
Batch 70, Loss: 0.3912
Batch 80, Loss: 0.3730
Batch 90, Loss: 0.3895
Batch 100, Loss: 0.3703
Batch 110, Loss: 0.3937
Batch 120, Loss: 0.4155
Batch 130, Loss: 0.4141
Batch 140, Loss: 0.4211
Batch 150, Loss: 0.4287
Batch 160, Loss: 0.4222
Batch 170, Loss: 0.4532
Batch 180, Loss: 0.4735
Batch 190, Loss: 0.4514
Batch 200, Loss: 0.4190
Batch 210, Loss: 0.4353
Batch 220, Loss: 0.4144
Batch 230, Loss: 0.4339
Batch 240, Loss: 0.4418
Batch 250, Loss: 0.4655
Batch 260, Loss: 0.4491
Batch 270, Loss: 0.4610
Batch 280, Loss: 0.4563
Batch 290, Loss: 0.4707
Batch 300, Loss: 0.4767
Batch 310, Loss: 0.4995
Batch 320, Loss: 0.4698
Batch 330, Loss: 0.4939
Batch 340, Loss: 0.5003
Batch 350, Loss: 0.4762
Batch 360, Loss: 0.4539
Batch 370, Loss: 0.4525
Batch 380, Loss: 0.4836
Batch 390, Loss: 0.5305
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.172202348709106 seconds
Epoch 113 accuracy: 65.31%
Batch 10, Loss: 0.4277
Batch 20, Loss: 0.4148
Batch 30, Loss: 0.3933
Batch 40, Loss: 0.4200
Batch 50, Loss: 0.3942
Batch 60, Loss: 0.3887
Batch 70, Loss: 0.3956
Batch 80, Loss: 0.3697
Batch 90, Loss: 0.4030
Batch 100, Loss: 0.4174
Batch 110, Loss: 0.4005
Batch 120, Loss: 0.4019
Batch 130, Loss: 0.3980
Batch 140, Loss: 0.4070
Batch 150, Loss: 0.3707
Batch 160, Loss: 0.4039
Batch 170, Loss: 0.4136
Batch 180, Loss: 0.4459
Batch 190, Loss: 0.4086
Batch 200, Loss: 0.4169
Batch 210, Loss: 0.4304
Batch 220, Loss: 0.4175
Batch 230, Loss: 0.4275
Batch 240, Loss: 0.4301
Batch 250, Loss: 0.4347
Batch 260, Loss: 0.4291
Batch 270, Loss: 0.4611
Batch 280, Loss: 0.4563
Batch 290, Loss: 0.4478
Batch 300, Loss: 0.4651
Batch 310, Loss: 0.4607
Batch 320, Loss: 0.4783
Batch 330, Loss: 0.4659
Batch 340, Loss: 0.4692
Batch 350, Loss: 0.4752
Batch 360, Loss: 0.4698
Batch 370, Loss: 0.5084
Batch 380, Loss: 0.4767
Batch 390, Loss: 0.4655
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 24.99425959587097 seconds
Epoch 114 accuracy: 67.73%
Batch 10, Loss: 0.3816
Batch 20, Loss: 0.3989
Batch 30, Loss: 0.3994
Batch 40, Loss: 0.3768
Batch 50, Loss: 0.3812
Batch 60, Loss: 0.3962
Batch 70, Loss: 0.3649
Batch 80, Loss: 0.3942
Batch 90, Loss: 0.3922
Batch 100, Loss: 0.3874
Batch 110, Loss: 0.3905
Batch 120, Loss: 0.3778
Batch 130, Loss: 0.4051
Batch 140, Loss: 0.3806
Batch 150, Loss: 0.3583
Batch 160, Loss: 0.4259
Batch 170, Loss: 0.4096
Batch 180, Loss: 0.3635
Batch 190, Loss: 0.4398
Batch 200, Loss: 0.4510
Batch 210, Loss: 0.4466
Batch 220, Loss: 0.4331
Batch 230, Loss: 0.4320
Batch 240, Loss: 0.4355
Batch 250, Loss: 0.4206
Batch 260, Loss: 0.4665
Batch 270, Loss: 0.4362
Batch 280, Loss: 0.4223
Batch 290, Loss: 0.4288
Batch 300, Loss: 0.4741
Batch 310, Loss: 0.4424
Batch 320, Loss: 0.5019
Batch 330, Loss: 0.4718
Batch 340, Loss: 0.4771
Batch 350, Loss: 0.4391
Batch 360, Loss: 0.4605
Batch 370, Loss: 0.4595
Batch 380, Loss: 0.4602
Batch 390, Loss: 0.4710
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.02116084098816 seconds
Epoch 115 accuracy: 67.34%
Batch 10, Loss: 0.4049
Batch 20, Loss: 0.3980
Batch 30, Loss: 0.3965
Batch 40, Loss: 0.3972
Batch 50, Loss: 0.3696
Batch 60, Loss: 0.3963
Batch 70, Loss: 0.3769
Batch 80, Loss: 0.3961
Batch 90, Loss: 0.3921
Batch 100, Loss: 0.3894
Batch 110, Loss: 0.4500
Batch 120, Loss: 0.3983
Batch 130, Loss: 0.4158
Batch 140, Loss: 0.4041
Batch 150, Loss: 0.3926
Batch 160, Loss: 0.4011
Batch 170, Loss: 0.4180
Batch 180, Loss: 0.4124
Batch 190, Loss: 0.4020
Batch 200, Loss: 0.3823
Batch 210, Loss: 0.4304
Batch 220, Loss: 0.4093
Batch 230, Loss: 0.4162
Batch 240, Loss: 0.4385
Batch 250, Loss: 0.4264
Batch 260, Loss: 0.4323
Batch 270, Loss: 0.4301
Batch 280, Loss: 0.4183
Batch 290, Loss: 0.4507
Batch 300, Loss: 0.4214
Batch 310, Loss: 0.4104
Batch 320, Loss: 0.4674
Batch 330, Loss: 0.4689
Batch 340, Loss: 0.4583
Batch 350, Loss: 0.4647
Batch 360, Loss: 0.4577
Batch 370, Loss: 0.4687
Batch 380, Loss: 0.4598
Batch 390, Loss: 0.4589
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.19629406929016 seconds
Epoch 116 accuracy: 67.35%
Batch 10, Loss: 0.3930
Batch 20, Loss: 0.3717
Batch 30, Loss: 0.3462
Batch 40, Loss: 0.3753
Batch 50, Loss: 0.3471
Batch 60, Loss: 0.3723
Batch 70, Loss: 0.3725
Batch 80, Loss: 0.3643
Batch 90, Loss: 0.3847
Batch 100, Loss: 0.3632
Batch 110, Loss: 0.3855
Batch 120, Loss: 0.3795
Batch 130, Loss: 0.4052
Batch 140, Loss: 0.3965
Batch 150, Loss: 0.4032
Batch 160, Loss: 0.3970
Batch 170, Loss: 0.3927
Batch 180, Loss: 0.3910
Batch 190, Loss: 0.4052
Batch 200, Loss: 0.3779
Batch 210, Loss: 0.4058
Batch 220, Loss: 0.3884
Batch 230, Loss: 0.4162
Batch 240, Loss: 0.4512
Batch 250, Loss: 0.4156
Batch 260, Loss: 0.4079
Batch 270, Loss: 0.4032
Batch 280, Loss: 0.4481
Batch 290, Loss: 0.4327
Batch 300, Loss: 0.4421
Batch 310, Loss: 0.4498
Batch 320, Loss: 0.4407
Batch 330, Loss: 0.4462
Batch 340, Loss: 0.4530
Batch 350, Loss: 0.4284
Batch 360, Loss: 0.4524
Batch 370, Loss: 0.4719
Batch 380, Loss: 0.4367
Batch 390, Loss: 0.4390
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.001925230026245 seconds
Epoch 117 accuracy: 68.89%
Batch 10, Loss: 0.3787
Batch 20, Loss: 0.3709
Batch 30, Loss: 0.3760
Batch 40, Loss: 0.3460
Batch 50, Loss: 0.3462
Batch 60, Loss: 0.3724
Batch 70, Loss: 0.3540
Batch 80, Loss: 0.3650
Batch 90, Loss: 0.3382
Batch 100, Loss: 0.3751
Batch 110, Loss: 0.3445
Batch 120, Loss: 0.3629
Batch 130, Loss: 0.3819
Batch 140, Loss: 0.3780
Batch 150, Loss: 0.3535
Batch 160, Loss: 0.3735
Batch 170, Loss: 0.3295
Batch 180, Loss: 0.3975
Batch 190, Loss: 0.4043
Batch 200, Loss: 0.3905
Batch 210, Loss: 0.3996
Batch 220, Loss: 0.4163
Batch 230, Loss: 0.4266
Batch 240, Loss: 0.3983
Batch 250, Loss: 0.3958
Batch 260, Loss: 0.4037
Batch 270, Loss: 0.3975
Batch 280, Loss: 0.3960
Batch 290, Loss: 0.3825
Batch 300, Loss: 0.4350
Batch 310, Loss: 0.4367
Batch 320, Loss: 0.4389
Batch 330, Loss: 0.4148
Batch 340, Loss: 0.4173
Batch 350, Loss: 0.4326
Batch 360, Loss: 0.4454
Batch 370, Loss: 0.4537
Batch 380, Loss: 0.4636
Batch 390, Loss: 0.4364
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.078676223754883 seconds
Epoch 118 accuracy: 68.1%
Batch 10, Loss: 0.4006
Batch 20, Loss: 0.4045
Batch 30, Loss: 0.3779
Batch 40, Loss: 0.3581
Batch 50, Loss: 0.4062
Batch 60, Loss: 0.3368
Batch 70, Loss: 0.3549
Batch 80, Loss: 0.3833
Batch 90, Loss: 0.3771
Batch 100, Loss: 0.3876
Batch 110, Loss: 0.3997
Batch 120, Loss: 0.3804
Batch 130, Loss: 0.3691
Batch 140, Loss: 0.3781
Batch 150, Loss: 0.3787
Batch 160, Loss: 0.4075
Batch 170, Loss: 0.3732
Batch 180, Loss: 0.3345
Batch 190, Loss: 0.3802
Batch 200, Loss: 0.3992
Batch 210, Loss: 0.4118
Batch 220, Loss: 0.3971
Batch 230, Loss: 0.3962
Batch 240, Loss: 0.4059
Batch 250, Loss: 0.4022
Batch 260, Loss: 0.4023
Batch 270, Loss: 0.3985
Batch 280, Loss: 0.4011
Batch 290, Loss: 0.3726
Batch 300, Loss: 0.4149
Batch 310, Loss: 0.4385
Batch 320, Loss: 0.3944
Batch 330, Loss: 0.4416
Batch 340, Loss: 0.4239
Batch 350, Loss: 0.4576
Batch 360, Loss: 0.3979
Batch 370, Loss: 0.4703
Batch 380, Loss: 0.4362
Batch 390, Loss: 0.4413
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.13821244239807 seconds
Epoch 119 accuracy: 68.6%
Batch 10, Loss: 0.3736
Batch 20, Loss: 0.3901
Batch 30, Loss: 0.3356
Batch 40, Loss: 0.3450
Batch 50, Loss: 0.3411
Batch 60, Loss: 0.3365
Batch 70, Loss: 0.3480
Batch 80, Loss: 0.3378
Batch 90, Loss: 0.3328
Batch 100, Loss: 0.3475
Batch 110, Loss: 0.3140
Batch 120, Loss: 0.3533
Batch 130, Loss: 0.3839
Batch 140, Loss: 0.3438
Batch 150, Loss: 0.3775
Batch 160, Loss: 0.3849
Batch 170, Loss: 0.4137
Batch 180, Loss: 0.4025
Batch 190, Loss: 0.3989
Batch 200, Loss: 0.3581
Batch 210, Loss: 0.3952
Batch 220, Loss: 0.3954
Batch 230, Loss: 0.3957
Batch 240, Loss: 0.3750
Batch 250, Loss: 0.3821
Batch 260, Loss: 0.3891
Batch 270, Loss: 0.3658
Batch 280, Loss: 0.3804
Batch 290, Loss: 0.3587
Batch 300, Loss: 0.3933
Batch 310, Loss: 0.4170
Batch 320, Loss: 0.4142
Batch 330, Loss: 0.4002
Batch 340, Loss: 0.4338
Batch 350, Loss: 0.4348
Batch 360, Loss: 0.4202
Batch 370, Loss: 0.4299
Batch 380, Loss: 0.4080
Batch 390, Loss: 0.4159
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 24.887516260147095 seconds
Epoch 120 accuracy: 68.35%
Batch 10, Loss: 0.3676
Batch 20, Loss: 0.3329
Batch 30, Loss: 0.3377
Batch 40, Loss: 0.3268
Batch 50, Loss: 0.3349
Batch 60, Loss: 0.3521
Batch 70, Loss: 0.3187
Batch 80, Loss: 0.3437
Batch 90, Loss: 0.3206
Batch 100, Loss: 0.3678
Batch 110, Loss: 0.3501
Batch 120, Loss: 0.3457
Batch 130, Loss: 0.3693
Batch 140, Loss: 0.3132
Batch 150, Loss: 0.3418
Batch 160, Loss: 0.3572
Batch 170, Loss: 0.3731
Batch 180, Loss: 0.3827
Batch 190, Loss: 0.3714
Batch 200, Loss: 0.3516
Batch 210, Loss: 0.3445
Batch 220, Loss: 0.3623
Batch 230, Loss: 0.3682
Batch 240, Loss: 0.3843
Batch 250, Loss: 0.3685
Batch 260, Loss: 0.3928
Batch 270, Loss: 0.3728
Batch 280, Loss: 0.3859
Batch 290, Loss: 0.4006
Batch 300, Loss: 0.4072
Batch 310, Loss: 0.3997
Batch 320, Loss: 0.4081
Batch 330, Loss: 0.4187
Batch 340, Loss: 0.3849
Batch 350, Loss: 0.4374
Batch 360, Loss: 0.4381
Batch 370, Loss: 0.4376
Batch 380, Loss: 0.4399
Batch 390, Loss: 0.4105
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.165224075317383 seconds
Epoch 121 accuracy: 67.87%
Batch 10, Loss: 0.3599
Batch 20, Loss: 0.3501
Batch 30, Loss: 0.3359
Batch 40, Loss: 0.3305
Batch 50, Loss: 0.3245
Batch 60, Loss: 0.2945
Batch 70, Loss: 0.3374
Batch 80, Loss: 0.3147
Batch 90, Loss: 0.3269
Batch 100, Loss: 0.3311
Batch 110, Loss: 0.3075
Batch 120, Loss: 0.3090
Batch 130, Loss: 0.3237
Batch 140, Loss: 0.3297
Batch 150, Loss: 0.3350
Batch 160, Loss: 0.3721
Batch 170, Loss: 0.3628
Batch 180, Loss: 0.3545
Batch 190, Loss: 0.3581
Batch 200, Loss: 0.3670
Batch 210, Loss: 0.3602
Batch 220, Loss: 0.3625
Batch 230, Loss: 0.3490
Batch 240, Loss: 0.3827
Batch 250, Loss: 0.3975
Batch 260, Loss: 0.3835
Batch 270, Loss: 0.4097
Batch 280, Loss: 0.3713
Batch 290, Loss: 0.3644
Batch 300, Loss: 0.3677
Batch 310, Loss: 0.4088
Batch 320, Loss: 0.3544
Batch 330, Loss: 0.3304
Batch 340, Loss: 0.3938
Batch 350, Loss: 0.4311
Batch 360, Loss: 0.3799
Batch 370, Loss: 0.4040
Batch 380, Loss: 0.4288
Batch 390, Loss: 0.4021
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 24.97204041481018 seconds
Epoch 122 accuracy: 68.19%
Batch 10, Loss: 0.3629
Batch 20, Loss: 0.3617
Batch 30, Loss: 0.3294
Batch 40, Loss: 0.3129
Batch 50, Loss: 0.3334
Batch 60, Loss: 0.3181
Batch 70, Loss: 0.3253
Batch 80, Loss: 0.3281
Batch 90, Loss: 0.3452
Batch 100, Loss: 0.3082
Batch 110, Loss: 0.3269
Batch 120, Loss: 0.3048
Batch 130, Loss: 0.3385
Batch 140, Loss: 0.3496
Batch 150, Loss: 0.3333
Batch 160, Loss: 0.3470
Batch 170, Loss: 0.3272
Batch 180, Loss: 0.3767
Batch 190, Loss: 0.3430
Batch 200, Loss: 0.3204
Batch 210, Loss: 0.3570
Batch 220, Loss: 0.3282
Batch 230, Loss: 0.3377
Batch 240, Loss: 0.3491
Batch 250, Loss: 0.3665
Batch 260, Loss: 0.3254
Batch 270, Loss: 0.3612
Batch 280, Loss: 0.3668
Batch 290, Loss: 0.3703
Batch 300, Loss: 0.3876
Batch 310, Loss: 0.3659
Batch 320, Loss: 0.3419
Batch 330, Loss: 0.3868
Batch 340, Loss: 0.3925
Batch 350, Loss: 0.3619
Batch 360, Loss: 0.3978
Batch 370, Loss: 0.3997
Batch 380, Loss: 0.3994
Batch 390, Loss: 0.4031
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 24.928322553634644 seconds
Epoch 123 accuracy: 68.63%
Batch 10, Loss: 0.3421
Batch 20, Loss: 0.3354
Batch 30, Loss: 0.3411
Batch 40, Loss: 0.3135
Batch 50, Loss: 0.3447
Batch 60, Loss: 0.3029
Batch 70, Loss: 0.3130
Batch 80, Loss: 0.3216
Batch 90, Loss: 0.3164
Batch 100, Loss: 0.3454
Batch 110, Loss: 0.3289
Batch 120, Loss: 0.3211
Batch 130, Loss: 0.3417
Batch 140, Loss: 0.3431
Batch 150, Loss: 0.3403
Batch 160, Loss: 0.3497
Batch 170, Loss: 0.3558
Batch 180, Loss: 0.3284
Batch 190, Loss: 0.3441
Batch 200, Loss: 0.3379
Batch 210, Loss: 0.3665
Batch 220, Loss: 0.3852
Batch 230, Loss: 0.3465
Batch 240, Loss: 0.3251
Batch 250, Loss: 0.3368
Batch 260, Loss: 0.3492
Batch 270, Loss: 0.3446
Batch 280, Loss: 0.3395
Batch 290, Loss: 0.3641
Batch 300, Loss: 0.3532
Batch 310, Loss: 0.3536
Batch 320, Loss: 0.3904
Batch 330, Loss: 0.3841
Batch 340, Loss: 0.3741
Batch 350, Loss: 0.3768
Batch 360, Loss: 0.3783
Batch 370, Loss: 0.3739
Batch 380, Loss: 0.4100
Batch 390, Loss: 0.3848
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.00239086151123 seconds
Epoch 124 accuracy: 69.84%
Batch 10, Loss: 0.3210
Batch 20, Loss: 0.2930
Batch 30, Loss: 0.3094
Batch 40, Loss: 0.3140
Batch 50, Loss: 0.3005
Batch 60, Loss: 0.3130
Batch 70, Loss: 0.3033
Batch 80, Loss: 0.2894
Batch 90, Loss: 0.2964
Batch 100, Loss: 0.3082
Batch 110, Loss: 0.2811
Batch 120, Loss: 0.3046
Batch 130, Loss: 0.3275
Batch 140, Loss: 0.3166
Batch 150, Loss: 0.3029
Batch 160, Loss: 0.3276
Batch 170, Loss: 0.3360
Batch 180, Loss: 0.3253
Batch 190, Loss: 0.3481
Batch 200, Loss: 0.3293
Batch 210, Loss: 0.3420
Batch 220, Loss: 0.3292
Batch 230, Loss: 0.3577
Batch 240, Loss: 0.3328
Batch 250, Loss: 0.3220
Batch 260, Loss: 0.3463
Batch 270, Loss: 0.3299
Batch 280, Loss: 0.3209
Batch 290, Loss: 0.3209
Batch 300, Loss: 0.3173
Batch 310, Loss: 0.3438
Batch 320, Loss: 0.3602
Batch 330, Loss: 0.3959
Batch 340, Loss: 0.3607
Batch 350, Loss: 0.3531
Batch 360, Loss: 0.3542
Batch 370, Loss: 0.3969
Batch 380, Loss: 0.4001
Batch 390, Loss: 0.4197
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 24.932101488113403 seconds
Epoch 125 accuracy: 68.84%
Batch 10, Loss: 0.3193
Batch 20, Loss: 0.3219
Batch 30, Loss: 0.3003
Batch 40, Loss: 0.2992
Batch 50, Loss: 0.2899
Batch 60, Loss: 0.3220
Batch 70, Loss: 0.3134
Batch 80, Loss: 0.2878
Batch 90, Loss: 0.3057
Batch 100, Loss: 0.3098
Batch 110, Loss: 0.3053
Batch 120, Loss: 0.3306
Batch 130, Loss: 0.3176
Batch 140, Loss: 0.3121
Batch 150, Loss: 0.3274
Batch 160, Loss: 0.2975
Batch 170, Loss: 0.3144
Batch 180, Loss: 0.3477
Batch 190, Loss: 0.3136
Batch 200, Loss: 0.3121
Batch 210, Loss: 0.3138
Batch 220, Loss: 0.3190
Batch 230, Loss: 0.3383
Batch 240, Loss: 0.3008
Batch 250, Loss: 0.3193
Batch 260, Loss: 0.3422
Batch 270, Loss: 0.3009
Batch 280, Loss: 0.3250
Batch 290, Loss: 0.3111
Batch 300, Loss: 0.3354
Batch 310, Loss: 0.3382
Batch 320, Loss: 0.3738
Batch 330, Loss: 0.3283
Batch 340, Loss: 0.3652
Batch 350, Loss: 0.3526
Batch 360, Loss: 0.3575
Batch 370, Loss: 0.3768
Batch 380, Loss: 0.3736
Batch 390, Loss: 0.3723
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.106688261032104 seconds
Epoch 126 accuracy: 70.32%
Batch 10, Loss: 0.2972
Batch 20, Loss: 0.3123
Batch 30, Loss: 0.2830
Batch 40, Loss: 0.2906
Batch 50, Loss: 0.2834
Batch 60, Loss: 0.2808
Batch 70, Loss: 0.2967
Batch 80, Loss: 0.2836
Batch 90, Loss: 0.2789
Batch 100, Loss: 0.2873
Batch 110, Loss: 0.2905
Batch 120, Loss: 0.2951
Batch 130, Loss: 0.2691
Batch 140, Loss: 0.2696
Batch 150, Loss: 0.3074
Batch 160, Loss: 0.3074
Batch 170, Loss: 0.3071
Batch 180, Loss: 0.3027
Batch 190, Loss: 0.2951
Batch 200, Loss: 0.3169
Batch 210, Loss: 0.2690
Batch 220, Loss: 0.2954
Batch 230, Loss: 0.2896
Batch 240, Loss: 0.3296
Batch 250, Loss: 0.3088
Batch 260, Loss: 0.2936
Batch 270, Loss: 0.3237
Batch 280, Loss: 0.3223
Batch 290, Loss: 0.3374
Batch 300, Loss: 0.3289
Batch 310, Loss: 0.3320
Batch 320, Loss: 0.3564
Batch 330, Loss: 0.3317
Batch 340, Loss: 0.3539
Batch 350, Loss: 0.3306
Batch 360, Loss: 0.3529
Batch 370, Loss: 0.3488
Batch 380, Loss: 0.3335
Batch 390, Loss: 0.3319
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.15500807762146 seconds
Epoch 127 accuracy: 70.58%
Batch 10, Loss: 0.2802
Batch 20, Loss: 0.3055
Batch 30, Loss: 0.2805
Batch 40, Loss: 0.2801
Batch 50, Loss: 0.2775
Batch 60, Loss: 0.2861
Batch 70, Loss: 0.2964
Batch 80, Loss: 0.2786
Batch 90, Loss: 0.2942
Batch 100, Loss: 0.2758
Batch 110, Loss: 0.3058
Batch 120, Loss: 0.3251
Batch 130, Loss: 0.2925
Batch 140, Loss: 0.3103
Batch 150, Loss: 0.3192
Batch 160, Loss: 0.2971
Batch 170, Loss: 0.3006
Batch 180, Loss: 0.2921
Batch 190, Loss: 0.2845
Batch 200, Loss: 0.2972
Batch 210, Loss: 0.2815
Batch 220, Loss: 0.2967
Batch 230, Loss: 0.3212
Batch 240, Loss: 0.2851
Batch 250, Loss: 0.2982
Batch 260, Loss: 0.3126
Batch 270, Loss: 0.3386
Batch 280, Loss: 0.3316
Batch 290, Loss: 0.3211
Batch 300, Loss: 0.3163
Batch 310, Loss: 0.3397
Batch 320, Loss: 0.3505
Batch 330, Loss: 0.3347
Batch 340, Loss: 0.3461
Batch 350, Loss: 0.3380
Batch 360, Loss: 0.3258
Batch 370, Loss: 0.3588
Batch 380, Loss: 0.3793
Batch 390, Loss: 0.3468
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 24.980462551116943 seconds
Epoch 128 accuracy: 70.2%
Batch 10, Loss: 0.2966
Batch 20, Loss: 0.2844
Batch 30, Loss: 0.2876
Batch 40, Loss: 0.2835
Batch 50, Loss: 0.2798
Batch 60, Loss: 0.2794
Batch 70, Loss: 0.2427
Batch 80, Loss: 0.2658
Batch 90, Loss: 0.2824
Batch 100, Loss: 0.2377
Batch 110, Loss: 0.2729
Batch 120, Loss: 0.2856
Batch 130, Loss: 0.2629
Batch 140, Loss: 0.2828
Batch 150, Loss: 0.2918
Batch 160, Loss: 0.2993
Batch 170, Loss: 0.2513
Batch 180, Loss: 0.2917
Batch 190, Loss: 0.2693
Batch 200, Loss: 0.2782
Batch 210, Loss: 0.3044
Batch 220, Loss: 0.2811
Batch 230, Loss: 0.2890
Batch 240, Loss: 0.3091
Batch 250, Loss: 0.2675
Batch 260, Loss: 0.2894
Batch 270, Loss: 0.3266
Batch 280, Loss: 0.3088
Batch 290, Loss: 0.3299
Batch 300, Loss: 0.3238
Batch 310, Loss: 0.3259
Batch 320, Loss: 0.3320
Batch 330, Loss: 0.3098
Batch 340, Loss: 0.3295
Batch 350, Loss: 0.3134
Batch 360, Loss: 0.3602
Batch 370, Loss: 0.3369
Batch 380, Loss: 0.3416
Batch 390, Loss: 0.3481
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.086219787597656 seconds
Epoch 129 accuracy: 69.09%
Batch 10, Loss: 0.3004
Batch 20, Loss: 0.2886
Batch 30, Loss: 0.2584
Batch 40, Loss: 0.2661
Batch 50, Loss: 0.2564
Batch 60, Loss: 0.2676
Batch 70, Loss: 0.2519
Batch 80, Loss: 0.2809
Batch 90, Loss: 0.2643
Batch 100, Loss: 0.2682
Batch 110, Loss: 0.2765
Batch 120, Loss: 0.2601
Batch 130, Loss: 0.2632
Batch 140, Loss: 0.2895
Batch 150, Loss: 0.2788
Batch 160, Loss: 0.2668
Batch 170, Loss: 0.2768
Batch 180, Loss: 0.2976
Batch 190, Loss: 0.2565
Batch 200, Loss: 0.2659
Batch 210, Loss: 0.2932
Batch 220, Loss: 0.2719
Batch 230, Loss: 0.2864
Batch 240, Loss: 0.2899
Batch 250, Loss: 0.2882
Batch 260, Loss: 0.2786
Batch 270, Loss: 0.2888
Batch 280, Loss: 0.3341
Batch 290, Loss: 0.3274
Batch 300, Loss: 0.3508
Batch 310, Loss: 0.3108
Batch 320, Loss: 0.3099
Batch 330, Loss: 0.2967
Batch 340, Loss: 0.3384
Batch 350, Loss: 0.3352
Batch 360, Loss: 0.3064
Batch 370, Loss: 0.3313
Batch 380, Loss: 0.3138
Batch 390, Loss: 0.3315
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 24.952327966690063 seconds
Epoch 130 accuracy: 70.57%
Batch 10, Loss: 0.2724
Batch 20, Loss: 0.2778
Batch 30, Loss: 0.2572
Batch 40, Loss: 0.2582
Batch 50, Loss: 0.2840
Batch 60, Loss: 0.2623
Batch 70, Loss: 0.2606
Batch 80, Loss: 0.2543
Batch 90, Loss: 0.2675
Batch 100, Loss: 0.2854
Batch 110, Loss: 0.2696
Batch 120, Loss: 0.2769
Batch 130, Loss: 0.2561
Batch 140, Loss: 0.2537
Batch 150, Loss: 0.2667
Batch 160, Loss: 0.2644
Batch 170, Loss: 0.2925
Batch 180, Loss: 0.2795
Batch 190, Loss: 0.2854
Batch 200, Loss: 0.2651
Batch 210, Loss: 0.2778
Batch 220, Loss: 0.2777
Batch 230, Loss: 0.2966
Batch 240, Loss: 0.2864
Batch 250, Loss: 0.2950
Batch 260, Loss: 0.2781
Batch 270, Loss: 0.2695
Batch 280, Loss: 0.2899
Batch 290, Loss: 0.3170
Batch 300, Loss: 0.2926
Batch 310, Loss: 0.3005
Batch 320, Loss: 0.3043
Batch 330, Loss: 0.3254
Batch 340, Loss: 0.3239
Batch 350, Loss: 0.3346
Batch 360, Loss: 0.3124
Batch 370, Loss: 0.3029
Batch 380, Loss: 0.3096
Batch 390, Loss: 0.3118
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 24.989807605743408 seconds
Epoch 131 accuracy: 70.25%
Batch 10, Loss: 0.2383
Batch 20, Loss: 0.2735
Batch 30, Loss: 0.2557
Batch 40, Loss: 0.2537
Batch 50, Loss: 0.2608
Batch 60, Loss: 0.2288
Batch 70, Loss: 0.2446
Batch 80, Loss: 0.2304
Batch 90, Loss: 0.2728
Batch 100, Loss: 0.2588
Batch 110, Loss: 0.2453
Batch 120, Loss: 0.2669
Batch 130, Loss: 0.2483
Batch 140, Loss: 0.2734
Batch 150, Loss: 0.2652
Batch 160, Loss: 0.2582
Batch 170, Loss: 0.2394
Batch 180, Loss: 0.2671
Batch 190, Loss: 0.2803
Batch 200, Loss: 0.2703
Batch 210, Loss: 0.2791
Batch 220, Loss: 0.2663
Batch 230, Loss: 0.2719
Batch 240, Loss: 0.2599
Batch 250, Loss: 0.2793
Batch 260, Loss: 0.2805
Batch 270, Loss: 0.2638
Batch 280, Loss: 0.2753
Batch 290, Loss: 0.2591
Batch 300, Loss: 0.2716
Batch 310, Loss: 0.2855
Batch 320, Loss: 0.2634
Batch 330, Loss: 0.2667
Batch 340, Loss: 0.2639
Batch 350, Loss: 0.2804
Batch 360, Loss: 0.2699
Batch 370, Loss: 0.2825
Batch 380, Loss: 0.2975
Batch 390, Loss: 0.2821
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 24.982970237731934 seconds
Epoch 132 accuracy: 70.39%
Batch 10, Loss: 0.2385
Batch 20, Loss: 0.2550
Batch 30, Loss: 0.2507
Batch 40, Loss: 0.2395
Batch 50, Loss: 0.2431
Batch 60, Loss: 0.2411
Batch 70, Loss: 0.2260
Batch 80, Loss: 0.2415
Batch 90, Loss: 0.2510
Batch 100, Loss: 0.2301
Batch 110, Loss: 0.2677
Batch 120, Loss: 0.2507
Batch 130, Loss: 0.2311
Batch 140, Loss: 0.2549
Batch 150, Loss: 0.2347
Batch 160, Loss: 0.2477
Batch 170, Loss: 0.2602
Batch 180, Loss: 0.2619
Batch 190, Loss: 0.2711
Batch 200, Loss: 0.2453
Batch 210, Loss: 0.2635
Batch 220, Loss: 0.2690
Batch 230, Loss: 0.2528
Batch 240, Loss: 0.2750
Batch 250, Loss: 0.2494
Batch 260, Loss: 0.2495
Batch 270, Loss: 0.2731
Batch 280, Loss: 0.2500
Batch 290, Loss: 0.2704
Batch 300, Loss: 0.2603
Batch 310, Loss: 0.2632
Batch 320, Loss: 0.2644
Batch 330, Loss: 0.2624
Batch 340, Loss: 0.2623
Batch 350, Loss: 0.2756
Batch 360, Loss: 0.2751
Batch 370, Loss: 0.2795
Batch 380, Loss: 0.2736
Batch 390, Loss: 0.2677
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 24.946980714797974 seconds
Epoch 133 accuracy: 71.2%
Batch 10, Loss: 0.2510
Batch 20, Loss: 0.2495
Batch 30, Loss: 0.2399
Batch 40, Loss: 0.2276
Batch 50, Loss: 0.2438
Batch 60, Loss: 0.2257
Batch 70, Loss: 0.2286
Batch 80, Loss: 0.2351
Batch 90, Loss: 0.2279
Batch 100, Loss: 0.2173
Batch 110, Loss: 0.2289
Batch 120, Loss: 0.2274
Batch 130, Loss: 0.2442
Batch 140, Loss: 0.2517
Batch 150, Loss: 0.2310
Batch 160, Loss: 0.2571
Batch 170, Loss: 0.2469
Batch 180, Loss: 0.2371
Batch 190, Loss: 0.2325
Batch 200, Loss: 0.2370
Batch 210, Loss: 0.2697
Batch 220, Loss: 0.2291
Batch 230, Loss: 0.2622
Batch 240, Loss: 0.2269
Batch 250, Loss: 0.2647
Batch 260, Loss: 0.2479
Batch 270, Loss: 0.2582
Batch 280, Loss: 0.2701
Batch 290, Loss: 0.2639
Batch 300, Loss: 0.2817
Batch 310, Loss: 0.2626
Batch 320, Loss: 0.2654
Batch 330, Loss: 0.2510
Batch 340, Loss: 0.2541
Batch 350, Loss: 0.2846
Batch 360, Loss: 0.2994
Batch 370, Loss: 0.2828
Batch 380, Loss: 0.2853
Batch 390, Loss: 0.2929
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.046754598617554 seconds
Epoch 134 accuracy: 71.28%
Batch 10, Loss: 0.2158
Batch 20, Loss: 0.2263
Batch 30, Loss: 0.2256
Batch 40, Loss: 0.2359
Batch 50, Loss: 0.2235
Batch 60, Loss: 0.2260
Batch 70, Loss: 0.2164
Batch 80, Loss: 0.2294
Batch 90, Loss: 0.2275
Batch 100, Loss: 0.2151
Batch 110, Loss: 0.2244
Batch 120, Loss: 0.2463
Batch 130, Loss: 0.2375
Batch 140, Loss: 0.2268
Batch 150, Loss: 0.2129
Batch 160, Loss: 0.2283
Batch 170, Loss: 0.2527
Batch 180, Loss: 0.2480
Batch 190, Loss: 0.2397
Batch 200, Loss: 0.2346
Batch 210, Loss: 0.2620
Batch 220, Loss: 0.2376
Batch 230, Loss: 0.2391
Batch 240, Loss: 0.2410
Batch 250, Loss: 0.2657
Batch 260, Loss: 0.2616
Batch 270, Loss: 0.2551
Batch 280, Loss: 0.2407
Batch 290, Loss: 0.2693
Batch 300, Loss: 0.2454
Batch 310, Loss: 0.2760
Batch 320, Loss: 0.2627
Batch 330, Loss: 0.2739
Batch 340, Loss: 0.2727
Batch 350, Loss: 0.2675
Batch 360, Loss: 0.2720
Batch 370, Loss: 0.2707
Batch 380, Loss: 0.2701
Batch 390, Loss: 0.2709
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 24.938190460205078 seconds
Epoch 135 accuracy: 71.66%
Batch 10, Loss: 0.2118
Batch 20, Loss: 0.2259
Batch 30, Loss: 0.2212
Batch 40, Loss: 0.2146
Batch 50, Loss: 0.1984
Batch 60, Loss: 0.2237
Batch 70, Loss: 0.2201
Batch 80, Loss: 0.2175
Batch 90, Loss: 0.1998
Batch 100, Loss: 0.2298
Batch 110, Loss: 0.2232
Batch 120, Loss: 0.2153
Batch 130, Loss: 0.2279
Batch 140, Loss: 0.2118
Batch 150, Loss: 0.1996
Batch 160, Loss: 0.2052
Batch 170, Loss: 0.2202
Batch 180, Loss: 0.2220
Batch 190, Loss: 0.2213
Batch 200, Loss: 0.2236
Batch 210, Loss: 0.2392
Batch 220, Loss: 0.2452
Batch 230, Loss: 0.2509
Batch 240, Loss: 0.2516
Batch 250, Loss: 0.2350
Batch 260, Loss: 0.2790
Batch 270, Loss: 0.2528
Batch 280, Loss: 0.2504
Batch 290, Loss: 0.2585
Batch 300, Loss: 0.2501
Batch 310, Loss: 0.2621
Batch 320, Loss: 0.2411
Batch 330, Loss: 0.2634
Batch 340, Loss: 0.2544
Batch 350, Loss: 0.2526
Batch 360, Loss: 0.2669
Batch 370, Loss: 0.2897
Batch 380, Loss: 0.2747
Batch 390, Loss: 0.2530
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.091349601745605 seconds
Epoch 136 accuracy: 70.57%
Batch 10, Loss: 0.2360
Batch 20, Loss: 0.2112
Batch 30, Loss: 0.2371
Batch 40, Loss: 0.1995
Batch 50, Loss: 0.2218
Batch 60, Loss: 0.2201
Batch 70, Loss: 0.1985
Batch 80, Loss: 0.2179
Batch 90, Loss: 0.2206
Batch 100, Loss: 0.2040
Batch 110, Loss: 0.2122
Batch 120, Loss: 0.2065
Batch 130, Loss: 0.2196
Batch 140, Loss: 0.2132
Batch 150, Loss: 0.2154
Batch 160, Loss: 0.2324
Batch 170, Loss: 0.2205
Batch 180, Loss: 0.2460
Batch 190, Loss: 0.2059
Batch 200, Loss: 0.2292
Batch 210, Loss: 0.2439
Batch 220, Loss: 0.2014
Batch 230, Loss: 0.2151
Batch 240, Loss: 0.2232
Batch 250, Loss: 0.2386
Batch 260, Loss: 0.2074
Batch 270, Loss: 0.2212
Batch 280, Loss: 0.2197
Batch 290, Loss: 0.2240
Batch 300, Loss: 0.2268
Batch 310, Loss: 0.2305
Batch 320, Loss: 0.2231
Batch 330, Loss: 0.2560
Batch 340, Loss: 0.2437
Batch 350, Loss: 0.2353
Batch 360, Loss: 0.2549
Batch 370, Loss: 0.2822
Batch 380, Loss: 0.2888
Batch 390, Loss: 0.2817
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 24.959737539291382 seconds
Epoch 137 accuracy: 71.25%
Batch 10, Loss: 0.2466
Batch 20, Loss: 0.2286
Batch 30, Loss: 0.2324
Batch 40, Loss: 0.2148
Batch 50, Loss: 0.2094
Batch 60, Loss: 0.2134
Batch 70, Loss: 0.2378
Batch 80, Loss: 0.2121
Batch 90, Loss: 0.1903
Batch 100, Loss: 0.2018
Batch 110, Loss: 0.2126
Batch 120, Loss: 0.1990
Batch 130, Loss: 0.1957
Batch 140, Loss: 0.2130
Batch 150, Loss: 0.2044
Batch 160, Loss: 0.2113
Batch 170, Loss: 0.2027
Batch 180, Loss: 0.2142
Batch 190, Loss: 0.1956
Batch 200, Loss: 0.2202
Batch 210, Loss: 0.2115
Batch 220, Loss: 0.2136
Batch 230, Loss: 0.2191
Batch 240, Loss: 0.2299
Batch 250, Loss: 0.2157
Batch 260, Loss: 0.2122
Batch 270, Loss: 0.2272
Batch 280, Loss: 0.2396
Batch 290, Loss: 0.2127
Batch 300, Loss: 0.2761
Batch 310, Loss: 0.2342
Batch 320, Loss: 0.2522
Batch 330, Loss: 0.2566
Batch 340, Loss: 0.2365
Batch 350, Loss: 0.2416
Batch 360, Loss: 0.2403
Batch 370, Loss: 0.2093
Batch 380, Loss: 0.2625
Batch 390, Loss: 0.2418
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 24.99590516090393 seconds
Epoch 138 accuracy: 71.04%
Batch 10, Loss: 0.2101
Batch 20, Loss: 0.2078
Batch 30, Loss: 0.2243
Batch 40, Loss: 0.2046
Batch 50, Loss: 0.1886
Batch 60, Loss: 0.1970
Batch 70, Loss: 0.1893
Batch 80, Loss: 0.1918
Batch 90, Loss: 0.1915
Batch 100, Loss: 0.2144
Batch 110, Loss: 0.2045
Batch 120, Loss: 0.2095
Batch 130, Loss: 0.2001
Batch 140, Loss: 0.2324
Batch 150, Loss: 0.2181
Batch 160, Loss: 0.2105
Batch 170, Loss: 0.2137
Batch 180, Loss: 0.2305
Batch 190, Loss: 0.2182
Batch 200, Loss: 0.1986
Batch 210, Loss: 0.2267
Batch 220, Loss: 0.2144
Batch 230, Loss: 0.2184
Batch 240, Loss: 0.2467
Batch 250, Loss: 0.2405
Batch 260, Loss: 0.2375
Batch 270, Loss: 0.2393
Batch 280, Loss: 0.2439
Batch 290, Loss: 0.2290
Batch 300, Loss: 0.2399
Batch 310, Loss: 0.2296
Batch 320, Loss: 0.2506
Batch 330, Loss: 0.2408
Batch 340, Loss: 0.2436
Batch 350, Loss: 0.2488
Batch 360, Loss: 0.2470
Batch 370, Loss: 0.2319
Batch 380, Loss: 0.2398
Batch 390, Loss: 0.2296
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 24.969762325286865 seconds
Epoch 139 accuracy: 71.97%
Batch 10, Loss: 0.2033
Batch 20, Loss: 0.2010
Batch 30, Loss: 0.2045
Batch 40, Loss: 0.1995
Batch 50, Loss: 0.1993
Batch 60, Loss: 0.1939
Batch 70, Loss: 0.2134
Batch 80, Loss: 0.2004
Batch 90, Loss: 0.1862
Batch 100, Loss: 0.1918
Batch 110, Loss: 0.1922
Batch 120, Loss: 0.1989
Batch 130, Loss: 0.2100
Batch 140, Loss: 0.2090
Batch 150, Loss: 0.2212
Batch 160, Loss: 0.2176
Batch 170, Loss: 0.2123
Batch 180, Loss: 0.2033
Batch 190, Loss: 0.2118
Batch 200, Loss: 0.2124
Batch 210, Loss: 0.1969
Batch 220, Loss: 0.2082
Batch 230, Loss: 0.2105
Batch 240, Loss: 0.2030
Batch 250, Loss: 0.2196
Batch 260, Loss: 0.2074
Batch 270, Loss: 0.2048
Batch 280, Loss: 0.2382
Batch 290, Loss: 0.1943
Batch 300, Loss: 0.2085
Batch 310, Loss: 0.1988
Batch 320, Loss: 0.1895
Batch 330, Loss: 0.2290
Batch 340, Loss: 0.2220
Batch 350, Loss: 0.2272
Batch 360, Loss: 0.2331
Batch 370, Loss: 0.2227
Batch 380, Loss: 0.2454
Batch 390, Loss: 0.2696
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.028260469436646 seconds
Epoch 140 accuracy: 71.28%
Batch 10, Loss: 0.1985
Batch 20, Loss: 0.2012
Batch 30, Loss: 0.1991
Batch 40, Loss: 0.1847
Batch 50, Loss: 0.2046
Batch 60, Loss: 0.2126
Batch 70, Loss: 0.2007
Batch 80, Loss: 0.1988
Batch 90, Loss: 0.1743
Batch 100, Loss: 0.1966
Batch 110, Loss: 0.1769
Batch 120, Loss: 0.1817
Batch 130, Loss: 0.1872
Batch 140, Loss: 0.1884
Batch 150, Loss: 0.1963
Batch 160, Loss: 0.1798
Batch 170, Loss: 0.2048
Batch 180, Loss: 0.2017
Batch 190, Loss: 0.2018
Batch 200, Loss: 0.2066
Batch 210, Loss: 0.1947
Batch 220, Loss: 0.1965
Batch 230, Loss: 0.1855
Batch 240, Loss: 0.1895
Batch 250, Loss: 0.2120
Batch 260, Loss: 0.1959
Batch 270, Loss: 0.2117
Batch 280, Loss: 0.1995
Batch 290, Loss: 0.2134
Batch 300, Loss: 0.2114
Batch 310, Loss: 0.2167
Batch 320, Loss: 0.2230
Batch 330, Loss: 0.2061
Batch 340, Loss: 0.2302
Batch 350, Loss: 0.1985
Batch 360, Loss: 0.2106
Batch 370, Loss: 0.2306
Batch 380, Loss: 0.2009
Batch 390, Loss: 0.2196
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.14974021911621 seconds
Epoch 141 accuracy: 73.16%
Batch 10, Loss: 0.1860
Batch 20, Loss: 0.1743
Batch 30, Loss: 0.1969
Batch 40, Loss: 0.1928
Batch 50, Loss: 0.1790
Batch 60, Loss: 0.1789
Batch 70, Loss: 0.1762
Batch 80, Loss: 0.1817
Batch 90, Loss: 0.1960
Batch 100, Loss: 0.2008
Batch 110, Loss: 0.2014
Batch 120, Loss: 0.1920
Batch 130, Loss: 0.1803
Batch 140, Loss: 0.2065
Batch 150, Loss: 0.1844
Batch 160, Loss: 0.1909
Batch 170, Loss: 0.1872
Batch 180, Loss: 0.1855
Batch 190, Loss: 0.1866
Batch 200, Loss: 0.1770
Batch 210, Loss: 0.1955
Batch 220, Loss: 0.1737
Batch 230, Loss: 0.1938
Batch 240, Loss: 0.2018
Batch 250, Loss: 0.1936
Batch 260, Loss: 0.1964
Batch 270, Loss: 0.2113
Batch 280, Loss: 0.1961
Batch 290, Loss: 0.1912
Batch 300, Loss: 0.1975
Batch 310, Loss: 0.2059
Batch 320, Loss: 0.1997
Batch 330, Loss: 0.2036
Batch 340, Loss: 0.1884
Batch 350, Loss: 0.1975
Batch 360, Loss: 0.2070
Batch 370, Loss: 0.2172
Batch 380, Loss: 0.2082
Batch 390, Loss: 0.1970
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.07745623588562 seconds
Epoch 142 accuracy: 72.54%
Batch 10, Loss: 0.1704
Batch 20, Loss: 0.1732
Batch 30, Loss: 0.1793
Batch 40, Loss: 0.1674
Batch 50, Loss: 0.1605
Batch 60, Loss: 0.1733
Batch 70, Loss: 0.1729
Batch 80, Loss: 0.1759
Batch 90, Loss: 0.1695
Batch 100, Loss: 0.1531
Batch 110, Loss: 0.1895
Batch 120, Loss: 0.1635
Batch 130, Loss: 0.1698
Batch 140, Loss: 0.1813
Batch 150, Loss: 0.1792
Batch 160, Loss: 0.1607
Batch 170, Loss: 0.1761
Batch 180, Loss: 0.1863
Batch 190, Loss: 0.1813
Batch 200, Loss: 0.1831
Batch 210, Loss: 0.1867
Batch 220, Loss: 0.1642
Batch 230, Loss: 0.1693
Batch 240, Loss: 0.1840
Batch 250, Loss: 0.1801
Batch 260, Loss: 0.1831
Batch 270, Loss: 0.1928
Batch 280, Loss: 0.2034
Batch 290, Loss: 0.2019
Batch 300, Loss: 0.2090
Batch 310, Loss: 0.1880
Batch 320, Loss: 0.1895
Batch 330, Loss: 0.1935
Batch 340, Loss: 0.1904
Batch 350, Loss: 0.1897
Batch 360, Loss: 0.2140
Batch 370, Loss: 0.2168
Batch 380, Loss: 0.2001
Batch 390, Loss: 0.2136
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 24.997517585754395 seconds
Epoch 143 accuracy: 73.02%
Batch 10, Loss: 0.1666
Batch 20, Loss: 0.1653
Batch 30, Loss: 0.1600
Batch 40, Loss: 0.1452
Batch 50, Loss: 0.1622
Batch 60, Loss: 0.1559
Batch 70, Loss: 0.1565
Batch 80, Loss: 0.1543
Batch 90, Loss: 0.1614
Batch 100, Loss: 0.1720
Batch 110, Loss: 0.1531
Batch 120, Loss: 0.1532
Batch 130, Loss: 0.1493
Batch 140, Loss: 0.1561
Batch 150, Loss: 0.1656
Batch 160, Loss: 0.1481
Batch 170, Loss: 0.1440
Batch 180, Loss: 0.1632
Batch 190, Loss: 0.1688
Batch 200, Loss: 0.1713
Batch 210, Loss: 0.1771
Batch 220, Loss: 0.1611
Batch 230, Loss: 0.1692
Batch 240, Loss: 0.1593
Batch 250, Loss: 0.1880
Batch 260, Loss: 0.1755
Batch 270, Loss: 0.1697
Batch 280, Loss: 0.1600
Batch 290, Loss: 0.1834
Batch 300, Loss: 0.1660
Batch 310, Loss: 0.1742
Batch 320, Loss: 0.1619
Batch 330, Loss: 0.1731
Batch 340, Loss: 0.1803
Batch 350, Loss: 0.1903
Batch 360, Loss: 0.1992
Batch 370, Loss: 0.1967
Batch 380, Loss: 0.1989
Batch 390, Loss: 0.1973
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 24.994462966918945 seconds
Epoch 144 accuracy: 73.35%
Batch 10, Loss: 0.1600
Batch 20, Loss: 0.1657
Batch 30, Loss: 0.1487
Batch 40, Loss: 0.1625
Batch 50, Loss: 0.1660
Batch 60, Loss: 0.1562
Batch 70, Loss: 0.1695
Batch 80, Loss: 0.1508
Batch 90, Loss: 0.1553
Batch 100, Loss: 0.1724
Batch 110, Loss: 0.1501
Batch 120, Loss: 0.1539
Batch 130, Loss: 0.1552
Batch 140, Loss: 0.1555
Batch 150, Loss: 0.1444
Batch 160, Loss: 0.1587
Batch 170, Loss: 0.1438
Batch 180, Loss: 0.1656
Batch 190, Loss: 0.1472
Batch 200, Loss: 0.1613
Batch 210, Loss: 0.1923
Batch 220, Loss: 0.1499
Batch 230, Loss: 0.1554
Batch 240, Loss: 0.1694
Batch 250, Loss: 0.1503
Batch 260, Loss: 0.1677
Batch 270, Loss: 0.1674
Batch 280, Loss: 0.1695
Batch 290, Loss: 0.1904
Batch 300, Loss: 0.1581
Batch 310, Loss: 0.1727
Batch 320, Loss: 0.1711
Batch 330, Loss: 0.1754
Batch 340, Loss: 0.1841
Batch 350, Loss: 0.1651
Batch 360, Loss: 0.1885
Batch 370, Loss: 0.1697
Batch 380, Loss: 0.1809
Batch 390, Loss: 0.1692
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.137284755706787 seconds
Epoch 145 accuracy: 73.31%
Batch 10, Loss: 0.1558
Batch 20, Loss: 0.1509
Batch 30, Loss: 0.1587
Batch 40, Loss: 0.1458
Batch 50, Loss: 0.1402
Batch 60, Loss: 0.1426
Batch 70, Loss: 0.1470
Batch 80, Loss: 0.1552
Batch 90, Loss: 0.1410
Batch 100, Loss: 0.1384
Batch 110, Loss: 0.1445
Batch 120, Loss: 0.1304
Batch 130, Loss: 0.1535
Batch 140, Loss: 0.1479
Batch 150, Loss: 0.1363
Batch 160, Loss: 0.1442
Batch 170, Loss: 0.1448
Batch 180, Loss: 0.1505
Batch 190, Loss: 0.1499
Batch 200, Loss: 0.1765
Batch 210, Loss: 0.1401
Batch 220, Loss: 0.1501
Batch 230, Loss: 0.1512
Batch 240, Loss: 0.1599
Batch 250, Loss: 0.1460
Batch 260, Loss: 0.1478
Batch 270, Loss: 0.1435
Batch 280, Loss: 0.1464
Batch 290, Loss: 0.1531
Batch 300, Loss: 0.1556
Batch 310, Loss: 0.1570
Batch 320, Loss: 0.1716
Batch 330, Loss: 0.1625
Batch 340, Loss: 0.1731
Batch 350, Loss: 0.1523
Batch 360, Loss: 0.1740
Batch 370, Loss: 0.1629
Batch 380, Loss: 0.1568
Batch 390, Loss: 0.1748
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.059643507003784 seconds
Epoch 146 accuracy: 73.33%
Batch 10, Loss: 0.1320
Batch 20, Loss: 0.1336
Batch 30, Loss: 0.1341
Batch 40, Loss: 0.1267
Batch 50, Loss: 0.1314
Batch 60, Loss: 0.1325
Batch 70, Loss: 0.1284
Batch 80, Loss: 0.1380
Batch 90, Loss: 0.1421
Batch 100, Loss: 0.1247
Batch 110, Loss: 0.1270
Batch 120, Loss: 0.1364
Batch 130, Loss: 0.1330
Batch 140, Loss: 0.1507
Batch 150, Loss: 0.1508
Batch 160, Loss: 0.1372
Batch 170, Loss: 0.1566
Batch 180, Loss: 0.1424
Batch 190, Loss: 0.1590
Batch 200, Loss: 0.1571
Batch 210, Loss: 0.1626
Batch 220, Loss: 0.1749
Batch 230, Loss: 0.1843
Batch 240, Loss: 0.1666
Batch 250, Loss: 0.1606
Batch 260, Loss: 0.1655
Batch 270, Loss: 0.1374
Batch 280, Loss: 0.1502
Batch 290, Loss: 0.1547
Batch 300, Loss: 0.1668
Batch 310, Loss: 0.1544
Batch 320, Loss: 0.1635
Batch 330, Loss: 0.1677
Batch 340, Loss: 0.1659
Batch 350, Loss: 0.1728
Batch 360, Loss: 0.1666
Batch 370, Loss: 0.1745
Batch 380, Loss: 0.1570
Batch 390, Loss: 0.1427
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.571749448776245 seconds
Epoch 147 accuracy: 73.56%
Batch 10, Loss: 0.1418
Batch 20, Loss: 0.1451
Batch 30, Loss: 0.1436
Batch 40, Loss: 0.1383
Batch 50, Loss: 0.1478
Batch 60, Loss: 0.1384
Batch 70, Loss: 0.1428
Batch 80, Loss: 0.1418
Batch 90, Loss: 0.1347
Batch 100, Loss: 0.1397
Batch 110, Loss: 0.1250
Batch 120, Loss: 0.1415
Batch 130, Loss: 0.1404
Batch 140, Loss: 0.1303
Batch 150, Loss: 0.1404
Batch 160, Loss: 0.1583
Batch 170, Loss: 0.1496
Batch 180, Loss: 0.1493
Batch 190, Loss: 0.1408
Batch 200, Loss: 0.1347
Batch 210, Loss: 0.1280
Batch 220, Loss: 0.1259
Batch 230, Loss: 0.1398
Batch 240, Loss: 0.1489
Batch 250, Loss: 0.1303
Batch 260, Loss: 0.1431
Batch 270, Loss: 0.1432
Batch 280, Loss: 0.1419
Batch 290, Loss: 0.1420
Batch 300, Loss: 0.1512
Batch 310, Loss: 0.1535
Batch 320, Loss: 0.1469
Batch 330, Loss: 0.1586
Batch 340, Loss: 0.1408
Batch 350, Loss: 0.1654
Batch 360, Loss: 0.1601
Batch 370, Loss: 0.1454
Batch 380, Loss: 0.1421
Batch 390, Loss: 0.1546
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.236904621124268 seconds
Epoch 148 accuracy: 74.27%
Batch 10, Loss: 0.1504
Batch 20, Loss: 0.1313
Batch 30, Loss: 0.1476
Batch 40, Loss: 0.1580
Batch 50, Loss: 0.1230
Batch 60, Loss: 0.1229
Batch 70, Loss: 0.1360
Batch 80, Loss: 0.1358
Batch 90, Loss: 0.1401
Batch 100, Loss: 0.1470
Batch 110, Loss: 0.1354
Batch 120, Loss: 0.1412
Batch 130, Loss: 0.1316
Batch 140, Loss: 0.1299
Batch 150, Loss: 0.1461
Batch 160, Loss: 0.1418
Batch 170, Loss: 0.1306
Batch 180, Loss: 0.1407
Batch 190, Loss: 0.1272
Batch 200, Loss: 0.1429
Batch 210, Loss: 0.1365
Batch 220, Loss: 0.1469
Batch 230, Loss: 0.1334
Batch 240, Loss: 0.1337
Batch 250, Loss: 0.1471
Batch 260, Loss: 0.1423
Batch 270, Loss: 0.1261
Batch 280, Loss: 0.1429
Batch 290, Loss: 0.1405
Batch 300, Loss: 0.1391
Batch 310, Loss: 0.1536
Batch 320, Loss: 0.1502
Batch 330, Loss: 0.1459
Batch 340, Loss: 0.1204
Batch 350, Loss: 0.1452
Batch 360, Loss: 0.1454
Batch 370, Loss: 0.1534
Batch 380, Loss: 0.1599
Batch 390, Loss: 0.1548
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.125131845474243 seconds
Epoch 149 accuracy: 73.89%
Batch 10, Loss: 0.1237
Batch 20, Loss: 0.1272
Batch 30, Loss: 0.1278
Batch 40, Loss: 0.1324
Batch 50, Loss: 0.1142
Batch 60, Loss: 0.1337
Batch 70, Loss: 0.1173
Batch 80, Loss: 0.1302
Batch 90, Loss: 0.1392
Batch 100, Loss: 0.1391
Batch 110, Loss: 0.1095
Batch 120, Loss: 0.1292
Batch 130, Loss: 0.1444
Batch 140, Loss: 0.1188
Batch 150, Loss: 0.1237
Batch 160, Loss: 0.1261
Batch 170, Loss: 0.1417
Batch 180, Loss: 0.1273
Batch 190, Loss: 0.1348
Batch 200, Loss: 0.1331
Batch 210, Loss: 0.1295
Batch 220, Loss: 0.1395
Batch 230, Loss: 0.1245
Batch 240, Loss: 0.1149
Batch 250, Loss: 0.1506
Batch 260, Loss: 0.1209
Batch 270, Loss: 0.1302
Batch 280, Loss: 0.1291
Batch 290, Loss: 0.1384
Batch 300, Loss: 0.1441
Batch 310, Loss: 0.1389
Batch 320, Loss: 0.1335
Batch 330, Loss: 0.1262
Batch 340, Loss: 0.1430
Batch 350, Loss: 0.1320
Batch 360, Loss: 0.1359
Batch 370, Loss: 0.1403
Batch 380, Loss: 0.1467
Batch 390, Loss: 0.1546
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.356977939605713 seconds
Epoch 150 accuracy: 73.93%
Batch 10, Loss: 0.1263
Batch 20, Loss: 0.1400
Batch 30, Loss: 0.1278
Batch 40, Loss: 0.1176
Batch 50, Loss: 0.1332
Batch 60, Loss: 0.1300
Batch 70, Loss: 0.1215
Batch 80, Loss: 0.1251
Batch 90, Loss: 0.1273
Batch 100, Loss: 0.1264
Batch 110, Loss: 0.1196
Batch 120, Loss: 0.1281
Batch 130, Loss: 0.1287
Batch 140, Loss: 0.1260
Batch 150, Loss: 0.1351
Batch 160, Loss: 0.1265
Batch 170, Loss: 0.1247
Batch 180, Loss: 0.1314
Batch 190, Loss: 0.1318
Batch 200, Loss: 0.1089
Batch 210, Loss: 0.1205
Batch 220, Loss: 0.1196
Batch 230, Loss: 0.1300
Batch 240, Loss: 0.1331
Batch 250, Loss: 0.1230
Batch 260, Loss: 0.1219
Batch 270, Loss: 0.1214
Batch 280, Loss: 0.1219
Batch 290, Loss: 0.1054
Batch 300, Loss: 0.1123
Batch 310, Loss: 0.1320
Batch 320, Loss: 0.1319
Batch 330, Loss: 0.1387
Batch 340, Loss: 0.1290
Batch 350, Loss: 0.1357
Batch 360, Loss: 0.1447
Batch 370, Loss: 0.1340
Batch 380, Loss: 0.1335
Batch 390, Loss: 0.1410
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.27921175956726 seconds
Epoch 151 accuracy: 74.16%
Batch 10, Loss: 0.1287
Batch 20, Loss: 0.1258
Batch 30, Loss: 0.1188
Batch 40, Loss: 0.1197
Batch 50, Loss: 0.1170
Batch 60, Loss: 0.1079
Batch 70, Loss: 0.1198
Batch 80, Loss: 0.1191
Batch 90, Loss: 0.1108
Batch 100, Loss: 0.1048
Batch 110, Loss: 0.1193
Batch 120, Loss: 0.1077
Batch 130, Loss: 0.1211
Batch 140, Loss: 0.1160
Batch 150, Loss: 0.1114
Batch 160, Loss: 0.1204
Batch 170, Loss: 0.1184
Batch 180, Loss: 0.1102
Batch 190, Loss: 0.1104
Batch 200, Loss: 0.1124
Batch 210, Loss: 0.1153
Batch 220, Loss: 0.1250
Batch 230, Loss: 0.1220
Batch 240, Loss: 0.1221
Batch 250, Loss: 0.1341
Batch 260, Loss: 0.1297
Batch 270, Loss: 0.1261
Batch 280, Loss: 0.1172
Batch 290, Loss: 0.1163
Batch 300, Loss: 0.1241
Batch 310, Loss: 0.1263
Batch 320, Loss: 0.1115
Batch 330, Loss: 0.1284
Batch 340, Loss: 0.1196
Batch 350, Loss: 0.1226
Batch 360, Loss: 0.1195
Batch 370, Loss: 0.1288
Batch 380, Loss: 0.1221
Batch 390, Loss: 0.1305
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.013594150543213 seconds
Epoch 152 accuracy: 74.75%
Batch 10, Loss: 0.1097
Batch 20, Loss: 0.1254
Batch 30, Loss: 0.1175
Batch 40, Loss: 0.1093
Batch 50, Loss: 0.1101
Batch 60, Loss: 0.1124
Batch 70, Loss: 0.1033
Batch 80, Loss: 0.1009
Batch 90, Loss: 0.1026
Batch 100, Loss: 0.1063
Batch 110, Loss: 0.1085
Batch 120, Loss: 0.1130
Batch 130, Loss: 0.1096
Batch 140, Loss: 0.1157
Batch 150, Loss: 0.1120
Batch 160, Loss: 0.0998
Batch 170, Loss: 0.1169
Batch 180, Loss: 0.1151
Batch 190, Loss: 0.1150
Batch 200, Loss: 0.1135
Batch 210, Loss: 0.1092
Batch 220, Loss: 0.1151
Batch 230, Loss: 0.1026
Batch 240, Loss: 0.1002
Batch 250, Loss: 0.1086
Batch 260, Loss: 0.1118
Batch 270, Loss: 0.1180
Batch 280, Loss: 0.1155
Batch 290, Loss: 0.1107
Batch 300, Loss: 0.1184
Batch 310, Loss: 0.1163
Batch 320, Loss: 0.1103
Batch 330, Loss: 0.1186
Batch 340, Loss: 0.1314
Batch 350, Loss: 0.1205
Batch 360, Loss: 0.1235
Batch 370, Loss: 0.1159
Batch 380, Loss: 0.1260
Batch 390, Loss: 0.1216
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 24.96310067176819 seconds
Epoch 153 accuracy: 74.72%
Batch 10, Loss: 0.1067
Batch 20, Loss: 0.1018
Batch 30, Loss: 0.1036
Batch 40, Loss: 0.1194
Batch 50, Loss: 0.0993
Batch 60, Loss: 0.1063
Batch 70, Loss: 0.1081
Batch 80, Loss: 0.1073
Batch 90, Loss: 0.1012
Batch 100, Loss: 0.1009
Batch 110, Loss: 0.1077
Batch 120, Loss: 0.1109
Batch 130, Loss: 0.0954
Batch 140, Loss: 0.0998
Batch 150, Loss: 0.1104
Batch 160, Loss: 0.1046
Batch 170, Loss: 0.1035
Batch 180, Loss: 0.1103
Batch 190, Loss: 0.1025
Batch 200, Loss: 0.1124
Batch 210, Loss: 0.1023
Batch 220, Loss: 0.1115
Batch 230, Loss: 0.1118
Batch 240, Loss: 0.1104
Batch 250, Loss: 0.1064
Batch 260, Loss: 0.1023
Batch 270, Loss: 0.1057
Batch 280, Loss: 0.1052
Batch 290, Loss: 0.1054
Batch 300, Loss: 0.1069
Batch 310, Loss: 0.1124
Batch 320, Loss: 0.0982
Batch 330, Loss: 0.1121
Batch 340, Loss: 0.1144
Batch 350, Loss: 0.0985
Batch 360, Loss: 0.1039
Batch 370, Loss: 0.1146
Batch 380, Loss: 0.1125
Batch 390, Loss: 0.1101
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 24.95283818244934 seconds
Epoch 154 accuracy: 75.59%
Batch 10, Loss: 0.0966
Batch 20, Loss: 0.0973
Batch 30, Loss: 0.1005
Batch 40, Loss: 0.0797
Batch 50, Loss: 0.0880
Batch 60, Loss: 0.0973
Batch 70, Loss: 0.0905
Batch 80, Loss: 0.0950
Batch 90, Loss: 0.0889
Batch 100, Loss: 0.0969
Batch 110, Loss: 0.0923
Batch 120, Loss: 0.1042
Batch 130, Loss: 0.0908
Batch 140, Loss: 0.1089
Batch 150, Loss: 0.1103
Batch 160, Loss: 0.1146
Batch 170, Loss: 0.0988
Batch 180, Loss: 0.0922
Batch 190, Loss: 0.0978
Batch 200, Loss: 0.0915
Batch 210, Loss: 0.0993
Batch 220, Loss: 0.1011
Batch 230, Loss: 0.0975
Batch 240, Loss: 0.0951
Batch 250, Loss: 0.0963
Batch 260, Loss: 0.1026
Batch 270, Loss: 0.1016
Batch 280, Loss: 0.0999
Batch 290, Loss: 0.0977
Batch 300, Loss: 0.0996
Batch 310, Loss: 0.0943
Batch 320, Loss: 0.0968
Batch 330, Loss: 0.1051
Batch 340, Loss: 0.1047
Batch 350, Loss: 0.1135
Batch 360, Loss: 0.1086
Batch 370, Loss: 0.1208
Batch 380, Loss: 0.1044
Batch 390, Loss: 0.1075
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 24.90668249130249 seconds
Epoch 155 accuracy: 75.59%
Batch 10, Loss: 0.1039
Batch 20, Loss: 0.0863
Batch 30, Loss: 0.0901
Batch 40, Loss: 0.0809
Batch 50, Loss: 0.0886
Batch 60, Loss: 0.0939
Batch 70, Loss: 0.0937
Batch 80, Loss: 0.0901
Batch 90, Loss: 0.0931
Batch 100, Loss: 0.0974
Batch 110, Loss: 0.0961
Batch 120, Loss: 0.0947
Batch 130, Loss: 0.0930
Batch 140, Loss: 0.0974
Batch 150, Loss: 0.0912
Batch 160, Loss: 0.0936
Batch 170, Loss: 0.0868
Batch 180, Loss: 0.0985
Batch 190, Loss: 0.1023
Batch 200, Loss: 0.0976
Batch 210, Loss: 0.0975
Batch 220, Loss: 0.1008
Batch 230, Loss: 0.1085
Batch 240, Loss: 0.0995
Batch 250, Loss: 0.0957
Batch 260, Loss: 0.1027
Batch 270, Loss: 0.0943
Batch 280, Loss: 0.1013
Batch 290, Loss: 0.0952
Batch 300, Loss: 0.1044
Batch 310, Loss: 0.0886
Batch 320, Loss: 0.0913
Batch 330, Loss: 0.0891
Batch 340, Loss: 0.0945
Batch 350, Loss: 0.0886
Batch 360, Loss: 0.0945
Batch 370, Loss: 0.1015
Batch 380, Loss: 0.0925
Batch 390, Loss: 0.0919
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 24.91849112510681 seconds
Epoch 156 accuracy: 75.65%
Batch 10, Loss: 0.0874
Batch 20, Loss: 0.0949
Batch 30, Loss: 0.0915
Batch 40, Loss: 0.0913
Batch 50, Loss: 0.0869
Batch 60, Loss: 0.0812
Batch 70, Loss: 0.0851
Batch 80, Loss: 0.0883
Batch 90, Loss: 0.0855
Batch 100, Loss: 0.0808
Batch 110, Loss: 0.0837
Batch 120, Loss: 0.0816
Batch 130, Loss: 0.0842
Batch 140, Loss: 0.0804
Batch 150, Loss: 0.0927
Batch 160, Loss: 0.0890
Batch 170, Loss: 0.0931
Batch 180, Loss: 0.0885
Batch 190, Loss: 0.0968
Batch 200, Loss: 0.0938
Batch 210, Loss: 0.0840
Batch 220, Loss: 0.0855
Batch 230, Loss: 0.0895
Batch 240, Loss: 0.0801
Batch 250, Loss: 0.0825
Batch 260, Loss: 0.0806
Batch 270, Loss: 0.0890
Batch 280, Loss: 0.0823
Batch 290, Loss: 0.0850
Batch 300, Loss: 0.0873
Batch 310, Loss: 0.0924
Batch 320, Loss: 0.1016
Batch 330, Loss: 0.0853
Batch 340, Loss: 0.0861
Batch 350, Loss: 0.0855
Batch 360, Loss: 0.0857
Batch 370, Loss: 0.0861
Batch 380, Loss: 0.0880
Batch 390, Loss: 0.0911
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 24.98058319091797 seconds
Epoch 157 accuracy: 76.29%
Batch 10, Loss: 0.0870
Batch 20, Loss: 0.0780
Batch 30, Loss: 0.0774
Batch 40, Loss: 0.0787
Batch 50, Loss: 0.0730
Batch 60, Loss: 0.0820
Batch 70, Loss: 0.0808
Batch 80, Loss: 0.0830
Batch 90, Loss: 0.0796
Batch 100, Loss: 0.0826
Batch 110, Loss: 0.0731
Batch 120, Loss: 0.0892
Batch 130, Loss: 0.0861
Batch 140, Loss: 0.0813
Batch 150, Loss: 0.0756
Batch 160, Loss: 0.0903
Batch 170, Loss: 0.0839
Batch 180, Loss: 0.0814
Batch 190, Loss: 0.0878
Batch 200, Loss: 0.0876
Batch 210, Loss: 0.0858
Batch 220, Loss: 0.0759
Batch 230, Loss: 0.0811
Batch 240, Loss: 0.0719
Batch 250, Loss: 0.0799
Batch 260, Loss: 0.0810
Batch 270, Loss: 0.0815
Batch 280, Loss: 0.0849
Batch 290, Loss: 0.0874
Batch 300, Loss: 0.0847
Batch 310, Loss: 0.0959
Batch 320, Loss: 0.0875
Batch 330, Loss: 0.0997
Batch 340, Loss: 0.0993
Batch 350, Loss: 0.0884
Batch 360, Loss: 0.0942
Batch 370, Loss: 0.0929
Batch 380, Loss: 0.0880
Batch 390, Loss: 0.0812
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.046960592269897 seconds
Epoch 158 accuracy: 76.15%
Batch 10, Loss: 0.0769
Batch 20, Loss: 0.0740
Batch 30, Loss: 0.0749
Batch 40, Loss: 0.0811
Batch 50, Loss: 0.0798
Batch 60, Loss: 0.0781
Batch 70, Loss: 0.0750
Batch 80, Loss: 0.0774
Batch 90, Loss: 0.0764
Batch 100, Loss: 0.0792
Batch 110, Loss: 0.0766
Batch 120, Loss: 0.0778
Batch 130, Loss: 0.0790
Batch 140, Loss: 0.0812
Batch 150, Loss: 0.0799
Batch 160, Loss: 0.0807
Batch 170, Loss: 0.0742
Batch 180, Loss: 0.0834
Batch 190, Loss: 0.0888
Batch 200, Loss: 0.0753
Batch 210, Loss: 0.0828
Batch 220, Loss: 0.0794
Batch 230, Loss: 0.0891
Batch 240, Loss: 0.0853
Batch 250, Loss: 0.0938
Batch 260, Loss: 0.0828
Batch 270, Loss: 0.0788
Batch 280, Loss: 0.0805
Batch 290, Loss: 0.0751
Batch 300, Loss: 0.0729
Batch 310, Loss: 0.0798
Batch 320, Loss: 0.0848
Batch 330, Loss: 0.0887
Batch 340, Loss: 0.0917
Batch 350, Loss: 0.0815
Batch 360, Loss: 0.0854
Batch 370, Loss: 0.0859
Batch 380, Loss: 0.0809
Batch 390, Loss: 0.0855
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 24.883670568466187 seconds
Epoch 159 accuracy: 76.05%
Batch 10, Loss: 0.0733
Batch 20, Loss: 0.0739
Batch 30, Loss: 0.0694
Batch 40, Loss: 0.0685
Batch 50, Loss: 0.0745
Batch 60, Loss: 0.0755
Batch 70, Loss: 0.0792
Batch 80, Loss: 0.0665
Batch 90, Loss: 0.0679
Batch 100, Loss: 0.0777
Batch 110, Loss: 0.0778
Batch 120, Loss: 0.0697
Batch 130, Loss: 0.0631
Batch 140, Loss: 0.0684
Batch 150, Loss: 0.0759
Batch 160, Loss: 0.0713
Batch 170, Loss: 0.0676
Batch 180, Loss: 0.0679
Batch 190, Loss: 0.0700
Batch 200, Loss: 0.0686
Batch 210, Loss: 0.0832
Batch 220, Loss: 0.0728
Batch 230, Loss: 0.0768
Batch 240, Loss: 0.0807
Batch 250, Loss: 0.0778
Batch 260, Loss: 0.0772
Batch 270, Loss: 0.0768
Batch 280, Loss: 0.0790
Batch 290, Loss: 0.0828
Batch 300, Loss: 0.0848
Batch 310, Loss: 0.0828
Batch 320, Loss: 0.0864
Batch 330, Loss: 0.0955
Batch 340, Loss: 0.0964
Batch 350, Loss: 0.0752
Batch 360, Loss: 0.0950
Batch 370, Loss: 0.0836
Batch 380, Loss: 0.0799
Batch 390, Loss: 0.0778
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 24.987018823623657 seconds
Epoch 160 accuracy: 77.11%
Batch 10, Loss: 0.0631
Batch 20, Loss: 0.0665
Batch 30, Loss: 0.0730
Batch 40, Loss: 0.0697
Batch 50, Loss: 0.0717
Batch 60, Loss: 0.0677
Batch 70, Loss: 0.0770
Batch 80, Loss: 0.0743
Batch 90, Loss: 0.0737
Batch 100, Loss: 0.0694
Batch 110, Loss: 0.0702
Batch 120, Loss: 0.0639
Batch 130, Loss: 0.0674
Batch 140, Loss: 0.0734
Batch 150, Loss: 0.0677
Batch 160, Loss: 0.0703
Batch 170, Loss: 0.0664
Batch 180, Loss: 0.0724
Batch 190, Loss: 0.0645
Batch 200, Loss: 0.0632
Batch 210, Loss: 0.0698
Batch 220, Loss: 0.0690
Batch 230, Loss: 0.0736
Batch 240, Loss: 0.0704
Batch 250, Loss: 0.0762
Batch 260, Loss: 0.0716
Batch 270, Loss: 0.0664
Batch 280, Loss: 0.0742
Batch 290, Loss: 0.0728
Batch 300, Loss: 0.0749
Batch 310, Loss: 0.0728
Batch 320, Loss: 0.0759
Batch 330, Loss: 0.0703
Batch 340, Loss: 0.0790
Batch 350, Loss: 0.0725
Batch 360, Loss: 0.0681
Batch 370, Loss: 0.0685
Batch 380, Loss: 0.0699
Batch 390, Loss: 0.0689
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 24.970591068267822 seconds
Epoch 161 accuracy: 76.14%
Batch 10, Loss: 0.0647
Batch 20, Loss: 0.0805
Batch 30, Loss: 0.0735
Batch 40, Loss: 0.0626
Batch 50, Loss: 0.0735
Batch 60, Loss: 0.0674
Batch 70, Loss: 0.0656
Batch 80, Loss: 0.0647
Batch 90, Loss: 0.0681
Batch 100, Loss: 0.0657
Batch 110, Loss: 0.0674
Batch 120, Loss: 0.0638
Batch 130, Loss: 0.0667
Batch 140, Loss: 0.0646
Batch 150, Loss: 0.0666
Batch 160, Loss: 0.0592
Batch 170, Loss: 0.0692
Batch 180, Loss: 0.0697
Batch 190, Loss: 0.0727
Batch 200, Loss: 0.0692
Batch 210, Loss: 0.0736
Batch 220, Loss: 0.0684
Batch 230, Loss: 0.0743
Batch 240, Loss: 0.0687
Batch 250, Loss: 0.0687
Batch 260, Loss: 0.0844
Batch 270, Loss: 0.0586
Batch 280, Loss: 0.0637
Batch 290, Loss: 0.0677
Batch 300, Loss: 0.0668
Batch 310, Loss: 0.0663
Batch 320, Loss: 0.0666
Batch 330, Loss: 0.0701
Batch 340, Loss: 0.0711
Batch 350, Loss: 0.0727
Batch 360, Loss: 0.0704
Batch 370, Loss: 0.0628
Batch 380, Loss: 0.0655
Batch 390, Loss: 0.0696
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 24.89423418045044 seconds
Epoch 162 accuracy: 77.28%
Batch 10, Loss: 0.0589
Batch 20, Loss: 0.0592
Batch 30, Loss: 0.0725
Batch 40, Loss: 0.0662
Batch 50, Loss: 0.0667
Batch 60, Loss: 0.0621
Batch 70, Loss: 0.0631
Batch 80, Loss: 0.0600
Batch 90, Loss: 0.0609
Batch 100, Loss: 0.0628
Batch 110, Loss: 0.0667
Batch 120, Loss: 0.0623
Batch 130, Loss: 0.0624
Batch 140, Loss: 0.0650
Batch 150, Loss: 0.0628
Batch 160, Loss: 0.0552
Batch 170, Loss: 0.0648
Batch 180, Loss: 0.0562
Batch 190, Loss: 0.0612
Batch 200, Loss: 0.0639
Batch 210, Loss: 0.0687
Batch 220, Loss: 0.0632
Batch 230, Loss: 0.0619
Batch 240, Loss: 0.0706
Batch 250, Loss: 0.0588
Batch 260, Loss: 0.0676
Batch 270, Loss: 0.0750
Batch 280, Loss: 0.0612
Batch 290, Loss: 0.0681
Batch 300, Loss: 0.0642
Batch 310, Loss: 0.0681
Batch 320, Loss: 0.0681
Batch 330, Loss: 0.0705
Batch 340, Loss: 0.0703
Batch 350, Loss: 0.0597
Batch 360, Loss: 0.0661
Batch 370, Loss: 0.0620
Batch 380, Loss: 0.0586
Batch 390, Loss: 0.0608
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 24.940261602401733 seconds
Epoch 163 accuracy: 77.24%
Batch 10, Loss: 0.0548
Batch 20, Loss: 0.0564
Batch 30, Loss: 0.0568
Batch 40, Loss: 0.0560
Batch 50, Loss: 0.0584
Batch 60, Loss: 0.0532
Batch 70, Loss: 0.0556
Batch 80, Loss: 0.0593
Batch 90, Loss: 0.0553
Batch 100, Loss: 0.0599
Batch 110, Loss: 0.0532
Batch 120, Loss: 0.0564
Batch 130, Loss: 0.0579
Batch 140, Loss: 0.0565
Batch 150, Loss: 0.0610
Batch 160, Loss: 0.0645
Batch 170, Loss: 0.0622
Batch 180, Loss: 0.0605
Batch 190, Loss: 0.0641
Batch 200, Loss: 0.0667
Batch 210, Loss: 0.0710
Batch 220, Loss: 0.0670
Batch 230, Loss: 0.0582
Batch 240, Loss: 0.0638
Batch 250, Loss: 0.0651
Batch 260, Loss: 0.0538
Batch 270, Loss: 0.0603
Batch 280, Loss: 0.0648
Batch 290, Loss: 0.0644
Batch 300, Loss: 0.0549
Batch 310, Loss: 0.0676
Batch 320, Loss: 0.0608
Batch 330, Loss: 0.0619
Batch 340, Loss: 0.0631
Batch 350, Loss: 0.0642
Batch 360, Loss: 0.0609
Batch 370, Loss: 0.0592
Batch 380, Loss: 0.0645
Batch 390, Loss: 0.0627
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 24.944199323654175 seconds
Epoch 164 accuracy: 77.44%
Batch 10, Loss: 0.0600
Batch 20, Loss: 0.0598
Batch 30, Loss: 0.0562
Batch 40, Loss: 0.0591
Batch 50, Loss: 0.0595
Batch 60, Loss: 0.0568
Batch 70, Loss: 0.0554
Batch 80, Loss: 0.0594
Batch 90, Loss: 0.0558
Batch 100, Loss: 0.0556
Batch 110, Loss: 0.0488
Batch 120, Loss: 0.0572
Batch 130, Loss: 0.0583
Batch 140, Loss: 0.0570
Batch 150, Loss: 0.0590
Batch 160, Loss: 0.0532
Batch 170, Loss: 0.0513
Batch 180, Loss: 0.0551
Batch 190, Loss: 0.0532
Batch 200, Loss: 0.0534
Batch 210, Loss: 0.0530
Batch 220, Loss: 0.0594
Batch 230, Loss: 0.0540
Batch 240, Loss: 0.0528
Batch 250, Loss: 0.0553
Batch 260, Loss: 0.0503
Batch 270, Loss: 0.0533
Batch 280, Loss: 0.0573
Batch 290, Loss: 0.0570
Batch 300, Loss: 0.0531
Batch 310, Loss: 0.0526
Batch 320, Loss: 0.0517
Batch 330, Loss: 0.0551
Batch 340, Loss: 0.0563
Batch 350, Loss: 0.0512
Batch 360, Loss: 0.0617
Batch 370, Loss: 0.0625
Batch 380, Loss: 0.0615
Batch 390, Loss: 0.0554
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 24.96700358390808 seconds
Epoch 165 accuracy: 77.41%
Batch 10, Loss: 0.0514
Batch 20, Loss: 0.0546
Batch 30, Loss: 0.0579
Batch 40, Loss: 0.0475
Batch 50, Loss: 0.0558
Batch 60, Loss: 0.0538
Batch 70, Loss: 0.0518
Batch 80, Loss: 0.0526
Batch 90, Loss: 0.0498
Batch 100, Loss: 0.0516
Batch 110, Loss: 0.0472
Batch 120, Loss: 0.0501
Batch 130, Loss: 0.0492
Batch 140, Loss: 0.0541
Batch 150, Loss: 0.0506
Batch 160, Loss: 0.0436
Batch 170, Loss: 0.0515
Batch 180, Loss: 0.0516
Batch 190, Loss: 0.0506
Batch 200, Loss: 0.0505
Batch 210, Loss: 0.0527
Batch 220, Loss: 0.0471
Batch 230, Loss: 0.0530
Batch 240, Loss: 0.0502
Batch 250, Loss: 0.0565
Batch 260, Loss: 0.0539
Batch 270, Loss: 0.0531
Batch 280, Loss: 0.0466
Batch 290, Loss: 0.0578
Batch 300, Loss: 0.0463
Batch 310, Loss: 0.0474
Batch 320, Loss: 0.0533
Batch 330, Loss: 0.0496
Batch 340, Loss: 0.0476
Batch 350, Loss: 0.0523
Batch 360, Loss: 0.0467
Batch 370, Loss: 0.0456
Batch 380, Loss: 0.0500
Batch 390, Loss: 0.0533
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 24.91420865058899 seconds
Epoch 166 accuracy: 77.97%
Batch 10, Loss: 0.0478
Batch 20, Loss: 0.0490
Batch 30, Loss: 0.0486
Batch 40, Loss: 0.0519
Batch 50, Loss: 0.0425
Batch 60, Loss: 0.0457
Batch 70, Loss: 0.0482
Batch 80, Loss: 0.0519
Batch 90, Loss: 0.0418
Batch 100, Loss: 0.0452
Batch 110, Loss: 0.0478
Batch 120, Loss: 0.0474
Batch 130, Loss: 0.0482
Batch 140, Loss: 0.0488
Batch 150, Loss: 0.0494
Batch 160, Loss: 0.0471
Batch 170, Loss: 0.0528
Batch 180, Loss: 0.0484
Batch 190, Loss: 0.0504
Batch 200, Loss: 0.0492
Batch 210, Loss: 0.0480
Batch 220, Loss: 0.0509
Batch 230, Loss: 0.0469
Batch 240, Loss: 0.0532
Batch 250, Loss: 0.0517
Batch 260, Loss: 0.0544
Batch 270, Loss: 0.0509
Batch 280, Loss: 0.0462
Batch 290, Loss: 0.0476
Batch 300, Loss: 0.0508
Batch 310, Loss: 0.0499
Batch 320, Loss: 0.0502
Batch 330, Loss: 0.0467
Batch 340, Loss: 0.0511
Batch 350, Loss: 0.0514
Batch 360, Loss: 0.0524
Batch 370, Loss: 0.0495
Batch 380, Loss: 0.0497
Batch 390, Loss: 0.0503
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 24.926435470581055 seconds
Epoch 167 accuracy: 77.94%
Batch 10, Loss: 0.0499
Batch 20, Loss: 0.0445
Batch 30, Loss: 0.0480
Batch 40, Loss: 0.0475
Batch 50, Loss: 0.0542
Batch 60, Loss: 0.0477
Batch 70, Loss: 0.0491
Batch 80, Loss: 0.0474
Batch 90, Loss: 0.0492
Batch 100, Loss: 0.0459
Batch 110, Loss: 0.0423
Batch 120, Loss: 0.0448
Batch 130, Loss: 0.0472
Batch 140, Loss: 0.0484
Batch 150, Loss: 0.0462
Batch 160, Loss: 0.0518
Batch 170, Loss: 0.0460
Batch 180, Loss: 0.0509
Batch 190, Loss: 0.0427
Batch 200, Loss: 0.0506
Batch 210, Loss: 0.0452
Batch 220, Loss: 0.0441
Batch 230, Loss: 0.0441
Batch 240, Loss: 0.0505
Batch 250, Loss: 0.0462
Batch 260, Loss: 0.0499
Batch 270, Loss: 0.0493
Batch 280, Loss: 0.0479
Batch 290, Loss: 0.0472
Batch 300, Loss: 0.0478
Batch 310, Loss: 0.0468
Batch 320, Loss: 0.0477
Batch 330, Loss: 0.0514
Batch 340, Loss: 0.0494
Batch 350, Loss: 0.0520
Batch 360, Loss: 0.0567
Batch 370, Loss: 0.0468
Batch 380, Loss: 0.0549
Batch 390, Loss: 0.0499
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 24.93824052810669 seconds
Epoch 168 accuracy: 77.63%
Batch 10, Loss: 0.0441
Batch 20, Loss: 0.0483
Batch 30, Loss: 0.0431
Batch 40, Loss: 0.0487
Batch 50, Loss: 0.0456
Batch 60, Loss: 0.0489
Batch 70, Loss: 0.0446
Batch 80, Loss: 0.0434
Batch 90, Loss: 0.0382
Batch 100, Loss: 0.0408
Batch 110, Loss: 0.0444
Batch 120, Loss: 0.0453
Batch 130, Loss: 0.0464
Batch 140, Loss: 0.0480
Batch 150, Loss: 0.0462
Batch 160, Loss: 0.0418
Batch 170, Loss: 0.0470
Batch 180, Loss: 0.0447
Batch 190, Loss: 0.0418
Batch 200, Loss: 0.0422
Batch 210, Loss: 0.0412
Batch 220, Loss: 0.0477
Batch 230, Loss: 0.0490
Batch 240, Loss: 0.0417
Batch 250, Loss: 0.0484
Batch 260, Loss: 0.0420
Batch 270, Loss: 0.0426
Batch 280, Loss: 0.0431
Batch 290, Loss: 0.0429
Batch 300, Loss: 0.0420
Batch 310, Loss: 0.0428
Batch 320, Loss: 0.0465
Batch 330, Loss: 0.0468
Batch 340, Loss: 0.0433
Batch 350, Loss: 0.0452
Batch 360, Loss: 0.0423
Batch 370, Loss: 0.0470
Batch 380, Loss: 0.0435
Batch 390, Loss: 0.0432
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.011056184768677 seconds
Epoch 169 accuracy: 78.32%
Batch 10, Loss: 0.0442
Batch 20, Loss: 0.0416
Batch 30, Loss: 0.0428
Batch 40, Loss: 0.0410
Batch 50, Loss: 0.0419
Batch 60, Loss: 0.0433
Batch 70, Loss: 0.0438
Batch 80, Loss: 0.0439
Batch 90, Loss: 0.0443
Batch 100, Loss: 0.0435
Batch 110, Loss: 0.0456
Batch 120, Loss: 0.0444
Batch 130, Loss: 0.0470
Batch 140, Loss: 0.0418
Batch 150, Loss: 0.0445
Batch 160, Loss: 0.0419
Batch 170, Loss: 0.0373
Batch 180, Loss: 0.0397
Batch 190, Loss: 0.0435
Batch 200, Loss: 0.0413
Batch 210, Loss: 0.0495
Batch 220, Loss: 0.0423
Batch 230, Loss: 0.0513
Batch 240, Loss: 0.0444
Batch 250, Loss: 0.0433
Batch 260, Loss: 0.0459
Batch 270, Loss: 0.0381
Batch 280, Loss: 0.0451
Batch 290, Loss: 0.0408
Batch 300, Loss: 0.0391
Batch 310, Loss: 0.0443
Batch 320, Loss: 0.0479
Batch 330, Loss: 0.0403
Batch 340, Loss: 0.0410
Batch 350, Loss: 0.0445
Batch 360, Loss: 0.0431
Batch 370, Loss: 0.0437
Batch 380, Loss: 0.0435
Batch 390, Loss: 0.0415
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 24.994173526763916 seconds
Epoch 170 accuracy: 78.21%
Batch 10, Loss: 0.0433
Batch 20, Loss: 0.0367
Batch 30, Loss: 0.0415
Batch 40, Loss: 0.0392
Batch 50, Loss: 0.0440
Batch 60, Loss: 0.0408
Batch 70, Loss: 0.0407
Batch 80, Loss: 0.0399
Batch 90, Loss: 0.0408
Batch 100, Loss: 0.0399
Batch 110, Loss: 0.0382
Batch 120, Loss: 0.0444
Batch 130, Loss: 0.0427
Batch 140, Loss: 0.0465
Batch 150, Loss: 0.0440
Batch 160, Loss: 0.0415
Batch 170, Loss: 0.0406
Batch 180, Loss: 0.0378
Batch 190, Loss: 0.0381
Batch 200, Loss: 0.0485
Batch 210, Loss: 0.0402
Batch 220, Loss: 0.0390
Batch 230, Loss: 0.0358
Batch 240, Loss: 0.0395
Batch 250, Loss: 0.0465
Batch 260, Loss: 0.0425
Batch 270, Loss: 0.0422
Batch 280, Loss: 0.0381
Batch 290, Loss: 0.0391
Batch 300, Loss: 0.0406
Batch 310, Loss: 0.0412
Batch 320, Loss: 0.0396
Batch 330, Loss: 0.0399
Batch 340, Loss: 0.0376
Batch 350, Loss: 0.0422
Batch 360, Loss: 0.0377
Batch 370, Loss: 0.0427
Batch 380, Loss: 0.0408
Batch 390, Loss: 0.0414
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 24.945652961730957 seconds
Epoch 171 accuracy: 78.5%
Batch 10, Loss: 0.0363
Batch 20, Loss: 0.0429
Batch 30, Loss: 0.0360
Batch 40, Loss: 0.0391
Batch 50, Loss: 0.0375
Batch 60, Loss: 0.0407
Batch 70, Loss: 0.0415
Batch 80, Loss: 0.0364
Batch 90, Loss: 0.0359
Batch 100, Loss: 0.0379
Batch 110, Loss: 0.0416
Batch 120, Loss: 0.0392
Batch 130, Loss: 0.0435
Batch 140, Loss: 0.0372
Batch 150, Loss: 0.0413
Batch 160, Loss: 0.0443
Batch 170, Loss: 0.0433
Batch 180, Loss: 0.0352
Batch 190, Loss: 0.0392
Batch 200, Loss: 0.0369
Batch 210, Loss: 0.0387
Batch 220, Loss: 0.0393
Batch 230, Loss: 0.0410
Batch 240, Loss: 0.0402
Batch 250, Loss: 0.0405
Batch 260, Loss: 0.0368
Batch 270, Loss: 0.0404
Batch 280, Loss: 0.0356
Batch 290, Loss: 0.0409
Batch 300, Loss: 0.0402
Batch 310, Loss: 0.0380
Batch 320, Loss: 0.0406
Batch 330, Loss: 0.0382
Batch 340, Loss: 0.0386
Batch 350, Loss: 0.0406
Batch 360, Loss: 0.0403
Batch 370, Loss: 0.0366
Batch 380, Loss: 0.0349
Batch 390, Loss: 0.0431
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.012080669403076 seconds
Epoch 172 accuracy: 78.44%
Batch 10, Loss: 0.0366
Batch 20, Loss: 0.0405
Batch 30, Loss: 0.0375
Batch 40, Loss: 0.0373
Batch 50, Loss: 0.0364
Batch 60, Loss: 0.0377
Batch 70, Loss: 0.0394
Batch 80, Loss: 0.0351
Batch 90, Loss: 0.0388
Batch 100, Loss: 0.0372
Batch 110, Loss: 0.0350
Batch 120, Loss: 0.0368
Batch 130, Loss: 0.0364
Batch 140, Loss: 0.0371
Batch 150, Loss: 0.0367
Batch 160, Loss: 0.0364
Batch 170, Loss: 0.0436
Batch 180, Loss: 0.0436
Batch 190, Loss: 0.0373
Batch 200, Loss: 0.0380
Batch 210, Loss: 0.0376
Batch 220, Loss: 0.0355
Batch 230, Loss: 0.0382
Batch 240, Loss: 0.0338
Batch 250, Loss: 0.0420
Batch 260, Loss: 0.0347
Batch 270, Loss: 0.0351
Batch 280, Loss: 0.0383
Batch 290, Loss: 0.0380
Batch 300, Loss: 0.0372
Batch 310, Loss: 0.0393
Batch 320, Loss: 0.0334
Batch 330, Loss: 0.0365
Batch 340, Loss: 0.0391
Batch 350, Loss: 0.0346
Batch 360, Loss: 0.0355
Batch 370, Loss: 0.0345
Batch 380, Loss: 0.0377
Batch 390, Loss: 0.0346
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 24.943971395492554 seconds
Epoch 173 accuracy: 78.68%
Batch 10, Loss: 0.0343
Batch 20, Loss: 0.0351
Batch 30, Loss: 0.0358
Batch 40, Loss: 0.0324
Batch 50, Loss: 0.0349
Batch 60, Loss: 0.0351
Batch 70, Loss: 0.0353
Batch 80, Loss: 0.0340
Batch 90, Loss: 0.0329
Batch 100, Loss: 0.0364
Batch 110, Loss: 0.0324
Batch 120, Loss: 0.0392
Batch 130, Loss: 0.0436
Batch 140, Loss: 0.0370
Batch 150, Loss: 0.0341
Batch 160, Loss: 0.0380
Batch 170, Loss: 0.0329
Batch 180, Loss: 0.0373
Batch 190, Loss: 0.0323
Batch 200, Loss: 0.0329
Batch 210, Loss: 0.0357
Batch 220, Loss: 0.0335
Batch 230, Loss: 0.0375
Batch 240, Loss: 0.0367
Batch 250, Loss: 0.0367
Batch 260, Loss: 0.0373
Batch 270, Loss: 0.0367
Batch 280, Loss: 0.0372
Batch 290, Loss: 0.0321
Batch 300, Loss: 0.0356
Batch 310, Loss: 0.0384
Batch 320, Loss: 0.0378
Batch 330, Loss: 0.0359
Batch 340, Loss: 0.0320
Batch 350, Loss: 0.0425
Batch 360, Loss: 0.0382
Batch 370, Loss: 0.0310
Batch 380, Loss: 0.0430
Batch 390, Loss: 0.0325
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 24.979541301727295 seconds
Epoch 174 accuracy: 78.5%
Batch 10, Loss: 0.0302
Batch 20, Loss: 0.0329
Batch 30, Loss: 0.0350
Batch 40, Loss: 0.0357
Batch 50, Loss: 0.0325
Batch 60, Loss: 0.0325
Batch 70, Loss: 0.0385
Batch 80, Loss: 0.0329
Batch 90, Loss: 0.0340
Batch 100, Loss: 0.0321
Batch 110, Loss: 0.0358
Batch 120, Loss: 0.0367
Batch 130, Loss: 0.0344
Batch 140, Loss: 0.0366
Batch 150, Loss: 0.0327
Batch 160, Loss: 0.0341
Batch 170, Loss: 0.0327
Batch 180, Loss: 0.0325
Batch 190, Loss: 0.0377
Batch 200, Loss: 0.0339
Batch 210, Loss: 0.0353
Batch 220, Loss: 0.0379
Batch 230, Loss: 0.0356
Batch 240, Loss: 0.0324
Batch 250, Loss: 0.0355
Batch 260, Loss: 0.0312
Batch 270, Loss: 0.0316
Batch 280, Loss: 0.0312
Batch 290, Loss: 0.0354
Batch 300, Loss: 0.0306
Batch 310, Loss: 0.0333
Batch 320, Loss: 0.0375
Batch 330, Loss: 0.0319
Batch 340, Loss: 0.0375
Batch 350, Loss: 0.0328
Batch 360, Loss: 0.0371
Batch 370, Loss: 0.0333
Batch 380, Loss: 0.0336
Batch 390, Loss: 0.0345
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.023662090301514 seconds
Epoch 175 accuracy: 78.45%
Batch 10, Loss: 0.0330
Batch 20, Loss: 0.0313
Batch 30, Loss: 0.0355
Batch 40, Loss: 0.0398
Batch 50, Loss: 0.0349
Batch 60, Loss: 0.0369
Batch 70, Loss: 0.0357
Batch 80, Loss: 0.0325
Batch 90, Loss: 0.0330
Batch 100, Loss: 0.0291
Batch 110, Loss: 0.0360
Batch 120, Loss: 0.0334
Batch 130, Loss: 0.0312
Batch 140, Loss: 0.0288
Batch 150, Loss: 0.0309
Batch 160, Loss: 0.0299
Batch 170, Loss: 0.0320
Batch 180, Loss: 0.0289
Batch 190, Loss: 0.0329
Batch 200, Loss: 0.0285
Batch 210, Loss: 0.0362
Batch 220, Loss: 0.0322
Batch 230, Loss: 0.0336
Batch 240, Loss: 0.0325
Batch 250, Loss: 0.0328
Batch 260, Loss: 0.0327
Batch 270, Loss: 0.0300
Batch 280, Loss: 0.0308
Batch 290, Loss: 0.0293
Batch 300, Loss: 0.0328
Batch 310, Loss: 0.0366
Batch 320, Loss: 0.0355
Batch 330, Loss: 0.0416
Batch 340, Loss: 0.0351
Batch 350, Loss: 0.0320
Batch 360, Loss: 0.0369
Batch 370, Loss: 0.0369
Batch 380, Loss: 0.0349
Batch 390, Loss: 0.0324
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.039872407913208 seconds
Epoch 176 accuracy: 78.88%
Batch 10, Loss: 0.0318
Batch 20, Loss: 0.0329
Batch 30, Loss: 0.0319
Batch 40, Loss: 0.0277
Batch 50, Loss: 0.0307
Batch 60, Loss: 0.0356
Batch 70, Loss: 0.0276
Batch 80, Loss: 0.0332
Batch 90, Loss: 0.0292
Batch 100, Loss: 0.0338
Batch 110, Loss: 0.0304
Batch 120, Loss: 0.0355
Batch 130, Loss: 0.0315
Batch 140, Loss: 0.0329
Batch 150, Loss: 0.0285
Batch 160, Loss: 0.0332
Batch 170, Loss: 0.0350
Batch 180, Loss: 0.0310
Batch 190, Loss: 0.0295
Batch 200, Loss: 0.0307
Batch 210, Loss: 0.0302
Batch 220, Loss: 0.0294
Batch 230, Loss: 0.0329
Batch 240, Loss: 0.0326
Batch 250, Loss: 0.0325
Batch 260, Loss: 0.0362
Batch 270, Loss: 0.0342
Batch 280, Loss: 0.0356
Batch 290, Loss: 0.0338
Batch 300, Loss: 0.0350
Batch 310, Loss: 0.0347
Batch 320, Loss: 0.0348
Batch 330, Loss: 0.0307
Batch 340, Loss: 0.0328
Batch 350, Loss: 0.0326
Batch 360, Loss: 0.0325
Batch 370, Loss: 0.0341
Batch 380, Loss: 0.0326
Batch 390, Loss: 0.0302
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 24.928507328033447 seconds
Epoch 177 accuracy: 79.03%
Batch 10, Loss: 0.0295
Batch 20, Loss: 0.0292
Batch 30, Loss: 0.0280
Batch 40, Loss: 0.0366
Batch 50, Loss: 0.0311
Batch 60, Loss: 0.0366
Batch 70, Loss: 0.0292
Batch 80, Loss: 0.0304
Batch 90, Loss: 0.0271
Batch 100, Loss: 0.0274
Batch 110, Loss: 0.0306
Batch 120, Loss: 0.0301
Batch 130, Loss: 0.0320
Batch 140, Loss: 0.0309
Batch 150, Loss: 0.0308
Batch 160, Loss: 0.0313
Batch 170, Loss: 0.0319
Batch 180, Loss: 0.0278
Batch 190, Loss: 0.0343
Batch 200, Loss: 0.0282
Batch 210, Loss: 0.0292
Batch 220, Loss: 0.0314
Batch 230, Loss: 0.0311
Batch 240, Loss: 0.0308
Batch 250, Loss: 0.0274
Batch 260, Loss: 0.0364
Batch 270, Loss: 0.0289
Batch 280, Loss: 0.0286
Batch 290, Loss: 0.0279
Batch 300, Loss: 0.0293
Batch 310, Loss: 0.0317
Batch 320, Loss: 0.0289
Batch 330, Loss: 0.0336
Batch 340, Loss: 0.0309
Batch 350, Loss: 0.0316
Batch 360, Loss: 0.0311
Batch 370, Loss: 0.0327
Batch 380, Loss: 0.0296
Batch 390, Loss: 0.0301
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 24.958861589431763 seconds
Epoch 178 accuracy: 78.69%
Batch 10, Loss: 0.0292
Batch 20, Loss: 0.0266
Batch 30, Loss: 0.0297
Batch 40, Loss: 0.0292
Batch 50, Loss: 0.0281
Batch 60, Loss: 0.0314
Batch 70, Loss: 0.0259
Batch 80, Loss: 0.0295
Batch 90, Loss: 0.0322
Batch 100, Loss: 0.0290
Batch 110, Loss: 0.0317
Batch 120, Loss: 0.0334
Batch 130, Loss: 0.0283
Batch 140, Loss: 0.0267
Batch 150, Loss: 0.0336
Batch 160, Loss: 0.0288
Batch 170, Loss: 0.0299
Batch 180, Loss: 0.0276
Batch 190, Loss: 0.0267
Batch 200, Loss: 0.0287
Batch 210, Loss: 0.0297
Batch 220, Loss: 0.0307
Batch 230, Loss: 0.0273
Batch 240, Loss: 0.0320
Batch 250, Loss: 0.0270
Batch 260, Loss: 0.0254
Batch 270, Loss: 0.0291
Batch 280, Loss: 0.0322
Batch 290, Loss: 0.0320
Batch 300, Loss: 0.0282
Batch 310, Loss: 0.0281
Batch 320, Loss: 0.0346
Batch 330, Loss: 0.0328
Batch 340, Loss: 0.0292
Batch 350, Loss: 0.0306
Batch 360, Loss: 0.0305
Batch 370, Loss: 0.0322
Batch 380, Loss: 0.0314
Batch 390, Loss: 0.0328
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 24.972997903823853 seconds
Epoch 179 accuracy: 79.04%
Batch 10, Loss: 0.0303
Batch 20, Loss: 0.0303
Batch 30, Loss: 0.0277
Batch 40, Loss: 0.0311
Batch 50, Loss: 0.0265
Batch 60, Loss: 0.0304
Batch 70, Loss: 0.0295
Batch 80, Loss: 0.0285
Batch 90, Loss: 0.0312
Batch 100, Loss: 0.0266
Batch 110, Loss: 0.0289
Batch 120, Loss: 0.0294
Batch 130, Loss: 0.0300
Batch 140, Loss: 0.0278
Batch 150, Loss: 0.0298
Batch 160, Loss: 0.0298
Batch 170, Loss: 0.0292
Batch 180, Loss: 0.0282
Batch 190, Loss: 0.0321
Batch 200, Loss: 0.0310
Batch 210, Loss: 0.0254
Batch 220, Loss: 0.0302
Batch 230, Loss: 0.0257
Batch 240, Loss: 0.0267
Batch 250, Loss: 0.0262
Batch 260, Loss: 0.0275
Batch 270, Loss: 0.0280
Batch 280, Loss: 0.0269
Batch 290, Loss: 0.0288
Batch 300, Loss: 0.0306
Batch 310, Loss: 0.0307
Batch 320, Loss: 0.0268
Batch 330, Loss: 0.0364
Batch 340, Loss: 0.0279
Batch 350, Loss: 0.0282
Batch 360, Loss: 0.0288
Batch 370, Loss: 0.0294
Batch 380, Loss: 0.0294
Batch 390, Loss: 0.0279
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 24.916651964187622 seconds
Epoch 180 accuracy: 79.34%
Batch 10, Loss: 0.0277
Batch 20, Loss: 0.0292
Batch 30, Loss: 0.0279
Batch 40, Loss: 0.0274
Batch 50, Loss: 0.0301
Batch 60, Loss: 0.0253
Batch 70, Loss: 0.0304
Batch 80, Loss: 0.0260
Batch 90, Loss: 0.0303
Batch 100, Loss: 0.0304
Batch 110, Loss: 0.0256
Batch 120, Loss: 0.0290
Batch 130, Loss: 0.0245
Batch 140, Loss: 0.0245
Batch 150, Loss: 0.0285
Batch 160, Loss: 0.0275
Batch 170, Loss: 0.0254
Batch 180, Loss: 0.0275
Batch 190, Loss: 0.0306
Batch 200, Loss: 0.0284
Batch 210, Loss: 0.0315
Batch 220, Loss: 0.0290
Batch 230, Loss: 0.0279
Batch 240, Loss: 0.0283
Batch 250, Loss: 0.0270
Batch 260, Loss: 0.0244
Batch 270, Loss: 0.0264
Batch 280, Loss: 0.0267
Batch 290, Loss: 0.0277
Batch 300, Loss: 0.0271
Batch 310, Loss: 0.0262
Batch 320, Loss: 0.0280
Batch 330, Loss: 0.0253
Batch 340, Loss: 0.0292
Batch 350, Loss: 0.0269
Batch 360, Loss: 0.0276
Batch 370, Loss: 0.0272
Batch 380, Loss: 0.0290
Batch 390, Loss: 0.0249
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 24.97133731842041 seconds
Epoch 181 accuracy: 79.13%
Batch 10, Loss: 0.0277
Batch 20, Loss: 0.0265
Batch 30, Loss: 0.0276
Batch 40, Loss: 0.0254
Batch 50, Loss: 0.0276
Batch 60, Loss: 0.0292
Batch 70, Loss: 0.0283
Batch 80, Loss: 0.0260
Batch 90, Loss: 0.0258
Batch 100, Loss: 0.0296
Batch 110, Loss: 0.0291
Batch 120, Loss: 0.0261
Batch 130, Loss: 0.0294
Batch 140, Loss: 0.0286
Batch 150, Loss: 0.0252
Batch 160, Loss: 0.0310
Batch 170, Loss: 0.0252
Batch 180, Loss: 0.0290
Batch 190, Loss: 0.0272
Batch 200, Loss: 0.0286
Batch 210, Loss: 0.0255
Batch 220, Loss: 0.0318
Batch 230, Loss: 0.0256
Batch 240, Loss: 0.0289
Batch 250, Loss: 0.0264
Batch 260, Loss: 0.0257
Batch 270, Loss: 0.0254
Batch 280, Loss: 0.0260
Batch 290, Loss: 0.0296
Batch 300, Loss: 0.0324
Batch 310, Loss: 0.0240
Batch 320, Loss: 0.0276
Batch 330, Loss: 0.0318
Batch 340, Loss: 0.0297
Batch 350, Loss: 0.0288
Batch 360, Loss: 0.0260
Batch 370, Loss: 0.0252
Batch 380, Loss: 0.0305
Batch 390, Loss: 0.0278
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 24.958170652389526 seconds
Epoch 182 accuracy: 79.28%
Batch 10, Loss: 0.0293
Batch 20, Loss: 0.0240
Batch 30, Loss: 0.0280
Batch 40, Loss: 0.0282
Batch 50, Loss: 0.0284
Batch 60, Loss: 0.0257
Batch 70, Loss: 0.0285
Batch 80, Loss: 0.0270
Batch 90, Loss: 0.0238
Batch 100, Loss: 0.0250
Batch 110, Loss: 0.0275
Batch 120, Loss: 0.0243
Batch 130, Loss: 0.0274
Batch 140, Loss: 0.0275
Batch 150, Loss: 0.0261
Batch 160, Loss: 0.0264
Batch 170, Loss: 0.0309
Batch 180, Loss: 0.0244
Batch 190, Loss: 0.0265
Batch 200, Loss: 0.0252
Batch 210, Loss: 0.0293
Batch 220, Loss: 0.0243
Batch 230, Loss: 0.0295
Batch 240, Loss: 0.0253
Batch 250, Loss: 0.0274
Batch 260, Loss: 0.0246
Batch 270, Loss: 0.0279
Batch 280, Loss: 0.0266
Batch 290, Loss: 0.0278
Batch 300, Loss: 0.0263
Batch 310, Loss: 0.0264
Batch 320, Loss: 0.0273
Batch 330, Loss: 0.0307
Batch 340, Loss: 0.0265
Batch 350, Loss: 0.0271
Batch 360, Loss: 0.0254
Batch 370, Loss: 0.0301
Batch 380, Loss: 0.0242
Batch 390, Loss: 0.0278
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 24.906653881072998 seconds
Epoch 183 accuracy: 79.29%
Batch 10, Loss: 0.0279
Batch 20, Loss: 0.0288
Batch 30, Loss: 0.0285
Batch 40, Loss: 0.0301
Batch 50, Loss: 0.0240
Batch 60, Loss: 0.0232
Batch 70, Loss: 0.0283
Batch 80, Loss: 0.0277
Batch 90, Loss: 0.0270
Batch 100, Loss: 0.0296
Batch 110, Loss: 0.0244
Batch 120, Loss: 0.0273
Batch 130, Loss: 0.0273
Batch 140, Loss: 0.0259
Batch 150, Loss: 0.0318
Batch 160, Loss: 0.0250
Batch 170, Loss: 0.0279
Batch 180, Loss: 0.0295
Batch 190, Loss: 0.0254
Batch 200, Loss: 0.0300
Batch 210, Loss: 0.0269
Batch 220, Loss: 0.0255
Batch 230, Loss: 0.0274
Batch 240, Loss: 0.0254
Batch 250, Loss: 0.0242
Batch 260, Loss: 0.0265
Batch 270, Loss: 0.0269
Batch 280, Loss: 0.0236
Batch 290, Loss: 0.0244
Batch 300, Loss: 0.0246
Batch 310, Loss: 0.0254
Batch 320, Loss: 0.0222
Batch 330, Loss: 0.0279
Batch 340, Loss: 0.0239
Batch 350, Loss: 0.0266
Batch 360, Loss: 0.0267
Batch 370, Loss: 0.0280
Batch 380, Loss: 0.0250
Batch 390, Loss: 0.0261
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 24.966824531555176 seconds
Epoch 184 accuracy: 79.22%
Batch 10, Loss: 0.0256
Batch 20, Loss: 0.0251
Batch 30, Loss: 0.0256
Batch 40, Loss: 0.0236
Batch 50, Loss: 0.0257
Batch 60, Loss: 0.0244
Batch 70, Loss: 0.0259
Batch 80, Loss: 0.0261
Batch 90, Loss: 0.0255
Batch 100, Loss: 0.0243
Batch 110, Loss: 0.0259
Batch 120, Loss: 0.0263
Batch 130, Loss: 0.0245
Batch 140, Loss: 0.0257
Batch 150, Loss: 0.0254
Batch 160, Loss: 0.0248
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0243
Batch 190, Loss: 0.0245
Batch 200, Loss: 0.0235
Batch 210, Loss: 0.0271
Batch 220, Loss: 0.0258
Batch 230, Loss: 0.0268
Batch 240, Loss: 0.0276
Batch 250, Loss: 0.0249
Batch 260, Loss: 0.0227
Batch 270, Loss: 0.0282
Batch 280, Loss: 0.0262
Batch 290, Loss: 0.0256
Batch 300, Loss: 0.0247
Batch 310, Loss: 0.0270
Batch 320, Loss: 0.0279
Batch 330, Loss: 0.0239
Batch 340, Loss: 0.0239
Batch 350, Loss: 0.0256
Batch 360, Loss: 0.0286
Batch 370, Loss: 0.0285
Batch 380, Loss: 0.0226
Batch 390, Loss: 0.0307
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 24.95622754096985 seconds
Epoch 185 accuracy: 79.27%
Batch 10, Loss: 0.0250
Batch 20, Loss: 0.0230
Batch 30, Loss: 0.0260
Batch 40, Loss: 0.0254
Batch 50, Loss: 0.0236
Batch 60, Loss: 0.0225
Batch 70, Loss: 0.0268
Batch 80, Loss: 0.0251
Batch 90, Loss: 0.0239
Batch 100, Loss: 0.0260
Batch 110, Loss: 0.0249
Batch 120, Loss: 0.0216
Batch 130, Loss: 0.0269
Batch 140, Loss: 0.0272
Batch 150, Loss: 0.0245
Batch 160, Loss: 0.0264
Batch 170, Loss: 0.0279
Batch 180, Loss: 0.0238
Batch 190, Loss: 0.0258
Batch 200, Loss: 0.0286
Batch 210, Loss: 0.0272
Batch 220, Loss: 0.0266
Batch 230, Loss: 0.0284
Batch 240, Loss: 0.0257
Batch 250, Loss: 0.0258
Batch 260, Loss: 0.0260
Batch 270, Loss: 0.0262
Batch 280, Loss: 0.0272
Batch 290, Loss: 0.0254
Batch 300, Loss: 0.0269
Batch 310, Loss: 0.0234
Batch 320, Loss: 0.0234
Batch 330, Loss: 0.0268
Batch 340, Loss: 0.0230
Batch 350, Loss: 0.0227
Batch 360, Loss: 0.0241
Batch 370, Loss: 0.0250
Batch 380, Loss: 0.0229
Batch 390, Loss: 0.0222
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 24.961695194244385 seconds
Epoch 186 accuracy: 79.39%
Batch 10, Loss: 0.0263
Batch 20, Loss: 0.0254
Batch 30, Loss: 0.0263
Batch 40, Loss: 0.0239
Batch 50, Loss: 0.0248
Batch 60, Loss: 0.0279
Batch 70, Loss: 0.0251
Batch 80, Loss: 0.0296
Batch 90, Loss: 0.0238
Batch 100, Loss: 0.0228
Batch 110, Loss: 0.0241
Batch 120, Loss: 0.0257
Batch 130, Loss: 0.0226
Batch 140, Loss: 0.0262
Batch 150, Loss: 0.0262
Batch 160, Loss: 0.0246
Batch 170, Loss: 0.0268
Batch 180, Loss: 0.0250
Batch 190, Loss: 0.0253
Batch 200, Loss: 0.0230
Batch 210, Loss: 0.0238
Batch 220, Loss: 0.0275
Batch 230, Loss: 0.0257
Batch 240, Loss: 0.0238
Batch 250, Loss: 0.0258
Batch 260, Loss: 0.0292
Batch 270, Loss: 0.0237
Batch 280, Loss: 0.0255
Batch 290, Loss: 0.0248
Batch 300, Loss: 0.0261
Batch 310, Loss: 0.0227
Batch 320, Loss: 0.0219
Batch 330, Loss: 0.0254
Batch 340, Loss: 0.0268
Batch 350, Loss: 0.0245
Batch 360, Loss: 0.0269
Batch 370, Loss: 0.0230
Batch 380, Loss: 0.0270
Batch 390, Loss: 0.0247
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 24.963682174682617 seconds
Epoch 187 accuracy: 79.13%
Batch 10, Loss: 0.0230
Batch 20, Loss: 0.0207
Batch 30, Loss: 0.0248
Batch 40, Loss: 0.0227
Batch 50, Loss: 0.0248
Batch 60, Loss: 0.0240
Batch 70, Loss: 0.0245
Batch 80, Loss: 0.0292
Batch 90, Loss: 0.0257
Batch 100, Loss: 0.0264
Batch 110, Loss: 0.0243
Batch 120, Loss: 0.0263
Batch 130, Loss: 0.0246
Batch 140, Loss: 0.0236
Batch 150, Loss: 0.0262
Batch 160, Loss: 0.0231
Batch 170, Loss: 0.0253
Batch 180, Loss: 0.0225
Batch 190, Loss: 0.0240
Batch 200, Loss: 0.0258
Batch 210, Loss: 0.0284
Batch 220, Loss: 0.0282
Batch 230, Loss: 0.0259
Batch 240, Loss: 0.0249
Batch 250, Loss: 0.0241
Batch 260, Loss: 0.0236
Batch 270, Loss: 0.0253
Batch 280, Loss: 0.0239
Batch 290, Loss: 0.0241
Batch 300, Loss: 0.0229
Batch 310, Loss: 0.0244
Batch 320, Loss: 0.0268
Batch 330, Loss: 0.0267
Batch 340, Loss: 0.0235
Batch 350, Loss: 0.0240
Batch 360, Loss: 0.0234
Batch 370, Loss: 0.0229
Batch 380, Loss: 0.0233
Batch 390, Loss: 0.0268
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 24.96231698989868 seconds
Epoch 188 accuracy: 79.38%
Batch 10, Loss: 0.0237
Batch 20, Loss: 0.0241
Batch 30, Loss: 0.0259
Batch 40, Loss: 0.0268
Batch 50, Loss: 0.0256
Batch 60, Loss: 0.0238
Batch 70, Loss: 0.0247
Batch 80, Loss: 0.0240
Batch 90, Loss: 0.0248
Batch 100, Loss: 0.0241
Batch 110, Loss: 0.0209
Batch 120, Loss: 0.0261
Batch 130, Loss: 0.0240
Batch 140, Loss: 0.0227
Batch 150, Loss: 0.0252
Batch 160, Loss: 0.0223
Batch 170, Loss: 0.0223
Batch 180, Loss: 0.0266
Batch 190, Loss: 0.0231
Batch 200, Loss: 0.0258
Batch 210, Loss: 0.0270
Batch 220, Loss: 0.0215
Batch 230, Loss: 0.0235
Batch 240, Loss: 0.0238
Batch 250, Loss: 0.0271
Batch 260, Loss: 0.0245
Batch 270, Loss: 0.0265
Batch 280, Loss: 0.0243
Batch 290, Loss: 0.0225
Batch 300, Loss: 0.0266
Batch 310, Loss: 0.0237
Batch 320, Loss: 0.0226
Batch 330, Loss: 0.0227
Batch 340, Loss: 0.0273
Batch 350, Loss: 0.0262
Batch 360, Loss: 0.0272
Batch 370, Loss: 0.0215
Batch 380, Loss: 0.0242
Batch 390, Loss: 0.0258
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 24.94460439682007 seconds
Epoch 189 accuracy: 79.36%
Batch 10, Loss: 0.0248
Batch 20, Loss: 0.0230
Batch 30, Loss: 0.0242
Batch 40, Loss: 0.0238
Batch 50, Loss: 0.0218
Batch 60, Loss: 0.0223
Batch 70, Loss: 0.0262
Batch 80, Loss: 0.0229
Batch 90, Loss: 0.0228
Batch 100, Loss: 0.0222
Batch 110, Loss: 0.0247
Batch 120, Loss: 0.0253
Batch 130, Loss: 0.0247
Batch 140, Loss: 0.0273
Batch 150, Loss: 0.0247
Batch 160, Loss: 0.0219
Batch 170, Loss: 0.0252
Batch 180, Loss: 0.0220
Batch 190, Loss: 0.0210
Batch 200, Loss: 0.0256
Batch 210, Loss: 0.0288
Batch 220, Loss: 0.0217
Batch 230, Loss: 0.0225
Batch 240, Loss: 0.0227
Batch 250, Loss: 0.0235
Batch 260, Loss: 0.0259
Batch 270, Loss: 0.0222
Batch 280, Loss: 0.0278
Batch 290, Loss: 0.0253
Batch 300, Loss: 0.0228
Batch 310, Loss: 0.0268
Batch 320, Loss: 0.0234
Batch 330, Loss: 0.0250
Batch 340, Loss: 0.0242
Batch 350, Loss: 0.0226
Batch 360, Loss: 0.0273
Batch 370, Loss: 0.0225
Batch 380, Loss: 0.0227
Batch 390, Loss: 0.0240
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 24.95427632331848 seconds
Epoch 190 accuracy: 79.46%
Batch 10, Loss: 0.0264
Batch 20, Loss: 0.0227
Batch 30, Loss: 0.0245
Batch 40, Loss: 0.0246
Batch 50, Loss: 0.0232
Batch 60, Loss: 0.0239
Batch 70, Loss: 0.0219
Batch 80, Loss: 0.0242
Batch 90, Loss: 0.0230
Batch 100, Loss: 0.0225
Batch 110, Loss: 0.0222
Batch 120, Loss: 0.0198
Batch 130, Loss: 0.0269
Batch 140, Loss: 0.0222
Batch 150, Loss: 0.0222
Batch 160, Loss: 0.0227
Batch 170, Loss: 0.0252
Batch 180, Loss: 0.0237
Batch 190, Loss: 0.0223
Batch 200, Loss: 0.0217
Batch 210, Loss: 0.0229
Batch 220, Loss: 0.0239
Batch 230, Loss: 0.0220
Batch 240, Loss: 0.0241
Batch 250, Loss: 0.0236
Batch 260, Loss: 0.0228
Batch 270, Loss: 0.0273
Batch 280, Loss: 0.0237
Batch 290, Loss: 0.0252
Batch 300, Loss: 0.0203
Batch 310, Loss: 0.0226
Batch 320, Loss: 0.0252
Batch 330, Loss: 0.0215
Batch 340, Loss: 0.0240
Batch 350, Loss: 0.0214
Batch 360, Loss: 0.0239
Batch 370, Loss: 0.0234
Batch 380, Loss: 0.0231
Batch 390, Loss: 0.0232
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 24.93840980529785 seconds
Epoch 191 accuracy: 79.54%
Batch 10, Loss: 0.0224
Batch 20, Loss: 0.0247
Batch 30, Loss: 0.0212
Batch 40, Loss: 0.0242
Batch 50, Loss: 0.0226
Batch 60, Loss: 0.0225
Batch 70, Loss: 0.0233
Batch 80, Loss: 0.0223
Batch 90, Loss: 0.0251
Batch 100, Loss: 0.0233
Batch 110, Loss: 0.0214
Batch 120, Loss: 0.0237
Batch 130, Loss: 0.0205
Batch 140, Loss: 0.0251
Batch 150, Loss: 0.0243
Batch 160, Loss: 0.0260
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0264
Batch 190, Loss: 0.0239
Batch 200, Loss: 0.0220
Batch 210, Loss: 0.0242
Batch 220, Loss: 0.0231
Batch 230, Loss: 0.0205
Batch 240, Loss: 0.0225
Batch 250, Loss: 0.0228
Batch 260, Loss: 0.0258
Batch 270, Loss: 0.0222
Batch 280, Loss: 0.0238
Batch 290, Loss: 0.0253
Batch 300, Loss: 0.0274
Batch 310, Loss: 0.0226
Batch 320, Loss: 0.0237
Batch 330, Loss: 0.0246
Batch 340, Loss: 0.0253
Batch 350, Loss: 0.0212
Batch 360, Loss: 0.0239
Batch 370, Loss: 0.0213
Batch 380, Loss: 0.0239
Batch 390, Loss: 0.0265
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 24.937058448791504 seconds
Epoch 192 accuracy: 79.52%
Batch 10, Loss: 0.0232
Batch 20, Loss: 0.0241
Batch 30, Loss: 0.0232
Batch 40, Loss: 0.0262
Batch 50, Loss: 0.0227
Batch 60, Loss: 0.0236
Batch 70, Loss: 0.0227
Batch 80, Loss: 0.0240
Batch 90, Loss: 0.0224
Batch 100, Loss: 0.0226
Batch 110, Loss: 0.0246
Batch 120, Loss: 0.0246
Batch 130, Loss: 0.0227
Batch 140, Loss: 0.0218
Batch 150, Loss: 0.0241
Batch 160, Loss: 0.0249
Batch 170, Loss: 0.0227
Batch 180, Loss: 0.0241
Batch 190, Loss: 0.0246
Batch 200, Loss: 0.0228
Batch 210, Loss: 0.0253
Batch 220, Loss: 0.0216
Batch 230, Loss: 0.0245
Batch 240, Loss: 0.0229
Batch 250, Loss: 0.0225
Batch 260, Loss: 0.0265
Batch 270, Loss: 0.0248
Batch 280, Loss: 0.0211
Batch 290, Loss: 0.0218
Batch 300, Loss: 0.0199
Batch 310, Loss: 0.0227
Batch 320, Loss: 0.0242
Batch 330, Loss: 0.0233
Batch 340, Loss: 0.0232
Batch 350, Loss: 0.0215
Batch 360, Loss: 0.0239
Batch 370, Loss: 0.0254
Batch 380, Loss: 0.0227
Batch 390, Loss: 0.0229
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.037699699401855 seconds
Epoch 193 accuracy: 79.62%
Batch 10, Loss: 0.0230
Batch 20, Loss: 0.0232
Batch 30, Loss: 0.0221
Batch 40, Loss: 0.0222
Batch 50, Loss: 0.0222
Batch 60, Loss: 0.0228
Batch 70, Loss: 0.0230
Batch 80, Loss: 0.0217
Batch 90, Loss: 0.0222
Batch 100, Loss: 0.0244
Batch 110, Loss: 0.0223
Batch 120, Loss: 0.0246
Batch 130, Loss: 0.0236
Batch 140, Loss: 0.0228
Batch 150, Loss: 0.0217
Batch 160, Loss: 0.0211
Batch 170, Loss: 0.0225
Batch 180, Loss: 0.0206
Batch 190, Loss: 0.0254
Batch 200, Loss: 0.0228
Batch 210, Loss: 0.0224
Batch 220, Loss: 0.0221
Batch 230, Loss: 0.0219
Batch 240, Loss: 0.0215
Batch 250, Loss: 0.0250
Batch 260, Loss: 0.0228
Batch 270, Loss: 0.0202
Batch 280, Loss: 0.0268
Batch 290, Loss: 0.0240
Batch 300, Loss: 0.0217
Batch 310, Loss: 0.0225
Batch 320, Loss: 0.0243
Batch 330, Loss: 0.0219
Batch 340, Loss: 0.0239
Batch 350, Loss: 0.0238
Batch 360, Loss: 0.0236
Batch 370, Loss: 0.0211
Batch 380, Loss: 0.0231
Batch 390, Loss: 0.0223
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.064658880233765 seconds
Epoch 194 accuracy: 79.63%
Batch 10, Loss: 0.0235
Batch 20, Loss: 0.0224
Batch 30, Loss: 0.0273
Batch 40, Loss: 0.0229
Batch 50, Loss: 0.0238
Batch 60, Loss: 0.0247
Batch 70, Loss: 0.0222
Batch 80, Loss: 0.0233
Batch 90, Loss: 0.0236
Batch 100, Loss: 0.0252
Batch 110, Loss: 0.0256
Batch 120, Loss: 0.0228
Batch 130, Loss: 0.0235
Batch 140, Loss: 0.0231
Batch 150, Loss: 0.0234
Batch 160, Loss: 0.0203
Batch 170, Loss: 0.0228
Batch 180, Loss: 0.0208
Batch 190, Loss: 0.0214
Batch 200, Loss: 0.0236
Batch 210, Loss: 0.0215
Batch 220, Loss: 0.0226
Batch 230, Loss: 0.0242
Batch 240, Loss: 0.0222
Batch 250, Loss: 0.0217
Batch 260, Loss: 0.0222
Batch 270, Loss: 0.0269
Batch 280, Loss: 0.0246
Batch 290, Loss: 0.0235
Batch 300, Loss: 0.0260
Batch 310, Loss: 0.0226
Batch 320, Loss: 0.0234
Batch 330, Loss: 0.0247
Batch 340, Loss: 0.0231
Batch 350, Loss: 0.0252
Batch 360, Loss: 0.0223
Batch 370, Loss: 0.0212
Batch 380, Loss: 0.0262
Batch 390, Loss: 0.0233
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 24.983031749725342 seconds
Epoch 195 accuracy: 79.39%
Batch 10, Loss: 0.0230
Batch 20, Loss: 0.0228
Batch 30, Loss: 0.0254
Batch 40, Loss: 0.0216
Batch 50, Loss: 0.0245
Batch 60, Loss: 0.0220
Batch 70, Loss: 0.0224
Batch 80, Loss: 0.0225
Batch 90, Loss: 0.0225
Batch 100, Loss: 0.0222
Batch 110, Loss: 0.0222
Batch 120, Loss: 0.0209
Batch 130, Loss: 0.0209
Batch 140, Loss: 0.0255
Batch 150, Loss: 0.0224
Batch 160, Loss: 0.0243
Batch 170, Loss: 0.0234
Batch 180, Loss: 0.0213
Batch 190, Loss: 0.0217
Batch 200, Loss: 0.0218
Batch 210, Loss: 0.0227
Batch 220, Loss: 0.0206
Batch 230, Loss: 0.0256
Batch 240, Loss: 0.0236
Batch 250, Loss: 0.0212
Batch 260, Loss: 0.0254
Batch 270, Loss: 0.0200
Batch 280, Loss: 0.0235
Batch 290, Loss: 0.0210
Batch 300, Loss: 0.0226
Batch 310, Loss: 0.0224
Batch 320, Loss: 0.0232
Batch 330, Loss: 0.0248
Batch 340, Loss: 0.0221
Batch 350, Loss: 0.0197
Batch 360, Loss: 0.0232
Batch 370, Loss: 0.0193
Batch 380, Loss: 0.0209
Batch 390, Loss: 0.0213
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 24.885122060775757 seconds
Epoch 196 accuracy: 79.48%
Batch 10, Loss: 0.0228
Batch 20, Loss: 0.0257
Batch 30, Loss: 0.0252
Batch 40, Loss: 0.0226
Batch 50, Loss: 0.0208
Batch 60, Loss: 0.0215
Batch 70, Loss: 0.0220
Batch 80, Loss: 0.0238
Batch 90, Loss: 0.0203
Batch 100, Loss: 0.0222
Batch 110, Loss: 0.0224
Batch 120, Loss: 0.0245
Batch 130, Loss: 0.0233
Batch 140, Loss: 0.0235
Batch 150, Loss: 0.0223
Batch 160, Loss: 0.0213
Batch 170, Loss: 0.0256
Batch 180, Loss: 0.0229
Batch 190, Loss: 0.0235
Batch 200, Loss: 0.0228
Batch 210, Loss: 0.0243
Batch 220, Loss: 0.0230
Batch 230, Loss: 0.0249
Batch 240, Loss: 0.0235
Batch 250, Loss: 0.0217
Batch 260, Loss: 0.0252
Batch 270, Loss: 0.0233
Batch 280, Loss: 0.0236
Batch 290, Loss: 0.0227
Batch 300, Loss: 0.0220
Batch 310, Loss: 0.0233
Batch 320, Loss: 0.0219
Batch 330, Loss: 0.0239
Batch 340, Loss: 0.0220
Batch 350, Loss: 0.0221
Batch 360, Loss: 0.0232
Batch 370, Loss: 0.0218
Batch 380, Loss: 0.0210
Batch 390, Loss: 0.0211
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 24.956522464752197 seconds
Epoch 197 accuracy: 79.57%
Batch 10, Loss: 0.0232
Batch 20, Loss: 0.0212
Batch 30, Loss: 0.0235
Batch 40, Loss: 0.0219
Batch 50, Loss: 0.0222
Batch 60, Loss: 0.0226
Batch 70, Loss: 0.0219
Batch 80, Loss: 0.0217
Batch 90, Loss: 0.0234
Batch 100, Loss: 0.0228
Batch 110, Loss: 0.0229
Batch 120, Loss: 0.0222
Batch 130, Loss: 0.0219
Batch 140, Loss: 0.0227
Batch 150, Loss: 0.0211
Batch 160, Loss: 0.0206
Batch 170, Loss: 0.0227
Batch 180, Loss: 0.0213
Batch 190, Loss: 0.0247
Batch 200, Loss: 0.0211
Batch 210, Loss: 0.0194
Batch 220, Loss: 0.0230
Batch 230, Loss: 0.0210
Batch 240, Loss: 0.0216
Batch 250, Loss: 0.0199
Batch 260, Loss: 0.0236
Batch 270, Loss: 0.0239
Batch 280, Loss: 0.0269
Batch 290, Loss: 0.0240
Batch 300, Loss: 0.0244
Batch 310, Loss: 0.0246
Batch 320, Loss: 0.0242
Batch 330, Loss: 0.0225
Batch 340, Loss: 0.0252
Batch 350, Loss: 0.0219
Batch 360, Loss: 0.0264
Batch 370, Loss: 0.0211
Batch 380, Loss: 0.0238
Batch 390, Loss: 0.0217
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 24.972798109054565 seconds
Epoch 198 accuracy: 79.48%
Batch 10, Loss: 0.0243
Batch 20, Loss: 0.0234
Batch 30, Loss: 0.0240
Batch 40, Loss: 0.0240
Batch 50, Loss: 0.0235
Batch 60, Loss: 0.0217
Batch 70, Loss: 0.0232
Batch 80, Loss: 0.0218
Batch 90, Loss: 0.0217
Batch 100, Loss: 0.0242
Batch 110, Loss: 0.0205
Batch 120, Loss: 0.0219
Batch 130, Loss: 0.0203
Batch 140, Loss: 0.0303
Batch 150, Loss: 0.0215
Batch 160, Loss: 0.0230
Batch 170, Loss: 0.0253
Batch 180, Loss: 0.0220
Batch 190, Loss: 0.0220
Batch 200, Loss: 0.0237
Batch 210, Loss: 0.0220
Batch 220, Loss: 0.0220
Batch 230, Loss: 0.0237
Batch 240, Loss: 0.0201
Batch 250, Loss: 0.0238
Batch 260, Loss: 0.0221
Batch 270, Loss: 0.0230
Batch 280, Loss: 0.0238
Batch 290, Loss: 0.0231
Batch 300, Loss: 0.0226
Batch 310, Loss: 0.0212
Batch 320, Loss: 0.0241
Batch 330, Loss: 0.0267
Batch 340, Loss: 0.0233
Batch 350, Loss: 0.0254
Batch 360, Loss: 0.0233
Batch 370, Loss: 0.0217
Batch 380, Loss: 0.0251
Batch 390, Loss: 0.0263
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 24.945763111114502 seconds
Epoch 199 accuracy: 79.38%
Batch 10, Loss: 0.0227
Batch 20, Loss: 0.0223
Batch 30, Loss: 0.0233
Batch 40, Loss: 0.0213
Batch 50, Loss: 0.0236
Batch 60, Loss: 0.0214
Batch 70, Loss: 0.0253
Batch 80, Loss: 0.0204
Batch 90, Loss: 0.0244
Batch 100, Loss: 0.0229
Batch 110, Loss: 0.0228
Batch 120, Loss: 0.0240
Batch 130, Loss: 0.0216
Batch 140, Loss: 0.0227
Batch 150, Loss: 0.0240
Batch 160, Loss: 0.0240
Batch 170, Loss: 0.0226
Batch 180, Loss: 0.0233
Batch 190, Loss: 0.0225
Batch 200, Loss: 0.0238
Batch 210, Loss: 0.0208
Batch 220, Loss: 0.0275
Batch 230, Loss: 0.0209
Batch 240, Loss: 0.0228
Batch 250, Loss: 0.0252
Batch 260, Loss: 0.0235
Batch 270, Loss: 0.0205
Batch 280, Loss: 0.0263
Batch 290, Loss: 0.0208
Batch 300, Loss: 0.0227
Batch 310, Loss: 0.0223
Batch 320, Loss: 0.0218
Batch 330, Loss: 0.0217
Batch 340, Loss: 0.0220
Batch 350, Loss: 0.0220
Batch 360, Loss: 0.0229
Batch 370, Loss: 0.0237
Batch 380, Loss: 0.0219
Batch 390, Loss: 0.0242
Epoch 200 learning rate: 0.0
Epoch 200 time: 24.90586519241333 seconds
Epoch 200 accuracy: 79.43%
Total training time: 5013.614190816879 seconds
