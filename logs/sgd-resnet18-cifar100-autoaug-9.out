The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.1463
Batch 20, Loss: 4.1228
Batch 30, Loss: 3.9630
Batch 40, Loss: 3.8860
Batch 50, Loss: 3.7782
Batch 60, Loss: 3.7569
Batch 70, Loss: 3.6849
Batch 80, Loss: 3.6726
Batch 90, Loss: 3.6264
Batch 100, Loss: 3.6500
Batch 110, Loss: 3.6396
Batch 120, Loss: 3.6004
Batch 130, Loss: 3.6261
Batch 140, Loss: 3.6753
Batch 150, Loss: 3.6265
Batch 160, Loss: 3.6137
Batch 170, Loss: 3.5871
Batch 180, Loss: 3.5631
Batch 190, Loss: 3.5932
Batch 200, Loss: 3.5650
Batch 210, Loss: 3.5365
Batch 220, Loss: 3.5123
Batch 230, Loss: 3.5006
Batch 240, Loss: 3.5144
Batch 250, Loss: 3.5211
Batch 260, Loss: 3.5195
Batch 270, Loss: 3.4830
Batch 280, Loss: 3.4698
Batch 290, Loss: 3.4859
Batch 300, Loss: 3.4772
Batch 310, Loss: 3.5062
Batch 320, Loss: 3.4587
Batch 330, Loss: 3.4673
Batch 340, Loss: 3.4383
Batch 350, Loss: 3.4543
Batch 360, Loss: 3.4220
Batch 370, Loss: 3.4749
Batch 380, Loss: 3.4288
Batch 390, Loss: 3.4552
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.5238094329834 seconds
Epoch 1 accuracy: 9.03%
Batch 10, Loss: 3.4434
Batch 20, Loss: 3.4578
Batch 30, Loss: 3.3903
Batch 40, Loss: 3.3799
Batch 50, Loss: 3.3834
Batch 60, Loss: 3.3503
Batch 70, Loss: 3.3382
Batch 80, Loss: 3.4033
Batch 90, Loss: 3.3703
Batch 100, Loss: 3.3524
Batch 110, Loss: 3.3827
Batch 120, Loss: 3.3426
Batch 130, Loss: 3.3872
Batch 140, Loss: 3.3394
Batch 150, Loss: 3.2956
Batch 160, Loss: 3.3180
Batch 170, Loss: 3.3271
Batch 180, Loss: 3.3666
Batch 190, Loss: 3.3236
Batch 200, Loss: 3.3179
Batch 210, Loss: 3.3078
Batch 220, Loss: 3.3142
Batch 230, Loss: 3.3455
Batch 240, Loss: 3.2861
Batch 250, Loss: 3.3081
Batch 260, Loss: 3.2425
Batch 270, Loss: 3.2411
Batch 280, Loss: 3.2586
Batch 290, Loss: 3.2372
Batch 300, Loss: 3.2568
Batch 310, Loss: 3.2395
Batch 320, Loss: 3.1730
Batch 330, Loss: 3.1905
Batch 340, Loss: 3.2181
Batch 350, Loss: 3.2610
Batch 360, Loss: 3.2105
Batch 370, Loss: 3.1974
Batch 380, Loss: 3.2003
Batch 390, Loss: 3.2424
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.227933406829834 seconds
Epoch 2 accuracy: 16.11%
Batch 10, Loss: 3.1858
Batch 20, Loss: 3.1484
Batch 30, Loss: 3.1090
Batch 40, Loss: 3.1205
Batch 50, Loss: 3.1254
Batch 60, Loss: 3.1470
Batch 70, Loss: 3.1198
Batch 80, Loss: 3.1473
Batch 90, Loss: 3.0969
Batch 100, Loss: 3.0769
Batch 110, Loss: 3.1214
Batch 120, Loss: 3.1709
Batch 130, Loss: 3.1096
Batch 140, Loss: 3.0684
Batch 150, Loss: 3.1358
Batch 160, Loss: 3.1034
Batch 170, Loss: 3.1030
Batch 180, Loss: 3.1107
Batch 190, Loss: 3.0351
Batch 200, Loss: 3.0995
Batch 210, Loss: 3.0378
Batch 220, Loss: 3.0639
Batch 230, Loss: 3.0446
Batch 240, Loss: 3.0468
Batch 250, Loss: 3.0340
Batch 260, Loss: 3.0850
Batch 270, Loss: 3.0185
Batch 280, Loss: 3.0604
Batch 290, Loss: 2.9861
Batch 300, Loss: 2.9969
Batch 310, Loss: 2.9962
Batch 320, Loss: 2.9891
Batch 330, Loss: 2.9414
Batch 340, Loss: 3.0076
Batch 350, Loss: 2.9668
Batch 360, Loss: 2.9724
Batch 370, Loss: 2.9547
Batch 380, Loss: 2.9306
Batch 390, Loss: 2.9488
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.246882915496826 seconds
Epoch 3 accuracy: 21.09%
Batch 10, Loss: 2.8754
Batch 20, Loss: 2.9097
Batch 30, Loss: 2.9245
Batch 40, Loss: 2.7790
Batch 50, Loss: 2.8945
Batch 60, Loss: 2.8585
Batch 70, Loss: 2.9639
Batch 80, Loss: 2.8565
Batch 90, Loss: 2.8713
Batch 100, Loss: 2.8108
Batch 110, Loss: 2.8264
Batch 120, Loss: 2.8259
Batch 130, Loss: 2.8741
Batch 140, Loss: 2.9054
Batch 150, Loss: 2.8016
Batch 160, Loss: 2.7952
Batch 170, Loss: 2.7742
Batch 180, Loss: 2.8033
Batch 190, Loss: 2.8069
Batch 200, Loss: 2.7295
Batch 210, Loss: 2.8268
Batch 220, Loss: 2.7705
Batch 230, Loss: 2.7490
Batch 240, Loss: 2.7857
Batch 250, Loss: 2.7694
Batch 260, Loss: 2.7609
Batch 270, Loss: 2.7443
Batch 280, Loss: 2.7118
Batch 290, Loss: 2.6992
Batch 300, Loss: 2.7038
Batch 310, Loss: 2.7940
Batch 320, Loss: 2.7282
Batch 330, Loss: 2.7554
Batch 340, Loss: 2.7222
Batch 350, Loss: 2.7059
Batch 360, Loss: 2.7374
Batch 370, Loss: 2.6859
Batch 380, Loss: 2.6199
Batch 390, Loss: 2.6782
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.13280487060547 seconds
Epoch 4 accuracy: 24.8%
Batch 10, Loss: 2.5724
Batch 20, Loss: 2.6538
Batch 30, Loss: 2.6034
Batch 40, Loss: 2.7125
Batch 50, Loss: 2.6020
Batch 60, Loss: 2.6599
Batch 70, Loss: 2.6183
Batch 80, Loss: 2.6344
Batch 90, Loss: 2.4925
Batch 100, Loss: 2.6527
Batch 110, Loss: 2.6249
Batch 120, Loss: 2.6731
Batch 130, Loss: 2.5839
Batch 140, Loss: 2.5187
Batch 150, Loss: 2.5213
Batch 160, Loss: 2.5679
Batch 170, Loss: 2.5050
Batch 180, Loss: 2.5612
Batch 190, Loss: 2.6051
Batch 200, Loss: 2.5505
Batch 210, Loss: 2.6271
Batch 220, Loss: 2.5545
Batch 230, Loss: 2.5098
Batch 240, Loss: 2.5430
Batch 250, Loss: 2.4873
Batch 260, Loss: 2.5195
Batch 270, Loss: 2.5244
Batch 280, Loss: 2.5314
Batch 290, Loss: 2.4694
Batch 300, Loss: 2.5428
Batch 310, Loss: 2.5453
Batch 320, Loss: 2.5260
Batch 330, Loss: 2.4427
Batch 340, Loss: 2.4155
Batch 350, Loss: 2.4917
Batch 360, Loss: 2.5209
Batch 370, Loss: 2.5223
Batch 380, Loss: 2.5524
Batch 390, Loss: 2.5665
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.19507360458374 seconds
Epoch 5 accuracy: 33.28%
Batch 10, Loss: 2.4482
Batch 20, Loss: 2.4488
Batch 30, Loss: 2.4491
Batch 40, Loss: 2.4110
Batch 50, Loss: 2.4162
Batch 60, Loss: 2.4335
Batch 70, Loss: 2.4355
Batch 80, Loss: 2.4363
Batch 90, Loss: 2.3187
Batch 100, Loss: 2.3962
Batch 110, Loss: 2.3138
Batch 120, Loss: 2.3685
Batch 130, Loss: 2.3406
Batch 140, Loss: 2.3463
Batch 150, Loss: 2.3651
Batch 160, Loss: 2.3965
Batch 170, Loss: 2.3287
Batch 180, Loss: 2.3258
Batch 190, Loss: 2.3411
Batch 200, Loss: 2.3132
Batch 210, Loss: 2.3436
Batch 220, Loss: 2.3300
Batch 230, Loss: 2.3419
Batch 240, Loss: 2.3362
Batch 250, Loss: 2.3845
Batch 260, Loss: 2.3939
Batch 270, Loss: 2.3497
Batch 280, Loss: 2.2899
Batch 290, Loss: 2.3011
Batch 300, Loss: 2.3400
Batch 310, Loss: 2.3092
Batch 320, Loss: 2.3406
Batch 330, Loss: 2.3457
Batch 340, Loss: 2.3536
Batch 350, Loss: 2.3449
Batch 360, Loss: 2.3282
Batch 370, Loss: 2.3435
Batch 380, Loss: 2.2804
Batch 390, Loss: 2.3199
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.164408445358276 seconds
Epoch 6 accuracy: 34.03%
Batch 10, Loss: 2.2272
Batch 20, Loss: 2.3319
Batch 30, Loss: 2.3208
Batch 40, Loss: 2.2244
Batch 50, Loss: 2.2805
Batch 60, Loss: 2.2100
Batch 70, Loss: 2.2318
Batch 80, Loss: 2.2492
Batch 90, Loss: 2.2086
Batch 100, Loss: 2.2166
Batch 110, Loss: 2.2518
Batch 120, Loss: 2.1710
Batch 130, Loss: 2.2342
Batch 140, Loss: 2.2352
Batch 150, Loss: 2.2819
Batch 160, Loss: 2.2421
Batch 170, Loss: 2.2843
Batch 180, Loss: 2.2065
Batch 190, Loss: 2.1970
Batch 200, Loss: 2.1824
Batch 210, Loss: 2.2175
Batch 220, Loss: 2.1566
Batch 230, Loss: 2.2919
Batch 240, Loss: 2.2533
Batch 250, Loss: 2.2042
Batch 260, Loss: 2.2289
Batch 270, Loss: 2.1437
Batch 280, Loss: 2.1755
Batch 290, Loss: 2.2004
Batch 300, Loss: 2.1757
Batch 310, Loss: 2.1569
Batch 320, Loss: 2.1341
Batch 330, Loss: 2.1821
Batch 340, Loss: 2.2002
Batch 350, Loss: 2.2038
Batch 360, Loss: 2.1435
Batch 370, Loss: 2.1537
Batch 380, Loss: 2.1477
Batch 390, Loss: 2.1503
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.08359670639038 seconds
Epoch 7 accuracy: 35.85%
Batch 10, Loss: 2.1907
Batch 20, Loss: 2.1331
Batch 30, Loss: 2.0831
Batch 40, Loss: 2.1355
Batch 50, Loss: 2.0862
Batch 60, Loss: 2.0938
Batch 70, Loss: 2.1797
Batch 80, Loss: 2.0172
Batch 90, Loss: 2.1067
Batch 100, Loss: 2.1290
Batch 110, Loss: 2.1773
Batch 120, Loss: 2.1052
Batch 130, Loss: 2.0427
Batch 140, Loss: 2.1408
Batch 150, Loss: 2.0814
Batch 160, Loss: 2.0137
Batch 170, Loss: 2.0450
Batch 180, Loss: 2.1132
Batch 190, Loss: 2.0990
Batch 200, Loss: 2.1196
Batch 210, Loss: 2.0488
Batch 220, Loss: 2.0859
Batch 230, Loss: 1.9945
Batch 240, Loss: 2.0937
Batch 250, Loss: 2.1018
Batch 260, Loss: 2.0824
Batch 270, Loss: 2.0862
Batch 280, Loss: 2.1656
Batch 290, Loss: 2.0974
Batch 300, Loss: 2.1377
Batch 310, Loss: 2.0728
Batch 320, Loss: 2.0976
Batch 330, Loss: 2.0323
Batch 340, Loss: 2.0713
Batch 350, Loss: 2.0860
Batch 360, Loss: 2.0149
Batch 370, Loss: 2.1069
Batch 380, Loss: 2.0464
Batch 390, Loss: 2.0540
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.117711305618286 seconds
Epoch 8 accuracy: 43.37%
Batch 10, Loss: 2.0012
Batch 20, Loss: 1.9845
Batch 30, Loss: 2.0377
Batch 40, Loss: 2.0384
Batch 50, Loss: 2.0480
Batch 60, Loss: 1.9986
Batch 70, Loss: 2.0239
Batch 80, Loss: 2.0472
Batch 90, Loss: 2.0343
Batch 100, Loss: 2.1016
Batch 110, Loss: 2.0316
Batch 120, Loss: 1.9568
Batch 130, Loss: 1.9747
Batch 140, Loss: 1.9905
Batch 150, Loss: 2.0182
Batch 160, Loss: 2.0239
Batch 170, Loss: 2.0442
Batch 180, Loss: 2.0333
Batch 190, Loss: 1.9255
Batch 200, Loss: 1.9912
Batch 210, Loss: 2.0168
Batch 220, Loss: 2.0280
Batch 230, Loss: 1.9801
Batch 240, Loss: 2.0072
Batch 250, Loss: 1.9506
Batch 260, Loss: 1.9867
Batch 270, Loss: 2.0237
Batch 280, Loss: 1.9820
Batch 290, Loss: 1.9853
Batch 300, Loss: 1.9721
Batch 310, Loss: 1.9652
Batch 320, Loss: 2.0597
Batch 330, Loss: 2.0296
Batch 340, Loss: 1.9260
Batch 350, Loss: 1.9676
Batch 360, Loss: 2.0086
Batch 370, Loss: 1.9941
Batch 380, Loss: 1.9765
Batch 390, Loss: 2.0327
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.232099771499634 seconds
Epoch 9 accuracy: 47.14%
Batch 10, Loss: 1.8938
Batch 20, Loss: 1.9447
Batch 30, Loss: 1.8064
Batch 40, Loss: 1.8269
Batch 50, Loss: 1.8677
Batch 60, Loss: 1.8970
Batch 70, Loss: 1.9121
Batch 80, Loss: 1.9679
Batch 90, Loss: 1.9180
Batch 100, Loss: 1.8940
Batch 110, Loss: 1.9802
Batch 120, Loss: 1.9486
Batch 130, Loss: 1.8925
Batch 140, Loss: 1.9233
Batch 150, Loss: 1.9558
Batch 160, Loss: 1.9029
Batch 170, Loss: 1.8770
Batch 180, Loss: 1.9238
Batch 190, Loss: 1.9060
Batch 200, Loss: 1.9736
Batch 210, Loss: 1.9534
Batch 220, Loss: 1.9239
Batch 230, Loss: 1.9273
Batch 240, Loss: 2.0000
Batch 250, Loss: 1.9292
Batch 260, Loss: 1.9123
Batch 270, Loss: 1.9547
Batch 280, Loss: 1.9295
Batch 290, Loss: 1.9203
Batch 300, Loss: 1.8942
Batch 310, Loss: 1.9508
Batch 320, Loss: 1.9508
Batch 330, Loss: 1.8800
Batch 340, Loss: 1.9502
Batch 350, Loss: 1.9367
Batch 360, Loss: 1.9717
Batch 370, Loss: 1.8857
Batch 380, Loss: 1.9469
Batch 390, Loss: 1.9759
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.1655375957489 seconds
Epoch 10 accuracy: 43.35%
Batch 10, Loss: 1.9029
Batch 20, Loss: 1.9011
Batch 30, Loss: 1.8619
Batch 40, Loss: 1.8381
Batch 50, Loss: 1.8730
Batch 60, Loss: 1.8080
Batch 70, Loss: 1.8759
Batch 80, Loss: 1.9119
Batch 90, Loss: 1.8881
Batch 100, Loss: 1.8699
Batch 110, Loss: 1.8592
Batch 120, Loss: 1.8800
Batch 130, Loss: 1.8482
Batch 140, Loss: 1.8534
Batch 150, Loss: 1.8741
Batch 160, Loss: 1.8408
Batch 170, Loss: 1.9150
Batch 180, Loss: 1.8769
Batch 190, Loss: 1.8565
Batch 200, Loss: 1.8463
Batch 210, Loss: 1.8760
Batch 220, Loss: 1.8364
Batch 230, Loss: 1.8509
Batch 240, Loss: 1.8365
Batch 250, Loss: 1.8582
Batch 260, Loss: 1.8475
Batch 270, Loss: 1.8809
Batch 280, Loss: 1.8720
Batch 290, Loss: 1.8293
Batch 300, Loss: 1.8737
Batch 310, Loss: 1.8991
Batch 320, Loss: 1.8584
Batch 330, Loss: 1.8493
Batch 340, Loss: 1.8134
Batch 350, Loss: 1.8051
Batch 360, Loss: 1.8672
Batch 370, Loss: 1.8144
Batch 380, Loss: 1.8205
Batch 390, Loss: 1.9132
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.127363204956055 seconds
Epoch 11 accuracy: 48.79%
Batch 10, Loss: 1.7992
Batch 20, Loss: 1.8553
Batch 30, Loss: 1.8953
Batch 40, Loss: 1.8540
Batch 50, Loss: 1.8004
Batch 60, Loss: 1.8396
Batch 70, Loss: 1.8383
Batch 80, Loss: 1.8520
Batch 90, Loss: 1.8414
Batch 100, Loss: 1.8075
Batch 110, Loss: 1.8809
Batch 120, Loss: 1.8195
Batch 130, Loss: 1.7657
Batch 140, Loss: 1.7963
Batch 150, Loss: 1.7693
Batch 160, Loss: 1.7676
Batch 170, Loss: 1.7536
Batch 180, Loss: 1.7834
Batch 190, Loss: 1.8728
Batch 200, Loss: 1.8122
Batch 210, Loss: 1.7952
Batch 220, Loss: 1.8493
Batch 230, Loss: 1.8701
Batch 240, Loss: 1.8289
Batch 250, Loss: 1.8254
Batch 260, Loss: 1.8231
Batch 270, Loss: 1.7978
Batch 280, Loss: 1.8039
Batch 290, Loss: 1.8339
Batch 300, Loss: 1.7715
Batch 310, Loss: 1.7921
Batch 320, Loss: 1.7612
Batch 330, Loss: 1.8255
Batch 340, Loss: 1.8433
Batch 350, Loss: 1.8081
Batch 360, Loss: 1.9067
Batch 370, Loss: 1.7990
Batch 380, Loss: 1.8554
Batch 390, Loss: 1.8412
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.101930141448975 seconds
Epoch 12 accuracy: 50.25%
Batch 10, Loss: 1.7460
Batch 20, Loss: 1.7943
Batch 30, Loss: 1.7770
Batch 40, Loss: 1.8476
Batch 50, Loss: 1.7239
Batch 60, Loss: 1.7236
Batch 70, Loss: 1.7603
Batch 80, Loss: 1.7430
Batch 90, Loss: 1.7248
Batch 100, Loss: 1.7897
Batch 110, Loss: 1.7667
Batch 120, Loss: 1.8539
Batch 130, Loss: 1.8253
Batch 140, Loss: 1.7470
Batch 150, Loss: 1.8111
Batch 160, Loss: 1.7146
Batch 170, Loss: 1.7130
Batch 180, Loss: 1.7310
Batch 190, Loss: 1.7742
Batch 200, Loss: 1.8476
Batch 210, Loss: 1.8440
Batch 220, Loss: 1.7532
Batch 230, Loss: 1.7771
Batch 240, Loss: 1.8135
Batch 250, Loss: 1.7370
Batch 260, Loss: 1.8238
Batch 270, Loss: 1.7562
Batch 280, Loss: 1.8245
Batch 290, Loss: 1.8632
Batch 300, Loss: 1.7428
Batch 310, Loss: 1.8848
Batch 320, Loss: 1.7429
Batch 330, Loss: 1.7619
Batch 340, Loss: 1.7657
Batch 350, Loss: 1.8281
Batch 360, Loss: 1.8473
Batch 370, Loss: 1.7272
Batch 380, Loss: 1.8403
Batch 390, Loss: 1.8194
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.13901686668396 seconds
Epoch 13 accuracy: 46.65%
Batch 10, Loss: 1.7561
Batch 20, Loss: 1.6972
Batch 30, Loss: 1.7391
Batch 40, Loss: 1.7268
Batch 50, Loss: 1.7462
Batch 60, Loss: 1.7404
Batch 70, Loss: 1.7396
Batch 80, Loss: 1.7574
Batch 90, Loss: 1.7729
Batch 100, Loss: 1.7550
Batch 110, Loss: 1.7287
Batch 120, Loss: 1.7262
Batch 130, Loss: 1.8282
Batch 140, Loss: 1.7878
Batch 150, Loss: 1.7559
Batch 160, Loss: 1.7630
Batch 170, Loss: 1.7146
Batch 180, Loss: 1.8143
Batch 190, Loss: 1.7557
Batch 200, Loss: 1.7397
Batch 210, Loss: 1.7502
Batch 220, Loss: 1.7982
Batch 230, Loss: 1.7468
Batch 240, Loss: 1.6973
Batch 250, Loss: 1.7043
Batch 260, Loss: 1.7252
Batch 270, Loss: 1.7184
Batch 280, Loss: 1.8089
Batch 290, Loss: 1.7494
Batch 300, Loss: 1.7025
Batch 310, Loss: 1.6805
Batch 320, Loss: 1.7877
Batch 330, Loss: 1.7252
Batch 340, Loss: 1.7035
Batch 350, Loss: 1.8083
Batch 360, Loss: 1.7793
Batch 370, Loss: 1.7976
Batch 380, Loss: 1.7252
Batch 390, Loss: 1.7692
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.038246870040894 seconds
Epoch 14 accuracy: 51.15%
Batch 10, Loss: 1.7551
Batch 20, Loss: 1.7379
Batch 30, Loss: 1.6734
Batch 40, Loss: 1.7406
Batch 50, Loss: 1.7502
Batch 60, Loss: 1.7098
Batch 70, Loss: 1.7055
Batch 80, Loss: 1.6977
Batch 90, Loss: 1.7132
Batch 100, Loss: 1.7226
Batch 110, Loss: 1.6643
Batch 120, Loss: 1.7168
Batch 130, Loss: 1.7461
Batch 140, Loss: 1.7048
Batch 150, Loss: 1.7724
Batch 160, Loss: 1.6644
Batch 170, Loss: 1.6935
Batch 180, Loss: 1.7485
Batch 190, Loss: 1.7399
Batch 200, Loss: 1.7519
Batch 210, Loss: 1.7129
Batch 220, Loss: 1.7189
Batch 230, Loss: 1.7504
Batch 240, Loss: 1.6881
Batch 250, Loss: 1.6873
Batch 260, Loss: 1.7447
Batch 270, Loss: 1.7569
Batch 280, Loss: 1.7769
Batch 290, Loss: 1.8020
Batch 300, Loss: 1.7923
Batch 310, Loss: 1.6822
Batch 320, Loss: 1.6803
Batch 330, Loss: 1.7373
Batch 340, Loss: 1.7087
Batch 350, Loss: 1.7474
Batch 360, Loss: 1.6844
Batch 370, Loss: 1.7365
Batch 380, Loss: 1.7492
Batch 390, Loss: 1.7747
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.088380098342896 seconds
Epoch 15 accuracy: 50.32%
Batch 10, Loss: 1.6878
Batch 20, Loss: 1.6188
Batch 30, Loss: 1.7042
Batch 40, Loss: 1.7007
Batch 50, Loss: 1.6536
Batch 60, Loss: 1.6464
Batch 70, Loss: 1.6757
Batch 80, Loss: 1.6768
Batch 90, Loss: 1.7237
Batch 100, Loss: 1.6912
Batch 110, Loss: 1.7049
Batch 120, Loss: 1.6515
Batch 130, Loss: 1.7391
Batch 140, Loss: 1.7495
Batch 150, Loss: 1.6963
Batch 160, Loss: 1.7500
Batch 170, Loss: 1.7749
Batch 180, Loss: 1.6569
Batch 190, Loss: 1.6805
Batch 200, Loss: 1.7195
Batch 210, Loss: 1.7117
Batch 220, Loss: 1.7071
Batch 230, Loss: 1.6570
Batch 240, Loss: 1.7964
Batch 250, Loss: 1.7053
Batch 260, Loss: 1.6935
Batch 270, Loss: 1.7389
Batch 280, Loss: 1.7302
Batch 290, Loss: 1.6943
Batch 300, Loss: 1.7338
Batch 310, Loss: 1.7414
Batch 320, Loss: 1.6809
Batch 330, Loss: 1.6658
Batch 340, Loss: 1.6456
Batch 350, Loss: 1.6915
Batch 360, Loss: 1.7019
Batch 370, Loss: 1.6882
Batch 380, Loss: 1.6991
Batch 390, Loss: 1.7993
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.241779565811157 seconds
Epoch 16 accuracy: 53.33%
Batch 10, Loss: 1.6248
Batch 20, Loss: 1.6677
Batch 30, Loss: 1.5830
Batch 40, Loss: 1.6104
Batch 50, Loss: 1.7258
Batch 60, Loss: 1.6771
Batch 70, Loss: 1.7143
Batch 80, Loss: 1.6265
Batch 90, Loss: 1.6376
Batch 100, Loss: 1.7131
Batch 110, Loss: 1.6702
Batch 120, Loss: 1.7361
Batch 130, Loss: 1.7412
Batch 140, Loss: 1.7001
Batch 150, Loss: 1.7006
Batch 160, Loss: 1.6453
Batch 170, Loss: 1.6896
Batch 180, Loss: 1.6405
Batch 190, Loss: 1.6496
Batch 200, Loss: 1.6137
Batch 210, Loss: 1.6968
Batch 220, Loss: 1.6413
Batch 230, Loss: 1.8333
Batch 240, Loss: 1.7173
Batch 250, Loss: 1.6840
Batch 260, Loss: 1.6426
Batch 270, Loss: 1.6294
Batch 280, Loss: 1.6540
Batch 290, Loss: 1.7071
Batch 300, Loss: 1.7385
Batch 310, Loss: 1.6610
Batch 320, Loss: 1.7214
Batch 330, Loss: 1.6577
Batch 340, Loss: 1.6776
Batch 350, Loss: 1.6292
Batch 360, Loss: 1.6794
Batch 370, Loss: 1.6164
Batch 380, Loss: 1.6596
Batch 390, Loss: 1.7286
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.15959095954895 seconds
Epoch 17 accuracy: 49.08%
Batch 10, Loss: 1.6165
Batch 20, Loss: 1.6693
Batch 30, Loss: 1.5799
Batch 40, Loss: 1.6433
Batch 50, Loss: 1.6635
Batch 60, Loss: 1.6494
Batch 70, Loss: 1.6636
Batch 80, Loss: 1.7055
Batch 90, Loss: 1.6536
Batch 100, Loss: 1.6764
Batch 110, Loss: 1.6199
Batch 120, Loss: 1.6254
Batch 130, Loss: 1.6388
Batch 140, Loss: 1.6240
Batch 150, Loss: 1.6400
Batch 160, Loss: 1.6078
Batch 170, Loss: 1.6113
Batch 180, Loss: 1.7433
Batch 190, Loss: 1.6523
Batch 200, Loss: 1.5967
Batch 210, Loss: 1.6046
Batch 220, Loss: 1.6707
Batch 230, Loss: 1.6619
Batch 240, Loss: 1.7281
Batch 250, Loss: 1.6591
Batch 260, Loss: 1.6648
Batch 270, Loss: 1.6179
Batch 280, Loss: 1.7100
Batch 290, Loss: 1.6356
Batch 300, Loss: 1.7140
Batch 310, Loss: 1.6822
Batch 320, Loss: 1.6094
Batch 330, Loss: 1.6407
Batch 340, Loss: 1.6174
Batch 350, Loss: 1.6713
Batch 360, Loss: 1.6620
Batch 370, Loss: 1.5997
Batch 380, Loss: 1.6847
Batch 390, Loss: 1.6708
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.062268257141113 seconds
Epoch 18 accuracy: 53.23%
Batch 10, Loss: 1.5965
Batch 20, Loss: 1.5867
Batch 30, Loss: 1.6006
Batch 40, Loss: 1.6341
Batch 50, Loss: 1.6085
Batch 60, Loss: 1.5533
Batch 70, Loss: 1.5432
Batch 80, Loss: 1.6636
Batch 90, Loss: 1.6670
Batch 100, Loss: 1.6544
Batch 110, Loss: 1.6190
Batch 120, Loss: 1.6271
Batch 130, Loss: 1.6645
Batch 140, Loss: 1.7141
Batch 150, Loss: 1.7662
Batch 160, Loss: 1.6723
Batch 170, Loss: 1.6458
Batch 180, Loss: 1.6197
Batch 190, Loss: 1.6550
Batch 200, Loss: 1.6321
Batch 210, Loss: 1.6699
Batch 220, Loss: 1.6081
Batch 230, Loss: 1.6267
Batch 240, Loss: 1.6600
Batch 250, Loss: 1.6546
Batch 260, Loss: 1.6267
Batch 270, Loss: 1.6096
Batch 280, Loss: 1.6826
Batch 290, Loss: 1.6582
Batch 300, Loss: 1.6503
Batch 310, Loss: 1.6661
Batch 320, Loss: 1.6357
Batch 330, Loss: 1.6706
Batch 340, Loss: 1.6376
Batch 350, Loss: 1.6201
Batch 360, Loss: 1.6781
Batch 370, Loss: 1.7032
Batch 380, Loss: 1.6878
Batch 390, Loss: 1.6558
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.122650384902954 seconds
Epoch 19 accuracy: 54.91%
Batch 10, Loss: 1.5381
Batch 20, Loss: 1.6175
Batch 30, Loss: 1.5745
Batch 40, Loss: 1.5557
Batch 50, Loss: 1.5834
Batch 60, Loss: 1.5749
Batch 70, Loss: 1.5590
Batch 80, Loss: 1.5758
Batch 90, Loss: 1.6198
Batch 100, Loss: 1.5974
Batch 110, Loss: 1.6571
Batch 120, Loss: 1.6057
Batch 130, Loss: 1.6693
Batch 140, Loss: 1.5660
Batch 150, Loss: 1.6494
Batch 160, Loss: 1.6089
Batch 170, Loss: 1.5824
Batch 180, Loss: 1.5935
Batch 190, Loss: 1.6434
Batch 200, Loss: 1.6616
Batch 210, Loss: 1.6427
Batch 220, Loss: 1.5420
Batch 230, Loss: 1.6155
Batch 240, Loss: 1.6632
Batch 250, Loss: 1.7011
Batch 260, Loss: 1.6058
Batch 270, Loss: 1.6147
Batch 280, Loss: 1.6754
Batch 290, Loss: 1.6562
Batch 300, Loss: 1.6384
Batch 310, Loss: 1.7011
Batch 320, Loss: 1.6590
Batch 330, Loss: 1.6619
Batch 340, Loss: 1.6363
Batch 350, Loss: 1.6077
Batch 360, Loss: 1.6730
Batch 370, Loss: 1.6150
Batch 380, Loss: 1.6728
Batch 390, Loss: 1.6267
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.111786127090454 seconds
Epoch 20 accuracy: 53.92%
Batch 10, Loss: 1.5744
Batch 20, Loss: 1.4967
Batch 30, Loss: 1.5761
Batch 40, Loss: 1.5722
Batch 50, Loss: 1.6018
Batch 60, Loss: 1.5934
Batch 70, Loss: 1.5274
Batch 80, Loss: 1.5858
Batch 90, Loss: 1.6401
Batch 100, Loss: 1.6280
Batch 110, Loss: 1.6129
Batch 120, Loss: 1.6100
Batch 130, Loss: 1.5876
Batch 140, Loss: 1.6642
Batch 150, Loss: 1.6127
Batch 160, Loss: 1.5850
Batch 170, Loss: 1.6438
Batch 180, Loss: 1.6208
Batch 190, Loss: 1.6546
Batch 200, Loss: 1.6037
Batch 210, Loss: 1.6035
Batch 220, Loss: 1.6463
Batch 230, Loss: 1.6204
Batch 240, Loss: 1.6031
Batch 250, Loss: 1.5343
Batch 260, Loss: 1.5570
Batch 270, Loss: 1.6053
Batch 280, Loss: 1.6552
Batch 290, Loss: 1.6065
Batch 300, Loss: 1.6911
Batch 310, Loss: 1.6224
Batch 320, Loss: 1.6763
Batch 330, Loss: 1.6720
Batch 340, Loss: 1.6170
Batch 350, Loss: 1.5131
Batch 360, Loss: 1.5910
Batch 370, Loss: 1.6180
Batch 380, Loss: 1.6662
Batch 390, Loss: 1.6362
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.159944534301758 seconds
Epoch 21 accuracy: 54.06%
Batch 10, Loss: 1.5348
Batch 20, Loss: 1.5798
Batch 30, Loss: 1.5854
Batch 40, Loss: 1.6092
Batch 50, Loss: 1.5936
Batch 60, Loss: 1.5946
Batch 70, Loss: 1.5733
Batch 80, Loss: 1.5241
Batch 90, Loss: 1.5593
Batch 100, Loss: 1.6869
Batch 110, Loss: 1.5386
Batch 120, Loss: 1.6014
Batch 130, Loss: 1.6069
Batch 140, Loss: 1.5325
Batch 150, Loss: 1.5914
Batch 160, Loss: 1.5986
Batch 170, Loss: 1.5693
Batch 180, Loss: 1.6772
Batch 190, Loss: 1.5758
Batch 200, Loss: 1.6589
Batch 210, Loss: 1.6160
Batch 220, Loss: 1.6237
Batch 230, Loss: 1.6358
Batch 240, Loss: 1.5850
Batch 250, Loss: 1.6813
Batch 260, Loss: 1.6451
Batch 270, Loss: 1.6165
Batch 280, Loss: 1.5467
Batch 290, Loss: 1.5880
Batch 300, Loss: 1.5883
Batch 310, Loss: 1.6044
Batch 320, Loss: 1.6491
Batch 330, Loss: 1.6402
Batch 340, Loss: 1.5850
Batch 350, Loss: 1.5588
Batch 360, Loss: 1.6192
Batch 370, Loss: 1.5974
Batch 380, Loss: 1.5898
Batch 390, Loss: 1.6101
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.07724952697754 seconds
Epoch 22 accuracy: 53.68%
Batch 10, Loss: 1.5519
Batch 20, Loss: 1.6216
Batch 30, Loss: 1.4930
Batch 40, Loss: 1.5650
Batch 50, Loss: 1.5382
Batch 60, Loss: 1.5429
Batch 70, Loss: 1.6173
Batch 80, Loss: 1.5970
Batch 90, Loss: 1.5403
Batch 100, Loss: 1.5098
Batch 110, Loss: 1.5614
Batch 120, Loss: 1.5792
Batch 130, Loss: 1.6389
Batch 140, Loss: 1.6359
Batch 150, Loss: 1.5788
Batch 160, Loss: 1.6155
Batch 170, Loss: 1.5712
Batch 180, Loss: 1.5346
Batch 190, Loss: 1.5701
Batch 200, Loss: 1.6013
Batch 210, Loss: 1.5932
Batch 220, Loss: 1.6341
Batch 230, Loss: 1.5574
Batch 240, Loss: 1.5727
Batch 250, Loss: 1.6674
Batch 260, Loss: 1.6606
Batch 270, Loss: 1.5843
Batch 280, Loss: 1.5806
Batch 290, Loss: 1.5621
Batch 300, Loss: 1.5772
Batch 310, Loss: 1.6064
Batch 320, Loss: 1.5956
Batch 330, Loss: 1.5897
Batch 340, Loss: 1.6493
Batch 350, Loss: 1.5561
Batch 360, Loss: 1.5716
Batch 370, Loss: 1.5792
Batch 380, Loss: 1.6817
Batch 390, Loss: 1.6312
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.088284015655518 seconds
Epoch 23 accuracy: 56.3%
Batch 10, Loss: 1.5736
Batch 20, Loss: 1.5661
Batch 30, Loss: 1.5351
Batch 40, Loss: 1.5887
Batch 50, Loss: 1.5171
Batch 60, Loss: 1.5773
Batch 70, Loss: 1.5162
Batch 80, Loss: 1.5383
Batch 90, Loss: 1.5179
Batch 100, Loss: 1.5789
Batch 110, Loss: 1.6697
Batch 120, Loss: 1.5330
Batch 130, Loss: 1.5243
Batch 140, Loss: 1.5686
Batch 150, Loss: 1.5771
Batch 160, Loss: 1.5372
Batch 170, Loss: 1.6105
Batch 180, Loss: 1.6141
Batch 190, Loss: 1.6393
Batch 200, Loss: 1.6277
Batch 210, Loss: 1.5380
Batch 220, Loss: 1.5720
Batch 230, Loss: 1.5723
Batch 240, Loss: 1.5910
Batch 250, Loss: 1.5437
Batch 260, Loss: 1.5740
Batch 270, Loss: 1.5663
Batch 280, Loss: 1.6489
Batch 290, Loss: 1.5608
Batch 300, Loss: 1.6126
Batch 310, Loss: 1.5563
Batch 320, Loss: 1.6332
Batch 330, Loss: 1.6182
Batch 340, Loss: 1.6149
Batch 350, Loss: 1.5878
Batch 360, Loss: 1.5484
Batch 370, Loss: 1.5743
Batch 380, Loss: 1.6131
Batch 390, Loss: 1.5659
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.106420516967773 seconds
Epoch 24 accuracy: 56.0%
Batch 10, Loss: 1.5360
Batch 20, Loss: 1.5458
Batch 30, Loss: 1.5356
Batch 40, Loss: 1.4984
Batch 50, Loss: 1.6076
Batch 60, Loss: 1.5844
Batch 70, Loss: 1.6062
Batch 80, Loss: 1.5724
Batch 90, Loss: 1.5723
Batch 100, Loss: 1.5599
Batch 110, Loss: 1.5416
Batch 120, Loss: 1.5672
Batch 130, Loss: 1.5577
Batch 140, Loss: 1.5450
Batch 150, Loss: 1.6023
Batch 160, Loss: 1.5461
Batch 170, Loss: 1.5545
Batch 180, Loss: 1.6043
Batch 190, Loss: 1.4943
Batch 200, Loss: 1.6063
Batch 210, Loss: 1.5542
Batch 220, Loss: 1.5979
Batch 230, Loss: 1.5576
Batch 240, Loss: 1.5433
Batch 250, Loss: 1.5898
Batch 260, Loss: 1.5378
Batch 270, Loss: 1.6222
Batch 280, Loss: 1.5446
Batch 290, Loss: 1.6016
Batch 300, Loss: 1.6337
Batch 310, Loss: 1.5823
Batch 320, Loss: 1.5267
Batch 330, Loss: 1.5831
Batch 340, Loss: 1.6020
Batch 350, Loss: 1.5651
Batch 360, Loss: 1.6236
Batch 370, Loss: 1.5691
Batch 380, Loss: 1.5523
Batch 390, Loss: 1.6274
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.11110258102417 seconds
Epoch 25 accuracy: 53.54%
Batch 10, Loss: 1.5172
Batch 20, Loss: 1.5387
Batch 30, Loss: 1.5080
Batch 40, Loss: 1.5196
Batch 50, Loss: 1.4693
Batch 60, Loss: 1.5214
Batch 70, Loss: 1.4811
Batch 80, Loss: 1.5135
Batch 90, Loss: 1.5975
Batch 100, Loss: 1.5555
Batch 110, Loss: 1.5247
Batch 120, Loss: 1.5839
Batch 130, Loss: 1.5422
Batch 140, Loss: 1.5405
Batch 150, Loss: 1.5789
Batch 160, Loss: 1.5197
Batch 170, Loss: 1.5211
Batch 180, Loss: 1.6189
Batch 190, Loss: 1.6356
Batch 200, Loss: 1.6613
Batch 210, Loss: 1.6116
Batch 220, Loss: 1.6327
Batch 230, Loss: 1.5407
Batch 240, Loss: 1.5944
Batch 250, Loss: 1.5607
Batch 260, Loss: 1.5524
Batch 270, Loss: 1.5900
Batch 280, Loss: 1.4955
Batch 290, Loss: 1.5515
Batch 300, Loss: 1.5645
Batch 310, Loss: 1.5449
Batch 320, Loss: 1.6017
Batch 330, Loss: 1.6240
Batch 340, Loss: 1.6090
Batch 350, Loss: 1.5254
Batch 360, Loss: 1.5800
Batch 370, Loss: 1.5432
Batch 380, Loss: 1.5908
Batch 390, Loss: 1.6127
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.145158052444458 seconds
Epoch 26 accuracy: 54.25%
Batch 10, Loss: 1.5540
Batch 20, Loss: 1.5487
Batch 30, Loss: 1.5431
Batch 40, Loss: 1.5026
Batch 50, Loss: 1.4900
Batch 60, Loss: 1.4671
Batch 70, Loss: 1.5496
Batch 80, Loss: 1.5418
Batch 90, Loss: 1.5425
Batch 100, Loss: 1.5616
Batch 110, Loss: 1.5458
Batch 120, Loss: 1.4624
Batch 130, Loss: 1.5526
Batch 140, Loss: 1.4875
Batch 150, Loss: 1.4553
Batch 160, Loss: 1.5799
Batch 170, Loss: 1.6166
Batch 180, Loss: 1.4869
Batch 190, Loss: 1.5878
Batch 200, Loss: 1.5827
Batch 210, Loss: 1.5984
Batch 220, Loss: 1.5271
Batch 230, Loss: 1.5320
Batch 240, Loss: 1.5375
Batch 250, Loss: 1.5755
Batch 260, Loss: 1.6042
Batch 270, Loss: 1.5440
Batch 280, Loss: 1.5106
Batch 290, Loss: 1.6160
Batch 300, Loss: 1.5735
Batch 310, Loss: 1.5623
Batch 320, Loss: 1.5609
Batch 330, Loss: 1.5452
Batch 340, Loss: 1.5575
Batch 350, Loss: 1.5246
Batch 360, Loss: 1.5670
Batch 370, Loss: 1.5685
Batch 380, Loss: 1.5934
Batch 390, Loss: 1.5572
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.249337196350098 seconds
Epoch 27 accuracy: 54.45%
Batch 10, Loss: 1.4795
Batch 20, Loss: 1.4939
Batch 30, Loss: 1.5125
Batch 40, Loss: 1.5127
Batch 50, Loss: 1.4910
Batch 60, Loss: 1.5159
Batch 70, Loss: 1.5079
Batch 80, Loss: 1.5062
Batch 90, Loss: 1.4724
Batch 100, Loss: 1.5209
Batch 110, Loss: 1.5527
Batch 120, Loss: 1.5213
Batch 130, Loss: 1.4890
Batch 140, Loss: 1.5611
Batch 150, Loss: 1.5041
Batch 160, Loss: 1.5869
Batch 170, Loss: 1.5450
Batch 180, Loss: 1.5810
Batch 190, Loss: 1.5276
Batch 200, Loss: 1.5290
Batch 210, Loss: 1.5526
Batch 220, Loss: 1.5214
Batch 230, Loss: 1.5686
Batch 240, Loss: 1.5736
Batch 250, Loss: 1.5766
Batch 260, Loss: 1.5914
Batch 270, Loss: 1.5778
Batch 280, Loss: 1.5688
Batch 290, Loss: 1.5141
Batch 300, Loss: 1.5733
Batch 310, Loss: 1.5697
Batch 320, Loss: 1.5200
Batch 330, Loss: 1.5265
Batch 340, Loss: 1.5972
Batch 350, Loss: 1.5020
Batch 360, Loss: 1.5908
Batch 370, Loss: 1.5084
Batch 380, Loss: 1.5213
Batch 390, Loss: 1.5832
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.05634832382202 seconds
Epoch 28 accuracy: 56.36%
Batch 10, Loss: 1.4855
Batch 20, Loss: 1.4984
Batch 30, Loss: 1.4867
Batch 40, Loss: 1.5456
Batch 50, Loss: 1.5229
Batch 60, Loss: 1.5361
Batch 70, Loss: 1.5412
Batch 80, Loss: 1.4512
Batch 90, Loss: 1.4859
Batch 100, Loss: 1.6131
Batch 110, Loss: 1.4837
Batch 120, Loss: 1.5112
Batch 130, Loss: 1.5459
Batch 140, Loss: 1.5722
Batch 150, Loss: 1.5454
Batch 160, Loss: 1.4511
Batch 170, Loss: 1.5574
Batch 180, Loss: 1.5211
Batch 190, Loss: 1.5846
Batch 200, Loss: 1.5407
Batch 210, Loss: 1.5304
Batch 220, Loss: 1.5951
Batch 230, Loss: 1.4457
Batch 240, Loss: 1.6002
Batch 250, Loss: 1.5930
Batch 260, Loss: 1.5681
Batch 270, Loss: 1.5614
Batch 280, Loss: 1.6194
Batch 290, Loss: 1.4706
Batch 300, Loss: 1.4853
Batch 310, Loss: 1.5929
Batch 320, Loss: 1.5196
Batch 330, Loss: 1.5135
Batch 340, Loss: 1.5587
Batch 350, Loss: 1.4974
Batch 360, Loss: 1.5394
Batch 370, Loss: 1.4693
Batch 380, Loss: 1.5382
Batch 390, Loss: 1.5337
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.067181825637817 seconds
Epoch 29 accuracy: 55.75%
Batch 10, Loss: 1.4182
Batch 20, Loss: 1.4755
Batch 30, Loss: 1.5212
Batch 40, Loss: 1.4884
Batch 50, Loss: 1.4995
Batch 60, Loss: 1.5364
Batch 70, Loss: 1.5463
Batch 80, Loss: 1.5488
Batch 90, Loss: 1.4749
Batch 100, Loss: 1.5103
Batch 110, Loss: 1.4863
Batch 120, Loss: 1.5607
Batch 130, Loss: 1.5267
Batch 140, Loss: 1.5390
Batch 150, Loss: 1.5092
Batch 160, Loss: 1.4826
Batch 170, Loss: 1.5417
Batch 180, Loss: 1.5212
Batch 190, Loss: 1.5335
Batch 200, Loss: 1.5370
Batch 210, Loss: 1.5082
Batch 220, Loss: 1.4713
Batch 230, Loss: 1.4958
Batch 240, Loss: 1.5839
Batch 250, Loss: 1.5558
Batch 260, Loss: 1.5667
Batch 270, Loss: 1.4947
Batch 280, Loss: 1.5133
Batch 290, Loss: 1.5377
Batch 300, Loss: 1.5461
Batch 310, Loss: 1.6161
Batch 320, Loss: 1.6044
Batch 330, Loss: 1.6449
Batch 340, Loss: 1.5837
Batch 350, Loss: 1.5561
Batch 360, Loss: 1.5844
Batch 370, Loss: 1.4859
Batch 380, Loss: 1.5998
Batch 390, Loss: 1.5261
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.07090449333191 seconds
Epoch 30 accuracy: 57.07%
Batch 10, Loss: 1.4639
Batch 20, Loss: 1.5451
Batch 30, Loss: 1.5006
Batch 40, Loss: 1.4731
Batch 50, Loss: 1.5141
Batch 60, Loss: 1.4519
Batch 70, Loss: 1.4450
Batch 80, Loss: 1.4001
Batch 90, Loss: 1.5266
Batch 100, Loss: 1.4592
Batch 110, Loss: 1.4994
Batch 120, Loss: 1.5314
Batch 130, Loss: 1.4907
Batch 140, Loss: 1.5202
Batch 150, Loss: 1.4251
Batch 160, Loss: 1.4798
Batch 170, Loss: 1.5256
Batch 180, Loss: 1.4814
Batch 190, Loss: 1.4875
Batch 200, Loss: 1.5364
Batch 210, Loss: 1.4955
Batch 220, Loss: 1.5164
Batch 230, Loss: 1.5789
Batch 240, Loss: 1.4876
Batch 250, Loss: 1.5105
Batch 260, Loss: 1.5314
Batch 270, Loss: 1.4852
Batch 280, Loss: 1.6138
Batch 290, Loss: 1.5506
Batch 300, Loss: 1.5290
Batch 310, Loss: 1.5369
Batch 320, Loss: 1.5298
Batch 330, Loss: 1.5166
Batch 340, Loss: 1.5383
Batch 350, Loss: 1.5700
Batch 360, Loss: 1.5520
Batch 370, Loss: 1.5897
Batch 380, Loss: 1.6554
Batch 390, Loss: 1.5634
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.16662096977234 seconds
Epoch 31 accuracy: 51.36%
Batch 10, Loss: 1.4618
Batch 20, Loss: 1.4593
Batch 30, Loss: 1.4387
Batch 40, Loss: 1.4770
Batch 50, Loss: 1.4642
Batch 60, Loss: 1.4230
Batch 70, Loss: 1.5126
Batch 80, Loss: 1.5203
Batch 90, Loss: 1.5279
Batch 100, Loss: 1.4823
Batch 110, Loss: 1.5371
Batch 120, Loss: 1.5334
Batch 130, Loss: 1.5493
Batch 140, Loss: 1.5096
Batch 150, Loss: 1.5674
Batch 160, Loss: 1.5416
Batch 170, Loss: 1.4771
Batch 180, Loss: 1.4599
Batch 190, Loss: 1.5162
Batch 200, Loss: 1.5082
Batch 210, Loss: 1.5862
Batch 220, Loss: 1.5402
Batch 230, Loss: 1.4995
Batch 240, Loss: 1.4070
Batch 250, Loss: 1.5419
Batch 260, Loss: 1.5393
Batch 270, Loss: 1.4948
Batch 280, Loss: 1.5478
Batch 290, Loss: 1.5371
Batch 300, Loss: 1.5549
Batch 310, Loss: 1.4910
Batch 320, Loss: 1.5188
Batch 330, Loss: 1.6053
Batch 340, Loss: 1.4989
Batch 350, Loss: 1.5655
Batch 360, Loss: 1.5265
Batch 370, Loss: 1.4983
Batch 380, Loss: 1.5648
Batch 390, Loss: 1.5472
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.10124707221985 seconds
Epoch 32 accuracy: 55.07%
Batch 10, Loss: 1.5121
Batch 20, Loss: 1.4183
Batch 30, Loss: 1.4617
Batch 40, Loss: 1.5288
Batch 50, Loss: 1.4467
Batch 60, Loss: 1.4707
Batch 70, Loss: 1.4490
Batch 80, Loss: 1.4921
Batch 90, Loss: 1.4947
Batch 100, Loss: 1.4875
Batch 110, Loss: 1.5039
Batch 120, Loss: 1.4129
Batch 130, Loss: 1.5163
Batch 140, Loss: 1.5168
Batch 150, Loss: 1.4547
Batch 160, Loss: 1.4264
Batch 170, Loss: 1.4768
Batch 180, Loss: 1.5052
Batch 190, Loss: 1.5510
Batch 200, Loss: 1.5069
Batch 210, Loss: 1.4680
Batch 220, Loss: 1.4883
Batch 230, Loss: 1.4761
Batch 240, Loss: 1.4907
Batch 250, Loss: 1.5593
Batch 260, Loss: 1.5184
Batch 270, Loss: 1.5140
Batch 280, Loss: 1.5723
Batch 290, Loss: 1.4988
Batch 300, Loss: 1.5105
Batch 310, Loss: 1.4958
Batch 320, Loss: 1.5256
Batch 330, Loss: 1.4711
Batch 340, Loss: 1.5454
Batch 350, Loss: 1.5121
Batch 360, Loss: 1.5402
Batch 370, Loss: 1.5205
Batch 380, Loss: 1.5477
Batch 390, Loss: 1.5454
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.020320892333984 seconds
Epoch 33 accuracy: 51.09%
Batch 10, Loss: 1.4876
Batch 20, Loss: 1.5175
Batch 30, Loss: 1.5018
Batch 40, Loss: 1.4068
Batch 50, Loss: 1.4946
Batch 60, Loss: 1.4466
Batch 70, Loss: 1.4359
Batch 80, Loss: 1.4273
Batch 90, Loss: 1.4485
Batch 100, Loss: 1.5652
Batch 110, Loss: 1.4883
Batch 120, Loss: 1.4893
Batch 130, Loss: 1.5188
Batch 140, Loss: 1.4436
Batch 150, Loss: 1.4786
Batch 160, Loss: 1.5050
Batch 170, Loss: 1.5246
Batch 180, Loss: 1.5207
Batch 190, Loss: 1.4931
Batch 200, Loss: 1.4135
Batch 210, Loss: 1.5141
Batch 220, Loss: 1.4940
Batch 230, Loss: 1.5107
Batch 240, Loss: 1.5147
Batch 250, Loss: 1.4774
Batch 260, Loss: 1.5807
Batch 270, Loss: 1.5385
Batch 280, Loss: 1.4870
Batch 290, Loss: 1.4857
Batch 300, Loss: 1.4907
Batch 310, Loss: 1.5607
Batch 320, Loss: 1.5198
Batch 330, Loss: 1.5366
Batch 340, Loss: 1.5220
Batch 350, Loss: 1.5050
Batch 360, Loss: 1.4661
Batch 370, Loss: 1.5751
Batch 380, Loss: 1.5025
Batch 390, Loss: 1.5063
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.146703004837036 seconds
Epoch 34 accuracy: 52.57%
Batch 10, Loss: 1.4022
Batch 20, Loss: 1.4648
Batch 30, Loss: 1.4338
Batch 40, Loss: 1.5215
Batch 50, Loss: 1.4700
Batch 60, Loss: 1.4287
Batch 70, Loss: 1.4286
Batch 80, Loss: 1.4897
Batch 90, Loss: 1.4311
Batch 100, Loss: 1.4150
Batch 110, Loss: 1.4191
Batch 120, Loss: 1.3893
Batch 130, Loss: 1.4125
Batch 140, Loss: 1.4372
Batch 150, Loss: 1.4476
Batch 160, Loss: 1.4347
Batch 170, Loss: 1.5390
Batch 180, Loss: 1.5018
Batch 190, Loss: 1.5660
Batch 200, Loss: 1.4508
Batch 210, Loss: 1.4985
Batch 220, Loss: 1.4885
Batch 230, Loss: 1.4904
Batch 240, Loss: 1.4782
Batch 250, Loss: 1.5307
Batch 260, Loss: 1.4909
Batch 270, Loss: 1.4905
Batch 280, Loss: 1.5273
Batch 290, Loss: 1.4979
Batch 300, Loss: 1.5286
Batch 310, Loss: 1.5240
Batch 320, Loss: 1.5289
Batch 330, Loss: 1.5471
Batch 340, Loss: 1.4921
Batch 350, Loss: 1.5240
Batch 360, Loss: 1.4598
Batch 370, Loss: 1.5106
Batch 380, Loss: 1.5459
Batch 390, Loss: 1.4958
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.09303116798401 seconds
Epoch 35 accuracy: 56.28%
Batch 10, Loss: 1.4094
Batch 20, Loss: 1.5082
Batch 30, Loss: 1.4276
Batch 40, Loss: 1.4798
Batch 50, Loss: 1.4162
Batch 60, Loss: 1.4517
Batch 70, Loss: 1.4655
Batch 80, Loss: 1.5118
Batch 90, Loss: 1.5015
Batch 100, Loss: 1.5058
Batch 110, Loss: 1.4774
Batch 120, Loss: 1.4937
Batch 130, Loss: 1.4865
Batch 140, Loss: 1.5227
Batch 150, Loss: 1.4448
Batch 160, Loss: 1.4336
Batch 170, Loss: 1.5117
Batch 180, Loss: 1.5176
Batch 190, Loss: 1.4894
Batch 200, Loss: 1.4360
Batch 210, Loss: 1.4259
Batch 220, Loss: 1.4582
Batch 230, Loss: 1.4925
Batch 240, Loss: 1.5600
Batch 250, Loss: 1.4801
Batch 260, Loss: 1.5084
Batch 270, Loss: 1.4693
Batch 280, Loss: 1.4781
Batch 290, Loss: 1.5313
Batch 300, Loss: 1.4613
Batch 310, Loss: 1.4728
Batch 320, Loss: 1.5188
Batch 330, Loss: 1.4850
Batch 340, Loss: 1.4906
Batch 350, Loss: 1.5060
Batch 360, Loss: 1.5188
Batch 370, Loss: 1.5077
Batch 380, Loss: 1.5267
Batch 390, Loss: 1.5195
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 24.972654104232788 seconds
Epoch 36 accuracy: 54.12%
Batch 10, Loss: 1.4484
Batch 20, Loss: 1.4232
Batch 30, Loss: 1.4517
Batch 40, Loss: 1.4535
Batch 50, Loss: 1.4281
Batch 60, Loss: 1.4314
Batch 70, Loss: 1.4264
Batch 80, Loss: 1.4694
Batch 90, Loss: 1.3922
Batch 100, Loss: 1.5504
Batch 110, Loss: 1.4980
Batch 120, Loss: 1.4938
Batch 130, Loss: 1.4947
Batch 140, Loss: 1.5011
Batch 150, Loss: 1.4303
Batch 160, Loss: 1.4973
Batch 170, Loss: 1.4834
Batch 180, Loss: 1.4328
Batch 190, Loss: 1.5485
Batch 200, Loss: 1.4201
Batch 210, Loss: 1.4747
Batch 220, Loss: 1.4532
Batch 230, Loss: 1.4873
Batch 240, Loss: 1.4827
Batch 250, Loss: 1.5467
Batch 260, Loss: 1.4984
Batch 270, Loss: 1.4076
Batch 280, Loss: 1.4448
Batch 290, Loss: 1.5111
Batch 300, Loss: 1.4342
Batch 310, Loss: 1.4753
Batch 320, Loss: 1.4613
Batch 330, Loss: 1.4495
Batch 340, Loss: 1.5319
Batch 350, Loss: 1.5241
Batch 360, Loss: 1.5304
Batch 370, Loss: 1.4599
Batch 380, Loss: 1.5012
Batch 390, Loss: 1.4978
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.071484565734863 seconds
Epoch 37 accuracy: 56.21%
Batch 10, Loss: 1.4843
Batch 20, Loss: 1.4191
Batch 30, Loss: 1.3507
Batch 40, Loss: 1.3959
Batch 50, Loss: 1.4621
Batch 60, Loss: 1.4166
Batch 70, Loss: 1.4077
Batch 80, Loss: 1.4284
Batch 90, Loss: 1.4211
Batch 100, Loss: 1.4402
Batch 110, Loss: 1.5066
Batch 120, Loss: 1.4076
Batch 130, Loss: 1.4963
Batch 140, Loss: 1.4533
Batch 150, Loss: 1.5116
Batch 160, Loss: 1.4720
Batch 170, Loss: 1.4550
Batch 180, Loss: 1.4197
Batch 190, Loss: 1.4847
Batch 200, Loss: 1.5124
Batch 210, Loss: 1.4627
Batch 220, Loss: 1.5066
Batch 230, Loss: 1.5057
Batch 240, Loss: 1.4554
Batch 250, Loss: 1.4717
Batch 260, Loss: 1.5619
Batch 270, Loss: 1.4913
Batch 280, Loss: 1.4805
Batch 290, Loss: 1.4668
Batch 300, Loss: 1.4421
Batch 310, Loss: 1.4849
Batch 320, Loss: 1.4279
Batch 330, Loss: 1.4955
Batch 340, Loss: 1.4816
Batch 350, Loss: 1.4450
Batch 360, Loss: 1.4246
Batch 370, Loss: 1.5359
Batch 380, Loss: 1.4809
Batch 390, Loss: 1.3938
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.13373374938965 seconds
Epoch 38 accuracy: 57.26%
Batch 10, Loss: 1.4501
Batch 20, Loss: 1.3845
Batch 30, Loss: 1.4403
Batch 40, Loss: 1.4561
Batch 50, Loss: 1.4114
Batch 60, Loss: 1.3655
Batch 70, Loss: 1.4415
Batch 80, Loss: 1.4339
Batch 90, Loss: 1.4761
Batch 100, Loss: 1.5326
Batch 110, Loss: 1.3945
Batch 120, Loss: 1.4316
Batch 130, Loss: 1.4645
Batch 140, Loss: 1.4753
Batch 150, Loss: 1.4250
Batch 160, Loss: 1.4072
Batch 170, Loss: 1.4355
Batch 180, Loss: 1.5222
Batch 190, Loss: 1.4419
Batch 200, Loss: 1.4522
Batch 210, Loss: 1.4378
Batch 220, Loss: 1.4752
Batch 230, Loss: 1.5478
Batch 240, Loss: 1.5062
Batch 250, Loss: 1.4697
Batch 260, Loss: 1.4832
Batch 270, Loss: 1.4743
Batch 280, Loss: 1.5413
Batch 290, Loss: 1.4858
Batch 300, Loss: 1.4243
Batch 310, Loss: 1.4437
Batch 320, Loss: 1.4752
Batch 330, Loss: 1.4498
Batch 340, Loss: 1.4358
Batch 350, Loss: 1.4842
Batch 360, Loss: 1.4457
Batch 370, Loss: 1.4892
Batch 380, Loss: 1.4855
Batch 390, Loss: 1.4509
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.13742470741272 seconds
Epoch 39 accuracy: 57.49%
Batch 10, Loss: 1.4519
Batch 20, Loss: 1.3407
Batch 30, Loss: 1.4464
Batch 40, Loss: 1.3976
Batch 50, Loss: 1.4516
Batch 60, Loss: 1.4805
Batch 70, Loss: 1.3998
Batch 80, Loss: 1.4135
Batch 90, Loss: 1.4253
Batch 100, Loss: 1.4276
Batch 110, Loss: 1.4906
Batch 120, Loss: 1.5005
Batch 130, Loss: 1.4389
Batch 140, Loss: 1.4267
Batch 150, Loss: 1.4460
Batch 160, Loss: 1.3532
Batch 170, Loss: 1.4581
Batch 180, Loss: 1.4681
Batch 190, Loss: 1.4579
Batch 200, Loss: 1.4719
Batch 210, Loss: 1.4684
Batch 220, Loss: 1.4020
Batch 230, Loss: 1.4145
Batch 240, Loss: 1.5668
Batch 250, Loss: 1.4600
Batch 260, Loss: 1.4260
Batch 270, Loss: 1.4461
Batch 280, Loss: 1.4726
Batch 290, Loss: 1.5457
Batch 300, Loss: 1.5316
Batch 310, Loss: 1.5201
Batch 320, Loss: 1.5331
Batch 330, Loss: 1.3980
Batch 340, Loss: 1.4530
Batch 350, Loss: 1.5484
Batch 360, Loss: 1.4767
Batch 370, Loss: 1.4386
Batch 380, Loss: 1.4266
Batch 390, Loss: 1.4569
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.1068217754364 seconds
Epoch 40 accuracy: 57.82%
Batch 10, Loss: 1.3991
Batch 20, Loss: 1.3785
Batch 30, Loss: 1.3517
Batch 40, Loss: 1.3780
Batch 50, Loss: 1.3830
Batch 60, Loss: 1.4210
Batch 70, Loss: 1.4108
Batch 80, Loss: 1.4892
Batch 90, Loss: 1.3523
Batch 100, Loss: 1.4464
Batch 110, Loss: 1.5235
Batch 120, Loss: 1.4894
Batch 130, Loss: 1.5351
Batch 140, Loss: 1.5251
Batch 150, Loss: 1.5223
Batch 160, Loss: 1.4754
Batch 170, Loss: 1.5121
Batch 180, Loss: 1.4491
Batch 190, Loss: 1.4839
Batch 200, Loss: 1.4747
Batch 210, Loss: 1.4950
Batch 220, Loss: 1.5186
Batch 230, Loss: 1.5030
Batch 240, Loss: 1.4385
Batch 250, Loss: 1.4590
Batch 260, Loss: 1.4548
Batch 270, Loss: 1.4379
Batch 280, Loss: 1.4538
Batch 290, Loss: 1.4507
Batch 300, Loss: 1.4579
Batch 310, Loss: 1.4722
Batch 320, Loss: 1.4828
Batch 330, Loss: 1.5263
Batch 340, Loss: 1.4386
Batch 350, Loss: 1.4412
Batch 360, Loss: 1.4432
Batch 370, Loss: 1.4366
Batch 380, Loss: 1.4499
Batch 390, Loss: 1.4174
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.03254723548889 seconds
Epoch 41 accuracy: 55.9%
Batch 10, Loss: 1.4398
Batch 20, Loss: 1.4681
Batch 30, Loss: 1.4225
Batch 40, Loss: 1.3727
Batch 50, Loss: 1.3798
Batch 60, Loss: 1.4086
Batch 70, Loss: 1.4743
Batch 80, Loss: 1.4187
Batch 90, Loss: 1.4565
Batch 100, Loss: 1.4450
Batch 110, Loss: 1.4366
Batch 120, Loss: 1.4764
Batch 130, Loss: 1.4172
Batch 140, Loss: 1.3852
Batch 150, Loss: 1.3881
Batch 160, Loss: 1.4396
Batch 170, Loss: 1.4703
Batch 180, Loss: 1.5096
Batch 190, Loss: 1.4895
Batch 200, Loss: 1.4269
Batch 210, Loss: 1.4105
Batch 220, Loss: 1.5006
Batch 230, Loss: 1.4705
Batch 240, Loss: 1.4108
Batch 250, Loss: 1.4456
Batch 260, Loss: 1.3945
Batch 270, Loss: 1.4918
Batch 280, Loss: 1.4570
Batch 290, Loss: 1.4683
Batch 300, Loss: 1.4745
Batch 310, Loss: 1.4024
Batch 320, Loss: 1.5040
Batch 330, Loss: 1.4692
Batch 340, Loss: 1.5210
Batch 350, Loss: 1.4928
Batch 360, Loss: 1.5033
Batch 370, Loss: 1.5225
Batch 380, Loss: 1.5183
Batch 390, Loss: 1.5567
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.120707750320435 seconds
Epoch 42 accuracy: 57.4%
Batch 10, Loss: 1.3804
Batch 20, Loss: 1.4304
Batch 30, Loss: 1.3722
Batch 40, Loss: 1.4082
Batch 50, Loss: 1.4201
Batch 60, Loss: 1.3745
Batch 70, Loss: 1.4337
Batch 80, Loss: 1.3436
Batch 90, Loss: 1.4707
Batch 100, Loss: 1.4438
Batch 110, Loss: 1.4215
Batch 120, Loss: 1.4052
Batch 130, Loss: 1.3569
Batch 140, Loss: 1.4224
Batch 150, Loss: 1.4292
Batch 160, Loss: 1.4158
Batch 170, Loss: 1.4185
Batch 180, Loss: 1.5035
Batch 190, Loss: 1.4603
Batch 200, Loss: 1.4483
Batch 210, Loss: 1.5195
Batch 220, Loss: 1.4743
Batch 230, Loss: 1.4910
Batch 240, Loss: 1.4452
Batch 250, Loss: 1.4957
Batch 260, Loss: 1.4778
Batch 270, Loss: 1.4453
Batch 280, Loss: 1.4056
Batch 290, Loss: 1.4236
Batch 300, Loss: 1.4810
Batch 310, Loss: 1.4237
Batch 320, Loss: 1.4652
Batch 330, Loss: 1.4577
Batch 340, Loss: 1.4113
Batch 350, Loss: 1.5530
Batch 360, Loss: 1.4996
Batch 370, Loss: 1.4587
Batch 380, Loss: 1.4564
Batch 390, Loss: 1.4462
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.043702602386475 seconds
Epoch 43 accuracy: 59.59%
Batch 10, Loss: 1.3788
Batch 20, Loss: 1.3337
Batch 30, Loss: 1.3403
Batch 40, Loss: 1.4485
Batch 50, Loss: 1.3967
Batch 60, Loss: 1.4423
Batch 70, Loss: 1.3951
Batch 80, Loss: 1.4520
Batch 90, Loss: 1.4087
Batch 100, Loss: 1.3822
Batch 110, Loss: 1.4628
Batch 120, Loss: 1.4668
Batch 130, Loss: 1.4161
Batch 140, Loss: 1.3983
Batch 150, Loss: 1.4676
Batch 160, Loss: 1.4637
Batch 170, Loss: 1.4690
Batch 180, Loss: 1.4265
Batch 190, Loss: 1.4123
Batch 200, Loss: 1.4142
Batch 210, Loss: 1.4246
Batch 220, Loss: 1.4427
Batch 230, Loss: 1.4421
Batch 240, Loss: 1.4827
Batch 250, Loss: 1.4989
Batch 260, Loss: 1.5081
Batch 270, Loss: 1.4270
Batch 280, Loss: 1.4286
Batch 290, Loss: 1.4494
Batch 300, Loss: 1.5042
Batch 310, Loss: 1.4331
Batch 320, Loss: 1.4332
Batch 330, Loss: 1.4491
Batch 340, Loss: 1.4380
Batch 350, Loss: 1.4516
Batch 360, Loss: 1.4541
Batch 370, Loss: 1.4541
Batch 380, Loss: 1.5002
Batch 390, Loss: 1.4123
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.039382934570312 seconds
Epoch 44 accuracy: 59.58%
Batch 10, Loss: 1.3519
Batch 20, Loss: 1.3695
Batch 30, Loss: 1.4013
Batch 40, Loss: 1.3739
Batch 50, Loss: 1.4491
Batch 60, Loss: 1.3646
Batch 70, Loss: 1.3681
Batch 80, Loss: 1.3397
Batch 90, Loss: 1.3322
Batch 100, Loss: 1.3919
Batch 110, Loss: 1.4112
Batch 120, Loss: 1.3829
Batch 130, Loss: 1.3809
Batch 140, Loss: 1.3818
Batch 150, Loss: 1.3975
Batch 160, Loss: 1.4674
Batch 170, Loss: 1.4645
Batch 180, Loss: 1.4557
Batch 190, Loss: 1.4280
Batch 200, Loss: 1.4780
Batch 210, Loss: 1.3946
Batch 220, Loss: 1.5174
Batch 230, Loss: 1.4321
Batch 240, Loss: 1.4272
Batch 250, Loss: 1.4106
Batch 260, Loss: 1.4670
Batch 270, Loss: 1.4826
Batch 280, Loss: 1.4367
Batch 290, Loss: 1.4241
Batch 300, Loss: 1.4049
Batch 310, Loss: 1.4207
Batch 320, Loss: 1.4252
Batch 330, Loss: 1.4093
Batch 340, Loss: 1.4978
Batch 350, Loss: 1.4622
Batch 360, Loss: 1.4231
Batch 370, Loss: 1.4144
Batch 380, Loss: 1.4647
Batch 390, Loss: 1.4350
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.17676043510437 seconds
Epoch 45 accuracy: 58.08%
Batch 10, Loss: 1.3952
Batch 20, Loss: 1.3909
Batch 30, Loss: 1.4301
Batch 40, Loss: 1.4210
Batch 50, Loss: 1.3932
Batch 60, Loss: 1.4065
Batch 70, Loss: 1.4124
Batch 80, Loss: 1.3920
Batch 90, Loss: 1.3669
Batch 100, Loss: 1.3495
Batch 110, Loss: 1.3825
Batch 120, Loss: 1.4245
Batch 130, Loss: 1.4622
Batch 140, Loss: 1.4661
Batch 150, Loss: 1.4022
Batch 160, Loss: 1.4524
Batch 170, Loss: 1.4048
Batch 180, Loss: 1.4649
Batch 190, Loss: 1.3796
Batch 200, Loss: 1.4448
Batch 210, Loss: 1.4773
Batch 220, Loss: 1.4275
Batch 230, Loss: 1.4225
Batch 240, Loss: 1.4628
Batch 250, Loss: 1.4505
Batch 260, Loss: 1.4620
Batch 270, Loss: 1.4400
Batch 280, Loss: 1.3891
Batch 290, Loss: 1.4032
Batch 300, Loss: 1.4033
Batch 310, Loss: 1.4559
Batch 320, Loss: 1.4123
Batch 330, Loss: 1.5205
Batch 340, Loss: 1.4502
Batch 350, Loss: 1.3879
Batch 360, Loss: 1.4737
Batch 370, Loss: 1.4100
Batch 380, Loss: 1.4559
Batch 390, Loss: 1.5010
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.11795949935913 seconds
Epoch 46 accuracy: 58.75%
Batch 10, Loss: 1.4113
Batch 20, Loss: 1.3970
Batch 30, Loss: 1.3295
Batch 40, Loss: 1.3564
Batch 50, Loss: 1.3826
Batch 60, Loss: 1.3908
Batch 70, Loss: 1.4371
Batch 80, Loss: 1.3715
Batch 90, Loss: 1.3665
Batch 100, Loss: 1.3516
Batch 110, Loss: 1.4035
Batch 120, Loss: 1.3932
Batch 130, Loss: 1.4133
Batch 140, Loss: 1.3685
Batch 150, Loss: 1.4246
Batch 160, Loss: 1.4175
Batch 170, Loss: 1.4460
Batch 180, Loss: 1.3379
Batch 190, Loss: 1.4179
Batch 200, Loss: 1.4421
Batch 210, Loss: 1.4838
Batch 220, Loss: 1.4278
Batch 230, Loss: 1.3812
Batch 240, Loss: 1.4956
Batch 250, Loss: 1.4693
Batch 260, Loss: 1.4646
Batch 270, Loss: 1.5140
Batch 280, Loss: 1.4282
Batch 290, Loss: 1.4245
Batch 300, Loss: 1.4316
Batch 310, Loss: 1.3917
Batch 320, Loss: 1.4707
Batch 330, Loss: 1.4451
Batch 340, Loss: 1.4231
Batch 350, Loss: 1.4596
Batch 360, Loss: 1.5028
Batch 370, Loss: 1.4637
Batch 380, Loss: 1.4324
Batch 390, Loss: 1.4327
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.05813980102539 seconds
Epoch 47 accuracy: 59.51%
Batch 10, Loss: 1.3435
Batch 20, Loss: 1.3971
Batch 30, Loss: 1.4106
Batch 40, Loss: 1.3866
Batch 50, Loss: 1.4068
Batch 60, Loss: 1.3736
Batch 70, Loss: 1.3620
Batch 80, Loss: 1.3897
Batch 90, Loss: 1.3612
Batch 100, Loss: 1.4276
Batch 110, Loss: 1.3567
Batch 120, Loss: 1.4294
Batch 130, Loss: 1.3882
Batch 140, Loss: 1.4775
Batch 150, Loss: 1.4230
Batch 160, Loss: 1.3911
Batch 170, Loss: 1.4168
Batch 180, Loss: 1.4636
Batch 190, Loss: 1.4403
Batch 200, Loss: 1.4102
Batch 210, Loss: 1.4949
Batch 220, Loss: 1.4207
Batch 230, Loss: 1.4721
Batch 240, Loss: 1.3918
Batch 250, Loss: 1.4906
Batch 260, Loss: 1.4862
Batch 270, Loss: 1.4055
Batch 280, Loss: 1.3858
Batch 290, Loss: 1.5049
Batch 300, Loss: 1.4217
Batch 310, Loss: 1.4572
Batch 320, Loss: 1.4422
Batch 330, Loss: 1.4483
Batch 340, Loss: 1.4688
Batch 350, Loss: 1.4289
Batch 360, Loss: 1.4192
Batch 370, Loss: 1.3826
Batch 380, Loss: 1.4823
Batch 390, Loss: 1.4090
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.020300149917603 seconds
Epoch 48 accuracy: 60.59%
Batch 10, Loss: 1.3350
Batch 20, Loss: 1.3792
Batch 30, Loss: 1.3855
Batch 40, Loss: 1.4060
Batch 50, Loss: 1.3569
Batch 60, Loss: 1.4586
Batch 70, Loss: 1.4452
Batch 80, Loss: 1.3990
Batch 90, Loss: 1.3421
Batch 100, Loss: 1.4043
Batch 110, Loss: 1.4379
Batch 120, Loss: 1.4090
Batch 130, Loss: 1.3983
Batch 140, Loss: 1.3660
Batch 150, Loss: 1.3972
Batch 160, Loss: 1.4401
Batch 170, Loss: 1.4058
Batch 180, Loss: 1.4115
Batch 190, Loss: 1.4235
Batch 200, Loss: 1.4509
Batch 210, Loss: 1.3971
Batch 220, Loss: 1.3813
Batch 230, Loss: 1.4570
Batch 240, Loss: 1.4453
Batch 250, Loss: 1.4179
Batch 260, Loss: 1.4312
Batch 270, Loss: 1.4053
Batch 280, Loss: 1.4207
Batch 290, Loss: 1.4291
Batch 300, Loss: 1.3712
Batch 310, Loss: 1.4263
Batch 320, Loss: 1.4443
Batch 330, Loss: 1.4484
Batch 340, Loss: 1.4255
Batch 350, Loss: 1.4171
Batch 360, Loss: 1.4513
Batch 370, Loss: 1.4012
Batch 380, Loss: 1.4268
Batch 390, Loss: 1.4162
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.09856867790222 seconds
Epoch 49 accuracy: 58.1%
Batch 10, Loss: 1.3856
Batch 20, Loss: 1.3703
Batch 30, Loss: 1.3332
Batch 40, Loss: 1.4060
Batch 50, Loss: 1.3513
Batch 60, Loss: 1.3683
Batch 70, Loss: 1.4130
Batch 80, Loss: 1.3718
Batch 90, Loss: 1.4087
Batch 100, Loss: 1.4100
Batch 110, Loss: 1.4345
Batch 120, Loss: 1.3605
Batch 130, Loss: 1.3536
Batch 140, Loss: 1.4339
Batch 150, Loss: 1.3261
Batch 160, Loss: 1.3832
Batch 170, Loss: 1.4072
Batch 180, Loss: 1.3985
Batch 190, Loss: 1.4325
Batch 200, Loss: 1.4231
Batch 210, Loss: 1.3878
Batch 220, Loss: 1.3897
Batch 230, Loss: 1.3910
Batch 240, Loss: 1.4037
Batch 250, Loss: 1.4162
Batch 260, Loss: 1.3713
Batch 270, Loss: 1.3852
Batch 280, Loss: 1.3162
Batch 290, Loss: 1.4262
Batch 300, Loss: 1.4306
Batch 310, Loss: 1.4347
Batch 320, Loss: 1.4402
Batch 330, Loss: 1.4234
Batch 340, Loss: 1.3827
Batch 350, Loss: 1.4002
Batch 360, Loss: 1.4373
Batch 370, Loss: 1.5402
Batch 380, Loss: 1.4798
Batch 390, Loss: 1.4443
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.170659065246582 seconds
Epoch 50 accuracy: 56.2%
Batch 10, Loss: 1.4274
Batch 20, Loss: 1.3827
Batch 30, Loss: 1.4179
Batch 40, Loss: 1.3691
Batch 50, Loss: 1.4510
Batch 60, Loss: 1.3557
Batch 70, Loss: 1.4110
Batch 80, Loss: 1.3638
Batch 90, Loss: 1.3477
Batch 100, Loss: 1.3791
Batch 110, Loss: 1.3743
Batch 120, Loss: 1.4540
Batch 130, Loss: 1.4057
Batch 140, Loss: 1.3985
Batch 150, Loss: 1.3328
Batch 160, Loss: 1.3369
Batch 170, Loss: 1.3475
Batch 180, Loss: 1.4146
Batch 190, Loss: 1.3669
Batch 200, Loss: 1.4076
Batch 210, Loss: 1.3545
Batch 220, Loss: 1.4359
Batch 230, Loss: 1.4203
Batch 240, Loss: 1.4317
Batch 250, Loss: 1.4042
Batch 260, Loss: 1.4493
Batch 270, Loss: 1.4094
Batch 280, Loss: 1.3750
Batch 290, Loss: 1.3525
Batch 300, Loss: 1.3075
Batch 310, Loss: 1.4139
Batch 320, Loss: 1.4650
Batch 330, Loss: 1.4459
Batch 340, Loss: 1.4980
Batch 350, Loss: 1.3848
Batch 360, Loss: 1.4373
Batch 370, Loss: 1.4293
Batch 380, Loss: 1.4613
Batch 390, Loss: 1.3768
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.127853393554688 seconds
Epoch 51 accuracy: 60.75%
Batch 10, Loss: 1.4355
Batch 20, Loss: 1.3967
Batch 30, Loss: 1.3232
Batch 40, Loss: 1.3590
Batch 50, Loss: 1.4094
Batch 60, Loss: 1.4169
Batch 70, Loss: 1.3803
Batch 80, Loss: 1.4336
Batch 90, Loss: 1.3919
Batch 100, Loss: 1.3624
Batch 110, Loss: 1.3506
Batch 120, Loss: 1.4436
Batch 130, Loss: 1.4278
Batch 140, Loss: 1.4128
Batch 150, Loss: 1.4140
Batch 160, Loss: 1.3410
Batch 170, Loss: 1.3547
Batch 180, Loss: 1.3470
Batch 190, Loss: 1.4096
Batch 200, Loss: 1.4417
Batch 210, Loss: 1.3611
Batch 220, Loss: 1.3682
Batch 230, Loss: 1.3924
Batch 240, Loss: 1.3754
Batch 250, Loss: 1.3805
Batch 260, Loss: 1.4038
Batch 270, Loss: 1.3798
Batch 280, Loss: 1.4549
Batch 290, Loss: 1.4362
Batch 300, Loss: 1.4612
Batch 310, Loss: 1.4783
Batch 320, Loss: 1.3863
Batch 330, Loss: 1.3864
Batch 340, Loss: 1.4302
Batch 350, Loss: 1.4108
Batch 360, Loss: 1.4196
Batch 370, Loss: 1.3621
Batch 380, Loss: 1.4522
Batch 390, Loss: 1.3791
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.041401147842407 seconds
Epoch 52 accuracy: 58.69%
Batch 10, Loss: 1.3643
Batch 20, Loss: 1.2544
Batch 30, Loss: 1.3444
Batch 40, Loss: 1.3116
Batch 50, Loss: 1.2656
Batch 60, Loss: 1.3820
Batch 70, Loss: 1.3799
Batch 80, Loss: 1.3686
Batch 90, Loss: 1.3641
Batch 100, Loss: 1.3588
Batch 110, Loss: 1.3726
Batch 120, Loss: 1.4091
Batch 130, Loss: 1.4317
Batch 140, Loss: 1.3941
Batch 150, Loss: 1.3782
Batch 160, Loss: 1.3354
Batch 170, Loss: 1.3680
Batch 180, Loss: 1.4022
Batch 190, Loss: 1.4730
Batch 200, Loss: 1.3833
Batch 210, Loss: 1.4244
Batch 220, Loss: 1.3981
Batch 230, Loss: 1.4359
Batch 240, Loss: 1.4030
Batch 250, Loss: 1.3762
Batch 260, Loss: 1.3494
Batch 270, Loss: 1.3701
Batch 280, Loss: 1.3806
Batch 290, Loss: 1.3843
Batch 300, Loss: 1.3640
Batch 310, Loss: 1.3347
Batch 320, Loss: 1.4173
Batch 330, Loss: 1.3737
Batch 340, Loss: 1.4485
Batch 350, Loss: 1.4332
Batch 360, Loss: 1.4625
Batch 370, Loss: 1.3685
Batch 380, Loss: 1.3692
Batch 390, Loss: 1.4066
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.17427635192871 seconds
Epoch 53 accuracy: 58.79%
Batch 10, Loss: 1.3321
Batch 20, Loss: 1.3536
Batch 30, Loss: 1.3322
Batch 40, Loss: 1.3832
Batch 50, Loss: 1.3728
Batch 60, Loss: 1.3564
Batch 70, Loss: 1.2866
Batch 80, Loss: 1.3420
Batch 90, Loss: 1.3411
Batch 100, Loss: 1.4398
Batch 110, Loss: 1.3101
Batch 120, Loss: 1.3707
Batch 130, Loss: 1.3774
Batch 140, Loss: 1.3921
Batch 150, Loss: 1.3667
Batch 160, Loss: 1.4227
Batch 170, Loss: 1.3280
Batch 180, Loss: 1.3545
Batch 190, Loss: 1.3819
Batch 200, Loss: 1.3321
Batch 210, Loss: 1.3361
Batch 220, Loss: 1.3905
Batch 230, Loss: 1.4287
Batch 240, Loss: 1.3550
Batch 250, Loss: 1.4510
Batch 260, Loss: 1.3883
Batch 270, Loss: 1.4040
Batch 280, Loss: 1.3715
Batch 290, Loss: 1.3290
Batch 300, Loss: 1.4158
Batch 310, Loss: 1.4294
Batch 320, Loss: 1.4147
Batch 330, Loss: 1.4316
Batch 340, Loss: 1.4871
Batch 350, Loss: 1.4414
Batch 360, Loss: 1.3859
Batch 370, Loss: 1.4419
Batch 380, Loss: 1.4954
Batch 390, Loss: 1.4020
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.061941623687744 seconds
Epoch 54 accuracy: 59.84%
Batch 10, Loss: 1.3550
Batch 20, Loss: 1.4118
Batch 30, Loss: 1.3594
Batch 40, Loss: 1.3819
Batch 50, Loss: 1.3870
Batch 60, Loss: 1.3196
Batch 70, Loss: 1.3072
Batch 80, Loss: 1.3166
Batch 90, Loss: 1.3220
Batch 100, Loss: 1.2673
Batch 110, Loss: 1.3553
Batch 120, Loss: 1.4076
Batch 130, Loss: 1.3396
Batch 140, Loss: 1.3100
Batch 150, Loss: 1.3930
Batch 160, Loss: 1.3645
Batch 170, Loss: 1.3582
Batch 180, Loss: 1.3544
Batch 190, Loss: 1.3803
Batch 200, Loss: 1.4009
Batch 210, Loss: 1.3431
Batch 220, Loss: 1.3946
Batch 230, Loss: 1.4111
Batch 240, Loss: 1.4222
Batch 250, Loss: 1.4337
Batch 260, Loss: 1.4096
Batch 270, Loss: 1.3863
Batch 280, Loss: 1.3961
Batch 290, Loss: 1.3223
Batch 300, Loss: 1.4232
Batch 310, Loss: 1.3981
Batch 320, Loss: 1.3793
Batch 330, Loss: 1.3427
Batch 340, Loss: 1.3870
Batch 350, Loss: 1.4188
Batch 360, Loss: 1.4431
Batch 370, Loss: 1.3950
Batch 380, Loss: 1.4206
Batch 390, Loss: 1.4016
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.182759523391724 seconds
Epoch 55 accuracy: 58.34%
Batch 10, Loss: 1.3053
Batch 20, Loss: 1.2992
Batch 30, Loss: 1.3197
Batch 40, Loss: 1.3865
Batch 50, Loss: 1.3443
Batch 60, Loss: 1.3650
Batch 70, Loss: 1.3261
Batch 80, Loss: 1.3328
Batch 90, Loss: 1.3247
Batch 100, Loss: 1.3531
Batch 110, Loss: 1.3284
Batch 120, Loss: 1.3976
Batch 130, Loss: 1.4192
Batch 140, Loss: 1.4481
Batch 150, Loss: 1.3881
Batch 160, Loss: 1.3932
Batch 170, Loss: 1.3576
Batch 180, Loss: 1.3752
Batch 190, Loss: 1.3768
Batch 200, Loss: 1.3634
Batch 210, Loss: 1.3796
Batch 220, Loss: 1.4095
Batch 230, Loss: 1.2847
Batch 240, Loss: 1.4000
Batch 250, Loss: 1.3724
Batch 260, Loss: 1.4610
Batch 270, Loss: 1.4027
Batch 280, Loss: 1.3351
Batch 290, Loss: 1.3380
Batch 300, Loss: 1.4276
Batch 310, Loss: 1.4091
Batch 320, Loss: 1.3915
Batch 330, Loss: 1.4334
Batch 340, Loss: 1.4540
Batch 350, Loss: 1.3803
Batch 360, Loss: 1.3660
Batch 370, Loss: 1.4371
Batch 380, Loss: 1.3808
Batch 390, Loss: 1.3949
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.153783321380615 seconds
Epoch 56 accuracy: 57.37%
Batch 10, Loss: 1.3158
Batch 20, Loss: 1.3348
Batch 30, Loss: 1.2625
Batch 40, Loss: 1.2734
Batch 50, Loss: 1.3676
Batch 60, Loss: 1.3095
Batch 70, Loss: 1.4064
Batch 80, Loss: 1.3595
Batch 90, Loss: 1.3264
Batch 100, Loss: 1.3952
Batch 110, Loss: 1.3281
Batch 120, Loss: 1.3014
Batch 130, Loss: 1.3620
Batch 140, Loss: 1.3483
Batch 150, Loss: 1.3325
Batch 160, Loss: 1.3487
Batch 170, Loss: 1.3128
Batch 180, Loss: 1.3835
Batch 190, Loss: 1.4287
Batch 200, Loss: 1.3831
Batch 210, Loss: 1.4020
Batch 220, Loss: 1.4181
Batch 230, Loss: 1.3296
Batch 240, Loss: 1.3624
Batch 250, Loss: 1.4023
Batch 260, Loss: 1.3870
Batch 270, Loss: 1.3858
Batch 280, Loss: 1.3707
Batch 290, Loss: 1.3715
Batch 300, Loss: 1.3689
Batch 310, Loss: 1.3810
Batch 320, Loss: 1.3823
Batch 330, Loss: 1.3498
Batch 340, Loss: 1.3300
Batch 350, Loss: 1.3851
Batch 360, Loss: 1.4838
Batch 370, Loss: 1.4317
Batch 380, Loss: 1.3245
Batch 390, Loss: 1.4306
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.115905284881592 seconds
Epoch 57 accuracy: 59.32%
Batch 10, Loss: 1.3203
Batch 20, Loss: 1.3101
Batch 30, Loss: 1.3577
Batch 40, Loss: 1.2826
Batch 50, Loss: 1.3878
Batch 60, Loss: 1.3450
Batch 70, Loss: 1.3393
Batch 80, Loss: 1.3072
Batch 90, Loss: 1.3539
Batch 100, Loss: 1.3374
Batch 110, Loss: 1.2537
Batch 120, Loss: 1.3606
Batch 130, Loss: 1.3418
Batch 140, Loss: 1.3758
Batch 150, Loss: 1.3544
Batch 160, Loss: 1.3582
Batch 170, Loss: 1.3093
Batch 180, Loss: 1.3763
Batch 190, Loss: 1.3511
Batch 200, Loss: 1.3681
Batch 210, Loss: 1.3757
Batch 220, Loss: 1.3895
Batch 230, Loss: 1.3685
Batch 240, Loss: 1.4019
Batch 250, Loss: 1.4252
Batch 260, Loss: 1.3531
Batch 270, Loss: 1.3994
Batch 280, Loss: 1.3872
Batch 290, Loss: 1.3083
Batch 300, Loss: 1.4029
Batch 310, Loss: 1.4279
Batch 320, Loss: 1.3589
Batch 330, Loss: 1.4025
Batch 340, Loss: 1.3700
Batch 350, Loss: 1.4057
Batch 360, Loss: 1.2932
Batch 370, Loss: 1.3942
Batch 380, Loss: 1.3881
Batch 390, Loss: 1.4013
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.076573133468628 seconds
Epoch 58 accuracy: 60.19%
Batch 10, Loss: 1.3662
Batch 20, Loss: 1.3189
Batch 30, Loss: 1.3158
Batch 40, Loss: 1.2941
Batch 50, Loss: 1.2761
Batch 60, Loss: 1.3160
Batch 70, Loss: 1.3513
Batch 80, Loss: 1.3146
Batch 90, Loss: 1.3903
Batch 100, Loss: 1.3761
Batch 110, Loss: 1.3584
Batch 120, Loss: 1.3839
Batch 130, Loss: 1.3179
Batch 140, Loss: 1.3243
Batch 150, Loss: 1.4291
Batch 160, Loss: 1.3610
Batch 170, Loss: 1.3900
Batch 180, Loss: 1.3891
Batch 190, Loss: 1.3886
Batch 200, Loss: 1.4050
Batch 210, Loss: 1.3813
Batch 220, Loss: 1.4111
Batch 230, Loss: 1.3379
Batch 240, Loss: 1.3577
Batch 250, Loss: 1.3275
Batch 260, Loss: 1.4083
Batch 270, Loss: 1.3305
Batch 280, Loss: 1.2991
Batch 290, Loss: 1.3497
Batch 300, Loss: 1.3981
Batch 310, Loss: 1.4058
Batch 320, Loss: 1.4011
Batch 330, Loss: 1.3906
Batch 340, Loss: 1.3714
Batch 350, Loss: 1.3490
Batch 360, Loss: 1.4113
Batch 370, Loss: 1.4069
Batch 380, Loss: 1.3837
Batch 390, Loss: 1.4179
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.043161869049072 seconds
Epoch 59 accuracy: 59.81%
Batch 10, Loss: 1.2938
Batch 20, Loss: 1.2671
Batch 30, Loss: 1.2763
Batch 40, Loss: 1.3131
Batch 50, Loss: 1.3020
Batch 60, Loss: 1.3045
Batch 70, Loss: 1.2788
Batch 80, Loss: 1.2897
Batch 90, Loss: 1.2951
Batch 100, Loss: 1.4194
Batch 110, Loss: 1.4281
Batch 120, Loss: 1.4482
Batch 130, Loss: 1.2886
Batch 140, Loss: 1.2919
Batch 150, Loss: 1.3307
Batch 160, Loss: 1.3180
Batch 170, Loss: 1.3093
Batch 180, Loss: 1.3610
Batch 190, Loss: 1.4033
Batch 200, Loss: 1.3483
Batch 210, Loss: 1.3299
Batch 220, Loss: 1.3812
Batch 230, Loss: 1.3062
Batch 240, Loss: 1.3879
Batch 250, Loss: 1.3947
Batch 260, Loss: 1.3940
Batch 270, Loss: 1.3300
Batch 280, Loss: 1.4048
Batch 290, Loss: 1.3725
Batch 300, Loss: 1.3198
Batch 310, Loss: 1.4238
Batch 320, Loss: 1.4501
Batch 330, Loss: 1.3756
Batch 340, Loss: 1.3842
Batch 350, Loss: 1.4341
Batch 360, Loss: 1.3478
Batch 370, Loss: 1.3262
Batch 380, Loss: 1.3464
Batch 390, Loss: 1.3741
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.15196442604065 seconds
Epoch 60 accuracy: 62.05%
Batch 10, Loss: 1.2624
Batch 20, Loss: 1.3109
Batch 30, Loss: 1.2902
Batch 40, Loss: 1.2883
Batch 50, Loss: 1.3251
Batch 60, Loss: 1.2733
Batch 70, Loss: 1.2707
Batch 80, Loss: 1.2663
Batch 90, Loss: 1.3864
Batch 100, Loss: 1.3372
Batch 110, Loss: 1.3492
Batch 120, Loss: 1.3191
Batch 130, Loss: 1.2954
Batch 140, Loss: 1.3750
Batch 150, Loss: 1.3729
Batch 160, Loss: 1.3146
Batch 170, Loss: 1.3802
Batch 180, Loss: 1.3957
Batch 190, Loss: 1.3175
Batch 200, Loss: 1.4008
Batch 210, Loss: 1.3306
Batch 220, Loss: 1.3659
Batch 230, Loss: 1.4224
Batch 240, Loss: 1.4293
Batch 250, Loss: 1.3534
Batch 260, Loss: 1.3570
Batch 270, Loss: 1.3612
Batch 280, Loss: 1.4646
Batch 290, Loss: 1.3782
Batch 300, Loss: 1.4109
Batch 310, Loss: 1.3753
Batch 320, Loss: 1.3290
Batch 330, Loss: 1.3293
Batch 340, Loss: 1.3794
Batch 350, Loss: 1.3655
Batch 360, Loss: 1.3558
Batch 370, Loss: 1.3608
Batch 380, Loss: 1.3430
Batch 390, Loss: 1.3714
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.024877548217773 seconds
Epoch 61 accuracy: 56.68%
Batch 10, Loss: 1.3250
Batch 20, Loss: 1.3411
Batch 30, Loss: 1.3417
Batch 40, Loss: 1.2281
Batch 50, Loss: 1.3322
Batch 60, Loss: 1.2396
Batch 70, Loss: 1.2917
Batch 80, Loss: 1.3649
Batch 90, Loss: 1.3796
Batch 100, Loss: 1.3012
Batch 110, Loss: 1.2738
Batch 120, Loss: 1.3040
Batch 130, Loss: 1.3709
Batch 140, Loss: 1.2968
Batch 150, Loss: 1.3183
Batch 160, Loss: 1.3072
Batch 170, Loss: 1.3054
Batch 180, Loss: 1.3226
Batch 190, Loss: 1.3511
Batch 200, Loss: 1.3772
Batch 210, Loss: 1.3141
Batch 220, Loss: 1.3272
Batch 230, Loss: 1.3066
Batch 240, Loss: 1.3458
Batch 250, Loss: 1.3996
Batch 260, Loss: 1.3557
Batch 270, Loss: 1.4118
Batch 280, Loss: 1.3649
Batch 290, Loss: 1.3833
Batch 300, Loss: 1.3640
Batch 310, Loss: 1.3899
Batch 320, Loss: 1.3307
Batch 330, Loss: 1.3903
Batch 340, Loss: 1.4095
Batch 350, Loss: 1.4399
Batch 360, Loss: 1.4132
Batch 370, Loss: 1.3620
Batch 380, Loss: 1.3907
Batch 390, Loss: 1.3685
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.066457748413086 seconds
Epoch 62 accuracy: 59.56%
Batch 10, Loss: 1.2952
Batch 20, Loss: 1.3002
Batch 30, Loss: 1.3229
Batch 40, Loss: 1.2979
Batch 50, Loss: 1.2546
Batch 60, Loss: 1.2824
Batch 70, Loss: 1.3472
Batch 80, Loss: 1.3369
Batch 90, Loss: 1.3111
Batch 100, Loss: 1.3168
Batch 110, Loss: 1.2977
Batch 120, Loss: 1.3459
Batch 130, Loss: 1.2792
Batch 140, Loss: 1.3648
Batch 150, Loss: 1.3333
Batch 160, Loss: 1.3374
Batch 170, Loss: 1.3760
Batch 180, Loss: 1.3478
Batch 190, Loss: 1.3490
Batch 200, Loss: 1.3786
Batch 210, Loss: 1.3280
Batch 220, Loss: 1.3757
Batch 230, Loss: 1.3844
Batch 240, Loss: 1.3605
Batch 250, Loss: 1.4371
Batch 260, Loss: 1.3324
Batch 270, Loss: 1.3323
Batch 280, Loss: 1.3519
Batch 290, Loss: 1.4257
Batch 300, Loss: 1.4124
Batch 310, Loss: 1.3931
Batch 320, Loss: 1.4092
Batch 330, Loss: 1.2630
Batch 340, Loss: 1.3927
Batch 350, Loss: 1.3069
Batch 360, Loss: 1.3092
Batch 370, Loss: 1.3712
Batch 380, Loss: 1.3857
Batch 390, Loss: 1.3966
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.112897157669067 seconds
Epoch 63 accuracy: 60.91%
Batch 10, Loss: 1.2835
Batch 20, Loss: 1.3108
Batch 30, Loss: 1.2923
Batch 40, Loss: 1.3477
Batch 50, Loss: 1.3185
Batch 60, Loss: 1.3339
Batch 70, Loss: 1.2989
Batch 80, Loss: 1.3249
Batch 90, Loss: 1.2951
Batch 100, Loss: 1.2948
Batch 110, Loss: 1.3306
Batch 120, Loss: 1.3107
Batch 130, Loss: 1.3462
Batch 140, Loss: 1.2999
Batch 150, Loss: 1.3359
Batch 160, Loss: 1.3583
Batch 170, Loss: 1.3438
Batch 180, Loss: 1.2840
Batch 190, Loss: 1.2948
Batch 200, Loss: 1.2414
Batch 210, Loss: 1.2892
Batch 220, Loss: 1.3284
Batch 230, Loss: 1.3034
Batch 240, Loss: 1.4017
Batch 250, Loss: 1.3193
Batch 260, Loss: 1.3432
Batch 270, Loss: 1.3386
Batch 280, Loss: 1.3062
Batch 290, Loss: 1.3345
Batch 300, Loss: 1.3142
Batch 310, Loss: 1.2954
Batch 320, Loss: 1.3742
Batch 330, Loss: 1.3561
Batch 340, Loss: 1.3467
Batch 350, Loss: 1.3076
Batch 360, Loss: 1.3325
Batch 370, Loss: 1.3051
Batch 380, Loss: 1.3199
Batch 390, Loss: 1.3357
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.073338985443115 seconds
Epoch 64 accuracy: 60.59%
Batch 10, Loss: 1.3153
Batch 20, Loss: 1.2431
Batch 30, Loss: 1.2723
Batch 40, Loss: 1.2494
Batch 50, Loss: 1.2890
Batch 60, Loss: 1.2973
Batch 70, Loss: 1.3040
Batch 80, Loss: 1.2910
Batch 90, Loss: 1.2739
Batch 100, Loss: 1.2910
Batch 110, Loss: 1.3008
Batch 120, Loss: 1.3268
Batch 130, Loss: 1.3745
Batch 140, Loss: 1.2512
Batch 150, Loss: 1.3284
Batch 160, Loss: 1.2634
Batch 170, Loss: 1.3311
Batch 180, Loss: 1.3636
Batch 190, Loss: 1.3098
Batch 200, Loss: 1.2532
Batch 210, Loss: 1.3685
Batch 220, Loss: 1.3417
Batch 230, Loss: 1.3462
Batch 240, Loss: 1.3875
Batch 250, Loss: 1.3306
Batch 260, Loss: 1.3133
Batch 270, Loss: 1.3325
Batch 280, Loss: 1.3774
Batch 290, Loss: 1.2970
Batch 300, Loss: 1.2972
Batch 310, Loss: 1.2746
Batch 320, Loss: 1.3040
Batch 330, Loss: 1.3158
Batch 340, Loss: 1.3562
Batch 350, Loss: 1.3748
Batch 360, Loss: 1.3570
Batch 370, Loss: 1.3745
Batch 380, Loss: 1.3604
Batch 390, Loss: 1.3410
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.115323066711426 seconds
Epoch 65 accuracy: 62.3%
Batch 10, Loss: 1.3138
Batch 20, Loss: 1.2708
Batch 30, Loss: 1.2399
Batch 40, Loss: 1.2313
Batch 50, Loss: 1.2823
Batch 60, Loss: 1.3047
Batch 70, Loss: 1.2433
Batch 80, Loss: 1.2827
Batch 90, Loss: 1.2918
Batch 100, Loss: 1.3747
Batch 110, Loss: 1.3542
Batch 120, Loss: 1.3364
Batch 130, Loss: 1.4153
Batch 140, Loss: 1.3251
Batch 150, Loss: 1.3099
Batch 160, Loss: 1.3940
Batch 170, Loss: 1.3091
Batch 180, Loss: 1.3261
Batch 190, Loss: 1.2236
Batch 200, Loss: 1.3250
Batch 210, Loss: 1.2938
Batch 220, Loss: 1.3091
Batch 230, Loss: 1.2980
Batch 240, Loss: 1.3213
Batch 250, Loss: 1.3750
Batch 260, Loss: 1.2778
Batch 270, Loss: 1.3844
Batch 280, Loss: 1.3099
Batch 290, Loss: 1.3135
Batch 300, Loss: 1.3590
Batch 310, Loss: 1.3147
Batch 320, Loss: 1.3798
Batch 330, Loss: 1.3602
Batch 340, Loss: 1.3784
Batch 350, Loss: 1.3077
Batch 360, Loss: 1.3733
Batch 370, Loss: 1.3533
Batch 380, Loss: 1.3803
Batch 390, Loss: 1.2949
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.101260662078857 seconds
Epoch 66 accuracy: 61.74%
Batch 10, Loss: 1.2410
Batch 20, Loss: 1.2739
Batch 30, Loss: 1.2191
Batch 40, Loss: 1.3109
Batch 50, Loss: 1.2581
Batch 60, Loss: 1.3184
Batch 70, Loss: 1.2520
Batch 80, Loss: 1.3414
Batch 90, Loss: 1.3211
Batch 100, Loss: 1.2526
Batch 110, Loss: 1.2583
Batch 120, Loss: 1.2292
Batch 130, Loss: 1.3447
Batch 140, Loss: 1.2666
Batch 150, Loss: 1.2456
Batch 160, Loss: 1.3424
Batch 170, Loss: 1.3650
Batch 180, Loss: 1.2685
Batch 190, Loss: 1.3186
Batch 200, Loss: 1.2919
Batch 210, Loss: 1.3286
Batch 220, Loss: 1.2689
Batch 230, Loss: 1.3664
Batch 240, Loss: 1.3335
Batch 250, Loss: 1.3161
Batch 260, Loss: 1.2891
Batch 270, Loss: 1.3001
Batch 280, Loss: 1.2754
Batch 290, Loss: 1.3017
Batch 300, Loss: 1.3348
Batch 310, Loss: 1.3412
Batch 320, Loss: 1.2974
Batch 330, Loss: 1.4292
Batch 340, Loss: 1.3586
Batch 350, Loss: 1.3322
Batch 360, Loss: 1.3428
Batch 370, Loss: 1.3892
Batch 380, Loss: 1.3709
Batch 390, Loss: 1.4416
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.14435338973999 seconds
Epoch 67 accuracy: 59.99%
Batch 10, Loss: 1.2407
Batch 20, Loss: 1.3145
Batch 30, Loss: 1.2723
Batch 40, Loss: 1.2117
Batch 50, Loss: 1.2478
Batch 60, Loss: 1.2154
Batch 70, Loss: 1.2988
Batch 80, Loss: 1.3096
Batch 90, Loss: 1.3362
Batch 100, Loss: 1.2495
Batch 110, Loss: 1.2515
Batch 120, Loss: 1.2922
Batch 130, Loss: 1.2719
Batch 140, Loss: 1.3888
Batch 150, Loss: 1.3560
Batch 160, Loss: 1.3590
Batch 170, Loss: 1.3304
Batch 180, Loss: 1.3697
Batch 190, Loss: 1.3497
Batch 200, Loss: 1.3259
Batch 210, Loss: 1.3631
Batch 220, Loss: 1.3870
Batch 230, Loss: 1.3441
Batch 240, Loss: 1.2461
Batch 250, Loss: 1.3364
Batch 260, Loss: 1.2924
Batch 270, Loss: 1.3892
Batch 280, Loss: 1.3843
Batch 290, Loss: 1.2210
Batch 300, Loss: 1.3794
Batch 310, Loss: 1.3525
Batch 320, Loss: 1.2752
Batch 330, Loss: 1.2806
Batch 340, Loss: 1.3013
Batch 350, Loss: 1.3818
Batch 360, Loss: 1.3721
Batch 370, Loss: 1.3063
Batch 380, Loss: 1.2506
Batch 390, Loss: 1.3669
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.057597398757935 seconds
Epoch 68 accuracy: 60.21%
Batch 10, Loss: 1.2163
Batch 20, Loss: 1.3266
Batch 30, Loss: 1.2098
Batch 40, Loss: 1.2891
Batch 50, Loss: 1.3088
Batch 60, Loss: 1.3699
Batch 70, Loss: 1.3251
Batch 80, Loss: 1.1928
Batch 90, Loss: 1.2788
Batch 100, Loss: 1.2922
Batch 110, Loss: 1.2737
Batch 120, Loss: 1.2697
Batch 130, Loss: 1.2648
Batch 140, Loss: 1.2856
Batch 150, Loss: 1.2664
Batch 160, Loss: 1.2995
Batch 170, Loss: 1.3134
Batch 180, Loss: 1.2892
Batch 190, Loss: 1.3239
Batch 200, Loss: 1.3240
Batch 210, Loss: 1.3321
Batch 220, Loss: 1.2985
Batch 230, Loss: 1.3221
Batch 240, Loss: 1.3641
Batch 250, Loss: 1.3177
Batch 260, Loss: 1.2699
Batch 270, Loss: 1.3266
Batch 280, Loss: 1.3062
Batch 290, Loss: 1.2918
Batch 300, Loss: 1.3578
Batch 310, Loss: 1.3313
Batch 320, Loss: 1.3520
Batch 330, Loss: 1.3299
Batch 340, Loss: 1.3418
Batch 350, Loss: 1.3654
Batch 360, Loss: 1.3583
Batch 370, Loss: 1.2810
Batch 380, Loss: 1.3141
Batch 390, Loss: 1.2710
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.03566575050354 seconds
Epoch 69 accuracy: 62.66%
Batch 10, Loss: 1.2943
Batch 20, Loss: 1.2100
Batch 30, Loss: 1.2817
Batch 40, Loss: 1.2645
Batch 50, Loss: 1.2729
Batch 60, Loss: 1.2736
Batch 70, Loss: 1.3089
Batch 80, Loss: 1.2575
Batch 90, Loss: 1.3124
Batch 100, Loss: 1.2013
Batch 110, Loss: 1.2701
Batch 120, Loss: 1.2550
Batch 130, Loss: 1.2357
Batch 140, Loss: 1.3202
Batch 150, Loss: 1.2302
Batch 160, Loss: 1.2562
Batch 170, Loss: 1.2709
Batch 180, Loss: 1.3266
Batch 190, Loss: 1.2944
Batch 200, Loss: 1.2880
Batch 210, Loss: 1.3222
Batch 220, Loss: 1.3001
Batch 230, Loss: 1.3370
Batch 240, Loss: 1.3478
Batch 250, Loss: 1.3339
Batch 260, Loss: 1.3248
Batch 270, Loss: 1.3093
Batch 280, Loss: 1.2717
Batch 290, Loss: 1.3104
Batch 300, Loss: 1.3510
Batch 310, Loss: 1.3344
Batch 320, Loss: 1.3364
Batch 330, Loss: 1.3037
Batch 340, Loss: 1.3867
Batch 350, Loss: 1.3489
Batch 360, Loss: 1.3391
Batch 370, Loss: 1.3336
Batch 380, Loss: 1.3613
Batch 390, Loss: 1.3336
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.096397161483765 seconds
Epoch 70 accuracy: 62.45%
Batch 10, Loss: 1.3168
Batch 20, Loss: 1.2311
Batch 30, Loss: 1.2232
Batch 40, Loss: 1.2710
Batch 50, Loss: 1.3072
Batch 60, Loss: 1.2099
Batch 70, Loss: 1.2652
Batch 80, Loss: 1.2096
Batch 90, Loss: 1.2752
Batch 100, Loss: 1.2063
Batch 110, Loss: 1.2739
Batch 120, Loss: 1.2892
Batch 130, Loss: 1.3050
Batch 140, Loss: 1.3088
Batch 150, Loss: 1.2256
Batch 160, Loss: 1.3059
Batch 170, Loss: 1.3335
Batch 180, Loss: 1.2584
Batch 190, Loss: 1.3442
Batch 200, Loss: 1.3023
Batch 210, Loss: 1.2415
Batch 220, Loss: 1.2573
Batch 230, Loss: 1.2230
Batch 240, Loss: 1.2294
Batch 250, Loss: 1.2725
Batch 260, Loss: 1.3248
Batch 270, Loss: 1.2962
Batch 280, Loss: 1.2440
Batch 290, Loss: 1.3591
Batch 300, Loss: 1.3538
Batch 310, Loss: 1.3250
Batch 320, Loss: 1.3145
Batch 330, Loss: 1.3467
Batch 340, Loss: 1.3009
Batch 350, Loss: 1.3731
Batch 360, Loss: 1.3560
Batch 370, Loss: 1.4035
Batch 380, Loss: 1.2701
Batch 390, Loss: 1.3229
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.12352466583252 seconds
Epoch 71 accuracy: 63.21%
Batch 10, Loss: 1.2486
Batch 20, Loss: 1.1992
Batch 30, Loss: 1.3149
Batch 40, Loss: 1.2436
Batch 50, Loss: 1.2492
Batch 60, Loss: 1.2449
Batch 70, Loss: 1.2654
Batch 80, Loss: 1.2392
Batch 90, Loss: 1.2481
Batch 100, Loss: 1.2379
Batch 110, Loss: 1.2617
Batch 120, Loss: 1.2363
Batch 130, Loss: 1.3172
Batch 140, Loss: 1.2341
Batch 150, Loss: 1.2713
Batch 160, Loss: 1.3227
Batch 170, Loss: 1.2741
Batch 180, Loss: 1.2104
Batch 190, Loss: 1.3387
Batch 200, Loss: 1.3537
Batch 210, Loss: 1.2513
Batch 220, Loss: 1.3359
Batch 230, Loss: 1.3118
Batch 240, Loss: 1.3528
Batch 250, Loss: 1.2068
Batch 260, Loss: 1.3151
Batch 270, Loss: 1.3646
Batch 280, Loss: 1.3424
Batch 290, Loss: 1.3175
Batch 300, Loss: 1.3019
Batch 310, Loss: 1.3015
Batch 320, Loss: 1.3514
Batch 330, Loss: 1.2831
Batch 340, Loss: 1.2530
Batch 350, Loss: 1.2988
Batch 360, Loss: 1.2801
Batch 370, Loss: 1.2898
Batch 380, Loss: 1.2324
Batch 390, Loss: 1.2940
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.055211305618286 seconds
Epoch 72 accuracy: 58.93%
Batch 10, Loss: 1.1929
Batch 20, Loss: 1.2811
Batch 30, Loss: 1.2734
Batch 40, Loss: 1.2985
Batch 50, Loss: 1.1696
Batch 60, Loss: 1.1552
Batch 70, Loss: 1.1818
Batch 80, Loss: 1.2482
Batch 90, Loss: 1.2027
Batch 100, Loss: 1.2498
Batch 110, Loss: 1.2588
Batch 120, Loss: 1.2214
Batch 130, Loss: 1.2596
Batch 140, Loss: 1.3199
Batch 150, Loss: 1.2975
Batch 160, Loss: 1.2736
Batch 170, Loss: 1.2215
Batch 180, Loss: 1.2558
Batch 190, Loss: 1.2786
Batch 200, Loss: 1.3043
Batch 210, Loss: 1.2619
Batch 220, Loss: 1.3145
Batch 230, Loss: 1.2962
Batch 240, Loss: 1.2701
Batch 250, Loss: 1.2591
Batch 260, Loss: 1.2824
Batch 270, Loss: 1.3092
Batch 280, Loss: 1.3194
Batch 290, Loss: 1.3287
Batch 300, Loss: 1.3446
Batch 310, Loss: 1.3282
Batch 320, Loss: 1.3048
Batch 330, Loss: 1.3020
Batch 340, Loss: 1.3733
Batch 350, Loss: 1.2978
Batch 360, Loss: 1.2885
Batch 370, Loss: 1.2758
Batch 380, Loss: 1.3003
Batch 390, Loss: 1.3452
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.071577072143555 seconds
Epoch 73 accuracy: 61.58%
Batch 10, Loss: 1.2529
Batch 20, Loss: 1.3009
Batch 30, Loss: 1.2087
Batch 40, Loss: 1.2040
Batch 50, Loss: 1.2805
Batch 60, Loss: 1.2830
Batch 70, Loss: 1.2546
Batch 80, Loss: 1.2938
Batch 90, Loss: 1.3080
Batch 100, Loss: 1.2439
Batch 110, Loss: 1.1925
Batch 120, Loss: 1.2263
Batch 130, Loss: 1.2367
Batch 140, Loss: 1.2670
Batch 150, Loss: 1.2838
Batch 160, Loss: 1.2111
Batch 170, Loss: 1.3061
Batch 180, Loss: 1.3296
Batch 190, Loss: 1.3534
Batch 200, Loss: 1.2675
Batch 210, Loss: 1.3601
Batch 220, Loss: 1.2354
Batch 230, Loss: 1.2454
Batch 240, Loss: 1.3037
Batch 250, Loss: 1.3072
Batch 260, Loss: 1.2698
Batch 270, Loss: 1.2283
Batch 280, Loss: 1.3096
Batch 290, Loss: 1.3102
Batch 300, Loss: 1.3006
Batch 310, Loss: 1.2511
Batch 320, Loss: 1.2712
Batch 330, Loss: 1.2962
Batch 340, Loss: 1.3109
Batch 350, Loss: 1.3402
Batch 360, Loss: 1.2735
Batch 370, Loss: 1.3175
Batch 380, Loss: 1.3194
Batch 390, Loss: 1.3495
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.204406261444092 seconds
Epoch 74 accuracy: 61.99%
Batch 10, Loss: 1.2490
Batch 20, Loss: 1.2315
Batch 30, Loss: 1.2616
Batch 40, Loss: 1.2080
Batch 50, Loss: 1.2584
Batch 60, Loss: 1.2014
Batch 70, Loss: 1.2977
Batch 80, Loss: 1.1727
Batch 90, Loss: 1.1910
Batch 100, Loss: 1.2421
Batch 110, Loss: 1.3068
Batch 120, Loss: 1.2703
Batch 130, Loss: 1.2582
Batch 140, Loss: 1.2953
Batch 150, Loss: 1.1974
Batch 160, Loss: 1.2268
Batch 170, Loss: 1.2314
Batch 180, Loss: 1.3459
Batch 190, Loss: 1.2492
Batch 200, Loss: 1.2743
Batch 210, Loss: 1.2936
Batch 220, Loss: 1.3429
Batch 230, Loss: 1.2725
Batch 240, Loss: 1.2707
Batch 250, Loss: 1.3463
Batch 260, Loss: 1.2578
Batch 270, Loss: 1.3179
Batch 280, Loss: 1.3428
Batch 290, Loss: 1.3305
Batch 300, Loss: 1.2659
Batch 310, Loss: 1.2841
Batch 320, Loss: 1.3227
Batch 330, Loss: 1.2560
Batch 340, Loss: 1.3171
Batch 350, Loss: 1.3259
Batch 360, Loss: 1.2198
Batch 370, Loss: 1.2146
Batch 380, Loss: 1.2852
Batch 390, Loss: 1.2284
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 25.37897753715515 seconds
Epoch 75 accuracy: 58.14%
Batch 10, Loss: 1.2585
Batch 20, Loss: 1.2612
Batch 30, Loss: 1.2378
Batch 40, Loss: 1.2322
Batch 50, Loss: 1.2335
Batch 60, Loss: 1.2244
Batch 70, Loss: 1.2915
Batch 80, Loss: 1.2460
Batch 90, Loss: 1.2790
Batch 100, Loss: 1.2456
Batch 110, Loss: 1.2804
Batch 120, Loss: 1.2430
Batch 130, Loss: 1.2459
Batch 140, Loss: 1.2864
Batch 150, Loss: 1.2206
Batch 160, Loss: 1.2690
Batch 170, Loss: 1.2294
Batch 180, Loss: 1.1925
Batch 190, Loss: 1.2871
Batch 200, Loss: 1.2358
Batch 210, Loss: 1.2488
Batch 220, Loss: 1.2054
Batch 230, Loss: 1.2887
Batch 240, Loss: 1.2967
Batch 250, Loss: 1.3234
Batch 260, Loss: 1.3262
Batch 270, Loss: 1.2626
Batch 280, Loss: 1.2953
Batch 290, Loss: 1.3067
Batch 300, Loss: 1.2422
Batch 310, Loss: 1.2830
Batch 320, Loss: 1.2905
Batch 330, Loss: 1.2444
Batch 340, Loss: 1.3070
Batch 350, Loss: 1.2849
Batch 360, Loss: 1.2773
Batch 370, Loss: 1.3544
Batch 380, Loss: 1.2984
Batch 390, Loss: 1.2609
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.17065191268921 seconds
Epoch 76 accuracy: 62.88%
Batch 10, Loss: 1.1705
Batch 20, Loss: 1.1690
Batch 30, Loss: 1.2350
Batch 40, Loss: 1.2531
Batch 50, Loss: 1.2240
Batch 60, Loss: 1.2157
Batch 70, Loss: 1.2651
Batch 80, Loss: 1.2171
Batch 90, Loss: 1.2339
Batch 100, Loss: 1.2655
Batch 110, Loss: 1.2758
Batch 120, Loss: 1.3062
Batch 130, Loss: 1.3086
Batch 140, Loss: 1.2055
Batch 150, Loss: 1.2437
Batch 160, Loss: 1.2783
Batch 170, Loss: 1.3360
Batch 180, Loss: 1.2851
Batch 190, Loss: 1.2383
Batch 200, Loss: 1.2377
Batch 210, Loss: 1.2308
Batch 220, Loss: 1.1914
Batch 230, Loss: 1.2062
Batch 240, Loss: 1.2848
Batch 250, Loss: 1.3172
Batch 260, Loss: 1.2863
Batch 270, Loss: 1.1904
Batch 280, Loss: 1.3895
Batch 290, Loss: 1.2596
Batch 300, Loss: 1.2866
Batch 310, Loss: 1.3052
Batch 320, Loss: 1.2969
Batch 330, Loss: 1.3146
Batch 340, Loss: 1.3180
Batch 350, Loss: 1.3272
Batch 360, Loss: 1.2543
Batch 370, Loss: 1.3039
Batch 380, Loss: 1.3612
Batch 390, Loss: 1.2911
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.165350198745728 seconds
Epoch 77 accuracy: 58.43%
Batch 10, Loss: 1.2603
Batch 20, Loss: 1.2209
Batch 30, Loss: 1.1564
Batch 40, Loss: 1.1653
Batch 50, Loss: 1.2118
Batch 60, Loss: 1.2768
Batch 70, Loss: 1.2453
Batch 80, Loss: 1.2001
Batch 90, Loss: 1.2844
Batch 100, Loss: 1.2436
Batch 110, Loss: 1.2732
Batch 120, Loss: 1.2188
Batch 130, Loss: 1.1905
Batch 140, Loss: 1.2158
Batch 150, Loss: 1.2608
Batch 160, Loss: 1.2862
Batch 170, Loss: 1.2718
Batch 180, Loss: 1.2849
Batch 190, Loss: 1.1686
Batch 200, Loss: 1.2952
Batch 210, Loss: 1.2749
Batch 220, Loss: 1.2400
Batch 230, Loss: 1.2623
Batch 240, Loss: 1.2636
Batch 250, Loss: 1.2614
Batch 260, Loss: 1.3087
Batch 270, Loss: 1.2958
Batch 280, Loss: 1.2385
Batch 290, Loss: 1.2630
Batch 300, Loss: 1.2200
Batch 310, Loss: 1.3234
Batch 320, Loss: 1.2429
Batch 330, Loss: 1.2802
Batch 340, Loss: 1.2586
Batch 350, Loss: 1.2734
Batch 360, Loss: 1.2573
Batch 370, Loss: 1.2908
Batch 380, Loss: 1.2032
Batch 390, Loss: 1.2429
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.093764305114746 seconds
Epoch 78 accuracy: 62.04%
Batch 10, Loss: 1.2116
Batch 20, Loss: 1.2396
Batch 30, Loss: 1.2368
Batch 40, Loss: 1.2211
Batch 50, Loss: 1.2348
Batch 60, Loss: 1.2122
Batch 70, Loss: 1.1914
Batch 80, Loss: 1.2366
Batch 90, Loss: 1.1660
Batch 100, Loss: 1.2885
Batch 110, Loss: 1.2210
Batch 120, Loss: 1.2024
Batch 130, Loss: 1.1717
Batch 140, Loss: 1.2453
Batch 150, Loss: 1.2069
Batch 160, Loss: 1.2434
Batch 170, Loss: 1.2598
Batch 180, Loss: 1.2788
Batch 190, Loss: 1.2970
Batch 200, Loss: 1.2897
Batch 210, Loss: 1.2688
Batch 220, Loss: 1.2429
Batch 230, Loss: 1.2443
Batch 240, Loss: 1.2493
Batch 250, Loss: 1.2361
Batch 260, Loss: 1.2765
Batch 270, Loss: 1.2457
Batch 280, Loss: 1.3164
Batch 290, Loss: 1.2339
Batch 300, Loss: 1.2248
Batch 310, Loss: 1.2154
Batch 320, Loss: 1.2394
Batch 330, Loss: 1.2802
Batch 340, Loss: 1.2526
Batch 350, Loss: 1.2909
Batch 360, Loss: 1.2733
Batch 370, Loss: 1.2800
Batch 380, Loss: 1.2780
Batch 390, Loss: 1.2040
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.017759323120117 seconds
Epoch 79 accuracy: 63.02%
Batch 10, Loss: 1.1688
Batch 20, Loss: 1.1181
Batch 30, Loss: 1.2019
Batch 40, Loss: 1.1873
Batch 50, Loss: 1.1853
Batch 60, Loss: 1.1852
Batch 70, Loss: 1.2207
Batch 80, Loss: 1.1926
Batch 90, Loss: 1.2014
Batch 100, Loss: 1.1919
Batch 110, Loss: 1.2501
Batch 120, Loss: 1.2080
Batch 130, Loss: 1.2565
Batch 140, Loss: 1.2128
Batch 150, Loss: 1.2376
Batch 160, Loss: 1.1567
Batch 170, Loss: 1.2592
Batch 180, Loss: 1.2084
Batch 190, Loss: 1.2311
Batch 200, Loss: 1.2189
Batch 210, Loss: 1.2970
Batch 220, Loss: 1.2822
Batch 230, Loss: 1.1800
Batch 240, Loss: 1.2602
Batch 250, Loss: 1.2906
Batch 260, Loss: 1.2656
Batch 270, Loss: 1.1817
Batch 280, Loss: 1.2778
Batch 290, Loss: 1.2823
Batch 300, Loss: 1.2380
Batch 310, Loss: 1.2770
Batch 320, Loss: 1.3225
Batch 330, Loss: 1.2660
Batch 340, Loss: 1.2250
Batch 350, Loss: 1.2684
Batch 360, Loss: 1.2894
Batch 370, Loss: 1.2258
Batch 380, Loss: 1.2645
Batch 390, Loss: 1.3081
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.039217233657837 seconds
Epoch 80 accuracy: 56.38%
Batch 10, Loss: 1.2274
Batch 20, Loss: 1.1753
Batch 30, Loss: 1.2407
Batch 40, Loss: 1.1917
Batch 50, Loss: 1.1899
Batch 60, Loss: 1.2056
Batch 70, Loss: 1.1287
Batch 80, Loss: 1.2658
Batch 90, Loss: 1.1766
Batch 100, Loss: 1.1855
Batch 110, Loss: 1.1764
Batch 120, Loss: 1.2321
Batch 130, Loss: 1.1871
Batch 140, Loss: 1.1649
Batch 150, Loss: 1.2377
Batch 160, Loss: 1.2252
Batch 170, Loss: 1.2888
Batch 180, Loss: 1.2780
Batch 190, Loss: 1.2897
Batch 200, Loss: 1.2232
Batch 210, Loss: 1.2829
Batch 220, Loss: 1.2087
Batch 230, Loss: 1.2785
Batch 240, Loss: 1.2285
Batch 250, Loss: 1.2107
Batch 260, Loss: 1.2989
Batch 270, Loss: 1.2148
Batch 280, Loss: 1.2071
Batch 290, Loss: 1.2680
Batch 300, Loss: 1.2416
Batch 310, Loss: 1.2085
Batch 320, Loss: 1.2330
Batch 330, Loss: 1.2886
Batch 340, Loss: 1.2981
Batch 350, Loss: 1.2739
Batch 360, Loss: 1.2541
Batch 370, Loss: 1.2382
Batch 380, Loss: 1.2543
Batch 390, Loss: 1.2476
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.034552574157715 seconds
Epoch 81 accuracy: 64.16%
Batch 10, Loss: 1.1856
Batch 20, Loss: 1.1874
Batch 30, Loss: 1.1907
Batch 40, Loss: 1.1528
Batch 50, Loss: 1.1910
Batch 60, Loss: 1.2468
Batch 70, Loss: 1.2424
Batch 80, Loss: 1.2340
Batch 90, Loss: 1.2265
Batch 100, Loss: 1.2047
Batch 110, Loss: 1.2410
Batch 120, Loss: 1.2182
Batch 130, Loss: 1.2123
Batch 140, Loss: 1.2319
Batch 150, Loss: 1.2738
Batch 160, Loss: 1.2492
Batch 170, Loss: 1.2253
Batch 180, Loss: 1.2825
Batch 190, Loss: 1.2205
Batch 200, Loss: 1.1719
Batch 210, Loss: 1.2481
Batch 220, Loss: 1.2427
Batch 230, Loss: 1.2677
Batch 240, Loss: 1.2568
Batch 250, Loss: 1.2241
Batch 260, Loss: 1.2623
Batch 270, Loss: 1.2691
Batch 280, Loss: 1.2370
Batch 290, Loss: 1.3509
Batch 300, Loss: 1.2170
Batch 310, Loss: 1.2667
Batch 320, Loss: 1.2032
Batch 330, Loss: 1.2250
Batch 340, Loss: 1.2858
Batch 350, Loss: 1.2568
Batch 360, Loss: 1.3062
Batch 370, Loss: 1.2672
Batch 380, Loss: 1.2054
Batch 390, Loss: 1.2292
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.136768579483032 seconds
Epoch 82 accuracy: 63.45%
Batch 10, Loss: 1.1987
Batch 20, Loss: 1.1914
Batch 30, Loss: 1.1487
Batch 40, Loss: 1.1801
Batch 50, Loss: 1.1567
Batch 60, Loss: 1.1813
Batch 70, Loss: 1.2225
Batch 80, Loss: 1.1564
Batch 90, Loss: 1.2007
Batch 100, Loss: 1.2396
Batch 110, Loss: 1.1506
Batch 120, Loss: 1.1751
Batch 130, Loss: 1.2279
Batch 140, Loss: 1.1389
Batch 150, Loss: 1.1649
Batch 160, Loss: 1.2878
Batch 170, Loss: 1.1932
Batch 180, Loss: 1.1947
Batch 190, Loss: 1.2149
Batch 200, Loss: 1.1807
Batch 210, Loss: 1.1965
Batch 220, Loss: 1.1707
Batch 230, Loss: 1.2011
Batch 240, Loss: 1.2795
Batch 250, Loss: 1.2035
Batch 260, Loss: 1.2148
Batch 270, Loss: 1.3008
Batch 280, Loss: 1.1904
Batch 290, Loss: 1.2245
Batch 300, Loss: 1.2496
Batch 310, Loss: 1.2581
Batch 320, Loss: 1.3118
Batch 330, Loss: 1.2204
Batch 340, Loss: 1.2148
Batch 350, Loss: 1.2641
Batch 360, Loss: 1.2347
Batch 370, Loss: 1.3300
Batch 380, Loss: 1.2540
Batch 390, Loss: 1.2379
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.02591323852539 seconds
Epoch 83 accuracy: 64.17%
Batch 10, Loss: 1.1208
Batch 20, Loss: 1.1898
Batch 30, Loss: 1.1154
Batch 40, Loss: 1.1570
Batch 50, Loss: 1.1363
Batch 60, Loss: 1.1497
Batch 70, Loss: 1.2330
Batch 80, Loss: 1.2036
Batch 90, Loss: 1.1988
Batch 100, Loss: 1.1049
Batch 110, Loss: 1.2293
Batch 120, Loss: 1.2408
Batch 130, Loss: 1.2338
Batch 140, Loss: 1.2415
Batch 150, Loss: 1.2543
Batch 160, Loss: 1.1994
Batch 170, Loss: 1.1721
Batch 180, Loss: 1.1900
Batch 190, Loss: 1.1820
Batch 200, Loss: 1.1676
Batch 210, Loss: 1.1327
Batch 220, Loss: 1.1615
Batch 230, Loss: 1.2432
Batch 240, Loss: 1.2546
Batch 250, Loss: 1.2328
Batch 260, Loss: 1.2262
Batch 270, Loss: 1.2170
Batch 280, Loss: 1.1930
Batch 290, Loss: 1.2186
Batch 300, Loss: 1.2579
Batch 310, Loss: 1.2504
Batch 320, Loss: 1.2578
Batch 330, Loss: 1.2201
Batch 340, Loss: 1.1514
Batch 350, Loss: 1.2843
Batch 360, Loss: 1.2833
Batch 370, Loss: 1.2896
Batch 380, Loss: 1.2445
Batch 390, Loss: 1.2574
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.1549654006958 seconds
Epoch 84 accuracy: 61.23%
Batch 10, Loss: 1.1903
Batch 20, Loss: 1.1872
Batch 30, Loss: 1.1432
Batch 40, Loss: 1.1734
Batch 50, Loss: 1.1715
Batch 60, Loss: 1.1284
Batch 70, Loss: 1.1405
Batch 80, Loss: 1.1207
Batch 90, Loss: 1.1996
Batch 100, Loss: 1.1269
Batch 110, Loss: 1.2229
Batch 120, Loss: 1.1973
Batch 130, Loss: 1.1985
Batch 140, Loss: 1.1710
Batch 150, Loss: 1.1377
Batch 160, Loss: 1.2377
Batch 170, Loss: 1.1659
Batch 180, Loss: 1.2353
Batch 190, Loss: 1.1755
Batch 200, Loss: 1.2666
Batch 210, Loss: 1.2585
Batch 220, Loss: 1.2718
Batch 230, Loss: 1.3077
Batch 240, Loss: 1.1839
Batch 250, Loss: 1.2104
Batch 260, Loss: 1.1324
Batch 270, Loss: 1.1909
Batch 280, Loss: 1.2236
Batch 290, Loss: 1.2373
Batch 300, Loss: 1.1344
Batch 310, Loss: 1.2431
Batch 320, Loss: 1.2299
Batch 330, Loss: 1.2054
Batch 340, Loss: 1.2002
Batch 350, Loss: 1.2361
Batch 360, Loss: 1.2206
Batch 370, Loss: 1.2568
Batch 380, Loss: 1.2476
Batch 390, Loss: 1.1864
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.08161163330078 seconds
Epoch 85 accuracy: 64.22%
Batch 10, Loss: 1.1417
Batch 20, Loss: 1.1310
Batch 30, Loss: 1.1919
Batch 40, Loss: 1.1488
Batch 50, Loss: 1.1737
Batch 60, Loss: 1.1580
Batch 70, Loss: 1.2149
Batch 80, Loss: 1.1588
Batch 90, Loss: 1.1108
Batch 100, Loss: 1.2019
Batch 110, Loss: 1.1983
Batch 120, Loss: 1.2162
Batch 130, Loss: 1.1681
Batch 140, Loss: 1.2162
Batch 150, Loss: 1.2384
Batch 160, Loss: 1.1992
Batch 170, Loss: 1.2426
Batch 180, Loss: 1.1995
Batch 190, Loss: 1.1334
Batch 200, Loss: 1.1650
Batch 210, Loss: 1.1654
Batch 220, Loss: 1.2215
Batch 230, Loss: 1.1742
Batch 240, Loss: 1.1994
Batch 250, Loss: 1.2342
Batch 260, Loss: 1.1423
Batch 270, Loss: 1.2152
Batch 280, Loss: 1.2073
Batch 290, Loss: 1.2783
Batch 300, Loss: 1.2733
Batch 310, Loss: 1.2291
Batch 320, Loss: 1.2335
Batch 330, Loss: 1.2196
Batch 340, Loss: 1.2007
Batch 350, Loss: 1.2027
Batch 360, Loss: 1.2503
Batch 370, Loss: 1.2253
Batch 380, Loss: 1.2309
Batch 390, Loss: 1.2526
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.093985319137573 seconds
Epoch 86 accuracy: 64.41%
Batch 10, Loss: 1.1806
Batch 20, Loss: 1.1624
Batch 30, Loss: 1.1860
Batch 40, Loss: 1.1932
Batch 50, Loss: 1.1756
Batch 60, Loss: 1.1615
Batch 70, Loss: 1.1663
Batch 80, Loss: 1.1660
Batch 90, Loss: 1.2050
Batch 100, Loss: 1.2399
Batch 110, Loss: 1.1895
Batch 120, Loss: 1.2488
Batch 130, Loss: 1.1634
Batch 140, Loss: 1.2205
Batch 150, Loss: 1.1915
Batch 160, Loss: 1.2040
Batch 170, Loss: 1.1852
Batch 180, Loss: 1.1115
Batch 190, Loss: 1.1569
Batch 200, Loss: 1.2086
Batch 210, Loss: 1.1849
Batch 220, Loss: 1.2150
Batch 230, Loss: 1.2484
Batch 240, Loss: 1.1880
Batch 250, Loss: 1.1765
Batch 260, Loss: 1.2213
Batch 270, Loss: 1.1977
Batch 280, Loss: 1.2452
Batch 290, Loss: 1.1945
Batch 300, Loss: 1.2023
Batch 310, Loss: 1.2105
Batch 320, Loss: 1.1933
Batch 330, Loss: 1.2060
Batch 340, Loss: 1.2952
Batch 350, Loss: 1.2138
Batch 360, Loss: 1.2549
Batch 370, Loss: 1.1711
Batch 380, Loss: 1.2801
Batch 390, Loss: 1.2666
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.016722202301025 seconds
Epoch 87 accuracy: 62.09%
Batch 10, Loss: 1.2033
Batch 20, Loss: 1.1360
Batch 30, Loss: 1.1457
Batch 40, Loss: 1.1261
Batch 50, Loss: 1.1466
Batch 60, Loss: 1.2107
Batch 70, Loss: 1.1790
Batch 80, Loss: 1.1222
Batch 90, Loss: 1.1369
Batch 100, Loss: 1.2036
Batch 110, Loss: 1.1490
Batch 120, Loss: 1.1428
Batch 130, Loss: 1.1345
Batch 140, Loss: 1.2203
Batch 150, Loss: 1.1717
Batch 160, Loss: 1.1662
Batch 170, Loss: 1.1972
Batch 180, Loss: 1.1776
Batch 190, Loss: 1.1232
Batch 200, Loss: 1.1646
Batch 210, Loss: 1.1563
Batch 220, Loss: 1.1865
Batch 230, Loss: 1.2261
Batch 240, Loss: 1.2098
Batch 250, Loss: 1.2015
Batch 260, Loss: 1.2218
Batch 270, Loss: 1.1626
Batch 280, Loss: 1.2088
Batch 290, Loss: 1.1480
Batch 300, Loss: 1.1843
Batch 310, Loss: 1.2060
Batch 320, Loss: 1.1753
Batch 330, Loss: 1.2313
Batch 340, Loss: 1.1894
Batch 350, Loss: 1.1578
Batch 360, Loss: 1.1645
Batch 370, Loss: 1.2210
Batch 380, Loss: 1.1776
Batch 390, Loss: 1.2204
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.134870767593384 seconds
Epoch 88 accuracy: 62.34%
Batch 10, Loss: 1.0748
Batch 20, Loss: 1.0867
Batch 30, Loss: 1.1513
Batch 40, Loss: 1.1582
Batch 50, Loss: 1.1217
Batch 60, Loss: 1.1307
Batch 70, Loss: 1.1263
Batch 80, Loss: 1.2103
Batch 90, Loss: 1.1320
Batch 100, Loss: 1.1861
Batch 110, Loss: 1.1515
Batch 120, Loss: 1.1860
Batch 130, Loss: 1.2117
Batch 140, Loss: 1.1276
Batch 150, Loss: 1.2207
Batch 160, Loss: 1.1353
Batch 170, Loss: 1.1991
Batch 180, Loss: 1.1703
Batch 190, Loss: 1.2330
Batch 200, Loss: 1.2207
Batch 210, Loss: 1.1804
Batch 220, Loss: 1.1750
Batch 230, Loss: 1.1982
Batch 240, Loss: 1.1725
Batch 250, Loss: 1.2339
Batch 260, Loss: 1.2138
Batch 270, Loss: 1.2126
Batch 280, Loss: 1.1942
Batch 290, Loss: 1.1937
Batch 300, Loss: 1.2132
Batch 310, Loss: 1.1749
Batch 320, Loss: 1.2190
Batch 330, Loss: 1.2325
Batch 340, Loss: 1.1856
Batch 350, Loss: 1.1847
Batch 360, Loss: 1.1778
Batch 370, Loss: 1.2160
Batch 380, Loss: 1.2313
Batch 390, Loss: 1.1422
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.071152687072754 seconds
Epoch 89 accuracy: 64.08%
Batch 10, Loss: 1.1301
Batch 20, Loss: 1.1689
Batch 30, Loss: 1.1459
Batch 40, Loss: 1.1711
Batch 50, Loss: 1.1309
Batch 60, Loss: 1.1066
Batch 70, Loss: 1.1269
Batch 80, Loss: 1.1594
Batch 90, Loss: 1.1070
Batch 100, Loss: 1.1676
Batch 110, Loss: 1.1457
Batch 120, Loss: 1.1504
Batch 130, Loss: 1.1167
Batch 140, Loss: 1.1260
Batch 150, Loss: 1.2011
Batch 160, Loss: 1.1975
Batch 170, Loss: 1.2439
Batch 180, Loss: 1.1931
Batch 190, Loss: 1.2543
Batch 200, Loss: 1.1404
Batch 210, Loss: 1.1325
Batch 220, Loss: 1.1778
Batch 230, Loss: 1.1305
Batch 240, Loss: 1.1804
Batch 250, Loss: 1.1878
Batch 260, Loss: 1.0951
Batch 270, Loss: 1.1720
Batch 280, Loss: 1.1809
Batch 290, Loss: 1.2735
Batch 300, Loss: 1.2232
Batch 310, Loss: 1.1865
Batch 320, Loss: 1.1777
Batch 330, Loss: 1.2261
Batch 340, Loss: 1.2625
Batch 350, Loss: 1.2076
Batch 360, Loss: 1.2371
Batch 370, Loss: 1.1838
Batch 380, Loss: 1.1783
Batch 390, Loss: 1.1711
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.056646585464478 seconds
Epoch 90 accuracy: 61.68%
Batch 10, Loss: 1.0619
Batch 20, Loss: 1.1281
Batch 30, Loss: 1.1533
Batch 40, Loss: 1.1344
Batch 50, Loss: 1.1284
Batch 60, Loss: 1.0818
Batch 70, Loss: 1.1413
Batch 80, Loss: 1.1884
Batch 90, Loss: 1.1673
Batch 100, Loss: 1.1173
Batch 110, Loss: 1.1856
Batch 120, Loss: 1.2205
Batch 130, Loss: 1.2277
Batch 140, Loss: 1.1398
Batch 150, Loss: 1.1366
Batch 160, Loss: 1.1871
Batch 170, Loss: 1.0880
Batch 180, Loss: 1.1863
Batch 190, Loss: 1.1667
Batch 200, Loss: 1.2391
Batch 210, Loss: 1.1701
Batch 220, Loss: 1.1736
Batch 230, Loss: 1.1721
Batch 240, Loss: 1.1668
Batch 250, Loss: 1.1552
Batch 260, Loss: 1.2197
Batch 270, Loss: 1.1961
Batch 280, Loss: 1.1694
Batch 290, Loss: 1.1130
Batch 300, Loss: 1.1089
Batch 310, Loss: 1.1806
Batch 320, Loss: 1.1611
Batch 330, Loss: 1.1785
Batch 340, Loss: 1.1863
Batch 350, Loss: 1.1286
Batch 360, Loss: 1.2546
Batch 370, Loss: 1.1415
Batch 380, Loss: 1.2862
Batch 390, Loss: 1.1891
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.06667160987854 seconds
Epoch 91 accuracy: 63.5%
Batch 10, Loss: 1.1166
Batch 20, Loss: 1.1291
Batch 30, Loss: 1.1026
Batch 40, Loss: 1.0697
Batch 50, Loss: 1.0931
Batch 60, Loss: 1.1629
Batch 70, Loss: 1.1754
Batch 80, Loss: 1.1320
Batch 90, Loss: 1.1594
Batch 100, Loss: 1.1848
Batch 110, Loss: 1.2007
Batch 120, Loss: 1.1689
Batch 130, Loss: 1.1208
Batch 140, Loss: 1.1581
Batch 150, Loss: 1.0578
Batch 160, Loss: 1.1135
Batch 170, Loss: 1.1229
Batch 180, Loss: 1.1633
Batch 190, Loss: 1.1570
Batch 200, Loss: 1.2219
Batch 210, Loss: 1.1429
Batch 220, Loss: 1.1443
Batch 230, Loss: 1.1919
Batch 240, Loss: 1.1989
Batch 250, Loss: 1.1302
Batch 260, Loss: 1.1883
Batch 270, Loss: 1.2016
Batch 280, Loss: 1.2010
Batch 290, Loss: 1.1814
Batch 300, Loss: 1.2844
Batch 310, Loss: 1.1440
Batch 320, Loss: 1.1870
Batch 330, Loss: 1.2143
Batch 340, Loss: 1.2496
Batch 350, Loss: 1.1735
Batch 360, Loss: 1.1405
Batch 370, Loss: 1.1617
Batch 380, Loss: 1.2273
Batch 390, Loss: 1.1785
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.147906064987183 seconds
Epoch 92 accuracy: 65.97%
Batch 10, Loss: 1.0978
Batch 20, Loss: 1.1280
Batch 30, Loss: 1.1034
Batch 40, Loss: 1.0773
Batch 50, Loss: 1.1732
Batch 60, Loss: 1.1222
Batch 70, Loss: 1.1303
Batch 80, Loss: 1.1493
Batch 90, Loss: 1.1186
Batch 100, Loss: 1.1464
Batch 110, Loss: 1.1310
Batch 120, Loss: 1.1202
Batch 130, Loss: 1.1100
Batch 140, Loss: 1.0938
Batch 150, Loss: 1.1473
Batch 160, Loss: 1.1378
Batch 170, Loss: 1.1641
Batch 180, Loss: 1.1346
Batch 190, Loss: 1.1639
Batch 200, Loss: 1.1730
Batch 210, Loss: 1.1993
Batch 220, Loss: 1.1764
Batch 230, Loss: 1.1264
Batch 240, Loss: 1.2241
Batch 250, Loss: 1.1943
Batch 260, Loss: 1.1906
Batch 270, Loss: 1.1486
Batch 280, Loss: 1.1954
Batch 290, Loss: 1.2028
Batch 300, Loss: 1.1925
Batch 310, Loss: 1.1675
Batch 320, Loss: 1.1150
Batch 330, Loss: 1.2073
Batch 340, Loss: 1.1315
Batch 350, Loss: 1.2038
Batch 360, Loss: 1.2374
Batch 370, Loss: 1.1798
Batch 380, Loss: 1.1299
Batch 390, Loss: 1.1932
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.115116596221924 seconds
Epoch 93 accuracy: 62.81%
Batch 10, Loss: 1.1138
Batch 20, Loss: 1.0738
Batch 30, Loss: 1.0610
Batch 40, Loss: 1.0975
Batch 50, Loss: 1.2413
Batch 60, Loss: 1.1337
Batch 70, Loss: 1.2179
Batch 80, Loss: 1.1995
Batch 90, Loss: 1.1307
Batch 100, Loss: 1.1232
Batch 110, Loss: 1.1072
Batch 120, Loss: 1.1662
Batch 130, Loss: 1.1627
Batch 140, Loss: 1.1036
Batch 150, Loss: 1.1815
Batch 160, Loss: 1.1851
Batch 170, Loss: 1.1715
Batch 180, Loss: 1.1699
Batch 190, Loss: 1.1385
Batch 200, Loss: 1.0840
Batch 210, Loss: 1.1627
Batch 220, Loss: 1.1518
Batch 230, Loss: 1.1643
Batch 240, Loss: 1.1477
Batch 250, Loss: 1.1672
Batch 260, Loss: 1.1754
Batch 270, Loss: 1.2183
Batch 280, Loss: 1.0373
Batch 290, Loss: 1.0813
Batch 300, Loss: 1.1898
Batch 310, Loss: 1.1977
Batch 320, Loss: 1.0893
Batch 330, Loss: 1.1822
Batch 340, Loss: 1.2256
Batch 350, Loss: 1.1852
Batch 360, Loss: 1.2351
Batch 370, Loss: 1.1036
Batch 380, Loss: 1.1497
Batch 390, Loss: 1.1358
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.086817502975464 seconds
Epoch 94 accuracy: 64.4%
Batch 10, Loss: 1.0917
Batch 20, Loss: 1.1116
Batch 30, Loss: 1.0902
Batch 40, Loss: 1.0855
Batch 50, Loss: 1.1000
Batch 60, Loss: 1.1322
Batch 70, Loss: 1.1112
Batch 80, Loss: 1.1120
Batch 90, Loss: 1.1155
Batch 100, Loss: 1.1282
Batch 110, Loss: 1.0883
Batch 120, Loss: 1.1254
Batch 130, Loss: 1.2207
Batch 140, Loss: 1.1269
Batch 150, Loss: 1.1755
Batch 160, Loss: 1.1553
Batch 170, Loss: 1.1189
Batch 180, Loss: 1.1451
Batch 190, Loss: 1.0746
Batch 200, Loss: 1.1913
Batch 210, Loss: 1.0954
Batch 220, Loss: 1.1468
Batch 230, Loss: 1.1444
Batch 240, Loss: 1.0921
Batch 250, Loss: 1.2231
Batch 260, Loss: 1.0918
Batch 270, Loss: 1.2081
Batch 280, Loss: 1.1778
Batch 290, Loss: 1.1557
Batch 300, Loss: 1.1410
Batch 310, Loss: 1.2099
Batch 320, Loss: 1.1672
Batch 330, Loss: 1.1678
Batch 340, Loss: 1.1208
Batch 350, Loss: 1.1070
Batch 360, Loss: 1.1749
Batch 370, Loss: 1.1762
Batch 380, Loss: 1.1304
Batch 390, Loss: 1.1320
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.091073989868164 seconds
Epoch 95 accuracy: 64.85%
Batch 10, Loss: 1.0844
Batch 20, Loss: 1.0773
Batch 30, Loss: 1.1317
Batch 40, Loss: 1.1248
Batch 50, Loss: 1.1064
Batch 60, Loss: 1.1549
Batch 70, Loss: 1.1367
Batch 80, Loss: 1.0777
Batch 90, Loss: 1.0804
Batch 100, Loss: 1.0993
Batch 110, Loss: 1.1711
Batch 120, Loss: 1.0773
Batch 130, Loss: 1.1107
Batch 140, Loss: 1.1438
Batch 150, Loss: 1.0970
Batch 160, Loss: 1.0793
Batch 170, Loss: 1.0973
Batch 180, Loss: 1.1546
Batch 190, Loss: 1.1269
Batch 200, Loss: 1.1870
Batch 210, Loss: 1.1751
Batch 220, Loss: 1.1612
Batch 230, Loss: 1.1167
Batch 240, Loss: 1.1950
Batch 250, Loss: 1.1096
Batch 260, Loss: 1.1425
Batch 270, Loss: 1.1066
Batch 280, Loss: 1.0886
Batch 290, Loss: 1.1479
Batch 300, Loss: 1.1472
Batch 310, Loss: 1.1510
Batch 320, Loss: 1.1523
Batch 330, Loss: 1.1590
Batch 340, Loss: 1.1485
Batch 350, Loss: 1.1984
Batch 360, Loss: 1.1554
Batch 370, Loss: 1.1866
Batch 380, Loss: 1.1873
Batch 390, Loss: 1.2030
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 24.990333557128906 seconds
Epoch 96 accuracy: 65.54%
Batch 10, Loss: 1.0545
Batch 20, Loss: 1.0728
Batch 30, Loss: 1.0767
Batch 40, Loss: 1.1680
Batch 50, Loss: 1.1222
Batch 60, Loss: 1.0637
Batch 70, Loss: 1.1046
Batch 80, Loss: 1.0935
Batch 90, Loss: 1.1357
Batch 100, Loss: 1.1389
Batch 110, Loss: 1.1429
Batch 120, Loss: 1.1415
Batch 130, Loss: 1.0469
Batch 140, Loss: 1.0984
Batch 150, Loss: 1.1419
Batch 160, Loss: 1.1172
Batch 170, Loss: 1.1352
Batch 180, Loss: 1.0954
Batch 190, Loss: 1.1220
Batch 200, Loss: 1.1378
Batch 210, Loss: 1.1148
Batch 220, Loss: 1.1407
Batch 230, Loss: 1.1991
Batch 240, Loss: 1.1261
Batch 250, Loss: 1.1024
Batch 260, Loss: 1.1644
Batch 270, Loss: 1.1880
Batch 280, Loss: 1.1133
Batch 290, Loss: 1.1195
Batch 300, Loss: 1.1174
Batch 310, Loss: 1.1552
Batch 320, Loss: 1.1725
Batch 330, Loss: 1.1520
Batch 340, Loss: 1.1556
Batch 350, Loss: 1.1611
Batch 360, Loss: 1.1658
Batch 370, Loss: 1.1313
Batch 380, Loss: 1.1814
Batch 390, Loss: 1.1935
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.076754093170166 seconds
Epoch 97 accuracy: 65.13%
Batch 10, Loss: 1.0366
Batch 20, Loss: 1.0646
Batch 30, Loss: 1.0899
Batch 40, Loss: 1.0900
Batch 50, Loss: 1.0942
Batch 60, Loss: 1.0816
Batch 70, Loss: 1.1656
Batch 80, Loss: 1.0592
Batch 90, Loss: 1.0672
Batch 100, Loss: 1.0552
Batch 110, Loss: 1.1115
Batch 120, Loss: 1.1019
Batch 130, Loss: 1.0842
Batch 140, Loss: 1.1279
Batch 150, Loss: 1.1260
Batch 160, Loss: 1.1215
Batch 170, Loss: 1.0965
Batch 180, Loss: 1.0832
Batch 190, Loss: 1.0776
Batch 200, Loss: 1.0895
Batch 210, Loss: 1.1107
Batch 220, Loss: 1.1082
Batch 230, Loss: 1.0924
Batch 240, Loss: 1.1321
Batch 250, Loss: 1.0871
Batch 260, Loss: 1.1194
Batch 270, Loss: 1.1579
Batch 280, Loss: 1.1441
Batch 290, Loss: 1.1595
Batch 300, Loss: 1.1507
Batch 310, Loss: 1.1682
Batch 320, Loss: 1.0826
Batch 330, Loss: 1.1811
Batch 340, Loss: 1.1760
Batch 350, Loss: 1.1534
Batch 360, Loss: 1.1478
Batch 370, Loss: 1.1670
Batch 380, Loss: 1.1598
Batch 390, Loss: 1.1714
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.11316442489624 seconds
Epoch 98 accuracy: 66.03%
Batch 10, Loss: 1.0709
Batch 20, Loss: 1.0118
Batch 30, Loss: 1.0670
Batch 40, Loss: 1.0712
Batch 50, Loss: 1.0566
Batch 60, Loss: 1.0984
Batch 70, Loss: 1.0620
Batch 80, Loss: 1.0266
Batch 90, Loss: 1.0720
Batch 100, Loss: 1.0358
Batch 110, Loss: 1.0403
Batch 120, Loss: 1.1042
Batch 130, Loss: 1.0903
Batch 140, Loss: 1.1107
Batch 150, Loss: 1.1135
Batch 160, Loss: 1.1018
Batch 170, Loss: 1.1176
Batch 180, Loss: 1.1227
Batch 190, Loss: 1.1342
Batch 200, Loss: 1.1276
Batch 210, Loss: 1.0832
Batch 220, Loss: 1.1221
Batch 230, Loss: 1.0471
Batch 240, Loss: 1.0685
Batch 250, Loss: 1.0712
Batch 260, Loss: 1.0750
Batch 270, Loss: 1.1983
Batch 280, Loss: 1.1823
Batch 290, Loss: 1.1705
Batch 300, Loss: 1.1582
Batch 310, Loss: 1.1519
Batch 320, Loss: 1.0961
Batch 330, Loss: 1.1912
Batch 340, Loss: 1.1428
Batch 350, Loss: 1.1679
Batch 360, Loss: 1.1362
Batch 370, Loss: 1.1113
Batch 380, Loss: 1.1799
Batch 390, Loss: 1.1275
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.085171699523926 seconds
Epoch 99 accuracy: 64.8%
Batch 10, Loss: 1.0640
Batch 20, Loss: 1.1198
Batch 30, Loss: 1.0111
Batch 40, Loss: 1.0989
Batch 50, Loss: 1.0933
Batch 60, Loss: 1.0671
Batch 70, Loss: 1.1002
Batch 80, Loss: 1.0643
Batch 90, Loss: 1.0543
Batch 100, Loss: 1.1197
Batch 110, Loss: 1.0226
Batch 120, Loss: 1.0674
Batch 130, Loss: 1.0501
Batch 140, Loss: 1.0774
Batch 150, Loss: 1.0447
Batch 160, Loss: 1.0333
Batch 170, Loss: 1.1425
Batch 180, Loss: 1.1126
Batch 190, Loss: 1.1221
Batch 200, Loss: 1.1029
Batch 210, Loss: 1.0775
Batch 220, Loss: 1.0804
Batch 230, Loss: 1.1245
Batch 240, Loss: 1.0597
Batch 250, Loss: 1.1327
Batch 260, Loss: 1.0934
Batch 270, Loss: 1.1095
Batch 280, Loss: 1.1503
Batch 290, Loss: 1.1117
Batch 300, Loss: 1.1746
Batch 310, Loss: 1.1336
Batch 320, Loss: 1.1705
Batch 330, Loss: 1.1512
Batch 340, Loss: 1.0517
Batch 350, Loss: 1.1002
Batch 360, Loss: 1.1317
Batch 370, Loss: 1.1651
Batch 380, Loss: 1.0727
Batch 390, Loss: 1.0979
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.041209936141968 seconds
Epoch 100 accuracy: 60.65%
Batch 10, Loss: 1.1010
Batch 20, Loss: 1.0704
Batch 30, Loss: 1.0765
Batch 40, Loss: 1.0600
Batch 50, Loss: 1.0253
Batch 60, Loss: 1.0213
Batch 70, Loss: 1.0589
Batch 80, Loss: 1.1191
Batch 90, Loss: 1.0465
Batch 100, Loss: 1.0992
Batch 110, Loss: 1.0626
Batch 120, Loss: 1.0511
Batch 130, Loss: 1.1210
Batch 140, Loss: 1.0891
Batch 150, Loss: 1.0592
Batch 160, Loss: 1.0950
Batch 170, Loss: 1.0956
Batch 180, Loss: 1.0866
Batch 190, Loss: 1.0680
Batch 200, Loss: 1.1411
Batch 210, Loss: 1.1268
Batch 220, Loss: 1.0953
Batch 230, Loss: 1.0749
Batch 240, Loss: 1.1237
Batch 250, Loss: 1.0695
Batch 260, Loss: 1.0718
Batch 270, Loss: 1.1028
Batch 280, Loss: 1.1122
Batch 290, Loss: 1.0876
Batch 300, Loss: 1.0667
Batch 310, Loss: 1.0981
Batch 320, Loss: 1.1584
Batch 330, Loss: 1.1246
Batch 340, Loss: 1.1509
Batch 350, Loss: 1.1376
Batch 360, Loss: 1.1312
Batch 370, Loss: 1.1238
Batch 380, Loss: 1.1013
Batch 390, Loss: 1.0559
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.133354663848877 seconds
Epoch 101 accuracy: 65.77%
Batch 10, Loss: 1.0586
Batch 20, Loss: 1.0055
Batch 30, Loss: 1.0403
Batch 40, Loss: 1.0797
Batch 50, Loss: 1.0271
Batch 60, Loss: 0.9983
Batch 70, Loss: 1.0625
Batch 80, Loss: 1.1125
Batch 90, Loss: 1.0368
Batch 100, Loss: 1.0873
Batch 110, Loss: 1.0567
Batch 120, Loss: 1.1491
Batch 130, Loss: 1.0322
Batch 140, Loss: 1.0009
Batch 150, Loss: 1.0949
Batch 160, Loss: 1.0699
Batch 170, Loss: 1.0604
Batch 180, Loss: 1.0380
Batch 190, Loss: 1.0348
Batch 200, Loss: 1.0820
Batch 210, Loss: 1.0979
Batch 220, Loss: 1.1280
Batch 230, Loss: 1.1771
Batch 240, Loss: 1.1322
Batch 250, Loss: 1.0922
Batch 260, Loss: 1.1209
Batch 270, Loss: 1.0921
Batch 280, Loss: 1.1302
Batch 290, Loss: 1.0806
Batch 300, Loss: 1.1229
Batch 310, Loss: 1.1015
Batch 320, Loss: 1.1014
Batch 330, Loss: 1.0938
Batch 340, Loss: 1.0779
Batch 350, Loss: 1.1160
Batch 360, Loss: 1.1064
Batch 370, Loss: 1.1035
Batch 380, Loss: 1.1222
Batch 390, Loss: 1.1120
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.106103658676147 seconds
Epoch 102 accuracy: 67.34%
Batch 10, Loss: 1.0129
Batch 20, Loss: 1.0539
Batch 30, Loss: 1.0042
Batch 40, Loss: 1.0666
Batch 50, Loss: 1.0095
Batch 60, Loss: 1.0749
Batch 70, Loss: 0.9973
Batch 80, Loss: 1.0546
Batch 90, Loss: 1.0216
Batch 100, Loss: 1.0504
Batch 110, Loss: 1.0854
Batch 120, Loss: 1.1043
Batch 130, Loss: 1.0780
Batch 140, Loss: 1.0740
Batch 150, Loss: 1.1128
Batch 160, Loss: 1.0793
Batch 170, Loss: 1.1114
Batch 180, Loss: 1.0963
Batch 190, Loss: 1.0897
Batch 200, Loss: 1.0870
Batch 210, Loss: 1.0597
Batch 220, Loss: 1.0606
Batch 230, Loss: 1.0959
Batch 240, Loss: 1.1064
Batch 250, Loss: 1.1026
Batch 260, Loss: 1.0511
Batch 270, Loss: 1.0637
Batch 280, Loss: 1.0605
Batch 290, Loss: 1.0832
Batch 300, Loss: 1.1081
Batch 310, Loss: 1.1234
Batch 320, Loss: 1.0636
Batch 330, Loss: 1.1383
Batch 340, Loss: 1.0847
Batch 350, Loss: 1.1282
Batch 360, Loss: 1.1037
Batch 370, Loss: 1.0790
Batch 380, Loss: 1.1070
Batch 390, Loss: 1.1116
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.050187349319458 seconds
Epoch 103 accuracy: 64.99%
Batch 10, Loss: 1.0636
Batch 20, Loss: 1.0548
Batch 30, Loss: 0.9870
Batch 40, Loss: 0.9967
Batch 50, Loss: 1.0448
Batch 60, Loss: 1.0579
Batch 70, Loss: 1.0332
Batch 80, Loss: 1.0982
Batch 90, Loss: 1.0574
Batch 100, Loss: 1.0503
Batch 110, Loss: 1.0599
Batch 120, Loss: 1.0056
Batch 130, Loss: 1.0438
Batch 140, Loss: 1.0707
Batch 150, Loss: 1.0128
Batch 160, Loss: 1.0229
Batch 170, Loss: 1.0819
Batch 180, Loss: 0.9876
Batch 190, Loss: 1.0154
Batch 200, Loss: 1.0842
Batch 210, Loss: 1.0746
Batch 220, Loss: 1.0743
Batch 230, Loss: 1.0876
Batch 240, Loss: 1.0960
Batch 250, Loss: 1.1129
Batch 260, Loss: 1.0916
Batch 270, Loss: 1.1112
Batch 280, Loss: 1.0840
Batch 290, Loss: 1.0383
Batch 300, Loss: 1.1400
Batch 310, Loss: 1.0588
Batch 320, Loss: 1.0449
Batch 330, Loss: 1.0966
Batch 340, Loss: 1.1371
Batch 350, Loss: 1.0992
Batch 360, Loss: 1.1827
Batch 370, Loss: 1.1452
Batch 380, Loss: 1.1234
Batch 390, Loss: 1.0895
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 24.992390394210815 seconds
Epoch 104 accuracy: 67.09%
Batch 10, Loss: 1.0130
Batch 20, Loss: 1.0093
Batch 30, Loss: 0.9777
Batch 40, Loss: 1.0643
Batch 50, Loss: 1.0389
Batch 60, Loss: 1.0541
Batch 70, Loss: 0.9906
Batch 80, Loss: 1.0554
Batch 90, Loss: 1.0154
Batch 100, Loss: 1.0391
Batch 110, Loss: 1.1746
Batch 120, Loss: 1.0198
Batch 130, Loss: 1.0308
Batch 140, Loss: 1.0575
Batch 150, Loss: 1.0458
Batch 160, Loss: 1.1051
Batch 170, Loss: 1.0679
Batch 180, Loss: 1.0297
Batch 190, Loss: 1.0811
Batch 200, Loss: 1.0210
Batch 210, Loss: 1.0698
Batch 220, Loss: 1.0950
Batch 230, Loss: 1.1018
Batch 240, Loss: 1.0291
Batch 250, Loss: 1.0979
Batch 260, Loss: 1.1041
Batch 270, Loss: 1.0972
Batch 280, Loss: 1.1018
Batch 290, Loss: 1.0350
Batch 300, Loss: 1.0488
Batch 310, Loss: 1.0508
Batch 320, Loss: 1.0400
Batch 330, Loss: 1.1085
Batch 340, Loss: 1.0571
Batch 350, Loss: 1.1332
Batch 360, Loss: 1.0669
Batch 370, Loss: 1.1635
Batch 380, Loss: 1.1367
Batch 390, Loss: 1.0825
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.123169422149658 seconds
Epoch 105 accuracy: 68.0%
Batch 10, Loss: 1.0269
Batch 20, Loss: 0.9836
Batch 30, Loss: 1.0124
Batch 40, Loss: 1.0100
Batch 50, Loss: 1.0343
Batch 60, Loss: 1.0513
Batch 70, Loss: 1.0094
Batch 80, Loss: 1.0473
Batch 90, Loss: 0.9601
Batch 100, Loss: 0.9669
Batch 110, Loss: 1.0482
Batch 120, Loss: 1.0147
Batch 130, Loss: 1.0190
Batch 140, Loss: 1.0382
Batch 150, Loss: 1.0946
Batch 160, Loss: 1.0697
Batch 170, Loss: 1.0822
Batch 180, Loss: 1.0330
Batch 190, Loss: 1.0981
Batch 200, Loss: 1.0558
Batch 210, Loss: 1.0291
Batch 220, Loss: 1.0803
Batch 230, Loss: 1.0478
Batch 240, Loss: 1.0100
Batch 250, Loss: 1.0236
Batch 260, Loss: 1.0631
Batch 270, Loss: 1.0473
Batch 280, Loss: 1.0626
Batch 290, Loss: 1.0752
Batch 300, Loss: 1.0255
Batch 310, Loss: 1.0407
Batch 320, Loss: 1.1319
Batch 330, Loss: 1.0519
Batch 340, Loss: 1.0683
Batch 350, Loss: 1.0766
Batch 360, Loss: 1.0905
Batch 370, Loss: 1.0550
Batch 380, Loss: 1.0620
Batch 390, Loss: 1.0453
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.051554441452026 seconds
Epoch 106 accuracy: 68.3%
Batch 10, Loss: 1.0283
Batch 20, Loss: 0.9892
Batch 30, Loss: 1.0363
Batch 40, Loss: 1.0239
Batch 50, Loss: 1.0127
Batch 60, Loss: 1.0131
Batch 70, Loss: 1.0422
Batch 80, Loss: 0.9917
Batch 90, Loss: 0.9824
Batch 100, Loss: 0.9805
Batch 110, Loss: 1.0090
Batch 120, Loss: 1.0338
Batch 130, Loss: 1.0528
Batch 140, Loss: 1.0179
Batch 150, Loss: 1.0623
Batch 160, Loss: 1.0766
Batch 170, Loss: 1.0705
Batch 180, Loss: 1.0652
Batch 190, Loss: 1.0763
Batch 200, Loss: 1.1644
Batch 210, Loss: 1.0176
Batch 220, Loss: 1.0481
Batch 230, Loss: 1.0080
Batch 240, Loss: 1.0219
Batch 250, Loss: 1.0653
Batch 260, Loss: 1.0492
Batch 270, Loss: 1.0310
Batch 280, Loss: 1.1026
Batch 290, Loss: 1.0641
Batch 300, Loss: 1.0770
Batch 310, Loss: 1.0826
Batch 320, Loss: 1.0790
Batch 330, Loss: 1.0112
Batch 340, Loss: 1.0204
Batch 350, Loss: 1.0555
Batch 360, Loss: 1.0620
Batch 370, Loss: 1.1104
Batch 380, Loss: 1.1066
Batch 390, Loss: 1.0931
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.050246000289917 seconds
Epoch 107 accuracy: 65.87%
Batch 10, Loss: 0.9703
Batch 20, Loss: 0.9687
Batch 30, Loss: 1.0139
Batch 40, Loss: 1.0033
Batch 50, Loss: 1.0074
Batch 60, Loss: 0.9781
Batch 70, Loss: 0.9912
Batch 80, Loss: 0.9845
Batch 90, Loss: 1.0046
Batch 100, Loss: 1.0423
Batch 110, Loss: 0.9983
Batch 120, Loss: 1.0430
Batch 130, Loss: 1.0426
Batch 140, Loss: 1.0620
Batch 150, Loss: 1.0287
Batch 160, Loss: 1.0339
Batch 170, Loss: 1.0893
Batch 180, Loss: 1.0334
Batch 190, Loss: 1.0263
Batch 200, Loss: 1.0045
Batch 210, Loss: 1.0774
Batch 220, Loss: 1.0851
Batch 230, Loss: 1.0735
Batch 240, Loss: 1.0547
Batch 250, Loss: 1.1100
Batch 260, Loss: 1.0861
Batch 270, Loss: 1.0368
Batch 280, Loss: 1.0594
Batch 290, Loss: 1.1532
Batch 300, Loss: 1.0126
Batch 310, Loss: 0.9607
Batch 320, Loss: 1.0069
Batch 330, Loss: 1.0479
Batch 340, Loss: 1.0846
Batch 350, Loss: 1.0823
Batch 360, Loss: 1.0780
Batch 370, Loss: 1.0540
Batch 380, Loss: 1.0191
Batch 390, Loss: 1.1183
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.026042461395264 seconds
Epoch 108 accuracy: 66.95%
Batch 10, Loss: 0.9772
Batch 20, Loss: 1.0075
Batch 30, Loss: 0.9994
Batch 40, Loss: 1.0199
Batch 50, Loss: 1.0263
Batch 60, Loss: 0.9341
Batch 70, Loss: 0.9363
Batch 80, Loss: 1.0027
Batch 90, Loss: 1.0064
Batch 100, Loss: 1.0372
Batch 110, Loss: 0.9588
Batch 120, Loss: 1.0209
Batch 130, Loss: 1.0307
Batch 140, Loss: 1.0889
Batch 150, Loss: 0.9922
Batch 160, Loss: 1.0064
Batch 170, Loss: 1.0506
Batch 180, Loss: 0.9867
Batch 190, Loss: 0.9834
Batch 200, Loss: 0.9892
Batch 210, Loss: 0.9790
Batch 220, Loss: 1.0085
Batch 230, Loss: 1.0497
Batch 240, Loss: 1.0488
Batch 250, Loss: 1.0314
Batch 260, Loss: 1.0306
Batch 270, Loss: 1.0496
Batch 280, Loss: 1.0359
Batch 290, Loss: 1.0159
Batch 300, Loss: 1.0462
Batch 310, Loss: 1.1020
Batch 320, Loss: 1.0588
Batch 330, Loss: 1.0917
Batch 340, Loss: 1.1025
Batch 350, Loss: 1.0567
Batch 360, Loss: 1.0511
Batch 370, Loss: 1.0530
Batch 380, Loss: 1.0846
Batch 390, Loss: 1.0656
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.03877902030945 seconds
Epoch 109 accuracy: 68.77%
Batch 10, Loss: 0.9719
Batch 20, Loss: 0.9894
Batch 30, Loss: 0.9636
Batch 40, Loss: 1.0114
Batch 50, Loss: 0.9525
Batch 60, Loss: 0.9661
Batch 70, Loss: 0.9229
Batch 80, Loss: 0.9805
Batch 90, Loss: 1.0283
Batch 100, Loss: 1.0147
Batch 110, Loss: 0.9903
Batch 120, Loss: 1.0097
Batch 130, Loss: 1.0749
Batch 140, Loss: 1.0777
Batch 150, Loss: 0.9840
Batch 160, Loss: 1.0615
Batch 170, Loss: 0.9992
Batch 180, Loss: 1.0157
Batch 190, Loss: 1.0178
Batch 200, Loss: 1.0200
Batch 210, Loss: 1.0400
Batch 220, Loss: 0.9912
Batch 230, Loss: 1.0187
Batch 240, Loss: 1.0287
Batch 250, Loss: 1.0222
Batch 260, Loss: 1.0511
Batch 270, Loss: 1.0470
Batch 280, Loss: 1.0503
Batch 290, Loss: 1.0414
Batch 300, Loss: 1.0335
Batch 310, Loss: 1.0509
Batch 320, Loss: 1.0933
Batch 330, Loss: 1.0356
Batch 340, Loss: 1.0616
Batch 350, Loss: 0.9985
Batch 360, Loss: 1.0401
Batch 370, Loss: 1.0057
Batch 380, Loss: 1.0539
Batch 390, Loss: 1.0615
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.127639293670654 seconds
Epoch 110 accuracy: 67.13%
Batch 10, Loss: 0.9964
Batch 20, Loss: 0.9476
Batch 30, Loss: 0.8844
Batch 40, Loss: 0.9651
Batch 50, Loss: 0.9505
Batch 60, Loss: 0.9677
Batch 70, Loss: 0.9667
Batch 80, Loss: 0.9720
Batch 90, Loss: 0.9664
Batch 100, Loss: 0.9074
Batch 110, Loss: 1.0272
Batch 120, Loss: 1.0201
Batch 130, Loss: 0.9721
Batch 140, Loss: 1.0155
Batch 150, Loss: 0.9818
Batch 160, Loss: 0.9947
Batch 170, Loss: 0.9886
Batch 180, Loss: 1.0033
Batch 190, Loss: 1.0617
Batch 200, Loss: 1.0082
Batch 210, Loss: 0.9940
Batch 220, Loss: 0.9885
Batch 230, Loss: 1.0403
Batch 240, Loss: 1.0370
Batch 250, Loss: 1.0235
Batch 260, Loss: 1.0014
Batch 270, Loss: 1.0196
Batch 280, Loss: 1.0768
Batch 290, Loss: 1.0478
Batch 300, Loss: 1.0683
Batch 310, Loss: 1.0450
Batch 320, Loss: 1.0227
Batch 330, Loss: 1.0331
Batch 340, Loss: 1.0277
Batch 350, Loss: 1.0803
Batch 360, Loss: 1.0654
Batch 370, Loss: 1.0541
Batch 380, Loss: 1.0261
Batch 390, Loss: 1.0392
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.057902574539185 seconds
Epoch 111 accuracy: 67.59%
Batch 10, Loss: 0.9679
Batch 20, Loss: 0.9450
Batch 30, Loss: 0.9581
Batch 40, Loss: 1.0215
Batch 50, Loss: 1.0117
Batch 60, Loss: 0.9782
Batch 70, Loss: 0.9582
Batch 80, Loss: 0.9720
Batch 90, Loss: 1.0344
Batch 100, Loss: 1.0387
Batch 110, Loss: 1.0037
Batch 120, Loss: 1.0138
Batch 130, Loss: 1.0030
Batch 140, Loss: 1.0184
Batch 150, Loss: 1.0060
Batch 160, Loss: 1.0531
Batch 170, Loss: 1.0064
Batch 180, Loss: 0.9772
Batch 190, Loss: 0.9566
Batch 200, Loss: 0.9876
Batch 210, Loss: 1.0442
Batch 220, Loss: 0.9972
Batch 230, Loss: 0.9559
Batch 240, Loss: 1.0594
Batch 250, Loss: 0.9953
Batch 260, Loss: 0.9547
Batch 270, Loss: 1.0038
Batch 280, Loss: 0.9600
Batch 290, Loss: 1.0121
Batch 300, Loss: 1.0712
Batch 310, Loss: 1.0631
Batch 320, Loss: 1.0728
Batch 330, Loss: 1.0349
Batch 340, Loss: 0.9797
Batch 350, Loss: 0.9906
Batch 360, Loss: 1.0177
Batch 370, Loss: 1.0010
Batch 380, Loss: 1.0543
Batch 390, Loss: 1.0167
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.055663347244263 seconds
Epoch 112 accuracy: 67.73%
Batch 10, Loss: 0.9612
Batch 20, Loss: 0.9912
Batch 30, Loss: 0.9484
Batch 40, Loss: 0.9874
Batch 50, Loss: 1.0061
Batch 60, Loss: 0.9234
Batch 70, Loss: 0.9836
Batch 80, Loss: 1.0109
Batch 90, Loss: 0.9995
Batch 100, Loss: 0.9685
Batch 110, Loss: 0.9466
Batch 120, Loss: 0.9982
Batch 130, Loss: 0.9735
Batch 140, Loss: 1.0231
Batch 150, Loss: 0.9312
Batch 160, Loss: 0.9366
Batch 170, Loss: 1.0049
Batch 180, Loss: 0.9603
Batch 190, Loss: 0.9798
Batch 200, Loss: 0.9415
Batch 210, Loss: 1.0146
Batch 220, Loss: 0.9968
Batch 230, Loss: 0.9577
Batch 240, Loss: 0.9752
Batch 250, Loss: 1.0030
Batch 260, Loss: 0.9633
Batch 270, Loss: 0.9712
Batch 280, Loss: 1.0294
Batch 290, Loss: 1.0028
Batch 300, Loss: 0.9585
Batch 310, Loss: 1.0263
Batch 320, Loss: 1.0092
Batch 330, Loss: 1.0533
Batch 340, Loss: 0.9637
Batch 350, Loss: 1.0652
Batch 360, Loss: 1.0237
Batch 370, Loss: 0.9910
Batch 380, Loss: 0.9923
Batch 390, Loss: 1.0681
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.21724796295166 seconds
Epoch 113 accuracy: 67.82%
Batch 10, Loss: 0.9914
Batch 20, Loss: 0.9495
Batch 30, Loss: 0.9659
Batch 40, Loss: 0.9201
Batch 50, Loss: 0.9460
Batch 60, Loss: 0.8944
Batch 70, Loss: 0.9523
Batch 80, Loss: 0.9707
Batch 90, Loss: 1.0099
Batch 100, Loss: 0.9565
Batch 110, Loss: 0.9610
Batch 120, Loss: 0.9147
Batch 130, Loss: 0.9930
Batch 140, Loss: 0.9700
Batch 150, Loss: 0.9439
Batch 160, Loss: 0.9398
Batch 170, Loss: 0.9449
Batch 180, Loss: 1.0244
Batch 190, Loss: 0.9877
Batch 200, Loss: 0.9726
Batch 210, Loss: 0.9821
Batch 220, Loss: 0.9877
Batch 230, Loss: 0.9561
Batch 240, Loss: 1.0504
Batch 250, Loss: 0.9805
Batch 260, Loss: 1.0150
Batch 270, Loss: 1.0053
Batch 280, Loss: 1.0010
Batch 290, Loss: 0.9494
Batch 300, Loss: 1.0104
Batch 310, Loss: 0.9998
Batch 320, Loss: 1.0051
Batch 330, Loss: 1.0646
Batch 340, Loss: 1.0427
Batch 350, Loss: 1.0194
Batch 360, Loss: 0.9890
Batch 370, Loss: 1.0836
Batch 380, Loss: 1.0839
Batch 390, Loss: 0.9960
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 24.96445345878601 seconds
Epoch 114 accuracy: 68.98%
Batch 10, Loss: 0.9423
Batch 20, Loss: 0.9849
Batch 30, Loss: 0.9741
Batch 40, Loss: 0.9487
Batch 50, Loss: 0.8812
Batch 60, Loss: 0.9586
Batch 70, Loss: 0.8891
Batch 80, Loss: 0.9724
Batch 90, Loss: 0.9795
Batch 100, Loss: 0.9498
Batch 110, Loss: 0.9808
Batch 120, Loss: 0.9974
Batch 130, Loss: 0.9820
Batch 140, Loss: 0.9457
Batch 150, Loss: 0.9619
Batch 160, Loss: 0.9686
Batch 170, Loss: 0.9810
Batch 180, Loss: 0.9994
Batch 190, Loss: 0.9671
Batch 200, Loss: 0.9822
Batch 210, Loss: 1.0206
Batch 220, Loss: 0.9961
Batch 230, Loss: 0.9202
Batch 240, Loss: 0.9833
Batch 250, Loss: 0.9658
Batch 260, Loss: 1.0236
Batch 270, Loss: 0.9679
Batch 280, Loss: 0.9777
Batch 290, Loss: 0.9839
Batch 300, Loss: 0.9945
Batch 310, Loss: 1.0133
Batch 320, Loss: 0.9847
Batch 330, Loss: 0.9328
Batch 340, Loss: 0.9815
Batch 350, Loss: 0.9884
Batch 360, Loss: 0.9980
Batch 370, Loss: 0.9957
Batch 380, Loss: 1.0207
Batch 390, Loss: 1.0351
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.072256326675415 seconds
Epoch 115 accuracy: 67.14%
Batch 10, Loss: 0.9560
Batch 20, Loss: 0.9319
Batch 30, Loss: 0.9141
Batch 40, Loss: 0.8944
Batch 50, Loss: 0.9519
Batch 60, Loss: 0.9594
Batch 70, Loss: 0.9338
Batch 80, Loss: 0.9366
Batch 90, Loss: 0.9382
Batch 100, Loss: 0.9360
Batch 110, Loss: 0.9467
Batch 120, Loss: 0.9190
Batch 130, Loss: 0.9712
Batch 140, Loss: 0.9359
Batch 150, Loss: 1.0527
Batch 160, Loss: 0.9593
Batch 170, Loss: 0.9290
Batch 180, Loss: 0.9556
Batch 190, Loss: 0.9717
Batch 200, Loss: 0.9419
Batch 210, Loss: 0.9058
Batch 220, Loss: 0.8983
Batch 230, Loss: 0.9605
Batch 240, Loss: 1.0030
Batch 250, Loss: 0.9909
Batch 260, Loss: 0.9894
Batch 270, Loss: 1.0060
Batch 280, Loss: 0.9525
Batch 290, Loss: 1.0105
Batch 300, Loss: 0.9679
Batch 310, Loss: 0.9776
Batch 320, Loss: 0.9902
Batch 330, Loss: 1.0020
Batch 340, Loss: 0.9873
Batch 350, Loss: 1.0291
Batch 360, Loss: 1.0531
Batch 370, Loss: 1.0053
Batch 380, Loss: 1.0295
Batch 390, Loss: 1.0325
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.0312922000885 seconds
Epoch 116 accuracy: 69.22%
Batch 10, Loss: 0.8768
Batch 20, Loss: 0.9699
Batch 30, Loss: 0.9092
Batch 40, Loss: 0.8988
Batch 50, Loss: 0.8580
Batch 60, Loss: 0.8669
Batch 70, Loss: 0.9433
Batch 80, Loss: 0.9497
Batch 90, Loss: 0.9416
Batch 100, Loss: 0.9358
Batch 110, Loss: 0.9293
Batch 120, Loss: 0.9533
Batch 130, Loss: 0.9693
Batch 140, Loss: 0.9705
Batch 150, Loss: 0.9649
Batch 160, Loss: 0.9921
Batch 170, Loss: 0.9435
Batch 180, Loss: 0.9570
Batch 190, Loss: 0.9681
Batch 200, Loss: 0.9278
Batch 210, Loss: 0.9080
Batch 220, Loss: 0.9767
Batch 230, Loss: 0.9642
Batch 240, Loss: 0.9613
Batch 250, Loss: 0.9954
Batch 260, Loss: 0.9692
Batch 270, Loss: 0.9931
Batch 280, Loss: 1.0018
Batch 290, Loss: 0.9579
Batch 300, Loss: 1.0262
Batch 310, Loss: 1.0080
Batch 320, Loss: 0.9813
Batch 330, Loss: 1.0107
Batch 340, Loss: 0.9719
Batch 350, Loss: 1.0122
Batch 360, Loss: 1.0147
Batch 370, Loss: 1.0150
Batch 380, Loss: 1.0255
Batch 390, Loss: 0.9693
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.059646368026733 seconds
Epoch 117 accuracy: 66.51%
Batch 10, Loss: 0.9429
Batch 20, Loss: 0.9479
Batch 30, Loss: 0.9319
Batch 40, Loss: 0.9460
Batch 50, Loss: 0.8815
Batch 60, Loss: 0.8671
Batch 70, Loss: 0.8937
Batch 80, Loss: 0.9791
Batch 90, Loss: 0.8983
Batch 100, Loss: 0.9476
Batch 110, Loss: 0.9292
Batch 120, Loss: 0.9311
Batch 130, Loss: 0.9313
Batch 140, Loss: 0.9098
Batch 150, Loss: 0.9144
Batch 160, Loss: 0.9264
Batch 170, Loss: 0.9476
Batch 180, Loss: 0.9906
Batch 190, Loss: 0.9013
Batch 200, Loss: 0.9690
Batch 210, Loss: 0.9243
Batch 220, Loss: 0.9477
Batch 230, Loss: 0.9999
Batch 240, Loss: 0.9080
Batch 250, Loss: 1.0220
Batch 260, Loss: 0.9571
Batch 270, Loss: 0.9766
Batch 280, Loss: 0.9890
Batch 290, Loss: 0.9644
Batch 300, Loss: 0.9474
Batch 310, Loss: 0.9184
Batch 320, Loss: 0.9424
Batch 330, Loss: 0.9827
Batch 340, Loss: 1.0136
Batch 350, Loss: 0.9757
Batch 360, Loss: 0.9745
Batch 370, Loss: 0.9582
Batch 380, Loss: 1.0288
Batch 390, Loss: 0.9201
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 24.977055072784424 seconds
Epoch 118 accuracy: 68.81%
Batch 10, Loss: 0.8556
Batch 20, Loss: 0.8817
Batch 30, Loss: 0.8705
Batch 40, Loss: 0.8681
Batch 50, Loss: 0.9016
Batch 60, Loss: 0.9512
Batch 70, Loss: 0.8966
Batch 80, Loss: 0.9286
Batch 90, Loss: 0.9128
Batch 100, Loss: 0.9403
Batch 110, Loss: 0.9002
Batch 120, Loss: 0.9041
Batch 130, Loss: 0.9164
Batch 140, Loss: 0.9264
Batch 150, Loss: 0.8958
Batch 160, Loss: 0.9264
Batch 170, Loss: 0.9077
Batch 180, Loss: 0.9215
Batch 190, Loss: 0.9262
Batch 200, Loss: 0.9679
Batch 210, Loss: 0.9354
Batch 220, Loss: 0.9916
Batch 230, Loss: 0.9783
Batch 240, Loss: 0.9228
Batch 250, Loss: 0.9232
Batch 260, Loss: 0.8992
Batch 270, Loss: 0.8712
Batch 280, Loss: 0.9482
Batch 290, Loss: 0.9621
Batch 300, Loss: 0.9526
Batch 310, Loss: 0.8911
Batch 320, Loss: 0.9656
Batch 330, Loss: 0.9836
Batch 340, Loss: 0.9685
Batch 350, Loss: 0.9484
Batch 360, Loss: 0.9621
Batch 370, Loss: 1.0115
Batch 380, Loss: 0.9624
Batch 390, Loss: 0.9358
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.125375747680664 seconds
Epoch 119 accuracy: 66.68%
Batch 10, Loss: 0.9585
Batch 20, Loss: 0.9077
Batch 30, Loss: 0.8934
Batch 40, Loss: 0.8909
Batch 50, Loss: 0.8493
Batch 60, Loss: 0.8855
Batch 70, Loss: 0.8990
Batch 80, Loss: 0.8938
Batch 90, Loss: 0.9308
Batch 100, Loss: 0.9197
Batch 110, Loss: 0.8996
Batch 120, Loss: 0.8820
Batch 130, Loss: 0.8828
Batch 140, Loss: 0.9520
Batch 150, Loss: 0.9215
Batch 160, Loss: 0.9173
Batch 170, Loss: 0.9203
Batch 180, Loss: 0.9667
Batch 190, Loss: 0.8564
Batch 200, Loss: 0.9100
Batch 210, Loss: 0.9368
Batch 220, Loss: 0.9521
Batch 230, Loss: 1.0565
Batch 240, Loss: 0.9409
Batch 250, Loss: 0.9777
Batch 260, Loss: 0.9685
Batch 270, Loss: 0.9401
Batch 280, Loss: 0.9519
Batch 290, Loss: 0.9126
Batch 300, Loss: 0.9911
Batch 310, Loss: 0.9653
Batch 320, Loss: 0.9340
Batch 330, Loss: 1.0081
Batch 340, Loss: 0.9544
Batch 350, Loss: 0.9426
Batch 360, Loss: 0.9995
Batch 370, Loss: 0.9493
Batch 380, Loss: 1.0028
Batch 390, Loss: 0.9948
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.11351442337036 seconds
Epoch 120 accuracy: 68.68%
Batch 10, Loss: 0.9039
Batch 20, Loss: 0.8973
Batch 30, Loss: 0.8032
Batch 40, Loss: 0.9063
Batch 50, Loss: 0.8604
Batch 60, Loss: 0.8679
Batch 70, Loss: 0.8682
Batch 80, Loss: 0.9152
Batch 90, Loss: 0.8598
Batch 100, Loss: 0.8706
Batch 110, Loss: 0.8571
Batch 120, Loss: 0.8340
Batch 130, Loss: 0.9259
Batch 140, Loss: 0.9367
Batch 150, Loss: 0.9788
Batch 160, Loss: 0.9090
Batch 170, Loss: 0.9233
Batch 180, Loss: 0.9308
Batch 190, Loss: 0.9241
Batch 200, Loss: 0.8806
Batch 210, Loss: 0.9393
Batch 220, Loss: 0.9222
Batch 230, Loss: 0.9116
Batch 240, Loss: 0.9019
Batch 250, Loss: 0.9327
Batch 260, Loss: 0.9475
Batch 270, Loss: 0.9506
Batch 280, Loss: 0.9502
Batch 290, Loss: 0.9264
Batch 300, Loss: 0.8916
Batch 310, Loss: 0.9460
Batch 320, Loss: 0.9284
Batch 330, Loss: 1.0283
Batch 340, Loss: 0.9687
Batch 350, Loss: 0.9572
Batch 360, Loss: 0.9641
Batch 370, Loss: 0.9346
Batch 380, Loss: 0.9584
Batch 390, Loss: 0.9628
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.094593286514282 seconds
Epoch 121 accuracy: 69.47%
Batch 10, Loss: 0.8909
Batch 20, Loss: 0.8744
Batch 30, Loss: 0.8773
Batch 40, Loss: 0.8948
Batch 50, Loss: 0.8554
Batch 60, Loss: 0.8801
Batch 70, Loss: 0.8717
Batch 80, Loss: 0.9170
Batch 90, Loss: 0.8409
Batch 100, Loss: 0.8590
Batch 110, Loss: 0.8419
Batch 120, Loss: 0.8159
Batch 130, Loss: 0.8450
Batch 140, Loss: 0.8828
Batch 150, Loss: 0.8341
Batch 160, Loss: 0.8968
Batch 170, Loss: 0.9186
Batch 180, Loss: 0.9170
Batch 190, Loss: 0.9530
Batch 200, Loss: 0.9311
Batch 210, Loss: 0.9386
Batch 220, Loss: 0.9458
Batch 230, Loss: 0.8786
Batch 240, Loss: 0.8959
Batch 250, Loss: 0.9142
Batch 260, Loss: 0.9200
Batch 270, Loss: 0.9629
Batch 280, Loss: 0.9157
Batch 290, Loss: 0.9632
Batch 300, Loss: 0.9691
Batch 310, Loss: 1.0190
Batch 320, Loss: 0.8945
Batch 330, Loss: 0.9908
Batch 340, Loss: 1.0347
Batch 350, Loss: 0.9231
Batch 360, Loss: 0.8792
Batch 370, Loss: 0.9690
Batch 380, Loss: 0.8804
Batch 390, Loss: 0.9944
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.055264711380005 seconds
Epoch 122 accuracy: 68.9%
Batch 10, Loss: 0.8852
Batch 20, Loss: 0.8489
Batch 30, Loss: 0.8341
Batch 40, Loss: 0.8369
Batch 50, Loss: 0.8724
Batch 60, Loss: 0.8624
Batch 70, Loss: 0.8722
Batch 80, Loss: 0.8830
Batch 90, Loss: 0.8214
Batch 100, Loss: 0.8908
Batch 110, Loss: 0.8398
Batch 120, Loss: 0.8568
Batch 130, Loss: 0.8839
Batch 140, Loss: 0.8462
Batch 150, Loss: 0.8247
Batch 160, Loss: 0.8473
Batch 170, Loss: 0.8974
Batch 180, Loss: 0.8606
Batch 190, Loss: 0.8869
Batch 200, Loss: 0.9218
Batch 210, Loss: 0.8926
Batch 220, Loss: 0.9042
Batch 230, Loss: 0.8877
Batch 240, Loss: 0.9321
Batch 250, Loss: 0.9604
Batch 260, Loss: 0.9097
Batch 270, Loss: 0.9138
Batch 280, Loss: 0.9194
Batch 290, Loss: 0.9417
Batch 300, Loss: 0.9418
Batch 310, Loss: 0.9624
Batch 320, Loss: 0.9440
Batch 330, Loss: 0.9828
Batch 340, Loss: 0.9489
Batch 350, Loss: 0.9148
Batch 360, Loss: 0.9396
Batch 370, Loss: 0.9199
Batch 380, Loss: 0.9309
Batch 390, Loss: 0.9834
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.02678370475769 seconds
Epoch 123 accuracy: 67.76%
Batch 10, Loss: 0.8074
Batch 20, Loss: 0.9234
Batch 30, Loss: 0.8541
Batch 40, Loss: 0.7988
Batch 50, Loss: 0.8176
Batch 60, Loss: 0.8732
Batch 70, Loss: 0.9057
Batch 80, Loss: 0.8546
Batch 90, Loss: 0.8552
Batch 100, Loss: 0.8482
Batch 110, Loss: 0.8698
Batch 120, Loss: 0.8818
Batch 130, Loss: 0.8736
Batch 140, Loss: 0.8759
Batch 150, Loss: 0.9150
Batch 160, Loss: 0.8666
Batch 170, Loss: 0.8466
Batch 180, Loss: 0.9104
Batch 190, Loss: 0.9388
Batch 200, Loss: 0.8925
Batch 210, Loss: 0.8678
Batch 220, Loss: 0.8902
Batch 230, Loss: 0.8645
Batch 240, Loss: 0.8654
Batch 250, Loss: 0.9279
Batch 260, Loss: 0.8516
Batch 270, Loss: 0.9715
Batch 280, Loss: 0.9428
Batch 290, Loss: 0.9804
Batch 300, Loss: 0.9282
Batch 310, Loss: 0.9302
Batch 320, Loss: 0.9093
Batch 330, Loss: 0.9145
Batch 340, Loss: 0.9147
Batch 350, Loss: 0.9294
Batch 360, Loss: 0.8711
Batch 370, Loss: 0.9400
Batch 380, Loss: 0.8908
Batch 390, Loss: 0.9475
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.011051177978516 seconds
Epoch 124 accuracy: 70.8%
Batch 10, Loss: 0.8391
Batch 20, Loss: 0.8135
Batch 30, Loss: 0.9112
Batch 40, Loss: 0.7937
Batch 50, Loss: 0.8294
Batch 60, Loss: 0.8285
Batch 70, Loss: 0.8667
Batch 80, Loss: 0.8383
Batch 90, Loss: 0.8141
Batch 100, Loss: 0.8475
Batch 110, Loss: 0.8773
Batch 120, Loss: 0.9074
Batch 130, Loss: 0.8882
Batch 140, Loss: 0.8668
Batch 150, Loss: 0.8217
Batch 160, Loss: 0.8999
Batch 170, Loss: 0.9092
Batch 180, Loss: 0.8376
Batch 190, Loss: 0.8682
Batch 200, Loss: 0.8892
Batch 210, Loss: 0.8679
Batch 220, Loss: 0.9215
Batch 230, Loss: 0.8584
Batch 240, Loss: 0.8686
Batch 250, Loss: 0.9674
Batch 260, Loss: 0.9196
Batch 270, Loss: 0.8699
Batch 280, Loss: 0.8674
Batch 290, Loss: 0.9083
Batch 300, Loss: 0.9544
Batch 310, Loss: 0.8562
Batch 320, Loss: 0.8818
Batch 330, Loss: 0.8834
Batch 340, Loss: 0.8732
Batch 350, Loss: 0.9338
Batch 360, Loss: 0.8560
Batch 370, Loss: 0.9520
Batch 380, Loss: 0.8505
Batch 390, Loss: 0.8542
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.00980305671692 seconds
Epoch 125 accuracy: 70.71%
Batch 10, Loss: 0.8118
Batch 20, Loss: 0.8793
Batch 30, Loss: 0.8033
Batch 40, Loss: 0.8499
Batch 50, Loss: 0.8945
Batch 60, Loss: 0.8492
Batch 70, Loss: 0.8623
Batch 80, Loss: 0.8413
Batch 90, Loss: 0.8061
Batch 100, Loss: 0.8795
Batch 110, Loss: 0.8927
Batch 120, Loss: 0.8114
Batch 130, Loss: 0.9205
Batch 140, Loss: 0.8796
Batch 150, Loss: 0.8090
Batch 160, Loss: 0.8542
Batch 170, Loss: 0.9036
Batch 180, Loss: 0.8329
Batch 190, Loss: 0.9069
Batch 200, Loss: 0.8289
Batch 210, Loss: 0.8841
Batch 220, Loss: 0.8823
Batch 230, Loss: 0.7969
Batch 240, Loss: 0.9069
Batch 250, Loss: 0.8524
Batch 260, Loss: 0.8042
Batch 270, Loss: 0.8622
Batch 280, Loss: 0.8746
Batch 290, Loss: 0.8526
Batch 300, Loss: 0.9081
Batch 310, Loss: 0.8532
Batch 320, Loss: 0.8167
Batch 330, Loss: 0.8719
Batch 340, Loss: 0.8727
Batch 350, Loss: 0.8965
Batch 360, Loss: 0.9704
Batch 370, Loss: 0.8920
Batch 380, Loss: 0.8555
Batch 390, Loss: 0.9055
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.095288038253784 seconds
Epoch 126 accuracy: 70.32%
Batch 10, Loss: 0.8410
Batch 20, Loss: 0.8179
Batch 30, Loss: 0.8253
Batch 40, Loss: 0.8552
Batch 50, Loss: 0.8554
Batch 60, Loss: 0.8267
Batch 70, Loss: 0.8054
Batch 80, Loss: 0.8554
Batch 90, Loss: 0.8234
Batch 100, Loss: 0.8560
Batch 110, Loss: 0.8818
Batch 120, Loss: 0.7991
Batch 130, Loss: 0.8642
Batch 140, Loss: 0.8755
Batch 150, Loss: 0.8573
Batch 160, Loss: 0.8481
Batch 170, Loss: 0.8232
Batch 180, Loss: 0.8375
Batch 190, Loss: 0.8912
Batch 200, Loss: 0.8797
Batch 210, Loss: 0.9254
Batch 220, Loss: 0.9119
Batch 230, Loss: 0.9055
Batch 240, Loss: 0.8705
Batch 250, Loss: 0.8593
Batch 260, Loss: 0.8395
Batch 270, Loss: 0.8932
Batch 280, Loss: 0.9144
Batch 290, Loss: 0.8756
Batch 300, Loss: 0.8772
Batch 310, Loss: 0.8760
Batch 320, Loss: 0.8912
Batch 330, Loss: 0.8927
Batch 340, Loss: 0.8621
Batch 350, Loss: 0.9129
Batch 360, Loss: 0.8931
Batch 370, Loss: 0.8324
Batch 380, Loss: 0.8365
Batch 390, Loss: 0.9069
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.038092851638794 seconds
Epoch 127 accuracy: 69.57%
Batch 10, Loss: 0.8353
Batch 20, Loss: 0.8072
Batch 30, Loss: 0.7741
Batch 40, Loss: 0.8141
Batch 50, Loss: 0.8045
Batch 60, Loss: 0.8076
Batch 70, Loss: 0.8215
Batch 80, Loss: 0.8077
Batch 90, Loss: 0.8804
Batch 100, Loss: 0.8044
Batch 110, Loss: 0.8361
Batch 120, Loss: 0.8439
Batch 130, Loss: 0.8085
Batch 140, Loss: 0.7860
Batch 150, Loss: 0.8697
Batch 160, Loss: 0.8551
Batch 170, Loss: 0.7924
Batch 180, Loss: 0.8020
Batch 190, Loss: 0.8642
Batch 200, Loss: 0.7895
Batch 210, Loss: 0.8454
Batch 220, Loss: 0.8905
Batch 230, Loss: 0.8862
Batch 240, Loss: 0.8809
Batch 250, Loss: 0.8531
Batch 260, Loss: 0.8776
Batch 270, Loss: 0.9286
Batch 280, Loss: 0.8771
Batch 290, Loss: 0.8468
Batch 300, Loss: 0.8582
Batch 310, Loss: 0.8768
Batch 320, Loss: 0.9296
Batch 330, Loss: 0.9125
Batch 340, Loss: 0.8746
Batch 350, Loss: 0.8572
Batch 360, Loss: 0.8367
Batch 370, Loss: 0.8933
Batch 380, Loss: 0.9123
Batch 390, Loss: 0.8944
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.138636827468872 seconds
Epoch 128 accuracy: 69.29%
Batch 10, Loss: 0.7878
Batch 20, Loss: 0.8113
Batch 30, Loss: 0.8007
Batch 40, Loss: 0.8197
Batch 50, Loss: 0.8116
Batch 60, Loss: 0.7965
Batch 70, Loss: 0.8108
Batch 80, Loss: 0.8401
Batch 90, Loss: 0.8079
Batch 100, Loss: 0.8087
Batch 110, Loss: 0.7797
Batch 120, Loss: 0.7933
Batch 130, Loss: 0.8228
Batch 140, Loss: 0.8211
Batch 150, Loss: 0.8346
Batch 160, Loss: 0.8098
Batch 170, Loss: 0.8324
Batch 180, Loss: 0.8544
Batch 190, Loss: 0.8146
Batch 200, Loss: 0.8136
Batch 210, Loss: 0.8510
Batch 220, Loss: 0.8530
Batch 230, Loss: 0.7997
Batch 240, Loss: 0.8351
Batch 250, Loss: 0.8646
Batch 260, Loss: 0.8731
Batch 270, Loss: 0.8569
Batch 280, Loss: 0.8016
Batch 290, Loss: 0.8284
Batch 300, Loss: 0.8861
Batch 310, Loss: 0.8794
Batch 320, Loss: 0.8431
Batch 330, Loss: 0.8376
Batch 340, Loss: 0.8641
Batch 350, Loss: 0.8223
Batch 360, Loss: 0.8825
Batch 370, Loss: 0.8321
Batch 380, Loss: 0.8977
Batch 390, Loss: 0.8622
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.013633966445923 seconds
Epoch 129 accuracy: 70.26%
Batch 10, Loss: 0.8274
Batch 20, Loss: 0.8345
Batch 30, Loss: 0.7796
Batch 40, Loss: 0.7472
Batch 50, Loss: 0.8102
Batch 60, Loss: 0.7554
Batch 70, Loss: 0.8104
Batch 80, Loss: 0.8740
Batch 90, Loss: 0.7978
Batch 100, Loss: 0.8270
Batch 110, Loss: 0.7959
Batch 120, Loss: 0.8481
Batch 130, Loss: 0.8475
Batch 140, Loss: 0.8684
Batch 150, Loss: 0.8212
Batch 160, Loss: 0.8108
Batch 170, Loss: 0.8258
Batch 180, Loss: 0.8209
Batch 190, Loss: 0.8555
Batch 200, Loss: 0.8052
Batch 210, Loss: 0.7928
Batch 220, Loss: 0.8545
Batch 230, Loss: 0.8814
Batch 240, Loss: 0.8543
Batch 250, Loss: 0.8342
Batch 260, Loss: 0.8983
Batch 270, Loss: 0.8490
Batch 280, Loss: 0.8466
Batch 290, Loss: 0.8712
Batch 300, Loss: 0.9076
Batch 310, Loss: 0.8522
Batch 320, Loss: 0.8742
Batch 330, Loss: 0.8936
Batch 340, Loss: 0.8035
Batch 350, Loss: 0.8787
Batch 360, Loss: 0.8638
Batch 370, Loss: 0.8377
Batch 380, Loss: 0.8681
Batch 390, Loss: 0.8455
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.06809401512146 seconds
Epoch 130 accuracy: 71.4%
Batch 10, Loss: 0.8490
Batch 20, Loss: 0.7933
Batch 30, Loss: 0.7843
Batch 40, Loss: 0.7507
Batch 50, Loss: 0.8076
Batch 60, Loss: 0.8875
Batch 70, Loss: 0.7541
Batch 80, Loss: 0.7909
Batch 90, Loss: 0.7515
Batch 100, Loss: 0.7613
Batch 110, Loss: 0.8213
Batch 120, Loss: 0.8069
Batch 130, Loss: 0.7585
Batch 140, Loss: 0.7826
Batch 150, Loss: 0.7960
Batch 160, Loss: 0.7924
Batch 170, Loss: 0.8285
Batch 180, Loss: 0.8133
Batch 190, Loss: 0.8196
Batch 200, Loss: 0.8669
Batch 210, Loss: 0.8206
Batch 220, Loss: 0.8294
Batch 230, Loss: 0.7911
Batch 240, Loss: 0.8474
Batch 250, Loss: 0.8222
Batch 260, Loss: 0.7693
Batch 270, Loss: 0.8229
Batch 280, Loss: 0.8868
Batch 290, Loss: 0.7881
Batch 300, Loss: 0.8038
Batch 310, Loss: 0.8115
Batch 320, Loss: 0.8217
Batch 330, Loss: 0.8245
Batch 340, Loss: 0.8748
Batch 350, Loss: 0.8324
Batch 360, Loss: 0.7859
Batch 370, Loss: 0.8468
Batch 380, Loss: 0.8669
Batch 390, Loss: 0.8500
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.025659561157227 seconds
Epoch 131 accuracy: 70.88%
Batch 10, Loss: 0.7209
Batch 20, Loss: 0.7891
Batch 30, Loss: 0.7406
Batch 40, Loss: 0.8004
Batch 50, Loss: 0.7851
Batch 60, Loss: 0.7303
Batch 70, Loss: 0.7200
Batch 80, Loss: 0.8719
Batch 90, Loss: 0.7937
Batch 100, Loss: 0.7369
Batch 110, Loss: 0.7843
Batch 120, Loss: 0.7592
Batch 130, Loss: 0.7562
Batch 140, Loss: 0.7927
Batch 150, Loss: 0.7833
Batch 160, Loss: 0.7920
Batch 170, Loss: 0.7951
Batch 180, Loss: 0.8421
Batch 190, Loss: 0.7945
Batch 200, Loss: 0.7904
Batch 210, Loss: 0.7555
Batch 220, Loss: 0.8264
Batch 230, Loss: 0.8175
Batch 240, Loss: 0.8133
Batch 250, Loss: 0.8098
Batch 260, Loss: 0.7883
Batch 270, Loss: 0.7976
Batch 280, Loss: 0.8234
Batch 290, Loss: 0.8531
Batch 300, Loss: 0.8280
Batch 310, Loss: 0.8482
Batch 320, Loss: 0.7936
Batch 330, Loss: 0.7753
Batch 340, Loss: 0.8715
Batch 350, Loss: 0.8700
Batch 360, Loss: 0.8461
Batch 370, Loss: 0.8448
Batch 380, Loss: 0.8720
Batch 390, Loss: 0.8875
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.071136713027954 seconds
Epoch 132 accuracy: 70.83%
Batch 10, Loss: 0.7868
Batch 20, Loss: 0.7334
Batch 30, Loss: 0.7720
Batch 40, Loss: 0.8150
Batch 50, Loss: 0.8038
Batch 60, Loss: 0.8064
Batch 70, Loss: 0.8023
Batch 80, Loss: 0.7703
Batch 90, Loss: 0.7401
Batch 100, Loss: 0.7537
Batch 110, Loss: 0.7813
Batch 120, Loss: 0.7974
Batch 130, Loss: 0.8122
Batch 140, Loss: 0.8481
Batch 150, Loss: 0.7965
Batch 160, Loss: 0.7819
Batch 170, Loss: 0.7676
Batch 180, Loss: 0.7590
Batch 190, Loss: 0.8077
Batch 200, Loss: 0.8601
Batch 210, Loss: 0.7837
Batch 220, Loss: 0.8025
Batch 230, Loss: 0.7274
Batch 240, Loss: 0.7843
Batch 250, Loss: 0.7928
Batch 260, Loss: 0.8080
Batch 270, Loss: 0.8260
Batch 280, Loss: 0.8086
Batch 290, Loss: 0.8178
Batch 300, Loss: 0.7643
Batch 310, Loss: 0.8250
Batch 320, Loss: 0.7971
Batch 330, Loss: 0.8561
Batch 340, Loss: 0.8031
Batch 350, Loss: 0.8489
Batch 360, Loss: 0.8046
Batch 370, Loss: 0.8282
Batch 380, Loss: 0.7687
Batch 390, Loss: 0.8099
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.059884071350098 seconds
Epoch 133 accuracy: 71.44%
Batch 10, Loss: 0.8051
Batch 20, Loss: 0.7458
Batch 30, Loss: 0.7787
Batch 40, Loss: 0.7466
Batch 50, Loss: 0.7034
Batch 60, Loss: 0.7521
Batch 70, Loss: 0.7425
Batch 80, Loss: 0.7739
Batch 90, Loss: 0.7602
Batch 100, Loss: 0.7542
Batch 110, Loss: 0.7776
Batch 120, Loss: 0.7883
Batch 130, Loss: 0.7343
Batch 140, Loss: 0.7626
Batch 150, Loss: 0.8146
Batch 160, Loss: 0.7578
Batch 170, Loss: 0.7154
Batch 180, Loss: 0.7949
Batch 190, Loss: 0.7850
Batch 200, Loss: 0.7533
Batch 210, Loss: 0.7405
Batch 220, Loss: 0.7987
Batch 230, Loss: 0.7803
Batch 240, Loss: 0.7670
Batch 250, Loss: 0.8265
Batch 260, Loss: 0.7996
Batch 270, Loss: 0.8280
Batch 280, Loss: 0.8554
Batch 290, Loss: 0.8655
Batch 300, Loss: 0.8089
Batch 310, Loss: 0.8276
Batch 320, Loss: 0.7686
Batch 330, Loss: 0.8542
Batch 340, Loss: 0.8130
Batch 350, Loss: 0.8196
Batch 360, Loss: 0.8488
Batch 370, Loss: 0.8639
Batch 380, Loss: 0.8269
Batch 390, Loss: 0.7847
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.023794174194336 seconds
Epoch 134 accuracy: 71.85%
Batch 10, Loss: 0.7267
Batch 20, Loss: 0.7212
Batch 30, Loss: 0.7475
Batch 40, Loss: 0.7593
Batch 50, Loss: 0.7498
Batch 60, Loss: 0.7550
Batch 70, Loss: 0.7859
Batch 80, Loss: 0.7147
Batch 90, Loss: 0.8216
Batch 100, Loss: 0.7338
Batch 110, Loss: 0.7316
Batch 120, Loss: 0.7276
Batch 130, Loss: 0.7418
Batch 140, Loss: 0.8166
Batch 150, Loss: 0.7356
Batch 160, Loss: 0.7525
Batch 170, Loss: 0.7443
Batch 180, Loss: 0.7484
Batch 190, Loss: 0.7753
Batch 200, Loss: 0.7882
Batch 210, Loss: 0.7809
Batch 220, Loss: 0.8515
Batch 230, Loss: 0.8088
Batch 240, Loss: 0.8086
Batch 250, Loss: 0.8215
Batch 260, Loss: 0.7736
Batch 270, Loss: 0.8161
Batch 280, Loss: 0.7705
Batch 290, Loss: 0.8158
Batch 300, Loss: 0.7669
Batch 310, Loss: 0.7996
Batch 320, Loss: 0.7717
Batch 330, Loss: 0.7825
Batch 340, Loss: 0.8225
Batch 350, Loss: 0.7697
Batch 360, Loss: 0.8108
Batch 370, Loss: 0.8212
Batch 380, Loss: 0.8292
Batch 390, Loss: 0.8293
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.010154724121094 seconds
Epoch 135 accuracy: 71.5%
Batch 10, Loss: 0.7210
Batch 20, Loss: 0.6973
Batch 30, Loss: 0.7595
Batch 40, Loss: 0.7309
Batch 50, Loss: 0.7861
Batch 60, Loss: 0.7149
Batch 70, Loss: 0.7416
Batch 80, Loss: 0.7327
Batch 90, Loss: 0.7145
Batch 100, Loss: 0.7463
Batch 110, Loss: 0.7414
Batch 120, Loss: 0.7471
Batch 130, Loss: 0.7356
Batch 140, Loss: 0.7674
Batch 150, Loss: 0.7192
Batch 160, Loss: 0.7530
Batch 170, Loss: 0.7771
Batch 180, Loss: 0.7760
Batch 190, Loss: 0.7538
Batch 200, Loss: 0.7416
Batch 210, Loss: 0.7967
Batch 220, Loss: 0.7814
Batch 230, Loss: 0.7534
Batch 240, Loss: 0.7405
Batch 250, Loss: 0.8014
Batch 260, Loss: 0.7965
Batch 270, Loss: 0.7483
Batch 280, Loss: 0.8088
Batch 290, Loss: 0.7863
Batch 300, Loss: 0.7538
Batch 310, Loss: 0.7280
Batch 320, Loss: 0.7405
Batch 330, Loss: 0.7992
Batch 340, Loss: 0.8018
Batch 350, Loss: 0.7675
Batch 360, Loss: 0.7740
Batch 370, Loss: 0.7838
Batch 380, Loss: 0.8433
Batch 390, Loss: 0.8146
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.002403259277344 seconds
Epoch 136 accuracy: 72.23%
Batch 10, Loss: 0.7216
Batch 20, Loss: 0.7026
Batch 30, Loss: 0.7136
Batch 40, Loss: 0.7418
Batch 50, Loss: 0.7262
Batch 60, Loss: 0.7300
Batch 70, Loss: 0.7528
Batch 80, Loss: 0.7520
Batch 90, Loss: 0.7509
Batch 100, Loss: 0.7450
Batch 110, Loss: 0.7099
Batch 120, Loss: 0.7423
Batch 130, Loss: 0.7199
Batch 140, Loss: 0.7390
Batch 150, Loss: 0.7699
Batch 160, Loss: 0.7605
Batch 170, Loss: 0.7069
Batch 180, Loss: 0.7346
Batch 190, Loss: 0.7478
Batch 200, Loss: 0.7474
Batch 210, Loss: 0.7177
Batch 220, Loss: 0.6865
Batch 230, Loss: 0.7026
Batch 240, Loss: 0.8000
Batch 250, Loss: 0.7576
Batch 260, Loss: 0.7478
Batch 270, Loss: 0.8179
Batch 280, Loss: 0.7461
Batch 290, Loss: 0.7251
Batch 300, Loss: 0.7424
Batch 310, Loss: 0.7426
Batch 320, Loss: 0.7170
Batch 330, Loss: 0.7879
Batch 340, Loss: 0.7715
Batch 350, Loss: 0.7646
Batch 360, Loss: 0.7557
Batch 370, Loss: 0.7882
Batch 380, Loss: 0.8008
Batch 390, Loss: 0.7120
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.02448320388794 seconds
Epoch 137 accuracy: 71.64%
Batch 10, Loss: 0.6945
Batch 20, Loss: 0.6936
Batch 30, Loss: 0.6834
Batch 40, Loss: 0.7043
Batch 50, Loss: 0.7175
Batch 60, Loss: 0.7218
Batch 70, Loss: 0.7157
Batch 80, Loss: 0.6642
Batch 90, Loss: 0.7407
Batch 100, Loss: 0.7076
Batch 110, Loss: 0.7561
Batch 120, Loss: 0.6765
Batch 130, Loss: 0.7371
Batch 140, Loss: 0.7396
Batch 150, Loss: 0.7730
Batch 160, Loss: 0.7485
Batch 170, Loss: 0.7749
Batch 180, Loss: 0.7714
Batch 190, Loss: 0.7684
Batch 200, Loss: 0.7392
Batch 210, Loss: 0.7449
Batch 220, Loss: 0.7500
Batch 230, Loss: 0.6952
Batch 240, Loss: 0.7425
Batch 250, Loss: 0.7596
Batch 260, Loss: 0.6993
Batch 270, Loss: 0.7713
Batch 280, Loss: 0.7586
Batch 290, Loss: 0.7579
Batch 300, Loss: 0.7212
Batch 310, Loss: 0.7323
Batch 320, Loss: 0.8374
Batch 330, Loss: 0.7674
Batch 340, Loss: 0.8029
Batch 350, Loss: 0.7846
Batch 360, Loss: 0.7898
Batch 370, Loss: 0.7551
Batch 380, Loss: 0.7037
Batch 390, Loss: 0.8088
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.162851333618164 seconds
Epoch 138 accuracy: 72.61%
Batch 10, Loss: 0.7032
Batch 20, Loss: 0.7087
Batch 30, Loss: 0.7048
Batch 40, Loss: 0.7231
Batch 50, Loss: 0.6795
Batch 60, Loss: 0.7458
Batch 70, Loss: 0.6787
Batch 80, Loss: 0.6981
Batch 90, Loss: 0.7314
Batch 100, Loss: 0.7498
Batch 110, Loss: 0.6751
Batch 120, Loss: 0.6747
Batch 130, Loss: 0.7188
Batch 140, Loss: 0.7048
Batch 150, Loss: 0.6974
Batch 160, Loss: 0.7237
Batch 170, Loss: 0.6584
Batch 180, Loss: 0.7329
Batch 190, Loss: 0.6928
Batch 200, Loss: 0.6984
Batch 210, Loss: 0.7717
Batch 220, Loss: 0.7387
Batch 230, Loss: 0.7182
Batch 240, Loss: 0.7601
Batch 250, Loss: 0.7356
Batch 260, Loss: 0.7741
Batch 270, Loss: 0.7395
Batch 280, Loss: 0.7129
Batch 290, Loss: 0.7624
Batch 300, Loss: 0.7198
Batch 310, Loss: 0.7241
Batch 320, Loss: 0.7224
Batch 330, Loss: 0.8030
Batch 340, Loss: 0.7012
Batch 350, Loss: 0.7436
Batch 360, Loss: 0.6816
Batch 370, Loss: 0.7434
Batch 380, Loss: 0.7430
Batch 390, Loss: 0.7575
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.108970880508423 seconds
Epoch 139 accuracy: 72.65%
Batch 10, Loss: 0.7048
Batch 20, Loss: 0.7153
Batch 30, Loss: 0.6927
Batch 40, Loss: 0.7022
Batch 50, Loss: 0.7143
Batch 60, Loss: 0.6763
Batch 70, Loss: 0.7359
Batch 80, Loss: 0.7463
Batch 90, Loss: 0.7229
Batch 100, Loss: 0.7105
Batch 110, Loss: 0.6882
Batch 120, Loss: 0.6783
Batch 130, Loss: 0.7089
Batch 140, Loss: 0.6979
Batch 150, Loss: 0.7398
Batch 160, Loss: 0.6598
Batch 170, Loss: 0.7441
Batch 180, Loss: 0.7443
Batch 190, Loss: 0.7250
Batch 200, Loss: 0.7052
Batch 210, Loss: 0.6888
Batch 220, Loss: 0.7054
Batch 230, Loss: 0.7290
Batch 240, Loss: 0.6824
Batch 250, Loss: 0.6859
Batch 260, Loss: 0.7596
Batch 270, Loss: 0.7768
Batch 280, Loss: 0.6791
Batch 290, Loss: 0.7313
Batch 300, Loss: 0.6790
Batch 310, Loss: 0.6998
Batch 320, Loss: 0.7231
Batch 330, Loss: 0.7426
Batch 340, Loss: 0.6947
Batch 350, Loss: 0.6953
Batch 360, Loss: 0.7689
Batch 370, Loss: 0.7051
Batch 380, Loss: 0.7365
Batch 390, Loss: 0.7210
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.050464630126953 seconds
Epoch 140 accuracy: 73.17%
Batch 10, Loss: 0.7017
Batch 20, Loss: 0.7105
Batch 30, Loss: 0.7442
Batch 40, Loss: 0.7186
Batch 50, Loss: 0.6677
Batch 60, Loss: 0.6614
Batch 70, Loss: 0.6902
Batch 80, Loss: 0.6890
Batch 90, Loss: 0.6882
Batch 100, Loss: 0.7069
Batch 110, Loss: 0.6645
Batch 120, Loss: 0.7207
Batch 130, Loss: 0.6523
Batch 140, Loss: 0.6805
Batch 150, Loss: 0.6486
Batch 160, Loss: 0.7122
Batch 170, Loss: 0.6772
Batch 180, Loss: 0.7230
Batch 190, Loss: 0.6886
Batch 200, Loss: 0.6997
Batch 210, Loss: 0.6774
Batch 220, Loss: 0.7556
Batch 230, Loss: 0.6849
Batch 240, Loss: 0.6835
Batch 250, Loss: 0.7264
Batch 260, Loss: 0.6662
Batch 270, Loss: 0.7807
Batch 280, Loss: 0.7217
Batch 290, Loss: 0.7307
Batch 300, Loss: 0.6893
Batch 310, Loss: 0.7235
Batch 320, Loss: 0.6444
Batch 330, Loss: 0.7177
Batch 340, Loss: 0.7338
Batch 350, Loss: 0.7468
Batch 360, Loss: 0.6900
Batch 370, Loss: 0.6570
Batch 380, Loss: 0.7532
Batch 390, Loss: 0.7210
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.05714511871338 seconds
Epoch 141 accuracy: 72.64%
Batch 10, Loss: 0.6758
Batch 20, Loss: 0.6769
Batch 30, Loss: 0.6713
Batch 40, Loss: 0.6727
Batch 50, Loss: 0.6623
Batch 60, Loss: 0.6925
Batch 70, Loss: 0.6368
Batch 80, Loss: 0.6636
Batch 90, Loss: 0.6604
Batch 100, Loss: 0.6200
Batch 110, Loss: 0.6861
Batch 120, Loss: 0.6586
Batch 130, Loss: 0.6538
Batch 140, Loss: 0.6981
Batch 150, Loss: 0.6751
Batch 160, Loss: 0.6632
Batch 170, Loss: 0.7221
Batch 180, Loss: 0.6633
Batch 190, Loss: 0.7278
Batch 200, Loss: 0.6628
Batch 210, Loss: 0.6856
Batch 220, Loss: 0.6384
Batch 230, Loss: 0.6974
Batch 240, Loss: 0.6895
Batch 250, Loss: 0.7381
Batch 260, Loss: 0.6965
Batch 270, Loss: 0.7081
Batch 280, Loss: 0.7084
Batch 290, Loss: 0.7329
Batch 300, Loss: 0.7513
Batch 310, Loss: 0.7268
Batch 320, Loss: 0.7349
Batch 330, Loss: 0.7651
Batch 340, Loss: 0.7826
Batch 350, Loss: 0.7673
Batch 360, Loss: 0.7176
Batch 370, Loss: 0.7846
Batch 380, Loss: 0.7565
Batch 390, Loss: 0.7089
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.139529705047607 seconds
Epoch 142 accuracy: 73.03%
Batch 10, Loss: 0.6058
Batch 20, Loss: 0.6575
Batch 30, Loss: 0.6781
Batch 40, Loss: 0.6641
Batch 50, Loss: 0.6701
Batch 60, Loss: 0.6322
Batch 70, Loss: 0.6741
Batch 80, Loss: 0.6995
Batch 90, Loss: 0.6495
Batch 100, Loss: 0.6936
Batch 110, Loss: 0.6668
Batch 120, Loss: 0.6784
Batch 130, Loss: 0.6695
Batch 140, Loss: 0.6383
Batch 150, Loss: 0.6705
Batch 160, Loss: 0.7071
Batch 170, Loss: 0.6752
Batch 180, Loss: 0.7097
Batch 190, Loss: 0.7116
Batch 200, Loss: 0.6627
Batch 210, Loss: 0.6960
Batch 220, Loss: 0.7211
Batch 230, Loss: 0.6758
Batch 240, Loss: 0.6388
Batch 250, Loss: 0.6833
Batch 260, Loss: 0.6932
Batch 270, Loss: 0.7211
Batch 280, Loss: 0.7013
Batch 290, Loss: 0.7149
Batch 300, Loss: 0.6860
Batch 310, Loss: 0.6948
Batch 320, Loss: 0.6729
Batch 330, Loss: 0.6777
Batch 340, Loss: 0.7462
Batch 350, Loss: 0.7690
Batch 360, Loss: 0.7671
Batch 370, Loss: 0.6978
Batch 380, Loss: 0.6717
Batch 390, Loss: 0.6805
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.05194091796875 seconds
Epoch 143 accuracy: 73.08%
Batch 10, Loss: 0.6421
Batch 20, Loss: 0.6799
Batch 30, Loss: 0.6393
Batch 40, Loss: 0.6627
Batch 50, Loss: 0.6602
Batch 60, Loss: 0.6553
Batch 70, Loss: 0.6957
Batch 80, Loss: 0.6509
Batch 90, Loss: 0.6327
Batch 100, Loss: 0.6559
Batch 110, Loss: 0.6295
Batch 120, Loss: 0.6008
Batch 130, Loss: 0.6158
Batch 140, Loss: 0.6438
Batch 150, Loss: 0.6595
Batch 160, Loss: 0.6501
Batch 170, Loss: 0.6610
Batch 180, Loss: 0.6598
Batch 190, Loss: 0.6845
Batch 200, Loss: 0.6243
Batch 210, Loss: 0.6771
Batch 220, Loss: 0.6465
Batch 230, Loss: 0.6762
Batch 240, Loss: 0.6649
Batch 250, Loss: 0.6978
Batch 260, Loss: 0.6816
Batch 270, Loss: 0.6916
Batch 280, Loss: 0.6678
Batch 290, Loss: 0.6601
Batch 300, Loss: 0.6758
Batch 310, Loss: 0.6677
Batch 320, Loss: 0.6975
Batch 330, Loss: 0.6842
Batch 340, Loss: 0.7352
Batch 350, Loss: 0.6668
Batch 360, Loss: 0.7070
Batch 370, Loss: 0.7207
Batch 380, Loss: 0.7389
Batch 390, Loss: 0.7017
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.03077507019043 seconds
Epoch 144 accuracy: 72.47%
Batch 10, Loss: 0.6323
Batch 20, Loss: 0.6337
Batch 30, Loss: 0.6166
Batch 40, Loss: 0.6146
Batch 50, Loss: 0.6292
Batch 60, Loss: 0.6240
Batch 70, Loss: 0.6129
Batch 80, Loss: 0.6869
Batch 90, Loss: 0.6568
Batch 100, Loss: 0.6153
Batch 110, Loss: 0.6440
Batch 120, Loss: 0.6593
Batch 130, Loss: 0.6115
Batch 140, Loss: 0.6671
Batch 150, Loss: 0.5823
Batch 160, Loss: 0.6715
Batch 170, Loss: 0.6397
Batch 180, Loss: 0.6532
Batch 190, Loss: 0.6892
Batch 200, Loss: 0.6464
Batch 210, Loss: 0.6194
Batch 220, Loss: 0.6692
Batch 230, Loss: 0.6362
Batch 240, Loss: 0.6731
Batch 250, Loss: 0.6515
Batch 260, Loss: 0.7152
Batch 270, Loss: 0.6620
Batch 280, Loss: 0.6863
Batch 290, Loss: 0.6998
Batch 300, Loss: 0.6302
Batch 310, Loss: 0.6811
Batch 320, Loss: 0.6348
Batch 330, Loss: 0.6719
Batch 340, Loss: 0.6346
Batch 350, Loss: 0.6619
Batch 360, Loss: 0.6754
Batch 370, Loss: 0.6615
Batch 380, Loss: 0.6980
Batch 390, Loss: 0.6801
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.08480453491211 seconds
Epoch 145 accuracy: 73.6%
Batch 10, Loss: 0.6852
Batch 20, Loss: 0.6292
Batch 30, Loss: 0.6754
Batch 40, Loss: 0.6128
Batch 50, Loss: 0.6520
Batch 60, Loss: 0.6175
Batch 70, Loss: 0.6144
Batch 80, Loss: 0.5914
Batch 90, Loss: 0.5415
Batch 100, Loss: 0.6241
Batch 110, Loss: 0.6176
Batch 120, Loss: 0.6331
Batch 130, Loss: 0.6424
Batch 140, Loss: 0.6114
Batch 150, Loss: 0.6614
Batch 160, Loss: 0.6468
Batch 170, Loss: 0.6290
Batch 180, Loss: 0.6482
Batch 190, Loss: 0.6964
Batch 200, Loss: 0.6401
Batch 210, Loss: 0.6890
Batch 220, Loss: 0.6617
Batch 230, Loss: 0.6390
Batch 240, Loss: 0.6381
Batch 250, Loss: 0.6630
Batch 260, Loss: 0.6486
Batch 270, Loss: 0.6257
Batch 280, Loss: 0.6696
Batch 290, Loss: 0.6964
Batch 300, Loss: 0.6638
Batch 310, Loss: 0.6054
Batch 320, Loss: 0.6540
Batch 330, Loss: 0.6659
Batch 340, Loss: 0.6270
Batch 350, Loss: 0.6449
Batch 360, Loss: 0.6457
Batch 370, Loss: 0.6449
Batch 380, Loss: 0.6639
Batch 390, Loss: 0.6989
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.14444875717163 seconds
Epoch 146 accuracy: 73.06%
Batch 10, Loss: 0.6424
Batch 20, Loss: 0.6029
Batch 30, Loss: 0.5745
Batch 40, Loss: 0.5987
Batch 50, Loss: 0.6248
Batch 60, Loss: 0.5860
Batch 70, Loss: 0.6135
Batch 80, Loss: 0.5965
Batch 90, Loss: 0.6391
Batch 100, Loss: 0.5907
Batch 110, Loss: 0.6282
Batch 120, Loss: 0.6319
Batch 130, Loss: 0.6146
Batch 140, Loss: 0.6063
Batch 150, Loss: 0.6315
Batch 160, Loss: 0.5760
Batch 170, Loss: 0.6673
Batch 180, Loss: 0.6292
Batch 190, Loss: 0.6595
Batch 200, Loss: 0.6147
Batch 210, Loss: 0.6307
Batch 220, Loss: 0.6408
Batch 230, Loss: 0.6651
Batch 240, Loss: 0.6323
Batch 250, Loss: 0.6090
Batch 260, Loss: 0.6106
Batch 270, Loss: 0.6323
Batch 280, Loss: 0.6410
Batch 290, Loss: 0.6680
Batch 300, Loss: 0.6495
Batch 310, Loss: 0.6498
Batch 320, Loss: 0.6576
Batch 330, Loss: 0.6533
Batch 340, Loss: 0.6474
Batch 350, Loss: 0.6441
Batch 360, Loss: 0.6369
Batch 370, Loss: 0.6850
Batch 380, Loss: 0.6433
Batch 390, Loss: 0.6619
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.05226707458496 seconds
Epoch 147 accuracy: 74.07%
Batch 10, Loss: 0.5726
Batch 20, Loss: 0.6247
Batch 30, Loss: 0.5821
Batch 40, Loss: 0.5878
Batch 50, Loss: 0.6089
Batch 60, Loss: 0.6054
Batch 70, Loss: 0.6071
Batch 80, Loss: 0.5821
Batch 90, Loss: 0.6253
Batch 100, Loss: 0.6785
Batch 110, Loss: 0.5864
Batch 120, Loss: 0.6098
Batch 130, Loss: 0.6420
Batch 140, Loss: 0.6225
Batch 150, Loss: 0.5694
Batch 160, Loss: 0.6648
Batch 170, Loss: 0.6471
Batch 180, Loss: 0.6363
Batch 190, Loss: 0.6023
Batch 200, Loss: 0.6478
Batch 210, Loss: 0.6118
Batch 220, Loss: 0.6340
Batch 230, Loss: 0.6588
Batch 240, Loss: 0.6306
Batch 250, Loss: 0.6463
Batch 260, Loss: 0.6582
Batch 270, Loss: 0.6045
Batch 280, Loss: 0.6170
Batch 290, Loss: 0.5790
Batch 300, Loss: 0.6371
Batch 310, Loss: 0.6650
Batch 320, Loss: 0.6116
Batch 330, Loss: 0.6625
Batch 340, Loss: 0.6387
Batch 350, Loss: 0.6624
Batch 360, Loss: 0.6923
Batch 370, Loss: 0.6678
Batch 380, Loss: 0.6516
Batch 390, Loss: 0.6319
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.022468328475952 seconds
Epoch 148 accuracy: 73.26%
Batch 10, Loss: 0.5612
Batch 20, Loss: 0.5622
Batch 30, Loss: 0.6183
Batch 40, Loss: 0.6090
Batch 50, Loss: 0.5776
Batch 60, Loss: 0.5937
Batch 70, Loss: 0.5811
Batch 80, Loss: 0.6169
Batch 90, Loss: 0.6111
Batch 100, Loss: 0.5827
Batch 110, Loss: 0.6032
Batch 120, Loss: 0.6182
Batch 130, Loss: 0.6030
Batch 140, Loss: 0.6169
Batch 150, Loss: 0.5679
Batch 160, Loss: 0.6590
Batch 170, Loss: 0.5741
Batch 180, Loss: 0.6260
Batch 190, Loss: 0.6557
Batch 200, Loss: 0.6237
Batch 210, Loss: 0.6251
Batch 220, Loss: 0.6210
Batch 230, Loss: 0.6426
Batch 240, Loss: 0.6303
Batch 250, Loss: 0.6424
Batch 260, Loss: 0.6084
Batch 270, Loss: 0.6300
Batch 280, Loss: 0.6202
Batch 290, Loss: 0.6667
Batch 300, Loss: 0.6165
Batch 310, Loss: 0.6161
Batch 320, Loss: 0.6638
Batch 330, Loss: 0.5959
Batch 340, Loss: 0.6284
Batch 350, Loss: 0.6150
Batch 360, Loss: 0.6233
Batch 370, Loss: 0.6706
Batch 380, Loss: 0.6089
Batch 390, Loss: 0.6642
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.08340048789978 seconds
Epoch 149 accuracy: 71.73%
Batch 10, Loss: 0.5998
Batch 20, Loss: 0.5806
Batch 30, Loss: 0.5757
Batch 40, Loss: 0.6160
Batch 50, Loss: 0.5537
Batch 60, Loss: 0.5697
Batch 70, Loss: 0.5781
Batch 80, Loss: 0.5188
Batch 90, Loss: 0.5695
Batch 100, Loss: 0.6334
Batch 110, Loss: 0.5426
Batch 120, Loss: 0.6015
Batch 130, Loss: 0.6176
Batch 140, Loss: 0.5842
Batch 150, Loss: 0.5939
Batch 160, Loss: 0.6400
Batch 170, Loss: 0.5696
Batch 180, Loss: 0.6027
Batch 190, Loss: 0.6141
Batch 200, Loss: 0.5836
Batch 210, Loss: 0.6016
Batch 220, Loss: 0.5857
Batch 230, Loss: 0.5823
Batch 240, Loss: 0.6210
Batch 250, Loss: 0.5970
Batch 260, Loss: 0.5642
Batch 270, Loss: 0.6032
Batch 280, Loss: 0.5731
Batch 290, Loss: 0.5964
Batch 300, Loss: 0.6159
Batch 310, Loss: 0.6781
Batch 320, Loss: 0.6061
Batch 330, Loss: 0.6090
Batch 340, Loss: 0.6089
Batch 350, Loss: 0.5836
Batch 360, Loss: 0.6123
Batch 370, Loss: 0.6159
Batch 380, Loss: 0.5744
Batch 390, Loss: 0.6086
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.025909900665283 seconds
Epoch 150 accuracy: 73.93%
Batch 10, Loss: 0.5320
Batch 20, Loss: 0.5960
Batch 30, Loss: 0.5660
Batch 40, Loss: 0.5481
Batch 50, Loss: 0.5671
Batch 60, Loss: 0.5517
Batch 70, Loss: 0.5870
Batch 80, Loss: 0.5157
Batch 90, Loss: 0.5651
Batch 100, Loss: 0.6073
Batch 110, Loss: 0.5459
Batch 120, Loss: 0.5532
Batch 130, Loss: 0.5553
Batch 140, Loss: 0.5904
Batch 150, Loss: 0.5842
Batch 160, Loss: 0.5777
Batch 170, Loss: 0.6167
Batch 180, Loss: 0.5995
Batch 190, Loss: 0.5472
Batch 200, Loss: 0.5498
Batch 210, Loss: 0.6007
Batch 220, Loss: 0.5787
Batch 230, Loss: 0.6309
Batch 240, Loss: 0.5736
Batch 250, Loss: 0.6124
Batch 260, Loss: 0.6254
Batch 270, Loss: 0.6091
Batch 280, Loss: 0.5901
Batch 290, Loss: 0.5685
Batch 300, Loss: 0.6424
Batch 310, Loss: 0.5730
Batch 320, Loss: 0.5944
Batch 330, Loss: 0.6151
Batch 340, Loss: 0.5866
Batch 350, Loss: 0.6089
Batch 360, Loss: 0.6002
Batch 370, Loss: 0.5822
Batch 380, Loss: 0.6501
Batch 390, Loss: 0.6452
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.06907296180725 seconds
Epoch 151 accuracy: 73.53%
Batch 10, Loss: 0.5508
Batch 20, Loss: 0.5541
Batch 30, Loss: 0.5423
Batch 40, Loss: 0.5705
Batch 50, Loss: 0.5554
Batch 60, Loss: 0.5656
Batch 70, Loss: 0.5323
Batch 80, Loss: 0.5490
Batch 90, Loss: 0.5930
Batch 100, Loss: 0.5459
Batch 110, Loss: 0.5570
Batch 120, Loss: 0.5900
Batch 130, Loss: 0.6254
Batch 140, Loss: 0.5226
Batch 150, Loss: 0.5521
Batch 160, Loss: 0.5444
Batch 170, Loss: 0.5933
Batch 180, Loss: 0.5581
Batch 190, Loss: 0.5647
Batch 200, Loss: 0.6072
Batch 210, Loss: 0.5745
Batch 220, Loss: 0.5518
Batch 230, Loss: 0.6061
Batch 240, Loss: 0.6085
Batch 250, Loss: 0.5556
Batch 260, Loss: 0.5580
Batch 270, Loss: 0.5819
Batch 280, Loss: 0.6240
Batch 290, Loss: 0.5816
Batch 300, Loss: 0.5868
Batch 310, Loss: 0.5283
Batch 320, Loss: 0.5997
Batch 330, Loss: 0.5727
Batch 340, Loss: 0.6151
Batch 350, Loss: 0.5901
Batch 360, Loss: 0.6000
Batch 370, Loss: 0.5827
Batch 380, Loss: 0.5778
Batch 390, Loss: 0.6049
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.058091640472412 seconds
Epoch 152 accuracy: 74.42%
Batch 10, Loss: 0.5764
Batch 20, Loss: 0.5498
Batch 30, Loss: 0.6096
Batch 40, Loss: 0.5592
Batch 50, Loss: 0.5082
Batch 60, Loss: 0.5193
Batch 70, Loss: 0.5241
Batch 80, Loss: 0.5333
Batch 90, Loss: 0.5986
Batch 100, Loss: 0.5646
Batch 110, Loss: 0.5071
Batch 120, Loss: 0.5617
Batch 130, Loss: 0.5827
Batch 140, Loss: 0.5102
Batch 150, Loss: 0.5792
Batch 160, Loss: 0.5315
Batch 170, Loss: 0.5282
Batch 180, Loss: 0.5248
Batch 190, Loss: 0.5472
Batch 200, Loss: 0.5827
Batch 210, Loss: 0.5406
Batch 220, Loss: 0.5441
Batch 230, Loss: 0.5543
Batch 240, Loss: 0.5476
Batch 250, Loss: 0.5680
Batch 260, Loss: 0.5630
Batch 270, Loss: 0.5840
Batch 280, Loss: 0.5886
Batch 290, Loss: 0.5334
Batch 300, Loss: 0.5670
Batch 310, Loss: 0.5956
Batch 320, Loss: 0.5795
Batch 330, Loss: 0.5844
Batch 340, Loss: 0.5772
Batch 350, Loss: 0.5666
Batch 360, Loss: 0.5536
Batch 370, Loss: 0.6012
Batch 380, Loss: 0.5635
Batch 390, Loss: 0.5734
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.05984115600586 seconds
Epoch 153 accuracy: 74.96%
Batch 10, Loss: 0.5380
Batch 20, Loss: 0.5547
Batch 30, Loss: 0.5196
Batch 40, Loss: 0.5448
Batch 50, Loss: 0.5645
Batch 60, Loss: 0.5787
Batch 70, Loss: 0.5799
Batch 80, Loss: 0.5315
Batch 90, Loss: 0.4631
Batch 100, Loss: 0.5775
Batch 110, Loss: 0.5417
Batch 120, Loss: 0.5583
Batch 130, Loss: 0.4992
Batch 140, Loss: 0.5754
Batch 150, Loss: 0.5552
Batch 160, Loss: 0.5161
Batch 170, Loss: 0.5642
Batch 180, Loss: 0.5457
Batch 190, Loss: 0.5675
Batch 200, Loss: 0.5515
Batch 210, Loss: 0.5405
Batch 220, Loss: 0.5271
Batch 230, Loss: 0.5651
Batch 240, Loss: 0.5530
Batch 250, Loss: 0.5279
Batch 260, Loss: 0.5502
Batch 270, Loss: 0.5296
Batch 280, Loss: 0.5643
Batch 290, Loss: 0.5403
Batch 300, Loss: 0.5636
Batch 310, Loss: 0.5292
Batch 320, Loss: 0.5301
Batch 330, Loss: 0.5546
Batch 340, Loss: 0.5065
Batch 350, Loss: 0.5348
Batch 360, Loss: 0.5788
Batch 370, Loss: 0.5871
Batch 380, Loss: 0.6151
Batch 390, Loss: 0.5504
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 24.983386754989624 seconds
Epoch 154 accuracy: 74.87%
Batch 10, Loss: 0.5395
Batch 20, Loss: 0.5238
Batch 30, Loss: 0.5044
Batch 40, Loss: 0.4940
Batch 50, Loss: 0.5385
Batch 60, Loss: 0.5397
Batch 70, Loss: 0.5326
Batch 80, Loss: 0.5113
Batch 90, Loss: 0.5221
Batch 100, Loss: 0.5259
Batch 110, Loss: 0.5183
Batch 120, Loss: 0.5051
Batch 130, Loss: 0.5198
Batch 140, Loss: 0.5176
Batch 150, Loss: 0.5223
Batch 160, Loss: 0.5178
Batch 170, Loss: 0.5445
Batch 180, Loss: 0.5643
Batch 190, Loss: 0.5506
Batch 200, Loss: 0.5096
Batch 210, Loss: 0.5375
Batch 220, Loss: 0.5452
Batch 230, Loss: 0.5770
Batch 240, Loss: 0.5610
Batch 250, Loss: 0.5125
Batch 260, Loss: 0.5216
Batch 270, Loss: 0.5442
Batch 280, Loss: 0.5250
Batch 290, Loss: 0.5278
Batch 300, Loss: 0.5314
Batch 310, Loss: 0.5668
Batch 320, Loss: 0.5767
Batch 330, Loss: 0.5881
Batch 340, Loss: 0.5480
Batch 350, Loss: 0.5483
Batch 360, Loss: 0.5386
Batch 370, Loss: 0.5474
Batch 380, Loss: 0.4940
Batch 390, Loss: 0.5772
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.10409927368164 seconds
Epoch 155 accuracy: 75.13%
Batch 10, Loss: 0.5197
Batch 20, Loss: 0.4969
Batch 30, Loss: 0.5055
Batch 40, Loss: 0.5404
Batch 50, Loss: 0.4988
Batch 60, Loss: 0.4860
Batch 70, Loss: 0.5340
Batch 80, Loss: 0.5386
Batch 90, Loss: 0.5455
Batch 100, Loss: 0.5300
Batch 110, Loss: 0.5270
Batch 120, Loss: 0.5394
Batch 130, Loss: 0.5254
Batch 140, Loss: 0.5295
Batch 150, Loss: 0.5149
Batch 160, Loss: 0.5237
Batch 170, Loss: 0.5068
Batch 180, Loss: 0.4993
Batch 190, Loss: 0.5013
Batch 200, Loss: 0.5624
Batch 210, Loss: 0.5141
Batch 220, Loss: 0.5686
Batch 230, Loss: 0.5354
Batch 240, Loss: 0.5199
Batch 250, Loss: 0.5498
Batch 260, Loss: 0.5288
Batch 270, Loss: 0.5267
Batch 280, Loss: 0.4757
Batch 290, Loss: 0.5320
Batch 300, Loss: 0.5382
Batch 310, Loss: 0.5470
Batch 320, Loss: 0.5539
Batch 330, Loss: 0.5342
Batch 340, Loss: 0.5430
Batch 350, Loss: 0.5475
Batch 360, Loss: 0.5307
Batch 370, Loss: 0.5087
Batch 380, Loss: 0.5698
Batch 390, Loss: 0.5842
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.149423122406006 seconds
Epoch 156 accuracy: 74.79%
Batch 10, Loss: 0.5459
Batch 20, Loss: 0.4939
Batch 30, Loss: 0.5396
Batch 40, Loss: 0.5362
Batch 50, Loss: 0.5407
Batch 60, Loss: 0.4761
Batch 70, Loss: 0.4856
Batch 80, Loss: 0.4754
Batch 90, Loss: 0.4593
Batch 100, Loss: 0.5058
Batch 110, Loss: 0.5002
Batch 120, Loss: 0.5227
Batch 130, Loss: 0.5125
Batch 140, Loss: 0.4875
Batch 150, Loss: 0.5280
Batch 160, Loss: 0.5010
Batch 170, Loss: 0.5191
Batch 180, Loss: 0.4899
Batch 190, Loss: 0.5023
Batch 200, Loss: 0.5121
Batch 210, Loss: 0.5291
Batch 220, Loss: 0.4984
Batch 230, Loss: 0.5398
Batch 240, Loss: 0.4992
Batch 250, Loss: 0.5255
Batch 260, Loss: 0.5163
Batch 270, Loss: 0.5508
Batch 280, Loss: 0.5084
Batch 290, Loss: 0.5412
Batch 300, Loss: 0.5067
Batch 310, Loss: 0.5413
Batch 320, Loss: 0.5147
Batch 330, Loss: 0.4562
Batch 340, Loss: 0.5165
Batch 350, Loss: 0.4816
Batch 360, Loss: 0.4982
Batch 370, Loss: 0.5115
Batch 380, Loss: 0.4929
Batch 390, Loss: 0.5657
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.083838939666748 seconds
Epoch 157 accuracy: 75.56%
Batch 10, Loss: 0.4730
Batch 20, Loss: 0.5046
Batch 30, Loss: 0.5084
Batch 40, Loss: 0.4787
Batch 50, Loss: 0.5118
Batch 60, Loss: 0.5501
Batch 70, Loss: 0.4964
Batch 80, Loss: 0.4473
Batch 90, Loss: 0.5283
Batch 100, Loss: 0.5008
Batch 110, Loss: 0.4657
Batch 120, Loss: 0.4978
Batch 130, Loss: 0.4885
Batch 140, Loss: 0.5657
Batch 150, Loss: 0.5144
Batch 160, Loss: 0.5223
Batch 170, Loss: 0.5025
Batch 180, Loss: 0.4814
Batch 190, Loss: 0.5120
Batch 200, Loss: 0.5185
Batch 210, Loss: 0.5249
Batch 220, Loss: 0.4827
Batch 230, Loss: 0.5001
Batch 240, Loss: 0.5023
Batch 250, Loss: 0.5115
Batch 260, Loss: 0.5056
Batch 270, Loss: 0.4953
Batch 280, Loss: 0.5426
Batch 290, Loss: 0.5256
Batch 300, Loss: 0.4674
Batch 310, Loss: 0.5262
Batch 320, Loss: 0.5054
Batch 330, Loss: 0.5296
Batch 340, Loss: 0.5235
Batch 350, Loss: 0.5176
Batch 360, Loss: 0.4806
Batch 370, Loss: 0.5385
Batch 380, Loss: 0.4892
Batch 390, Loss: 0.5437
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.010398149490356 seconds
Epoch 158 accuracy: 75.55%
Batch 10, Loss: 0.4556
Batch 20, Loss: 0.5125
Batch 30, Loss: 0.4537
Batch 40, Loss: 0.4663
Batch 50, Loss: 0.4723
Batch 60, Loss: 0.4882
Batch 70, Loss: 0.4847
Batch 80, Loss: 0.5112
Batch 90, Loss: 0.4832
Batch 100, Loss: 0.4441
Batch 110, Loss: 0.5240
Batch 120, Loss: 0.4549
Batch 130, Loss: 0.4338
Batch 140, Loss: 0.4638
Batch 150, Loss: 0.5190
Batch 160, Loss: 0.4984
Batch 170, Loss: 0.5279
Batch 180, Loss: 0.5002
Batch 190, Loss: 0.5151
Batch 200, Loss: 0.4923
Batch 210, Loss: 0.4671
Batch 220, Loss: 0.4977
Batch 230, Loss: 0.5074
Batch 240, Loss: 0.4711
Batch 250, Loss: 0.5175
Batch 260, Loss: 0.4897
Batch 270, Loss: 0.5311
Batch 280, Loss: 0.5077
Batch 290, Loss: 0.4548
Batch 300, Loss: 0.5108
Batch 310, Loss: 0.4894
Batch 320, Loss: 0.5028
Batch 330, Loss: 0.5475
Batch 340, Loss: 0.4744
Batch 350, Loss: 0.5326
Batch 360, Loss: 0.5088
Batch 370, Loss: 0.5257
Batch 380, Loss: 0.5513
Batch 390, Loss: 0.5016
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.04490828514099 seconds
Epoch 159 accuracy: 74.97%
Batch 10, Loss: 0.4823
Batch 20, Loss: 0.4994
Batch 30, Loss: 0.4863
Batch 40, Loss: 0.4711
Batch 50, Loss: 0.4827
Batch 60, Loss: 0.4614
Batch 70, Loss: 0.5305
Batch 80, Loss: 0.4668
Batch 90, Loss: 0.4390
Batch 100, Loss: 0.4697
Batch 110, Loss: 0.4686
Batch 120, Loss: 0.4624
Batch 130, Loss: 0.4880
Batch 140, Loss: 0.4455
Batch 150, Loss: 0.4475
Batch 160, Loss: 0.4673
Batch 170, Loss: 0.4889
Batch 180, Loss: 0.4841
Batch 190, Loss: 0.4998
Batch 200, Loss: 0.4715
Batch 210, Loss: 0.4684
Batch 220, Loss: 0.4310
Batch 230, Loss: 0.4525
Batch 240, Loss: 0.4513
Batch 250, Loss: 0.5222
Batch 260, Loss: 0.4561
Batch 270, Loss: 0.4510
Batch 280, Loss: 0.5108
Batch 290, Loss: 0.4829
Batch 300, Loss: 0.4706
Batch 310, Loss: 0.4525
Batch 320, Loss: 0.4811
Batch 330, Loss: 0.5019
Batch 340, Loss: 0.5011
Batch 350, Loss: 0.5227
Batch 360, Loss: 0.5244
Batch 370, Loss: 0.5095
Batch 380, Loss: 0.4483
Batch 390, Loss: 0.5365
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.158634662628174 seconds
Epoch 160 accuracy: 76.09%
Batch 10, Loss: 0.4408
Batch 20, Loss: 0.5067
Batch 30, Loss: 0.4681
Batch 40, Loss: 0.4265
Batch 50, Loss: 0.4548
Batch 60, Loss: 0.4571
Batch 70, Loss: 0.4818
Batch 80, Loss: 0.4448
Batch 90, Loss: 0.4585
Batch 100, Loss: 0.4162
Batch 110, Loss: 0.4829
Batch 120, Loss: 0.4808
Batch 130, Loss: 0.4333
Batch 140, Loss: 0.4658
Batch 150, Loss: 0.4541
Batch 160, Loss: 0.4774
Batch 170, Loss: 0.4692
Batch 180, Loss: 0.5046
Batch 190, Loss: 0.4669
Batch 200, Loss: 0.4691
Batch 210, Loss: 0.4910
Batch 220, Loss: 0.4833
Batch 230, Loss: 0.4917
Batch 240, Loss: 0.4778
Batch 250, Loss: 0.4605
Batch 260, Loss: 0.4601
Batch 270, Loss: 0.5050
Batch 280, Loss: 0.4698
Batch 290, Loss: 0.5426
Batch 300, Loss: 0.4839
Batch 310, Loss: 0.4953
Batch 320, Loss: 0.4559
Batch 330, Loss: 0.4533
Batch 340, Loss: 0.4826
Batch 350, Loss: 0.4942
Batch 360, Loss: 0.4965
Batch 370, Loss: 0.4769
Batch 380, Loss: 0.4633
Batch 390, Loss: 0.4655
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.052987098693848 seconds
Epoch 161 accuracy: 76.63%
Batch 10, Loss: 0.4078
Batch 20, Loss: 0.4666
Batch 30, Loss: 0.4564
Batch 40, Loss: 0.4353
Batch 50, Loss: 0.4514
Batch 60, Loss: 0.4811
Batch 70, Loss: 0.4569
Batch 80, Loss: 0.4761
Batch 90, Loss: 0.4431
Batch 100, Loss: 0.4053
Batch 110, Loss: 0.4374
Batch 120, Loss: 0.4265
Batch 130, Loss: 0.4790
Batch 140, Loss: 0.4337
Batch 150, Loss: 0.4933
Batch 160, Loss: 0.4394
Batch 170, Loss: 0.4637
Batch 180, Loss: 0.4673
Batch 190, Loss: 0.4745
Batch 200, Loss: 0.5162
Batch 210, Loss: 0.4912
Batch 220, Loss: 0.4738
Batch 230, Loss: 0.4559
Batch 240, Loss: 0.4687
Batch 250, Loss: 0.4481
Batch 260, Loss: 0.4279
Batch 270, Loss: 0.4395
Batch 280, Loss: 0.4344
Batch 290, Loss: 0.4320
Batch 300, Loss: 0.4419
Batch 310, Loss: 0.4989
Batch 320, Loss: 0.4787
Batch 330, Loss: 0.4453
Batch 340, Loss: 0.4796
Batch 350, Loss: 0.4486
Batch 360, Loss: 0.4724
Batch 370, Loss: 0.4911
Batch 380, Loss: 0.4480
Batch 390, Loss: 0.4449
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.07632040977478 seconds
Epoch 162 accuracy: 75.69%
Batch 10, Loss: 0.4264
Batch 20, Loss: 0.4424
Batch 30, Loss: 0.4597
Batch 40, Loss: 0.4345
Batch 50, Loss: 0.4150
Batch 60, Loss: 0.4317
Batch 70, Loss: 0.4111
Batch 80, Loss: 0.4395
Batch 90, Loss: 0.4747
Batch 100, Loss: 0.4453
Batch 110, Loss: 0.4485
Batch 120, Loss: 0.4338
Batch 130, Loss: 0.4249
Batch 140, Loss: 0.4466
Batch 150, Loss: 0.4419
Batch 160, Loss: 0.4656
Batch 170, Loss: 0.4358
Batch 180, Loss: 0.4406
Batch 190, Loss: 0.4648
Batch 200, Loss: 0.4253
Batch 210, Loss: 0.4927
Batch 220, Loss: 0.4436
Batch 230, Loss: 0.4377
Batch 240, Loss: 0.4382
Batch 250, Loss: 0.4848
Batch 260, Loss: 0.4453
Batch 270, Loss: 0.4414
Batch 280, Loss: 0.4267
Batch 290, Loss: 0.4418
Batch 300, Loss: 0.4829
Batch 310, Loss: 0.4260
Batch 320, Loss: 0.4055
Batch 330, Loss: 0.4372
Batch 340, Loss: 0.4285
Batch 350, Loss: 0.4684
Batch 360, Loss: 0.4472
Batch 370, Loss: 0.4543
Batch 380, Loss: 0.4450
Batch 390, Loss: 0.4161
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.13139820098877 seconds
Epoch 163 accuracy: 76.9%
Batch 10, Loss: 0.4217
Batch 20, Loss: 0.4442
Batch 30, Loss: 0.3706
Batch 40, Loss: 0.4530
Batch 50, Loss: 0.3900
Batch 60, Loss: 0.4150
Batch 70, Loss: 0.4136
Batch 80, Loss: 0.4278
Batch 90, Loss: 0.4410
Batch 100, Loss: 0.4239
Batch 110, Loss: 0.4351
Batch 120, Loss: 0.4465
Batch 130, Loss: 0.4075
Batch 140, Loss: 0.4278
Batch 150, Loss: 0.4357
Batch 160, Loss: 0.4146
Batch 170, Loss: 0.4424
Batch 180, Loss: 0.4142
Batch 190, Loss: 0.4379
Batch 200, Loss: 0.4518
Batch 210, Loss: 0.4172
Batch 220, Loss: 0.4371
Batch 230, Loss: 0.4487
Batch 240, Loss: 0.4823
Batch 250, Loss: 0.4299
Batch 260, Loss: 0.4549
Batch 270, Loss: 0.4379
Batch 280, Loss: 0.4452
Batch 290, Loss: 0.4172
Batch 300, Loss: 0.4207
Batch 310, Loss: 0.4267
Batch 320, Loss: 0.4387
Batch 330, Loss: 0.4123
Batch 340, Loss: 0.4762
Batch 350, Loss: 0.4458
Batch 360, Loss: 0.4335
Batch 370, Loss: 0.4446
Batch 380, Loss: 0.4563
Batch 390, Loss: 0.4661
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.058080673217773 seconds
Epoch 164 accuracy: 76.78%
Batch 10, Loss: 0.3867
Batch 20, Loss: 0.4143
Batch 30, Loss: 0.4498
Batch 40, Loss: 0.4134
Batch 50, Loss: 0.4151
Batch 60, Loss: 0.4599
Batch 70, Loss: 0.4184
Batch 80, Loss: 0.3732
Batch 90, Loss: 0.3831
Batch 100, Loss: 0.3972
Batch 110, Loss: 0.3870
Batch 120, Loss: 0.4465
Batch 130, Loss: 0.3943
Batch 140, Loss: 0.4348
Batch 150, Loss: 0.3992
Batch 160, Loss: 0.4320
Batch 170, Loss: 0.3919
Batch 180, Loss: 0.4733
Batch 190, Loss: 0.4116
Batch 200, Loss: 0.4352
Batch 210, Loss: 0.4296
Batch 220, Loss: 0.4389
Batch 230, Loss: 0.4267
Batch 240, Loss: 0.4601
Batch 250, Loss: 0.4065
Batch 260, Loss: 0.4060
Batch 270, Loss: 0.4224
Batch 280, Loss: 0.3774
Batch 290, Loss: 0.4614
Batch 300, Loss: 0.4152
Batch 310, Loss: 0.4322
Batch 320, Loss: 0.4325
Batch 330, Loss: 0.4268
Batch 340, Loss: 0.4123
Batch 350, Loss: 0.4249
Batch 360, Loss: 0.4511
Batch 370, Loss: 0.4444
Batch 380, Loss: 0.4563
Batch 390, Loss: 0.4208
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 24.974032163619995 seconds
Epoch 165 accuracy: 76.75%
Batch 10, Loss: 0.4384
Batch 20, Loss: 0.4133
Batch 30, Loss: 0.3815
Batch 40, Loss: 0.4198
Batch 50, Loss: 0.3930
Batch 60, Loss: 0.3648
Batch 70, Loss: 0.3671
Batch 80, Loss: 0.3989
Batch 90, Loss: 0.4265
Batch 100, Loss: 0.3782
Batch 110, Loss: 0.4202
Batch 120, Loss: 0.3877
Batch 130, Loss: 0.3975
Batch 140, Loss: 0.4242
Batch 150, Loss: 0.4109
Batch 160, Loss: 0.4339
Batch 170, Loss: 0.3795
Batch 180, Loss: 0.4287
Batch 190, Loss: 0.4250
Batch 200, Loss: 0.4392
Batch 210, Loss: 0.3809
Batch 220, Loss: 0.4302
Batch 230, Loss: 0.4484
Batch 240, Loss: 0.4025
Batch 250, Loss: 0.3912
Batch 260, Loss: 0.3644
Batch 270, Loss: 0.4464
Batch 280, Loss: 0.4087
Batch 290, Loss: 0.4189
Batch 300, Loss: 0.4032
Batch 310, Loss: 0.4347
Batch 320, Loss: 0.3906
Batch 330, Loss: 0.4097
Batch 340, Loss: 0.4284
Batch 350, Loss: 0.4168
Batch 360, Loss: 0.4077
Batch 370, Loss: 0.3887
Batch 380, Loss: 0.4404
Batch 390, Loss: 0.4275
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.07680320739746 seconds
Epoch 166 accuracy: 76.74%
Batch 10, Loss: 0.3707
Batch 20, Loss: 0.3801
Batch 30, Loss: 0.3702
Batch 40, Loss: 0.3835
Batch 50, Loss: 0.3898
Batch 60, Loss: 0.3986
Batch 70, Loss: 0.3884
Batch 80, Loss: 0.4327
Batch 90, Loss: 0.4091
Batch 100, Loss: 0.3900
Batch 110, Loss: 0.3886
Batch 120, Loss: 0.3453
Batch 130, Loss: 0.4068
Batch 140, Loss: 0.3638
Batch 150, Loss: 0.4005
Batch 160, Loss: 0.3852
Batch 170, Loss: 0.4154
Batch 180, Loss: 0.3834
Batch 190, Loss: 0.4182
Batch 200, Loss: 0.4217
Batch 210, Loss: 0.3831
Batch 220, Loss: 0.4074
Batch 230, Loss: 0.3671
Batch 240, Loss: 0.4094
Batch 250, Loss: 0.4009
Batch 260, Loss: 0.4102
Batch 270, Loss: 0.3830
Batch 280, Loss: 0.4019
Batch 290, Loss: 0.4103
Batch 300, Loss: 0.4040
Batch 310, Loss: 0.4522
Batch 320, Loss: 0.4336
Batch 330, Loss: 0.3881
Batch 340, Loss: 0.3979
Batch 350, Loss: 0.3949
Batch 360, Loss: 0.4048
Batch 370, Loss: 0.4345
Batch 380, Loss: 0.4291
Batch 390, Loss: 0.3973
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.029950380325317 seconds
Epoch 167 accuracy: 77.14%
Batch 10, Loss: 0.3670
Batch 20, Loss: 0.3827
Batch 30, Loss: 0.3619
Batch 40, Loss: 0.4143
Batch 50, Loss: 0.3969
Batch 60, Loss: 0.3744
Batch 70, Loss: 0.3826
Batch 80, Loss: 0.3756
Batch 90, Loss: 0.3612
Batch 100, Loss: 0.3880
Batch 110, Loss: 0.3978
Batch 120, Loss: 0.3970
Batch 130, Loss: 0.3939
Batch 140, Loss: 0.3817
Batch 150, Loss: 0.3661
Batch 160, Loss: 0.3860
Batch 170, Loss: 0.3812
Batch 180, Loss: 0.4077
Batch 190, Loss: 0.3989
Batch 200, Loss: 0.3694
Batch 210, Loss: 0.3805
Batch 220, Loss: 0.3675
Batch 230, Loss: 0.4309
Batch 240, Loss: 0.4261
Batch 250, Loss: 0.4273
Batch 260, Loss: 0.3870
Batch 270, Loss: 0.4346
Batch 280, Loss: 0.4243
Batch 290, Loss: 0.3866
Batch 300, Loss: 0.3781
Batch 310, Loss: 0.4174
Batch 320, Loss: 0.4075
Batch 330, Loss: 0.3883
Batch 340, Loss: 0.4228
Batch 350, Loss: 0.4018
Batch 360, Loss: 0.4221
Batch 370, Loss: 0.4072
Batch 380, Loss: 0.4135
Batch 390, Loss: 0.4025
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.08362889289856 seconds
Epoch 168 accuracy: 77.49%
Batch 10, Loss: 0.4086
Batch 20, Loss: 0.3534
Batch 30, Loss: 0.3781
Batch 40, Loss: 0.3962
Batch 50, Loss: 0.3699
Batch 60, Loss: 0.3446
Batch 70, Loss: 0.3627
Batch 80, Loss: 0.3864
Batch 90, Loss: 0.3800
Batch 100, Loss: 0.3815
Batch 110, Loss: 0.3655
Batch 120, Loss: 0.3908
Batch 130, Loss: 0.4015
Batch 140, Loss: 0.3524
Batch 150, Loss: 0.3716
Batch 160, Loss: 0.3666
Batch 170, Loss: 0.4080
Batch 180, Loss: 0.3963
Batch 190, Loss: 0.3687
Batch 200, Loss: 0.3779
Batch 210, Loss: 0.3819
Batch 220, Loss: 0.3603
Batch 230, Loss: 0.3896
Batch 240, Loss: 0.3939
Batch 250, Loss: 0.3868
Batch 260, Loss: 0.3906
Batch 270, Loss: 0.3918
Batch 280, Loss: 0.4077
Batch 290, Loss: 0.3912
Batch 300, Loss: 0.4223
Batch 310, Loss: 0.3858
Batch 320, Loss: 0.3854
Batch 330, Loss: 0.3694
Batch 340, Loss: 0.3757
Batch 350, Loss: 0.4257
Batch 360, Loss: 0.3800
Batch 370, Loss: 0.3924
Batch 380, Loss: 0.3471
Batch 390, Loss: 0.4169
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.06419348716736 seconds
Epoch 169 accuracy: 77.67%
Batch 10, Loss: 0.4017
Batch 20, Loss: 0.3905
Batch 30, Loss: 0.3727
Batch 40, Loss: 0.3770
Batch 50, Loss: 0.3198
Batch 60, Loss: 0.3713
Batch 70, Loss: 0.3896
Batch 80, Loss: 0.4059
Batch 90, Loss: 0.3929
Batch 100, Loss: 0.3716
Batch 110, Loss: 0.3655
Batch 120, Loss: 0.4205
Batch 130, Loss: 0.3881
Batch 140, Loss: 0.3777
Batch 150, Loss: 0.4018
Batch 160, Loss: 0.3869
Batch 170, Loss: 0.3948
Batch 180, Loss: 0.3610
Batch 190, Loss: 0.4028
Batch 200, Loss: 0.3751
Batch 210, Loss: 0.3745
Batch 220, Loss: 0.3725
Batch 230, Loss: 0.3384
Batch 240, Loss: 0.3667
Batch 250, Loss: 0.3706
Batch 260, Loss: 0.4079
Batch 270, Loss: 0.3626
Batch 280, Loss: 0.3791
Batch 290, Loss: 0.3670
Batch 300, Loss: 0.3311
Batch 310, Loss: 0.3519
Batch 320, Loss: 0.3846
Batch 330, Loss: 0.3342
Batch 340, Loss: 0.3848
Batch 350, Loss: 0.3963
Batch 360, Loss: 0.3678
Batch 370, Loss: 0.4223
Batch 380, Loss: 0.3484
Batch 390, Loss: 0.3852
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.050227880477905 seconds
Epoch 170 accuracy: 77.46%
Batch 10, Loss: 0.3580
Batch 20, Loss: 0.4017
Batch 30, Loss: 0.3391
Batch 40, Loss: 0.3527
Batch 50, Loss: 0.3761
Batch 60, Loss: 0.3821
Batch 70, Loss: 0.3581
Batch 80, Loss: 0.3410
Batch 90, Loss: 0.3670
Batch 100, Loss: 0.3775
Batch 110, Loss: 0.3516
Batch 120, Loss: 0.3498
Batch 130, Loss: 0.3713
Batch 140, Loss: 0.3612
Batch 150, Loss: 0.3453
Batch 160, Loss: 0.3577
Batch 170, Loss: 0.3670
Batch 180, Loss: 0.3305
Batch 190, Loss: 0.3713
Batch 200, Loss: 0.3425
Batch 210, Loss: 0.3690
Batch 220, Loss: 0.3815
Batch 230, Loss: 0.3692
Batch 240, Loss: 0.3552
Batch 250, Loss: 0.3736
Batch 260, Loss: 0.3490
Batch 270, Loss: 0.3634
Batch 280, Loss: 0.3545
Batch 290, Loss: 0.3675
Batch 300, Loss: 0.3663
Batch 310, Loss: 0.3520
Batch 320, Loss: 0.3576
Batch 330, Loss: 0.3490
Batch 340, Loss: 0.3816
Batch 350, Loss: 0.3996
Batch 360, Loss: 0.3683
Batch 370, Loss: 0.3752
Batch 380, Loss: 0.3743
Batch 390, Loss: 0.3473
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.024255514144897 seconds
Epoch 171 accuracy: 77.56%
Batch 10, Loss: 0.3299
Batch 20, Loss: 0.3458
Batch 30, Loss: 0.3208
Batch 40, Loss: 0.3101
Batch 50, Loss: 0.3601
Batch 60, Loss: 0.3102
Batch 70, Loss: 0.3313
Batch 80, Loss: 0.3347
Batch 90, Loss: 0.3729
Batch 100, Loss: 0.3465
Batch 110, Loss: 0.3452
Batch 120, Loss: 0.3617
Batch 130, Loss: 0.3130
Batch 140, Loss: 0.3284
Batch 150, Loss: 0.3104
Batch 160, Loss: 0.3081
Batch 170, Loss: 0.3276
Batch 180, Loss: 0.3432
Batch 190, Loss: 0.3410
Batch 200, Loss: 0.3555
Batch 210, Loss: 0.3645
Batch 220, Loss: 0.2881
Batch 230, Loss: 0.3676
Batch 240, Loss: 0.3585
Batch 250, Loss: 0.3344
Batch 260, Loss: 0.3571
Batch 270, Loss: 0.3337
Batch 280, Loss: 0.3487
Batch 290, Loss: 0.3595
Batch 300, Loss: 0.3561
Batch 310, Loss: 0.3643
Batch 320, Loss: 0.3816
Batch 330, Loss: 0.3348
Batch 340, Loss: 0.3354
Batch 350, Loss: 0.3603
Batch 360, Loss: 0.3449
Batch 370, Loss: 0.3354
Batch 380, Loss: 0.3476
Batch 390, Loss: 0.3612
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.037294149398804 seconds
Epoch 172 accuracy: 78.14%
Batch 10, Loss: 0.3378
Batch 20, Loss: 0.3570
Batch 30, Loss: 0.3456
Batch 40, Loss: 0.3332
Batch 50, Loss: 0.3163
Batch 60, Loss: 0.3409
Batch 70, Loss: 0.3328
Batch 80, Loss: 0.3163
Batch 90, Loss: 0.3542
Batch 100, Loss: 0.3349
Batch 110, Loss: 0.2949
Batch 120, Loss: 0.3998
Batch 130, Loss: 0.3668
Batch 140, Loss: 0.3230
Batch 150, Loss: 0.3788
Batch 160, Loss: 0.3292
Batch 170, Loss: 0.3291
Batch 180, Loss: 0.3398
Batch 190, Loss: 0.3408
Batch 200, Loss: 0.3542
Batch 210, Loss: 0.3218
Batch 220, Loss: 0.3252
Batch 230, Loss: 0.3486
Batch 240, Loss: 0.3228
Batch 250, Loss: 0.3262
Batch 260, Loss: 0.3183
Batch 270, Loss: 0.3642
Batch 280, Loss: 0.3572
Batch 290, Loss: 0.3432
Batch 300, Loss: 0.3431
Batch 310, Loss: 0.3823
Batch 320, Loss: 0.3627
Batch 330, Loss: 0.3484
Batch 340, Loss: 0.3380
Batch 350, Loss: 0.3351
Batch 360, Loss: 0.3629
Batch 370, Loss: 0.3440
Batch 380, Loss: 0.3288
Batch 390, Loss: 0.3721
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.064013957977295 seconds
Epoch 173 accuracy: 78.18%
Batch 10, Loss: 0.3328
Batch 20, Loss: 0.3453
Batch 30, Loss: 0.3365
Batch 40, Loss: 0.3573
Batch 50, Loss: 0.3402
Batch 60, Loss: 0.3684
Batch 70, Loss: 0.3139
Batch 80, Loss: 0.3484
Batch 90, Loss: 0.3486
Batch 100, Loss: 0.3256
Batch 110, Loss: 0.3430
Batch 120, Loss: 0.3765
Batch 130, Loss: 0.3455
Batch 140, Loss: 0.3374
Batch 150, Loss: 0.3236
Batch 160, Loss: 0.3358
Batch 170, Loss: 0.3554
Batch 180, Loss: 0.3353
Batch 190, Loss: 0.2791
Batch 200, Loss: 0.3619
Batch 210, Loss: 0.3003
Batch 220, Loss: 0.3407
Batch 230, Loss: 0.3267
Batch 240, Loss: 0.3589
Batch 250, Loss: 0.3309
Batch 260, Loss: 0.3406
Batch 270, Loss: 0.3694
Batch 280, Loss: 0.3404
Batch 290, Loss: 0.3313
Batch 300, Loss: 0.3007
Batch 310, Loss: 0.3257
Batch 320, Loss: 0.3548
Batch 330, Loss: 0.3075
Batch 340, Loss: 0.3747
Batch 350, Loss: 0.3303
Batch 360, Loss: 0.3168
Batch 370, Loss: 0.3409
Batch 380, Loss: 0.3284
Batch 390, Loss: 0.3235
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.056784868240356 seconds
Epoch 174 accuracy: 78.24%
Batch 10, Loss: 0.3251
Batch 20, Loss: 0.3036
Batch 30, Loss: 0.3333
Batch 40, Loss: 0.3089
Batch 50, Loss: 0.3566
Batch 60, Loss: 0.3109
Batch 70, Loss: 0.3069
Batch 80, Loss: 0.3174
Batch 90, Loss: 0.3089
Batch 100, Loss: 0.3288
Batch 110, Loss: 0.3082
Batch 120, Loss: 0.3240
Batch 130, Loss: 0.3274
Batch 140, Loss: 0.3012
Batch 150, Loss: 0.3075
Batch 160, Loss: 0.3400
Batch 170, Loss: 0.3244
Batch 180, Loss: 0.3412
Batch 190, Loss: 0.3461
Batch 200, Loss: 0.3431
Batch 210, Loss: 0.2944
Batch 220, Loss: 0.3270
Batch 230, Loss: 0.3530
Batch 240, Loss: 0.3296
Batch 250, Loss: 0.3529
Batch 260, Loss: 0.3341
Batch 270, Loss: 0.3232
Batch 280, Loss: 0.3107
Batch 290, Loss: 0.3190
Batch 300, Loss: 0.3626
Batch 310, Loss: 0.3091
Batch 320, Loss: 0.3430
Batch 330, Loss: 0.3342
Batch 340, Loss: 0.3369
Batch 350, Loss: 0.2890
Batch 360, Loss: 0.3214
Batch 370, Loss: 0.3024
Batch 380, Loss: 0.3098
Batch 390, Loss: 0.3241
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.102498531341553 seconds
Epoch 175 accuracy: 78.37%
Batch 10, Loss: 0.3160
Batch 20, Loss: 0.3305
Batch 30, Loss: 0.3353
Batch 40, Loss: 0.3300
Batch 50, Loss: 0.3326
Batch 60, Loss: 0.3036
Batch 70, Loss: 0.3202
Batch 80, Loss: 0.3055
Batch 90, Loss: 0.3140
Batch 100, Loss: 0.3100
Batch 110, Loss: 0.3019
Batch 120, Loss: 0.2825
Batch 130, Loss: 0.3539
Batch 140, Loss: 0.3033
Batch 150, Loss: 0.3252
Batch 160, Loss: 0.3210
Batch 170, Loss: 0.3021
Batch 180, Loss: 0.3054
Batch 190, Loss: 0.3588
Batch 200, Loss: 0.3152
Batch 210, Loss: 0.3232
Batch 220, Loss: 0.3123
Batch 230, Loss: 0.3334
Batch 240, Loss: 0.3214
Batch 250, Loss: 0.3038
Batch 260, Loss: 0.3070
Batch 270, Loss: 0.3266
Batch 280, Loss: 0.3030
Batch 290, Loss: 0.3100
Batch 300, Loss: 0.3255
Batch 310, Loss: 0.2944
Batch 320, Loss: 0.3236
Batch 330, Loss: 0.3093
Batch 340, Loss: 0.3053
Batch 350, Loss: 0.3000
Batch 360, Loss: 0.3196
Batch 370, Loss: 0.3387
Batch 380, Loss: 0.3418
Batch 390, Loss: 0.3438
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.128133058547974 seconds
Epoch 176 accuracy: 78.3%
Batch 10, Loss: 0.3137
Batch 20, Loss: 0.3578
Batch 30, Loss: 0.3013
Batch 40, Loss: 0.3265
Batch 50, Loss: 0.3349
Batch 60, Loss: 0.2912
Batch 70, Loss: 0.3092
Batch 80, Loss: 0.3167
Batch 90, Loss: 0.3117
Batch 100, Loss: 0.3278
Batch 110, Loss: 0.3074
Batch 120, Loss: 0.3209
Batch 130, Loss: 0.3122
Batch 140, Loss: 0.3146
Batch 150, Loss: 0.2849
Batch 160, Loss: 0.2872
Batch 170, Loss: 0.3019
Batch 180, Loss: 0.3401
Batch 190, Loss: 0.3325
Batch 200, Loss: 0.2916
Batch 210, Loss: 0.3168
Batch 220, Loss: 0.2815
Batch 230, Loss: 0.3129
Batch 240, Loss: 0.3311
Batch 250, Loss: 0.3414
Batch 260, Loss: 0.3008
Batch 270, Loss: 0.2800
Batch 280, Loss: 0.3118
Batch 290, Loss: 0.3070
Batch 300, Loss: 0.3326
Batch 310, Loss: 0.3146
Batch 320, Loss: 0.3160
Batch 330, Loss: 0.3225
Batch 340, Loss: 0.3207
Batch 350, Loss: 0.3082
Batch 360, Loss: 0.3510
Batch 370, Loss: 0.3222
Batch 380, Loss: 0.3292
Batch 390, Loss: 0.3333
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.11102795600891 seconds
Epoch 177 accuracy: 78.67%
Batch 10, Loss: 0.2952
Batch 20, Loss: 0.3097
Batch 30, Loss: 0.2941
Batch 40, Loss: 0.2896
Batch 50, Loss: 0.3029
Batch 60, Loss: 0.3172
Batch 70, Loss: 0.2936
Batch 80, Loss: 0.2985
Batch 90, Loss: 0.3175
Batch 100, Loss: 0.2891
Batch 110, Loss: 0.2694
Batch 120, Loss: 0.2749
Batch 130, Loss: 0.3369
Batch 140, Loss: 0.3181
Batch 150, Loss: 0.3108
Batch 160, Loss: 0.3440
Batch 170, Loss: 0.3174
Batch 180, Loss: 0.2957
Batch 190, Loss: 0.2781
Batch 200, Loss: 0.3088
Batch 210, Loss: 0.2977
Batch 220, Loss: 0.2952
Batch 230, Loss: 0.3177
Batch 240, Loss: 0.2856
Batch 250, Loss: 0.3307
Batch 260, Loss: 0.2754
Batch 270, Loss: 0.3127
Batch 280, Loss: 0.3032
Batch 290, Loss: 0.2888
Batch 300, Loss: 0.2701
Batch 310, Loss: 0.2972
Batch 320, Loss: 0.3247
Batch 330, Loss: 0.3046
Batch 340, Loss: 0.2774
Batch 350, Loss: 0.3018
Batch 360, Loss: 0.3229
Batch 370, Loss: 0.2953
Batch 380, Loss: 0.3080
Batch 390, Loss: 0.3184
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.08324956893921 seconds
Epoch 178 accuracy: 78.84%
Batch 10, Loss: 0.2881
Batch 20, Loss: 0.3013
Batch 30, Loss: 0.3126
Batch 40, Loss: 0.2928
Batch 50, Loss: 0.2613
Batch 60, Loss: 0.3084
Batch 70, Loss: 0.2973
Batch 80, Loss: 0.2901
Batch 90, Loss: 0.2790
Batch 100, Loss: 0.2874
Batch 110, Loss: 0.2909
Batch 120, Loss: 0.2860
Batch 130, Loss: 0.3083
Batch 140, Loss: 0.3312
Batch 150, Loss: 0.2388
Batch 160, Loss: 0.3093
Batch 170, Loss: 0.2866
Batch 180, Loss: 0.3176
Batch 190, Loss: 0.2640
Batch 200, Loss: 0.3414
Batch 210, Loss: 0.3108
Batch 220, Loss: 0.2982
Batch 230, Loss: 0.3045
Batch 240, Loss: 0.3016
Batch 250, Loss: 0.3089
Batch 260, Loss: 0.3085
Batch 270, Loss: 0.2625
Batch 280, Loss: 0.3088
Batch 290, Loss: 0.2925
Batch 300, Loss: 0.3169
Batch 310, Loss: 0.3089
Batch 320, Loss: 0.2736
Batch 330, Loss: 0.2935
Batch 340, Loss: 0.2718
Batch 350, Loss: 0.2849
Batch 360, Loss: 0.3090
Batch 370, Loss: 0.3362
Batch 380, Loss: 0.2925
Batch 390, Loss: 0.2769
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.015546798706055 seconds
Epoch 179 accuracy: 78.41%
Batch 10, Loss: 0.2634
Batch 20, Loss: 0.2840
Batch 30, Loss: 0.3235
Batch 40, Loss: 0.2899
Batch 50, Loss: 0.2900
Batch 60, Loss: 0.2806
Batch 70, Loss: 0.2847
Batch 80, Loss: 0.3043
Batch 90, Loss: 0.3235
Batch 100, Loss: 0.3129
Batch 110, Loss: 0.2710
Batch 120, Loss: 0.3192
Batch 130, Loss: 0.3151
Batch 140, Loss: 0.2708
Batch 150, Loss: 0.2988
Batch 160, Loss: 0.2928
Batch 170, Loss: 0.2585
Batch 180, Loss: 0.2860
Batch 190, Loss: 0.3091
Batch 200, Loss: 0.2717
Batch 210, Loss: 0.3260
Batch 220, Loss: 0.2895
Batch 230, Loss: 0.3270
Batch 240, Loss: 0.3066
Batch 250, Loss: 0.2574
Batch 260, Loss: 0.3087
Batch 270, Loss: 0.2943
Batch 280, Loss: 0.3156
Batch 290, Loss: 0.2991
Batch 300, Loss: 0.3440
Batch 310, Loss: 0.2876
Batch 320, Loss: 0.2894
Batch 330, Loss: 0.3038
Batch 340, Loss: 0.3201
Batch 350, Loss: 0.3300
Batch 360, Loss: 0.3064
Batch 370, Loss: 0.2569
Batch 380, Loss: 0.2833
Batch 390, Loss: 0.2926
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.102590084075928 seconds
Epoch 180 accuracy: 78.86%
Batch 10, Loss: 0.3044
Batch 20, Loss: 0.2887
Batch 30, Loss: 0.2950
Batch 40, Loss: 0.2842
Batch 50, Loss: 0.2537
Batch 60, Loss: 0.2837
Batch 70, Loss: 0.3030
Batch 80, Loss: 0.2614
Batch 90, Loss: 0.3104
Batch 100, Loss: 0.2977
Batch 110, Loss: 0.2689
Batch 120, Loss: 0.2616
Batch 130, Loss: 0.2861
Batch 140, Loss: 0.2614
Batch 150, Loss: 0.3114
Batch 160, Loss: 0.2789
Batch 170, Loss: 0.2859
Batch 180, Loss: 0.2983
Batch 190, Loss: 0.2836
Batch 200, Loss: 0.2788
Batch 210, Loss: 0.2808
Batch 220, Loss: 0.2591
Batch 230, Loss: 0.3199
Batch 240, Loss: 0.2913
Batch 250, Loss: 0.2955
Batch 260, Loss: 0.2913
Batch 270, Loss: 0.3073
Batch 280, Loss: 0.2989
Batch 290, Loss: 0.2829
Batch 300, Loss: 0.2836
Batch 310, Loss: 0.2894
Batch 320, Loss: 0.2598
Batch 330, Loss: 0.2991
Batch 340, Loss: 0.3099
Batch 350, Loss: 0.3214
Batch 360, Loss: 0.2575
Batch 370, Loss: 0.2754
Batch 380, Loss: 0.2937
Batch 390, Loss: 0.2774
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.045507669448853 seconds
Epoch 181 accuracy: 78.97%
Batch 10, Loss: 0.2932
Batch 20, Loss: 0.2604
Batch 30, Loss: 0.3058
Batch 40, Loss: 0.2736
Batch 50, Loss: 0.2951
Batch 60, Loss: 0.2722
Batch 70, Loss: 0.2775
Batch 80, Loss: 0.2933
Batch 90, Loss: 0.2567
Batch 100, Loss: 0.2637
Batch 110, Loss: 0.2812
Batch 120, Loss: 0.2883
Batch 130, Loss: 0.2853
Batch 140, Loss: 0.2871
Batch 150, Loss: 0.2992
Batch 160, Loss: 0.2995
Batch 170, Loss: 0.2562
Batch 180, Loss: 0.2820
Batch 190, Loss: 0.2973
Batch 200, Loss: 0.2925
Batch 210, Loss: 0.2759
Batch 220, Loss: 0.2565
Batch 230, Loss: 0.2810
Batch 240, Loss: 0.3025
Batch 250, Loss: 0.2685
Batch 260, Loss: 0.3086
Batch 270, Loss: 0.2841
Batch 280, Loss: 0.2631
Batch 290, Loss: 0.3315
Batch 300, Loss: 0.2771
Batch 310, Loss: 0.2950
Batch 320, Loss: 0.2868
Batch 330, Loss: 0.3524
Batch 340, Loss: 0.2950
Batch 350, Loss: 0.3001
Batch 360, Loss: 0.2873
Batch 370, Loss: 0.3038
Batch 380, Loss: 0.3026
Batch 390, Loss: 0.2521
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.03498411178589 seconds
Epoch 182 accuracy: 79.04%
Batch 10, Loss: 0.2499
Batch 20, Loss: 0.2701
Batch 30, Loss: 0.2723
Batch 40, Loss: 0.2501
Batch 50, Loss: 0.2777
Batch 60, Loss: 0.2685
Batch 70, Loss: 0.2860
Batch 80, Loss: 0.2456
Batch 90, Loss: 0.2784
Batch 100, Loss: 0.3002
Batch 110, Loss: 0.2604
Batch 120, Loss: 0.2940
Batch 130, Loss: 0.2717
Batch 140, Loss: 0.2645
Batch 150, Loss: 0.2913
Batch 160, Loss: 0.2518
Batch 170, Loss: 0.2644
Batch 180, Loss: 0.2490
Batch 190, Loss: 0.3020
Batch 200, Loss: 0.2986
Batch 210, Loss: 0.2440
Batch 220, Loss: 0.2947
Batch 230, Loss: 0.2937
Batch 240, Loss: 0.2705
Batch 250, Loss: 0.2976
Batch 260, Loss: 0.3023
Batch 270, Loss: 0.2866
Batch 280, Loss: 0.2964
Batch 290, Loss: 0.3090
Batch 300, Loss: 0.2425
Batch 310, Loss: 0.2721
Batch 320, Loss: 0.2934
Batch 330, Loss: 0.2903
Batch 340, Loss: 0.2636
Batch 350, Loss: 0.3079
Batch 360, Loss: 0.2667
Batch 370, Loss: 0.2987
Batch 380, Loss: 0.2842
Batch 390, Loss: 0.2644
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.0480899810791 seconds
Epoch 183 accuracy: 78.88%
Batch 10, Loss: 0.2806
Batch 20, Loss: 0.2816
Batch 30, Loss: 0.3030
Batch 40, Loss: 0.2887
Batch 50, Loss: 0.2281
Batch 60, Loss: 0.2816
Batch 70, Loss: 0.2790
Batch 80, Loss: 0.2706
Batch 90, Loss: 0.2628
Batch 100, Loss: 0.2706
Batch 110, Loss: 0.2443
Batch 120, Loss: 0.2829
Batch 130, Loss: 0.2452
Batch 140, Loss: 0.2919
Batch 150, Loss: 0.2519
Batch 160, Loss: 0.2683
Batch 170, Loss: 0.2857
Batch 180, Loss: 0.2547
Batch 190, Loss: 0.2680
Batch 200, Loss: 0.2415
Batch 210, Loss: 0.2530
Batch 220, Loss: 0.3116
Batch 230, Loss: 0.2738
Batch 240, Loss: 0.2401
Batch 250, Loss: 0.3075
Batch 260, Loss: 0.3132
Batch 270, Loss: 0.2831
Batch 280, Loss: 0.2811
Batch 290, Loss: 0.2530
Batch 300, Loss: 0.3123
Batch 310, Loss: 0.2773
Batch 320, Loss: 0.2609
Batch 330, Loss: 0.2730
Batch 340, Loss: 0.2757
Batch 350, Loss: 0.3013
Batch 360, Loss: 0.2602
Batch 370, Loss: 0.2838
Batch 380, Loss: 0.2693
Batch 390, Loss: 0.2749
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.11761498451233 seconds
Epoch 184 accuracy: 79.2%
Batch 10, Loss: 0.2951
Batch 20, Loss: 0.2693
Batch 30, Loss: 0.2909
Batch 40, Loss: 0.2682
Batch 50, Loss: 0.2394
Batch 60, Loss: 0.2331
Batch 70, Loss: 0.2533
Batch 80, Loss: 0.2613
Batch 90, Loss: 0.2767
Batch 100, Loss: 0.3132
Batch 110, Loss: 0.2517
Batch 120, Loss: 0.2525
Batch 130, Loss: 0.2486
Batch 140, Loss: 0.2763
Batch 150, Loss: 0.2850
Batch 160, Loss: 0.2515
Batch 170, Loss: 0.2390
Batch 180, Loss: 0.2496
Batch 190, Loss: 0.2838
Batch 200, Loss: 0.2656
Batch 210, Loss: 0.2593
Batch 220, Loss: 0.2693
Batch 230, Loss: 0.2570
Batch 240, Loss: 0.2593
Batch 250, Loss: 0.2718
Batch 260, Loss: 0.2773
Batch 270, Loss: 0.2882
Batch 280, Loss: 0.2449
Batch 290, Loss: 0.2885
Batch 300, Loss: 0.3060
Batch 310, Loss: 0.2586
Batch 320, Loss: 0.2410
Batch 330, Loss: 0.2698
Batch 340, Loss: 0.2928
Batch 350, Loss: 0.2919
Batch 360, Loss: 0.2822
Batch 370, Loss: 0.2668
Batch 380, Loss: 0.2760
Batch 390, Loss: 0.2793
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.09720468521118 seconds
Epoch 185 accuracy: 79.65%
Batch 10, Loss: 0.2486
Batch 20, Loss: 0.2503
Batch 30, Loss: 0.2773
Batch 40, Loss: 0.2595
Batch 50, Loss: 0.2590
Batch 60, Loss: 0.2632
Batch 70, Loss: 0.2356
Batch 80, Loss: 0.2746
Batch 90, Loss: 0.2704
Batch 100, Loss: 0.2858
Batch 110, Loss: 0.2511
Batch 120, Loss: 0.2515
Batch 130, Loss: 0.2591
Batch 140, Loss: 0.2359
Batch 150, Loss: 0.2420
Batch 160, Loss: 0.2535
Batch 170, Loss: 0.2373
Batch 180, Loss: 0.2701
Batch 190, Loss: 0.2774
Batch 200, Loss: 0.2634
Batch 210, Loss: 0.2514
Batch 220, Loss: 0.2703
Batch 230, Loss: 0.2674
Batch 240, Loss: 0.2947
Batch 250, Loss: 0.2465
Batch 260, Loss: 0.2396
Batch 270, Loss: 0.2491
Batch 280, Loss: 0.2805
Batch 290, Loss: 0.2890
Batch 300, Loss: 0.2405
Batch 310, Loss: 0.2759
Batch 320, Loss: 0.2491
Batch 330, Loss: 0.2860
Batch 340, Loss: 0.2370
Batch 350, Loss: 0.2598
Batch 360, Loss: 0.2784
Batch 370, Loss: 0.2588
Batch 380, Loss: 0.2638
Batch 390, Loss: 0.2812
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.104777097702026 seconds
Epoch 186 accuracy: 79.58%
Batch 10, Loss: 0.2732
Batch 20, Loss: 0.2791
Batch 30, Loss: 0.2347
Batch 40, Loss: 0.2425
Batch 50, Loss: 0.2611
Batch 60, Loss: 0.2891
Batch 70, Loss: 0.2539
Batch 80, Loss: 0.2699
Batch 90, Loss: 0.2666
Batch 100, Loss: 0.2605
Batch 110, Loss: 0.2710
Batch 120, Loss: 0.2591
Batch 130, Loss: 0.2533
Batch 140, Loss: 0.2707
Batch 150, Loss: 0.2737
Batch 160, Loss: 0.2449
Batch 170, Loss: 0.2842
Batch 180, Loss: 0.2233
Batch 190, Loss: 0.2975
Batch 200, Loss: 0.2704
Batch 210, Loss: 0.2237
Batch 220, Loss: 0.2600
Batch 230, Loss: 0.2341
Batch 240, Loss: 0.2318
Batch 250, Loss: 0.2408
Batch 260, Loss: 0.2453
Batch 270, Loss: 0.2639
Batch 280, Loss: 0.2919
Batch 290, Loss: 0.2845
Batch 300, Loss: 0.2406
Batch 310, Loss: 0.2687
Batch 320, Loss: 0.2693
Batch 330, Loss: 0.2883
Batch 340, Loss: 0.2423
Batch 350, Loss: 0.2386
Batch 360, Loss: 0.2723
Batch 370, Loss: 0.2756
Batch 380, Loss: 0.2755
Batch 390, Loss: 0.2515
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.10955262184143 seconds
Epoch 187 accuracy: 79.69%
Batch 10, Loss: 0.2504
Batch 20, Loss: 0.2024
Batch 30, Loss: 0.2905
Batch 40, Loss: 0.2399
Batch 50, Loss: 0.2746
Batch 60, Loss: 0.2804
Batch 70, Loss: 0.2691
Batch 80, Loss: 0.2059
Batch 90, Loss: 0.2540
Batch 100, Loss: 0.2475
Batch 110, Loss: 0.2468
Batch 120, Loss: 0.2714
Batch 130, Loss: 0.2564
Batch 140, Loss: 0.2770
Batch 150, Loss: 0.2785
Batch 160, Loss: 0.2790
Batch 170, Loss: 0.2667
Batch 180, Loss: 0.2457
Batch 190, Loss: 0.2474
Batch 200, Loss: 0.2439
Batch 210, Loss: 0.2552
Batch 220, Loss: 0.2638
Batch 230, Loss: 0.2507
Batch 240, Loss: 0.2732
Batch 250, Loss: 0.2124
Batch 260, Loss: 0.2482
Batch 270, Loss: 0.2718
Batch 280, Loss: 0.2580
Batch 290, Loss: 0.2340
Batch 300, Loss: 0.2476
Batch 310, Loss: 0.2628
Batch 320, Loss: 0.2710
Batch 330, Loss: 0.2481
Batch 340, Loss: 0.2437
Batch 350, Loss: 0.2415
Batch 360, Loss: 0.2355
Batch 370, Loss: 0.2369
Batch 380, Loss: 0.2455
Batch 390, Loss: 0.2514
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.106019258499146 seconds
Epoch 188 accuracy: 79.72%
Batch 10, Loss: 0.2421
Batch 20, Loss: 0.2686
Batch 30, Loss: 0.2348
Batch 40, Loss: 0.2503
Batch 50, Loss: 0.2747
Batch 60, Loss: 0.2867
Batch 70, Loss: 0.2360
Batch 80, Loss: 0.2603
Batch 90, Loss: 0.2232
Batch 100, Loss: 0.2195
Batch 110, Loss: 0.2151
Batch 120, Loss: 0.2427
Batch 130, Loss: 0.2278
Batch 140, Loss: 0.2480
Batch 150, Loss: 0.2716
Batch 160, Loss: 0.2121
Batch 170, Loss: 0.2599
Batch 180, Loss: 0.2624
Batch 190, Loss: 0.2659
Batch 200, Loss: 0.2847
Batch 210, Loss: 0.2762
Batch 220, Loss: 0.2289
Batch 230, Loss: 0.2490
Batch 240, Loss: 0.3060
Batch 250, Loss: 0.2882
Batch 260, Loss: 0.2468
Batch 270, Loss: 0.2657
Batch 280, Loss: 0.2648
Batch 290, Loss: 0.2761
Batch 300, Loss: 0.2707
Batch 310, Loss: 0.2349
Batch 320, Loss: 0.2475
Batch 330, Loss: 0.2500
Batch 340, Loss: 0.2670
Batch 350, Loss: 0.2430
Batch 360, Loss: 0.2428
Batch 370, Loss: 0.2284
Batch 380, Loss: 0.2433
Batch 390, Loss: 0.2738
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.084956884384155 seconds
Epoch 189 accuracy: 79.86%
Batch 10, Loss: 0.2747
Batch 20, Loss: 0.2757
Batch 30, Loss: 0.2355
Batch 40, Loss: 0.2325
Batch 50, Loss: 0.2392
Batch 60, Loss: 0.2295
Batch 70, Loss: 0.2694
Batch 80, Loss: 0.2539
Batch 90, Loss: 0.2481
Batch 100, Loss: 0.2515
Batch 110, Loss: 0.2479
Batch 120, Loss: 0.2577
Batch 130, Loss: 0.2493
Batch 140, Loss: 0.2581
Batch 150, Loss: 0.2292
Batch 160, Loss: 0.2532
Batch 170, Loss: 0.2237
Batch 180, Loss: 0.2519
Batch 190, Loss: 0.2586
Batch 200, Loss: 0.2271
Batch 210, Loss: 0.2566
Batch 220, Loss: 0.2465
Batch 230, Loss: 0.2554
Batch 240, Loss: 0.2750
Batch 250, Loss: 0.2626
Batch 260, Loss: 0.2247
Batch 270, Loss: 0.2686
Batch 280, Loss: 0.2303
Batch 290, Loss: 0.2652
Batch 300, Loss: 0.2403
Batch 310, Loss: 0.2235
Batch 320, Loss: 0.2253
Batch 330, Loss: 0.2466
Batch 340, Loss: 0.2626
Batch 350, Loss: 0.2270
Batch 360, Loss: 0.2195
Batch 370, Loss: 0.2478
Batch 380, Loss: 0.2356
Batch 390, Loss: 0.2389
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.05612564086914 seconds
Epoch 190 accuracy: 79.81%
Batch 10, Loss: 0.2574
Batch 20, Loss: 0.2761
Batch 30, Loss: 0.2541
Batch 40, Loss: 0.2462
Batch 50, Loss: 0.2293
Batch 60, Loss: 0.2401
Batch 70, Loss: 0.2621
Batch 80, Loss: 0.2733
Batch 90, Loss: 0.2426
Batch 100, Loss: 0.2173
Batch 110, Loss: 0.2342
Batch 120, Loss: 0.2413
Batch 130, Loss: 0.2581
Batch 140, Loss: 0.2421
Batch 150, Loss: 0.2417
Batch 160, Loss: 0.2483
Batch 170, Loss: 0.2791
Batch 180, Loss: 0.2488
Batch 190, Loss: 0.2469
Batch 200, Loss: 0.2303
Batch 210, Loss: 0.2425
Batch 220, Loss: 0.2763
Batch 230, Loss: 0.2615
Batch 240, Loss: 0.2428
Batch 250, Loss: 0.2389
Batch 260, Loss: 0.2363
Batch 270, Loss: 0.2963
Batch 280, Loss: 0.2580
Batch 290, Loss: 0.2285
Batch 300, Loss: 0.2623
Batch 310, Loss: 0.2497
Batch 320, Loss: 0.2403
Batch 330, Loss: 0.2385
Batch 340, Loss: 0.2522
Batch 350, Loss: 0.2056
Batch 360, Loss: 0.2710
Batch 370, Loss: 0.2610
Batch 380, Loss: 0.2322
Batch 390, Loss: 0.2480
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.054893016815186 seconds
Epoch 191 accuracy: 79.8%
Batch 10, Loss: 0.2648
Batch 20, Loss: 0.2303
Batch 30, Loss: 0.2693
Batch 40, Loss: 0.2063
Batch 50, Loss: 0.2382
Batch 60, Loss: 0.2666
Batch 70, Loss: 0.2345
Batch 80, Loss: 0.2481
Batch 90, Loss: 0.2238
Batch 100, Loss: 0.2358
Batch 110, Loss: 0.2537
Batch 120, Loss: 0.2382
Batch 130, Loss: 0.2373
Batch 140, Loss: 0.2298
Batch 150, Loss: 0.2319
Batch 160, Loss: 0.2388
Batch 170, Loss: 0.2646
Batch 180, Loss: 0.2318
Batch 190, Loss: 0.2175
Batch 200, Loss: 0.2705
Batch 210, Loss: 0.2390
Batch 220, Loss: 0.2508
Batch 230, Loss: 0.2463
Batch 240, Loss: 0.2218
Batch 250, Loss: 0.2383
Batch 260, Loss: 0.2373
Batch 270, Loss: 0.2367
Batch 280, Loss: 0.2330
Batch 290, Loss: 0.2338
Batch 300, Loss: 0.2351
Batch 310, Loss: 0.2303
Batch 320, Loss: 0.2234
Batch 330, Loss: 0.2565
Batch 340, Loss: 0.2034
Batch 350, Loss: 0.2342
Batch 360, Loss: 0.2630
Batch 370, Loss: 0.2373
Batch 380, Loss: 0.2635
Batch 390, Loss: 0.2329
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.20415735244751 seconds
Epoch 192 accuracy: 80.11%
Batch 10, Loss: 0.2720
Batch 20, Loss: 0.2084
Batch 30, Loss: 0.2546
Batch 40, Loss: 0.2464
Batch 50, Loss: 0.2482
Batch 60, Loss: 0.2302
Batch 70, Loss: 0.2651
Batch 80, Loss: 0.2784
Batch 90, Loss: 0.2481
Batch 100, Loss: 0.2491
Batch 110, Loss: 0.2536
Batch 120, Loss: 0.2531
Batch 130, Loss: 0.2286
Batch 140, Loss: 0.2528
Batch 150, Loss: 0.2744
Batch 160, Loss: 0.2375
Batch 170, Loss: 0.2837
Batch 180, Loss: 0.2080
Batch 190, Loss: 0.2523
Batch 200, Loss: 0.2698
Batch 210, Loss: 0.2445
Batch 220, Loss: 0.2386
Batch 230, Loss: 0.2380
Batch 240, Loss: 0.2195
Batch 250, Loss: 0.2428
Batch 260, Loss: 0.2732
Batch 270, Loss: 0.2333
Batch 280, Loss: 0.2733
Batch 290, Loss: 0.2405
Batch 300, Loss: 0.2453
Batch 310, Loss: 0.2518
Batch 320, Loss: 0.2440
Batch 330, Loss: 0.2451
Batch 340, Loss: 0.2330
Batch 350, Loss: 0.2251
Batch 360, Loss: 0.2670
Batch 370, Loss: 0.2569
Batch 380, Loss: 0.2466
Batch 390, Loss: 0.2690
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.138447284698486 seconds
Epoch 193 accuracy: 79.99%
Batch 10, Loss: 0.2409
Batch 20, Loss: 0.2707
Batch 30, Loss: 0.2536
Batch 40, Loss: 0.2446
Batch 50, Loss: 0.2572
Batch 60, Loss: 0.2674
Batch 70, Loss: 0.2272
Batch 80, Loss: 0.2485
Batch 90, Loss: 0.2551
Batch 100, Loss: 0.2406
Batch 110, Loss: 0.2387
Batch 120, Loss: 0.2636
Batch 130, Loss: 0.2309
Batch 140, Loss: 0.2476
Batch 150, Loss: 0.2391
Batch 160, Loss: 0.2342
Batch 170, Loss: 0.2586
Batch 180, Loss: 0.2499
Batch 190, Loss: 0.2724
Batch 200, Loss: 0.2500
Batch 210, Loss: 0.2358
Batch 220, Loss: 0.2674
Batch 230, Loss: 0.2515
Batch 240, Loss: 0.2359
Batch 250, Loss: 0.2823
Batch 260, Loss: 0.2385
Batch 270, Loss: 0.2305
Batch 280, Loss: 0.2150
Batch 290, Loss: 0.2542
Batch 300, Loss: 0.1990
Batch 310, Loss: 0.2520
Batch 320, Loss: 0.2384
Batch 330, Loss: 0.2396
Batch 340, Loss: 0.2379
Batch 350, Loss: 0.2425
Batch 360, Loss: 0.2310
Batch 370, Loss: 0.2288
Batch 380, Loss: 0.2245
Batch 390, Loss: 0.2160
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.064757347106934 seconds
Epoch 194 accuracy: 79.85%
Batch 10, Loss: 0.2248
Batch 20, Loss: 0.2554
Batch 30, Loss: 0.2152
Batch 40, Loss: 0.2224
Batch 50, Loss: 0.2639
Batch 60, Loss: 0.2374
Batch 70, Loss: 0.2270
Batch 80, Loss: 0.2469
Batch 90, Loss: 0.2746
Batch 100, Loss: 0.2529
Batch 110, Loss: 0.2322
Batch 120, Loss: 0.2530
Batch 130, Loss: 0.2293
Batch 140, Loss: 0.2637
Batch 150, Loss: 0.2488
Batch 160, Loss: 0.2241
Batch 170, Loss: 0.2489
Batch 180, Loss: 0.2106
Batch 190, Loss: 0.2388
Batch 200, Loss: 0.2491
Batch 210, Loss: 0.2253
Batch 220, Loss: 0.2195
Batch 230, Loss: 0.2355
Batch 240, Loss: 0.2663
Batch 250, Loss: 0.2437
Batch 260, Loss: 0.2669
Batch 270, Loss: 0.2412
Batch 280, Loss: 0.2284
Batch 290, Loss: 0.2184
Batch 300, Loss: 0.2315
Batch 310, Loss: 0.2324
Batch 320, Loss: 0.2122
Batch 330, Loss: 0.2410
Batch 340, Loss: 0.2201
Batch 350, Loss: 0.2092
Batch 360, Loss: 0.2200
Batch 370, Loss: 0.2160
Batch 380, Loss: 0.2765
Batch 390, Loss: 0.2179
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.02667999267578 seconds
Epoch 195 accuracy: 79.81%
Batch 10, Loss: 0.2508
Batch 20, Loss: 0.2435
Batch 30, Loss: 0.2272
Batch 40, Loss: 0.1960
Batch 50, Loss: 0.2289
Batch 60, Loss: 0.2589
Batch 70, Loss: 0.2213
Batch 80, Loss: 0.2511
Batch 90, Loss: 0.2399
Batch 100, Loss: 0.2581
Batch 110, Loss: 0.2267
Batch 120, Loss: 0.2663
Batch 130, Loss: 0.2428
Batch 140, Loss: 0.2465
Batch 150, Loss: 0.2393
Batch 160, Loss: 0.2255
Batch 170, Loss: 0.2045
Batch 180, Loss: 0.2456
Batch 190, Loss: 0.2296
Batch 200, Loss: 0.2289
Batch 210, Loss: 0.2255
Batch 220, Loss: 0.2441
Batch 230, Loss: 0.2599
Batch 240, Loss: 0.2300
Batch 250, Loss: 0.2094
Batch 260, Loss: 0.2407
Batch 270, Loss: 0.2356
Batch 280, Loss: 0.2440
Batch 290, Loss: 0.2302
Batch 300, Loss: 0.2549
Batch 310, Loss: 0.2750
Batch 320, Loss: 0.2473
Batch 330, Loss: 0.2598
Batch 340, Loss: 0.1968
Batch 350, Loss: 0.2183
Batch 360, Loss: 0.2534
Batch 370, Loss: 0.2305
Batch 380, Loss: 0.2300
Batch 390, Loss: 0.2564
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.085400104522705 seconds
Epoch 196 accuracy: 79.81%
Batch 10, Loss: 0.2165
Batch 20, Loss: 0.2335
Batch 30, Loss: 0.2201
Batch 40, Loss: 0.2165
Batch 50, Loss: 0.2472
Batch 60, Loss: 0.2520
Batch 70, Loss: 0.2000
Batch 80, Loss: 0.2263
Batch 90, Loss: 0.2168
Batch 100, Loss: 0.2207
Batch 110, Loss: 0.2788
Batch 120, Loss: 0.2751
Batch 130, Loss: 0.2493
Batch 140, Loss: 0.2198
Batch 150, Loss: 0.2233
Batch 160, Loss: 0.2235
Batch 170, Loss: 0.2272
Batch 180, Loss: 0.2632
Batch 190, Loss: 0.2176
Batch 200, Loss: 0.2417
Batch 210, Loss: 0.2281
Batch 220, Loss: 0.2426
Batch 230, Loss: 0.2271
Batch 240, Loss: 0.2321
Batch 250, Loss: 0.2693
Batch 260, Loss: 0.2671
Batch 270, Loss: 0.2329
Batch 280, Loss: 0.2261
Batch 290, Loss: 0.2381
Batch 300, Loss: 0.2244
Batch 310, Loss: 0.2417
Batch 320, Loss: 0.2513
Batch 330, Loss: 0.2179
Batch 340, Loss: 0.2475
Batch 350, Loss: 0.2501
Batch 360, Loss: 0.2505
Batch 370, Loss: 0.2488
Batch 380, Loss: 0.2163
Batch 390, Loss: 0.2469
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.040194272994995 seconds
Epoch 197 accuracy: 79.77%
Batch 10, Loss: 0.2576
Batch 20, Loss: 0.2576
Batch 30, Loss: 0.2345
Batch 40, Loss: 0.2283
Batch 50, Loss: 0.2072
Batch 60, Loss: 0.2571
Batch 70, Loss: 0.2188
Batch 80, Loss: 0.2231
Batch 90, Loss: 0.2508
Batch 100, Loss: 0.2212
Batch 110, Loss: 0.2304
Batch 120, Loss: 0.2087
Batch 130, Loss: 0.2615
Batch 140, Loss: 0.2096
Batch 150, Loss: 0.2146
Batch 160, Loss: 0.2201
Batch 170, Loss: 0.2308
Batch 180, Loss: 0.2253
Batch 190, Loss: 0.2577
Batch 200, Loss: 0.2476
Batch 210, Loss: 0.2471
Batch 220, Loss: 0.2613
Batch 230, Loss: 0.2761
Batch 240, Loss: 0.2482
Batch 250, Loss: 0.2263
Batch 260, Loss: 0.2674
Batch 270, Loss: 0.2758
Batch 280, Loss: 0.2285
Batch 290, Loss: 0.2522
Batch 300, Loss: 0.2320
Batch 310, Loss: 0.2462
Batch 320, Loss: 0.2391
Batch 330, Loss: 0.2422
Batch 340, Loss: 0.2289
Batch 350, Loss: 0.2012
Batch 360, Loss: 0.2399
Batch 370, Loss: 0.2333
Batch 380, Loss: 0.2476
Batch 390, Loss: 0.2667
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.042566061019897 seconds
Epoch 198 accuracy: 79.96%
Batch 10, Loss: 0.2493
Batch 20, Loss: 0.2499
Batch 30, Loss: 0.2392
Batch 40, Loss: 0.2406
Batch 50, Loss: 0.2160
Batch 60, Loss: 0.2142
Batch 70, Loss: 0.2237
Batch 80, Loss: 0.2398
Batch 90, Loss: 0.2449
Batch 100, Loss: 0.2102
Batch 110, Loss: 0.2191
Batch 120, Loss: 0.2623
Batch 130, Loss: 0.2364
Batch 140, Loss: 0.2392
Batch 150, Loss: 0.2387
Batch 160, Loss: 0.2263
Batch 170, Loss: 0.2569
Batch 180, Loss: 0.2176
Batch 190, Loss: 0.2469
Batch 200, Loss: 0.2387
Batch 210, Loss: 0.2220
Batch 220, Loss: 0.2469
Batch 230, Loss: 0.2599
Batch 240, Loss: 0.2186
Batch 250, Loss: 0.2229
Batch 260, Loss: 0.2560
Batch 270, Loss: 0.2406
Batch 280, Loss: 0.2598
Batch 290, Loss: 0.2530
Batch 300, Loss: 0.2606
Batch 310, Loss: 0.2218
Batch 320, Loss: 0.2527
Batch 330, Loss: 0.2348
Batch 340, Loss: 0.2599
Batch 350, Loss: 0.2024
Batch 360, Loss: 0.1965
Batch 370, Loss: 0.2630
Batch 380, Loss: 0.2378
Batch 390, Loss: 0.2448
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.124449253082275 seconds
Epoch 199 accuracy: 79.8%
Batch 10, Loss: 0.2488
Batch 20, Loss: 0.2372
Batch 30, Loss: 0.2138
Batch 40, Loss: 0.2193
Batch 50, Loss: 0.2275
Batch 60, Loss: 0.2175
Batch 70, Loss: 0.2149
Batch 80, Loss: 0.2331
Batch 90, Loss: 0.2360
Batch 100, Loss: 0.2648
Batch 110, Loss: 0.2294
Batch 120, Loss: 0.2332
Batch 130, Loss: 0.2601
Batch 140, Loss: 0.2235
Batch 150, Loss: 0.1962
Batch 160, Loss: 0.2201
Batch 170, Loss: 0.2286
Batch 180, Loss: 0.2307
Batch 190, Loss: 0.2662
Batch 200, Loss: 0.2566
Batch 210, Loss: 0.2053
Batch 220, Loss: 0.2301
Batch 230, Loss: 0.2278
Batch 240, Loss: 0.2396
Batch 250, Loss: 0.2232
Batch 260, Loss: 0.2354
Batch 270, Loss: 0.2453
Batch 280, Loss: 0.2710
Batch 290, Loss: 0.2221
Batch 300, Loss: 0.2518
Batch 310, Loss: 0.2567
Batch 320, Loss: 0.2072
Batch 330, Loss: 0.2190
Batch 340, Loss: 0.2367
Batch 350, Loss: 0.2479
Batch 360, Loss: 0.2142
Batch 370, Loss: 0.2304
Batch 380, Loss: 0.2525
Batch 390, Loss: 0.2392
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.09152317047119 seconds
Epoch 200 accuracy: 79.95%
Total training time: 5024.1683604717255 seconds
