The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR10/GAM
Batch 10, Loss: 2.9670
Batch 20, Loss: 2.4913
Batch 30, Loss: 1.9002
Batch 40, Loss: 1.8057
Batch 50, Loss: 1.7622
Batch 60, Loss: 1.7167
Batch 70, Loss: 1.6503
Batch 80, Loss: 1.6397
Batch 90, Loss: 1.6245
Batch 100, Loss: 1.6034
Batch 110, Loss: 1.5969
Batch 120, Loss: 1.5858
Batch 130, Loss: 1.6035
Batch 140, Loss: 1.5902
Batch 150, Loss: 1.5821
Batch 160, Loss: 1.5463
Batch 170, Loss: 1.5224
Batch 180, Loss: 1.5561
Batch 190, Loss: 1.5211
Batch 200, Loss: 1.5224
Batch 210, Loss: 1.5534
Batch 220, Loss: 1.5339
Batch 230, Loss: 1.5177
Batch 240, Loss: 1.4977
Batch 250, Loss: 1.5442
Batch 260, Loss: 1.5033
Batch 270, Loss: 1.4685
Batch 280, Loss: 1.5194
Batch 290, Loss: 1.4785
Batch 300, Loss: 1.5018
Batch 310, Loss: 1.5018
Batch 320, Loss: 1.4805
Batch 330, Loss: 1.4585
Batch 340, Loss: 1.4799
Batch 350, Loss: 1.4367
Batch 360, Loss: 1.4821
Batch 370, Loss: 1.4961
Batch 380, Loss: 1.4666
Batch 390, Loss: 1.4167
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.457459449768066 seconds
Epoch 1 accuracy: 36.75%
Batch 10, Loss: 1.4216
Batch 20, Loss: 1.4319
Batch 30, Loss: 1.4446
Batch 40, Loss: 1.4726
Batch 50, Loss: 1.4380
Batch 60, Loss: 1.4093
Batch 70, Loss: 1.4222
Batch 80, Loss: 1.4303
Batch 90, Loss: 1.4194
Batch 100, Loss: 1.4069
Batch 110, Loss: 1.4280
Batch 120, Loss: 1.3905
Batch 130, Loss: 1.3998
Batch 140, Loss: 1.4166
Batch 150, Loss: 1.3636
Batch 160, Loss: 1.3917
Batch 170, Loss: 1.3735
Batch 180, Loss: 1.3715
Batch 190, Loss: 1.3755
Batch 200, Loss: 1.3912
Batch 210, Loss: 1.4114
Batch 220, Loss: 1.3673
Batch 230, Loss: 1.3887
Batch 240, Loss: 1.3849
Batch 250, Loss: 1.3890
Batch 260, Loss: 1.3851
Batch 270, Loss: 1.3842
Batch 280, Loss: 1.3376
Batch 290, Loss: 1.3549
Batch 300, Loss: 1.3453
Batch 310, Loss: 1.3160
Batch 320, Loss: 1.3597
Batch 330, Loss: 1.3127
Batch 340, Loss: 1.3442
Batch 350, Loss: 1.2725
Batch 360, Loss: 1.3178
Batch 370, Loss: 1.3298
Batch 380, Loss: 1.3751
Batch 390, Loss: 1.3210
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.10534691810608 seconds
Epoch 2 accuracy: 41.63%
Batch 10, Loss: 1.3009
Batch 20, Loss: 1.3148
Batch 30, Loss: 1.3213
Batch 40, Loss: 1.2478
Batch 50, Loss: 1.2520
Batch 60, Loss: 1.2731
Batch 70, Loss: 1.2498
Batch 80, Loss: 1.2630
Batch 90, Loss: 1.2714
Batch 100, Loss: 1.2733
Batch 110, Loss: 1.2561
Batch 120, Loss: 1.2398
Batch 130, Loss: 1.2483
Batch 140, Loss: 1.2310
Batch 150, Loss: 1.2717
Batch 160, Loss: 1.2197
Batch 170, Loss: 1.2480
Batch 180, Loss: 1.2609
Batch 190, Loss: 1.2513
Batch 200, Loss: 1.2069
Batch 210, Loss: 1.2411
Batch 220, Loss: 1.1667
Batch 230, Loss: 1.1936
Batch 240, Loss: 1.2185
Batch 250, Loss: 1.2442
Batch 260, Loss: 1.1928
Batch 270, Loss: 1.2245
Batch 280, Loss: 1.2705
Batch 290, Loss: 1.2530
Batch 300, Loss: 1.2287
Batch 310, Loss: 1.2051
Batch 320, Loss: 1.1950
Batch 330, Loss: 1.1929
Batch 340, Loss: 1.1787
Batch 350, Loss: 1.2106
Batch 360, Loss: 1.1762
Batch 370, Loss: 1.1709
Batch 380, Loss: 1.1554
Batch 390, Loss: 1.1486
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.110371589660645 seconds
Epoch 3 accuracy: 49.98%
Batch 10, Loss: 1.1485
Batch 20, Loss: 1.2287
Batch 30, Loss: 1.1692
Batch 40, Loss: 1.1350
Batch 50, Loss: 1.1759
Batch 60, Loss: 1.1686
Batch 70, Loss: 1.1552
Batch 80, Loss: 1.2015
Batch 90, Loss: 1.1886
Batch 100, Loss: 1.1487
Batch 110, Loss: 1.1675
Batch 120, Loss: 1.1258
Batch 130, Loss: 1.1773
Batch 140, Loss: 1.1301
Batch 150, Loss: 1.1412
Batch 160, Loss: 1.1252
Batch 170, Loss: 1.1078
Batch 180, Loss: 1.1802
Batch 190, Loss: 1.1247
Batch 200, Loss: 1.1376
Batch 210, Loss: 1.1061
Batch 220, Loss: 1.1106
Batch 230, Loss: 1.1883
Batch 240, Loss: 1.1401
Batch 250, Loss: 1.1204
Batch 260, Loss: 1.0735
Batch 270, Loss: 1.1126
Batch 280, Loss: 1.0778
Batch 290, Loss: 1.0649
Batch 300, Loss: 1.0996
Batch 310, Loss: 1.1361
Batch 320, Loss: 1.0942
Batch 330, Loss: 1.0948
Batch 340, Loss: 1.0694
Batch 350, Loss: 1.0943
Batch 360, Loss: 1.1000
Batch 370, Loss: 1.1070
Batch 380, Loss: 1.0506
Batch 390, Loss: 1.1174
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 24.99337887763977 seconds
Epoch 4 accuracy: 56.64%
Batch 10, Loss: 1.1251
Batch 20, Loss: 1.0598
Batch 30, Loss: 1.0631
Batch 40, Loss: 1.0443
Batch 50, Loss: 1.1066
Batch 60, Loss: 1.1058
Batch 70, Loss: 1.0454
Batch 80, Loss: 1.0551
Batch 90, Loss: 1.0325
Batch 100, Loss: 1.0426
Batch 110, Loss: 1.0470
Batch 120, Loss: 0.9843
Batch 130, Loss: 1.0885
Batch 140, Loss: 1.0338
Batch 150, Loss: 1.0584
Batch 160, Loss: 1.0165
Batch 170, Loss: 1.1042
Batch 180, Loss: 1.0434
Batch 190, Loss: 0.9990
Batch 200, Loss: 1.0495
Batch 210, Loss: 1.0440
Batch 220, Loss: 1.0076
Batch 230, Loss: 1.0580
Batch 240, Loss: 1.0507
Batch 250, Loss: 1.0278
Batch 260, Loss: 1.0612
Batch 270, Loss: 1.0019
Batch 280, Loss: 1.0030
Batch 290, Loss: 0.9896
Batch 300, Loss: 1.0354
Batch 310, Loss: 0.9848
Batch 320, Loss: 1.0324
Batch 330, Loss: 1.0516
Batch 340, Loss: 1.0356
Batch 350, Loss: 1.0157
Batch 360, Loss: 0.9856
Batch 370, Loss: 0.9816
Batch 380, Loss: 1.0134
Batch 390, Loss: 0.9807
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.065686464309692 seconds
Epoch 5 accuracy: 61.73%
Batch 10, Loss: 0.9991
Batch 20, Loss: 0.9386
Batch 30, Loss: 0.9970
Batch 40, Loss: 0.9881
Batch 50, Loss: 0.9831
Batch 60, Loss: 0.9941
Batch 70, Loss: 0.9401
Batch 80, Loss: 1.0158
Batch 90, Loss: 0.9797
Batch 100, Loss: 0.9450
Batch 110, Loss: 0.9941
Batch 120, Loss: 0.9575
Batch 130, Loss: 1.0150
Batch 140, Loss: 1.0139
Batch 150, Loss: 0.9810
Batch 160, Loss: 0.9700
Batch 170, Loss: 0.9279
Batch 180, Loss: 0.9427
Batch 190, Loss: 0.9432
Batch 200, Loss: 0.9449
Batch 210, Loss: 0.9795
Batch 220, Loss: 0.9140
Batch 230, Loss: 0.9618
Batch 240, Loss: 0.9898
Batch 250, Loss: 0.9473
Batch 260, Loss: 0.9572
Batch 270, Loss: 0.9751
Batch 280, Loss: 0.9895
Batch 290, Loss: 0.9630
Batch 300, Loss: 0.9121
Batch 310, Loss: 0.9410
Batch 320, Loss: 0.9419
Batch 330, Loss: 0.8991
Batch 340, Loss: 0.9482
Batch 350, Loss: 0.9224
Batch 360, Loss: 0.9349
Batch 370, Loss: 0.9385
Batch 380, Loss: 0.9685
Batch 390, Loss: 0.9638
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.038888216018677 seconds
Epoch 6 accuracy: 62.98%
Batch 10, Loss: 0.9034
Batch 20, Loss: 0.9290
Batch 30, Loss: 0.9459
Batch 40, Loss: 0.9136
Batch 50, Loss: 0.9296
Batch 60, Loss: 0.9137
Batch 70, Loss: 0.9355
Batch 80, Loss: 0.8901
Batch 90, Loss: 0.9374
Batch 100, Loss: 0.8712
Batch 110, Loss: 0.8753
Batch 120, Loss: 0.8767
Batch 130, Loss: 0.9163
Batch 140, Loss: 0.9050
Batch 150, Loss: 0.9028
Batch 160, Loss: 0.8883
Batch 170, Loss: 0.9256
Batch 180, Loss: 0.8988
Batch 190, Loss: 0.8816
Batch 200, Loss: 0.8519
Batch 210, Loss: 0.8498
Batch 220, Loss: 0.8754
Batch 230, Loss: 0.9008
Batch 240, Loss: 0.8953
Batch 250, Loss: 0.8837
Batch 260, Loss: 0.8873
Batch 270, Loss: 0.8736
Batch 280, Loss: 0.9175
Batch 290, Loss: 0.8685
Batch 300, Loss: 0.9176
Batch 310, Loss: 0.8414
Batch 320, Loss: 0.8585
Batch 330, Loss: 0.8638
Batch 340, Loss: 0.9001
Batch 350, Loss: 0.8661
Batch 360, Loss: 0.8622
Batch 370, Loss: 0.8535
Batch 380, Loss: 0.8751
Batch 390, Loss: 0.8483
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.0061092376709 seconds
Epoch 7 accuracy: 65.12%
Batch 10, Loss: 0.8674
Batch 20, Loss: 0.8671
Batch 30, Loss: 0.8402
Batch 40, Loss: 0.8236
Batch 50, Loss: 0.8634
Batch 60, Loss: 0.8684
Batch 70, Loss: 0.8544
Batch 80, Loss: 0.8492
Batch 90, Loss: 0.8593
Batch 100, Loss: 0.8117
Batch 110, Loss: 0.8307
Batch 120, Loss: 0.8219
Batch 130, Loss: 0.8077
Batch 140, Loss: 0.8515
Batch 150, Loss: 0.7986
Batch 160, Loss: 0.8560
Batch 170, Loss: 0.8685
Batch 180, Loss: 0.8195
Batch 190, Loss: 0.8448
Batch 200, Loss: 0.8584
Batch 210, Loss: 0.8473
Batch 220, Loss: 0.7898
Batch 230, Loss: 0.8069
Batch 240, Loss: 0.8264
Batch 250, Loss: 0.8698
Batch 260, Loss: 0.8408
Batch 270, Loss: 0.7985
Batch 280, Loss: 0.8151
Batch 290, Loss: 0.8247
Batch 300, Loss: 0.8043
Batch 310, Loss: 0.8055
Batch 320, Loss: 0.7987
Batch 330, Loss: 0.8045
Batch 340, Loss: 0.7768
Batch 350, Loss: 0.8088
Batch 360, Loss: 0.8574
Batch 370, Loss: 0.8187
Batch 380, Loss: 0.7534
Batch 390, Loss: 0.7896
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.06164860725403 seconds
Epoch 8 accuracy: 56.6%
Batch 10, Loss: 0.8489
Batch 20, Loss: 0.8373
Batch 30, Loss: 0.7849
Batch 40, Loss: 0.7634
Batch 50, Loss: 0.7506
Batch 60, Loss: 0.7981
Batch 70, Loss: 0.8720
Batch 80, Loss: 0.8089
Batch 90, Loss: 0.8018
Batch 100, Loss: 0.7829
Batch 110, Loss: 0.7797
Batch 120, Loss: 0.7941
Batch 130, Loss: 0.8034
Batch 140, Loss: 0.8061
Batch 150, Loss: 0.7582
Batch 160, Loss: 0.8042
Batch 170, Loss: 0.7505
Batch 180, Loss: 0.8262
Batch 190, Loss: 0.7619
Batch 200, Loss: 0.7612
Batch 210, Loss: 0.8033
Batch 220, Loss: 0.7631
Batch 230, Loss: 0.7818
Batch 240, Loss: 0.7752
Batch 250, Loss: 0.7630
Batch 260, Loss: 0.7846
Batch 270, Loss: 0.7970
Batch 280, Loss: 0.8050
Batch 290, Loss: 0.7642
Batch 300, Loss: 0.7799
Batch 310, Loss: 0.7487
Batch 320, Loss: 0.7789
Batch 330, Loss: 0.7890
Batch 340, Loss: 0.7467
Batch 350, Loss: 0.7928
Batch 360, Loss: 0.7673
Batch 370, Loss: 0.8007
Batch 380, Loss: 0.8158
Batch 390, Loss: 0.7616
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.016401052474976 seconds
Epoch 9 accuracy: 64.74%
Batch 10, Loss: 0.7650
Batch 20, Loss: 0.7514
Batch 30, Loss: 0.6966
Batch 40, Loss: 0.7782
Batch 50, Loss: 0.7608
Batch 60, Loss: 0.7691
Batch 70, Loss: 0.7361
Batch 80, Loss: 0.7718
Batch 90, Loss: 0.7914
Batch 100, Loss: 0.7844
Batch 110, Loss: 0.7687
Batch 120, Loss: 0.7794
Batch 130, Loss: 0.7779
Batch 140, Loss: 0.7636
Batch 150, Loss: 0.7357
Batch 160, Loss: 0.8055
Batch 170, Loss: 0.7721
Batch 180, Loss: 0.7480
Batch 190, Loss: 0.7368
Batch 200, Loss: 0.7675
Batch 210, Loss: 0.7675
Batch 220, Loss: 0.7410
Batch 230, Loss: 0.7247
Batch 240, Loss: 0.7376
Batch 250, Loss: 0.7223
Batch 260, Loss: 0.7711
Batch 270, Loss: 0.7902
Batch 280, Loss: 0.7540
Batch 290, Loss: 0.7725
Batch 300, Loss: 0.7811
Batch 310, Loss: 0.7323
Batch 320, Loss: 0.7142
Batch 330, Loss: 0.7563
Batch 340, Loss: 0.7422
Batch 350, Loss: 0.7824
Batch 360, Loss: 0.7734
Batch 370, Loss: 0.7686
Batch 380, Loss: 0.6973
Batch 390, Loss: 0.7300
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.03343629837036 seconds
Epoch 10 accuracy: 77.3%
Batch 10, Loss: 0.7265
Batch 20, Loss: 0.7483
Batch 30, Loss: 0.7412
Batch 40, Loss: 0.7294
Batch 50, Loss: 0.7058
Batch 60, Loss: 0.7293
Batch 70, Loss: 0.7020
Batch 80, Loss: 0.7476
Batch 90, Loss: 0.7553
Batch 100, Loss: 0.7638
Batch 110, Loss: 0.7284
Batch 120, Loss: 0.7350
Batch 130, Loss: 0.7552
Batch 140, Loss: 0.7362
Batch 150, Loss: 0.7126
Batch 160, Loss: 0.7418
Batch 170, Loss: 0.7314
Batch 180, Loss: 0.7639
Batch 190, Loss: 0.7307
Batch 200, Loss: 0.7067
Batch 210, Loss: 0.7413
Batch 220, Loss: 0.6832
Batch 230, Loss: 0.7257
Batch 240, Loss: 0.7454
Batch 250, Loss: 0.7242
Batch 260, Loss: 0.7261
Batch 270, Loss: 0.7148
Batch 280, Loss: 0.7414
Batch 290, Loss: 0.7265
Batch 300, Loss: 0.7054
Batch 310, Loss: 0.6806
Batch 320, Loss: 0.6770
Batch 330, Loss: 0.7282
Batch 340, Loss: 0.7796
Batch 350, Loss: 0.7298
Batch 360, Loss: 0.7220
Batch 370, Loss: 0.7573
Batch 380, Loss: 0.7321
Batch 390, Loss: 0.7251
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.052207231521606 seconds
Epoch 11 accuracy: 74.06%
Batch 10, Loss: 0.7324
Batch 20, Loss: 0.7751
Batch 30, Loss: 0.6886
Batch 40, Loss: 0.6605
Batch 50, Loss: 0.7039
Batch 60, Loss: 0.7256
Batch 70, Loss: 0.7296
Batch 80, Loss: 0.7111
Batch 90, Loss: 0.7055
Batch 100, Loss: 0.7836
Batch 110, Loss: 0.7404
Batch 120, Loss: 0.7028
Batch 130, Loss: 0.7592
Batch 140, Loss: 0.7071
Batch 150, Loss: 0.6838
Batch 160, Loss: 0.7101
Batch 170, Loss: 0.7314
Batch 180, Loss: 0.7147
Batch 190, Loss: 0.6740
Batch 200, Loss: 0.7429
Batch 210, Loss: 0.7035
Batch 220, Loss: 0.7033
Batch 230, Loss: 0.7256
Batch 240, Loss: 0.7339
Batch 250, Loss: 0.6951
Batch 260, Loss: 0.7398
Batch 270, Loss: 0.6985
Batch 280, Loss: 0.6748
Batch 290, Loss: 0.7221
Batch 300, Loss: 0.7052
Batch 310, Loss: 0.7054
Batch 320, Loss: 0.6765
Batch 330, Loss: 0.7171
Batch 340, Loss: 0.7231
Batch 350, Loss: 0.7170
Batch 360, Loss: 0.6913
Batch 370, Loss: 0.7109
Batch 380, Loss: 0.6724
Batch 390, Loss: 0.6733
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.034562587738037 seconds
Epoch 12 accuracy: 77.19%
Batch 10, Loss: 0.6822
Batch 20, Loss: 0.6842
Batch 30, Loss: 0.7101
Batch 40, Loss: 0.6967
Batch 50, Loss: 0.6808
Batch 60, Loss: 0.7453
Batch 70, Loss: 0.6739
Batch 80, Loss: 0.6887
Batch 90, Loss: 0.7310
Batch 100, Loss: 0.7494
Batch 110, Loss: 0.7015
Batch 120, Loss: 0.7362
Batch 130, Loss: 0.7090
Batch 140, Loss: 0.7261
Batch 150, Loss: 0.6790
Batch 160, Loss: 0.6767
Batch 170, Loss: 0.6865
Batch 180, Loss: 0.7044
Batch 190, Loss: 0.7254
Batch 200, Loss: 0.6807
Batch 210, Loss: 0.6989
Batch 220, Loss: 0.7387
Batch 230, Loss: 0.6787
Batch 240, Loss: 0.6764
Batch 250, Loss: 0.7261
Batch 260, Loss: 0.6986
Batch 270, Loss: 0.6709
Batch 280, Loss: 0.6887
Batch 290, Loss: 0.6937
Batch 300, Loss: 0.6668
Batch 310, Loss: 0.6858
Batch 320, Loss: 0.7012
Batch 330, Loss: 0.6548
Batch 340, Loss: 0.6805
Batch 350, Loss: 0.7031
Batch 360, Loss: 0.7197
Batch 370, Loss: 0.6513
Batch 380, Loss: 0.6604
Batch 390, Loss: 0.7231
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 24.988152503967285 seconds
Epoch 13 accuracy: 63.93%
Batch 10, Loss: 0.7081
Batch 20, Loss: 0.7048
Batch 30, Loss: 0.6799
Batch 40, Loss: 0.6777
Batch 50, Loss: 0.6691
Batch 60, Loss: 0.6659
Batch 70, Loss: 0.6924
Batch 80, Loss: 0.6907
Batch 90, Loss: 0.6467
Batch 100, Loss: 0.6420
Batch 110, Loss: 0.6952
Batch 120, Loss: 0.6632
Batch 130, Loss: 0.6865
Batch 140, Loss: 0.7243
Batch 150, Loss: 0.6908
Batch 160, Loss: 0.6586
Batch 170, Loss: 0.6831
Batch 180, Loss: 0.6777
Batch 190, Loss: 0.7002
Batch 200, Loss: 0.6695
Batch 210, Loss: 0.6283
Batch 220, Loss: 0.6723
Batch 230, Loss: 0.6751
Batch 240, Loss: 0.7104
Batch 250, Loss: 0.6615
Batch 260, Loss: 0.6551
Batch 270, Loss: 0.6646
Batch 280, Loss: 0.6682
Batch 290, Loss: 0.6922
Batch 300, Loss: 0.6618
Batch 310, Loss: 0.6954
Batch 320, Loss: 0.6505
Batch 330, Loss: 0.6616
Batch 340, Loss: 0.6521
Batch 350, Loss: 0.7073
Batch 360, Loss: 0.6995
Batch 370, Loss: 0.6576
Batch 380, Loss: 0.7052
Batch 390, Loss: 0.6665
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.0433406829834 seconds
Epoch 14 accuracy: 78.72%
Batch 10, Loss: 0.6337
Batch 20, Loss: 0.6351
Batch 30, Loss: 0.6734
Batch 40, Loss: 0.6872
Batch 50, Loss: 0.6416
Batch 60, Loss: 0.6776
Batch 70, Loss: 0.7031
Batch 80, Loss: 0.7297
Batch 90, Loss: 0.7124
Batch 100, Loss: 0.7029
Batch 110, Loss: 0.6507
Batch 120, Loss: 0.6195
Batch 130, Loss: 0.6867
Batch 140, Loss: 0.6703
Batch 150, Loss: 0.6572
Batch 160, Loss: 0.6864
Batch 170, Loss: 0.7004
Batch 180, Loss: 0.6760
Batch 190, Loss: 0.6994
Batch 200, Loss: 0.6691
Batch 210, Loss: 0.6768
Batch 220, Loss: 0.6966
Batch 230, Loss: 0.6348
Batch 240, Loss: 0.6154
Batch 250, Loss: 0.6532
Batch 260, Loss: 0.6618
Batch 270, Loss: 0.6496
Batch 280, Loss: 0.7034
Batch 290, Loss: 0.6862
Batch 300, Loss: 0.6583
Batch 310, Loss: 0.7172
Batch 320, Loss: 0.6804
Batch 330, Loss: 0.6972
Batch 340, Loss: 0.6852
Batch 350, Loss: 0.6394
Batch 360, Loss: 0.6680
Batch 370, Loss: 0.6606
Batch 380, Loss: 0.6958
Batch 390, Loss: 0.6336
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.010890007019043 seconds
Epoch 15 accuracy: 75.63%
Batch 10, Loss: 0.6312
Batch 20, Loss: 0.6573
Batch 30, Loss: 0.7009
Batch 40, Loss: 0.6276
Batch 50, Loss: 0.6567
Batch 60, Loss: 0.6273
Batch 70, Loss: 0.6966
Batch 80, Loss: 0.6432
Batch 90, Loss: 0.6708
Batch 100, Loss: 0.7238
Batch 110, Loss: 0.6622
Batch 120, Loss: 0.6292
Batch 130, Loss: 0.6771
Batch 140, Loss: 0.6404
Batch 150, Loss: 0.6393
Batch 160, Loss: 0.6438
Batch 170, Loss: 0.6088
Batch 180, Loss: 0.6674
Batch 190, Loss: 0.6609
Batch 200, Loss: 0.6726
Batch 210, Loss: 0.6577
Batch 220, Loss: 0.6984
Batch 230, Loss: 0.6808
Batch 240, Loss: 0.6378
Batch 250, Loss: 0.6694
Batch 260, Loss: 0.6665
Batch 270, Loss: 0.6574
Batch 280, Loss: 0.6188
Batch 290, Loss: 0.6669
Batch 300, Loss: 0.6475
Batch 310, Loss: 0.6329
Batch 320, Loss: 0.6473
Batch 330, Loss: 0.6821
Batch 340, Loss: 0.6766
Batch 350, Loss: 0.6397
Batch 360, Loss: 0.6329
Batch 370, Loss: 0.6569
Batch 380, Loss: 0.6625
Batch 390, Loss: 0.6854
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.048097133636475 seconds
Epoch 16 accuracy: 81.28%
Batch 10, Loss: 0.6512
Batch 20, Loss: 0.6295
Batch 30, Loss: 0.6168
Batch 40, Loss: 0.6567
Batch 50, Loss: 0.6490
Batch 60, Loss: 0.6545
Batch 70, Loss: 0.6443
Batch 80, Loss: 0.6603
Batch 90, Loss: 0.6713
Batch 100, Loss: 0.6698
Batch 110, Loss: 0.6284
Batch 120, Loss: 0.6218
Batch 130, Loss: 0.6749
Batch 140, Loss: 0.6518
Batch 150, Loss: 0.6460
Batch 160, Loss: 0.6226
Batch 170, Loss: 0.6328
Batch 180, Loss: 0.6675
Batch 190, Loss: 0.6226
Batch 200, Loss: 0.6443
Batch 210, Loss: 0.6675
Batch 220, Loss: 0.6841
Batch 230, Loss: 0.6116
Batch 240, Loss: 0.6668
Batch 250, Loss: 0.6502
Batch 260, Loss: 0.6000
Batch 270, Loss: 0.6136
Batch 280, Loss: 0.6859
Batch 290, Loss: 0.6318
Batch 300, Loss: 0.6851
Batch 310, Loss: 0.6872
Batch 320, Loss: 0.6504
Batch 330, Loss: 0.6358
Batch 340, Loss: 0.6629
Batch 350, Loss: 0.6724
Batch 360, Loss: 0.6672
Batch 370, Loss: 0.6592
Batch 380, Loss: 0.6296
Batch 390, Loss: 0.6477
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 24.9937264919281 seconds
Epoch 17 accuracy: 79.56%
Batch 10, Loss: 0.6692
Batch 20, Loss: 0.6288
Batch 30, Loss: 0.6691
Batch 40, Loss: 0.6424
Batch 50, Loss: 0.6342
Batch 60, Loss: 0.6129
Batch 70, Loss: 0.6314
Batch 80, Loss: 0.6619
Batch 90, Loss: 0.6429
Batch 100, Loss: 0.6273
Batch 110, Loss: 0.6646
Batch 120, Loss: 0.6440
Batch 130, Loss: 0.6134
Batch 140, Loss: 0.6028
Batch 150, Loss: 0.6372
Batch 160, Loss: 0.6632
Batch 170, Loss: 0.6417
Batch 180, Loss: 0.6305
Batch 190, Loss: 0.6029
Batch 200, Loss: 0.6368
Batch 210, Loss: 0.6743
Batch 220, Loss: 0.6150
Batch 230, Loss: 0.6406
Batch 240, Loss: 0.6479
Batch 250, Loss: 0.6473
Batch 260, Loss: 0.6405
Batch 270, Loss: 0.6036
Batch 280, Loss: 0.6247
Batch 290, Loss: 0.6297
Batch 300, Loss: 0.6630
Batch 310, Loss: 0.6435
Batch 320, Loss: 0.6414
Batch 330, Loss: 0.6761
Batch 340, Loss: 0.6245
Batch 350, Loss: 0.6659
Batch 360, Loss: 0.6740
Batch 370, Loss: 0.6601
Batch 380, Loss: 0.6455
Batch 390, Loss: 0.6260
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 24.980525970458984 seconds
Epoch 18 accuracy: 79.53%
Batch 10, Loss: 0.6497
Batch 20, Loss: 0.6039
Batch 30, Loss: 0.6179
Batch 40, Loss: 0.6217
Batch 50, Loss: 0.6247
Batch 60, Loss: 0.6395
Batch 70, Loss: 0.6381
Batch 80, Loss: 0.6457
Batch 90, Loss: 0.5736
Batch 100, Loss: 0.6450
Batch 110, Loss: 0.6276
Batch 120, Loss: 0.6875
Batch 130, Loss: 0.6215
Batch 140, Loss: 0.6239
Batch 150, Loss: 0.6512
Batch 160, Loss: 0.6171
Batch 170, Loss: 0.6593
Batch 180, Loss: 0.6329
Batch 190, Loss: 0.5946
Batch 200, Loss: 0.6350
Batch 210, Loss: 0.6314
Batch 220, Loss: 0.6357
Batch 230, Loss: 0.6362
Batch 240, Loss: 0.6489
Batch 250, Loss: 0.5769
Batch 260, Loss: 0.6558
Batch 270, Loss: 0.6498
Batch 280, Loss: 0.6492
Batch 290, Loss: 0.6772
Batch 300, Loss: 0.6407
Batch 310, Loss: 0.6482
Batch 320, Loss: 0.6386
Batch 330, Loss: 0.6462
Batch 340, Loss: 0.6348
Batch 350, Loss: 0.6447
Batch 360, Loss: 0.6905
Batch 370, Loss: 0.6473
Batch 380, Loss: 0.6904
Batch 390, Loss: 0.6411
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 24.99552345275879 seconds
Epoch 19 accuracy: 77.44%
Batch 10, Loss: 0.6227
Batch 20, Loss: 0.6106
Batch 30, Loss: 0.6564
Batch 40, Loss: 0.6507
Batch 50, Loss: 0.6172
Batch 60, Loss: 0.5766
Batch 70, Loss: 0.6997
Batch 80, Loss: 0.6720
Batch 90, Loss: 0.6104
Batch 100, Loss: 0.6131
Batch 110, Loss: 0.6578
Batch 120, Loss: 0.6399
Batch 130, Loss: 0.6471
Batch 140, Loss: 0.5857
Batch 150, Loss: 0.6441
Batch 160, Loss: 0.6629
Batch 170, Loss: 0.6125
Batch 180, Loss: 0.6460
Batch 190, Loss: 0.6353
Batch 200, Loss: 0.6162
Batch 210, Loss: 0.5795
Batch 220, Loss: 0.6035
Batch 230, Loss: 0.6393
Batch 240, Loss: 0.6792
Batch 250, Loss: 0.6233
Batch 260, Loss: 0.6370
Batch 270, Loss: 0.5685
Batch 280, Loss: 0.6523
Batch 290, Loss: 0.6184
Batch 300, Loss: 0.6645
Batch 310, Loss: 0.6020
Batch 320, Loss: 0.6609
Batch 330, Loss: 0.6039
Batch 340, Loss: 0.6364
Batch 350, Loss: 0.6039
Batch 360, Loss: 0.6255
Batch 370, Loss: 0.5807
Batch 380, Loss: 0.5849
Batch 390, Loss: 0.6685
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.01125693321228 seconds
Epoch 20 accuracy: 73.33%
Batch 10, Loss: 0.6497
Batch 20, Loss: 0.6405
Batch 30, Loss: 0.6190
Batch 40, Loss: 0.5927
Batch 50, Loss: 0.6187
Batch 60, Loss: 0.6126
Batch 70, Loss: 0.6212
Batch 80, Loss: 0.6364
Batch 90, Loss: 0.6472
Batch 100, Loss: 0.6302
Batch 110, Loss: 0.6269
Batch 120, Loss: 0.6579
Batch 130, Loss: 0.5967
Batch 140, Loss: 0.6511
Batch 150, Loss: 0.6285
Batch 160, Loss: 0.6411
Batch 170, Loss: 0.6185
Batch 180, Loss: 0.5981
Batch 190, Loss: 0.6397
Batch 200, Loss: 0.6416
Batch 210, Loss: 0.6510
Batch 220, Loss: 0.6475
Batch 230, Loss: 0.6528
Batch 240, Loss: 0.6300
Batch 250, Loss: 0.6651
Batch 260, Loss: 0.6237
Batch 270, Loss: 0.6170
Batch 280, Loss: 0.6309
Batch 290, Loss: 0.6399
Batch 300, Loss: 0.6263
Batch 310, Loss: 0.6320
Batch 320, Loss: 0.6293
Batch 330, Loss: 0.6066
Batch 340, Loss: 0.5836
Batch 350, Loss: 0.6413
Batch 360, Loss: 0.6382
Batch 370, Loss: 0.6574
Batch 380, Loss: 0.6305
Batch 390, Loss: 0.6213
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.014816522598267 seconds
Epoch 21 accuracy: 76.49%
Batch 10, Loss: 0.6561
Batch 20, Loss: 0.6145
Batch 30, Loss: 0.5932
Batch 40, Loss: 0.6084
Batch 50, Loss: 0.6316
Batch 60, Loss: 0.6178
Batch 70, Loss: 0.6028
Batch 80, Loss: 0.6753
Batch 90, Loss: 0.6101
Batch 100, Loss: 0.6342
Batch 110, Loss: 0.5935
Batch 120, Loss: 0.6287
Batch 130, Loss: 0.5958
Batch 140, Loss: 0.6160
Batch 150, Loss: 0.6091
Batch 160, Loss: 0.6221
Batch 170, Loss: 0.6236
Batch 180, Loss: 0.6768
Batch 190, Loss: 0.6432
Batch 200, Loss: 0.6387
Batch 210, Loss: 0.5807
Batch 220, Loss: 0.6312
Batch 230, Loss: 0.5996
Batch 240, Loss: 0.5674
Batch 250, Loss: 0.6204
Batch 260, Loss: 0.6654
Batch 270, Loss: 0.6311
Batch 280, Loss: 0.6128
Batch 290, Loss: 0.5760
Batch 300, Loss: 0.6310
Batch 310, Loss: 0.5906
Batch 320, Loss: 0.6374
Batch 330, Loss: 0.5855
Batch 340, Loss: 0.6077
Batch 350, Loss: 0.6332
Batch 360, Loss: 0.6086
Batch 370, Loss: 0.6322
Batch 380, Loss: 0.6334
Batch 390, Loss: 0.6207
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.062031984329224 seconds
Epoch 22 accuracy: 77.32%
Batch 10, Loss: 0.6189
Batch 20, Loss: 0.6279
Batch 30, Loss: 0.6292
Batch 40, Loss: 0.6048
Batch 50, Loss: 0.6233
Batch 60, Loss: 0.5858
Batch 70, Loss: 0.5979
Batch 80, Loss: 0.6072
Batch 90, Loss: 0.5838
Batch 100, Loss: 0.6070
Batch 110, Loss: 0.6103
Batch 120, Loss: 0.6029
Batch 130, Loss: 0.6032
Batch 140, Loss: 0.5817
Batch 150, Loss: 0.6174
Batch 160, Loss: 0.6269
Batch 170, Loss: 0.6539
Batch 180, Loss: 0.6412
Batch 190, Loss: 0.6095
Batch 200, Loss: 0.5862
Batch 210, Loss: 0.6261
Batch 220, Loss: 0.6097
Batch 230, Loss: 0.6403
Batch 240, Loss: 0.5944
Batch 250, Loss: 0.6031
Batch 260, Loss: 0.5606
Batch 270, Loss: 0.6200
Batch 280, Loss: 0.6222
Batch 290, Loss: 0.5907
Batch 300, Loss: 0.5749
Batch 310, Loss: 0.5874
Batch 320, Loss: 0.6143
Batch 330, Loss: 0.5856
Batch 340, Loss: 0.6129
Batch 350, Loss: 0.6013
Batch 360, Loss: 0.5958
Batch 370, Loss: 0.6473
Batch 380, Loss: 0.6067
Batch 390, Loss: 0.6096
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.00275754928589 seconds
Epoch 23 accuracy: 83.6%
Batch 10, Loss: 0.6030
Batch 20, Loss: 0.6335
Batch 30, Loss: 0.6401
Batch 40, Loss: 0.6084
Batch 50, Loss: 0.6413
Batch 60, Loss: 0.5772
Batch 70, Loss: 0.5799
Batch 80, Loss: 0.5604
Batch 90, Loss: 0.6362
Batch 100, Loss: 0.6477
Batch 110, Loss: 0.6577
Batch 120, Loss: 0.6311
Batch 130, Loss: 0.5976
Batch 140, Loss: 0.5878
Batch 150, Loss: 0.5739
Batch 160, Loss: 0.6184
Batch 170, Loss: 0.6131
Batch 180, Loss: 0.6045
Batch 190, Loss: 0.6100
Batch 200, Loss: 0.5819
Batch 210, Loss: 0.5886
Batch 220, Loss: 0.5764
Batch 230, Loss: 0.5599
Batch 240, Loss: 0.6090
Batch 250, Loss: 0.5638
Batch 260, Loss: 0.6462
Batch 270, Loss: 0.6227
Batch 280, Loss: 0.6086
Batch 290, Loss: 0.6551
Batch 300, Loss: 0.5947
Batch 310, Loss: 0.6241
Batch 320, Loss: 0.6061
Batch 330, Loss: 0.6426
Batch 340, Loss: 0.5862
Batch 350, Loss: 0.6155
Batch 360, Loss: 0.6111
Batch 370, Loss: 0.6043
Batch 380, Loss: 0.6186
Batch 390, Loss: 0.5941
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.053932905197144 seconds
Epoch 24 accuracy: 82.09%
Batch 10, Loss: 0.6193
Batch 20, Loss: 0.6150
Batch 30, Loss: 0.6321
Batch 40, Loss: 0.6021
Batch 50, Loss: 0.6150
Batch 60, Loss: 0.5774
Batch 70, Loss: 0.5894
Batch 80, Loss: 0.6073
Batch 90, Loss: 0.6623
Batch 100, Loss: 0.5745
Batch 110, Loss: 0.5947
Batch 120, Loss: 0.5739
Batch 130, Loss: 0.6076
Batch 140, Loss: 0.6197
Batch 150, Loss: 0.5979
Batch 160, Loss: 0.6155
Batch 170, Loss: 0.5808
Batch 180, Loss: 0.6154
Batch 190, Loss: 0.6274
Batch 200, Loss: 0.5767
Batch 210, Loss: 0.5901
Batch 220, Loss: 0.5862
Batch 230, Loss: 0.5646
Batch 240, Loss: 0.6166
Batch 250, Loss: 0.5776
Batch 260, Loss: 0.5915
Batch 270, Loss: 0.6390
Batch 280, Loss: 0.5900
Batch 290, Loss: 0.5833
Batch 300, Loss: 0.5492
Batch 310, Loss: 0.6104
Batch 320, Loss: 0.5879
Batch 330, Loss: 0.6131
Batch 340, Loss: 0.5890
Batch 350, Loss: 0.5769
Batch 360, Loss: 0.5958
Batch 370, Loss: 0.6051
Batch 380, Loss: 0.5756
Batch 390, Loss: 0.6334
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 24.998138189315796 seconds
Epoch 25 accuracy: 81.13%
Batch 10, Loss: 0.5968
Batch 20, Loss: 0.5687
Batch 30, Loss: 0.5933
Batch 40, Loss: 0.5912
Batch 50, Loss: 0.5906
Batch 60, Loss: 0.5735
Batch 70, Loss: 0.5585
Batch 80, Loss: 0.6347
Batch 90, Loss: 0.6019
Batch 100, Loss: 0.5892
Batch 110, Loss: 0.6089
Batch 120, Loss: 0.5866
Batch 130, Loss: 0.5841
Batch 140, Loss: 0.6387
Batch 150, Loss: 0.5829
Batch 160, Loss: 0.5743
Batch 170, Loss: 0.5811
Batch 180, Loss: 0.5628
Batch 190, Loss: 0.5940
Batch 200, Loss: 0.5840
Batch 210, Loss: 0.6051
Batch 220, Loss: 0.5845
Batch 230, Loss: 0.6222
Batch 240, Loss: 0.6182
Batch 250, Loss: 0.5687
Batch 260, Loss: 0.5781
Batch 270, Loss: 0.6555
Batch 280, Loss: 0.6435
Batch 290, Loss: 0.6027
Batch 300, Loss: 0.5888
Batch 310, Loss: 0.5623
Batch 320, Loss: 0.6485
Batch 330, Loss: 0.5787
Batch 340, Loss: 0.6013
Batch 350, Loss: 0.6320
Batch 360, Loss: 0.6007
Batch 370, Loss: 0.5989
Batch 380, Loss: 0.6012
Batch 390, Loss: 0.6082
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 24.985371112823486 seconds
Epoch 26 accuracy: 82.34%
Batch 10, Loss: 0.5726
Batch 20, Loss: 0.6002
Batch 30, Loss: 0.6265
Batch 40, Loss: 0.6002
Batch 50, Loss: 0.5647
Batch 60, Loss: 0.5896
Batch 70, Loss: 0.6090
Batch 80, Loss: 0.5902
Batch 90, Loss: 0.5678
Batch 100, Loss: 0.5739
Batch 110, Loss: 0.6280
Batch 120, Loss: 0.6032
Batch 130, Loss: 0.5950
Batch 140, Loss: 0.5774
Batch 150, Loss: 0.5531
Batch 160, Loss: 0.6055
Batch 170, Loss: 0.6402
Batch 180, Loss: 0.5878
Batch 190, Loss: 0.5735
Batch 200, Loss: 0.5908
Batch 210, Loss: 0.6036
Batch 220, Loss: 0.5834
Batch 230, Loss: 0.6090
Batch 240, Loss: 0.5660
Batch 250, Loss: 0.5973
Batch 260, Loss: 0.5845
Batch 270, Loss: 0.6126
Batch 280, Loss: 0.6182
Batch 290, Loss: 0.5836
Batch 300, Loss: 0.6382
Batch 310, Loss: 0.6300
Batch 320, Loss: 0.5913
Batch 330, Loss: 0.6162
Batch 340, Loss: 0.5607
Batch 350, Loss: 0.5821
Batch 360, Loss: 0.5678
Batch 370, Loss: 0.5933
Batch 380, Loss: 0.6082
Batch 390, Loss: 0.6260
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 24.994788646697998 seconds
Epoch 27 accuracy: 80.35%
Batch 10, Loss: 0.5693
Batch 20, Loss: 0.6015
Batch 30, Loss: 0.5717
Batch 40, Loss: 0.5431
Batch 50, Loss: 0.5916
Batch 60, Loss: 0.6052
Batch 70, Loss: 0.6115
Batch 80, Loss: 0.5761
Batch 90, Loss: 0.6208
Batch 100, Loss: 0.6153
Batch 110, Loss: 0.5859
Batch 120, Loss: 0.6342
Batch 130, Loss: 0.6068
Batch 140, Loss: 0.5661
Batch 150, Loss: 0.5477
Batch 160, Loss: 0.5963
Batch 170, Loss: 0.5641
Batch 180, Loss: 0.6290
Batch 190, Loss: 0.5886
Batch 200, Loss: 0.5771
Batch 210, Loss: 0.6116
Batch 220, Loss: 0.5753
Batch 230, Loss: 0.6040
Batch 240, Loss: 0.5911
Batch 250, Loss: 0.6051
Batch 260, Loss: 0.6039
Batch 270, Loss: 0.5634
Batch 280, Loss: 0.5639
Batch 290, Loss: 0.5816
Batch 300, Loss: 0.6536
Batch 310, Loss: 0.5843
Batch 320, Loss: 0.5800
Batch 330, Loss: 0.6210
Batch 340, Loss: 0.5894
Batch 350, Loss: 0.5967
Batch 360, Loss: 0.5972
Batch 370, Loss: 0.5883
Batch 380, Loss: 0.5864
Batch 390, Loss: 0.5889
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 24.983655214309692 seconds
Epoch 28 accuracy: 79.58%
Batch 10, Loss: 0.5929
Batch 20, Loss: 0.5994
Batch 30, Loss: 0.5504
Batch 40, Loss: 0.5543
Batch 50, Loss: 0.5540
Batch 60, Loss: 0.5976
Batch 70, Loss: 0.5604
Batch 80, Loss: 0.5412
Batch 90, Loss: 0.5906
Batch 100, Loss: 0.6014
Batch 110, Loss: 0.5788
Batch 120, Loss: 0.5887
Batch 130, Loss: 0.5738
Batch 140, Loss: 0.6326
Batch 150, Loss: 0.5982
Batch 160, Loss: 0.5471
Batch 170, Loss: 0.6171
Batch 180, Loss: 0.5819
Batch 190, Loss: 0.5985
Batch 200, Loss: 0.5751
Batch 210, Loss: 0.5671
Batch 220, Loss: 0.5456
Batch 230, Loss: 0.5547
Batch 240, Loss: 0.5427
Batch 250, Loss: 0.5565
Batch 260, Loss: 0.5677
Batch 270, Loss: 0.6092
Batch 280, Loss: 0.6057
Batch 290, Loss: 0.5773
Batch 300, Loss: 0.5578
Batch 310, Loss: 0.6353
Batch 320, Loss: 0.5995
Batch 330, Loss: 0.6058
Batch 340, Loss: 0.5869
Batch 350, Loss: 0.6311
Batch 360, Loss: 0.5638
Batch 370, Loss: 0.5732
Batch 380, Loss: 0.6054
Batch 390, Loss: 0.5807
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.0215904712677 seconds
Epoch 29 accuracy: 84.42%
Batch 10, Loss: 0.5854
Batch 20, Loss: 0.5494
Batch 30, Loss: 0.6082
Batch 40, Loss: 0.5955
Batch 50, Loss: 0.5781
Batch 60, Loss: 0.5864
Batch 70, Loss: 0.5711
Batch 80, Loss: 0.5590
Batch 90, Loss: 0.5979
Batch 100, Loss: 0.6237
Batch 110, Loss: 0.5901
Batch 120, Loss: 0.5628
Batch 130, Loss: 0.5789
Batch 140, Loss: 0.5551
Batch 150, Loss: 0.5969
Batch 160, Loss: 0.5802
Batch 170, Loss: 0.6118
Batch 180, Loss: 0.5437
Batch 190, Loss: 0.5780
Batch 200, Loss: 0.6029
Batch 210, Loss: 0.5858
Batch 220, Loss: 0.5916
Batch 230, Loss: 0.5718
Batch 240, Loss: 0.5748
Batch 250, Loss: 0.5569
Batch 260, Loss: 0.5773
Batch 270, Loss: 0.6169
Batch 280, Loss: 0.5825
Batch 290, Loss: 0.5649
Batch 300, Loss: 0.5297
Batch 310, Loss: 0.6239
Batch 320, Loss: 0.6010
Batch 330, Loss: 0.5812
Batch 340, Loss: 0.5850
Batch 350, Loss: 0.5742
Batch 360, Loss: 0.5935
Batch 370, Loss: 0.5670
Batch 380, Loss: 0.5660
Batch 390, Loss: 0.6075
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.07682180404663 seconds
Epoch 30 accuracy: 77.99%
Batch 10, Loss: 0.5294
Batch 20, Loss: 0.5540
Batch 30, Loss: 0.5383
Batch 40, Loss: 0.5444
Batch 50, Loss: 0.5557
Batch 60, Loss: 0.5419
Batch 70, Loss: 0.5936
Batch 80, Loss: 0.5813
Batch 90, Loss: 0.6108
Batch 100, Loss: 0.5425
Batch 110, Loss: 0.5844
Batch 120, Loss: 0.6025
Batch 130, Loss: 0.5837
Batch 140, Loss: 0.6200
Batch 150, Loss: 0.6077
Batch 160, Loss: 0.6139
Batch 170, Loss: 0.5548
Batch 180, Loss: 0.5722
Batch 190, Loss: 0.6125
Batch 200, Loss: 0.6094
Batch 210, Loss: 0.6107
Batch 220, Loss: 0.5898
Batch 230, Loss: 0.5791
Batch 240, Loss: 0.5412
Batch 250, Loss: 0.5497
Batch 260, Loss: 0.5685
Batch 270, Loss: 0.6332
Batch 280, Loss: 0.5791
Batch 290, Loss: 0.5848
Batch 300, Loss: 0.5920
Batch 310, Loss: 0.6001
Batch 320, Loss: 0.5649
Batch 330, Loss: 0.5552
Batch 340, Loss: 0.5969
Batch 350, Loss: 0.6007
Batch 360, Loss: 0.5575
Batch 370, Loss: 0.6034
Batch 380, Loss: 0.5796
Batch 390, Loss: 0.5863
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.00076651573181 seconds
Epoch 31 accuracy: 81.63%
Batch 10, Loss: 0.5874
Batch 20, Loss: 0.5652
Batch 30, Loss: 0.5982
Batch 40, Loss: 0.5777
Batch 50, Loss: 0.5556
Batch 60, Loss: 0.5649
Batch 70, Loss: 0.5326
Batch 80, Loss: 0.6091
Batch 90, Loss: 0.5982
Batch 100, Loss: 0.5963
Batch 110, Loss: 0.5482
Batch 120, Loss: 0.6030
Batch 130, Loss: 0.6108
Batch 140, Loss: 0.5700
Batch 150, Loss: 0.5888
Batch 160, Loss: 0.5717
Batch 170, Loss: 0.6109
Batch 180, Loss: 0.6173
Batch 190, Loss: 0.5930
Batch 200, Loss: 0.5595
Batch 210, Loss: 0.5764
Batch 220, Loss: 0.5858
Batch 230, Loss: 0.5836
Batch 240, Loss: 0.6221
Batch 250, Loss: 0.5760
Batch 260, Loss: 0.5463
Batch 270, Loss: 0.5732
Batch 280, Loss: 0.5676
Batch 290, Loss: 0.5757
Batch 300, Loss: 0.5358
Batch 310, Loss: 0.5477
Batch 320, Loss: 0.5426
Batch 330, Loss: 0.5662
Batch 340, Loss: 0.5953
Batch 350, Loss: 0.5873
Batch 360, Loss: 0.5942
Batch 370, Loss: 0.5599
Batch 380, Loss: 0.5368
Batch 390, Loss: 0.5635
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 24.983631134033203 seconds
Epoch 32 accuracy: 80.09%
Batch 10, Loss: 0.5896
Batch 20, Loss: 0.6192
Batch 30, Loss: 0.5794
Batch 40, Loss: 0.5998
Batch 50, Loss: 0.5577
Batch 60, Loss: 0.5693
Batch 70, Loss: 0.5843
Batch 80, Loss: 0.5696
Batch 90, Loss: 0.5372
Batch 100, Loss: 0.5661
Batch 110, Loss: 0.6032
Batch 120, Loss: 0.5709
Batch 130, Loss: 0.5461
Batch 140, Loss: 0.5504
Batch 150, Loss: 0.5950
Batch 160, Loss: 0.5704
Batch 170, Loss: 0.6032
Batch 180, Loss: 0.5703
Batch 190, Loss: 0.5502
Batch 200, Loss: 0.5642
Batch 210, Loss: 0.5932
Batch 220, Loss: 0.6150
Batch 230, Loss: 0.5838
Batch 240, Loss: 0.5493
Batch 250, Loss: 0.5536
Batch 260, Loss: 0.5594
Batch 270, Loss: 0.5836
Batch 280, Loss: 0.5838
Batch 290, Loss: 0.5686
Batch 300, Loss: 0.5709
Batch 310, Loss: 0.5705
Batch 320, Loss: 0.5614
Batch 330, Loss: 0.5806
Batch 340, Loss: 0.5742
Batch 350, Loss: 0.5412
Batch 360, Loss: 0.6013
Batch 370, Loss: 0.5655
Batch 380, Loss: 0.5996
Batch 390, Loss: 0.5565
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.022462368011475 seconds
Epoch 33 accuracy: 80.78%
Batch 10, Loss: 0.6114
Batch 20, Loss: 0.5983
Batch 30, Loss: 0.5798
Batch 40, Loss: 0.5916
Batch 50, Loss: 0.5590
Batch 60, Loss: 0.5785
Batch 70, Loss: 0.5357
Batch 80, Loss: 0.5946
Batch 90, Loss: 0.6102
Batch 100, Loss: 0.5702
Batch 110, Loss: 0.5481
Batch 120, Loss: 0.6147
Batch 130, Loss: 0.5880
Batch 140, Loss: 0.5579
Batch 150, Loss: 0.5449
Batch 160, Loss: 0.5634
Batch 170, Loss: 0.5643
Batch 180, Loss: 0.5840
Batch 190, Loss: 0.5568
Batch 200, Loss: 0.6067
Batch 210, Loss: 0.5986
Batch 220, Loss: 0.5900
Batch 230, Loss: 0.5531
Batch 240, Loss: 0.5603
Batch 250, Loss: 0.5515
Batch 260, Loss: 0.6098
Batch 270, Loss: 0.5795
Batch 280, Loss: 0.5897
Batch 290, Loss: 0.5519
Batch 300, Loss: 0.5301
Batch 310, Loss: 0.5293
Batch 320, Loss: 0.5333
Batch 330, Loss: 0.5677
Batch 340, Loss: 0.5739
Batch 350, Loss: 0.5751
Batch 360, Loss: 0.5731
Batch 370, Loss: 0.5854
Batch 380, Loss: 0.6116
Batch 390, Loss: 0.5751
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.036478996276855 seconds
Epoch 34 accuracy: 81.52%
Batch 10, Loss: 0.5657
Batch 20, Loss: 0.5412
Batch 30, Loss: 0.5987
Batch 40, Loss: 0.6063
Batch 50, Loss: 0.5649
Batch 60, Loss: 0.5529
Batch 70, Loss: 0.5698
Batch 80, Loss: 0.5880
Batch 90, Loss: 0.5474
Batch 100, Loss: 0.6118
Batch 110, Loss: 0.5837
Batch 120, Loss: 0.5732
Batch 130, Loss: 0.5673
Batch 140, Loss: 0.5772
Batch 150, Loss: 0.5724
Batch 160, Loss: 0.5752
Batch 170, Loss: 0.5345
Batch 180, Loss: 0.5426
Batch 190, Loss: 0.5788
Batch 200, Loss: 0.5681
Batch 210, Loss: 0.5626
Batch 220, Loss: 0.5450
Batch 230, Loss: 0.5438
Batch 240, Loss: 0.5722
Batch 250, Loss: 0.5884
Batch 260, Loss: 0.6101
Batch 270, Loss: 0.5354
Batch 280, Loss: 0.5901
Batch 290, Loss: 0.5640
Batch 300, Loss: 0.5446
Batch 310, Loss: 0.5622
Batch 320, Loss: 0.5631
Batch 330, Loss: 0.5478
Batch 340, Loss: 0.5712
Batch 350, Loss: 0.5669
Batch 360, Loss: 0.5230
Batch 370, Loss: 0.6109
Batch 380, Loss: 0.5627
Batch 390, Loss: 0.5767
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.013877153396606 seconds
Epoch 35 accuracy: 83.0%
Batch 10, Loss: 0.5913
Batch 20, Loss: 0.5648
Batch 30, Loss: 0.5584
Batch 40, Loss: 0.5592
Batch 50, Loss: 0.5412
Batch 60, Loss: 0.5498
Batch 70, Loss: 0.5598
Batch 80, Loss: 0.5697
Batch 90, Loss: 0.5741
Batch 100, Loss: 0.5585
Batch 110, Loss: 0.5740
Batch 120, Loss: 0.5768
Batch 130, Loss: 0.5838
Batch 140, Loss: 0.5834
Batch 150, Loss: 0.5653
Batch 160, Loss: 0.5967
Batch 170, Loss: 0.5316
Batch 180, Loss: 0.5379
Batch 190, Loss: 0.5746
Batch 200, Loss: 0.5573
Batch 210, Loss: 0.5644
Batch 220, Loss: 0.5490
Batch 230, Loss: 0.5456
Batch 240, Loss: 0.5776
Batch 250, Loss: 0.5036
Batch 260, Loss: 0.5453
Batch 270, Loss: 0.5846
Batch 280, Loss: 0.5627
Batch 290, Loss: 0.5981
Batch 300, Loss: 0.5509
Batch 310, Loss: 0.5752
Batch 320, Loss: 0.5733
Batch 330, Loss: 0.5235
Batch 340, Loss: 0.5500
Batch 350, Loss: 0.5813
Batch 360, Loss: 0.5900
Batch 370, Loss: 0.5779
Batch 380, Loss: 0.5736
Batch 390, Loss: 0.5747
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.020851612091064 seconds
Epoch 36 accuracy: 80.12%
Batch 10, Loss: 0.5364
Batch 20, Loss: 0.5969
Batch 30, Loss: 0.5728
Batch 40, Loss: 0.5611
Batch 50, Loss: 0.5723
Batch 60, Loss: 0.5692
Batch 70, Loss: 0.5550
Batch 80, Loss: 0.5508
Batch 90, Loss: 0.5451
Batch 100, Loss: 0.5916
Batch 110, Loss: 0.5511
Batch 120, Loss: 0.5859
Batch 130, Loss: 0.5576
Batch 140, Loss: 0.5269
Batch 150, Loss: 0.5262
Batch 160, Loss: 0.5879
Batch 170, Loss: 0.6149
Batch 180, Loss: 0.5974
Batch 190, Loss: 0.5777
Batch 200, Loss: 0.5770
Batch 210, Loss: 0.6264
Batch 220, Loss: 0.5679
Batch 230, Loss: 0.5667
Batch 240, Loss: 0.5313
Batch 250, Loss: 0.5762
Batch 260, Loss: 0.6171
Batch 270, Loss: 0.5835
Batch 280, Loss: 0.5647
Batch 290, Loss: 0.5401
Batch 300, Loss: 0.5984
Batch 310, Loss: 0.5254
Batch 320, Loss: 0.5712
Batch 330, Loss: 0.5148
Batch 340, Loss: 0.5415
Batch 350, Loss: 0.5633
Batch 360, Loss: 0.6006
Batch 370, Loss: 0.5553
Batch 380, Loss: 0.5594
Batch 390, Loss: 0.5617
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 24.979793310165405 seconds
Epoch 37 accuracy: 84.56%
Batch 10, Loss: 0.5618
Batch 20, Loss: 0.5421
Batch 30, Loss: 0.5624
Batch 40, Loss: 0.5667
Batch 50, Loss: 0.5992
Batch 60, Loss: 0.5652
Batch 70, Loss: 0.5366
Batch 80, Loss: 0.5760
Batch 90, Loss: 0.5079
Batch 100, Loss: 0.5661
Batch 110, Loss: 0.5292
Batch 120, Loss: 0.5512
Batch 130, Loss: 0.5544
Batch 140, Loss: 0.5560
Batch 150, Loss: 0.5653
Batch 160, Loss: 0.5650
Batch 170, Loss: 0.5778
Batch 180, Loss: 0.5797
Batch 190, Loss: 0.6092
Batch 200, Loss: 0.5548
Batch 210, Loss: 0.5552
Batch 220, Loss: 0.5551
Batch 230, Loss: 0.5546
Batch 240, Loss: 0.5848
Batch 250, Loss: 0.5426
Batch 260, Loss: 0.5740
Batch 270, Loss: 0.5481
Batch 280, Loss: 0.5486
Batch 290, Loss: 0.5601
Batch 300, Loss: 0.5538
Batch 310, Loss: 0.5708
Batch 320, Loss: 0.5419
Batch 330, Loss: 0.5540
Batch 340, Loss: 0.5423
Batch 350, Loss: 0.5510
Batch 360, Loss: 0.5681
Batch 370, Loss: 0.5843
Batch 380, Loss: 0.5749
Batch 390, Loss: 0.5899
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 24.972453117370605 seconds
Epoch 38 accuracy: 83.29%
Batch 10, Loss: 0.5682
Batch 20, Loss: 0.5501
Batch 30, Loss: 0.5620
Batch 40, Loss: 0.5659
Batch 50, Loss: 0.5649
Batch 60, Loss: 0.5531
Batch 70, Loss: 0.5681
Batch 80, Loss: 0.5435
Batch 90, Loss: 0.5889
Batch 100, Loss: 0.5797
Batch 110, Loss: 0.5429
Batch 120, Loss: 0.5705
Batch 130, Loss: 0.5717
Batch 140, Loss: 0.5488
Batch 150, Loss: 0.5799
Batch 160, Loss: 0.5805
Batch 170, Loss: 0.5747
Batch 180, Loss: 0.5321
Batch 190, Loss: 0.5813
Batch 200, Loss: 0.5662
Batch 210, Loss: 0.5616
Batch 220, Loss: 0.5587
Batch 230, Loss: 0.5742
Batch 240, Loss: 0.5919
Batch 250, Loss: 0.5653
Batch 260, Loss: 0.5652
Batch 270, Loss: 0.5805
Batch 280, Loss: 0.5612
Batch 290, Loss: 0.5673
Batch 300, Loss: 0.5709
Batch 310, Loss: 0.5241
Batch 320, Loss: 0.5492
Batch 330, Loss: 0.5849
Batch 340, Loss: 0.5729
Batch 350, Loss: 0.6014
Batch 360, Loss: 0.5776
Batch 370, Loss: 0.6021
Batch 380, Loss: 0.5776
Batch 390, Loss: 0.5234
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.05046558380127 seconds
Epoch 39 accuracy: 77.39%
Batch 10, Loss: 0.5468
Batch 20, Loss: 0.5593
Batch 30, Loss: 0.5371
Batch 40, Loss: 0.5180
Batch 50, Loss: 0.5732
Batch 60, Loss: 0.5348
Batch 70, Loss: 0.5682
Batch 80, Loss: 0.6048
Batch 90, Loss: 0.5514
Batch 100, Loss: 0.5480
Batch 110, Loss: 0.5814
Batch 120, Loss: 0.5570
Batch 130, Loss: 0.5623
Batch 140, Loss: 0.5798
Batch 150, Loss: 0.5300
Batch 160, Loss: 0.5107
Batch 170, Loss: 0.5752
Batch 180, Loss: 0.5800
Batch 190, Loss: 0.5817
Batch 200, Loss: 0.5600
Batch 210, Loss: 0.5673
Batch 220, Loss: 0.5768
Batch 230, Loss: 0.5377
Batch 240, Loss: 0.5380
Batch 250, Loss: 0.4992
Batch 260, Loss: 0.5406
Batch 270, Loss: 0.5657
Batch 280, Loss: 0.5677
Batch 290, Loss: 0.5716
Batch 300, Loss: 0.5611
Batch 310, Loss: 0.5803
Batch 320, Loss: 0.5899
Batch 330, Loss: 0.5639
Batch 340, Loss: 0.5699
Batch 350, Loss: 0.5199
Batch 360, Loss: 0.5857
Batch 370, Loss: 0.5442
Batch 380, Loss: 0.5070
Batch 390, Loss: 0.5555
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 24.967817068099976 seconds
Epoch 40 accuracy: 83.29%
Batch 10, Loss: 0.5771
Batch 20, Loss: 0.5566
Batch 30, Loss: 0.5496
Batch 40, Loss: 0.6094
Batch 50, Loss: 0.5434
Batch 60, Loss: 0.5645
Batch 70, Loss: 0.5515
Batch 80, Loss: 0.5600
Batch 90, Loss: 0.5364
Batch 100, Loss: 0.5800
Batch 110, Loss: 0.5503
Batch 120, Loss: 0.5304
Batch 130, Loss: 0.5909
Batch 140, Loss: 0.5555
Batch 150, Loss: 0.5825
Batch 160, Loss: 0.5887
Batch 170, Loss: 0.5306
Batch 180, Loss: 0.5441
Batch 190, Loss: 0.5613
Batch 200, Loss: 0.5363
Batch 210, Loss: 0.5815
Batch 220, Loss: 0.5580
Batch 230, Loss: 0.5496
Batch 240, Loss: 0.5725
Batch 250, Loss: 0.5725
Batch 260, Loss: 0.5615
Batch 270, Loss: 0.5942
Batch 280, Loss: 0.6175
Batch 290, Loss: 0.5394
Batch 300, Loss: 0.5506
Batch 310, Loss: 0.5652
Batch 320, Loss: 0.5433
Batch 330, Loss: 0.5734
Batch 340, Loss: 0.5299
Batch 350, Loss: 0.5610
Batch 360, Loss: 0.5544
Batch 370, Loss: 0.5338
Batch 380, Loss: 0.5526
Batch 390, Loss: 0.5633
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.03486180305481 seconds
Epoch 41 accuracy: 81.3%
Batch 10, Loss: 0.5477
Batch 20, Loss: 0.5559
Batch 30, Loss: 0.5636
Batch 40, Loss: 0.5618
Batch 50, Loss: 0.5076
Batch 60, Loss: 0.5855
Batch 70, Loss: 0.5571
Batch 80, Loss: 0.5774
Batch 90, Loss: 0.5466
Batch 100, Loss: 0.5496
Batch 110, Loss: 0.5779
Batch 120, Loss: 0.5386
Batch 130, Loss: 0.5310
Batch 140, Loss: 0.5302
Batch 150, Loss: 0.5582
Batch 160, Loss: 0.5149
Batch 170, Loss: 0.5664
Batch 180, Loss: 0.5901
Batch 190, Loss: 0.5172
Batch 200, Loss: 0.5593
Batch 210, Loss: 0.5805
Batch 220, Loss: 0.5710
Batch 230, Loss: 0.5258
Batch 240, Loss: 0.5514
Batch 250, Loss: 0.5654
Batch 260, Loss: 0.6061
Batch 270, Loss: 0.6035
Batch 280, Loss: 0.5605
Batch 290, Loss: 0.6034
Batch 300, Loss: 0.5799
Batch 310, Loss: 0.5356
Batch 320, Loss: 0.5654
Batch 330, Loss: 0.5693
Batch 340, Loss: 0.5632
Batch 350, Loss: 0.5562
Batch 360, Loss: 0.5230
Batch 370, Loss: 0.5704
Batch 380, Loss: 0.5309
Batch 390, Loss: 0.5651
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.01425004005432 seconds
Epoch 42 accuracy: 87.05%
Batch 10, Loss: 0.5311
Batch 20, Loss: 0.5677
Batch 30, Loss: 0.5283
Batch 40, Loss: 0.5927
Batch 50, Loss: 0.5899
Batch 60, Loss: 0.5183
Batch 70, Loss: 0.5254
Batch 80, Loss: 0.5668
Batch 90, Loss: 0.5460
Batch 100, Loss: 0.5404
Batch 110, Loss: 0.5482
Batch 120, Loss: 0.5720
Batch 130, Loss: 0.5118
Batch 140, Loss: 0.5493
Batch 150, Loss: 0.5438
Batch 160, Loss: 0.5573
Batch 170, Loss: 0.5314
Batch 180, Loss: 0.5511
Batch 190, Loss: 0.5607
Batch 200, Loss: 0.5701
Batch 210, Loss: 0.5445
Batch 220, Loss: 0.5862
Batch 230, Loss: 0.5376
Batch 240, Loss: 0.5630
Batch 250, Loss: 0.5945
Batch 260, Loss: 0.5380
Batch 270, Loss: 0.5381
Batch 280, Loss: 0.5815
Batch 290, Loss: 0.5823
Batch 300, Loss: 0.5486
Batch 310, Loss: 0.5310
Batch 320, Loss: 0.5778
Batch 330, Loss: 0.5825
Batch 340, Loss: 0.5891
Batch 350, Loss: 0.5206
Batch 360, Loss: 0.5418
Batch 370, Loss: 0.5616
Batch 380, Loss: 0.5585
Batch 390, Loss: 0.5691
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.0556640625 seconds
Epoch 43 accuracy: 82.11%
Batch 10, Loss: 0.5563
Batch 20, Loss: 0.5690
Batch 30, Loss: 0.5402
Batch 40, Loss: 0.5671
Batch 50, Loss: 0.5418
Batch 60, Loss: 0.5579
Batch 70, Loss: 0.5652
Batch 80, Loss: 0.5064
Batch 90, Loss: 0.5837
Batch 100, Loss: 0.5546
Batch 110, Loss: 0.5445
Batch 120, Loss: 0.4986
Batch 130, Loss: 0.5302
Batch 140, Loss: 0.5387
Batch 150, Loss: 0.4762
Batch 160, Loss: 0.6013
Batch 170, Loss: 0.5672
Batch 180, Loss: 0.5968
Batch 190, Loss: 0.5592
Batch 200, Loss: 0.5327
Batch 210, Loss: 0.4992
Batch 220, Loss: 0.5134
Batch 230, Loss: 0.6088
Batch 240, Loss: 0.5559
Batch 250, Loss: 0.5501
Batch 260, Loss: 0.5361
Batch 270, Loss: 0.5383
Batch 280, Loss: 0.5398
Batch 290, Loss: 0.5465
Batch 300, Loss: 0.5351
Batch 310, Loss: 0.5298
Batch 320, Loss: 0.5624
Batch 330, Loss: 0.5898
Batch 340, Loss: 0.5541
Batch 350, Loss: 0.5379
Batch 360, Loss: 0.5529
Batch 370, Loss: 0.5641
Batch 380, Loss: 0.5358
Batch 390, Loss: 0.5440
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.04560422897339 seconds
Epoch 44 accuracy: 85.03%
Batch 10, Loss: 0.5372
Batch 20, Loss: 0.5032
Batch 30, Loss: 0.5487
Batch 40, Loss: 0.5271
Batch 50, Loss: 0.5452
Batch 60, Loss: 0.5576
Batch 70, Loss: 0.5561
Batch 80, Loss: 0.5878
Batch 90, Loss: 0.5658
Batch 100, Loss: 0.5312
Batch 110, Loss: 0.5649
Batch 120, Loss: 0.5468
Batch 130, Loss: 0.5284
Batch 140, Loss: 0.5561
Batch 150, Loss: 0.5304
Batch 160, Loss: 0.5248
Batch 170, Loss: 0.5549
Batch 180, Loss: 0.5461
Batch 190, Loss: 0.5309
Batch 200, Loss: 0.5257
Batch 210, Loss: 0.5284
Batch 220, Loss: 0.5380
Batch 230, Loss: 0.5250
Batch 240, Loss: 0.5703
Batch 250, Loss: 0.5329
Batch 260, Loss: 0.5339
Batch 270, Loss: 0.5287
Batch 280, Loss: 0.6015
Batch 290, Loss: 0.5490
Batch 300, Loss: 0.4894
Batch 310, Loss: 0.5512
Batch 320, Loss: 0.5035
Batch 330, Loss: 0.5354
Batch 340, Loss: 0.5502
Batch 350, Loss: 0.5739
Batch 360, Loss: 0.5879
Batch 370, Loss: 0.5755
Batch 380, Loss: 0.5344
Batch 390, Loss: 0.5308
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.013242721557617 seconds
Epoch 45 accuracy: 85.3%
Batch 10, Loss: 0.5883
Batch 20, Loss: 0.5822
Batch 30, Loss: 0.5417
Batch 40, Loss: 0.5382
Batch 50, Loss: 0.5332
Batch 60, Loss: 0.5368
Batch 70, Loss: 0.5054
Batch 80, Loss: 0.5311
Batch 90, Loss: 0.5771
Batch 100, Loss: 0.5730
Batch 110, Loss: 0.5520
Batch 120, Loss: 0.5448
Batch 130, Loss: 0.5460
Batch 140, Loss: 0.5545
Batch 150, Loss: 0.5154
Batch 160, Loss: 0.5263
Batch 170, Loss: 0.5798
Batch 180, Loss: 0.5594
Batch 190, Loss: 0.5050
Batch 200, Loss: 0.5698
Batch 210, Loss: 0.5642
Batch 220, Loss: 0.5177
Batch 230, Loss: 0.5085
Batch 240, Loss: 0.5209
Batch 250, Loss: 0.5478
Batch 260, Loss: 0.5323
Batch 270, Loss: 0.5644
Batch 280, Loss: 0.5556
Batch 290, Loss: 0.5380
Batch 300, Loss: 0.5559
Batch 310, Loss: 0.5645
Batch 320, Loss: 0.5623
Batch 330, Loss: 0.5275
Batch 340, Loss: 0.5730
Batch 350, Loss: 0.5912
Batch 360, Loss: 0.5169
Batch 370, Loss: 0.4989
Batch 380, Loss: 0.5369
Batch 390, Loss: 0.5655
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 24.970977306365967 seconds
Epoch 46 accuracy: 82.61%
Batch 10, Loss: 0.5619
Batch 20, Loss: 0.5249
Batch 30, Loss: 0.5338
Batch 40, Loss: 0.5539
Batch 50, Loss: 0.5722
Batch 60, Loss: 0.5642
Batch 70, Loss: 0.5277
Batch 80, Loss: 0.4942
Batch 90, Loss: 0.5136
Batch 100, Loss: 0.5740
Batch 110, Loss: 0.5635
Batch 120, Loss: 0.5168
Batch 130, Loss: 0.5676
Batch 140, Loss: 0.5278
Batch 150, Loss: 0.5197
Batch 160, Loss: 0.5413
Batch 170, Loss: 0.5487
Batch 180, Loss: 0.5581
Batch 190, Loss: 0.5437
Batch 200, Loss: 0.5399
Batch 210, Loss: 0.5680
Batch 220, Loss: 0.5300
Batch 230, Loss: 0.5269
Batch 240, Loss: 0.5506
Batch 250, Loss: 0.5869
Batch 260, Loss: 0.5272
Batch 270, Loss: 0.5689
Batch 280, Loss: 0.5775
Batch 290, Loss: 0.5604
Batch 300, Loss: 0.5652
Batch 310, Loss: 0.6004
Batch 320, Loss: 0.5579
Batch 330, Loss: 0.5209
Batch 340, Loss: 0.5429
Batch 350, Loss: 0.5945
Batch 360, Loss: 0.5421
Batch 370, Loss: 0.5767
Batch 380, Loss: 0.5541
Batch 390, Loss: 0.5174
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.03592038154602 seconds
Epoch 47 accuracy: 79.84%
Batch 10, Loss: 0.5643
Batch 20, Loss: 0.5068
Batch 30, Loss: 0.5104
Batch 40, Loss: 0.5544
Batch 50, Loss: 0.5536
Batch 60, Loss: 0.5317
Batch 70, Loss: 0.5022
Batch 80, Loss: 0.5129
Batch 90, Loss: 0.5745
Batch 100, Loss: 0.5401
Batch 110, Loss: 0.5307
Batch 120, Loss: 0.5406
Batch 130, Loss: 0.5471
Batch 140, Loss: 0.5512
Batch 150, Loss: 0.5504
Batch 160, Loss: 0.5457
Batch 170, Loss: 0.5193
Batch 180, Loss: 0.5420
Batch 190, Loss: 0.5540
Batch 200, Loss: 0.5102
Batch 210, Loss: 0.5108
Batch 220, Loss: 0.5388
Batch 230, Loss: 0.5018
Batch 240, Loss: 0.5810
Batch 250, Loss: 0.5692
Batch 260, Loss: 0.5501
Batch 270, Loss: 0.5527
Batch 280, Loss: 0.5435
Batch 290, Loss: 0.4995
Batch 300, Loss: 0.5522
Batch 310, Loss: 0.5410
Batch 320, Loss: 0.5182
Batch 330, Loss: 0.5472
Batch 340, Loss: 0.5423
Batch 350, Loss: 0.5549
Batch 360, Loss: 0.5636
Batch 370, Loss: 0.5910
Batch 380, Loss: 0.5189
Batch 390, Loss: 0.5370
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.03956627845764 seconds
Epoch 48 accuracy: 85.83%
Batch 10, Loss: 0.5407
Batch 20, Loss: 0.5427
Batch 30, Loss: 0.5122
Batch 40, Loss: 0.5323
Batch 50, Loss: 0.5584
Batch 60, Loss: 0.5224
Batch 70, Loss: 0.5702
Batch 80, Loss: 0.5143
Batch 90, Loss: 0.5199
Batch 100, Loss: 0.5526
Batch 110, Loss: 0.5532
Batch 120, Loss: 0.5307
Batch 130, Loss: 0.5420
Batch 140, Loss: 0.5306
Batch 150, Loss: 0.5617
Batch 160, Loss: 0.5518
Batch 170, Loss: 0.5403
Batch 180, Loss: 0.5253
Batch 190, Loss: 0.5468
Batch 200, Loss: 0.5102
Batch 210, Loss: 0.5469
Batch 220, Loss: 0.5374
Batch 230, Loss: 0.5575
Batch 240, Loss: 0.5080
Batch 250, Loss: 0.5367
Batch 260, Loss: 0.5163
Batch 270, Loss: 0.5367
Batch 280, Loss: 0.5533
Batch 290, Loss: 0.5666
Batch 300, Loss: 0.5193
Batch 310, Loss: 0.5589
Batch 320, Loss: 0.5150
Batch 330, Loss: 0.5568
Batch 340, Loss: 0.5862
Batch 350, Loss: 0.5290
Batch 360, Loss: 0.5487
Batch 370, Loss: 0.5247
Batch 380, Loss: 0.5918
Batch 390, Loss: 0.5190
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 24.961446523666382 seconds
Epoch 49 accuracy: 82.44%
Batch 10, Loss: 0.5185
Batch 20, Loss: 0.5730
Batch 30, Loss: 0.5447
Batch 40, Loss: 0.5104
Batch 50, Loss: 0.5191
Batch 60, Loss: 0.5393
Batch 70, Loss: 0.5333
Batch 80, Loss: 0.5481
Batch 90, Loss: 0.5422
Batch 100, Loss: 0.5483
Batch 110, Loss: 0.5572
Batch 120, Loss: 0.5599
Batch 130, Loss: 0.5321
Batch 140, Loss: 0.5276
Batch 150, Loss: 0.5530
Batch 160, Loss: 0.5770
Batch 170, Loss: 0.5392
Batch 180, Loss: 0.5685
Batch 190, Loss: 0.5520
Batch 200, Loss: 0.5269
Batch 210, Loss: 0.5189
Batch 220, Loss: 0.5277
Batch 230, Loss: 0.5387
Batch 240, Loss: 0.5115
Batch 250, Loss: 0.5209
Batch 260, Loss: 0.5727
Batch 270, Loss: 0.5819
Batch 280, Loss: 0.5355
Batch 290, Loss: 0.5508
Batch 300, Loss: 0.5643
Batch 310, Loss: 0.5400
Batch 320, Loss: 0.5263
Batch 330, Loss: 0.4902
Batch 340, Loss: 0.5684
Batch 350, Loss: 0.5336
Batch 360, Loss: 0.5577
Batch 370, Loss: 0.5578
Batch 380, Loss: 0.5203
Batch 390, Loss: 0.5636
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.01999568939209 seconds
Epoch 50 accuracy: 85.45%
Batch 10, Loss: 0.5111
Batch 20, Loss: 0.5755
Batch 30, Loss: 0.5130
Batch 40, Loss: 0.5201
Batch 50, Loss: 0.5037
Batch 60, Loss: 0.5142
Batch 70, Loss: 0.5137
Batch 80, Loss: 0.5191
Batch 90, Loss: 0.5685
Batch 100, Loss: 0.5724
Batch 110, Loss: 0.5756
Batch 120, Loss: 0.5778
Batch 130, Loss: 0.5767
Batch 140, Loss: 0.5233
Batch 150, Loss: 0.4969
Batch 160, Loss: 0.5586
Batch 170, Loss: 0.5128
Batch 180, Loss: 0.5190
Batch 190, Loss: 0.5478
Batch 200, Loss: 0.5304
Batch 210, Loss: 0.5439
Batch 220, Loss: 0.4981
Batch 230, Loss: 0.5386
Batch 240, Loss: 0.5671
Batch 250, Loss: 0.5536
Batch 260, Loss: 0.5049
Batch 270, Loss: 0.5160
Batch 280, Loss: 0.5424
Batch 290, Loss: 0.5309
Batch 300, Loss: 0.5242
Batch 310, Loss: 0.5149
Batch 320, Loss: 0.5574
Batch 330, Loss: 0.5784
Batch 340, Loss: 0.5693
Batch 350, Loss: 0.5473
Batch 360, Loss: 0.5620
Batch 370, Loss: 0.5496
Batch 380, Loss: 0.5608
Batch 390, Loss: 0.5337
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.013049125671387 seconds
Epoch 51 accuracy: 82.19%
Batch 10, Loss: 0.5486
Batch 20, Loss: 0.5239
Batch 30, Loss: 0.5055
Batch 40, Loss: 0.5589
Batch 50, Loss: 0.5808
Batch 60, Loss: 0.5520
Batch 70, Loss: 0.5638
Batch 80, Loss: 0.5093
Batch 90, Loss: 0.4898
Batch 100, Loss: 0.5331
Batch 110, Loss: 0.5491
Batch 120, Loss: 0.5278
Batch 130, Loss: 0.5465
Batch 140, Loss: 0.5647
Batch 150, Loss: 0.5082
Batch 160, Loss: 0.5313
Batch 170, Loss: 0.5351
Batch 180, Loss: 0.5324
Batch 190, Loss: 0.5607
Batch 200, Loss: 0.5724
Batch 210, Loss: 0.5226
Batch 220, Loss: 0.5584
Batch 230, Loss: 0.5430
Batch 240, Loss: 0.5898
Batch 250, Loss: 0.5121
Batch 260, Loss: 0.5064
Batch 270, Loss: 0.5749
Batch 280, Loss: 0.5456
Batch 290, Loss: 0.5617
Batch 300, Loss: 0.5160
Batch 310, Loss: 0.5178
Batch 320, Loss: 0.5380
Batch 330, Loss: 0.5350
Batch 340, Loss: 0.5397
Batch 350, Loss: 0.5125
Batch 360, Loss: 0.5415
Batch 370, Loss: 0.5233
Batch 380, Loss: 0.5294
Batch 390, Loss: 0.5590
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 24.985601902008057 seconds
Epoch 52 accuracy: 85.94%
Batch 10, Loss: 0.5447
Batch 20, Loss: 0.5178
Batch 30, Loss: 0.5005
Batch 40, Loss: 0.5427
Batch 50, Loss: 0.5241
Batch 60, Loss: 0.5143
Batch 70, Loss: 0.5454
Batch 80, Loss: 0.5196
Batch 90, Loss: 0.5141
Batch 100, Loss: 0.5327
Batch 110, Loss: 0.5528
Batch 120, Loss: 0.5626
Batch 130, Loss: 0.5614
Batch 140, Loss: 0.5251
Batch 150, Loss: 0.5449
Batch 160, Loss: 0.5361
Batch 170, Loss: 0.5389
Batch 180, Loss: 0.5617
Batch 190, Loss: 0.5646
Batch 200, Loss: 0.5435
Batch 210, Loss: 0.4865
Batch 220, Loss: 0.5246
Batch 230, Loss: 0.4995
Batch 240, Loss: 0.5453
Batch 250, Loss: 0.5440
Batch 260, Loss: 0.5426
Batch 270, Loss: 0.5389
Batch 280, Loss: 0.5248
Batch 290, Loss: 0.5098
Batch 300, Loss: 0.4996
Batch 310, Loss: 0.5236
Batch 320, Loss: 0.5423
Batch 330, Loss: 0.5755
Batch 340, Loss: 0.5487
Batch 350, Loss: 0.5265
Batch 360, Loss: 0.5084
Batch 370, Loss: 0.5232
Batch 380, Loss: 0.5795
Batch 390, Loss: 0.5177
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 24.955165147781372 seconds
Epoch 53 accuracy: 82.87%
Batch 10, Loss: 0.5013
Batch 20, Loss: 0.5387
Batch 30, Loss: 0.5053
Batch 40, Loss: 0.4928
Batch 50, Loss: 0.5338
Batch 60, Loss: 0.5097
Batch 70, Loss: 0.5179
Batch 80, Loss: 0.5620
Batch 90, Loss: 0.5064
Batch 100, Loss: 0.5316
Batch 110, Loss: 0.5050
Batch 120, Loss: 0.5487
Batch 130, Loss: 0.5218
Batch 140, Loss: 0.5557
Batch 150, Loss: 0.5639
Batch 160, Loss: 0.5149
Batch 170, Loss: 0.5583
Batch 180, Loss: 0.5449
Batch 190, Loss: 0.5328
Batch 200, Loss: 0.5355
Batch 210, Loss: 0.5622
Batch 220, Loss: 0.5455
Batch 230, Loss: 0.5548
Batch 240, Loss: 0.5079
Batch 250, Loss: 0.4918
Batch 260, Loss: 0.5349
Batch 270, Loss: 0.5286
Batch 280, Loss: 0.5274
Batch 290, Loss: 0.5264
Batch 300, Loss: 0.5279
Batch 310, Loss: 0.5178
Batch 320, Loss: 0.4965
Batch 330, Loss: 0.5119
Batch 340, Loss: 0.5723
Batch 350, Loss: 0.5633
Batch 360, Loss: 0.5238
Batch 370, Loss: 0.5268
Batch 380, Loss: 0.4989
Batch 390, Loss: 0.5214
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 24.99434804916382 seconds
Epoch 54 accuracy: 84.12%
Batch 10, Loss: 0.5058
Batch 20, Loss: 0.5356
Batch 30, Loss: 0.4956
Batch 40, Loss: 0.5385
Batch 50, Loss: 0.5157
Batch 60, Loss: 0.5533
Batch 70, Loss: 0.5480
Batch 80, Loss: 0.5565
Batch 90, Loss: 0.5392
Batch 100, Loss: 0.5391
Batch 110, Loss: 0.4811
Batch 120, Loss: 0.5437
Batch 130, Loss: 0.5296
Batch 140, Loss: 0.5019
Batch 150, Loss: 0.5185
Batch 160, Loss: 0.5678
Batch 170, Loss: 0.4978
Batch 180, Loss: 0.5479
Batch 190, Loss: 0.5288
Batch 200, Loss: 0.5118
Batch 210, Loss: 0.5066
Batch 220, Loss: 0.5103
Batch 230, Loss: 0.5336
Batch 240, Loss: 0.5177
Batch 250, Loss: 0.5104
Batch 260, Loss: 0.5111
Batch 270, Loss: 0.5734
Batch 280, Loss: 0.6137
Batch 290, Loss: 0.5587
Batch 300, Loss: 0.5398
Batch 310, Loss: 0.5336
Batch 320, Loss: 0.5917
Batch 330, Loss: 0.5031
Batch 340, Loss: 0.5011
Batch 350, Loss: 0.5416
Batch 360, Loss: 0.5393
Batch 370, Loss: 0.5217
Batch 380, Loss: 0.5171
Batch 390, Loss: 0.5148
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.003319263458252 seconds
Epoch 55 accuracy: 84.56%
Batch 10, Loss: 0.5204
Batch 20, Loss: 0.4779
Batch 30, Loss: 0.5072
Batch 40, Loss: 0.5222
Batch 50, Loss: 0.5364
Batch 60, Loss: 0.5503
Batch 70, Loss: 0.5549
Batch 80, Loss: 0.4899
Batch 90, Loss: 0.5448
Batch 100, Loss: 0.5534
Batch 110, Loss: 0.4797
Batch 120, Loss: 0.5235
Batch 130, Loss: 0.4984
Batch 140, Loss: 0.5005
Batch 150, Loss: 0.4919
Batch 160, Loss: 0.4819
Batch 170, Loss: 0.5368
Batch 180, Loss: 0.5410
Batch 190, Loss: 0.5237
Batch 200, Loss: 0.5491
Batch 210, Loss: 0.5646
Batch 220, Loss: 0.5403
Batch 230, Loss: 0.5258
Batch 240, Loss: 0.5518
Batch 250, Loss: 0.4948
Batch 260, Loss: 0.5380
Batch 270, Loss: 0.5306
Batch 280, Loss: 0.5062
Batch 290, Loss: 0.5518
Batch 300, Loss: 0.5262
Batch 310, Loss: 0.5570
Batch 320, Loss: 0.5258
Batch 330, Loss: 0.5466
Batch 340, Loss: 0.5309
Batch 350, Loss: 0.5012
Batch 360, Loss: 0.5476
Batch 370, Loss: 0.5256
Batch 380, Loss: 0.5573
Batch 390, Loss: 0.5341
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.019537210464478 seconds
Epoch 56 accuracy: 83.87%
Batch 10, Loss: 0.5160
Batch 20, Loss: 0.5468
Batch 30, Loss: 0.4896
Batch 40, Loss: 0.5274
Batch 50, Loss: 0.5225
Batch 60, Loss: 0.5502
Batch 70, Loss: 0.5351
Batch 80, Loss: 0.5318
Batch 90, Loss: 0.5330
Batch 100, Loss: 0.5348
Batch 110, Loss: 0.5224
Batch 120, Loss: 0.5318
Batch 130, Loss: 0.5323
Batch 140, Loss: 0.5094
Batch 150, Loss: 0.5526
Batch 160, Loss: 0.5022
Batch 170, Loss: 0.5249
Batch 180, Loss: 0.5419
Batch 190, Loss: 0.5427
Batch 200, Loss: 0.5271
Batch 210, Loss: 0.5498
Batch 220, Loss: 0.5662
Batch 230, Loss: 0.5225
Batch 240, Loss: 0.5485
Batch 250, Loss: 0.5279
Batch 260, Loss: 0.5186
Batch 270, Loss: 0.4943
Batch 280, Loss: 0.5072
Batch 290, Loss: 0.5402
Batch 300, Loss: 0.5120
Batch 310, Loss: 0.5436
Batch 320, Loss: 0.5339
Batch 330, Loss: 0.4778
Batch 340, Loss: 0.5402
Batch 350, Loss: 0.5026
Batch 360, Loss: 0.5262
Batch 370, Loss: 0.4998
Batch 380, Loss: 0.4854
Batch 390, Loss: 0.5376
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.002195596694946 seconds
Epoch 57 accuracy: 83.48%
Batch 10, Loss: 0.5502
Batch 20, Loss: 0.5478
Batch 30, Loss: 0.5447
Batch 40, Loss: 0.5032
Batch 50, Loss: 0.5124
Batch 60, Loss: 0.5295
Batch 70, Loss: 0.4979
Batch 80, Loss: 0.5260
Batch 90, Loss: 0.5268
Batch 100, Loss: 0.5256
Batch 110, Loss: 0.5044
Batch 120, Loss: 0.5196
Batch 130, Loss: 0.5429
Batch 140, Loss: 0.5211
Batch 150, Loss: 0.5286
Batch 160, Loss: 0.5668
Batch 170, Loss: 0.5503
Batch 180, Loss: 0.5168
Batch 190, Loss: 0.5432
Batch 200, Loss: 0.5828
Batch 210, Loss: 0.4947
Batch 220, Loss: 0.5158
Batch 230, Loss: 0.5317
Batch 240, Loss: 0.5319
Batch 250, Loss: 0.5098
Batch 260, Loss: 0.5177
Batch 270, Loss: 0.5180
Batch 280, Loss: 0.5532
Batch 290, Loss: 0.5071
Batch 300, Loss: 0.5103
Batch 310, Loss: 0.5423
Batch 320, Loss: 0.5475
Batch 330, Loss: 0.5334
Batch 340, Loss: 0.5701
Batch 350, Loss: 0.5252
Batch 360, Loss: 0.5194
Batch 370, Loss: 0.5362
Batch 380, Loss: 0.5109
Batch 390, Loss: 0.5204
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.0819149017334 seconds
Epoch 58 accuracy: 84.61%
Batch 10, Loss: 0.5422
Batch 20, Loss: 0.5004
Batch 30, Loss: 0.5134
Batch 40, Loss: 0.4833
Batch 50, Loss: 0.4875
Batch 60, Loss: 0.5148
Batch 70, Loss: 0.4837
Batch 80, Loss: 0.5122
Batch 90, Loss: 0.5379
Batch 100, Loss: 0.5036
Batch 110, Loss: 0.4910
Batch 120, Loss: 0.5021
Batch 130, Loss: 0.5109
Batch 140, Loss: 0.5327
Batch 150, Loss: 0.5749
Batch 160, Loss: 0.5363
Batch 170, Loss: 0.5176
Batch 180, Loss: 0.4876
Batch 190, Loss: 0.4542
Batch 200, Loss: 0.5372
Batch 210, Loss: 0.5280
Batch 220, Loss: 0.5510
Batch 230, Loss: 0.5722
Batch 240, Loss: 0.5180
Batch 250, Loss: 0.5122
Batch 260, Loss: 0.5331
Batch 270, Loss: 0.5272
Batch 280, Loss: 0.5379
Batch 290, Loss: 0.4654
Batch 300, Loss: 0.5129
Batch 310, Loss: 0.5263
Batch 320, Loss: 0.5480
Batch 330, Loss: 0.5197
Batch 340, Loss: 0.5250
Batch 350, Loss: 0.5124
Batch 360, Loss: 0.4951
Batch 370, Loss: 0.5403
Batch 380, Loss: 0.5235
Batch 390, Loss: 0.5385
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.021914958953857 seconds
Epoch 59 accuracy: 83.22%
Batch 10, Loss: 0.5542
Batch 20, Loss: 0.4872
Batch 30, Loss: 0.5759
Batch 40, Loss: 0.5452
Batch 50, Loss: 0.4931
Batch 60, Loss: 0.5101
Batch 70, Loss: 0.5189
Batch 80, Loss: 0.4858
Batch 90, Loss: 0.5162
Batch 100, Loss: 0.5260
Batch 110, Loss: 0.5033
Batch 120, Loss: 0.5278
Batch 130, Loss: 0.5161
Batch 140, Loss: 0.5032
Batch 150, Loss: 0.5148
Batch 160, Loss: 0.5179
Batch 170, Loss: 0.5308
Batch 180, Loss: 0.5302
Batch 190, Loss: 0.5483
Batch 200, Loss: 0.5582
Batch 210, Loss: 0.5328
Batch 220, Loss: 0.5189
Batch 230, Loss: 0.5531
Batch 240, Loss: 0.5322
Batch 250, Loss: 0.4633
Batch 260, Loss: 0.4838
Batch 270, Loss: 0.5108
Batch 280, Loss: 0.5425
Batch 290, Loss: 0.5149
Batch 300, Loss: 0.4986
Batch 310, Loss: 0.4976
Batch 320, Loss: 0.4984
Batch 330, Loss: 0.5120
Batch 340, Loss: 0.5462
Batch 350, Loss: 0.5086
Batch 360, Loss: 0.5062
Batch 370, Loss: 0.5520
Batch 380, Loss: 0.5585
Batch 390, Loss: 0.5319
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.015088081359863 seconds
Epoch 60 accuracy: 80.67%
Batch 10, Loss: 0.5430
Batch 20, Loss: 0.5248
Batch 30, Loss: 0.4956
Batch 40, Loss: 0.5344
Batch 50, Loss: 0.5039
Batch 60, Loss: 0.4904
Batch 70, Loss: 0.4972
Batch 80, Loss: 0.4918
Batch 90, Loss: 0.5155
Batch 100, Loss: 0.5298
Batch 110, Loss: 0.4759
Batch 120, Loss: 0.4432
Batch 130, Loss: 0.4971
Batch 140, Loss: 0.5539
Batch 150, Loss: 0.5674
Batch 160, Loss: 0.5227
Batch 170, Loss: 0.4952
Batch 180, Loss: 0.5182
Batch 190, Loss: 0.4907
Batch 200, Loss: 0.5007
Batch 210, Loss: 0.5189
Batch 220, Loss: 0.5046
Batch 230, Loss: 0.5366
Batch 240, Loss: 0.5198
Batch 250, Loss: 0.4981
Batch 260, Loss: 0.4973
Batch 270, Loss: 0.5210
Batch 280, Loss: 0.5358
Batch 290, Loss: 0.4997
Batch 300, Loss: 0.5370
Batch 310, Loss: 0.5039
Batch 320, Loss: 0.5268
Batch 330, Loss: 0.5240
Batch 340, Loss: 0.5247
Batch 350, Loss: 0.5320
Batch 360, Loss: 0.5190
Batch 370, Loss: 0.5349
Batch 380, Loss: 0.5260
Batch 390, Loss: 0.5171
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.013167142868042 seconds
Epoch 61 accuracy: 76.61%
Batch 10, Loss: 0.5371
Batch 20, Loss: 0.4789
Batch 30, Loss: 0.5124
Batch 40, Loss: 0.5363
Batch 50, Loss: 0.5421
Batch 60, Loss: 0.4985
Batch 70, Loss: 0.5589
Batch 80, Loss: 0.5079
Batch 90, Loss: 0.5017
Batch 100, Loss: 0.4847
Batch 110, Loss: 0.5108
Batch 120, Loss: 0.5057
Batch 130, Loss: 0.4874
Batch 140, Loss: 0.4940
Batch 150, Loss: 0.5541
Batch 160, Loss: 0.5265
Batch 170, Loss: 0.5067
Batch 180, Loss: 0.5334
Batch 190, Loss: 0.5159
Batch 200, Loss: 0.5245
Batch 210, Loss: 0.5083
Batch 220, Loss: 0.4733
Batch 230, Loss: 0.5411
Batch 240, Loss: 0.5214
Batch 250, Loss: 0.5407
Batch 260, Loss: 0.5123
Batch 270, Loss: 0.5132
Batch 280, Loss: 0.4632
Batch 290, Loss: 0.5112
Batch 300, Loss: 0.5471
Batch 310, Loss: 0.5394
Batch 320, Loss: 0.4936
Batch 330, Loss: 0.5306
Batch 340, Loss: 0.5290
Batch 350, Loss: 0.5452
Batch 360, Loss: 0.5429
Batch 370, Loss: 0.5472
Batch 380, Loss: 0.5332
Batch 390, Loss: 0.4850
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.05146050453186 seconds
Epoch 62 accuracy: 84.94%
Batch 10, Loss: 0.4985
Batch 20, Loss: 0.5357
Batch 30, Loss: 0.5015
Batch 40, Loss: 0.4971
Batch 50, Loss: 0.5391
Batch 60, Loss: 0.5035
Batch 70, Loss: 0.4884
Batch 80, Loss: 0.5035
Batch 90, Loss: 0.5084
Batch 100, Loss: 0.5287
Batch 110, Loss: 0.5332
Batch 120, Loss: 0.5126
Batch 130, Loss: 0.5533
Batch 140, Loss: 0.5339
Batch 150, Loss: 0.5032
Batch 160, Loss: 0.5681
Batch 170, Loss: 0.5361
Batch 180, Loss: 0.5454
Batch 190, Loss: 0.5408
Batch 200, Loss: 0.5221
Batch 210, Loss: 0.5462
Batch 220, Loss: 0.5308
Batch 230, Loss: 0.5424
Batch 240, Loss: 0.5240
Batch 250, Loss: 0.4887
Batch 260, Loss: 0.4831
Batch 270, Loss: 0.5236
Batch 280, Loss: 0.4960
Batch 290, Loss: 0.5026
Batch 300, Loss: 0.4668
Batch 310, Loss: 0.4903
Batch 320, Loss: 0.4972
Batch 330, Loss: 0.5305
Batch 340, Loss: 0.4881
Batch 350, Loss: 0.5376
Batch 360, Loss: 0.5043
Batch 370, Loss: 0.5317
Batch 380, Loss: 0.5588
Batch 390, Loss: 0.5022
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.0395827293396 seconds
Epoch 63 accuracy: 82.93%
Batch 10, Loss: 0.5230
Batch 20, Loss: 0.5061
Batch 30, Loss: 0.4806
Batch 40, Loss: 0.5165
Batch 50, Loss: 0.5111
Batch 60, Loss: 0.5038
Batch 70, Loss: 0.4948
Batch 80, Loss: 0.4774
Batch 90, Loss: 0.5871
Batch 100, Loss: 0.5207
Batch 110, Loss: 0.5177
Batch 120, Loss: 0.5063
Batch 130, Loss: 0.5118
Batch 140, Loss: 0.5220
Batch 150, Loss: 0.4836
Batch 160, Loss: 0.5399
Batch 170, Loss: 0.5111
Batch 180, Loss: 0.5355
Batch 190, Loss: 0.5174
Batch 200, Loss: 0.5072
Batch 210, Loss: 0.5033
Batch 220, Loss: 0.5273
Batch 230, Loss: 0.5005
Batch 240, Loss: 0.4832
Batch 250, Loss: 0.5383
Batch 260, Loss: 0.4744
Batch 270, Loss: 0.5164
Batch 280, Loss: 0.5130
Batch 290, Loss: 0.4685
Batch 300, Loss: 0.4679
Batch 310, Loss: 0.4933
Batch 320, Loss: 0.4847
Batch 330, Loss: 0.5597
Batch 340, Loss: 0.5455
Batch 350, Loss: 0.5461
Batch 360, Loss: 0.5522
Batch 370, Loss: 0.5485
Batch 380, Loss: 0.5741
Batch 390, Loss: 0.5394
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 24.993244409561157 seconds
Epoch 64 accuracy: 81.99%
Batch 10, Loss: 0.5451
Batch 20, Loss: 0.5071
Batch 30, Loss: 0.4945
Batch 40, Loss: 0.5372
Batch 50, Loss: 0.5558
Batch 60, Loss: 0.5066
Batch 70, Loss: 0.5156
Batch 80, Loss: 0.4735
Batch 90, Loss: 0.5201
Batch 100, Loss: 0.4870
Batch 110, Loss: 0.5282
Batch 120, Loss: 0.5192
Batch 130, Loss: 0.4875
Batch 140, Loss: 0.5218
Batch 150, Loss: 0.5052
Batch 160, Loss: 0.5305
Batch 170, Loss: 0.5070
Batch 180, Loss: 0.5124
Batch 190, Loss: 0.4890
Batch 200, Loss: 0.5111
Batch 210, Loss: 0.4840
Batch 220, Loss: 0.4928
Batch 230, Loss: 0.5069
Batch 240, Loss: 0.5089
Batch 250, Loss: 0.5367
Batch 260, Loss: 0.5093
Batch 270, Loss: 0.4967
Batch 280, Loss: 0.5216
Batch 290, Loss: 0.4964
Batch 300, Loss: 0.5061
Batch 310, Loss: 0.4787
Batch 320, Loss: 0.5270
Batch 330, Loss: 0.5399
Batch 340, Loss: 0.5141
Batch 350, Loss: 0.5156
Batch 360, Loss: 0.4915
Batch 370, Loss: 0.5014
Batch 380, Loss: 0.4914
Batch 390, Loss: 0.5041
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.060758352279663 seconds
Epoch 65 accuracy: 87.25%
Batch 10, Loss: 0.4903
Batch 20, Loss: 0.5548
Batch 30, Loss: 0.5083
Batch 40, Loss: 0.5062
Batch 50, Loss: 0.5214
Batch 60, Loss: 0.4802
Batch 70, Loss: 0.5261
Batch 80, Loss: 0.5048
Batch 90, Loss: 0.5146
Batch 100, Loss: 0.5054
Batch 110, Loss: 0.5124
Batch 120, Loss: 0.4838
Batch 130, Loss: 0.5234
Batch 140, Loss: 0.5050
Batch 150, Loss: 0.5116
Batch 160, Loss: 0.5221
Batch 170, Loss: 0.5449
Batch 180, Loss: 0.4829
Batch 190, Loss: 0.5068
Batch 200, Loss: 0.4918
Batch 210, Loss: 0.4953
Batch 220, Loss: 0.5143
Batch 230, Loss: 0.4982
Batch 240, Loss: 0.5469
Batch 250, Loss: 0.5368
Batch 260, Loss: 0.5065
Batch 270, Loss: 0.5207
Batch 280, Loss: 0.4997
Batch 290, Loss: 0.5131
Batch 300, Loss: 0.4888
Batch 310, Loss: 0.4990
Batch 320, Loss: 0.5218
Batch 330, Loss: 0.5349
Batch 340, Loss: 0.5299
Batch 350, Loss: 0.5483
Batch 360, Loss: 0.4888
Batch 370, Loss: 0.4931
Batch 380, Loss: 0.5193
Batch 390, Loss: 0.4854
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.030414581298828 seconds
Epoch 66 accuracy: 86.78%
Batch 10, Loss: 0.5062
Batch 20, Loss: 0.5152
Batch 30, Loss: 0.5044
Batch 40, Loss: 0.5079
Batch 50, Loss: 0.5362
Batch 60, Loss: 0.4800
Batch 70, Loss: 0.4793
Batch 80, Loss: 0.4772
Batch 90, Loss: 0.4877
Batch 100, Loss: 0.4888
Batch 110, Loss: 0.5324
Batch 120, Loss: 0.5252
Batch 130, Loss: 0.5241
Batch 140, Loss: 0.4880
Batch 150, Loss: 0.5065
Batch 160, Loss: 0.5013
Batch 170, Loss: 0.4783
Batch 180, Loss: 0.4806
Batch 190, Loss: 0.4923
Batch 200, Loss: 0.5491
Batch 210, Loss: 0.5108
Batch 220, Loss: 0.5053
Batch 230, Loss: 0.4823
Batch 240, Loss: 0.4675
Batch 250, Loss: 0.4894
Batch 260, Loss: 0.5500
Batch 270, Loss: 0.5010
Batch 280, Loss: 0.5455
Batch 290, Loss: 0.4875
Batch 300, Loss: 0.5163
Batch 310, Loss: 0.4923
Batch 320, Loss: 0.5407
Batch 330, Loss: 0.5292
Batch 340, Loss: 0.5157
Batch 350, Loss: 0.4985
Batch 360, Loss: 0.5112
Batch 370, Loss: 0.4969
Batch 380, Loss: 0.5300
Batch 390, Loss: 0.4956
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.30392360687256 seconds
Epoch 67 accuracy: 86.05%
Batch 10, Loss: 0.5275
Batch 20, Loss: 0.5261
Batch 30, Loss: 0.4747
Batch 40, Loss: 0.5143
Batch 50, Loss: 0.5049
Batch 60, Loss: 0.5196
Batch 70, Loss: 0.4966
Batch 80, Loss: 0.5140
Batch 90, Loss: 0.5474
Batch 100, Loss: 0.4699
Batch 110, Loss: 0.5008
Batch 120, Loss: 0.4690
Batch 130, Loss: 0.4985
Batch 140, Loss: 0.5671
Batch 150, Loss: 0.5063
Batch 160, Loss: 0.4611
Batch 170, Loss: 0.4964
Batch 180, Loss: 0.5095
Batch 190, Loss: 0.4400
Batch 200, Loss: 0.4731
Batch 210, Loss: 0.4849
Batch 220, Loss: 0.5046
Batch 230, Loss: 0.5366
Batch 240, Loss: 0.5380
Batch 250, Loss: 0.5193
Batch 260, Loss: 0.5262
Batch 270, Loss: 0.5225
Batch 280, Loss: 0.4907
Batch 290, Loss: 0.5070
Batch 300, Loss: 0.4734
Batch 310, Loss: 0.5173
Batch 320, Loss: 0.4983
Batch 330, Loss: 0.5221
Batch 340, Loss: 0.5128
Batch 350, Loss: 0.4987
Batch 360, Loss: 0.4890
Batch 370, Loss: 0.5078
Batch 380, Loss: 0.5179
Batch 390, Loss: 0.4850
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.058828592300415 seconds
Epoch 68 accuracy: 82.04%
Batch 10, Loss: 0.4704
Batch 20, Loss: 0.4891
Batch 30, Loss: 0.5418
Batch 40, Loss: 0.5044
Batch 50, Loss: 0.5367
Batch 60, Loss: 0.4929
Batch 70, Loss: 0.5147
Batch 80, Loss: 0.4789
Batch 90, Loss: 0.5054
Batch 100, Loss: 0.5055
Batch 110, Loss: 0.4940
Batch 120, Loss: 0.5211
Batch 130, Loss: 0.5241
Batch 140, Loss: 0.4884
Batch 150, Loss: 0.5125
Batch 160, Loss: 0.4884
Batch 170, Loss: 0.5199
Batch 180, Loss: 0.4938
Batch 190, Loss: 0.5134
Batch 200, Loss: 0.4888
Batch 210, Loss: 0.5220
Batch 220, Loss: 0.4942
Batch 230, Loss: 0.4696
Batch 240, Loss: 0.5040
Batch 250, Loss: 0.4646
Batch 260, Loss: 0.5227
Batch 270, Loss: 0.5119
Batch 280, Loss: 0.5124
Batch 290, Loss: 0.5169
Batch 300, Loss: 0.5492
Batch 310, Loss: 0.5049
Batch 320, Loss: 0.4845
Batch 330, Loss: 0.5018
Batch 340, Loss: 0.4685
Batch 350, Loss: 0.4987
Batch 360, Loss: 0.5339
Batch 370, Loss: 0.5126
Batch 380, Loss: 0.4920
Batch 390, Loss: 0.4813
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.03540015220642 seconds
Epoch 69 accuracy: 86.14%
Batch 10, Loss: 0.4901
Batch 20, Loss: 0.4897
Batch 30, Loss: 0.4960
Batch 40, Loss: 0.4774
Batch 50, Loss: 0.5217
Batch 60, Loss: 0.4745
Batch 70, Loss: 0.4692
Batch 80, Loss: 0.4628
Batch 90, Loss: 0.5576
Batch 100, Loss: 0.5314
Batch 110, Loss: 0.5083
Batch 120, Loss: 0.4860
Batch 130, Loss: 0.4868
Batch 140, Loss: 0.4662
Batch 150, Loss: 0.4910
Batch 160, Loss: 0.5085
Batch 170, Loss: 0.5092
Batch 180, Loss: 0.5385
Batch 190, Loss: 0.5048
Batch 200, Loss: 0.5035
Batch 210, Loss: 0.5150
Batch 220, Loss: 0.5293
Batch 230, Loss: 0.4623
Batch 240, Loss: 0.4754
Batch 250, Loss: 0.4686
Batch 260, Loss: 0.4973
Batch 270, Loss: 0.4918
Batch 280, Loss: 0.4957
Batch 290, Loss: 0.5380
Batch 300, Loss: 0.4925
Batch 310, Loss: 0.5339
Batch 320, Loss: 0.4964
Batch 330, Loss: 0.5053
Batch 340, Loss: 0.4987
Batch 350, Loss: 0.5118
Batch 360, Loss: 0.5479
Batch 370, Loss: 0.4828
Batch 380, Loss: 0.4864
Batch 390, Loss: 0.4891
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.028042793273926 seconds
Epoch 70 accuracy: 84.66%
Batch 10, Loss: 0.4754
Batch 20, Loss: 0.5196
Batch 30, Loss: 0.5011
Batch 40, Loss: 0.5284
Batch 50, Loss: 0.5486
Batch 60, Loss: 0.5125
Batch 70, Loss: 0.4641
Batch 80, Loss: 0.5025
Batch 90, Loss: 0.4895
Batch 100, Loss: 0.5519
Batch 110, Loss: 0.4911
Batch 120, Loss: 0.4813
Batch 130, Loss: 0.5262
Batch 140, Loss: 0.5205
Batch 150, Loss: 0.4965
Batch 160, Loss: 0.5100
Batch 170, Loss: 0.5035
Batch 180, Loss: 0.4737
Batch 190, Loss: 0.5181
Batch 200, Loss: 0.5141
Batch 210, Loss: 0.4749
Batch 220, Loss: 0.5413
Batch 230, Loss: 0.5058
Batch 240, Loss: 0.4450
Batch 250, Loss: 0.4552
Batch 260, Loss: 0.4663
Batch 270, Loss: 0.4785
Batch 280, Loss: 0.4912
Batch 290, Loss: 0.4879
Batch 300, Loss: 0.5274
Batch 310, Loss: 0.4945
Batch 320, Loss: 0.5185
Batch 330, Loss: 0.4520
Batch 340, Loss: 0.4700
Batch 350, Loss: 0.5214
Batch 360, Loss: 0.5127
Batch 370, Loss: 0.5216
Batch 380, Loss: 0.4923
Batch 390, Loss: 0.4881
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.047701835632324 seconds
Epoch 71 accuracy: 84.1%
Batch 10, Loss: 0.5011
Batch 20, Loss: 0.4845
Batch 30, Loss: 0.4633
Batch 40, Loss: 0.4741
Batch 50, Loss: 0.5130
Batch 60, Loss: 0.4602
Batch 70, Loss: 0.4883
Batch 80, Loss: 0.5127
Batch 90, Loss: 0.4846
Batch 100, Loss: 0.4900
Batch 110, Loss: 0.4888
Batch 120, Loss: 0.4819
Batch 130, Loss: 0.4970
Batch 140, Loss: 0.5418
Batch 150, Loss: 0.5098
Batch 160, Loss: 0.5200
Batch 170, Loss: 0.4867
Batch 180, Loss: 0.4793
Batch 190, Loss: 0.4801
Batch 200, Loss: 0.5031
Batch 210, Loss: 0.4799
Batch 220, Loss: 0.4830
Batch 230, Loss: 0.5043
Batch 240, Loss: 0.4985
Batch 250, Loss: 0.5258
Batch 260, Loss: 0.4980
Batch 270, Loss: 0.4806
Batch 280, Loss: 0.5238
Batch 290, Loss: 0.4961
Batch 300, Loss: 0.5059
Batch 310, Loss: 0.5180
Batch 320, Loss: 0.5244
Batch 330, Loss: 0.4973
Batch 340, Loss: 0.4724
Batch 350, Loss: 0.5329
Batch 360, Loss: 0.5322
Batch 370, Loss: 0.5351
Batch 380, Loss: 0.4552
Batch 390, Loss: 0.4911
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 24.991141319274902 seconds
Epoch 72 accuracy: 85.73%
Batch 10, Loss: 0.4876
Batch 20, Loss: 0.4809
Batch 30, Loss: 0.5045
Batch 40, Loss: 0.4452
Batch 50, Loss: 0.5188
Batch 60, Loss: 0.4850
Batch 70, Loss: 0.4697
Batch 80, Loss: 0.5147
Batch 90, Loss: 0.4840
Batch 100, Loss: 0.4802
Batch 110, Loss: 0.4944
Batch 120, Loss: 0.4795
Batch 130, Loss: 0.4991
Batch 140, Loss: 0.5083
Batch 150, Loss: 0.5223
Batch 160, Loss: 0.4756
Batch 170, Loss: 0.5182
Batch 180, Loss: 0.4819
Batch 190, Loss: 0.4736
Batch 200, Loss: 0.4603
Batch 210, Loss: 0.5003
Batch 220, Loss: 0.5307
Batch 230, Loss: 0.5206
Batch 240, Loss: 0.5200
Batch 250, Loss: 0.4859
Batch 260, Loss: 0.4984
Batch 270, Loss: 0.4972
Batch 280, Loss: 0.4441
Batch 290, Loss: 0.4990
Batch 300, Loss: 0.5019
Batch 310, Loss: 0.4842
Batch 320, Loss: 0.4741
Batch 330, Loss: 0.4503
Batch 340, Loss: 0.5337
Batch 350, Loss: 0.5408
Batch 360, Loss: 0.4966
Batch 370, Loss: 0.4849
Batch 380, Loss: 0.4703
Batch 390, Loss: 0.5023
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.045034885406494 seconds
Epoch 73 accuracy: 80.11%
Batch 10, Loss: 0.5115
Batch 20, Loss: 0.5063
Batch 30, Loss: 0.4881
Batch 40, Loss: 0.4850
Batch 50, Loss: 0.4926
Batch 60, Loss: 0.4581
Batch 70, Loss: 0.4644
Batch 80, Loss: 0.4843
Batch 90, Loss: 0.4947
Batch 100, Loss: 0.5128
Batch 110, Loss: 0.5114
Batch 120, Loss: 0.4929
Batch 130, Loss: 0.4848
Batch 140, Loss: 0.5192
Batch 150, Loss: 0.4792
Batch 160, Loss: 0.4840
Batch 170, Loss: 0.5118
Batch 180, Loss: 0.4532
Batch 190, Loss: 0.5253
Batch 200, Loss: 0.5429
Batch 210, Loss: 0.5271
Batch 220, Loss: 0.4837
Batch 230, Loss: 0.4649
Batch 240, Loss: 0.4809
Batch 250, Loss: 0.5171
Batch 260, Loss: 0.4833
Batch 270, Loss: 0.4727
Batch 280, Loss: 0.4882
Batch 290, Loss: 0.4976
Batch 300, Loss: 0.5179
Batch 310, Loss: 0.5104
Batch 320, Loss: 0.4836
Batch 330, Loss: 0.5183
Batch 340, Loss: 0.4973
Batch 350, Loss: 0.5005
Batch 360, Loss: 0.4836
Batch 370, Loss: 0.4719
Batch 380, Loss: 0.5146
Batch 390, Loss: 0.4791
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 24.99355983734131 seconds
Epoch 74 accuracy: 83.42%
Batch 10, Loss: 0.4927
Batch 20, Loss: 0.5083
Batch 30, Loss: 0.5088
Batch 40, Loss: 0.4687
Batch 50, Loss: 0.5066
Batch 60, Loss: 0.4802
Batch 70, Loss: 0.4730
Batch 80, Loss: 0.4428
Batch 90, Loss: 0.4921
Batch 100, Loss: 0.4801
Batch 110, Loss: 0.4456
Batch 120, Loss: 0.4892
Batch 130, Loss: 0.4938
Batch 140, Loss: 0.4500
Batch 150, Loss: 0.4788
Batch 160, Loss: 0.4892
Batch 170, Loss: 0.4884
Batch 180, Loss: 0.5217
Batch 190, Loss: 0.5164
Batch 200, Loss: 0.4772
Batch 210, Loss: 0.5209
Batch 220, Loss: 0.4865
Batch 230, Loss: 0.4861
Batch 240, Loss: 0.4926
Batch 250, Loss: 0.4662
Batch 260, Loss: 0.4683
Batch 270, Loss: 0.4669
Batch 280, Loss: 0.5535
Batch 290, Loss: 0.4686
Batch 300, Loss: 0.4765
Batch 310, Loss: 0.5273
Batch 320, Loss: 0.4780
Batch 330, Loss: 0.4877
Batch 340, Loss: 0.4883
Batch 350, Loss: 0.5402
Batch 360, Loss: 0.4843
Batch 370, Loss: 0.5067
Batch 380, Loss: 0.5052
Batch 390, Loss: 0.4748
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 24.99816131591797 seconds
Epoch 75 accuracy: 85.01%
Batch 10, Loss: 0.5041
Batch 20, Loss: 0.4905
Batch 30, Loss: 0.5376
Batch 40, Loss: 0.4957
Batch 50, Loss: 0.4781
Batch 60, Loss: 0.4868
Batch 70, Loss: 0.4951
Batch 80, Loss: 0.4821
Batch 90, Loss: 0.5243
Batch 100, Loss: 0.4663
Batch 110, Loss: 0.4857
Batch 120, Loss: 0.5150
Batch 130, Loss: 0.5245
Batch 140, Loss: 0.4575
Batch 150, Loss: 0.4770
Batch 160, Loss: 0.5142
Batch 170, Loss: 0.5271
Batch 180, Loss: 0.4702
Batch 190, Loss: 0.4846
Batch 200, Loss: 0.4702
Batch 210, Loss: 0.4939
Batch 220, Loss: 0.5122
Batch 230, Loss: 0.5154
Batch 240, Loss: 0.4713
Batch 250, Loss: 0.4829
Batch 260, Loss: 0.4403
Batch 270, Loss: 0.4736
Batch 280, Loss: 0.4858
Batch 290, Loss: 0.4987
Batch 300, Loss: 0.5333
Batch 310, Loss: 0.4811
Batch 320, Loss: 0.5150
Batch 330, Loss: 0.4763
Batch 340, Loss: 0.4850
Batch 350, Loss: 0.5066
Batch 360, Loss: 0.5005
Batch 370, Loss: 0.5207
Batch 380, Loss: 0.4866
Batch 390, Loss: 0.5198
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.022164344787598 seconds
Epoch 76 accuracy: 84.32%
Batch 10, Loss: 0.4581
Batch 20, Loss: 0.4826
Batch 30, Loss: 0.4380
Batch 40, Loss: 0.4495
Batch 50, Loss: 0.5182
Batch 60, Loss: 0.4699
Batch 70, Loss: 0.4823
Batch 80, Loss: 0.4697
Batch 90, Loss: 0.5066
Batch 100, Loss: 0.4886
Batch 110, Loss: 0.4968
Batch 120, Loss: 0.4767
Batch 130, Loss: 0.5026
Batch 140, Loss: 0.5020
Batch 150, Loss: 0.4663
Batch 160, Loss: 0.4836
Batch 170, Loss: 0.4945
Batch 180, Loss: 0.4594
Batch 190, Loss: 0.4874
Batch 200, Loss: 0.4700
Batch 210, Loss: 0.4497
Batch 220, Loss: 0.4766
Batch 230, Loss: 0.4931
Batch 240, Loss: 0.4674
Batch 250, Loss: 0.4550
Batch 260, Loss: 0.4700
Batch 270, Loss: 0.5093
Batch 280, Loss: 0.4966
Batch 290, Loss: 0.5114
Batch 300, Loss: 0.4857
Batch 310, Loss: 0.5063
Batch 320, Loss: 0.4869
Batch 330, Loss: 0.4666
Batch 340, Loss: 0.4803
Batch 350, Loss: 0.4684
Batch 360, Loss: 0.4820
Batch 370, Loss: 0.5097
Batch 380, Loss: 0.4667
Batch 390, Loss: 0.4529
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 24.97262144088745 seconds
Epoch 77 accuracy: 84.86%
Batch 10, Loss: 0.5177
Batch 20, Loss: 0.4996
Batch 30, Loss: 0.4934
Batch 40, Loss: 0.4772
Batch 50, Loss: 0.4751
Batch 60, Loss: 0.4972
Batch 70, Loss: 0.4501
Batch 80, Loss: 0.5114
Batch 90, Loss: 0.5237
Batch 100, Loss: 0.5081
Batch 110, Loss: 0.5032
Batch 120, Loss: 0.4670
Batch 130, Loss: 0.4490
Batch 140, Loss: 0.4792
Batch 150, Loss: 0.5024
Batch 160, Loss: 0.4938
Batch 170, Loss: 0.4909
Batch 180, Loss: 0.5007
Batch 190, Loss: 0.4995
Batch 200, Loss: 0.4676
Batch 210, Loss: 0.4926
Batch 220, Loss: 0.4658
Batch 230, Loss: 0.4860
Batch 240, Loss: 0.5034
Batch 250, Loss: 0.5189
Batch 260, Loss: 0.4666
Batch 270, Loss: 0.4993
Batch 280, Loss: 0.4464
Batch 290, Loss: 0.4610
Batch 300, Loss: 0.4549
Batch 310, Loss: 0.4706
Batch 320, Loss: 0.4914
Batch 330, Loss: 0.5195
Batch 340, Loss: 0.4901
Batch 350, Loss: 0.4662
Batch 360, Loss: 0.5005
Batch 370, Loss: 0.4317
Batch 380, Loss: 0.5148
Batch 390, Loss: 0.4906
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 24.987420797348022 seconds
Epoch 78 accuracy: 87.87%
Batch 10, Loss: 0.4622
Batch 20, Loss: 0.4528
Batch 30, Loss: 0.4776
Batch 40, Loss: 0.4650
Batch 50, Loss: 0.4841
Batch 60, Loss: 0.4362
Batch 70, Loss: 0.4643
Batch 80, Loss: 0.4939
Batch 90, Loss: 0.5144
Batch 100, Loss: 0.4829
Batch 110, Loss: 0.5052
Batch 120, Loss: 0.4783
Batch 130, Loss: 0.4566
Batch 140, Loss: 0.4838
Batch 150, Loss: 0.4836
Batch 160, Loss: 0.5242
Batch 170, Loss: 0.4705
Batch 180, Loss: 0.4327
Batch 190, Loss: 0.4714
Batch 200, Loss: 0.5120
Batch 210, Loss: 0.4876
Batch 220, Loss: 0.4754
Batch 230, Loss: 0.4808
Batch 240, Loss: 0.4835
Batch 250, Loss: 0.4663
Batch 260, Loss: 0.4712
Batch 270, Loss: 0.4607
Batch 280, Loss: 0.4610
Batch 290, Loss: 0.4866
Batch 300, Loss: 0.4862
Batch 310, Loss: 0.4572
Batch 320, Loss: 0.4631
Batch 330, Loss: 0.5005
Batch 340, Loss: 0.4670
Batch 350, Loss: 0.4935
Batch 360, Loss: 0.4717
Batch 370, Loss: 0.4973
Batch 380, Loss: 0.5362
Batch 390, Loss: 0.5199
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 24.985113859176636 seconds
Epoch 79 accuracy: 87.16%
Batch 10, Loss: 0.4576
Batch 20, Loss: 0.5025
Batch 30, Loss: 0.4739
Batch 40, Loss: 0.4932
Batch 50, Loss: 0.4836
Batch 60, Loss: 0.4751
Batch 70, Loss: 0.4493
Batch 80, Loss: 0.5020
Batch 90, Loss: 0.4986
Batch 100, Loss: 0.4885
Batch 110, Loss: 0.4782
Batch 120, Loss: 0.5007
Batch 130, Loss: 0.4984
Batch 140, Loss: 0.5082
Batch 150, Loss: 0.5106
Batch 160, Loss: 0.4500
Batch 170, Loss: 0.4754
Batch 180, Loss: 0.4989
Batch 190, Loss: 0.4936
Batch 200, Loss: 0.4646
Batch 210, Loss: 0.4550
Batch 220, Loss: 0.4833
Batch 230, Loss: 0.5077
Batch 240, Loss: 0.5056
Batch 250, Loss: 0.5115
Batch 260, Loss: 0.4845
Batch 270, Loss: 0.4833
Batch 280, Loss: 0.4883
Batch 290, Loss: 0.4930
Batch 300, Loss: 0.4911
Batch 310, Loss: 0.4815
Batch 320, Loss: 0.4912
Batch 330, Loss: 0.4782
Batch 340, Loss: 0.4534
Batch 350, Loss: 0.4688
Batch 360, Loss: 0.5017
Batch 370, Loss: 0.4706
Batch 380, Loss: 0.4639
Batch 390, Loss: 0.4991
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.02669858932495 seconds
Epoch 80 accuracy: 86.25%
Batch 10, Loss: 0.4374
Batch 20, Loss: 0.4799
Batch 30, Loss: 0.5116
Batch 40, Loss: 0.4439
Batch 50, Loss: 0.4638
Batch 60, Loss: 0.4282
Batch 70, Loss: 0.4689
Batch 80, Loss: 0.5093
Batch 90, Loss: 0.4670
Batch 100, Loss: 0.4735
Batch 110, Loss: 0.5096
Batch 120, Loss: 0.4915
Batch 130, Loss: 0.4756
Batch 140, Loss: 0.4911
Batch 150, Loss: 0.4546
Batch 160, Loss: 0.4574
Batch 170, Loss: 0.5061
Batch 180, Loss: 0.4676
Batch 190, Loss: 0.4944
Batch 200, Loss: 0.4645
Batch 210, Loss: 0.5199
Batch 220, Loss: 0.4850
Batch 230, Loss: 0.4653
Batch 240, Loss: 0.4656
Batch 250, Loss: 0.4639
Batch 260, Loss: 0.5161
Batch 270, Loss: 0.5017
Batch 280, Loss: 0.4911
Batch 290, Loss: 0.4833
Batch 300, Loss: 0.4711
Batch 310, Loss: 0.5074
Batch 320, Loss: 0.5030
Batch 330, Loss: 0.4799
Batch 340, Loss: 0.4964
Batch 350, Loss: 0.4614
Batch 360, Loss: 0.4766
Batch 370, Loss: 0.4575
Batch 380, Loss: 0.5224
Batch 390, Loss: 0.4543
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.049437999725342 seconds
Epoch 81 accuracy: 84.11%
Batch 10, Loss: 0.4815
Batch 20, Loss: 0.4629
Batch 30, Loss: 0.4378
Batch 40, Loss: 0.4828
Batch 50, Loss: 0.4772
Batch 60, Loss: 0.4876
Batch 70, Loss: 0.4938
Batch 80, Loss: 0.4689
Batch 90, Loss: 0.4593
Batch 100, Loss: 0.5115
Batch 110, Loss: 0.4784
Batch 120, Loss: 0.4787
Batch 130, Loss: 0.4373
Batch 140, Loss: 0.4720
Batch 150, Loss: 0.4563
Batch 160, Loss: 0.5032
Batch 170, Loss: 0.5030
Batch 180, Loss: 0.5110
Batch 190, Loss: 0.5091
Batch 200, Loss: 0.4629
Batch 210, Loss: 0.5090
Batch 220, Loss: 0.5076
Batch 230, Loss: 0.4924
Batch 240, Loss: 0.4642
Batch 250, Loss: 0.4461
Batch 260, Loss: 0.4540
Batch 270, Loss: 0.5057
Batch 280, Loss: 0.4991
Batch 290, Loss: 0.4968
Batch 300, Loss: 0.4660
Batch 310, Loss: 0.4677
Batch 320, Loss: 0.5107
Batch 330, Loss: 0.5107
Batch 340, Loss: 0.4762
Batch 350, Loss: 0.5256
Batch 360, Loss: 0.4864
Batch 370, Loss: 0.4809
Batch 380, Loss: 0.4594
Batch 390, Loss: 0.4514
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.00299072265625 seconds
Epoch 82 accuracy: 84.65%
Batch 10, Loss: 0.4925
Batch 20, Loss: 0.4805
Batch 30, Loss: 0.4906
Batch 40, Loss: 0.4369
Batch 50, Loss: 0.4873
Batch 60, Loss: 0.4742
Batch 70, Loss: 0.4718
Batch 80, Loss: 0.4331
Batch 90, Loss: 0.4643
Batch 100, Loss: 0.4524
Batch 110, Loss: 0.4763
Batch 120, Loss: 0.5278
Batch 130, Loss: 0.4947
Batch 140, Loss: 0.4731
Batch 150, Loss: 0.4601
Batch 160, Loss: 0.4677
Batch 170, Loss: 0.4894
Batch 180, Loss: 0.4628
Batch 190, Loss: 0.4396
Batch 200, Loss: 0.4787
Batch 210, Loss: 0.4945
Batch 220, Loss: 0.4899
Batch 230, Loss: 0.4850
Batch 240, Loss: 0.4312
Batch 250, Loss: 0.4604
Batch 260, Loss: 0.4684
Batch 270, Loss: 0.4678
Batch 280, Loss: 0.4560
Batch 290, Loss: 0.4826
Batch 300, Loss: 0.4818
Batch 310, Loss: 0.4766
Batch 320, Loss: 0.4599
Batch 330, Loss: 0.4553
Batch 340, Loss: 0.4623
Batch 350, Loss: 0.4806
Batch 360, Loss: 0.4791
Batch 370, Loss: 0.4819
Batch 380, Loss: 0.4881
Batch 390, Loss: 0.5028
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.043116569519043 seconds
Epoch 83 accuracy: 87.37%
Batch 10, Loss: 0.4499
Batch 20, Loss: 0.4953
Batch 30, Loss: 0.4538
Batch 40, Loss: 0.4808
Batch 50, Loss: 0.4624
Batch 60, Loss: 0.4530
Batch 70, Loss: 0.4782
Batch 80, Loss: 0.4670
Batch 90, Loss: 0.4544
Batch 100, Loss: 0.4487
Batch 110, Loss: 0.4527
Batch 120, Loss: 0.4878
Batch 130, Loss: 0.4813
Batch 140, Loss: 0.4712
Batch 150, Loss: 0.4888
Batch 160, Loss: 0.4791
Batch 170, Loss: 0.4789
Batch 180, Loss: 0.4619
Batch 190, Loss: 0.4555
Batch 200, Loss: 0.4869
Batch 210, Loss: 0.4831
Batch 220, Loss: 0.4922
Batch 230, Loss: 0.4716
Batch 240, Loss: 0.4542
Batch 250, Loss: 0.4502
Batch 260, Loss: 0.4967
Batch 270, Loss: 0.4551
Batch 280, Loss: 0.4837
Batch 290, Loss: 0.4719
Batch 300, Loss: 0.5021
Batch 310, Loss: 0.4897
Batch 320, Loss: 0.4737
Batch 330, Loss: 0.4833
Batch 340, Loss: 0.4783
Batch 350, Loss: 0.4624
Batch 360, Loss: 0.4507
Batch 370, Loss: 0.4630
Batch 380, Loss: 0.4483
Batch 390, Loss: 0.4652
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.050774335861206 seconds
Epoch 84 accuracy: 87.97%
Batch 10, Loss: 0.4626
Batch 20, Loss: 0.4709
Batch 30, Loss: 0.4938
Batch 40, Loss: 0.4709
Batch 50, Loss: 0.4474
Batch 60, Loss: 0.4445
Batch 70, Loss: 0.4695
Batch 80, Loss: 0.4659
Batch 90, Loss: 0.4892
Batch 100, Loss: 0.5120
Batch 110, Loss: 0.4821
Batch 120, Loss: 0.4965
Batch 130, Loss: 0.4851
Batch 140, Loss: 0.4839
Batch 150, Loss: 0.4975
Batch 160, Loss: 0.4671
Batch 170, Loss: 0.4589
Batch 180, Loss: 0.4487
Batch 190, Loss: 0.4642
Batch 200, Loss: 0.4816
Batch 210, Loss: 0.4306
Batch 220, Loss: 0.4545
Batch 230, Loss: 0.4826
Batch 240, Loss: 0.5167
Batch 250, Loss: 0.4356
Batch 260, Loss: 0.4575
Batch 270, Loss: 0.4559
Batch 280, Loss: 0.5370
Batch 290, Loss: 0.4643
Batch 300, Loss: 0.4594
Batch 310, Loss: 0.4820
Batch 320, Loss: 0.5289
Batch 330, Loss: 0.4671
Batch 340, Loss: 0.4732
Batch 350, Loss: 0.4770
Batch 360, Loss: 0.4833
Batch 370, Loss: 0.4756
Batch 380, Loss: 0.4357
Batch 390, Loss: 0.4986
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.005357027053833 seconds
Epoch 85 accuracy: 85.01%
Batch 10, Loss: 0.4671
Batch 20, Loss: 0.4456
Batch 30, Loss: 0.4572
Batch 40, Loss: 0.4656
Batch 50, Loss: 0.4297
Batch 60, Loss: 0.4893
Batch 70, Loss: 0.4689
Batch 80, Loss: 0.4484
Batch 90, Loss: 0.4707
Batch 100, Loss: 0.4463
Batch 110, Loss: 0.4663
Batch 120, Loss: 0.4735
Batch 130, Loss: 0.5122
Batch 140, Loss: 0.4680
Batch 150, Loss: 0.4900
Batch 160, Loss: 0.4699
Batch 170, Loss: 0.5209
Batch 180, Loss: 0.4643
Batch 190, Loss: 0.4790
Batch 200, Loss: 0.4511
Batch 210, Loss: 0.4916
Batch 220, Loss: 0.5005
Batch 230, Loss: 0.4760
Batch 240, Loss: 0.4600
Batch 250, Loss: 0.4695
Batch 260, Loss: 0.4435
Batch 270, Loss: 0.4740
Batch 280, Loss: 0.4981
Batch 290, Loss: 0.4666
Batch 300, Loss: 0.4576
Batch 310, Loss: 0.4479
Batch 320, Loss: 0.4809
Batch 330, Loss: 0.4929
Batch 340, Loss: 0.4743
Batch 350, Loss: 0.4824
Batch 360, Loss: 0.4844
Batch 370, Loss: 0.4493
Batch 380, Loss: 0.4785
Batch 390, Loss: 0.4671
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.004420042037964 seconds
Epoch 86 accuracy: 84.42%
Batch 10, Loss: 0.4827
Batch 20, Loss: 0.4712
Batch 30, Loss: 0.4590
Batch 40, Loss: 0.4526
Batch 50, Loss: 0.4682
Batch 60, Loss: 0.4444
Batch 70, Loss: 0.4983
Batch 80, Loss: 0.4737
Batch 90, Loss: 0.4689
Batch 100, Loss: 0.4346
Batch 110, Loss: 0.4673
Batch 120, Loss: 0.4610
Batch 130, Loss: 0.4701
Batch 140, Loss: 0.4910
Batch 150, Loss: 0.4989
Batch 160, Loss: 0.4561
Batch 170, Loss: 0.4854
Batch 180, Loss: 0.5031
Batch 190, Loss: 0.4207
Batch 200, Loss: 0.4909
Batch 210, Loss: 0.4744
Batch 220, Loss: 0.4787
Batch 230, Loss: 0.4534
Batch 240, Loss: 0.5100
Batch 250, Loss: 0.4544
Batch 260, Loss: 0.4671
Batch 270, Loss: 0.4344
Batch 280, Loss: 0.4979
Batch 290, Loss: 0.4539
Batch 300, Loss: 0.4929
Batch 310, Loss: 0.4694
Batch 320, Loss: 0.4838
Batch 330, Loss: 0.4747
Batch 340, Loss: 0.5064
Batch 350, Loss: 0.4546
Batch 360, Loss: 0.4488
Batch 370, Loss: 0.4296
Batch 380, Loss: 0.4872
Batch 390, Loss: 0.4422
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.02827262878418 seconds
Epoch 87 accuracy: 84.13%
Batch 10, Loss: 0.4524
Batch 20, Loss: 0.4669
Batch 30, Loss: 0.4651
Batch 40, Loss: 0.4683
Batch 50, Loss: 0.4311
Batch 60, Loss: 0.4516
Batch 70, Loss: 0.4866
Batch 80, Loss: 0.4590
Batch 90, Loss: 0.4752
Batch 100, Loss: 0.4952
Batch 110, Loss: 0.4814
Batch 120, Loss: 0.4631
Batch 130, Loss: 0.4859
Batch 140, Loss: 0.4302
Batch 150, Loss: 0.4975
Batch 160, Loss: 0.4603
Batch 170, Loss: 0.4432
Batch 180, Loss: 0.4590
Batch 190, Loss: 0.4789
Batch 200, Loss: 0.4405
Batch 210, Loss: 0.4571
Batch 220, Loss: 0.5080
Batch 230, Loss: 0.4520
Batch 240, Loss: 0.4595
Batch 250, Loss: 0.4949
Batch 260, Loss: 0.4750
Batch 270, Loss: 0.4867
Batch 280, Loss: 0.4512
Batch 290, Loss: 0.4526
Batch 300, Loss: 0.4795
Batch 310, Loss: 0.4563
Batch 320, Loss: 0.4366
Batch 330, Loss: 0.4749
Batch 340, Loss: 0.4847
Batch 350, Loss: 0.4950
Batch 360, Loss: 0.4604
Batch 370, Loss: 0.4604
Batch 380, Loss: 0.4551
Batch 390, Loss: 0.5017
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.00577402114868 seconds
Epoch 88 accuracy: 86.9%
Batch 10, Loss: 0.4212
Batch 20, Loss: 0.4455
Batch 30, Loss: 0.4414
Batch 40, Loss: 0.4564
Batch 50, Loss: 0.4497
Batch 60, Loss: 0.4447
Batch 70, Loss: 0.4664
Batch 80, Loss: 0.4495
Batch 90, Loss: 0.4819
Batch 100, Loss: 0.4688
Batch 110, Loss: 0.4551
Batch 120, Loss: 0.4315
Batch 130, Loss: 0.4700
Batch 140, Loss: 0.5021
Batch 150, Loss: 0.4612
Batch 160, Loss: 0.4941
Batch 170, Loss: 0.4292
Batch 180, Loss: 0.4241
Batch 190, Loss: 0.4678
Batch 200, Loss: 0.4563
Batch 210, Loss: 0.4163
Batch 220, Loss: 0.4302
Batch 230, Loss: 0.4917
Batch 240, Loss: 0.4612
Batch 250, Loss: 0.4489
Batch 260, Loss: 0.4568
Batch 270, Loss: 0.5072
Batch 280, Loss: 0.4383
Batch 290, Loss: 0.4273
Batch 300, Loss: 0.4513
Batch 310, Loss: 0.5123
Batch 320, Loss: 0.4543
Batch 330, Loss: 0.4733
Batch 340, Loss: 0.4892
Batch 350, Loss: 0.4407
Batch 360, Loss: 0.4677
Batch 370, Loss: 0.4581
Batch 380, Loss: 0.4660
Batch 390, Loss: 0.4848
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.05606698989868 seconds
Epoch 89 accuracy: 86.62%
Batch 10, Loss: 0.4802
Batch 20, Loss: 0.4995
Batch 30, Loss: 0.4561
Batch 40, Loss: 0.4506
Batch 50, Loss: 0.4814
Batch 60, Loss: 0.5025
Batch 70, Loss: 0.4651
Batch 80, Loss: 0.4344
Batch 90, Loss: 0.4547
Batch 100, Loss: 0.4578
Batch 110, Loss: 0.4079
Batch 120, Loss: 0.4582
Batch 130, Loss: 0.4506
Batch 140, Loss: 0.4540
Batch 150, Loss: 0.4360
Batch 160, Loss: 0.4430
Batch 170, Loss: 0.4531
Batch 180, Loss: 0.4418
Batch 190, Loss: 0.4698
Batch 200, Loss: 0.4513
Batch 210, Loss: 0.4623
Batch 220, Loss: 0.4945
Batch 230, Loss: 0.4769
Batch 240, Loss: 0.4895
Batch 250, Loss: 0.4095
Batch 260, Loss: 0.4481
Batch 270, Loss: 0.4689
Batch 280, Loss: 0.4676
Batch 290, Loss: 0.4603
Batch 300, Loss: 0.4833
Batch 310, Loss: 0.4406
Batch 320, Loss: 0.4613
Batch 330, Loss: 0.4582
Batch 340, Loss: 0.4461
Batch 350, Loss: 0.4384
Batch 360, Loss: 0.4832
Batch 370, Loss: 0.4631
Batch 380, Loss: 0.4366
Batch 390, Loss: 0.4835
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 24.979795694351196 seconds
Epoch 90 accuracy: 86.38%
Batch 10, Loss: 0.4630
Batch 20, Loss: 0.4499
Batch 30, Loss: 0.4523
Batch 40, Loss: 0.4693
Batch 50, Loss: 0.4613
Batch 60, Loss: 0.4531
Batch 70, Loss: 0.4708
Batch 80, Loss: 0.4886
Batch 90, Loss: 0.4791
Batch 100, Loss: 0.4768
Batch 110, Loss: 0.4618
Batch 120, Loss: 0.4578
Batch 130, Loss: 0.4397
Batch 140, Loss: 0.4282
Batch 150, Loss: 0.4776
Batch 160, Loss: 0.4643
Batch 170, Loss: 0.4328
Batch 180, Loss: 0.4566
Batch 190, Loss: 0.4839
Batch 200, Loss: 0.4679
Batch 210, Loss: 0.4581
Batch 220, Loss: 0.4497
Batch 230, Loss: 0.4561
Batch 240, Loss: 0.4704
Batch 250, Loss: 0.4771
Batch 260, Loss: 0.4482
Batch 270, Loss: 0.4512
Batch 280, Loss: 0.5024
Batch 290, Loss: 0.4436
Batch 300, Loss: 0.4609
Batch 310, Loss: 0.4256
Batch 320, Loss: 0.4790
Batch 330, Loss: 0.4654
Batch 340, Loss: 0.4264
Batch 350, Loss: 0.4296
Batch 360, Loss: 0.4480
Batch 370, Loss: 0.4499
Batch 380, Loss: 0.4930
Batch 390, Loss: 0.4645
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.02639889717102 seconds
Epoch 91 accuracy: 88.12%
Batch 10, Loss: 0.4676
Batch 20, Loss: 0.4514
Batch 30, Loss: 0.4375
Batch 40, Loss: 0.4510
Batch 50, Loss: 0.4790
Batch 60, Loss: 0.4318
Batch 70, Loss: 0.5037
Batch 80, Loss: 0.4577
Batch 90, Loss: 0.4332
Batch 100, Loss: 0.4521
Batch 110, Loss: 0.4517
Batch 120, Loss: 0.4414
Batch 130, Loss: 0.4651
Batch 140, Loss: 0.4391
Batch 150, Loss: 0.4613
Batch 160, Loss: 0.4700
Batch 170, Loss: 0.4753
Batch 180, Loss: 0.3984
Batch 190, Loss: 0.4401
Batch 200, Loss: 0.4346
Batch 210, Loss: 0.5024
Batch 220, Loss: 0.4233
Batch 230, Loss: 0.4764
Batch 240, Loss: 0.4293
Batch 250, Loss: 0.4874
Batch 260, Loss: 0.4934
Batch 270, Loss: 0.4259
Batch 280, Loss: 0.4538
Batch 290, Loss: 0.4492
Batch 300, Loss: 0.4582
Batch 310, Loss: 0.4313
Batch 320, Loss: 0.4379
Batch 330, Loss: 0.4653
Batch 340, Loss: 0.4705
Batch 350, Loss: 0.4260
Batch 360, Loss: 0.4837
Batch 370, Loss: 0.4642
Batch 380, Loss: 0.4658
Batch 390, Loss: 0.4383
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.004858016967773 seconds
Epoch 92 accuracy: 88.04%
Batch 10, Loss: 0.4398
Batch 20, Loss: 0.4073
Batch 30, Loss: 0.4547
Batch 40, Loss: 0.4455
Batch 50, Loss: 0.4858
Batch 60, Loss: 0.4423
Batch 70, Loss: 0.4656
Batch 80, Loss: 0.4368
Batch 90, Loss: 0.4246
Batch 100, Loss: 0.4938
Batch 110, Loss: 0.5154
Batch 120, Loss: 0.4343
Batch 130, Loss: 0.4664
Batch 140, Loss: 0.4620
Batch 150, Loss: 0.4232
Batch 160, Loss: 0.4305
Batch 170, Loss: 0.4688
Batch 180, Loss: 0.4604
Batch 190, Loss: 0.4532
Batch 200, Loss: 0.4138
Batch 210, Loss: 0.4409
Batch 220, Loss: 0.4384
Batch 230, Loss: 0.4420
Batch 240, Loss: 0.4787
Batch 250, Loss: 0.4749
Batch 260, Loss: 0.4967
Batch 270, Loss: 0.4211
Batch 280, Loss: 0.4813
Batch 290, Loss: 0.4543
Batch 300, Loss: 0.4757
Batch 310, Loss: 0.4503
Batch 320, Loss: 0.4468
Batch 330, Loss: 0.4415
Batch 340, Loss: 0.4418
Batch 350, Loss: 0.4636
Batch 360, Loss: 0.4655
Batch 370, Loss: 0.5012
Batch 380, Loss: 0.4127
Batch 390, Loss: 0.4703
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.04763650894165 seconds
Epoch 93 accuracy: 85.44%
Batch 10, Loss: 0.4336
Batch 20, Loss: 0.4783
Batch 30, Loss: 0.4585
Batch 40, Loss: 0.4324
Batch 50, Loss: 0.4648
Batch 60, Loss: 0.4353
Batch 70, Loss: 0.4618
Batch 80, Loss: 0.4569
Batch 90, Loss: 0.4432
Batch 100, Loss: 0.4705
Batch 110, Loss: 0.4287
Batch 120, Loss: 0.4323
Batch 130, Loss: 0.4954
Batch 140, Loss: 0.4266
Batch 150, Loss: 0.5083
Batch 160, Loss: 0.4349
Batch 170, Loss: 0.4251
Batch 180, Loss: 0.4555
Batch 190, Loss: 0.4768
Batch 200, Loss: 0.4483
Batch 210, Loss: 0.4628
Batch 220, Loss: 0.4973
Batch 230, Loss: 0.4711
Batch 240, Loss: 0.4663
Batch 250, Loss: 0.4560
Batch 260, Loss: 0.4689
Batch 270, Loss: 0.4557
Batch 280, Loss: 0.4285
Batch 290, Loss: 0.4301
Batch 300, Loss: 0.4637
Batch 310, Loss: 0.4530
Batch 320, Loss: 0.4578
Batch 330, Loss: 0.4795
Batch 340, Loss: 0.4255
Batch 350, Loss: 0.4466
Batch 360, Loss: 0.4259
Batch 370, Loss: 0.4597
Batch 380, Loss: 0.4490
Batch 390, Loss: 0.4836
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.033530950546265 seconds
Epoch 94 accuracy: 87.92%
Batch 10, Loss: 0.4499
Batch 20, Loss: 0.4502
Batch 30, Loss: 0.4303
Batch 40, Loss: 0.4279
Batch 50, Loss: 0.4652
Batch 60, Loss: 0.4219
Batch 70, Loss: 0.4562
Batch 80, Loss: 0.4280
Batch 90, Loss: 0.4891
Batch 100, Loss: 0.4104
Batch 110, Loss: 0.4827
Batch 120, Loss: 0.4437
Batch 130, Loss: 0.4544
Batch 140, Loss: 0.4284
Batch 150, Loss: 0.4374
Batch 160, Loss: 0.4227
Batch 170, Loss: 0.4487
Batch 180, Loss: 0.4643
Batch 190, Loss: 0.4315
Batch 200, Loss: 0.4447
Batch 210, Loss: 0.4495
Batch 220, Loss: 0.4700
Batch 230, Loss: 0.4378
Batch 240, Loss: 0.5240
Batch 250, Loss: 0.4455
Batch 260, Loss: 0.4729
Batch 270, Loss: 0.4321
Batch 280, Loss: 0.4691
Batch 290, Loss: 0.4039
Batch 300, Loss: 0.4512
Batch 310, Loss: 0.3986
Batch 320, Loss: 0.4444
Batch 330, Loss: 0.4257
Batch 340, Loss: 0.3783
Batch 350, Loss: 0.4681
Batch 360, Loss: 0.4563
Batch 370, Loss: 0.4374
Batch 380, Loss: 0.4528
Batch 390, Loss: 0.4229
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.011313676834106 seconds
Epoch 95 accuracy: 88.18%
Batch 10, Loss: 0.4468
Batch 20, Loss: 0.4118
Batch 30, Loss: 0.4746
Batch 40, Loss: 0.4833
Batch 50, Loss: 0.4586
Batch 60, Loss: 0.4460
Batch 70, Loss: 0.4655
Batch 80, Loss: 0.4950
Batch 90, Loss: 0.4488
Batch 100, Loss: 0.4096
Batch 110, Loss: 0.4463
Batch 120, Loss: 0.4554
Batch 130, Loss: 0.4677
Batch 140, Loss: 0.4789
Batch 150, Loss: 0.4624
Batch 160, Loss: 0.4582
Batch 170, Loss: 0.4463
Batch 180, Loss: 0.4596
Batch 190, Loss: 0.4604
Batch 200, Loss: 0.4628
Batch 210, Loss: 0.4427
Batch 220, Loss: 0.4414
Batch 230, Loss: 0.4058
Batch 240, Loss: 0.4669
Batch 250, Loss: 0.4364
Batch 260, Loss: 0.4730
Batch 270, Loss: 0.4444
Batch 280, Loss: 0.4755
Batch 290, Loss: 0.4570
Batch 300, Loss: 0.4291
Batch 310, Loss: 0.4644
Batch 320, Loss: 0.4424
Batch 330, Loss: 0.4669
Batch 340, Loss: 0.4536
Batch 350, Loss: 0.4297
Batch 360, Loss: 0.4321
Batch 370, Loss: 0.4556
Batch 380, Loss: 0.4742
Batch 390, Loss: 0.4908
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.014745950698853 seconds
Epoch 96 accuracy: 87.82%
Batch 10, Loss: 0.4669
Batch 20, Loss: 0.4411
Batch 30, Loss: 0.4721
Batch 40, Loss: 0.4013
Batch 50, Loss: 0.4022
Batch 60, Loss: 0.4696
Batch 70, Loss: 0.4299
Batch 80, Loss: 0.4421
Batch 90, Loss: 0.4192
Batch 100, Loss: 0.4073
Batch 110, Loss: 0.4447
Batch 120, Loss: 0.4415
Batch 130, Loss: 0.4351
Batch 140, Loss: 0.4385
Batch 150, Loss: 0.4461
Batch 160, Loss: 0.4202
Batch 170, Loss: 0.4203
Batch 180, Loss: 0.4667
Batch 190, Loss: 0.4160
Batch 200, Loss: 0.4259
Batch 210, Loss: 0.4383
Batch 220, Loss: 0.4849
Batch 230, Loss: 0.4575
Batch 240, Loss: 0.4652
Batch 250, Loss: 0.4455
Batch 260, Loss: 0.4846
Batch 270, Loss: 0.4283
Batch 280, Loss: 0.4346
Batch 290, Loss: 0.4532
Batch 300, Loss: 0.4465
Batch 310, Loss: 0.4283
Batch 320, Loss: 0.4361
Batch 330, Loss: 0.4539
Batch 340, Loss: 0.4431
Batch 350, Loss: 0.4579
Batch 360, Loss: 0.4688
Batch 370, Loss: 0.4195
Batch 380, Loss: 0.4349
Batch 390, Loss: 0.4560
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.02894163131714 seconds
Epoch 97 accuracy: 88.44%
Batch 10, Loss: 0.4369
Batch 20, Loss: 0.4416
Batch 30, Loss: 0.4189
Batch 40, Loss: 0.4192
Batch 50, Loss: 0.4332
Batch 60, Loss: 0.4688
Batch 70, Loss: 0.4802
Batch 80, Loss: 0.4679
Batch 90, Loss: 0.4011
Batch 100, Loss: 0.4220
Batch 110, Loss: 0.4092
Batch 120, Loss: 0.4139
Batch 130, Loss: 0.4336
Batch 140, Loss: 0.4576
Batch 150, Loss: 0.4673
Batch 160, Loss: 0.4489
Batch 170, Loss: 0.4423
Batch 180, Loss: 0.4308
Batch 190, Loss: 0.4282
Batch 200, Loss: 0.4530
Batch 210, Loss: 0.4447
Batch 220, Loss: 0.4606
Batch 230, Loss: 0.4389
Batch 240, Loss: 0.4464
Batch 250, Loss: 0.4466
Batch 260, Loss: 0.4428
Batch 270, Loss: 0.4276
Batch 280, Loss: 0.4386
Batch 290, Loss: 0.4343
Batch 300, Loss: 0.4278
Batch 310, Loss: 0.4505
Batch 320, Loss: 0.4088
Batch 330, Loss: 0.4284
Batch 340, Loss: 0.4353
Batch 350, Loss: 0.4591
Batch 360, Loss: 0.4343
Batch 370, Loss: 0.4399
Batch 380, Loss: 0.4486
Batch 390, Loss: 0.4121
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 24.969322204589844 seconds
Epoch 98 accuracy: 89.55%
Batch 10, Loss: 0.4045
Batch 20, Loss: 0.4487
Batch 30, Loss: 0.4166
Batch 40, Loss: 0.4402
Batch 50, Loss: 0.4574
Batch 60, Loss: 0.4380
Batch 70, Loss: 0.4627
Batch 80, Loss: 0.4182
Batch 90, Loss: 0.4212
Batch 100, Loss: 0.4209
Batch 110, Loss: 0.4356
Batch 120, Loss: 0.4092
Batch 130, Loss: 0.4117
Batch 140, Loss: 0.4004
Batch 150, Loss: 0.4668
Batch 160, Loss: 0.4568
Batch 170, Loss: 0.4174
Batch 180, Loss: 0.4528
Batch 190, Loss: 0.4274
Batch 200, Loss: 0.4354
Batch 210, Loss: 0.4768
Batch 220, Loss: 0.4540
Batch 230, Loss: 0.4815
Batch 240, Loss: 0.4539
Batch 250, Loss: 0.4225
Batch 260, Loss: 0.4549
Batch 270, Loss: 0.4179
Batch 280, Loss: 0.4391
Batch 290, Loss: 0.4303
Batch 300, Loss: 0.4111
Batch 310, Loss: 0.4304
Batch 320, Loss: 0.4406
Batch 330, Loss: 0.4761
Batch 340, Loss: 0.4483
Batch 350, Loss: 0.4357
Batch 360, Loss: 0.4556
Batch 370, Loss: 0.4151
Batch 380, Loss: 0.4251
Batch 390, Loss: 0.4611
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.0500705242157 seconds
Epoch 99 accuracy: 88.8%
Batch 10, Loss: 0.4464
Batch 20, Loss: 0.4233
Batch 30, Loss: 0.4887
Batch 40, Loss: 0.4753
Batch 50, Loss: 0.4291
Batch 60, Loss: 0.4585
Batch 70, Loss: 0.4381
Batch 80, Loss: 0.4629
Batch 90, Loss: 0.4603
Batch 100, Loss: 0.4307
Batch 110, Loss: 0.4289
Batch 120, Loss: 0.4804
Batch 130, Loss: 0.4313
Batch 140, Loss: 0.4175
Batch 150, Loss: 0.3841
Batch 160, Loss: 0.3914
Batch 170, Loss: 0.4518
Batch 180, Loss: 0.4469
Batch 190, Loss: 0.4404
Batch 200, Loss: 0.4319
Batch 210, Loss: 0.4107
Batch 220, Loss: 0.4139
Batch 230, Loss: 0.3933
Batch 240, Loss: 0.4037
Batch 250, Loss: 0.4117
Batch 260, Loss: 0.4364
Batch 270, Loss: 0.4420
Batch 280, Loss: 0.4185
Batch 290, Loss: 0.4026
Batch 300, Loss: 0.4564
Batch 310, Loss: 0.4334
Batch 320, Loss: 0.4307
Batch 330, Loss: 0.4126
Batch 340, Loss: 0.4137
Batch 350, Loss: 0.4503
Batch 360, Loss: 0.4135
Batch 370, Loss: 0.4456
Batch 380, Loss: 0.4276
Batch 390, Loss: 0.4137
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.06243920326233 seconds
Epoch 100 accuracy: 87.56%
Batch 10, Loss: 0.4180
Batch 20, Loss: 0.4149
Batch 30, Loss: 0.4342
Batch 40, Loss: 0.3875
Batch 50, Loss: 0.4016
Batch 60, Loss: 0.4413
Batch 70, Loss: 0.4186
Batch 80, Loss: 0.4361
Batch 90, Loss: 0.4283
Batch 100, Loss: 0.4110
Batch 110, Loss: 0.4042
Batch 120, Loss: 0.4364
Batch 130, Loss: 0.4628
Batch 140, Loss: 0.4836
Batch 150, Loss: 0.4609
Batch 160, Loss: 0.4438
Batch 170, Loss: 0.4469
Batch 180, Loss: 0.4474
Batch 190, Loss: 0.4127
Batch 200, Loss: 0.3992
Batch 210, Loss: 0.4492
Batch 220, Loss: 0.4648
Batch 230, Loss: 0.4420
Batch 240, Loss: 0.4213
Batch 250, Loss: 0.4378
Batch 260, Loss: 0.4197
Batch 270, Loss: 0.4270
Batch 280, Loss: 0.4476
Batch 290, Loss: 0.4552
Batch 300, Loss: 0.4467
Batch 310, Loss: 0.4227
Batch 320, Loss: 0.4451
Batch 330, Loss: 0.4626
Batch 340, Loss: 0.4100
Batch 350, Loss: 0.4194
Batch 360, Loss: 0.4317
Batch 370, Loss: 0.4218
Batch 380, Loss: 0.4179
Batch 390, Loss: 0.4141
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 24.9797146320343 seconds
Epoch 101 accuracy: 89.55%
Batch 10, Loss: 0.4506
Batch 20, Loss: 0.4973
Batch 30, Loss: 0.4000
Batch 40, Loss: 0.4358
Batch 50, Loss: 0.4233
Batch 60, Loss: 0.4203
Batch 70, Loss: 0.4495
Batch 80, Loss: 0.4412
Batch 90, Loss: 0.4418
Batch 100, Loss: 0.4466
Batch 110, Loss: 0.4314
Batch 120, Loss: 0.4304
Batch 130, Loss: 0.4116
Batch 140, Loss: 0.4470
Batch 150, Loss: 0.4181
Batch 160, Loss: 0.4447
Batch 170, Loss: 0.3921
Batch 180, Loss: 0.4424
Batch 190, Loss: 0.3908
Batch 200, Loss: 0.4335
Batch 210, Loss: 0.4457
Batch 220, Loss: 0.4381
Batch 230, Loss: 0.4332
Batch 240, Loss: 0.4314
Batch 250, Loss: 0.4168
Batch 260, Loss: 0.4312
Batch 270, Loss: 0.4181
Batch 280, Loss: 0.4200
Batch 290, Loss: 0.4117
Batch 300, Loss: 0.4580
Batch 310, Loss: 0.4109
Batch 320, Loss: 0.4228
Batch 330, Loss: 0.4274
Batch 340, Loss: 0.4287
Batch 350, Loss: 0.4217
Batch 360, Loss: 0.4465
Batch 370, Loss: 0.4445
Batch 380, Loss: 0.4431
Batch 390, Loss: 0.4445
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.041857719421387 seconds
Epoch 102 accuracy: 89.19%
Batch 10, Loss: 0.4061
Batch 20, Loss: 0.4037
Batch 30, Loss: 0.3931
Batch 40, Loss: 0.3934
Batch 50, Loss: 0.4721
Batch 60, Loss: 0.4469
Batch 70, Loss: 0.4187
Batch 80, Loss: 0.4209
Batch 90, Loss: 0.4276
Batch 100, Loss: 0.4333
Batch 110, Loss: 0.4366
Batch 120, Loss: 0.4424
Batch 130, Loss: 0.3855
Batch 140, Loss: 0.4673
Batch 150, Loss: 0.4376
Batch 160, Loss: 0.4260
Batch 170, Loss: 0.4073
Batch 180, Loss: 0.4112
Batch 190, Loss: 0.4005
Batch 200, Loss: 0.4138
Batch 210, Loss: 0.4321
Batch 220, Loss: 0.4331
Batch 230, Loss: 0.4110
Batch 240, Loss: 0.4148
Batch 250, Loss: 0.4091
Batch 260, Loss: 0.4393
Batch 270, Loss: 0.4252
Batch 280, Loss: 0.4184
Batch 290, Loss: 0.4468
Batch 300, Loss: 0.4449
Batch 310, Loss: 0.4132
Batch 320, Loss: 0.4646
Batch 330, Loss: 0.4305
Batch 340, Loss: 0.4100
Batch 350, Loss: 0.4043
Batch 360, Loss: 0.4232
Batch 370, Loss: 0.4169
Batch 380, Loss: 0.4232
Batch 390, Loss: 0.4524
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 24.99639105796814 seconds
Epoch 103 accuracy: 87.5%
Batch 10, Loss: 0.4308
Batch 20, Loss: 0.4043
Batch 30, Loss: 0.4425
Batch 40, Loss: 0.3822
Batch 50, Loss: 0.4187
Batch 60, Loss: 0.3919
Batch 70, Loss: 0.4054
Batch 80, Loss: 0.4157
Batch 90, Loss: 0.4547
Batch 100, Loss: 0.4568
Batch 110, Loss: 0.4176
Batch 120, Loss: 0.4289
Batch 130, Loss: 0.4306
Batch 140, Loss: 0.4697
Batch 150, Loss: 0.4312
Batch 160, Loss: 0.4402
Batch 170, Loss: 0.4455
Batch 180, Loss: 0.4101
Batch 190, Loss: 0.4173
Batch 200, Loss: 0.4171
Batch 210, Loss: 0.4090
Batch 220, Loss: 0.4212
Batch 230, Loss: 0.4264
Batch 240, Loss: 0.4252
Batch 250, Loss: 0.4196
Batch 260, Loss: 0.4156
Batch 270, Loss: 0.4033
Batch 280, Loss: 0.4434
Batch 290, Loss: 0.4440
Batch 300, Loss: 0.4474
Batch 310, Loss: 0.4413
Batch 320, Loss: 0.4357
Batch 330, Loss: 0.4369
Batch 340, Loss: 0.4256
Batch 350, Loss: 0.4304
Batch 360, Loss: 0.4199
Batch 370, Loss: 0.4707
Batch 380, Loss: 0.4297
Batch 390, Loss: 0.4615
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.009854316711426 seconds
Epoch 104 accuracy: 82.95%
Batch 10, Loss: 0.4526
Batch 20, Loss: 0.4174
Batch 30, Loss: 0.4080
Batch 40, Loss: 0.4303
Batch 50, Loss: 0.4311
Batch 60, Loss: 0.3984
Batch 70, Loss: 0.4421
Batch 80, Loss: 0.4221
Batch 90, Loss: 0.3914
Batch 100, Loss: 0.4413
Batch 110, Loss: 0.4648
Batch 120, Loss: 0.4783
Batch 130, Loss: 0.3975
Batch 140, Loss: 0.4026
Batch 150, Loss: 0.4422
Batch 160, Loss: 0.3824
Batch 170, Loss: 0.4339
Batch 180, Loss: 0.4106
Batch 190, Loss: 0.3750
Batch 200, Loss: 0.4253
Batch 210, Loss: 0.4234
Batch 220, Loss: 0.4470
Batch 230, Loss: 0.4061
Batch 240, Loss: 0.4124
Batch 250, Loss: 0.4003
Batch 260, Loss: 0.4456
Batch 270, Loss: 0.4114
Batch 280, Loss: 0.4007
Batch 290, Loss: 0.4167
Batch 300, Loss: 0.4446
Batch 310, Loss: 0.4257
Batch 320, Loss: 0.4169
Batch 330, Loss: 0.4127
Batch 340, Loss: 0.4428
Batch 350, Loss: 0.4388
Batch 360, Loss: 0.4044
Batch 370, Loss: 0.4292
Batch 380, Loss: 0.4540
Batch 390, Loss: 0.4387
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.060505628585815 seconds
Epoch 105 accuracy: 89.58%
Batch 10, Loss: 0.4190
Batch 20, Loss: 0.3991
Batch 30, Loss: 0.4255
Batch 40, Loss: 0.3949
Batch 50, Loss: 0.4237
Batch 60, Loss: 0.4067
Batch 70, Loss: 0.4213
Batch 80, Loss: 0.3992
Batch 90, Loss: 0.4079
Batch 100, Loss: 0.4127
Batch 110, Loss: 0.4201
Batch 120, Loss: 0.4507
Batch 130, Loss: 0.4401
Batch 140, Loss: 0.4384
Batch 150, Loss: 0.3979
Batch 160, Loss: 0.3999
Batch 170, Loss: 0.3902
Batch 180, Loss: 0.4251
Batch 190, Loss: 0.4042
Batch 200, Loss: 0.4476
Batch 210, Loss: 0.4243
Batch 220, Loss: 0.4049
Batch 230, Loss: 0.4616
Batch 240, Loss: 0.4360
Batch 250, Loss: 0.3919
Batch 260, Loss: 0.4278
Batch 270, Loss: 0.4380
Batch 280, Loss: 0.4289
Batch 290, Loss: 0.3986
Batch 300, Loss: 0.4303
Batch 310, Loss: 0.4217
Batch 320, Loss: 0.4500
Batch 330, Loss: 0.4119
Batch 340, Loss: 0.4206
Batch 350, Loss: 0.4313
Batch 360, Loss: 0.4411
Batch 370, Loss: 0.4120
Batch 380, Loss: 0.4045
Batch 390, Loss: 0.4246
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.015674591064453 seconds
Epoch 106 accuracy: 90.05%
Batch 10, Loss: 0.3949
Batch 20, Loss: 0.4099
Batch 30, Loss: 0.4030
Batch 40, Loss: 0.4275
Batch 50, Loss: 0.4255
Batch 60, Loss: 0.3993
Batch 70, Loss: 0.4192
Batch 80, Loss: 0.4126
Batch 90, Loss: 0.3983
Batch 100, Loss: 0.4029
Batch 110, Loss: 0.4037
Batch 120, Loss: 0.4293
Batch 130, Loss: 0.4175
Batch 140, Loss: 0.4069
Batch 150, Loss: 0.4489
Batch 160, Loss: 0.3936
Batch 170, Loss: 0.3950
Batch 180, Loss: 0.4160
Batch 190, Loss: 0.4291
Batch 200, Loss: 0.3908
Batch 210, Loss: 0.4238
Batch 220, Loss: 0.4287
Batch 230, Loss: 0.3668
Batch 240, Loss: 0.3779
Batch 250, Loss: 0.3915
Batch 260, Loss: 0.4301
Batch 270, Loss: 0.4222
Batch 280, Loss: 0.4723
Batch 290, Loss: 0.4249
Batch 300, Loss: 0.4109
Batch 310, Loss: 0.4454
Batch 320, Loss: 0.3883
Batch 330, Loss: 0.4357
Batch 340, Loss: 0.3698
Batch 350, Loss: 0.4291
Batch 360, Loss: 0.4229
Batch 370, Loss: 0.4535
Batch 380, Loss: 0.4562
Batch 390, Loss: 0.4176
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.04677700996399 seconds
Epoch 107 accuracy: 90.29%
Batch 10, Loss: 0.4532
Batch 20, Loss: 0.4233
Batch 30, Loss: 0.4199
Batch 40, Loss: 0.4071
Batch 50, Loss: 0.4248
Batch 60, Loss: 0.3754
Batch 70, Loss: 0.3595
Batch 80, Loss: 0.4321
Batch 90, Loss: 0.4056
Batch 100, Loss: 0.4030
Batch 110, Loss: 0.4124
Batch 120, Loss: 0.4516
Batch 130, Loss: 0.3998
Batch 140, Loss: 0.4001
Batch 150, Loss: 0.4214
Batch 160, Loss: 0.4315
Batch 170, Loss: 0.3915
Batch 180, Loss: 0.4104
Batch 190, Loss: 0.3983
Batch 200, Loss: 0.4003
Batch 210, Loss: 0.4189
Batch 220, Loss: 0.4038
Batch 230, Loss: 0.4367
Batch 240, Loss: 0.4380
Batch 250, Loss: 0.4136
Batch 260, Loss: 0.4038
Batch 270, Loss: 0.4321
Batch 280, Loss: 0.4143
Batch 290, Loss: 0.4060
Batch 300, Loss: 0.4145
Batch 310, Loss: 0.3905
Batch 320, Loss: 0.4322
Batch 330, Loss: 0.3979
Batch 340, Loss: 0.4121
Batch 350, Loss: 0.4210
Batch 360, Loss: 0.4158
Batch 370, Loss: 0.3983
Batch 380, Loss: 0.4546
Batch 390, Loss: 0.4259
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 24.966982126235962 seconds
Epoch 108 accuracy: 87.04%
Batch 10, Loss: 0.4347
Batch 20, Loss: 0.4063
Batch 30, Loss: 0.4146
Batch 40, Loss: 0.3988
Batch 50, Loss: 0.3697
Batch 60, Loss: 0.3951
Batch 70, Loss: 0.4204
Batch 80, Loss: 0.4117
Batch 90, Loss: 0.3956
Batch 100, Loss: 0.4187
Batch 110, Loss: 0.3802
Batch 120, Loss: 0.4050
Batch 130, Loss: 0.4152
Batch 140, Loss: 0.4031
Batch 150, Loss: 0.3953
Batch 160, Loss: 0.4102
Batch 170, Loss: 0.3780
Batch 180, Loss: 0.4095
Batch 190, Loss: 0.3579
Batch 200, Loss: 0.3967
Batch 210, Loss: 0.4099
Batch 220, Loss: 0.4299
Batch 230, Loss: 0.4262
Batch 240, Loss: 0.4082
Batch 250, Loss: 0.4421
Batch 260, Loss: 0.4372
Batch 270, Loss: 0.4216
Batch 280, Loss: 0.4294
Batch 290, Loss: 0.4042
Batch 300, Loss: 0.3906
Batch 310, Loss: 0.3683
Batch 320, Loss: 0.4531
Batch 330, Loss: 0.4434
Batch 340, Loss: 0.4161
Batch 350, Loss: 0.4203
Batch 360, Loss: 0.4166
Batch 370, Loss: 0.4429
Batch 380, Loss: 0.4624
Batch 390, Loss: 0.4286
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.034868240356445 seconds
Epoch 109 accuracy: 87.99%
Batch 10, Loss: 0.4082
Batch 20, Loss: 0.3841
Batch 30, Loss: 0.3865
Batch 40, Loss: 0.4041
Batch 50, Loss: 0.4339
Batch 60, Loss: 0.3707
Batch 70, Loss: 0.3809
Batch 80, Loss: 0.4287
Batch 90, Loss: 0.4083
Batch 100, Loss: 0.4464
Batch 110, Loss: 0.4189
Batch 120, Loss: 0.4432
Batch 130, Loss: 0.4048
Batch 140, Loss: 0.4252
Batch 150, Loss: 0.3818
Batch 160, Loss: 0.3946
Batch 170, Loss: 0.3766
Batch 180, Loss: 0.4224
Batch 190, Loss: 0.4114
Batch 200, Loss: 0.4325
Batch 210, Loss: 0.4109
Batch 220, Loss: 0.3802
Batch 230, Loss: 0.4002
Batch 240, Loss: 0.4378
Batch 250, Loss: 0.4382
Batch 260, Loss: 0.4161
Batch 270, Loss: 0.3548
Batch 280, Loss: 0.4248
Batch 290, Loss: 0.4198
Batch 300, Loss: 0.4428
Batch 310, Loss: 0.3735
Batch 320, Loss: 0.3831
Batch 330, Loss: 0.4277
Batch 340, Loss: 0.4245
Batch 350, Loss: 0.3997
Batch 360, Loss: 0.4466
Batch 370, Loss: 0.4292
Batch 380, Loss: 0.4406
Batch 390, Loss: 0.4225
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 24.997588396072388 seconds
Epoch 110 accuracy: 88.52%
Batch 10, Loss: 0.4178
Batch 20, Loss: 0.3757
Batch 30, Loss: 0.3839
Batch 40, Loss: 0.3842
Batch 50, Loss: 0.4199
Batch 60, Loss: 0.3671
Batch 70, Loss: 0.3733
Batch 80, Loss: 0.4280
Batch 90, Loss: 0.4021
Batch 100, Loss: 0.4144
Batch 110, Loss: 0.4407
Batch 120, Loss: 0.4047
Batch 130, Loss: 0.4303
Batch 140, Loss: 0.4354
Batch 150, Loss: 0.4171
Batch 160, Loss: 0.4043
Batch 170, Loss: 0.4071
Batch 180, Loss: 0.4349
Batch 190, Loss: 0.3669
Batch 200, Loss: 0.4024
Batch 210, Loss: 0.3834
Batch 220, Loss: 0.4539
Batch 230, Loss: 0.3835
Batch 240, Loss: 0.4064
Batch 250, Loss: 0.3919
Batch 260, Loss: 0.3835
Batch 270, Loss: 0.4250
Batch 280, Loss: 0.3980
Batch 290, Loss: 0.4386
Batch 300, Loss: 0.4066
Batch 310, Loss: 0.3985
Batch 320, Loss: 0.3903
Batch 330, Loss: 0.4011
Batch 340, Loss: 0.4400
Batch 350, Loss: 0.4565
Batch 360, Loss: 0.4152
Batch 370, Loss: 0.4462
Batch 380, Loss: 0.4246
Batch 390, Loss: 0.4058
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 24.977355003356934 seconds
Epoch 111 accuracy: 89.65%
Batch 10, Loss: 0.4158
Batch 20, Loss: 0.4236
Batch 30, Loss: 0.3851
Batch 40, Loss: 0.3628
Batch 50, Loss: 0.4043
Batch 60, Loss: 0.3823
Batch 70, Loss: 0.4060
Batch 80, Loss: 0.3848
Batch 90, Loss: 0.4164
Batch 100, Loss: 0.4090
Batch 110, Loss: 0.3773
Batch 120, Loss: 0.3877
Batch 130, Loss: 0.4102
Batch 140, Loss: 0.3732
Batch 150, Loss: 0.3833
Batch 160, Loss: 0.4163
Batch 170, Loss: 0.3857
Batch 180, Loss: 0.4092
Batch 190, Loss: 0.4002
Batch 200, Loss: 0.4179
Batch 210, Loss: 0.4124
Batch 220, Loss: 0.3745
Batch 230, Loss: 0.4186
Batch 240, Loss: 0.4060
Batch 250, Loss: 0.4017
Batch 260, Loss: 0.4385
Batch 270, Loss: 0.4050
Batch 280, Loss: 0.4037
Batch 290, Loss: 0.3949
Batch 300, Loss: 0.4114
Batch 310, Loss: 0.3435
Batch 320, Loss: 0.4088
Batch 330, Loss: 0.3723
Batch 340, Loss: 0.4260
Batch 350, Loss: 0.4051
Batch 360, Loss: 0.4334
Batch 370, Loss: 0.4219
Batch 380, Loss: 0.3874
Batch 390, Loss: 0.4236
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 24.977445125579834 seconds
Epoch 112 accuracy: 88.69%
Batch 10, Loss: 0.4131
Batch 20, Loss: 0.4054
Batch 30, Loss: 0.3721
Batch 40, Loss: 0.4305
Batch 50, Loss: 0.4241
Batch 60, Loss: 0.3923
Batch 70, Loss: 0.4152
Batch 80, Loss: 0.3859
Batch 90, Loss: 0.4019
Batch 100, Loss: 0.4006
Batch 110, Loss: 0.4053
Batch 120, Loss: 0.3836
Batch 130, Loss: 0.3708
Batch 140, Loss: 0.4015
Batch 150, Loss: 0.3808
Batch 160, Loss: 0.3735
Batch 170, Loss: 0.3899
Batch 180, Loss: 0.3811
Batch 190, Loss: 0.4287
Batch 200, Loss: 0.3828
Batch 210, Loss: 0.3944
Batch 220, Loss: 0.4298
Batch 230, Loss: 0.4044
Batch 240, Loss: 0.4212
Batch 250, Loss: 0.3928
Batch 260, Loss: 0.4081
Batch 270, Loss: 0.4121
Batch 280, Loss: 0.3985
Batch 290, Loss: 0.3964
Batch 300, Loss: 0.3906
Batch 310, Loss: 0.4164
Batch 320, Loss: 0.3823
Batch 330, Loss: 0.4041
Batch 340, Loss: 0.4285
Batch 350, Loss: 0.3650
Batch 360, Loss: 0.4236
Batch 370, Loss: 0.3930
Batch 380, Loss: 0.3883
Batch 390, Loss: 0.4049
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.044492721557617 seconds
Epoch 113 accuracy: 87.17%
Batch 10, Loss: 0.4377
Batch 20, Loss: 0.3941
Batch 30, Loss: 0.4325
Batch 40, Loss: 0.4118
Batch 50, Loss: 0.3849
Batch 60, Loss: 0.3782
Batch 70, Loss: 0.3830
Batch 80, Loss: 0.3433
Batch 90, Loss: 0.4015
Batch 100, Loss: 0.3803
Batch 110, Loss: 0.4119
Batch 120, Loss: 0.3766
Batch 130, Loss: 0.3990
Batch 140, Loss: 0.3854
Batch 150, Loss: 0.4337
Batch 160, Loss: 0.3912
Batch 170, Loss: 0.3998
Batch 180, Loss: 0.4010
Batch 190, Loss: 0.4079
Batch 200, Loss: 0.4042
Batch 210, Loss: 0.3963
Batch 220, Loss: 0.4045
Batch 230, Loss: 0.3515
Batch 240, Loss: 0.4038
Batch 250, Loss: 0.4355
Batch 260, Loss: 0.4007
Batch 270, Loss: 0.3777
Batch 280, Loss: 0.3926
Batch 290, Loss: 0.3931
Batch 300, Loss: 0.3899
Batch 310, Loss: 0.3904
Batch 320, Loss: 0.4215
Batch 330, Loss: 0.3856
Batch 340, Loss: 0.3971
Batch 350, Loss: 0.3770
Batch 360, Loss: 0.4201
Batch 370, Loss: 0.4252
Batch 380, Loss: 0.3836
Batch 390, Loss: 0.4128
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 24.967060565948486 seconds
Epoch 114 accuracy: 88.59%
Batch 10, Loss: 0.4299
Batch 20, Loss: 0.3670
Batch 30, Loss: 0.3717
Batch 40, Loss: 0.3882
Batch 50, Loss: 0.4351
Batch 60, Loss: 0.4403
Batch 70, Loss: 0.4083
Batch 80, Loss: 0.3968
Batch 90, Loss: 0.4165
Batch 100, Loss: 0.4188
Batch 110, Loss: 0.3947
Batch 120, Loss: 0.3954
Batch 130, Loss: 0.3908
Batch 140, Loss: 0.3522
Batch 150, Loss: 0.3857
Batch 160, Loss: 0.4018
Batch 170, Loss: 0.3953
Batch 180, Loss: 0.4012
Batch 190, Loss: 0.4103
Batch 200, Loss: 0.3859
Batch 210, Loss: 0.4245
Batch 220, Loss: 0.4049
Batch 230, Loss: 0.4041
Batch 240, Loss: 0.3914
Batch 250, Loss: 0.4359
Batch 260, Loss: 0.4176
Batch 270, Loss: 0.4007
Batch 280, Loss: 0.3317
Batch 290, Loss: 0.3786
Batch 300, Loss: 0.4060
Batch 310, Loss: 0.4076
Batch 320, Loss: 0.3747
Batch 330, Loss: 0.3856
Batch 340, Loss: 0.4092
Batch 350, Loss: 0.3775
Batch 360, Loss: 0.3951
Batch 370, Loss: 0.3725
Batch 380, Loss: 0.4364
Batch 390, Loss: 0.3701
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.05532145500183 seconds
Epoch 115 accuracy: 88.39%
Batch 10, Loss: 0.3862
Batch 20, Loss: 0.3889
Batch 30, Loss: 0.3936
Batch 40, Loss: 0.3661
Batch 50, Loss: 0.3686
Batch 60, Loss: 0.3884
Batch 70, Loss: 0.3778
Batch 80, Loss: 0.3881
Batch 90, Loss: 0.3804
Batch 100, Loss: 0.4110
Batch 110, Loss: 0.3841
Batch 120, Loss: 0.4132
Batch 130, Loss: 0.3903
Batch 140, Loss: 0.3834
Batch 150, Loss: 0.3719
Batch 160, Loss: 0.3941
Batch 170, Loss: 0.3885
Batch 180, Loss: 0.3990
Batch 190, Loss: 0.3916
Batch 200, Loss: 0.4248
Batch 210, Loss: 0.4034
Batch 220, Loss: 0.4154
Batch 230, Loss: 0.3640
Batch 240, Loss: 0.3806
Batch 250, Loss: 0.4276
Batch 260, Loss: 0.3996
Batch 270, Loss: 0.4361
Batch 280, Loss: 0.3694
Batch 290, Loss: 0.3754
Batch 300, Loss: 0.4364
Batch 310, Loss: 0.3591
Batch 320, Loss: 0.3981
Batch 330, Loss: 0.3805
Batch 340, Loss: 0.4010
Batch 350, Loss: 0.3949
Batch 360, Loss: 0.4521
Batch 370, Loss: 0.3583
Batch 380, Loss: 0.3242
Batch 390, Loss: 0.3767
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 24.975794076919556 seconds
Epoch 116 accuracy: 90.45%
Batch 10, Loss: 0.3883
Batch 20, Loss: 0.3825
Batch 30, Loss: 0.3503
Batch 40, Loss: 0.3886
Batch 50, Loss: 0.3928
Batch 60, Loss: 0.4035
Batch 70, Loss: 0.3781
Batch 80, Loss: 0.3656
Batch 90, Loss: 0.3918
Batch 100, Loss: 0.3977
Batch 110, Loss: 0.3779
Batch 120, Loss: 0.4035
Batch 130, Loss: 0.3576
Batch 140, Loss: 0.3606
Batch 150, Loss: 0.3927
Batch 160, Loss: 0.4180
Batch 170, Loss: 0.4070
Batch 180, Loss: 0.3995
Batch 190, Loss: 0.3960
Batch 200, Loss: 0.4187
Batch 210, Loss: 0.3858
Batch 220, Loss: 0.3785
Batch 230, Loss: 0.3977
Batch 240, Loss: 0.4073
Batch 250, Loss: 0.4052
Batch 260, Loss: 0.3833
Batch 270, Loss: 0.3750
Batch 280, Loss: 0.3759
Batch 290, Loss: 0.3877
Batch 300, Loss: 0.3965
Batch 310, Loss: 0.4005
Batch 320, Loss: 0.4354
Batch 330, Loss: 0.4295
Batch 340, Loss: 0.3859
Batch 350, Loss: 0.4008
Batch 360, Loss: 0.3973
Batch 370, Loss: 0.3824
Batch 380, Loss: 0.3917
Batch 390, Loss: 0.3829
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.057908296585083 seconds
Epoch 117 accuracy: 90.2%
Batch 10, Loss: 0.4060
Batch 20, Loss: 0.3857
Batch 30, Loss: 0.3601
Batch 40, Loss: 0.3748
Batch 50, Loss: 0.3727
Batch 60, Loss: 0.4056
Batch 70, Loss: 0.4045
Batch 80, Loss: 0.4103
Batch 90, Loss: 0.3664
Batch 100, Loss: 0.3564
Batch 110, Loss: 0.3877
Batch 120, Loss: 0.3964
Batch 130, Loss: 0.3755
Batch 140, Loss: 0.3971
Batch 150, Loss: 0.3866
Batch 160, Loss: 0.3743
Batch 170, Loss: 0.3837
Batch 180, Loss: 0.3881
Batch 190, Loss: 0.3814
Batch 200, Loss: 0.3517
Batch 210, Loss: 0.3852
Batch 220, Loss: 0.4103
Batch 230, Loss: 0.3946
Batch 240, Loss: 0.3680
Batch 250, Loss: 0.3927
Batch 260, Loss: 0.3739
Batch 270, Loss: 0.3606
Batch 280, Loss: 0.3821
Batch 290, Loss: 0.3993
Batch 300, Loss: 0.4237
Batch 310, Loss: 0.3900
Batch 320, Loss: 0.3768
Batch 330, Loss: 0.3667
Batch 340, Loss: 0.3862
Batch 350, Loss: 0.3796
Batch 360, Loss: 0.4113
Batch 370, Loss: 0.3540
Batch 380, Loss: 0.3760
Batch 390, Loss: 0.4046
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 24.98279643058777 seconds
Epoch 118 accuracy: 90.23%
Batch 10, Loss: 0.3719
Batch 20, Loss: 0.3591
Batch 30, Loss: 0.3814
Batch 40, Loss: 0.3904
Batch 50, Loss: 0.3744
Batch 60, Loss: 0.3938
Batch 70, Loss: 0.3744
Batch 80, Loss: 0.4129
Batch 90, Loss: 0.4083
Batch 100, Loss: 0.3740
Batch 110, Loss: 0.3782
Batch 120, Loss: 0.3666
Batch 130, Loss: 0.3569
Batch 140, Loss: 0.3556
Batch 150, Loss: 0.3793
Batch 160, Loss: 0.3932
Batch 170, Loss: 0.4040
Batch 180, Loss: 0.3981
Batch 190, Loss: 0.4166
Batch 200, Loss: 0.3826
Batch 210, Loss: 0.3726
Batch 220, Loss: 0.3946
Batch 230, Loss: 0.3850
Batch 240, Loss: 0.3991
Batch 250, Loss: 0.3949
Batch 260, Loss: 0.3683
Batch 270, Loss: 0.3993
Batch 280, Loss: 0.3587
Batch 290, Loss: 0.3693
Batch 300, Loss: 0.4231
Batch 310, Loss: 0.3978
Batch 320, Loss: 0.3758
Batch 330, Loss: 0.3744
Batch 340, Loss: 0.3822
Batch 350, Loss: 0.3868
Batch 360, Loss: 0.4160
Batch 370, Loss: 0.4093
Batch 380, Loss: 0.3991
Batch 390, Loss: 0.4407
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.05761170387268 seconds
Epoch 119 accuracy: 88.05%
Batch 10, Loss: 0.3894
Batch 20, Loss: 0.3940
Batch 30, Loss: 0.3471
Batch 40, Loss: 0.3648
Batch 50, Loss: 0.3517
Batch 60, Loss: 0.3899
Batch 70, Loss: 0.4158
Batch 80, Loss: 0.3878
Batch 90, Loss: 0.3957
Batch 100, Loss: 0.3784
Batch 110, Loss: 0.4070
Batch 120, Loss: 0.3856
Batch 130, Loss: 0.3839
Batch 140, Loss: 0.3867
Batch 150, Loss: 0.4108
Batch 160, Loss: 0.3707
Batch 170, Loss: 0.3629
Batch 180, Loss: 0.3951
Batch 190, Loss: 0.3879
Batch 200, Loss: 0.3912
Batch 210, Loss: 0.3260
Batch 220, Loss: 0.3786
Batch 230, Loss: 0.3753
Batch 240, Loss: 0.4154
Batch 250, Loss: 0.3772
Batch 260, Loss: 0.4178
Batch 270, Loss: 0.3881
Batch 280, Loss: 0.3689
Batch 290, Loss: 0.3951
Batch 300, Loss: 0.4259
Batch 310, Loss: 0.3540
Batch 320, Loss: 0.3755
Batch 330, Loss: 0.3935
Batch 340, Loss: 0.3530
Batch 350, Loss: 0.3932
Batch 360, Loss: 0.4068
Batch 370, Loss: 0.3893
Batch 380, Loss: 0.4151
Batch 390, Loss: 0.3707
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 24.956639289855957 seconds
Epoch 120 accuracy: 90.06%
Batch 10, Loss: 0.3648
Batch 20, Loss: 0.3940
Batch 30, Loss: 0.3667
Batch 40, Loss: 0.3671
Batch 50, Loss: 0.3879
Batch 60, Loss: 0.3505
Batch 70, Loss: 0.3850
Batch 80, Loss: 0.3833
Batch 90, Loss: 0.3762
Batch 100, Loss: 0.3755
Batch 110, Loss: 0.3603
Batch 120, Loss: 0.3788
Batch 130, Loss: 0.3870
Batch 140, Loss: 0.3673
Batch 150, Loss: 0.3485
Batch 160, Loss: 0.3549
Batch 170, Loss: 0.4173
Batch 180, Loss: 0.3747
Batch 190, Loss: 0.3884
Batch 200, Loss: 0.3606
Batch 210, Loss: 0.3852
Batch 220, Loss: 0.3474
Batch 230, Loss: 0.3672
Batch 240, Loss: 0.3625
Batch 250, Loss: 0.3875
Batch 260, Loss: 0.4089
Batch 270, Loss: 0.3938
Batch 280, Loss: 0.4190
Batch 290, Loss: 0.3906
Batch 300, Loss: 0.3906
Batch 310, Loss: 0.3965
Batch 320, Loss: 0.3856
Batch 330, Loss: 0.3876
Batch 340, Loss: 0.3856
Batch 350, Loss: 0.3760
Batch 360, Loss: 0.3725
Batch 370, Loss: 0.3595
Batch 380, Loss: 0.4102
Batch 390, Loss: 0.3836
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 24.99444007873535 seconds
Epoch 121 accuracy: 91.31%
Batch 10, Loss: 0.3316
Batch 20, Loss: 0.3936
Batch 30, Loss: 0.3540
Batch 40, Loss: 0.3740
Batch 50, Loss: 0.3437
Batch 60, Loss: 0.3622
Batch 70, Loss: 0.3710
Batch 80, Loss: 0.3885
Batch 90, Loss: 0.4042
Batch 100, Loss: 0.3611
Batch 110, Loss: 0.3710
Batch 120, Loss: 0.3664
Batch 130, Loss: 0.3627
Batch 140, Loss: 0.3847
Batch 150, Loss: 0.3733
Batch 160, Loss: 0.4062
Batch 170, Loss: 0.3980
Batch 180, Loss: 0.3745
Batch 190, Loss: 0.4197
Batch 200, Loss: 0.3917
Batch 210, Loss: 0.3501
Batch 220, Loss: 0.3703
Batch 230, Loss: 0.3752
Batch 240, Loss: 0.3930
Batch 250, Loss: 0.3717
Batch 260, Loss: 0.3708
Batch 270, Loss: 0.3493
Batch 280, Loss: 0.3372
Batch 290, Loss: 0.3494
Batch 300, Loss: 0.3703
Batch 310, Loss: 0.3740
Batch 320, Loss: 0.4076
Batch 330, Loss: 0.3463
Batch 340, Loss: 0.3665
Batch 350, Loss: 0.3905
Batch 360, Loss: 0.3955
Batch 370, Loss: 0.3374
Batch 380, Loss: 0.3813
Batch 390, Loss: 0.3821
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 24.998032331466675 seconds
Epoch 122 accuracy: 90.04%
Batch 10, Loss: 0.3685
Batch 20, Loss: 0.3674
Batch 30, Loss: 0.3665
Batch 40, Loss: 0.3575
Batch 50, Loss: 0.3682
Batch 60, Loss: 0.3858
Batch 70, Loss: 0.3423
Batch 80, Loss: 0.3637
Batch 90, Loss: 0.3769
Batch 100, Loss: 0.4033
Batch 110, Loss: 0.3776
Batch 120, Loss: 0.3863
Batch 130, Loss: 0.3741
Batch 140, Loss: 0.3851
Batch 150, Loss: 0.4100
Batch 160, Loss: 0.3916
Batch 170, Loss: 0.3747
Batch 180, Loss: 0.3739
Batch 190, Loss: 0.3816
Batch 200, Loss: 0.3642
Batch 210, Loss: 0.3748
Batch 220, Loss: 0.3400
Batch 230, Loss: 0.3828
Batch 240, Loss: 0.3790
Batch 250, Loss: 0.3872
Batch 260, Loss: 0.3913
Batch 270, Loss: 0.3896
Batch 280, Loss: 0.3650
Batch 290, Loss: 0.3846
Batch 300, Loss: 0.3627
Batch 310, Loss: 0.3731
Batch 320, Loss: 0.3890
Batch 330, Loss: 0.4089
Batch 340, Loss: 0.4031
Batch 350, Loss: 0.3763
Batch 360, Loss: 0.3765
Batch 370, Loss: 0.3429
Batch 380, Loss: 0.3822
Batch 390, Loss: 0.3600
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 24.995322704315186 seconds
Epoch 123 accuracy: 90.37%
Batch 10, Loss: 0.3438
Batch 20, Loss: 0.3627
Batch 30, Loss: 0.3620
Batch 40, Loss: 0.3691
Batch 50, Loss: 0.3974
Batch 60, Loss: 0.4249
Batch 70, Loss: 0.3972
Batch 80, Loss: 0.3708
Batch 90, Loss: 0.3857
Batch 100, Loss: 0.4002
Batch 110, Loss: 0.3587
Batch 120, Loss: 0.3862
Batch 130, Loss: 0.3491
Batch 140, Loss: 0.3345
Batch 150, Loss: 0.3570
Batch 160, Loss: 0.3748
Batch 170, Loss: 0.3557
Batch 180, Loss: 0.3883
Batch 190, Loss: 0.3811
Batch 200, Loss: 0.3612
Batch 210, Loss: 0.3695
Batch 220, Loss: 0.3907
Batch 230, Loss: 0.3387
Batch 240, Loss: 0.3689
Batch 250, Loss: 0.3678
Batch 260, Loss: 0.4095
Batch 270, Loss: 0.3529
Batch 280, Loss: 0.3664
Batch 290, Loss: 0.3857
Batch 300, Loss: 0.3963
Batch 310, Loss: 0.3633
Batch 320, Loss: 0.3779
Batch 330, Loss: 0.3726
Batch 340, Loss: 0.3724
Batch 350, Loss: 0.3773
Batch 360, Loss: 0.3778
Batch 370, Loss: 0.4051
Batch 380, Loss: 0.3805
Batch 390, Loss: 0.3806
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.01888942718506 seconds
Epoch 124 accuracy: 90.09%
Batch 10, Loss: 0.3471
Batch 20, Loss: 0.3509
Batch 30, Loss: 0.3673
Batch 40, Loss: 0.3284
Batch 50, Loss: 0.3390
Batch 60, Loss: 0.3780
Batch 70, Loss: 0.3353
Batch 80, Loss: 0.3519
Batch 90, Loss: 0.3948
Batch 100, Loss: 0.3724
Batch 110, Loss: 0.3713
Batch 120, Loss: 0.4091
Batch 130, Loss: 0.4016
Batch 140, Loss: 0.3642
Batch 150, Loss: 0.3961
Batch 160, Loss: 0.3810
Batch 170, Loss: 0.3618
Batch 180, Loss: 0.3729
Batch 190, Loss: 0.3453
Batch 200, Loss: 0.3785
Batch 210, Loss: 0.3871
Batch 220, Loss: 0.3667
Batch 230, Loss: 0.3482
Batch 240, Loss: 0.3861
Batch 250, Loss: 0.3833
Batch 260, Loss: 0.3760
Batch 270, Loss: 0.3452
Batch 280, Loss: 0.3462
Batch 290, Loss: 0.3642
Batch 300, Loss: 0.3627
Batch 310, Loss: 0.3489
Batch 320, Loss: 0.3597
Batch 330, Loss: 0.3403
Batch 340, Loss: 0.3529
Batch 350, Loss: 0.3861
Batch 360, Loss: 0.3522
Batch 370, Loss: 0.3522
Batch 380, Loss: 0.3927
Batch 390, Loss: 0.3682
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.035229921340942 seconds
Epoch 125 accuracy: 91.49%
Batch 10, Loss: 0.3743
Batch 20, Loss: 0.3607
Batch 30, Loss: 0.3824
Batch 40, Loss: 0.3252
Batch 50, Loss: 0.3249
Batch 60, Loss: 0.3591
Batch 70, Loss: 0.3754
Batch 80, Loss: 0.3375
Batch 90, Loss: 0.3464
Batch 100, Loss: 0.3438
Batch 110, Loss: 0.3587
Batch 120, Loss: 0.3679
Batch 130, Loss: 0.3404
Batch 140, Loss: 0.3579
Batch 150, Loss: 0.3434
Batch 160, Loss: 0.3614
Batch 170, Loss: 0.3597
Batch 180, Loss: 0.3332
Batch 190, Loss: 0.3944
Batch 200, Loss: 0.3656
Batch 210, Loss: 0.4348
Batch 220, Loss: 0.3680
Batch 230, Loss: 0.3858
Batch 240, Loss: 0.3483
Batch 250, Loss: 0.3979
Batch 260, Loss: 0.3491
Batch 270, Loss: 0.3626
Batch 280, Loss: 0.3714
Batch 290, Loss: 0.3477
Batch 300, Loss: 0.3617
Batch 310, Loss: 0.3518
Batch 320, Loss: 0.3964
Batch 330, Loss: 0.3446
Batch 340, Loss: 0.3639
Batch 350, Loss: 0.3767
Batch 360, Loss: 0.3580
Batch 370, Loss: 0.3778
Batch 380, Loss: 0.3960
Batch 390, Loss: 0.3891
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 24.95537304878235 seconds
Epoch 126 accuracy: 88.26%
Batch 10, Loss: 0.3572
Batch 20, Loss: 0.3677
Batch 30, Loss: 0.3546
Batch 40, Loss: 0.3492
Batch 50, Loss: 0.3387
Batch 60, Loss: 0.3681
Batch 70, Loss: 0.3507
Batch 80, Loss: 0.3241
Batch 90, Loss: 0.3422
Batch 100, Loss: 0.3873
Batch 110, Loss: 0.3838
Batch 120, Loss: 0.3509
Batch 130, Loss: 0.3926
Batch 140, Loss: 0.3558
Batch 150, Loss: 0.3341
Batch 160, Loss: 0.3582
Batch 170, Loss: 0.3824
Batch 180, Loss: 0.3833
Batch 190, Loss: 0.3590
Batch 200, Loss: 0.3693
Batch 210, Loss: 0.3701
Batch 220, Loss: 0.3391
Batch 230, Loss: 0.3493
Batch 240, Loss: 0.3933
Batch 250, Loss: 0.3462
Batch 260, Loss: 0.3785
Batch 270, Loss: 0.4030
Batch 280, Loss: 0.3448
Batch 290, Loss: 0.3630
Batch 300, Loss: 0.3629
Batch 310, Loss: 0.3868
Batch 320, Loss: 0.3706
Batch 330, Loss: 0.4181
Batch 340, Loss: 0.3675
Batch 350, Loss: 0.3584
Batch 360, Loss: 0.3495
Batch 370, Loss: 0.3715
Batch 380, Loss: 0.3786
Batch 390, Loss: 0.3618
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.018980741500854 seconds
Epoch 127 accuracy: 91.46%
Batch 10, Loss: 0.3493
Batch 20, Loss: 0.3517
Batch 30, Loss: 0.3501
Batch 40, Loss: 0.3505
Batch 50, Loss: 0.3660
Batch 60, Loss: 0.3528
Batch 70, Loss: 0.3699
Batch 80, Loss: 0.3854
Batch 90, Loss: 0.3376
Batch 100, Loss: 0.3777
Batch 110, Loss: 0.3801
Batch 120, Loss: 0.3340
Batch 130, Loss: 0.3461
Batch 140, Loss: 0.3537
Batch 150, Loss: 0.3387
Batch 160, Loss: 0.3528
Batch 170, Loss: 0.3180
Batch 180, Loss: 0.3522
Batch 190, Loss: 0.3485
Batch 200, Loss: 0.3133
Batch 210, Loss: 0.3405
Batch 220, Loss: 0.3606
Batch 230, Loss: 0.3703
Batch 240, Loss: 0.3680
Batch 250, Loss: 0.3756
Batch 260, Loss: 0.3539
Batch 270, Loss: 0.3469
Batch 280, Loss: 0.3559
Batch 290, Loss: 0.3918
Batch 300, Loss: 0.3415
Batch 310, Loss: 0.3469
Batch 320, Loss: 0.3842
Batch 330, Loss: 0.3574
Batch 340, Loss: 0.4096
Batch 350, Loss: 0.3626
Batch 360, Loss: 0.3401
Batch 370, Loss: 0.3607
Batch 380, Loss: 0.3742
Batch 390, Loss: 0.3639
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 24.98126459121704 seconds
Epoch 128 accuracy: 90.88%
Batch 10, Loss: 0.3399
Batch 20, Loss: 0.3107
Batch 30, Loss: 0.3431
Batch 40, Loss: 0.3507
Batch 50, Loss: 0.3545
Batch 60, Loss: 0.3699
Batch 70, Loss: 0.3523
Batch 80, Loss: 0.3172
Batch 90, Loss: 0.3090
Batch 100, Loss: 0.3454
Batch 110, Loss: 0.3459
Batch 120, Loss: 0.3332
Batch 130, Loss: 0.3787
Batch 140, Loss: 0.3548
Batch 150, Loss: 0.3857
Batch 160, Loss: 0.3482
Batch 170, Loss: 0.3706
Batch 180, Loss: 0.3881
Batch 190, Loss: 0.4088
Batch 200, Loss: 0.3647
Batch 210, Loss: 0.3559
Batch 220, Loss: 0.3808
Batch 230, Loss: 0.3393
Batch 240, Loss: 0.3690
Batch 250, Loss: 0.3347
Batch 260, Loss: 0.3676
Batch 270, Loss: 0.3495
Batch 280, Loss: 0.3580
Batch 290, Loss: 0.3790
Batch 300, Loss: 0.3390
Batch 310, Loss: 0.3469
Batch 320, Loss: 0.3450
Batch 330, Loss: 0.3235
Batch 340, Loss: 0.3450
Batch 350, Loss: 0.3617
Batch 360, Loss: 0.3592
Batch 370, Loss: 0.3802
Batch 380, Loss: 0.3572
Batch 390, Loss: 0.3904
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 24.997684001922607 seconds
Epoch 129 accuracy: 91.38%
Batch 10, Loss: 0.3627
Batch 20, Loss: 0.3418
Batch 30, Loss: 0.3367
Batch 40, Loss: 0.3349
Batch 50, Loss: 0.3183
Batch 60, Loss: 0.3714
Batch 70, Loss: 0.3562
Batch 80, Loss: 0.3641
Batch 90, Loss: 0.3476
Batch 100, Loss: 0.3359
Batch 110, Loss: 0.3448
Batch 120, Loss: 0.3328
Batch 130, Loss: 0.3346
Batch 140, Loss: 0.3242
Batch 150, Loss: 0.3503
Batch 160, Loss: 0.3734
Batch 170, Loss: 0.3253
Batch 180, Loss: 0.3669
Batch 190, Loss: 0.3654
Batch 200, Loss: 0.3628
Batch 210, Loss: 0.3444
Batch 220, Loss: 0.3552
Batch 230, Loss: 0.3519
Batch 240, Loss: 0.3586
Batch 250, Loss: 0.3672
Batch 260, Loss: 0.3285
Batch 270, Loss: 0.3537
Batch 280, Loss: 0.3633
Batch 290, Loss: 0.3402
Batch 300, Loss: 0.3446
Batch 310, Loss: 0.3277
Batch 320, Loss: 0.3251
Batch 330, Loss: 0.3454
Batch 340, Loss: 0.3366
Batch 350, Loss: 0.3687
Batch 360, Loss: 0.3516
Batch 370, Loss: 0.3322
Batch 380, Loss: 0.3575
Batch 390, Loss: 0.3513
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.027737855911255 seconds
Epoch 130 accuracy: 91.24%
Batch 10, Loss: 0.3080
Batch 20, Loss: 0.3285
Batch 30, Loss: 0.3512
Batch 40, Loss: 0.3675
Batch 50, Loss: 0.3702
Batch 60, Loss: 0.3395
Batch 70, Loss: 0.3452
Batch 80, Loss: 0.3102
Batch 90, Loss: 0.3186
Batch 100, Loss: 0.3383
Batch 110, Loss: 0.3262
Batch 120, Loss: 0.3313
Batch 130, Loss: 0.3479
Batch 140, Loss: 0.3777
Batch 150, Loss: 0.3602
Batch 160, Loss: 0.3500
Batch 170, Loss: 0.3379
Batch 180, Loss: 0.3506
Batch 190, Loss: 0.3655
Batch 200, Loss: 0.3549
Batch 210, Loss: 0.3437
Batch 220, Loss: 0.3330
Batch 230, Loss: 0.3743
Batch 240, Loss: 0.3618
Batch 250, Loss: 0.3576
Batch 260, Loss: 0.3407
Batch 270, Loss: 0.3619
Batch 280, Loss: 0.3432
Batch 290, Loss: 0.3040
Batch 300, Loss: 0.3216
Batch 310, Loss: 0.3940
Batch 320, Loss: 0.3676
Batch 330, Loss: 0.3577
Batch 340, Loss: 0.3606
Batch 350, Loss: 0.3518
Batch 360, Loss: 0.3391
Batch 370, Loss: 0.3879
Batch 380, Loss: 0.4034
Batch 390, Loss: 0.3510
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.045848846435547 seconds
Epoch 131 accuracy: 91.42%
Batch 10, Loss: 0.3301
Batch 20, Loss: 0.3513
Batch 30, Loss: 0.3122
Batch 40, Loss: 0.3381
Batch 50, Loss: 0.3467
Batch 60, Loss: 0.3473
Batch 70, Loss: 0.3243
Batch 80, Loss: 0.3621
Batch 90, Loss: 0.3568
Batch 100, Loss: 0.3431
Batch 110, Loss: 0.3393
Batch 120, Loss: 0.3850
Batch 130, Loss: 0.3383
Batch 140, Loss: 0.3370
Batch 150, Loss: 0.3595
Batch 160, Loss: 0.3197
Batch 170, Loss: 0.3757
Batch 180, Loss: 0.3495
Batch 190, Loss: 0.3039
Batch 200, Loss: 0.3248
Batch 210, Loss: 0.3286
Batch 220, Loss: 0.3505
Batch 230, Loss: 0.3698
Batch 240, Loss: 0.3248
Batch 250, Loss: 0.3430
Batch 260, Loss: 0.3507
Batch 270, Loss: 0.3320
Batch 280, Loss: 0.3633
Batch 290, Loss: 0.3477
Batch 300, Loss: 0.3630
Batch 310, Loss: 0.3511
Batch 320, Loss: 0.3260
Batch 330, Loss: 0.3362
Batch 340, Loss: 0.3220
Batch 350, Loss: 0.3276
Batch 360, Loss: 0.2880
Batch 370, Loss: 0.3081
Batch 380, Loss: 0.3435
Batch 390, Loss: 0.3481
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.02111029624939 seconds
Epoch 132 accuracy: 91.47%
Batch 10, Loss: 0.3338
Batch 20, Loss: 0.3384
Batch 30, Loss: 0.3509
Batch 40, Loss: 0.3104
Batch 50, Loss: 0.3388
Batch 60, Loss: 0.3224
Batch 70, Loss: 0.3137
Batch 80, Loss: 0.3412
Batch 90, Loss: 0.3204
Batch 100, Loss: 0.3384
Batch 110, Loss: 0.3424
Batch 120, Loss: 0.3502
Batch 130, Loss: 0.3718
Batch 140, Loss: 0.3451
Batch 150, Loss: 0.3706
Batch 160, Loss: 0.3308
Batch 170, Loss: 0.3326
Batch 180, Loss: 0.3406
Batch 190, Loss: 0.3160
Batch 200, Loss: 0.3287
Batch 210, Loss: 0.3206
Batch 220, Loss: 0.3179
Batch 230, Loss: 0.3358
Batch 240, Loss: 0.3393
Batch 250, Loss: 0.3415
Batch 260, Loss: 0.3210
Batch 270, Loss: 0.3500
Batch 280, Loss: 0.3453
Batch 290, Loss: 0.3533
Batch 300, Loss: 0.3405
Batch 310, Loss: 0.3499
Batch 320, Loss: 0.3273
Batch 330, Loss: 0.3613
Batch 340, Loss: 0.3428
Batch 350, Loss: 0.3281
Batch 360, Loss: 0.3341
Batch 370, Loss: 0.3548
Batch 380, Loss: 0.3329
Batch 390, Loss: 0.3302
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.046924352645874 seconds
Epoch 133 accuracy: 91.73%
Batch 10, Loss: 0.3448
Batch 20, Loss: 0.3343
Batch 30, Loss: 0.3564
Batch 40, Loss: 0.3401
Batch 50, Loss: 0.3398
Batch 60, Loss: 0.3475
Batch 70, Loss: 0.3079
Batch 80, Loss: 0.3522
Batch 90, Loss: 0.3115
Batch 100, Loss: 0.3167
Batch 110, Loss: 0.3525
Batch 120, Loss: 0.3120
Batch 130, Loss: 0.3420
Batch 140, Loss: 0.3569
Batch 150, Loss: 0.3391
Batch 160, Loss: 0.3520
Batch 170, Loss: 0.3317
Batch 180, Loss: 0.3448
Batch 190, Loss: 0.3286
Batch 200, Loss: 0.3385
Batch 210, Loss: 0.3629
Batch 220, Loss: 0.3418
Batch 230, Loss: 0.3259
Batch 240, Loss: 0.3895
Batch 250, Loss: 0.3215
Batch 260, Loss: 0.3393
Batch 270, Loss: 0.3287
Batch 280, Loss: 0.3287
Batch 290, Loss: 0.3646
Batch 300, Loss: 0.3465
Batch 310, Loss: 0.3327
Batch 320, Loss: 0.3317
Batch 330, Loss: 0.3483
Batch 340, Loss: 0.3461
Batch 350, Loss: 0.3437
Batch 360, Loss: 0.3524
Batch 370, Loss: 0.3339
Batch 380, Loss: 0.3421
Batch 390, Loss: 0.3481
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.03138494491577 seconds
Epoch 134 accuracy: 91.65%
Batch 10, Loss: 0.3650
Batch 20, Loss: 0.2939
Batch 30, Loss: 0.3052
Batch 40, Loss: 0.3332
Batch 50, Loss: 0.3401
Batch 60, Loss: 0.3451
Batch 70, Loss: 0.3428
Batch 80, Loss: 0.3260
Batch 90, Loss: 0.3132
Batch 100, Loss: 0.3909
Batch 110, Loss: 0.3289
Batch 120, Loss: 0.3075
Batch 130, Loss: 0.3239
Batch 140, Loss: 0.3208
Batch 150, Loss: 0.3620
Batch 160, Loss: 0.3275
Batch 170, Loss: 0.3359
Batch 180, Loss: 0.3249
Batch 190, Loss: 0.3214
Batch 200, Loss: 0.3279
Batch 210, Loss: 0.3204
Batch 220, Loss: 0.3268
Batch 230, Loss: 0.3838
Batch 240, Loss: 0.3403
Batch 250, Loss: 0.3974
Batch 260, Loss: 0.3424
Batch 270, Loss: 0.3158
Batch 280, Loss: 0.3461
Batch 290, Loss: 0.3309
Batch 300, Loss: 0.3358
Batch 310, Loss: 0.3511
Batch 320, Loss: 0.3439
Batch 330, Loss: 0.3768
Batch 340, Loss: 0.3548
Batch 350, Loss: 0.3368
Batch 360, Loss: 0.3507
Batch 370, Loss: 0.3420
Batch 380, Loss: 0.3504
Batch 390, Loss: 0.3054
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.018243312835693 seconds
Epoch 135 accuracy: 92.26%
Batch 10, Loss: 0.3186
Batch 20, Loss: 0.3212
Batch 30, Loss: 0.3149
Batch 40, Loss: 0.3223
Batch 50, Loss: 0.3685
Batch 60, Loss: 0.3330
Batch 70, Loss: 0.3378
Batch 80, Loss: 0.3182
Batch 90, Loss: 0.3077
Batch 100, Loss: 0.3375
Batch 110, Loss: 0.3157
Batch 120, Loss: 0.3279
Batch 130, Loss: 0.3604
Batch 140, Loss: 0.3225
Batch 150, Loss: 0.3027
Batch 160, Loss: 0.3214
Batch 170, Loss: 0.3165
Batch 180, Loss: 0.3637
Batch 190, Loss: 0.3323
Batch 200, Loss: 0.3728
Batch 210, Loss: 0.3249
Batch 220, Loss: 0.3443
Batch 230, Loss: 0.3310
Batch 240, Loss: 0.3367
Batch 250, Loss: 0.3079
Batch 260, Loss: 0.3104
Batch 270, Loss: 0.3419
Batch 280, Loss: 0.3143
Batch 290, Loss: 0.3505
Batch 300, Loss: 0.3330
Batch 310, Loss: 0.3043
Batch 320, Loss: 0.3136
Batch 330, Loss: 0.3428
Batch 340, Loss: 0.3376
Batch 350, Loss: 0.3318
Batch 360, Loss: 0.3346
Batch 370, Loss: 0.3746
Batch 380, Loss: 0.3493
Batch 390, Loss: 0.3107
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.06395721435547 seconds
Epoch 136 accuracy: 91.31%
Batch 10, Loss: 0.3411
Batch 20, Loss: 0.3052
Batch 30, Loss: 0.3092
Batch 40, Loss: 0.3048
Batch 50, Loss: 0.3190
Batch 60, Loss: 0.3158
Batch 70, Loss: 0.3251
Batch 80, Loss: 0.3029
Batch 90, Loss: 0.3004
Batch 100, Loss: 0.3246
Batch 110, Loss: 0.3357
Batch 120, Loss: 0.3475
Batch 130, Loss: 0.3333
Batch 140, Loss: 0.3454
Batch 150, Loss: 0.3457
Batch 160, Loss: 0.3397
Batch 170, Loss: 0.3044
Batch 180, Loss: 0.3332
Batch 190, Loss: 0.3306
Batch 200, Loss: 0.3157
Batch 210, Loss: 0.3367
Batch 220, Loss: 0.3110
Batch 230, Loss: 0.3050
Batch 240, Loss: 0.3490
Batch 250, Loss: 0.2943
Batch 260, Loss: 0.3490
Batch 270, Loss: 0.3380
Batch 280, Loss: 0.3130
Batch 290, Loss: 0.3525
Batch 300, Loss: 0.3216
Batch 310, Loss: 0.3304
Batch 320, Loss: 0.3289
Batch 330, Loss: 0.3175
Batch 340, Loss: 0.3383
Batch 350, Loss: 0.3530
Batch 360, Loss: 0.3072
Batch 370, Loss: 0.3049
Batch 380, Loss: 0.3325
Batch 390, Loss: 0.3207
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.06179118156433 seconds
Epoch 137 accuracy: 92.35%
Batch 10, Loss: 0.3216
Batch 20, Loss: 0.2889
Batch 30, Loss: 0.3157
Batch 40, Loss: 0.3066
Batch 50, Loss: 0.2947
Batch 60, Loss: 0.3108
Batch 70, Loss: 0.3292
Batch 80, Loss: 0.2996
Batch 90, Loss: 0.3357
Batch 100, Loss: 0.3218
Batch 110, Loss: 0.3431
Batch 120, Loss: 0.3135
Batch 130, Loss: 0.3195
Batch 140, Loss: 0.3228
Batch 150, Loss: 0.3539
Batch 160, Loss: 0.3403
Batch 170, Loss: 0.3038
Batch 180, Loss: 0.3162
Batch 190, Loss: 0.3210
Batch 200, Loss: 0.3416
Batch 210, Loss: 0.3095
Batch 220, Loss: 0.3219
Batch 230, Loss: 0.3304
Batch 240, Loss: 0.3564
Batch 250, Loss: 0.3244
Batch 260, Loss: 0.3407
Batch 270, Loss: 0.2758
Batch 280, Loss: 0.3207
Batch 290, Loss: 0.3509
Batch 300, Loss: 0.3153
Batch 310, Loss: 0.3112
Batch 320, Loss: 0.3482
Batch 330, Loss: 0.3077
Batch 340, Loss: 0.3473
Batch 350, Loss: 0.3270
Batch 360, Loss: 0.3253
Batch 370, Loss: 0.3384
Batch 380, Loss: 0.3153
Batch 390, Loss: 0.3028
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 24.9759304523468 seconds
Epoch 138 accuracy: 93.13%
Batch 10, Loss: 0.3649
Batch 20, Loss: 0.2820
Batch 30, Loss: 0.2769
Batch 40, Loss: 0.3302
Batch 50, Loss: 0.3513
Batch 60, Loss: 0.3208
Batch 70, Loss: 0.3004
Batch 80, Loss: 0.2950
Batch 90, Loss: 0.3224
Batch 100, Loss: 0.3261
Batch 110, Loss: 0.3150
Batch 120, Loss: 0.3096
Batch 130, Loss: 0.3039
Batch 140, Loss: 0.3259
Batch 150, Loss: 0.2997
Batch 160, Loss: 0.3158
Batch 170, Loss: 0.3155
Batch 180, Loss: 0.3340
Batch 190, Loss: 0.3566
Batch 200, Loss: 0.2829
Batch 210, Loss: 0.3270
Batch 220, Loss: 0.3491
Batch 230, Loss: 0.3052
Batch 240, Loss: 0.3198
Batch 250, Loss: 0.3211
Batch 260, Loss: 0.2897
Batch 270, Loss: 0.3077
Batch 280, Loss: 0.3410
Batch 290, Loss: 0.3480
Batch 300, Loss: 0.3283
Batch 310, Loss: 0.3118
Batch 320, Loss: 0.3244
Batch 330, Loss: 0.3298
Batch 340, Loss: 0.3196
Batch 350, Loss: 0.2971
Batch 360, Loss: 0.2689
Batch 370, Loss: 0.3363
Batch 380, Loss: 0.3400
Batch 390, Loss: 0.3359
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.076945304870605 seconds
Epoch 139 accuracy: 92.02%
Batch 10, Loss: 0.3276
Batch 20, Loss: 0.3073
Batch 30, Loss: 0.3077
Batch 40, Loss: 0.2815
Batch 50, Loss: 0.3349
Batch 60, Loss: 0.2916
Batch 70, Loss: 0.3086
Batch 80, Loss: 0.3173
Batch 90, Loss: 0.3112
Batch 100, Loss: 0.3143
Batch 110, Loss: 0.3128
Batch 120, Loss: 0.3276
Batch 130, Loss: 0.3156
Batch 140, Loss: 0.3079
Batch 150, Loss: 0.3159
Batch 160, Loss: 0.3236
Batch 170, Loss: 0.3479
Batch 180, Loss: 0.3233
Batch 190, Loss: 0.3008
Batch 200, Loss: 0.3190
Batch 210, Loss: 0.2985
Batch 220, Loss: 0.3149
Batch 230, Loss: 0.2854
Batch 240, Loss: 0.3353
Batch 250, Loss: 0.3192
Batch 260, Loss: 0.3247
Batch 270, Loss: 0.3226
Batch 280, Loss: 0.2983
Batch 290, Loss: 0.3153
Batch 300, Loss: 0.3253
Batch 310, Loss: 0.3084
Batch 320, Loss: 0.3310
Batch 330, Loss: 0.3360
Batch 340, Loss: 0.3402
Batch 350, Loss: 0.3134
Batch 360, Loss: 0.3303
Batch 370, Loss: 0.3293
Batch 380, Loss: 0.3189
Batch 390, Loss: 0.3379
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 24.995091438293457 seconds
Epoch 140 accuracy: 91.67%
Batch 10, Loss: 0.2923
Batch 20, Loss: 0.3235
Batch 30, Loss: 0.3265
Batch 40, Loss: 0.2978
Batch 50, Loss: 0.2612
Batch 60, Loss: 0.2942
Batch 70, Loss: 0.3088
Batch 80, Loss: 0.3410
Batch 90, Loss: 0.3084
Batch 100, Loss: 0.3057
Batch 110, Loss: 0.2743
Batch 120, Loss: 0.2869
Batch 130, Loss: 0.2839
Batch 140, Loss: 0.2919
Batch 150, Loss: 0.3167
Batch 160, Loss: 0.3342
Batch 170, Loss: 0.3106
Batch 180, Loss: 0.3115
Batch 190, Loss: 0.2998
Batch 200, Loss: 0.3497
Batch 210, Loss: 0.3140
Batch 220, Loss: 0.3041
Batch 230, Loss: 0.2963
Batch 240, Loss: 0.3282
Batch 250, Loss: 0.3208
Batch 260, Loss: 0.3089
Batch 270, Loss: 0.2929
Batch 280, Loss: 0.3060
Batch 290, Loss: 0.3160
Batch 300, Loss: 0.3113
Batch 310, Loss: 0.2895
Batch 320, Loss: 0.3243
Batch 330, Loss: 0.3416
Batch 340, Loss: 0.3345
Batch 350, Loss: 0.3250
Batch 360, Loss: 0.3529
Batch 370, Loss: 0.3506
Batch 380, Loss: 0.3563
Batch 390, Loss: 0.3146
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 24.982319355010986 seconds
Epoch 141 accuracy: 91.85%
Batch 10, Loss: 0.3310
Batch 20, Loss: 0.3207
Batch 30, Loss: 0.2632
Batch 40, Loss: 0.2912
Batch 50, Loss: 0.3011
Batch 60, Loss: 0.3201
Batch 70, Loss: 0.3320
Batch 80, Loss: 0.2847
Batch 90, Loss: 0.3173
Batch 100, Loss: 0.3122
Batch 110, Loss: 0.3258
Batch 120, Loss: 0.3161
Batch 130, Loss: 0.2807
Batch 140, Loss: 0.3074
Batch 150, Loss: 0.2831
Batch 160, Loss: 0.3223
Batch 170, Loss: 0.3334
Batch 180, Loss: 0.3293
Batch 190, Loss: 0.3184
Batch 200, Loss: 0.3435
Batch 210, Loss: 0.3136
Batch 220, Loss: 0.3336
Batch 230, Loss: 0.3220
Batch 240, Loss: 0.2942
Batch 250, Loss: 0.3020
Batch 260, Loss: 0.3294
Batch 270, Loss: 0.2959
Batch 280, Loss: 0.2977
Batch 290, Loss: 0.2763
Batch 300, Loss: 0.3085
Batch 310, Loss: 0.2971
Batch 320, Loss: 0.3233
Batch 330, Loss: 0.3275
Batch 340, Loss: 0.3065
Batch 350, Loss: 0.3096
Batch 360, Loss: 0.3092
Batch 370, Loss: 0.3221
Batch 380, Loss: 0.2871
Batch 390, Loss: 0.3168
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.031243801116943 seconds
Epoch 142 accuracy: 92.31%
Batch 10, Loss: 0.3091
Batch 20, Loss: 0.3206
Batch 30, Loss: 0.3292
Batch 40, Loss: 0.2986
Batch 50, Loss: 0.3008
Batch 60, Loss: 0.2981
Batch 70, Loss: 0.2981
Batch 80, Loss: 0.2972
Batch 90, Loss: 0.3301
Batch 100, Loss: 0.2970
Batch 110, Loss: 0.3065
Batch 120, Loss: 0.3016
Batch 130, Loss: 0.3027
Batch 140, Loss: 0.3294
Batch 150, Loss: 0.3258
Batch 160, Loss: 0.3272
Batch 170, Loss: 0.2877
Batch 180, Loss: 0.3178
Batch 190, Loss: 0.3046
Batch 200, Loss: 0.3027
Batch 210, Loss: 0.2980
Batch 220, Loss: 0.3101
Batch 230, Loss: 0.2975
Batch 240, Loss: 0.2907
Batch 250, Loss: 0.3075
Batch 260, Loss: 0.3319
Batch 270, Loss: 0.2899
Batch 280, Loss: 0.3310
Batch 290, Loss: 0.2868
Batch 300, Loss: 0.3060
Batch 310, Loss: 0.3030
Batch 320, Loss: 0.3225
Batch 330, Loss: 0.3105
Batch 340, Loss: 0.2993
Batch 350, Loss: 0.3174
Batch 360, Loss: 0.3350
Batch 370, Loss: 0.2805
Batch 380, Loss: 0.3087
Batch 390, Loss: 0.3269
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 24.974666595458984 seconds
Epoch 143 accuracy: 92.83%
Batch 10, Loss: 0.2877
Batch 20, Loss: 0.3036
Batch 30, Loss: 0.2768
Batch 40, Loss: 0.2648
Batch 50, Loss: 0.3114
Batch 60, Loss: 0.2925
Batch 70, Loss: 0.2696
Batch 80, Loss: 0.2837
Batch 90, Loss: 0.2987
Batch 100, Loss: 0.2867
Batch 110, Loss: 0.3022
Batch 120, Loss: 0.3136
Batch 130, Loss: 0.3143
Batch 140, Loss: 0.3055
Batch 150, Loss: 0.2621
Batch 160, Loss: 0.3254
Batch 170, Loss: 0.3400
Batch 180, Loss: 0.3220
Batch 190, Loss: 0.3043
Batch 200, Loss: 0.3137
Batch 210, Loss: 0.3102
Batch 220, Loss: 0.2925
Batch 230, Loss: 0.3009
Batch 240, Loss: 0.3041
Batch 250, Loss: 0.3194
Batch 260, Loss: 0.3117
Batch 270, Loss: 0.3187
Batch 280, Loss: 0.2961
Batch 290, Loss: 0.2929
Batch 300, Loss: 0.3154
Batch 310, Loss: 0.3112
Batch 320, Loss: 0.3100
Batch 330, Loss: 0.3101
Batch 340, Loss: 0.3227
Batch 350, Loss: 0.3018
Batch 360, Loss: 0.2620
Batch 370, Loss: 0.3021
Batch 380, Loss: 0.2949
Batch 390, Loss: 0.2935
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 24.957019567489624 seconds
Epoch 144 accuracy: 92.91%
Batch 10, Loss: 0.3078
Batch 20, Loss: 0.3111
Batch 30, Loss: 0.2699
Batch 40, Loss: 0.2990
Batch 50, Loss: 0.2988
Batch 60, Loss: 0.3110
Batch 70, Loss: 0.3047
Batch 80, Loss: 0.2807
Batch 90, Loss: 0.2943
Batch 100, Loss: 0.2892
Batch 110, Loss: 0.2682
Batch 120, Loss: 0.2701
Batch 130, Loss: 0.2844
Batch 140, Loss: 0.3043
Batch 150, Loss: 0.2639
Batch 160, Loss: 0.3076
Batch 170, Loss: 0.2924
Batch 180, Loss: 0.3007
Batch 190, Loss: 0.3051
Batch 200, Loss: 0.2822
Batch 210, Loss: 0.3082
Batch 220, Loss: 0.2857
Batch 230, Loss: 0.2992
Batch 240, Loss: 0.2851
Batch 250, Loss: 0.3082
Batch 260, Loss: 0.2886
Batch 270, Loss: 0.2909
Batch 280, Loss: 0.2779
Batch 290, Loss: 0.2968
Batch 300, Loss: 0.3012
Batch 310, Loss: 0.3216
Batch 320, Loss: 0.2707
Batch 330, Loss: 0.3147
Batch 340, Loss: 0.3105
Batch 350, Loss: 0.2742
Batch 360, Loss: 0.3145
Batch 370, Loss: 0.3071
Batch 380, Loss: 0.2918
Batch 390, Loss: 0.3016
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.025904417037964 seconds
Epoch 145 accuracy: 93.37%
Batch 10, Loss: 0.3096
Batch 20, Loss: 0.2971
Batch 30, Loss: 0.2758
Batch 40, Loss: 0.2770
Batch 50, Loss: 0.2787
Batch 60, Loss: 0.2826
Batch 70, Loss: 0.3110
Batch 80, Loss: 0.2773
Batch 90, Loss: 0.2670
Batch 100, Loss: 0.2999
Batch 110, Loss: 0.3182
Batch 120, Loss: 0.3087
Batch 130, Loss: 0.2790
Batch 140, Loss: 0.2807
Batch 150, Loss: 0.2905
Batch 160, Loss: 0.3117
Batch 170, Loss: 0.3311
Batch 180, Loss: 0.3279
Batch 190, Loss: 0.3195
Batch 200, Loss: 0.2912
Batch 210, Loss: 0.2884
Batch 220, Loss: 0.3033
Batch 230, Loss: 0.3112
Batch 240, Loss: 0.3366
Batch 250, Loss: 0.2621
Batch 260, Loss: 0.2881
Batch 270, Loss: 0.3048
Batch 280, Loss: 0.2872
Batch 290, Loss: 0.2769
Batch 300, Loss: 0.2856
Batch 310, Loss: 0.2992
Batch 320, Loss: 0.2816
Batch 330, Loss: 0.3326
Batch 340, Loss: 0.2980
Batch 350, Loss: 0.2896
Batch 360, Loss: 0.2478
Batch 370, Loss: 0.3081
Batch 380, Loss: 0.2859
Batch 390, Loss: 0.3177
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.081008911132812 seconds
Epoch 146 accuracy: 92.74%
Batch 10, Loss: 0.2820
Batch 20, Loss: 0.3071
Batch 30, Loss: 0.2934
Batch 40, Loss: 0.2745
Batch 50, Loss: 0.2643
Batch 60, Loss: 0.2838
Batch 70, Loss: 0.2726
Batch 80, Loss: 0.2878
Batch 90, Loss: 0.2753
Batch 100, Loss: 0.2704
Batch 110, Loss: 0.2608
Batch 120, Loss: 0.2931
Batch 130, Loss: 0.2849
Batch 140, Loss: 0.2821
Batch 150, Loss: 0.2715
Batch 160, Loss: 0.3031
Batch 170, Loss: 0.3037
Batch 180, Loss: 0.2828
Batch 190, Loss: 0.2739
Batch 200, Loss: 0.2843
Batch 210, Loss: 0.2934
Batch 220, Loss: 0.2923
Batch 230, Loss: 0.2673
Batch 240, Loss: 0.2965
Batch 250, Loss: 0.3227
Batch 260, Loss: 0.2873
Batch 270, Loss: 0.3161
Batch 280, Loss: 0.2980
Batch 290, Loss: 0.3104
Batch 300, Loss: 0.2999
Batch 310, Loss: 0.2572
Batch 320, Loss: 0.2963
Batch 330, Loss: 0.3077
Batch 340, Loss: 0.2899
Batch 350, Loss: 0.3213
Batch 360, Loss: 0.2856
Batch 370, Loss: 0.2594
Batch 380, Loss: 0.3303
Batch 390, Loss: 0.2924
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 24.984801769256592 seconds
Epoch 147 accuracy: 93.04%
Batch 10, Loss: 0.2656
Batch 20, Loss: 0.2800
Batch 30, Loss: 0.2888
Batch 40, Loss: 0.2598
Batch 50, Loss: 0.2935
Batch 60, Loss: 0.3147
Batch 70, Loss: 0.2944
Batch 80, Loss: 0.2822
Batch 90, Loss: 0.2502
Batch 100, Loss: 0.2881
Batch 110, Loss: 0.2688
Batch 120, Loss: 0.2880
Batch 130, Loss: 0.2689
Batch 140, Loss: 0.2972
Batch 150, Loss: 0.3192
Batch 160, Loss: 0.3011
Batch 170, Loss: 0.2954
Batch 180, Loss: 0.2674
Batch 190, Loss: 0.3024
Batch 200, Loss: 0.2736
Batch 210, Loss: 0.2437
Batch 220, Loss: 0.2884
Batch 230, Loss: 0.2649
Batch 240, Loss: 0.2957
Batch 250, Loss: 0.3201
Batch 260, Loss: 0.2901
Batch 270, Loss: 0.2891
Batch 280, Loss: 0.2746
Batch 290, Loss: 0.3011
Batch 300, Loss: 0.3209
Batch 310, Loss: 0.2971
Batch 320, Loss: 0.2781
Batch 330, Loss: 0.2916
Batch 340, Loss: 0.2694
Batch 350, Loss: 0.2826
Batch 360, Loss: 0.2908
Batch 370, Loss: 0.2819
Batch 380, Loss: 0.2864
Batch 390, Loss: 0.2896
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.040297746658325 seconds
Epoch 148 accuracy: 93.38%
Batch 10, Loss: 0.2856
Batch 20, Loss: 0.2959
Batch 30, Loss: 0.3135
Batch 40, Loss: 0.2564
Batch 50, Loss: 0.2783
Batch 60, Loss: 0.2682
Batch 70, Loss: 0.2802
Batch 80, Loss: 0.2825
Batch 90, Loss: 0.2593
Batch 100, Loss: 0.2765
Batch 110, Loss: 0.2966
Batch 120, Loss: 0.2766
Batch 130, Loss: 0.2876
Batch 140, Loss: 0.2679
Batch 150, Loss: 0.2999
Batch 160, Loss: 0.2641
Batch 170, Loss: 0.2766
Batch 180, Loss: 0.3007
Batch 190, Loss: 0.2917
Batch 200, Loss: 0.2673
Batch 210, Loss: 0.2657
Batch 220, Loss: 0.2597
Batch 230, Loss: 0.2818
Batch 240, Loss: 0.2610
Batch 250, Loss: 0.2810
Batch 260, Loss: 0.3103
Batch 270, Loss: 0.2669
Batch 280, Loss: 0.2682
Batch 290, Loss: 0.2823
Batch 300, Loss: 0.3111
Batch 310, Loss: 0.3051
Batch 320, Loss: 0.3044
Batch 330, Loss: 0.2980
Batch 340, Loss: 0.2763
Batch 350, Loss: 0.2619
Batch 360, Loss: 0.2607
Batch 370, Loss: 0.3063
Batch 380, Loss: 0.2789
Batch 390, Loss: 0.2807
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.040982961654663 seconds
Epoch 149 accuracy: 93.25%
Batch 10, Loss: 0.2993
Batch 20, Loss: 0.2716
Batch 30, Loss: 0.2555
Batch 40, Loss: 0.2619
Batch 50, Loss: 0.2911
Batch 60, Loss: 0.2966
Batch 70, Loss: 0.2598
Batch 80, Loss: 0.2612
Batch 90, Loss: 0.3001
Batch 100, Loss: 0.2552
Batch 110, Loss: 0.2908
Batch 120, Loss: 0.2819
Batch 130, Loss: 0.2349
Batch 140, Loss: 0.2673
Batch 150, Loss: 0.2694
Batch 160, Loss: 0.2643
Batch 170, Loss: 0.2646
Batch 180, Loss: 0.2591
Batch 190, Loss: 0.2743
Batch 200, Loss: 0.2990
Batch 210, Loss: 0.2928
Batch 220, Loss: 0.3011
Batch 230, Loss: 0.2756
Batch 240, Loss: 0.2776
Batch 250, Loss: 0.2607
Batch 260, Loss: 0.2859
Batch 270, Loss: 0.2809
Batch 280, Loss: 0.2836
Batch 290, Loss: 0.3026
Batch 300, Loss: 0.2442
Batch 310, Loss: 0.2883
Batch 320, Loss: 0.2815
Batch 330, Loss: 0.2805
Batch 340, Loss: 0.2767
Batch 350, Loss: 0.2832
Batch 360, Loss: 0.2891
Batch 370, Loss: 0.2803
Batch 380, Loss: 0.2946
Batch 390, Loss: 0.2720
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.075608730316162 seconds
Epoch 150 accuracy: 92.93%
Batch 10, Loss: 0.2672
Batch 20, Loss: 0.3040
Batch 30, Loss: 0.2716
Batch 40, Loss: 0.2577
Batch 50, Loss: 0.2772
Batch 60, Loss: 0.2650
Batch 70, Loss: 0.2638
Batch 80, Loss: 0.2746
Batch 90, Loss: 0.2928
Batch 100, Loss: 0.2878
Batch 110, Loss: 0.3019
Batch 120, Loss: 0.2371
Batch 130, Loss: 0.2696
Batch 140, Loss: 0.2742
Batch 150, Loss: 0.2694
Batch 160, Loss: 0.2644
Batch 170, Loss: 0.2519
Batch 180, Loss: 0.2545
Batch 190, Loss: 0.2650
Batch 200, Loss: 0.2748
Batch 210, Loss: 0.2927
Batch 220, Loss: 0.2565
Batch 230, Loss: 0.3049
Batch 240, Loss: 0.2871
Batch 250, Loss: 0.2469
Batch 260, Loss: 0.2821
Batch 270, Loss: 0.2696
Batch 280, Loss: 0.2974
Batch 290, Loss: 0.2811
Batch 300, Loss: 0.2850
Batch 310, Loss: 0.2785
Batch 320, Loss: 0.2926
Batch 330, Loss: 0.2606
Batch 340, Loss: 0.2939
Batch 350, Loss: 0.2637
Batch 360, Loss: 0.2944
Batch 370, Loss: 0.2787
Batch 380, Loss: 0.2465
Batch 390, Loss: 0.2634
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.018552780151367 seconds
Epoch 151 accuracy: 94.2%
Batch 10, Loss: 0.2547
Batch 20, Loss: 0.2640
Batch 30, Loss: 0.2644
Batch 40, Loss: 0.2683
Batch 50, Loss: 0.2708
Batch 60, Loss: 0.2568
Batch 70, Loss: 0.2814
Batch 80, Loss: 0.2661
Batch 90, Loss: 0.2284
Batch 100, Loss: 0.2571
Batch 110, Loss: 0.2893
Batch 120, Loss: 0.2524
Batch 130, Loss: 0.2626
Batch 140, Loss: 0.2905
Batch 150, Loss: 0.2507
Batch 160, Loss: 0.2654
Batch 170, Loss: 0.2511
Batch 180, Loss: 0.2471
Batch 190, Loss: 0.2580
Batch 200, Loss: 0.2862
Batch 210, Loss: 0.2767
Batch 220, Loss: 0.2842
Batch 230, Loss: 0.2919
Batch 240, Loss: 0.2921
Batch 250, Loss: 0.2678
Batch 260, Loss: 0.2442
Batch 270, Loss: 0.2640
Batch 280, Loss: 0.2622
Batch 290, Loss: 0.2613
Batch 300, Loss: 0.2561
Batch 310, Loss: 0.3107
Batch 320, Loss: 0.2695
Batch 330, Loss: 0.2938
Batch 340, Loss: 0.2473
Batch 350, Loss: 0.2904
Batch 360, Loss: 0.2532
Batch 370, Loss: 0.2761
Batch 380, Loss: 0.2705
Batch 390, Loss: 0.2523
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.042603969573975 seconds
Epoch 152 accuracy: 93.72%
Batch 10, Loss: 0.2697
Batch 20, Loss: 0.2763
Batch 30, Loss: 0.2448
Batch 40, Loss: 0.2543
Batch 50, Loss: 0.2687
Batch 60, Loss: 0.2618
Batch 70, Loss: 0.2596
Batch 80, Loss: 0.2743
Batch 90, Loss: 0.2685
Batch 100, Loss: 0.2498
Batch 110, Loss: 0.2439
Batch 120, Loss: 0.2527
Batch 130, Loss: 0.2836
Batch 140, Loss: 0.2499
Batch 150, Loss: 0.2886
Batch 160, Loss: 0.2960
Batch 170, Loss: 0.2761
Batch 180, Loss: 0.2733
Batch 190, Loss: 0.2695
Batch 200, Loss: 0.3035
Batch 210, Loss: 0.2613
Batch 220, Loss: 0.2648
Batch 230, Loss: 0.2331
Batch 240, Loss: 0.2614
Batch 250, Loss: 0.2631
Batch 260, Loss: 0.2746
Batch 270, Loss: 0.2802
Batch 280, Loss: 0.2853
Batch 290, Loss: 0.2688
Batch 300, Loss: 0.2985
Batch 310, Loss: 0.2743
Batch 320, Loss: 0.2670
Batch 330, Loss: 0.2929
Batch 340, Loss: 0.2709
Batch 350, Loss: 0.2561
Batch 360, Loss: 0.2856
Batch 370, Loss: 0.2518
Batch 380, Loss: 0.2402
Batch 390, Loss: 0.2859
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.041913986206055 seconds
Epoch 153 accuracy: 93.98%
Batch 10, Loss: 0.2554
Batch 20, Loss: 0.2533
Batch 30, Loss: 0.2657
Batch 40, Loss: 0.2513
Batch 50, Loss: 0.2481
Batch 60, Loss: 0.2324
Batch 70, Loss: 0.2819
Batch 80, Loss: 0.2854
Batch 90, Loss: 0.2501
Batch 100, Loss: 0.2700
Batch 110, Loss: 0.2670
Batch 120, Loss: 0.2519
Batch 130, Loss: 0.2614
Batch 140, Loss: 0.2577
Batch 150, Loss: 0.2558
Batch 160, Loss: 0.2508
Batch 170, Loss: 0.2392
Batch 180, Loss: 0.2486
Batch 190, Loss: 0.2726
Batch 200, Loss: 0.2535
Batch 210, Loss: 0.2764
Batch 220, Loss: 0.2744
Batch 230, Loss: 0.2577
Batch 240, Loss: 0.2800
Batch 250, Loss: 0.2498
Batch 260, Loss: 0.2483
Batch 270, Loss: 0.2623
Batch 280, Loss: 0.2839
Batch 290, Loss: 0.2648
Batch 300, Loss: 0.2386
Batch 310, Loss: 0.2605
Batch 320, Loss: 0.2849
Batch 330, Loss: 0.2835
Batch 340, Loss: 0.2808
Batch 350, Loss: 0.2615
Batch 360, Loss: 0.2965
Batch 370, Loss: 0.2998
Batch 380, Loss: 0.2724
Batch 390, Loss: 0.2764
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 24.993621587753296 seconds
Epoch 154 accuracy: 94.2%
Batch 10, Loss: 0.2747
Batch 20, Loss: 0.2703
Batch 30, Loss: 0.3156
Batch 40, Loss: 0.2666
Batch 50, Loss: 0.2519
Batch 60, Loss: 0.2517
Batch 70, Loss: 0.2469
Batch 80, Loss: 0.2388
Batch 90, Loss: 0.2254
Batch 100, Loss: 0.2225
Batch 110, Loss: 0.2400
Batch 120, Loss: 0.2703
Batch 130, Loss: 0.2606
Batch 140, Loss: 0.2807
Batch 150, Loss: 0.2728
Batch 160, Loss: 0.2752
Batch 170, Loss: 0.2458
Batch 180, Loss: 0.2581
Batch 190, Loss: 0.2533
Batch 200, Loss: 0.2703
Batch 210, Loss: 0.2662
Batch 220, Loss: 0.2512
Batch 230, Loss: 0.2615
Batch 240, Loss: 0.2437
Batch 250, Loss: 0.2383
Batch 260, Loss: 0.2348
Batch 270, Loss: 0.2712
Batch 280, Loss: 0.2639
Batch 290, Loss: 0.2769
Batch 300, Loss: 0.2668
Batch 310, Loss: 0.2834
Batch 320, Loss: 0.2645
Batch 330, Loss: 0.2498
Batch 340, Loss: 0.2764
Batch 350, Loss: 0.2698
Batch 360, Loss: 0.2729
Batch 370, Loss: 0.2445
Batch 380, Loss: 0.2573
Batch 390, Loss: 0.2788
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 24.999862670898438 seconds
Epoch 155 accuracy: 93.98%
Batch 10, Loss: 0.2482
Batch 20, Loss: 0.2494
Batch 30, Loss: 0.2644
Batch 40, Loss: 0.2627
Batch 50, Loss: 0.2399
Batch 60, Loss: 0.2550
Batch 70, Loss: 0.2379
Batch 80, Loss: 0.2256
Batch 90, Loss: 0.2346
Batch 100, Loss: 0.2665
Batch 110, Loss: 0.2591
Batch 120, Loss: 0.2486
Batch 130, Loss: 0.2530
Batch 140, Loss: 0.2741
Batch 150, Loss: 0.2695
Batch 160, Loss: 0.2888
Batch 170, Loss: 0.2836
Batch 180, Loss: 0.2790
Batch 190, Loss: 0.2756
Batch 200, Loss: 0.2667
Batch 210, Loss: 0.2493
Batch 220, Loss: 0.2620
Batch 230, Loss: 0.2426
Batch 240, Loss: 0.2888
Batch 250, Loss: 0.2885
Batch 260, Loss: 0.2506
Batch 270, Loss: 0.2491
Batch 280, Loss: 0.2530
Batch 290, Loss: 0.2407
Batch 300, Loss: 0.2389
Batch 310, Loss: 0.2382
Batch 320, Loss: 0.2740
Batch 330, Loss: 0.2704
Batch 340, Loss: 0.2625
Batch 350, Loss: 0.2604
Batch 360, Loss: 0.2658
Batch 370, Loss: 0.2542
Batch 380, Loss: 0.2758
Batch 390, Loss: 0.2363
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.010525941848755 seconds
Epoch 156 accuracy: 93.79%
Batch 10, Loss: 0.2766
Batch 20, Loss: 0.2384
Batch 30, Loss: 0.2483
Batch 40, Loss: 0.2472
Batch 50, Loss: 0.2597
Batch 60, Loss: 0.2584
Batch 70, Loss: 0.2550
Batch 80, Loss: 0.2953
Batch 90, Loss: 0.2590
Batch 100, Loss: 0.2539
Batch 110, Loss: 0.2521
Batch 120, Loss: 0.2487
Batch 130, Loss: 0.2508
Batch 140, Loss: 0.2707
Batch 150, Loss: 0.2468
Batch 160, Loss: 0.2296
Batch 170, Loss: 0.2612
Batch 180, Loss: 0.2353
Batch 190, Loss: 0.2516
Batch 200, Loss: 0.2244
Batch 210, Loss: 0.2283
Batch 220, Loss: 0.2500
Batch 230, Loss: 0.2475
Batch 240, Loss: 0.2760
Batch 250, Loss: 0.2498
Batch 260, Loss: 0.2368
Batch 270, Loss: 0.2550
Batch 280, Loss: 0.2421
Batch 290, Loss: 0.2618
Batch 300, Loss: 0.2137
Batch 310, Loss: 0.2428
Batch 320, Loss: 0.2700
Batch 330, Loss: 0.2679
Batch 340, Loss: 0.2728
Batch 350, Loss: 0.2588
Batch 360, Loss: 0.2572
Batch 370, Loss: 0.2686
Batch 380, Loss: 0.2353
Batch 390, Loss: 0.2614
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.1020188331604 seconds
Epoch 157 accuracy: 94.27%
Batch 10, Loss: 0.2520
Batch 20, Loss: 0.2439
Batch 30, Loss: 0.2790
Batch 40, Loss: 0.2556
Batch 50, Loss: 0.2578
Batch 60, Loss: 0.2413
Batch 70, Loss: 0.2230
Batch 80, Loss: 0.2572
Batch 90, Loss: 0.2449
Batch 100, Loss: 0.2425
Batch 110, Loss: 0.2669
Batch 120, Loss: 0.2617
Batch 130, Loss: 0.2742
Batch 140, Loss: 0.2263
Batch 150, Loss: 0.2528
Batch 160, Loss: 0.2495
Batch 170, Loss: 0.2670
Batch 180, Loss: 0.2519
Batch 190, Loss: 0.2497
Batch 200, Loss: 0.2740
Batch 210, Loss: 0.2502
Batch 220, Loss: 0.2581
Batch 230, Loss: 0.2227
Batch 240, Loss: 0.2686
Batch 250, Loss: 0.2304
Batch 260, Loss: 0.2601
Batch 270, Loss: 0.2324
Batch 280, Loss: 0.2648
Batch 290, Loss: 0.2730
Batch 300, Loss: 0.2332
Batch 310, Loss: 0.2636
Batch 320, Loss: 0.2646
Batch 330, Loss: 0.2453
Batch 340, Loss: 0.2204
Batch 350, Loss: 0.2408
Batch 360, Loss: 0.2846
Batch 370, Loss: 0.2641
Batch 380, Loss: 0.2605
Batch 390, Loss: 0.2365
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.052951335906982 seconds
Epoch 158 accuracy: 94.04%
Batch 10, Loss: 0.2513
Batch 20, Loss: 0.2426
Batch 30, Loss: 0.2425
Batch 40, Loss: 0.2364
Batch 50, Loss: 0.2448
Batch 60, Loss: 0.2102
Batch 70, Loss: 0.2295
Batch 80, Loss: 0.2539
Batch 90, Loss: 0.2349
Batch 100, Loss: 0.2592
Batch 110, Loss: 0.2556
Batch 120, Loss: 0.2545
Batch 130, Loss: 0.2364
Batch 140, Loss: 0.2863
Batch 150, Loss: 0.2467
Batch 160, Loss: 0.2300
Batch 170, Loss: 0.2450
Batch 180, Loss: 0.2305
Batch 190, Loss: 0.2323
Batch 200, Loss: 0.2725
Batch 210, Loss: 0.2412
Batch 220, Loss: 0.2616
Batch 230, Loss: 0.2368
Batch 240, Loss: 0.2230
Batch 250, Loss: 0.2550
Batch 260, Loss: 0.2518
Batch 270, Loss: 0.2322
Batch 280, Loss: 0.2423
Batch 290, Loss: 0.2268
Batch 300, Loss: 0.2509
Batch 310, Loss: 0.2567
Batch 320, Loss: 0.2781
Batch 330, Loss: 0.2497
Batch 340, Loss: 0.2470
Batch 350, Loss: 0.2568
Batch 360, Loss: 0.2516
Batch 370, Loss: 0.2751
Batch 380, Loss: 0.2441
Batch 390, Loss: 0.2540
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.035180807113647 seconds
Epoch 159 accuracy: 93.98%
Batch 10, Loss: 0.2264
Batch 20, Loss: 0.2251
Batch 30, Loss: 0.2326
Batch 40, Loss: 0.2488
Batch 50, Loss: 0.2246
Batch 60, Loss: 0.2487
Batch 70, Loss: 0.2240
Batch 80, Loss: 0.2566
Batch 90, Loss: 0.2355
Batch 100, Loss: 0.2670
Batch 110, Loss: 0.2628
Batch 120, Loss: 0.2300
Batch 130, Loss: 0.2287
Batch 140, Loss: 0.2509
Batch 150, Loss: 0.2432
Batch 160, Loss: 0.2067
Batch 170, Loss: 0.2712
Batch 180, Loss: 0.2271
Batch 190, Loss: 0.2501
Batch 200, Loss: 0.2343
Batch 210, Loss: 0.2267
Batch 220, Loss: 0.2463
Batch 230, Loss: 0.2469
Batch 240, Loss: 0.2421
Batch 250, Loss: 0.2548
Batch 260, Loss: 0.2518
Batch 270, Loss: 0.2732
Batch 280, Loss: 0.2223
Batch 290, Loss: 0.2384
Batch 300, Loss: 0.2336
Batch 310, Loss: 0.2340
Batch 320, Loss: 0.2363
Batch 330, Loss: 0.2620
Batch 340, Loss: 0.2278
Batch 350, Loss: 0.2329
Batch 360, Loss: 0.2594
Batch 370, Loss: 0.2379
Batch 380, Loss: 0.2380
Batch 390, Loss: 0.2306
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.021331310272217 seconds
Epoch 160 accuracy: 94.32%
Batch 10, Loss: 0.2577
Batch 20, Loss: 0.2442
Batch 30, Loss: 0.2311
Batch 40, Loss: 0.2418
Batch 50, Loss: 0.2313
Batch 60, Loss: 0.2617
Batch 70, Loss: 0.2174
Batch 80, Loss: 0.2544
Batch 90, Loss: 0.2368
Batch 100, Loss: 0.2552
Batch 110, Loss: 0.2468
Batch 120, Loss: 0.2437
Batch 130, Loss: 0.2338
Batch 140, Loss: 0.2252
Batch 150, Loss: 0.2302
Batch 160, Loss: 0.2371
Batch 170, Loss: 0.2413
Batch 180, Loss: 0.2023
Batch 190, Loss: 0.2462
Batch 200, Loss: 0.2365
Batch 210, Loss: 0.2362
Batch 220, Loss: 0.2165
Batch 230, Loss: 0.2312
Batch 240, Loss: 0.2291
Batch 250, Loss: 0.2232
Batch 260, Loss: 0.2246
Batch 270, Loss: 0.2286
Batch 280, Loss: 0.2402
Batch 290, Loss: 0.2341
Batch 300, Loss: 0.2205
Batch 310, Loss: 0.2286
Batch 320, Loss: 0.2495
Batch 330, Loss: 0.2466
Batch 340, Loss: 0.2450
Batch 350, Loss: 0.2498
Batch 360, Loss: 0.2466
Batch 370, Loss: 0.2434
Batch 380, Loss: 0.2449
Batch 390, Loss: 0.2136
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.003969430923462 seconds
Epoch 161 accuracy: 94.69%
Batch 10, Loss: 0.2464
Batch 20, Loss: 0.2480
Batch 30, Loss: 0.2288
Batch 40, Loss: 0.2115
Batch 50, Loss: 0.2310
Batch 60, Loss: 0.2242
Batch 70, Loss: 0.2120
Batch 80, Loss: 0.2388
Batch 90, Loss: 0.2316
Batch 100, Loss: 0.2299
Batch 110, Loss: 0.2256
Batch 120, Loss: 0.2389
Batch 130, Loss: 0.2591
Batch 140, Loss: 0.2145
Batch 150, Loss: 0.1911
Batch 160, Loss: 0.2368
Batch 170, Loss: 0.2291
Batch 180, Loss: 0.2444
Batch 190, Loss: 0.2365
Batch 200, Loss: 0.2290
Batch 210, Loss: 0.2366
Batch 220, Loss: 0.2215
Batch 230, Loss: 0.2625
Batch 240, Loss: 0.2063
Batch 250, Loss: 0.2288
Batch 260, Loss: 0.2231
Batch 270, Loss: 0.2240
Batch 280, Loss: 0.1974
Batch 290, Loss: 0.2257
Batch 300, Loss: 0.2274
Batch 310, Loss: 0.2325
Batch 320, Loss: 0.2429
Batch 330, Loss: 0.2454
Batch 340, Loss: 0.2194
Batch 350, Loss: 0.2347
Batch 360, Loss: 0.2432
Batch 370, Loss: 0.2166
Batch 380, Loss: 0.2220
Batch 390, Loss: 0.2641
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.00097680091858 seconds
Epoch 162 accuracy: 94.76%
Batch 10, Loss: 0.2136
Batch 20, Loss: 0.2263
Batch 30, Loss: 0.2166
Batch 40, Loss: 0.2210
Batch 50, Loss: 0.1981
Batch 60, Loss: 0.2280
Batch 70, Loss: 0.2113
Batch 80, Loss: 0.2555
Batch 90, Loss: 0.2094
Batch 100, Loss: 0.2304
Batch 110, Loss: 0.2237
Batch 120, Loss: 0.2336
Batch 130, Loss: 0.2564
Batch 140, Loss: 0.2215
Batch 150, Loss: 0.2163
Batch 160, Loss: 0.2274
Batch 170, Loss: 0.2255
Batch 180, Loss: 0.1862
Batch 190, Loss: 0.2493
Batch 200, Loss: 0.2471
Batch 210, Loss: 0.2635
Batch 220, Loss: 0.2136
Batch 230, Loss: 0.2346
Batch 240, Loss: 0.2035
Batch 250, Loss: 0.2142
Batch 260, Loss: 0.2186
Batch 270, Loss: 0.2519
Batch 280, Loss: 0.2153
Batch 290, Loss: 0.2043
Batch 300, Loss: 0.2026
Batch 310, Loss: 0.2437
Batch 320, Loss: 0.2455
Batch 330, Loss: 0.2184
Batch 340, Loss: 0.2322
Batch 350, Loss: 0.2524
Batch 360, Loss: 0.2264
Batch 370, Loss: 0.2702
Batch 380, Loss: 0.2336
Batch 390, Loss: 0.2243
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.052364826202393 seconds
Epoch 163 accuracy: 94.93%
Batch 10, Loss: 0.2273
Batch 20, Loss: 0.2172
Batch 30, Loss: 0.2198
Batch 40, Loss: 0.2382
Batch 50, Loss: 0.2105
Batch 60, Loss: 0.2069
Batch 70, Loss: 0.2301
Batch 80, Loss: 0.2271
Batch 90, Loss: 0.2131
Batch 100, Loss: 0.2447
Batch 110, Loss: 0.2064
Batch 120, Loss: 0.1993
Batch 130, Loss: 0.2078
Batch 140, Loss: 0.1986
Batch 150, Loss: 0.2402
Batch 160, Loss: 0.2185
Batch 170, Loss: 0.2107
Batch 180, Loss: 0.2207
Batch 190, Loss: 0.2303
Batch 200, Loss: 0.2040
Batch 210, Loss: 0.2298
Batch 220, Loss: 0.2229
Batch 230, Loss: 0.2088
Batch 240, Loss: 0.2501
Batch 250, Loss: 0.2388
Batch 260, Loss: 0.2357
Batch 270, Loss: 0.2079
Batch 280, Loss: 0.2364
Batch 290, Loss: 0.2449
Batch 300, Loss: 0.2342
Batch 310, Loss: 0.2037
Batch 320, Loss: 0.2258
Batch 330, Loss: 0.2273
Batch 340, Loss: 0.1926
Batch 350, Loss: 0.2338
Batch 360, Loss: 0.2153
Batch 370, Loss: 0.2147
Batch 380, Loss: 0.2123
Batch 390, Loss: 0.2230
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.038546562194824 seconds
Epoch 164 accuracy: 94.75%
Batch 10, Loss: 0.2309
Batch 20, Loss: 0.2067
Batch 30, Loss: 0.2042
Batch 40, Loss: 0.2318
Batch 50, Loss: 0.2043
Batch 60, Loss: 0.2060
Batch 70, Loss: 0.2061
Batch 80, Loss: 0.1996
Batch 90, Loss: 0.2260
Batch 100, Loss: 0.2442
Batch 110, Loss: 0.2143
Batch 120, Loss: 0.2373
Batch 130, Loss: 0.2390
Batch 140, Loss: 0.2262
Batch 150, Loss: 0.2288
Batch 160, Loss: 0.2203
Batch 170, Loss: 0.2018
Batch 180, Loss: 0.1945
Batch 190, Loss: 0.2167
Batch 200, Loss: 0.2081
Batch 210, Loss: 0.2227
Batch 220, Loss: 0.2329
Batch 230, Loss: 0.2006
Batch 240, Loss: 0.2264
Batch 250, Loss: 0.2330
Batch 260, Loss: 0.2043
Batch 270, Loss: 0.2282
Batch 280, Loss: 0.2402
Batch 290, Loss: 0.2430
Batch 300, Loss: 0.2197
Batch 310, Loss: 0.2315
Batch 320, Loss: 0.2488
Batch 330, Loss: 0.2246
Batch 340, Loss: 0.2372
Batch 350, Loss: 0.2355
Batch 360, Loss: 0.2184
Batch 370, Loss: 0.2323
Batch 380, Loss: 0.2234
Batch 390, Loss: 0.2034
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.068758726119995 seconds
Epoch 165 accuracy: 94.4%
Batch 10, Loss: 0.2019
Batch 20, Loss: 0.2220
Batch 30, Loss: 0.2107
Batch 40, Loss: 0.1952
Batch 50, Loss: 0.2157
Batch 60, Loss: 0.2140
Batch 70, Loss: 0.2087
Batch 80, Loss: 0.2083
Batch 90, Loss: 0.1960
Batch 100, Loss: 0.1945
Batch 110, Loss: 0.2265
Batch 120, Loss: 0.2261
Batch 130, Loss: 0.1938
Batch 140, Loss: 0.2123
Batch 150, Loss: 0.2301
Batch 160, Loss: 0.2022
Batch 170, Loss: 0.2359
Batch 180, Loss: 0.2052
Batch 190, Loss: 0.2170
Batch 200, Loss: 0.2511
Batch 210, Loss: 0.2189
Batch 220, Loss: 0.2322
Batch 230, Loss: 0.2332
Batch 240, Loss: 0.2027
Batch 250, Loss: 0.2094
Batch 260, Loss: 0.2104
Batch 270, Loss: 0.1996
Batch 280, Loss: 0.2052
Batch 290, Loss: 0.2025
Batch 300, Loss: 0.2125
Batch 310, Loss: 0.2070
Batch 320, Loss: 0.2178
Batch 330, Loss: 0.2283
Batch 340, Loss: 0.2241
Batch 350, Loss: 0.2191
Batch 360, Loss: 0.2054
Batch 370, Loss: 0.2106
Batch 380, Loss: 0.2124
Batch 390, Loss: 0.2230
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.06409788131714 seconds
Epoch 166 accuracy: 94.89%
Batch 10, Loss: 0.2032
Batch 20, Loss: 0.1988
Batch 30, Loss: 0.2197
Batch 40, Loss: 0.2002
Batch 50, Loss: 0.2240
Batch 60, Loss: 0.1963
Batch 70, Loss: 0.2290
Batch 80, Loss: 0.2173
Batch 90, Loss: 0.2093
Batch 100, Loss: 0.1873
Batch 110, Loss: 0.2185
Batch 120, Loss: 0.2041
Batch 130, Loss: 0.2063
Batch 140, Loss: 0.2244
Batch 150, Loss: 0.2133
Batch 160, Loss: 0.2079
Batch 170, Loss: 0.2142
Batch 180, Loss: 0.2253
Batch 190, Loss: 0.1823
Batch 200, Loss: 0.1995
Batch 210, Loss: 0.2146
Batch 220, Loss: 0.2068
Batch 230, Loss: 0.2026
Batch 240, Loss: 0.2223
Batch 250, Loss: 0.1854
Batch 260, Loss: 0.1930
Batch 270, Loss: 0.2053
Batch 280, Loss: 0.2299
Batch 290, Loss: 0.1809
Batch 300, Loss: 0.2127
Batch 310, Loss: 0.2250
Batch 320, Loss: 0.2287
Batch 330, Loss: 0.1999
Batch 340, Loss: 0.1603
Batch 350, Loss: 0.2421
Batch 360, Loss: 0.2213
Batch 370, Loss: 0.2113
Batch 380, Loss: 0.1895
Batch 390, Loss: 0.2063
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.07247829437256 seconds
Epoch 167 accuracy: 95.12%
Batch 10, Loss: 0.2056
Batch 20, Loss: 0.2052
Batch 30, Loss: 0.2067
Batch 40, Loss: 0.2142
Batch 50, Loss: 0.1902
Batch 60, Loss: 0.1862
Batch 70, Loss: 0.2035
Batch 80, Loss: 0.1970
Batch 90, Loss: 0.1977
Batch 100, Loss: 0.1988
Batch 110, Loss: 0.2223
Batch 120, Loss: 0.2330
Batch 130, Loss: 0.2267
Batch 140, Loss: 0.2318
Batch 150, Loss: 0.2024
Batch 160, Loss: 0.2349
Batch 170, Loss: 0.2185
Batch 180, Loss: 0.2028
Batch 190, Loss: 0.2180
Batch 200, Loss: 0.2036
Batch 210, Loss: 0.2025
Batch 220, Loss: 0.2061
Batch 230, Loss: 0.2193
Batch 240, Loss: 0.2129
Batch 250, Loss: 0.2388
Batch 260, Loss: 0.2089
Batch 270, Loss: 0.2181
Batch 280, Loss: 0.1967
Batch 290, Loss: 0.1919
Batch 300, Loss: 0.1976
Batch 310, Loss: 0.2104
Batch 320, Loss: 0.2046
Batch 330, Loss: 0.2312
Batch 340, Loss: 0.2248
Batch 350, Loss: 0.2206
Batch 360, Loss: 0.2150
Batch 370, Loss: 0.2030
Batch 380, Loss: 0.1952
Batch 390, Loss: 0.2391
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.05819797515869 seconds
Epoch 168 accuracy: 94.72%
Batch 10, Loss: 0.1814
Batch 20, Loss: 0.2165
Batch 30, Loss: 0.1736
Batch 40, Loss: 0.2283
Batch 50, Loss: 0.2330
Batch 60, Loss: 0.1937
Batch 70, Loss: 0.1982
Batch 80, Loss: 0.1888
Batch 90, Loss: 0.2280
Batch 100, Loss: 0.1915
Batch 110, Loss: 0.1970
Batch 120, Loss: 0.2227
Batch 130, Loss: 0.2262
Batch 140, Loss: 0.2134
Batch 150, Loss: 0.1962
Batch 160, Loss: 0.2032
Batch 170, Loss: 0.2142
Batch 180, Loss: 0.1959
Batch 190, Loss: 0.1867
Batch 200, Loss: 0.1841
Batch 210, Loss: 0.1994
Batch 220, Loss: 0.1961
Batch 230, Loss: 0.1904
Batch 240, Loss: 0.2022
Batch 250, Loss: 0.1964
Batch 260, Loss: 0.2052
Batch 270, Loss: 0.1956
Batch 280, Loss: 0.2002
Batch 290, Loss: 0.1964
Batch 300, Loss: 0.2089
Batch 310, Loss: 0.2209
Batch 320, Loss: 0.2039
Batch 330, Loss: 0.1861
Batch 340, Loss: 0.1937
Batch 350, Loss: 0.2196
Batch 360, Loss: 0.2024
Batch 370, Loss: 0.1789
Batch 380, Loss: 0.2033
Batch 390, Loss: 0.2107
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.07262945175171 seconds
Epoch 169 accuracy: 94.97%
Batch 10, Loss: 0.2053
Batch 20, Loss: 0.2138
Batch 30, Loss: 0.1910
Batch 40, Loss: 0.2095
Batch 50, Loss: 0.2094
Batch 60, Loss: 0.2040
Batch 70, Loss: 0.1876
Batch 80, Loss: 0.2187
Batch 90, Loss: 0.2008
Batch 100, Loss: 0.1946
Batch 110, Loss: 0.2137
Batch 120, Loss: 0.2101
Batch 130, Loss: 0.2099
Batch 140, Loss: 0.2101
Batch 150, Loss: 0.1963
Batch 160, Loss: 0.2004
Batch 170, Loss: 0.1851
Batch 180, Loss: 0.1851
Batch 190, Loss: 0.2048
Batch 200, Loss: 0.1872
Batch 210, Loss: 0.2168
Batch 220, Loss: 0.1864
Batch 230, Loss: 0.1962
Batch 240, Loss: 0.1899
Batch 250, Loss: 0.2112
Batch 260, Loss: 0.2014
Batch 270, Loss: 0.2150
Batch 280, Loss: 0.1916
Batch 290, Loss: 0.2030
Batch 300, Loss: 0.2338
Batch 310, Loss: 0.1790
Batch 320, Loss: 0.2181
Batch 330, Loss: 0.2085
Batch 340, Loss: 0.1931
Batch 350, Loss: 0.1888
Batch 360, Loss: 0.2100
Batch 370, Loss: 0.1887
Batch 380, Loss: 0.2041
Batch 390, Loss: 0.1782
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.012961387634277 seconds
Epoch 170 accuracy: 95.13%
Batch 10, Loss: 0.2145
Batch 20, Loss: 0.2115
Batch 30, Loss: 0.1829
Batch 40, Loss: 0.2058
Batch 50, Loss: 0.2000
Batch 60, Loss: 0.1823
Batch 70, Loss: 0.1857
Batch 80, Loss: 0.1906
Batch 90, Loss: 0.2184
Batch 100, Loss: 0.2064
Batch 110, Loss: 0.1845
Batch 120, Loss: 0.1955
Batch 130, Loss: 0.1971
Batch 140, Loss: 0.1717
Batch 150, Loss: 0.1873
Batch 160, Loss: 0.1902
Batch 170, Loss: 0.1891
Batch 180, Loss: 0.1995
Batch 190, Loss: 0.2091
Batch 200, Loss: 0.2155
Batch 210, Loss: 0.2004
Batch 220, Loss: 0.1934
Batch 230, Loss: 0.2024
Batch 240, Loss: 0.1872
Batch 250, Loss: 0.1986
Batch 260, Loss: 0.1983
Batch 270, Loss: 0.1869
Batch 280, Loss: 0.1783
Batch 290, Loss: 0.1799
Batch 300, Loss: 0.1753
Batch 310, Loss: 0.2105
Batch 320, Loss: 0.1747
Batch 330, Loss: 0.2122
Batch 340, Loss: 0.1926
Batch 350, Loss: 0.2042
Batch 360, Loss: 0.2026
Batch 370, Loss: 0.2091
Batch 380, Loss: 0.1811
Batch 390, Loss: 0.2097
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.022109746932983 seconds
Epoch 171 accuracy: 95.13%
Batch 10, Loss: 0.1739
Batch 20, Loss: 0.1883
Batch 30, Loss: 0.1831
Batch 40, Loss: 0.1978
Batch 50, Loss: 0.1948
Batch 60, Loss: 0.1841
Batch 70, Loss: 0.1974
Batch 80, Loss: 0.1812
Batch 90, Loss: 0.2167
Batch 100, Loss: 0.1872
Batch 110, Loss: 0.1879
Batch 120, Loss: 0.1930
Batch 130, Loss: 0.2112
Batch 140, Loss: 0.1765
Batch 150, Loss: 0.1936
Batch 160, Loss: 0.2084
Batch 170, Loss: 0.2020
Batch 180, Loss: 0.2073
Batch 190, Loss: 0.1884
Batch 200, Loss: 0.1996
Batch 210, Loss: 0.2056
Batch 220, Loss: 0.2146
Batch 230, Loss: 0.2183
Batch 240, Loss: 0.1844
Batch 250, Loss: 0.1982
Batch 260, Loss: 0.1613
Batch 270, Loss: 0.2046
Batch 280, Loss: 0.1627
Batch 290, Loss: 0.1821
Batch 300, Loss: 0.1704
Batch 310, Loss: 0.1702
Batch 320, Loss: 0.1824
Batch 330, Loss: 0.1995
Batch 340, Loss: 0.1843
Batch 350, Loss: 0.1953
Batch 360, Loss: 0.1778
Batch 370, Loss: 0.2111
Batch 380, Loss: 0.1846
Batch 390, Loss: 0.1998
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 24.989020109176636 seconds
Epoch 172 accuracy: 95.04%
Batch 10, Loss: 0.1642
Batch 20, Loss: 0.1799
Batch 30, Loss: 0.1770
Batch 40, Loss: 0.1744
Batch 50, Loss: 0.1959
Batch 60, Loss: 0.1882
Batch 70, Loss: 0.1973
Batch 80, Loss: 0.1849
Batch 90, Loss: 0.1856
Batch 100, Loss: 0.2002
Batch 110, Loss: 0.1905
Batch 120, Loss: 0.1751
Batch 130, Loss: 0.1779
Batch 140, Loss: 0.1971
Batch 150, Loss: 0.1728
Batch 160, Loss: 0.1792
Batch 170, Loss: 0.1780
Batch 180, Loss: 0.1864
Batch 190, Loss: 0.1743
Batch 200, Loss: 0.1748
Batch 210, Loss: 0.1862
Batch 220, Loss: 0.1849
Batch 230, Loss: 0.1704
Batch 240, Loss: 0.1938
Batch 250, Loss: 0.1829
Batch 260, Loss: 0.1825
Batch 270, Loss: 0.1879
Batch 280, Loss: 0.1821
Batch 290, Loss: 0.1865
Batch 300, Loss: 0.2053
Batch 310, Loss: 0.1923
Batch 320, Loss: 0.1740
Batch 330, Loss: 0.1580
Batch 340, Loss: 0.1874
Batch 350, Loss: 0.1898
Batch 360, Loss: 0.1932
Batch 370, Loss: 0.1998
Batch 380, Loss: 0.2126
Batch 390, Loss: 0.1659
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.032422065734863 seconds
Epoch 173 accuracy: 95.44%
Batch 10, Loss: 0.1818
Batch 20, Loss: 0.1783
Batch 30, Loss: 0.1633
Batch 40, Loss: 0.1771
Batch 50, Loss: 0.2106
Batch 60, Loss: 0.1792
Batch 70, Loss: 0.1864
Batch 80, Loss: 0.1901
Batch 90, Loss: 0.1496
Batch 100, Loss: 0.1662
Batch 110, Loss: 0.1818
Batch 120, Loss: 0.1896
Batch 130, Loss: 0.2063
Batch 140, Loss: 0.1619
Batch 150, Loss: 0.1773
Batch 160, Loss: 0.1664
Batch 170, Loss: 0.1829
Batch 180, Loss: 0.1932
Batch 190, Loss: 0.1777
Batch 200, Loss: 0.1580
Batch 210, Loss: 0.1694
Batch 220, Loss: 0.1721
Batch 230, Loss: 0.1728
Batch 240, Loss: 0.1794
Batch 250, Loss: 0.1842
Batch 260, Loss: 0.1973
Batch 270, Loss: 0.2147
Batch 280, Loss: 0.2012
Batch 290, Loss: 0.1821
Batch 300, Loss: 0.1685
Batch 310, Loss: 0.1786
Batch 320, Loss: 0.1768
Batch 330, Loss: 0.1908
Batch 340, Loss: 0.1605
Batch 350, Loss: 0.1697
Batch 360, Loss: 0.1814
Batch 370, Loss: 0.1831
Batch 380, Loss: 0.1872
Batch 390, Loss: 0.1776
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.065511226654053 seconds
Epoch 174 accuracy: 95.47%
Batch 10, Loss: 0.1671
Batch 20, Loss: 0.1621
Batch 30, Loss: 0.1894
Batch 40, Loss: 0.1721
Batch 50, Loss: 0.1751
Batch 60, Loss: 0.1646
Batch 70, Loss: 0.1770
Batch 80, Loss: 0.1645
Batch 90, Loss: 0.1875
Batch 100, Loss: 0.1610
Batch 110, Loss: 0.1574
Batch 120, Loss: 0.1789
Batch 130, Loss: 0.1770
Batch 140, Loss: 0.1818
Batch 150, Loss: 0.1728
Batch 160, Loss: 0.1783
Batch 170, Loss: 0.1652
Batch 180, Loss: 0.1794
Batch 190, Loss: 0.1631
Batch 200, Loss: 0.1994
Batch 210, Loss: 0.1643
Batch 220, Loss: 0.1950
Batch 230, Loss: 0.2135
Batch 240, Loss: 0.1801
Batch 250, Loss: 0.1726
Batch 260, Loss: 0.1838
Batch 270, Loss: 0.1776
Batch 280, Loss: 0.1981
Batch 290, Loss: 0.1823
Batch 300, Loss: 0.2010
Batch 310, Loss: 0.2200
Batch 320, Loss: 0.1809
Batch 330, Loss: 0.1760
Batch 340, Loss: 0.1590
Batch 350, Loss: 0.2016
Batch 360, Loss: 0.1930
Batch 370, Loss: 0.1659
Batch 380, Loss: 0.2229
Batch 390, Loss: 0.1964
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.017403602600098 seconds
Epoch 175 accuracy: 95.64%
Batch 10, Loss: 0.1625
Batch 20, Loss: 0.1601
Batch 30, Loss: 0.1594
Batch 40, Loss: 0.1973
Batch 50, Loss: 0.1893
Batch 60, Loss: 0.1735
Batch 70, Loss: 0.1742
Batch 80, Loss: 0.1821
Batch 90, Loss: 0.1588
Batch 100, Loss: 0.1694
Batch 110, Loss: 0.1517
Batch 120, Loss: 0.1759
Batch 130, Loss: 0.1655
Batch 140, Loss: 0.1652
Batch 150, Loss: 0.1811
Batch 160, Loss: 0.1796
Batch 170, Loss: 0.1688
Batch 180, Loss: 0.1949
Batch 190, Loss: 0.1650
Batch 200, Loss: 0.1596
Batch 210, Loss: 0.1440
Batch 220, Loss: 0.2150
Batch 230, Loss: 0.1754
Batch 240, Loss: 0.1711
Batch 250, Loss: 0.2020
Batch 260, Loss: 0.1716
Batch 270, Loss: 0.1859
Batch 280, Loss: 0.1832
Batch 290, Loss: 0.1744
Batch 300, Loss: 0.1853
Batch 310, Loss: 0.1544
Batch 320, Loss: 0.1764
Batch 330, Loss: 0.1792
Batch 340, Loss: 0.1738
Batch 350, Loss: 0.1614
Batch 360, Loss: 0.1730
Batch 370, Loss: 0.1730
Batch 380, Loss: 0.1806
Batch 390, Loss: 0.1914
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.072490215301514 seconds
Epoch 176 accuracy: 95.73%
Batch 10, Loss: 0.1490
Batch 20, Loss: 0.1645
Batch 30, Loss: 0.2107
Batch 40, Loss: 0.1563
Batch 50, Loss: 0.1576
Batch 60, Loss: 0.1372
Batch 70, Loss: 0.1622
Batch 80, Loss: 0.1610
Batch 90, Loss: 0.1669
Batch 100, Loss: 0.1891
Batch 110, Loss: 0.1687
Batch 120, Loss: 0.1658
Batch 130, Loss: 0.1865
Batch 140, Loss: 0.1678
Batch 150, Loss: 0.2005
Batch 160, Loss: 0.1515
Batch 170, Loss: 0.1477
Batch 180, Loss: 0.1988
Batch 190, Loss: 0.1695
Batch 200, Loss: 0.1593
Batch 210, Loss: 0.1554
Batch 220, Loss: 0.1716
Batch 230, Loss: 0.1721
Batch 240, Loss: 0.1933
Batch 250, Loss: 0.1657
Batch 260, Loss: 0.1744
Batch 270, Loss: 0.1851
Batch 280, Loss: 0.1726
Batch 290, Loss: 0.1783
Batch 300, Loss: 0.1370
Batch 310, Loss: 0.1526
Batch 320, Loss: 0.1690
Batch 330, Loss: 0.1525
Batch 340, Loss: 0.1621
Batch 350, Loss: 0.1460
Batch 360, Loss: 0.1739
Batch 370, Loss: 0.1644
Batch 380, Loss: 0.1457
Batch 390, Loss: 0.1469
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 24.997568130493164 seconds
Epoch 177 accuracy: 95.61%
Batch 10, Loss: 0.1746
Batch 20, Loss: 0.1736
Batch 30, Loss: 0.1790
Batch 40, Loss: 0.1930
Batch 50, Loss: 0.1736
Batch 60, Loss: 0.1734
Batch 70, Loss: 0.1533
Batch 80, Loss: 0.1847
Batch 90, Loss: 0.1620
Batch 100, Loss: 0.1815
Batch 110, Loss: 0.1529
Batch 120, Loss: 0.1505
Batch 130, Loss: 0.1420
Batch 140, Loss: 0.1419
Batch 150, Loss: 0.1439
Batch 160, Loss: 0.1828
Batch 170, Loss: 0.1428
Batch 180, Loss: 0.1675
Batch 190, Loss: 0.1673
Batch 200, Loss: 0.1758
Batch 210, Loss: 0.1646
Batch 220, Loss: 0.1786
Batch 230, Loss: 0.1654
Batch 240, Loss: 0.1637
Batch 250, Loss: 0.1660
Batch 260, Loss: 0.1472
Batch 270, Loss: 0.1592
Batch 280, Loss: 0.1622
Batch 290, Loss: 0.1645
Batch 300, Loss: 0.1589
Batch 310, Loss: 0.1960
Batch 320, Loss: 0.1697
Batch 330, Loss: 0.1872
Batch 340, Loss: 0.1552
Batch 350, Loss: 0.1625
Batch 360, Loss: 0.1548
Batch 370, Loss: 0.1752
Batch 380, Loss: 0.1711
Batch 390, Loss: 0.1916
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 24.962072134017944 seconds
Epoch 178 accuracy: 95.61%
Batch 10, Loss: 0.1563
Batch 20, Loss: 0.1886
Batch 30, Loss: 0.1452
Batch 40, Loss: 0.1579
Batch 50, Loss: 0.1629
Batch 60, Loss: 0.1829
Batch 70, Loss: 0.1571
Batch 80, Loss: 0.1595
Batch 90, Loss: 0.1670
Batch 100, Loss: 0.1606
Batch 110, Loss: 0.1496
Batch 120, Loss: 0.1524
Batch 130, Loss: 0.1826
Batch 140, Loss: 0.1543
Batch 150, Loss: 0.1493
Batch 160, Loss: 0.1686
Batch 170, Loss: 0.1403
Batch 180, Loss: 0.1639
Batch 190, Loss: 0.1493
Batch 200, Loss: 0.1516
Batch 210, Loss: 0.1320
Batch 220, Loss: 0.1513
Batch 230, Loss: 0.1480
Batch 240, Loss: 0.1676
Batch 250, Loss: 0.1502
Batch 260, Loss: 0.1539
Batch 270, Loss: 0.1929
Batch 280, Loss: 0.1550
Batch 290, Loss: 0.1651
Batch 300, Loss: 0.1958
Batch 310, Loss: 0.1522
Batch 320, Loss: 0.1510
Batch 330, Loss: 0.1518
Batch 340, Loss: 0.1387
Batch 350, Loss: 0.1616
Batch 360, Loss: 0.1782
Batch 370, Loss: 0.1835
Batch 380, Loss: 0.1642
Batch 390, Loss: 0.1787
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.070214986801147 seconds
Epoch 179 accuracy: 95.71%
Batch 10, Loss: 0.1643
Batch 20, Loss: 0.1678
Batch 30, Loss: 0.1458
Batch 40, Loss: 0.1593
Batch 50, Loss: 0.1501
Batch 60, Loss: 0.1737
Batch 70, Loss: 0.1544
Batch 80, Loss: 0.1604
Batch 90, Loss: 0.1752
Batch 100, Loss: 0.1536
Batch 110, Loss: 0.1582
Batch 120, Loss: 0.1823
Batch 130, Loss: 0.1355
Batch 140, Loss: 0.1652
Batch 150, Loss: 0.1678
Batch 160, Loss: 0.1822
Batch 170, Loss: 0.1567
Batch 180, Loss: 0.1643
Batch 190, Loss: 0.1640
Batch 200, Loss: 0.1888
Batch 210, Loss: 0.1553
Batch 220, Loss: 0.1592
Batch 230, Loss: 0.1754
Batch 240, Loss: 0.1540
Batch 250, Loss: 0.1760
Batch 260, Loss: 0.1449
Batch 270, Loss: 0.1699
Batch 280, Loss: 0.1470
Batch 290, Loss: 0.1617
Batch 300, Loss: 0.1497
Batch 310, Loss: 0.1325
Batch 320, Loss: 0.1443
Batch 330, Loss: 0.1659
Batch 340, Loss: 0.1603
Batch 350, Loss: 0.1413
Batch 360, Loss: 0.1618
Batch 370, Loss: 0.1528
Batch 380, Loss: 0.1772
Batch 390, Loss: 0.1647
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 24.99000597000122 seconds
Epoch 180 accuracy: 95.8%
Batch 10, Loss: 0.1780
Batch 20, Loss: 0.1702
Batch 30, Loss: 0.1579
Batch 40, Loss: 0.1563
Batch 50, Loss: 0.1543
Batch 60, Loss: 0.1536
Batch 70, Loss: 0.1580
Batch 80, Loss: 0.1587
Batch 90, Loss: 0.1620
Batch 100, Loss: 0.1785
Batch 110, Loss: 0.1739
Batch 120, Loss: 0.1485
Batch 130, Loss: 0.1715
Batch 140, Loss: 0.1647
Batch 150, Loss: 0.1351
Batch 160, Loss: 0.1201
Batch 170, Loss: 0.1544
Batch 180, Loss: 0.1724
Batch 190, Loss: 0.1659
Batch 200, Loss: 0.1469
Batch 210, Loss: 0.1709
Batch 220, Loss: 0.1399
Batch 230, Loss: 0.1549
Batch 240, Loss: 0.1676
Batch 250, Loss: 0.1434
Batch 260, Loss: 0.1808
Batch 270, Loss: 0.1938
Batch 280, Loss: 0.1557
Batch 290, Loss: 0.1636
Batch 300, Loss: 0.1519
Batch 310, Loss: 0.1722
Batch 320, Loss: 0.1390
Batch 330, Loss: 0.1635
Batch 340, Loss: 0.1639
Batch 350, Loss: 0.1666
Batch 360, Loss: 0.1596
Batch 370, Loss: 0.1698
Batch 380, Loss: 0.1425
Batch 390, Loss: 0.1591
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.01422357559204 seconds
Epoch 181 accuracy: 95.95%
Batch 10, Loss: 0.1408
Batch 20, Loss: 0.1565
Batch 30, Loss: 0.1497
Batch 40, Loss: 0.1862
Batch 50, Loss: 0.1441
Batch 60, Loss: 0.1483
Batch 70, Loss: 0.1360
Batch 80, Loss: 0.1411
Batch 90, Loss: 0.1465
Batch 100, Loss: 0.1542
Batch 110, Loss: 0.1346
Batch 120, Loss: 0.1698
Batch 130, Loss: 0.1641
Batch 140, Loss: 0.1487
Batch 150, Loss: 0.1362
Batch 160, Loss: 0.1393
Batch 170, Loss: 0.1487
Batch 180, Loss: 0.1459
Batch 190, Loss: 0.1303
Batch 200, Loss: 0.1433
Batch 210, Loss: 0.1403
Batch 220, Loss: 0.1427
Batch 230, Loss: 0.1464
Batch 240, Loss: 0.1374
Batch 250, Loss: 0.1360
Batch 260, Loss: 0.1345
Batch 270, Loss: 0.1461
Batch 280, Loss: 0.1449
Batch 290, Loss: 0.1350
Batch 300, Loss: 0.1428
Batch 310, Loss: 0.1464
Batch 320, Loss: 0.1544
Batch 330, Loss: 0.1588
Batch 340, Loss: 0.1485
Batch 350, Loss: 0.1725
Batch 360, Loss: 0.1471
Batch 370, Loss: 0.1654
Batch 380, Loss: 0.1534
Batch 390, Loss: 0.1424
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.05121397972107 seconds
Epoch 182 accuracy: 95.99%
Batch 10, Loss: 0.1510
Batch 20, Loss: 0.1521
Batch 30, Loss: 0.1627
Batch 40, Loss: 0.1593
Batch 50, Loss: 0.1828
Batch 60, Loss: 0.1410
Batch 70, Loss: 0.1555
Batch 80, Loss: 0.1433
Batch 90, Loss: 0.1418
Batch 100, Loss: 0.1416
Batch 110, Loss: 0.1421
Batch 120, Loss: 0.1400
Batch 130, Loss: 0.1411
Batch 140, Loss: 0.1626
Batch 150, Loss: 0.1253
Batch 160, Loss: 0.1703
Batch 170, Loss: 0.1685
Batch 180, Loss: 0.1512
Batch 190, Loss: 0.1396
Batch 200, Loss: 0.1631
Batch 210, Loss: 0.1350
Batch 220, Loss: 0.1610
Batch 230, Loss: 0.1481
Batch 240, Loss: 0.1319
Batch 250, Loss: 0.1595
Batch 260, Loss: 0.1432
Batch 270, Loss: 0.1578
Batch 280, Loss: 0.1463
Batch 290, Loss: 0.1490
Batch 300, Loss: 0.1628
Batch 310, Loss: 0.1637
Batch 320, Loss: 0.1382
Batch 330, Loss: 0.1724
Batch 340, Loss: 0.1501
Batch 350, Loss: 0.1429
Batch 360, Loss: 0.1507
Batch 370, Loss: 0.1309
Batch 380, Loss: 0.1753
Batch 390, Loss: 0.1300
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 24.972239017486572 seconds
Epoch 183 accuracy: 96.08%
Batch 10, Loss: 0.1548
Batch 20, Loss: 0.1327
Batch 30, Loss: 0.1340
Batch 40, Loss: 0.1464
Batch 50, Loss: 0.1141
Batch 60, Loss: 0.1462
Batch 70, Loss: 0.1361
Batch 80, Loss: 0.1424
Batch 90, Loss: 0.1311
Batch 100, Loss: 0.1611
Batch 110, Loss: 0.1568
Batch 120, Loss: 0.1348
Batch 130, Loss: 0.1622
Batch 140, Loss: 0.1517
Batch 150, Loss: 0.1557
Batch 160, Loss: 0.1302
Batch 170, Loss: 0.1430
Batch 180, Loss: 0.1393
Batch 190, Loss: 0.1290
Batch 200, Loss: 0.1506
Batch 210, Loss: 0.1369
Batch 220, Loss: 0.1429
Batch 230, Loss: 0.1461
Batch 240, Loss: 0.1422
Batch 250, Loss: 0.1588
Batch 260, Loss: 0.1323
Batch 270, Loss: 0.1579
Batch 280, Loss: 0.1473
Batch 290, Loss: 0.1393
Batch 300, Loss: 0.1633
Batch 310, Loss: 0.1247
Batch 320, Loss: 0.1406
Batch 330, Loss: 0.1637
Batch 340, Loss: 0.1512
Batch 350, Loss: 0.1502
Batch 360, Loss: 0.1450
Batch 370, Loss: 0.1426
Batch 380, Loss: 0.1462
Batch 390, Loss: 0.1490
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.012141227722168 seconds
Epoch 184 accuracy: 96.09%
Batch 10, Loss: 0.1558
Batch 20, Loss: 0.1371
Batch 30, Loss: 0.1536
Batch 40, Loss: 0.1517
Batch 50, Loss: 0.1306
Batch 60, Loss: 0.1384
Batch 70, Loss: 0.1651
Batch 80, Loss: 0.1485
Batch 90, Loss: 0.1478
Batch 100, Loss: 0.1342
Batch 110, Loss: 0.1769
Batch 120, Loss: 0.1434
Batch 130, Loss: 0.1370
Batch 140, Loss: 0.1532
Batch 150, Loss: 0.1366
Batch 160, Loss: 0.1643
Batch 170, Loss: 0.1501
Batch 180, Loss: 0.1299
Batch 190, Loss: 0.1333
Batch 200, Loss: 0.1340
Batch 210, Loss: 0.1475
Batch 220, Loss: 0.1529
Batch 230, Loss: 0.1246
Batch 240, Loss: 0.1337
Batch 250, Loss: 0.1404
Batch 260, Loss: 0.1339
Batch 270, Loss: 0.1381
Batch 280, Loss: 0.1745
Batch 290, Loss: 0.1298
Batch 300, Loss: 0.1593
Batch 310, Loss: 0.1457
Batch 320, Loss: 0.1553
Batch 330, Loss: 0.1363
Batch 340, Loss: 0.1500
Batch 350, Loss: 0.1309
Batch 360, Loss: 0.1281
Batch 370, Loss: 0.1464
Batch 380, Loss: 0.1381
Batch 390, Loss: 0.1338
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 24.997762441635132 seconds
Epoch 185 accuracy: 95.98%
Batch 10, Loss: 0.1570
Batch 20, Loss: 0.1552
Batch 30, Loss: 0.1659
Batch 40, Loss: 0.1584
Batch 50, Loss: 0.1458
Batch 60, Loss: 0.1489
Batch 70, Loss: 0.1368
Batch 80, Loss: 0.1481
Batch 90, Loss: 0.1401
Batch 100, Loss: 0.1136
Batch 110, Loss: 0.1445
Batch 120, Loss: 0.1508
Batch 130, Loss: 0.1259
Batch 140, Loss: 0.1462
Batch 150, Loss: 0.1571
Batch 160, Loss: 0.1382
Batch 170, Loss: 0.1471
Batch 180, Loss: 0.1494
Batch 190, Loss: 0.1514
Batch 200, Loss: 0.0994
Batch 210, Loss: 0.1607
Batch 220, Loss: 0.1563
Batch 230, Loss: 0.1376
Batch 240, Loss: 0.1698
Batch 250, Loss: 0.1218
Batch 260, Loss: 0.1336
Batch 270, Loss: 0.1199
Batch 280, Loss: 0.1250
Batch 290, Loss: 0.1384
Batch 300, Loss: 0.1355
Batch 310, Loss: 0.1384
Batch 320, Loss: 0.1253
Batch 330, Loss: 0.1283
Batch 340, Loss: 0.1233
Batch 350, Loss: 0.1450
Batch 360, Loss: 0.1504
Batch 370, Loss: 0.1282
Batch 380, Loss: 0.1524
Batch 390, Loss: 0.1349
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 24.981526374816895 seconds
Epoch 186 accuracy: 96.13%
Batch 10, Loss: 0.1519
Batch 20, Loss: 0.1290
Batch 30, Loss: 0.1441
Batch 40, Loss: 0.1420
Batch 50, Loss: 0.1212
Batch 60, Loss: 0.1338
Batch 70, Loss: 0.1320
Batch 80, Loss: 0.1386
Batch 90, Loss: 0.1343
Batch 100, Loss: 0.1432
Batch 110, Loss: 0.1473
Batch 120, Loss: 0.1454
Batch 130, Loss: 0.1269
Batch 140, Loss: 0.1454
Batch 150, Loss: 0.1270
Batch 160, Loss: 0.1461
Batch 170, Loss: 0.1438
Batch 180, Loss: 0.1189
Batch 190, Loss: 0.1420
Batch 200, Loss: 0.1574
Batch 210, Loss: 0.1421
Batch 220, Loss: 0.1412
Batch 230, Loss: 0.1394
Batch 240, Loss: 0.1247
Batch 250, Loss: 0.1413
Batch 260, Loss: 0.1434
Batch 270, Loss: 0.1504
Batch 280, Loss: 0.1605
Batch 290, Loss: 0.1553
Batch 300, Loss: 0.1510
Batch 310, Loss: 0.1244
Batch 320, Loss: 0.1563
Batch 330, Loss: 0.1322
Batch 340, Loss: 0.1258
Batch 350, Loss: 0.1513
Batch 360, Loss: 0.1503
Batch 370, Loss: 0.1329
Batch 380, Loss: 0.1312
Batch 390, Loss: 0.1263
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.0670108795166 seconds
Epoch 187 accuracy: 96.12%
Batch 10, Loss: 0.1411
Batch 20, Loss: 0.1288
Batch 30, Loss: 0.1126
Batch 40, Loss: 0.1488
Batch 50, Loss: 0.1472
Batch 60, Loss: 0.1302
Batch 70, Loss: 0.1330
Batch 80, Loss: 0.1523
Batch 90, Loss: 0.1309
Batch 100, Loss: 0.1364
Batch 110, Loss: 0.1254
Batch 120, Loss: 0.1376
Batch 130, Loss: 0.1553
Batch 140, Loss: 0.1473
Batch 150, Loss: 0.1576
Batch 160, Loss: 0.1410
Batch 170, Loss: 0.1502
Batch 180, Loss: 0.1473
Batch 190, Loss: 0.1285
Batch 200, Loss: 0.1231
Batch 210, Loss: 0.1610
Batch 220, Loss: 0.1200
Batch 230, Loss: 0.1376
Batch 240, Loss: 0.1369
Batch 250, Loss: 0.1410
Batch 260, Loss: 0.1410
Batch 270, Loss: 0.1440
Batch 280, Loss: 0.1633
Batch 290, Loss: 0.1320
Batch 300, Loss: 0.1359
Batch 310, Loss: 0.1275
Batch 320, Loss: 0.1282
Batch 330, Loss: 0.1369
Batch 340, Loss: 0.1180
Batch 350, Loss: 0.1403
Batch 360, Loss: 0.1241
Batch 370, Loss: 0.1129
Batch 380, Loss: 0.1186
Batch 390, Loss: 0.1530
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.002755165100098 seconds
Epoch 188 accuracy: 96.19%
Batch 10, Loss: 0.1237
Batch 20, Loss: 0.1340
Batch 30, Loss: 0.1694
Batch 40, Loss: 0.1313
Batch 50, Loss: 0.1268
Batch 60, Loss: 0.1373
Batch 70, Loss: 0.1309
Batch 80, Loss: 0.1166
Batch 90, Loss: 0.1347
Batch 100, Loss: 0.1230
Batch 110, Loss: 0.1286
Batch 120, Loss: 0.1168
Batch 130, Loss: 0.1401
Batch 140, Loss: 0.1150
Batch 150, Loss: 0.1482
Batch 160, Loss: 0.1473
Batch 170, Loss: 0.1228
Batch 180, Loss: 0.1186
Batch 190, Loss: 0.1323
Batch 200, Loss: 0.1278
Batch 210, Loss: 0.1315
Batch 220, Loss: 0.1477
Batch 230, Loss: 0.1392
Batch 240, Loss: 0.1442
Batch 250, Loss: 0.1385
Batch 260, Loss: 0.1378
Batch 270, Loss: 0.1221
Batch 280, Loss: 0.1195
Batch 290, Loss: 0.1328
Batch 300, Loss: 0.1334
Batch 310, Loss: 0.1518
Batch 320, Loss: 0.1419
Batch 330, Loss: 0.1261
Batch 340, Loss: 0.1333
Batch 350, Loss: 0.1373
Batch 360, Loss: 0.1400
Batch 370, Loss: 0.1217
Batch 380, Loss: 0.1314
Batch 390, Loss: 0.1375
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.02140164375305 seconds
Epoch 189 accuracy: 96.34%
Batch 10, Loss: 0.1396
Batch 20, Loss: 0.1344
Batch 30, Loss: 0.1377
Batch 40, Loss: 0.1434
Batch 50, Loss: 0.1082
Batch 60, Loss: 0.1353
Batch 70, Loss: 0.1208
Batch 80, Loss: 0.1254
Batch 90, Loss: 0.1420
Batch 100, Loss: 0.1358
Batch 110, Loss: 0.1225
Batch 120, Loss: 0.1370
Batch 130, Loss: 0.1191
Batch 140, Loss: 0.1254
Batch 150, Loss: 0.1328
Batch 160, Loss: 0.1358
Batch 170, Loss: 0.1194
Batch 180, Loss: 0.1276
Batch 190, Loss: 0.1429
Batch 200, Loss: 0.1309
Batch 210, Loss: 0.1249
Batch 220, Loss: 0.1272
Batch 230, Loss: 0.1167
Batch 240, Loss: 0.1161
Batch 250, Loss: 0.1264
Batch 260, Loss: 0.1358
Batch 270, Loss: 0.1371
Batch 280, Loss: 0.1516
Batch 290, Loss: 0.1271
Batch 300, Loss: 0.1324
Batch 310, Loss: 0.1353
Batch 320, Loss: 0.1313
Batch 330, Loss: 0.1259
Batch 340, Loss: 0.1380
Batch 350, Loss: 0.1360
Batch 360, Loss: 0.1232
Batch 370, Loss: 0.1285
Batch 380, Loss: 0.1384
Batch 390, Loss: 0.1226
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.10079073905945 seconds
Epoch 190 accuracy: 96.3%
Batch 10, Loss: 0.1168
Batch 20, Loss: 0.1309
Batch 30, Loss: 0.1492
Batch 40, Loss: 0.1221
Batch 50, Loss: 0.1064
Batch 60, Loss: 0.1228
Batch 70, Loss: 0.1256
Batch 80, Loss: 0.1241
Batch 90, Loss: 0.1440
Batch 100, Loss: 0.1224
Batch 110, Loss: 0.1283
Batch 120, Loss: 0.1497
Batch 130, Loss: 0.1172
Batch 140, Loss: 0.1347
Batch 150, Loss: 0.1193
Batch 160, Loss: 0.1210
Batch 170, Loss: 0.1221
Batch 180, Loss: 0.1402
Batch 190, Loss: 0.1317
Batch 200, Loss: 0.1622
Batch 210, Loss: 0.1212
Batch 220, Loss: 0.1117
Batch 230, Loss: 0.1308
Batch 240, Loss: 0.1480
Batch 250, Loss: 0.1387
Batch 260, Loss: 0.1303
Batch 270, Loss: 0.1387
Batch 280, Loss: 0.1418
Batch 290, Loss: 0.1280
Batch 300, Loss: 0.1195
Batch 310, Loss: 0.1289
Batch 320, Loss: 0.1383
Batch 330, Loss: 0.1320
Batch 340, Loss: 0.1384
Batch 350, Loss: 0.1256
Batch 360, Loss: 0.1456
Batch 370, Loss: 0.1107
Batch 380, Loss: 0.1251
Batch 390, Loss: 0.1261
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.019818544387817 seconds
Epoch 191 accuracy: 96.32%
Batch 10, Loss: 0.1375
Batch 20, Loss: 0.1330
Batch 30, Loss: 0.1244
Batch 40, Loss: 0.1377
Batch 50, Loss: 0.1362
Batch 60, Loss: 0.1489
Batch 70, Loss: 0.1338
Batch 80, Loss: 0.1596
Batch 90, Loss: 0.1105
Batch 100, Loss: 0.1140
Batch 110, Loss: 0.1208
Batch 120, Loss: 0.1390
Batch 130, Loss: 0.1284
Batch 140, Loss: 0.1195
Batch 150, Loss: 0.1339
Batch 160, Loss: 0.1232
Batch 170, Loss: 0.1368
Batch 180, Loss: 0.1331
Batch 190, Loss: 0.1201
Batch 200, Loss: 0.1285
Batch 210, Loss: 0.1474
Batch 220, Loss: 0.1373
Batch 230, Loss: 0.1159
Batch 240, Loss: 0.1314
Batch 250, Loss: 0.1142
Batch 260, Loss: 0.1421
Batch 270, Loss: 0.1308
Batch 280, Loss: 0.1338
Batch 290, Loss: 0.1143
Batch 300, Loss: 0.1312
Batch 310, Loss: 0.1340
Batch 320, Loss: 0.1165
Batch 330, Loss: 0.1541
Batch 340, Loss: 0.1282
Batch 350, Loss: 0.1269
Batch 360, Loss: 0.1386
Batch 370, Loss: 0.1370
Batch 380, Loss: 0.1033
Batch 390, Loss: 0.1238
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.02139186859131 seconds
Epoch 192 accuracy: 96.27%
Batch 10, Loss: 0.1250
Batch 20, Loss: 0.1589
Batch 30, Loss: 0.1390
Batch 40, Loss: 0.1399
Batch 50, Loss: 0.1506
Batch 60, Loss: 0.1169
Batch 70, Loss: 0.1178
Batch 80, Loss: 0.1229
Batch 90, Loss: 0.1219
Batch 100, Loss: 0.1131
Batch 110, Loss: 0.1275
Batch 120, Loss: 0.1206
Batch 130, Loss: 0.0994
Batch 140, Loss: 0.1394
Batch 150, Loss: 0.1028
Batch 160, Loss: 0.1245
Batch 170, Loss: 0.1349
Batch 180, Loss: 0.1367
Batch 190, Loss: 0.1372
Batch 200, Loss: 0.1209
Batch 210, Loss: 0.1297
Batch 220, Loss: 0.1433
Batch 230, Loss: 0.1266
Batch 240, Loss: 0.1674
Batch 250, Loss: 0.1333
Batch 260, Loss: 0.1083
Batch 270, Loss: 0.1113
Batch 280, Loss: 0.0993
Batch 290, Loss: 0.1293
Batch 300, Loss: 0.1285
Batch 310, Loss: 0.1550
Batch 320, Loss: 0.1002
Batch 330, Loss: 0.1306
Batch 340, Loss: 0.1348
Batch 350, Loss: 0.1408
Batch 360, Loss: 0.1503
Batch 370, Loss: 0.1225
Batch 380, Loss: 0.1041
Batch 390, Loss: 0.1327
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.017319679260254 seconds
Epoch 193 accuracy: 96.19%
Batch 10, Loss: 0.1396
Batch 20, Loss: 0.1023
Batch 30, Loss: 0.1473
Batch 40, Loss: 0.1319
Batch 50, Loss: 0.1342
Batch 60, Loss: 0.1269
Batch 70, Loss: 0.1238
Batch 80, Loss: 0.1204
Batch 90, Loss: 0.1148
Batch 100, Loss: 0.1349
Batch 110, Loss: 0.1398
Batch 120, Loss: 0.1454
Batch 130, Loss: 0.1489
Batch 140, Loss: 0.1286
Batch 150, Loss: 0.1368
Batch 160, Loss: 0.1155
Batch 170, Loss: 0.1306
Batch 180, Loss: 0.1103
Batch 190, Loss: 0.1235
Batch 200, Loss: 0.1269
Batch 210, Loss: 0.1142
Batch 220, Loss: 0.1048
Batch 230, Loss: 0.1384
Batch 240, Loss: 0.1077
Batch 250, Loss: 0.1205
Batch 260, Loss: 0.1223
Batch 270, Loss: 0.1217
Batch 280, Loss: 0.1221
Batch 290, Loss: 0.1156
Batch 300, Loss: 0.1171
Batch 310, Loss: 0.1324
Batch 320, Loss: 0.1218
Batch 330, Loss: 0.1441
Batch 340, Loss: 0.1251
Batch 350, Loss: 0.1256
Batch 360, Loss: 0.1214
Batch 370, Loss: 0.1201
Batch 380, Loss: 0.1339
Batch 390, Loss: 0.1299
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 24.994916677474976 seconds
Epoch 194 accuracy: 96.3%
Batch 10, Loss: 0.1084
Batch 20, Loss: 0.1220
Batch 30, Loss: 0.1192
Batch 40, Loss: 0.1357
Batch 50, Loss: 0.1287
Batch 60, Loss: 0.1417
Batch 70, Loss: 0.1299
Batch 80, Loss: 0.1231
Batch 90, Loss: 0.1398
Batch 100, Loss: 0.1417
Batch 110, Loss: 0.1224
Batch 120, Loss: 0.1129
Batch 130, Loss: 0.1235
Batch 140, Loss: 0.1275
Batch 150, Loss: 0.1281
Batch 160, Loss: 0.1317
Batch 170, Loss: 0.1342
Batch 180, Loss: 0.1203
Batch 190, Loss: 0.1267
Batch 200, Loss: 0.1168
Batch 210, Loss: 0.1180
Batch 220, Loss: 0.1249
Batch 230, Loss: 0.1101
Batch 240, Loss: 0.1311
Batch 250, Loss: 0.1237
Batch 260, Loss: 0.1114
Batch 270, Loss: 0.1340
Batch 280, Loss: 0.1106
Batch 290, Loss: 0.1294
Batch 300, Loss: 0.1358
Batch 310, Loss: 0.1347
Batch 320, Loss: 0.1222
Batch 330, Loss: 0.1221
Batch 340, Loss: 0.1182
Batch 350, Loss: 0.1397
Batch 360, Loss: 0.1211
Batch 370, Loss: 0.1312
Batch 380, Loss: 0.1186
Batch 390, Loss: 0.1184
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.00926971435547 seconds
Epoch 195 accuracy: 96.24%
Batch 10, Loss: 0.1072
Batch 20, Loss: 0.1210
Batch 30, Loss: 0.1377
Batch 40, Loss: 0.1068
Batch 50, Loss: 0.1432
Batch 60, Loss: 0.1277
Batch 70, Loss: 0.1295
Batch 80, Loss: 0.1218
Batch 90, Loss: 0.1405
Batch 100, Loss: 0.1135
Batch 110, Loss: 0.1390
Batch 120, Loss: 0.1139
Batch 130, Loss: 0.1155
Batch 140, Loss: 0.1402
Batch 150, Loss: 0.1196
Batch 160, Loss: 0.1121
Batch 170, Loss: 0.1365
Batch 180, Loss: 0.1134
Batch 190, Loss: 0.1394
Batch 200, Loss: 0.1423
Batch 210, Loss: 0.1187
Batch 220, Loss: 0.1294
Batch 230, Loss: 0.1418
Batch 240, Loss: 0.1232
Batch 250, Loss: 0.1064
Batch 260, Loss: 0.1302
Batch 270, Loss: 0.1382
Batch 280, Loss: 0.1284
Batch 290, Loss: 0.1393
Batch 300, Loss: 0.1402
Batch 310, Loss: 0.1281
Batch 320, Loss: 0.1196
Batch 330, Loss: 0.1488
Batch 340, Loss: 0.1209
Batch 350, Loss: 0.1132
Batch 360, Loss: 0.1242
Batch 370, Loss: 0.1196
Batch 380, Loss: 0.1363
Batch 390, Loss: 0.1215
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.03213930130005 seconds
Epoch 196 accuracy: 96.24%
Batch 10, Loss: 0.1136
Batch 20, Loss: 0.1236
Batch 30, Loss: 0.1438
Batch 40, Loss: 0.1368
Batch 50, Loss: 0.1206
Batch 60, Loss: 0.1369
Batch 70, Loss: 0.1155
Batch 80, Loss: 0.1113
Batch 90, Loss: 0.1236
Batch 100, Loss: 0.1157
Batch 110, Loss: 0.1210
Batch 120, Loss: 0.1226
Batch 130, Loss: 0.1267
Batch 140, Loss: 0.1290
Batch 150, Loss: 0.1336
Batch 160, Loss: 0.1215
Batch 170, Loss: 0.1341
Batch 180, Loss: 0.1172
Batch 190, Loss: 0.1160
Batch 200, Loss: 0.1296
Batch 210, Loss: 0.1086
Batch 220, Loss: 0.1179
Batch 230, Loss: 0.1190
Batch 240, Loss: 0.1463
Batch 250, Loss: 0.1427
Batch 260, Loss: 0.1259
Batch 270, Loss: 0.1239
Batch 280, Loss: 0.1200
Batch 290, Loss: 0.1153
Batch 300, Loss: 0.1261
Batch 310, Loss: 0.1439
Batch 320, Loss: 0.1148
Batch 330, Loss: 0.1145
Batch 340, Loss: 0.1293
Batch 350, Loss: 0.1459
Batch 360, Loss: 0.1377
Batch 370, Loss: 0.1051
Batch 380, Loss: 0.1404
Batch 390, Loss: 0.1294
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 24.988229513168335 seconds
Epoch 197 accuracy: 96.28%
Batch 10, Loss: 0.1241
Batch 20, Loss: 0.1090
Batch 30, Loss: 0.1229
Batch 40, Loss: 0.1289
Batch 50, Loss: 0.1064
Batch 60, Loss: 0.1368
Batch 70, Loss: 0.1095
Batch 80, Loss: 0.1298
Batch 90, Loss: 0.1289
Batch 100, Loss: 0.1454
Batch 110, Loss: 0.1052
Batch 120, Loss: 0.1060
Batch 130, Loss: 0.1438
Batch 140, Loss: 0.1074
Batch 150, Loss: 0.1325
Batch 160, Loss: 0.1181
Batch 170, Loss: 0.1374
Batch 180, Loss: 0.1615
Batch 190, Loss: 0.1315
Batch 200, Loss: 0.1352
Batch 210, Loss: 0.1231
Batch 220, Loss: 0.1370
Batch 230, Loss: 0.1326
Batch 240, Loss: 0.1276
Batch 250, Loss: 0.1203
Batch 260, Loss: 0.1338
Batch 270, Loss: 0.1291
Batch 280, Loss: 0.1227
Batch 290, Loss: 0.1099
Batch 300, Loss: 0.1309
Batch 310, Loss: 0.1269
Batch 320, Loss: 0.1302
Batch 330, Loss: 0.1413
Batch 340, Loss: 0.1427
Batch 350, Loss: 0.1211
Batch 360, Loss: 0.1445
Batch 370, Loss: 0.1191
Batch 380, Loss: 0.1524
Batch 390, Loss: 0.1289
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.021010398864746 seconds
Epoch 198 accuracy: 96.3%
Batch 10, Loss: 0.1257
Batch 20, Loss: 0.1147
Batch 30, Loss: 0.1269
Batch 40, Loss: 0.1135
Batch 50, Loss: 0.1354
Batch 60, Loss: 0.1397
Batch 70, Loss: 0.1247
Batch 80, Loss: 0.1265
Batch 90, Loss: 0.1126
Batch 100, Loss: 0.1206
Batch 110, Loss: 0.1171
Batch 120, Loss: 0.1330
Batch 130, Loss: 0.1342
Batch 140, Loss: 0.1261
Batch 150, Loss: 0.1270
Batch 160, Loss: 0.1110
Batch 170, Loss: 0.1217
Batch 180, Loss: 0.1353
Batch 190, Loss: 0.1119
Batch 200, Loss: 0.1308
Batch 210, Loss: 0.1281
Batch 220, Loss: 0.1140
Batch 230, Loss: 0.1246
Batch 240, Loss: 0.1367
Batch 250, Loss: 0.1145
Batch 260, Loss: 0.1403
Batch 270, Loss: 0.1202
Batch 280, Loss: 0.1126
Batch 290, Loss: 0.1070
Batch 300, Loss: 0.1425
Batch 310, Loss: 0.1218
Batch 320, Loss: 0.1342
Batch 330, Loss: 0.1242
Batch 340, Loss: 0.1118
Batch 350, Loss: 0.1135
Batch 360, Loss: 0.1303
Batch 370, Loss: 0.1404
Batch 380, Loss: 0.1161
Batch 390, Loss: 0.1183
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 24.989351511001587 seconds
Epoch 199 accuracy: 96.3%
Batch 10, Loss: 0.1237
Batch 20, Loss: 0.1068
Batch 30, Loss: 0.1321
Batch 40, Loss: 0.1148
Batch 50, Loss: 0.1385
Batch 60, Loss: 0.1409
Batch 70, Loss: 0.1217
Batch 80, Loss: 0.1469
Batch 90, Loss: 0.1352
Batch 100, Loss: 0.1377
Batch 110, Loss: 0.1313
Batch 120, Loss: 0.1321
Batch 130, Loss: 0.1383
Batch 140, Loss: 0.1433
Batch 150, Loss: 0.1182
Batch 160, Loss: 0.1313
Batch 170, Loss: 0.1353
Batch 180, Loss: 0.1365
Batch 190, Loss: 0.1250
Batch 200, Loss: 0.1243
Batch 210, Loss: 0.1414
Batch 220, Loss: 0.1260
Batch 230, Loss: 0.1260
Batch 240, Loss: 0.1260
Batch 250, Loss: 0.1136
Batch 260, Loss: 0.1359
Batch 270, Loss: 0.1330
Batch 280, Loss: 0.1264
Batch 290, Loss: 0.1263
Batch 300, Loss: 0.1091
Batch 310, Loss: 0.0981
Batch 320, Loss: 0.1233
Batch 330, Loss: 0.1239
Batch 340, Loss: 0.1252
Batch 350, Loss: 0.1344
Batch 360, Loss: 0.1030
Batch 370, Loss: 0.1174
Batch 380, Loss: 0.1084
Batch 390, Loss: 0.1193
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.01178503036499 seconds
Epoch 200 accuracy: 96.25%
Total training time: 5010.892743349075 seconds
