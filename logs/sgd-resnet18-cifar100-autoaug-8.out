The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) imkl/2023.2.0
  3) gcccore/.12.3   8)  pmix/4.2.4         13) StdEnv/2023
  4) gcc/12.3        9)  ucc/1.2.0
  5) hwloc/2.9.1     10) openmpi/4.1.5
/project/6070520/tkleinkn/Vanilla-GAM/main_cifar.py:187: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
model name space ['resnet101_c', 'resnet152_c', 'resnet18_c', 'resnet34_c', 'resnet50_c']
Use GPU: 0 for training
=> creating model 'resnet18_c'
Files already downloaded and verified
Files already downloaded and verified
tensorboard dir ./results/CIFAR100/GAM
Batch 10, Loss: 4.0890
Batch 20, Loss: 4.1061
Batch 30, Loss: 3.9441
Batch 40, Loss: 3.8562
Batch 50, Loss: 3.7857
Batch 60, Loss: 3.7408
Batch 70, Loss: 3.7171
Batch 80, Loss: 3.6781
Batch 90, Loss: 3.6652
Batch 100, Loss: 3.6619
Batch 110, Loss: 3.6535
Batch 120, Loss: 3.6327
Batch 130, Loss: 3.5953
Batch 140, Loss: 3.5938
Batch 150, Loss: 3.6058
Batch 160, Loss: 3.5665
Batch 170, Loss: 3.6137
Batch 180, Loss: 3.5783
Batch 190, Loss: 3.6000
Batch 200, Loss: 3.5416
Batch 210, Loss: 3.5473
Batch 220, Loss: 3.5592
Batch 230, Loss: 3.5237
Batch 240, Loss: 3.5525
Batch 250, Loss: 3.5036
Batch 260, Loss: 3.5261
Batch 270, Loss: 3.4712
Batch 280, Loss: 3.4965
Batch 290, Loss: 3.5084
Batch 300, Loss: 3.5096
Batch 310, Loss: 3.5295
Batch 320, Loss: 3.4634
Batch 330, Loss: 3.4710
Batch 340, Loss: 3.4712
Batch 350, Loss: 3.4492
Batch 360, Loss: 3.4385
Batch 370, Loss: 3.4019
Batch 380, Loss: 3.4157
Batch 390, Loss: 3.4536
Epoch 1 learning rate: 0.09999383162408304
Epoch 1 time: 31.549027919769287 seconds
Epoch 1 accuracy: 9.06%
Batch 10, Loss: 3.4385
Batch 20, Loss: 3.4103
Batch 30, Loss: 3.4077
Batch 40, Loss: 3.4117
Batch 50, Loss: 3.4261
Batch 60, Loss: 3.4261
Batch 70, Loss: 3.4093
Batch 80, Loss: 3.4285
Batch 90, Loss: 3.3623
Batch 100, Loss: 3.3538
Batch 110, Loss: 3.3270
Batch 120, Loss: 3.3784
Batch 130, Loss: 3.3931
Batch 140, Loss: 3.3505
Batch 150, Loss: 3.3491
Batch 160, Loss: 3.3437
Batch 170, Loss: 3.3273
Batch 180, Loss: 3.2471
Batch 190, Loss: 3.2923
Batch 200, Loss: 3.3235
Batch 210, Loss: 3.2903
Batch 220, Loss: 3.2724
Batch 230, Loss: 3.3238
Batch 240, Loss: 3.2580
Batch 250, Loss: 3.2908
Batch 260, Loss: 3.2604
Batch 270, Loss: 3.2089
Batch 280, Loss: 3.2533
Batch 290, Loss: 3.1908
Batch 300, Loss: 3.2125
Batch 310, Loss: 3.2229
Batch 320, Loss: 3.1998
Batch 330, Loss: 3.2257
Batch 340, Loss: 3.1995
Batch 350, Loss: 3.1996
Batch 360, Loss: 3.2439
Batch 370, Loss: 3.2154
Batch 380, Loss: 3.1707
Batch 390, Loss: 3.1966
Epoch 2 learning rate: 0.09997532801828658
Epoch 2 time: 25.636924028396606 seconds
Epoch 2 accuracy: 14.42%
Batch 10, Loss: 3.1630
Batch 20, Loss: 3.1809
Batch 30, Loss: 3.1186
Batch 40, Loss: 3.1203
Batch 50, Loss: 3.0827
Batch 60, Loss: 3.1093
Batch 70, Loss: 3.1001
Batch 80, Loss: 3.0126
Batch 90, Loss: 3.1172
Batch 100, Loss: 3.0987
Batch 110, Loss: 3.0605
Batch 120, Loss: 3.0789
Batch 130, Loss: 3.0849
Batch 140, Loss: 3.0925
Batch 150, Loss: 3.0768
Batch 160, Loss: 3.0828
Batch 170, Loss: 3.0515
Batch 180, Loss: 3.0637
Batch 190, Loss: 2.9751
Batch 200, Loss: 2.9631
Batch 210, Loss: 2.9390
Batch 220, Loss: 2.9298
Batch 230, Loss: 3.0104
Batch 240, Loss: 3.0169
Batch 250, Loss: 3.0013
Batch 260, Loss: 3.0007
Batch 270, Loss: 3.0102
Batch 280, Loss: 2.9827
Batch 290, Loss: 2.9526
Batch 300, Loss: 2.9857
Batch 310, Loss: 2.9710
Batch 320, Loss: 2.9274
Batch 330, Loss: 2.9549
Batch 340, Loss: 2.9865
Batch 350, Loss: 2.9230
Batch 360, Loss: 2.8823
Batch 370, Loss: 2.9611
Batch 380, Loss: 2.9023
Batch 390, Loss: 2.9545
Epoch 3 learning rate: 0.09994449374809851
Epoch 3 time: 25.317065477371216 seconds
Epoch 3 accuracy: 20.67%
Batch 10, Loss: 2.8901
Batch 20, Loss: 2.8751
Batch 30, Loss: 2.8264
Batch 40, Loss: 2.8613
Batch 50, Loss: 2.8416
Batch 60, Loss: 2.8301
Batch 70, Loss: 2.7926
Batch 80, Loss: 2.8289
Batch 90, Loss: 2.8242
Batch 100, Loss: 2.8949
Batch 110, Loss: 2.8717
Batch 120, Loss: 2.8589
Batch 130, Loss: 2.8335
Batch 140, Loss: 2.7858
Batch 150, Loss: 2.7325
Batch 160, Loss: 2.7712
Batch 170, Loss: 2.7545
Batch 180, Loss: 2.7457
Batch 190, Loss: 2.7199
Batch 200, Loss: 2.8302
Batch 210, Loss: 2.7552
Batch 220, Loss: 2.7176
Batch 230, Loss: 2.6997
Batch 240, Loss: 2.7180
Batch 250, Loss: 2.7521
Batch 260, Loss: 2.7446
Batch 270, Loss: 2.7800
Batch 280, Loss: 2.6925
Batch 290, Loss: 2.6552
Batch 300, Loss: 2.6168
Batch 310, Loss: 2.6853
Batch 320, Loss: 2.6604
Batch 330, Loss: 2.6231
Batch 340, Loss: 2.6724
Batch 350, Loss: 2.6553
Batch 360, Loss: 2.6421
Batch 370, Loss: 2.6092
Batch 380, Loss: 2.6900
Batch 390, Loss: 2.6782
Epoch 4 learning rate: 0.09990133642141359
Epoch 4 time: 25.605332851409912 seconds
Epoch 4 accuracy: 27.84%
Batch 10, Loss: 2.6043
Batch 20, Loss: 2.6034
Batch 30, Loss: 2.6296
Batch 40, Loss: 2.6351
Batch 50, Loss: 2.6254
Batch 60, Loss: 2.5186
Batch 70, Loss: 2.5375
Batch 80, Loss: 2.5886
Batch 90, Loss: 2.5218
Batch 100, Loss: 2.5502
Batch 110, Loss: 2.5822
Batch 120, Loss: 2.5755
Batch 130, Loss: 2.6436
Batch 140, Loss: 2.5274
Batch 150, Loss: 2.5004
Batch 160, Loss: 2.5169
Batch 170, Loss: 2.4516
Batch 180, Loss: 2.4826
Batch 190, Loss: 2.5731
Batch 200, Loss: 2.5129
Batch 210, Loss: 2.4978
Batch 220, Loss: 2.4806
Batch 230, Loss: 2.4554
Batch 240, Loss: 2.5004
Batch 250, Loss: 2.4588
Batch 260, Loss: 2.4446
Batch 270, Loss: 2.4896
Batch 280, Loss: 2.4038
Batch 290, Loss: 2.4090
Batch 300, Loss: 2.3829
Batch 310, Loss: 2.4535
Batch 320, Loss: 2.3937
Batch 330, Loss: 2.3999
Batch 340, Loss: 2.4224
Batch 350, Loss: 2.5015
Batch 360, Loss: 2.3869
Batch 370, Loss: 2.3557
Batch 380, Loss: 2.3699
Batch 390, Loss: 2.3858
Epoch 5 learning rate: 0.09984586668665642
Epoch 5 time: 25.667953968048096 seconds
Epoch 5 accuracy: 31.48%
Batch 10, Loss: 2.4437
Batch 20, Loss: 2.3847
Batch 30, Loss: 2.3012
Batch 40, Loss: 2.3438
Batch 50, Loss: 2.3766
Batch 60, Loss: 2.3326
Batch 70, Loss: 2.3298
Batch 80, Loss: 2.3483
Batch 90, Loss: 2.3843
Batch 100, Loss: 2.3414
Batch 110, Loss: 2.3699
Batch 120, Loss: 2.3607
Batch 130, Loss: 2.2889
Batch 140, Loss: 2.2886
Batch 150, Loss: 2.2742
Batch 160, Loss: 2.2686
Batch 170, Loss: 2.2853
Batch 180, Loss: 2.3069
Batch 190, Loss: 2.2771
Batch 200, Loss: 2.3478
Batch 210, Loss: 2.2683
Batch 220, Loss: 2.2692
Batch 230, Loss: 2.2984
Batch 240, Loss: 2.3270
Batch 250, Loss: 2.2981
Batch 260, Loss: 2.3241
Batch 270, Loss: 2.3049
Batch 280, Loss: 2.3344
Batch 290, Loss: 2.3448
Batch 300, Loss: 2.3085
Batch 310, Loss: 2.2891
Batch 320, Loss: 2.2820
Batch 330, Loss: 2.2694
Batch 340, Loss: 2.2779
Batch 350, Loss: 2.2508
Batch 360, Loss: 2.2260
Batch 370, Loss: 2.2847
Batch 380, Loss: 2.1754
Batch 390, Loss: 2.2579
Epoch 6 learning rate: 0.09977809823015402
Epoch 6 time: 25.503767251968384 seconds
Epoch 6 accuracy: 40.97%
Batch 10, Loss: 2.1595
Batch 20, Loss: 2.1386
Batch 30, Loss: 2.1846
Batch 40, Loss: 2.1378
Batch 50, Loss: 2.1332
Batch 60, Loss: 2.1857
Batch 70, Loss: 2.1045
Batch 80, Loss: 2.1899
Batch 90, Loss: 2.1962
Batch 100, Loss: 2.2101
Batch 110, Loss: 2.2116
Batch 120, Loss: 2.1308
Batch 130, Loss: 2.1910
Batch 140, Loss: 2.2272
Batch 150, Loss: 2.2350
Batch 160, Loss: 2.1931
Batch 170, Loss: 2.1916
Batch 180, Loss: 2.1380
Batch 190, Loss: 2.1508
Batch 200, Loss: 2.1507
Batch 210, Loss: 2.1386
Batch 220, Loss: 2.1756
Batch 230, Loss: 2.1570
Batch 240, Loss: 2.1187
Batch 250, Loss: 2.1066
Batch 260, Loss: 2.1486
Batch 270, Loss: 2.1435
Batch 280, Loss: 2.1297
Batch 290, Loss: 2.1331
Batch 300, Loss: 2.1722
Batch 310, Loss: 2.2285
Batch 320, Loss: 2.1376
Batch 330, Loss: 2.0765
Batch 340, Loss: 2.0595
Batch 350, Loss: 2.0623
Batch 360, Loss: 2.1305
Batch 370, Loss: 2.0722
Batch 380, Loss: 2.0674
Batch 390, Loss: 2.0849
Epoch 7 learning rate: 0.09969804777275901
Epoch 7 time: 25.56455707550049 seconds
Epoch 7 accuracy: 40.71%
Batch 10, Loss: 2.1029
Batch 20, Loss: 2.0925
Batch 30, Loss: 2.0189
Batch 40, Loss: 2.0259
Batch 50, Loss: 1.9822
Batch 60, Loss: 2.0827
Batch 70, Loss: 2.0286
Batch 80, Loss: 2.0801
Batch 90, Loss: 2.0860
Batch 100, Loss: 2.0220
Batch 110, Loss: 2.1143
Batch 120, Loss: 2.1197
Batch 130, Loss: 1.9980
Batch 140, Loss: 2.0340
Batch 150, Loss: 2.0525
Batch 160, Loss: 2.0742
Batch 170, Loss: 2.0286
Batch 180, Loss: 2.0316
Batch 190, Loss: 2.0521
Batch 200, Loss: 1.9913
Batch 210, Loss: 2.0096
Batch 220, Loss: 2.0140
Batch 230, Loss: 2.0735
Batch 240, Loss: 2.0438
Batch 250, Loss: 2.0589
Batch 260, Loss: 2.0152
Batch 270, Loss: 2.0267
Batch 280, Loss: 2.0230
Batch 290, Loss: 2.0497
Batch 300, Loss: 1.9847
Batch 310, Loss: 2.0268
Batch 320, Loss: 1.9992
Batch 330, Loss: 1.9658
Batch 340, Loss: 1.9788
Batch 350, Loss: 1.9846
Batch 360, Loss: 2.0072
Batch 370, Loss: 2.0035
Batch 380, Loss: 1.9510
Batch 390, Loss: 1.9310
Epoch 8 learning rate: 0.09960573506572391
Epoch 8 time: 25.606513500213623 seconds
Epoch 8 accuracy: 40.87%
Batch 10, Loss: 1.9848
Batch 20, Loss: 2.0186
Batch 30, Loss: 2.0183
Batch 40, Loss: 1.9191
Batch 50, Loss: 1.9810
Batch 60, Loss: 1.9431
Batch 70, Loss: 1.9472
Batch 80, Loss: 1.9596
Batch 90, Loss: 1.9817
Batch 100, Loss: 1.9830
Batch 110, Loss: 1.9218
Batch 120, Loss: 1.9772
Batch 130, Loss: 1.9348
Batch 140, Loss: 1.9972
Batch 150, Loss: 1.9396
Batch 160, Loss: 1.9173
Batch 170, Loss: 1.9667
Batch 180, Loss: 1.9527
Batch 190, Loss: 2.0083
Batch 200, Loss: 1.9327
Batch 210, Loss: 1.9403
Batch 220, Loss: 1.9681
Batch 230, Loss: 1.8970
Batch 240, Loss: 1.9644
Batch 250, Loss: 1.9326
Batch 260, Loss: 1.9418
Batch 270, Loss: 1.9395
Batch 280, Loss: 1.8598
Batch 290, Loss: 1.9444
Batch 300, Loss: 2.0243
Batch 310, Loss: 1.9749
Batch 320, Loss: 2.0096
Batch 330, Loss: 1.9040
Batch 340, Loss: 1.9324
Batch 350, Loss: 1.9340
Batch 360, Loss: 1.8827
Batch 370, Loss: 1.8706
Batch 380, Loss: 1.9493
Batch 390, Loss: 1.9417
Epoch 9 learning rate: 0.09950118288582789
Epoch 9 time: 25.483296632766724 seconds
Epoch 9 accuracy: 46.36%
Batch 10, Loss: 1.8193
Batch 20, Loss: 1.8804
Batch 30, Loss: 1.9511
Batch 40, Loss: 1.9039
Batch 50, Loss: 1.8917
Batch 60, Loss: 1.9553
Batch 70, Loss: 1.9482
Batch 80, Loss: 1.8441
Batch 90, Loss: 1.9075
Batch 100, Loss: 1.8696
Batch 110, Loss: 1.9007
Batch 120, Loss: 1.9010
Batch 130, Loss: 1.7876
Batch 140, Loss: 1.8725
Batch 150, Loss: 1.8350
Batch 160, Loss: 1.9349
Batch 170, Loss: 1.9084
Batch 180, Loss: 1.8889
Batch 190, Loss: 1.9066
Batch 200, Loss: 1.9061
Batch 210, Loss: 1.8832
Batch 220, Loss: 1.9015
Batch 230, Loss: 1.9204
Batch 240, Loss: 1.9878
Batch 250, Loss: 1.8106
Batch 260, Loss: 1.8931
Batch 270, Loss: 1.9414
Batch 280, Loss: 1.8575
Batch 290, Loss: 1.8561
Batch 300, Loss: 1.8644
Batch 310, Loss: 1.8944
Batch 320, Loss: 1.8874
Batch 330, Loss: 1.8683
Batch 340, Loss: 1.9129
Batch 350, Loss: 1.8748
Batch 360, Loss: 1.8658
Batch 370, Loss: 1.8594
Batch 380, Loss: 1.9064
Batch 390, Loss: 1.9526
Epoch 10 learning rate: 0.09938441702975691
Epoch 10 time: 25.659742832183838 seconds
Epoch 10 accuracy: 46.87%
Batch 10, Loss: 1.9025
Batch 20, Loss: 1.7835
Batch 30, Loss: 1.9108
Batch 40, Loss: 1.8058
Batch 50, Loss: 1.8435
Batch 60, Loss: 1.8003
Batch 70, Loss: 1.8221
Batch 80, Loss: 1.8364
Batch 90, Loss: 1.8380
Batch 100, Loss: 1.7776
Batch 110, Loss: 1.7924
Batch 120, Loss: 1.8205
Batch 130, Loss: 1.7584
Batch 140, Loss: 1.8778
Batch 150, Loss: 1.8291
Batch 160, Loss: 1.9255
Batch 170, Loss: 1.8521
Batch 180, Loss: 1.8134
Batch 190, Loss: 1.9178
Batch 200, Loss: 1.9246
Batch 210, Loss: 1.8961
Batch 220, Loss: 1.8321
Batch 230, Loss: 1.8607
Batch 240, Loss: 1.8571
Batch 250, Loss: 1.8341
Batch 260, Loss: 1.8529
Batch 270, Loss: 1.8293
Batch 280, Loss: 1.7724
Batch 290, Loss: 1.8281
Batch 300, Loss: 1.8448
Batch 310, Loss: 1.8111
Batch 320, Loss: 1.8221
Batch 330, Loss: 1.8780
Batch 340, Loss: 1.8782
Batch 350, Loss: 1.8099
Batch 360, Loss: 1.8782
Batch 370, Loss: 1.8492
Batch 380, Loss: 1.7745
Batch 390, Loss: 1.8364
Epoch 11 learning rate: 0.09925546630773871
Epoch 11 time: 25.593741178512573 seconds
Epoch 11 accuracy: 52.81%
Batch 10, Loss: 1.7354
Batch 20, Loss: 1.7535
Batch 30, Loss: 1.7569
Batch 40, Loss: 1.8196
Batch 50, Loss: 1.7895
Batch 60, Loss: 1.7547
Batch 70, Loss: 1.7744
Batch 80, Loss: 1.7769
Batch 90, Loss: 1.8094
Batch 100, Loss: 1.8098
Batch 110, Loss: 1.8576
Batch 120, Loss: 1.8334
Batch 130, Loss: 1.7138
Batch 140, Loss: 1.7899
Batch 150, Loss: 1.7452
Batch 160, Loss: 1.7614
Batch 170, Loss: 1.8238
Batch 180, Loss: 1.8073
Batch 190, Loss: 1.7744
Batch 200, Loss: 1.8190
Batch 210, Loss: 1.8585
Batch 220, Loss: 1.7967
Batch 230, Loss: 1.8900
Batch 240, Loss: 1.8328
Batch 250, Loss: 1.8073
Batch 260, Loss: 1.8367
Batch 270, Loss: 1.7705
Batch 280, Loss: 1.7652
Batch 290, Loss: 1.7826
Batch 300, Loss: 1.8472
Batch 310, Loss: 1.7738
Batch 320, Loss: 1.7411
Batch 330, Loss: 1.7566
Batch 340, Loss: 1.7721
Batch 350, Loss: 1.8819
Batch 360, Loss: 1.8092
Batch 370, Loss: 1.8357
Batch 380, Loss: 1.8400
Batch 390, Loss: 1.7672
Epoch 12 learning rate: 0.09911436253643445
Epoch 12 time: 25.582712650299072 seconds
Epoch 12 accuracy: 50.95%
Batch 10, Loss: 1.7032
Batch 20, Loss: 1.7417
Batch 30, Loss: 1.7413
Batch 40, Loss: 1.7441
Batch 50, Loss: 1.7279
Batch 60, Loss: 1.7445
Batch 70, Loss: 1.7604
Batch 80, Loss: 1.7809
Batch 90, Loss: 1.7363
Batch 100, Loss: 1.7426
Batch 110, Loss: 1.7845
Batch 120, Loss: 1.7395
Batch 130, Loss: 1.7375
Batch 140, Loss: 1.7556
Batch 150, Loss: 1.7268
Batch 160, Loss: 1.7888
Batch 170, Loss: 1.8263
Batch 180, Loss: 1.8078
Batch 190, Loss: 1.7700
Batch 200, Loss: 1.7467
Batch 210, Loss: 1.7159
Batch 220, Loss: 1.8016
Batch 230, Loss: 1.7565
Batch 240, Loss: 1.7563
Batch 250, Loss: 1.7595
Batch 260, Loss: 1.7487
Batch 270, Loss: 1.7411
Batch 280, Loss: 1.8304
Batch 290, Loss: 1.7464
Batch 300, Loss: 1.8097
Batch 310, Loss: 1.8013
Batch 320, Loss: 1.7464
Batch 330, Loss: 1.7908
Batch 340, Loss: 1.7014
Batch 350, Loss: 1.7613
Batch 360, Loss: 1.8213
Batch 370, Loss: 1.7996
Batch 380, Loss: 1.7241
Batch 390, Loss: 1.7477
Epoch 13 learning rate: 0.0989611405310883
Epoch 13 time: 25.557471990585327 seconds
Epoch 13 accuracy: 46.69%
Batch 10, Loss: 1.7430
Batch 20, Loss: 1.6857
Batch 30, Loss: 1.7223
Batch 40, Loss: 1.7101
Batch 50, Loss: 1.7544
Batch 60, Loss: 1.6613
Batch 70, Loss: 1.7544
Batch 80, Loss: 1.8021
Batch 90, Loss: 1.7584
Batch 100, Loss: 1.6461
Batch 110, Loss: 1.7611
Batch 120, Loss: 1.7128
Batch 130, Loss: 1.7327
Batch 140, Loss: 1.7167
Batch 150, Loss: 1.7409
Batch 160, Loss: 1.7015
Batch 170, Loss: 1.7794
Batch 180, Loss: 1.7519
Batch 190, Loss: 1.6935
Batch 200, Loss: 1.6537
Batch 210, Loss: 1.6940
Batch 220, Loss: 1.6960
Batch 230, Loss: 1.6610
Batch 240, Loss: 1.7116
Batch 250, Loss: 1.7772
Batch 260, Loss: 1.7602
Batch 270, Loss: 1.7611
Batch 280, Loss: 1.7563
Batch 290, Loss: 1.7715
Batch 300, Loss: 1.7531
Batch 310, Loss: 1.7442
Batch 320, Loss: 1.7369
Batch 330, Loss: 1.7336
Batch 340, Loss: 1.8032
Batch 350, Loss: 1.7516
Batch 360, Loss: 1.7520
Batch 370, Loss: 1.7165
Batch 380, Loss: 1.7507
Batch 390, Loss: 1.6993
Epoch 14 learning rate: 0.09879583809693739
Epoch 14 time: 25.557183027267456 seconds
Epoch 14 accuracy: 52.51%
Batch 10, Loss: 1.6275
Batch 20, Loss: 1.7041
Batch 30, Loss: 1.6848
Batch 40, Loss: 1.6977
Batch 50, Loss: 1.7066
Batch 60, Loss: 1.6763
Batch 70, Loss: 1.6602
Batch 80, Loss: 1.7040
Batch 90, Loss: 1.6455
Batch 100, Loss: 1.7214
Batch 110, Loss: 1.6688
Batch 120, Loss: 1.8033
Batch 130, Loss: 1.6980
Batch 140, Loss: 1.7110
Batch 150, Loss: 1.6786
Batch 160, Loss: 1.6553
Batch 170, Loss: 1.7057
Batch 180, Loss: 1.7082
Batch 190, Loss: 1.7567
Batch 200, Loss: 1.6777
Batch 210, Loss: 1.6573
Batch 220, Loss: 1.7068
Batch 230, Loss: 1.6792
Batch 240, Loss: 1.7213
Batch 250, Loss: 1.6438
Batch 260, Loss: 1.6611
Batch 270, Loss: 1.6848
Batch 280, Loss: 1.7297
Batch 290, Loss: 1.7855
Batch 300, Loss: 1.7760
Batch 310, Loss: 1.7197
Batch 320, Loss: 1.6752
Batch 330, Loss: 1.7001
Batch 340, Loss: 1.7079
Batch 350, Loss: 1.7047
Batch 360, Loss: 1.7169
Batch 370, Loss: 1.7220
Batch 380, Loss: 1.7059
Batch 390, Loss: 1.7797
Epoch 15 learning rate: 0.09861849601988384
Epoch 15 time: 25.600839138031006 seconds
Epoch 15 accuracy: 47.44%
Batch 10, Loss: 1.6505
Batch 20, Loss: 1.7371
Batch 30, Loss: 1.6705
Batch 40, Loss: 1.7545
Batch 50, Loss: 1.6221
Batch 60, Loss: 1.6648
Batch 70, Loss: 1.6700
Batch 80, Loss: 1.6004
Batch 90, Loss: 1.6473
Batch 100, Loss: 1.6721
Batch 110, Loss: 1.6463
Batch 120, Loss: 1.7325
Batch 130, Loss: 1.7526
Batch 140, Loss: 1.6587
Batch 150, Loss: 1.6238
Batch 160, Loss: 1.6962
Batch 170, Loss: 1.6332
Batch 180, Loss: 1.7290
Batch 190, Loss: 1.6194
Batch 200, Loss: 1.7284
Batch 210, Loss: 1.7754
Batch 220, Loss: 1.7212
Batch 230, Loss: 1.6650
Batch 240, Loss: 1.6279
Batch 250, Loss: 1.7027
Batch 260, Loss: 1.6148
Batch 270, Loss: 1.6679
Batch 280, Loss: 1.6972
Batch 290, Loss: 1.6635
Batch 300, Loss: 1.6500
Batch 310, Loss: 1.7066
Batch 320, Loss: 1.7357
Batch 330, Loss: 1.7440
Batch 340, Loss: 1.6815
Batch 350, Loss: 1.7053
Batch 360, Loss: 1.6533
Batch 370, Loss: 1.7538
Batch 380, Loss: 1.6923
Batch 390, Loss: 1.6813
Epoch 16 learning rate: 0.09842915805643157
Epoch 16 time: 25.631330966949463 seconds
Epoch 16 accuracy: 47.42%
Batch 10, Loss: 1.6158
Batch 20, Loss: 1.6530
Batch 30, Loss: 1.6714
Batch 40, Loss: 1.7223
Batch 50, Loss: 1.6501
Batch 60, Loss: 1.6018
Batch 70, Loss: 1.6302
Batch 80, Loss: 1.6188
Batch 90, Loss: 1.6601
Batch 100, Loss: 1.7213
Batch 110, Loss: 1.6297
Batch 120, Loss: 1.6841
Batch 130, Loss: 1.6944
Batch 140, Loss: 1.6438
Batch 150, Loss: 1.6628
Batch 160, Loss: 1.7008
Batch 170, Loss: 1.6616
Batch 180, Loss: 1.5910
Batch 190, Loss: 1.7023
Batch 200, Loss: 1.5775
Batch 210, Loss: 1.6390
Batch 220, Loss: 1.6302
Batch 230, Loss: 1.6262
Batch 240, Loss: 1.7504
Batch 250, Loss: 1.6271
Batch 260, Loss: 1.6713
Batch 270, Loss: 1.6059
Batch 280, Loss: 1.6103
Batch 290, Loss: 1.6530
Batch 300, Loss: 1.6814
Batch 310, Loss: 1.6975
Batch 320, Loss: 1.7280
Batch 330, Loss: 1.6453
Batch 340, Loss: 1.6322
Batch 350, Loss: 1.6791
Batch 360, Loss: 1.6752
Batch 370, Loss: 1.7102
Batch 380, Loss: 1.6737
Batch 390, Loss: 1.7014
Epoch 17 learning rate: 0.09822787092288993
Epoch 17 time: 25.614036321640015 seconds
Epoch 17 accuracy: 48.27%
Batch 10, Loss: 1.5995
Batch 20, Loss: 1.6135
Batch 30, Loss: 1.5962
Batch 40, Loss: 1.5550
Batch 50, Loss: 1.5740
Batch 60, Loss: 1.6000
Batch 70, Loss: 1.6636
Batch 80, Loss: 1.6280
Batch 90, Loss: 1.6855
Batch 100, Loss: 1.6380
Batch 110, Loss: 1.6737
Batch 120, Loss: 1.6932
Batch 130, Loss: 1.6602
Batch 140, Loss: 1.6856
Batch 150, Loss: 1.6023
Batch 160, Loss: 1.7006
Batch 170, Loss: 1.6167
Batch 180, Loss: 1.5877
Batch 190, Loss: 1.7148
Batch 200, Loss: 1.6123
Batch 210, Loss: 1.6195
Batch 220, Loss: 1.7022
Batch 230, Loss: 1.6123
Batch 240, Loss: 1.6669
Batch 250, Loss: 1.6837
Batch 260, Loss: 1.6045
Batch 270, Loss: 1.6944
Batch 280, Loss: 1.6109
Batch 290, Loss: 1.6161
Batch 300, Loss: 1.6139
Batch 310, Loss: 1.5581
Batch 320, Loss: 1.6529
Batch 330, Loss: 1.7015
Batch 340, Loss: 1.6930
Batch 350, Loss: 1.6805
Batch 360, Loss: 1.6773
Batch 370, Loss: 1.6937
Batch 380, Loss: 1.5582
Batch 390, Loss: 1.6654
Epoch 18 learning rate: 0.09801468428384717
Epoch 18 time: 25.553688764572144 seconds
Epoch 18 accuracy: 51.38%
Batch 10, Loss: 1.6522
Batch 20, Loss: 1.5375
Batch 30, Loss: 1.6260
Batch 40, Loss: 1.6489
Batch 50, Loss: 1.5841
Batch 60, Loss: 1.6539
Batch 70, Loss: 1.7186
Batch 80, Loss: 1.6379
Batch 90, Loss: 1.5993
Batch 100, Loss: 1.5939
Batch 110, Loss: 1.5299
Batch 120, Loss: 1.6196
Batch 130, Loss: 1.6512
Batch 140, Loss: 1.6522
Batch 150, Loss: 1.6301
Batch 160, Loss: 1.5712
Batch 170, Loss: 1.6014
Batch 180, Loss: 1.6140
Batch 190, Loss: 1.6544
Batch 200, Loss: 1.5845
Batch 210, Loss: 1.6295
Batch 220, Loss: 1.6281
Batch 230, Loss: 1.6812
Batch 240, Loss: 1.6891
Batch 250, Loss: 1.6240
Batch 260, Loss: 1.6102
Batch 270, Loss: 1.5987
Batch 280, Loss: 1.6733
Batch 290, Loss: 1.6069
Batch 300, Loss: 1.6273
Batch 310, Loss: 1.6150
Batch 320, Loss: 1.5515
Batch 330, Loss: 1.6697
Batch 340, Loss: 1.6263
Batch 350, Loss: 1.6501
Batch 360, Loss: 1.6480
Batch 370, Loss: 1.6681
Batch 380, Loss: 1.6333
Batch 390, Loss: 1.6277
Epoch 19 learning rate: 0.09778965073991652
Epoch 19 time: 25.669042825698853 seconds
Epoch 19 accuracy: 55.53%
Batch 10, Loss: 1.5657
Batch 20, Loss: 1.6402
Batch 30, Loss: 1.5366
Batch 40, Loss: 1.5398
Batch 50, Loss: 1.5200
Batch 60, Loss: 1.6476
Batch 70, Loss: 1.5194
Batch 80, Loss: 1.6633
Batch 90, Loss: 1.5717
Batch 100, Loss: 1.5428
Batch 110, Loss: 1.5709
Batch 120, Loss: 1.5611
Batch 130, Loss: 1.6104
Batch 140, Loss: 1.6967
Batch 150, Loss: 1.5964
Batch 160, Loss: 1.6122
Batch 170, Loss: 1.5897
Batch 180, Loss: 1.6040
Batch 190, Loss: 1.6329
Batch 200, Loss: 1.5668
Batch 210, Loss: 1.6142
Batch 220, Loss: 1.6691
Batch 230, Loss: 1.5728
Batch 240, Loss: 1.5616
Batch 250, Loss: 1.6329
Batch 260, Loss: 1.6322
Batch 270, Loss: 1.7517
Batch 280, Loss: 1.5481
Batch 290, Loss: 1.5491
Batch 300, Loss: 1.6489
Batch 310, Loss: 1.6795
Batch 320, Loss: 1.6861
Batch 330, Loss: 1.5632
Batch 340, Loss: 1.6146
Batch 350, Loss: 1.6653
Batch 360, Loss: 1.6224
Batch 370, Loss: 1.5183
Batch 380, Loss: 1.6159
Batch 390, Loss: 1.6509
Epoch 20 learning rate: 0.0975528258147577
Epoch 20 time: 25.571292877197266 seconds
Epoch 20 accuracy: 52.3%
Batch 10, Loss: 1.5638
Batch 20, Loss: 1.5599
Batch 30, Loss: 1.6047
Batch 40, Loss: 1.5761
Batch 50, Loss: 1.6468
Batch 60, Loss: 1.5375
Batch 70, Loss: 1.5441
Batch 80, Loss: 1.4971
Batch 90, Loss: 1.5997
Batch 100, Loss: 1.5810
Batch 110, Loss: 1.5812
Batch 120, Loss: 1.5538
Batch 130, Loss: 1.5459
Batch 140, Loss: 1.5598
Batch 150, Loss: 1.5958
Batch 160, Loss: 1.6945
Batch 170, Loss: 1.5659
Batch 180, Loss: 1.5697
Batch 190, Loss: 1.6155
Batch 200, Loss: 1.5518
Batch 210, Loss: 1.6899
Batch 220, Loss: 1.6397
Batch 230, Loss: 1.6239
Batch 240, Loss: 1.5360
Batch 250, Loss: 1.5622
Batch 260, Loss: 1.5756
Batch 270, Loss: 1.6099
Batch 280, Loss: 1.5888
Batch 290, Loss: 1.6175
Batch 300, Loss: 1.5948
Batch 310, Loss: 1.5969
Batch 320, Loss: 1.6100
Batch 330, Loss: 1.6978
Batch 340, Loss: 1.5854
Batch 350, Loss: 1.6415
Batch 360, Loss: 1.6276
Batch 370, Loss: 1.6076
Batch 380, Loss: 1.6373
Batch 390, Loss: 1.6925
Epoch 21 learning rate: 0.09730426794137728
Epoch 21 time: 25.40047335624695 seconds
Epoch 21 accuracy: 51.23%
Batch 10, Loss: 1.5657
Batch 20, Loss: 1.5612
Batch 30, Loss: 1.6404
Batch 40, Loss: 1.5688
Batch 50, Loss: 1.5289
Batch 60, Loss: 1.5947
Batch 70, Loss: 1.5085
Batch 80, Loss: 1.5287
Batch 90, Loss: 1.5737
Batch 100, Loss: 1.5421
Batch 110, Loss: 1.6297
Batch 120, Loss: 1.5958
Batch 130, Loss: 1.5858
Batch 140, Loss: 1.5490
Batch 150, Loss: 1.5444
Batch 160, Loss: 1.6431
Batch 170, Loss: 1.5734
Batch 180, Loss: 1.5966
Batch 190, Loss: 1.5806
Batch 200, Loss: 1.5354
Batch 210, Loss: 1.5580
Batch 220, Loss: 1.5497
Batch 230, Loss: 1.5666
Batch 240, Loss: 1.5966
Batch 250, Loss: 1.5833
Batch 260, Loss: 1.5795
Batch 270, Loss: 1.5927
Batch 280, Loss: 1.5897
Batch 290, Loss: 1.6161
Batch 300, Loss: 1.5759
Batch 310, Loss: 1.6053
Batch 320, Loss: 1.6354
Batch 330, Loss: 1.6733
Batch 340, Loss: 1.5721
Batch 350, Loss: 1.6788
Batch 360, Loss: 1.7052
Batch 370, Loss: 1.6803
Batch 380, Loss: 1.6157
Batch 390, Loss: 1.5913
Epoch 22 learning rate: 0.09704403844771128
Epoch 22 time: 25.485275983810425 seconds
Epoch 22 accuracy: 53.7%
Batch 10, Loss: 1.4572
Batch 20, Loss: 1.5217
Batch 30, Loss: 1.5457
Batch 40, Loss: 1.5428
Batch 50, Loss: 1.5820
Batch 60, Loss: 1.5568
Batch 70, Loss: 1.5612
Batch 80, Loss: 1.5416
Batch 90, Loss: 1.5863
Batch 100, Loss: 1.5233
Batch 110, Loss: 1.5779
Batch 120, Loss: 1.5872
Batch 130, Loss: 1.6415
Batch 140, Loss: 1.5635
Batch 150, Loss: 1.5884
Batch 160, Loss: 1.5744
Batch 170, Loss: 1.6641
Batch 180, Loss: 1.5558
Batch 190, Loss: 1.6068
Batch 200, Loss: 1.5727
Batch 210, Loss: 1.6323
Batch 220, Loss: 1.5319
Batch 230, Loss: 1.5732
Batch 240, Loss: 1.6072
Batch 250, Loss: 1.6103
Batch 260, Loss: 1.5616
Batch 270, Loss: 1.5344
Batch 280, Loss: 1.6077
Batch 290, Loss: 1.5818
Batch 300, Loss: 1.5768
Batch 310, Loss: 1.6505
Batch 320, Loss: 1.6247
Batch 330, Loss: 1.5634
Batch 340, Loss: 1.5650
Batch 350, Loss: 1.5443
Batch 360, Loss: 1.5980
Batch 370, Loss: 1.5197
Batch 380, Loss: 1.6079
Batch 390, Loss: 1.5464
Epoch 23 learning rate: 0.09677220154149338
Epoch 23 time: 25.62256693840027 seconds
Epoch 23 accuracy: 53.39%
Batch 10, Loss: 1.4944
Batch 20, Loss: 1.5645
Batch 30, Loss: 1.5452
Batch 40, Loss: 1.5650
Batch 50, Loss: 1.5061
Batch 60, Loss: 1.5621
Batch 70, Loss: 1.5274
Batch 80, Loss: 1.5563
Batch 90, Loss: 1.5540
Batch 100, Loss: 1.6265
Batch 110, Loss: 1.5380
Batch 120, Loss: 1.5696
Batch 130, Loss: 1.4994
Batch 140, Loss: 1.5608
Batch 150, Loss: 1.5152
Batch 160, Loss: 1.5217
Batch 170, Loss: 1.5926
Batch 180, Loss: 1.5288
Batch 190, Loss: 1.5663
Batch 200, Loss: 1.4837
Batch 210, Loss: 1.5173
Batch 220, Loss: 1.5725
Batch 230, Loss: 1.5881
Batch 240, Loss: 1.5221
Batch 250, Loss: 1.5203
Batch 260, Loss: 1.5945
Batch 270, Loss: 1.5783
Batch 280, Loss: 1.5881
Batch 290, Loss: 1.5707
Batch 300, Loss: 1.5583
Batch 310, Loss: 1.6114
Batch 320, Loss: 1.5820
Batch 330, Loss: 1.6200
Batch 340, Loss: 1.6314
Batch 350, Loss: 1.5963
Batch 360, Loss: 1.6012
Batch 370, Loss: 1.5625
Batch 380, Loss: 1.5471
Batch 390, Loss: 1.5618
Epoch 24 learning rate: 0.09648882429441258
Epoch 24 time: 25.505099534988403 seconds
Epoch 24 accuracy: 55.83%
Batch 10, Loss: 1.5209
Batch 20, Loss: 1.4777
Batch 30, Loss: 1.5139
Batch 40, Loss: 1.6035
Batch 50, Loss: 1.5682
Batch 60, Loss: 1.5405
Batch 70, Loss: 1.4864
Batch 80, Loss: 1.5042
Batch 90, Loss: 1.5080
Batch 100, Loss: 1.5636
Batch 110, Loss: 1.5965
Batch 120, Loss: 1.6092
Batch 130, Loss: 1.5551
Batch 140, Loss: 1.5297
Batch 150, Loss: 1.5940
Batch 160, Loss: 1.5219
Batch 170, Loss: 1.5635
Batch 180, Loss: 1.5839
Batch 190, Loss: 1.5312
Batch 200, Loss: 1.6173
Batch 210, Loss: 1.5267
Batch 220, Loss: 1.6006
Batch 230, Loss: 1.5389
Batch 240, Loss: 1.6058
Batch 250, Loss: 1.5550
Batch 260, Loss: 1.5328
Batch 270, Loss: 1.5666
Batch 280, Loss: 1.5267
Batch 290, Loss: 1.5879
Batch 300, Loss: 1.5242
Batch 310, Loss: 1.5368
Batch 320, Loss: 1.5883
Batch 330, Loss: 1.5586
Batch 340, Loss: 1.5298
Batch 350, Loss: 1.5096
Batch 360, Loss: 1.5629
Batch 370, Loss: 1.6590
Batch 380, Loss: 1.6090
Batch 390, Loss: 1.5274
Epoch 25 learning rate: 0.09619397662556435
Epoch 25 time: 25.569830894470215 seconds
Epoch 25 accuracy: 56.17%
Batch 10, Loss: 1.5844
Batch 20, Loss: 1.5604
Batch 30, Loss: 1.5120
Batch 40, Loss: 1.5600
Batch 50, Loss: 1.5659
Batch 60, Loss: 1.5368
Batch 70, Loss: 1.5293
Batch 80, Loss: 1.4970
Batch 90, Loss: 1.5989
Batch 100, Loss: 1.5575
Batch 110, Loss: 1.5213
Batch 120, Loss: 1.5225
Batch 130, Loss: 1.4702
Batch 140, Loss: 1.4893
Batch 150, Loss: 1.5839
Batch 160, Loss: 1.4868
Batch 170, Loss: 1.5391
Batch 180, Loss: 1.5479
Batch 190, Loss: 1.4704
Batch 200, Loss: 1.4970
Batch 210, Loss: 1.5113
Batch 220, Loss: 1.6095
Batch 230, Loss: 1.5164
Batch 240, Loss: 1.4991
Batch 250, Loss: 1.6116
Batch 260, Loss: 1.5128
Batch 270, Loss: 1.5717
Batch 280, Loss: 1.5865
Batch 290, Loss: 1.5908
Batch 300, Loss: 1.5382
Batch 310, Loss: 1.5628
Batch 320, Loss: 1.5753
Batch 330, Loss: 1.5681
Batch 340, Loss: 1.5656
Batch 350, Loss: 1.5431
Batch 360, Loss: 1.6148
Batch 370, Loss: 1.5757
Batch 380, Loss: 1.5656
Batch 390, Loss: 1.6152
Epoch 26 learning rate: 0.09588773128419906
Epoch 26 time: 25.552708864212036 seconds
Epoch 26 accuracy: 55.11%
Batch 10, Loss: 1.4419
Batch 20, Loss: 1.4491
Batch 30, Loss: 1.4892
Batch 40, Loss: 1.5377
Batch 50, Loss: 1.4497
Batch 60, Loss: 1.4925
Batch 70, Loss: 1.5529
Batch 80, Loss: 1.4901
Batch 90, Loss: 1.5474
Batch 100, Loss: 1.5188
Batch 110, Loss: 1.5704
Batch 120, Loss: 1.5186
Batch 130, Loss: 1.5550
Batch 140, Loss: 1.5709
Batch 150, Loss: 1.5472
Batch 160, Loss: 1.4975
Batch 170, Loss: 1.5288
Batch 180, Loss: 1.5253
Batch 190, Loss: 1.5028
Batch 200, Loss: 1.4948
Batch 210, Loss: 1.4502
Batch 220, Loss: 1.5317
Batch 230, Loss: 1.5743
Batch 240, Loss: 1.5322
Batch 250, Loss: 1.5129
Batch 260, Loss: 1.5399
Batch 270, Loss: 1.5832
Batch 280, Loss: 1.6130
Batch 290, Loss: 1.5766
Batch 300, Loss: 1.5413
Batch 310, Loss: 1.5273
Batch 320, Loss: 1.5817
Batch 330, Loss: 1.5407
Batch 340, Loss: 1.5183
Batch 350, Loss: 1.5161
Batch 360, Loss: 1.5705
Batch 370, Loss: 1.5545
Batch 380, Loss: 1.5572
Batch 390, Loss: 1.5788
Epoch 27 learning rate: 0.09557016383177226
Epoch 27 time: 25.60971760749817 seconds
Epoch 27 accuracy: 49.26%
Batch 10, Loss: 1.4922
Batch 20, Loss: 1.5167
Batch 30, Loss: 1.5590
Batch 40, Loss: 1.4887
Batch 50, Loss: 1.4795
Batch 60, Loss: 1.5317
Batch 70, Loss: 1.5146
Batch 80, Loss: 1.5061
Batch 90, Loss: 1.5085
Batch 100, Loss: 1.5194
Batch 110, Loss: 1.4599
Batch 120, Loss: 1.5061
Batch 130, Loss: 1.5160
Batch 140, Loss: 1.5703
Batch 150, Loss: 1.5082
Batch 160, Loss: 1.5387
Batch 170, Loss: 1.5166
Batch 180, Loss: 1.5633
Batch 190, Loss: 1.5366
Batch 200, Loss: 1.5281
Batch 210, Loss: 1.5597
Batch 220, Loss: 1.5196
Batch 230, Loss: 1.5954
Batch 240, Loss: 1.5184
Batch 250, Loss: 1.5570
Batch 260, Loss: 1.5201
Batch 270, Loss: 1.5068
Batch 280, Loss: 1.5604
Batch 290, Loss: 1.4936
Batch 300, Loss: 1.5739
Batch 310, Loss: 1.4898
Batch 320, Loss: 1.5432
Batch 330, Loss: 1.5188
Batch 340, Loss: 1.5369
Batch 350, Loss: 1.5799
Batch 360, Loss: 1.5271
Batch 370, Loss: 1.5770
Batch 380, Loss: 1.5223
Batch 390, Loss: 1.5167
Epoch 28 learning rate: 0.09524135262330098
Epoch 28 time: 25.655017137527466 seconds
Epoch 28 accuracy: 54.17%
Batch 10, Loss: 1.4656
Batch 20, Loss: 1.5250
Batch 30, Loss: 1.5176
Batch 40, Loss: 1.4551
Batch 50, Loss: 1.4794
Batch 60, Loss: 1.4557
Batch 70, Loss: 1.4906
Batch 80, Loss: 1.5013
Batch 90, Loss: 1.5418
Batch 100, Loss: 1.4916
Batch 110, Loss: 1.4823
Batch 120, Loss: 1.5595
Batch 130, Loss: 1.5140
Batch 140, Loss: 1.5547
Batch 150, Loss: 1.5216
Batch 160, Loss: 1.5694
Batch 170, Loss: 1.5312
Batch 180, Loss: 1.5417
Batch 190, Loss: 1.6252
Batch 200, Loss: 1.5415
Batch 210, Loss: 1.4727
Batch 220, Loss: 1.5186
Batch 230, Loss: 1.5291
Batch 240, Loss: 1.4800
Batch 250, Loss: 1.5180
Batch 260, Loss: 1.5534
Batch 270, Loss: 1.4780
Batch 280, Loss: 1.5401
Batch 290, Loss: 1.5864
Batch 300, Loss: 1.5391
Batch 310, Loss: 1.4806
Batch 320, Loss: 1.5438
Batch 330, Loss: 1.5582
Batch 340, Loss: 1.5222
Batch 350, Loss: 1.5183
Batch 360, Loss: 1.5517
Batch 370, Loss: 1.5323
Batch 380, Loss: 1.5465
Batch 390, Loss: 1.4818
Epoch 29 learning rate: 0.09490137878803079
Epoch 29 time: 25.612504959106445 seconds
Epoch 29 accuracy: 51.05%
Batch 10, Loss: 1.4858
Batch 20, Loss: 1.4342
Batch 30, Loss: 1.5037
Batch 40, Loss: 1.4536
Batch 50, Loss: 1.5353
Batch 60, Loss: 1.5601
Batch 70, Loss: 1.5590
Batch 80, Loss: 1.4959
Batch 90, Loss: 1.5111
Batch 100, Loss: 1.5140
Batch 110, Loss: 1.4607
Batch 120, Loss: 1.5227
Batch 130, Loss: 1.5649
Batch 140, Loss: 1.5277
Batch 150, Loss: 1.6257
Batch 160, Loss: 1.5400
Batch 170, Loss: 1.4350
Batch 180, Loss: 1.4750
Batch 190, Loss: 1.4499
Batch 200, Loss: 1.5194
Batch 210, Loss: 1.4655
Batch 220, Loss: 1.5343
Batch 230, Loss: 1.5496
Batch 240, Loss: 1.5154
Batch 250, Loss: 1.6059
Batch 260, Loss: 1.5213
Batch 270, Loss: 1.4941
Batch 280, Loss: 1.5229
Batch 290, Loss: 1.4622
Batch 300, Loss: 1.5184
Batch 310, Loss: 1.6054
Batch 320, Loss: 1.5507
Batch 330, Loss: 1.4669
Batch 340, Loss: 1.5218
Batch 350, Loss: 1.5275
Batch 360, Loss: 1.4956
Batch 370, Loss: 1.5258
Batch 380, Loss: 1.5539
Batch 390, Loss: 1.5599
Epoch 30 learning rate: 0.0945503262094184
Epoch 30 time: 25.419629335403442 seconds
Epoch 30 accuracy: 52.41%
Batch 10, Loss: 1.4859
Batch 20, Loss: 1.4612
Batch 30, Loss: 1.3248
Batch 40, Loss: 1.5177
Batch 50, Loss: 1.4854
Batch 60, Loss: 1.4991
Batch 70, Loss: 1.5600
Batch 80, Loss: 1.5358
Batch 90, Loss: 1.4881
Batch 100, Loss: 1.4086
Batch 110, Loss: 1.4520
Batch 120, Loss: 1.4688
Batch 130, Loss: 1.5004
Batch 140, Loss: 1.5466
Batch 150, Loss: 1.5403
Batch 160, Loss: 1.5307
Batch 170, Loss: 1.5249
Batch 180, Loss: 1.5072
Batch 190, Loss: 1.5420
Batch 200, Loss: 1.5572
Batch 210, Loss: 1.5309
Batch 220, Loss: 1.5170
Batch 230, Loss: 1.5176
Batch 240, Loss: 1.5438
Batch 250, Loss: 1.4944
Batch 260, Loss: 1.5224
Batch 270, Loss: 1.4714
Batch 280, Loss: 1.5097
Batch 290, Loss: 1.4666
Batch 300, Loss: 1.4672
Batch 310, Loss: 1.5371
Batch 320, Loss: 1.5166
Batch 330, Loss: 1.5122
Batch 340, Loss: 1.5248
Batch 350, Loss: 1.5444
Batch 360, Loss: 1.5326
Batch 370, Loss: 1.5048
Batch 380, Loss: 1.5978
Batch 390, Loss: 1.4873
Epoch 31 learning rate: 0.0941882815044347
Epoch 31 time: 25.448723554611206 seconds
Epoch 31 accuracy: 57.34%
Batch 10, Loss: 1.4567
Batch 20, Loss: 1.5794
Batch 30, Loss: 1.4293
Batch 40, Loss: 1.5022
Batch 50, Loss: 1.4966
Batch 60, Loss: 1.4622
Batch 70, Loss: 1.4756
Batch 80, Loss: 1.4588
Batch 90, Loss: 1.4574
Batch 100, Loss: 1.4880
Batch 110, Loss: 1.4538
Batch 120, Loss: 1.4775
Batch 130, Loss: 1.4978
Batch 140, Loss: 1.4958
Batch 150, Loss: 1.5480
Batch 160, Loss: 1.4869
Batch 170, Loss: 1.5012
Batch 180, Loss: 1.4801
Batch 190, Loss: 1.5179
Batch 200, Loss: 1.5435
Batch 210, Loss: 1.4615
Batch 220, Loss: 1.4467
Batch 230, Loss: 1.4939
Batch 240, Loss: 1.6079
Batch 250, Loss: 1.4676
Batch 260, Loss: 1.5232
Batch 270, Loss: 1.4618
Batch 280, Loss: 1.5306
Batch 290, Loss: 1.5077
Batch 300, Loss: 1.5283
Batch 310, Loss: 1.4600
Batch 320, Loss: 1.5016
Batch 330, Loss: 1.4917
Batch 340, Loss: 1.5797
Batch 350, Loss: 1.5327
Batch 360, Loss: 1.4600
Batch 370, Loss: 1.5613
Batch 380, Loss: 1.5659
Batch 390, Loss: 1.4807
Epoch 32 learning rate: 0.09381533400219319
Epoch 32 time: 25.6511070728302 seconds
Epoch 32 accuracy: 56.45%
Batch 10, Loss: 1.4014
Batch 20, Loss: 1.4364
Batch 30, Loss: 1.4965
Batch 40, Loss: 1.4557
Batch 50, Loss: 1.4558
Batch 60, Loss: 1.4337
Batch 70, Loss: 1.4731
Batch 80, Loss: 1.5358
Batch 90, Loss: 1.5325
Batch 100, Loss: 1.5217
Batch 110, Loss: 1.4183
Batch 120, Loss: 1.4342
Batch 130, Loss: 1.4281
Batch 140, Loss: 1.4916
Batch 150, Loss: 1.5218
Batch 160, Loss: 1.4971
Batch 170, Loss: 1.5806
Batch 180, Loss: 1.4240
Batch 190, Loss: 1.5081
Batch 200, Loss: 1.4658
Batch 210, Loss: 1.4626
Batch 220, Loss: 1.4733
Batch 230, Loss: 1.5118
Batch 240, Loss: 1.4814
Batch 250, Loss: 1.4218
Batch 260, Loss: 1.5296
Batch 270, Loss: 1.5190
Batch 280, Loss: 1.4925
Batch 290, Loss: 1.4509
Batch 300, Loss: 1.5099
Batch 310, Loss: 1.5217
Batch 320, Loss: 1.4843
Batch 330, Loss: 1.5111
Batch 340, Loss: 1.5694
Batch 350, Loss: 1.4471
Batch 360, Loss: 1.5271
Batch 370, Loss: 1.5021
Batch 380, Loss: 1.5561
Batch 390, Loss: 1.5717
Epoch 33 learning rate: 0.09343157572190958
Epoch 33 time: 25.572540760040283 seconds
Epoch 33 accuracy: 57.04%
Batch 10, Loss: 1.5003
Batch 20, Loss: 1.3905
Batch 30, Loss: 1.4834
Batch 40, Loss: 1.4747
Batch 50, Loss: 1.4111
Batch 60, Loss: 1.5124
Batch 70, Loss: 1.4673
Batch 80, Loss: 1.4480
Batch 90, Loss: 1.4981
Batch 100, Loss: 1.4035
Batch 110, Loss: 1.5231
Batch 120, Loss: 1.5011
Batch 130, Loss: 1.4580
Batch 140, Loss: 1.4837
Batch 150, Loss: 1.4851
Batch 160, Loss: 1.4991
Batch 170, Loss: 1.4832
Batch 180, Loss: 1.4607
Batch 190, Loss: 1.4527
Batch 200, Loss: 1.4921
Batch 210, Loss: 1.5464
Batch 220, Loss: 1.4837
Batch 230, Loss: 1.5522
Batch 240, Loss: 1.5351
Batch 250, Loss: 1.4836
Batch 260, Loss: 1.4430
Batch 270, Loss: 1.5175
Batch 280, Loss: 1.4529
Batch 290, Loss: 1.4714
Batch 300, Loss: 1.4730
Batch 310, Loss: 1.5106
Batch 320, Loss: 1.5065
Batch 330, Loss: 1.4603
Batch 340, Loss: 1.5272
Batch 350, Loss: 1.4852
Batch 360, Loss: 1.5456
Batch 370, Loss: 1.5165
Batch 380, Loss: 1.4050
Batch 390, Loss: 1.5122
Epoch 34 learning rate: 0.0930371013501972
Epoch 34 time: 25.588165760040283 seconds
Epoch 34 accuracy: 55.03%
Batch 10, Loss: 1.4226
Batch 20, Loss: 1.3964
Batch 30, Loss: 1.5089
Batch 40, Loss: 1.5008
Batch 50, Loss: 1.5049
Batch 60, Loss: 1.4461
Batch 70, Loss: 1.5297
Batch 80, Loss: 1.5033
Batch 90, Loss: 1.4348
Batch 100, Loss: 1.4593
Batch 110, Loss: 1.4629
Batch 120, Loss: 1.4692
Batch 130, Loss: 1.4551
Batch 140, Loss: 1.4620
Batch 150, Loss: 1.4107
Batch 160, Loss: 1.5163
Batch 170, Loss: 1.5215
Batch 180, Loss: 1.4957
Batch 190, Loss: 1.5385
Batch 200, Loss: 1.4988
Batch 210, Loss: 1.5025
Batch 220, Loss: 1.4452
Batch 230, Loss: 1.4586
Batch 240, Loss: 1.4752
Batch 250, Loss: 1.4661
Batch 260, Loss: 1.5144
Batch 270, Loss: 1.4795
Batch 280, Loss: 1.4972
Batch 290, Loss: 1.5684
Batch 300, Loss: 1.5136
Batch 310, Loss: 1.5652
Batch 320, Loss: 1.4948
Batch 330, Loss: 1.5063
Batch 340, Loss: 1.4880
Batch 350, Loss: 1.5031
Batch 360, Loss: 1.4918
Batch 370, Loss: 1.4855
Batch 380, Loss: 1.5177
Batch 390, Loss: 1.5268
Epoch 35 learning rate: 0.09263200821770463
Epoch 35 time: 25.655113220214844 seconds
Epoch 35 accuracy: 57.97%
Batch 10, Loss: 1.4825
Batch 20, Loss: 1.4192
Batch 30, Loss: 1.4798
Batch 40, Loss: 1.4638
Batch 50, Loss: 1.4101
Batch 60, Loss: 1.4977
Batch 70, Loss: 1.4397
Batch 80, Loss: 1.4817
Batch 90, Loss: 1.4479
Batch 100, Loss: 1.5120
Batch 110, Loss: 1.4320
Batch 120, Loss: 1.5164
Batch 130, Loss: 1.4711
Batch 140, Loss: 1.4654
Batch 150, Loss: 1.4754
Batch 160, Loss: 1.3938
Batch 170, Loss: 1.5042
Batch 180, Loss: 1.4840
Batch 190, Loss: 1.4831
Batch 200, Loss: 1.4932
Batch 210, Loss: 1.5131
Batch 220, Loss: 1.5309
Batch 230, Loss: 1.4813
Batch 240, Loss: 1.4916
Batch 250, Loss: 1.4892
Batch 260, Loss: 1.5054
Batch 270, Loss: 1.4919
Batch 280, Loss: 1.5010
Batch 290, Loss: 1.4550
Batch 300, Loss: 1.4453
Batch 310, Loss: 1.4799
Batch 320, Loss: 1.4553
Batch 330, Loss: 1.5333
Batch 340, Loss: 1.4545
Batch 350, Loss: 1.5216
Batch 360, Loss: 1.4696
Batch 370, Loss: 1.4416
Batch 380, Loss: 1.5756
Batch 390, Loss: 1.4909
Epoch 36 learning rate: 0.09221639627510078
Epoch 36 time: 25.683170080184937 seconds
Epoch 36 accuracy: 58.53%
Batch 10, Loss: 1.3949
Batch 20, Loss: 1.3614
Batch 30, Loss: 1.4348
Batch 40, Loss: 1.4617
Batch 50, Loss: 1.3574
Batch 60, Loss: 1.3672
Batch 70, Loss: 1.4162
Batch 80, Loss: 1.5291
Batch 90, Loss: 1.4686
Batch 100, Loss: 1.4744
Batch 110, Loss: 1.4374
Batch 120, Loss: 1.4493
Batch 130, Loss: 1.4661
Batch 140, Loss: 1.4523
Batch 150, Loss: 1.4833
Batch 160, Loss: 1.4740
Batch 170, Loss: 1.4147
Batch 180, Loss: 1.4931
Batch 190, Loss: 1.4589
Batch 200, Loss: 1.5389
Batch 210, Loss: 1.5453
Batch 220, Loss: 1.5174
Batch 230, Loss: 1.4746
Batch 240, Loss: 1.5389
Batch 250, Loss: 1.5461
Batch 260, Loss: 1.4946
Batch 270, Loss: 1.4615
Batch 280, Loss: 1.4711
Batch 290, Loss: 1.4741
Batch 300, Loss: 1.4286
Batch 310, Loss: 1.4701
Batch 320, Loss: 1.4527
Batch 330, Loss: 1.4736
Batch 340, Loss: 1.4909
Batch 350, Loss: 1.4905
Batch 360, Loss: 1.5300
Batch 370, Loss: 1.5373
Batch 380, Loss: 1.5124
Batch 390, Loss: 1.4933
Epoch 37 learning rate: 0.09179036806841355
Epoch 37 time: 25.543365955352783 seconds
Epoch 37 accuracy: 56.4%
Batch 10, Loss: 1.4483
Batch 20, Loss: 1.4006
Batch 30, Loss: 1.4249
Batch 40, Loss: 1.5106
Batch 50, Loss: 1.3725
Batch 60, Loss: 1.4340
Batch 70, Loss: 1.4312
Batch 80, Loss: 1.4541
Batch 90, Loss: 1.4952
Batch 100, Loss: 1.4576
Batch 110, Loss: 1.4348
Batch 120, Loss: 1.4588
Batch 130, Loss: 1.4368
Batch 140, Loss: 1.4854
Batch 150, Loss: 1.4459
Batch 160, Loss: 1.4943
Batch 170, Loss: 1.3950
Batch 180, Loss: 1.5234
Batch 190, Loss: 1.5016
Batch 200, Loss: 1.4351
Batch 210, Loss: 1.4203
Batch 220, Loss: 1.4692
Batch 230, Loss: 1.4783
Batch 240, Loss: 1.4941
Batch 250, Loss: 1.3815
Batch 260, Loss: 1.4752
Batch 270, Loss: 1.4838
Batch 280, Loss: 1.4351
Batch 290, Loss: 1.4829
Batch 300, Loss: 1.5104
Batch 310, Loss: 1.5226
Batch 320, Loss: 1.4237
Batch 330, Loss: 1.4509
Batch 340, Loss: 1.4475
Batch 350, Loss: 1.4170
Batch 360, Loss: 1.4799
Batch 370, Loss: 1.5657
Batch 380, Loss: 1.4611
Batch 390, Loss: 1.4307
Epoch 38 learning rate: 0.09135402871372812
Epoch 38 time: 25.63710594177246 seconds
Epoch 38 accuracy: 56.49%
Batch 10, Loss: 1.4629
Batch 20, Loss: 1.3898
Batch 30, Loss: 1.4567
Batch 40, Loss: 1.4783
Batch 50, Loss: 1.4064
Batch 60, Loss: 1.3545
Batch 70, Loss: 1.4582
Batch 80, Loss: 1.4649
Batch 90, Loss: 1.3922
Batch 100, Loss: 1.3956
Batch 110, Loss: 1.4726
Batch 120, Loss: 1.4237
Batch 130, Loss: 1.4288
Batch 140, Loss: 1.4229
Batch 150, Loss: 1.4448
Batch 160, Loss: 1.4681
Batch 170, Loss: 1.4642
Batch 180, Loss: 1.4665
Batch 190, Loss: 1.4475
Batch 200, Loss: 1.3813
Batch 210, Loss: 1.4435
Batch 220, Loss: 1.5108
Batch 230, Loss: 1.4407
Batch 240, Loss: 1.4636
Batch 250, Loss: 1.4844
Batch 260, Loss: 1.4720
Batch 270, Loss: 1.4741
Batch 280, Loss: 1.3971
Batch 290, Loss: 1.5092
Batch 300, Loss: 1.5178
Batch 310, Loss: 1.4788
Batch 320, Loss: 1.5253
Batch 330, Loss: 1.4253
Batch 340, Loss: 1.5479
Batch 350, Loss: 1.4388
Batch 360, Loss: 1.4293
Batch 370, Loss: 1.4830
Batch 380, Loss: 1.4339
Batch 390, Loss: 1.5084
Epoch 39 learning rate: 0.0909074858712512
Epoch 39 time: 25.569995880126953 seconds
Epoch 39 accuracy: 55.77%
Batch 10, Loss: 1.4374
Batch 20, Loss: 1.4244
Batch 30, Loss: 1.4116
Batch 40, Loss: 1.4357
Batch 50, Loss: 1.4238
Batch 60, Loss: 1.3872
Batch 70, Loss: 1.4720
Batch 80, Loss: 1.4293
Batch 90, Loss: 1.4299
Batch 100, Loss: 1.4288
Batch 110, Loss: 1.3958
Batch 120, Loss: 1.4903
Batch 130, Loss: 1.3612
Batch 140, Loss: 1.4548
Batch 150, Loss: 1.4647
Batch 160, Loss: 1.4179
Batch 170, Loss: 1.4036
Batch 180, Loss: 1.4598
Batch 190, Loss: 1.4170
Batch 200, Loss: 1.5140
Batch 210, Loss: 1.4506
Batch 220, Loss: 1.4927
Batch 230, Loss: 1.4775
Batch 240, Loss: 1.4345
Batch 250, Loss: 1.4669
Batch 260, Loss: 1.4850
Batch 270, Loss: 1.4327
Batch 280, Loss: 1.4471
Batch 290, Loss: 1.4594
Batch 300, Loss: 1.4118
Batch 310, Loss: 1.5025
Batch 320, Loss: 1.4447
Batch 330, Loss: 1.5580
Batch 340, Loss: 1.4706
Batch 350, Loss: 1.4670
Batch 360, Loss: 1.4251
Batch 370, Loss: 1.4751
Batch 380, Loss: 1.4407
Batch 390, Loss: 1.4267
Epoch 40 learning rate: 0.09045084971874741
Epoch 40 time: 25.566195726394653 seconds
Epoch 40 accuracy: 53.92%
Batch 10, Loss: 1.4233
Batch 20, Loss: 1.3493
Batch 30, Loss: 1.4615
Batch 40, Loss: 1.3562
Batch 50, Loss: 1.3517
Batch 60, Loss: 1.4140
Batch 70, Loss: 1.4708
Batch 80, Loss: 1.4507
Batch 90, Loss: 1.4016
Batch 100, Loss: 1.4145
Batch 110, Loss: 1.4743
Batch 120, Loss: 1.3978
Batch 130, Loss: 1.3926
Batch 140, Loss: 1.4687
Batch 150, Loss: 1.3749
Batch 160, Loss: 1.4314
Batch 170, Loss: 1.4161
Batch 180, Loss: 1.4674
Batch 190, Loss: 1.4820
Batch 200, Loss: 1.4386
Batch 210, Loss: 1.3812
Batch 220, Loss: 1.3994
Batch 230, Loss: 1.4823
Batch 240, Loss: 1.3954
Batch 250, Loss: 1.3876
Batch 260, Loss: 1.4667
Batch 270, Loss: 1.4337
Batch 280, Loss: 1.4110
Batch 290, Loss: 1.4254
Batch 300, Loss: 1.4284
Batch 310, Loss: 1.4246
Batch 320, Loss: 1.5281
Batch 330, Loss: 1.5036
Batch 340, Loss: 1.4299
Batch 350, Loss: 1.4980
Batch 360, Loss: 1.4706
Batch 370, Loss: 1.4363
Batch 380, Loss: 1.4540
Batch 390, Loss: 1.4498
Epoch 41 learning rate: 0.08998423292435458
Epoch 41 time: 25.53154993057251 seconds
Epoch 41 accuracy: 57.76%
Batch 10, Loss: 1.4374
Batch 20, Loss: 1.3973
Batch 30, Loss: 1.3942
Batch 40, Loss: 1.4813
Batch 50, Loss: 1.4566
Batch 60, Loss: 1.5197
Batch 70, Loss: 1.4450
Batch 80, Loss: 1.4515
Batch 90, Loss: 1.4480
Batch 100, Loss: 1.3663
Batch 110, Loss: 1.4324
Batch 120, Loss: 1.4622
Batch 130, Loss: 1.4231
Batch 140, Loss: 1.5309
Batch 150, Loss: 1.4074
Batch 160, Loss: 1.4331
Batch 170, Loss: 1.4439
Batch 180, Loss: 1.4146
Batch 190, Loss: 1.4724
Batch 200, Loss: 1.4276
Batch 210, Loss: 1.4209
Batch 220, Loss: 1.4640
Batch 230, Loss: 1.4371
Batch 240, Loss: 1.4397
Batch 250, Loss: 1.4266
Batch 260, Loss: 1.4514
Batch 270, Loss: 1.4864
Batch 280, Loss: 1.3986
Batch 290, Loss: 1.4705
Batch 300, Loss: 1.3365
Batch 310, Loss: 1.5227
Batch 320, Loss: 1.5375
Batch 330, Loss: 1.4161
Batch 340, Loss: 1.4706
Batch 350, Loss: 1.4129
Batch 360, Loss: 1.4526
Batch 370, Loss: 1.4968
Batch 380, Loss: 1.4725
Batch 390, Loss: 1.4271
Epoch 42 learning rate: 0.08950775061878455
Epoch 42 time: 25.49638605117798 seconds
Epoch 42 accuracy: 57.69%
Batch 10, Loss: 1.3673
Batch 20, Loss: 1.4949
Batch 30, Loss: 1.4254
Batch 40, Loss: 1.3535
Batch 50, Loss: 1.3844
Batch 60, Loss: 1.4224
Batch 70, Loss: 1.4005
Batch 80, Loss: 1.4062
Batch 90, Loss: 1.4446
Batch 100, Loss: 1.4039
Batch 110, Loss: 1.4608
Batch 120, Loss: 1.4475
Batch 130, Loss: 1.3838
Batch 140, Loss: 1.4523
Batch 150, Loss: 1.4297
Batch 160, Loss: 1.4474
Batch 170, Loss: 1.4424
Batch 180, Loss: 1.4425
Batch 190, Loss: 1.4563
Batch 200, Loss: 1.3862
Batch 210, Loss: 1.4182
Batch 220, Loss: 1.4695
Batch 230, Loss: 1.4124
Batch 240, Loss: 1.4385
Batch 250, Loss: 1.4633
Batch 260, Loss: 1.4653
Batch 270, Loss: 1.4772
Batch 280, Loss: 1.4038
Batch 290, Loss: 1.4500
Batch 300, Loss: 1.4195
Batch 310, Loss: 1.4651
Batch 320, Loss: 1.4865
Batch 330, Loss: 1.4929
Batch 340, Loss: 1.4122
Batch 350, Loss: 1.4193
Batch 360, Loss: 1.4624
Batch 370, Loss: 1.4470
Batch 380, Loss: 1.4837
Batch 390, Loss: 1.5045
Epoch 43 learning rate: 0.08902152036691653
Epoch 43 time: 25.637864351272583 seconds
Epoch 43 accuracy: 56.27%
Batch 10, Loss: 1.4269
Batch 20, Loss: 1.3532
Batch 30, Loss: 1.3817
Batch 40, Loss: 1.3622
Batch 50, Loss: 1.3423
Batch 60, Loss: 1.3879
Batch 70, Loss: 1.3954
Batch 80, Loss: 1.3779
Batch 90, Loss: 1.3975
Batch 100, Loss: 1.3800
Batch 110, Loss: 1.4373
Batch 120, Loss: 1.4202
Batch 130, Loss: 1.3850
Batch 140, Loss: 1.3831
Batch 150, Loss: 1.4267
Batch 160, Loss: 1.4183
Batch 170, Loss: 1.5506
Batch 180, Loss: 1.4287
Batch 190, Loss: 1.4846
Batch 200, Loss: 1.4312
Batch 210, Loss: 1.4512
Batch 220, Loss: 1.4188
Batch 230, Loss: 1.4209
Batch 240, Loss: 1.4327
Batch 250, Loss: 1.4075
Batch 260, Loss: 1.4571
Batch 270, Loss: 1.4477
Batch 280, Loss: 1.4923
Batch 290, Loss: 1.3892
Batch 300, Loss: 1.4730
Batch 310, Loss: 1.4523
Batch 320, Loss: 1.4166
Batch 330, Loss: 1.4558
Batch 340, Loss: 1.3916
Batch 350, Loss: 1.4531
Batch 360, Loss: 1.4816
Batch 370, Loss: 1.4248
Batch 380, Loss: 1.4636
Batch 390, Loss: 1.4671
Epoch 44 learning rate: 0.08852566213878951
Epoch 44 time: 25.513768672943115 seconds
Epoch 44 accuracy: 53.39%
Batch 10, Loss: 1.4224
Batch 20, Loss: 1.4078
Batch 30, Loss: 1.3380
Batch 40, Loss: 1.3407
Batch 50, Loss: 1.3881
Batch 60, Loss: 1.4153
Batch 70, Loss: 1.3907
Batch 80, Loss: 1.4492
Batch 90, Loss: 1.4288
Batch 100, Loss: 1.3564
Batch 110, Loss: 1.3583
Batch 120, Loss: 1.4157
Batch 130, Loss: 1.4469
Batch 140, Loss: 1.4517
Batch 150, Loss: 1.4023
Batch 160, Loss: 1.4300
Batch 170, Loss: 1.5054
Batch 180, Loss: 1.4441
Batch 190, Loss: 1.4339
Batch 200, Loss: 1.4429
Batch 210, Loss: 1.3869
Batch 220, Loss: 1.4315
Batch 230, Loss: 1.4197
Batch 240, Loss: 1.3891
Batch 250, Loss: 1.4551
Batch 260, Loss: 1.4807
Batch 270, Loss: 1.4821
Batch 280, Loss: 1.5192
Batch 290, Loss: 1.4358
Batch 300, Loss: 1.4356
Batch 310, Loss: 1.4256
Batch 320, Loss: 1.3832
Batch 330, Loss: 1.4893
Batch 340, Loss: 1.4302
Batch 350, Loss: 1.4297
Batch 360, Loss: 1.4312
Batch 370, Loss: 1.4586
Batch 380, Loss: 1.4627
Batch 390, Loss: 1.4084
Epoch 45 learning rate: 0.0880202982800016
Epoch 45 time: 25.547802209854126 seconds
Epoch 45 accuracy: 56.72%
Batch 10, Loss: 1.3788
Batch 20, Loss: 1.3460
Batch 30, Loss: 1.4133
Batch 40, Loss: 1.3968
Batch 50, Loss: 1.3608
Batch 60, Loss: 1.3956
Batch 70, Loss: 1.4304
Batch 80, Loss: 1.4151
Batch 90, Loss: 1.4725
Batch 100, Loss: 1.4027
Batch 110, Loss: 1.3503
Batch 120, Loss: 1.4280
Batch 130, Loss: 1.4282
Batch 140, Loss: 1.4535
Batch 150, Loss: 1.4118
Batch 160, Loss: 1.3464
Batch 170, Loss: 1.4461
Batch 180, Loss: 1.4086
Batch 190, Loss: 1.5146
Batch 200, Loss: 1.4251
Batch 210, Loss: 1.4513
Batch 220, Loss: 1.3970
Batch 230, Loss: 1.3715
Batch 240, Loss: 1.4367
Batch 250, Loss: 1.3867
Batch 260, Loss: 1.4304
Batch 270, Loss: 1.4588
Batch 280, Loss: 1.4234
Batch 290, Loss: 1.4871
Batch 300, Loss: 1.4033
Batch 310, Loss: 1.4083
Batch 320, Loss: 1.4103
Batch 330, Loss: 1.4164
Batch 340, Loss: 1.3594
Batch 350, Loss: 1.4870
Batch 360, Loss: 1.4250
Batch 370, Loss: 1.4852
Batch 380, Loss: 1.4266
Batch 390, Loss: 1.4602
Epoch 46 learning rate: 0.08750555348152303
Epoch 46 time: 25.466118574142456 seconds
Epoch 46 accuracy: 55.36%
Batch 10, Loss: 1.3603
Batch 20, Loss: 1.4305
Batch 30, Loss: 1.3555
Batch 40, Loss: 1.4123
Batch 50, Loss: 1.3810
Batch 60, Loss: 1.4067
Batch 70, Loss: 1.3594
Batch 80, Loss: 1.3329
Batch 90, Loss: 1.3317
Batch 100, Loss: 1.3591
Batch 110, Loss: 1.4313
Batch 120, Loss: 1.4074
Batch 130, Loss: 1.3513
Batch 140, Loss: 1.3560
Batch 150, Loss: 1.4113
Batch 160, Loss: 1.3820
Batch 170, Loss: 1.4792
Batch 180, Loss: 1.3378
Batch 190, Loss: 1.3812
Batch 200, Loss: 1.4549
Batch 210, Loss: 1.4177
Batch 220, Loss: 1.4654
Batch 230, Loss: 1.4139
Batch 240, Loss: 1.4346
Batch 250, Loss: 1.4103
Batch 260, Loss: 1.3907
Batch 270, Loss: 1.4441
Batch 280, Loss: 1.4992
Batch 290, Loss: 1.4392
Batch 300, Loss: 1.3801
Batch 310, Loss: 1.4317
Batch 320, Loss: 1.4061
Batch 330, Loss: 1.4232
Batch 340, Loss: 1.4442
Batch 350, Loss: 1.4481
Batch 360, Loss: 1.4873
Batch 370, Loss: 1.4857
Batch 380, Loss: 1.4091
Batch 390, Loss: 1.4060
Epoch 47 learning rate: 0.08698155474893052
Epoch 47 time: 25.60537338256836 seconds
Epoch 47 accuracy: 58.92%
Batch 10, Loss: 1.3420
Batch 20, Loss: 1.3404
Batch 30, Loss: 1.3424
Batch 40, Loss: 1.3212
Batch 50, Loss: 1.2600
Batch 60, Loss: 1.4689
Batch 70, Loss: 1.4497
Batch 80, Loss: 1.4499
Batch 90, Loss: 1.3644
Batch 100, Loss: 1.3653
Batch 110, Loss: 1.4002
Batch 120, Loss: 1.3676
Batch 130, Loss: 1.4089
Batch 140, Loss: 1.3930
Batch 150, Loss: 1.4034
Batch 160, Loss: 1.4362
Batch 170, Loss: 1.4059
Batch 180, Loss: 1.3520
Batch 190, Loss: 1.3981
Batch 200, Loss: 1.3687
Batch 210, Loss: 1.4184
Batch 220, Loss: 1.4451
Batch 230, Loss: 1.4243
Batch 240, Loss: 1.3976
Batch 250, Loss: 1.4510
Batch 260, Loss: 1.3626
Batch 270, Loss: 1.4010
Batch 280, Loss: 1.4739
Batch 290, Loss: 1.4125
Batch 300, Loss: 1.4720
Batch 310, Loss: 1.4919
Batch 320, Loss: 1.4538
Batch 330, Loss: 1.4413
Batch 340, Loss: 1.4619
Batch 350, Loss: 1.4381
Batch 360, Loss: 1.4899
Batch 370, Loss: 1.4429
Batch 380, Loss: 1.4395
Batch 390, Loss: 1.4383
Epoch 48 learning rate: 0.08644843137107061
Epoch 48 time: 25.55688214302063 seconds
Epoch 48 accuracy: 57.83%
Batch 10, Loss: 1.3572
Batch 20, Loss: 1.3784
Batch 30, Loss: 1.3153
Batch 40, Loss: 1.3457
Batch 50, Loss: 1.3134
Batch 60, Loss: 1.3702
Batch 70, Loss: 1.3861
Batch 80, Loss: 1.3971
Batch 90, Loss: 1.3961
Batch 100, Loss: 1.3641
Batch 110, Loss: 1.3922
Batch 120, Loss: 1.4128
Batch 130, Loss: 1.4303
Batch 140, Loss: 1.3898
Batch 150, Loss: 1.4292
Batch 160, Loss: 1.4340
Batch 170, Loss: 1.4069
Batch 180, Loss: 1.4154
Batch 190, Loss: 1.4107
Batch 200, Loss: 1.5183
Batch 210, Loss: 1.4670
Batch 220, Loss: 1.4767
Batch 230, Loss: 1.4869
Batch 240, Loss: 1.4256
Batch 250, Loss: 1.3870
Batch 260, Loss: 1.3898
Batch 270, Loss: 1.4369
Batch 280, Loss: 1.4009
Batch 290, Loss: 1.3995
Batch 300, Loss: 1.3698
Batch 310, Loss: 1.3752
Batch 320, Loss: 1.4136
Batch 330, Loss: 1.3957
Batch 340, Loss: 1.4303
Batch 350, Loss: 1.4544
Batch 360, Loss: 1.4671
Batch 370, Loss: 1.3978
Batch 380, Loss: 1.4579
Batch 390, Loss: 1.4389
Epoch 49 learning rate: 0.08590631488815947
Epoch 49 time: 25.60311269760132 seconds
Epoch 49 accuracy: 59.09%
Batch 10, Loss: 1.3288
Batch 20, Loss: 1.3773
Batch 30, Loss: 1.3651
Batch 40, Loss: 1.3643
Batch 50, Loss: 1.3929
Batch 60, Loss: 1.4208
Batch 70, Loss: 1.3918
Batch 80, Loss: 1.3709
Batch 90, Loss: 1.2951
Batch 100, Loss: 1.3836
Batch 110, Loss: 1.4556
Batch 120, Loss: 1.3586
Batch 130, Loss: 1.3797
Batch 140, Loss: 1.4385
Batch 150, Loss: 1.3863
Batch 160, Loss: 1.4486
Batch 170, Loss: 1.4211
Batch 180, Loss: 1.3505
Batch 190, Loss: 1.3888
Batch 200, Loss: 1.3464
Batch 210, Loss: 1.3856
Batch 220, Loss: 1.4272
Batch 230, Loss: 1.3234
Batch 240, Loss: 1.4360
Batch 250, Loss: 1.4428
Batch 260, Loss: 1.4054
Batch 270, Loss: 1.3867
Batch 280, Loss: 1.4325
Batch 290, Loss: 1.4346
Batch 300, Loss: 1.4097
Batch 310, Loss: 1.4465
Batch 320, Loss: 1.4704
Batch 330, Loss: 1.3874
Batch 340, Loss: 1.4661
Batch 350, Loss: 1.3783
Batch 360, Loss: 1.3404
Batch 370, Loss: 1.4463
Batch 380, Loss: 1.4107
Batch 390, Loss: 1.4273
Epoch 50 learning rate: 0.0853553390593274
Epoch 50 time: 25.604963541030884 seconds
Epoch 50 accuracy: 56.23%
Batch 10, Loss: 1.3992
Batch 20, Loss: 1.3921
Batch 30, Loss: 1.3402
Batch 40, Loss: 1.3658
Batch 50, Loss: 1.3123
Batch 60, Loss: 1.3291
Batch 70, Loss: 1.4196
Batch 80, Loss: 1.4046
Batch 90, Loss: 1.3664
Batch 100, Loss: 1.4546
Batch 110, Loss: 1.3928
Batch 120, Loss: 1.4364
Batch 130, Loss: 1.4441
Batch 140, Loss: 1.3963
Batch 150, Loss: 1.3966
Batch 160, Loss: 1.3617
Batch 170, Loss: 1.3281
Batch 180, Loss: 1.3437
Batch 190, Loss: 1.3759
Batch 200, Loss: 1.3939
Batch 210, Loss: 1.4206
Batch 220, Loss: 1.4030
Batch 230, Loss: 1.3870
Batch 240, Loss: 1.3589
Batch 250, Loss: 1.4462
Batch 260, Loss: 1.4176
Batch 270, Loss: 1.4031
Batch 280, Loss: 1.4439
Batch 290, Loss: 1.4082
Batch 300, Loss: 1.4190
Batch 310, Loss: 1.4313
Batch 320, Loss: 1.3070
Batch 330, Loss: 1.3620
Batch 340, Loss: 1.4292
Batch 350, Loss: 1.4034
Batch 360, Loss: 1.4097
Batch 370, Loss: 1.4562
Batch 380, Loss: 1.4278
Batch 390, Loss: 1.4338
Epoch 51 learning rate: 0.08479563982961574
Epoch 51 time: 25.713398456573486 seconds
Epoch 51 accuracy: 59.48%
Batch 10, Loss: 1.3374
Batch 20, Loss: 1.4013
Batch 30, Loss: 1.2931
Batch 40, Loss: 1.3395
Batch 50, Loss: 1.3588
Batch 60, Loss: 1.3563
Batch 70, Loss: 1.3927
Batch 80, Loss: 1.3211
Batch 90, Loss: 1.3658
Batch 100, Loss: 1.4042
Batch 110, Loss: 1.4024
Batch 120, Loss: 1.3124
Batch 130, Loss: 1.3934
Batch 140, Loss: 1.3827
Batch 150, Loss: 1.3590
Batch 160, Loss: 1.3321
Batch 170, Loss: 1.3777
Batch 180, Loss: 1.3586
Batch 190, Loss: 1.3327
Batch 200, Loss: 1.3751
Batch 210, Loss: 1.4089
Batch 220, Loss: 1.3694
Batch 230, Loss: 1.3604
Batch 240, Loss: 1.3787
Batch 250, Loss: 1.3553
Batch 260, Loss: 1.3661
Batch 270, Loss: 1.4246
Batch 280, Loss: 1.3755
Batch 290, Loss: 1.4247
Batch 300, Loss: 1.4096
Batch 310, Loss: 1.3862
Batch 320, Loss: 1.3884
Batch 330, Loss: 1.4031
Batch 340, Loss: 1.4482
Batch 350, Loss: 1.4653
Batch 360, Loss: 1.4556
Batch 370, Loss: 1.3793
Batch 380, Loss: 1.4332
Batch 390, Loss: 1.5202
Epoch 52 learning rate: 0.08422735529643446
Epoch 52 time: 25.583271741867065 seconds
Epoch 52 accuracy: 56.94%
Batch 10, Loss: 1.3551
Batch 20, Loss: 1.3779
Batch 30, Loss: 1.3528
Batch 40, Loss: 1.3781
Batch 50, Loss: 1.3783
Batch 60, Loss: 1.3428
Batch 70, Loss: 1.3437
Batch 80, Loss: 1.4471
Batch 90, Loss: 1.3791
Batch 100, Loss: 1.3830
Batch 110, Loss: 1.3507
Batch 120, Loss: 1.3325
Batch 130, Loss: 1.4015
Batch 140, Loss: 1.4127
Batch 150, Loss: 1.3543
Batch 160, Loss: 1.4035
Batch 170, Loss: 1.3623
Batch 180, Loss: 1.3655
Batch 190, Loss: 1.3937
Batch 200, Loss: 1.3313
Batch 210, Loss: 1.3844
Batch 220, Loss: 1.4443
Batch 230, Loss: 1.3916
Batch 240, Loss: 1.3909
Batch 250, Loss: 1.3035
Batch 260, Loss: 1.3646
Batch 270, Loss: 1.4059
Batch 280, Loss: 1.4213
Batch 290, Loss: 1.4289
Batch 300, Loss: 1.4128
Batch 310, Loss: 1.3228
Batch 320, Loss: 1.3599
Batch 330, Loss: 1.4901
Batch 340, Loss: 1.3405
Batch 350, Loss: 1.4746
Batch 360, Loss: 1.3958
Batch 370, Loss: 1.4096
Batch 380, Loss: 1.4069
Batch 390, Loss: 1.4076
Epoch 53 learning rate: 0.08365062567548869
Epoch 53 time: 25.603229999542236 seconds
Epoch 53 accuracy: 55.44%
Batch 10, Loss: 1.3196
Batch 20, Loss: 1.3210
Batch 30, Loss: 1.3077
Batch 40, Loss: 1.3587
Batch 50, Loss: 1.3845
Batch 60, Loss: 1.4152
Batch 70, Loss: 1.3543
Batch 80, Loss: 1.3511
Batch 90, Loss: 1.3998
Batch 100, Loss: 1.3800
Batch 110, Loss: 1.3821
Batch 120, Loss: 1.2943
Batch 130, Loss: 1.3367
Batch 140, Loss: 1.4746
Batch 150, Loss: 1.3949
Batch 160, Loss: 1.3737
Batch 170, Loss: 1.3403
Batch 180, Loss: 1.3138
Batch 190, Loss: 1.3157
Batch 200, Loss: 1.3706
Batch 210, Loss: 1.3646
Batch 220, Loss: 1.4111
Batch 230, Loss: 1.3373
Batch 240, Loss: 1.3993
Batch 250, Loss: 1.3558
Batch 260, Loss: 1.3212
Batch 270, Loss: 1.3716
Batch 280, Loss: 1.3474
Batch 290, Loss: 1.4224
Batch 300, Loss: 1.3326
Batch 310, Loss: 1.3470
Batch 320, Loss: 1.4147
Batch 330, Loss: 1.4695
Batch 340, Loss: 1.4164
Batch 350, Loss: 1.4469
Batch 360, Loss: 1.4106
Batch 370, Loss: 1.3812
Batch 380, Loss: 1.4150
Batch 390, Loss: 1.4712
Epoch 54 learning rate: 0.08306559326618261
Epoch 54 time: 25.523558139801025 seconds
Epoch 54 accuracy: 59.58%
Batch 10, Loss: 1.3386
Batch 20, Loss: 1.3325
Batch 30, Loss: 1.2953
Batch 40, Loss: 1.2553
Batch 50, Loss: 1.2564
Batch 60, Loss: 1.2814
Batch 70, Loss: 1.3188
Batch 80, Loss: 1.3259
Batch 90, Loss: 1.4279
Batch 100, Loss: 1.3820
Batch 110, Loss: 1.3300
Batch 120, Loss: 1.3746
Batch 130, Loss: 1.3568
Batch 140, Loss: 1.4452
Batch 150, Loss: 1.3889
Batch 160, Loss: 1.3845
Batch 170, Loss: 1.3632
Batch 180, Loss: 1.3839
Batch 190, Loss: 1.4047
Batch 200, Loss: 1.3935
Batch 210, Loss: 1.3545
Batch 220, Loss: 1.4127
Batch 230, Loss: 1.3482
Batch 240, Loss: 1.3730
Batch 250, Loss: 1.4144
Batch 260, Loss: 1.4075
Batch 270, Loss: 1.4407
Batch 280, Loss: 1.3094
Batch 290, Loss: 1.4165
Batch 300, Loss: 1.3633
Batch 310, Loss: 1.4209
Batch 320, Loss: 1.4005
Batch 330, Loss: 1.3838
Batch 340, Loss: 1.3493
Batch 350, Loss: 1.4045
Batch 360, Loss: 1.4369
Batch 370, Loss: 1.3767
Batch 380, Loss: 1.4692
Batch 390, Loss: 1.3835
Epoch 55 learning rate: 0.0824724024165092
Epoch 55 time: 25.563173532485962 seconds
Epoch 55 accuracy: 60.16%
Batch 10, Loss: 1.3331
Batch 20, Loss: 1.3899
Batch 30, Loss: 1.3376
Batch 40, Loss: 1.3375
Batch 50, Loss: 1.3216
Batch 60, Loss: 1.3340
Batch 70, Loss: 1.2924
Batch 80, Loss: 1.3520
Batch 90, Loss: 1.4057
Batch 100, Loss: 1.3587
Batch 110, Loss: 1.3959
Batch 120, Loss: 1.3443
Batch 130, Loss: 1.3251
Batch 140, Loss: 1.3799
Batch 150, Loss: 1.3733
Batch 160, Loss: 1.4212
Batch 170, Loss: 1.4283
Batch 180, Loss: 1.3390
Batch 190, Loss: 1.3567
Batch 200, Loss: 1.3592
Batch 210, Loss: 1.3008
Batch 220, Loss: 1.3603
Batch 230, Loss: 1.3777
Batch 240, Loss: 1.3914
Batch 250, Loss: 1.4123
Batch 260, Loss: 1.4182
Batch 270, Loss: 1.4325
Batch 280, Loss: 1.3105
Batch 290, Loss: 1.3779
Batch 300, Loss: 1.3813
Batch 310, Loss: 1.4043
Batch 320, Loss: 1.3523
Batch 330, Loss: 1.4138
Batch 340, Loss: 1.3640
Batch 350, Loss: 1.4401
Batch 360, Loss: 1.3483
Batch 370, Loss: 1.4656
Batch 380, Loss: 1.4483
Batch 390, Loss: 1.4096
Epoch 56 learning rate: 0.0818711994874345
Epoch 56 time: 25.63508129119873 seconds
Epoch 56 accuracy: 57.52%
Batch 10, Loss: 1.3329
Batch 20, Loss: 1.3203
Batch 30, Loss: 1.3365
Batch 40, Loss: 1.2836
Batch 50, Loss: 1.2810
Batch 60, Loss: 1.3986
Batch 70, Loss: 1.3977
Batch 80, Loss: 1.3525
Batch 90, Loss: 1.3572
Batch 100, Loss: 1.4421
Batch 110, Loss: 1.3349
Batch 120, Loss: 1.3110
Batch 130, Loss: 1.3034
Batch 140, Loss: 1.3692
Batch 150, Loss: 1.3974
Batch 160, Loss: 1.3608
Batch 170, Loss: 1.3703
Batch 180, Loss: 1.3484
Batch 190, Loss: 1.3700
Batch 200, Loss: 1.3800
Batch 210, Loss: 1.3208
Batch 220, Loss: 1.3783
Batch 230, Loss: 1.3482
Batch 240, Loss: 1.3222
Batch 250, Loss: 1.3924
Batch 260, Loss: 1.3382
Batch 270, Loss: 1.4306
Batch 280, Loss: 1.4241
Batch 290, Loss: 1.3890
Batch 300, Loss: 1.3578
Batch 310, Loss: 1.4540
Batch 320, Loss: 1.3968
Batch 330, Loss: 1.3328
Batch 340, Loss: 1.4255
Batch 350, Loss: 1.3692
Batch 360, Loss: 1.4365
Batch 370, Loss: 1.4086
Batch 380, Loss: 1.4029
Batch 390, Loss: 1.3455
Epoch 57 learning rate: 0.08126213281678528
Epoch 57 time: 25.586495637893677 seconds
Epoch 57 accuracy: 60.22%
Batch 10, Loss: 1.3262
Batch 20, Loss: 1.3066
Batch 30, Loss: 1.3351
Batch 40, Loss: 1.2625
Batch 50, Loss: 1.3004
Batch 60, Loss: 1.3366
Batch 70, Loss: 1.2687
Batch 80, Loss: 1.3889
Batch 90, Loss: 1.3362
Batch 100, Loss: 1.3120
Batch 110, Loss: 1.3165
Batch 120, Loss: 1.3298
Batch 130, Loss: 1.3131
Batch 140, Loss: 1.3408
Batch 150, Loss: 1.3495
Batch 160, Loss: 1.2564
Batch 170, Loss: 1.4119
Batch 180, Loss: 1.3477
Batch 190, Loss: 1.3175
Batch 200, Loss: 1.4443
Batch 210, Loss: 1.3647
Batch 220, Loss: 1.3384
Batch 230, Loss: 1.4124
Batch 240, Loss: 1.3134
Batch 250, Loss: 1.3938
Batch 260, Loss: 1.3274
Batch 270, Loss: 1.3306
Batch 280, Loss: 1.3135
Batch 290, Loss: 1.4060
Batch 300, Loss: 1.3961
Batch 310, Loss: 1.3939
Batch 320, Loss: 1.3221
Batch 330, Loss: 1.3685
Batch 340, Loss: 1.3311
Batch 350, Loss: 1.3561
Batch 360, Loss: 1.3830
Batch 370, Loss: 1.4248
Batch 380, Loss: 1.3620
Batch 390, Loss: 1.3616
Epoch 58 learning rate: 0.08064535268264884
Epoch 58 time: 25.53404188156128 seconds
Epoch 58 accuracy: 54.08%
Batch 10, Loss: 1.2540
Batch 20, Loss: 1.3136
Batch 30, Loss: 1.2912
Batch 40, Loss: 1.3148
Batch 50, Loss: 1.3390
Batch 60, Loss: 1.3541
Batch 70, Loss: 1.3235
Batch 80, Loss: 1.3634
Batch 90, Loss: 1.3407
Batch 100, Loss: 1.3503
Batch 110, Loss: 1.2915
Batch 120, Loss: 1.3060
Batch 130, Loss: 1.3209
Batch 140, Loss: 1.3294
Batch 150, Loss: 1.3725
Batch 160, Loss: 1.3270
Batch 170, Loss: 1.3263
Batch 180, Loss: 1.3703
Batch 190, Loss: 1.3149
Batch 200, Loss: 1.3618
Batch 210, Loss: 1.3683
Batch 220, Loss: 1.3302
Batch 230, Loss: 1.3918
Batch 240, Loss: 1.3205
Batch 250, Loss: 1.3276
Batch 260, Loss: 1.4080
Batch 270, Loss: 1.3678
Batch 280, Loss: 1.3717
Batch 290, Loss: 1.3934
Batch 300, Loss: 1.3936
Batch 310, Loss: 1.4217
Batch 320, Loss: 1.4076
Batch 330, Loss: 1.4425
Batch 340, Loss: 1.3655
Batch 350, Loss: 1.4089
Batch 360, Loss: 1.3781
Batch 370, Loss: 1.4286
Batch 380, Loss: 1.3238
Batch 390, Loss: 1.3639
Epoch 59 learning rate: 0.08002101126629421
Epoch 59 time: 25.40693163871765 seconds
Epoch 59 accuracy: 61.55%
Batch 10, Loss: 1.3167
Batch 20, Loss: 1.3715
Batch 30, Loss: 1.2657
Batch 40, Loss: 1.3211
Batch 50, Loss: 1.3782
Batch 60, Loss: 1.3358
Batch 70, Loss: 1.3633
Batch 80, Loss: 1.3536
Batch 90, Loss: 1.2862
Batch 100, Loss: 1.3049
Batch 110, Loss: 1.3664
Batch 120, Loss: 1.2630
Batch 130, Loss: 1.3117
Batch 140, Loss: 1.3580
Batch 150, Loss: 1.3926
Batch 160, Loss: 1.3265
Batch 170, Loss: 1.3672
Batch 180, Loss: 1.4063
Batch 190, Loss: 1.3770
Batch 200, Loss: 1.3361
Batch 210, Loss: 1.3533
Batch 220, Loss: 1.3379
Batch 230, Loss: 1.3245
Batch 240, Loss: 1.3559
Batch 250, Loss: 1.3575
Batch 260, Loss: 1.3173
Batch 270, Loss: 1.3458
Batch 280, Loss: 1.3524
Batch 290, Loss: 1.3442
Batch 300, Loss: 1.3630
Batch 310, Loss: 1.4150
Batch 320, Loss: 1.4119
Batch 330, Loss: 1.3608
Batch 340, Loss: 1.3765
Batch 350, Loss: 1.3275
Batch 360, Loss: 1.4241
Batch 370, Loss: 1.3481
Batch 380, Loss: 1.3777
Batch 390, Loss: 1.3904
Epoch 60 learning rate: 0.07938926261462367
Epoch 60 time: 25.498417615890503 seconds
Epoch 60 accuracy: 60.6%
Batch 10, Loss: 1.3237
Batch 20, Loss: 1.2046
Batch 30, Loss: 1.3091
Batch 40, Loss: 1.3636
Batch 50, Loss: 1.2988
Batch 60, Loss: 1.2895
Batch 70, Loss: 1.2957
Batch 80, Loss: 1.3392
Batch 90, Loss: 1.3123
Batch 100, Loss: 1.3844
Batch 110, Loss: 1.3673
Batch 120, Loss: 1.3157
Batch 130, Loss: 1.3390
Batch 140, Loss: 1.2932
Batch 150, Loss: 1.3663
Batch 160, Loss: 1.3373
Batch 170, Loss: 1.3665
Batch 180, Loss: 1.3253
Batch 190, Loss: 1.3940
Batch 200, Loss: 1.2788
Batch 210, Loss: 1.3451
Batch 220, Loss: 1.3226
Batch 230, Loss: 1.3469
Batch 240, Loss: 1.3096
Batch 250, Loss: 1.3244
Batch 260, Loss: 1.3440
Batch 270, Loss: 1.3945
Batch 280, Loss: 1.3488
Batch 290, Loss: 1.3311
Batch 300, Loss: 1.3653
Batch 310, Loss: 1.4374
Batch 320, Loss: 1.4091
Batch 330, Loss: 1.3991
Batch 340, Loss: 1.3510
Batch 350, Loss: 1.2604
Batch 360, Loss: 1.3446
Batch 370, Loss: 1.3943
Batch 380, Loss: 1.3659
Batch 390, Loss: 1.3951
Epoch 61 learning rate: 0.07875026260216395
Epoch 61 time: 25.402007341384888 seconds
Epoch 61 accuracy: 58.33%
Batch 10, Loss: 1.3771
Batch 20, Loss: 1.3143
Batch 30, Loss: 1.2152
Batch 40, Loss: 1.2908
Batch 50, Loss: 1.2839
Batch 60, Loss: 1.3256
Batch 70, Loss: 1.3074
Batch 80, Loss: 1.3464
Batch 90, Loss: 1.3645
Batch 100, Loss: 1.3518
Batch 110, Loss: 1.3021
Batch 120, Loss: 1.3660
Batch 130, Loss: 1.4333
Batch 140, Loss: 1.3592
Batch 150, Loss: 1.3756
Batch 160, Loss: 1.3204
Batch 170, Loss: 1.3436
Batch 180, Loss: 1.3389
Batch 190, Loss: 1.2540
Batch 200, Loss: 1.2994
Batch 210, Loss: 1.2875
Batch 220, Loss: 1.2787
Batch 230, Loss: 1.4024
Batch 240, Loss: 1.3500
Batch 250, Loss: 1.3517
Batch 260, Loss: 1.3594
Batch 270, Loss: 1.3674
Batch 280, Loss: 1.3383
Batch 290, Loss: 1.3556
Batch 300, Loss: 1.3973
Batch 310, Loss: 1.3531
Batch 320, Loss: 1.3865
Batch 330, Loss: 1.3363
Batch 340, Loss: 1.3806
Batch 350, Loss: 1.3457
Batch 360, Loss: 1.3381
Batch 370, Loss: 1.3839
Batch 380, Loss: 1.3877
Batch 390, Loss: 1.3175
Epoch 62 learning rate: 0.07810416889260656
Epoch 62 time: 25.442163944244385 seconds
Epoch 62 accuracy: 58.38%
Batch 10, Loss: 1.2148
Batch 20, Loss: 1.2894
Batch 30, Loss: 1.3334
Batch 40, Loss: 1.3614
Batch 50, Loss: 1.3167
Batch 60, Loss: 1.2920
Batch 70, Loss: 1.2948
Batch 80, Loss: 1.2214
Batch 90, Loss: 1.3042
Batch 100, Loss: 1.3272
Batch 110, Loss: 1.3539
Batch 120, Loss: 1.2786
Batch 130, Loss: 1.3650
Batch 140, Loss: 1.3137
Batch 150, Loss: 1.3199
Batch 160, Loss: 1.3396
Batch 170, Loss: 1.3408
Batch 180, Loss: 1.2971
Batch 190, Loss: 1.2819
Batch 200, Loss: 1.3218
Batch 210, Loss: 1.3457
Batch 220, Loss: 1.3468
Batch 230, Loss: 1.4328
Batch 240, Loss: 1.3318
Batch 250, Loss: 1.3437
Batch 260, Loss: 1.3711
Batch 270, Loss: 1.4023
Batch 280, Loss: 1.3758
Batch 290, Loss: 1.3265
Batch 300, Loss: 1.3271
Batch 310, Loss: 1.3074
Batch 320, Loss: 1.3216
Batch 330, Loss: 1.3356
Batch 340, Loss: 1.3153
Batch 350, Loss: 1.3744
Batch 360, Loss: 1.3231
Batch 370, Loss: 1.3778
Batch 380, Loss: 1.3930
Batch 390, Loss: 1.3240
Epoch 63 learning rate: 0.07745114089990661
Epoch 63 time: 25.39746332168579 seconds
Epoch 63 accuracy: 60.36%
Batch 10, Loss: 1.2589
Batch 20, Loss: 1.2741
Batch 30, Loss: 1.2615
Batch 40, Loss: 1.3178
Batch 50, Loss: 1.2759
Batch 60, Loss: 1.2239
Batch 70, Loss: 1.3024
Batch 80, Loss: 1.3288
Batch 90, Loss: 1.2799
Batch 100, Loss: 1.2880
Batch 110, Loss: 1.3630
Batch 120, Loss: 1.2868
Batch 130, Loss: 1.2774
Batch 140, Loss: 1.2430
Batch 150, Loss: 1.2759
Batch 160, Loss: 1.3438
Batch 170, Loss: 1.3473
Batch 180, Loss: 1.2819
Batch 190, Loss: 1.3165
Batch 200, Loss: 1.3326
Batch 210, Loss: 1.3930
Batch 220, Loss: 1.3980
Batch 230, Loss: 1.2930
Batch 240, Loss: 1.3200
Batch 250, Loss: 1.3168
Batch 260, Loss: 1.3477
Batch 270, Loss: 1.3578
Batch 280, Loss: 1.3753
Batch 290, Loss: 1.2864
Batch 300, Loss: 1.3063
Batch 310, Loss: 1.3643
Batch 320, Loss: 1.3518
Batch 330, Loss: 1.3153
Batch 340, Loss: 1.3833
Batch 350, Loss: 1.3360
Batch 360, Loss: 1.3700
Batch 370, Loss: 1.3604
Batch 380, Loss: 1.3366
Batch 390, Loss: 1.3855
Epoch 64 learning rate: 0.07679133974894985
Epoch 64 time: 25.472309112548828 seconds
Epoch 64 accuracy: 57.22%
Batch 10, Loss: 1.3339
Batch 20, Loss: 1.3200
Batch 30, Loss: 1.3096
Batch 40, Loss: 1.2616
Batch 50, Loss: 1.2819
Batch 60, Loss: 1.2728
Batch 70, Loss: 1.3307
Batch 80, Loss: 1.3216
Batch 90, Loss: 1.2912
Batch 100, Loss: 1.3300
Batch 110, Loss: 1.3589
Batch 120, Loss: 1.3062
Batch 130, Loss: 1.3122
Batch 140, Loss: 1.3745
Batch 150, Loss: 1.3312
Batch 160, Loss: 1.3638
Batch 170, Loss: 1.3695
Batch 180, Loss: 1.3307
Batch 190, Loss: 1.3792
Batch 200, Loss: 1.3334
Batch 210, Loss: 1.3100
Batch 220, Loss: 1.3538
Batch 230, Loss: 1.2618
Batch 240, Loss: 1.3025
Batch 250, Loss: 1.2739
Batch 260, Loss: 1.3367
Batch 270, Loss: 1.3532
Batch 280, Loss: 1.3300
Batch 290, Loss: 1.3219
Batch 300, Loss: 1.3203
Batch 310, Loss: 1.3355
Batch 320, Loss: 1.3874
Batch 330, Loss: 1.3337
Batch 340, Loss: 1.2898
Batch 350, Loss: 1.3638
Batch 360, Loss: 1.2444
Batch 370, Loss: 1.3153
Batch 380, Loss: 1.3715
Batch 390, Loss: 1.3429
Epoch 65 learning rate: 0.07612492823579746
Epoch 65 time: 25.402364253997803 seconds
Epoch 65 accuracy: 60.57%
Batch 10, Loss: 1.2823
Batch 20, Loss: 1.2914
Batch 30, Loss: 1.3407
Batch 40, Loss: 1.2105
Batch 50, Loss: 1.2566
Batch 60, Loss: 1.3132
Batch 70, Loss: 1.2574
Batch 80, Loss: 1.2319
Batch 90, Loss: 1.3115
Batch 100, Loss: 1.2767
Batch 110, Loss: 1.2799
Batch 120, Loss: 1.3097
Batch 130, Loss: 1.3040
Batch 140, Loss: 1.2902
Batch 150, Loss: 1.3040
Batch 160, Loss: 1.3456
Batch 170, Loss: 1.3327
Batch 180, Loss: 1.3642
Batch 190, Loss: 1.3174
Batch 200, Loss: 1.3305
Batch 210, Loss: 1.3610
Batch 220, Loss: 1.3353
Batch 230, Loss: 1.3916
Batch 240, Loss: 1.3081
Batch 250, Loss: 1.2716
Batch 260, Loss: 1.3831
Batch 270, Loss: 1.2872
Batch 280, Loss: 1.2901
Batch 290, Loss: 1.3479
Batch 300, Loss: 1.3115
Batch 310, Loss: 1.3216
Batch 320, Loss: 1.2858
Batch 330, Loss: 1.3360
Batch 340, Loss: 1.3263
Batch 350, Loss: 1.2936
Batch 360, Loss: 1.3955
Batch 370, Loss: 1.3801
Batch 380, Loss: 1.3279
Batch 390, Loss: 1.3493
Epoch 66 learning rate: 0.07545207078751859
Epoch 66 time: 25.506619691848755 seconds
Epoch 66 accuracy: 61.53%
Batch 10, Loss: 1.2677
Batch 20, Loss: 1.2889
Batch 30, Loss: 1.2843
Batch 40, Loss: 1.2892
Batch 50, Loss: 1.2560
Batch 60, Loss: 1.3582
Batch 70, Loss: 1.3078
Batch 80, Loss: 1.3303
Batch 90, Loss: 1.3063
Batch 100, Loss: 1.2674
Batch 110, Loss: 1.3498
Batch 120, Loss: 1.3182
Batch 130, Loss: 1.2522
Batch 140, Loss: 1.3634
Batch 150, Loss: 1.2832
Batch 160, Loss: 1.2872
Batch 170, Loss: 1.3050
Batch 180, Loss: 1.3146
Batch 190, Loss: 1.3313
Batch 200, Loss: 1.3222
Batch 210, Loss: 1.3160
Batch 220, Loss: 1.3570
Batch 230, Loss: 1.2942
Batch 240, Loss: 1.2606
Batch 250, Loss: 1.2946
Batch 260, Loss: 1.3075
Batch 270, Loss: 1.3290
Batch 280, Loss: 1.2757
Batch 290, Loss: 1.3457
Batch 300, Loss: 1.3278
Batch 310, Loss: 1.3408
Batch 320, Loss: 1.2695
Batch 330, Loss: 1.3109
Batch 340, Loss: 1.3035
Batch 350, Loss: 1.2985
Batch 360, Loss: 1.3328
Batch 370, Loss: 1.3009
Batch 380, Loss: 1.2831
Batch 390, Loss: 1.2819
Epoch 67 learning rate: 0.0747729334216204
Epoch 67 time: 25.601307153701782 seconds
Epoch 67 accuracy: 61.71%
Batch 10, Loss: 1.2362
Batch 20, Loss: 1.2882
Batch 30, Loss: 1.2531
Batch 40, Loss: 1.2899
Batch 50, Loss: 1.2567
Batch 60, Loss: 1.3210
Batch 70, Loss: 1.2621
Batch 80, Loss: 1.3232
Batch 90, Loss: 1.2668
Batch 100, Loss: 1.2912
Batch 110, Loss: 1.2248
Batch 120, Loss: 1.2624
Batch 130, Loss: 1.2958
Batch 140, Loss: 1.2869
Batch 150, Loss: 1.2432
Batch 160, Loss: 1.2845
Batch 170, Loss: 1.2770
Batch 180, Loss: 1.3219
Batch 190, Loss: 1.2877
Batch 200, Loss: 1.3927
Batch 210, Loss: 1.2851
Batch 220, Loss: 1.3326
Batch 230, Loss: 1.3188
Batch 240, Loss: 1.3609
Batch 250, Loss: 1.3392
Batch 260, Loss: 1.2789
Batch 270, Loss: 1.2866
Batch 280, Loss: 1.2777
Batch 290, Loss: 1.3605
Batch 300, Loss: 1.3137
Batch 310, Loss: 1.3165
Batch 320, Loss: 1.3658
Batch 330, Loss: 1.3543
Batch 340, Loss: 1.3063
Batch 350, Loss: 1.3395
Batch 360, Loss: 1.3347
Batch 370, Loss: 1.3090
Batch 380, Loss: 1.3196
Batch 390, Loss: 1.3402
Epoch 68 learning rate: 0.07408768370508578
Epoch 68 time: 25.42795157432556 seconds
Epoch 68 accuracy: 59.68%
Batch 10, Loss: 1.2777
Batch 20, Loss: 1.3427
Batch 30, Loss: 1.2459
Batch 40, Loss: 1.2421
Batch 50, Loss: 1.2218
Batch 60, Loss: 1.2712
Batch 70, Loss: 1.2835
Batch 80, Loss: 1.2755
Batch 90, Loss: 1.2866
Batch 100, Loss: 1.2864
Batch 110, Loss: 1.2726
Batch 120, Loss: 1.2767
Batch 130, Loss: 1.3083
Batch 140, Loss: 1.2535
Batch 150, Loss: 1.3032
Batch 160, Loss: 1.2840
Batch 170, Loss: 1.2602
Batch 180, Loss: 1.3549
Batch 190, Loss: 1.2474
Batch 200, Loss: 1.3118
Batch 210, Loss: 1.3334
Batch 220, Loss: 1.2998
Batch 230, Loss: 1.2807
Batch 240, Loss: 1.2794
Batch 250, Loss: 1.3440
Batch 260, Loss: 1.4027
Batch 270, Loss: 1.3199
Batch 280, Loss: 1.3782
Batch 290, Loss: 1.3369
Batch 300, Loss: 1.2517
Batch 310, Loss: 1.2960
Batch 320, Loss: 1.3780
Batch 330, Loss: 1.3877
Batch 340, Loss: 1.3399
Batch 350, Loss: 1.2790
Batch 360, Loss: 1.3223
Batch 370, Loss: 1.2963
Batch 380, Loss: 1.3360
Batch 390, Loss: 1.3522
Epoch 69 learning rate: 0.0733964907130287
Epoch 69 time: 25.516223430633545 seconds
Epoch 69 accuracy: 61.2%
Batch 10, Loss: 1.2283
Batch 20, Loss: 1.2640
Batch 30, Loss: 1.2230
Batch 40, Loss: 1.1968
Batch 50, Loss: 1.2400
Batch 60, Loss: 1.2912
Batch 70, Loss: 1.2698
Batch 80, Loss: 1.3026
Batch 90, Loss: 1.2592
Batch 100, Loss: 1.2719
Batch 110, Loss: 1.2967
Batch 120, Loss: 1.2840
Batch 130, Loss: 1.3151
Batch 140, Loss: 1.2622
Batch 150, Loss: 1.2398
Batch 160, Loss: 1.2938
Batch 170, Loss: 1.3049
Batch 180, Loss: 1.3203
Batch 190, Loss: 1.2214
Batch 200, Loss: 1.3502
Batch 210, Loss: 1.2875
Batch 220, Loss: 1.3512
Batch 230, Loss: 1.2627
Batch 240, Loss: 1.3009
Batch 250, Loss: 1.3076
Batch 260, Loss: 1.3553
Batch 270, Loss: 1.3329
Batch 280, Loss: 1.2929
Batch 290, Loss: 1.3348
Batch 300, Loss: 1.3735
Batch 310, Loss: 1.2699
Batch 320, Loss: 1.2980
Batch 330, Loss: 1.2961
Batch 340, Loss: 1.3605
Batch 350, Loss: 1.3750
Batch 360, Loss: 1.1937
Batch 370, Loss: 1.3311
Batch 380, Loss: 1.3645
Batch 390, Loss: 1.3632
Epoch 70 learning rate: 0.07269952498697736
Epoch 70 time: 25.408061027526855 seconds
Epoch 70 accuracy: 62.1%
Batch 10, Loss: 1.2559
Batch 20, Loss: 1.2089
Batch 30, Loss: 1.3308
Batch 40, Loss: 1.2491
Batch 50, Loss: 1.2668
Batch 60, Loss: 1.3521
Batch 70, Loss: 1.2906
Batch 80, Loss: 1.1942
Batch 90, Loss: 1.2558
Batch 100, Loss: 1.2325
Batch 110, Loss: 1.2487
Batch 120, Loss: 1.3240
Batch 130, Loss: 1.2158
Batch 140, Loss: 1.2334
Batch 150, Loss: 1.3140
Batch 160, Loss: 1.2362
Batch 170, Loss: 1.2470
Batch 180, Loss: 1.2584
Batch 190, Loss: 1.3383
Batch 200, Loss: 1.2293
Batch 210, Loss: 1.3553
Batch 220, Loss: 1.3597
Batch 230, Loss: 1.2829
Batch 240, Loss: 1.2879
Batch 250, Loss: 1.2791
Batch 260, Loss: 1.2614
Batch 270, Loss: 1.2797
Batch 280, Loss: 1.2709
Batch 290, Loss: 1.2959
Batch 300, Loss: 1.3271
Batch 310, Loss: 1.3602
Batch 320, Loss: 1.3921
Batch 330, Loss: 1.3232
Batch 340, Loss: 1.3393
Batch 350, Loss: 1.3081
Batch 360, Loss: 1.3372
Batch 370, Loss: 1.3244
Batch 380, Loss: 1.3060
Batch 390, Loss: 1.3145
Epoch 71 learning rate: 0.07199695849279578
Epoch 71 time: 25.559340238571167 seconds
Epoch 71 accuracy: 59.37%
Batch 10, Loss: 1.2714
Batch 20, Loss: 1.2031
Batch 30, Loss: 1.2743
Batch 40, Loss: 1.1849
Batch 50, Loss: 1.2333
Batch 60, Loss: 1.1704
Batch 70, Loss: 1.2199
Batch 80, Loss: 1.1985
Batch 90, Loss: 1.2568
Batch 100, Loss: 1.3086
Batch 110, Loss: 1.3368
Batch 120, Loss: 1.3353
Batch 130, Loss: 1.2824
Batch 140, Loss: 1.2860
Batch 150, Loss: 1.3376
Batch 160, Loss: 1.2677
Batch 170, Loss: 1.2397
Batch 180, Loss: 1.2483
Batch 190, Loss: 1.3379
Batch 200, Loss: 1.2819
Batch 210, Loss: 1.2583
Batch 220, Loss: 1.2905
Batch 230, Loss: 1.3206
Batch 240, Loss: 1.3511
Batch 250, Loss: 1.2945
Batch 260, Loss: 1.3090
Batch 270, Loss: 1.3119
Batch 280, Loss: 1.2872
Batch 290, Loss: 1.3389
Batch 300, Loss: 1.3158
Batch 310, Loss: 1.3107
Batch 320, Loss: 1.3355
Batch 330, Loss: 1.2689
Batch 340, Loss: 1.2662
Batch 350, Loss: 1.3283
Batch 360, Loss: 1.2634
Batch 370, Loss: 1.2814
Batch 380, Loss: 1.2728
Batch 390, Loss: 1.2683
Epoch 72 learning rate: 0.07128896457825366
Epoch 72 time: 25.617888927459717 seconds
Epoch 72 accuracy: 63.34%
Batch 10, Loss: 1.2279
Batch 20, Loss: 1.2447
Batch 30, Loss: 1.2554
Batch 40, Loss: 1.2016
Batch 50, Loss: 1.2643
Batch 60, Loss: 1.1673
Batch 70, Loss: 1.2401
Batch 80, Loss: 1.2766
Batch 90, Loss: 1.2934
Batch 100, Loss: 1.2892
Batch 110, Loss: 1.2597
Batch 120, Loss: 1.2360
Batch 130, Loss: 1.2156
Batch 140, Loss: 1.2742
Batch 150, Loss: 1.3127
Batch 160, Loss: 1.3153
Batch 170, Loss: 1.3093
Batch 180, Loss: 1.3317
Batch 190, Loss: 1.2253
Batch 200, Loss: 1.2610
Batch 210, Loss: 1.2773
Batch 220, Loss: 1.2109
Batch 230, Loss: 1.3231
Batch 240, Loss: 1.3059
Batch 250, Loss: 1.2700
Batch 260, Loss: 1.2061
Batch 270, Loss: 1.2122
Batch 280, Loss: 1.3423
Batch 290, Loss: 1.2364
Batch 300, Loss: 1.2869
Batch 310, Loss: 1.2693
Batch 320, Loss: 1.2895
Batch 330, Loss: 1.2723
Batch 340, Loss: 1.3016
Batch 350, Loss: 1.2739
Batch 360, Loss: 1.2986
Batch 370, Loss: 1.2757
Batch 380, Loss: 1.2855
Batch 390, Loss: 1.2239
Epoch 73 learning rate: 0.07057571793025548
Epoch 73 time: 25.519076108932495 seconds
Epoch 73 accuracy: 60.82%
Batch 10, Loss: 1.2282
Batch 20, Loss: 1.2225
Batch 30, Loss: 1.2685
Batch 40, Loss: 1.1555
Batch 50, Loss: 1.2294
Batch 60, Loss: 1.2140
Batch 70, Loss: 1.2938
Batch 80, Loss: 1.2907
Batch 90, Loss: 1.2519
Batch 100, Loss: 1.2889
Batch 110, Loss: 1.2400
Batch 120, Loss: 1.2696
Batch 130, Loss: 1.3258
Batch 140, Loss: 1.2620
Batch 150, Loss: 1.2968
Batch 160, Loss: 1.2706
Batch 170, Loss: 1.2484
Batch 180, Loss: 1.2534
Batch 190, Loss: 1.2931
Batch 200, Loss: 1.2426
Batch 210, Loss: 1.2223
Batch 220, Loss: 1.3032
Batch 230, Loss: 1.3140
Batch 240, Loss: 1.3251
Batch 250, Loss: 1.2543
Batch 260, Loss: 1.3199
Batch 270, Loss: 1.2796
Batch 280, Loss: 1.3018
Batch 290, Loss: 1.3049
Batch 300, Loss: 1.2489
Batch 310, Loss: 1.2160
Batch 320, Loss: 1.2942
Batch 330, Loss: 1.2803
Batch 340, Loss: 1.2627
Batch 350, Loss: 1.2174
Batch 360, Loss: 1.3264
Batch 370, Loss: 1.2638
Batch 380, Loss: 1.2384
Batch 390, Loss: 1.3228
Epoch 74 learning rate: 0.06985739453173906
Epoch 74 time: 25.622376441955566 seconds
Epoch 74 accuracy: 60.85%
Batch 10, Loss: 1.2475
Batch 20, Loss: 1.2329
Batch 30, Loss: 1.2105
Batch 40, Loss: 1.2102
Batch 50, Loss: 1.1938
Batch 60, Loss: 1.1926
Batch 70, Loss: 1.1896
Batch 80, Loss: 1.2860
Batch 90, Loss: 1.1947
Batch 100, Loss: 1.2818
Batch 110, Loss: 1.2421
Batch 120, Loss: 1.2394
Batch 130, Loss: 1.3224
Batch 140, Loss: 1.2810
Batch 150, Loss: 1.3378
Batch 160, Loss: 1.2243
Batch 170, Loss: 1.2505
Batch 180, Loss: 1.2555
Batch 190, Loss: 1.2755
Batch 200, Loss: 1.2792
Batch 210, Loss: 1.3226
Batch 220, Loss: 1.2714
Batch 230, Loss: 1.2397
Batch 240, Loss: 1.2347
Batch 250, Loss: 1.2967
Batch 260, Loss: 1.3147
Batch 270, Loss: 1.2376
Batch 280, Loss: 1.2643
Batch 290, Loss: 1.2797
Batch 300, Loss: 1.2632
Batch 310, Loss: 1.3447
Batch 320, Loss: 1.2941
Batch 330, Loss: 1.2525
Batch 340, Loss: 1.2451
Batch 350, Loss: 1.3220
Batch 360, Loss: 1.3107
Batch 370, Loss: 1.3217
Batch 380, Loss: 1.3046
Batch 390, Loss: 1.2857
Epoch 75 learning rate: 0.06913417161825453
Epoch 75 time: 26.277905464172363 seconds
Epoch 75 accuracy: 59.96%
Batch 10, Loss: 1.2391
Batch 20, Loss: 1.2106
Batch 30, Loss: 1.2240
Batch 40, Loss: 1.2127
Batch 50, Loss: 1.1285
Batch 60, Loss: 1.2033
Batch 70, Loss: 1.1984
Batch 80, Loss: 1.1997
Batch 90, Loss: 1.2013
Batch 100, Loss: 1.2480
Batch 110, Loss: 1.3086
Batch 120, Loss: 1.2053
Batch 130, Loss: 1.2310
Batch 140, Loss: 1.2383
Batch 150, Loss: 1.3029
Batch 160, Loss: 1.2693
Batch 170, Loss: 1.3095
Batch 180, Loss: 1.2527
Batch 190, Loss: 1.2808
Batch 200, Loss: 1.2958
Batch 210, Loss: 1.2604
Batch 220, Loss: 1.2813
Batch 230, Loss: 1.3177
Batch 240, Loss: 1.3118
Batch 250, Loss: 1.3340
Batch 260, Loss: 1.3326
Batch 270, Loss: 1.2418
Batch 280, Loss: 1.2393
Batch 290, Loss: 1.2455
Batch 300, Loss: 1.2643
Batch 310, Loss: 1.2488
Batch 320, Loss: 1.2855
Batch 330, Loss: 1.2861
Batch 340, Loss: 1.2861
Batch 350, Loss: 1.2944
Batch 360, Loss: 1.2484
Batch 370, Loss: 1.2753
Batch 380, Loss: 1.2748
Batch 390, Loss: 1.2798
Epoch 76 learning rate: 0.06840622763423394
Epoch 76 time: 25.60790705680847 seconds
Epoch 76 accuracy: 62.28%
Batch 10, Loss: 1.1272
Batch 20, Loss: 1.2169
Batch 30, Loss: 1.2194
Batch 40, Loss: 1.2362
Batch 50, Loss: 1.2302
Batch 60, Loss: 1.2269
Batch 70, Loss: 1.2617
Batch 80, Loss: 1.1937
Batch 90, Loss: 1.2599
Batch 100, Loss: 1.2260
Batch 110, Loss: 1.2567
Batch 120, Loss: 1.2287
Batch 130, Loss: 1.2466
Batch 140, Loss: 1.2990
Batch 150, Loss: 1.2580
Batch 160, Loss: 1.2278
Batch 170, Loss: 1.1876
Batch 180, Loss: 1.2162
Batch 190, Loss: 1.3077
Batch 200, Loss: 1.2782
Batch 210, Loss: 1.2220
Batch 220, Loss: 1.2456
Batch 230, Loss: 1.2586
Batch 240, Loss: 1.2761
Batch 250, Loss: 1.3030
Batch 260, Loss: 1.3350
Batch 270, Loss: 1.2440
Batch 280, Loss: 1.3113
Batch 290, Loss: 1.2327
Batch 300, Loss: 1.2607
Batch 310, Loss: 1.2878
Batch 320, Loss: 1.2794
Batch 330, Loss: 1.3174
Batch 340, Loss: 1.2973
Batch 350, Loss: 1.2755
Batch 360, Loss: 1.3153
Batch 370, Loss: 1.2137
Batch 380, Loss: 1.2341
Batch 390, Loss: 1.3406
Epoch 77 learning rate: 0.0676737421889629
Epoch 77 time: 25.572648286819458 seconds
Epoch 77 accuracy: 62.99%
Batch 10, Loss: 1.2088
Batch 20, Loss: 1.2171
Batch 30, Loss: 1.2121
Batch 40, Loss: 1.2065
Batch 50, Loss: 1.1953
Batch 60, Loss: 1.2297
Batch 70, Loss: 1.1935
Batch 80, Loss: 1.2101
Batch 90, Loss: 1.2688
Batch 100, Loss: 1.1887
Batch 110, Loss: 1.2047
Batch 120, Loss: 1.2484
Batch 130, Loss: 1.2030
Batch 140, Loss: 1.1469
Batch 150, Loss: 1.2194
Batch 160, Loss: 1.2277
Batch 170, Loss: 1.2759
Batch 180, Loss: 1.2717
Batch 190, Loss: 1.2498
Batch 200, Loss: 1.1552
Batch 210, Loss: 1.2616
Batch 220, Loss: 1.2116
Batch 230, Loss: 1.2201
Batch 240, Loss: 1.2717
Batch 250, Loss: 1.2676
Batch 260, Loss: 1.3014
Batch 270, Loss: 1.2745
Batch 280, Loss: 1.2614
Batch 290, Loss: 1.2866
Batch 300, Loss: 1.2418
Batch 310, Loss: 1.1674
Batch 320, Loss: 1.2910
Batch 330, Loss: 1.2460
Batch 340, Loss: 1.2672
Batch 350, Loss: 1.2480
Batch 360, Loss: 1.2516
Batch 370, Loss: 1.3278
Batch 380, Loss: 1.2859
Batch 390, Loss: 1.2214
Epoch 78 learning rate: 0.06693689601226462
Epoch 78 time: 25.531260013580322 seconds
Epoch 78 accuracy: 63.01%
Batch 10, Loss: 1.1732
Batch 20, Loss: 1.1423
Batch 30, Loss: 1.2010
Batch 40, Loss: 1.1797
Batch 50, Loss: 1.2078
Batch 60, Loss: 1.2575
Batch 70, Loss: 1.1889
Batch 80, Loss: 1.2631
Batch 90, Loss: 1.2778
Batch 100, Loss: 1.2347
Batch 110, Loss: 1.1995
Batch 120, Loss: 1.2493
Batch 130, Loss: 1.2413
Batch 140, Loss: 1.2217
Batch 150, Loss: 1.1680
Batch 160, Loss: 1.1429
Batch 170, Loss: 1.2236
Batch 180, Loss: 1.2279
Batch 190, Loss: 1.2570
Batch 200, Loss: 1.1810
Batch 210, Loss: 1.2587
Batch 220, Loss: 1.2657
Batch 230, Loss: 1.2029
Batch 240, Loss: 1.2228
Batch 250, Loss: 1.1836
Batch 260, Loss: 1.2237
Batch 270, Loss: 1.2098
Batch 280, Loss: 1.2426
Batch 290, Loss: 1.3025
Batch 300, Loss: 1.2574
Batch 310, Loss: 1.2639
Batch 320, Loss: 1.2686
Batch 330, Loss: 1.2425
Batch 340, Loss: 1.2700
Batch 350, Loss: 1.2714
Batch 360, Loss: 1.2553
Batch 370, Loss: 1.2274
Batch 380, Loss: 1.2574
Batch 390, Loss: 1.2871
Epoch 79 learning rate: 0.06619587090990751
Epoch 79 time: 25.523311853408813 seconds
Epoch 79 accuracy: 61.18%
Batch 10, Loss: 1.2423
Batch 20, Loss: 1.1936
Batch 30, Loss: 1.1974
Batch 40, Loss: 1.2034
Batch 50, Loss: 1.2139
Batch 60, Loss: 1.2398
Batch 70, Loss: 1.2079
Batch 80, Loss: 1.1910
Batch 90, Loss: 1.1979
Batch 100, Loss: 1.1745
Batch 110, Loss: 1.1988
Batch 120, Loss: 1.2295
Batch 130, Loss: 1.2025
Batch 140, Loss: 1.2525
Batch 150, Loss: 1.1803
Batch 160, Loss: 1.1947
Batch 170, Loss: 1.2534
Batch 180, Loss: 1.2222
Batch 190, Loss: 1.2340
Batch 200, Loss: 1.2293
Batch 210, Loss: 1.2699
Batch 220, Loss: 1.2059
Batch 230, Loss: 1.2048
Batch 240, Loss: 1.2128
Batch 250, Loss: 1.1956
Batch 260, Loss: 1.2884
Batch 270, Loss: 1.2475
Batch 280, Loss: 1.2714
Batch 290, Loss: 1.3197
Batch 300, Loss: 1.2952
Batch 310, Loss: 1.2854
Batch 320, Loss: 1.2464
Batch 330, Loss: 1.2222
Batch 340, Loss: 1.2681
Batch 350, Loss: 1.1901
Batch 360, Loss: 1.2655
Batch 370, Loss: 1.2766
Batch 380, Loss: 1.3090
Batch 390, Loss: 1.2479
Epoch 80 learning rate: 0.06545084971874741
Epoch 80 time: 25.436914682388306 seconds
Epoch 80 accuracy: 63.8%
Batch 10, Loss: 1.1987
Batch 20, Loss: 1.1570
Batch 30, Loss: 1.1961
Batch 40, Loss: 1.1750
Batch 50, Loss: 1.1956
Batch 60, Loss: 1.2511
Batch 70, Loss: 1.2388
Batch 80, Loss: 1.2216
Batch 90, Loss: 1.2226
Batch 100, Loss: 1.2171
Batch 110, Loss: 1.2086
Batch 120, Loss: 1.1992
Batch 130, Loss: 1.2439
Batch 140, Loss: 1.2353
Batch 150, Loss: 1.2638
Batch 160, Loss: 1.2461
Batch 170, Loss: 1.2578
Batch 180, Loss: 1.2179
Batch 190, Loss: 1.2699
Batch 200, Loss: 1.2089
Batch 210, Loss: 1.2347
Batch 220, Loss: 1.1884
Batch 230, Loss: 1.2077
Batch 240, Loss: 1.2449
Batch 250, Loss: 1.2407
Batch 260, Loss: 1.2182
Batch 270, Loss: 1.2110
Batch 280, Loss: 1.2790
Batch 290, Loss: 1.2122
Batch 300, Loss: 1.2139
Batch 310, Loss: 1.1974
Batch 320, Loss: 1.3130
Batch 330, Loss: 1.2486
Batch 340, Loss: 1.2380
Batch 350, Loss: 1.2168
Batch 360, Loss: 1.1869
Batch 370, Loss: 1.2438
Batch 380, Loss: 1.2654
Batch 390, Loss: 1.2338
Epoch 81 learning rate: 0.06470201626161524
Epoch 81 time: 25.495891094207764 seconds
Epoch 81 accuracy: 62.63%
Batch 10, Loss: 1.1487
Batch 20, Loss: 1.1172
Batch 30, Loss: 1.1624
Batch 40, Loss: 1.2221
Batch 50, Loss: 1.1148
Batch 60, Loss: 1.1750
Batch 70, Loss: 1.1920
Batch 80, Loss: 1.2086
Batch 90, Loss: 1.1700
Batch 100, Loss: 1.1784
Batch 110, Loss: 1.1965
Batch 120, Loss: 1.2498
Batch 130, Loss: 1.2306
Batch 140, Loss: 1.1870
Batch 150, Loss: 1.2473
Batch 160, Loss: 1.1836
Batch 170, Loss: 1.2706
Batch 180, Loss: 1.1924
Batch 190, Loss: 1.2936
Batch 200, Loss: 1.2051
Batch 210, Loss: 1.2989
Batch 220, Loss: 1.2239
Batch 230, Loss: 1.1620
Batch 240, Loss: 1.2319
Batch 250, Loss: 1.2358
Batch 260, Loss: 1.2872
Batch 270, Loss: 1.2055
Batch 280, Loss: 1.2141
Batch 290, Loss: 1.2760
Batch 300, Loss: 1.2158
Batch 310, Loss: 1.2788
Batch 320, Loss: 1.2913
Batch 330, Loss: 1.2560
Batch 340, Loss: 1.1725
Batch 350, Loss: 1.2395
Batch 360, Loss: 1.2220
Batch 370, Loss: 1.3139
Batch 380, Loss: 1.2907
Batch 390, Loss: 1.2629
Epoch 82 learning rate: 0.06394955530196152
Epoch 82 time: 25.366657495498657 seconds
Epoch 82 accuracy: 61.37%
Batch 10, Loss: 1.1434
Batch 20, Loss: 1.1811
Batch 30, Loss: 1.1271
Batch 40, Loss: 1.1650
Batch 50, Loss: 1.1481
Batch 60, Loss: 1.2186
Batch 70, Loss: 1.2170
Batch 80, Loss: 1.1876
Batch 90, Loss: 1.2082
Batch 100, Loss: 1.1540
Batch 110, Loss: 1.1854
Batch 120, Loss: 1.2221
Batch 130, Loss: 1.2290
Batch 140, Loss: 1.1762
Batch 150, Loss: 1.2596
Batch 160, Loss: 1.2525
Batch 170, Loss: 1.2265
Batch 180, Loss: 1.2123
Batch 190, Loss: 1.2335
Batch 200, Loss: 1.2705
Batch 210, Loss: 1.2912
Batch 220, Loss: 1.1855
Batch 230, Loss: 1.2622
Batch 240, Loss: 1.2205
Batch 250, Loss: 1.2571
Batch 260, Loss: 1.2010
Batch 270, Loss: 1.2490
Batch 280, Loss: 1.2649
Batch 290, Loss: 1.2246
Batch 300, Loss: 1.2774
Batch 310, Loss: 1.1486
Batch 320, Loss: 1.1857
Batch 330, Loss: 1.2412
Batch 340, Loss: 1.2676
Batch 350, Loss: 1.1437
Batch 360, Loss: 1.2049
Batch 370, Loss: 1.2393
Batch 380, Loss: 1.2184
Batch 390, Loss: 1.2240
Epoch 83 learning rate: 0.06319365249826868
Epoch 83 time: 25.517913341522217 seconds
Epoch 83 accuracy: 63.49%
Batch 10, Loss: 1.1531
Batch 20, Loss: 1.1916
Batch 30, Loss: 1.1660
Batch 40, Loss: 1.1835
Batch 50, Loss: 1.1803
Batch 60, Loss: 1.1601
Batch 70, Loss: 1.1559
Batch 80, Loss: 1.1957
Batch 90, Loss: 1.1990
Batch 100, Loss: 1.1446
Batch 110, Loss: 1.1607
Batch 120, Loss: 1.2422
Batch 130, Loss: 1.1590
Batch 140, Loss: 1.1874
Batch 150, Loss: 1.1969
Batch 160, Loss: 1.1712
Batch 170, Loss: 1.1950
Batch 180, Loss: 1.2016
Batch 190, Loss: 1.2210
Batch 200, Loss: 1.2426
Batch 210, Loss: 1.2182
Batch 220, Loss: 1.2091
Batch 230, Loss: 1.2447
Batch 240, Loss: 1.2750
Batch 250, Loss: 1.2140
Batch 260, Loss: 1.2460
Batch 270, Loss: 1.2384
Batch 280, Loss: 1.1614
Batch 290, Loss: 1.2178
Batch 300, Loss: 1.2378
Batch 310, Loss: 1.2844
Batch 320, Loss: 1.1982
Batch 330, Loss: 1.2577
Batch 340, Loss: 1.2090
Batch 350, Loss: 1.2132
Batch 360, Loss: 1.2421
Batch 370, Loss: 1.2305
Batch 380, Loss: 1.2754
Batch 390, Loss: 1.1937
Epoch 84 learning rate: 0.06243449435824277
Epoch 84 time: 25.538616180419922 seconds
Epoch 84 accuracy: 65.42%
Batch 10, Loss: 1.1724
Batch 20, Loss: 1.1208
Batch 30, Loss: 1.2293
Batch 40, Loss: 1.2053
Batch 50, Loss: 1.1428
Batch 60, Loss: 1.1477
Batch 70, Loss: 1.1414
Batch 80, Loss: 1.2103
Batch 90, Loss: 1.2250
Batch 100, Loss: 1.1751
Batch 110, Loss: 1.2895
Batch 120, Loss: 1.1183
Batch 130, Loss: 1.2218
Batch 140, Loss: 1.1639
Batch 150, Loss: 1.2383
Batch 160, Loss: 1.1340
Batch 170, Loss: 1.2058
Batch 180, Loss: 1.1687
Batch 190, Loss: 1.2370
Batch 200, Loss: 1.2035
Batch 210, Loss: 1.1425
Batch 220, Loss: 1.2228
Batch 230, Loss: 1.1935
Batch 240, Loss: 1.2897
Batch 250, Loss: 1.2409
Batch 260, Loss: 1.2167
Batch 270, Loss: 1.2399
Batch 280, Loss: 1.1880
Batch 290, Loss: 1.2060
Batch 300, Loss: 1.2606
Batch 310, Loss: 1.1825
Batch 320, Loss: 1.1613
Batch 330, Loss: 1.1950
Batch 340, Loss: 1.2177
Batch 350, Loss: 1.2006
Batch 360, Loss: 1.1972
Batch 370, Loss: 1.2297
Batch 380, Loss: 1.2000
Batch 390, Loss: 1.2006
Epoch 85 learning rate: 0.06167226819279532
Epoch 85 time: 25.524019718170166 seconds
Epoch 85 accuracy: 62.08%
Batch 10, Loss: 1.1450
Batch 20, Loss: 1.1301
Batch 30, Loss: 1.1351
Batch 40, Loss: 1.1724
Batch 50, Loss: 1.2169
Batch 60, Loss: 1.1402
Batch 70, Loss: 1.2036
Batch 80, Loss: 1.1556
Batch 90, Loss: 1.1816
Batch 100, Loss: 1.1831
Batch 110, Loss: 1.1713
Batch 120, Loss: 1.1484
Batch 130, Loss: 1.1479
Batch 140, Loss: 1.1925
Batch 150, Loss: 1.2254
Batch 160, Loss: 1.2123
Batch 170, Loss: 1.1912
Batch 180, Loss: 1.2211
Batch 190, Loss: 1.1801
Batch 200, Loss: 1.2822
Batch 210, Loss: 1.2270
Batch 220, Loss: 1.2468
Batch 230, Loss: 1.2693
Batch 240, Loss: 1.2394
Batch 250, Loss: 1.1885
Batch 260, Loss: 1.1873
Batch 270, Loss: 1.2316
Batch 280, Loss: 1.1669
Batch 290, Loss: 1.1838
Batch 300, Loss: 1.1473
Batch 310, Loss: 1.1600
Batch 320, Loss: 1.2052
Batch 330, Loss: 1.2090
Batch 340, Loss: 1.2375
Batch 350, Loss: 1.2321
Batch 360, Loss: 1.2512
Batch 370, Loss: 1.1973
Batch 380, Loss: 1.2192
Batch 390, Loss: 1.2668
Epoch 86 learning rate: 0.06090716206982718
Epoch 86 time: 25.377248764038086 seconds
Epoch 86 accuracy: 63.36%
Batch 10, Loss: 1.1441
Batch 20, Loss: 1.1388
Batch 30, Loss: 1.1666
Batch 40, Loss: 1.1210
Batch 50, Loss: 1.1599
Batch 60, Loss: 1.2195
Batch 70, Loss: 1.1566
Batch 80, Loss: 1.1970
Batch 90, Loss: 1.2233
Batch 100, Loss: 1.1874
Batch 110, Loss: 1.1930
Batch 120, Loss: 1.2387
Batch 130, Loss: 1.1198
Batch 140, Loss: 1.2221
Batch 150, Loss: 1.1733
Batch 160, Loss: 1.2271
Batch 170, Loss: 1.2184
Batch 180, Loss: 1.1490
Batch 190, Loss: 1.2204
Batch 200, Loss: 1.1612
Batch 210, Loss: 1.2478
Batch 220, Loss: 1.1832
Batch 230, Loss: 1.1502
Batch 240, Loss: 1.1675
Batch 250, Loss: 1.2284
Batch 260, Loss: 1.2240
Batch 270, Loss: 1.2486
Batch 280, Loss: 1.2711
Batch 290, Loss: 1.2002
Batch 300, Loss: 1.1999
Batch 310, Loss: 1.1984
Batch 320, Loss: 1.1538
Batch 330, Loss: 1.2079
Batch 340, Loss: 1.2050
Batch 350, Loss: 1.2470
Batch 360, Loss: 1.1554
Batch 370, Loss: 1.2673
Batch 380, Loss: 1.2328
Batch 390, Loss: 1.2780
Epoch 87 learning rate: 0.06013936476782568
Epoch 87 time: 25.401252031326294 seconds
Epoch 87 accuracy: 63.96%
Batch 10, Loss: 1.1425
Batch 20, Loss: 1.1677
Batch 30, Loss: 1.1233
Batch 40, Loss: 1.1572
Batch 50, Loss: 1.0952
Batch 60, Loss: 1.1395
Batch 70, Loss: 1.1926
Batch 80, Loss: 1.1802
Batch 90, Loss: 1.1803
Batch 100, Loss: 1.2045
Batch 110, Loss: 1.1207
Batch 120, Loss: 1.1787
Batch 130, Loss: 1.2042
Batch 140, Loss: 1.1912
Batch 150, Loss: 1.1403
Batch 160, Loss: 1.1246
Batch 170, Loss: 1.1961
Batch 180, Loss: 1.1407
Batch 190, Loss: 1.1361
Batch 200, Loss: 1.2046
Batch 210, Loss: 1.1513
Batch 220, Loss: 1.2123
Batch 230, Loss: 1.1879
Batch 240, Loss: 1.1394
Batch 250, Loss: 1.2115
Batch 260, Loss: 1.1164
Batch 270, Loss: 1.1660
Batch 280, Loss: 1.1768
Batch 290, Loss: 1.2564
Batch 300, Loss: 1.1715
Batch 310, Loss: 1.2728
Batch 320, Loss: 1.2378
Batch 330, Loss: 1.2512
Batch 340, Loss: 1.1752
Batch 350, Loss: 1.1857
Batch 360, Loss: 1.2424
Batch 370, Loss: 1.1815
Batch 380, Loss: 1.1921
Batch 390, Loss: 1.1692
Epoch 88 learning rate: 0.05936906572928629
Epoch 88 time: 25.54274034500122 seconds
Epoch 88 accuracy: 65.45%
Batch 10, Loss: 1.1715
Batch 20, Loss: 1.1085
Batch 30, Loss: 1.2310
Batch 40, Loss: 1.1723
Batch 50, Loss: 1.1393
Batch 60, Loss: 1.1338
Batch 70, Loss: 1.1709
Batch 80, Loss: 1.1409
Batch 90, Loss: 1.1841
Batch 100, Loss: 1.1789
Batch 110, Loss: 1.1484
Batch 120, Loss: 1.1585
Batch 130, Loss: 1.1586
Batch 140, Loss: 1.1877
Batch 150, Loss: 1.1958
Batch 160, Loss: 1.1238
Batch 170, Loss: 1.2569
Batch 180, Loss: 1.2308
Batch 190, Loss: 1.2060
Batch 200, Loss: 1.1426
Batch 210, Loss: 1.1156
Batch 220, Loss: 1.1782
Batch 230, Loss: 1.1469
Batch 240, Loss: 1.1540
Batch 250, Loss: 1.1793
Batch 260, Loss: 1.1928
Batch 270, Loss: 1.2020
Batch 280, Loss: 1.2310
Batch 290, Loss: 1.2455
Batch 300, Loss: 1.1920
Batch 310, Loss: 1.1343
Batch 320, Loss: 1.1474
Batch 330, Loss: 1.1945
Batch 340, Loss: 1.1460
Batch 350, Loss: 1.2345
Batch 360, Loss: 1.1405
Batch 370, Loss: 1.2182
Batch 380, Loss: 1.2307
Batch 390, Loss: 1.2065
Epoch 89 learning rate: 0.05859645501397052
Epoch 89 time: 25.385871410369873 seconds
Epoch 89 accuracy: 63.83%
Batch 10, Loss: 1.0890
Batch 20, Loss: 1.1151
Batch 30, Loss: 1.1205
Batch 40, Loss: 1.1047
Batch 50, Loss: 1.0912
Batch 60, Loss: 1.1728
Batch 70, Loss: 1.1096
Batch 80, Loss: 1.1452
Batch 90, Loss: 1.1117
Batch 100, Loss: 1.0735
Batch 110, Loss: 1.1136
Batch 120, Loss: 1.1442
Batch 130, Loss: 1.1713
Batch 140, Loss: 1.1502
Batch 150, Loss: 1.1957
Batch 160, Loss: 1.1595
Batch 170, Loss: 1.2443
Batch 180, Loss: 1.1624
Batch 190, Loss: 1.1287
Batch 200, Loss: 1.1562
Batch 210, Loss: 1.2075
Batch 220, Loss: 1.1846
Batch 230, Loss: 1.2164
Batch 240, Loss: 1.2270
Batch 250, Loss: 1.2036
Batch 260, Loss: 1.1743
Batch 270, Loss: 1.1810
Batch 280, Loss: 1.2073
Batch 290, Loss: 1.1700
Batch 300, Loss: 1.2432
Batch 310, Loss: 1.2382
Batch 320, Loss: 1.2145
Batch 330, Loss: 1.2134
Batch 340, Loss: 1.1983
Batch 350, Loss: 1.2007
Batch 360, Loss: 1.2084
Batch 370, Loss: 1.2001
Batch 380, Loss: 1.1853
Batch 390, Loss: 1.2086
Epoch 90 learning rate: 0.05782172325201159
Epoch 90 time: 25.285226345062256 seconds
Epoch 90 accuracy: 65.7%
Batch 10, Loss: 1.0704
Batch 20, Loss: 1.1415
Batch 30, Loss: 1.0583
Batch 40, Loss: 1.1064
Batch 50, Loss: 1.1409
Batch 60, Loss: 1.0996
Batch 70, Loss: 1.1274
Batch 80, Loss: 1.0750
Batch 90, Loss: 1.1985
Batch 100, Loss: 1.1533
Batch 110, Loss: 1.1166
Batch 120, Loss: 1.1541
Batch 130, Loss: 1.0671
Batch 140, Loss: 1.1456
Batch 150, Loss: 1.1831
Batch 160, Loss: 1.2024
Batch 170, Loss: 1.2098
Batch 180, Loss: 1.1747
Batch 190, Loss: 1.1997
Batch 200, Loss: 1.1327
Batch 210, Loss: 1.1788
Batch 220, Loss: 1.1750
Batch 230, Loss: 1.1545
Batch 240, Loss: 1.1359
Batch 250, Loss: 1.2200
Batch 260, Loss: 1.2467
Batch 270, Loss: 1.2411
Batch 280, Loss: 1.2105
Batch 290, Loss: 1.2260
Batch 300, Loss: 1.2063
Batch 310, Loss: 1.2496
Batch 320, Loss: 1.1878
Batch 330, Loss: 1.1498
Batch 340, Loss: 1.2244
Batch 350, Loss: 1.2035
Batch 360, Loss: 1.2161
Batch 370, Loss: 1.1653
Batch 380, Loss: 1.2064
Batch 390, Loss: 1.1997
Epoch 91 learning rate: 0.057045061596879186
Epoch 91 time: 25.3620285987854 seconds
Epoch 91 accuracy: 63.94%
Batch 10, Loss: 1.1481
Batch 20, Loss: 1.1133
Batch 30, Loss: 1.1307
Batch 40, Loss: 1.1076
Batch 50, Loss: 1.1454
Batch 60, Loss: 1.1361
Batch 70, Loss: 1.1657
Batch 80, Loss: 1.1867
Batch 90, Loss: 1.1255
Batch 100, Loss: 1.1528
Batch 110, Loss: 1.1128
Batch 120, Loss: 1.1370
Batch 130, Loss: 1.1760
Batch 140, Loss: 1.1522
Batch 150, Loss: 1.0719
Batch 160, Loss: 1.0913
Batch 170, Loss: 1.1534
Batch 180, Loss: 1.2035
Batch 190, Loss: 1.1551
Batch 200, Loss: 1.2076
Batch 210, Loss: 1.1881
Batch 220, Loss: 1.1515
Batch 230, Loss: 1.1608
Batch 240, Loss: 1.1844
Batch 250, Loss: 1.1741
Batch 260, Loss: 1.1264
Batch 270, Loss: 1.1914
Batch 280, Loss: 1.1507
Batch 290, Loss: 1.1117
Batch 300, Loss: 1.1809
Batch 310, Loss: 1.1866
Batch 320, Loss: 1.1651
Batch 330, Loss: 1.1772
Batch 340, Loss: 1.1044
Batch 350, Loss: 1.1362
Batch 360, Loss: 1.2093
Batch 370, Loss: 1.1698
Batch 380, Loss: 1.1919
Batch 390, Loss: 1.1888
Epoch 92 learning rate: 0.056266661678215264
Epoch 92 time: 25.383490800857544 seconds
Epoch 92 accuracy: 64.62%
Batch 10, Loss: 1.1169
Batch 20, Loss: 1.1120
Batch 30, Loss: 1.1283
Batch 40, Loss: 1.1482
Batch 50, Loss: 1.1073
Batch 60, Loss: 1.1373
Batch 70, Loss: 1.1352
Batch 80, Loss: 1.1464
Batch 90, Loss: 1.2067
Batch 100, Loss: 1.1477
Batch 110, Loss: 1.1772
Batch 120, Loss: 1.1480
Batch 130, Loss: 1.1114
Batch 140, Loss: 1.0961
Batch 150, Loss: 1.0927
Batch 160, Loss: 1.1307
Batch 170, Loss: 1.0925
Batch 180, Loss: 1.1973
Batch 190, Loss: 1.1806
Batch 200, Loss: 1.2117
Batch 210, Loss: 1.2663
Batch 220, Loss: 1.1870
Batch 230, Loss: 1.1658
Batch 240, Loss: 1.1559
Batch 250, Loss: 1.1481
Batch 260, Loss: 1.2411
Batch 270, Loss: 1.1544
Batch 280, Loss: 1.0951
Batch 290, Loss: 1.1050
Batch 300, Loss: 1.1751
Batch 310, Loss: 1.1692
Batch 320, Loss: 1.1392
Batch 330, Loss: 1.1594
Batch 340, Loss: 1.1059
Batch 350, Loss: 1.1475
Batch 360, Loss: 1.1278
Batch 370, Loss: 1.1837
Batch 380, Loss: 1.1232
Batch 390, Loss: 1.2380
Epoch 93 learning rate: 0.055486715554552306
Epoch 93 time: 25.3797824382782 seconds
Epoch 93 accuracy: 62.97%
Batch 10, Loss: 1.0736
Batch 20, Loss: 1.0922
Batch 30, Loss: 1.0731
Batch 40, Loss: 1.1333
Batch 50, Loss: 1.1418
Batch 60, Loss: 1.1384
Batch 70, Loss: 1.1560
Batch 80, Loss: 1.1901
Batch 90, Loss: 1.1645
Batch 100, Loss: 1.1234
Batch 110, Loss: 1.0930
Batch 120, Loss: 1.1228
Batch 130, Loss: 1.1954
Batch 140, Loss: 1.1985
Batch 150, Loss: 1.1244
Batch 160, Loss: 1.1336
Batch 170, Loss: 1.1817
Batch 180, Loss: 1.2028
Batch 190, Loss: 1.1388
Batch 200, Loss: 1.0967
Batch 210, Loss: 1.1789
Batch 220, Loss: 1.1395
Batch 230, Loss: 1.1818
Batch 240, Loss: 1.1445
Batch 250, Loss: 1.1376
Batch 260, Loss: 1.1135
Batch 270, Loss: 1.1843
Batch 280, Loss: 1.1397
Batch 290, Loss: 1.1503
Batch 300, Loss: 1.1173
Batch 310, Loss: 1.2079
Batch 320, Loss: 1.1454
Batch 330, Loss: 1.1822
Batch 340, Loss: 1.1335
Batch 350, Loss: 1.2119
Batch 360, Loss: 1.1391
Batch 370, Loss: 1.1751
Batch 380, Loss: 1.1601
Batch 390, Loss: 1.1753
Epoch 94 learning rate: 0.05470541566592575
Epoch 94 time: 25.407217979431152 seconds
Epoch 94 accuracy: 65.72%
Batch 10, Loss: 1.0179
Batch 20, Loss: 1.1165
Batch 30, Loss: 1.0920
Batch 40, Loss: 1.1060
Batch 50, Loss: 1.1087
Batch 60, Loss: 1.0304
Batch 70, Loss: 1.0824
Batch 80, Loss: 1.0606
Batch 90, Loss: 1.0966
Batch 100, Loss: 1.0999
Batch 110, Loss: 1.0799
Batch 120, Loss: 1.1316
Batch 130, Loss: 1.1507
Batch 140, Loss: 1.0649
Batch 150, Loss: 1.1480
Batch 160, Loss: 1.0973
Batch 170, Loss: 1.1718
Batch 180, Loss: 1.1127
Batch 190, Loss: 1.1663
Batch 200, Loss: 1.1291
Batch 210, Loss: 1.1015
Batch 220, Loss: 1.1275
Batch 230, Loss: 1.1468
Batch 240, Loss: 1.1220
Batch 250, Loss: 1.1031
Batch 260, Loss: 1.1366
Batch 270, Loss: 1.1869
Batch 280, Loss: 1.1294
Batch 290, Loss: 1.1431
Batch 300, Loss: 1.2137
Batch 310, Loss: 1.0986
Batch 320, Loss: 1.1872
Batch 330, Loss: 1.1675
Batch 340, Loss: 1.1540
Batch 350, Loss: 1.1541
Batch 360, Loss: 1.1816
Batch 370, Loss: 1.1495
Batch 380, Loss: 1.1664
Batch 390, Loss: 1.2028
Epoch 95 learning rate: 0.05392295478639229
Epoch 95 time: 25.463669776916504 seconds
Epoch 95 accuracy: 66.85%
Batch 10, Loss: 1.0900
Batch 20, Loss: 1.0792
Batch 30, Loss: 1.0773
Batch 40, Loss: 1.0822
Batch 50, Loss: 1.0626
Batch 60, Loss: 1.1090
Batch 70, Loss: 1.0857
Batch 80, Loss: 1.0988
Batch 90, Loss: 1.1231
Batch 100, Loss: 1.1643
Batch 110, Loss: 1.1470
Batch 120, Loss: 1.1396
Batch 130, Loss: 1.1313
Batch 140, Loss: 1.1411
Batch 150, Loss: 1.1256
Batch 160, Loss: 1.1121
Batch 170, Loss: 1.1453
Batch 180, Loss: 1.1229
Batch 190, Loss: 1.1819
Batch 200, Loss: 1.0764
Batch 210, Loss: 1.1072
Batch 220, Loss: 1.2119
Batch 230, Loss: 1.1407
Batch 240, Loss: 1.1345
Batch 250, Loss: 1.1289
Batch 260, Loss: 1.1518
Batch 270, Loss: 1.1232
Batch 280, Loss: 1.1267
Batch 290, Loss: 1.1919
Batch 300, Loss: 1.1676
Batch 310, Loss: 1.1540
Batch 320, Loss: 1.1704
Batch 330, Loss: 1.2182
Batch 340, Loss: 1.1460
Batch 350, Loss: 1.1509
Batch 360, Loss: 1.1804
Batch 370, Loss: 1.1599
Batch 380, Loss: 1.1286
Batch 390, Loss: 1.1485
Epoch 96 learning rate: 0.05313952597646571
Epoch 96 time: 25.450134992599487 seconds
Epoch 96 accuracy: 64.37%
Batch 10, Loss: 1.1070
Batch 20, Loss: 1.0295
Batch 30, Loss: 1.0876
Batch 40, Loss: 1.0915
Batch 50, Loss: 1.0541
Batch 60, Loss: 1.0617
Batch 70, Loss: 1.0743
Batch 80, Loss: 1.0754
Batch 90, Loss: 1.1137
Batch 100, Loss: 1.0710
Batch 110, Loss: 1.1402
Batch 120, Loss: 1.0905
Batch 130, Loss: 1.1023
Batch 140, Loss: 1.0829
Batch 150, Loss: 1.1485
Batch 160, Loss: 1.0621
Batch 170, Loss: 1.1359
Batch 180, Loss: 1.1433
Batch 190, Loss: 1.0912
Batch 200, Loss: 1.1233
Batch 210, Loss: 1.1359
Batch 220, Loss: 1.1449
Batch 230, Loss: 1.0692
Batch 240, Loss: 1.1622
Batch 250, Loss: 1.1115
Batch 260, Loss: 1.0557
Batch 270, Loss: 1.1449
Batch 280, Loss: 1.0862
Batch 290, Loss: 1.0975
Batch 300, Loss: 1.0798
Batch 310, Loss: 1.1313
Batch 320, Loss: 1.0822
Batch 330, Loss: 1.1358
Batch 340, Loss: 1.1472
Batch 350, Loss: 1.2133
Batch 360, Loss: 1.1285
Batch 370, Loss: 1.1510
Batch 380, Loss: 1.1469
Batch 390, Loss: 1.1824
Epoch 97 learning rate: 0.05235532253548216
Epoch 97 time: 25.48162078857422 seconds
Epoch 97 accuracy: 63.95%
Batch 10, Loss: 1.0321
Batch 20, Loss: 1.1186
Batch 30, Loss: 1.1370
Batch 40, Loss: 1.1171
Batch 50, Loss: 1.0722
Batch 60, Loss: 1.1411
Batch 70, Loss: 1.1172
Batch 80, Loss: 1.0377
Batch 90, Loss: 1.1533
Batch 100, Loss: 1.0400
Batch 110, Loss: 1.0982
Batch 120, Loss: 1.1426
Batch 130, Loss: 1.0923
Batch 140, Loss: 1.1203
Batch 150, Loss: 1.0969
Batch 160, Loss: 1.1178
Batch 170, Loss: 1.1504
Batch 180, Loss: 1.2070
Batch 190, Loss: 1.1476
Batch 200, Loss: 1.1537
Batch 210, Loss: 1.1008
Batch 220, Loss: 1.1357
Batch 230, Loss: 1.0830
Batch 240, Loss: 1.0709
Batch 250, Loss: 1.1278
Batch 260, Loss: 1.1295
Batch 270, Loss: 1.1456
Batch 280, Loss: 1.1602
Batch 290, Loss: 1.1601
Batch 300, Loss: 1.1035
Batch 310, Loss: 1.1470
Batch 320, Loss: 1.1480
Batch 330, Loss: 1.0865
Batch 340, Loss: 1.0776
Batch 350, Loss: 1.1235
Batch 360, Loss: 1.1823
Batch 370, Loss: 1.1629
Batch 380, Loss: 1.1696
Batch 390, Loss: 1.1548
Epoch 98 learning rate: 0.051570537953906447
Epoch 98 time: 25.365721940994263 seconds
Epoch 98 accuracy: 64.57%
Batch 10, Loss: 1.0319
Batch 20, Loss: 1.0290
Batch 30, Loss: 1.0150
Batch 40, Loss: 1.0764
Batch 50, Loss: 1.0443
Batch 60, Loss: 1.1307
Batch 70, Loss: 1.0675
Batch 80, Loss: 1.0787
Batch 90, Loss: 1.1178
Batch 100, Loss: 1.1182
Batch 110, Loss: 1.1658
Batch 120, Loss: 1.1235
Batch 130, Loss: 1.1044
Batch 140, Loss: 1.0907
Batch 150, Loss: 1.1387
Batch 160, Loss: 1.0807
Batch 170, Loss: 1.0474
Batch 180, Loss: 1.1481
Batch 190, Loss: 1.0821
Batch 200, Loss: 1.1243
Batch 210, Loss: 1.1138
Batch 220, Loss: 1.0981
Batch 230, Loss: 1.0627
Batch 240, Loss: 1.1272
Batch 250, Loss: 1.0726
Batch 260, Loss: 1.1830
Batch 270, Loss: 1.1324
Batch 280, Loss: 1.1393
Batch 290, Loss: 1.1582
Batch 300, Loss: 1.1090
Batch 310, Loss: 1.0835
Batch 320, Loss: 1.0739
Batch 330, Loss: 1.1349
Batch 340, Loss: 1.0916
Batch 350, Loss: 1.1540
Batch 360, Loss: 1.1765
Batch 370, Loss: 1.1078
Batch 380, Loss: 1.1696
Batch 390, Loss: 1.1593
Epoch 99 learning rate: 0.05078536586559106
Epoch 99 time: 25.40212869644165 seconds
Epoch 99 accuracy: 65.05%
Batch 10, Loss: 1.0247
Batch 20, Loss: 1.0307
Batch 30, Loss: 1.0998
Batch 40, Loss: 1.0460
Batch 50, Loss: 1.0299
Batch 60, Loss: 0.9827
Batch 70, Loss: 1.0644
Batch 80, Loss: 1.0555
Batch 90, Loss: 1.0857
Batch 100, Loss: 1.0903
Batch 110, Loss: 1.0144
Batch 120, Loss: 1.0878
Batch 130, Loss: 1.0678
Batch 140, Loss: 1.1041
Batch 150, Loss: 1.0639
Batch 160, Loss: 1.1094
Batch 170, Loss: 1.1025
Batch 180, Loss: 1.1269
Batch 190, Loss: 1.1041
Batch 200, Loss: 1.1530
Batch 210, Loss: 1.1225
Batch 220, Loss: 1.1069
Batch 230, Loss: 1.1058
Batch 240, Loss: 1.0856
Batch 250, Loss: 1.1068
Batch 260, Loss: 1.0538
Batch 270, Loss: 1.0685
Batch 280, Loss: 1.1316
Batch 290, Loss: 1.1100
Batch 300, Loss: 1.0968
Batch 310, Loss: 1.1668
Batch 320, Loss: 1.1314
Batch 330, Loss: 1.1348
Batch 340, Loss: 1.1680
Batch 350, Loss: 1.1512
Batch 360, Loss: 1.1621
Batch 370, Loss: 1.1209
Batch 380, Loss: 1.1228
Batch 390, Loss: 1.1801
Epoch 100 learning rate: 0.050000000000000024
Epoch 100 time: 25.368340253829956 seconds
Epoch 100 accuracy: 64.1%
Batch 10, Loss: 1.0451
Batch 20, Loss: 1.0773
Batch 30, Loss: 1.0346
Batch 40, Loss: 1.0326
Batch 50, Loss: 1.0713
Batch 60, Loss: 1.0228
Batch 70, Loss: 1.0799
Batch 80, Loss: 1.0121
Batch 90, Loss: 1.0705
Batch 100, Loss: 1.0980
Batch 110, Loss: 1.0730
Batch 120, Loss: 1.0522
Batch 130, Loss: 1.1291
Batch 140, Loss: 1.0697
Batch 150, Loss: 1.0687
Batch 160, Loss: 1.0483
Batch 170, Loss: 1.1250
Batch 180, Loss: 1.1145
Batch 190, Loss: 1.0901
Batch 200, Loss: 1.0530
Batch 210, Loss: 1.0938
Batch 220, Loss: 1.1636
Batch 230, Loss: 1.1183
Batch 240, Loss: 1.0912
Batch 250, Loss: 1.0762
Batch 260, Loss: 1.1386
Batch 270, Loss: 1.0497
Batch 280, Loss: 1.0814
Batch 290, Loss: 1.0649
Batch 300, Loss: 1.1155
Batch 310, Loss: 1.1633
Batch 320, Loss: 1.1369
Batch 330, Loss: 1.1058
Batch 340, Loss: 1.1150
Batch 350, Loss: 1.1243
Batch 360, Loss: 1.0910
Batch 370, Loss: 1.1069
Batch 380, Loss: 1.0875
Batch 390, Loss: 1.1247
Epoch 101 learning rate: 0.049214634134409
Epoch 101 time: 25.400914430618286 seconds
Epoch 101 accuracy: 64.58%
Batch 10, Loss: 1.0223
Batch 20, Loss: 1.0428
Batch 30, Loss: 0.9993
Batch 40, Loss: 1.0810
Batch 50, Loss: 1.0639
Batch 60, Loss: 1.0520
Batch 70, Loss: 1.1242
Batch 80, Loss: 1.0241
Batch 90, Loss: 1.0515
Batch 100, Loss: 1.0700
Batch 110, Loss: 1.0330
Batch 120, Loss: 1.0882
Batch 130, Loss: 1.0853
Batch 140, Loss: 1.0707
Batch 150, Loss: 1.0169
Batch 160, Loss: 1.1079
Batch 170, Loss: 1.1037
Batch 180, Loss: 1.0595
Batch 190, Loss: 1.0726
Batch 200, Loss: 1.1762
Batch 210, Loss: 1.0781
Batch 220, Loss: 1.1000
Batch 230, Loss: 1.1164
Batch 240, Loss: 1.1283
Batch 250, Loss: 1.0680
Batch 260, Loss: 1.0629
Batch 270, Loss: 1.1294
Batch 280, Loss: 1.1033
Batch 290, Loss: 1.1266
Batch 300, Loss: 1.1398
Batch 310, Loss: 1.1666
Batch 320, Loss: 1.1051
Batch 330, Loss: 1.1097
Batch 340, Loss: 1.0891
Batch 350, Loss: 1.0570
Batch 360, Loss: 1.1447
Batch 370, Loss: 1.1357
Batch 380, Loss: 1.1177
Batch 390, Loss: 1.0840
Epoch 102 learning rate: 0.04842946204609361
Epoch 102 time: 25.381983757019043 seconds
Epoch 102 accuracy: 66.36%
Batch 10, Loss: 1.0144
Batch 20, Loss: 1.0441
Batch 30, Loss: 1.0102
Batch 40, Loss: 0.9735
Batch 50, Loss: 0.9983
Batch 60, Loss: 0.9530
Batch 70, Loss: 1.0240
Batch 80, Loss: 1.0349
Batch 90, Loss: 1.0351
Batch 100, Loss: 1.0617
Batch 110, Loss: 1.0374
Batch 120, Loss: 1.0249
Batch 130, Loss: 0.9887
Batch 140, Loss: 1.0843
Batch 150, Loss: 1.1171
Batch 160, Loss: 1.0488
Batch 170, Loss: 1.0694
Batch 180, Loss: 1.0971
Batch 190, Loss: 1.0841
Batch 200, Loss: 1.0533
Batch 210, Loss: 1.0309
Batch 220, Loss: 1.0654
Batch 230, Loss: 1.0502
Batch 240, Loss: 1.0960
Batch 250, Loss: 1.1184
Batch 260, Loss: 1.0698
Batch 270, Loss: 1.1219
Batch 280, Loss: 1.0785
Batch 290, Loss: 1.0973
Batch 300, Loss: 1.1168
Batch 310, Loss: 1.1093
Batch 320, Loss: 1.0756
Batch 330, Loss: 1.1128
Batch 340, Loss: 1.1430
Batch 350, Loss: 1.1342
Batch 360, Loss: 1.1168
Batch 370, Loss: 1.0834
Batch 380, Loss: 1.0861
Batch 390, Loss: 1.0690
Epoch 103 learning rate: 0.04764467746451789
Epoch 103 time: 25.393775463104248 seconds
Epoch 103 accuracy: 66.55%
Batch 10, Loss: 1.0304
Batch 20, Loss: 1.0637
Batch 30, Loss: 1.0892
Batch 40, Loss: 1.0374
Batch 50, Loss: 0.9693
Batch 60, Loss: 1.0160
Batch 70, Loss: 1.0796
Batch 80, Loss: 1.0051
Batch 90, Loss: 1.0264
Batch 100, Loss: 1.0343
Batch 110, Loss: 1.0513
Batch 120, Loss: 1.0628
Batch 130, Loss: 1.0373
Batch 140, Loss: 0.9689
Batch 150, Loss: 1.0102
Batch 160, Loss: 1.0519
Batch 170, Loss: 1.0652
Batch 180, Loss: 1.0040
Batch 190, Loss: 1.0469
Batch 200, Loss: 1.0407
Batch 210, Loss: 1.0522
Batch 220, Loss: 1.1356
Batch 230, Loss: 1.0561
Batch 240, Loss: 1.0962
Batch 250, Loss: 1.1612
Batch 260, Loss: 1.1280
Batch 270, Loss: 1.0376
Batch 280, Loss: 1.1133
Batch 290, Loss: 1.1823
Batch 300, Loss: 1.0762
Batch 310, Loss: 1.1010
Batch 320, Loss: 1.1920
Batch 330, Loss: 1.1203
Batch 340, Loss: 1.1187
Batch 350, Loss: 1.0964
Batch 360, Loss: 1.0793
Batch 370, Loss: 1.0864
Batch 380, Loss: 1.1541
Batch 390, Loss: 1.1368
Epoch 104 learning rate: 0.046860474023534354
Epoch 104 time: 25.432035207748413 seconds
Epoch 104 accuracy: 66.36%
Batch 10, Loss: 1.0093
Batch 20, Loss: 0.9680
Batch 30, Loss: 1.0250
Batch 40, Loss: 1.0010
Batch 50, Loss: 1.0031
Batch 60, Loss: 1.0537
Batch 70, Loss: 1.0683
Batch 80, Loss: 1.0074
Batch 90, Loss: 1.0745
Batch 100, Loss: 1.0338
Batch 110, Loss: 1.0754
Batch 120, Loss: 1.0298
Batch 130, Loss: 1.0506
Batch 140, Loss: 0.9855
Batch 150, Loss: 1.0532
Batch 160, Loss: 1.0222
Batch 170, Loss: 1.0379
Batch 180, Loss: 1.0351
Batch 190, Loss: 1.0278
Batch 200, Loss: 1.1530
Batch 210, Loss: 1.1107
Batch 220, Loss: 1.0970
Batch 230, Loss: 1.0993
Batch 240, Loss: 1.0889
Batch 250, Loss: 1.0699
Batch 260, Loss: 1.0763
Batch 270, Loss: 1.0561
Batch 280, Loss: 1.0209
Batch 290, Loss: 1.0311
Batch 300, Loss: 1.0944
Batch 310, Loss: 1.0942
Batch 320, Loss: 1.1121
Batch 330, Loss: 1.1104
Batch 340, Loss: 1.0777
Batch 350, Loss: 1.0929
Batch 360, Loss: 1.1118
Batch 370, Loss: 1.1054
Batch 380, Loss: 1.0587
Batch 390, Loss: 1.1622
Epoch 105 learning rate: 0.04607704521360778
Epoch 105 time: 25.2710440158844 seconds
Epoch 105 accuracy: 66.19%
Batch 10, Loss: 1.0369
Batch 20, Loss: 1.0276
Batch 30, Loss: 0.9782
Batch 40, Loss: 1.0512
Batch 50, Loss: 0.9996
Batch 60, Loss: 1.0408
Batch 70, Loss: 0.9823
Batch 80, Loss: 1.0581
Batch 90, Loss: 1.0332
Batch 100, Loss: 1.0231
Batch 110, Loss: 1.0638
Batch 120, Loss: 1.0485
Batch 130, Loss: 1.0608
Batch 140, Loss: 1.0192
Batch 150, Loss: 1.0565
Batch 160, Loss: 1.0311
Batch 170, Loss: 1.0331
Batch 180, Loss: 1.0299
Batch 190, Loss: 1.0274
Batch 200, Loss: 1.0862
Batch 210, Loss: 1.0063
Batch 220, Loss: 1.0308
Batch 230, Loss: 1.0835
Batch 240, Loss: 1.0677
Batch 250, Loss: 1.0887
Batch 260, Loss: 1.1026
Batch 270, Loss: 1.0240
Batch 280, Loss: 1.0651
Batch 290, Loss: 1.0443
Batch 300, Loss: 1.0013
Batch 310, Loss: 1.0489
Batch 320, Loss: 1.0504
Batch 330, Loss: 1.0668
Batch 340, Loss: 1.0324
Batch 350, Loss: 1.0802
Batch 360, Loss: 1.0672
Batch 370, Loss: 1.0679
Batch 380, Loss: 1.0508
Batch 390, Loss: 1.0471
Epoch 106 learning rate: 0.04529458433407431
Epoch 106 time: 25.471872091293335 seconds
Epoch 106 accuracy: 65.21%
Batch 10, Loss: 1.0523
Batch 20, Loss: 0.9572
Batch 30, Loss: 1.0104
Batch 40, Loss: 1.1129
Batch 50, Loss: 0.9755
Batch 60, Loss: 0.9922
Batch 70, Loss: 1.0517
Batch 80, Loss: 1.0501
Batch 90, Loss: 0.9461
Batch 100, Loss: 1.0589
Batch 110, Loss: 0.9721
Batch 120, Loss: 1.0065
Batch 130, Loss: 1.0016
Batch 140, Loss: 1.0814
Batch 150, Loss: 1.1165
Batch 160, Loss: 0.9997
Batch 170, Loss: 1.0533
Batch 180, Loss: 1.0253
Batch 190, Loss: 1.0313
Batch 200, Loss: 0.9881
Batch 210, Loss: 0.9917
Batch 220, Loss: 1.0279
Batch 230, Loss: 1.0938
Batch 240, Loss: 1.0804
Batch 250, Loss: 1.0692
Batch 260, Loss: 1.0554
Batch 270, Loss: 1.0065
Batch 280, Loss: 1.0568
Batch 290, Loss: 1.0476
Batch 300, Loss: 1.0724
Batch 310, Loss: 1.0859
Batch 320, Loss: 1.0465
Batch 330, Loss: 1.1166
Batch 340, Loss: 1.0523
Batch 350, Loss: 1.1079
Batch 360, Loss: 1.0303
Batch 370, Loss: 1.0580
Batch 380, Loss: 1.0518
Batch 390, Loss: 1.0963
Epoch 107 learning rate: 0.04451328444544776
Epoch 107 time: 25.44990611076355 seconds
Epoch 107 accuracy: 66.43%
Batch 10, Loss: 0.9892
Batch 20, Loss: 0.9966
Batch 30, Loss: 1.0293
Batch 40, Loss: 1.0558
Batch 50, Loss: 1.0629
Batch 60, Loss: 1.0023
Batch 70, Loss: 1.0042
Batch 80, Loss: 0.9792
Batch 90, Loss: 1.0019
Batch 100, Loss: 1.0289
Batch 110, Loss: 1.0404
Batch 120, Loss: 1.0634
Batch 130, Loss: 1.0358
Batch 140, Loss: 1.0270
Batch 150, Loss: 0.9622
Batch 160, Loss: 1.0702
Batch 170, Loss: 0.9867
Batch 180, Loss: 0.9845
Batch 190, Loss: 1.0409
Batch 200, Loss: 1.0114
Batch 210, Loss: 1.0028
Batch 220, Loss: 0.9884
Batch 230, Loss: 1.0463
Batch 240, Loss: 1.0325
Batch 250, Loss: 1.0304
Batch 260, Loss: 1.1185
Batch 270, Loss: 1.0659
Batch 280, Loss: 1.0967
Batch 290, Loss: 1.0292
Batch 300, Loss: 1.0796
Batch 310, Loss: 1.0853
Batch 320, Loss: 1.0984
Batch 330, Loss: 1.0751
Batch 340, Loss: 1.0318
Batch 350, Loss: 1.0290
Batch 360, Loss: 1.0705
Batch 370, Loss: 1.0485
Batch 380, Loss: 1.0580
Batch 390, Loss: 1.0517
Epoch 108 learning rate: 0.04373333832178482
Epoch 108 time: 25.38859486579895 seconds
Epoch 108 accuracy: 64.52%
Batch 10, Loss: 1.0129
Batch 20, Loss: 1.0189
Batch 30, Loss: 0.9707
Batch 40, Loss: 0.9913
Batch 50, Loss: 0.9596
Batch 60, Loss: 1.0023
Batch 70, Loss: 1.0030
Batch 80, Loss: 1.0107
Batch 90, Loss: 1.0010
Batch 100, Loss: 1.0181
Batch 110, Loss: 1.0716
Batch 120, Loss: 0.9525
Batch 130, Loss: 1.0222
Batch 140, Loss: 0.9720
Batch 150, Loss: 0.9811
Batch 160, Loss: 1.0209
Batch 170, Loss: 1.0382
Batch 180, Loss: 0.9851
Batch 190, Loss: 1.0499
Batch 200, Loss: 1.0274
Batch 210, Loss: 1.0338
Batch 220, Loss: 1.0960
Batch 230, Loss: 1.0763
Batch 240, Loss: 1.0515
Batch 250, Loss: 1.0892
Batch 260, Loss: 1.0528
Batch 270, Loss: 1.0888
Batch 280, Loss: 1.0267
Batch 290, Loss: 1.0252
Batch 300, Loss: 1.0680
Batch 310, Loss: 1.0340
Batch 320, Loss: 1.1059
Batch 330, Loss: 1.0595
Batch 340, Loss: 1.0029
Batch 350, Loss: 1.0431
Batch 360, Loss: 1.0519
Batch 370, Loss: 1.0311
Batch 380, Loss: 1.0440
Batch 390, Loss: 0.9674
Epoch 109 learning rate: 0.0429549384031209
Epoch 109 time: 25.52098274230957 seconds
Epoch 109 accuracy: 67.75%
Batch 10, Loss: 0.9672
Batch 20, Loss: 0.9593
Batch 30, Loss: 1.0382
Batch 40, Loss: 0.9850
Batch 50, Loss: 0.9866
Batch 60, Loss: 1.0458
Batch 70, Loss: 1.0430
Batch 80, Loss: 0.9751
Batch 90, Loss: 1.0686
Batch 100, Loss: 0.9309
Batch 110, Loss: 0.9806
Batch 120, Loss: 0.9466
Batch 130, Loss: 0.9884
Batch 140, Loss: 1.0670
Batch 150, Loss: 1.0270
Batch 160, Loss: 1.0536
Batch 170, Loss: 1.0312
Batch 180, Loss: 1.0491
Batch 190, Loss: 1.0245
Batch 200, Loss: 0.9758
Batch 210, Loss: 1.0085
Batch 220, Loss: 1.0509
Batch 230, Loss: 1.0442
Batch 240, Loss: 1.0300
Batch 250, Loss: 0.9726
Batch 260, Loss: 0.9972
Batch 270, Loss: 1.1030
Batch 280, Loss: 1.0089
Batch 290, Loss: 1.0059
Batch 300, Loss: 1.0214
Batch 310, Loss: 1.0188
Batch 320, Loss: 1.0248
Batch 330, Loss: 1.0991
Batch 340, Loss: 1.0627
Batch 350, Loss: 1.0456
Batch 360, Loss: 1.0333
Batch 370, Loss: 1.0621
Batch 380, Loss: 1.0572
Batch 390, Loss: 1.0073
Epoch 110 learning rate: 0.042178276747988484
Epoch 110 time: 25.38763689994812 seconds
Epoch 110 accuracy: 67.12%
Batch 10, Loss: 0.9446
Batch 20, Loss: 0.9752
Batch 30, Loss: 0.9668
Batch 40, Loss: 0.9418
Batch 50, Loss: 0.9979
Batch 60, Loss: 0.9881
Batch 70, Loss: 0.9668
Batch 80, Loss: 0.9877
Batch 90, Loss: 1.0767
Batch 100, Loss: 0.9839
Batch 110, Loss: 1.0497
Batch 120, Loss: 0.9820
Batch 130, Loss: 1.0385
Batch 140, Loss: 1.0506
Batch 150, Loss: 0.9606
Batch 160, Loss: 1.0028
Batch 170, Loss: 0.9911
Batch 180, Loss: 0.9678
Batch 190, Loss: 0.9483
Batch 200, Loss: 0.9913
Batch 210, Loss: 1.0377
Batch 220, Loss: 1.0881
Batch 230, Loss: 0.9933
Batch 240, Loss: 1.0300
Batch 250, Loss: 1.0451
Batch 260, Loss: 0.9336
Batch 270, Loss: 1.0247
Batch 280, Loss: 1.0536
Batch 290, Loss: 1.0702
Batch 300, Loss: 1.0043
Batch 310, Loss: 1.0704
Batch 320, Loss: 0.9919
Batch 330, Loss: 0.9734
Batch 340, Loss: 1.0074
Batch 350, Loss: 1.0466
Batch 360, Loss: 0.9923
Batch 370, Loss: 1.0199
Batch 380, Loss: 1.0217
Batch 390, Loss: 0.9776
Epoch 111 learning rate: 0.04140354498602954
Epoch 111 time: 25.367247104644775 seconds
Epoch 111 accuracy: 67.86%
Batch 10, Loss: 0.9921
Batch 20, Loss: 0.9704
Batch 30, Loss: 0.9240
Batch 40, Loss: 0.9698
Batch 50, Loss: 0.9945
Batch 60, Loss: 0.8759
Batch 70, Loss: 0.9372
Batch 80, Loss: 0.9998
Batch 90, Loss: 1.0146
Batch 100, Loss: 1.0008
Batch 110, Loss: 0.9998
Batch 120, Loss: 0.9962
Batch 130, Loss: 0.9874
Batch 140, Loss: 1.0028
Batch 150, Loss: 1.0022
Batch 160, Loss: 0.9114
Batch 170, Loss: 0.9873
Batch 180, Loss: 1.0331
Batch 190, Loss: 1.0373
Batch 200, Loss: 1.0277
Batch 210, Loss: 0.9988
Batch 220, Loss: 1.0211
Batch 230, Loss: 1.0051
Batch 240, Loss: 1.0624
Batch 250, Loss: 1.0952
Batch 260, Loss: 1.0438
Batch 270, Loss: 1.0241
Batch 280, Loss: 1.0189
Batch 290, Loss: 1.0435
Batch 300, Loss: 0.9847
Batch 310, Loss: 1.0456
Batch 320, Loss: 0.9501
Batch 330, Loss: 1.0197
Batch 340, Loss: 0.9872
Batch 350, Loss: 1.0110
Batch 360, Loss: 0.9759
Batch 370, Loss: 1.0309
Batch 380, Loss: 1.0317
Batch 390, Loss: 0.9801
Epoch 112 learning rate: 0.0406309342707138
Epoch 112 time: 25.39667010307312 seconds
Epoch 112 accuracy: 66.69%
Batch 10, Loss: 0.9431
Batch 20, Loss: 0.9380
Batch 30, Loss: 0.9484
Batch 40, Loss: 0.9710
Batch 50, Loss: 0.9603
Batch 60, Loss: 0.9047
Batch 70, Loss: 0.9534
Batch 80, Loss: 1.0607
Batch 90, Loss: 0.9754
Batch 100, Loss: 1.0433
Batch 110, Loss: 0.9771
Batch 120, Loss: 0.9614
Batch 130, Loss: 1.0111
Batch 140, Loss: 0.9487
Batch 150, Loss: 0.9784
Batch 160, Loss: 0.9826
Batch 170, Loss: 0.9953
Batch 180, Loss: 1.0313
Batch 190, Loss: 0.9134
Batch 200, Loss: 1.0105
Batch 210, Loss: 0.9846
Batch 220, Loss: 0.9901
Batch 230, Loss: 0.9809
Batch 240, Loss: 1.0618
Batch 250, Loss: 1.0043
Batch 260, Loss: 1.0117
Batch 270, Loss: 0.9405
Batch 280, Loss: 1.0144
Batch 290, Loss: 1.0028
Batch 300, Loss: 1.0418
Batch 310, Loss: 1.0414
Batch 320, Loss: 0.9897
Batch 330, Loss: 1.0166
Batch 340, Loss: 0.9820
Batch 350, Loss: 1.0275
Batch 360, Loss: 0.9969
Batch 370, Loss: 1.0057
Batch 380, Loss: 1.0003
Batch 390, Loss: 0.9876
Epoch 113 learning rate: 0.03986063523217441
Epoch 113 time: 25.45878529548645 seconds
Epoch 113 accuracy: 68.76%
Batch 10, Loss: 0.9613
Batch 20, Loss: 0.9149
Batch 30, Loss: 0.9756
Batch 40, Loss: 0.9911
Batch 50, Loss: 0.9530
Batch 60, Loss: 0.9458
Batch 70, Loss: 0.9233
Batch 80, Loss: 0.9970
Batch 90, Loss: 0.9809
Batch 100, Loss: 0.9631
Batch 110, Loss: 0.9652
Batch 120, Loss: 1.0077
Batch 130, Loss: 0.9351
Batch 140, Loss: 0.9403
Batch 150, Loss: 0.9085
Batch 160, Loss: 0.9320
Batch 170, Loss: 0.9650
Batch 180, Loss: 0.9913
Batch 190, Loss: 0.9826
Batch 200, Loss: 1.0245
Batch 210, Loss: 0.9726
Batch 220, Loss: 0.9799
Batch 230, Loss: 0.9671
Batch 240, Loss: 1.0043
Batch 250, Loss: 0.9902
Batch 260, Loss: 1.0177
Batch 270, Loss: 1.0351
Batch 280, Loss: 1.0251
Batch 290, Loss: 0.9569
Batch 300, Loss: 0.9769
Batch 310, Loss: 1.0597
Batch 320, Loss: 1.0265
Batch 330, Loss: 0.9581
Batch 340, Loss: 1.0380
Batch 350, Loss: 1.0336
Batch 360, Loss: 1.0247
Batch 370, Loss: 0.9603
Batch 380, Loss: 1.0340
Batch 390, Loss: 0.9994
Epoch 114 learning rate: 0.039092837930172916
Epoch 114 time: 25.348994970321655 seconds
Epoch 114 accuracy: 67.73%
Batch 10, Loss: 0.9729
Batch 20, Loss: 0.9482
Batch 30, Loss: 0.9529
Batch 40, Loss: 0.9485
Batch 50, Loss: 0.9748
Batch 60, Loss: 0.9380
Batch 70, Loss: 0.8977
Batch 80, Loss: 0.9761
Batch 90, Loss: 0.9375
Batch 100, Loss: 0.9495
Batch 110, Loss: 0.9088
Batch 120, Loss: 0.9722
Batch 130, Loss: 0.9373
Batch 140, Loss: 0.9900
Batch 150, Loss: 0.9463
Batch 160, Loss: 0.9529
Batch 170, Loss: 0.9846
Batch 180, Loss: 0.9386
Batch 190, Loss: 0.9452
Batch 200, Loss: 0.9552
Batch 210, Loss: 0.9671
Batch 220, Loss: 0.9402
Batch 230, Loss: 0.9246
Batch 240, Loss: 0.9640
Batch 250, Loss: 0.9592
Batch 260, Loss: 0.9810
Batch 270, Loss: 0.9671
Batch 280, Loss: 0.9610
Batch 290, Loss: 0.9454
Batch 300, Loss: 0.9649
Batch 310, Loss: 1.0144
Batch 320, Loss: 0.9933
Batch 330, Loss: 1.0176
Batch 340, Loss: 1.0691
Batch 350, Loss: 1.0328
Batch 360, Loss: 0.9764
Batch 370, Loss: 1.0572
Batch 380, Loss: 1.0003
Batch 390, Loss: 1.0425
Epoch 115 learning rate: 0.03832773180720475
Epoch 115 time: 25.372495889663696 seconds
Epoch 115 accuracy: 68.33%
Batch 10, Loss: 0.9208
Batch 20, Loss: 0.8911
Batch 30, Loss: 0.8610
Batch 40, Loss: 0.8793
Batch 50, Loss: 0.9201
Batch 60, Loss: 0.9512
Batch 70, Loss: 0.9333
Batch 80, Loss: 0.9664
Batch 90, Loss: 0.9198
Batch 100, Loss: 0.9489
Batch 110, Loss: 0.9369
Batch 120, Loss: 0.9802
Batch 130, Loss: 0.9597
Batch 140, Loss: 0.9337
Batch 150, Loss: 0.9785
Batch 160, Loss: 0.9869
Batch 170, Loss: 1.0182
Batch 180, Loss: 0.9539
Batch 190, Loss: 0.9838
Batch 200, Loss: 0.9384
Batch 210, Loss: 1.0079
Batch 220, Loss: 0.9632
Batch 230, Loss: 1.0133
Batch 240, Loss: 0.9683
Batch 250, Loss: 0.9842
Batch 260, Loss: 0.9735
Batch 270, Loss: 0.9593
Batch 280, Loss: 0.9541
Batch 290, Loss: 0.9566
Batch 300, Loss: 0.9365
Batch 310, Loss: 1.0180
Batch 320, Loss: 0.9751
Batch 330, Loss: 1.0029
Batch 340, Loss: 0.9423
Batch 350, Loss: 1.0173
Batch 360, Loss: 0.9766
Batch 370, Loss: 1.0365
Batch 380, Loss: 1.0168
Batch 390, Loss: 0.9391
Epoch 116 learning rate: 0.037565505641757285
Epoch 116 time: 25.427133083343506 seconds
Epoch 116 accuracy: 67.06%
Batch 10, Loss: 0.9199
Batch 20, Loss: 0.9261
Batch 30, Loss: 0.9230
Batch 40, Loss: 0.9239
Batch 50, Loss: 0.8416
Batch 60, Loss: 0.9295
Batch 70, Loss: 0.8633
Batch 80, Loss: 0.9315
Batch 90, Loss: 0.9003
Batch 100, Loss: 0.9424
Batch 110, Loss: 0.8705
Batch 120, Loss: 0.9448
Batch 130, Loss: 0.9181
Batch 140, Loss: 0.9885
Batch 150, Loss: 0.9554
Batch 160, Loss: 1.0013
Batch 170, Loss: 1.0150
Batch 180, Loss: 0.9282
Batch 190, Loss: 1.0535
Batch 200, Loss: 0.9905
Batch 210, Loss: 0.9531
Batch 220, Loss: 1.0035
Batch 230, Loss: 0.9378
Batch 240, Loss: 0.9372
Batch 250, Loss: 1.0171
Batch 260, Loss: 0.9706
Batch 270, Loss: 0.9628
Batch 280, Loss: 0.9824
Batch 290, Loss: 0.9289
Batch 300, Loss: 1.0429
Batch 310, Loss: 0.9259
Batch 320, Loss: 0.9247
Batch 330, Loss: 0.9480
Batch 340, Loss: 0.9378
Batch 350, Loss: 0.9281
Batch 360, Loss: 0.9615
Batch 370, Loss: 0.9948
Batch 380, Loss: 1.0161
Batch 390, Loss: 0.9302
Epoch 117 learning rate: 0.03680634750173138
Epoch 117 time: 25.45093297958374 seconds
Epoch 117 accuracy: 66.77%
Batch 10, Loss: 0.8790
Batch 20, Loss: 0.8886
Batch 30, Loss: 0.9109
Batch 40, Loss: 0.8874
Batch 50, Loss: 0.9475
Batch 60, Loss: 0.8571
Batch 70, Loss: 0.9173
Batch 80, Loss: 0.9220
Batch 90, Loss: 0.9306
Batch 100, Loss: 0.9630
Batch 110, Loss: 0.9707
Batch 120, Loss: 0.9144
Batch 130, Loss: 0.9566
Batch 140, Loss: 0.9281
Batch 150, Loss: 0.9326
Batch 160, Loss: 0.9276
Batch 170, Loss: 0.9311
Batch 180, Loss: 0.9160
Batch 190, Loss: 0.9782
Batch 200, Loss: 0.9511
Batch 210, Loss: 0.9048
Batch 220, Loss: 0.9820
Batch 230, Loss: 0.9761
Batch 240, Loss: 0.9216
Batch 250, Loss: 0.9778
Batch 260, Loss: 0.9869
Batch 270, Loss: 0.9243
Batch 280, Loss: 0.9277
Batch 290, Loss: 1.0103
Batch 300, Loss: 0.9925
Batch 310, Loss: 1.0083
Batch 320, Loss: 1.0168
Batch 330, Loss: 1.0175
Batch 340, Loss: 0.9895
Batch 350, Loss: 0.9005
Batch 360, Loss: 1.0057
Batch 370, Loss: 0.9115
Batch 380, Loss: 0.9446
Batch 390, Loss: 0.9684
Epoch 118 learning rate: 0.036050444698038565
Epoch 118 time: 25.415529489517212 seconds
Epoch 118 accuracy: 69.4%
Batch 10, Loss: 0.8768
Batch 20, Loss: 0.9048
Batch 30, Loss: 0.9590
Batch 40, Loss: 0.9102
Batch 50, Loss: 0.9088
Batch 60, Loss: 0.9473
Batch 70, Loss: 0.9295
Batch 80, Loss: 0.8559
Batch 90, Loss: 0.9037
Batch 100, Loss: 0.8961
Batch 110, Loss: 0.8232
Batch 120, Loss: 0.9278
Batch 130, Loss: 0.8985
Batch 140, Loss: 0.9005
Batch 150, Loss: 0.9007
Batch 160, Loss: 1.0273
Batch 170, Loss: 0.9154
Batch 180, Loss: 0.9832
Batch 190, Loss: 0.9405
Batch 200, Loss: 0.8933
Batch 210, Loss: 0.9021
Batch 220, Loss: 0.8968
Batch 230, Loss: 0.9863
Batch 240, Loss: 0.9502
Batch 250, Loss: 0.9303
Batch 260, Loss: 0.9508
Batch 270, Loss: 0.9899
Batch 280, Loss: 0.9365
Batch 290, Loss: 0.9910
Batch 300, Loss: 0.9299
Batch 310, Loss: 0.9308
Batch 320, Loss: 0.9770
Batch 330, Loss: 0.9172
Batch 340, Loss: 0.9337
Batch 350, Loss: 0.9500
Batch 360, Loss: 0.9532
Batch 370, Loss: 0.9842
Batch 380, Loss: 0.9532
Batch 390, Loss: 0.9248
Epoch 119 learning rate: 0.03529798373838483
Epoch 119 time: 25.450605392456055 seconds
Epoch 119 accuracy: 70.49%
Batch 10, Loss: 0.8587
Batch 20, Loss: 0.9131
Batch 30, Loss: 0.9122
Batch 40, Loss: 0.9020
Batch 50, Loss: 0.9620
Batch 60, Loss: 0.9122
Batch 70, Loss: 0.8931
Batch 80, Loss: 0.9234
Batch 90, Loss: 0.8978
Batch 100, Loss: 0.9498
Batch 110, Loss: 0.9275
Batch 120, Loss: 0.8920
Batch 130, Loss: 0.9283
Batch 140, Loss: 0.9164
Batch 150, Loss: 0.8960
Batch 160, Loss: 0.9195
Batch 170, Loss: 0.9504
Batch 180, Loss: 0.9727
Batch 190, Loss: 0.9160
Batch 200, Loss: 0.9785
Batch 210, Loss: 0.9487
Batch 220, Loss: 0.9381
Batch 230, Loss: 0.9204
Batch 240, Loss: 0.9470
Batch 250, Loss: 0.9313
Batch 260, Loss: 0.9537
Batch 270, Loss: 0.9774
Batch 280, Loss: 0.9126
Batch 290, Loss: 0.9614
Batch 300, Loss: 0.9572
Batch 310, Loss: 0.9088
Batch 320, Loss: 0.9405
Batch 330, Loss: 0.8948
Batch 340, Loss: 0.9572
Batch 350, Loss: 0.8738
Batch 360, Loss: 0.9652
Batch 370, Loss: 0.9629
Batch 380, Loss: 0.9379
Batch 390, Loss: 0.9684
Epoch 120 learning rate: 0.03454915028125267
Epoch 120 time: 25.401083946228027 seconds
Epoch 120 accuracy: 69.56%
Batch 10, Loss: 0.9106
Batch 20, Loss: 0.8763
Batch 30, Loss: 0.8483
Batch 40, Loss: 0.8783
Batch 50, Loss: 0.9078
Batch 60, Loss: 0.8831
Batch 70, Loss: 0.8591
Batch 80, Loss: 0.9175
Batch 90, Loss: 0.8212
Batch 100, Loss: 0.8775
Batch 110, Loss: 0.8633
Batch 120, Loss: 0.8921
Batch 130, Loss: 0.8542
Batch 140, Loss: 0.9047
Batch 150, Loss: 0.8810
Batch 160, Loss: 0.9606
Batch 170, Loss: 0.9062
Batch 180, Loss: 0.9593
Batch 190, Loss: 0.9201
Batch 200, Loss: 0.9358
Batch 210, Loss: 0.8992
Batch 220, Loss: 0.9574
Batch 230, Loss: 0.9313
Batch 240, Loss: 0.9365
Batch 250, Loss: 0.9012
Batch 260, Loss: 0.8794
Batch 270, Loss: 0.9530
Batch 280, Loss: 0.8634
Batch 290, Loss: 0.8882
Batch 300, Loss: 0.9700
Batch 310, Loss: 0.9520
Batch 320, Loss: 0.9000
Batch 330, Loss: 0.9417
Batch 340, Loss: 0.9637
Batch 350, Loss: 0.9963
Batch 360, Loss: 0.9121
Batch 370, Loss: 0.9207
Batch 380, Loss: 0.9828
Batch 390, Loss: 0.9580
Epoch 121 learning rate: 0.03380412909009255
Epoch 121 time: 25.48356795310974 seconds
Epoch 121 accuracy: 69.81%
Batch 10, Loss: 0.8850
Batch 20, Loss: 0.9030
Batch 30, Loss: 0.8918
Batch 40, Loss: 0.9214
Batch 50, Loss: 0.9246
Batch 60, Loss: 0.8590
Batch 70, Loss: 0.9053
Batch 80, Loss: 0.8407
Batch 90, Loss: 0.8490
Batch 100, Loss: 0.8861
Batch 110, Loss: 0.8713
Batch 120, Loss: 0.8483
Batch 130, Loss: 0.8690
Batch 140, Loss: 0.8539
Batch 150, Loss: 0.7914
Batch 160, Loss: 0.9284
Batch 170, Loss: 0.8640
Batch 180, Loss: 0.8703
Batch 190, Loss: 0.8757
Batch 200, Loss: 0.8752
Batch 210, Loss: 0.8995
Batch 220, Loss: 0.8710
Batch 230, Loss: 0.9493
Batch 240, Loss: 0.9274
Batch 250, Loss: 0.9269
Batch 260, Loss: 0.9450
Batch 270, Loss: 0.9397
Batch 280, Loss: 0.9215
Batch 290, Loss: 0.9325
Batch 300, Loss: 0.9002
Batch 310, Loss: 0.9703
Batch 320, Loss: 0.9605
Batch 330, Loss: 0.8785
Batch 340, Loss: 0.9806
Batch 350, Loss: 0.9019
Batch 360, Loss: 0.9531
Batch 370, Loss: 0.8733
Batch 380, Loss: 0.9502
Batch 390, Loss: 0.8773
Epoch 122 learning rate: 0.03306310398773545
Epoch 122 time: 25.44657564163208 seconds
Epoch 122 accuracy: 69.34%
Batch 10, Loss: 0.9126
Batch 20, Loss: 0.8768
Batch 30, Loss: 0.9083
Batch 40, Loss: 0.8763
Batch 50, Loss: 0.8863
Batch 60, Loss: 0.8791
Batch 70, Loss: 0.8729
Batch 80, Loss: 0.8597
Batch 90, Loss: 0.8552
Batch 100, Loss: 0.9100
Batch 110, Loss: 0.8699
Batch 120, Loss: 0.9004
Batch 130, Loss: 0.9110
Batch 140, Loss: 0.8462
Batch 150, Loss: 0.9449
Batch 160, Loss: 0.8747
Batch 170, Loss: 0.9447
Batch 180, Loss: 0.8544
Batch 190, Loss: 0.8979
Batch 200, Loss: 0.9482
Batch 210, Loss: 0.8515
Batch 220, Loss: 0.8646
Batch 230, Loss: 0.9348
Batch 240, Loss: 0.8835
Batch 250, Loss: 0.9269
Batch 260, Loss: 0.8464
Batch 270, Loss: 0.8753
Batch 280, Loss: 0.9306
Batch 290, Loss: 0.9322
Batch 300, Loss: 1.0092
Batch 310, Loss: 0.9099
Batch 320, Loss: 0.8672
Batch 330, Loss: 0.8698
Batch 340, Loss: 0.9243
Batch 350, Loss: 0.9015
Batch 360, Loss: 0.9081
Batch 370, Loss: 0.9724
Batch 380, Loss: 0.8519
Batch 390, Loss: 0.9110
Epoch 123 learning rate: 0.03232625781103717
Epoch 123 time: 25.374552249908447 seconds
Epoch 123 accuracy: 68.77%
Batch 10, Loss: 0.8211
Batch 20, Loss: 0.8266
Batch 30, Loss: 0.8374
Batch 40, Loss: 0.8325
Batch 50, Loss: 0.8857
Batch 60, Loss: 0.8633
Batch 70, Loss: 0.8730
Batch 80, Loss: 0.8609
Batch 90, Loss: 0.8885
Batch 100, Loss: 0.9128
Batch 110, Loss: 0.8552
Batch 120, Loss: 0.8689
Batch 130, Loss: 0.8689
Batch 140, Loss: 0.8348
Batch 150, Loss: 0.8478
Batch 160, Loss: 0.8199
Batch 170, Loss: 0.8338
Batch 180, Loss: 0.8741
Batch 190, Loss: 0.8614
Batch 200, Loss: 0.8874
Batch 210, Loss: 0.8680
Batch 220, Loss: 0.8428
Batch 230, Loss: 0.9175
Batch 240, Loss: 0.9268
Batch 250, Loss: 0.9104
Batch 260, Loss: 0.9209
Batch 270, Loss: 0.8893
Batch 280, Loss: 0.9135
Batch 290, Loss: 0.9255
Batch 300, Loss: 0.9810
Batch 310, Loss: 0.8901
Batch 320, Loss: 0.9177
Batch 330, Loss: 0.8935
Batch 340, Loss: 0.9110
Batch 350, Loss: 0.9164
Batch 360, Loss: 0.8791
Batch 370, Loss: 0.9470
Batch 380, Loss: 0.9681
Batch 390, Loss: 0.8873
Epoch 124 learning rate: 0.03159377236576613
Epoch 124 time: 25.38676381111145 seconds
Epoch 124 accuracy: 69.44%
Batch 10, Loss: 0.8114
Batch 20, Loss: 0.8099
Batch 30, Loss: 0.8451
Batch 40, Loss: 0.8070
Batch 50, Loss: 0.8506
Batch 60, Loss: 0.8272
Batch 70, Loss: 0.8841
Batch 80, Loss: 0.9065
Batch 90, Loss: 0.8395
Batch 100, Loss: 0.8776
Batch 110, Loss: 0.8197
Batch 120, Loss: 0.8280
Batch 130, Loss: 0.9008
Batch 140, Loss: 0.8515
Batch 150, Loss: 0.8614
Batch 160, Loss: 0.8399
Batch 170, Loss: 0.8644
Batch 180, Loss: 0.9061
Batch 190, Loss: 0.9371
Batch 200, Loss: 0.8553
Batch 210, Loss: 0.8652
Batch 220, Loss: 0.8927
Batch 230, Loss: 0.9095
Batch 240, Loss: 0.8753
Batch 250, Loss: 0.9206
Batch 260, Loss: 0.9368
Batch 270, Loss: 0.8994
Batch 280, Loss: 0.8612
Batch 290, Loss: 0.8677
Batch 300, Loss: 0.9114
Batch 310, Loss: 0.8777
Batch 320, Loss: 0.9264
Batch 330, Loss: 0.8788
Batch 340, Loss: 0.9495
Batch 350, Loss: 0.8478
Batch 360, Loss: 0.9059
Batch 370, Loss: 0.9105
Batch 380, Loss: 0.9188
Batch 390, Loss: 0.9026
Epoch 125 learning rate: 0.030865828381745543
Epoch 125 time: 25.594141244888306 seconds
Epoch 125 accuracy: 69.37%
Batch 10, Loss: 0.8517
Batch 20, Loss: 0.8126
Batch 30, Loss: 0.7453
Batch 40, Loss: 0.8490
Batch 50, Loss: 0.8230
Batch 60, Loss: 0.8200
Batch 70, Loss: 0.8534
Batch 80, Loss: 0.7897
Batch 90, Loss: 0.8210
Batch 100, Loss: 0.8696
Batch 110, Loss: 0.8598
Batch 120, Loss: 0.8843
Batch 130, Loss: 0.9275
Batch 140, Loss: 0.8980
Batch 150, Loss: 0.8758
Batch 160, Loss: 0.8505
Batch 170, Loss: 0.8469
Batch 180, Loss: 0.8981
Batch 190, Loss: 0.8696
Batch 200, Loss: 0.8382
Batch 210, Loss: 0.8943
Batch 220, Loss: 0.9096
Batch 230, Loss: 0.8913
Batch 240, Loss: 0.8322
Batch 250, Loss: 0.8366
Batch 260, Loss: 0.8465
Batch 270, Loss: 0.8647
Batch 280, Loss: 0.8712
Batch 290, Loss: 0.8089
Batch 300, Loss: 0.8600
Batch 310, Loss: 0.9020
Batch 320, Loss: 0.8586
Batch 330, Loss: 0.8770
Batch 340, Loss: 0.8980
Batch 350, Loss: 0.9368
Batch 360, Loss: 0.8986
Batch 370, Loss: 0.8707
Batch 380, Loss: 0.9565
Batch 390, Loss: 0.9186
Epoch 126 learning rate: 0.03014260546826098
Epoch 126 time: 25.537007093429565 seconds
Epoch 126 accuracy: 70.78%
Batch 10, Loss: 0.7565
Batch 20, Loss: 0.8365
Batch 30, Loss: 0.8248
Batch 40, Loss: 0.8553
Batch 50, Loss: 0.8598
Batch 60, Loss: 0.8409
Batch 70, Loss: 0.8758
Batch 80, Loss: 0.8632
Batch 90, Loss: 0.8263
Batch 100, Loss: 0.8500
Batch 110, Loss: 0.8619
Batch 120, Loss: 0.8451
Batch 130, Loss: 0.8727
Batch 140, Loss: 0.8211
Batch 150, Loss: 0.8374
Batch 160, Loss: 0.8335
Batch 170, Loss: 0.8481
Batch 180, Loss: 0.8462
Batch 190, Loss: 0.8856
Batch 200, Loss: 0.8568
Batch 210, Loss: 0.8881
Batch 220, Loss: 0.8698
Batch 230, Loss: 0.8768
Batch 240, Loss: 0.8889
Batch 250, Loss: 0.8850
Batch 260, Loss: 0.8443
Batch 270, Loss: 0.8685
Batch 280, Loss: 0.8335
Batch 290, Loss: 0.8768
Batch 300, Loss: 0.9219
Batch 310, Loss: 0.8613
Batch 320, Loss: 0.9196
Batch 330, Loss: 0.8732
Batch 340, Loss: 0.8311
Batch 350, Loss: 0.8921
Batch 360, Loss: 0.8744
Batch 370, Loss: 0.8835
Batch 380, Loss: 0.8451
Batch 390, Loss: 0.8831
Epoch 127 learning rate: 0.02942428206974458
Epoch 127 time: 25.54132628440857 seconds
Epoch 127 accuracy: 70.62%
Batch 10, Loss: 0.8182
Batch 20, Loss: 0.8297
Batch 30, Loss: 0.8504
Batch 40, Loss: 0.8195
Batch 50, Loss: 0.8797
Batch 60, Loss: 0.7999
Batch 70, Loss: 0.8370
Batch 80, Loss: 0.8086
Batch 90, Loss: 0.8387
Batch 100, Loss: 0.7929
Batch 110, Loss: 0.8304
Batch 120, Loss: 0.8686
Batch 130, Loss: 0.8253
Batch 140, Loss: 0.8272
Batch 150, Loss: 0.8423
Batch 160, Loss: 0.8433
Batch 170, Loss: 0.8249
Batch 180, Loss: 0.8477
Batch 190, Loss: 0.8716
Batch 200, Loss: 0.8270
Batch 210, Loss: 0.8125
Batch 220, Loss: 0.9068
Batch 230, Loss: 0.8648
Batch 240, Loss: 0.8006
Batch 250, Loss: 0.8874
Batch 260, Loss: 0.8356
Batch 270, Loss: 0.8775
Batch 280, Loss: 0.8808
Batch 290, Loss: 0.8749
Batch 300, Loss: 0.8668
Batch 310, Loss: 0.8593
Batch 320, Loss: 0.8884
Batch 330, Loss: 0.9352
Batch 340, Loss: 0.8512
Batch 350, Loss: 0.8736
Batch 360, Loss: 0.8942
Batch 370, Loss: 0.8885
Batch 380, Loss: 0.8052
Batch 390, Loss: 0.8854
Epoch 128 learning rate: 0.028711035421746387
Epoch 128 time: 25.499572277069092 seconds
Epoch 128 accuracy: 70.11%
Batch 10, Loss: 0.7928
Batch 20, Loss: 0.7826
Batch 30, Loss: 0.7309
Batch 40, Loss: 0.8242
Batch 50, Loss: 0.7875
Batch 60, Loss: 0.7997
Batch 70, Loss: 0.8065
Batch 80, Loss: 0.7852
Batch 90, Loss: 0.8185
Batch 100, Loss: 0.8033
Batch 110, Loss: 0.7956
Batch 120, Loss: 0.7774
Batch 130, Loss: 0.8100
Batch 140, Loss: 0.8053
Batch 150, Loss: 0.8239
Batch 160, Loss: 0.8111
Batch 170, Loss: 0.7987
Batch 180, Loss: 0.8619
Batch 190, Loss: 0.8376
Batch 200, Loss: 0.8337
Batch 210, Loss: 0.8640
Batch 220, Loss: 0.8683
Batch 230, Loss: 0.8661
Batch 240, Loss: 0.8732
Batch 250, Loss: 0.8310
Batch 260, Loss: 0.7980
Batch 270, Loss: 0.8128
Batch 280, Loss: 0.8579
Batch 290, Loss: 0.9012
Batch 300, Loss: 0.8424
Batch 310, Loss: 0.8300
Batch 320, Loss: 0.8710
Batch 330, Loss: 0.8692
Batch 340, Loss: 0.8271
Batch 350, Loss: 0.8877
Batch 360, Loss: 0.8184
Batch 370, Loss: 0.8705
Batch 380, Loss: 0.9130
Batch 390, Loss: 0.9244
Epoch 129 learning rate: 0.02800304150720426
Epoch 129 time: 25.54635453224182 seconds
Epoch 129 accuracy: 70.43%
Batch 10, Loss: 0.7354
Batch 20, Loss: 0.7751
Batch 30, Loss: 0.8008
Batch 40, Loss: 0.8186
Batch 50, Loss: 0.8219
Batch 60, Loss: 0.7757
Batch 70, Loss: 0.7447
Batch 80, Loss: 0.7970
Batch 90, Loss: 0.7943
Batch 100, Loss: 0.7368
Batch 110, Loss: 0.7691
Batch 120, Loss: 0.7998
Batch 130, Loss: 0.7801
Batch 140, Loss: 0.8341
Batch 150, Loss: 0.8150
Batch 160, Loss: 0.8363
Batch 170, Loss: 0.7867
Batch 180, Loss: 0.8110
Batch 190, Loss: 0.7977
Batch 200, Loss: 0.8556
Batch 210, Loss: 0.8366
Batch 220, Loss: 0.8605
Batch 230, Loss: 0.8390
Batch 240, Loss: 0.8188
Batch 250, Loss: 0.8281
Batch 260, Loss: 0.8331
Batch 270, Loss: 0.7618
Batch 280, Loss: 0.8369
Batch 290, Loss: 0.8646
Batch 300, Loss: 0.8886
Batch 310, Loss: 0.8603
Batch 320, Loss: 0.8060
Batch 330, Loss: 0.8467
Batch 340, Loss: 0.8636
Batch 350, Loss: 0.8546
Batch 360, Loss: 0.8722
Batch 370, Loss: 0.8543
Batch 380, Loss: 0.9003
Batch 390, Loss: 0.7998
Epoch 130 learning rate: 0.02730047501302268
Epoch 130 time: 25.51412606239319 seconds
Epoch 130 accuracy: 70.23%
Batch 10, Loss: 0.7981
Batch 20, Loss: 0.7709
Batch 30, Loss: 0.7797
Batch 40, Loss: 0.8201
Batch 50, Loss: 0.7605
Batch 60, Loss: 0.7821
Batch 70, Loss: 0.7877
Batch 80, Loss: 0.8347
Batch 90, Loss: 0.7618
Batch 100, Loss: 0.8341
Batch 110, Loss: 0.8038
Batch 120, Loss: 0.8342
Batch 130, Loss: 0.8512
Batch 140, Loss: 0.7932
Batch 150, Loss: 0.8034
Batch 160, Loss: 0.7545
Batch 170, Loss: 0.8343
Batch 180, Loss: 0.8341
Batch 190, Loss: 0.7994
Batch 200, Loss: 0.8011
Batch 210, Loss: 0.7808
Batch 220, Loss: 0.8057
Batch 230, Loss: 0.8143
Batch 240, Loss: 0.7945
Batch 250, Loss: 0.8474
Batch 260, Loss: 0.8255
Batch 270, Loss: 0.8183
Batch 280, Loss: 0.8163
Batch 290, Loss: 0.8322
Batch 300, Loss: 0.8160
Batch 310, Loss: 0.8444
Batch 320, Loss: 0.8073
Batch 330, Loss: 0.8387
Batch 340, Loss: 0.8552
Batch 350, Loss: 0.7869
Batch 360, Loss: 0.8836
Batch 370, Loss: 0.8212
Batch 380, Loss: 0.8377
Batch 390, Loss: 0.8305
Epoch 131 learning rate: 0.026603509286971357
Epoch 131 time: 25.43100929260254 seconds
Epoch 131 accuracy: 71.44%
Batch 10, Loss: 0.7826
Batch 20, Loss: 0.7546
Batch 30, Loss: 0.7183
Batch 40, Loss: 0.7730
Batch 50, Loss: 0.7588
Batch 60, Loss: 0.7815
Batch 70, Loss: 0.8266
Batch 80, Loss: 0.8045
Batch 90, Loss: 0.7655
Batch 100, Loss: 0.7452
Batch 110, Loss: 0.7530
Batch 120, Loss: 0.7700
Batch 130, Loss: 0.7823
Batch 140, Loss: 0.7840
Batch 150, Loss: 0.8233
Batch 160, Loss: 0.7887
Batch 170, Loss: 0.7343
Batch 180, Loss: 0.7785
Batch 190, Loss: 0.8221
Batch 200, Loss: 0.8166
Batch 210, Loss: 0.7926
Batch 220, Loss: 0.7587
Batch 230, Loss: 0.7949
Batch 240, Loss: 0.7668
Batch 250, Loss: 0.8055
Batch 260, Loss: 0.7980
Batch 270, Loss: 0.7245
Batch 280, Loss: 0.7816
Batch 290, Loss: 0.7872
Batch 300, Loss: 0.7892
Batch 310, Loss: 0.8242
Batch 320, Loss: 0.8040
Batch 330, Loss: 0.7956
Batch 340, Loss: 0.7937
Batch 350, Loss: 0.8437
Batch 360, Loss: 0.8201
Batch 370, Loss: 0.8788
Batch 380, Loss: 0.8738
Batch 390, Loss: 0.7720
Epoch 132 learning rate: 0.025912316294914244
Epoch 132 time: 25.454171180725098 seconds
Epoch 132 accuracy: 70.87%
Batch 10, Loss: 0.7642
Batch 20, Loss: 0.7539
Batch 30, Loss: 0.8153
Batch 40, Loss: 0.8358
Batch 50, Loss: 0.7143
Batch 60, Loss: 0.7801
Batch 70, Loss: 0.7590
Batch 80, Loss: 0.7873
Batch 90, Loss: 0.8357
Batch 100, Loss: 0.8000
Batch 110, Loss: 0.7991
Batch 120, Loss: 0.7093
Batch 130, Loss: 0.7905
Batch 140, Loss: 0.7111
Batch 150, Loss: 0.7682
Batch 160, Loss: 0.8623
Batch 170, Loss: 0.8311
Batch 180, Loss: 0.7699
Batch 190, Loss: 0.8015
Batch 200, Loss: 0.7392
Batch 210, Loss: 0.7512
Batch 220, Loss: 0.8154
Batch 230, Loss: 0.7653
Batch 240, Loss: 0.7994
Batch 250, Loss: 0.8115
Batch 260, Loss: 0.7961
Batch 270, Loss: 0.7712
Batch 280, Loss: 0.8404
Batch 290, Loss: 0.8434
Batch 300, Loss: 0.8122
Batch 310, Loss: 0.8493
Batch 320, Loss: 0.7821
Batch 330, Loss: 0.8198
Batch 340, Loss: 0.8181
Batch 350, Loss: 0.8364
Batch 360, Loss: 0.8513
Batch 370, Loss: 0.8355
Batch 380, Loss: 0.8243
Batch 390, Loss: 0.8088
Epoch 133 learning rate: 0.025227066578379632
Epoch 133 time: 25.50140118598938 seconds
Epoch 133 accuracy: 70.19%
Batch 10, Loss: 0.7696
Batch 20, Loss: 0.7213
Batch 30, Loss: 0.7788
Batch 40, Loss: 0.7044
Batch 50, Loss: 0.7950
Batch 60, Loss: 0.8388
Batch 70, Loss: 0.7225
Batch 80, Loss: 0.8159
Batch 90, Loss: 0.7929
Batch 100, Loss: 0.7679
Batch 110, Loss: 0.7564
Batch 120, Loss: 0.7977
Batch 130, Loss: 0.7849
Batch 140, Loss: 0.7945
Batch 150, Loss: 0.7373
Batch 160, Loss: 0.7207
Batch 170, Loss: 0.7344
Batch 180, Loss: 0.7708
Batch 190, Loss: 0.7716
Batch 200, Loss: 0.8105
Batch 210, Loss: 0.7426
Batch 220, Loss: 0.7270
Batch 230, Loss: 0.7947
Batch 240, Loss: 0.7480
Batch 250, Loss: 0.8069
Batch 260, Loss: 0.7837
Batch 270, Loss: 0.8094
Batch 280, Loss: 0.7933
Batch 290, Loss: 0.7509
Batch 300, Loss: 0.7720
Batch 310, Loss: 0.7921
Batch 320, Loss: 0.7919
Batch 330, Loss: 0.8406
Batch 340, Loss: 0.8166
Batch 350, Loss: 0.8573
Batch 360, Loss: 0.7564
Batch 370, Loss: 0.8324
Batch 380, Loss: 0.8082
Batch 390, Loss: 0.7930
Epoch 134 learning rate: 0.024547929212481445
Epoch 134 time: 25.442602157592773 seconds
Epoch 134 accuracy: 71.0%
Batch 10, Loss: 0.7567
Batch 20, Loss: 0.7508
Batch 30, Loss: 0.7384
Batch 40, Loss: 0.7439
Batch 50, Loss: 0.7789
Batch 60, Loss: 0.7054
Batch 70, Loss: 0.7125
Batch 80, Loss: 0.7546
Batch 90, Loss: 0.7653
Batch 100, Loss: 0.7495
Batch 110, Loss: 0.7471
Batch 120, Loss: 0.7589
Batch 130, Loss: 0.7600
Batch 140, Loss: 0.7624
Batch 150, Loss: 0.7646
Batch 160, Loss: 0.7814
Batch 170, Loss: 0.7413
Batch 180, Loss: 0.7336
Batch 190, Loss: 0.7679
Batch 200, Loss: 0.7491
Batch 210, Loss: 0.8272
Batch 220, Loss: 0.7353
Batch 230, Loss: 0.7407
Batch 240, Loss: 0.8065
Batch 250, Loss: 0.8354
Batch 260, Loss: 0.7816
Batch 270, Loss: 0.7141
Batch 280, Loss: 0.7685
Batch 290, Loss: 0.7666
Batch 300, Loss: 0.7520
Batch 310, Loss: 0.7971
Batch 320, Loss: 0.8100
Batch 330, Loss: 0.7609
Batch 340, Loss: 0.8012
Batch 350, Loss: 0.7912
Batch 360, Loss: 0.8026
Batch 370, Loss: 0.8276
Batch 380, Loss: 0.8878
Batch 390, Loss: 0.8398
Epoch 135 learning rate: 0.02387507176420257
Epoch 135 time: 25.505396366119385 seconds
Epoch 135 accuracy: 71.58%
Batch 10, Loss: 0.7448
Batch 20, Loss: 0.7617
Batch 30, Loss: 0.7286
Batch 40, Loss: 0.7004
Batch 50, Loss: 0.6991
Batch 60, Loss: 0.6849
Batch 70, Loss: 0.7378
Batch 80, Loss: 0.7260
Batch 90, Loss: 0.7648
Batch 100, Loss: 0.7670
Batch 110, Loss: 0.7483
Batch 120, Loss: 0.7696
Batch 130, Loss: 0.7489
Batch 140, Loss: 0.7761
Batch 150, Loss: 0.7411
Batch 160, Loss: 0.7434
Batch 170, Loss: 0.7847
Batch 180, Loss: 0.7651
Batch 190, Loss: 0.7443
Batch 200, Loss: 0.7094
Batch 210, Loss: 0.8097
Batch 220, Loss: 0.7728
Batch 230, Loss: 0.7900
Batch 240, Loss: 0.8279
Batch 250, Loss: 0.7772
Batch 260, Loss: 0.7613
Batch 270, Loss: 0.7471
Batch 280, Loss: 0.8086
Batch 290, Loss: 0.7421
Batch 300, Loss: 0.7893
Batch 310, Loss: 0.7902
Batch 320, Loss: 0.7610
Batch 330, Loss: 0.7762
Batch 340, Loss: 0.7789
Batch 350, Loss: 0.6954
Batch 360, Loss: 0.8306
Batch 370, Loss: 0.8121
Batch 380, Loss: 0.8318
Batch 390, Loss: 0.8336
Epoch 136 learning rate: 0.023208660251050166
Epoch 136 time: 25.37120008468628 seconds
Epoch 136 accuracy: 72.53%
Batch 10, Loss: 0.7416
Batch 20, Loss: 0.7513
Batch 30, Loss: 0.7538
Batch 40, Loss: 0.7337
Batch 50, Loss: 0.7765
Batch 60, Loss: 0.6761
Batch 70, Loss: 0.6716
Batch 80, Loss: 0.7128
Batch 90, Loss: 0.7450
Batch 100, Loss: 0.7221
Batch 110, Loss: 0.7639
Batch 120, Loss: 0.7657
Batch 130, Loss: 0.6867
Batch 140, Loss: 0.7011
Batch 150, Loss: 0.7196
Batch 160, Loss: 0.7558
Batch 170, Loss: 0.7557
Batch 180, Loss: 0.7619
Batch 190, Loss: 0.7703
Batch 200, Loss: 0.7420
Batch 210, Loss: 0.7246
Batch 220, Loss: 0.7536
Batch 230, Loss: 0.7646
Batch 240, Loss: 0.7459
Batch 250, Loss: 0.7553
Batch 260, Loss: 0.7726
Batch 270, Loss: 0.7025
Batch 280, Loss: 0.7786
Batch 290, Loss: 0.7892
Batch 300, Loss: 0.7327
Batch 310, Loss: 0.7571
Batch 320, Loss: 0.7566
Batch 330, Loss: 0.7099
Batch 340, Loss: 0.7751
Batch 350, Loss: 0.7699
Batch 360, Loss: 0.7224
Batch 370, Loss: 0.7850
Batch 380, Loss: 0.7807
Batch 390, Loss: 0.8238
Epoch 137 learning rate: 0.022548859100093414
Epoch 137 time: 25.437342405319214 seconds
Epoch 137 accuracy: 71.64%
Batch 10, Loss: 0.7317
Batch 20, Loss: 0.7612
Batch 30, Loss: 0.6711
Batch 40, Loss: 0.7194
Batch 50, Loss: 0.7052
Batch 60, Loss: 0.7331
Batch 70, Loss: 0.7190
Batch 80, Loss: 0.7125
Batch 90, Loss: 0.7019
Batch 100, Loss: 0.7279
Batch 110, Loss: 0.7264
Batch 120, Loss: 0.7361
Batch 130, Loss: 0.7388
Batch 140, Loss: 0.7227
Batch 150, Loss: 0.7423
Batch 160, Loss: 0.7232
Batch 170, Loss: 0.7236
Batch 180, Loss: 0.7479
Batch 190, Loss: 0.7206
Batch 200, Loss: 0.7205
Batch 210, Loss: 0.7376
Batch 220, Loss: 0.7654
Batch 230, Loss: 0.7320
Batch 240, Loss: 0.7063
Batch 250, Loss: 0.7781
Batch 260, Loss: 0.7658
Batch 270, Loss: 0.7391
Batch 280, Loss: 0.7569
Batch 290, Loss: 0.7685
Batch 300, Loss: 0.7224
Batch 310, Loss: 0.7633
Batch 320, Loss: 0.7738
Batch 330, Loss: 0.7108
Batch 340, Loss: 0.7214
Batch 350, Loss: 0.7201
Batch 360, Loss: 0.7561
Batch 370, Loss: 0.7873
Batch 380, Loss: 0.7535
Batch 390, Loss: 0.7889
Epoch 138 learning rate: 0.021895831107393474
Epoch 138 time: 25.484066009521484 seconds
Epoch 138 accuracy: 71.09%
Batch 10, Loss: 0.7321
Batch 20, Loss: 0.6990
Batch 30, Loss: 0.6929
Batch 40, Loss: 0.6432
Batch 50, Loss: 0.7350
Batch 60, Loss: 0.7099
Batch 70, Loss: 0.7217
Batch 80, Loss: 0.6861
Batch 90, Loss: 0.7192
Batch 100, Loss: 0.7282
Batch 110, Loss: 0.6903
Batch 120, Loss: 0.6943
Batch 130, Loss: 0.7023
Batch 140, Loss: 0.6902
Batch 150, Loss: 0.7172
Batch 160, Loss: 0.7377
Batch 170, Loss: 0.7170
Batch 180, Loss: 0.7476
Batch 190, Loss: 0.7736
Batch 200, Loss: 0.7210
Batch 210, Loss: 0.6729
Batch 220, Loss: 0.7352
Batch 230, Loss: 0.7603
Batch 240, Loss: 0.6702
Batch 250, Loss: 0.7228
Batch 260, Loss: 0.7495
Batch 270, Loss: 0.6937
Batch 280, Loss: 0.7552
Batch 290, Loss: 0.7343
Batch 300, Loss: 0.7402
Batch 310, Loss: 0.7148
Batch 320, Loss: 0.7019
Batch 330, Loss: 0.7598
Batch 340, Loss: 0.7741
Batch 350, Loss: 0.7387
Batch 360, Loss: 0.7896
Batch 370, Loss: 0.7687
Batch 380, Loss: 0.7192
Batch 390, Loss: 0.7444
Epoch 139 learning rate: 0.02124973739783608
Epoch 139 time: 25.28571891784668 seconds
Epoch 139 accuracy: 71.52%
Batch 10, Loss: 0.7147
Batch 20, Loss: 0.6874
Batch 30, Loss: 0.6964
Batch 40, Loss: 0.6696
Batch 50, Loss: 0.7030
Batch 60, Loss: 0.7108
Batch 70, Loss: 0.7018
Batch 80, Loss: 0.6464
Batch 90, Loss: 0.6928
Batch 100, Loss: 0.7186
Batch 110, Loss: 0.6687
Batch 120, Loss: 0.6833
Batch 130, Loss: 0.7158
Batch 140, Loss: 0.7003
Batch 150, Loss: 0.6863
Batch 160, Loss: 0.7401
Batch 170, Loss: 0.7023
Batch 180, Loss: 0.6786
Batch 190, Loss: 0.7075
Batch 200, Loss: 0.6834
Batch 210, Loss: 0.7143
Batch 220, Loss: 0.7043
Batch 230, Loss: 0.6826
Batch 240, Loss: 0.7008
Batch 250, Loss: 0.6937
Batch 260, Loss: 0.7138
Batch 270, Loss: 0.7208
Batch 280, Loss: 0.7187
Batch 290, Loss: 0.7414
Batch 300, Loss: 0.7160
Batch 310, Loss: 0.7314
Batch 320, Loss: 0.6957
Batch 330, Loss: 0.7447
Batch 340, Loss: 0.7735
Batch 350, Loss: 0.7623
Batch 360, Loss: 0.7822
Batch 370, Loss: 0.7602
Batch 380, Loss: 0.7465
Batch 390, Loss: 0.7363
Epoch 140 learning rate: 0.02061073738537636
Epoch 140 time: 25.38957905769348 seconds
Epoch 140 accuracy: 72.51%
Batch 10, Loss: 0.6479
Batch 20, Loss: 0.6504
Batch 30, Loss: 0.6498
Batch 40, Loss: 0.6722
Batch 50, Loss: 0.7340
Batch 60, Loss: 0.6759
Batch 70, Loss: 0.6526
Batch 80, Loss: 0.6946
Batch 90, Loss: 0.6972
Batch 100, Loss: 0.6900
Batch 110, Loss: 0.6803
Batch 120, Loss: 0.6570
Batch 130, Loss: 0.6819
Batch 140, Loss: 0.7057
Batch 150, Loss: 0.7151
Batch 160, Loss: 0.7159
Batch 170, Loss: 0.6868
Batch 180, Loss: 0.7231
Batch 190, Loss: 0.6836
Batch 200, Loss: 0.6692
Batch 210, Loss: 0.7217
Batch 220, Loss: 0.6683
Batch 230, Loss: 0.7493
Batch 240, Loss: 0.7170
Batch 250, Loss: 0.6830
Batch 260, Loss: 0.6853
Batch 270, Loss: 0.7053
Batch 280, Loss: 0.7240
Batch 290, Loss: 0.7078
Batch 300, Loss: 0.7258
Batch 310, Loss: 0.6862
Batch 320, Loss: 0.7427
Batch 330, Loss: 0.7255
Batch 340, Loss: 0.7664
Batch 350, Loss: 0.7298
Batch 360, Loss: 0.7161
Batch 370, Loss: 0.7338
Batch 380, Loss: 0.7484
Batch 390, Loss: 0.7308
Epoch 141 learning rate: 0.019978988733705814
Epoch 141 time: 25.401008129119873 seconds
Epoch 141 accuracy: 72.15%
Batch 10, Loss: 0.6301
Batch 20, Loss: 0.6168
Batch 30, Loss: 0.7517
Batch 40, Loss: 0.6739
Batch 50, Loss: 0.6893
Batch 60, Loss: 0.6689
Batch 70, Loss: 0.6517
Batch 80, Loss: 0.7006
Batch 90, Loss: 0.6505
Batch 100, Loss: 0.6758
Batch 110, Loss: 0.6971
Batch 120, Loss: 0.6734
Batch 130, Loss: 0.6912
Batch 140, Loss: 0.6680
Batch 150, Loss: 0.6953
Batch 160, Loss: 0.6356
Batch 170, Loss: 0.6899
Batch 180, Loss: 0.6979
Batch 190, Loss: 0.7028
Batch 200, Loss: 0.6423
Batch 210, Loss: 0.6634
Batch 220, Loss: 0.7263
Batch 230, Loss: 0.6618
Batch 240, Loss: 0.6906
Batch 250, Loss: 0.6554
Batch 260, Loss: 0.7439
Batch 270, Loss: 0.6938
Batch 280, Loss: 0.7476
Batch 290, Loss: 0.6938
Batch 300, Loss: 0.7403
Batch 310, Loss: 0.7423
Batch 320, Loss: 0.7202
Batch 330, Loss: 0.7517
Batch 340, Loss: 0.6835
Batch 350, Loss: 0.6878
Batch 360, Loss: 0.6612
Batch 370, Loss: 0.7423
Batch 380, Loss: 0.7188
Batch 390, Loss: 0.7253
Epoch 142 learning rate: 0.01935464731735118
Epoch 142 time: 25.43363642692566 seconds
Epoch 142 accuracy: 72.02%
Batch 10, Loss: 0.5948
Batch 20, Loss: 0.6682
Batch 30, Loss: 0.6228
Batch 40, Loss: 0.6738
Batch 50, Loss: 0.6583
Batch 60, Loss: 0.6618
Batch 70, Loss: 0.6203
Batch 80, Loss: 0.6291
Batch 90, Loss: 0.6796
Batch 100, Loss: 0.6906
Batch 110, Loss: 0.6430
Batch 120, Loss: 0.7140
Batch 130, Loss: 0.7095
Batch 140, Loss: 0.6723
Batch 150, Loss: 0.6782
Batch 160, Loss: 0.6560
Batch 170, Loss: 0.6494
Batch 180, Loss: 0.6334
Batch 190, Loss: 0.6561
Batch 200, Loss: 0.6094
Batch 210, Loss: 0.6465
Batch 220, Loss: 0.6778
Batch 230, Loss: 0.6807
Batch 240, Loss: 0.6951
Batch 250, Loss: 0.6776
Batch 260, Loss: 0.7267
Batch 270, Loss: 0.7316
Batch 280, Loss: 0.6770
Batch 290, Loss: 0.7034
Batch 300, Loss: 0.6611
Batch 310, Loss: 0.7000
Batch 320, Loss: 0.7219
Batch 330, Loss: 0.7012
Batch 340, Loss: 0.7092
Batch 350, Loss: 0.7281
Batch 360, Loss: 0.7443
Batch 370, Loss: 0.7784
Batch 380, Loss: 0.7440
Batch 390, Loss: 0.7037
Epoch 143 learning rate: 0.018737867183214747
Epoch 143 time: 25.54516625404358 seconds
Epoch 143 accuracy: 72.99%
Batch 10, Loss: 0.6474
Batch 20, Loss: 0.6824
Batch 30, Loss: 0.6152
Batch 40, Loss: 0.5814
Batch 50, Loss: 0.6566
Batch 60, Loss: 0.6525
Batch 70, Loss: 0.6269
Batch 80, Loss: 0.6532
Batch 90, Loss: 0.6319
Batch 100, Loss: 0.6259
Batch 110, Loss: 0.6866
Batch 120, Loss: 0.6426
Batch 130, Loss: 0.6541
Batch 140, Loss: 0.6362
Batch 150, Loss: 0.7277
Batch 160, Loss: 0.6131
Batch 170, Loss: 0.6644
Batch 180, Loss: 0.6555
Batch 190, Loss: 0.6451
Batch 200, Loss: 0.6378
Batch 210, Loss: 0.6071
Batch 220, Loss: 0.6277
Batch 230, Loss: 0.6272
Batch 240, Loss: 0.6649
Batch 250, Loss: 0.6885
Batch 260, Loss: 0.6867
Batch 270, Loss: 0.6974
Batch 280, Loss: 0.6752
Batch 290, Loss: 0.6907
Batch 300, Loss: 0.6707
Batch 310, Loss: 0.6552
Batch 320, Loss: 0.6788
Batch 330, Loss: 0.6826
Batch 340, Loss: 0.6573
Batch 350, Loss: 0.6952
Batch 360, Loss: 0.6987
Batch 370, Loss: 0.6783
Batch 380, Loss: 0.7113
Batch 390, Loss: 0.6789
Epoch 144 learning rate: 0.01812880051256552
Epoch 144 time: 25.629385471343994 seconds
Epoch 144 accuracy: 73.54%
Batch 10, Loss: 0.6424
Batch 20, Loss: 0.6094
Batch 30, Loss: 0.6495
Batch 40, Loss: 0.6228
Batch 50, Loss: 0.6104
Batch 60, Loss: 0.6386
Batch 70, Loss: 0.6647
Batch 80, Loss: 0.5892
Batch 90, Loss: 0.6493
Batch 100, Loss: 0.6642
Batch 110, Loss: 0.6563
Batch 120, Loss: 0.6322
Batch 130, Loss: 0.6632
Batch 140, Loss: 0.6596
Batch 150, Loss: 0.6592
Batch 160, Loss: 0.6313
Batch 170, Loss: 0.6372
Batch 180, Loss: 0.6747
Batch 190, Loss: 0.6791
Batch 200, Loss: 0.6425
Batch 210, Loss: 0.6420
Batch 220, Loss: 0.6791
Batch 230, Loss: 0.6562
Batch 240, Loss: 0.6979
Batch 250, Loss: 0.6635
Batch 260, Loss: 0.6726
Batch 270, Loss: 0.6491
Batch 280, Loss: 0.6608
Batch 290, Loss: 0.6369
Batch 300, Loss: 0.6226
Batch 310, Loss: 0.6335
Batch 320, Loss: 0.6295
Batch 330, Loss: 0.7256
Batch 340, Loss: 0.6772
Batch 350, Loss: 0.6403
Batch 360, Loss: 0.6341
Batch 370, Loss: 0.7365
Batch 380, Loss: 0.6859
Batch 390, Loss: 0.6799
Epoch 145 learning rate: 0.017527597583490827
Epoch 145 time: 25.47382926940918 seconds
Epoch 145 accuracy: 73.0%
Batch 10, Loss: 0.5981
Batch 20, Loss: 0.6292
Batch 30, Loss: 0.6645
Batch 40, Loss: 0.5994
Batch 50, Loss: 0.6388
Batch 60, Loss: 0.6437
Batch 70, Loss: 0.6363
Batch 80, Loss: 0.5989
Batch 90, Loss: 0.6231
Batch 100, Loss: 0.6453
Batch 110, Loss: 0.6242
Batch 120, Loss: 0.6648
Batch 130, Loss: 0.6500
Batch 140, Loss: 0.6381
Batch 150, Loss: 0.6345
Batch 160, Loss: 0.6090
Batch 170, Loss: 0.6575
Batch 180, Loss: 0.6179
Batch 190, Loss: 0.6208
Batch 200, Loss: 0.6432
Batch 210, Loss: 0.6173
Batch 220, Loss: 0.6291
Batch 230, Loss: 0.6642
Batch 240, Loss: 0.6747
Batch 250, Loss: 0.6424
Batch 260, Loss: 0.6341
Batch 270, Loss: 0.6899
Batch 280, Loss: 0.6707
Batch 290, Loss: 0.7103
Batch 300, Loss: 0.6699
Batch 310, Loss: 0.6190
Batch 320, Loss: 0.6202
Batch 330, Loss: 0.6545
Batch 340, Loss: 0.6623
Batch 350, Loss: 0.6357
Batch 360, Loss: 0.6441
Batch 370, Loss: 0.5894
Batch 380, Loss: 0.6606
Batch 390, Loss: 0.6546
Epoch 146 learning rate: 0.01693440673381742
Epoch 146 time: 25.552114009857178 seconds
Epoch 146 accuracy: 73.83%
Batch 10, Loss: 0.6217
Batch 20, Loss: 0.5970
Batch 30, Loss: 0.5917
Batch 40, Loss: 0.5880
Batch 50, Loss: 0.5674
Batch 60, Loss: 0.5576
Batch 70, Loss: 0.6637
Batch 80, Loss: 0.6740
Batch 90, Loss: 0.6481
Batch 100, Loss: 0.6329
Batch 110, Loss: 0.5995
Batch 120, Loss: 0.6528
Batch 130, Loss: 0.6617
Batch 140, Loss: 0.6295
Batch 150, Loss: 0.6022
Batch 160, Loss: 0.6180
Batch 170, Loss: 0.6321
Batch 180, Loss: 0.6173
Batch 190, Loss: 0.6084
Batch 200, Loss: 0.6379
Batch 210, Loss: 0.6529
Batch 220, Loss: 0.6476
Batch 230, Loss: 0.6578
Batch 240, Loss: 0.6367
Batch 250, Loss: 0.7131
Batch 260, Loss: 0.6267
Batch 270, Loss: 0.6747
Batch 280, Loss: 0.6230
Batch 290, Loss: 0.5865
Batch 300, Loss: 0.6602
Batch 310, Loss: 0.7254
Batch 320, Loss: 0.6859
Batch 330, Loss: 0.6915
Batch 340, Loss: 0.6436
Batch 350, Loss: 0.6654
Batch 360, Loss: 0.6894
Batch 370, Loss: 0.6340
Batch 380, Loss: 0.6748
Batch 390, Loss: 0.6568
Epoch 147 learning rate: 0.016349374324511334
Epoch 147 time: 25.543423414230347 seconds
Epoch 147 accuracy: 73.0%
Batch 10, Loss: 0.6400
Batch 20, Loss: 0.6250
Batch 30, Loss: 0.5763
Batch 40, Loss: 0.5854
Batch 50, Loss: 0.6129
Batch 60, Loss: 0.5663
Batch 70, Loss: 0.5876
Batch 80, Loss: 0.5533
Batch 90, Loss: 0.6090
Batch 100, Loss: 0.6097
Batch 110, Loss: 0.5615
Batch 120, Loss: 0.5864
Batch 130, Loss: 0.5625
Batch 140, Loss: 0.6015
Batch 150, Loss: 0.6175
Batch 160, Loss: 0.6705
Batch 170, Loss: 0.5988
Batch 180, Loss: 0.6414
Batch 190, Loss: 0.6044
Batch 200, Loss: 0.6429
Batch 210, Loss: 0.6674
Batch 220, Loss: 0.6176
Batch 230, Loss: 0.5995
Batch 240, Loss: 0.6458
Batch 250, Loss: 0.5991
Batch 260, Loss: 0.6654
Batch 270, Loss: 0.6345
Batch 280, Loss: 0.6400
Batch 290, Loss: 0.5993
Batch 300, Loss: 0.6072
Batch 310, Loss: 0.6240
Batch 320, Loss: 0.5978
Batch 330, Loss: 0.6155
Batch 340, Loss: 0.6282
Batch 350, Loss: 0.6207
Batch 360, Loss: 0.6103
Batch 370, Loss: 0.6782
Batch 380, Loss: 0.6442
Batch 390, Loss: 0.6490
Epoch 148 learning rate: 0.01577264470356557
Epoch 148 time: 25.539341688156128 seconds
Epoch 148 accuracy: 73.52%
Batch 10, Loss: 0.6181
Batch 20, Loss: 0.6271
Batch 30, Loss: 0.6035
Batch 40, Loss: 0.5904
Batch 50, Loss: 0.5998
Batch 60, Loss: 0.6553
Batch 70, Loss: 0.5909
Batch 80, Loss: 0.5815
Batch 90, Loss: 0.5739
Batch 100, Loss: 0.6357
Batch 110, Loss: 0.6187
Batch 120, Loss: 0.5990
Batch 130, Loss: 0.5763
Batch 140, Loss: 0.6131
Batch 150, Loss: 0.5825
Batch 160, Loss: 0.6523
Batch 170, Loss: 0.6225
Batch 180, Loss: 0.5786
Batch 190, Loss: 0.6696
Batch 200, Loss: 0.6492
Batch 210, Loss: 0.5930
Batch 220, Loss: 0.6370
Batch 230, Loss: 0.6262
Batch 240, Loss: 0.6150
Batch 250, Loss: 0.6489
Batch 260, Loss: 0.5957
Batch 270, Loss: 0.6232
Batch 280, Loss: 0.6459
Batch 290, Loss: 0.5750
Batch 300, Loss: 0.6250
Batch 310, Loss: 0.6363
Batch 320, Loss: 0.5823
Batch 330, Loss: 0.6267
Batch 340, Loss: 0.5601
Batch 350, Loss: 0.5871
Batch 360, Loss: 0.6165
Batch 370, Loss: 0.6526
Batch 380, Loss: 0.6100
Batch 390, Loss: 0.6524
Epoch 149 learning rate: 0.01520436017038429
Epoch 149 time: 25.471628665924072 seconds
Epoch 149 accuracy: 73.39%
Batch 10, Loss: 0.5777
Batch 20, Loss: 0.5984
Batch 30, Loss: 0.5671
Batch 40, Loss: 0.6216
Batch 50, Loss: 0.5747
Batch 60, Loss: 0.5762
Batch 70, Loss: 0.5702
Batch 80, Loss: 0.5949
Batch 90, Loss: 0.5663
Batch 100, Loss: 0.5772
Batch 110, Loss: 0.5811
Batch 120, Loss: 0.5876
Batch 130, Loss: 0.5734
Batch 140, Loss: 0.6044
Batch 150, Loss: 0.6274
Batch 160, Loss: 0.5881
Batch 170, Loss: 0.6051
Batch 180, Loss: 0.5534
Batch 190, Loss: 0.6667
Batch 200, Loss: 0.5614
Batch 210, Loss: 0.5995
Batch 220, Loss: 0.6205
Batch 230, Loss: 0.5812
Batch 240, Loss: 0.5999
Batch 250, Loss: 0.6054
Batch 260, Loss: 0.6063
Batch 270, Loss: 0.6008
Batch 280, Loss: 0.5811
Batch 290, Loss: 0.6005
Batch 300, Loss: 0.6125
Batch 310, Loss: 0.5840
Batch 320, Loss: 0.6494
Batch 330, Loss: 0.5793
Batch 340, Loss: 0.6538
Batch 350, Loss: 0.6241
Batch 360, Loss: 0.6071
Batch 370, Loss: 0.6085
Batch 380, Loss: 0.6701
Batch 390, Loss: 0.6616
Epoch 150 learning rate: 0.014644660940672632
Epoch 150 time: 25.54648518562317 seconds
Epoch 150 accuracy: 74.22%
Batch 10, Loss: 0.5638
Batch 20, Loss: 0.5991
Batch 30, Loss: 0.5975
Batch 40, Loss: 0.5533
Batch 50, Loss: 0.5565
Batch 60, Loss: 0.6043
Batch 70, Loss: 0.5557
Batch 80, Loss: 0.6070
Batch 90, Loss: 0.5425
Batch 100, Loss: 0.5871
Batch 110, Loss: 0.5348
Batch 120, Loss: 0.5100
Batch 130, Loss: 0.5648
Batch 140, Loss: 0.5757
Batch 150, Loss: 0.5842
Batch 160, Loss: 0.6047
Batch 170, Loss: 0.6096
Batch 180, Loss: 0.5977
Batch 190, Loss: 0.5847
Batch 200, Loss: 0.5505
Batch 210, Loss: 0.5447
Batch 220, Loss: 0.5802
Batch 230, Loss: 0.5963
Batch 240, Loss: 0.5582
Batch 250, Loss: 0.5513
Batch 260, Loss: 0.5797
Batch 270, Loss: 0.6258
Batch 280, Loss: 0.6636
Batch 290, Loss: 0.5941
Batch 300, Loss: 0.5571
Batch 310, Loss: 0.5942
Batch 320, Loss: 0.5552
Batch 330, Loss: 0.5708
Batch 340, Loss: 0.6121
Batch 350, Loss: 0.5399
Batch 360, Loss: 0.6074
Batch 370, Loss: 0.5549
Batch 380, Loss: 0.6062
Batch 390, Loss: 0.6118
Epoch 151 learning rate: 0.01409368511184057
Epoch 151 time: 25.6165509223938 seconds
Epoch 151 accuracy: 74.13%
Batch 10, Loss: 0.5618
Batch 20, Loss: 0.5505
Batch 30, Loss: 0.5280
Batch 40, Loss: 0.5815
Batch 50, Loss: 0.5996
Batch 60, Loss: 0.5829
Batch 70, Loss: 0.5814
Batch 80, Loss: 0.5892
Batch 90, Loss: 0.5733
Batch 100, Loss: 0.5644
Batch 110, Loss: 0.5471
Batch 120, Loss: 0.5655
Batch 130, Loss: 0.5582
Batch 140, Loss: 0.5844
Batch 150, Loss: 0.5907
Batch 160, Loss: 0.5888
Batch 170, Loss: 0.5502
Batch 180, Loss: 0.5177
Batch 190, Loss: 0.5591
Batch 200, Loss: 0.5976
Batch 210, Loss: 0.5668
Batch 220, Loss: 0.6050
Batch 230, Loss: 0.5840
Batch 240, Loss: 0.5383
Batch 250, Loss: 0.5663
Batch 260, Loss: 0.5649
Batch 270, Loss: 0.5538
Batch 280, Loss: 0.5897
Batch 290, Loss: 0.5644
Batch 300, Loss: 0.5471
Batch 310, Loss: 0.5964
Batch 320, Loss: 0.6013
Batch 330, Loss: 0.5620
Batch 340, Loss: 0.5568
Batch 350, Loss: 0.5641
Batch 360, Loss: 0.5727
Batch 370, Loss: 0.6059
Batch 380, Loss: 0.6643
Batch 390, Loss: 0.5919
Epoch 152 learning rate: 0.013551568628929438
Epoch 152 time: 25.36618447303772 seconds
Epoch 152 accuracy: 74.36%
Batch 10, Loss: 0.5243
Batch 20, Loss: 0.5196
Batch 30, Loss: 0.5336
Batch 40, Loss: 0.5388
Batch 50, Loss: 0.5389
Batch 60, Loss: 0.5450
Batch 70, Loss: 0.5505
Batch 80, Loss: 0.5415
Batch 90, Loss: 0.5139
Batch 100, Loss: 0.5028
Batch 110, Loss: 0.5295
Batch 120, Loss: 0.5821
Batch 130, Loss: 0.5957
Batch 140, Loss: 0.5759
Batch 150, Loss: 0.5819
Batch 160, Loss: 0.5442
Batch 170, Loss: 0.5340
Batch 180, Loss: 0.5313
Batch 190, Loss: 0.5298
Batch 200, Loss: 0.5942
Batch 210, Loss: 0.5782
Batch 220, Loss: 0.5659
Batch 230, Loss: 0.5705
Batch 240, Loss: 0.5592
Batch 250, Loss: 0.5379
Batch 260, Loss: 0.5941
Batch 270, Loss: 0.6143
Batch 280, Loss: 0.5680
Batch 290, Loss: 0.5652
Batch 300, Loss: 0.5607
Batch 310, Loss: 0.5893
Batch 320, Loss: 0.5517
Batch 330, Loss: 0.5441
Batch 340, Loss: 0.6026
Batch 350, Loss: 0.6052
Batch 360, Loss: 0.5980
Batch 370, Loss: 0.5934
Batch 380, Loss: 0.5567
Batch 390, Loss: 0.5340
Epoch 153 learning rate: 0.013018445251069516
Epoch 153 time: 25.42663073539734 seconds
Epoch 153 accuracy: 74.9%
Batch 10, Loss: 0.5253
Batch 20, Loss: 0.5546
Batch 30, Loss: 0.5755
Batch 40, Loss: 0.5391
Batch 50, Loss: 0.5692
Batch 60, Loss: 0.5376
Batch 70, Loss: 0.5477
Batch 80, Loss: 0.5162
Batch 90, Loss: 0.5250
Batch 100, Loss: 0.5453
Batch 110, Loss: 0.5837
Batch 120, Loss: 0.5707
Batch 130, Loss: 0.5311
Batch 140, Loss: 0.5368
Batch 150, Loss: 0.5929
Batch 160, Loss: 0.5290
Batch 170, Loss: 0.5282
Batch 180, Loss: 0.5277
Batch 190, Loss: 0.5046
Batch 200, Loss: 0.5722
Batch 210, Loss: 0.5424
Batch 220, Loss: 0.5290
Batch 230, Loss: 0.5582
Batch 240, Loss: 0.5471
Batch 250, Loss: 0.5513
Batch 260, Loss: 0.5643
Batch 270, Loss: 0.5364
Batch 280, Loss: 0.5777
Batch 290, Loss: 0.5346
Batch 300, Loss: 0.5516
Batch 310, Loss: 0.5848
Batch 320, Loss: 0.5485
Batch 330, Loss: 0.5293
Batch 340, Loss: 0.5437
Batch 350, Loss: 0.5671
Batch 360, Loss: 0.4832
Batch 370, Loss: 0.5616
Batch 380, Loss: 0.5478
Batch 390, Loss: 0.5518
Epoch 154 learning rate: 0.012494446518477026
Epoch 154 time: 25.413405179977417 seconds
Epoch 154 accuracy: 74.1%
Batch 10, Loss: 0.5061
Batch 20, Loss: 0.5065
Batch 30, Loss: 0.4956
Batch 40, Loss: 0.4817
Batch 50, Loss: 0.5398
Batch 60, Loss: 0.5115
Batch 70, Loss: 0.5402
Batch 80, Loss: 0.4750
Batch 90, Loss: 0.5666
Batch 100, Loss: 0.5075
Batch 110, Loss: 0.5280
Batch 120, Loss: 0.5345
Batch 130, Loss: 0.5203
Batch 140, Loss: 0.5348
Batch 150, Loss: 0.5306
Batch 160, Loss: 0.5170
Batch 170, Loss: 0.4864
Batch 180, Loss: 0.5103
Batch 190, Loss: 0.5523
Batch 200, Loss: 0.5469
Batch 210, Loss: 0.5109
Batch 220, Loss: 0.5194
Batch 230, Loss: 0.5385
Batch 240, Loss: 0.5086
Batch 250, Loss: 0.5188
Batch 260, Loss: 0.5396
Batch 270, Loss: 0.5382
Batch 280, Loss: 0.5483
Batch 290, Loss: 0.5335
Batch 300, Loss: 0.5560
Batch 310, Loss: 0.5401
Batch 320, Loss: 0.5239
Batch 330, Loss: 0.5802
Batch 340, Loss: 0.5450
Batch 350, Loss: 0.5653
Batch 360, Loss: 0.5262
Batch 370, Loss: 0.5522
Batch 380, Loss: 0.5877
Batch 390, Loss: 0.5598
Epoch 155 learning rate: 0.011979701719998459
Epoch 155 time: 25.51110339164734 seconds
Epoch 155 accuracy: 74.8%
Batch 10, Loss: 0.4897
Batch 20, Loss: 0.5396
Batch 30, Loss: 0.5043
Batch 40, Loss: 0.4778
Batch 50, Loss: 0.4995
Batch 60, Loss: 0.4949
Batch 70, Loss: 0.5171
Batch 80, Loss: 0.4835
Batch 90, Loss: 0.4502
Batch 100, Loss: 0.5353
Batch 110, Loss: 0.4913
Batch 120, Loss: 0.5696
Batch 130, Loss: 0.4976
Batch 140, Loss: 0.4724
Batch 150, Loss: 0.5236
Batch 160, Loss: 0.5470
Batch 170, Loss: 0.4978
Batch 180, Loss: 0.5362
Batch 190, Loss: 0.5320
Batch 200, Loss: 0.4914
Batch 210, Loss: 0.5380
Batch 220, Loss: 0.5239
Batch 230, Loss: 0.5329
Batch 240, Loss: 0.5606
Batch 250, Loss: 0.5672
Batch 260, Loss: 0.5229
Batch 270, Loss: 0.5279
Batch 280, Loss: 0.5456
Batch 290, Loss: 0.5162
Batch 300, Loss: 0.5183
Batch 310, Loss: 0.5169
Batch 320, Loss: 0.4986
Batch 330, Loss: 0.5714
Batch 340, Loss: 0.5865
Batch 350, Loss: 0.5370
Batch 360, Loss: 0.5513
Batch 370, Loss: 0.5659
Batch 380, Loss: 0.5858
Batch 390, Loss: 0.5233
Epoch 156 learning rate: 0.011474337861210548
Epoch 156 time: 25.42031192779541 seconds
Epoch 156 accuracy: 75.54%
Batch 10, Loss: 0.4686
Batch 20, Loss: 0.4888
Batch 30, Loss: 0.5179
Batch 40, Loss: 0.4885
Batch 50, Loss: 0.5276
Batch 60, Loss: 0.5011
Batch 70, Loss: 0.5499
Batch 80, Loss: 0.4672
Batch 90, Loss: 0.5045
Batch 100, Loss: 0.5018
Batch 110, Loss: 0.5228
Batch 120, Loss: 0.4518
Batch 130, Loss: 0.5047
Batch 140, Loss: 0.4673
Batch 150, Loss: 0.5206
Batch 160, Loss: 0.5237
Batch 170, Loss: 0.5179
Batch 180, Loss: 0.5395
Batch 190, Loss: 0.4892
Batch 200, Loss: 0.5094
Batch 210, Loss: 0.4756
Batch 220, Loss: 0.5135
Batch 230, Loss: 0.5464
Batch 240, Loss: 0.5427
Batch 250, Loss: 0.5113
Batch 260, Loss: 0.4874
Batch 270, Loss: 0.4839
Batch 280, Loss: 0.5232
Batch 290, Loss: 0.5279
Batch 300, Loss: 0.5201
Batch 310, Loss: 0.5194
Batch 320, Loss: 0.5067
Batch 330, Loss: 0.5355
Batch 340, Loss: 0.5125
Batch 350, Loss: 0.4926
Batch 360, Loss: 0.5159
Batch 370, Loss: 0.5225
Batch 380, Loss: 0.5221
Batch 390, Loss: 0.5419
Epoch 157 learning rate: 0.010978479633083526
Epoch 157 time: 25.413724184036255 seconds
Epoch 157 accuracy: 75.62%
Batch 10, Loss: 0.4795
Batch 20, Loss: 0.4565
Batch 30, Loss: 0.4705
Batch 40, Loss: 0.4717
Batch 50, Loss: 0.5056
Batch 60, Loss: 0.4482
Batch 70, Loss: 0.5014
Batch 80, Loss: 0.5187
Batch 90, Loss: 0.4944
Batch 100, Loss: 0.4757
Batch 110, Loss: 0.5029
Batch 120, Loss: 0.4796
Batch 130, Loss: 0.5132
Batch 140, Loss: 0.4656
Batch 150, Loss: 0.4940
Batch 160, Loss: 0.4837
Batch 170, Loss: 0.4607
Batch 180, Loss: 0.5491
Batch 190, Loss: 0.5103
Batch 200, Loss: 0.5126
Batch 210, Loss: 0.4670
Batch 220, Loss: 0.4829
Batch 230, Loss: 0.5282
Batch 240, Loss: 0.5151
Batch 250, Loss: 0.4716
Batch 260, Loss: 0.5264
Batch 270, Loss: 0.4925
Batch 280, Loss: 0.4813
Batch 290, Loss: 0.4631
Batch 300, Loss: 0.4892
Batch 310, Loss: 0.5233
Batch 320, Loss: 0.5171
Batch 330, Loss: 0.5189
Batch 340, Loss: 0.5154
Batch 350, Loss: 0.4912
Batch 360, Loss: 0.5113
Batch 370, Loss: 0.4970
Batch 380, Loss: 0.5149
Batch 390, Loss: 0.5354
Epoch 158 learning rate: 0.010492249381215483
Epoch 158 time: 25.511781692504883 seconds
Epoch 158 accuracy: 75.2%
Batch 10, Loss: 0.4667
Batch 20, Loss: 0.4826
Batch 30, Loss: 0.4566
Batch 40, Loss: 0.4735
Batch 50, Loss: 0.4854
Batch 60, Loss: 0.4662
Batch 70, Loss: 0.4707
Batch 80, Loss: 0.4894
Batch 90, Loss: 0.4728
Batch 100, Loss: 0.4635
Batch 110, Loss: 0.5108
Batch 120, Loss: 0.4765
Batch 130, Loss: 0.5025
Batch 140, Loss: 0.4898
Batch 150, Loss: 0.4921
Batch 160, Loss: 0.4997
Batch 170, Loss: 0.4899
Batch 180, Loss: 0.4813
Batch 190, Loss: 0.4247
Batch 200, Loss: 0.5243
Batch 210, Loss: 0.4907
Batch 220, Loss: 0.5064
Batch 230, Loss: 0.4874
Batch 240, Loss: 0.4946
Batch 250, Loss: 0.4538
Batch 260, Loss: 0.5045
Batch 270, Loss: 0.5085
Batch 280, Loss: 0.5143
Batch 290, Loss: 0.5094
Batch 300, Loss: 0.4944
Batch 310, Loss: 0.4917
Batch 320, Loss: 0.5351
Batch 330, Loss: 0.4999
Batch 340, Loss: 0.5252
Batch 350, Loss: 0.5149
Batch 360, Loss: 0.5022
Batch 370, Loss: 0.4551
Batch 380, Loss: 0.5362
Batch 390, Loss: 0.4879
Epoch 159 learning rate: 0.010015767075645474
Epoch 159 time: 25.4272940158844 seconds
Epoch 159 accuracy: 76.19%
Batch 10, Loss: 0.4505
Batch 20, Loss: 0.4576
Batch 30, Loss: 0.4781
Batch 40, Loss: 0.4792
Batch 50, Loss: 0.5253
Batch 60, Loss: 0.4624
Batch 70, Loss: 0.4485
Batch 80, Loss: 0.4668
Batch 90, Loss: 0.4197
Batch 100, Loss: 0.5013
Batch 110, Loss: 0.4669
Batch 120, Loss: 0.4555
Batch 130, Loss: 0.4744
Batch 140, Loss: 0.4712
Batch 150, Loss: 0.4792
Batch 160, Loss: 0.4515
Batch 170, Loss: 0.4561
Batch 180, Loss: 0.4174
Batch 190, Loss: 0.4261
Batch 200, Loss: 0.4741
Batch 210, Loss: 0.4993
Batch 220, Loss: 0.4829
Batch 230, Loss: 0.5026
Batch 240, Loss: 0.5172
Batch 250, Loss: 0.4971
Batch 260, Loss: 0.4427
Batch 270, Loss: 0.4843
Batch 280, Loss: 0.4997
Batch 290, Loss: 0.4586
Batch 300, Loss: 0.5153
Batch 310, Loss: 0.4555
Batch 320, Loss: 0.4571
Batch 330, Loss: 0.5079
Batch 340, Loss: 0.5057
Batch 350, Loss: 0.5112
Batch 360, Loss: 0.4907
Batch 370, Loss: 0.5064
Batch 380, Loss: 0.5009
Batch 390, Loss: 0.4869
Epoch 160 learning rate: 0.009549150281252637
Epoch 160 time: 25.44170069694519 seconds
Epoch 160 accuracy: 75.73%
Batch 10, Loss: 0.4676
Batch 20, Loss: 0.4374
Batch 30, Loss: 0.4548
Batch 40, Loss: 0.4530
Batch 50, Loss: 0.4697
Batch 60, Loss: 0.4640
Batch 70, Loss: 0.4369
Batch 80, Loss: 0.4134
Batch 90, Loss: 0.4208
Batch 100, Loss: 0.4388
Batch 110, Loss: 0.4272
Batch 120, Loss: 0.4742
Batch 130, Loss: 0.4828
Batch 140, Loss: 0.4738
Batch 150, Loss: 0.4546
Batch 160, Loss: 0.4480
Batch 170, Loss: 0.4792
Batch 180, Loss: 0.4407
Batch 190, Loss: 0.4452
Batch 200, Loss: 0.4433
Batch 210, Loss: 0.4745
Batch 220, Loss: 0.4862
Batch 230, Loss: 0.4591
Batch 240, Loss: 0.4849
Batch 250, Loss: 0.4349
Batch 260, Loss: 0.4590
Batch 270, Loss: 0.4681
Batch 280, Loss: 0.4450
Batch 290, Loss: 0.4798
Batch 300, Loss: 0.4330
Batch 310, Loss: 0.4422
Batch 320, Loss: 0.4530
Batch 330, Loss: 0.4688
Batch 340, Loss: 0.4571
Batch 350, Loss: 0.5294
Batch 360, Loss: 0.4520
Batch 370, Loss: 0.4591
Batch 380, Loss: 0.4759
Batch 390, Loss: 0.4499
Epoch 161 learning rate: 0.00909251412874884
Epoch 161 time: 25.335784912109375 seconds
Epoch 161 accuracy: 76.09%
Batch 10, Loss: 0.4487
Batch 20, Loss: 0.4468
Batch 30, Loss: 0.4979
Batch 40, Loss: 0.4235
Batch 50, Loss: 0.4840
Batch 60, Loss: 0.4459
Batch 70, Loss: 0.4869
Batch 80, Loss: 0.4811
Batch 90, Loss: 0.4690
Batch 100, Loss: 0.4601
Batch 110, Loss: 0.4348
Batch 120, Loss: 0.4245
Batch 130, Loss: 0.4135
Batch 140, Loss: 0.4572
Batch 150, Loss: 0.4711
Batch 160, Loss: 0.4804
Batch 170, Loss: 0.4212
Batch 180, Loss: 0.4641
Batch 190, Loss: 0.4459
Batch 200, Loss: 0.4517
Batch 210, Loss: 0.4220
Batch 220, Loss: 0.4275
Batch 230, Loss: 0.4568
Batch 240, Loss: 0.4551
Batch 250, Loss: 0.4765
Batch 260, Loss: 0.4754
Batch 270, Loss: 0.4265
Batch 280, Loss: 0.4751
Batch 290, Loss: 0.4528
Batch 300, Loss: 0.4798
Batch 310, Loss: 0.4812
Batch 320, Loss: 0.4427
Batch 330, Loss: 0.4292
Batch 340, Loss: 0.4673
Batch 350, Loss: 0.4962
Batch 360, Loss: 0.4683
Batch 370, Loss: 0.4288
Batch 380, Loss: 0.4825
Batch 390, Loss: 0.4451
Epoch 162 learning rate: 0.008645971286271918
Epoch 162 time: 25.41301441192627 seconds
Epoch 162 accuracy: 75.66%
Batch 10, Loss: 0.4530
Batch 20, Loss: 0.4298
Batch 30, Loss: 0.4308
Batch 40, Loss: 0.4083
Batch 50, Loss: 0.4129
Batch 60, Loss: 0.4774
Batch 70, Loss: 0.4090
Batch 80, Loss: 0.4201
Batch 90, Loss: 0.4244
Batch 100, Loss: 0.4228
Batch 110, Loss: 0.4245
Batch 120, Loss: 0.4254
Batch 130, Loss: 0.4280
Batch 140, Loss: 0.4941
Batch 150, Loss: 0.4066
Batch 160, Loss: 0.4696
Batch 170, Loss: 0.4504
Batch 180, Loss: 0.4328
Batch 190, Loss: 0.4343
Batch 200, Loss: 0.4544
Batch 210, Loss: 0.4402
Batch 220, Loss: 0.4658
Batch 230, Loss: 0.4471
Batch 240, Loss: 0.4827
Batch 250, Loss: 0.4825
Batch 260, Loss: 0.4073
Batch 270, Loss: 0.4379
Batch 280, Loss: 0.4306
Batch 290, Loss: 0.4919
Batch 300, Loss: 0.4414
Batch 310, Loss: 0.4301
Batch 320, Loss: 0.4068
Batch 330, Loss: 0.4565
Batch 340, Loss: 0.4095
Batch 350, Loss: 0.4114
Batch 360, Loss: 0.4520
Batch 370, Loss: 0.4112
Batch 380, Loss: 0.4665
Batch 390, Loss: 0.4412
Epoch 163 learning rate: 0.008209631931586501
Epoch 163 time: 25.473368167877197 seconds
Epoch 163 accuracy: 76.65%
Batch 10, Loss: 0.4113
Batch 20, Loss: 0.4269
Batch 30, Loss: 0.4336
Batch 40, Loss: 0.4236
Batch 50, Loss: 0.4218
Batch 60, Loss: 0.3989
Batch 70, Loss: 0.3799
Batch 80, Loss: 0.4213
Batch 90, Loss: 0.4111
Batch 100, Loss: 0.4203
Batch 110, Loss: 0.4220
Batch 120, Loss: 0.4429
Batch 130, Loss: 0.4161
Batch 140, Loss: 0.4151
Batch 150, Loss: 0.4387
Batch 160, Loss: 0.4170
Batch 170, Loss: 0.3884
Batch 180, Loss: 0.4345
Batch 190, Loss: 0.4343
Batch 200, Loss: 0.4480
Batch 210, Loss: 0.3927
Batch 220, Loss: 0.4679
Batch 230, Loss: 0.4238
Batch 240, Loss: 0.4549
Batch 250, Loss: 0.4277
Batch 260, Loss: 0.4581
Batch 270, Loss: 0.4439
Batch 280, Loss: 0.4336
Batch 290, Loss: 0.4129
Batch 300, Loss: 0.4306
Batch 310, Loss: 0.4427
Batch 320, Loss: 0.4361
Batch 330, Loss: 0.4640
Batch 340, Loss: 0.4523
Batch 350, Loss: 0.4768
Batch 360, Loss: 0.4538
Batch 370, Loss: 0.4050
Batch 380, Loss: 0.4099
Batch 390, Loss: 0.4325
Epoch 164 learning rate: 0.0077836037248992605
Epoch 164 time: 25.409457206726074 seconds
Epoch 164 accuracy: 77.06%
Batch 10, Loss: 0.4182
Batch 20, Loss: 0.4418
Batch 30, Loss: 0.4191
Batch 40, Loss: 0.4087
Batch 50, Loss: 0.4121
Batch 60, Loss: 0.4242
Batch 70, Loss: 0.4003
Batch 80, Loss: 0.4161
Batch 90, Loss: 0.3934
Batch 100, Loss: 0.4314
Batch 110, Loss: 0.3901
Batch 120, Loss: 0.4361
Batch 130, Loss: 0.4702
Batch 140, Loss: 0.4268
Batch 150, Loss: 0.4179
Batch 160, Loss: 0.3614
Batch 170, Loss: 0.4404
Batch 180, Loss: 0.4199
Batch 190, Loss: 0.4468
Batch 200, Loss: 0.4114
Batch 210, Loss: 0.4105
Batch 220, Loss: 0.3967
Batch 230, Loss: 0.4332
Batch 240, Loss: 0.4272
Batch 250, Loss: 0.4143
Batch 260, Loss: 0.3860
Batch 270, Loss: 0.4371
Batch 280, Loss: 0.4444
Batch 290, Loss: 0.4159
Batch 300, Loss: 0.4036
Batch 310, Loss: 0.4269
Batch 320, Loss: 0.4210
Batch 330, Loss: 0.4056
Batch 340, Loss: 0.3969
Batch 350, Loss: 0.4141
Batch 360, Loss: 0.4599
Batch 370, Loss: 0.4032
Batch 380, Loss: 0.3917
Batch 390, Loss: 0.4220
Epoch 165 learning rate: 0.0073679917822954055
Epoch 165 time: 25.331207275390625 seconds
Epoch 165 accuracy: 77.0%
Batch 10, Loss: 0.4111
Batch 20, Loss: 0.4254
Batch 30, Loss: 0.4250
Batch 40, Loss: 0.3699
Batch 50, Loss: 0.4212
Batch 60, Loss: 0.3673
Batch 70, Loss: 0.3815
Batch 80, Loss: 0.4130
Batch 90, Loss: 0.4099
Batch 100, Loss: 0.3768
Batch 110, Loss: 0.4218
Batch 120, Loss: 0.3789
Batch 130, Loss: 0.3978
Batch 140, Loss: 0.4232
Batch 150, Loss: 0.4007
Batch 160, Loss: 0.3924
Batch 170, Loss: 0.4151
Batch 180, Loss: 0.4261
Batch 190, Loss: 0.3858
Batch 200, Loss: 0.4310
Batch 210, Loss: 0.4607
Batch 220, Loss: 0.3964
Batch 230, Loss: 0.4326
Batch 240, Loss: 0.3994
Batch 250, Loss: 0.4082
Batch 260, Loss: 0.4597
Batch 270, Loss: 0.4160
Batch 280, Loss: 0.4160
Batch 290, Loss: 0.4013
Batch 300, Loss: 0.4074
Batch 310, Loss: 0.4171
Batch 320, Loss: 0.4213
Batch 330, Loss: 0.4133
Batch 340, Loss: 0.4034
Batch 350, Loss: 0.3600
Batch 360, Loss: 0.4164
Batch 370, Loss: 0.4327
Batch 380, Loss: 0.4280
Batch 390, Loss: 0.4253
Epoch 166 learning rate: 0.006962898649802815
Epoch 166 time: 25.416260719299316 seconds
Epoch 166 accuracy: 76.66%
Batch 10, Loss: 0.4337
Batch 20, Loss: 0.4031
Batch 30, Loss: 0.3692
Batch 40, Loss: 0.4183
Batch 50, Loss: 0.3984
Batch 60, Loss: 0.3722
Batch 70, Loss: 0.3788
Batch 80, Loss: 0.3810
Batch 90, Loss: 0.4018
Batch 100, Loss: 0.4243
Batch 110, Loss: 0.3842
Batch 120, Loss: 0.3951
Batch 130, Loss: 0.4319
Batch 140, Loss: 0.3851
Batch 150, Loss: 0.4026
Batch 160, Loss: 0.4186
Batch 170, Loss: 0.4098
Batch 180, Loss: 0.4257
Batch 190, Loss: 0.4176
Batch 200, Loss: 0.4029
Batch 210, Loss: 0.4026
Batch 220, Loss: 0.3881
Batch 230, Loss: 0.4153
Batch 240, Loss: 0.4121
Batch 250, Loss: 0.3990
Batch 260, Loss: 0.4118
Batch 270, Loss: 0.3433
Batch 280, Loss: 0.3984
Batch 290, Loss: 0.4106
Batch 300, Loss: 0.4134
Batch 310, Loss: 0.4256
Batch 320, Loss: 0.4168
Batch 330, Loss: 0.4098
Batch 340, Loss: 0.4003
Batch 350, Loss: 0.3680
Batch 360, Loss: 0.3630
Batch 370, Loss: 0.4244
Batch 380, Loss: 0.4059
Batch 390, Loss: 0.3937
Epoch 167 learning rate: 0.006568424278090438
Epoch 167 time: 25.48615860939026 seconds
Epoch 167 accuracy: 77.0%
Batch 10, Loss: 0.3544
Batch 20, Loss: 0.4019
Batch 30, Loss: 0.3565
Batch 40, Loss: 0.3806
Batch 50, Loss: 0.3976
Batch 60, Loss: 0.3722
Batch 70, Loss: 0.3439
Batch 80, Loss: 0.3912
Batch 90, Loss: 0.4003
Batch 100, Loss: 0.3743
Batch 110, Loss: 0.4353
Batch 120, Loss: 0.3691
Batch 130, Loss: 0.3857
Batch 140, Loss: 0.3778
Batch 150, Loss: 0.3720
Batch 160, Loss: 0.4033
Batch 170, Loss: 0.3917
Batch 180, Loss: 0.4148
Batch 190, Loss: 0.4170
Batch 200, Loss: 0.3778
Batch 210, Loss: 0.4052
Batch 220, Loss: 0.3945
Batch 230, Loss: 0.3876
Batch 240, Loss: 0.4044
Batch 250, Loss: 0.4152
Batch 260, Loss: 0.3809
Batch 270, Loss: 0.3816
Batch 280, Loss: 0.4139
Batch 290, Loss: 0.4110
Batch 300, Loss: 0.3438
Batch 310, Loss: 0.3993
Batch 320, Loss: 0.3996
Batch 330, Loss: 0.4065
Batch 340, Loss: 0.3727
Batch 350, Loss: 0.3671
Batch 360, Loss: 0.3928
Batch 370, Loss: 0.4158
Batch 380, Loss: 0.4330
Batch 390, Loss: 0.4219
Epoch 168 learning rate: 0.006184665997806824
Epoch 168 time: 25.458715438842773 seconds
Epoch 168 accuracy: 76.97%
Batch 10, Loss: 0.3886
Batch 20, Loss: 0.3705
Batch 30, Loss: 0.3592
Batch 40, Loss: 0.3892
Batch 50, Loss: 0.3582
Batch 60, Loss: 0.3627
Batch 70, Loss: 0.3869
Batch 80, Loss: 0.3913
Batch 90, Loss: 0.3989
Batch 100, Loss: 0.3735
Batch 110, Loss: 0.4257
Batch 120, Loss: 0.3655
Batch 130, Loss: 0.4144
Batch 140, Loss: 0.4064
Batch 150, Loss: 0.3606
Batch 160, Loss: 0.3789
Batch 170, Loss: 0.4133
Batch 180, Loss: 0.3557
Batch 190, Loss: 0.3747
Batch 200, Loss: 0.3702
Batch 210, Loss: 0.3874
Batch 220, Loss: 0.3994
Batch 230, Loss: 0.3873
Batch 240, Loss: 0.4143
Batch 250, Loss: 0.4172
Batch 260, Loss: 0.4143
Batch 270, Loss: 0.3603
Batch 280, Loss: 0.4286
Batch 290, Loss: 0.3829
Batch 300, Loss: 0.3664
Batch 310, Loss: 0.4126
Batch 320, Loss: 0.4194
Batch 330, Loss: 0.4135
Batch 340, Loss: 0.3845
Batch 350, Loss: 0.4078
Batch 360, Loss: 0.3627
Batch 370, Loss: 0.3791
Batch 380, Loss: 0.3871
Batch 390, Loss: 0.4018
Epoch 169 learning rate: 0.00581171849556533
Epoch 169 time: 25.346027374267578 seconds
Epoch 169 accuracy: 77.39%
Batch 10, Loss: 0.3425
Batch 20, Loss: 0.3719
Batch 30, Loss: 0.3787
Batch 40, Loss: 0.3470
Batch 50, Loss: 0.3598
Batch 60, Loss: 0.3445
Batch 70, Loss: 0.3934
Batch 80, Loss: 0.3720
Batch 90, Loss: 0.4101
Batch 100, Loss: 0.3664
Batch 110, Loss: 0.3815
Batch 120, Loss: 0.3716
Batch 130, Loss: 0.3377
Batch 140, Loss: 0.3621
Batch 150, Loss: 0.3698
Batch 160, Loss: 0.3594
Batch 170, Loss: 0.3728
Batch 180, Loss: 0.3443
Batch 190, Loss: 0.3564
Batch 200, Loss: 0.3515
Batch 210, Loss: 0.3644
Batch 220, Loss: 0.3720
Batch 230, Loss: 0.3995
Batch 240, Loss: 0.3722
Batch 250, Loss: 0.3521
Batch 260, Loss: 0.3730
Batch 270, Loss: 0.3136
Batch 280, Loss: 0.4051
Batch 290, Loss: 0.3638
Batch 300, Loss: 0.3452
Batch 310, Loss: 0.3810
Batch 320, Loss: 0.3713
Batch 330, Loss: 0.3478
Batch 340, Loss: 0.3974
Batch 350, Loss: 0.3725
Batch 360, Loss: 0.3395
Batch 370, Loss: 0.3924
Batch 380, Loss: 0.3895
Batch 390, Loss: 0.3720
Epoch 170 learning rate: 0.0054496737905816136
Epoch 170 time: 25.408507823944092 seconds
Epoch 170 accuracy: 77.58%
Batch 10, Loss: 0.3621
Batch 20, Loss: 0.3808
Batch 30, Loss: 0.3485
Batch 40, Loss: 0.3474
Batch 50, Loss: 0.3703
Batch 60, Loss: 0.3590
Batch 70, Loss: 0.3458
Batch 80, Loss: 0.3825
Batch 90, Loss: 0.3250
Batch 100, Loss: 0.3453
Batch 110, Loss: 0.3870
Batch 120, Loss: 0.3696
Batch 130, Loss: 0.3416
Batch 140, Loss: 0.3560
Batch 150, Loss: 0.3449
Batch 160, Loss: 0.3736
Batch 170, Loss: 0.3908
Batch 180, Loss: 0.3821
Batch 190, Loss: 0.3472
Batch 200, Loss: 0.3583
Batch 210, Loss: 0.3964
Batch 220, Loss: 0.3440
Batch 230, Loss: 0.3626
Batch 240, Loss: 0.3630
Batch 250, Loss: 0.3674
Batch 260, Loss: 0.3594
Batch 270, Loss: 0.3585
Batch 280, Loss: 0.3878
Batch 290, Loss: 0.3662
Batch 300, Loss: 0.3383
Batch 310, Loss: 0.3961
Batch 320, Loss: 0.4088
Batch 330, Loss: 0.3431
Batch 340, Loss: 0.3748
Batch 350, Loss: 0.3988
Batch 360, Loss: 0.3265
Batch 370, Loss: 0.3337
Batch 380, Loss: 0.4062
Batch 390, Loss: 0.3306
Epoch 171 learning rate: 0.005098621211969226
Epoch 171 time: 25.478567361831665 seconds
Epoch 171 accuracy: 77.6%
Batch 10, Loss: 0.3573
Batch 20, Loss: 0.3352
Batch 30, Loss: 0.3140
Batch 40, Loss: 0.3632
Batch 50, Loss: 0.3684
Batch 60, Loss: 0.3021
Batch 70, Loss: 0.3653
Batch 80, Loss: 0.3624
Batch 90, Loss: 0.3612
Batch 100, Loss: 0.3724
Batch 110, Loss: 0.3730
Batch 120, Loss: 0.3425
Batch 130, Loss: 0.3696
Batch 140, Loss: 0.3435
Batch 150, Loss: 0.3407
Batch 160, Loss: 0.3692
Batch 170, Loss: 0.3457
Batch 180, Loss: 0.3533
Batch 190, Loss: 0.3519
Batch 200, Loss: 0.3721
Batch 210, Loss: 0.3361
Batch 220, Loss: 0.3637
Batch 230, Loss: 0.3582
Batch 240, Loss: 0.4132
Batch 250, Loss: 0.3514
Batch 260, Loss: 0.3460
Batch 270, Loss: 0.3654
Batch 280, Loss: 0.3447
Batch 290, Loss: 0.3093
Batch 300, Loss: 0.3637
Batch 310, Loss: 0.3108
Batch 320, Loss: 0.3735
Batch 330, Loss: 0.3610
Batch 340, Loss: 0.3491
Batch 350, Loss: 0.3549
Batch 360, Loss: 0.3650
Batch 370, Loss: 0.3388
Batch 380, Loss: 0.3841
Batch 390, Loss: 0.3942
Epoch 172 learning rate: 0.004758647376699035
Epoch 172 time: 25.48379111289978 seconds
Epoch 172 accuracy: 77.52%
Batch 10, Loss: 0.3432
Batch 20, Loss: 0.3222
Batch 30, Loss: 0.3360
Batch 40, Loss: 0.3362
Batch 50, Loss: 0.3870
Batch 60, Loss: 0.3797
Batch 70, Loss: 0.3779
Batch 80, Loss: 0.3275
Batch 90, Loss: 0.3286
Batch 100, Loss: 0.3655
Batch 110, Loss: 0.3536
Batch 120, Loss: 0.3538
Batch 130, Loss: 0.3450
Batch 140, Loss: 0.3387
Batch 150, Loss: 0.3186
Batch 160, Loss: 0.3469
Batch 170, Loss: 0.3166
Batch 180, Loss: 0.3338
Batch 190, Loss: 0.3326
Batch 200, Loss: 0.3607
Batch 210, Loss: 0.3171
Batch 220, Loss: 0.3312
Batch 230, Loss: 0.3660
Batch 240, Loss: 0.3383
Batch 250, Loss: 0.3441
Batch 260, Loss: 0.3474
Batch 270, Loss: 0.3455
Batch 280, Loss: 0.3336
Batch 290, Loss: 0.3545
Batch 300, Loss: 0.3426
Batch 310, Loss: 0.3350
Batch 320, Loss: 0.3569
Batch 330, Loss: 0.3438
Batch 340, Loss: 0.3977
Batch 350, Loss: 0.3096
Batch 360, Loss: 0.3139
Batch 370, Loss: 0.3446
Batch 380, Loss: 0.3671
Batch 390, Loss: 0.3596
Epoch 173 learning rate: 0.00442983616822775
Epoch 173 time: 25.496073007583618 seconds
Epoch 173 accuracy: 78.13%
Batch 10, Loss: 0.3357
Batch 20, Loss: 0.3133
Batch 30, Loss: 0.3352
Batch 40, Loss: 0.3480
Batch 50, Loss: 0.3244
Batch 60, Loss: 0.3545
Batch 70, Loss: 0.3551
Batch 80, Loss: 0.3363
Batch 90, Loss: 0.3194
Batch 100, Loss: 0.3412
Batch 110, Loss: 0.3217
Batch 120, Loss: 0.3032
Batch 130, Loss: 0.3177
Batch 140, Loss: 0.3509
Batch 150, Loss: 0.3248
Batch 160, Loss: 0.3739
Batch 170, Loss: 0.3345
Batch 180, Loss: 0.3793
Batch 190, Loss: 0.3440
Batch 200, Loss: 0.3267
Batch 210, Loss: 0.3307
Batch 220, Loss: 0.3628
Batch 230, Loss: 0.3413
Batch 240, Loss: 0.3397
Batch 250, Loss: 0.3459
Batch 260, Loss: 0.3537
Batch 270, Loss: 0.3113
Batch 280, Loss: 0.3618
Batch 290, Loss: 0.3898
Batch 300, Loss: 0.3215
Batch 310, Loss: 0.2997
Batch 320, Loss: 0.3237
Batch 330, Loss: 0.3450
Batch 340, Loss: 0.3093
Batch 350, Loss: 0.3777
Batch 360, Loss: 0.3364
Batch 370, Loss: 0.3308
Batch 380, Loss: 0.3222
Batch 390, Loss: 0.3301
Epoch 174 learning rate: 0.004112268715800957
Epoch 174 time: 25.63542127609253 seconds
Epoch 174 accuracy: 77.96%
Batch 10, Loss: 0.3276
Batch 20, Loss: 0.2958
Batch 30, Loss: 0.3276
Batch 40, Loss: 0.2981
Batch 50, Loss: 0.3263
Batch 60, Loss: 0.3171
Batch 70, Loss: 0.2911
Batch 80, Loss: 0.3328
Batch 90, Loss: 0.3263
Batch 100, Loss: 0.3404
Batch 110, Loss: 0.3151
Batch 120, Loss: 0.3202
Batch 130, Loss: 0.3026
Batch 140, Loss: 0.2823
Batch 150, Loss: 0.3327
Batch 160, Loss: 0.3163
Batch 170, Loss: 0.3135
Batch 180, Loss: 0.3046
Batch 190, Loss: 0.3319
Batch 200, Loss: 0.3246
Batch 210, Loss: 0.3518
Batch 220, Loss: 0.2951
Batch 230, Loss: 0.3608
Batch 240, Loss: 0.3490
Batch 250, Loss: 0.3288
Batch 260, Loss: 0.3034
Batch 270, Loss: 0.3346
Batch 280, Loss: 0.3155
Batch 290, Loss: 0.3195
Batch 300, Loss: 0.3293
Batch 310, Loss: 0.3314
Batch 320, Loss: 0.3253
Batch 330, Loss: 0.3171
Batch 340, Loss: 0.3298
Batch 350, Loss: 0.3000
Batch 360, Loss: 0.3422
Batch 370, Loss: 0.3369
Batch 380, Loss: 0.3805
Batch 390, Loss: 0.3185
Epoch 175 learning rate: 0.003806023374435677
Epoch 175 time: 25.526654720306396 seconds
Epoch 175 accuracy: 77.71%
Batch 10, Loss: 0.3326
Batch 20, Loss: 0.3369
Batch 30, Loss: 0.3265
Batch 40, Loss: 0.3253
Batch 50, Loss: 0.2778
Batch 60, Loss: 0.3426
Batch 70, Loss: 0.3516
Batch 80, Loss: 0.2976
Batch 90, Loss: 0.3390
Batch 100, Loss: 0.3176
Batch 110, Loss: 0.3192
Batch 120, Loss: 0.2931
Batch 130, Loss: 0.3207
Batch 140, Loss: 0.3331
Batch 150, Loss: 0.3015
Batch 160, Loss: 0.2992
Batch 170, Loss: 0.3126
Batch 180, Loss: 0.3397
Batch 190, Loss: 0.3573
Batch 200, Loss: 0.3126
Batch 210, Loss: 0.3222
Batch 220, Loss: 0.3292
Batch 230, Loss: 0.3395
Batch 240, Loss: 0.3190
Batch 250, Loss: 0.3255
Batch 260, Loss: 0.3117
Batch 270, Loss: 0.2999
Batch 280, Loss: 0.3382
Batch 290, Loss: 0.3222
Batch 300, Loss: 0.3048
Batch 310, Loss: 0.3439
Batch 320, Loss: 0.2995
Batch 330, Loss: 0.3293
Batch 340, Loss: 0.3310
Batch 350, Loss: 0.3027
Batch 360, Loss: 0.3184
Batch 370, Loss: 0.3241
Batch 380, Loss: 0.3378
Batch 390, Loss: 0.2931
Epoch 176 learning rate: 0.003511175705587435
Epoch 176 time: 25.611133575439453 seconds
Epoch 176 accuracy: 78.28%
Batch 10, Loss: 0.3288
Batch 20, Loss: 0.2741
Batch 30, Loss: 0.2934
Batch 40, Loss: 0.2986
Batch 50, Loss: 0.3215
Batch 60, Loss: 0.3108
Batch 70, Loss: 0.2879
Batch 80, Loss: 0.3225
Batch 90, Loss: 0.3396
Batch 100, Loss: 0.3311
Batch 110, Loss: 0.3192
Batch 120, Loss: 0.3160
Batch 130, Loss: 0.2944
Batch 140, Loss: 0.3258
Batch 150, Loss: 0.3197
Batch 160, Loss: 0.3210
Batch 170, Loss: 0.2812
Batch 180, Loss: 0.3252
Batch 190, Loss: 0.3144
Batch 200, Loss: 0.3332
Batch 210, Loss: 0.3256
Batch 220, Loss: 0.3104
Batch 230, Loss: 0.3034
Batch 240, Loss: 0.3532
Batch 250, Loss: 0.3136
Batch 260, Loss: 0.3230
Batch 270, Loss: 0.3349
Batch 280, Loss: 0.3121
Batch 290, Loss: 0.3220
Batch 300, Loss: 0.3106
Batch 310, Loss: 0.3067
Batch 320, Loss: 0.3214
Batch 330, Loss: 0.3118
Batch 340, Loss: 0.3145
Batch 350, Loss: 0.3108
Batch 360, Loss: 0.2886
Batch 370, Loss: 0.3230
Batch 380, Loss: 0.2964
Batch 390, Loss: 0.2986
Epoch 177 learning rate: 0.0032277984585066333
Epoch 177 time: 25.45513367652893 seconds
Epoch 177 accuracy: 78.25%
Batch 10, Loss: 0.2850
Batch 20, Loss: 0.2974
Batch 30, Loss: 0.3129
Batch 40, Loss: 0.3008
Batch 50, Loss: 0.3200
Batch 60, Loss: 0.3121
Batch 70, Loss: 0.2575
Batch 80, Loss: 0.3220
Batch 90, Loss: 0.2807
Batch 100, Loss: 0.3022
Batch 110, Loss: 0.3190
Batch 120, Loss: 0.3558
Batch 130, Loss: 0.2827
Batch 140, Loss: 0.3063
Batch 150, Loss: 0.3014
Batch 160, Loss: 0.3211
Batch 170, Loss: 0.2941
Batch 180, Loss: 0.3175
Batch 190, Loss: 0.2749
Batch 200, Loss: 0.3052
Batch 210, Loss: 0.3165
Batch 220, Loss: 0.3058
Batch 230, Loss: 0.2871
Batch 240, Loss: 0.2710
Batch 250, Loss: 0.2892
Batch 260, Loss: 0.3137
Batch 270, Loss: 0.3015
Batch 280, Loss: 0.3072
Batch 290, Loss: 0.2987
Batch 300, Loss: 0.3180
Batch 310, Loss: 0.3269
Batch 320, Loss: 0.3208
Batch 330, Loss: 0.3310
Batch 340, Loss: 0.3477
Batch 350, Loss: 0.3174
Batch 360, Loss: 0.3493
Batch 370, Loss: 0.3374
Batch 380, Loss: 0.2743
Batch 390, Loss: 0.2896
Epoch 178 learning rate: 0.002955961552288729
Epoch 178 time: 25.610667943954468 seconds
Epoch 178 accuracy: 78.22%
Batch 10, Loss: 0.3059
Batch 20, Loss: 0.3184
Batch 30, Loss: 0.3051
Batch 40, Loss: 0.2994
Batch 50, Loss: 0.2552
Batch 60, Loss: 0.2925
Batch 70, Loss: 0.3029
Batch 80, Loss: 0.2778
Batch 90, Loss: 0.3059
Batch 100, Loss: 0.2639
Batch 110, Loss: 0.3055
Batch 120, Loss: 0.2863
Batch 130, Loss: 0.2759
Batch 140, Loss: 0.3160
Batch 150, Loss: 0.3167
Batch 160, Loss: 0.3197
Batch 170, Loss: 0.3140
Batch 180, Loss: 0.2956
Batch 190, Loss: 0.3001
Batch 200, Loss: 0.3124
Batch 210, Loss: 0.2619
Batch 220, Loss: 0.2777
Batch 230, Loss: 0.2837
Batch 240, Loss: 0.2889
Batch 250, Loss: 0.3198
Batch 260, Loss: 0.2858
Batch 270, Loss: 0.3108
Batch 280, Loss: 0.3099
Batch 290, Loss: 0.2771
Batch 300, Loss: 0.2972
Batch 310, Loss: 0.2918
Batch 320, Loss: 0.2700
Batch 330, Loss: 0.2900
Batch 340, Loss: 0.2565
Batch 350, Loss: 0.2763
Batch 360, Loss: 0.2894
Batch 370, Loss: 0.2965
Batch 380, Loss: 0.2705
Batch 390, Loss: 0.2800
Epoch 179 learning rate: 0.0026957320586227366
Epoch 179 time: 25.521432638168335 seconds
Epoch 179 accuracy: 79.0%
Batch 10, Loss: 0.3088
Batch 20, Loss: 0.2904
Batch 30, Loss: 0.2669
Batch 40, Loss: 0.2907
Batch 50, Loss: 0.3054
Batch 60, Loss: 0.2941
Batch 70, Loss: 0.2520
Batch 80, Loss: 0.3030
Batch 90, Loss: 0.2967
Batch 100, Loss: 0.2934
Batch 110, Loss: 0.2957
Batch 120, Loss: 0.2837
Batch 130, Loss: 0.2575
Batch 140, Loss: 0.2791
Batch 150, Loss: 0.2967
Batch 160, Loss: 0.2850
Batch 170, Loss: 0.3101
Batch 180, Loss: 0.3109
Batch 190, Loss: 0.3148
Batch 200, Loss: 0.3011
Batch 210, Loss: 0.3021
Batch 220, Loss: 0.2883
Batch 230, Loss: 0.3015
Batch 240, Loss: 0.2982
Batch 250, Loss: 0.2846
Batch 260, Loss: 0.3076
Batch 270, Loss: 0.2650
Batch 280, Loss: 0.2866
Batch 290, Loss: 0.3060
Batch 300, Loss: 0.3023
Batch 310, Loss: 0.2823
Batch 320, Loss: 0.2974
Batch 330, Loss: 0.2572
Batch 340, Loss: 0.2673
Batch 350, Loss: 0.2957
Batch 360, Loss: 0.2982
Batch 370, Loss: 0.3052
Batch 380, Loss: 0.2940
Batch 390, Loss: 0.3009
Epoch 180 learning rate: 0.002447174185242325
Epoch 180 time: 25.546753644943237 seconds
Epoch 180 accuracy: 78.58%
Batch 10, Loss: 0.3016
Batch 20, Loss: 0.2917
Batch 30, Loss: 0.2914
Batch 40, Loss: 0.2462
Batch 50, Loss: 0.2778
Batch 60, Loss: 0.2896
Batch 70, Loss: 0.2777
Batch 80, Loss: 0.3051
Batch 90, Loss: 0.2831
Batch 100, Loss: 0.2643
Batch 110, Loss: 0.2517
Batch 120, Loss: 0.2899
Batch 130, Loss: 0.2731
Batch 140, Loss: 0.2931
Batch 150, Loss: 0.2557
Batch 160, Loss: 0.2616
Batch 170, Loss: 0.2988
Batch 180, Loss: 0.2810
Batch 190, Loss: 0.3119
Batch 200, Loss: 0.3153
Batch 210, Loss: 0.2862
Batch 220, Loss: 0.2618
Batch 230, Loss: 0.2874
Batch 240, Loss: 0.2788
Batch 250, Loss: 0.3204
Batch 260, Loss: 0.3019
Batch 270, Loss: 0.3029
Batch 280, Loss: 0.2730
Batch 290, Loss: 0.2889
Batch 300, Loss: 0.2758
Batch 310, Loss: 0.2675
Batch 320, Loss: 0.2821
Batch 330, Loss: 0.2905
Batch 340, Loss: 0.3240
Batch 350, Loss: 0.2874
Batch 360, Loss: 0.2913
Batch 370, Loss: 0.2897
Batch 380, Loss: 0.2586
Batch 390, Loss: 0.2766
Epoch 181 learning rate: 0.0022103492600834954
Epoch 181 time: 25.422783851623535 seconds
Epoch 181 accuracy: 79.13%
Batch 10, Loss: 0.2927
Batch 20, Loss: 0.2933
Batch 30, Loss: 0.2740
Batch 40, Loss: 0.2738
Batch 50, Loss: 0.2821
Batch 60, Loss: 0.2768
Batch 70, Loss: 0.2490
Batch 80, Loss: 0.2528
Batch 90, Loss: 0.2847
Batch 100, Loss: 0.2860
Batch 110, Loss: 0.2935
Batch 120, Loss: 0.2693
Batch 130, Loss: 0.2807
Batch 140, Loss: 0.2524
Batch 150, Loss: 0.2827
Batch 160, Loss: 0.2740
Batch 170, Loss: 0.3029
Batch 180, Loss: 0.2962
Batch 190, Loss: 0.2531
Batch 200, Loss: 0.2530
Batch 210, Loss: 0.2953
Batch 220, Loss: 0.2826
Batch 230, Loss: 0.3045
Batch 240, Loss: 0.2735
Batch 250, Loss: 0.2875
Batch 260, Loss: 0.2854
Batch 270, Loss: 0.2878
Batch 280, Loss: 0.3080
Batch 290, Loss: 0.2624
Batch 300, Loss: 0.2742
Batch 310, Loss: 0.2517
Batch 320, Loss: 0.2785
Batch 330, Loss: 0.2655
Batch 340, Loss: 0.2998
Batch 350, Loss: 0.2909
Batch 360, Loss: 0.2927
Batch 370, Loss: 0.2702
Batch 380, Loss: 0.3003
Batch 390, Loss: 0.2605
Epoch 182 learning rate: 0.0019853157161528537
Epoch 182 time: 25.54529905319214 seconds
Epoch 182 accuracy: 78.88%
Batch 10, Loss: 0.2498
Batch 20, Loss: 0.2595
Batch 30, Loss: 0.2708
Batch 40, Loss: 0.2430
Batch 50, Loss: 0.2728
Batch 60, Loss: 0.2866
Batch 70, Loss: 0.2531
Batch 80, Loss: 0.2715
Batch 90, Loss: 0.2539
Batch 100, Loss: 0.2601
Batch 110, Loss: 0.2560
Batch 120, Loss: 0.2741
Batch 130, Loss: 0.3160
Batch 140, Loss: 0.2629
Batch 150, Loss: 0.2847
Batch 160, Loss: 0.2786
Batch 170, Loss: 0.2638
Batch 180, Loss: 0.2854
Batch 190, Loss: 0.2896
Batch 200, Loss: 0.2863
Batch 210, Loss: 0.2617
Batch 220, Loss: 0.2815
Batch 230, Loss: 0.2888
Batch 240, Loss: 0.2554
Batch 250, Loss: 0.2765
Batch 260, Loss: 0.2895
Batch 270, Loss: 0.3117
Batch 280, Loss: 0.2684
Batch 290, Loss: 0.2507
Batch 300, Loss: 0.2470
Batch 310, Loss: 0.3050
Batch 320, Loss: 0.2607
Batch 330, Loss: 0.2905
Batch 340, Loss: 0.2714
Batch 350, Loss: 0.2483
Batch 360, Loss: 0.2618
Batch 370, Loss: 0.2420
Batch 380, Loss: 0.2773
Batch 390, Loss: 0.2727
Epoch 183 learning rate: 0.001772129077110103
Epoch 183 time: 25.504586458206177 seconds
Epoch 183 accuracy: 79.25%
Batch 10, Loss: 0.2760
Batch 20, Loss: 0.2482
Batch 30, Loss: 0.2773
Batch 40, Loss: 0.2553
Batch 50, Loss: 0.2958
Batch 60, Loss: 0.2612
Batch 70, Loss: 0.2308
Batch 80, Loss: 0.2608
Batch 90, Loss: 0.2502
Batch 100, Loss: 0.2389
Batch 110, Loss: 0.2902
Batch 120, Loss: 0.2612
Batch 130, Loss: 0.2708
Batch 140, Loss: 0.2697
Batch 150, Loss: 0.2645
Batch 160, Loss: 0.2482
Batch 170, Loss: 0.2683
Batch 180, Loss: 0.2765
Batch 190, Loss: 0.2432
Batch 200, Loss: 0.2653
Batch 210, Loss: 0.2755
Batch 220, Loss: 0.2719
Batch 230, Loss: 0.2559
Batch 240, Loss: 0.2675
Batch 250, Loss: 0.2774
Batch 260, Loss: 0.2648
Batch 270, Loss: 0.2624
Batch 280, Loss: 0.2847
Batch 290, Loss: 0.2776
Batch 300, Loss: 0.2693
Batch 310, Loss: 0.2919
Batch 320, Loss: 0.2728
Batch 330, Loss: 0.2944
Batch 340, Loss: 0.2969
Batch 350, Loss: 0.2746
Batch 360, Loss: 0.2459
Batch 370, Loss: 0.2665
Batch 380, Loss: 0.2758
Batch 390, Loss: 0.2452
Epoch 184 learning rate: 0.0015708419435684529
Epoch 184 time: 25.38232111930847 seconds
Epoch 184 accuracy: 79.41%
Batch 10, Loss: 0.2705
Batch 20, Loss: 0.2629
Batch 30, Loss: 0.2642
Batch 40, Loss: 0.2499
Batch 50, Loss: 0.2389
Batch 60, Loss: 0.2551
Batch 70, Loss: 0.2531
Batch 80, Loss: 0.2746
Batch 90, Loss: 0.2620
Batch 100, Loss: 0.2648
Batch 110, Loss: 0.2607
Batch 120, Loss: 0.2551
Batch 130, Loss: 0.2851
Batch 140, Loss: 0.2573
Batch 150, Loss: 0.2742
Batch 160, Loss: 0.2690
Batch 170, Loss: 0.2531
Batch 180, Loss: 0.2757
Batch 190, Loss: 0.2550
Batch 200, Loss: 0.2906
Batch 210, Loss: 0.2578
Batch 220, Loss: 0.2709
Batch 230, Loss: 0.2787
Batch 240, Loss: 0.2522
Batch 250, Loss: 0.2748
Batch 260, Loss: 0.2661
Batch 270, Loss: 0.2622
Batch 280, Loss: 0.2830
Batch 290, Loss: 0.2742
Batch 300, Loss: 0.2426
Batch 310, Loss: 0.2516
Batch 320, Loss: 0.2651
Batch 330, Loss: 0.2846
Batch 340, Loss: 0.2834
Batch 350, Loss: 0.2714
Batch 360, Loss: 0.2419
Batch 370, Loss: 0.2679
Batch 380, Loss: 0.2557
Batch 390, Loss: 0.2706
Epoch 185 learning rate: 0.0013815039801161732
Epoch 185 time: 25.390554666519165 seconds
Epoch 185 accuracy: 79.47%
Batch 10, Loss: 0.2687
Batch 20, Loss: 0.2372
Batch 30, Loss: 0.2892
Batch 40, Loss: 0.2870
Batch 50, Loss: 0.2669
Batch 60, Loss: 0.2215
Batch 70, Loss: 0.2407
Batch 80, Loss: 0.2769
Batch 90, Loss: 0.2548
Batch 100, Loss: 0.2725
Batch 110, Loss: 0.2602
Batch 120, Loss: 0.2436
Batch 130, Loss: 0.2548
Batch 140, Loss: 0.2316
Batch 150, Loss: 0.2420
Batch 160, Loss: 0.2643
Batch 170, Loss: 0.2620
Batch 180, Loss: 0.2482
Batch 190, Loss: 0.2745
Batch 200, Loss: 0.2500
Batch 210, Loss: 0.2523
Batch 220, Loss: 0.2735
Batch 230, Loss: 0.2688
Batch 240, Loss: 0.2853
Batch 250, Loss: 0.2500
Batch 260, Loss: 0.2721
Batch 270, Loss: 0.2771
Batch 280, Loss: 0.2688
Batch 290, Loss: 0.2615
Batch 300, Loss: 0.2677
Batch 310, Loss: 0.2316
Batch 320, Loss: 0.2579
Batch 330, Loss: 0.2706
Batch 340, Loss: 0.2687
Batch 350, Loss: 0.2516
Batch 360, Loss: 0.2499
Batch 370, Loss: 0.2708
Batch 380, Loss: 0.2648
Batch 390, Loss: 0.2702
Epoch 186 learning rate: 0.0012041619030626347
Epoch 186 time: 25.3860867023468 seconds
Epoch 186 accuracy: 79.46%
Batch 10, Loss: 0.2332
Batch 20, Loss: 0.2425
Batch 30, Loss: 0.2512
Batch 40, Loss: 0.2541
Batch 50, Loss: 0.2211
Batch 60, Loss: 0.2561
Batch 70, Loss: 0.2533
Batch 80, Loss: 0.2664
Batch 90, Loss: 0.2819
Batch 100, Loss: 0.2635
Batch 110, Loss: 0.2656
Batch 120, Loss: 0.2610
Batch 130, Loss: 0.2434
Batch 140, Loss: 0.2648
Batch 150, Loss: 0.2067
Batch 160, Loss: 0.2720
Batch 170, Loss: 0.2473
Batch 180, Loss: 0.2174
Batch 190, Loss: 0.2488
Batch 200, Loss: 0.2696
Batch 210, Loss: 0.2313
Batch 220, Loss: 0.2476
Batch 230, Loss: 0.2659
Batch 240, Loss: 0.2667
Batch 250, Loss: 0.2901
Batch 260, Loss: 0.2463
Batch 270, Loss: 0.2341
Batch 280, Loss: 0.2561
Batch 290, Loss: 0.2564
Batch 300, Loss: 0.2288
Batch 310, Loss: 0.2797
Batch 320, Loss: 0.2916
Batch 330, Loss: 0.2315
Batch 340, Loss: 0.2805
Batch 350, Loss: 0.2906
Batch 360, Loss: 0.2602
Batch 370, Loss: 0.2595
Batch 380, Loss: 0.2746
Batch 390, Loss: 0.2491
Epoch 187 learning rate: 0.0010388594689117077
Epoch 187 time: 25.43978261947632 seconds
Epoch 187 accuracy: 79.41%
Batch 10, Loss: 0.2384
Batch 20, Loss: 0.2666
Batch 30, Loss: 0.2407
Batch 40, Loss: 0.2400
Batch 50, Loss: 0.2346
Batch 60, Loss: 0.2301
Batch 70, Loss: 0.2513
Batch 80, Loss: 0.2598
Batch 90, Loss: 0.2251
Batch 100, Loss: 0.2522
Batch 110, Loss: 0.2449
Batch 120, Loss: 0.2496
Batch 130, Loss: 0.2201
Batch 140, Loss: 0.2574
Batch 150, Loss: 0.2446
Batch 160, Loss: 0.2585
Batch 170, Loss: 0.2379
Batch 180, Loss: 0.2423
Batch 190, Loss: 0.2509
Batch 200, Loss: 0.2540
Batch 210, Loss: 0.2647
Batch 220, Loss: 0.2429
Batch 230, Loss: 0.2485
Batch 240, Loss: 0.2216
Batch 250, Loss: 0.2573
Batch 260, Loss: 0.2697
Batch 270, Loss: 0.2555
Batch 280, Loss: 0.2762
Batch 290, Loss: 0.2294
Batch 300, Loss: 0.2666
Batch 310, Loss: 0.2444
Batch 320, Loss: 0.2641
Batch 330, Loss: 0.2521
Batch 340, Loss: 0.2549
Batch 350, Loss: 0.2346
Batch 360, Loss: 0.2635
Batch 370, Loss: 0.2294
Batch 380, Loss: 0.2698
Batch 390, Loss: 0.2744
Epoch 188 learning rate: 0.0008856374635655645
Epoch 188 time: 25.44325613975525 seconds
Epoch 188 accuracy: 79.78%
Batch 10, Loss: 0.2663
Batch 20, Loss: 0.2720
Batch 30, Loss: 0.2185
Batch 40, Loss: 0.2301
Batch 50, Loss: 0.2433
Batch 60, Loss: 0.2235
Batch 70, Loss: 0.2464
Batch 80, Loss: 0.2578
Batch 90, Loss: 0.2456
Batch 100, Loss: 0.2456
Batch 110, Loss: 0.2546
Batch 120, Loss: 0.2425
Batch 130, Loss: 0.2380
Batch 140, Loss: 0.2587
Batch 150, Loss: 0.2474
Batch 160, Loss: 0.2465
Batch 170, Loss: 0.2702
Batch 180, Loss: 0.2131
Batch 190, Loss: 0.2770
Batch 200, Loss: 0.2406
Batch 210, Loss: 0.2439
Batch 220, Loss: 0.2510
Batch 230, Loss: 0.2535
Batch 240, Loss: 0.2360
Batch 250, Loss: 0.2446
Batch 260, Loss: 0.2501
Batch 270, Loss: 0.2888
Batch 280, Loss: 0.2687
Batch 290, Loss: 0.2374
Batch 300, Loss: 0.2700
Batch 310, Loss: 0.2581
Batch 320, Loss: 0.2309
Batch 330, Loss: 0.2581
Batch 340, Loss: 0.2197
Batch 350, Loss: 0.2500
Batch 360, Loss: 0.2553
Batch 370, Loss: 0.2391
Batch 380, Loss: 0.2610
Batch 390, Loss: 0.2476
Epoch 189 learning rate: 0.000744533692261307
Epoch 189 time: 25.505409002304077 seconds
Epoch 189 accuracy: 79.7%
Batch 10, Loss: 0.2698
Batch 20, Loss: 0.2685
Batch 30, Loss: 0.2870
Batch 40, Loss: 0.2381
Batch 50, Loss: 0.2542
Batch 60, Loss: 0.2439
Batch 70, Loss: 0.2628
Batch 80, Loss: 0.2498
Batch 90, Loss: 0.2082
Batch 100, Loss: 0.2275
Batch 110, Loss: 0.2193
Batch 120, Loss: 0.2415
Batch 130, Loss: 0.2751
Batch 140, Loss: 0.2386
Batch 150, Loss: 0.2616
Batch 160, Loss: 0.2445
Batch 170, Loss: 0.2526
Batch 180, Loss: 0.2443
Batch 190, Loss: 0.2496
Batch 200, Loss: 0.2557
Batch 210, Loss: 0.2545
Batch 220, Loss: 0.2251
Batch 230, Loss: 0.2254
Batch 240, Loss: 0.2232
Batch 250, Loss: 0.2643
Batch 260, Loss: 0.2504
Batch 270, Loss: 0.2537
Batch 280, Loss: 0.2593
Batch 290, Loss: 0.2816
Batch 300, Loss: 0.2572
Batch 310, Loss: 0.2055
Batch 320, Loss: 0.2727
Batch 330, Loss: 0.2667
Batch 340, Loss: 0.2500
Batch 350, Loss: 0.2723
Batch 360, Loss: 0.2498
Batch 370, Loss: 0.2186
Batch 380, Loss: 0.2736
Batch 390, Loss: 0.2640
Epoch 190 learning rate: 0.0006155829702431174
Epoch 190 time: 25.33798885345459 seconds
Epoch 190 accuracy: 79.71%
Batch 10, Loss: 0.2164
Batch 20, Loss: 0.2614
Batch 30, Loss: 0.2849
Batch 40, Loss: 0.2260
Batch 50, Loss: 0.2033
Batch 60, Loss: 0.2260
Batch 70, Loss: 0.2281
Batch 80, Loss: 0.2521
Batch 90, Loss: 0.2470
Batch 100, Loss: 0.2761
Batch 110, Loss: 0.2487
Batch 120, Loss: 0.2525
Batch 130, Loss: 0.2777
Batch 140, Loss: 0.2302
Batch 150, Loss: 0.2247
Batch 160, Loss: 0.2446
Batch 170, Loss: 0.2602
Batch 180, Loss: 0.2512
Batch 190, Loss: 0.2434
Batch 200, Loss: 0.2675
Batch 210, Loss: 0.2404
Batch 220, Loss: 0.2495
Batch 230, Loss: 0.2435
Batch 240, Loss: 0.2500
Batch 250, Loss: 0.2468
Batch 260, Loss: 0.2482
Batch 270, Loss: 0.2477
Batch 280, Loss: 0.2611
Batch 290, Loss: 0.2248
Batch 300, Loss: 0.2500
Batch 310, Loss: 0.2238
Batch 320, Loss: 0.2673
Batch 330, Loss: 0.2536
Batch 340, Loss: 0.2447
Batch 350, Loss: 0.2585
Batch 360, Loss: 0.2476
Batch 370, Loss: 0.2545
Batch 380, Loss: 0.2499
Batch 390, Loss: 0.2674
Epoch 191 learning rate: 0.0004988171141721235
Epoch 191 time: 25.40111207962036 seconds
Epoch 191 accuracy: 79.83%
Batch 10, Loss: 0.2194
Batch 20, Loss: 0.2100
Batch 30, Loss: 0.2587
Batch 40, Loss: 0.2722
Batch 50, Loss: 0.1946
Batch 60, Loss: 0.2401
Batch 70, Loss: 0.2600
Batch 80, Loss: 0.2291
Batch 90, Loss: 0.2227
Batch 100, Loss: 0.2185
Batch 110, Loss: 0.2118
Batch 120, Loss: 0.2698
Batch 130, Loss: 0.2294
Batch 140, Loss: 0.2514
Batch 150, Loss: 0.2562
Batch 160, Loss: 0.2529
Batch 170, Loss: 0.2781
Batch 180, Loss: 0.2593
Batch 190, Loss: 0.2151
Batch 200, Loss: 0.2334
Batch 210, Loss: 0.2504
Batch 220, Loss: 0.2217
Batch 230, Loss: 0.2518
Batch 240, Loss: 0.2285
Batch 250, Loss: 0.2035
Batch 260, Loss: 0.2507
Batch 270, Loss: 0.2310
Batch 280, Loss: 0.2548
Batch 290, Loss: 0.2177
Batch 300, Loss: 0.2245
Batch 310, Loss: 0.2122
Batch 320, Loss: 0.2441
Batch 330, Loss: 0.2232
Batch 340, Loss: 0.2405
Batch 350, Loss: 0.2450
Batch 360, Loss: 0.2544
Batch 370, Loss: 0.2499
Batch 380, Loss: 0.2264
Batch 390, Loss: 0.2136
Epoch 192 learning rate: 0.00039426493427611206
Epoch 192 time: 25.42997145652771 seconds
Epoch 192 accuracy: 79.86%
Batch 10, Loss: 0.2338
Batch 20, Loss: 0.2407
Batch 30, Loss: 0.2225
Batch 40, Loss: 0.2655
Batch 50, Loss: 0.2581
Batch 60, Loss: 0.2249
Batch 70, Loss: 0.2182
Batch 80, Loss: 0.2474
Batch 90, Loss: 0.2321
Batch 100, Loss: 0.2642
Batch 110, Loss: 0.2212
Batch 120, Loss: 0.2470
Batch 130, Loss: 0.2429
Batch 140, Loss: 0.2420
Batch 150, Loss: 0.2674
Batch 160, Loss: 0.2763
Batch 170, Loss: 0.2544
Batch 180, Loss: 0.2262
Batch 190, Loss: 0.2272
Batch 200, Loss: 0.2248
Batch 210, Loss: 0.2711
Batch 220, Loss: 0.2088
Batch 230, Loss: 0.2591
Batch 240, Loss: 0.2560
Batch 250, Loss: 0.2456
Batch 260, Loss: 0.2246
Batch 270, Loss: 0.2435
Batch 280, Loss: 0.2238
Batch 290, Loss: 0.2459
Batch 300, Loss: 0.2261
Batch 310, Loss: 0.2648
Batch 320, Loss: 0.2257
Batch 330, Loss: 0.2676
Batch 340, Loss: 0.2574
Batch 350, Loss: 0.2397
Batch 360, Loss: 0.2367
Batch 370, Loss: 0.2419
Batch 380, Loss: 0.2692
Batch 390, Loss: 0.2575
Epoch 193 learning rate: 0.00030195222724102046
Epoch 193 time: 25.332942008972168 seconds
Epoch 193 accuracy: 80.0%
Batch 10, Loss: 0.2522
Batch 20, Loss: 0.2640
Batch 30, Loss: 0.2459
Batch 40, Loss: 0.2502
Batch 50, Loss: 0.2504
Batch 60, Loss: 0.2427
Batch 70, Loss: 0.2213
Batch 80, Loss: 0.2153
Batch 90, Loss: 0.2278
Batch 100, Loss: 0.2538
Batch 110, Loss: 0.2459
Batch 120, Loss: 0.2279
Batch 130, Loss: 0.2791
Batch 140, Loss: 0.2173
Batch 150, Loss: 0.2082
Batch 160, Loss: 0.2218
Batch 170, Loss: 0.2650
Batch 180, Loss: 0.2524
Batch 190, Loss: 0.2379
Batch 200, Loss: 0.2974
Batch 210, Loss: 0.2264
Batch 220, Loss: 0.2646
Batch 230, Loss: 0.2280
Batch 240, Loss: 0.2289
Batch 250, Loss: 0.2444
Batch 260, Loss: 0.2717
Batch 270, Loss: 0.2380
Batch 280, Loss: 0.2470
Batch 290, Loss: 0.2614
Batch 300, Loss: 0.2316
Batch 310, Loss: 0.2274
Batch 320, Loss: 0.2235
Batch 330, Loss: 0.2586
Batch 340, Loss: 0.2462
Batch 350, Loss: 0.2271
Batch 360, Loss: 0.2062
Batch 370, Loss: 0.2701
Batch 380, Loss: 0.2206
Batch 390, Loss: 0.2434
Epoch 194 learning rate: 0.00022190176984600036
Epoch 194 time: 25.401422023773193 seconds
Epoch 194 accuracy: 79.77%
Batch 10, Loss: 0.2681
Batch 20, Loss: 0.2281
Batch 30, Loss: 0.2343
Batch 40, Loss: 0.2535
Batch 50, Loss: 0.2409
Batch 60, Loss: 0.2241
Batch 70, Loss: 0.2456
Batch 80, Loss: 0.2293
Batch 90, Loss: 0.2061
Batch 100, Loss: 0.2456
Batch 110, Loss: 0.2320
Batch 120, Loss: 0.2201
Batch 130, Loss: 0.2129
Batch 140, Loss: 0.2241
Batch 150, Loss: 0.2323
Batch 160, Loss: 0.2485
Batch 170, Loss: 0.2264
Batch 180, Loss: 0.2725
Batch 190, Loss: 0.2060
Batch 200, Loss: 0.2375
Batch 210, Loss: 0.2332
Batch 220, Loss: 0.2586
Batch 230, Loss: 0.2393
Batch 240, Loss: 0.2477
Batch 250, Loss: 0.2465
Batch 260, Loss: 0.2428
Batch 270, Loss: 0.2395
Batch 280, Loss: 0.2480
Batch 290, Loss: 0.2491
Batch 300, Loss: 0.2477
Batch 310, Loss: 0.2214
Batch 320, Loss: 0.2337
Batch 330, Loss: 0.2533
Batch 340, Loss: 0.2382
Batch 350, Loss: 0.2056
Batch 360, Loss: 0.2633
Batch 370, Loss: 0.2593
Batch 380, Loss: 0.2239
Batch 390, Loss: 0.2224
Epoch 195 learning rate: 0.00015413331334360192
Epoch 195 time: 25.439127445220947 seconds
Epoch 195 accuracy: 79.77%
Batch 10, Loss: 0.2134
Batch 20, Loss: 0.2388
Batch 30, Loss: 0.2610
Batch 40, Loss: 0.2499
Batch 50, Loss: 0.2099
Batch 60, Loss: 0.2100
Batch 70, Loss: 0.2124
Batch 80, Loss: 0.2314
Batch 90, Loss: 0.2328
Batch 100, Loss: 0.2327
Batch 110, Loss: 0.2265
Batch 120, Loss: 0.2351
Batch 130, Loss: 0.2268
Batch 140, Loss: 0.2104
Batch 150, Loss: 0.2404
Batch 160, Loss: 0.2522
Batch 170, Loss: 0.2656
Batch 180, Loss: 0.2442
Batch 190, Loss: 0.2804
Batch 200, Loss: 0.2423
Batch 210, Loss: 0.2635
Batch 220, Loss: 0.2449
Batch 230, Loss: 0.2069
Batch 240, Loss: 0.2175
Batch 250, Loss: 0.2509
Batch 260, Loss: 0.2416
Batch 270, Loss: 0.2088
Batch 280, Loss: 0.2554
Batch 290, Loss: 0.2340
Batch 300, Loss: 0.2401
Batch 310, Loss: 0.2590
Batch 320, Loss: 0.2483
Batch 330, Loss: 0.2741
Batch 340, Loss: 0.2245
Batch 350, Loss: 0.2567
Batch 360, Loss: 0.2381
Batch 370, Loss: 0.2235
Batch 380, Loss: 0.2526
Batch 390, Loss: 0.2215
Epoch 196 learning rate: 9.866357858642213e-05
Epoch 196 time: 25.388904809951782 seconds
Epoch 196 accuracy: 79.84%
Batch 10, Loss: 0.2496
Batch 20, Loss: 0.2635
Batch 30, Loss: 0.2347
Batch 40, Loss: 0.2450
Batch 50, Loss: 0.2609
Batch 60, Loss: 0.2274
Batch 70, Loss: 0.2337
Batch 80, Loss: 0.2142
Batch 90, Loss: 0.2104
Batch 100, Loss: 0.2712
Batch 110, Loss: 0.2352
Batch 120, Loss: 0.2330
Batch 130, Loss: 0.2550
Batch 140, Loss: 0.2355
Batch 150, Loss: 0.2412
Batch 160, Loss: 0.2296
Batch 170, Loss: 0.2179
Batch 180, Loss: 0.2248
Batch 190, Loss: 0.2389
Batch 200, Loss: 0.2241
Batch 210, Loss: 0.2474
Batch 220, Loss: 0.2708
Batch 230, Loss: 0.2588
Batch 240, Loss: 0.2252
Batch 250, Loss: 0.2263
Batch 260, Loss: 0.2143
Batch 270, Loss: 0.2338
Batch 280, Loss: 0.2250
Batch 290, Loss: 0.2285
Batch 300, Loss: 0.2632
Batch 310, Loss: 0.2376
Batch 320, Loss: 0.2268
Batch 330, Loss: 0.2481
Batch 340, Loss: 0.2607
Batch 350, Loss: 0.2198
Batch 360, Loss: 0.2584
Batch 370, Loss: 0.2225
Batch 380, Loss: 0.2483
Batch 390, Loss: 0.2461
Epoch 197 learning rate: 5.5506251901504864e-05
Epoch 197 time: 25.462496757507324 seconds
Epoch 197 accuracy: 80.06%
Batch 10, Loss: 0.2167
Batch 20, Loss: 0.2597
Batch 30, Loss: 0.2198
Batch 40, Loss: 0.2572
Batch 50, Loss: 0.2292
Batch 60, Loss: 0.2263
Batch 70, Loss: 0.2350
Batch 80, Loss: 0.2191
Batch 90, Loss: 0.2299
Batch 100, Loss: 0.2440
Batch 110, Loss: 0.2357
Batch 120, Loss: 0.2338
Batch 130, Loss: 0.2413
Batch 140, Loss: 0.2286
Batch 150, Loss: 0.2451
Batch 160, Loss: 0.2321
Batch 170, Loss: 0.2692
Batch 180, Loss: 0.2302
Batch 190, Loss: 0.2280
Batch 200, Loss: 0.2252
Batch 210, Loss: 0.2277
Batch 220, Loss: 0.1966
Batch 230, Loss: 0.2076
Batch 240, Loss: 0.2361
Batch 250, Loss: 0.2342
Batch 260, Loss: 0.2464
Batch 270, Loss: 0.2671
Batch 280, Loss: 0.2211
Batch 290, Loss: 0.2394
Batch 300, Loss: 0.2598
Batch 310, Loss: 0.2402
Batch 320, Loss: 0.2372
Batch 330, Loss: 0.2348
Batch 340, Loss: 0.2303
Batch 350, Loss: 0.2071
Batch 360, Loss: 0.2463
Batch 370, Loss: 0.2008
Batch 380, Loss: 0.2508
Batch 390, Loss: 0.2186
Epoch 198 learning rate: 2.4671981713420017e-05
Epoch 198 time: 25.33262062072754 seconds
Epoch 198 accuracy: 79.96%
Batch 10, Loss: 0.2230
Batch 20, Loss: 0.2476
Batch 30, Loss: 0.2324
Batch 40, Loss: 0.2203
Batch 50, Loss: 0.2600
Batch 60, Loss: 0.2300
Batch 70, Loss: 0.2638
Batch 80, Loss: 0.2507
Batch 90, Loss: 0.2408
Batch 100, Loss: 0.2439
Batch 110, Loss: 0.2221
Batch 120, Loss: 0.2562
Batch 130, Loss: 0.2190
Batch 140, Loss: 0.2361
Batch 150, Loss: 0.2477
Batch 160, Loss: 0.2260
Batch 170, Loss: 0.2443
Batch 180, Loss: 0.2673
Batch 190, Loss: 0.2411
Batch 200, Loss: 0.2398
Batch 210, Loss: 0.2178
Batch 220, Loss: 0.2427
Batch 230, Loss: 0.2397
Batch 240, Loss: 0.2252
Batch 250, Loss: 0.2197
Batch 260, Loss: 0.2367
Batch 270, Loss: 0.2630
Batch 280, Loss: 0.2482
Batch 290, Loss: 0.2293
Batch 300, Loss: 0.2471
Batch 310, Loss: 0.2193
Batch 320, Loss: 0.2280
Batch 330, Loss: 0.2193
Batch 340, Loss: 0.2446
Batch 350, Loss: 0.2437
Batch 360, Loss: 0.2421
Batch 370, Loss: 0.2305
Batch 380, Loss: 0.2702
Batch 390, Loss: 0.2428
Epoch 199 learning rate: 6.168375916970619e-06
Epoch 199 time: 25.38903522491455 seconds
Epoch 199 accuracy: 79.99%
Batch 10, Loss: 0.2549
Batch 20, Loss: 0.2276
Batch 30, Loss: 0.2144
Batch 40, Loss: 0.2318
Batch 50, Loss: 0.2832
Batch 60, Loss: 0.2338
Batch 70, Loss: 0.2270
Batch 80, Loss: 0.2742
Batch 90, Loss: 0.2375
Batch 100, Loss: 0.2149
Batch 110, Loss: 0.2438
Batch 120, Loss: 0.2470
Batch 130, Loss: 0.2177
Batch 140, Loss: 0.2241
Batch 150, Loss: 0.2646
Batch 160, Loss: 0.2312
Batch 170, Loss: 0.2313
Batch 180, Loss: 0.2694
Batch 190, Loss: 0.2452
Batch 200, Loss: 0.2355
Batch 210, Loss: 0.2094
Batch 220, Loss: 0.2205
Batch 230, Loss: 0.2328
Batch 240, Loss: 0.2369
Batch 250, Loss: 0.2064
Batch 260, Loss: 0.2364
Batch 270, Loss: 0.2295
Batch 280, Loss: 0.2455
Batch 290, Loss: 0.2505
Batch 300, Loss: 0.2571
Batch 310, Loss: 0.2208
Batch 320, Loss: 0.2615
Batch 330, Loss: 0.2579
Batch 340, Loss: 0.2401
Batch 350, Loss: 0.2453
Batch 360, Loss: 0.2326
Batch 370, Loss: 0.2413
Batch 380, Loss: 0.2295
Batch 390, Loss: 0.2439
Epoch 200 learning rate: 0.0
Epoch 200 time: 25.491300582885742 seconds
Epoch 200 accuracy: 79.88%
Total training time: 5104.575213432312 seconds
