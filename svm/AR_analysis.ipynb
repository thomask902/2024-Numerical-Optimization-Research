{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and graphing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Chart Function\n",
    "def plot_results(file_paths, labels):\n",
    "    \"\"\"\n",
    "    Plots various metrics from machine learning training runs.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths: List of strings representing the file paths to CSV files.\n",
    "    - labels: List of strings representing the labels for each dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read DataFrames\n",
    "    dataframes = [pd.read_csv(fp) for fp in file_paths]\n",
    "    num_datasets = len(dataframes)\n",
    "\n",
    "    # Extract data\n",
    "    epochs_list = [df['Epoch'] for df in dataframes]\n",
    "    test_accuracy_list = [df['Test Accuracy'] for df in dataframes]\n",
    "    test_error_list = [df['Test Error'] for df in dataframes]\n",
    "    training_loss_list = [df['Training Loss'] for df in dataframes]\n",
    "    test_loss_list = [df['Test Loss'] for df in dataframes]\n",
    "    x_k_list = [df['x_k Comparison'] if 'x_k Comparison' in df.columns else pd.Series([0] * len(df)) for df in dataframes]\n",
    "    x_ag_k_list = [df['x_ag_k Comparison'] if 'x_ag_k Comparison' in df.columns else pd.Series([0] * len(df)) for df in dataframes]\n",
    "\n",
    "    # Square the gradient norms\n",
    "    training_grad_norm_squared_list = [df['Training Gradient Norm']**2 for df in dataframes]\n",
    "    test_grad_norm_squared_list = [df['Test Gradient Norm']**2 for df in dataframes]\n",
    "    total_training_time_list = [df['Training Time (s)'].cumsum() for df in dataframes]\n",
    "\n",
    "    # Check if Epochs are the same across datasets\n",
    "    epoch_lengths = [len(e) for e in epochs_list]\n",
    "    max_epochs = max(epoch_lengths)\n",
    "    if len(set(epoch_lengths)) > 1:\n",
    "        print(f\"Warning: Epochs in dataset(s) differ from the longest dataset.\")\n",
    "\n",
    "    # Set up colors using a colormap\n",
    "    cmap_name = 'tab10' if num_datasets <= 10 else 'tab20'\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    colors = [cmap(i % cmap.N) for i in range(num_datasets)]\n",
    "\n",
    "    # Create subplots with 7 rows and 2 columns\n",
    "    fig, axes = plt.subplots(7, 2, figsize=(20, 38))\n",
    "\n",
    "    # Row 1: Test Accuracy over Epochs and Training Time\n",
    "    # Plot 1: Test Accuracy over Epochs (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[0, 0].plot(epochs_list[i], test_accuracy_list[i], label=labels[i], color=colors[i])\n",
    "    axes[0, 0].axhline(y=0.68, color='gray', linestyle='--', linewidth=1)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Test Accuracy')\n",
    "    axes[0, 0].set_title(f'Test Accuracy over {max_epochs} Epochs')\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "    # Plot 2: Test Accuracy vs Total Training Time (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[0, 1].plot(total_training_time_list[i], test_accuracy_list[i], label=labels[i], color=colors[i])\n",
    "    axes[0, 1].axhline(y=0.68, color='gray', linestyle='--', linewidth=1)\n",
    "    axes[0, 1].set_xlabel('Training Time (s)')\n",
    "    axes[0, 1].set_ylabel('Test Accuracy')\n",
    "    axes[0, 1].set_title('Test Accuracy vs Total Training Time')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Row 2: Training Loss over Epochs and Test Loss over Epochs\n",
    "    # Plot 3: Training Loss over Epochs (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[1, 0].plot(epochs_list[i], training_loss_list[i], label=labels[i], color=colors[i])\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Training Loss')\n",
    "    axes[1, 0].set_title(f'Training Loss over {max_epochs} Epochs')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Plot 4: Test Loss over Epochs (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[1, 1].plot(epochs_list[i], test_loss_list[i], label=labels[i], color=colors[i])\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Test Loss')\n",
    "    axes[1, 1].set_title(f'Test Loss over {max_epochs} Epochs')\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "    # Row 3: Training Gradient Norm Squared over Epochs and Test Gradient Norm Squared over Epochs\n",
    "    # Plot 5: Training Gradient Norm Squared over Epochs (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[2, 0].plot(epochs_list[i], training_grad_norm_squared_list[i], label=labels[i], color=colors[i])\n",
    "    axes[2, 0].set_xlabel('Epoch')\n",
    "    axes[2, 0].set_ylabel('Gradient Norm Squared')\n",
    "    axes[2, 0].set_title(f'Training Gradient Norm Squared over {max_epochs} Epochs')\n",
    "    axes[2, 0].legend()\n",
    "\n",
    "    # Plot 6: Test Gradient Norm Squared over Epochs (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[2, 1].plot(epochs_list[i], test_grad_norm_squared_list[i], label=labels[i], color=colors[i])\n",
    "    axes[2, 1].set_xlabel('Epoch')\n",
    "    axes[2, 1].set_ylabel('Gradient Norm Squared')\n",
    "    axes[2, 1].set_title(f'Test Gradient Norm Squared over {max_epochs} Epochs')\n",
    "    axes[2, 1].legend()\n",
    "\n",
    "    # Row 4: Training Loss vs Total Training Time and Test Loss vs Total Training Time\n",
    "    # Plot 7: Training Loss vs Total Training Time (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[3, 0].plot(total_training_time_list[i], training_loss_list[i], label=labels[i], color=colors[i])\n",
    "    axes[3, 0].set_xlabel('Training Time (s)')\n",
    "    axes[3, 0].set_ylabel('Training Loss')\n",
    "    axes[3, 0].set_title('Training Loss vs Total Training Time')\n",
    "    axes[3, 0].legend()\n",
    "\n",
    "    # Plot 8: Test Loss vs Total Training Time (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[3, 1].plot(total_training_time_list[i], test_loss_list[i], label=labels[i], color=colors[i])\n",
    "    axes[3, 1].set_xlabel('Training Time (s)')\n",
    "    axes[3, 1].set_ylabel('Test Loss')\n",
    "    axes[3, 1].set_title('Test Loss vs Total Training Time')\n",
    "    axes[3, 1].legend()\n",
    "\n",
    "    # Row 5: Training Gradient Norm Squared vs Total Training Time and Test Gradient Norm Squared vs Total Training Time\n",
    "    # Plot 9: Training Gradient Norm Squared vs Total Training Time (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[4, 0].plot(total_training_time_list[i], training_grad_norm_squared_list[i], label=labels[i], color=colors[i])\n",
    "    axes[4, 0].set_xlabel('Training Time (s)')\n",
    "    axes[4, 0].set_ylabel('Gradient Norm Squared')\n",
    "    axes[4, 0].set_title('Training Gradient Norm Squared vs Total Training Time')\n",
    "    axes[4, 0].legend()\n",
    "\n",
    "    # Plot 10: Test Gradient Norm Squared vs Total Training Time (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[4, 1].plot(total_training_time_list[i], test_grad_norm_squared_list[i], label=labels[i], color=colors[i])\n",
    "    axes[4, 1].set_xlabel('Training Time (s)')\n",
    "    axes[4, 1].set_ylabel('Gradient Norm Squared')\n",
    "    axes[4, 1].set_title('Test Gradient Norm Squared vs Total Training Time')\n",
    "    axes[4, 1].legend()\n",
    "\n",
    "    # Row 6: Test Error Rate over Epochs and Training Time\n",
    "    # Plot 11: Test Error Rate vs Epoch (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[5, 0].plot(epochs_list[i], test_error_list[i], label=labels[i], color=colors[i])\n",
    "    axes[5, 0].set_xlabel('Epoch')\n",
    "    axes[5, 0].set_ylabel('Test Error')\n",
    "    axes[5, 0].set_title(f'Test Error over {max_epochs} Epochs')\n",
    "    axes[5, 0].legend()\n",
    "\n",
    "    # Plot 12: Test Error Rate vs Training Time (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[5, 1].plot(total_training_time_list[i], test_error_list[i], label=labels[i], color=colors[i])\n",
    "    axes[5, 1].set_xlabel('Training Time (s)')\n",
    "    axes[5, 1].set_ylabel('Test Error')\n",
    "    axes[5, 1].set_title('Test Error vs Total Training Time')\n",
    "    axes[5, 1].legend()\n",
    "\n",
    "    # Row 7: x_bar and x_k comparisons\n",
    "    # Plot 11: x_bar vs x_k vs Epoch (left plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[6, 0].plot(epochs_list[i], x_k_list[i], label=labels[i], color=colors[i])\n",
    "    axes[6, 0].set_xlabel('Epoch')\n",
    "    axes[6, 0].set_ylabel('||x_bar - x_k||')\n",
    "    axes[6, 0].set_title(f'||x_bar - x_k|| over {max_epochs} Epochs')\n",
    "    axes[6, 0].legend()\n",
    "\n",
    "    # Plot 12: x_bar vs x_ag_k vs Epoch (right plot)\n",
    "    for i in range(num_datasets):\n",
    "        axes[6, 1].plot(epochs_list[i], x_ag_k_list[i], label=labels[i], color=colors[i])\n",
    "    axes[6, 1].set_xlabel('Epoch')\n",
    "    axes[6, 1].set_ylabel('||x_bar - x_ag_k||')\n",
    "    axes[6, 1].set_title(f'||x_bar - x_ag_k|| over {max_epochs} Epochs')\n",
    "    axes[6, 1].legend()\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = \"generated/hinge/n_2000_m_1000/AR/no-lr/100/1000/2024-12-03-14:12:55/results.csv\"\n",
    "two = \"generated/hinge/n_2000_m_1000/AR/no-lr/100/1000/2024-12-03-14:13:46/results.csv\"\n",
    "\n",
    "files = [one, two]\n",
    "labels = [\"one\", \"two\"]\n",
    "\n",
    "plot_results(files, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diverging runs\n",
    "\n",
    "e1500 = \"generated/hinge/n_2000_m_1000/AR/no-lr/1493/2024-12-04-09:49:16/results.csv\"\n",
    "e6000 = \"generated/hinge/n_2000_m_1000/AR/no-lr/5897/1000/2024-12-04-10:01:06/results.csv\"\n",
    "\n",
    "files = [e1500, e6000]\n",
    "labels = [\"AR w/ AG, 1500 iterations\", \"AR w/ AG, 6000 iterations\"]\n",
    "\n",
    "plot_results(files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converging runs\n",
    "\n",
    "e110 = \"generated/hinge/n_2000_m_1000/AR/no-lr/110/1000/2024-12-04-09:53:04/results.csv\"\n",
    "e110_2 = \"generated/hinge/n_2000_m_1000/AR/no-lr/110/1000/2024-12-04-09:57:01/results.csv\"\n",
    "e136 = \"generated/hinge/n_2000_m_1000/AR/no-lr/136/1000/2024-12-04-09:57:49/results.csv\"\n",
    "\n",
    "files = [e110, e110_2, e136]\n",
    "labels = [\"AR w/ AG, 110 iterations\", \"AR w/ AG, 110 iterations (2)\", \"AR w/ AG, 136 iterations\"]\n",
    "\n",
    "plot_results(files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best AR vs. AG vs. SGD\n",
    "\n",
    "ar = \"generated/hinge/n_2000_m_1000/AR/no-lr/sigma_ratio_10.0/136/1000/2024-12-04-09:57:49/results.csv\"\n",
    "ag = \"generated/hinge/n_2000_m_1000/AG/lr-0.01/200/no_batching/no_wd/2024-11-06-16:28:14/results.csv\"\n",
    "ag_pf = \"generated/hinge/n_2000_m_1000/AG_pf/lr-0.01/200/no_batching/no_wd/2024-12-12-14:10:12/results.csv\"\n",
    "\n",
    "files = [ar, ag, ag_pf]\n",
    "labels = [\"AR w/ AG, 136 iterations\", \"AG w/ 200 iterations\", \"Param-free AG w/ 200 iterations\"]\n",
    "\n",
    "plot_results(files, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR vs AG Through 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_df = pd.read_csv(\"generated/hinge/n_2000_m_1000/AR/no-lr/sigma_ratio_10.0/136/1000/2024-12-04-09:57:49/results.csv\")\n",
    "ag_df = pd.read_csv(\"generated/hinge/n_2000_m_1000/AG/lr-0.01/200/no_batching/no_wd/2024-11-06-16:28:14/results.csv\")\n",
    "ag_pf_df = pd.read_csv(\"generated/hinge/n_2000_m_1000/AG_pf/lr-0.01/200/no_batching/no_wd/2024-12-12-14:10:12/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subproblem</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Gradient Norm</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Gradient Norm</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>x_k Comparison</th>\n",
       "      <th>x_ag_k Comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.019294</td>\n",
       "      <td>0.422298</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>1.003211</td>\n",
       "      <td>0.250641</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>1.142885</td>\n",
       "      <td>1.124351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994098</td>\n",
       "      <td>0.393303</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.237511</td>\n",
       "      <td>0.5278</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>1.108680</td>\n",
       "      <td>1.103336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.964283</td>\n",
       "      <td>0.364193</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.982883</td>\n",
       "      <td>0.230585</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>1.070114</td>\n",
       "      <td>1.079440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.931811</td>\n",
       "      <td>0.333729</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>1.039333</td>\n",
       "      <td>1.056504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.898696</td>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>1.028272</td>\n",
       "      <td>1.038446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subproblem  Iteration  Epoch  Training Loss  Training Gradient Norm  \\\n",
       "0           1          1      1       1.019294                0.422298   \n",
       "1           1          2      2       0.994098                0.393303   \n",
       "2           1          3      3       0.964283                0.364193   \n",
       "3           1          4      4       0.931811                0.333729   \n",
       "4           1          5      5       0.898696                0.300849   \n",
       "\n",
       "   Training Time (s)  Test Loss  Test Gradient Norm  Test Accuracy  \\\n",
       "0           0.082850   1.003211            0.250641         0.5093   \n",
       "1           0.013710   0.994143            0.237511         0.5278   \n",
       "2           0.010204   0.982883            0.230585         0.5559   \n",
       "3           0.010168   0.970091            0.227097         0.5800   \n",
       "4           0.009606   0.956520            0.224642         0.6034   \n",
       "\n",
       "   Test Error  x_k Comparison  x_ag_k Comparison  \n",
       "0      0.4907        1.142885           1.124351  \n",
       "1      0.4722        1.108680           1.103336  \n",
       "2      0.4441        1.070114           1.079440  \n",
       "3      0.4200        1.039333           1.056504  \n",
       "4      0.3966        1.028272           1.038446  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Total Training Loss</th>\n",
       "      <th>Training Gradient Norm</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Gradient Norm</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>x_k Comparison</th>\n",
       "      <th>x_ag_k Comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>1.004354</td>\n",
       "      <td>0.402547</td>\n",
       "      <td>0.048453</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.240259</td>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>1.130374</td>\n",
       "      <td>1.111550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945805</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.988030</td>\n",
       "      <td>0.232380</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>1.094942</td>\n",
       "      <td>1.089717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.892166</td>\n",
       "      <td>0.942607</td>\n",
       "      <td>0.373036</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>0.227727</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>1.056473</td>\n",
       "      <td>1.065403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.826146</td>\n",
       "      <td>0.900864</td>\n",
       "      <td>0.353593</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.224529</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>1.032765</td>\n",
       "      <td>1.043979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.751317</td>\n",
       "      <td>0.853342</td>\n",
       "      <td>0.330632</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>0.943076</td>\n",
       "      <td>0.221540</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>1.045547</td>\n",
       "      <td>1.032014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Total Training Loss  Training Gradient Norm  \\\n",
       "0      1       0.984066             1.004354                0.402547   \n",
       "1      2       0.945805             0.977416                0.389094   \n",
       "2      3       0.892166             0.942607                0.373036   \n",
       "3      4       0.826146             0.900864                0.353593   \n",
       "4      5       0.751317             0.853342                0.330632   \n",
       "\n",
       "   Training Time (s)  Test Loss  Test Gradient Norm  Test Accuracy  \\\n",
       "0           0.048453   0.997442            0.240259         0.5233   \n",
       "1           0.011979   0.988030            0.232380         0.5474   \n",
       "2           0.010374   0.975378            0.227727         0.5738   \n",
       "3           0.013964   0.960118            0.224529         0.6006   \n",
       "4           0.010234   0.943076            0.221540         0.6204   \n",
       "\n",
       "   Test Error  x_k Comparison  x_ag_k Comparison  \n",
       "0      0.4767        1.130374           1.111550  \n",
       "1      0.4526        1.094942           1.089717  \n",
       "2      0.4262        1.056473           1.065403  \n",
       "3      0.3994        1.032765           1.043979  \n",
       "4      0.3796        1.045547           1.032014  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Total Training Loss</th>\n",
       "      <th>Training Gradient Norm</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Gradient Norm</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>x_k Comparison</th>\n",
       "      <th>x_ag_k Comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.414394</td>\n",
       "      <td>0.044052</td>\n",
       "      <td>0.980267</td>\n",
       "      <td>0.289406</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>1.075862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.740850</td>\n",
       "      <td>0.747984</td>\n",
       "      <td>0.714629</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>1.013239</td>\n",
       "      <td>0.682824</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>1.181559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.709236</td>\n",
       "      <td>0.657788</td>\n",
       "      <td>0.975365</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>1.062698</td>\n",
       "      <td>0.920178</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>1.452568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.504018</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.675901</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.962866</td>\n",
       "      <td>0.678113</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>1.757685</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.920219</td>\n",
       "      <td>0.570291</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>2.172332</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Total Training Loss  Training Gradient Norm  \\\n",
       "0      1       0.858524             0.858524                0.414394   \n",
       "1      2       0.740850             0.747984                0.714629   \n",
       "2      3       0.709236             0.657788                0.975365   \n",
       "3      4       0.504018             0.579739                0.675901   \n",
       "4      5       0.389733             0.503051                0.573085   \n",
       "\n",
       "   Training Time (s)  Test Loss  Test Gradient Norm  Test Accuracy  \\\n",
       "0           0.044052   0.980267            0.289406         0.5441   \n",
       "1           0.015619   1.013239            0.682824         0.5071   \n",
       "2           0.018614   1.062698            0.920178         0.5303   \n",
       "3           0.017562   0.962866            0.678113         0.5761   \n",
       "4           0.020681   0.920219            0.570291         0.6093   \n",
       "\n",
       "   Test Error  x_k Comparison  x_ag_k Comparison  \n",
       "0      0.4559        1.075862                0.0  \n",
       "1      0.4929        1.181559                0.0  \n",
       "2      0.4697        1.452568                0.0  \n",
       "3      0.4239        1.757685                0.0  \n",
       "4      0.3907        2.172332                0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_pf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Total Training Loss</th>\n",
       "      <th>Training Gradient Norm</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Gradient Norm</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>x_k Comparison</th>\n",
       "      <th>x_ag_k Comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.155118</td>\n",
       "      <td>0.188046</td>\n",
       "      <td>0.241883</td>\n",
       "      <td>0.024946</td>\n",
       "      <td>1.015081</td>\n",
       "      <td>0.430701</td>\n",
       "      <td>0.648873</td>\n",
       "      <td>0.351127</td>\n",
       "      <td>5.564085</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.803408</td>\n",
       "      <td>0.249015</td>\n",
       "      <td>0.252377</td>\n",
       "      <td>0.289770</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.244368</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>2.408354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.875327</td>\n",
       "      <td>0.231228</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>1.075862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.974034</td>\n",
       "      <td>0.232474</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.319375</td>\n",
       "      <td>3.787799</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.060754</td>\n",
       "      <td>0.144265</td>\n",
       "      <td>0.021567</td>\n",
       "      <td>1.019288</td>\n",
       "      <td>0.325272</td>\n",
       "      <td>0.671950</td>\n",
       "      <td>0.328050</td>\n",
       "      <td>6.397954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.750000</td>\n",
       "      <td>0.236951</td>\n",
       "      <td>0.281372</td>\n",
       "      <td>0.405992</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>1.072365</td>\n",
       "      <td>0.528653</td>\n",
       "      <td>0.680625</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>7.755509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.975365</td>\n",
       "      <td>0.081038</td>\n",
       "      <td>1.177094</td>\n",
       "      <td>1.182893</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>7.926498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Epoch  Training Loss  Total Training Loss  Training Gradient Norm  \\\n",
       "count  30.000000      30.000000            30.000000               30.000000   \n",
       "mean   15.500000       0.155118             0.188046                0.241883   \n",
       "std     8.803408       0.249015             0.252377                0.289770   \n",
       "min     1.000000       0.000018             0.000005                0.001493   \n",
       "25%     8.250000       0.000077             0.003831                0.003183   \n",
       "50%    15.500000       0.018758             0.060754                0.144265   \n",
       "75%    22.750000       0.236951             0.281372                0.405992   \n",
       "max    30.000000       0.858524             0.858524                0.975365   \n",
       "\n",
       "       Training Time (s)  Test Loss  Test Gradient Norm  Test Accuracy  \\\n",
       "count          30.000000  30.000000           30.000000      30.000000   \n",
       "mean            0.024946   1.015081            0.430701       0.648873   \n",
       "std             0.013578   0.069153            0.244368       0.049918   \n",
       "min             0.013958   0.875327            0.231228       0.507100   \n",
       "25%             0.016771   0.974034            0.232474       0.640625   \n",
       "50%             0.021567   1.019288            0.325272       0.671950   \n",
       "75%             0.025230   1.072365            0.528653       0.680625   \n",
       "max             0.081038   1.177094            1.182893       0.681300   \n",
       "\n",
       "       Test Error  x_k Comparison  x_ag_k Comparison  \n",
       "count   30.000000       30.000000               30.0  \n",
       "mean     0.351127        5.564085                0.0  \n",
       "std      0.049918        2.408354                0.0  \n",
       "min      0.318700        1.075862                0.0  \n",
       "25%      0.319375        3.787799                0.0  \n",
       "50%      0.328050        6.397954                0.0  \n",
       "75%      0.359375        7.755509                0.0  \n",
       "max      0.492900        7.926498                0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_pf_30 = ag_pf_df.iloc[:30]\n",
    "ag_pf_30.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_pf_30.to_csv(\"generated/hinge/n_2000_m_1000/cutoff30/ar_pf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best AR vs. AG through 30 epochs\n",
    "\n",
    "ar = \"generated/hinge/n_2000_m_1000/cutoff30/ar.csv\"\n",
    "ag = \"generated/hinge/n_2000_m_1000/cutoff30/ag.csv\"\n",
    "ag_pf = \"generated/hinge/n_2000_m_1000/cutoff30/ar_pf.csv\"\n",
    "\n",
    "files = [ar, ag, ag_pf]\n",
    "labels = [\"AR w/ AG\", \"AG\", \"AG_pf\"]\n",
    "\n",
    "plot_results(files, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subproblem</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss_AR</th>\n",
       "      <th>Training Gradient Norm_AR</th>\n",
       "      <th>Training Time (s)_AR</th>\n",
       "      <th>Test Loss_AR</th>\n",
       "      <th>Test Gradient Norm_AR</th>\n",
       "      <th>Test Accuracy_AR</th>\n",
       "      <th>Test Error_AR</th>\n",
       "      <th>...</th>\n",
       "      <th>Training Loss_AG_pf</th>\n",
       "      <th>Total Training Loss_AG_pf</th>\n",
       "      <th>Training Gradient Norm_AG_pf</th>\n",
       "      <th>Training Time (s)_AG_pf</th>\n",
       "      <th>Test Loss_AG_pf</th>\n",
       "      <th>Test Gradient Norm_AG_pf</th>\n",
       "      <th>Test Accuracy_AG_pf</th>\n",
       "      <th>Test Error_AG_pf</th>\n",
       "      <th>x_k Comparison_AG_pf</th>\n",
       "      <th>x_ag_k Comparison_AG_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.019294</td>\n",
       "      <td>0.422298</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>1.003211</td>\n",
       "      <td>0.250641</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.414394</td>\n",
       "      <td>0.044052</td>\n",
       "      <td>0.980267</td>\n",
       "      <td>0.289406</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>1.075862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994098</td>\n",
       "      <td>0.393303</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.237511</td>\n",
       "      <td>0.5278</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740850</td>\n",
       "      <td>0.747984</td>\n",
       "      <td>0.714629</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>1.013239</td>\n",
       "      <td>0.682824</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>1.181559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.964283</td>\n",
       "      <td>0.364193</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.982883</td>\n",
       "      <td>0.230585</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709236</td>\n",
       "      <td>0.657788</td>\n",
       "      <td>0.975365</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>1.062698</td>\n",
       "      <td>0.920178</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>1.452568</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.931811</td>\n",
       "      <td>0.333729</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504018</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.675901</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.962866</td>\n",
       "      <td>0.678113</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>1.757685</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.898696</td>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389733</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.920219</td>\n",
       "      <td>0.570291</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>2.172332</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subproblem  Iteration  Epoch  Training Loss_AR  Training Gradient Norm_AR  \\\n",
       "0           1          1      1          1.019294                   0.422298   \n",
       "1           1          2      2          0.994098                   0.393303   \n",
       "2           1          3      3          0.964283                   0.364193   \n",
       "3           1          4      4          0.931811                   0.333729   \n",
       "4           1          5      5          0.898696                   0.300849   \n",
       "\n",
       "   Training Time (s)_AR  Test Loss_AR  Test Gradient Norm_AR  \\\n",
       "0              0.082850      1.003211               0.250641   \n",
       "1              0.013710      0.994143               0.237511   \n",
       "2              0.010204      0.982883               0.230585   \n",
       "3              0.010168      0.970091               0.227097   \n",
       "4              0.009606      0.956520               0.224642   \n",
       "\n",
       "   Test Accuracy_AR  Test Error_AR  ...  Training Loss_AG_pf  \\\n",
       "0            0.5093         0.4907  ...             0.858524   \n",
       "1            0.5278         0.4722  ...             0.740850   \n",
       "2            0.5559         0.4441  ...             0.709236   \n",
       "3            0.5800         0.4200  ...             0.504018   \n",
       "4            0.6034         0.3966  ...             0.389733   \n",
       "\n",
       "   Total Training Loss_AG_pf  Training Gradient Norm_AG_pf  \\\n",
       "0                   0.858524                      0.414394   \n",
       "1                   0.747984                      0.714629   \n",
       "2                   0.657788                      0.975365   \n",
       "3                   0.579739                      0.675901   \n",
       "4                   0.503051                      0.573085   \n",
       "\n",
       "   Training Time (s)_AG_pf  Test Loss_AG_pf  Test Gradient Norm_AG_pf  \\\n",
       "0                 0.044052         0.980267                  0.289406   \n",
       "1                 0.015619         1.013239                  0.682824   \n",
       "2                 0.018614         1.062698                  0.920178   \n",
       "3                 0.017562         0.962866                  0.678113   \n",
       "4                 0.020681         0.920219                  0.570291   \n",
       "\n",
       "   Test Accuracy_AG_pf  Test Error_AG_pf  x_k Comparison_AG_pf  \\\n",
       "0               0.5441            0.4559              1.075862   \n",
       "1               0.5071            0.4929              1.181559   \n",
       "2               0.5303            0.4697              1.452568   \n",
       "3               0.5761            0.4239              1.757685   \n",
       "4               0.6093            0.3907              2.172332   \n",
       "\n",
       "   x_ag_k Comparison_AG_pf  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(\n",
    "    ar_df,\n",
    "    ag_df,\n",
    "    on=\"Epoch\",\n",
    "    suffixes=(\"_AR\", \"_AG\")\n",
    ")\n",
    "\n",
    "ag_pf_df = ag_pf_df.rename(\n",
    "    columns={col: f\"{col}_AG_pf\" for col in ag_pf_df.columns if col != \"Epoch\"}\n",
    ")\n",
    "\n",
    "# Perform the second merge\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    ag_pf_df,\n",
    "    on=\"Epoch\"\n",
    ")\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subproblem', 'Iteration', 'Epoch', 'Training Loss_AR', 'Training Gradient Norm_AR', 'Training Time (s)_AR', 'Test Loss_AR', 'Test Gradient Norm_AR', 'Test Accuracy_AR', 'Test Error_AR', 'x_k Comparison_AR', 'x_ag_k Comparison_AR', 'Training Loss_AG', 'Total Training Loss', 'Training Gradient Norm_AG', 'Training Time (s)_AG', 'Test Loss_AG', 'Test Gradient Norm_AG', 'Test Accuracy_AG', 'Test Error_AG', 'x_k Comparison_AG', 'x_ag_k Comparison_AG', 'Training Loss_AG_pf', 'Total Training Loss_AG_pf', 'Training Gradient Norm_AG_pf', 'Training Time (s)_AG_pf', 'Test Loss_AG_pf', 'Test Gradient Norm_AG_pf', 'Test Accuracy_AG_pf', 'Test Error_AG_pf', 'x_k Comparison_AG_pf', 'x_ag_k Comparison_AG_pf']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Test Accuracy_AR</th>\n",
       "      <th>Test Accuracy_AG</th>\n",
       "      <th>Test Accuracy_AG_pf</th>\n",
       "      <th>Training Gradient Norm_AR</th>\n",
       "      <th>Training Gradient Norm_AG</th>\n",
       "      <th>Training Gradient Norm_AG_pf</th>\n",
       "      <th>Training Loss_AR</th>\n",
       "      <th>Training Loss_AG</th>\n",
       "      <th>Training Loss_AG_pf</th>\n",
       "      <th>Test Gradient Norm_AR</th>\n",
       "      <th>Test Gradient Norm_AG</th>\n",
       "      <th>Test Gradient Norm_AG_pf</th>\n",
       "      <th>Test Loss_AR</th>\n",
       "      <th>Test Loss_AG</th>\n",
       "      <th>Test Loss_AG_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.5233</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.422298</td>\n",
       "      <td>0.402547</td>\n",
       "      <td>0.414394</td>\n",
       "      <td>1.019294</td>\n",
       "      <td>0.984066</td>\n",
       "      <td>8.585238e-01</td>\n",
       "      <td>0.250641</td>\n",
       "      <td>0.240259</td>\n",
       "      <td>0.289406</td>\n",
       "      <td>1.003211</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.980267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5278</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.393303</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.714629</td>\n",
       "      <td>0.994098</td>\n",
       "      <td>0.945805</td>\n",
       "      <td>7.408500e-01</td>\n",
       "      <td>0.237511</td>\n",
       "      <td>0.232380</td>\n",
       "      <td>0.682824</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.988030</td>\n",
       "      <td>1.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.364193</td>\n",
       "      <td>0.373036</td>\n",
       "      <td>0.975365</td>\n",
       "      <td>0.964283</td>\n",
       "      <td>0.892166</td>\n",
       "      <td>7.092359e-01</td>\n",
       "      <td>0.230585</td>\n",
       "      <td>0.227727</td>\n",
       "      <td>0.920178</td>\n",
       "      <td>0.982883</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>1.062698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.333729</td>\n",
       "      <td>0.353593</td>\n",
       "      <td>0.675901</td>\n",
       "      <td>0.931811</td>\n",
       "      <td>0.826146</td>\n",
       "      <td>5.040178e-01</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.224529</td>\n",
       "      <td>0.678113</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.962866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.330632</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.898696</td>\n",
       "      <td>0.751317</td>\n",
       "      <td>3.897327e-01</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>0.221540</td>\n",
       "      <td>0.570291</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>0.943076</td>\n",
       "      <td>0.920219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.265825</td>\n",
       "      <td>0.304815</td>\n",
       "      <td>0.453093</td>\n",
       "      <td>0.866898</td>\n",
       "      <td>0.671542</td>\n",
       "      <td>2.921141e-01</td>\n",
       "      <td>0.222529</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>0.510337</td>\n",
       "      <td>0.942992</td>\n",
       "      <td>0.925237</td>\n",
       "      <td>0.897287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.229656</td>\n",
       "      <td>0.277012</td>\n",
       "      <td>0.344908</td>\n",
       "      <td>0.838042</td>\n",
       "      <td>0.590588</td>\n",
       "      <td>2.183895e-01</td>\n",
       "      <td>0.220570</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>0.406318</td>\n",
       "      <td>0.930206</td>\n",
       "      <td>0.907592</td>\n",
       "      <td>0.875327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>0.193479</td>\n",
       "      <td>0.248118</td>\n",
       "      <td>0.638676</td>\n",
       "      <td>0.813244</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>2.431387e-01</td>\n",
       "      <td>0.218687</td>\n",
       "      <td>0.212665</td>\n",
       "      <td>0.850462</td>\n",
       "      <td>0.918656</td>\n",
       "      <td>0.891058</td>\n",
       "      <td>0.998412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.158345</td>\n",
       "      <td>0.219092</td>\n",
       "      <td>0.814278</td>\n",
       "      <td>0.793068</td>\n",
       "      <td>0.438146</td>\n",
       "      <td>3.266322e-01</td>\n",
       "      <td>0.216932</td>\n",
       "      <td>0.210032</td>\n",
       "      <td>1.182893</td>\n",
       "      <td>0.908642</td>\n",
       "      <td>0.876425</td>\n",
       "      <td>1.177094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.125181</td>\n",
       "      <td>0.191168</td>\n",
       "      <td>0.380785</td>\n",
       "      <td>0.777574</td>\n",
       "      <td>0.371578</td>\n",
       "      <td>1.204900e-01</td>\n",
       "      <td>0.215404</td>\n",
       "      <td>0.207804</td>\n",
       "      <td>0.604510</td>\n",
       "      <td>0.900287</td>\n",
       "      <td>0.864306</td>\n",
       "      <td>0.942119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>0.190155</td>\n",
       "      <td>0.766421</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>6.627122e-02</td>\n",
       "      <td>0.214166</td>\n",
       "      <td>0.206125</td>\n",
       "      <td>0.361139</td>\n",
       "      <td>0.893585</td>\n",
       "      <td>0.855087</td>\n",
       "      <td>0.902290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.6672</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.067801</td>\n",
       "      <td>0.144461</td>\n",
       "      <td>0.241189</td>\n",
       "      <td>0.758989</td>\n",
       "      <td>0.263424</td>\n",
       "      <td>5.695155e-02</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>0.205047</td>\n",
       "      <td>0.490118</td>\n",
       "      <td>0.888448</td>\n",
       "      <td>0.848914</td>\n",
       "      <td>0.945870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.044891</td>\n",
       "      <td>0.127116</td>\n",
       "      <td>0.237394</td>\n",
       "      <td>0.754509</td>\n",
       "      <td>0.221160</td>\n",
       "      <td>5.002689e-02</td>\n",
       "      <td>0.212565</td>\n",
       "      <td>0.204543</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.884755</td>\n",
       "      <td>0.845705</td>\n",
       "      <td>0.972758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.113210</td>\n",
       "      <td>0.184603</td>\n",
       "      <td>0.752185</td>\n",
       "      <td>0.185410</td>\n",
       "      <td>3.071563e-02</td>\n",
       "      <td>0.212144</td>\n",
       "      <td>0.204642</td>\n",
       "      <td>0.481711</td>\n",
       "      <td>0.882383</td>\n",
       "      <td>0.845205</td>\n",
       "      <td>0.979815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.6706</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.165069</td>\n",
       "      <td>0.751285</td>\n",
       "      <td>0.155078</td>\n",
       "      <td>2.452911e-02</td>\n",
       "      <td>0.211940</td>\n",
       "      <td>0.204949</td>\n",
       "      <td>0.499380</td>\n",
       "      <td>0.881216</td>\n",
       "      <td>0.847015</td>\n",
       "      <td>1.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.091237</td>\n",
       "      <td>0.052715</td>\n",
       "      <td>0.751200</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>5.671457e-03</td>\n",
       "      <td>0.211931</td>\n",
       "      <td>0.205510</td>\n",
       "      <td>0.282350</td>\n",
       "      <td>0.881152</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.977860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.082341</td>\n",
       "      <td>0.123462</td>\n",
       "      <td>0.751476</td>\n",
       "      <td>0.107384</td>\n",
       "      <td>1.298710e-02</td>\n",
       "      <td>0.212098</td>\n",
       "      <td>0.206206</td>\n",
       "      <td>0.509310</td>\n",
       "      <td>0.882083</td>\n",
       "      <td>0.855886</td>\n",
       "      <td>1.044880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>0.074347</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.751812</td>\n",
       "      <td>0.088615</td>\n",
       "      <td>1.367723e-03</td>\n",
       "      <td>0.212422</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.248452</td>\n",
       "      <td>0.883887</td>\n",
       "      <td>0.862270</td>\n",
       "      <td>1.006514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6763</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>0.067031</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.752045</td>\n",
       "      <td>0.072505</td>\n",
       "      <td>9.798157e-04</td>\n",
       "      <td>0.212874</td>\n",
       "      <td>0.207747</td>\n",
       "      <td>0.259787</td>\n",
       "      <td>0.886414</td>\n",
       "      <td>0.869642</td>\n",
       "      <td>1.025337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.060251</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.752114</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>2.231556e-04</td>\n",
       "      <td>0.213421</td>\n",
       "      <td>0.208753</td>\n",
       "      <td>0.234496</td>\n",
       "      <td>0.889482</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>1.037301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.054029</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.752029</td>\n",
       "      <td>0.047034</td>\n",
       "      <td>2.152086e-04</td>\n",
       "      <td>0.214026</td>\n",
       "      <td>0.209884</td>\n",
       "      <td>0.234925</td>\n",
       "      <td>0.892883</td>\n",
       "      <td>0.886557</td>\n",
       "      <td>1.050267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.024968</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.751837</td>\n",
       "      <td>0.037214</td>\n",
       "      <td>9.640565e-05</td>\n",
       "      <td>0.214649</td>\n",
       "      <td>0.211008</td>\n",
       "      <td>0.231589</td>\n",
       "      <td>0.896394</td>\n",
       "      <td>0.895768</td>\n",
       "      <td>1.060253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.021635</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.751595</td>\n",
       "      <td>0.029063</td>\n",
       "      <td>7.070144e-05</td>\n",
       "      <td>0.215251</td>\n",
       "      <td>0.212206</td>\n",
       "      <td>0.231228</td>\n",
       "      <td>0.899796</td>\n",
       "      <td>0.905350</td>\n",
       "      <td>1.068139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.038340</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.751354</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>6.184982e-05</td>\n",
       "      <td>0.215796</td>\n",
       "      <td>0.213445</td>\n",
       "      <td>0.231956</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.915210</td>\n",
       "      <td>1.073774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.034069</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.751150</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>5.913366e-05</td>\n",
       "      <td>0.216257</td>\n",
       "      <td>0.214748</td>\n",
       "      <td>0.232332</td>\n",
       "      <td>0.905508</td>\n",
       "      <td>0.925270</td>\n",
       "      <td>1.077343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>5.417368e-05</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.215984</td>\n",
       "      <td>0.232466</td>\n",
       "      <td>0.907537</td>\n",
       "      <td>0.935483</td>\n",
       "      <td>1.079229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.026298</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.750906</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>4.510215e-05</td>\n",
       "      <td>0.216856</td>\n",
       "      <td>0.217103</td>\n",
       "      <td>0.232498</td>\n",
       "      <td>0.908911</td>\n",
       "      <td>0.945777</td>\n",
       "      <td>1.080035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.022766</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.750860</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>3.586739e-05</td>\n",
       "      <td>0.216983</td>\n",
       "      <td>0.218183</td>\n",
       "      <td>0.232430</td>\n",
       "      <td>0.909620</td>\n",
       "      <td>0.956096</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.750846</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>2.678347e-05</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.219339</td>\n",
       "      <td>0.232387</td>\n",
       "      <td>0.909695</td>\n",
       "      <td>0.966399</td>\n",
       "      <td>1.080310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.750851</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>1.792584e-05</td>\n",
       "      <td>0.216920</td>\n",
       "      <td>0.220583</td>\n",
       "      <td>0.232374</td>\n",
       "      <td>0.909209</td>\n",
       "      <td>0.976629</td>\n",
       "      <td>1.080276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.750862</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>1.114225e-05</td>\n",
       "      <td>0.216759</td>\n",
       "      <td>0.221752</td>\n",
       "      <td>0.232439</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>0.986696</td>\n",
       "      <td>1.080259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.750870</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>6.589713e-06</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.222854</td>\n",
       "      <td>0.232525</td>\n",
       "      <td>0.906952</td>\n",
       "      <td>0.996557</td>\n",
       "      <td>1.080261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.750871</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>3.964490e-06</td>\n",
       "      <td>0.216273</td>\n",
       "      <td>0.223928</td>\n",
       "      <td>0.232579</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>1.006144</td>\n",
       "      <td>1.080271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.750866</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>1.981436e-06</td>\n",
       "      <td>0.215988</td>\n",
       "      <td>0.224977</td>\n",
       "      <td>0.232605</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>1.015383</td>\n",
       "      <td>1.080287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.750855</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>7.418678e-07</td>\n",
       "      <td>0.215699</td>\n",
       "      <td>0.225980</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.902070</td>\n",
       "      <td>1.024225</td>\n",
       "      <td>1.080302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>3.127942e-07</td>\n",
       "      <td>0.215422</td>\n",
       "      <td>0.226968</td>\n",
       "      <td>0.232595</td>\n",
       "      <td>0.900470</td>\n",
       "      <td>1.032621</td>\n",
       "      <td>1.080313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.750825</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>2.463399e-07</td>\n",
       "      <td>0.215171</td>\n",
       "      <td>0.227916</td>\n",
       "      <td>0.232572</td>\n",
       "      <td>0.899025</td>\n",
       "      <td>1.040518</td>\n",
       "      <td>1.080320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.750811</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>1.686858e-07</td>\n",
       "      <td>0.214955</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.232542</td>\n",
       "      <td>0.897794</td>\n",
       "      <td>1.047878</td>\n",
       "      <td>1.080324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.750799</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>9.466558e-08</td>\n",
       "      <td>0.214782</td>\n",
       "      <td>0.229604</td>\n",
       "      <td>0.232510</td>\n",
       "      <td>0.896820</td>\n",
       "      <td>1.054664</td>\n",
       "      <td>1.080326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.750791</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>3.878613e-08</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.230274</td>\n",
       "      <td>0.232487</td>\n",
       "      <td>0.896126</td>\n",
       "      <td>1.060823</td>\n",
       "      <td>1.080328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.750785</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>7.533239e-09</td>\n",
       "      <td>0.214580</td>\n",
       "      <td>0.230886</td>\n",
       "      <td>0.232473</td>\n",
       "      <td>0.895719</td>\n",
       "      <td>1.066356</td>\n",
       "      <td>1.080328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.6793</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750781</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214550</td>\n",
       "      <td>0.231480</td>\n",
       "      <td>0.232465</td>\n",
       "      <td>0.895588</td>\n",
       "      <td>1.071273</td>\n",
       "      <td>1.080328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750779</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214564</td>\n",
       "      <td>0.232062</td>\n",
       "      <td>0.232460</td>\n",
       "      <td>0.895713</td>\n",
       "      <td>1.075569</td>\n",
       "      <td>1.080327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750778</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214616</td>\n",
       "      <td>0.232580</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.896058</td>\n",
       "      <td>1.079252</td>\n",
       "      <td>1.080326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750777</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214699</td>\n",
       "      <td>0.233049</td>\n",
       "      <td>0.232453</td>\n",
       "      <td>0.896580</td>\n",
       "      <td>1.082346</td>\n",
       "      <td>1.080326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750776</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214805</td>\n",
       "      <td>0.233438</td>\n",
       "      <td>0.232451</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>1.084883</td>\n",
       "      <td>1.080326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750776</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214926</td>\n",
       "      <td>0.233665</td>\n",
       "      <td>0.232450</td>\n",
       "      <td>0.897967</td>\n",
       "      <td>1.086903</td>\n",
       "      <td>1.080325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750775</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.233669</td>\n",
       "      <td>0.232450</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>1.088441</td>\n",
       "      <td>1.080325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750774</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.215182</td>\n",
       "      <td>0.233563</td>\n",
       "      <td>0.232450</td>\n",
       "      <td>0.899489</td>\n",
       "      <td>1.089553</td>\n",
       "      <td>1.080325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750773</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.215303</td>\n",
       "      <td>0.233490</td>\n",
       "      <td>0.232450</td>\n",
       "      <td>0.900191</td>\n",
       "      <td>1.090350</td>\n",
       "      <td>1.080325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  Test Accuracy_AR  Test Accuracy_AG  Test Accuracy_AG_pf  \\\n",
       "0       1            0.5093            0.5233               0.5441   \n",
       "1       2            0.5278            0.5474               0.5071   \n",
       "2       3            0.5559            0.5738               0.5303   \n",
       "3       4            0.5800            0.6006               0.5761   \n",
       "4       5            0.6034            0.6204               0.6093   \n",
       "5       6            0.6209            0.6359               0.6382   \n",
       "6       7            0.6325            0.6451               0.6479   \n",
       "7       8            0.6409            0.6502               0.6182   \n",
       "8       9            0.6464            0.6562               0.5975   \n",
       "9      10            0.6504            0.6591               0.6545   \n",
       "10     11            0.6531            0.6634               0.6699   \n",
       "11     12            0.6540            0.6672               0.6681   \n",
       "12     13            0.6558            0.6698               0.6646   \n",
       "13     14            0.6580            0.6725               0.6719   \n",
       "14     15            0.6600            0.6739               0.6706   \n",
       "15     16            0.6606            0.6747               0.6798   \n",
       "16     17            0.6604            0.6753               0.6720   \n",
       "17     18            0.6594            0.6765               0.6796   \n",
       "18     19            0.6596            0.6763               0.6796   \n",
       "19     20            0.6589            0.6773               0.6796   \n",
       "20     21            0.6590            0.6757               0.6792   \n",
       "21     22            0.6583            0.6773               0.6801   \n",
       "22     23            0.6573            0.6775               0.6813   \n",
       "23     24            0.6558            0.6776               0.6810   \n",
       "24     25            0.6535            0.6778               0.6812   \n",
       "25     26            0.6508            0.6780               0.6808   \n",
       "26     27            0.6506            0.6792               0.6809   \n",
       "27     28            0.6493            0.6790               0.6808   \n",
       "28     29            0.6489            0.6783               0.6810   \n",
       "29     30            0.6482            0.6790               0.6810   \n",
       "30     31            0.6486            0.6786               0.6814   \n",
       "31     32            0.6489            0.6784               0.6812   \n",
       "32     33            0.6497            0.6776               0.6813   \n",
       "33     34            0.6500            0.6770               0.6812   \n",
       "34     35            0.6507            0.6777               0.6812   \n",
       "35     36            0.6517            0.6774               0.6812   \n",
       "36     37            0.6517            0.6774               0.6811   \n",
       "37     38            0.6531            0.6785               0.6811   \n",
       "38     39            0.6542            0.6787               0.6811   \n",
       "39     40            0.6551            0.6783               0.6811   \n",
       "40     41            0.6562            0.6791               0.6811   \n",
       "41     42            0.6567            0.6793               0.6811   \n",
       "42     43            0.6560            0.6794               0.6812   \n",
       "43     44            0.6557            0.6797               0.6813   \n",
       "44     45            0.6560            0.6805               0.6813   \n",
       "45     46            0.6563            0.6802               0.6813   \n",
       "46     47            0.6556            0.6798               0.6813   \n",
       "47     48            0.6558            0.6796               0.6813   \n",
       "48     49            0.6556            0.6798               0.6813   \n",
       "49     50            0.6542            0.6797               0.6813   \n",
       "\n",
       "    Training Gradient Norm_AR  Training Gradient Norm_AG  \\\n",
       "0                    0.422298                   0.402547   \n",
       "1                    0.393303                   0.389094   \n",
       "2                    0.364193                   0.373036   \n",
       "3                    0.333729                   0.353593   \n",
       "4                    0.300849                   0.330632   \n",
       "5                    0.265825                   0.304815   \n",
       "6                    0.229656                   0.277012   \n",
       "7                    0.193479                   0.248118   \n",
       "8                    0.158345                   0.219092   \n",
       "9                    0.125181                   0.191168   \n",
       "10                   0.094776                   0.165776   \n",
       "11                   0.067801                   0.144461   \n",
       "12                   0.044891                   0.127116   \n",
       "13                   0.026999                   0.113210   \n",
       "14                   0.016667                   0.101449   \n",
       "15                   0.016928                   0.091237   \n",
       "16                   0.021932                   0.082341   \n",
       "17                   0.026193                   0.074347   \n",
       "18                   0.028486                   0.067031   \n",
       "19                   0.028817                   0.060251   \n",
       "20                   0.027506                   0.054029   \n",
       "21                   0.024968                   0.048304   \n",
       "22                   0.021635                   0.043072   \n",
       "23                   0.017932                   0.038340   \n",
       "24                   0.014262                   0.034069   \n",
       "25                   0.011025                   0.030090   \n",
       "26                   0.008630                   0.026298   \n",
       "27                   0.007395                   0.022766   \n",
       "28                   0.007234                   0.019335   \n",
       "29                   0.007618                   0.016301   \n",
       "30                   0.008043                   0.013907   \n",
       "31                   0.008250                   0.012100   \n",
       "32                   0.008161                   0.010670   \n",
       "33                   0.007794                   0.009574   \n",
       "34                   0.007212                   0.008661   \n",
       "35                   0.006499                   0.007831   \n",
       "36                   0.005741                   0.007043   \n",
       "37                   0.005019                   0.006413   \n",
       "38                   0.004398                   0.005985   \n",
       "39                   0.003916                   0.005616   \n",
       "40                   0.003579                   0.005248   \n",
       "41                   0.003360                   0.004858   \n",
       "42                   0.003216                   0.004493   \n",
       "43                   0.003107                   0.004207   \n",
       "44                   0.003004                   0.004048   \n",
       "45                   0.002894                   0.003986   \n",
       "46                   0.002772                   0.003951   \n",
       "47                   0.002641                   0.003863   \n",
       "48                   0.002503                   0.003700   \n",
       "49                   0.002360                   0.003498   \n",
       "\n",
       "    Training Gradient Norm_AG_pf  Training Loss_AR  Training Loss_AG  \\\n",
       "0                       0.414394          1.019294          0.984066   \n",
       "1                       0.714629          0.994098          0.945805   \n",
       "2                       0.975365          0.964283          0.892166   \n",
       "3                       0.675901          0.931811          0.826146   \n",
       "4                       0.573085          0.898696          0.751317   \n",
       "5                       0.453093          0.866898          0.671542   \n",
       "6                       0.344908          0.838042          0.590588   \n",
       "7                       0.638676          0.813244          0.511848   \n",
       "8                       0.814278          0.793068          0.438146   \n",
       "9                       0.380785          0.777574          0.371578   \n",
       "10                      0.190155          0.766421          0.313305   \n",
       "11                      0.241189          0.758989          0.263424   \n",
       "12                      0.237394          0.754509          0.221160   \n",
       "13                      0.184603          0.752185          0.185410   \n",
       "14                      0.165069          0.751285          0.155078   \n",
       "15                      0.052715          0.751200          0.129310   \n",
       "16                      0.123462          0.751476          0.107384   \n",
       "17                      0.021779          0.751812          0.088615   \n",
       "18                      0.019386          0.752045          0.072505   \n",
       "19                      0.005848          0.752114          0.058733   \n",
       "20                      0.006729          0.752029          0.047034   \n",
       "21                      0.003647          0.751837          0.037214   \n",
       "22                      0.003028          0.751595          0.029063   \n",
       "23                      0.002869          0.751354          0.022356   \n",
       "24                      0.002848          0.751150          0.016895   \n",
       "25                      0.002708          0.751000          0.012502   \n",
       "26                      0.002453          0.750906          0.009026   \n",
       "27                      0.002156          0.750860          0.006344   \n",
       "28                      0.001847          0.750846          0.004340   \n",
       "29                      0.001493          0.750851          0.002899   \n",
       "30                      0.001169          0.750862          0.001920   \n",
       "31                      0.000900          0.750870          0.001285   \n",
       "32                      0.000703          0.750871          0.000899   \n",
       "33                      0.000501          0.750866          0.000663   \n",
       "34                      0.000311          0.750855          0.000521   \n",
       "35                      0.000200          0.750840          0.000420   \n",
       "36                      0.000177          0.750825          0.000343   \n",
       "37                      0.000146          0.750811          0.000290   \n",
       "38                      0.000109          0.750799          0.000255   \n",
       "39                      0.000070          0.750791          0.000225   \n",
       "40                      0.000031          0.750785          0.000195   \n",
       "41                      0.000000          0.750781          0.000167   \n",
       "42                      0.000000          0.750779          0.000144   \n",
       "43                      0.000000          0.750778          0.000128   \n",
       "44                      0.000000          0.750777          0.000118   \n",
       "45                      0.000000          0.750776          0.000112   \n",
       "46                      0.000000          0.750776          0.000109   \n",
       "47                      0.000000          0.750775          0.000105   \n",
       "48                      0.000000          0.750774          0.000098   \n",
       "49                      0.000000          0.750773          0.000089   \n",
       "\n",
       "    Training Loss_AG_pf  Test Gradient Norm_AR  Test Gradient Norm_AG  \\\n",
       "0          8.585238e-01               0.250641               0.240259   \n",
       "1          7.408500e-01               0.237511               0.232380   \n",
       "2          7.092359e-01               0.230585               0.227727   \n",
       "3          5.040178e-01               0.227097               0.224529   \n",
       "4          3.897327e-01               0.224642               0.221540   \n",
       "5          2.921141e-01               0.222529               0.218535   \n",
       "6          2.183895e-01               0.220570               0.215549   \n",
       "7          2.431387e-01               0.218687               0.212665   \n",
       "8          3.266322e-01               0.216932               0.210032   \n",
       "9          1.204900e-01               0.215404               0.207804   \n",
       "10         6.627122e-02               0.214166               0.206125   \n",
       "11         5.695155e-02               0.213228               0.205047   \n",
       "12         5.002689e-02               0.212565               0.204543   \n",
       "13         3.071563e-02               0.212144               0.204642   \n",
       "14         2.452911e-02               0.211940               0.204949   \n",
       "15         5.671457e-03               0.211931               0.205510   \n",
       "16         1.298710e-02               0.212098               0.206206   \n",
       "17         1.367723e-03               0.212422               0.206897   \n",
       "18         9.798157e-04               0.212874               0.207747   \n",
       "19         2.231556e-04               0.213421               0.208753   \n",
       "20         2.152086e-04               0.214026               0.209884   \n",
       "21         9.640565e-05               0.214649               0.211008   \n",
       "22         7.070144e-05               0.215251               0.212206   \n",
       "23         6.184982e-05               0.215796               0.213445   \n",
       "24         5.913366e-05               0.216257               0.214748   \n",
       "25         5.417368e-05               0.216614               0.215984   \n",
       "26         4.510215e-05               0.216856               0.217103   \n",
       "27         3.586739e-05               0.216983               0.218183   \n",
       "28         2.678347e-05               0.217000               0.219339   \n",
       "29         1.792584e-05               0.216920               0.220583   \n",
       "30         1.114225e-05               0.216759               0.221752   \n",
       "31         6.589713e-06               0.216537               0.222854   \n",
       "32         3.964490e-06               0.216273               0.223928   \n",
       "33         1.981436e-06               0.215988               0.224977   \n",
       "34         7.418678e-07               0.215699               0.225980   \n",
       "35         3.127942e-07               0.215422               0.226968   \n",
       "36         2.463399e-07               0.215171               0.227916   \n",
       "37         1.686858e-07               0.214955               0.228800   \n",
       "38         9.466558e-08               0.214782               0.229604   \n",
       "39         3.878613e-08               0.214657               0.230274   \n",
       "40         7.533239e-09               0.214580               0.230886   \n",
       "41         0.000000e+00               0.214550               0.231480   \n",
       "42         0.000000e+00               0.214564               0.232062   \n",
       "43         0.000000e+00               0.214616               0.232580   \n",
       "44         0.000000e+00               0.214699               0.233049   \n",
       "45         0.000000e+00               0.214805               0.233438   \n",
       "46         0.000000e+00               0.214926               0.233665   \n",
       "47         0.000000e+00               0.215054               0.233669   \n",
       "48         0.000000e+00               0.215182               0.233563   \n",
       "49         0.000000e+00               0.215303               0.233490   \n",
       "\n",
       "    Test Gradient Norm_AG_pf  Test Loss_AR  Test Loss_AG  Test Loss_AG_pf  \n",
       "0                   0.289406      1.003211      0.997442         0.980267  \n",
       "1                   0.682824      0.994143      0.988030         1.013239  \n",
       "2                   0.920178      0.982883      0.975378         1.062698  \n",
       "3                   0.678113      0.970091      0.960118         0.962866  \n",
       "4                   0.570291      0.956520      0.943076         0.920219  \n",
       "5                   0.510337      0.942992      0.925237         0.897287  \n",
       "6                   0.406318      0.930206      0.907592         0.875327  \n",
       "7                   0.850462      0.918656      0.891058         0.998412  \n",
       "8                   1.182893      0.908642      0.876425         1.177094  \n",
       "9                   0.604510      0.900287      0.864306         0.942119  \n",
       "10                  0.361139      0.893585      0.855087         0.902290  \n",
       "11                  0.490118      0.888448      0.848914         0.945870  \n",
       "12                  0.534759      0.884755      0.845705         0.972758  \n",
       "13                  0.481711      0.882383      0.845205         0.979815  \n",
       "14                  0.499380      0.881216      0.847015         1.000360  \n",
       "15                  0.282350      0.881152      0.850709         0.977860  \n",
       "16                  0.509310      0.882083      0.855886         1.044880  \n",
       "17                  0.248452      0.883887      0.862270         1.006514  \n",
       "18                  0.259787      0.886414      0.869642         1.025337  \n",
       "19                  0.234496      0.889482      0.877800         1.037301  \n",
       "20                  0.234925      0.892883      0.886557         1.050267  \n",
       "21                  0.231589      0.896394      0.895768         1.060253  \n",
       "22                  0.231228      0.899796      0.905350         1.068139  \n",
       "23                  0.231956      0.902889      0.915210         1.073774  \n",
       "24                  0.232332      0.905508      0.925270         1.077343  \n",
       "25                  0.232466      0.907537      0.935483         1.079229  \n",
       "26                  0.232498      0.908911      0.945777         1.080035  \n",
       "27                  0.232430      0.909620      0.956096         1.080300  \n",
       "28                  0.232387      0.909695      0.966399         1.080310  \n",
       "29                  0.232374      0.909209      0.976629         1.080276  \n",
       "30                  0.232439      0.908257      0.986696         1.080259  \n",
       "31                  0.232525      0.906952      0.996557         1.080261  \n",
       "32                  0.232579      0.905411      1.006144         1.080271  \n",
       "33                  0.232605      0.903748      1.015383         1.080287  \n",
       "34                  0.232609      0.902070      1.024225         1.080302  \n",
       "35                  0.232595      0.900470      1.032621         1.080313  \n",
       "36                  0.232572      0.899025      1.040518         1.080320  \n",
       "37                  0.232542      0.897794      1.047878         1.080324  \n",
       "38                  0.232510      0.896820      1.054664         1.080326  \n",
       "39                  0.232487      0.896126      1.060823         1.080328  \n",
       "40                  0.232473      0.895719      1.066356         1.080328  \n",
       "41                  0.232465      0.895588      1.071273         1.080328  \n",
       "42                  0.232460      0.895713      1.075569         1.080327  \n",
       "43                  0.232456      0.896058      1.079252         1.080326  \n",
       "44                  0.232453      0.896580      1.082346         1.080326  \n",
       "45                  0.232451      0.897233      1.084883         1.080326  \n",
       "46                  0.232450      0.897967      1.086903         1.080325  \n",
       "47                  0.232450      0.898734      1.088441         1.080325  \n",
       "48                  0.232450      0.899489      1.089553         1.080325  \n",
       "49                  0.232450      0.900191      1.090350         1.080325  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"Epoch\",\n",
    "    \"Test Accuracy_AR\",\n",
    "    \"Test Accuracy_AG\",\n",
    "    \"Test Accuracy_AG_pf\",\n",
    "    \"Training Gradient Norm_AR\",\n",
    "    \"Training Gradient Norm_AG\",\n",
    "    \"Training Gradient Norm_AG_pf\",\n",
    "    \"Training Loss_AR\",\n",
    "    \"Training Loss_AG\",\n",
    "    \"Training Loss_AG_pf\",\n",
    "    \"Test Gradient Norm_AR\",\n",
    "    \"Test Gradient Norm_AG\",\n",
    "    \"Test Gradient Norm_AG_pf\",\n",
    "    \"Test Loss_AR\",\n",
    "    \"Test Loss_AG\",\n",
    "    \"Test Loss_AG_pf\"\n",
    "]\n",
    "\n",
    "merged_clean = merged_df[cols]\n",
    "merged_clean.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison at sigma_1 = {L_approx / 10, L_approx / 15, L_approx / 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For sigma_1 = L / 10.0: 30% convergence**\n",
    "<br>\n",
    "\n",
    "3/10 converged (iterations = 110, 100, 136)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**For sigma_1 = L / 15.0: 40% convergence**\n",
    "<br>\n",
    "\n",
    "Converged: \n",
    "\n",
    "158-3 (2.3e-7), 197-4 (9e-7), 162-3 (2.8e-7), 129-2 (1e-6)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Diverged: sub3, sub4, sub3, 1295-12 (norm=0.06), sub5, sub3\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**For sigma_1 = L / 5.0: 50% convergence**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Converged:\n",
    "\n",
    "84-2 (1.61e-7), 84-2 (1.49e-7), 110-3 (5e-7), 139-4 (2e-6), 84-2 (1.54e-7)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Diverged:\n",
    "\n",
    "1092-15 (7.7), sub5, sub4, sub3, 2200-12 (0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing graphs\n",
    "\n",
    "r10 = \"generated/hinge/n_2000_m_1000/AR/no-lr/sigma_ratio_10.0/136/1000/2024-12-04-09:57:49/results.csv\"\n",
    "r15 = \"generated/hinge/n_2000_m_1000/AR/no-lr/sigma_ratio_15.0/158/2024-12-04-11:05:18/results.csv\"\n",
    "r5 = \"generated/hinge/n_2000_m_1000/AR/no-lr/sigma_ratio_5.0/85/2024-12-04-11:14:56/results.csv\"\n",
    "\n",
    "files = [r10, r15, r5]\n",
    "labels = [\"AR w/ AG, ratio = 10\", \"AR w/ AG, ratio = 15\", \"AR w/ AG, ratio = 5\"]\n",
    "\n",
    "plot_results(files, labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54ee8ad09054042b765fe01c0487e6cc18abb01d522b7848423350aaa59332bc"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('gam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
